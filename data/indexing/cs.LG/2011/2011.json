[{"id": "2011.00003", "submitter": "Zoe de Beurs", "authors": "Zoe L. de Beurs, Andrew Vanderburg, Christopher J. Shallue, Xavier\n  Dumusque, Andrew Collier Cameron, Lars A. Buchhave, Rosario Cosentino,\n  Adriano Ghedina, Rapha\\\"elle D. Haywood, Nicholas Langellier, David W.\n  Latham, Mercedes L\\'opez-Morales, Michel Mayor, Giusi Micela, Timothy W.\n  Milbourne, Annelies Mortier, Emilio Molinari, Francesco Pepe, David F.\n  Phillips, Matteo Pinamonti, Giampaolo Piotto, Ken Rice, Dimitar Sasselov,\n  Alessandro Sozzetti, St\\'ephane Udry, Christopher A. Watson", "title": "Identifying Exoplanets with Deep Learning. IV. Removing Stellar Activity\n  Signals from Radial Velocity Measurements Using Neural Networks", "comments": "26 pages, 12 figures, Submitted to the Astronomical Journal, v2 fixes\n  some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP astro-ph.IM astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exoplanet detection with precise radial velocity (RV) observations is\ncurrently limited by spurious RV signals introduced by stellar activity. We\nshow that machine learning techniques such as linear regression and neural\nnetworks can effectively remove the activity signals (due to starspots/faculae)\nfrom RV observations. Previous efforts focused on carefully filtering out\nactivity signals in time using modeling techniques like Gaussian Process\nregression (e.g. Haywood et al. 2014). Instead, we systematically remove\nactivity signals using only changes to the average shape of spectral lines, and\nno information about when the observations were collected. We trained our\nmachine learning models on both simulated data (generated with the SOAP 2.0\nsoftware; Dumusque et al. 2014) and observations of the Sun from the HARPS-N\nSolar Telescope (Dumusque et al. 2015; Phillips et al. 2016; Collier Cameron et\nal. 2019). We find that these techniques can predict and remove stellar\nactivity from both simulated data (improving RV scatter from 82 cm/s to 3 cm/s)\nand from more than 600 real observations taken nearly daily over three years\nwith the HARPS-N Solar Telescope (improving the RV scatter from 1.47 m/s to\n0.78 m/s, a factor of ~ 1.9 improvement). In the future, these or similar\ntechniques could remove activity signals from observations of stars outside our\nsolar system and eventually help detect habitable-zone Earth-mass exoplanets\naround Sun-like stars.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:00:00 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:15:56 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["de Beurs", "Zoe L.", ""], ["Vanderburg", "Andrew", ""], ["Shallue", "Christopher J.", ""], ["Dumusque", "Xavier", ""], ["Cameron", "Andrew Collier", ""], ["Buchhave", "Lars A.", ""], ["Cosentino", "Rosario", ""], ["Ghedina", "Adriano", ""], ["Haywood", "Rapha\u00eblle D.", ""], ["Langellier", "Nicholas", ""], ["Latham", "David W.", ""], ["L\u00f3pez-Morales", "Mercedes", ""], ["Mayor", "Michel", ""], ["Micela", "Giusi", ""], ["Milbourne", "Timothy W.", ""], ["Mortier", "Annelies", ""], ["Molinari", "Emilio", ""], ["Pepe", "Francesco", ""], ["Phillips", "David F.", ""], ["Pinamonti", "Matteo", ""], ["Piotto", "Giampaolo", ""], ["Rice", "Ken", ""], ["Sasselov", "Dimitar", ""], ["Sozzetti", "Alessandro", ""], ["Udry", "St\u00e9phane", ""], ["Watson", "Christopher A.", ""]]}, {"id": "2011.00027", "submitter": "David Sutter", "authors": "Amira Abbas, David Sutter, Christa Zoufal, Aur\\'elien Lucchi, Alessio\n  Figalli, Stefan Woerner", "title": "The power of quantum neural networks", "comments": "25 pages, 10 figures", "journal-ref": "Nat Comput Sci 1, 403-409 (2021)", "doi": "10.1038/s43588-021-00084-1", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault-tolerant quantum computers offer the promise of dramatically improving\nmachine learning through speed-ups in computation or improved model\nscalability. In the near-term, however, the benefits of quantum machine\nlearning are not so clear. Understanding expressibility and trainability of\nquantum models-and quantum neural networks in particular-requires further\ninvestigation. In this work, we use tools from information geometry to define a\nnotion of expressibility for quantum and classical models. The effective\ndimension, which depends on the Fisher information, is used to prove a novel\ngeneralisation bound and establish a robust measure of expressibility. We show\nthat quantum neural networks are able to achieve a significantly better\neffective dimension than comparable classical neural networks. To then assess\nthe trainability of quantum models, we connect the Fisher information spectrum\nto barren plateaus, the problem of vanishing gradients. Importantly, certain\nquantum neural networks can show resilience to this phenomenon and train faster\nthan classical models due to their favourable optimisation landscapes, captured\nby a more evenly spread Fisher information spectrum. Our work is the first to\ndemonstrate that well-designed quantum neural networks offer an advantage over\nclassical neural networks through a higher effective dimension and faster\ntraining ability, which we verify on real quantum hardware.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:13:32 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Abbas", "Amira", ""], ["Sutter", "David", ""], ["Zoufal", "Christa", ""], ["Lucchi", "Aur\u00e9lien", ""], ["Figalli", "Alessio", ""], ["Woerner", "Stefan", ""]]}, {"id": "2011.00041", "submitter": "Mouloud Belbahri", "authors": "Belbahri Mouloud, Gandouet Olivier, Kazma Ghaith", "title": "Adapting Neural Networks for Uplift Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift is a particular case of individual treatment effect modeling. Such\nmodels deal with cause-and-effect inference for a specific factor, such as a\nmarketing intervention. In practice, these models are built on customer data\nwho purchased products or services to improve product marketing. Uplift is\nestimated using either i) conditional mean regression or ii) transformed\noutcome regression. Most existing approaches are adaptations of classification\nand regression trees for the uplift case. However, in practice, these\nconventional approaches are prone to overfitting. Here we propose a new method\nusing neural networks. This representation allows to jointly optimize the\ndifference in conditional means and the transformed outcome losses. As a\nconsequence, the model not only estimates the uplift, but also ensures\nconsistency in predicting the outcome. We focus on fully randomized\nexperiments, which is the case of our data. We show our proposed method\nimproves the state-of-the-art on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:42:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mouloud", "Belbahri", ""], ["Olivier", "Gandouet", ""], ["Ghaith", "Kazma", ""]]}, {"id": "2011.00046", "submitter": "Edoardo Belli", "authors": "Edoardo Belli, Simone Vantini", "title": "Measure Inducing Classification and Regression Trees for Functional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tree-based algorithm for classification and regression problems\nin the context of functional data analysis, which allows to leverage\nrepresentation learning and multiple splitting rules at the node level,\nreducing generalization error while retaining the interpretability of a tree.\nThis is achieved by learning a weighted functional $L^{2}$ space by means of\nconstrained convex optimization, which is then used to extract multiple\nweighted integral features from the input functions, in order to determine the\nbinary split for each internal node of the tree. The approach is designed to\nmanage multiple functional inputs and/or outputs, by defining suitable\nsplitting rules and loss functions that can depend on the specific problem and\ncan also be combined with scalar and categorical data, as the tree is grown\nwith the original greedy CART algorithm. We focus on the case of scalar-valued\nfunctional inputs defined on unidimensional domains and illustrate the\neffectiveness of our method in both classification and regression tasks,\nthrough a simulation study and four real world applications.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:49:53 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Belli", "Edoardo", ""], ["Vantini", "Simone", ""]]}, {"id": "2011.00050", "submitter": "Timothy Nguyen", "authors": "Timothy Nguyen, Zhourong Chen, Jaehoon Lee", "title": "Dataset Meta-Learning from Kernel Ridge-Regression", "comments": "Accepted to ICLR 2021. Open source implementation:\n  https://colab.sandbox.google.com/github/google-research/google-research/blob/master/kip/KIP.ipynb", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most fundamental aspects of any machine learning algorithm is the\ntraining data used by the algorithm. We introduce the novel concept of\n$\\epsilon$-approximation of datasets, obtaining datasets which are much smaller\nthan or are significant corruptions of the original training data while\nmaintaining similar model performance. We introduce a meta-learning algorithm\ncalled Kernel Inducing Points (KIP) for obtaining such remarkable datasets,\ninspired by the recent developments in the correspondence between\ninfinitely-wide neural networks and kernel ridge-regression (KRR). For KRR\ntasks, we demonstrate that KIP can compress datasets by one or two orders of\nmagnitude, significantly improving previous dataset distillation and subset\nselection methods while obtaining state of the art results for MNIST and\nCIFAR-10 classification. Furthermore, our KIP-learned datasets are transferable\nto the training of finite-width neural networks even beyond the lazy-training\nregime, which leads to state of the art results for neural network dataset\ndistillation with potential applications to privacy-preservation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:54:04 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 16:52:32 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 19:15:46 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Nguyen", "Timothy", ""], ["Chen", "Zhourong", ""], ["Lee", "Jaehoon", ""]]}, {"id": "2011.00071", "submitter": "Arissa Wongpanich", "authors": "Arissa Wongpanich, Hieu Pham, James Demmel, Mingxing Tan, Quoc Le,\n  Yang You, Sameer Kumar", "title": "Training EfficientNets at Supercomputer Scale: 83% ImageNet Top-1\n  Accuracy in One Hour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EfficientNets are a family of state-of-the-art image classification models\nbased on efficiently scaled convolutional neural networks. Currently,\nEfficientNets can take on the order of days to train; for example, training an\nEfficientNet-B0 model takes 23 hours on a Cloud TPU v2-8 node. In this paper,\nwe explore techniques to scale up the training of EfficientNets on TPU-v3 Pods\nwith 2048 cores, motivated by speedups that can be achieved when training at\nsuch scales. We discuss optimizations required to scale training to a batch\nsize of 65536 on 1024 TPU-v3 cores, such as selecting large batch optimizers\nand learning rate schedules as well as utilizing distributed evaluation and\nbatch normalization techniques. Additionally, we present timing and performance\nbenchmarks for EfficientNet models trained on the ImageNet dataset in order to\nanalyze the behavior of EfficientNets at scale. With our optimizations, we are\nable to train EfficientNet on ImageNet to an accuracy of 83% in 1 hour and 4\nminutes.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 19:27:11 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 02:17:22 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Wongpanich", "Arissa", ""], ["Pham", "Hieu", ""], ["Demmel", "James", ""], ["Tan", "Mingxing", ""], ["Le", "Quoc", ""], ["You", "Yang", ""], ["Kumar", "Sameer", ""]]}, {"id": "2011.00073", "submitter": "Mohamad Nasr-Azadani", "authors": "Yao Yang, Andrew Nam, Mohamad M. Nasr-Azadani, Teresa Tung", "title": "Resource-Aware Pareto-Optimal Automated Machine Learning Platform", "comments": "Accepted for International Seminar on Research of Information\n  Technology and Intelligent Systems (ISRITI), IEEE. December 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we introduce a novel platform Resource-Aware AutoML\n(RA-AutoML) which enables flexible and generalized algorithms to build machine\nlearning models subjected to multiple objectives, as well as resource and\nhard-ware constraints. RA-AutoML intelligently conducts Hyper-Parameter\nSearch(HPS) as well as Neural Architecture Search (NAS) to build models\noptimizing predefined objectives. RA-AutoML is a versatile framework that\nallows user to prescribe many resource/hardware constraints along with\nobjectives demanded by the problem at hand or business requirements. At its\ncore, RA-AutoML relies on our in-house search-engine algorithm,MOBOGA, which\ncombines a modified constraint-aware Bayesian Optimization and Genetic\nAlgorithm to construct Pareto optimal candidates. Our experiments on CIFAR-10\ndataset shows very good accuracy compared to results obtained by state-of-art\nneural network models, while subjected to resource constraints in the form of\nmodel size.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 19:37:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yang", "Yao", ""], ["Nam", "Andrew", ""], ["Nasr-Azadani", "Mohamad M.", ""], ["Tung", "Teresa", ""]]}, {"id": "2011.00080", "submitter": "John Lalor", "authors": "John P. Lalor and Hong Yu", "title": "Dynamic Data Selection for Curriculum Learning via Ability Estimation", "comments": "Findings of EMNLP 2020, presented at CoNLL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Curriculum learning methods typically rely on heuristics to estimate the\ndifficulty of training examples or the ability of the model. In this work, we\npropose replacing difficulty heuristics with learned difficulty parameters. We\nalso propose Dynamic Data selection for Curriculum Learning via Ability\nEstimation (DDaCLAE), a strategy that probes model ability at each training\nepoch to select the best training examples at that point. We show that models\nusing learned difficulty and/or ability outperform heuristic-based curriculum\nlearning models on the GLUE classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:01:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lalor", "John P.", ""], ["Yu", "Hong", ""]]}, {"id": "2011.00083", "submitter": "Ziteng Sun", "authors": "Jayadev Acharya, Peter Kairouz, Yuhan Liu, Ziteng Sun", "title": "Estimating Sparse Discrete Distributions Under Local Privacy and\n  Communication Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DS cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating sparse discrete distributions under\nlocal differential privacy (LDP) and communication constraints. We characterize\nthe sample complexity for sparse estimation under LDP constraints up to a\nconstant factor and the sample complexity under communication constraints up to\na logarithmic factor. Our upper bounds under LDP are based on the Hadamard\nResponse, a private coin scheme that requires only one bit of communication per\nuser. Under communication constraints, we propose public coin schemes based on\nrandom hashing functions. Our tight lower bounds are based on the recently\nproposed method of chi squared contractions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:06:35 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 19:48:16 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 04:06:00 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Acharya", "Jayadev", ""], ["Kairouz", "Peter", ""], ["Liu", "Yuhan", ""], ["Sun", "Ziteng", ""]]}, {"id": "2011.00093", "submitter": "Chaitanya Talnikar", "authors": "Chaitanya Talnikar, Tatiana Likhomanenko, Ronan Collobert, Gabriel\n  Synnaeve", "title": "Joint Masked CPC and CTC Training for ASR", "comments": "ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning (SSL) has shown promise in learning representations\nof audio that are useful for automatic speech recognition (ASR). But, training\nSSL models like wav2vec~2.0 requires a two-stage pipeline. In this paper we\ndemonstrate a single-stage training of ASR models that can utilize both\nunlabeled and labeled data. During training, we alternately minimize two\nlosses: an unsupervised masked Contrastive Predictive Coding (CPC) loss and the\nsupervised audio-to-text alignment loss Connectionist Temporal Classification\n(CTC). We show that this joint training method directly optimizes performance\nfor the downstream ASR task using unsupervised data while achieving similar\nword error rates to wav2vec~2.0 on the Librispeech 100-hour dataset. Finally,\nwe postulate that solving the contrastive task is a regularization for the\nsupervised CTC loss.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:28:20 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 18:59:35 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Talnikar", "Chaitanya", ""], ["Likhomanenko", "Tatiana", ""], ["Collobert", "Ronan", ""], ["Synnaeve", "Gabriel", ""]]}, {"id": "2011.00094", "submitter": "Yuan Chen", "authors": "Yuan Chen, Donglin Zeng, Tianchen Xu, Yuanjia Wang", "title": "Representation Learning for Integrating Multi-domain Outcomes to\n  Optimize Individualized Treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For mental disorders, patients' underlying mental states are non-observed\nlatent constructs which have to be inferred from observed multi-domain\nmeasurements such as diagnostic symptoms and patient functioning scores.\nAdditionally, substantial heterogeneity in the disease diagnosis between\npatients needs to be addressed for optimizing individualized treatment policy\nin order to achieve precision medicine. To address these challenges, we propose\nan integrated learning framework that can simultaneously learn patients'\nunderlying mental states and recommend optimal treatments for each individual.\nThis learning framework is based on the measurement theory in psychiatry for\nmodeling multiple disease diagnostic measures as arising from the underlying\ncauses (true mental states). It allows incorporation of the multivariate pre-\nand post-treatment outcomes as well as biological measures while preserving the\ninvariant structure for representing patients' latent mental states. A\nmulti-layer neural network is used to allow complex treatment effect\nheterogeneity. Optimal treatment policy can be inferred for future patients by\ncomparing their potential mental states under different treatments given the\nobserved multi-domain pre-treatment measurements. Experiments on simulated data\nand a real-world clinical trial data show that the learned treatment polices\ncompare favorably to alternative methods on heterogeneous treatment effects,\nand have broad utilities which lead to better patient outcomes on multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:30:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Chen", "Yuan", ""], ["Zeng", "Donglin", ""], ["Xu", "Tianchen", ""], ["Wang", "Yuanjia", ""]]}, {"id": "2011.00101", "submitter": "Dongrui Wu", "authors": "Lubin Meng, Jian Huang, Zhigang Zeng, Xue Jiang, Shan Yu, Tzyy-Ping\n  Jung, Chin-Teng Lin, Ricardo Chavarriaga, Dongrui Wu", "title": "EEG-Based Brain-Computer Interfaces Are Vulnerable to Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research and development of electroencephalogram (EEG) based brain-computer\ninterfaces (BCIs) have advanced rapidly, partly due to deeper understanding of\nthe brain and wide adoption of sophisticated machine learning approaches for\ndecoding the EEG signals. However, recent studies have shown that machine\nlearning algorithms are vulnerable to adversarial attacks. This article\nproposes to use narrow period pulse for poisoning attack of EEG-based BCIs,\nwhich is implementable in practice and has never been considered before. One\ncan create dangerous backdoors in the machine learning model by injecting\npoisoning samples into the training set. Test samples with the backdoor key\nwill then be classified into the target class specified by the attacker. What\nmost distinguishes our approach from previous ones is that the backdoor key\ndoes not need to be synchronized with the EEG trials, making it very easy to\nimplement. The effectiveness and robustness of the backdoor attack approach is\ndemonstrated, highlighting a critical security concern for EEG-based BCIs and\ncalling for urgent attention to address it.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:49:42 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 23:16:26 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Meng", "Lubin", ""], ["Huang", "Jian", ""], ["Zeng", "Zhigang", ""], ["Jiang", "Xue", ""], ["Yu", "Shan", ""], ["Jung", "Tzyy-Ping", ""], ["Lin", "Chin-Teng", ""], ["Chavarriaga", "Ricardo", ""], ["Wu", "Dongrui", ""]]}, {"id": "2011.00109", "submitter": "Houcemeddine Turki", "authors": "Houcemeddine Turki, Mohamed Ali Hadj Taieb, Mohamed Ben Aouicha", "title": "Semantic similarity-based approach to enhance supervised classification\n  learning accuracy", "comments": "Sent for review to Journal of the Association for Information Science\n  and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This brief communication discusses the usefulness of semantic similarity\nmeasures for the evaluation and amelioration of the accuracy of supervised\nclassification learning. It proposes a semantic similarity-based method to\nenhance the choice of adequate labels for the classification algorithm as well\nas two metrics (SS-Score and TD-Score) and a curve (SA-Curve) that can be\ncoupled to statistical evaluation measures of supervised classification\nlearning to take into consideration the impact of the semantic aspect of the\nlabels on the classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 21:18:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Turki", "Houcemeddine", ""], ["Taieb", "Mohamed Ali Hadj", ""], ["Aouicha", "Mohamed Ben", ""]]}, {"id": "2011.00120", "submitter": "Eugene Vinitsky", "authors": "Eugene Vinitsky, Nathan Lichtle, Kanaad Parvate, Alexandre Bayen", "title": "Optimizing Mixed Autonomy Traffic Flow With Decentralized Autonomous\n  Vehicles and Multi-Agent RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.MA cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the ability of autonomous vehicles to improve the throughput of a\nbottleneck using a fully decentralized control scheme in a mixed autonomy\nsetting. We consider the problem of improving the throughput of a scaled model\nof the San Francisco-Oakland Bay Bridge: a two-stage bottleneck where four\nlanes reduce to two and then reduce to one. Although there is extensive work\nexamining variants of bottleneck control in a centralized setting, there is\nless study of the challenging multi-agent setting where the large number of\ninteracting AVs leads to significant optimization difficulties for\nreinforcement learning methods. We apply multi-agent reinforcement algorithms\nto this problem and demonstrate that significant improvements in bottleneck\nthroughput, from 20\\% at a 5\\% penetration rate to 33\\% at a 40\\% penetration\nrate, can be achieved. We compare our results to a hand-designed feedback\ncontroller and demonstrate that our results sharply outperform the feedback\ncontroller despite extensive tuning. Additionally, we demonstrate that the\nRL-based controllers adopt a robust strategy that works across penetration\nrates whereas the feedback controllers degrade immediately upon penetration\nrate variation. We investigate the feasibility of both action and observation\ndecentralization and demonstrate that effective strategies are possible using\npurely local sensing. Finally, we open-source our code at\nhttps://github.com/eugenevinitsky/decentralized_bottlenecks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 22:06:05 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Vinitsky", "Eugene", ""], ["Lichtle", "Nathan", ""], ["Parvate", "Kanaad", ""], ["Bayen", "Alexandre", ""]]}, {"id": "2011.00136", "submitter": "Nathan Ng", "authors": "Nathan Ng and Marzyeh Ghassemi and Narendran Thangarajan and Jiacheng\n  Pan and Qi Guo", "title": "Improving Dialogue Breakdown Detection with Semi-Supervised Learning", "comments": "6 pages, 1 figure, accepted at the NeurIPS Workshop on Human in the\n  Loop Dialogue Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building user trust in dialogue agents requires smooth and consistent\ndialogue exchanges. However, agents can easily lose conversational context and\ngenerate irrelevant utterances. These situations are called dialogue breakdown,\nwhere agent utterances prevent users from continuing the conversation. Building\nsystems to detect dialogue breakdown allows agents to recover appropriately or\navoid breakdown entirely. In this paper we investigate the use of\nsemi-supervised learning methods to improve dialogue breakdown detection,\nincluding continued pre-training on the Reddit dataset and a manifold-based\ndata augmentation method. We demonstrate the effectiveness of these methods on\nthe Dialogue Breakdown Detection Challenge (DBDC) English shared task. Our\nsubmissions to the 2020 DBDC5 shared task place first, beating baselines and\nother submissions by over 12\\% accuracy. In ablations on DBDC4 data from 2019,\nour semi-supervised learning methods improve the performance of a baseline BERT\nmodel by 2\\% accuracy. These methods are applicable generally to any dialogue\ntask and provide a simple way to improve model performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 23:04:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ng", "Nathan", ""], ["Ghassemi", "Marzyeh", ""], ["Thangarajan", "Narendran", ""], ["Pan", "Jiacheng", ""], ["Guo", "Qi", ""]]}, {"id": "2011.00144", "submitter": "Samarth Gupta", "authors": "Samarth Gupta, Saurabh Amin", "title": "Integer Programming-based Error-Correcting Output Code Design for Robust\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error-Correcting Output Codes (ECOCs) offer a principled approach for\ncombining simple binary classifiers into multiclass classifiers. In this paper,\nwe investigate the problem of designing optimal ECOCs to achieve both nominal\nand adversarial accuracy using Support Vector Machines (SVMs) and binary deep\nlearning models. In contrast to previous literature, we present an Integer\nProgramming (IP) formulation to design minimal codebooks with desirable error\ncorrecting properties. Our work leverages the advances in IP solvers to\ngenerate codebooks with optimality guarantees. To achieve tractability, we\nexploit the underlying graph-theoretic structure of the constraint set in our\nIP formulation. This enables us to use edge clique covers to substantially\nreduce the constraint set. Our codebooks achieve a high nominal accuracy\nrelative to standard codebooks (e.g., one-vs-all, one-vs-one, and dense/sparse\ncodes). We also estimate the adversarial accuracy of our ECOC-based classifiers\nin a white-box setting. Our IP-generated codebooks provide non-trivial\nrobustness to adversarial perturbations even without any adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 23:35:18 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Gupta", "Samarth", ""], ["Amin", "Saurabh", ""]]}, {"id": "2011.00155", "submitter": "Kei Ota", "authors": "Kei Ota, Devesh K. Jha, Tadashi Onishi, Asako Kanezaki, Yusuke\n  Yoshiyasu, Yoko Sasaki, Toshisada Mariyama, Daniel Nikovski", "title": "Deep Reactive Planning in Dynamic Environments", "comments": "15 pages, 5 figures. Accepted at CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main novelty of the proposed approach is that it allows a robot to learn\nan end-to-end policy which can adapt to changes in the environment during\nexecution. While goal conditioning of policies has been studied in the RL\nliterature, such approaches are not easily extended to cases where the robot's\ngoal can change during execution. This is something that humans are naturally\nable to do. However, it is difficult for robots to learn such reflexes (i.e.,\nto naturally respond to dynamic environments), especially when the goal\nlocation is not explicitly provided to the robot, and instead needs to be\nperceived through a vision sensor. In the current work, we present a method\nthat can achieve such behavior by combining traditional kinematic planning,\ndeep learning, and deep reinforcement learning in a synergistic fashion to\ngeneralize to arbitrary environments. We demonstrate the proposed approach for\nseveral reaching and pick-and-place tasks in simulation, as well as on a real\nsystem of a 6-DoF industrial manipulator. A video describing our work could be\nfound \\url{https://youtu.be/hE-Ew59GRPQ}.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 00:46:13 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 21:31:44 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Ota", "Kei", ""], ["Jha", "Devesh K.", ""], ["Onishi", "Tadashi", ""], ["Kanezaki", "Asako", ""], ["Yoshiyasu", "Yusuke", ""], ["Sasaki", "Yoko", ""], ["Mariyama", "Toshisada", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2011.00159", "submitter": "Xiaowu Dai", "authors": "Xiaowu Dai and Michael I. Jordan", "title": "Learning Strategies in Decentralized Matching Markets under Uncertain\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two-sided decentralized matching markets in which participants have\nuncertain preferences. We present a statistical model to learn the preferences.\nThe model incorporates uncertain state and the participants' competition on one\nside of the market. We derive an optimal strategy that maximizes the agent's\nexpected payoff and calibrate the uncertain state by taking the opportunity\ncosts into account. We discuss the sense in which the matching derived from the\nproposed strategy has a stability property. We also prove a fairness property\nthat asserts that there exists no justified envy according to the proposed\nstrategy. We provide numerical results to demonstrate the improved payoff,\nstability and fairness, compared to alternative methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 03:08:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Dai", "Xiaowu", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.00160", "submitter": "Gustavo Zanoni Felipe", "authors": "Gustavo Z. Felipe, Jacqueline N. Zanoni, Camila C.\n  Sehaber-Sierakowski, Gleison D. P. Bossolani, Sara R. G. Souza, Franklin C.\n  Flores, Luiz E. S. Oliveira, Rodolfo M. Pereira, Yandre M. G. Costa", "title": "Automatic Chronic Degenerative Diseases Identification Using Enteric\n  Nervous System Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies recently accomplished on the Enteric Nervous System have shown that\nchronic degenerative diseases affect the Enteric Glial Cells (EGC) and, thus,\nthe development of recognition methods able to identify whether or not the EGC\nare affected by these type of diseases may be helpful in its diagnoses. In this\nwork, we propose the use of pattern recognition and machine learning techniques\nto evaluate if a given animal EGC image was obtained from a healthy individual\nor one affect by a chronic degenerative disease. In the proposed approach, we\nhave performed the classification task with handcrafted features and deep\nlearning based techniques, also known as non-handcrafted features. The\nhandcrafted features were obtained from the textural content of the ECG images\nusing texture descriptors, such as the Local Binary Pattern (LBP). Moreover,\nthe representation learning techniques employed in the approach are based on\ndifferent Convolutional Neural Network (CNN) architectures, such as AlexNet and\nVGG16, with and without transfer learning. The complementarity between the\nhandcrafted and non-handcrafted features was also evaluated with late fusion\ntechniques. The datasets of EGC images used in the experiments, which are also\ncontributions of this paper, are composed of three different chronic\ndegenerative diseases: Cancer, Diabetes Mellitus, and Rheumatoid Arthritis. The\nexperimental results, supported by statistical analysis, shown that the\nproposed approach can distinguish healthy cells from the sick ones with a\nrecognition rate of 89.30% (Rheumatoid Arthritis), 98.45% (Cancer), and 95.13%\n(Diabetes Mellitus), being achieved by combining classifiers obtained both\nfeature scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 01:04:46 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Felipe", "Gustavo Z.", ""], ["Zanoni", "Jacqueline N.", ""], ["Sehaber-Sierakowski", "Camila C.", ""], ["Bossolani", "Gleison D. P.", ""], ["Souza", "Sara R. G.", ""], ["Flores", "Franklin C.", ""], ["Oliveira", "Luiz E. S.", ""], ["Pereira", "Rodolfo M.", ""], ["Costa", "Yandre M. G.", ""]]}, {"id": "2011.00164", "submitter": "Fanhua Shang", "authors": "Tao Xu, Fanhua Shang, Yuanyuan Liu, Hongying Liu, Longjie Shen, Maoguo\n  Gong", "title": "Differentially Private ADMM Algorithms for Machine Learning", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study efficient differentially private alternating\ndirection methods of multipliers (ADMM) via gradient perturbation for many\nmachine learning problems. For smooth convex loss functions with (non)-smooth\nregularization, we propose the first differentially private ADMM (DP-ADMM)\nalgorithm with performance guarantee of $(\\epsilon,\\delta)$-differential\nprivacy ($(\\epsilon,\\delta)$-DP). From the viewpoint of theoretical analysis,\nwe use the Gaussian mechanism and the conversion relationship between R\\'enyi\nDifferential Privacy (RDP) and DP to perform a comprehensive privacy analysis\nfor our algorithm. Then we establish a new criterion to prove the convergence\nof the proposed algorithms including DP-ADMM. We also give the utility analysis\nof our DP-ADMM. Moreover, we propose an accelerated DP-ADMM (DP-AccADMM) with\nthe Nesterov's acceleration technique. Finally, we conduct numerical\nexperiments on many real-world datasets to show the privacy-utility tradeoff of\nthe two proposed algorithms, and all the comparative analysis shows that\nDP-AccADMM converges faster and has a better utility than DP-ADMM, when the\nprivacy budget $\\epsilon$ is larger than a threshold.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 01:37:24 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xu", "Tao", ""], ["Shang", "Fanhua", ""], ["Liu", "Yuanyuan", ""], ["Liu", "Hongying", ""], ["Shen", "Longjie", ""], ["Gong", "Maoguo", ""]]}, {"id": "2011.00165", "submitter": "Esmaeil Seraj", "authors": "Esmaeil Seraj, Xiyang Wu, Matthew Gombolay", "title": "FireCommander: An Interactive, Probabilistic Multi-agent Environment for\n  Joint Perception-Action Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this tutorial is to help individuals use the\n\\underline{FireCommander} game environment for research applications. The\nFireCommander is an interactive, probabilistic joint perception-action\nreconnaissance environment in which a composite team of agents (e.g., robots)\ncooperate to fight dynamic, propagating firespots (e.g., targets). In\nFireCommander game, a team of agents must be tasked to optimally deal with a\nwildfire situation in an environment with propagating fire areas and some\nfacilities such as houses, hospitals, power stations, etc. The team of agents\ncan accomplish their mission by first sensing (e.g., estimating fire states),\ncommunicating the sensed fire-information among each other and then taking\naction to put the firespots out based on the sensed information (e.g., dropping\nwater on estimated fire locations). The FireCommander environment can be useful\nfor research topics spanning a wide range of applications from Reinforcement\nLearning (RL) and Learning from Demonstration (LfD), to Coordination,\nPsychology, Human-Robot Interaction (HRI) and Teaming. There are four important\nfacets of the FireCommander environment that overall, create a non-trivial\ngame: (1) Complex Objectives: Multi-objective Stochastic Environment,\n(2)Probabilistic Environment: Agents' actions result in probabilistic\nperformance, (3) Hidden Targets: Partially Observable Environment and, (4)\nUni-task Robots: Perception-only and Action-only agents. The FireCommander\nenvironment is first-of-its-kind in terms of including Perception-only and\nAction-only agents for coordination. It is a general multi-purpose game that\ncan be useful in a variety of combinatorial optimization problems and\nstochastic games, such as applications of Reinforcement Learning (RL), Learning\nfrom Demonstration (LfD) and Inverse RL (iRL).\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 02:06:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Seraj", "Esmaeil", ""], ["Wu", "Xiyang", ""], ["Gombolay", "Matthew", ""]]}, {"id": "2011.00168", "submitter": "Aniruddha Tamhane", "authors": "Aniruddha Tamhane, Jie Ying Wu, Mathias Unberath", "title": "Multimodal and self-supervised representation learning for automatic\n  gesture recognition in surgical robotics", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised, multi-modal learning has been successful in holistic\nrepresentation of complex scenarios. This can be useful to consolidate\ninformation from multiple modalities which have multiple, versatile uses. Its\napplication in surgical robotics can lead to simultaneously developing a\ngeneralised machine understanding of the surgical process and reduce the\ndependency on quality, expert annotations which are generally difficult to\nobtain. We develop a self-supervised, multi-modal representation learning\nparadigm that learns representations for surgical gestures from video and\nkinematics. We use an encoder-decoder network configuration that encodes\nrepresentations from surgical videos and decodes them to yield kinematics. We\nquantitatively demonstrate the efficacy of our learnt representations for\ngesture recognition (with accuracy between 69.6 % and 77.8 %), transfer\nlearning across multiple tasks (with accuracy between 44.6 % and 64.8 %) and\nsurgeon skill classification (with accuracy between 76.8 % and 81.2 %).\nFurther, we qualitatively demonstrate that our self-supervised representations\ncluster in semantically meaningful properties (surgeon skill and gestures).\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 02:20:32 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Tamhane", "Aniruddha", ""], ["Wu", "Jie Ying", ""], ["Unberath", "Mathias", ""]]}, {"id": "2011.00177", "submitter": "Maoqiang Wu", "authors": "Maoqiang Wu, Xinyue Zhang, Jiahao Ding, Hien Nguyen, Rong Yu, Miao\n  Pan, Stephen T. Wong", "title": "Evaluation of Inference Attack Models for Deep Learning on Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has attracted broad interest in healthcare and medical\ncommunities. However, there has been little research into the privacy issues\ncreated by deep networks trained for medical applications. Recently developed\ninference attack algorithms indicate that images and text records can be\nreconstructed by malicious parties that have the ability to query deep\nnetworks. This gives rise to the concern that medical images and electronic\nhealth records containing sensitive patient information are vulnerable to these\nattacks. This paper aims to attract interest from researchers in the medical\ndeep learning community to this important problem. We evaluate two prominent\ninference attack models, namely, attribute inference attack and model inversion\nattack. We show that they can reconstruct real-world medical images and\nclinical reports with high fidelity. We then investigate how to protect\npatients' privacy using defense mechanisms, such as label perturbation and\nmodel perturbation. We provide a comparison of attack results between the\noriginal and the medical deep learning models with defenses. The experimental\nevaluations show that our proposed defense approaches can effectively reduce\nthe potential privacy leakage of medical deep learning from the inference\nattacks.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 03:18:36 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wu", "Maoqiang", ""], ["Zhang", "Xinyue", ""], ["Ding", "Jiahao", ""], ["Nguyen", "Hien", ""], ["Yu", "Rong", ""], ["Pan", "Miao", ""], ["Wong", "Stephen T.", ""]]}, {"id": "2011.00178", "submitter": "Guangyao Chen", "authors": "Guangyao Chen, Limeng Qiao, Yemin Shi, Peixi Peng, Jia Li, Tiejun\n  Huang, Shiliang Pu, Yonghong Tian", "title": "Learning Open Set Network with Discriminative Reciprocal Points", "comments": "ECCV 2020 (spotlight)", "journal-ref": "ECCV 2020", "doi": "10.1007/978-3-030-58580-8_30", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open set recognition is an emerging research area that aims to simultaneously\nclassify samples from predefined classes and identify the rest as 'unknown'. In\nthis process, one of the key challenges is to reduce the risk of generalizing\nthe inherent characteristics of numerous unknown samples learned from a small\namount of known data. In this paper, we propose a new concept, Reciprocal\nPoint, which is the potential representation of the extra-class space\ncorresponding to each known category. The sample can be classified to known or\nunknown by the otherness with reciprocal points. To tackle the open set\nproblem, we offer a novel open space risk regularization term. Based on the\nbounded space constructed by reciprocal points, the risk of unknown is reduced\nthrough multi-category interaction. The novel learning framework called\nReciprocal Point Learning (RPL), which can indirectly introduce the unknown\ninformation into the learner with only known classes, so as to learn more\ncompact and discriminative representations. Moreover, we further construct a\nnew large-scale challenging aircraft dataset for open set recognition: Aircraft\n300 (Air-300). Extensive experiments on multiple benchmark datasets indicate\nthat our framework is significantly superior to other existing approaches and\nachieves state-of-the-art performance on standard open set benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 03:20:31 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Chen", "Guangyao", ""], ["Qiao", "Limeng", ""], ["Shi", "Yemin", ""], ["Peng", "Peixi", ""], ["Li", "Jia", ""], ["Huang", "Tiejun", ""], ["Pu", "Shiliang", ""], ["Tian", "Yonghong", ""]]}, {"id": "2011.00179", "submitter": "Shuman Peng", "authors": "Shuman Peng, Weilian Song, Martin Ester", "title": "Combining Domain-Specific Meta-Learners in the Parameter Space for\n  Cross-Domain Few-Shot Classification", "comments": "Code coming soon at https://github.com/shumanpng/CosML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of few-shot classification is to learn a model that can classify\nnovel classes using only a few training examples. Despite the promising results\nshown by existing meta-learning algorithms in solving the few-shot\nclassification problem, there still remains an important challenge: how to\ngeneralize to unseen domains while meta-learning on multiple seen domains? In\nthis paper, we propose an optimization-based meta-learning method, called\nCombining Domain-Specific Meta-Learners (CosML), that addresses the\ncross-domain few-shot classification problem. CosML first trains a set of\nmeta-learners, one for each training domain, to learn prior knowledge (i.e.,\nmeta-parameters) specific to each domain. The domain-specific meta-learners are\nthen combined in the \\emph{parameter space}, by taking a weighted average of\ntheir meta-parameters, which is used as the initialization parameters of a task\nnetwork that is quickly adapted to novel few-shot classification tasks in an\nunseen domain. Our experiments show that CosML outperforms a range of\nstate-of-the-art methods and achieves strong cross-domain generalization\nability.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 03:33:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Peng", "Shuman", ""], ["Song", "Weilian", ""], ["Ester", "Martin", ""]]}, {"id": "2011.00187", "submitter": "Bingxu Li", "authors": "Bingxu Li, Fanyong Cheng, Xin Zhang, Can Cui, Wenjian Cai", "title": "A Novel Semi-Supervised Data-Driven Method for Chiller Fault Diagnosis\n  with Unlabeled Data", "comments": null, "journal-ref": "Applied Energy, Volume 285, 2021, 116459", "doi": "10.1016/j.apenergy.2021.116459", "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical chiller systems, applying efficient fault diagnosis techniques\ncan significantly reduce energy consumption and improve energy efficiency of\nbuildings. The success of the existing methods for fault diagnosis of chillers\nrelies on the condition that sufficient labeled data are available for\ntraining. However, label acquisition is laborious and costly in practice.\nUsually, the number of labeled data is limited and most data available are\nunlabeled. The existing methods cannot exploit the information contained in\nunlabeled data, which significantly limits the improvement of fault diagnosis\nperformance in chiller systems. To make effective use of unlabeled data to\nfurther improve fault diagnosis performance and reduce the dependency on\nlabeled data, we proposed a novel semi-supervised data-driven fault diagnosis\nmethod for chiller systems based on the semi-generative adversarial network,\nwhich incorporates both unlabeled and labeled data into learning process. The\nsemi-generative adversarial network can learn the information of data\ndistribution from unlabeled data and this information can help to significantly\nimprove the diagnostic performance. Experimental results demonstrate the\neffectiveness of the proposed method. Under the scenario that there are only 80\nlabeled samples and 16000 unlabeled samples, the proposed method can improve\nthe diagnostic accuracy to 84%, while the supervised baseline methods only\nreach the accuracy of 65% at most. Besides, the minimal required number of\nlabeled samples can be reduced by about 60% with the proposed method when there\nare enough unlabeled samples.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 04:57:38 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Li", "Bingxu", ""], ["Cheng", "Fanyong", ""], ["Zhang", "Xin", ""], ["Cui", "Can", ""], ["Cai", "Wenjian", ""]]}, {"id": "2011.00194", "submitter": "Ali Lotfi Rezaabad", "authors": "Ali Lotfi Rezaabad, Rahi Kalantari, Sriram Vishwanath, Mingyuan Zhou,\n  Jonathan Tamir", "title": "Hyperbolic Graph Embedding with Enhanced Semi-Implicit Variational\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Efficient modeling of relational data arising in physical, social, and\ninformation sciences is challenging due to complicated dependencies within the\ndata. In this work, we build off of semi-implicit graph variational\nauto-encoders to capture higher-order statistics in a low-dimensional graph\nlatent representation. We incorporate hyperbolic geometry in the latent space\nthrough a Poincare embedding to efficiently represent graphs exhibiting\nhierarchical structure. To address the naive posterior latent distribution\nassumptions in classical variational inference, we use semi-implicit\nhierarchical variational Bayes to implicitly capture posteriors of given graph\ndata, which may exhibit heavy tails, multiple modes, skewness, and highly\ncorrelated latent structures. We show that the existing semi-implicit\nvariational inference objective provably reduces information in the observed\ngraph. Based on this observation, we estimate and add an additional mutual\ninformation term to the semi-implicit variational inference learning objective\nto capture rich correlations arising between the input and latent spaces. We\nshow that the inclusion of this regularization term in conjunction with the\nPoincare embedding boosts the quality of learned high-level representations and\nenables more flexible and faithful graphical modeling. We experimentally\ndemonstrate that our approach outperforms existing graph variational\nauto-encoders both in Euclidean and in hyperbolic spaces for edge link\nprediction and node classification.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 05:48:34 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 21:48:07 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Rezaabad", "Ali Lotfi", ""], ["Kalantari", "Rahi", ""], ["Vishwanath", "Sriram", ""], ["Zhou", "Mingyuan", ""], ["Tamir", "Jonathan", ""]]}, {"id": "2011.00196", "submitter": "Siddhartha Gairola", "authors": "Siddhartha Gairola, Francis Tom, Nipun Kwatra, Mohit Jain", "title": "RespireNet: A Deep Neural Network for Accurately Detecting Abnormal Lung\n  Sounds in Limited Data Setting", "comments": "Code visible at https://github.com/microsoft/RespireNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Auscultation of respiratory sounds is the primary tool for screening and\ndiagnosing lung diseases. Automated analysis, coupled with digital\nstethoscopes, can play a crucial role in enabling tele-screening of fatal lung\ndiseases. Deep neural networks (DNNs) have shown a lot of promise for such\nproblems, and are an obvious choice. However, DNNs are extremely data hungry,\nand the largest respiratory dataset ICBHI has only 6898 breathing cycles, which\nis still small for training a satisfactory DNN model. In this work, RespireNet,\nwe propose a simple CNN-based model, along with a suite of novel techniques --\ndevice specific fine-tuning, concatenation-based augmentation, blank region\nclipping, and smart padding -- enabling us to efficiently use the small-sized\ndataset. We perform extensive evaluation on the ICBHI dataset, and improve upon\nthe state-of-the-art results for 4-class classification by 2.2%\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 05:53:37 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 14:31:58 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Gairola", "Siddhartha", ""], ["Tom", "Francis", ""], ["Kwatra", "Nipun", ""], ["Jain", "Mohit", ""]]}, {"id": "2011.00209", "submitter": "Sungyong Baik", "authors": "Sungyong Baik, Myungsub Choi, Janghoon Choi, Heewon Kim, Kyoung Mu Lee", "title": "Meta-Learning with Adaptive Hyperparameters", "comments": "NeurIPS 2020. Code at https://github.com/baiksung/alfa. Typo fix in\n  the updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its popularity, several recent works question the effectiveness of\nMAML when test tasks are different from training tasks, thus suggesting various\ntask-conditioned methodology to improve the initialization. Instead of\nsearching for better task-aware initialization, we focus on a complementary\nfactor in MAML framework, inner-loop optimization (or fast adaptation).\nConsequently, we propose a new weight update rule that greatly enhances the\nfast adaptation process. Specifically, we introduce a small meta-network that\ncan adaptively generate per-step hyperparameters: learning rate and weight\ndecay coefficients. The experimental results validate that the Adaptive\nLearning of hyperparameters for Fast Adaptation (ALFA) is the equally important\ningredient that was often neglected in the recent few-shot learning approaches.\nSurprisingly, fast adaptation from random initialization with ALFA can already\noutperform MAML.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 08:05:34 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 06:53:01 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Baik", "Sungyong", ""], ["Choi", "Myungsub", ""], ["Choi", "Janghoon", ""], ["Kim", "Heewon", ""], ["Lee", "Kyoung Mu", ""]]}, {"id": "2011.00213", "submitter": "Wenhao Yang", "authors": "Wenhao Yang, Xiang Li, Guangzeng Xie, Zhihua Zhang", "title": "Finding the Near Optimal Policy via Adaptive Reduced Regularization in\n  MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularized MDPs serve as a smooth version of original MDPs. However, biased\noptimal policy always exists for regularized MDPs. Instead of making the\ncoefficient{\\lambda}of regularized term sufficiently small, we propose an\nadaptive reduction scheme for {\\lambda} to approximate optimal policy of the\noriginal MDP. It is shown that the iteration complexity for obtaining\nan{\\epsilon}-optimal policy could be reduced in comparison with setting\nsufficiently small{\\lambda}. In addition, there exists strong duality\nconnection between the reduction method and solving the original MDP directly,\nfrom which we can derive more adaptive reduction method for certain algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 08:31:34 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yang", "Wenhao", ""], ["Li", "Xiang", ""], ["Xie", "Guangzeng", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2011.00228", "submitter": "Ilia Sucholutsky", "authors": "Ilia Sucholutsky, Matthias Schonlau", "title": "Optimal 1-NN Prototypes for Pathological Geometries", "comments": "8 pages", "journal-ref": null, "doi": "10.7717/peerj-cs.464", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using prototype methods to reduce the size of training datasets can\ndrastically reduce the computational cost of classification with instance-based\nlearning algorithms like the k-Nearest Neighbour classifier. The number and\ndistribution of prototypes required for the classifier to match its original\nperformance is intimately related to the geometry of the training data. As a\nresult, it is often difficult to find the optimal prototypes for a given\ndataset, and heuristic algorithms are used instead. However, we consider a\nparticularly challenging setting where commonly used heuristic algorithms fail\nto find suitable prototypes and show that the optimal prototypes can instead be\nfound analytically. We also propose an algorithm for finding nearly-optimal\nprototypes in this setting, and use it to empirically validate the theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 10:15:08 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sucholutsky", "Ilia", ""], ["Schonlau", "Matthias", ""]]}, {"id": "2011.00241", "submitter": "Sunil Vadera", "authors": "Sunil Vadera and Salem Ameen", "title": "Methods for Pruning Deep Neural Networks", "comments": "Pre-Print version 1, prior to submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a survey of methods for pruning deep neural networks,\nfrom algorithms first proposed for fully connected networks in the 1990s to the\nrecent methods developed for reducing the size of convolutional neural\nnetworks. The paper begins by bringing together many different algorithms by\ncategorising them based on the underlying approach used. It then focuses on\nthree categories: methods that use magnitude-based pruning, methods that\nutilise clustering to identify redundancy, and methods that utilise sensitivity\nanalysis. Some of the key influencing studies within these categories are\npresented to illuminate the underlying approaches and results achieved.\n  Most studies on pruning present results from empirical evaluations, which are\ndistributed in the literature as new architectures, algorithms and data sets\nhave evolved with time. This paper brings together the reported results from\nsome key papers in one place by providing a resource that can be used to\nquickly compare reported results, and trace studies where specific methods,\ndata sets and architectures have been used.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 10:58:51 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Vadera", "Sunil", ""], ["Ameen", "Salem", ""]]}, {"id": "2011.00261", "submitter": "Cheng Fu Dr.", "authors": "Cheng Fu and Robert Weibel", "title": "Towards Measuring Place Function Similarity at Fine Spatial Granularity\n  with Trajectory Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling place functions from a computational perspective is a prevalent\nresearch topic. Trajectory embedding, as a neural-network-backed dimension\nreduction technology, allows the possibility to put places with similar social\nfunctions at close locations in the embedding space if the places share similar\nchronological context as part of a trajectory. The embedding similarity was\npreviously proposed as a new metric for measuring the similarity of place\nfunctions. This study explores if this approach is meaningful for geographical\nunits at a much smaller geographical granularity compared to previous studies.\nIn addition, this study investigates if the geographical distance can influence\nthe embedding similarity. The empirical evaluations based on a big vehicle\ntrajectory data set confirm that the embedding similarity can be a metric proxy\nfor place functions. However, the results also show that the embedding\nsimilarity is still bounded by the distance at the local scale.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 12:59:46 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 16:13:29 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fu", "Cheng", ""], ["Weibel", "Robert", ""]]}, {"id": "2011.00288", "submitter": "Oscar Leong", "authors": "Paul Hand, Oscar Leong, Vladislav Voroninski", "title": "Optimal Sample Complexity of Gradient Descent for Amplitude Flow via\n  Non-Lipschitz Matrix Concentration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a real-valued $n$-dimensional signal\nfrom $m$ phaseless, linear measurements and analyze the amplitude-based\nnon-smooth least squares objective. We establish local convergence of gradient\ndescent with optimal sample complexity based on the uniform concentration of a\nrandom, discontinuous matrix-valued operator arising from the objective's\ngradient dynamics. While common techniques to establish uniform concentration\nof random functions exploit Lipschitz continuity, we prove that the\ndiscontinuous matrix-valued operator satisfies a uniform matrix concentration\ninequality when the measurement vectors are Gaussian as soon as $m = \\Omega(n)$\nwith high probability. We then show that satisfaction of this inequality is\nsufficient for gradient descent with proper initialization to converge linearly\nto the true solution up to the global sign ambiguity. As a consequence, this\nguarantees local convergence for Gaussian measurements at optimal sample\ncomplexity. The concentration methods in the present work have previously been\nused to establish recovery guarantees for a variety of inverse problems under\ngenerative neural network priors. This paper demonstrates the applicability of\nthese techniques to more traditional inverse problems and serves as a\npedagogical introduction to those results.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 15:03:30 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hand", "Paul", ""], ["Leong", "Oscar", ""], ["Voroninski", "Vladislav", ""]]}, {"id": "2011.00289", "submitter": "Edoardo Belli", "authors": "Edoardo Belli", "title": "Smoothly Adaptively Centered Ridge Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a focus on linear models with smooth functional covariates, we propose a\npenalization framework (SACR) based on the nonzero centered ridge, where the\ncenter of the penalty is optimally reweighted in a supervised way, starting\nfrom the ordinary ridge solution as the initial centerfunction. In particular,\nwe introduce a convex formulation that jointly estimates the model's\ncoefficients and the weight function, with a roughness penalty on the\ncenterfunction and constraints on the weights in order to recover a possibly\nsmooth and/or sparse solution. This allows for a non-iterative and continuous\nvariable selection mechanism, as the weight function can either inflate or\ndeflate the initial center, in order to target the penalty towards a suitable\ncenter, with the objective to reduce the unwanted shrinkage on the nonzero\ncoefficients, instead of uniformly shrinking the whole coefficient function. As\nempirical evidence of the interpretability and predictive power of our method,\nwe provide a simulation study and two real world spectroscopy applications with\nboth classification and regression.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 15:04:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Belli", "Edoardo", ""]]}, {"id": "2011.00307", "submitter": "Liang Liao", "authors": "Liang Liao and Stephen John Maybank", "title": "General Data Analytics with Applications to Visual Information Analysis:\n  A Provable Backward-Compatible Semisimple Paradigm over T-Algebra", "comments": "38 page, 12 figures. two typos are removed. Official code repository:\n  https://github.com/liaoliang2020/talgebra", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel backward-compatible paradigm of general data analytics\nover a recently-reported semisimple algebra (called t-algebra). We study the\nabstract algebraic framework over the t-algebra by representing the elements of\nt-algebra by fix-sized multi-way arrays of complex numbers and the algebraic\nstructure over the t-algebra by a collection of direct-product constituents.\nOver the t-algebra, many algorithms are generalized in a straightforward manner\nusing this new semisimple paradigm. To demonstrate the new paradigm's\nperformance and its backward-compatibility, we generalize some canonical\nalgorithms for visual pattern analysis. Experiments on public datasets show\nthat the generalized algorithms compare favorably with their canonical\ncounterparts.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 16:41:09 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:25:09 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 10:22:55 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 02:03:34 GMT"}, {"version": "v5", "created": "Tue, 5 Jan 2021 12:48:32 GMT"}, {"version": "v6", "created": "Mon, 25 Jan 2021 11:31:49 GMT"}, {"version": "v7", "created": "Thu, 8 Apr 2021 07:47:40 GMT"}, {"version": "v8", "created": "Sun, 2 May 2021 15:45:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Liao", "Liang", ""], ["Maybank", "Stephen John", ""]]}, {"id": "2011.00320", "submitter": "Jhony Kaesemodel Pontes", "authors": "Jhony Kaesemodel Pontes, James Hays, and Simon Lucey", "title": "Scene Flow from Point Clouds with or without Learning", "comments": "International Conference on 3D Vision (3DV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene flow is the three-dimensional (3D) motion field of a scene. It provides\ninformation about the spatial arrangement and rate of change of objects in\ndynamic environments. Current learning-based approaches seek to estimate the\nscene flow directly from point clouds and have achieved state-of-the-art\nperformance. However, supervised learning methods are inherently domain\nspecific and require a large amount of labeled data. Annotation of scene flow\non real-world point clouds is expensive and challenging, and the lack of such\ndatasets has recently sparked interest in self-supervised learning methods. How\nto accurately and robustly learn scene flow representations without labeled\nreal-world data is still an open problem. Here we present a simple and\ninterpretable objective function to recover the scene flow from point clouds.\nWe use the graph Laplacian of a point cloud to regularize the scene flow to be\n\"as-rigid-as-possible\". Our proposed objective function can be used with or\nwithout learning---as a self-supervisory signal to learn scene flow\nrepresentations, or as a non-learning-based method in which the scene flow is\noptimized during runtime. Our approach outperforms related works in many\ndatasets. We also show the immediate applications of our proposed method for\ntwo applications: motion segmentation and point cloud densification.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 17:24:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pontes", "Jhony Kaesemodel", ""], ["Hays", "James", ""], ["Lucey", "Simon", ""]]}, {"id": "2011.00328", "submitter": "Adam Krzyzak", "authors": "Michael Kohler and Adam Krzyzak", "title": "On the rate of convergence of a deep recurrent neural network estimate\n  in a regression problem with dependent data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A regression problem with dependent data is considered. Regularity\nassumptions on the dependency of the data are introduced, and it is shown that\nunder suitable structural assumptions on the regression function a deep\nrecurrent neural network estimate is able to circumvent the curse of\ndimensionality.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:07:06 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kohler", "Michael", ""], ["Krzyzak", "Adam", ""]]}, {"id": "2011.00330", "submitter": "Brijen Thananjeyan", "authors": "Brijen Thananjeyan, Kirthevasan Kandasamy, Ion Stoica, Michael I.\n  Jordan, Ken Goldberg, Joseph E. Gonzalez", "title": "Resource Allocation in Multi-armed Bandit Exploration: Overcoming\n  Sublinear Scaling with Adaptive Parallelism", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study exploration in stochastic multi-armed bandits when we have access to\na divisible resource that can be allocated in varying amounts to arm pulls. We\nfocus in particular on the allocation of distributed computing resources, where\nwe may obtain results faster by allocating more resources per pull, but might\nhave reduced throughput due to nonlinear scaling. For example, in\nsimulation-based scientific studies, an expensive simulation can be sped up by\nrunning it on multiple cores. This speed-up however, is partly offset by the\ncommunication among cores, which results in lower throughput than if fewer\ncores were allocated per trial to run more trials in parallel. In this paper,\nwe explore these trade-offs in two settings. First, in a fixed confidence\nsetting, we need to find the best arm with a given target success probability\nas quickly as possible. We propose an algorithm which trades off between\ninformation accumulation and throughput and show that the time taken can be\nupper bounded by the solution of a dynamic program whose inputs are the gaps\nbetween the sub-optimal and optimal arms. We also prove a matching hardness\nresult. Second, we present an algorithm for a fixed deadline setting, where we\nare given a time deadline and need to maximize the probability of finding the\nbest arm. We corroborate our theoretical insights with simulation experiments\nthat show that the algorithms consistently match or outperform baseline\nalgorithms on a variety of problem instances.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:19:29 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 19:25:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Thananjeyan", "Brijen", ""], ["Kandasamy", "Kirthevasan", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""], ["Goldberg", "Ken", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2011.00344", "submitter": "Mikhail Konobeev", "authors": "Mikhail Konobeev, Ilja Kuzborskij, Csaba Szepesv\\'ari", "title": "A Distribution-Dependent Analysis of Meta-Learning", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in the theory of meta-learning is to understand how the task\ndistributions influence transfer risk, the expected error of a meta-learner on\na new task drawn from the unknown task distribution. In this paper, focusing on\nfixed design linear regression with Gaussian noise and a Gaussian task (or\nparameter) distribution, we give distribution-dependent lower bounds on the\ntransfer risk of any algorithm, while we also show that a novel, weighted\nversion of the so-called biased regularized regression method is able to match\nthese lower bounds up to a fixed constant factor. Notably, the weighting is\nderived from the covariance of the Gaussian task distribution. Altogether, our\nresults provide a precise characterization of the difficulty of meta-learning\nin this Gaussian setting. While this problem setting may appear simple, we show\nthat it is rich enough to unify the \"parameter sharing\" and \"representation\nlearning\" streams of meta-learning; in particular, representation learning is\nobtained as the special case when the covariance matrix of the task\ndistribution is unknown. For this case we propose to adopt the EM method, which\nis shown to enjoy efficient updates in our case. The paper is completed by an\nempirical study of EM. In particular, our experimental results show that the EM\nalgorithm can attain the lower bound as the number of tasks grows, while the\nalgorithm is also successful in competing with its alternatives when used in a\nrepresentation learning context.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 19:36:15 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 15:47:47 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 03:38:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Konobeev", "Mikhail", ""], ["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2011.00355", "submitter": "Yatong Chen", "authors": "Yatong Chen, Jialu Wang, Yang Liu", "title": "Linear Classifiers that Encourage Constructive Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems are often used in settings where individuals adapt\ntheir features to obtain a desired outcome. In such settings, strategic\nbehavior leads to a sharp loss in model performance in deployment. In this\nwork, we aim to address this problem by learning classifiers that encourage\ndecision subjects to change their features in a way that leads to improvement\nin both predicted \\emph{and} true outcome. We frame the dynamics of prediction\nand adaptation as a two-stage game, and characterize optimal strategies for the\nmodel designer and its decision subjects. In benchmarks on simulated and\nreal-world datasets, we find that classifiers trained using our method maintain\nthe accuracy of existing approaches while inducing higher levels of improvement\nand less manipulation.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 20:35:32 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 08:17:18 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 04:13:23 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chen", "Yatong", ""], ["Wang", "Jialu", ""], ["Liu", "Yang", ""]]}, {"id": "2011.00359", "submitter": "Wenshan Wang", "authors": "Wenshan Wang, Yaoyu Hu, Sebastian Scherer", "title": "TartanVO: A Generalizable Learning-based VO", "comments": null, "journal-ref": "The Conference on Robot Learning 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first learning-based visual odometry (VO) model, which\ngeneralizes to multiple datasets and real-world scenarios and outperforms\ngeometry-based methods in challenging scenes. We achieve this by leveraging the\nSLAM dataset TartanAir, which provides a large amount of diverse synthetic data\nin challenging environments. Furthermore, to make our VO model generalize\nacross datasets, we propose an up-to-scale loss function and incorporate the\ncamera intrinsic parameters into the model. Experiments show that a single\nmodel, TartanVO, trained only on synthetic data, without any finetuning, can be\ngeneralized to real-world datasets such as KITTI and EuRoC, demonstrating\nsignificant advantages over the geometry-based methods on challenging\ntrajectories. Our code is available at https://github.com/castacks/tartanvo.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 20:49:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Wenshan", ""], ["Hu", "Yaoyu", ""], ["Scherer", "Sebastian", ""]]}, {"id": "2011.00364", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas, Constantinos Daskalakis, and Michael I. Jordan", "title": "Efficient Methods for Structured Nonconvex-Nonconcave Min-Max\n  Optimization", "comments": "in Proc. AISTATS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of min-max optimization in adversarial training of deep neural\nnetwork classifiers and training of generative adversarial networks has\nmotivated the study of nonconvex-nonconcave optimization objectives, which\nfrequently arise in these applications. Unfortunately, recent results have\nestablished that even approximate first-order stationary points of such\nobjectives are intractable, even under smoothness conditions, motivating the\nstudy of min-max objectives with additional structure. We introduce a new class\nof structured nonconvex-nonconcave min-max optimization problems, proposing a\ngeneralization of the extragradient algorithm which provably converges to a\nstationary point. The algorithm applies not only to Euclidean spaces, but also\nto general $\\ell_p$-normed finite-dimensional real vector spaces. We also\ndiscuss its stability under stochastic oracles and provide bounds on its sample\ncomplexity. Our iteration complexity and sample complexity bounds either match\nor improve the best known bounds for the same or less general\nnonconvex-nonconcave settings, such as those that satisfy variational coherence\nor in which a weak solution to the associated variational inequality problem is\nassumed to exist.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 21:35:42 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 22:09:24 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Daskalakis", "Constantinos", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.00368", "submitter": "Hossein Rahmani", "authors": "Maryam Dialameh and Ali Hamzeh and Hossein Rahmani", "title": "DL-Reg: A Deep Learning Regularization Technique using Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization plays a vital role in the context of deep learning by\npreventing deep neural networks from the danger of overfitting. This paper\nproposes a novel deep learning regularization method named as DL-Reg, which\ncarefully reduces the nonlinearity of deep networks to a certain extent by\nexplicitly enforcing the network to behave as much linear as possible. The key\nidea is to add a linear constraint to the objective function of the deep neural\nnetworks, which is simply the error of a linear mapping from the inputs to the\noutputs of the model. More precisely, the proposed DL-Reg carefully forces the\nnetwork to behave in a linear manner. This linear constraint, which is further\nadjusted by a regularization factor, prevents the network from the risk of\noverfitting. The performance of DL-Reg is evaluated by training\nstate-of-the-art deep network models on several benchmark datasets. The\nexperimental results show that the proposed regularization method: 1) gives\nmajor improvements over the existing regularization techniques, and 2)\nsignificantly improves the performance of deep neural networks, especially in\nthe case of small-sized training datasets.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 21:53:24 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 23:22:48 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Dialameh", "Maryam", ""], ["Hamzeh", "Ali", ""], ["Rahmani", "Hossein", ""]]}, {"id": "2011.00377", "submitter": "Swati Padhee", "authors": "Ankita Agarwal and Preetham Salehundam and Swati Padhee and William L.\n  Romine and Tanvi Banerjee", "title": "Leveraging Natural Language Processing to Mine Issues on Twitter During\n  the COVID-19 Pandemic", "comments": "11 pages, 5 figures, 5 tables. Long version of accepted Paper at IEEE\n  Big Data 2020 (https://bigdataieee.org/BigData2020/AcceptedPapers.html)", "journal-ref": null, "doi": null, "report-no": "BigD560", "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent global outbreak of the coronavirus disease (COVID-19) has spread\nto all corners of the globe. The international travel ban, panic buying, and\nthe need for self-quarantine are among the many other social challenges brought\nabout in this new era. Twitter platforms have been used in various public\nhealth studies to identify public opinion about an event at the local and\nglobal scale. To understand the public concerns and responses to the pandemic,\na system that can leverage machine learning techniques to filter out irrelevant\ntweets and identify the important topics of discussion on social media\nplatforms like Twitter is needed. In this study, we constructed a system to\nidentify the relevant tweets related to the COVID-19 pandemic throughout\nJanuary 1st, 2020 to April 30th, 2020, and explored topic modeling to identify\nthe most discussed topics and themes during this period in our data set.\nAdditionally, we analyzed the temporal changes in the topics with respect to\nthe events that occurred during this pandemic. We found out that eight topics\nwere sufficient to identify the themes in our corpus. These topics depicted a\ntemporal trend. The dominant topics vary over time and align with the events\nrelated to the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 22:26:26 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 02:42:05 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Agarwal", "Ankita", ""], ["Salehundam", "Preetham", ""], ["Padhee", "Swati", ""], ["Romine", "William L.", ""], ["Banerjee", "Tanvi", ""]]}, {"id": "2011.00379", "submitter": "Jialu Wang", "authors": "Jialu Wang, Yang Liu, Caleb Levy", "title": "Fair Classification with Group-Dependent Label Noise", "comments": "11 pages, 9 tables", "journal-ref": null, "doi": "10.1145/3442188.3445915", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines how to train fair classifiers in settings where training\nlabels are corrupted with random noise, and where the error rates of corruption\ndepend both on the label class and on the membership function for a protected\nsubgroup. Heterogeneous label noise models systematic biases towards particular\ngroups when generating annotations. We begin by presenting analytical results\nwhich show that naively imposing parity constraints on demographic disparity\nmeasures, without accounting for heterogeneous and group-dependent error rates,\ncan decrease both the accuracy and the fairness of the resulting classifier.\nOur experiments demonstrate these issues arise in practice as well. We address\nthese problems by performing empirical risk minimization with carefully defined\nsurrogate loss functions and surrogate constraints that help avoid the pitfalls\nintroduced by heterogeneous label noise. We provide both theoretical and\nempirical justifications for the efficacy of our methods. We view our results\nas an important example of how imposing fairness on biased data sets without\nproper care can do at least as much harm as it does good.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 22:35:01 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 00:01:56 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Wang", "Jialu", ""], ["Liu", "Yang", ""], ["Levy", "Caleb", ""]]}, {"id": "2011.00382", "submitter": "Dong-Ki Kim", "authors": "Dong-Ki Kim, Miao Liu, Matthew Riemer, Chuangchuang Sun, Marwa\n  Abdulhai, Golnaz Habibi, Sebastian Lopez-Cot, Gerald Tesauro, Jonathan P. How", "title": "A Policy Gradient Algorithm for Learning to Learn in Multiagent\n  Reinforcement Learning", "comments": "Accepted to ICML 2021. Code at https://github.com/dkkim93/meta-mapg\n  and Videos at https://sites.google.com/view/meta-mapg/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in multiagent reinforcement learning is to learn\nbeneficial behaviors in a shared environment with other simultaneously learning\nagents. In particular, each agent perceives the environment as effectively\nnon-stationary due to the changing policies of other agents. Moreover, each\nagent is itself constantly learning, leading to natural non-stationarity in the\ndistribution of experiences encountered. In this paper, we propose a novel\nmeta-multiagent policy gradient theorem that directly accounts for the\nnon-stationary policy dynamics inherent to multiagent learning settings. This\nis achieved by modeling our gradient updates to consider both an agent's own\nnon-stationary policy dynamics and the non-stationary policy dynamics of other\nagents in the environment. We show that our theoretically grounded approach\nprovides a general solution to the multiagent learning problem, which\ninherently comprises all key aspects of previous state of the art approaches on\nthis topic. We test our method on a diverse suite of multiagent benchmarks and\ndemonstrate a more efficient ability to adapt to new agents as they learn than\nbaseline methods across the full spectrum of mixed incentive, competitive, and\ncooperative domains.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 22:50:21 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 22:08:50 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 17:45:17 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 16:46:58 GMT"}, {"version": "v5", "created": "Fri, 11 Jun 2021 22:21:49 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Kim", "Dong-Ki", ""], ["Liu", "Miao", ""], ["Riemer", "Matthew", ""], ["Sun", "Chuangchuang", ""], ["Abdulhai", "Marwa", ""], ["Habibi", "Golnaz", ""], ["Lopez-Cot", "Sebastian", ""], ["Tesauro", "Gerald", ""], ["How", "Jonathan P.", ""]]}, {"id": "2011.00384", "submitter": "Meiyi Ma", "authors": "Meiyi Ma, John Stankovic, Ezio Bartocci, Lu Feng", "title": "Predictive Monitoring with Logic-Calibrated Uncertainty for\n  Cyber-Physical Systems", "comments": "This article appears as part of the ESWEEK-TECS special issue and was\n  presented in the International Conference on Embedded Software (EMSOFT), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive monitoring -- making predictions about future states and\nmonitoring if the predicted states satisfy requirements -- offers a promising\nparadigm in supporting the decision making of Cyber-Physical Systems (CPS).\nExisting works of predictive monitoring mostly focus on monitoring individual\npredictions rather than sequential predictions. We develop a novel approach for\nmonitoring sequential predictions generated from Bayesian Recurrent Neural\nNetworks (RNNs) that can capture the inherent uncertainty in CPS, drawing on\ninsights from our study of real-world CPS datasets. We propose a new logic\nnamed \\emph{Signal Temporal Logic with Uncertainty} (STL-U) to monitor a\nflowpipe containing an infinite set of uncertain sequences predicted by\nBayesian RNNs. We define STL-U strong and weak satisfaction semantics based on\nif all or some sequences contained in a flowpipe satisfy the requirement. We\nalso develop methods to compute the range of confidence levels under which a\nflowpipe is guaranteed to strongly (weakly) satisfy an STL-U formula.\nFurthermore, we develop novel criteria that leverage STL-U monitoring results\nto calibrate the uncertainty estimation in Bayesian RNNs. Finally, we evaluate\nthe proposed approach via experiments with real-world datasets and a simulated\nsmart city case study, which show very encouraging results of STL-U based\npredictive monitoring approach outperforming baselines.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 23:18:15 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 16:40:44 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 19:24:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ma", "Meiyi", ""], ["Stankovic", "John", ""], ["Bartocci", "Ezio", ""], ["Feng", "Lu", ""]]}, {"id": "2011.00388", "submitter": "Dan Nguyen", "authors": "Dan Nguyen, Azar Sadeghnejad Barkousaraie, Gyanendra Bohara, Anjali\n  Balagopal, Rafe McBeth, Mu-Han Lin, Steve Jiang", "title": "A comparison of Monte Carlo dropout and bootstrap aggregation on the\n  performance and uncertainty estimation in radiation therapy dose prediction\n  with deep learning neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, artificial intelligence technologies and algorithms have become a\nmajor focus for advancements in treatment planning for radiation therapy. As\nthese are starting to become incorporated into the clinical workflow, a major\nconcern from clinicians is not whether the model is accurate, but whether the\nmodel can express to a human operator when it does not know if its answer is\ncorrect. We propose to use Monte Carlo dropout (MCDO) and the bootstrap\naggregation (bagging) technique on deep learning models to produce uncertainty\nestimations for radiation therapy dose prediction. We show that both models are\ncapable of generating a reasonable uncertainty map, and, with our proposed\nscaling technique, creating interpretable uncertainties and bounds on the\nprediction and any relevant metrics. Performance-wise, bagging provides\nstatistically significant reduced loss value and errors in most of the metrics\ninvestigated in this study. The addition of bagging was able to further reduce\nerrors by another 0.34% for Dmean and 0.19% for Dmax, on average, when compared\nto the baseline framework. Overall, the bagging framework provided\nsignificantly lower MAE of 2.62, as opposed to the baseline framework's MAE of\n2.87. The usefulness of bagging, from solely a performance standpoint, does\nhighly depend on the problem and the acceptable predictive error, and its high\nupfront computational cost during training should be factored in to deciding\nwhether it is advantageous to use it. In terms of deployment with uncertainty\nestimations turned on, both frameworks offer the same performance time of about\n12 seconds. As an ensemble-based metaheuristic, bagging can be used with\nexisting machine learning architectures to improve stability and performance,\nand MCDO can be applied to any deep learning models that have dropout as part\nof their architecture.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 00:24:43 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 02:28:03 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Nguyen", "Dan", ""], ["Barkousaraie", "Azar Sadeghnejad", ""], ["Bohara", "Gyanendra", ""], ["Balagopal", "Anjali", ""], ["McBeth", "Rafe", ""], ["Lin", "Mu-Han", ""], ["Jiang", "Steve", ""]]}, {"id": "2011.00392", "submitter": "Ankit Bandyopadhyay", "authors": "Ankit Bandyopadhyay", "title": "Measure Theoretic Approach to Nonuniform Learnability", "comments": "Submitting to STOC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An earlier introduced characterization of nonuniform learnability that allows\nthe sample size to depend on the hypothesis to which the learner is compared\nhas been redefined using the measure theoretic approach. Where nonuniform\nlearnability is a strict relaxation of the Probably Approximately Correct\nframework. Introduction of a new algorithm, Generalize Measure Learnability\nframework, to implement this approach with the study of its sample and\ncomputational complexity bounds. Like the Minimum Description Length principle,\nthis approach can be regarded as an explication of Occam razor. Furthermore,\nmany situations were presented, Hypothesis Classes that are countable where we\ncan apply the GML framework, which we can learn to use the GML scheme and can\nachieve statistical consistency.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 01:03:26 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bandyopadhyay", "Ankit", ""]]}, {"id": "2011.00401", "submitter": "Sam Toyer", "authors": "Sam Toyer, Rohin Shah, Andrew Critch, Stuart Russell", "title": "The MAGICAL Benchmark for Robust Imitation", "comments": "NeurIPS 2020 conference paper (poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imitation Learning (IL) algorithms are typically evaluated in the same\nenvironment that was used to create demonstrations. This rewards precise\nreproduction of demonstrations in one particular environment, but provides\nlittle information about how robustly an algorithm can generalise the\ndemonstrator's intent to substantially different deployment settings. This\npaper presents the MAGICAL benchmark suite, which permits systematic evaluation\nof generalisation by quantifying robustness to different kinds of distribution\nshift that an IL algorithm is likely to encounter in practice. Using the\nMAGICAL suite, we confirm that existing IL algorithms overfit significantly to\nthe context in which demonstrations are provided. We also show that standard\nmethods for reducing overfitting are effective at creating narrow perceptual\ninvariances, but are not sufficient to enable transfer to contexts that require\nsubstantially different behaviour, which suggests that new approaches will be\nneeded in order to robustly generalise demonstrator intent. Code and data for\nthe MAGICAL suite is available at https://github.com/qxcv/magical/.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 02:04:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Toyer", "Sam", ""], ["Shah", "Rohin", ""], ["Critch", "Andrew", ""], ["Russell", "Stuart", ""]]}, {"id": "2011.00403", "submitter": "Yipeng Zhang", "authors": "Minh Tran, Yipeng Zhang, Mohammad Soleymani", "title": "Towards A Friendly Online Community: An Unsupervised Style Transfer\n  Framework for Profanity Redaction", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offensive and abusive language is a pressing problem on social media\nplatforms. In this work, we propose a method for transforming offensive\ncomments, statements containing profanity or offensive language, into\nnon-offensive ones. We design a RETRIEVE, GENERATE and EDIT unsupervised style\ntransfer pipeline to redact the offensive comments in a word-restricted manner\nwhile maintaining a high level of fluency and preserving the content of the\noriginal text. We extensively evaluate our method's performance and compare it\nto previous style transfer models using both automatic metrics and human\nevaluations. Experimental results show that our method outperforms other models\non human evaluations and is the only approach that consistently performs well\non all automatic evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 02:10:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Tran", "Minh", ""], ["Zhang", "Yipeng", ""], ["Soleymani", "Mohammad", ""]]}, {"id": "2011.00415", "submitter": "Tim G. J. Rudner", "authors": "Tim G. J. Rudner, Dino Sejdinovic, Yarin Gal", "title": "Inter-domain Deep Gaussian Processes", "comments": "Published in Proceedings of the 37th International Conference on\n  Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-domain Gaussian processes (GPs) allow for high flexibility and low\ncomputational cost when performing approximate inference in GP models. They are\nparticularly suitable for modeling data exhibiting global structure but are\nlimited to stationary covariance functions and thus fail to model\nnon-stationary data effectively. We propose Inter-domain Deep Gaussian\nProcesses, an extension of inter-domain shallow GPs that combines the\nadvantages of inter-domain and deep Gaussian processes (DGPs), and demonstrate\nhow to leverage existing approximate inference methods to perform simple and\nscalable approximate inference using inter-domain features in DGPs. We assess\nthe performance of our method on a range of regression tasks and demonstrate\nthat it outperforms inter-domain shallow GPs and conventional DGPs on\nchallenging large-scale real-world datasets exhibiting both global structure as\nwell as a high-degree of non-stationarity.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:03:35 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Rudner", "Tim G. J.", ""], ["Sejdinovic", "Dino", ""], ["Gal", "Yarin", ""]]}, {"id": "2011.00416", "submitter": "Zhijing Jin", "authors": "Di Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova, Rada Mihalcea", "title": "Deep Learning for Text Style Transfer: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text style transfer (TST) is an important task in natural language generation\n(NLG), which aims to control certain attributes in the generated text, such as\npoliteness, emotion, humor, and many others. It has a long history in the field\nof natural language processing (NLP), and recently has re-gained significant\nattention thanks to the promising performance brought by deep neural models. In\nthis paper, we present a systematic survey of the research on neural text style\ntransfer, spanning over 100 representative articles since the first neural text\nstyle transfer work in 2017. We discuss the task formulation, existing datasets\nand subtasks, evaluation, as well as the rich methodologies in the presence of\nparallel and non-parallel data. We also provide discussions on a variety of\nimportant topics regarding the future development of TST. Our curated paper\nlist is at https://github.com/zhijing-jin/Text_Style_Transfer_Survey\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:04:43 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 14:21:58 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 05:42:27 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Hu", "Zhiting", ""], ["Vechtomova", "Olga", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2011.00417", "submitter": "Shiyun Xu", "authors": "Shiyun Xu, Zhiqi Bu", "title": "DebiNet: Debiasing Linear Models with Nonlinear Overparameterized Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed strong empirical performance of\nover-parameterized neural networks on various tasks and many advances in the\ntheory, e.g. the universal approximation and provable convergence to global\nminimum. In this paper, we incorporate over-parameterized neural networks into\nsemi-parametric models to bridge the gap between inference and prediction,\nespecially in the high dimensional linear problem. By doing so, we can exploit\na wide class of networks to approximate the nuisance functions and to estimate\nthe parameters of interest consistently. Therefore, we may offer the best of\ntwo worlds: the universal approximation ability from neural networks and the\ninterpretability from classic ordinary linear model, leading to both valid\ninference and accurate prediction. We show the theoretical foundations that\nmake this possible and demonstrate with numerical experiments. Furthermore, we\npropose a framework, DebiNet, in which we plug-in arbitrary feature selection\nmethods to our semi-parametric neural network. DebiNet can debias the\nregularized estimators (e.g. Lasso) and perform well, in terms of the\npost-selection inference and the generalization error.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:12:53 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 00:50:23 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Xu", "Shiyun", ""], ["Bu", "Zhiqi", ""]]}, {"id": "2011.00418", "submitter": "Xiaoguang Li", "authors": "Haonan Yan, Xiaoguang Li, Hui Li, Jiamin Li, Wenhai Sun and Fenghua Li", "title": "Monitoring-based Differential Privacy Mechanism Against Query-Flooding\n  Parameter Duplication Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public intelligent services enabled by machine learning algorithms are\nvulnerable to model extraction attacks that can steal confidential information\nof the learning models through public queries. Though there are some protection\noptions such as differential privacy (DP) and monitoring, which are considered\npromising techniques to mitigate this attack, we still find that the\nvulnerability persists. In this paper, we propose an adaptive query-flooding\nparameter duplication (QPD) attack. The adversary can infer the model\ninformation with black-box access and no prior knowledge of any model\nparameters or training data via QPD. We also develop a defense strategy using\nDP called monitoring-based DP (MDP) against this new attack. In MDP, we first\npropose a novel real-time model extraction status assessment scheme called\nMonitor to evaluate the situation of the model. Then, we design a method to\nguide the differential privacy budget allocation called APBA adaptively.\nFinally, all DP-based defenses with MDP could dynamically adjust the amount of\nnoise added in the model response according to the result from Monitor and\neffectively defends the QPD attack. Furthermore, we thoroughly evaluate and\ncompare the QPD attack and MDP defense performance on real-world models with DP\nand monitoring protection.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:21:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yan", "Haonan", ""], ["Li", "Xiaoguang", ""], ["Li", "Hui", ""], ["Li", "Jiamin", ""], ["Sun", "Wenhai", ""], ["Li", "Fenghua", ""]]}, {"id": "2011.00424", "submitter": "Hardik Meisheri", "authors": "Hardik Meisheri, Harshad Khadilkar", "title": "Sample Efficient Training in Multi-Agent Adversarial Games with Limited\n  Teammate Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe our solution approach for Pommerman TeamRadio, a competition\nenvironment associated with NeurIPS 2019. The defining feature of our algorithm\nis achieving sample efficiency within a restrictive computational budget while\nbeating the previous years learning agents. The proposed algorithm (i) uses\nimitation learning to seed the policy, (ii) explicitly defines the\ncommunication protocol between the two teammates, (iii) shapes the reward to\nprovide a richer feedback signal to each agent during training and (iv) uses\nmasking for catastrophic bad actions. We describe extensive tests against\nbaselines, including those from the 2019 competition leaderboard, and also a\nspecific investigation of the learned policy and the effect of each\nmodification on performance. We show that the proposed approach is able to\nachieve competitive performance within half a million games of training,\nsignificantly faster than other studies in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:50:02 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Meisheri", "Hardik", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2011.00425", "submitter": "Arda Akdemir", "authors": "Arda Akdemir and Tetsuo Shibuya", "title": "Analyzing the Effect of Multi-task Learning for Biomedical Named Entity\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developing high-performing systems for detecting biomedical named entities\nhas major implications. State-of-the-art deep-learning based solutions for\nentity recognition often require large annotated datasets, which is not\navailable in the biomedical domain. Transfer learning and multi-task learning\nhave been shown to improve performance for low-resource domains. However, the\napplications of these methods are relatively scarce in the biomedical domain,\nand a theoretical understanding of why these methods improve the performance is\nlacking. In this study, we performed an extensive analysis to understand the\ntransferability between different biomedical entity datasets. We found useful\nmeasures to predict transferability between these datasets. Besides, we propose\ncombining transfer learning and multi-task learning to improve the performance\nof biomedical named entity recognition systems, which is not applied before to\nthe best of our knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 04:52:56 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Akdemir", "Arda", ""], ["Shibuya", "Tetsuo", ""]]}, {"id": "2011.00428", "submitter": "Xikai Yang", "authors": "Xikai Yang, Yong Long, Saiprasad Ravishankar", "title": "Two-layer clustering-based sparsifying transform learning for low-dose\n  CT reconstruction", "comments": "5 pages, 3 figures, submitted to ISBI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high-quality reconstructions from low-dose computed tomography\n(LDCT) measurements is of much importance in clinical settings. Model-based\nimage reconstruction methods have been proven to be effective in removing\nartifacts in LDCT. In this work, we propose an approach to learn a rich\ntwo-layer clustering-based sparsifying transform model (MCST2), where image\npatches and their subsequent feature maps (filter residuals) are clustered into\ngroups with different learned sparsifying filters per group. We investigate a\npenalized weighted least squares (PWLS) approach for LDCT reconstruction\nincorporating learned MCST2 priors. Experimental results show the superior\nperformance of the proposed PWLS-MCST2 approach compared to other related\nrecent schemes.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 05:15:37 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yang", "Xikai", ""], ["Long", "Yong", ""], ["Ravishankar", "Saiprasad", ""]]}, {"id": "2011.00440", "submitter": "Brendan Tidd", "authors": "Brendan Tidd, Nicolas Hudson, Akansel Cosgun, Jurgen Leitner", "title": "Learning When to Switch: Composing Controllers to Traverse a Sequence of\n  Terrain Artifacts", "comments": "2021 IEEE International Conference on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legged robots often use separate control policies that are highly engineered\nfor traversing difficult terrain such as stairs, gaps, and steps, where\nswitching between policies is only possible when the robot is in a region that\nis common to adjacent controllers. Deep Reinforcement Learning (DRL) is a\npromising alternative to hand-crafted control design, though typically requires\nthe full set of test conditions to be known before training. DRL policies can\nresult in complex (often unrealistic) behaviours that have few or no\noverlapping regions between adjacent policies, making it difficult to switch\nbehaviours. In this work we develop multiple DRL policies with Curriculum\nLearning (CL), each that can traverse a single respective terrain condition,\nwhile ensuring an overlap between policies. We then train a network for each\ndestination policy that estimates the likelihood of successfully switching from\nany other policy. We evaluate our switching method on a previously unseen\ncombination of terrain artifacts and show that it performs better than\nheuristic methods. While our method is trained on individual terrain types, it\nperforms comparably to a Deep Q Network trained on the full set of terrain\nconditions. This approach allows the development of separate policies in\nconstrained conditions with embedded prior knowledge about each behaviour, that\nis scalable to any number of behaviours, and prepares DRL methods for\napplications in the real world\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 06:34:42 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Tidd", "Brendan", ""], ["Hudson", "Nicolas", ""], ["Cosgun", "Akansel", ""], ["Leitner", "Jurgen", ""]]}, {"id": "2011.00444", "submitter": "Keyu Chen", "authors": "Keyu Chen, Di Zhuang, J. Morris Chang", "title": "Discriminative Adversarial Domain Generalization with Meta-learning\n  based Cross-domain Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization capability of machine learning models, which refers to\ngeneralizing the knowledge for an \"unseen\" domain via learning from one or\nmultiple seen domain(s), is of great importance to develop and deploy machine\nlearning applications in the real-world conditions. Domain Generalization (DG)\ntechniques aim to enhance such generalization capability of machine learning\nmodels, where the learnt feature representation and the classifier are two\ncrucial factors to improve generalization and make decisions. In this paper, we\npropose Discriminative Adversarial Domain Generalization (DADG) with\nmeta-learning-based cross-domain validation. Our proposed framework contains\ntwo main components that work synergistically to build a domain-generalized DNN\nmodel: (i) discriminative adversarial learning, which proactively learns a\ngeneralized feature representation on multiple \"seen\" domains, and (ii)\nmeta-learning based cross-domain validation, which simulates train/test domain\nshift via applying meta-learning techniques in the training process. In the\nexperimental evaluation, a comprehensive comparison has been made among our\nproposed approach and other existing approaches on three benchmark datasets.\nThe results shown that DADG consistently outperforms a strong baseline DeepAll,\nand outperforms the other existing DG algorithms in most of the evaluation\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 07:48:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Chen", "Keyu", ""], ["Zhuang", "Di", ""], ["Chang", "J. Morris", ""]]}, {"id": "2011.00467", "submitter": "Tejas Kulkarni", "authors": "Tejas Kulkarni, Joonas J\\\"alk\\\"o, Antti Koskela, Samuel Kaski and\n  Antti Honkela", "title": "Differentially Private Bayesian Inference for Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalized linear models (GLMs) such as logistic regression are among the\nmost widely used arms in data analyst's repertoire and often used on sensitive\ndatasets. A large body of prior works that investigate GLMs under differential\nprivacy (DP) constraints provide only private point estimates of the regression\ncoefficients, and are not able to quantify parameter uncertainty. In this work,\nwith logistic and Poisson regression as running examples, we introduce a\ngeneric noise-aware DP Bayesian inference method for a GLM at hand, given a\nnoisy sum of summary statistics. Quantifying uncertainty allows us to determine\nwhich of the regression coefficients are statistically significantly different\nfrom zero. We provide a previously unknown tight privacy analysis and\nexperimentally demonstrate that the posteriors obtained from our model, while\nadhering to strong privacy guarantees, are close to the non-private posteriors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 10:38:22 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 15:05:08 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 08:57:39 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Kulkarni", "Tejas", ""], ["J\u00e4lk\u00f6", "Joonas", ""], ["Koskela", "Antti", ""], ["Kaski", "Samuel", ""], ["Honkela", "Antti", ""]]}, {"id": "2011.00485", "submitter": "Marco Wiering", "authors": "Xiangxie Zhang, Ben Beinke, Berlian Al Kindhi and Marco Wiering", "title": "Comparing Machine Learning Algorithms with or without Feature Extraction\n  for DNA Classification", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The classification of DNA sequences is a key research area in bioinformatics\nas it enables researchers to conduct genomic analysis and detect possible\ndiseases. In this paper, three state-of-the-art algorithms, namely\nConvolutional Neural Networks, Deep Neural Networks, and N-gram Probabilistic\nModels, are used for the task of DNA classification. Furthermore, we introduce\na novel feature extraction method based on the Levenshtein distance and\nrandomly generated DNA sub-sequences to compute information-rich features from\nthe DNA sequences. We also use an existing feature extraction method based on\n3-grams to represent amino acids and combine both feature extraction methods\nwith a multitude of machine learning algorithms. Four different data sets, each\nconcerning viral diseases such as Covid-19, AIDS, Influenza, and Hepatitis C,\nare used for evaluating the different approaches. The results of the\nexperiments show that all methods obtain high accuracies on the different DNA\ndatasets. Furthermore, the domain-specific 3-gram feature extraction method\nleads in general to the best results in the experiments, while the newly\nproposed technique outperforms all other methods on the smallest Covid-19\ndataset\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 12:04:54 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Xiangxie", ""], ["Beinke", "Ben", ""], ["Kindhi", "Berlian Al", ""], ["Wiering", "Marco", ""]]}, {"id": "2011.00496", "submitter": "Niv Pekar", "authors": "Niv Pekar, Yaniv Benny, Lior Wolf", "title": "Generating Correct Answers for Progressive Matrices Intelligence Tests", "comments": "To appear in the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raven's Progressive Matrices are multiple-choice intelligence tests, where\none tries to complete the missing location in a $3\\times 3$ grid of abstract\nimages. Previous attempts to address this test have focused solely on selecting\nthe right answer out of the multiple choices. In this work, we focus, instead,\non generating a correct answer given the grid, without seeing the choices,\nwhich is a harder task, by definition. The proposed neural model combines\nmultiple advances in generative models, including employing multiple pathways\nthrough the same network, using the reparameterization trick along two pathways\nto make their encoding compatible, a dynamic application of variational losses,\nand a complex perceptual loss that is coupled with a selective backpropagation\nprocedure. Our algorithm is able not only to generate a set of plausible\nanswers, but also to be competitive to the state of the art methods in\nmultiple-choice tests.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 13:21:07 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pekar", "Niv", ""], ["Benny", "Yaniv", ""], ["Wolf", "Lior", ""]]}, {"id": "2011.00508", "submitter": "Lihua Chen", "authors": "Lihua Chen, Ghanshyam Pilania, Rohit Batra, Tran Doan Huan, Chiho Kim,\n  Christopher Kuenneth, Rampi Ramprasad", "title": "Polymer Informatics: Current Status and Critical Next Steps", "comments": null, "journal-ref": null, "doi": "10.1016/j.mser.2020.100595", "report-no": null, "categories": "cond-mat.soft cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) based approaches are beginning to impact several\ndomains of human life, science and technology. Polymer informatics is one such\ndomain where AI and machine learning (ML) tools are being used in the efficient\ndevelopment, design and discovery of polymers. Surrogate models are trained on\navailable polymer data for instant property prediction, allowing screening of\npromising polymer candidates with specific target property requirements.\nQuestions regarding synthesizability, and potential (retro)synthesis steps to\ncreate a target polymer, are being explored using statistical means.\nData-driven strategies to tackle unique challenges resulting from the\nextraordinary chemical and physical diversity of polymers at small and large\nscales are being explored. Other major hurdles for polymer informatics are the\nlack of widespread availability of curated and organized data, and approaches\nto create machine-readable representations that capture not just the structure\nof complex polymeric situations but also synthesis and processing conditions.\nMethods to solve inverse problems, wherein polymer recommendations are made\nusing advanced AI algorithms that meet application targets, are being\ninvestigated. As various parts of the burgeoning polymer informatics ecosystem\nmature and become integrated, efficiency improvements, accelerated discoveries\nand increased productivity can result. Here, we review emergent components of\nthis polymer informatics ecosystem and discuss imminent challenges and\nopportunities.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:17:22 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Lihua", ""], ["Pilania", "Ghanshyam", ""], ["Batra", "Rohit", ""], ["Huan", "Tran Doan", ""], ["Kim", "Chiho", ""], ["Kuenneth", "Christopher", ""], ["Ramprasad", "Rampi", ""]]}, {"id": "2011.00509", "submitter": "Majd Hawasly", "authors": "Henry Pulver, Francisco Eiras, Ludovico Carozza, Majd Hawasly, Stefano\n  Albrecht and Subramanian Ramamoorthy", "title": "PILOT: Efficient Planning by Imitation Learning and Optimisation for\n  Safe Autonomous Driving", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving the right balance between planning quality, safety and efficiency\nis a major challenge for autonomous driving. Optimisation-based motion planners\nare capable of producing safe, smooth and comfortable plans, but often at the\ncost of runtime efficiency. On the other hand, naively deploying trajectories\nproduced by efficient-to-run deep imitation learning approaches might risk\ncompromising safety. In this paper, we present PILOT -- a planning framework\nthat comprises an imitation neural network followed by an efficient optimiser\nthat actively rectifies the network's plan, guaranteeing fulfilment of safety\nand comfort requirements. The objective of the efficient optimiser is the same\nas the objective of an expensive-to-run optimisation-based planning system that\nthe neural network is trained offline to imitate. This efficient optimiser\nprovides a key layer of online protection from learning failures or deficiency\non out-of-distribution situations that might compromise safety or comfort.\nUsing a state-of-the-art, runtime-intensive optimisation-based method as the\nexpert, we demonstrate in simulated autonomous driving experiments in CARLA\nthat PILOT achieves a significant reduction in runtime when compared to the\nexpert it imitates without sacrificing planning quality.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:18:45 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 10:28:04 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Pulver", "Henry", ""], ["Eiras", "Francisco", ""], ["Carozza", "Ludovico", ""], ["Hawasly", "Majd", ""], ["Albrecht", "Stefano", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2011.00512", "submitter": "Hanzhou Wu", "authors": "Xiangyu Zhao, Hanzhou Wu and Xinpeng Zhang", "title": "Watermarking Graph Neural Networks by Random Graphs", "comments": "https://hzwu.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning tasks require us to deal with graph data which contains rich\nrelational information among elements, leading increasing graph neural network\n(GNN) models to be deployed in industrial products for improving the quality of\nservice. However, they also raise challenges to model authentication. It is\nnecessary to protect the ownership of the GNN models, which motivates us to\npresent a watermarking method to GNN models in this paper. In the proposed\nmethod, an Erdos-Renyi (ER) random graph with random node feature vectors and\nlabels is randomly generated as a trigger to train the GNN to be protected\ntogether with the normal samples. During model training, the secret watermark\nis embedded into the label predictions of the ER graph nodes. During model\nverification, by activating a marked GNN with the trigger ER graph, the\nwatermark can be reconstructed from the output to verify the ownership. Since\nthe ER graph was randomly generated, by feeding it to a non-marked GNN, the\nlabel predictions of the graph nodes are random, resulting in a low false alarm\nrate (of the proposed work). Experimental results have also shown that, the\nperformance of a marked GNN on its original task will not be impaired.\nMoreover, it is robust against model compression and fine-tuning, which has\nshown the superiority and applicability.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:22:48 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 12:18:42 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Wu", "Hanzhou", ""], ["Zhang", "Xinpeng", ""]]}, {"id": "2011.00515", "submitter": "Tim G. J. Rudner", "authors": "Tim G. J. Rudner, Oscar Key, Yarin Gal, Tom Rainforth", "title": "On Signal-to-Noise Ratio Issues in Variational Inference for Deep\n  Gaussian Processes", "comments": "Published in Proceedings of the 38th International Conference on\n  Machine Learning (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the gradient estimates used in training Deep Gaussian Processes\n(DGPs) with importance-weighted variational inference are susceptible to\nsignal-to-noise ratio (SNR) issues. Specifically, we show both theoretically\nand via an extensive empirical evaluation that the SNR of the gradient\nestimates for the latent variable's variational parameters decreases as the\nnumber of importance samples increases. As a result, these gradient estimates\ndegrade to pure noise if the number of importance samples is too large. To\naddress this pathology, we show how doubly reparameterized gradient estimators,\noriginally proposed for training variational autoencoders, can be adapted to\nthe DGP setting and that the resultant estimators completely remedy the SNR\nissue, thereby providing more reliable training. Finally, we demonstrate that\nour fix can lead to consistent improvements in the predictive performance of\nDGP models.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:38:02 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 12:14:08 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Rudner", "Tim G. J.", ""], ["Key", "Oscar", ""], ["Gal", "Yarin", ""], ["Rainforth", "Tom", ""]]}, {"id": "2011.00517", "submitter": "Valerie Chen", "authors": "Valerie Chen, Abhinav Gupta, Kenneth Marino", "title": "Ask Your Humans: Using Human Instructions to Improve Generalization in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex, multi-task problems have proven to be difficult to solve efficiently\nin a sparse-reward reinforcement learning setting. In order to be sample\nefficient, multi-task learning requires reuse and sharing of low-level\npolicies. To facilitate the automatic decomposition of hierarchical tasks, we\npropose the use of step-by-step human demonstrations in the form of natural\nlanguage instructions and action trajectories. We introduce a dataset of such\ndemonstrations in a crafting-based grid world. Our model consists of a\nhigh-level language generator and low-level policy, conditioned on language. We\nfind that human demonstrations help solve the most complex tasks. We also find\nthat incorporating natural language allows the model to generalize to unseen\ntasks in a zero-shot setting and to learn quickly from a few demonstrations.\nGeneralization is not only reflected in the actions of the agent, but also in\nthe generated natural language instructions in unseen tasks. Our approach also\ngives our trained agent interpretable behaviors because it is able to generate\na sequence of high-level descriptions of its actions.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 14:39:46 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 21:10:56 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Chen", "Valerie", ""], ["Gupta", "Abhinav", ""], ["Marino", "Kenneth", ""]]}, {"id": "2011.00521", "submitter": "Hao Wang", "authors": "Bas van Stein and Hao Wang and Thomas B\\\"ack", "title": "Neural Network Design: Learning from Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) aims to optimize deep neural networks'\narchitecture for better accuracy or smaller computational cost and has recently\ngained more research interests. Despite various successful approaches proposed\nto solve the NAS task, the landscape of it, along with its properties, are\nrarely investigated. In this paper, we argue for the necessity of studying the\nlandscape property thereof and propose to use the so-called Exploratory\nLandscape Analysis (ELA) techniques for this goal. Taking a broad set of\ndesigns of the deep convolutional network, we conduct extensive experimentation\nto obtain their performance. Based on our analysis of the experimental results,\nwe observed high similarities between well-performing architecture designs,\nwhich is then used to significantly narrow the search space to improve the\nefficiency of any NAS algorithm. Moreover, we extract the ELA features over the\nNAS landscapes on three common image classification data sets, MNIST, Fashion,\nand CIFAR-10, which shows that the NAS landscape can be distinguished for those\nthree data sets. Also, when comparing to the ELA features of the well-known\nBlack-Box Optimization Benchmarking (BBOB) problem set, we found out that the\nNAS landscapes surprisingly form a new problem class on its own, which can be\nseparated from all $24$ BBOB problems. Given this interesting observation, we,\ntherefore, state the importance of further investigation on selecting an\nefficient optimizer for the NAS landscape as well as the necessity of\naugmenting the current benchmark problem set.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 15:02:02 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["van Stein", "Bas", ""], ["Wang", "Hao", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2011.00538", "submitter": "Badr AlKhamissi", "authors": "Badr AlKhamissi, Muhammad N. ElNokrashy and Mohamed Gabr", "title": "Deep Diacritization: Efficient Hierarchical Recurrence for Improved\n  Arabic Diacritization", "comments": "This work was accepted at the Fifth Arabic Natural Language\n  Processing Workshop (COLING/WANLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel architecture for labelling character sequences that\nachieves state-of-the-art results on the Tashkeela Arabic diacritization\nbenchmark. The core is a two-level recurrence hierarchy that operates on the\nword and character levels separately---enabling faster training and inference\nthan comparable traditional models. A cross-level attention module further\nconnects the two, and opens the door for network interpretability. The task\nmodule is a softmax classifier that enumerates valid combinations of\ndiacritics. This architecture can be extended with a recurrent decoder that\noptionally accepts priors from partially diacritized text, which improves\nresults. We employ extra tricks such as sentence dropout and majority voting to\nfurther boost the final result. Our best model achieves a WER of 5.34%,\noutperforming the previous state-of-the-art with a 30.56% relative error\nreduction.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 15:33:43 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["AlKhamissi", "Badr", ""], ["ElNokrashy", "Muhammad N.", ""], ["Gabr", "Mohamed", ""]]}, {"id": "2011.00540", "submitter": "Huy Kang Kim", "authors": "Kyung Ho Park, Eunji Park, Huy Kang Kim", "title": "Unsupervised Intrusion Detection System for Unmanned Aerial Vehicle with\n  Less Labeling Effort", "comments": "14 pages, 4 tables, 3 figures, 5 equations, In Proceeding of WISA\n  2020 (THE 21ST WORLD CONFERENCE ON INFORMATION SECURITY APPLICATIONS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the importance of safety, an IDS has become a significant task in\nthe real world. Prior studies proposed various intrusion detection models for\nthe UAV. Past rule-based approaches provided a concrete baseline IDS model, and\nthe machine learning-based method achieved a precise intrusion detection\nperformance on the UAV with supervised learning models. However, previous\nmethods have room for improvement to be implemented in the real world. Prior\nmethods required a large labeling effort on the dataset, and the model could\nnot identify attacks that were not trained before. To jump over these hurdles,\nwe propose an IDS with unsupervised learning. As unsupervised learning does not\nrequire labeling, our model let the practitioner not to label every type of\nattack from the flight data. Moreover, the model can identify an abnormal\nstatus of the UAV regardless of the type of attack. We trained an autoencoder\nwith the benign flight data only and checked the model provides a different\nreconstruction loss at the benign flight and the flight under attack. We\ndiscovered that the model produces much higher reconstruction loss with the\nflight under attack than the benign flight; thus, this reconstruction loss can\nbe utilized to recognize an intrusion to the UAV. With consideration of the\ncomputation overhead and the detection performance in the wild, we expect our\nmodel can be a concrete and practical baseline IDS on the UAV.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 15:52:22 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Park", "Kyung Ho", ""], ["Park", "Eunji", ""], ["Kim", "Huy Kang", ""]]}, {"id": "2011.00559", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Sarthak Gupte, Marcos Zampieri, Ifeoma Nwogu", "title": "WLV-RIT at HASOC-Dravidian-CodeMix-FIRE2020: Offensive Language\n  Identification in Code-switched YouTube Comments", "comments": "Accepted to FIRE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the WLV-RIT entry to the Hate Speech and Offensive\nContent Identification in Indo-European Languages (HASOC) shared task 2020. The\nHASOC 2020 organizers provided participants with annotated datasets containing\nsocial media posts of code-mixed in Dravidian languages (Malayalam-English and\nTamil-English). We participated in task 1: Offensive comment identification in\nCode-mixed Malayalam Youtube comments. In our methodology, we take advantage of\navailable English data by applying cross-lingual contextual word embeddings and\ntransfer learning to make predictions to Malayalam data. We further improve the\nresults using various fine tuning strategies. Our system achieved 0.89 weighted\naverage F1 score for the test set and it ranked 5th place out of 12\nparticipants.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 16:52:08 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Gupte", "Sarthak", ""], ["Zampieri", "Marcos", ""], ["Nwogu", "Ifeoma", ""]]}, {"id": "2011.00569", "submitter": "C.-H. Huck Yang", "authors": "Jia-Hong Huang, Chao-Han Huck Yang, Fangyu Liu, Meng Tian, Yi-Chieh\n  Liu, Ting-Wei Wu, I-Hung Lin, Kang Wang, Hiromasa Morikawa, Hernghua Chang,\n  Jesper Tegner, Marcel Worring", "title": "DeepOpht: Medical Report Generation for Retinal Images via Deep Models\n  and Visual Explanation", "comments": "Accepted to IEEE WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an AI-based method that intends to improve the\nconventional retinal disease treatment procedure and help ophthalmologists\nincrease diagnosis efficiency and accuracy. The proposed method is composed of\na deep neural networks-based (DNN-based) module, including a retinal disease\nidentifier and clinical description generator, and a DNN visual explanation\nmodule. To train and validate the effectiveness of our DNN-based module, we\npropose a large-scale retinal disease image dataset. Also, as ground truth, we\nprovide a retinal image dataset manually labeled by ophthalmologists to\nqualitatively show, the proposed AI-based method is effective. With our\nexperimental results, we show that the proposed method is quantitatively and\nqualitatively effective. Our method is capable of creating meaningful retinal\nimage descriptions and visual explanations that are clinically relevant.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:28:12 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Huang", "Jia-Hong", ""], ["Yang", "Chao-Han Huck", ""], ["Liu", "Fangyu", ""], ["Tian", "Meng", ""], ["Liu", "Yi-Chieh", ""], ["Wu", "Ting-Wei", ""], ["Lin", "I-Hung", ""], ["Wang", "Kang", ""], ["Morikawa", "Hiromasa", ""], ["Chang", "Hernghua", ""], ["Tegner", "Jesper", ""], ["Worring", "Marcel", ""]]}, {"id": "2011.00573", "submitter": "Nikolaos Tselepidis", "authors": "Nikolaos Tselepidis and Jonas Kohler and Antonio Orvieto", "title": "Two-Level K-FAC Preconditioning for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of deep learning, many optimization methods use gradient\ncovariance information in order to accelerate the convergence of Stochastic\nGradient Descent. In particular, starting with Adagrad, a seemingly endless\nline of research advocates the use of diagonal approximations of the so-called\nempirical Fisher matrix in stochastic gradient-based algorithms, with the most\nprominent one arguably being Adam. However, in recent years, several works cast\ndoubt on the theoretical basis of preconditioning with the empirical Fisher\nmatrix, and it has been shown that more sophisticated approximations of the\nactual Fisher matrix more closely resemble the theoretically well-motivated\nNatural Gradient Descent. One particularly successful variant of such methods\nis the so-called K-FAC optimizer, which uses a Kronecker-factored\nblock-diagonal Fisher approximation as preconditioner. In this work, drawing\ninspiration from two-level domain decomposition methods used as preconditioners\nin the field of scientific computing, we extend K-FAC by enriching it with\noff-diagonal (i.e. global) curvature information in a computationally efficient\nway. We achieve this by adding a coarse-space correction term to the\npreconditioner, which captures the global Fisher information matrix at a\ncoarser scale. We present a small set of experimental results suggesting\nimproved convergence behaviour of our proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:54:21 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 23:07:36 GMT"}, {"version": "v3", "created": "Sun, 6 Dec 2020 21:35:46 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tselepidis", "Nikolaos", ""], ["Kohler", "Jonas", ""], ["Orvieto", "Antonio", ""]]}, {"id": "2011.00576", "submitter": "Andrew Wagenmaker", "authors": "Andrew Wagenmaker, Julian Katz-Samuels, Kevin Jamieson", "title": "Experimental Design for Regret Minimization in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel experimental design-based algorithm to\nminimize regret in online stochastic linear and combinatorial bandits. While\nexisting literature tends to focus on optimism-based algorithms--which have\nbeen shown to be suboptimal in many cases--our approach carefully plans which\naction to take by balancing the tradeoff between information gain and reward,\novercoming the failures of optimism. In addition, we leverage tools from the\ntheory of suprema of empirical processes to obtain regret guarantees that scale\nwith the Gaussian width of the action set, avoiding wasteful union bounds. We\nprovide state-of-the-art finite time regret guarantees and show that our\nalgorithm can be applied in both the bandit and semi-bandit feedback regime. In\nthe combinatorial semi-bandit setting, we show that our algorithm is\ncomputationally efficient and relies only on calls to a linear maximization\noracle. In addition, we show that with slight modification our algorithm can be\nused for pure exploration, obtaining state-of-the-art pure exploration\nguarantees in the semi-bandit setting. Finally, we provide, to the best of our\nknowledge, the first example where optimism fails in the semi-bandit regime,\nand show that in this setting our algorithm succeeds.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:59:19 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 01:07:39 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wagenmaker", "Andrew", ""], ["Katz-Samuels", "Julian", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2011.00578", "submitter": "Basma Alharbi", "authors": "Basma Alharbi, Hind Alamro, Manal Alshehri, Zuhair Khayyat, Manal\n  Kalkatawi, Inji Ibrahim Jaber, Xiangliang Zhang", "title": "ASAD: A Twitter-based Benchmark Arabic Sentiment Analysis Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a detailed description of a new Twitter-based benchmark\ndataset for Arabic Sentiment Analysis (ASAD), which is launched in a\ncompetition3, sponsored by KAUST for awarding 10000 USD, 5000 USD and 2000 USD\nto the first, second and third place winners, respectively. Compared to other\npublicly released Arabic datasets, ASAD is a large, high-quality annotated\ndataset(including 95K tweets), with three-class sentiment labels (positive,\nnegative and neutral). We presents the details of the data collection process\nand annotation process. In addition, we implement several baseline models for\nthe competition task and report the results as a reference for the participants\nto the competition.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:03:22 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 20:34:36 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 03:46:46 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Alharbi", "Basma", ""], ["Alamro", "Hind", ""], ["Alshehri", "Manal", ""], ["Khayyat", "Zuhair", ""], ["Kalkatawi", "Manal", ""], ["Jaber", "Inji Ibrahim", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2011.00580", "submitter": "Xiang Deng", "authors": "Xiang Deng and Zhongfei Zhang", "title": "An Embarrassingly Simple Approach to Training Ternary Weight Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have achieved great successes in various domains\nof artificial intelligence, but they require large amounts of memory and\ncomputational power. This severely restricts their implementation on\nresource-limited hardware. One approach to solving this problem is to train\nDNNs with ternary weights \\{-1, 0, +1\\}, thus avoiding multiplications and\ndramatically reducing the memory and computation requirements. However, the\nexisting approaches to training ternary weight networks either have a large\nperformance gap to the full precision counterparts or have a complex training\nprocess, which makes ternary weight networks not widely used. In this paper, we\npropose an embarrassingly simple approach (ESA) to training ternary weight\nnetworks. Specifically, ESA first parameterizes the weights $W$ in a DNN with\n$\\tanh(\\Theta)$ where $\\Theta$ are the parameters, so that the weight values\nare limited in the range between -1 and +1, and then a weight discretization\nregularization (WDR) is used to force the weights to be ternary. Consequently,\nESA has an extremely high code reuse rate when converting a full precision\nweight DNN to the ternary version. More importantly, ESA is able to control the\nsparsity (i.e., the percentage of 0s) of the ternary weights through a\ncontroller $\\alpha$ in WDR. We theoretically and empirically show that the\nsparsity of the trained ternary weights is positively related to $\\alpha$. To\nthe best of our knowledge, ESA is the first sparsity-controlling approach to\ntraining ternary weight networks. Extensive experiments on several benchmark\ndatasets demonstrate that ESA beats the state-of-the-art approaches\nsignificantly and matches the performances of the full precision weight\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:06:26 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Deng", "Xiang", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "2011.00597", "submitter": "Simon Ging", "authors": "Simon Ging (1), Mohammadreza Zolfaghari (1), Hamed Pirsiavash (2),\n  Thomas Brox (1) ((1) University of Freiburg, (2) University of Maryland\n  Baltimore County)", "title": "COOT: Cooperative Hierarchical Transformer for Video-Text Representation\n  Learning", "comments": "27 pages, 5 figures, 19 tables. To be published in the 34th\n  conference on Neural Information Processing Systems (NeurIPS 2020). The first\n  two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real-world video-text tasks involve different levels of granularity,\nsuch as frames and words, clip and sentences or videos and paragraphs, each\nwith distinct semantics. In this paper, we propose a Cooperative hierarchical\nTransformer (COOT) to leverage this hierarchy information and model the\ninteractions between different levels of granularity and different modalities.\nThe method consists of three major components: an attention-aware feature\naggregation layer, which leverages the local temporal context (intra-level,\ne.g., within a clip), a contextual transformer to learn the interactions\nbetween low-level and high-level semantics (inter-level, e.g. clip-video,\nsentence-paragraph), and a cross-modal cycle-consistency loss to connect video\nand text. The resulting method compares favorably to the state of the art on\nseveral benchmarks while having few parameters. All code is available\nopen-source at https://github.com/gingsi/coot-videotext\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 18:54:09 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ging", "Simon", ""], ["Zolfaghari", "Mohammadreza", ""], ["Pirsiavash", "Hamed", ""], ["Brox", "Thomas", ""]]}, {"id": "2011.00603", "submitter": "Guilherme Alves", "authors": "Guilherme Alves, Vaishnavi Bhargava, Miguel Couceiro, Amedeo Napoli", "title": "Making ML models fairer through explanations: the case of LimeOut", "comments": "11 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Algorithmic decisions are now being used on a daily basis, and based on\nMachine Learning (ML) processes that may be complex and biased. This raises\nseveral concerns given the critical impact that biased decisions may have on\nindividuals or on society as a whole. Not only unfair outcomes affect human\nrights, they also undermine public trust in ML and AI. In this paper we address\nfairness issues of ML models based on decision outcomes, and we show how the\nsimple idea of \"feature dropout\" followed by an \"ensemble approach\" can improve\nmodel fairness. To illustrate, we will revisit the case of \"LimeOut\" that was\nproposed to tackle \"process fairness\", which measures a model's reliance on\nsensitive or discriminatory features. Given a classifier, a dataset and a set\nof sensitive features, LimeOut first assesses whether the classifier is fair by\nchecking its reliance on sensitive features using \"Lime explanations\". If\ndeemed unfair, LimeOut then applies feature dropout to obtain a pool of\nclassifiers. These are then combined into an ensemble classifier that was\nempirically shown to be less dependent on sensitive features without\ncompromising the classifier's accuracy. We present different experiments on\nmultiple datasets and several state of the art classifiers, which show that\nLimeOut's classifiers improve (or at least maintain) not only process fairness\nbut also other fairness metrics such as individual and group fairness, equal\nopportunity, and demographic parity.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:07:11 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Alves", "Guilherme", ""], ["Bhargava", "Vaishnavi", ""], ["Couceiro", "Miguel", ""], ["Napoli", "Amedeo", ""]]}, {"id": "2011.00613", "submitter": "Yansong Gao Mr.", "authors": "Yansong Gao and Pratik Chaudhari", "title": "An Information-Geometric Distance on the Space of Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper prescribes a distance between learning tasks modeled as joint\ndistributions on data and labels. Using tools in information geometry, the\ndistance is defined to be the length of the shortest weight trajectory on a\nRiemannian manifold as a classifier is fitted on an interpolated task. The\ninterpolated task evolves from the source to the target task using an optimal\ntransport formulation. This distance, which we call the \"coupled transfer\ndistance\" can be compared across different classifier architectures. We develop\nan algorithm to compute the distance which iteratively transports the marginal\non the data of the source task to that of the target task while updating the\nweights of the classifier to track this evolving data distribution. We develop\ntheory to show that our distance captures the intuitive idea that a good\ntransfer trajectory is the one that keeps the generalization gap small during\ntransfer, in particular at the end on the target task. We perform thorough\nempirical validation and analysis across diverse image classification datasets\nto show that the coupled transfer distance correlates strongly with the\ndifficulty of fine-tuning.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:48:39 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 03:33:30 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gao", "Yansong", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2011.00617", "submitter": "Brittany Carr", "authors": "Henry Adams, Brittany Carr, Elin Farnell", "title": "Support Vector Machines and Radon's Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO math.GN math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A support vector machine (SVM) is an algorithm which finds a hyperplane that\noptimally separates labeled data points in $\\mathbb{R}^n$ into positive and\nnegative classes. The data points on the margin of this separating hyperplane\nare called support vectors. We study the possible configurations of support\nvectors for points in general position. In particular, we connect the possible\nconfigurations to Radon's theorem, which provides guarantees for when a set of\npoints can be divided into two classes (positive and negative) whose convex\nhulls intersect. If the positive and negative support vectors in a generic SVM\nconfiguration are projected to the separating hyperplane, then these projected\npoints will form a Radon configuration. Further, with a particular type of\ngeneral position, we show there are at most $n+1$ support vectors. This can be\nused to test the level of machine precision needed in a support vector machine\nimplementation. We also show the projections of the convex hulls of the support\nvectors intersect in a single Radon point, and under a small enough\nperturbation, the points labeled as support vectors remain labeled as support\nvectors. We furthermore consider computations studying the expected number of\nsupport vectors for randomly generated data.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:57:46 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Adams", "Henry", ""], ["Carr", "Brittany", ""], ["Farnell", "Elin", ""]]}, {"id": "2011.00618", "submitter": "Sunder Ali Khowaja", "authors": "Kapal Dev, Sunder Ali Khowaja, Ankur Singh Bist, Vaibhav Saini, Surbhi\n  Bhatia", "title": "Triage of Potential COVID-19 Patients from Chest X-ray Images using\n  Hierarchical Convolutional Networks", "comments": "23 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The current COVID-19 pandemic has motivated the researchers to use artificial\nintelligence techniques for a potential alternative to reverse\ntranscription-polymerase chain reaction (RT-PCR) due to the limited scale of\ntesting. The chest X-ray (CXR) is one of the alternatives to achieve fast\ndiagnosis but the unavailability of large-scale annotated data makes the\nclinical implementation of machine learning-based COVID detection difficult.\nAnother issue is the usage of ImageNet pre-trained networks which does not\nextract reliable feature representations from medical images. In this paper, we\npropose the use of hierarchical convolutional network (HCN) architecture to\nnaturally augment the data along with diversified features. The HCN uses the\nfirst convolution layer from COVIDNet followed by the convolutional layers from\nwell-known pre-trained networks to extract the features. The use of the\nconvolution layer from COVIDNet ensures the extraction of representations\nrelevant to the CXR modality. We also propose the use of ECOC for encoding\nmulticlass problems to binary classification for improving the recognition\nperformance. Experimental results show that HCN architecture is capable of\nachieving better results in comparison to the existing studies. The proposed\nmethod can accurately triage potential COVID-19 patients through CXR images for\nsharing the testing load and increasing the testing capacity.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 20:01:22 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 15:47:46 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Dev", "Kapal", ""], ["Khowaja", "Sunder Ali", ""], ["Bist", "Ankur Singh", ""], ["Saini", "Vaibhav", ""], ["Bhatia", "Surbhi", ""]]}, {"id": "2011.00635", "submitter": "Jakub Marecek", "authors": "Jakub Marecek", "title": "Screening for an Infectious Disease as a Problem in Stochastic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent interest in screening populations for an\ninfectious disease. Here, we present a stochastic-control model, wherein the\noptimum screening policy is provably difficult to find, but wherein Thompson\nsampling has provably optimal performance guarantees in the form of Bayesian\nregret. Thompson sampling seems applicable especially to diseases, for which we\ndo not understand the dynamics well, such as to the super-spreading COVID-19.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 22:03:26 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Marecek", "Jakub", ""]]}, {"id": "2011.00639", "submitter": "Xing Han", "authors": "Xing Han, Joydeep Ghosh", "title": "Model-Agnostic Explanations using Minimal Forcing Subsets", "comments": "International Joint Conference on Neural Networks (IJCNN), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we find a subset of training samples that are most responsible for a\nspecific prediction made by a complex black-box machine learning model? More\ngenerally, how can we explain the model's decisions to end-users in a\ntransparent way? We propose a new model-agnostic algorithm to identify a\nminimal set of training samples that are indispensable for a given model's\ndecision at a particular test point, i.e., the model's decision would have\nchanged upon the removal of this subset from the training dataset. Our\nalgorithm identifies such a set of \"indispensable\" samples iteratively by\nsolving a constrained optimization problem. Further, we speed up the algorithm\nthrough efficient approximations and provide theoretical justification for its\nperformance. To demonstrate the applicability and effectiveness of our\napproach, we apply it to a variety of tasks including data poisoning detection,\ntraining set debugging and understanding loan decisions. The results show that\nour algorithm is an effective and easy-to-comprehend tool that helps to better\nunderstand local model behavior, and therefore facilitates the adoption of\nmachine learning in domains where such understanding is a requisite.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 22:45:16 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:27:22 GMT"}, {"version": "v3", "created": "Sun, 20 Jun 2021 03:32:40 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Han", "Xing", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "2011.00641", "submitter": "Chandler Squires", "authors": "Chandler Squires, Sara Magliacane, Kristjan Greenewald, Dmitriy Katz,\n  Murat Kocaoglu, Karthikeyan Shanmugam", "title": "Active Structure Learning of Causal DAGs via Directed Clique Tree", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of work has begun to study intervention design for efficient\nstructure learning of causal directed acyclic graphs (DAGs). A typical setting\nis a causally sufficient setting, i.e. a system with no latent confounders,\nselection bias, or feedback, when the essential graph of the observational\nequivalence class (EC) is given as an input and interventions are assumed to be\nnoiseless. Most existing works focus on worst-case or average-case lower bounds\nfor the number of interventions required to orient a DAG. These worst-case\nlower bounds only establish that the largest clique in the essential graph\ncould make it difficult to learn the true DAG. In this work, we develop a\nuniversal lower bound for single-node interventions that establishes that the\nlargest clique is always a fundamental impediment to structure learning.\nSpecifically, we present a decomposition of a DAG into independently orientable\ncomponents through directed clique trees and use it to prove that the number of\nsingle-node interventions necessary to orient any DAG in an EC is at least the\nsum of half the size of the largest cliques in each chain component of the\nessential graph. Moreover, we present a two-phase intervention design algorithm\nthat, under certain conditions on the chordal skeleton, matches the optimal\nnumber of interventions up to a multiplicative logarithmic factor in the number\nof maximal cliques. We show via synthetic experiments that our algorithm can\nscale to much larger graphs than most of the related work and achieves better\nworst-case performance than other scalable approaches. A code base to recreate\nthese results can be found at https://github.com/csquires/dct-policy\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 23:11:17 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Squires", "Chandler", ""], ["Magliacane", "Sara", ""], ["Greenewald", "Kristjan", ""], ["Katz", "Dmitriy", ""], ["Kocaoglu", "Murat", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "2011.00650", "submitter": "Konstantina Dritsa Mrs.", "authors": "Konstantina Dritsa, Thodoris Sotiropoulos, Haris Skarpetis, Panos\n  Louridas", "title": "Search Engine Similarity Analysis: A Combined Content and Rankings\n  Approach", "comments": "Shorter version of this paper was accepted in the 21st International\n  Conference on Web Information Systems Engineering (WISE 2020). The final\n  authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-62008-0_2", "journal-ref": null, "doi": "10.1007/978-3-030-62008-0_2", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How different are search engines? The search engine wars are a favorite topic\nof on-line analysts, as two of the biggest companies in the world, Google and\nMicrosoft, battle for prevalence of the web search space. Differences in search\nengine popularity can be explained by their effectiveness or other factors,\nsuch as familiarity with the most popular first engine, peer imitation, or\nforce of habit. In this work we present a thorough analysis of the affinity of\nthe two major search engines, Google and Bing, along with DuckDuckGo, which\ngoes to great lengths to emphasize its privacy-friendly credentials. To do so,\nwe collected search results using a comprehensive set of 300 unique queries for\ntwo time periods in 2016 and 2019, and developed a new similarity metric that\nleverages both the content and the ranking of search responses. We evaluated\nthe characteristics of the metric against other metrics and approaches that\nhave been proposed in the literature, and used it to (1) investigate the\nsimilarities of search engine results, (2) the evolution of their affinity over\ntime, (3) what aspects of the results influence similarity, and (4) how the\nmetric differs over different kinds of search services. We found that Google\nstands apart, but Bing and DuckDuckGo are largely indistinguishable from each\nother.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 23:57:24 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:11:10 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Dritsa", "Konstantina", ""], ["Sotiropoulos", "Thodoris", ""], ["Skarpetis", "Haris", ""], ["Louridas", "Panos", ""]]}, {"id": "2011.00659", "submitter": "Navodini Wijethilake", "authors": "Navodini Wijethilake, Dulani Meedeniya, Charith Chitraranjan, Indika\n  Perera", "title": "Survival prediction and risk estimation of Glioma patients using mRNA\n  expressions", "comments": "Presented at the 20th IEEE International Conference on BioInformatics\n  And BioEngineering (BIBE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gliomas are lethal type of central nervous system tumors with a poor\nprognosis. Recently, with the advancements in the micro-array technologies\nthousands of gene expression related data of glioma patients are acquired,\nleading for salient analysis in many aspects. Thus, genomics are been emerged\ninto the field of prognosis analysis. In this work, we identify survival\nrelated 7 gene signature and explore two approaches for survival prediction and\nrisk estimation. For survival prediction, we propose a novel probabilistic\nprogramming based approach, which outperforms the existing traditional machine\nlearning algorithms. An average 4 fold accuracy of 74% is obtained with the\nproposed algorithm. Further, we construct a prognostic risk model for risk\nestimation of glioma patients. This model reflects the survival of glioma\npatients, with high risk for low survival patients.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 00:39:04 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wijethilake", "Navodini", ""], ["Meedeniya", "Dulani", ""], ["Chitraranjan", "Charith", ""], ["Perera", "Indika", ""]]}, {"id": "2011.00697", "submitter": "Frank Xiao", "authors": "Frank Xiao", "title": "Time Series Forecasting with Stacked Long Short-Term Memory Networks", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) networks are often used to capture temporal\ndependency patterns. By stacking multi-layer LSTM networks, it can capture even\nmore complex patterns. This paper explores the effectiveness of applying\nstacked LSTM networks in the time series prediction domain, specifically, the\ntraffic volume forecasting. Being able to predict traffic volume more\naccurately can result in better planning, thus greatly reduce the operation\ncost and improve overall efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 03:09:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Xiao", "Frank", ""]]}, {"id": "2011.00701", "submitter": "Xiao Zhang", "authors": "Jiapeng Liu, Xiao Zhang, Dan Goldwasser, Xiao Wang", "title": "Cross-Lingual Document Retrieval with Smooth Learning", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual document search is an information retrieval task in which the\nqueries' language differs from the documents' language. In this paper, we study\nthe instability of neural document search models and propose a novel end-to-end\nrobust framework that achieves improved performance in cross-lingual search\nwith different documents' languages. This framework includes a novel measure of\nthe relevance, smooth cosine similarity, between queries and documents, and a\nnovel loss function, Smooth Ordinal Search Loss, as the objective. We further\nprovide theoretical guarantee on the generalization error bound for the\nproposed framework. We conduct experiments to compare our approach with other\ndocument search models, and observe significant gains under commonly used\nranking metrics on the cross-lingual document retrieval task in a variety of\nlanguages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 03:17:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Liu", "Jiapeng", ""], ["Zhang", "Xiao", ""], ["Goldwasser", "Dan", ""], ["Wang", "Xiao", ""]]}, {"id": "2011.00702", "submitter": "Rafael Pinto", "authors": "Rafael Pinto", "title": "Fast Reinforcement Learning with Incremental Gaussian Mixture Models", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a novel algorithm that integrates a data-efficient\nfunction approximator with reinforcement learning in continuous state spaces.\nAn online and incremental algorithm capable of learning from a single pass\nthrough data, called Incremental Gaussian Mixture Network (IGMN), was employed\nas a sample-efficient function approximator for the joint state and Q-values\nspace, all in a single model, resulting in a concise and data-efficient\nalgorithm, i.e., a reinforcement learning algorithm that learns from very few\ninteractions with the environment. Results are analyzed to explain the\nproperties of the obtained algorithm, and it is observed that the use of the\nIGMN function approximator brings some important advantages to reinforcement\nlearning in relation to conventional neural networks trained by gradient\ndescent methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 03:18:15 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Pinto", "Rafael", ""]]}, {"id": "2011.00704", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Dan Goldwasser", "title": "Semi-supervised Autoencoding Projective Dependency Parsing", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two end-to-end autoencoding models for semi-supervised\ngraph-based projective dependency parsing. The first model is a Locally\nAutoencoding Parser (LAP) encoding the input using continuous latent variables\nin a sequential manner; The second model is a Globally Autoencoding Parser\n(GAP) encoding the input into dependency trees as latent variables, with exact\ninference. Both models consist of two parts: an encoder enhanced by deep neural\nnetworks (DNN) that can utilize the contextual information to encode the input\ninto latent variables, and a decoder which is a generative model able to\nreconstruct the input. Both LAP and GAP admit a unified structure with\ndifferent loss functions for labeled and unlabeled data with shared parameters.\nWe conducted experiments on WSJ and UD dependency parsing data sets, showing\nthat our models can exploit the unlabeled data to improve the performance given\na limited amount of labeled data, and outperform a previously proposed\nsemi-supervised model.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 03:21:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhang", "Xiao", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2011.00716", "submitter": "Sangdon Park", "authors": "Sangdon Park, Shuo Li, Insup Lee, Osbert Bastani", "title": "PAC Confidence Predictions for Deep Neural Network Classifiers", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for deploying deep neural networks (DNNs) in safety critical\nsettings is the need to provide rigorous ways to quantify their uncertainty. In\nthis paper, we propose a novel algorithm for constructing predicted\nclassification confidences for DNNs that comes with provable correctness\nguarantees. Our approach uses Clopper-Pearson confidence intervals for the\nBinomial distribution in conjunction with the histogram binning approach to\ncalibrated prediction. In addition, we demonstrate how our predicted\nconfidences can be used to enable downstream guarantees in two settings: (i)\nfast DNN inference, where we demonstrate how to compose a fast but inaccurate\nDNN with an accurate but slow DNN in a rigorous way to improve performance\nwithout sacrificing accuracy, and (ii) safe planning, where we guarantee safety\nwhen using a DNN to predict whether a given action is safe based on visual\nobservations. In our experiments, we demonstrate that our approach can be used\nto provide guarantees for state-of-the-art DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:09:17 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 19:20:42 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 02:57:49 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 20:57:35 GMT"}, {"version": "v5", "created": "Wed, 17 Mar 2021 19:51:37 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Park", "Sangdon", ""], ["Li", "Shuo", ""], ["Lee", "Insup", ""], ["Bastani", "Osbert", ""]]}, {"id": "2011.00717", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei, Tom Wan, Jason Eisner", "title": "Noise-Contrastive Estimation for Multivariate Point Processes", "comments": "NeurIPS 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The log-likelihood of a generative model often involves both positive and\nnegative terms. For a temporal multivariate point process, the negative term\nsums over all the possible event types at each time and also integrates over\nall the possible times. As a result, maximum likelihood estimation is\nexpensive. We show how to instead apply a version of noise-contrastive\nestimation---a general parameter estimation method with a less expensive\nstochastic objective. Our specific instantiation of this general idea works out\nin an interestingly non-trivial way and has provable guarantees for its\noptimality, consistency and efficiency. On several synthetic and real-world\ndatasets, our method shows benefits: for the model to achieve the same level of\nlog-likelihood on held-out data, our method needs considerably fewer function\nevaluations and less wall-clock time.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:09:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mei", "Hongyuan", ""], ["Wan", "Tom", ""], ["Eisner", "Jason", ""]]}, {"id": "2011.00718", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Fundamental Limits of Obfuscation for Linear Gaussian Dynamical Systems:\n  An Information-Theoretic Approach", "comments": "arXiv admin note: text overlap with arXiv:2008.04893", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.LG cs.SY eess.SP eess.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the fundamental limits of obfuscation in terms of\nprivacy-distortion tradeoffs for linear Gaussian dynamical systems via an\ninformation-theoretic approach. Particularly, we obtain analytical formulas\nthat capture the fundamental privacy-distortion tradeoffs when privacy masks\nare to be added to the outputs of the dynamical systems, while indicating\nexplicitly how to design the privacy masks in an optimal way: The privacy masks\nshould be colored Gaussian with power spectra shaped specifically based upon\nthe system and noise properties.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 20:05:50 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2011.00728", "submitter": "Keval Doshi", "authors": "Keval Doshi, Yasin Yilmaz", "title": "Road Damage Detection using Deep Ensemble Learning", "comments": "Submitted to IEEE BigData 2020. arXiv admin note: text overlap with\n  arXiv:2008.13101, arXiv:1811.04535 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road damage detection is critical for the maintenance of a road, which\ntraditionally has been performed using expensive high-performance sensors. With\nthe recent advances in technology, especially in computer vision, it is now\npossible to detect and categorize different types of road damages, which can\nfacilitate efficient maintenance and resource management. In this work, we\npresent an ensemble model for efficient detection and classification of road\ndamages, which we have submitted to the IEEE BigData Cup Challenge 2020. Our\nsolution utilizes a state-of-the-art object detector known as You Only Look\nOnce (YOLO-v4), which is trained on images of various types of road damages\nfrom Czech, Japan and India. Our ensemble approach was extensively tested with\nseveral different model versions and it was able to achieve an F1 score of\n0.628 on the test 1 dataset and 0.6358 on the test 2 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 03:18:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Doshi", "Keval", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2011.00731", "submitter": "Gary Pui-Tung Choi", "authors": "Ho Law, Gary P. T. Choi, Ka Chun Lam, Lok Ming Lui", "title": "Quasiconformal model with CNN features for large deformation image\n  registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG math.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration has been widely studied over the past several decades,\nwith numerous applications in science, engineering and medicine. Most of the\nconventional mathematical models for large deformation image registration rely\non prescribed landmarks, which usually require tedious manual labeling and are\nprone to error. In recent years, there has been a surge of interest in the use\nof machine learning for image registration. In this paper, we develop a novel\nmethod for large deformation image registration by a fusion of quasiconformal\ntheory and convolutional neural network (CNN). More specifically, we propose a\nquasiconformal energy model with a novel fidelity term that incorporates the\nfeatures extracted using a pre-trained CNN, thereby allowing us to obtain\nmeaningful registration results without any guidance of prescribed landmarks.\nMoreover, unlike many prior image registration methods, the bijectivity of our\nmethod is guaranteed by quasiconformal theory. Experimental results are\npresented to demonstrate the effectiveness of the proposed method. More\nbroadly, our work sheds light on how rigorous mathematical theories and\npractical machine learning approaches can be integrated for developing\ncomputational methods with improved performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:15:31 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:14:53 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2021 10:59:26 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Law", "Ho", ""], ["Choi", "Gary P. T.", ""], ["Lam", "Ka Chun", ""], ["Lui", "Lok Ming", ""]]}, {"id": "2011.00739", "submitter": "Qingjie Meng", "authors": "Qingjie Meng, Jacqueline Matthew, Veronika A. Zimmer, Alberto Gomez,\n  David F.A. Lloyd, Daniel Rueckert, Bernhard Kainz", "title": "Mutual Information-based Disentangled Neural Networks for Classifying\n  Unseen Categories in Different Domains: Application to Fetal Ultrasound\n  Imaging", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.00321", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks exhibit limited generalizability across images with\ndifferent entangled domain features and categorical features. Learning\ngeneralizable features that can form universal categorical decision boundaries\nacross domains is an interesting and difficult challenge. This problem occurs\nfrequently in medical imaging applications when attempts are made to deploy and\nimprove deep learning models across different image acquisition devices, across\nacquisition parameters or if some classes are unavailable in new training\ndatabases. To address this problem, we propose Mutual Information-based\nDisentangled Neural Networks (MIDNet), which extract generalizable categorical\nfeatures to transfer knowledge to unseen categories in a target domain. The\nproposed MIDNet adopts a semi-supervised learning paradigm to alleviate the\ndependency on labeled data. This is important for real-world applications where\ndata annotation is time-consuming, costly and requires training and expertise.\nWe extensively evaluate the proposed method on fetal ultrasound datasets for\ntwo different image classification tasks where domain features are respectively\ndefined by shadow artifacts and image acquisition devices. Experimental results\nshow that the proposed method outperforms the state-of-the-art on the\nclassification of unseen categories in a target domain with sparsely labeled\ntraining data.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:32:18 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 17:11:52 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Meng", "Qingjie", ""], ["Matthew", "Jacqueline", ""], ["Zimmer", "Veronika A.", ""], ["Gomez", "Alberto", ""], ["Lloyd", "David F. A.", ""], ["Rueckert", "Daniel", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2011.00745", "submitter": "Kai Ma", "authors": "Kai Ma, Peng Wan, Daoqiang Zhang", "title": "Transport based Graph Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph kernel is a powerful tool measuring the similarity between graphs. Most\nof the existing graph kernels focused on node labels or attributes and ignored\ngraph hierarchical structure information. In order to effectively utilize graph\nhierarchical structure information, we propose pyramid graph kernel based on\noptimal transport (OT). Each graph is embedded into hierarchical structures of\nthe pyramid. Then, the OT distance is utilized to measure the similarity\nbetween graphs in hierarchical structures. We also utilize the OT distance to\nmeasure the similarity between subgraphs and propose subgraph kernel based on\nOT. The positive semidefinite (p.s.d) of graph kernels based on optimal\ntransport distance is not necessarily possible. We further propose regularized\ngraph kernel based on OT where we add the kernel regularization to the original\noptimal transport distance to obtain p.s.d kernel matrix. We evaluate the\nproposed graph kernels on several benchmark classification tasks and compare\ntheir performance with the existing state-of-the-art graph kernels. In most\ncases, our proposed graph kernel algorithms outperform the competing methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 04:44:27 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ma", "Kai", ""], ["Wan", "Peng", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2011.00748", "submitter": "Bei Wang", "authors": "Ilkin Safarli, Youjia Zhou, Bei Wang", "title": "Interpreting Graph Drawing with Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning techniques to graph drawing has become an emergent\narea of research in visualization. In this paper, we interpret graph drawing as\na multi-agent reinforcement learning (MARL) problem. We first demonstrate that\na large number of classic graph drawing algorithms, including force-directed\nlayouts and stress majorization, can be interpreted within the framework of\nMARL. Using this interpretation, a node in the graph is assigned to an agent\nwith a reward function. Via multi-agent reward maximization, we obtain an\naesthetically pleasing graph layout that is comparable to the outputs of\nclassic algorithms. The main strength of a MARL framework for graph drawing is\nthat it not only unifies a number of classic drawing algorithms in a general\nformulation but also supports the creation of novel graph drawing algorithms by\nintroducing a diverse set of reward functions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 05:00:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Safarli", "Ilkin", ""], ["Zhou", "Youjia", ""], ["Wang", "Bei", ""]]}, {"id": "2011.00753", "submitter": "Sarkar Snigdha Sarathi Das", "authors": "Sarkar Snigdha Sarathi Das, Subangkar Karmaker Shanto, Masum Rahman,\n  Md. Saiful Islam, Atif Rahman, Mohammad Mehedy Masud, Mohammed Eunus Ali", "title": "BayesBeat: A Bayesian Deep Learning Approach for Atrial Fibrillation\n  Detection from Noisy Photoplethysmography Data", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of smartwatches as affordable and longitudinal\nmonitoring devices enables us to capture photoplethysmography (PPG) sensor data\nfor detecting Atrial Fibrillation (AF) in real-time. A significant challenge in\nAF detection from PPG signals comes from the inherent noise in the smartwatch\nPPG signals. In this paper, we propose a novel deep learning based approach,\nBayesBeat that leverages the power of Bayesian deep learning to accurately\ninfer AF risks from noisy PPG signals, and at the same time provide the\nuncertainty estimate of the prediction. Bayesbeat is efficient, robust,\nflexible, and highly scalable which makes it particularly suitable for\ndeployment in commercially available wearable devices. Extensive experiments on\na recently published large dataset reveal that our proposed method BayesBeat\nsubstantially outperforms the existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 05:20:32 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Das", "Sarkar Snigdha Sarathi", ""], ["Shanto", "Subangkar Karmaker", ""], ["Rahman", "Masum", ""], ["Islam", "Md. Saiful", ""], ["Rahman", "Atif", ""], ["Masud", "Mohammad Mehedy", ""], ["Ali", "Mohammed Eunus", ""]]}, {"id": "2011.00754", "submitter": "Thanh-Tung Hoang", "authors": "Hoang Thanh-Tung, Truyen Tran", "title": "Toward a Generalization Metric for Deep Generative Models", "comments": "1st I Can't Believe It's Not Better Workshop (ICBINB@NeurIPS 2020).\n  Source code is available at https://github.com/htt210/GeneralizationMetricGAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the generalization capacity of Deep Generative Models (DGMs) is\ndifficult because of the curse of dimensionality. Evaluation metrics for DGMs\nsuch as Inception Score, Fr\\'echet Inception Distance, Precision-Recall, and\nNeural Net Divergence try to estimate the distance between the generated\ndistribution and the target distribution using a polynomial number of samples.\nThese metrics are the target of researchers when designing new models. Despite\nthe claims, it is still unclear how well can they measure the generalization\ncapacity of a generative model. In this paper, we investigate the capacity of\nthese metrics in measuring the generalization capacity. We introduce a\nframework for comparing the robustness of evaluation metrics. We show that\nbetter scores in these metrics do not imply better generalization. They can be\nfooled easily by a generator that memorizes a small subset of the training set.\nWe propose a fix to the NND metric to make it more robust to noise in the\ngenerated data. Toward building a robust metric for generalization, we propose\nto apply the Minimum Description Length principle to the problem of evaluating\nDGMs. We develop an efficient method for estimating the complexity of\nGenerative Latent Variable Models (GLVMs). Experimental results show that our\nmetric can effectively detect training set memorization and distinguish GLVMs\nof different generalization capacities. Source code is available at\nhttps://github.com/htt210/GeneralizationMetricGAN.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 05:32:07 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 03:42:29 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 12:36:45 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Thanh-Tung", "Hoang", ""], ["Tran", "Truyen", ""]]}, {"id": "2011.00756", "submitter": "Joanne Kim", "authors": "Joanne Taery Kim and Sehoon Ha", "title": "Observation Space Matters: Benchmark and Optimization Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep reinforcement learning (deep RL) enable researchers\nto solve challenging control problems, from simulated environments to\nreal-world robotic tasks. However, deep RL algorithms are known to be sensitive\nto the problem formulation, including observation spaces, action spaces, and\nreward functions. There exist numerous choices for observation spaces but they\nare often designed solely based on prior knowledge due to the lack of\nestablished principles. In this work, we conduct benchmark experiments to\nverify common design choices for observation spaces, such as Cartesian\ntransformation, binary contact flags, a short history, or global positions.\nThen we propose a search algorithm to find the optimal observation spaces,\nwhich examines various candidate observation spaces and removes unnecessary\nobservation channels with a Dropout-Permutation test. We demonstrate that our\nalgorithm significantly improves learning speed compared to manually designed\nobservation spaces. We also analyze the proposed algorithm by evaluating\ndifferent hyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 05:40:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kim", "Joanne Taery", ""], ["Ha", "Sehoon", ""]]}, {"id": "2011.00768", "submitter": "Feng Cen", "authors": "Feng Cen (1), Xiaoyu Zhao (1), Wuzhuang Li (1) and Guanghui Wang (2)\n  ((1) The Department of Control Science & Engineering, College of Electronics\n  and Information Engineering, Tongji University, Shanghai 201804, China, (2)\n  Department of Computer Science, Ryerson University, Toronto, ON, Canada M5B\n  2K3)", "title": "Deep Feature Augmentation for Occluded Image Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2020.107737", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the difficulty in acquiring massive task-specific occluded images, the\nclassification of occluded images with deep convolutional neural networks\n(CNNs) remains highly challenging. To alleviate the dependency on large-scale\noccluded image datasets, we propose a novel approach to improve the\nclassification accuracy of occluded images by fine-tuning the pre-trained\nmodels with a set of augmented deep feature vectors (DFVs). The set of\naugmented DFVs is composed of original DFVs and pseudo-DFVs. The pseudo-DFVs\nare generated by randomly adding difference vectors (DVs), extracted from a\nsmall set of clean and occluded image pairs, to the real DFVs. In the\nfine-tuning, the back-propagation is conducted on the DFV data flow to update\nthe network parameters. The experiments on various datasets and network\nstructures show that the deep feature augmentation significantly improves the\nclassification accuracy of occluded images without a noticeable influence on\nthe performance of clean images. Specifically, on the ILSVRC2012 dataset with\nsynthetic occluded images, the proposed approach achieves 11.21% and 9.14%\naverage increases in classification accuracy for the ResNet50 networks\nfine-tuned on the occlusion-exclusive and occlusion-inclusive training sets,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 06:25:05 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cen", "Feng", ""], ["Zhao", "Xiaoyu", ""], ["Li", "Wuzhuang", ""], ["Wang", "Guanghui", ""]]}, {"id": "2011.00771", "submitter": "Jae-Jin Jeon", "authors": "Jae-Jin Jeon, Eesung Kim", "title": "Multitask Learning and Joint Optimization for Transformer-RNN-Transducer\n  Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several types of end-to-end speech recognition methods named\ntransformer-transducer were introduced. According to those kinds of methods,\ntranscription networks are generally modeled by transformer-based neural\nnetworks, while prediction networks could be modeled by either transformers or\nrecurrent neural networks (RNN). This paper explores multitask learning, joint\noptimization, and joint decoding methods for transformer-RNN-transducer\nsystems. Our proposed methods have the main advantage in that the model can\nmaintain information on the large text corpus. We prove their effectiveness by\nperforming experiments utilizing the well-known ESPNET toolkit for the widely\nused Librispeech datasets. We also show that the proposed methods can reduce\nword error rate (WER) by 16.6 % and 13.3 % for test-clean and test-other\ndatasets, respectively, without changing the overall model structure nor\nexploiting an external LM.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 06:38:06 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Jeon", "Jae-Jin", ""], ["Kim", "Eesung", ""]]}, {"id": "2011.00773", "submitter": "Varun Behera", "authors": "Ashish Ranjan, Varun Nagesh Jolly Behera, Motahar Reza", "title": "Using a Bi-directional LSTM Model with Attention Mechanism trained on\n  MIDI Data for Generating Unique Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating music is an interesting and challenging problem in the field of\nmachine learning. Mimicking human creativity has been popular in recent years,\nespecially in the field of computer vision and image processing. With the\nadvent of GANs, it is possible to generate new similar images, based on trained\ndata. But this cannot be done for music similarly, as music has an extra\ntemporal dimension. So it is necessary to understand how music is represented\nin digital form. When building models that perform this generative task, the\nlearning and generation part is done in some high-level representation such as\nMIDI (Musical Instrument Digital Interface) or scores. This paper proposes a\nbi-directional LSTM (Long short-term memory) model with attention mechanism\ncapable of generating similar type of music based on MIDI data. The music\ngenerated by the model follows the theme/style of the music the model is\ntrained on. Also, due to the nature of MIDI, the tempo, instrument, and other\nparameters can be defined, and changed, post generation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 06:43:28 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ranjan", "Ashish", ""], ["Behera", "Varun Nagesh Jolly", ""], ["Reza", "Motahar", ""]]}, {"id": "2011.00789", "submitter": "Yang Zhao", "authors": "Yang Zhao and Hao Zhang", "title": "A topological approach to exploring convolutional neural networks", "comments": "8 pages, 4 figures, pnas manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the elusive understanding concerning convolution neural networks\n(CNNs) in view of topology, we present two theoretical frameworks to interpret\ntwo topics by using topological data analysis. The first one reveals the\ntopological essence of CNN filters. Our theory first abstracts a topological\nrepresentation of how the features locate for a CNN filter, named feature\ntopology, and characterises it by defining the starting edge density. We reveal\na principle of CNN filters: tending to organize the feature topologies for the\nsame category, and thus propose the SED Distribution to statistically describe\nsuch an organization. We demonstrate the effectiveness of CNN filters reflects\nin the compactness of SED Distribution, and introduce filter entropy to measure\nit. Remarkably, the variation of filter entropy during training reveals the\nessence of CNN training: a filter-entropy-decrease process. Also, based on the\nprinciple, we give a metric to assess the filter performance. The second one\ninvestigates the inter-class distinguishability in a model-agnostic way. For\neach class, we propose the MBC Distribution, a distribution that could\ndifferentiate categories by characterising the intrinsic organization of the\ngiven category. As for multi-classes, we introduce the category distance which\nmetricizes the distance between two categories, and moreover propose the CD\nMatrix that comprehensively evaluates not just the distinguishability between\neach two category pair but the distinguishable degree for each category.\nFinally, our experiment results confirm our theories.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 07:37:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhao", "Yang", ""], ["Zhang", "Hao", ""]]}, {"id": "2011.00791", "submitter": "Han Zheng", "authors": "Han Zheng, Pengfei Wei, Jing Jiang, Guodong Long, Qinghua Lu, Chengqi\n  Zhang", "title": "Cooperative Heterogeneous Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous deep reinforcement learning agents have been proposed, and each of\nthem has its strengths and flaws. In this work, we present a Cooperative\nHeterogeneous Deep Reinforcement Learning (CHDRL) framework that can learn a\npolicy by integrating the advantages of heterogeneous agents. Specifically, we\npropose a cooperative learning framework that classifies heterogeneous agents\ninto two classes: global agents and local agents. Global agents are off-policy\nagents that can utilize experiences from the other agents. Local agents are\neither on-policy agents or population-based evolutionary algorithms (EAs)\nagents that can explore the local area effectively. We employ global agents,\nwhich are sample-efficient, to guide the learning of local agents so that local\nagents can benefit from sample-efficient agents and simultaneously maintain\ntheir advantages, e.g., stability. Global agents also benefit from effective\nlocal searches. Experimental studies on a range of continuous control tasks\nfrom the Mujoco benchmark show that CHDRL achieves better performance compared\nwith state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 07:39:09 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zheng", "Han", ""], ["Wei", "Pengfei", ""], ["Jiang", "Jing", ""], ["Long", "Guodong", ""], ["Lu", "Qinghua", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2011.00792", "submitter": "Marcel Wever", "authors": "Eyke H\\\"ullermeier, Marcel Wever, Eneldo Loza Mencia, Johannes\n  F\\\"urnkranz, Michael Rapp", "title": "A Flexible Class of Dependence-aware Multi-Label Loss Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label classification is the task of assigning a subset of labels to a\ngiven query instance. For evaluating such predictions, the set of predicted\nlabels needs to be compared to the ground-truth label set associated with that\ninstance, and various loss functions have been proposed for this purpose. In\naddition to assessing predictive accuracy, a key concern in this regard is to\nfoster and to analyze a learner's ability to capture label dependencies. In\nthis paper, we introduce a new class of loss functions for multi-label\nclassification, which overcome disadvantages of commonly used losses such as\nHamming and subset 0/1. To this end, we leverage the mathematical framework of\nnon-additive measures and integrals. Roughly speaking, a non-additive measure\nallows for modeling the importance of correct predictions of label subsets\n(instead of single labels), and thereby their impact on the overall evaluation,\nin a flexible way - by giving full importance to single labels and the entire\nlabel set, respectively, Hamming and subset 0/1 are rather extreme in this\nregard. We present concrete instantiations of this class, which comprise\nHamming and subset 0/1 as special cases, and which appear to be especially\nappealing from a modeling perspective. The assessment of multi-label\nclassifiers in terms of these losses is illustrated in an empirical study.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 07:42:15 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["H\u00fcllermeier", "Eyke", ""], ["Wever", "Marcel", ""], ["Mencia", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""], ["Rapp", "Michael", ""]]}, {"id": "2011.00802", "submitter": "Zhongfen Deng", "authors": "Zhongfen Deng, Hao Peng, Congying Xia, Jianxin Li, Lifang He, Philip\n  S. Yu", "title": "Hierarchical Bi-Directional Self-Attention Networks for Paper Review\n  Rating Recommendation", "comments": "Accepted by COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Review rating prediction of text reviews is a rapidly growing technology with\na wide range of applications in natural language processing. However, most\nexisting methods either use hand-crafted features or learn features using deep\nlearning with simple text corpus as input for review rating prediction,\nignoring the hierarchies among data. In this paper, we propose a Hierarchical\nbi-directional self-attention Network framework (HabNet) for paper review\nrating prediction and recommendation, which can serve as an effective\ndecision-making tool for the academic paper review process. Specifically, we\nleverage the hierarchical structure of the paper reviews with three levels of\nencoders: sentence encoder (level one), intra-review encoder (level two) and\ninter-review encoder (level three). Each encoder first derives contextual\nrepresentation of each level, then generates a higher-level representation, and\nafter the learning process, we are able to identify useful predictors to make\nthe final acceptance decision, as well as to help discover the inconsistency\nbetween numerical review ratings and text sentiment conveyed by reviewers.\nFurthermore, we introduce two new metrics to evaluate models in data imbalance\nsituations. Extensive experiments on a publicly available dataset (PeerRead)\nand our own collected dataset (OpenReview) demonstrate the superiority of the\nproposed approach compared with state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:07:50 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Deng", "Zhongfen", ""], ["Peng", "Hao", ""], ["Xia", "Congying", ""], ["Li", "Jianxin", ""], ["He", "Lifang", ""], ["Yu", "Philip S.", ""]]}, {"id": "2011.00810", "submitter": "Konstantinos Stavropoulos", "authors": "Dimitris Fotakis, Alkis Kalavasis, Konstantinos Stavropoulos", "title": "Aggregating Incomplete and Noisy Rankings", "comments": "21 pages, 3 figures. Minor changes and experimental results added in\n  this version. Corresponding to the camera-ready version that appeared in the\n  24th International Conference on Artificial Intelligence and Statistics\n  (AISTATS 2021)", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics, PMLR 130:2278-2286, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning the true ordering of a set of\nalternatives from largely incomplete and noisy rankings. We introduce a natural\ngeneralization of both the classical Mallows model of ranking distributions and\nthe extensively studied model of noisy pairwise comparisons. Our selective\nMallows model outputs a noisy ranking on any given subset of alternatives,\nbased on an underlying Mallows distribution. Assuming a sequence of subsets\nwhere each pair of alternatives appears frequently enough, we obtain strong\nasymptotically tight upper and lower bounds on the sample complexity of\nlearning the underlying complete ranking and the (identities and the) ranking\nof the top-k alternatives from selective Mallows rankings. Moreover, building\non the work of (Braverman and Mossel, 2009), we show how to efficiently compute\nthe maximum likelihood complete ranking from selective Mallows rankings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:18:33 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 13:01:15 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Fotakis", "Dimitris", ""], ["Kalavasis", "Alkis", ""], ["Stavropoulos", "Konstantinos", ""]]}, {"id": "2011.00813", "submitter": "Viktor Bengs", "authors": "Viktor Bengs and Eyke H\\\"ullermeier", "title": "Multi-Armed Bandits with Censored Consumption of Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a resource-aware variant of the classical multi-armed bandit\nproblem: In each round, the learner selects an arm and determines a resource\nlimit. It then observes a corresponding (random) reward, provided the (random)\namount of consumed resources remains below the limit. Otherwise, the\nobservation is censored, i.e., no reward is obtained. For this problem setting,\nwe introduce a measure of regret, which incorporates the actual amount of\nallocated resources of each learning round as well as the optimality of\nrealizable rewards. Thus, to minimize regret, the learner needs to set a\nresource limit and choose an arm in such a way that the chance to realize a\nhigh reward within the predefined resource limit is high, while the resource\nlimit itself should be kept as low as possible. We derive the theoretical lower\nbound on the cumulative regret and propose a learning algorithm having a regret\nupper bound that matches the lower bound. In a simulation study, we show that\nour learning algorithm outperforms straightforward extensions of standard\nmulti-armed bandit algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:27:38 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bengs", "Viktor", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2011.00819", "submitter": "Yoan Russac", "authors": "Yoan Russac (DI-ENS, CNRS, PSL, VALDA), Louis Faury, Olivier Capp\\'e\n  (DI-ENS, VALDA), Aur\\'elien Garivier (UMPA-ENSL)", "title": "Self-Concordant Analysis of Generalized Linear Bandits with Forgetting", "comments": null, "journal-ref": "AISTATS 2021 - International Conference on Artificial Intelligence\n  and Statistics, Apr 2021, San Diego / Virtual, United States", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual sequential decision problems with categorical or numerical\nobservations are ubiquitous and Generalized Linear Bandits (GLB) offer a solid\ntheoretical framework to address them. In contrast to the case of linear\nbandits, existing algorithms for GLB have two drawbacks undermining their\napplicability. First, they rely on excessively pessimistic concentration bounds\ndue to the non-linear nature of the model. Second, they require either\nnon-convex projection steps or burn-in phases to enforce boundedness of the\nestimators. Both of these issues are worsened when considering non-stationary\nmodels, in which the GLB parameter may vary with time. In this work, we focus\non self-concordant GLB (which include logistic and Poisson regression) with\nforgetting achieved either by the use of a sliding window or exponential\nweights. We propose a novel confidence-based algorithm for the maximum-likehood\nestimator with forgetting and analyze its perfomance in abruptly changing\nenvironments. These results as well as the accompanying numerical simulations\nhighlight the potential of the proposed approach to address non-stationarity in\nGLB.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:36:39 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 09:37:14 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Russac", "Yoan", "", "DI-ENS, CNRS, PSL, VALDA"], ["Faury", "Louis", "", "DI-ENS, VALDA"], ["Capp\u00e9", "Olivier", "", "DI-ENS, VALDA"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"]]}, {"id": "2011.00825", "submitter": "Hayan Yin", "authors": "Haiyan Yin and Yingzhen Li and Sinno Jialin Pan and Cheng Zhang and\n  Sebastian Tschiatschek", "title": "Reinforcement Learning with Efficient Active Feature Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving real-life sequential decision making problems under partial\nobservability involves an exploration-exploitation problem. To be successful,\nan agent needs to efficiently gather valuable information about the state of\nthe world for making rewarding decisions. However, in real-life, acquiring\nvaluable information is often highly costly, e.g., in the medical domain,\ninformation acquisition might correspond to performing a medical test on a\npatient. This poses a significant challenge for the agent to perform optimally\nfor the task while reducing the cost for information acquisition. In this\npaper, we propose a model-based reinforcement learning framework that learns an\nactive feature acquisition policy to solve the exploration-exploitation problem\nduring its execution. Key to the success is a novel sequential variational\nauto-encoder that learns high-quality representations from partially observed\nstates, which are then used by the policy to maximize the task reward in a cost\nefficient manner. We demonstrate the efficacy of our proposed framework in a\ncontrol domain as well as using a medical simulator. In both tasks, our\nproposed method outperforms conventional baselines and results in policies with\ngreater cost efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 08:46:27 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yin", "Haiyan", ""], ["Li", "Yingzhen", ""], ["Pan", "Sinno Jialin", ""], ["Zhang", "Cheng", ""], ["Tschiatschek", "Sebastian", ""]]}, {"id": "2011.00835", "submitter": "Jeremie Messud Dr", "authors": "Thibault Lesieur, J\\'er\\'emie Messud, Issa Hammoud, Hanyuan Peng,\n  C\\'eline Lacombe, Paulien Jeunesse", "title": "Adversarial training for predictive tasks: theoretical analysis and\n  limitations in the deterministic case", "comments": "NeurIPS 2020, ICBINB Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To train a deep neural network to mimic the outcomes of processing sequences,\na version of Conditional Generalized Adversarial Network (CGAN) can be used. It\nhas been observed by others that CGAN can help to improve the results even for\ndeterministic sequences, where only one output is associated with the\nprocessing of a given input. Surprisingly, our CGAN-based tests on\ndeterministic geophysical processing sequences did not produce a real\nimprovement compared to the use of an $L_p$ loss; we here propose a first\ntheoretical explanation why. Our analysis goes from the non-deterministic case\nto the deterministic one. It led us to develop an adversarial way to train a\ncontent loss that gave better results on our data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:05:38 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 07:11:19 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 07:41:52 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lesieur", "Thibault", ""], ["Messud", "J\u00e9r\u00e9mie", ""], ["Hammoud", "Issa", ""], ["Peng", "Hanyuan", ""], ["Lacombe", "C\u00e9line", ""], ["Jeunesse", "Paulien", ""]]}, {"id": "2011.00836", "submitter": "Koushik Kumaran", "authors": "Pranav Mani, ES Gopi, Koushik Kumaran, Hrishikesh Shekhar, Sharan\n  Chandra", "title": "Ant Colony Inspired Machine Learning Algorithm for Identifying and\n  Emulating Virtual Sensors", "comments": "9 Pages, 7 Figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible. All Authors are Co-First\n  Authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of systems employed in industrial environments demands a large\nnumber of sensors to facilitate meticulous monitoring and functioning. These\nrequirements could potentially lead to inefficient system designs. The data\ncoming from various sensors are often correlated due to the underlying\nrelations in the system parameters that the sensors monitor. In theory, it\nshould be possible to emulate the output of certain sensors based on other\nsensors. Tapping into such possibilities holds tremendous advantages in terms\nof reducing system design complexity. In order to identify the subset of\nsensors whose readings can be emulated, the sensors must be grouped into\nclusters. Complex systems generally have a large quantity of sensors that\ncollect and store data over prolonged periods of time. This leads to the\naccumulation of massive amounts of data. In this paper we propose an end-to-end\nalgorithmic solution, to realise virtual sensors in such systems. This\nalgorithm splits the dataset into blocks and clusters each of them\nindividually. It then fuses these clustering solutions to obtain a global\nsolution using an Ant Colony inspired technique, FAC2T. Having grouped the\nsensors into clusters, we select representative sensors from each cluster.\nThese sensors are retained in the system while the other sensors readings are\nemulated by applying supervised learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:06:14 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 08:10:38 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mani", "Pranav", ""], ["Gopi", "ES", ""], ["Kumaran", "Koushik", ""], ["Shekhar", "Hrishikesh", ""], ["Chandra", "Sharan", ""]]}, {"id": "2011.00840", "submitter": "C\\'ecilia Ostertag", "authors": "Cecilia Ostertag, Marie Beurton-Aimar, Muriel Visani, Thierry Urruty,\n  Karell Bertet", "title": "Predicting Brain Degeneration with a Multimodal Siamese Neural Network", "comments": "Accepted in the 10th International Conference on Image Processing\n  Theory, Tools and Applications (IPTA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study neurodegenerative diseases, longitudinal studies are carried on\nvolunteer patients. During a time span of several months to several years, they\ngo through regular medical visits to acquire data from different modalities,\nsuch as biological samples, cognitive tests, structural and functional imaging.\nThese variables are heterogeneous but they all depend on the patient's health\ncondition, meaning that there are possibly unknown relationships between all\nmodalities. Some information may be specific to some modalities, others may be\ncomplementary, and others may be redundant. Some data may also be missing. In\nthis work we present a neural network architecture for multimodal learning,\nable to use imaging and clinical data from two time points to predict the\nevolution of a neurodegenerative disease, and robust to missing values. Our\nmultimodal network achieves 92.5\\% accuracy and an AUC score of 0.978 over a\ntest set of 57 subjects. We also show the superiority of the multimodal\narchitecture, for up to 37.5\\% of missing values in test set subjects' clinical\nmeasurements, compared to a model using only the clinical modality.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:21:47 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ostertag", "Cecilia", ""], ["Beurton-Aimar", "Marie", ""], ["Visani", "Muriel", ""], ["Urruty", "Thierry", ""], ["Bertet", "Karell", ""]]}, {"id": "2011.00841", "submitter": "Arnab Bhattacharjee Mr", "authors": "Arnab Bhattacharjee, Ashu Verma, Sukumar Mishra, Tapan K Saha", "title": "Estimating State of Charge for xEV batteries using 1D Convolutional\n  Neural Networks and Transfer Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a one-dimensional convolutional neural network\n(CNN)-based state of charge estimation algorithm for electric vehicles. The CNN\nis trained using two publicly available battery datasets. The influence of\ndifferent types of noises on the estimation capabilities of the CNN model has\nbeen studied. Moreover, a transfer learning mechanism is proposed in order to\nmake the developed algorithm generalize better and estimate with an acceptable\naccuracy when a battery with different chemical characteristics than the one\nused for training the model, is used. It has been observed that using transfer\nlearning, the model can learn sufficiently well with significantly less amount\nof battery data. The proposed method fares well in terms of estimation\naccuracy, learning speed and generalization capability.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:27:03 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 10:59:27 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Bhattacharjee", "Arnab", ""], ["Verma", "Ashu", ""], ["Mishra", "Sukumar", ""], ["Saha", "Tapan K", ""]]}, {"id": "2011.00850", "submitter": "Mahesh Chandra", "authors": "Mahesh Chandra", "title": "On the Impact of Partial Sums on Interconnect Bandwidth and Memory\n  Accesses in a DNN Accelerator", "comments": null, "journal-ref": "2020 IEEE 15th International Conference on Industrial and\n  Information Systems (ICIIS)", "doi": "10.1109/ICIIS51140.2020.9342717", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dedicated accelerators are being designed to address the huge resource\nrequirement of the deep neural network (DNN) applications. The power,\nperformance and area (PPA) constraints limit the number of MACs available in\nthese accelerators. The convolution layers which require huge number of MACs\nare often partitioned into multiple iterative sub-tasks. This puts huge\npressure on the available system resources such as interconnect and memory\nbandwidth. The optimal partitioning of the feature maps for these sub-tasks can\nreduce the bandwidth requirement substantially. Some accelerators avoid\noff-chip or interconnect transfers by implementing local memories; however, the\nmemory accesses are still performed and a reduced bandwidth can help in saving\npower in such architectures. In this paper, we propose a first order analytical\nmethod to partition the feature maps for optimal bandwidth and evaluate the\nimpact of such partitioning on the bandwidth. This bandwidth can be saved by\ndesigning an active memory controller which can perform basic arithmetic\noperations. It is shown that the optimal partitioning and active memory\ncontroller can achieve up to 40% bandwidth reduction.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:44:50 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Chandra", "Mahesh", ""]]}, {"id": "2011.00851", "submitter": "Yuchen Zhao", "authors": "Yuchen Zhao, Hanyang Liu, Honglin Li, Payam Barnaghi, Hamed Haddadi", "title": "Semi-supervised Federated Learning for Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep learning models on in-home IoT sensory data is commonly used to\nrecognise human activities. Recently, federated learning systems that use edge\ndevices as clients to support local human activity recognition have emerged as\na new paradigm to combine local (individual-level) and global (group-level)\nmodels. This approach provides better scalability and generalisability and also\noffers better privacy compared with the traditional centralised analysis and\nlearning models. The assumption behind federated learning, however, relies on\nsupervised learning on clients. This requires a large volume of labelled data,\nwhich is difficult to collect in uncontrolled IoT environments such as remote\nin-home monitoring.\n  In this paper, we propose an activity recognition system that uses\nsemi-supervised federated learning, wherein clients conduct unsupervised\nlearning on autoencoders with unlabelled local data to learn general\nrepresentations, and a cloud server conducts supervised learning on an activity\nclassifier with labelled data. Our experimental results show that using a long\nshort-term memory autoencoder and a Softmax classifier, the accuracy of our\nproposed system is higher than that of both centralised systems and\nsemi-supervised federated learning using data augmentation. The accuracy is\nalso comparable to that of supervised federated learning systems. Meanwhile, we\ndemonstrate that our system can reduce the number of needed labels and the size\nof local models, and has faster local activity recognition speed than\nsupervised federated learning does.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:47:14 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 15:36:41 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 10:47:40 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Zhao", "Yuchen", ""], ["Liu", "Hanyang", ""], ["Li", "Honglin", ""], ["Barnaghi", "Payam", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2011.00860", "submitter": "Daniele Castellana", "authors": "Daniele Castellana, Davide Bacciu", "title": "Learning from Non-Binary Constituency Trees via Tensor Decomposition", "comments": "Accepted at COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing sentence constituency trees in binarised form is a common and\npopular approach in literature. However, constituency trees are non-binary by\nnature. The binarisation procedure changes deeply the structure, furthering\nconstituents that instead are close. In this work, we introduce a new approach\nto deal with non-binary constituency trees which leverages tensor-based models.\nIn particular, we show how a powerful composition function based on the\ncanonical tensor decomposition can exploit such a rich structure. A key point\nof our approach is the weight sharing constraint imposed on the factor\nmatrices, which allows limiting the number of model parameters. Finally, we\nintroduce a Tree-LSTM model which takes advantage of this composition function\nand we experimentally assess its performance on different NLP tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:06:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Castellana", "Daniele", ""], ["Bacciu", "Davide", ""]]}, {"id": "2011.00865", "submitter": "Matthias H\\\"user", "authors": "Jonathan Heitz, Joanna Ficek, Martin Faltys, Tobias M. Merz, Gunnar\n  R\\\"atsch, Matthias H\\\"user", "title": "WRSE -- a non-parametric weighted-resolution ensemble for predicting\n  individual survival distributions in the ICU", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic assessment of mortality risk in the intensive care unit (ICU) can be\nused to stratify patients, inform about treatment effectiveness or serve as\npart of an early-warning system. Static risk scoring systems, such as APACHE or\nSAPS, have recently been supplemented with data-driven approaches that track\nthe dynamic mortality risk over time. Recent works have focused on enhancing\nthe information delivered to clinicians even further by producing full survival\ndistributions instead of point predictions or fixed horizon risks. In this\nwork, we propose a non-parametric ensemble model, Weighted Resolution Survival\nEnsemble (WRSE), tailored to estimate such dynamic individual survival\ndistributions. Inspired by the simplicity and robustness of ensemble methods,\nthe proposed approach combines a set of binary classifiers spaced according to\na decay function reflecting the relevance of short-term mortality predictions.\nModels and baselines are evaluated under weighted calibration and\ndiscrimination metrics for individual survival distributions which closely\nreflect the utility of a model in ICU practice. We show competitive results\nwith state-of-the-art probabilistic models, while greatly reducing training\ntime by factors of 2-9x.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:13:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Heitz", "Jonathan", ""], ["Ficek", "Joanna", ""], ["Faltys", "Martin", ""], ["Merz", "Tobias M.", ""], ["R\u00e4tsch", "Gunnar", ""], ["H\u00fcser", "Matthias", ""]]}, {"id": "2011.00866", "submitter": "Rahul Radhakrishnan Iyer", "authors": "Rahul Radhakrishnan Iyer, Praveenkumar Kanumala, Stephen Guo, Kannan\n  Achan", "title": "An End-to-End ML System for Personalized Conversational Voice Models in\n  Walmart E-Commerce", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching for and making decisions about products is becoming increasingly\neasier in the e-commerce space, thanks to the evolution of recommender systems.\nPersonalization and recommender systems have gone hand-in-hand to help\ncustomers fulfill their shopping needs and improve their experiences in the\nprocess. With the growing adoption of conversational platforms for shopping, it\nhas become important to build personalized models at scale to handle the large\ninflux of data and perform inference in real-time. In this work, we present an\nend-to-end machine learning system for personalized conversational voice\ncommerce. We include components for implicit feedback to the model, model\ntraining, evaluation on update, and a real-time inference engine. Our system\npersonalizes voice shopping for Walmart Grocery customers and is currently\navailable via Google Assistant, Siri and Google Home devices.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:14:55 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Iyer", "Rahul Radhakrishnan", ""], ["Kanumala", "Praveenkumar", ""], ["Guo", "Stephen", ""], ["Achan", "Kannan", ""]]}, {"id": "2011.00871", "submitter": "Suvajit Majumder", "authors": "Heng-Yu Chen, Yang-Hui He, Shailesh Lal, Suvajit Majumder", "title": "Machine Learning Lie Structures & Applications to Physics", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.physletb.2021.136297", "report-no": null, "categories": "hep-th cs.LG hep-ph math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical and exceptional Lie algebras and their representations are among\nthe most important tools in the analysis of symmetry in physical systems. In\nthis letter we show how the computation of tensor products and branching rules\nof irreducible representations are machine-learnable, and can achieve relative\nspeed-ups of orders of magnitude in comparison to the non-ML algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:27:29 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 18:47:26 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Chen", "Heng-Yu", ""], ["He", "Yang-Hui", ""], ["Lal", "Shailesh", ""], ["Majumder", "Suvajit", ""]]}, {"id": "2011.00890", "submitter": "Yaoyiran Li", "authors": "Yaoyiran Li, Edoardo M. Ponti, Ivan Vuli\\'c and Anna Korhonen", "title": "Emergent Communication Pretraining for Few-Shot Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While state-of-the-art models that rely upon massively multilingual\npretrained encoders achieve sample efficiency in downstream applications, they\nstill require abundant amounts of unlabelled text. Nevertheless, most of the\nworld's languages lack such resources. Hence, we investigate a more radical\nform of unsupervised knowledge transfer in the absence of linguistic data. In\nparticular, for the first time we pretrain neural networks via emergent\ncommunication from referential games. Our key assumption is that grounding\ncommunication on images---as a crude approximation of real-world\nenvironments---inductively biases the model towards learning natural languages.\nOn the one hand, we show that this substantially benefits machine translation\nin few-shot settings. On the other hand, this also provides an extrinsic\nevaluation protocol to probe the properties of emergent languages ex vitro.\nIntuitively, the closer they are to natural languages, the higher the gains\nfrom pretraining on them should be. For instance, in this work we measure the\ninfluence of communication success and maximum sequence length on downstream\nperformances. Finally, we introduce a customised adapter layer and annealing\nstrategies for the regulariser of maximum-a-posteriori inference during\nfine-tuning. These turn out to be crucial to facilitate knowledge transfer and\nprevent catastrophic forgetting. Compared to a recurrent baseline, our method\nyields gains of $59.0\\%$$\\sim$$147.6\\%$ in BLEU score with only $500$ NMT\ntraining instances and $65.1\\%$$\\sim$$196.7\\%$ with $1,000$ NMT training\ninstances across four language pairs. These proof-of-concept results reveal the\npotential of emergent communication pretraining for both natural language\nprocessing tasks in resource-poor settings and extrinsic evaluation of\nartificial languages.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 10:57:53 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Li", "Yaoyiran", ""], ["Ponti", "Edoardo M.", ""], ["Vuli\u0107", "Ivan", ""], ["Korhonen", "Anna", ""]]}, {"id": "2011.00928", "submitter": "Andrea Bontempelli", "authors": "Andrea Bontempelli, Stefano Teso, Fausto Giunchiglia, Andrea Passerini", "title": "Learning in the Wild with Incremental Skeptical Gaussian Processes", "comments": "7 pages, 3 figures, code:\n  https://gitlab.com/abonte/incremental-skeptical-gp", "journal-ref": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence (IJCAI20). (2020). Pages 2886-2892", "doi": "10.24963/ijcai.2020/399", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn from human supervision is fundamental for personal\nassistants and other interactive applications of AI. Two central challenges for\ndeploying interactive learners in the wild are the unreliable nature of the\nsupervision and the varying complexity of the prediction task. We address a\nsimple but representative setting, incremental classification in the wild,\nwhere the supervision is noisy and the number of classes grows over time. In\norder to tackle this task, we propose a redesign of skeptical learning centered\naround Gaussian Processes (GPs). Skeptical learning is a recent interactive\nstrategy in which, if the machine is sufficiently confident that an example is\nmislabeled, it asks the annotator to reconsider her feedback. In many cases,\nthis is often enough to obtain clean supervision. Our redesign, dubbed ISGP,\nleverages the uncertainty estimates supplied by GPs to better allocate labeling\nand contradiction queries, especially in the presence of noise. Our experiments\non synthetic and real-world data show that, as a result, while the original\nformulation of skeptical learning produces over-confident models that can fail\ncompletely in the wild, ISGP works well at varying levels of noise and as new\nclasses are observed.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 12:19:47 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bontempelli", "Andrea", ""], ["Teso", "Stefano", ""], ["Giunchiglia", "Fausto", ""], ["Passerini", "Andrea", ""]]}, {"id": "2011.00958", "submitter": "Anton Smerdov", "authors": "Anton Smerdov, Bo Zhou, Paul Lukowicz, Andrey Somov", "title": "Collection and Validation of Psycophysiological Data from Professional\n  and Amateur Players: a Multimodal eSports Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proper training and analytics in eSports require accurately collected and\nannotated data. Most eSports research focuses exclusively on in-game data\nanalysis, and there is a lack of prior work involving eSports athletes'\npsychophysiological data. In this paper, we present a dataset collected from\nprofessional and amateur teams in 22 matches in League of Legends video game.\nRecorded data include the players' physiological activity, e.g. movements,\npulse, saccades, obtained from various sensors, self-reported after-match\nsurvey, and in-game data. An important feature of the dataset is simultaneous\ndata collection from five players, which facilitates the analysis of sensor\ndata on a team level. Upon the collection of dataset we carried out its\nvalidation. In particular, we demonstrate that stress and concentration levels\nfor professional players are less correlated, meaning more independent\nplaystyle. Also, we show that the absence of team communication does not affect\nthe professional players as much as amateur ones. To investigate other possible\nuse cases of the dataset, we have trained classical machine learning algorithms\nfor skill prediction and player re-identification using 3-minute sessions of\nsensor data. Best models achieved 0.856 and 0.521 (0.10 for a chance level)\naccuracy scores on a validation set for skill prediction and player re-id\nproblems, respectively. The dataset is available at\nhttps://github.com/asmerdov/eSports_Sensors_Dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:25:11 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Smerdov", "Anton", ""], ["Zhou", "Bo", ""], ["Lukowicz", "Paul", ""], ["Somov", "Andrey", ""]]}, {"id": "2011.00966", "submitter": "Shweta Mahajan", "authors": "Shweta Mahajan, Stefan Roth", "title": "Diverse Image Captioning with Context-Object Split Latent Spaces", "comments": "To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse image captioning models aim to learn one-to-many mappings that are\ninnate to cross-domain datasets, such as of images and texts. Current methods\nfor this task are based on generative latent variable models, e.g. VAEs with\nstructured latent spaces. Yet, the amount of multimodality captured by prior\nwork is limited to that of the paired training data -- the true diversity of\nthe underlying generative process is not fully captured. To address this\nlimitation, we leverage the contextual descriptions in the dataset that explain\nsimilar contexts in different visual scenes. To this end, we introduce a novel\nfactorization of the latent space, termed context-object split, to model\ndiversity in contextual descriptions across images and texts within the\ndataset. Our framework not only enables diverse captioning through\ncontext-based pseudo supervision, but extends this to images with novel objects\nand without paired captions in the training data. We evaluate our COS-CVAE\napproach on the standard COCO dataset and on the held-out COCO dataset\nconsisting of images with novel objects, showing significant gains in accuracy\nand diversity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:33:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mahajan", "Shweta", ""], ["Roth", "Stefan", ""]]}, {"id": "2011.00971", "submitter": "Jiayuan Gu", "authors": "Tongzhou Mu, Jiayuan Gu, Zhiwei Jia, Hao Tang, Hao Su", "title": "Refactoring Policy for Compositional Generalizability using\n  Self-Supervised Object Proposals", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how to learn a policy with compositional generalizability. We\npropose a two-stage framework, which refactorizes a high-reward teacher policy\ninto a generalizable student policy with strong inductive bias. Particularly,\nwe implement an object-centric GNN-based student policy, whose input objects\nare learned from images through self-supervised learning. Empirically, we\nevaluate our approach on four difficult tasks that require compositional\ngeneralizability, and achieve superior performance compared to baselines.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2020 17:46:08 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mu", "Tongzhou", ""], ["Gu", "Jiayuan", ""], ["Jia", "Zhiwei", ""], ["Tang", "Hao", ""], ["Su", "Hao", ""]]}, {"id": "2011.00981", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang, K. Sudhir, Nisheeth K. Vishnoi", "title": "Coresets for Regressions with Panel Data", "comments": "This is a Full version of a paper to appear in NeurIPS 2020. The code\n  can be found in\n  https://github.com/huanglx12/Coresets-for-regressions-with-panel-data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the problem of coresets for regression problems to\npanel data settings. We first define coresets for several variants of\nregression problems with panel data and then present efficient algorithms to\nconstruct coresets of size that depend polynomially on 1/$\\varepsilon$ (where\n$\\varepsilon$ is the error parameter) and the number of regression parameters -\nindependent of the number of individuals in the panel data or the time units\neach individual is observed for. Our approach is based on the Feldman-Langberg\nframework in which a key step is to upper bound the \"total sensitivity\" that is\nroughly the sum of maximum influences of all individual-time pairs taken over\nall possible choices of regression parameters. Empirically, we assess our\napproach with synthetic and real-world datasets; the coreset sizes constructed\nusing our approach are much smaller than the full dataset and coresets indeed\naccelerate the running time of computing the regression objective.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:58:31 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 02:52:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Huang", "Lingxiao", ""], ["Sudhir", "K.", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2011.00986", "submitter": "Auguste Charles", "authors": "Charles Auguste (IMI), Sean Malory, Ivan Smirnov", "title": "A better method to enforce monotonic constraints in regression and\n  classification trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we present two new ways of enforcing monotone constraints in\nregression and classification trees. One yields better results than the current\nLightGBM, and has a similar computation time. The other one yields even better\nresults, but is much slower than the current LightGBM. We also propose a\nheuristic that takes into account that greedily splitting a tree by choosing a\nmonotone split with respect to its immediate gain is far from optimal. Then, we\ncompare the results with the current implementation of the constraints in the\nLightGBM library, using the well known Adult public dataset. Throughout the\nreport, we mostly focus on the implementation of our methods that we made for\nthe LightGBM library, even though they are general and could be implemented in\nany regression or classification tree. The best method we propose (a smarter\nway to split the tree coupled to a penalization of monotone splits)\nconsistently beats the current implementation of LightGBM. With small or\naverage trees, the loss reduction can be as high as 1% in the early stages of\ntraining and decreases to around 0.1% at the loss peak for the Adult dataset.\nThe results would be even better with larger trees. In our experiments, we\ndidn't do a lot of tuning of the regularization parameters, and we wouldn't be\nsurprised to see that increasing the performance of our methods on test sets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:04:21 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Auguste", "Charles", "", "IMI"], ["Malory", "Sean", ""], ["Smirnov", "Ivan", ""]]}, {"id": "2011.00998", "submitter": "Mitt Shah", "authors": "Mitt Shah and Nandit Pujara", "title": "A Review On Software Defects Prediction Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Software quality is one of the essential aspects of a software. With\nincreasing demand, software designs are becoming more complex, increasing the\nprobability of software defects. Testers improve the quality of software by\nfixing defects. Hence the analysis of defects significantly improves software\nquality. The complexity of software also results in a higher number of defects,\nand thus manual detection can become a very time-consuming process. This gave\nresearchers incentives to develop techniques for automatic software defects\ndetection. In this paper, we try to analyze the state of the art machine\nlearning algorithms' performance for software defect classification. We used\nseven datasets from the NASA promise dataset repository for this research work.\nThe performance of Neural Networks and Gradient Boosting classifier dominated\nother algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 16:10:23 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 17:20:47 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Shah", "Mitt", ""], ["Pujara", "Nandit", ""]]}, {"id": "2011.01010", "submitter": "Hal Ashton", "authors": "Hal Ashton", "title": "Causal Campbell-Goodhart's law and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Campbell-Goodhart's law relates to the causal inference error whereby\ndecision-making agents aim to influence variables which are correlated to their\ngoal objective but do not reliably cause it. This is a well known error in\nEconomics and Political Science but not widely labelled in Artificial\nIntelligence research. Through a simple example, we show how off-the-shelf deep\nReinforcement Learning (RL) algorithms are not necessarily immune to this\ncognitive error. The off-policy learning method is tricked, whilst the\non-policy method is not. The practical implication is that naive application of\nRL to complex real life problems can result in the same types of policy errors\nthat humans make. Great care should be taken around understanding the causal\nmodel that underpins a solution derived from Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:42:20 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 10:19:00 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ashton", "Hal", ""]]}, {"id": "2011.01014", "submitter": "Berk Kapicioglu", "authors": "Berk Kapicioglu, Ramiz Iqbal, Tarik Koc, Louis Nicolas Andre,\n  Katharina Sophia Volz", "title": "Chess2vec: Learning Vector Representations for Chess", "comments": "Relational Representation Learning Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct the first study of its kind to generate and evaluate vector\nrepresentations for chess pieces. In particular, we uncover the latent\nstructure of chess pieces and moves, as well as predict chess moves from chess\npositions. We share preliminary results which anticipate our ongoing work on a\nneural network architecture that learns these embeddings directly from\nsupervised feedback.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:50:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kapicioglu", "Berk", ""], ["Iqbal", "Ramiz", ""], ["Koc", "Tarik", ""], ["Andre", "Louis Nicolas", ""], ["Volz", "Katharina Sophia", ""]]}, {"id": "2011.01016", "submitter": "Advait Parulekar", "authors": "Advait Parulekar, Soumya Basu, Aditya Gopalan, Karthikeyan Shanmugam,\n  Sanjay Shakkottai", "title": "Stochastic Linear Bandits with Protected Subspace", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the stochastic linear bandit problem wherein we\noptimize a linear objective function but rewards are accrued only orthogonal to\nan unknown subspace (which we interpret as a \\textit{protected space}) given\nonly zero-order stochastic oracle access to both the objective itself and\nprotected subspace. In particular, at each round, the learner must choose\nwhether to query the objective or the protected subspace alongside choosing an\naction. Our algorithm, derived from the OFUL principle, uses some of the\nqueries to get an estimate of the protected space, and (in almost all rounds)\nplays optimistically with respect to a confidence set for this space. We\nprovide a $\\tilde{O}(sd\\sqrt{T})$ regret upper bound in the case where the\naction space is the complete unit ball in $\\mathbb{R}^d$, $s < d$ is the\ndimension of the protected subspace, and $T$ is the time horizon. Moreover, we\ndemonstrate that a discrete action space can lead to linear regret with an\noptimistic algorithm, reinforcing the sub-optimality of optimism in certain\nsettings. We also show that protection constraints imply that for certain\nsettings, no consistent algorithm can have a regret smaller than\n$\\Omega(T^{3/4}).$ We finally empirically validate our results with synthetic\nand real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:59:39 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 21:40:26 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Parulekar", "Advait", ""], ["Basu", "Soumya", ""], ["Gopalan", "Aditya", ""], ["Shanmugam", "Karthikeyan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2011.01023", "submitter": "Peter Wijeratne", "authors": "Peter A. Wijeratne and Daniel C. Alexander", "title": "Learning transition times in event sequences: the Event-Based Hidden\n  Markov Model of disease progression", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progressive diseases worsen over time and are characterised by monotonic\nchange in features that track disease progression. Here we connect ideas from\ntwo formerly separate methodologies -- event-based and hidden Markov modelling\n-- to derive a new generative model of disease progression. Our model can\nuniquely infer the most likely group-level sequence and timing of events\n(natural history) from limited datasets. Moreover, it can infer and predict\nindividual-level trajectories (prognosis) even when data are missing, giving it\nhigh clinical utility. Here we derive the model and provide an inference scheme\nbased on the expectation maximisation algorithm. We use clinical, imaging and\nbiofluid data from the Alzheimer's Disease Neuroimaging Initiative to\ndemonstrate the validity and utility of our model. First, we train our model to\nuncover a new group-level sequence of feature changes in Alzheimer's disease\nover a period of ${\\sim}17.3$ years. Next, we demonstrate that our model\nprovides improved utility over a continuous time hidden Markov model by area\nunder the receiver operator characteristic curve ${\\sim}0.23$. Finally, we\ndemonstrate that our model maintains predictive accuracy with up to $50\\%$\nmissing data. These results support the clinical validity of our model and its\nbroader utility in resource-limited medical applications.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:13:03 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 13:15:17 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Wijeratne", "Peter A.", ""], ["Alexander", "Daniel C.", ""]]}, {"id": "2011.01035", "submitter": "Akshar Nair", "authors": "Nikhil Fernandes, Alexandra Gkolia, Nicolas Pizzo, James Davenport,\n  Akshar Nair", "title": "Unification of HDP and LDA Models for Optimal Topic Clustering of\n  Subject Specific Question Banks", "comments": "8 pages, 5 figures, Submitted to EAAI21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasingly popular trend in Universities for curriculum\ntransformation to make teaching more interactive and suitable for online\ncourses. An increase in the popularity of online courses would result in an\nincrease in the number of course-related queries for academics. This, coupled\nwith the fact that if lectures were delivered in a video on demand format,\nthere would be no fixed time where the majority of students could ask\nquestions. When questions are asked in a lecture there is a negligible chance\nof having similar questions repeatedly, but asynchronously this is more likely.\nIn order to reduce the time spent on answering each individual question,\nclustering them is an ideal choice. There are different unsupervised models fit\nfor text clustering, of which the Latent Dirichlet Allocation model is the most\ncommonly used. We use the Hierarchical Dirichlet Process to determine an\noptimal topic number input for our LDA model runs. Due to the probabilistic\nnature of these topic models, the outputs of them vary for different runs. The\ngeneral trend we found is that not all the topics were being used for\nclustering on the first run of the LDA model, which results in a less effective\nclustering. To tackle probabilistic output, we recursively use the LDA model on\nthe effective topics being used until we obtain an efficiency ratio of 1.\nThrough our experimental results we also establish a reasoning on how Zeno's\nparadox is avoided.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2020 18:21:20 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Fernandes", "Nikhil", ""], ["Gkolia", "Alexandra", ""], ["Pizzo", "Nicolas", ""], ["Davenport", "James", ""], ["Nair", "Akshar", ""]]}, {"id": "2011.01046", "submitter": "Yuxuan Li", "authors": "Nan Lin, Yuxuan Li, Yujun Zhu, Ruolin Wang, Xiayu Zhang, Jianmin Ji,\n  Keke Tang, Xiaoping Chen, Xinming Zhang", "title": "NEARL: Non-Explicit Action Reinforcement Learning for Robotic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, reinforcement learning methods predict the next action based\non the current state. However, in many situations, directly applying actions to\ncontrol systems or robots is dangerous and may lead to unexpected behaviors\nbecause action is rather low-level. In this paper, we propose a novel\nhierarchical reinforcement learning framework without explicit action. Our meta\npolicy tries to manipulate the next optimal state and actual action is produced\nby the inverse dynamics model. To stabilize the training process, we integrate\nadversarial learning and information bottleneck into our framework. Under our\nframework, widely available state-only demonstrations can be exploited\neffectively for imitation learning. Also, prior knowledge and constraints can\nbe applied to meta policy. We test our algorithm in simulation tasks and its\ncombination with imitation learning. The experimental results show the\nreliability and robustness of our algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:28:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Lin", "Nan", ""], ["Li", "Yuxuan", ""], ["Zhu", "Yujun", ""], ["Wang", "Ruolin", ""], ["Zhang", "Xiayu", ""], ["Ji", "Jianmin", ""], ["Tang", "Keke", ""], ["Chen", "Xiaoping", ""], ["Zhang", "Xinming", ""]]}, {"id": "2011.01047", "submitter": "Yong Yu", "authors": "Yong Yu", "title": "AI Chiller: An Open IoT Cloud Based Machine Learning Framework for the\n  Energy Saving of Building HVAC System via Big Data Analytics on the Fusion of\n  BMS and Environmental Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy saving and carbon emission reduction in buildings is one of the key\nmeasures in combating climate change. Heating, Ventilation, and Air\nConditioning (HVAC) system account for the majority of the energy consumption\nin the built environment, and among which, the chiller plant constitutes the\ntop portion. The optimization of chiller system power consumption had been\nextensively studied in the mechanical engineering and building service domains.\nMany works employ physical models from the domain knowledge. With the advance\nof big data and AI, the adoption of machine learning into the optimization\nproblems becomes popular. Although many research works and projects turn to\nthis direction for energy saving, the application into the optimization problem\nremains a challenging task. This work is targeted to outline a framework for\nsuch problems on how the energy saving should be benchmarked, if holistic or\nindividually modeling should be used, how the optimization is to be conducted,\nwhy data pattern augmentation at the initial deployment is a must, why the\ngradually increasing changes strategy must be used. Results of analysis on\nhistorical data and empirical experiment on live data are presented.\n", "versions": [{"version": "v1", "created": "Fri, 9 Oct 2020 09:51:03 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yu", "Yong", ""]]}, {"id": "2011.01048", "submitter": "Edoardo Belli", "authors": "Edoardo Belli, Simone Vantini", "title": "Ridge regression with adaptive additive rectangles and other piecewise\n  functional templates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an $L_{2}$-based penalization algorithm for functional linear\nregression models, where the coefficient function is shrunk towards a\ndata-driven shape template $\\gamma$, which is constrained to belong to a class\nof piecewise functions by restricting its basis expansion. In particular, we\nfocus on the case where $\\gamma$ can be expressed as a sum of $q$ rectangles\nthat are adaptively positioned with respect to the regression error. As the\nproblem of finding the optimal knot placement of a piecewise function is\nnonconvex, the proposed parametrization allows to reduce the number of\nvariables in the global optimization scheme, resulting in a fitting algorithm\nthat alternates between approximating a suitable template and solving a convex\nridge-like problem. The predictive power and interpretability of our method is\nshown on multiple simulations and two real world case studies.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:28:54 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Belli", "Edoardo", ""], ["Vantini", "Simone", ""]]}, {"id": "2011.01054", "submitter": "Ricardo Luna Gutierrez", "authors": "Ricardo Luna Gutierrez, Matteo Leonetti", "title": "Information-theoretic Task Selection for Meta-Reinforcement Learning", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Meta-Reinforcement Learning (meta-RL) an agent is trained on a set of\ntasks to prepare for and learn faster in new, unseen, but related tasks. The\ntraining tasks are usually hand-crafted to be representative of the expected\ndistribution of test tasks and hence all used in training. We show that given a\nset of training tasks, learning can be both faster and more effective (leading\nto better performance in the test tasks), if the training tasks are\nappropriately selected. We propose a task selection algorithm,\nInformation-Theoretic Task Selection (ITTS), based on information theory, which\noptimizes the set of tasks used for training in meta-RL, irrespectively of how\nthey are generated. The algorithm establishes which training tasks are both\nsufficiently relevant for the test tasks, and different enough from one\nanother. We reproduce different meta-RL experiments from the literature and\nshow that ITTS improves the final performance in all of them.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:37:37 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 13:45:56 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Gutierrez", "Ricardo Luna", ""], ["Leonetti", "Matteo", ""]]}, {"id": "2011.01075", "submitter": "Nan Jiang", "authors": "Philip Amortila, Nan Jiang, Tengyang Xie", "title": "A Variant of the Wang-Foster-Kakade Lower Bound for the Discounted\n  Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Wang et al. (2020) showed a highly intriguing hardness result for\nbatch reinforcement learning (RL) with linearly realizable value function and\ngood feature coverage in the finite-horizon case. In this note we show that\nonce adapted to the discounted setting, the construction can be simplified to a\n2-state MDP with 1-dimensional features, such that learning is impossible even\nwith an infinite amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:04:42 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 03:53:02 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Amortila", "Philip", ""], ["Jiang", "Nan", ""], ["Xie", "Tengyang", ""]]}, {"id": "2011.01089", "submitter": "Martin Bertran", "authors": "Martin Bertran, Natalia Martinez, Mariano Phielipp, Guillermo Sapiro", "title": "Instance based Generalization in Reinforcement Learning", "comments": "Accepted on NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents trained via deep reinforcement learning (RL) routinely fail to\ngeneralize to unseen environments, even when these share the same underlying\ndynamics as the training levels. Understanding the generalization properties of\nRL is one of the challenges of modern machine learning. Towards this goal, we\nanalyze policy learning in the context of Partially Observable Markov Decision\nProcesses (POMDPs) and formalize the dynamics of training levels as instances.\nWe prove that, independently of the exploration strategy, reusing instances\nintroduces significant changes on the effective Markov dynamics the agent\nobserves during training. Maximizing expected rewards impacts the learned\nbelief state of the agent by inducing undesired instance specific speedrunning\npolicies instead of generalizeable ones, which are suboptimal on the training\nset. We provide generalization bounds to the value gap in train and test\nenvironments based on the number of training instances, and use insights based\non these to improve performance on unseen levels. We propose training a shared\nbelief representation over an ensemble of specialized policies, from which we\ncompute a consensus policy that is used for data collection, disallowing\ninstance specific exploitation. We experimentally validate our theory,\nobservations, and the proposed computational solution over the CoinRun\nbenchmark.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:19:44 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bertran", "Martin", ""], ["Martinez", "Natalia", ""], ["Phielipp", "Mariano", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "2011.01090", "submitter": "Cong Shen", "authors": "Chengshuai Shi, Cong Shen", "title": "On No-Sensing Adversarial Multi-player Multi-armed Bandits with\n  Collision Communications", "comments": "19 pages, 8 figures. Accepted to IEEE Journal on Selected Areas in\n  Information Theory, Special Issue on Sequential, Active, and Reinforcement\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the notoriously difficult no-sensing adversarial multi-player\nmulti-armed bandits (MP-MAB) problem from a new perspective. Instead of\nfocusing on the hardness of multiple players, we introduce a new dimension of\nhardness, called attackability. All adversaries can be categorized based on the\nattackability and we introduce Adversary-Adaptive Collision-Communication\n(A2C2), a family of algorithms with forced-collision communication among\nplayers. Both attackability-aware and unaware settings are studied, and\ninformation-theoretic tools of the Z-channel model and error-correction coding\nare utilized to address the challenge of implicit communication without\ncollision information in an adversarial environment. For the more challenging\nattackability-unaware problem, we propose a simple method to estimate the\nattackability enabled by a novel error-detection repetition code and randomized\ncommunication for synchronization. Theoretical analysis proves that asymptotic\nattackability-dependent sublinear regret can be achieved, with or without\nknowing the attackability. In particular, the asymptotic regret does not have\nan exponential dependence on the number of players, revealing a fundamental\ntradeoff between the two dimensions of hardness in this problem.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:21:18 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 18:36:25 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Shi", "Chengshuai", ""], ["Shen", "Cong", ""]]}, {"id": "2011.01103", "submitter": "Danilo Dess\\`i", "authors": "Danilo Dess\\`i, Francesco Osborne, Diego Reforgiato Recupero, Davide\n  Buscaldi, Enrico Motta", "title": "Generating Knowledge Graphs by Employing Natural Language Processing and\n  Machine Learning Techniques within the Scholarly Domain", "comments": "Accepted for publication in Future Generation Computer Systems\n  journal - Special Issue on Machine Learning and Knowledge Graphs", "journal-ref": null, "doi": "10.1016/j.future.2020.10.026", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous growth of scientific literature brings innovations and, at the\nsame time, raises new challenges. One of them is related to the fact that its\nanalysis has become difficult due to the high volume of published papers for\nwhich manual effort for annotations and management is required. Novel\ntechnological infrastructures are needed to help researchers, research policy\nmakers, and companies to time-efficiently browse, analyse, and forecast\nscientific research. Knowledge graphs i.e., large networks of entities and\nrelationships, have proved to be effective solution in this space. Scientific\nknowledge graphs focus on the scholarly domain and typically contain metadata\ndescribing research publications such as authors, venues, organizations,\nresearch topics, and citations. However, the current generation of knowledge\ngraphs lacks of an explicit representation of the knowledge presented in the\nresearch papers. As such, in this paper, we present a new architecture that\ntakes advantage of Natural Language Processing and Machine Learning methods for\nextracting entities and relationships from research publications and integrates\nthem in a large-scale knowledge graph. Within this research work, we i) tackle\nthe challenge of knowledge extraction by employing several state-of-the-art\nNatural Language Processing and Text Mining tools, ii) describe an approach for\nintegrating entities and relationships generated by these tools, iii) show the\nadvantage of such an hybrid system over alternative approaches, and vi) as a\nchosen use case, we generated a scientific knowledge graph including 109,105\ntriples, extracted from 26,827 abstracts of papers within the Semantic Web\ndomain. As our approach is general and can be applied to any domain, we expect\nthat it can facilitate the management, analysis, dissemination, and processing\nof scientific knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 08:31:40 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Dess\u00ec", "Danilo", ""], ["Osborne", "Francesco", ""], ["Recupero", "Diego Reforgiato", ""], ["Buscaldi", "Davide", ""], ["Motta", "Enrico", ""]]}, {"id": "2011.01104", "submitter": "Shiwei Zeng", "authors": "Shiwei Zeng, Jie Shen", "title": "Learning from the Crowd with Pairwise Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient learning of halfspaces is arguably one of the most important\nproblems in machine learning and statistics. With the unprecedented growth of\nlarge-scale data sets, it has become ubiquitous to appeal to crowd for data\nannotation, and the central problem that attracts a surge of recent interests\nis how one can provably learn the underlying halfspace from the highly noisy\ncrowd feedback. On the other hand, a large body of recent works have been\ndedicated to the problem of learning with not only labels, but also pairwise\ncomparisons, since in many cases it is easier to compare than to label. In this\npaper we study the problem of learning halfspaces from the crowd under the\nrealizable PAC learning setting, and we assume that the crowd workers can\nprovide (noisy) labels or pairwise comparison tags upon request. We show that\nwith a powerful boosting framework, together with our novel design of a\nfiltering process, the overhead (to be defined) of the crowd acts as a\nconstant, whereas the natural extension of standard approaches to crowd setting\nleads to an overhead growing with the size of the data sets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:37:55 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 17:58:28 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Zeng", "Shiwei", ""], ["Shen", "Jie", ""]]}, {"id": "2011.01111", "submitter": "Ping Li", "authors": "Yunfeng Cai and Ping Li", "title": "Identification of Matrix Joint Block Diagonalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set $\\mathcal{C}=\\{C_i\\}_{i=1}^m$ of square matrices, the matrix\nblind joint block diagonalization problem (BJBDP) is to find a full column rank\nmatrix $A$ such that $C_i=A\\Sigma_iA^\\text{T}$ for all $i$, where $\\Sigma_i$'s\nare all block diagonal matrices with as many diagonal blocks as possible. The\nBJBDP plays an important role in independent subspace analysis (ISA). This\npaper considers the identification problem for BJBDP, that is, under what\nconditions and by what means, we can identify the diagonalizer $A$ and the\nblock diagonal structure of $\\Sigma_i$, especially when there is noise in\n$C_i$'s. In this paper, we propose a ``bi-block diagonalization'' method to\nsolve BJBDP, and establish sufficient conditions under which the method is able\nto accomplish the task. Numerical simulations validate our theoretical results.\nTo the best of the authors' knowledge, existing numerical methods for BJBDP\nhave no theoretical guarantees for the identification of the exact solution,\nwhereas our method does.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:42:32 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cai", "Yunfeng", ""], ["Li", "Ping", ""]]}, {"id": "2011.01112", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Yifan Hao, Yiran Zhao, Huajie Shao, Dongxin Liu,\n  Shengzhong Liu, Tianshi Wang, Jinyang Li, Tarek Abdelzaher", "title": "Scheduling Real-time Deep Learning Services as Imprecise Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an efficient real-time scheduling algorithm for\nintelligent real-time edge services, defined as those that perform machine\nintelligence tasks, such as voice recognition, LIDAR processing, or machine\nvision, on behalf of local embedded devices that are themselves unable to\nsupport extensive computations. The work contributes to a recent direction in\nreal-time computing that develops scheduling algorithms for machine\nintelligence tasks with anytime prediction. We show that deep neural network\nworkflows can be cast as imprecise computations, each with a mandatory part and\n(several) optional parts whose execution utility depends on input data. The\ngoal of the real-time scheduler is to maximize the average accuracy of deep\nneural network outputs while meeting task deadlines, thanks to opportunistic\nshedding of the least necessary optional parts. The work is motivated by the\nproliferation of increasingly ubiquitous but resource-constrained embedded\ndevices (for applications ranging from autonomous cars to the Internet of\nThings) and the desire to develop services that endow them with intelligence.\nExperiments on recent GPU hardware and a state of the art deep neural network\nfor machine vision illustrate that our scheme can increase the overall accuracy\nby 10%-20% while incurring (nearly) no deadline misses.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:43:04 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yao", "Shuochao", ""], ["Hao", "Yifan", ""], ["Zhao", "Yiran", ""], ["Shao", "Huajie", ""], ["Liu", "Dongxin", ""], ["Liu", "Shengzhong", ""], ["Wang", "Tianshi", ""], ["Li", "Jinyang", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2011.01113", "submitter": "Mhd Wesam Al-Nabki", "authors": "Mhd Wesam Al-Nabki, Eduardo Fidalgo, Enrique Alegre, Roc\\'io\n  Alaiz-Rodr\\'iguez", "title": "Short Text Classification Approach to Identify Child Sexual Exploitation\n  Material", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Producing or sharing Child Sexual Exploitation Material (CSEM) is a serious\ncrime fought vigorously by Law Enforcement Agencies (LEAs). When an LEA seizes\na computer from a potential producer or consumer of CSEM, they need to analyze\nthe suspect's hard disk's files looking for pieces of evidence. However, a\nmanual inspection of the file content looking for CSEM is a time-consuming\ntask. In most cases, it is unfeasible in the amount of time available for the\nSpanish police using a search warrant. Instead of analyzing its content,\nanother approach that can be used to speed up the process is to identify CSEM\nby analyzing the file names and their absolute paths. The main challenge for\nthis task lies behind dealing with short text distorted deliberately by the\nowners of this material using obfuscated words and user-defined naming\npatterns. This paper presents and compares two approaches based on short text\nclassification to identify CSEM files. The first one employs two independent\nsupervised classifiers, one for the file name and the other for the path, and\ntheir outputs are later on fused into a single score. Conversely, the second\napproach uses only the file name classifier to iterate over the file's absolute\npath. Both approaches operate at the character n-grams level, while binary and\northographic features enrich the file name representation, and a binary\nLogistic Regression model is used for classification. The presented file\nclassifier achieved an average class recall of 0.98. This solution could be\nintegrated into forensic tools and services to support Law Enforcement Agencies\nto identify CSEM without tackling every file's visual content, which is\ncomputationally much more highly demanding.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 09:37:16 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 09:39:29 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Al-Nabki", "Mhd Wesam", ""], ["Fidalgo", "Eduardo", ""], ["Alegre", "Enrique", ""], ["Alaiz-Rodr\u00edguez", "Roc\u00edo", ""]]}, {"id": "2011.01118", "submitter": "Sidike Paheding", "authors": "Nahian Siddique, Paheding Sidike, Colin Elkin and Vijay Devabhaktuni", "title": "U-Net and its variants for medical image segmentation: theory and\n  applications", "comments": "42 pages, in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2021.3086020", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  U-net is an image segmentation technique developed primarily for medical\nimage analysis that can precisely segment images using a scarce amount of\ntraining data. These traits provide U-net with a very high utility within the\nmedical imaging community and have resulted in extensive adoption of U-net as\nthe primary tool for segmentation tasks in medical imaging. The success of\nU-net is evident in its widespread use in all major image modalities from CT\nscans and MRI to X-rays and microscopy. Furthermore, while U-net is largely a\nsegmentation tool, there have been instances of the use of U-net in other\napplications. As the potential of U-net is still increasing, in this review we\nlook at the various developments that have been made in the U-net architecture\nand provide observations on recent trends. We examine the various innovations\nthat have been made in deep learning and discuss how these tools facilitate\nU-net. Furthermore, we look at image modalities and application areas where\nU-net has been applied.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 16:50:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Siddique", "Nahian", ""], ["Sidike", "Paheding", ""], ["Elkin", "Colin", ""], ["Devabhaktuni", "Vijay", ""]]}, {"id": "2011.01128", "submitter": "Sayak Mukherjee", "authors": "Sayak Mukherjee, Thanh Long Vu", "title": "Reinforcement Learning of Structured Control for Linear Systems with\n  Unknown State Matrix", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper delves into designing stabilizing feedback control gains for\ncontinuous linear systems with unknown state matrix, in which the control is\nsubject to a general structural constraint. We bring forth the ideas from\nreinforcement learning (RL) in conjunction with sufficient stability and\nperformance guarantees in order to design these structured gains using the\ntrajectory measurements of states and controls. We first formulate a\nmodel-based framework using dynamic programming (DP) to embed the structural\nconstraint to the Linear Quadratic Regulator (LQR) gain computation in the\ncontinuous-time setting. Subsequently, we transform this LQR formulation into a\npolicy iteration RL algorithm that can alleviate the requirement of known state\nmatrix in conjunction with maintaining the feedback gain structure. Theoretical\nguarantees are provided for stability and convergence of the structured RL\n(SRL) algorithm. The introduced RL framework is general and can be applied to\nany control structure. A special control structure enabled by this RL framework\nis distributed learning control which is necessary for many large-scale\ncyber-physical systems. As such, we validate our theoretical results with\nnumerical simulations on a multi-agent networked linear time-invariant (LTI)\ndynamic system.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:04:34 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mukherjee", "Sayak", ""], ["Vu", "Thanh Long", ""]]}, {"id": "2011.01129", "submitter": "Jingxi Chen", "authors": "Jingxi Chen, Amrish Baskaran, Zhongshun Zhang, Pratap Tokekar", "title": "Multi-Agent Reinforcement Learning for Persistent Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Persistent Monitoring (PM) problem seeks to find a set of trajectories\n(or controllers) for robots to persistently monitor a changing environment.\nEach robot has a limited field-of-view and may need to coordinate with others\nto ensure no point in the environment is left unmonitored for long periods of\ntime. We model the problem such that there is a penalty that accrues every time\nstep if a point is left unmonitored. However, the dynamics of the penalty are\nunknown to us. We present a Multi-Agent Reinforcement Learning (MARL) algorithm\nfor the persistent monitoring problem. Specifically, we present a Multi-Agent\nGraph Attention Proximal Policy Optimization (MA-G-PPO) algorithm that takes as\ninput the local observations of all agents combined with a low resolution\nglobal map to learn a policy for each agent. The graph attention allows agents\nto share their information with others leading to an effective joint policy.\nOur main focus is to understand how effective MARL is for the PM problem. We\ninvestigate five research questions with this broader goal. We find that\nMA-G-PPO is able to learn a better policy than the non-RL baseline in most\ncases, the effectiveness depends on agents sharing information with each other,\nand the policy learnt shows emergent behavior for the agents.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:05:40 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Chen", "Jingxi", ""], ["Baskaran", "Amrish", ""], ["Zhang", "Zhongshun", ""], ["Tokekar", "Pratap", ""]]}, {"id": "2011.01132", "submitter": "Rajeev Sahay", "authors": "Rajeev Sahay and Christopher G. Brinton and David J. Love", "title": "Frequency-based Automated Modulation Classification in the Presence of\n  Adversaries", "comments": "6 pages, 7 figures. Published in Proc. of the 2021 IEEE International\n  Conference on Communications (ICC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic modulation classification (AMC) aims to improve the efficiency of\ncrowded radio spectrums by automatically predicting the modulation\nconstellation of wireless RF signals. Recent work has demonstrated the ability\nof deep learning to achieve robust AMC performance using raw in-phase and\nquadrature (IQ) time samples. Yet, deep learning models are highly susceptible\nto adversarial interference, which cause intelligent prediction models to\nmisclassify received samples with high confidence. Furthermore, adversarial\ninterference is often transferable, allowing an adversary to attack multiple\ndeep learning models with a single perturbation crafted for a particular\nclassification network. In this work, we present a novel receiver architecture\nconsisting of deep learning models capable of withstanding transferable\nadversarial interference. Specifically, we show that adversarial attacks\ncrafted to fool models trained on time-domain features are not easily\ntransferable to models trained using frequency-domain features. In this\ncapacity, we demonstrate classification performance improvements greater than\n30% on recurrent neural networks (RNNs) and greater than 50% on convolutional\nneural networks (CNNs). We further demonstrate our frequency feature-based\nclassification models to achieve accuracies greater than 99% in the absence of\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:12:22 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 20:09:13 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 20:14:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sahay", "Rajeev", ""], ["Brinton", "Christopher G.", ""], ["Love", "David J.", ""]]}, {"id": "2011.01135", "submitter": "Niraj Kushwaha", "authors": "Niraj Kushwaha, Naveen Kumar Mendola, Saptarshi Ghosh, Ajay Deep\n  Kachhvah, Sarika Jalan", "title": "Machine Learning assisted Chimera and Solitary states in Networks", "comments": "11 Pages, 9 Figures, Contains revised abstract and publication\n  details", "journal-ref": "Frontiers in Physics, 9, 147 (2021)", "doi": "10.3389/fphy.2021.513969", "report-no": null, "categories": "nlin.AO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chimera and Solitary states have captivated scientists and engineers due to\ntheir peculiar dynamical states corresponding to the co-existence of coherent\nand incoherent dynamical evolution in coupled units in various natural and\nartificial systems. It has been further demonstrated that such states can be\nengineered in systems of coupled oscillators by the suitable implementation of\ncommunication delays. Here, using supervised machine learning, we predict (a)\nthe precise value of delay which is sufficient for engineering chimera and\nsolitary states for a given set of system parameters, as well as (b) the\nintensity of incoherence for such engineered states. The results are\ndemonstrated for two different examples consisting of single layer and multi\nlayer networks. First, the chimera states (solitary states) are engineered by\nestablishing delays in the neighboring links of a node (the interlayer links)\nin a 2-D lattice (multiplex network) of oscillators. Then, different machine\nlearning classifiers, KNN, SVM and MLP-Neural Network are employed by feeding\nthe data obtained from the network models. Once a machine learning model is\ntrained using a limited amount of data, it makes predictions for a given\nunknown systems parameter values. Testing accuracy, sensitivity, and\nspecificity analysis reveal that MLP-NN classifier is better suited than Knn or\nSVM classifier for the predictions of parameters values for engineered chimera\nand solitary states. The technique provides an easy methodology to predict\ncritical delay values as well as the intensity of incoherence for designing an\nexperimental setup to create solitary and chimera states.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:20:20 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 12:04:07 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Kushwaha", "Niraj", ""], ["Mendola", "Naveen Kumar", ""], ["Ghosh", "Saptarshi", ""], ["Kachhvah", "Ajay Deep", ""], ["Jalan", "Sarika", ""]]}, {"id": "2011.01136", "submitter": "Ruizhe Li", "authors": "Ruizhe Li, Xiao Li, Guanyi Chen, Chenghua Lin", "title": "Improving Variational Autoencoder for Text Modelling with Timestep-Wise\n  Regularisation", "comments": "Accepted by COLING 2020, final camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Autoencoder (VAE) is a popular and powerful model applied to\ntext modelling to generate diverse sentences. However, an issue known as\nposterior collapse (or KL loss vanishing) happens when the VAE is used in text\nmodelling, where the approximate posterior collapses to the prior, and the\nmodel will totally ignore the latent variables and be degraded to a plain\nlanguage model during text generation. Such an issue is particularly prevalent\nwhen RNN-based VAE models are employed for text modelling. In this paper, we\npropose a simple, generic architecture called Timestep-Wise Regularisation VAE\n(TWR-VAE), which can effectively avoid posterior collapse and can be applied to\nany RNN-based VAE models. The effectiveness and versatility of our model are\ndemonstrated in different tasks, including language modelling and dialogue\nresponse generation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:20:56 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 15:20:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Li", "Ruizhe", ""], ["Li", "Xiao", ""], ["Chen", "Guanyi", ""], ["Lin", "Chenghua", ""]]}, {"id": "2011.01140", "submitter": "Didier A. Vega-Oliveros", "authors": "Alessandra Marli, Didier A Vega-Oliveros, Mosh\\'e Cotacallapa,\n  Leonardo N Ferreira, Elbert EN Macau, Marcos G Quiles", "title": "Dynamic Community Detection into Analyzing of Wildfires Events", "comments": "16 pages, 8 figures", "journal-ref": "ICCSA 2020. Lecture Notes in Computer Science, vol 12249.\n  Springer, Cham", "doi": "10.1007/978-3-030-58799-4_74", "report-no": null, "categories": "cs.SI cs.LG physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study and comprehension of complex systems are crucial intellectual and\nscientific challenges of the 21st century. In this scenario, network science\nhas emerged as a mathematical tool to support the study of such systems.\nExamples include environmental processes such as wildfires, which are known for\ntheir considerable impact on human life. However, there is a considerable lack\nof studies of wildfire from a network science perspective. Here, employing the\nchronological network concept -- a temporal network where nodes are linked if\ntwo consecutive events occur between them -- we investigate the information\nthat dynamic community structures reveal about the wildfires' dynamics.\nParticularly, we explore a two-phase dynamic community detection approach,\ni.e., we applied the Louvain algorithm on a series of snapshots. Then we used\nthe Jaccard similarity coefficient to match communities across adjacent\nsnapshots. Experiments with the MODIS dataset of fire events in the Amazon\nbasing were conducted. Our results show that the dynamic communities can reveal\nwildfire patterns observed throughout the year.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:31:47 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Marli", "Alessandra", ""], ["Vega-Oliveros", "Didier A", ""], ["Cotacallapa", "Mosh\u00e9", ""], ["Ferreira", "Leonardo N", ""], ["Macau", "Elbert EN", ""], ["Quiles", "Marcos G", ""]]}, {"id": "2011.01141", "submitter": "Junghoon Kim", "authors": "Junghoon Kim, Seyyedali Hosseinalipour, Taejoon Kim, David J. Love,\n  Christopher G. Brinton", "title": "Multi-IRS-assisted Multi-Cell Uplink MIMO Communications under Imperfect\n  CSI: A Deep Reinforcement Learning Approach", "comments": "7 pages, 3 figures, Accepted for publication in Proceedings of IEEE\n  International Conference on Communications (ICC) Workshop, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of intelligent reflecting surfaces (IRSs) in wireless networks\nhave attracted significant attention recently. Most of the relevant literature\nis focused on the single cell setting where a single IRS is deployed and\nperfect channel state information (CSI) is assumed. In this work, we develop a\nnovel methodology for multi-IRS-assisted multi-cell networks in the uplink. We\nconsider the scenario in which (i) channels are dynamic and (ii) only partial\nCSI is available at each base station (BS); specifically, scalar effective\nchannel powers from only a subset of user equipments (UE). We formulate the\nsum-rate maximization problem aiming to jointly optimize the IRS reflect\nbeamformers, BS combiners, and UE transmit powers. In casting this as a\nsequential decision making problem, we propose a multi-agent deep reinforcement\nlearning algorithm to solve it, where each BS acts as an independent agent in\ncharge of tuning the local UE transmit powers, the local IRS reflect\nbeamformer, and its combiners. We introduce an efficient information-sharing\nscheme that requires limited information exchange among neighboring BSs to cope\nwith the non-stationarity caused by the coupling of actions taken by multiple\nBSs. Our numerical results show that our method obtains substantial improvement\nin average data rate compared to baseline approaches, e.g., fixed UE transmit\npower and maximum ratio combining.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:33:23 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 18:48:29 GMT"}, {"version": "v3", "created": "Sun, 8 Nov 2020 17:16:00 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 19:21:06 GMT"}, {"version": "v5", "created": "Wed, 24 Feb 2021 12:32:14 GMT"}, {"version": "v6", "created": "Thu, 1 Apr 2021 10:22:28 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Kim", "Junghoon", ""], ["Hosseinalipour", "Seyyedali", ""], ["Kim", "Taejoon", ""], ["Love", "David J.", ""], ["Brinton", "Christopher G.", ""]]}, {"id": "2011.01148", "submitter": "Zahra Ebrahimi", "authors": "Zahra Ebrahimi and Salim Ullah and Akash Kumar", "title": "SIMDive: Approximate SIMD Soft Multiplier-Divider for FPGAs with Tunable\n  Accuracy", "comments": null, "journal-ref": "ACM Great Lakes Symposium on VLSI (GLSVLSI) 2020", "doi": "10.1145/3386263.3406907", "report-no": null, "categories": "cs.AR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing quest for data-level parallelism and variable precision\nin ubiquitous multimedia and Deep Neural Network (DNN) applications has\nmotivated the use of Single Instruction, Multiple Data (SIMD) architectures. To\nalleviate energy as their main resource constraint, approximate computing has\nre-emerged,albeit mainly specialized for their Application-Specific Integrated\nCircuit (ASIC) implementations. This paper, presents for the first time, an\nSIMD architecture based on novel multiplier and divider with tunable accuracy,\ntargeted for Field-Programmable Gate Arrays (FPGAs). The proposed hybrid\narchitecture implements Mitchell's algorithms and supports precision\nvariability from 8 to 32 bits. Experimental results obtained from Vivado,\nmultimedia and DNN applications indicate superiority of proposed architecture\n(both SISD and SIMD) over accurate and state-of-the-art approximate\ncounterparts. In particular, the proposed SISD divider outperforms the accurate\nIntellectual Property (IP) divider provided by Xilinx with 4x higher speed and\n4.6x less energy and tolerating only < 0.8% error. Moreover, the proposed SIMD\nmultiplier-divider supersede accurate SIMD multiplier by achieving up to 26%,\n45%, 36%, and 56% improvement in area, throughput, power, and energy,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:40:44 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ebrahimi", "Zahra", ""], ["Ullah", "Salim", ""], ["Kumar", "Akash", ""]]}, {"id": "2011.01149", "submitter": "Grigori Fursin", "authors": "Grigori Fursin", "title": "Collective Knowledge: organizing research projects as a database of\n  reusable components and portable workflows with common APIs", "comments": "Accepted for Philosophical Transactions of the Royal Society. arXiv\n  admin note: text overlap with arXiv:2006.07161", "journal-ref": null, "doi": "10.1098/rsta.2020.0211", "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides the motivation and overview of the Collective Knowledge\nframework (CK or cKnowledge). The CK concept is to decompose research projects\ninto reusable components that encapsulate research artifacts and provide\nunified application programming interfaces (APIs), command-line interfaces\n(CLIs), meta descriptions and common automation actions for related artifacts.\nThe CK framework is used to organize and manage research projects as a database\nof such components.\n  Inspired by the USB \"plug and play\" approach for hardware, CK also helps to\nassemble portable workflows that can automatically plug in compatible\ncomponents from different users and vendors (models, datasets, frameworks,\ncompilers, tools). Such workflows can build and run algorithms on different\nplatforms and environments in a unified way using the universal CK program\npipeline with software detection plugins and the automatic installation of\nmissing packages.\n  This article presents a number of industrial projects in which the modular CK\napproach was successfully validated in order to automate benchmarking,\nauto-tuning and co-design of efficient software and hardware for machine\nlearning (ML) and artificial intelligence (AI) in terms of speed, accuracy,\nenergy, size and various costs. The CK framework also helped to automate the\nartifact evaluation process at several computer science conferences as well as\nto make it easier to reproduce, compare and reuse research techniques from\npublished papers, deploy them in production, and automatically adapt them to\ncontinuously changing datasets, models and systems.\n  The long-term goal is to accelerate innovation by connecting researchers and\npractitioners to share and reuse all their knowledge, best practices,\nartifacts, workflows and experimental results in a common, portable and\nreproducible format at https://cKnowledge.io .\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:42:59 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 15:01:14 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Fursin", "Grigori", ""]]}, {"id": "2011.01150", "submitter": "Daniel Fern\\'andez-S\\'anchez", "authors": "Daniel Fern\\'andez-S\\'anchez, Eduardo C. Garrido-Merch\\'an and Daniel\n  Hern\\'andez-Lobato", "title": "Improved Max-value Entropy Search for Multi-objective Bayesian\n  Optimization with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MESMOC+, an improved version of Max-value Entropy search for\nMulti-Objective Bayesian optimization with Constraints (MESMOC). MESMOC+ can be\nused to solve constrained multi-objective problems when the objectives and the\nconstraints are expensive to evaluate. MESMOC+ works by minimizing the entropy\nof the solution of the optimization problem in function space, i.e., the Pareto\nfrontier, to guide the search for the optimum. The cost of MESMOC+ is linear in\nthe number of objectives and constraints. Furthermore, it is often\nsignificantly smaller than the cost of alternative methods based on minimizing\nthe entropy of the Pareto set. The reason for this is that it is easier to\napproximate the required computations in MESMOC+. Moreover, MESMOC+'s\nacquisition function is expressed as the sum of one acquisition per each\nblack-box (objective or constraint). Thus, it can be used in a decoupled\nevaluation setting in which one chooses not only the next input location to\nevaluate, but also which black-box to evaluate there. We compare MESMOC+ with\nrelated methods in synthetic and real optimization problems. These experiments\nshow that the entropy estimation provided by MESMOC+ is more accurate than that\nof previous methods. This leads to better optimization results. MESMOC+ is also\ncompetitive with other information-based methods for constrained\nmulti-objective Bayesian optimization, but it is significantly faster.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:45:25 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 15:37:38 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Fern\u00e1ndez-S\u00e1nchez", "Daniel", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2011.01151", "submitter": "Ashish Shrivastava", "authors": "Ashish Shrivastava, Arnav Kundu, Chandra Dhir, Devang Naik, Oncel\n  Tuzel", "title": "Optimize what matters: Training DNN-HMM Keyword Spotting Model Using End\n  Metric", "comments": "Accepted at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network--Hidden Markov Model (DNN-HMM) based methods have been\nsuccessfully used for many always-on keyword spotting algorithms that detect a\nwake word to trigger a device. The DNN predicts the state probabilities of a\ngiven speech frame, while HMM decoder combines the DNN predictions of multiple\nspeech frames to compute the keyword detection score. The DNN, in prior\nmethods, is trained independent of the HMM parameters to minimize the\ncross-entropy loss between the predicted and the ground-truth state\nprobabilities. The mis-match between the DNN training loss (cross-entropy) and\nthe end metric (detection score) is the main source of sub-optimal performance\nfor the keyword spotting task. We address this loss-metric mismatch with a\nnovel end-to-end training strategy that learns the DNN parameters by optimizing\nfor the detection score. To this end, we make the HMM decoder (dynamic\nprogramming) differentiable and back-propagate through it to maximize the score\nfor the keyword and minimize the scores for non-keyword speech segments. Our\nmethod does not require any change in the model architecture or the inference\nframework; therefore, there is no overhead in run-time memory or compute\nrequirements. Moreover, we show significant reduction in false rejection rate\n(FRR) at the same false trigger experience (> 70% over independent DNN\ntraining).\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:47:21 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 00:06:41 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Shrivastava", "Ashish", ""], ["Kundu", "Arnav", ""], ["Dhir", "Chandra", ""], ["Naik", "Devang", ""], ["Tuzel", "Oncel", ""]]}, {"id": "2011.01153", "submitter": "Mengye Ren", "authors": "Bob Wei, Mengye Ren, Wenyuan Zeng, Ming Liang, Bin Yang, Raquel\n  Urtasun", "title": "Perceive, Attend, and Drive: Learning Spatial Attention for Safe\n  Self-Driving", "comments": "ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an end-to-end self-driving network featuring a\nsparse attention module that learns to automatically attend to important\nregions of the input. The attention module specifically targets motion\nplanning, whereas prior literature only applied attention in perception tasks.\nLearning an attention mask directly targeted for motion planning significantly\nimproves the planner safety by performing more focused computation.\nFurthermore, visualizing the attention improves interpretability of end-to-end\nself-driving.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:47:54 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 03:43:18 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wei", "Bob", ""], ["Ren", "Mengye", ""], ["Zeng", "Wenyuan", ""], ["Liang", "Ming", ""], ["Yang", "Bin", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2011.01154", "submitter": "Seid Muhie Yimam", "authors": "Seid Muhie Yimam and Abinew Ali Ayele and Gopalakrishnan Venkatesh and\n  Chris Biemann", "title": "Introducing various Semantic Models for Amharic: Experimentation and\n  Evaluation with multiple Tasks and Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The availability of different pre-trained semantic models enabled the quick\ndevelopment of machine learning components for downstream applications. Despite\nthe availability of abundant text data for low resource languages, only a few\nsemantic models are publicly available. Publicly available pre-trained models\nare usually built as a multilingual version of semantic models that can not fit\nwell for each language due to context variations. In this work, we introduce\ndifferent semantic models for Amharic. After we experiment with the existing\npre-trained semantic models, we trained and fine-tuned nine new different\nmodels using a monolingual text corpus. The models are build using word2Vec\nembeddings, distributional thesaurus (DT), contextual embeddings, and DT\nembeddings obtained via network embedding algorithms. Moreover, we employ these\nmodels for different NLP tasks and investigate their impact. We find that newly\ntrained models perform better than pre-trained multilingual models.\nFurthermore, models based on contextual embeddings from RoBERTA perform better\nthan the word2Vec models.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:48:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yimam", "Seid Muhie", ""], ["Ayele", "Abinew Ali", ""], ["Venkatesh", "Gopalakrishnan", ""], ["Biemann", "Chris", ""]]}, {"id": "2011.01156", "submitter": "Ashish Shrivastava", "authors": "Ting-Yao Hu, Ashish Shrivastava, Jen-Hao Rick Chang, Hema Koppula,\n  Stefan Braun, Kyuyeon Hwang, Ozlem Kalinli, Oncel Tuzel", "title": "SapAugment: Learning A Sample Adaptive Policy for Data Augmentation", "comments": "Accepted at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation methods usually apply the same augmentation (or a mix of\nthem) to all the training samples. For example, to perturb data with noise, the\nnoise is sampled from a Normal distribution with a fixed standard deviation,\nfor all samples. We hypothesize that a hard sample with high training loss\nalready provides strong training signal to update the model parameters and\nshould be perturbed with mild or no augmentation. Perturbing a hard sample with\na strong augmentation may also make it too hard to learn from. Furthermore, a\nsample with low training loss should be perturbed by a stronger augmentation to\nprovide more robustness to a variety of conditions. To formalize these\nintuitions, we propose a novel method to learn a Sample-Adaptive Policy for\nAugmentation -- SapAugment. Our policy adapts the augmentation parameters based\non the training loss of the data samples. In the example of Gaussian noise, a\nhard sample will be perturbed with a low variance noise and an easy sample with\na high variance noise. Furthermore, the proposed method combines multiple\naugmentation methods into a methodical policy learning framework and obviates\nhand-crafting augmentation parameters by trial-and-error. We apply our method\non an automatic speech recognition (ASR) task, and combine existing and novel\naugmentations using the proposed framework. We show substantial improvement, up\nto 21% relative reduction in word error rate on LibriSpeech dataset, over the\nstate-of-the-art speech augmentation method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 17:52:26 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 18:02:59 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hu", "Ting-Yao", ""], ["Shrivastava", "Ashish", ""], ["Chang", "Jen-Hao Rick", ""], ["Koppula", "Hema", ""], ["Braun", "Stefan", ""], ["Hwang", "Kyuyeon", ""], ["Kalinli", "Ozlem", ""], ["Tuzel", "Oncel", ""]]}, {"id": "2011.01168", "submitter": "Ammar Shaker", "authors": "Ammar Shaker, Francesco Alesiani, Shujian Yu, Wenzhe Yin", "title": "Bilevel Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) studies the problem of learning a sequence of tasks,\none at a time, such that the learning of each new task does not lead to the\ndeterioration in performance on the previously seen ones while exploiting\npreviously learned features. This paper presents Bilevel Continual Learning\n(BiCL), a general framework for continual learning that fuses bilevel\noptimization and recent advances in meta-learning for deep neural networks.\nBiCL is able to train both deep discriminative and generative models under the\nconservative setting of the online continual learning. Experimental results\nshow that BiCL provides competitive performance in terms of accuracy for the\ncurrent task while reducing the effect of catastrophic forgetting. This is a\nconcurrent work with [1]. We submitted it to AAAI 2020 and IJCAI 2020. Now we\nput it on the arxiv for record. Different from [1], we also consider continual\ngenerative model as well. At the same time, the authors are aware of a recent\nproposal on bilevel optimization based coreset construction for continual\nlearning [2].\n  [1] Q. Pham, D. Sahoo, C. Liu, and S. C. Hoi. Bilevel continual learning.\narXiv preprint arXiv:2007.15553, 2020.\n  [2] Z. Borsos, M. Mutny, and A. Krause. Coresets via bilevel optimization for\ncontinual learning and streaming. arXiv preprint arXiv:2006.03875, 2020\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:06:42 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Shaker", "Ammar", ""], ["Alesiani", "Francesco", ""], ["Yu", "Shujian", ""], ["Yin", "Wenzhe", ""]]}, {"id": "2011.01170", "submitter": "Frederik Kunstner", "authors": "Frederik Kunstner, Raunak Kumar, Mark Schmidt", "title": "Homeomorphic-Invariance of EM: Non-Asymptotic Convergence in KL\n  Divergence for Exponential Families via Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expectation maximization (EM) is the default algorithm for fitting\nprobabilistic models with missing or latent variables, yet we lack a full\nunderstanding of its non-asymptotic convergence properties. Previous works show\nresults along the lines of \"EM converges at least as fast as gradient descent\"\nby assuming the conditions for the convergence of gradient descent apply to EM.\nThis approach is not only loose, in that it does not capture that EM can make\nmore progress than a gradient step, but the assumptions fail to hold for\ntextbook examples of EM like Gaussian mixtures. In this work we first show that\nfor the common setting of exponential family distributions, viewing EM as a\nmirror descent algorithm leads to convergence rates in Kullback-Leibler (KL)\ndivergence. Then, we show how the KL divergence is related to first-order\nstationarity via Bregman divergences. In contrast to previous works, the\nanalysis is invariant to the choice of parametrization and holds with minimal\nassumptions. We also show applications of these ideas to local linear (and\nsuperlinear) convergence rates, generalized EM, and non-exponential family\ndistributions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:09:05 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 03:42:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kunstner", "Frederik", ""], ["Kumar", "Raunak", ""], ["Schmidt", "Mark", ""]]}, {"id": "2011.01174", "submitter": "Yeunju Choi", "authors": "Yeunju Choi, Youngmoon Jung, Youngjoo Suh, Hoirin Kim", "title": "Perceptually Guided End-to-End Text-to-Speech", "comments": "5 pages, 1 figure, submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several fast text-to-speech (TTS) models have been proposed for real-time\nprocessing, but there is room for improvement in speech quality. Meanwhile,\nthere is a mismatch between the loss function for training and the mean opinion\nscore (MOS) for evaluation, which may limit the speech quality of TTS models.\nIn this work, we propose a method that can improve the speech quality of a fast\nTTS model while maintaining the inference speed. To do so, we train a TTS model\nusing a perceptual loss based on the predicted MOS. Under the supervision of a\nMOS prediction model, a TTS model can learn to increase the perceptual quality\nof speech directly. In experiments, we train FastSpeech on our internal Korean\ndataset using the MOS prediction model pre-trained on the Voice Conversion\nChallenge 2018 evaluation results. The MOS test results show that our proposed\napproach outperforms FastSpeech in speech quality.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:13:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Choi", "Yeunju", ""], ["Jung", "Youngmoon", ""], ["Suh", "Youngjoo", ""], ["Kim", "Hoirin", ""]]}, {"id": "2011.01183", "submitter": "Ryan Sheatsley", "authors": "Ryan Sheatsley, Nicolas Papernot, Michael Weisman, Gunjan Verma,\n  Patrick McDaniel", "title": "Adversarial Examples in Constrained Domains", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have been shown to be vulnerable to adversarial\nmanipulation through systematic modification of inputs (e.g., adversarial\nexamples) in domains such as image recognition. Under the default threat model,\nthe adversary exploits the unconstrained nature of images; each feature (pixel)\nis fully under control of the adversary. However, it is not clear how these\nattacks translate to constrained domains that limit which and how features can\nbe modified by the adversary (e.g., network intrusion detection). In this\npaper, we explore whether constrained domains are less vulnerable than\nunconstrained domains to adversarial example generation algorithms. We create\nan algorithm for generating adversarial sketches: targeted universal\nperturbation vectors which encode feature saliency within the envelope of\ndomain constraints. To assess how these algorithms perform, we evaluate them in\nconstrained (e.g., network intrusion detection) and unconstrained (e.g., image\nrecognition) domains. The results demonstrate that our approaches generate\nmisclassification rates in constrained domains that were comparable to those of\nunconstrained domains (greater than 95%). Our investigation shows that the\nnarrow attack surface exposed by constrained domains is still sufficiently\nlarge to craft successful adversarial examples; and thus, constraints do not\nappear to make a domain robust. Indeed, with as little as five randomly\nselected features, one can still generate adversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:19:44 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Sheatsley", "Ryan", ""], ["Papernot", "Nicolas", ""], ["Weisman", "Michael", ""], ["Verma", "Gunjan", ""], ["McDaniel", "Patrick", ""]]}, {"id": "2011.01188", "submitter": "Mohamed Mejri", "authors": "Mohamed Mejri and Aymen Mejri", "title": "RandomForestMLP: An Ensemble-Based Multi-Layer Perceptron Against Curse\n  of Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel and practical deep learning pipeline termed\nRandomForestMLP. This core trainable classification engine consists of a\nconvolutional neural network backbone followed by an ensemble-based multi-layer\nperceptrons core for the classification task. It is designed in the context of\nself and semi-supervised learning tasks to avoid overfitting while training on\nvery small datasets. The paper details the architecture of the RandomForestMLP\nand present different strategies for neural network decision aggregation. Then,\nit assesses its robustness to overfitting when trained on realistic image\ndatasets and compares its classification performance with existing regular\nclassifiers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:25:36 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Mejri", "Mohamed", ""], ["Mejri", "Aymen", ""]]}, {"id": "2011.01191", "submitter": "Mohamad H Danesh", "authors": "Mohamad H. Danesh", "title": "Reducing Neural Network Parameter Initialization Into an SMT Problem", "comments": "AAAI-21 SA Program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network (NN) depends on multiple factors, including but not\nlimited to the initial weights. In this paper, we focus on initializing deep NN\nparameters such that it performs better, comparing to random or zero\ninitialization. We do this by reducing the process of initialization into an\nSMT solver. Previous works consider certain activation functions on small NNs,\nhowever the studied NN is a deep network with different activation functions.\nOur experiments show that the proposed approach for parameter initialization\nachieves better performance comparing to randomly initialized networks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:31:29 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:15:58 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 06:28:16 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Danesh", "Mohamad H.", ""]]}, {"id": "2011.01205", "submitter": "Jeffrey Li", "authors": "Jeffrey Li, Vaishnavh Nagarajan, Gregory Plumb, Ameet Talwalkar", "title": "A Learning Theoretic Perspective on Local Explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore connections between interpretable machine learning\nand learning theory through the lens of local approximation explanations.\nFirst, we tackle the traditional problem of performance generalization and\nbound the test-time accuracy of a model using a notion of how locally\nexplainable it is. Second, we explore the novel problem of explanation\ngeneralization which is an important concern for a growing class of finite\nsample-based local approximation explanations. Finally, we validate our\ntheoretical results empirically and show that they reflect what can be seen in\npractice.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:48:46 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Li", "Jeffrey", ""], ["Nagarajan", "Vaishnavh", ""], ["Plumb", "Gregory", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2011.01210", "submitter": "Nanxin Chen", "authors": "Nanxin Chen, Piotr \\.Zelasko, Jes\\'us Villalba, Najim Dehak", "title": "Focus on the present: a regularization method for the ASR source-target\n  attention layer", "comments": "submitted to ICASSP2021. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method to diagnose the source-target attention\nin state-of-the-art end-to-end speech recognition models with joint\nconnectionist temporal classification (CTC) and attention training. Our method\nis based on the fact that both, CTC and source-target attention, are acting on\nthe same encoder representations. To understand the functionality of the\nattention, CTC is applied to compute the token posteriors given the attention\noutputs. We found that the source-target attention heads are able to predict\nseveral tokens ahead of the current one. Inspired by the observation, a new\nregularization method is proposed which leverages CTC to make source-target\nattention more focused on the frames corresponding to the output token being\npredicted by the decoder. Experiments reveal stable improvements up to 7\\% and\n13\\% relatively with the proposed regularization on TED-LIUM 2 and LibriSpeech.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:56:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Chen", "Nanxin", ""], ["\u017belasko", "Piotr", ""], ["Villalba", "Jes\u00fas", ""], ["Dehak", "Najim", ""]]}, {"id": "2011.01217", "submitter": "Erhan Bayraktar", "authors": "Erhan Bayraktar and Ibrahim Ekren and Xin Zhang", "title": "Prediction against a limited adversary", "comments": "To appear in Journal of Machine Learning Research (JMLR). Keywords:\n  machine learning, expert advice framework, asymptotic expansion,\n  discontinuous viscosity solutions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of prediction with expert advice with adversarial\ncorruption where the adversary can at most corrupt one expert. Using tools from\nviscosity theory, we characterize the long-time behavior of the value function\nof the game between the forecaster and the adversary. We provide lower and\nupper bounds for the growth rate of regret without relying on a comparison\nresult. We show that depending on the description of regret, the limiting\nbehavior of the game can significantly differ.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 00:15:39 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 22:31:07 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 17:15:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Bayraktar", "Erhan", ""], ["Ekren", "Ibrahim", ""], ["Zhang", "Xin", ""]]}, {"id": "2011.01219", "submitter": "Zhaowei She", "authors": "Zhaowei She, Zilong Wang, Turgay Ayer, Asmae Toumi, Jagpreet Chhatwal", "title": "Estimating County-Level COVID-19 Exponential Growth Rates Using\n  Generalized Random Forests", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid and accurate detection of community outbreaks is critical to address\nthe threat of resurgent waves of COVID-19. A practical challenge in outbreak\ndetection is balancing accuracy vs. speed. In particular, while estimation\naccuracy improves with longer fitting windows, speed degrades. This paper\npresents a machine learning framework to balance this tradeoff using\ngeneralized random forests (GRF), and applies it to detect county level\nCOVID-19 outbreaks. This algorithm chooses an adaptive fitting window size for\neach county based on relevant features affecting the disease spread, such as\nchanges in social distancing policies. Experiment results show that our method\noutperforms any non-adaptive window size choices in 7-day ahead COVID-19\noutbreak case number predictions.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 02:34:15 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:02:39 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 18:11:07 GMT"}, {"version": "v4", "created": "Sat, 14 Nov 2020 17:22:17 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["She", "Zhaowei", ""], ["Wang", "Zilong", ""], ["Ayer", "Turgay", ""], ["Toumi", "Asmae", ""], ["Chhatwal", "Jagpreet", ""]]}, {"id": "2011.01223", "submitter": "Zicun Cong", "authors": "Zicun Cong, Lingyang Chu, Yu Yang, Jian Pei", "title": "Comprehensible Counterfactual Explanation on Kolmogorov-Smirnov Test", "comments": "Accepted by VLDB 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kolmogorov-Smirnov (KS) test is popularly used in many applications, such\nas anomaly detection, astronomy, database security and AI systems. One\nchallenge remained untouched is how we can obtain an explanation on why a test\nset fails the KS test. In this paper, we tackle the problem of producing\ncounterfactual explanations for test data failing the KS test. Concept-wise, we\npropose the notion of most comprehensible counterfactual explanations, which\naccommodates both the KS test data and the user domain knowledge in producing\nexplanations. Computation-wise, we develop an efficient algorithm MOCHE (for\nMOst CompreHensible Explanation) that avoids enumerating and checking an\nexponential number of subsets of the test set failing the KS test. MOCHE not\nonly guarantees to produce the most comprehensible counterfactual explanations,\nbut also is orders of magnitudes faster than the baselines. Experiment-wise, we\npresent a systematic empirical study on a series of benchmark real datasets to\nverify the effectiveness, efficiency and scalability of most comprehensible\ncounterfactual explanations and MOCHE.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 06:46:01 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 01:23:23 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Cong", "Zicun", ""], ["Chu", "Lingyang", ""], ["Yang", "Yu", ""], ["Pei", "Jian", ""]]}, {"id": "2011.01224", "submitter": "Yue Zhang", "authors": "Yue Zhang, Yajie Zou, Jinjun Tang, Jian Liang", "title": "A Lane-Changing Prediction Method Based on Temporal Convolution Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lane-changing is an important driving behavior and unreasonable lane changes\ncan result in potentially dangerous traffic collisions. Advanced Driver\nAssistance System (ADAS) can assist drivers to change lanes safely and\nefficiently. To capture the stochastic time series of lane-changing behavior,\nthis study proposes a temporal convolutional network (TCN) to predict the\nlong-term lane-changing trajectory and behavior. In addition, the convolutional\nneural network (CNN) and recurrent neural network (RNN) methods are considered\nas the benchmark models to demonstrate the learning ability of the TCN. The\nlane-changing dataset was collected by the driving simulator. The prediction\nperformance of TCN is demonstrated from three aspects: different input\nvariables, different input dimensions and different driving scenarios.\nPrediction results show that the TCN can accurately predict the long-term\nlane-changing trajectory and driving behavior with shorter computational time\ncompared with two benchmark models. The TCN can provide accurate lane-changing\nprediction, which is one key information for the development of accurate ADAS.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 07:33:10 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhang", "Yue", ""], ["Zou", "Yajie", ""], ["Tang", "Jinjun", ""], ["Liang", "Jian", ""]]}, {"id": "2011.01226", "submitter": "Charles Gadd", "authors": "Charles Gadd, Markus Heinonen, Harri L\\\"ahdesm\\\"aki and Samuel Kaski", "title": "Sample-efficient reinforcement learning using deep Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning provides a framework for learning to control which\nactions to take towards completing a task through trial-and-error. In many\napplications observing interactions is costly, necessitating sample-efficient\nlearning. In model-based reinforcement learning efficiency is improved by\nlearning to simulate the world dynamics. The challenge is that model\ninaccuracies rapidly accumulate over planned trajectories. We introduce deep\nGaussian processes where the depth of the compositions introduces model\ncomplexity while incorporating prior knowledge on the dynamics brings\nsmoothness and structure. Our approach is able to sample a Bayesian posterior\nover trajectories. We demonstrate highly improved early sample-efficiency over\ncompeting methods. This is shown across a number of continuous control tasks,\nincluding the half-cheetah whose contact dynamics have previously posed an\ninsurmountable problem for earlier sample-efficient Gaussian process based\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:37:57 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Gadd", "Charles", ""], ["Heinonen", "Markus", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""], ["Kaski", "Samuel", ""]]}, {"id": "2011.01243", "submitter": "Keming Zhang", "authors": "Keming Zhang, Joshua S. Bloom", "title": "Classification of Periodic Variable Stars with Novel Cyclic-Permutation\n  Invariant Neural Networks", "comments": "Accepted to MNRAS. Extended abstract accepted to NeurIPS 2020:\n  Machine Learning for the Physical Sciences. Initially appeared in ICLR 2020:\n  Fundamental Science in the Era of AI. Open source implementation at\n  https://github.com/kmzzhang/periodicnetwork. 8 pages, 4 figures", "journal-ref": null, "doi": "10.1093/mnras/stab1248", "report-no": null, "categories": "astro-ph.IM astro-ph.SR cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) have been shown to be competitive against\nstate-of-the-art feature engineering and random forest (RF) classification of\nperiodic variable stars. Although previous work utilising NNs has made use of\nperiodicity by period folding multiple-cycle time-series into a single cycle --\nfrom time-space to phase-space -- no approach to date has taken advantage of\nthe fact that network predictions should be invariant to the initial phase of\nthe period-folded sequence. Initial phase is exogenous to the physical origin\nof the variability and should thus be factored out. Here, we present\ncyclic-permutation invariant networks, a novel class of NNs for which\ninvariance to phase shifts is guaranteed through polar coordinate convolutions,\nwhich we implement by means of \"Symmetry Padding.\" Across three different\ndatasets of variable star light curves, we show that two implementations of the\ncyclic-permutation invariant network: the iTCN and the iResNet, consistently\noutperform non-invariant baselines and reduce overall error rates by between 4%\nto 22%. Over a 10-class OGLE-III sample, the iTCN/iResNet achieves an average\nper-class accuracy of 93.4%/93.3%, compared to RNN/RF accuracies of 70.5%/89.5%\nin a recent study using the same data. Finding improvement on a non-astronomy\nbenchmark, we suggest that the methodology introduced here should also be\napplicable to a wide range of science domains where periodic data abounds due\nto physical symmetries.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 19:00:01 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 16:38:20 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhang", "Keming", ""], ["Bloom", "Joshua S.", ""]]}, {"id": "2011.01272", "submitter": "Ammar Shaker", "authors": "Ammar Shaker, Shujian Yu, Francesco Alesiani", "title": "Modular-Relatedness for Continual Learning", "comments": "We realized one conclusion in the submission is erroneous and\n  disconnected from the results shown in one theorem is. We decide to withdraw\n  the current version to avoid misleading conclusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a continual learning (CL) technique that is\nbeneficial to sequential task learners by improving their retained accuracy and\nreducing catastrophic forgetting. The principal target of our approach is the\nautomatic extraction of modular parts of the neural network and then estimating\nthe relatedness between the tasks given these modular components. This\ntechnique is applicable to different families of CL methods such as\nregularization-based (e.g., the Elastic Weight Consolidation) or the\nrehearsal-based (e.g., the Gradient Episodic Memory) approaches where episodic\nmemory is needed. Empirical results demonstrate remarkable performance gain (in\nterms of robustness to forgetting) for methods such as EWC and GEM based on our\ntechnique, especially when the memory budget is very limited.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 19:30:15 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 02:47:19 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Shaker", "Ammar", ""], ["Yu", "Shujian", ""], ["Alesiani", "Francesco", ""]]}, {"id": "2011.01285", "submitter": "Jason Hartford", "authors": "Jason Hartford, Kevin Leyton-Brown, Hadas Raviv, Dan Padnos, Shahar\n  Lev, Barak Lenz", "title": "Exemplar Guided Active Learning", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of wisely using a limited budget to label a small\nsubset of a large unlabeled dataset. We are motivated by the NLP problem of\nword sense disambiguation. For any word, we have a set of candidate labels from\na knowledge base, but the label set is not necessarily representative of what\noccurs in the data: there may exist labels in the knowledge base that very\nrarely occur in the corpus because the sense is rare in modern English; and\nconversely there may exist true labels that do not exist in our knowledge base.\nOur aim is to obtain a classifier that performs as well as possible on examples\nof each \"common class\" that occurs with frequency above a given threshold in\nthe unlabeled set while annotating as few examples as possible from \"rare\nclasses\" whose labels occur with less than this frequency. The challenge is\nthat we are not informed which labels are common and which are rare, and the\ntrue label distribution may exhibit extreme skew. We describe an active\nlearning approach that (1) explicitly searches for rare classes by leveraging\nthe contextual embedding spaces provided by modern language models, and (2)\nincorporates a stopping rule that ignores classes once we prove that they occur\nbelow our target threshold with high probability. We prove that our algorithm\nonly costs logarithmically more than a hypothetical approach that knows all\ntrue label frequencies and show experimentally that incorporating automated\nsearch can significantly reduce the number of samples needed to reach target\naccuracy levels.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:01:39 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hartford", "Jason", ""], ["Leyton-Brown", "Kevin", ""], ["Raviv", "Hadas", ""], ["Padnos", "Dan", ""], ["Lev", "Shahar", ""], ["Lenz", "Barak", ""]]}, {"id": "2011.01297", "submitter": "Paniz Behboudian", "authors": "Paniz Behboudian, Yash Satsangi, Matthew E. Taylor, Anna Harutyunyan,\n  Michael Bowling", "title": "Useful Policy Invariant Shaping from Arbitrary Advice", "comments": "9 pages, 6 figures, Adaptive and Learning Agents (ALA) 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a powerful learning paradigm in which agents can\nlearn to maximize sparse and delayed reward signals. Although RL has had many\nimpressive successes in complex domains, learning can take hours, days, or even\nyears of training data. A major challenge of contemporary RL research is to\ndiscover how to learn with less data. Previous work has shown that domain\ninformation can be successfully used to shape the reward; by adding additional\nreward information, the agent can learn with much less data. Furthermore, if\nthe reward is constructed from a potential function, the optimal policy is\nguaranteed to be unaltered. While such potential-based reward shaping (PBRS)\nholds promise, it is limited by the need for a well-defined potential function.\nIdeally, we would like to be able to take arbitrary advice from a human or\nother agent and improve performance without affecting the optimal policy. The\nrecently introduced dynamic potential based advice (DPBA) method tackles this\nchallenge by admitting arbitrary advice from a human or other agent and\nimproves performance without affecting the optimal policy. The main\ncontribution of this paper is to expose, theoretically and empirically, a flaw\nin DPBA. Alternatively, to achieve the ideal goals, we present a simple method\ncalled policy invariant explicit shaping (PIES) and show theoretically and\nempirically that PIES succeeds where DPBA fails.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:29:09 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Behboudian", "Paniz", ""], ["Satsangi", "Yash", ""], ["Taylor", "Matthew E.", ""], ["Harutyunyan", "Anna", ""], ["Bowling", "Michael", ""]]}, {"id": "2011.01298", "submitter": "Yuchen Wu", "authors": "Yuchen Wu, Melissa Mozifian, Florian Shkurti", "title": "Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations\n  using Generative Models", "comments": "submitted to ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential benefits of model-free reinforcement learning to real robotics\nsystems are limited by its uninformed exploration that leads to slow\nconvergence, lack of data-efficiency, and unnecessary interactions with the\nenvironment. To address these drawbacks we propose a method that combines\nreinforcement and imitation learning by shaping the reward function with a\nstate-and-action-dependent potential that is trained from demonstration data,\nusing a generative model. We show that this accelerates policy learning by\nspecifying high-value areas of the state and action space that are worth\nexploring first. Unlike the majority of existing methods that assume optimal\ndemonstrations and incorporate the demonstration data as hard constraints on\npolicy optimization, we instead incorporate demonstration data as advice in the\nform of a reward shaping potential trained as a generative model of states and\nactions. In particular, we examine both normalizing flows and Generative\nAdversarial Networks to represent these potentials. We show that, unlike many\nexisting approaches that incorporate demonstrations as hard constraints, our\napproach is unbiased even in the case of suboptimal and noisy demonstrations.\nWe present an extensive range of simulations, as well as experiments on the\nFranka Emika 7DOF arm, to demonstrate the practicality of our method.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:32:05 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wu", "Yuchen", ""], ["Mozifian", "Melissa", ""], ["Shkurti", "Florian", ""]]}, {"id": "2011.01302", "submitter": "Yaoyao Ding", "authors": "Yaoyao Ding, Ligeng Zhu, Zhihao Jia, Gennady Pekhimenko and Song Han", "title": "IOS: Inter-Operator Scheduler for CNN Acceleration", "comments": "Accepted by MLSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accelerate CNN inference, existing deep learning frameworks focus on\noptimizing intra-operator parallelization. However, a single operator can no\nlonger fully utilize the available parallelism given the rapid advances in\nhigh-performance hardware, resulting in a large gap between the peak\nperformance and the real performance. This performance gap is more severe under\nsmaller batch sizes. In this work, we extensively study the parallelism between\noperators and propose Inter-Operator Scheduler (IOS) to automatically schedule\nmultiple operators' parallel execution through a novel dynamic programming\nalgorithm. IOS consistently outperforms state-of-the-art libraries (e.g.,\nTensorRT) by 1.1 to 1.5x on modern CNN benchmarks. The code to reproduce each\nexperiment is available at:\nhttps://github.com/mit-han-lab/inter-operator-scheduler.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:42:26 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 16:32:25 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Ding", "Yaoyao", ""], ["Zhu", "Ligeng", ""], ["Jia", "Zhihao", ""], ["Pekhimenko", "Gennady", ""], ["Han", "Song", ""]]}, {"id": "2011.01307", "submitter": "Luke Melas-Kyriazi", "authors": "Luke Melas-Kyriazi", "title": "The Mathematical Foundations of Manifold Learning", "comments": "Undergraduate Thesis (Harvard Mathematics Department)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning is a popular and quickly-growing subfield of machine\nlearning based on the assumption that one's observed data lie on a\nlow-dimensional manifold embedded in a higher-dimensional space. This thesis\npresents a mathematical perspective on manifold learning, delving into the\nintersection of kernel learning, spectral graph theory, and differential\ngeometry. Emphasis is placed on the remarkable interplay between graphs and\nmanifolds, which forms the foundation for the widely-used technique of manifold\nregularization. This work is written to be accessible to a broad mathematical\naudience, including machine learning researchers and practitioners interested\nin understanding the theorems underlying popular manifold learning algorithms\nand dimensionality reduction techniques.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 12:04:20 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Melas-Kyriazi", "Luke", ""]]}, {"id": "2011.01324", "submitter": "Peter Xenopoulos", "authors": "Peter Xenopoulos, Harish Doraiswamy, Claudio Silva", "title": "Valuing Player Actions in Counter-Strike: Global Offensive", "comments": "to be published in 2020 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Esports, despite its expanding interest, lacks fundamental sports analytics\nresources such as accessible data or proven and reproducible analytical\nframeworks. Even Counter-Strike: Global Offensive (CSGO), the second most\npopular esport, suffers from these problems. Thus, quantitative evaluation of\nCSGO players, a task important to teams, media, bettors and fans, is difficult.\nTo address this, we introduce (1) a data model for CSGO with an open-source\nimplementation; (2) a graph distance measure for defining distances in CSGO;\nand (3) a context-aware framework to value players' actions based on changes in\ntheir team's chances of winning. Using over 70 million in-game CSGO events, we\ndemonstrate our framework's consistency and independence compared to existing\nvaluation frameworks. We also provide use cases demonstrating high-impact play\nidentification and uncertainty estimation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 21:11:14 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 18:35:51 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Xenopoulos", "Peter", ""], ["Doraiswamy", "Harish", ""], ["Silva", "Claudio", ""]]}, {"id": "2011.01334", "submitter": "Dane Taylor", "authors": "Bao Huynh, Haimonti Dutta, Dane Taylor", "title": "Impact of Community Structure on Consensus Machine Learning", "comments": "9 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus dynamics support decentralized machine learning for data that is\ndistributed across a cloud compute cluster or across the internet of things. In\nthese and other settings, one seeks to minimize the time $\\tau_\\epsilon$\nrequired to obtain consensus within some $\\epsilon>0$ margin of error.\n$\\tau_\\epsilon$ typically depends on the topology of the underlying\ncommunication network, and for many algorithms $\\tau_\\epsilon$ depends on the\nsecond-smallest eigenvalue $\\lambda_2\\in[0,1]$ of the network's normalized\nLaplacian matrix: $\\tau_\\epsilon\\sim\\mathcal{O}(\\lambda_2^{-1})$. Here, we\nanalyze the effect on $\\tau_\\epsilon$ of network community structure, which can\narise when compute nodes/sensors are spatially clustered, for example. We study\nconsensus machine learning over networks drawn from stochastic block models,\nwhich yield random networks that can contain heterogeneous communities with\ndifferent sizes and densities. Using random matrix theory, we analyze the\neffects of communities on $\\lambda_2$ and consensus, finding that $\\lambda_2$\ngenerally increases (i.e., $\\tau_\\epsilon$ decreases) as one decreases the\nextent of community structure. We further observe that there exists a critical\nlevel of community structure at which $\\tau_\\epsilon$ reaches a lower bound and\nis no longer limited by the presence of communities. We support our findings\nwith empirical experiments for decentralized support vector machines.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 21:41:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Huynh", "Bao", ""], ["Dutta", "Haimonti", ""], ["Taylor", "Dane", ""]]}, {"id": "2011.01337", "submitter": "Pablo Barros", "authors": "Pablo Barros, Ana Tanevska, Ozge Yalcin, Alessandra Sciutti", "title": "Incorporating Rivalry in Reinforcement Learning for a Competitive Game", "comments": "Accepted at the Pre-registration Workshop @ NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in reinforcement learning with social agents have allowed us\nto achieve human-level performance on some interaction tasks. However, most\ninteractive scenarios do not have as end-goal performance alone; instead, the\nsocial impact of these agents when interacting with humans is as important and,\nin most cases, never explored properly. This preregistration study focuses on\nproviding a novel learning mechanism based on a rivalry social impact. Our\nscenario explored different reinforcement learning-based agents playing a\ncompetitive card game against human players. Based on the concept of\ncompetitive rivalry, our analysis aims to investigate if we can change the\nassessment of these agents from a human perspective.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 21:54:18 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Barros", "Pablo", ""], ["Tanevska", "Ana", ""], ["Yalcin", "Ozge", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2011.01352", "submitter": "Mari Kobayashi", "authors": "Mohammad Mahdi Mahvari, Mari Kobayashi, Abdellatif Zaidi", "title": "On the Relevance-Complexity Region of Scalable Information Bottleneck", "comments": "Submitted to IEEE Information Theory Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Bottleneck method is a learning technique that seeks a right\nbalance between accuracy and generalization capability through a suitable\ntradeoff between compression complexity, measured by minimum description\nlength, and distortion evaluated under logarithmic loss measure. In this paper,\nwe study a variation of the problem, called scalable information bottleneck,\nwhere the encoder outputs multiple descriptions of the observation with\nincreasingly richer features. The problem at hand is motivated by some\napplication scenarios that require varying levels of accuracy depending on the\nallowed level of generalization. First, we establish explicit (analytic)\ncharacterizations of the relevance-complexity region for memoryless Gaussian\nsources and memoryless binary sources. Then, we derive a Blahut-Arimoto type\nalgorithm that allows us to compute (an approximation of) the region for\ngeneral discrete sources. Finally, an application example in the pattern\nclassification problem is provided along with numerical results.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:25:28 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Mahvari", "Mohammad Mahdi", ""], ["Kobayashi", "Mari", ""], ["Zaidi", "Abdellatif", ""]]}, {"id": "2011.01354", "submitter": "Kenny Chen", "authors": "Kenny Chen, Alexandra Pogue, Brett T. Lopez, Ali-akbar Agha-mohammadi,\n  and Ankur Mehta", "title": "Unsupervised Monocular Depth Learning with Integrated Intrinsics and\n  Spatio-Temporal Constraints", "comments": "Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2021), Prague, Czech Republic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monocular depth inference has gained tremendous attention from researchers in\nrecent years and remains as a promising replacement for expensive\ntime-of-flight sensors, but issues with scale acquisition and implementation\noverhead still plague these systems. To this end, this work presents an\nunsupervised learning framework that is able to predict at-scale depth maps and\negomotion, in addition to camera intrinsics, from a sequence of monocular\nimages via a single network. Our method incorporates both spatial and temporal\ngeometric constraints to resolve depth and pose scale factors, which are\nenforced within the supervisory reconstruction loss functions at training time.\nOnly unlabeled stereo sequences are required for training the weights of our\nsingle-network architecture, which reduces overall implementation overhead as\ncompared to previous methods. Our results demonstrate strong performance when\ncompared to the current state-of-the-art on multiple sequences of the KITTI\ndriving dataset and can provide faster training times with its reduced network\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:26:58 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 20:36:06 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Chen", "Kenny", ""], ["Pogue", "Alexandra", ""], ["Lopez", "Brett T.", ""], ["Agha-mohammadi", "Ali-akbar", ""], ["Mehta", "Ankur", ""]]}, {"id": "2011.01355", "submitter": "Shreyas Fadnavis", "authors": "Shreyas Fadnavis, Joshua Batson, Eleftherios Garyfallidis", "title": "Patch2Self: Denoising Diffusion MRI with Self-Supervised Learning", "comments": null, "journal-ref": "Thirty-fourth Conference on Neural Information Processing Systems,\n  2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diffusion-weighted magnetic resonance imaging (DWI) is the only noninvasive\nmethod for quantifying microstructure and reconstructing white-matter pathways\nin the living human brain. Fluctuations from multiple sources create\nsignificant additive noise in DWI data which must be suppressed before\nsubsequent microstructure analysis. We introduce a self-supervised learning\nmethod for denoising DWI data, Patch2Self, which uses the entire volume to\nlearn a full-rank locally linear denoiser for that volume. By taking advantage\nof the oversampled q-space of DWI data, Patch2Self can separate structure from\nnoise without requiring an explicit model for either. We demonstrate the\neffectiveness of Patch2Self via quantitative and qualitative improvements in\nmicrostructure modeling, tracking (via fiber bundle coherency) and model\nestimation relative to other unsupervised methods on real and simulated data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:27:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Fadnavis", "Shreyas", ""], ["Batson", "Joshua", ""], ["Garyfallidis", "Eleftherios", ""]]}, {"id": "2011.01358", "submitter": "Azton Wells", "authors": "Azton I. Wells and Michael L. Norman", "title": "Predicting Localized Primordial Star Formation with Deep Convolutional\n  Neural Networks", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": "10.3847/1538-4365/abfa17", "report-no": null, "categories": "astro-ph.GA astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate applying 3D deep convolutional neural networks as fast\nsurrogate models of the formation and feedback effects of primordial stars in\nhydrodynamic cosmological simulations of the first galaxies. Here, we present\nthe surrogate model to predict localized primordial star formation; the\nfeedback model will be presented in a subsequent paper. The star formation\nprediction model consists of two sub-models: the first is a 3D volume\nclassifier that predicts which (10 comoving kpc)$^3$ volumes will host star\nformation, followed by a 3D Inception-based U-net voxel segmentation model that\npredicts which voxels will form primordial stars. We find that the combined\nmodel predicts primordial star forming volumes with high skill, with $F_1\n>0.995$ and true skill score $>0.994$. The star formation is localized within\nthe volume to $\\lesssim5^3$~voxels ($\\sim1.6$~comoving kpc$^3$) with\n$F_1>0.399$ and true skill score $>0.857$. Applied to simulations with low\nspatial resolution, the model predicts star forming regions in the same\nlocations and at similar redshifts as sites in resolved full-physics\nsimulations that explicitly model primordial star formation and feedback. When\napplied to simulations with lower mass resolution, we find that the model\npredicts star forming regions at later redshift due to delayed structure\nformation resulting from lower mass resolution. Our model predicts primordial\nstar formation without halo finding, so will be useful in spatially\nunder-resolved simulations that cannot resolve primordial star forming halos.\nTo our knowledge, this is the first model that can predict primordial star\nforming regions that match highly-resolved cosmological simulations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:32:27 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 21:47:02 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wells", "Azton I.", ""], ["Norman", "Michael L.", ""]]}, {"id": "2011.01364", "submitter": "Feicheng Wang", "authors": "Feicheng Wang and Lucas Janson", "title": "Exact Asymptotics for Linear Quadratic Adaptive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in reinforcement learning has led to remarkable performance\nin a range of applications, but its deployment in high-stakes settings remains\nquite rare. One reason is a limited understanding of the behavior of\nreinforcement algorithms, both in terms of their regret and their ability to\nlearn the underlying system dynamics---existing work is focused almost\nexclusively on characterizing rates, with little attention paid to the\nconstants multiplying those rates that can be critically important in practice.\nTo start to address this challenge, we study perhaps the simplest non-bandit\nreinforcement learning problem: linear quadratic adaptive control (LQAC). By\ncarefully combining recent finite-sample performance bounds for the LQAC\nproblem with a particular (less-recent) martingale central limit theorem, we\nare able to derive asymptotically-exact expressions for the regret, estimation\nerror, and prediction error of a rate-optimal stepwise-updating LQAC algorithm.\nIn simulations on both stable and unstable systems, we find that our asymptotic\ntheory also describes the algorithm's finite-sample behavior remarkably well.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:43:30 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Feicheng", ""], ["Janson", "Lucas", ""]]}, {"id": "2011.01374", "submitter": "Allison Koenecke", "authors": "Allison Koenecke and Hal Varian", "title": "Synthetic Data Generation for Economists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more tech companies engage in rigorous economic analyses, we are\nconfronted with a data problem: in-house papers cannot be replicated due to use\nof sensitive, proprietary, or private data. Readers are left to assume that the\nobscured true data (e.g., internal Google information) indeed produced the\nresults given, or they must seek out comparable public-facing data (e.g.,\nGoogle Trends) that yield similar results. One way to ameliorate this\nreproducibility issue is to have researchers release synthetic datasets based\non their true data; this allows external parties to replicate an internal\nresearcher's methodology. In this brief overview, we explore synthetic data\ngeneration at a high level for economic analyses.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 23:05:55 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 21:03:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Koenecke", "Allison", ""], ["Varian", "Hal", ""]]}, {"id": "2011.01381", "submitter": "Dennis Wei", "authors": "Dennis Wei", "title": "Optimal Policies for the Homogeneous Selective Labels Problem", "comments": "12 pages, 1 figure. To be presented at the Workshop on Consequential\n  Decision Making in Dynamic Environments at the 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective labels are a common feature of consequential decision-making\napplications, referring to the lack of observed outcomes under one of the\npossible decisions. This paper reports work in progress on learning decision\npolicies in the face of selective labels. The setting considered is both a\nsimplified homogeneous one, disregarding individuals' features to facilitate\ndetermination of optimal policies, and an online one, to balance costs incurred\nin learning with future utility. For maximizing discounted total reward, the\noptimal policy is shown to be a threshold policy, and the problem is one of\noptimal stopping. In contrast, for undiscounted infinite-horizon average\nreward, optimal policies have positive acceptance probability in all states.\nFuture work stemming from these results is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 23:32:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wei", "Dennis", ""]]}, {"id": "2011.01383", "submitter": "Pratik Fegade", "authors": "Pratik Fegade, Tianqi Chen, Phillip B. Gibbons, Todd C. Mowry", "title": "Cortex: A Compiler for Recursive Deep Learning Models", "comments": "11 pages, 12 figures and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing deep learning models is generally performed in two steps: (i)\nhigh-level graph optimizations such as kernel fusion and (ii) low level kernel\noptimizations such as those found in vendor libraries. This approach often\nleaves significant performance on the table, especially for the case of\nrecursive deep learning models. In this paper, we present Cortex, a\ncompiler-based approach to generate highly-efficient code for recursive models\nfor low latency inference. Our compiler approach and low reliance on vendor\nlibraries enables us to perform end-to-end optimizations, leading to up to 14X\nlower inference latencies over past work, across different backends.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 23:35:14 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 16:37:53 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Fegade", "Pratik", ""], ["Chen", "Tianqi", ""], ["Gibbons", "Phillip B.", ""], ["Mowry", "Todd C.", ""]]}, {"id": "2011.01393", "submitter": "Xu Chen", "authors": "Yunpeng Weng and Xu Chen and Liang Chen and Wei Liu", "title": "GAIN: Graph Attention & Interaction Network for Inductive\n  Semi-Supervised Learning over Large-scale Graphs", "comments": "Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have led to state-of-the-art performance on a\nvariety of machine learning tasks such as recommendation, node classification\nand link prediction. Graph neural network models generate node embeddings by\nmerging nodes features with the aggregated neighboring nodes information. Most\nexisting GNN models exploit a single type of aggregator (e.g., mean-pooling) to\naggregate neighboring nodes information, and then add or concatenate the output\nof aggregator to the current representation vector of the center node. However,\nusing only a single type of aggregator is difficult to capture the different\naspects of neighboring information and the simple addition or concatenation\nupdate methods limit the expressive capability of GNNs. Not only that, existing\nsupervised or semi-supervised GNN models are trained based on the loss function\nof the node label, which leads to the neglect of graph structure information.\nIn this paper, we propose a novel graph neural network architecture, Graph\nAttention \\& Interaction Network (GAIN), for inductive learning on graphs.\nUnlike the previous GNN models that only utilize a single type of aggregation\nmethod, we use multiple types of aggregators to gather neighboring information\nin different aspects and integrate the outputs of these aggregators through the\naggregator-level attention mechanism. Furthermore, we design a graph\nregularized loss to better capture the topological relationship of the nodes in\nthe graph. Additionally, we first present the concept of graph feature\ninteraction and propose a vector-wise explicit feature interaction mechanism to\nupdate the node embeddings. We conduct comprehensive experiments on two\nnode-classification benchmarks and a real-world financial news dataset. The\nexperiments demonstrate our GAIN model outperforms current state-of-the-art\nperformances on all the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 00:20:24 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Weng", "Yunpeng", ""], ["Chen", "Xu", ""], ["Chen", "Liang", ""], ["Liu", "Wei", ""]]}, {"id": "2011.01403", "submitter": "Beliz Gunel", "authors": "Beliz Gunel, Jingfei Du, Alexis Conneau, Ves Stoyanov", "title": "Supervised Contrastive Learning for Pre-trained Language Model\n  Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art natural language understanding classification models follow\ntwo-stages: pre-training a large language model on an auxiliary task, and then\nfine-tuning the model on a task-specific labeled dataset using cross-entropy\nloss. However, the cross-entropy loss has several shortcomings that can lead to\nsub-optimal generalization and instability. Driven by the intuition that good\ngeneralization requires capturing the similarity between examples in one class\nand contrasting them with examples in other classes, we propose a supervised\ncontrastive learning (SCL) objective for the fine-tuning stage. Combined with\ncross-entropy, our proposed SCL loss obtains significant improvements over a\nstrong RoBERTa-Large baseline on multiple datasets of the GLUE benchmark in\nfew-shot learning settings, without requiring specialized architecture, data\naugmentations, memory banks, or additional unsupervised data. Our proposed\nfine-tuning objective leads to models that are more robust to different levels\nof noise in the fine-tuning training data, and can generalize better to related\ntasks with limited labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 01:10:39 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 02:05:56 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 20:27:44 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gunel", "Beliz", ""], ["Du", "Jingfei", ""], ["Conneau", "Alexis", ""], ["Stoyanov", "Ves", ""]]}, {"id": "2011.01406", "submitter": "Majed El Helou", "authors": "Majed El Helou and Sabine S\\\"usstrunk", "title": "BIGPrior: Towards Decoupling Learned Prior Hallucination and Data\n  Fidelity in Image Restoration", "comments": "Under submission. Code available on\n  https://github.com/majedelhelou/BIGPrior", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image restoration encompasses fundamental image processing tasks that have\nbeen addressed with different algorithms and deep learning methods. Classical\nrestoration algorithms leverage a variety of priors, either implicitly or\nexplicitly. Their priors are hand-designed and their corresponding weights are\nheuristically assigned. Thus, deep learning methods often produce superior\nrestoration quality. Deep networks are, however, capable of strong and\nhardly-predictable hallucinations. Networks jointly and implicitly learn to be\nfaithful to the observed data while learning an image prior, and the separation\nof original and hallucinated data downstream is then not possible. This limits\ntheir wide-spread adoption in restoration applications. Furthermore, it is\noften the hallucinated part that is victim to degradation-model overfitting. We\npresent an approach with decoupled network-prior hallucination and data\nfidelity. We refer to our framework as the Bayesian Integration of a Generative\nPrior (BIGPrior). Our BIGPrior method is rooted in a Bayesian restoration\nframework, and tightly connected to classical restoration methods. In fact, our\napproach can be viewed as a generalization of a large family of classical\nrestoration algorithms. We leverage a recent network inversion method to\nextract image prior information from a generative network. We show on image\ncolorization, inpainting, and denoising that our framework consistently\nimproves the prior results through good integration of data fidelity. Our\nmethod, though partly reliant on the quality of the generative network\ninversion, is competitive with state-of-the-art supervised and task-specific\nrestoration methods. It also provides an additional metric that sets forth the\ndegree of prior reliance per pixel. Indeed, the per pixel contributions of the\ndecoupled data fidelity and prior terms are readily available in our proposed\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 01:16:41 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 18:51:48 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Helou", "Majed El", ""], ["S\u00fcsstrunk", "Sabine", ""]]}, {"id": "2011.01412", "submitter": "Siheng Chen", "authors": "Siheng Chen and Maosen Li and Ya Zhang", "title": "Sampling and Recovery of Graph Signals based on Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose interpretable graph neural networks for sampling and recovery of\ngraph signals, respectively. To take informative measurements, we propose a new\ngraph neural sampling module, which aims to select those vertices that\nmaximally express their corresponding neighborhoods. Such expressiveness can be\nquantified by the mutual information between vertices' features and\nneighborhoods' features, which are estimated via a graph neural network. To\nreconstruct an original graph signal from the sampled measurements, we propose\na graph neural recovery module based on the algorithm-unrolling technique.\nCompared to previous analytical sampling and recovery, the proposed methods are\nable to flexibly learn a variety of graph signal models from data by leveraging\nthe learning ability of neural networks; compared to previous\nneural-network-based sampling and recovery, the proposed methods are designed\nthrough exploiting specific graph properties and provide interpretability. We\nfurther design a new multiscale graph neural network, which is a trainable\nmultiscale graph filter bank and can handle various graph-related learning\ntasks. The multiscale network leverages the proposed graph neural sampling and\nrecovery modules to achieve multiscale representations of a graph. In the\nexperiments, we illustrate the effects of the proposed graph neural sampling\nand recovery modules and find that the modules can flexibly adapt to various\ngraph structures and graph signals. In the task of active-sampling-based\nsemi-supervised learning, the graph neural sampling module improves the\nclassification accuracy over 10% in Cora dataset. We further validate the\nproposed multiscale graph neural network on several standard datasets for both\nvertex and graph classification. The results show that our method consistently\nimproves the classification accuracies.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 01:45:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Siheng", ""], ["Li", "Maosen", ""], ["Zhang", "Ya", ""]]}, {"id": "2011.01417", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "Non-Equilibrium Skewness, Market Crises, and Option Pricing: Non-Linear\n  Langevin Model of Markets with Supersymmetry", "comments": "45 pages, 13 figures, 11 tables. Extended the section on numerical\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a tractable model of non-linear dynamics of market\nreturns using a Langevin approach.Due to non-linearity of an interaction\npotential, the model admits regimes of both small and large return\nfluctuations. Langevin dynamics are mapped onto an equivalent quantum\nmechanical (QM) system. Borrowing ideas from supersymmetric quantum mechanics\n(SUSY QM), we use a parameterized ground state wave function (WF) of this QM\nsystem as a direct input to the model, which also fixes a non-linear Langevin\npotential. A stationary distribution of the original Langevin model is given by\nthe square of this WF, and thus is also a direct input to the model. Using a\ntwo-component Gaussian mixture as a ground state WF with an asymmetric double\nwell potential produces a tractable low-parametric model with interpretable\nparameters, referred to as the NES (Non-Equilibrium Skew) model. Supersymmetry\n(SUSY) is then used to find time-dependent solutions of the model in an\nanalytically tractable way. The model produces time-varying variance, skewness\nand kurtosis of market returns, whose time variability can be linked to\nprobabilities of crisis-like events. For option pricing out of equilibrium, the\nNES model offers a closed-form approximation by a mixture of three\nBlack-Scholes prices, which can be calibrated to index options data and used to\npredict moments of future returns. The NES model is shown to be able to\ndescribe both regimes of a benign market and a market in a crisis or a severe\ndistress.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 01:56:06 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 04:53:05 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "2011.01418", "submitter": "Hong Liu", "authors": "Hong Liu, Jeff Z. HaoChen, Colin Wei, Tengyu Ma", "title": "Meta-learning Transferable Representations with a Single Target Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works found that fine-tuning and joint training---two popular\napproaches for transfer learning---do not always improve accuracy on downstream\ntasks. First, we aim to understand more about when and why fine-tuning and\njoint training can be suboptimal or even harmful for transfer learning. We\ndesign semi-synthetic datasets where the source task can be solved by either\nsource-specific features or transferable features. We observe that (1)\npre-training may not have incentive to learn transferable features and (2)\njoint training may simultaneously learn source-specific features and overfit to\nthe target. Second, to improve over fine-tuning and joint training, we propose\nMeta Representation Learning (MeRLin) to learn transferable features. MeRLin\nmeta-learns representations by ensuring that a head fit on top of the\nrepresentations with target training data also performs well on target\nvalidation data. We also prove that MeRLin recovers the target ground-truth\nmodel with a quadratic neural net parameterization and a source distribution\nthat contains both transferable and source-specific features. On the same\ndistribution, pre-training and joint training provably fail to learn\ntransferable features. MeRLin empirically outperforms previous state-of-the-art\ntransfer learning algorithms on various real-world vision and NLP transfer\nlearning benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 01:57:37 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Liu", "Hong", ""], ["HaoChen", "Jeff Z.", ""], ["Wei", "Colin", ""], ["Ma", "Tengyu", ""]]}, {"id": "2011.01422", "submitter": "Charilaos Kanatsoulis", "authors": "Charilaos I. Kanatsoulis, and Nicholas D. Sidiropoulos", "title": "GAGE: Geometry Preserving Attributed Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node representation learning is the task of extracting concise and\ninformative feature embeddings of certain entities that are connected in a\nnetwork. Many real world network datasets include information about both node\nconnectivity and certain node attributes, in the form of features or\ntime-series data. Modern representation learning techniques utilize both\nconnectivity and attribute information of the nodes to produce embeddings in an\nunsupervised manner. In this context, deriving embeddings that preserve the\ngeometry of the network and the attribute vectors would be highly desirable, as\nthey would reflect both the topological neighborhood structure and proximity in\nfeature space. While this is fairly straightforward to maintain when only\nobserving the connectivity or attributed information of the network, preserving\nthe geometry of both types of information is challenging. A novel tensor\nfactorization approach for node embedding in attributed networks that preserves\nthe distances of both the connections and the attributes is proposed in this\npaper, along with an effective and lightweight algorithm to tackle the learning\ntask. Judicious experiments with multiple state-of-art baselines suggest that\nthe proposed algorithm offers significant performance improvements in node\nclassification and link prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 02:07:02 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kanatsoulis", "Charilaos I.", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "2011.01424", "submitter": "Guo-Hua Wang", "authors": "Guo-Hua Wang, Yifan Ge, Jianxin Wu", "title": "In Defense of Feature Mimicking for Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a popular method to train efficient networks\n(\"student\") with the help of high-capacity networks (\"teacher\"). Traditional\nmethods use the teacher's soft logit as extra supervision to train the student\nnetwork. In this paper, we argue that it is more advantageous to make the\nstudent mimic the teacher's features in the penultimate layer. Not only the\nstudent can directly learn more effective information from the teacher feature,\nfeature mimicking can also be applied for teachers trained without a softmax\nlayer. Experiments show that it can achieve higher accuracy than traditional\nKD. To further facilitate feature mimicking, we decompose a feature vector into\nthe magnitude and the direction. We argue that the teacher should give more\nfreedom to the student feature's magnitude, and let the student pay more\nattention on mimicking the feature direction. To meet this requirement, we\npropose a loss term based on locality-sensitive hashing (LSH). With the help of\nthis new loss, our method indeed mimics feature directions more accurately,\nrelaxes constraints on feature magnitudes, and achieves state-of-the-art\ndistillation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 02:15:14 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Guo-Hua", ""], ["Ge", "Yifan", ""], ["Wu", "Jianxin", ""]]}, {"id": "2011.01429", "submitter": "Jiacheng Wang", "authors": "Jiacheng Wang, Yue Ma, and Shuang Gao", "title": "Self-semi-supervised Learning to Learn from NoisyLabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable success of today's deep neural networks highly depends on a\nmassive number of correctly labeled data. However, it is rather costly to\nobtain high-quality human-labeled data, leading to the active research area of\ntraining models robust to noisy labels. To achieve this goal, on the one hand,\nmany papers have been dedicated to differentiating noisy labels from clean ones\nto increase the generalization of DNN. On the other hand, the increasingly\nprevalent methods of self-semi-supervised learning have been proven to benefit\nthe tasks when labels are incomplete. By 'semi' we regard the wrongly labeled\ndata detected as un-labeled data; by 'self' we choose a self-supervised\ntechnique to conduct semi-supervised learning. In this project, we designed\nmethods to more accurately differentiate clean and noisy labels and borrowed\nthe wisdom of self-semi-supervised learning to train noisy labeled data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 02:31:29 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Jiacheng", ""], ["Ma", "Yue", ""], ["Gao", "Shuang", ""]]}, {"id": "2011.01436", "submitter": "Minho Kim", "authors": "Minho Kim, Doyoung Jeong, Hyoungwoo Choi, Yongil Kim", "title": "Developing High Quality Training Samples for Deep Learning Based Local\n  Climate Zone Classification in Korea", "comments": "7 pages, 7 figures; AI for Earth Workshop at NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two out of three people will be living in urban areas by 2050, as projected\nby the United Nations, emphasizing the need for sustainable urban development\nand monitoring. Common urban footprint data provide high-resolution city\nextents but lack essential information on the distribution, pattern, and\ncharacteristics. The Local Climate Zone (LCZ) offers an efficient and\nstandardized framework that can delineate the internal structure and\ncharacteristics of urban areas. Global-scale LCZ mapping has been explored, but\nare limited by low accuracy, variable labeling quality, or domain adaptation\nchallenges. Instead, this study developed a custom LCZ data to map key Korean\ncities using a multi-scale convolutional neural network. Results demonstrated\nthat using a novel, custom LCZ data with deep learning can generate more\naccurate LCZ map results compared to conventional community-based LCZ mapping\nwith machine learning as well as transfer learning of the global So2Sat\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 02:52:37 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 09:20:52 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Kim", "Minho", ""], ["Jeong", "Doyoung", ""], ["Choi", "Hyoungwoo", ""], ["Kim", "Yongil", ""]]}, {"id": "2011.01444", "submitter": "Charupriya Sharma", "authors": "Charupriya Sharma, Zhenyu A. Liao, James Cussens, Peter van Beek", "title": "A Score-and-Search Approach to Learning Bayesian Networks with Noisy-OR\n  Relations", "comments": "Accepted to Probabilistic Graphical Models, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian network is a probabilistic graphical model that consists of a\ndirected acyclic graph (DAG), where each node is a random variable and attached\nto each node is a conditional probability distribution (CPD). A Bayesian\nnetwork can be learned from data using the well-known score-and-search\napproach, and within this approach a key consideration is how to simultaneously\nlearn the global structure in the form of the underlying DAG and the local\nstructure in the CPDs. Several useful forms of local structure have been\nidentified in the literature but thus far the score-and-search approach has\nonly been extended to handle local structure in form of context-specific\nindependence. In this paper, we show how to extend the score-and-search\napproach to the important and widely useful case of noisy-OR relations. We\nprovide an effective gradient descent algorithm to score a candidate noisy-OR\nusing the widely used BIC score and we provide pruning rules that allow the\nsearch to successfully scale to medium sized networks. Our empirical results\nprovide evidence for the success of our approach to learning Bayesian networks\nthat incorporate noisy-OR relations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:20:44 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sharma", "Charupriya", ""], ["Liao", "Zhenyu A.", ""], ["Cussens", "James", ""], ["van Beek", "Peter", ""]]}, {"id": "2011.01445", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Lin F. Yang, Zizhuo Wang", "title": "Towards Fundamental Limits of Multi-armed Bandits with Random Walk\n  Feedback", "comments": "typo correction on plot labelling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the ubiquitous applications of bandit learning algorithms in\nrecommendation systems, social network, or online advertisement, where user\nbehaviors can be modeled as a random walk over a network, few studies have\nutilized the network structure to improve learning efficiency. In this paper,\nwe address this issue by providing a novel bandit learning formulation, where\neach arm is the starting node of a random walk in a network and the reward is\nthe length of walk. This formulation not only captures a large number of\napplications in practice but also provides a framework to actively reduce\nlearning complexity by utilizing graph structure in the random walk feedback.\nWe provide a comprehensive understanding of this formulation by studying both\nthe stochastic and the adversarial setting. In the stochastic setting, we\nobserve that, there exists a difficult problem instance on which the following\ntwo seemingly conflicting facts simultaneously hold: 1. No algorithm can\nachieve a regret bound independent of problem intrinsics information\ntheoretically; 2. There exists an algorithm whose performance is independent of\nproblem intrinsics in terms of tail of mistakes. This reveals an intriguing\nphenomenon in general semi-bandit feedback learning problems. In the\nadversarial setting, we establish a novel algorithm that achieve regret bound\nof order $\\widetilde{\\mathcal{O}} \\left( \\sqrt{ \\kappa T}\\right) $, where\n$\\kappa$ is a constant that depends on the structure of the graph, instead of\nnumber of arms (nodes). This bounds significantly improves regular bandit\nalgorithms, whose complexity depends on number of arms (nodes).\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:21:22 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 03:42:03 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 05:53:16 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 12:05:31 GMT"}, {"version": "v5", "created": "Sun, 11 Apr 2021 20:08:17 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Tianyu", ""], ["Yang", "Lin F.", ""], ["Wang", "Zizhuo", ""]]}, {"id": "2011.01447", "submitter": "C.-H. Huck Yang", "authors": "Hu Hu, Chao-Han Huck Yang, Xianjun Xia, Xue Bai, Xin Tang, Yajian\n  Wang, Shutong Niu, Li Chai, Juanjuan Li, Hongning Zhu, Feng Bao, Yuanjun\n  Zhao, Sabato Marco Siniscalchi, Yannan Wang, Jun Du, Chin-Hui Lee", "title": "A Two-Stage Approach to Device-Robust Acoustic Scene Classification", "comments": "Submitted to ICASSP 2021. Code available:\n  https://github.com/MihawkHu/DCASE2020_task1", "journal-ref": "ICASSP 2021-2021 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": null, "report-no": "845--849", "categories": "cs.SD cs.AI cs.LG cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To improve device robustness, a highly desirable key feature of a competitive\ndata-driven acoustic scene classification (ASC) system, a novel two-stage\nsystem based on fully convolutional neural networks (CNNs) is proposed. Our\ntwo-stage system leverages on an ad-hoc score combination based on two CNN\nclassifiers: (i) the first CNN classifies acoustic inputs into one of three\nbroad classes, and (ii) the second CNN classifies the same inputs into one of\nten finer-grained classes. Three different CNN architectures are explored to\nimplement the two-stage classifiers, and a frequency sub-sampling scheme is\ninvestigated. Moreover, novel data augmentation schemes for ASC are also\ninvestigated. Evaluated on DCASE 2020 Task 1a, our results show that the\nproposed ASC system attains a state-of-the-art accuracy on the development set,\nwhere our best system, a two-stage fusion of CNN ensembles, delivers a 81.9%\naverage accuracy among multi-device test data, and it obtains a significant\nimprovement on unseen devices. Finally, neural saliency analysis with class\nactivation mapping (CAM) gives new insights on the patterns learnt by our\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:27:18 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hu", "Hu", ""], ["Yang", "Chao-Han Huck", ""], ["Xia", "Xianjun", ""], ["Bai", "Xue", ""], ["Tang", "Xin", ""], ["Wang", "Yajian", ""], ["Niu", "Shutong", ""], ["Chai", "Li", ""], ["Li", "Juanjuan", ""], ["Zhu", "Hongning", ""], ["Bao", "Feng", ""], ["Zhao", "Yuanjun", ""], ["Siniscalchi", "Sabato Marco", ""], ["Wang", "Yannan", ""], ["Du", "Jun", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2011.01452", "submitter": "Jiacheng Wang", "authors": "Jiacheng Wang, Yong Fan, Duo Jiang, Shiqing Li", "title": "Meta-Learning for Natural Language Understanding under Continual\n  Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network has been recognized with its accomplishments on tackling\nvarious natural language understanding (NLU) tasks. Methods have been developed\nto train a robust model to handle multiple tasks to gain a general\nrepresentation of text. In this paper, we implement the model-agnostic\nmeta-learning (MAML) and Online aware Meta-learning (OML) meta-objective under\nthe continual framework for NLU tasks. We validate our methods on selected\nSuperGLUE and GLUE benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:41:10 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Jiacheng", ""], ["Fan", "Yong", ""], ["Jiang", "Duo", ""], ["Li", "Shiqing", ""]]}, {"id": "2011.01456", "submitter": "Biswadip Dey", "authors": "Tongtao Zhang, Biswadip Dey, Pratik Kakkar, Arindam Dasgupta, Amit\n  Chakraborty", "title": "Frequency-compensated PINNs for Fluid-dynamic Design Problems", "comments": "Machine Learning for Engineering Modeling, Simulation, and Design\n  (ML4Eng) Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incompressible fluid flow around a cylinder is one of the classical problems\nin fluid-dynamics with strong relevance with many real-world engineering\nproblems, for example, design of offshore structures or design of a pin-fin\nheat exchanger. Thus learning a high-accuracy surrogate for this problem can\ndemonstrate the efficacy of a novel machine learning approach. In this work, we\npropose a physics-informed neural network (PINN) architecture for learning the\nrelationship between simulation output and the underlying geometry and boundary\nconditions. In addition to using a physics-based regularization term, the\nproposed approach also exploits the underlying physics to learn a set of\nFourier features, i.e. frequency and phase offset parameters, and then use them\nfor predicting flow velocity and pressure over the spatio-temporal domain. We\ndemonstrate this approach by predicting simulation results over out of range\ntime interval and for novel design conditions. Our results show that\nincorporation of Fourier features improves the generalization performance over\nboth temporal domain and design space.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:56:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zhang", "Tongtao", ""], ["Dey", "Biswadip", ""], ["Kakkar", "Pratik", ""], ["Dasgupta", "Arindam", ""], ["Chakraborty", "Amit", ""]]}, {"id": "2011.01457", "submitter": "Gadekallu Thippa Reddy", "authors": "Thippa Reddy Gadekallu, Manoj M K, Sivarama Krishnan S, Neeraj Kumar,\n  Saqib Hakak, Sweta Bhattacharya", "title": "Blockchain based Attack Detection on Machine Learning Algorithms for IoT\n  based E-Health Applications", "comments": "Accepted in IEEE IoT Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of machine learning (ML) algorithms are massively scaling-up\ndue to rapid digitization and emergence of new tecnologies like Internet of\nThings (IoT). In today's digital era, we can find ML algorithms being applied\nin the areas of healthcare, IoT, engineering, finance and so on. However, all\nthese algorithms need to be trained in order to predict/solve a particular\nproblem. There is high possibility of tampering the training datasets and\nproduce biased results. Hence, in this article, we have proposed blockchain\nbased solution to secure the datasets generated from IoT devices for E-Health\napplications. The proposed blockchain based solution uses using private cloud\nto tackle the aforementioned issue. For evaluation, we have developed a system\nthat can be used by dataset owners to secure their data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 03:59:27 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Gadekallu", "Thippa Reddy", ""], ["K", "Manoj M", ""], ["S", "Sivarama Krishnan", ""], ["Kumar", "Neeraj", ""], ["Hakak", "Saqib", ""], ["Bhattacharya", "Sweta", ""]]}, {"id": "2011.01459", "submitter": "Danish Pruthi", "authors": "Danish Pruthi, Bhuwan Dhingra, Graham Neubig, Zachary C. Lipton", "title": "Weakly- and Semi-supervised Evidence Extraction", "comments": "Accepted to the Findings of EMNLP 2020, to be presented at\n  BlackBoxNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many prediction tasks, stakeholders desire not only predictions but also\nsupporting evidence that a human can use to verify its correctness. However, in\npractice, additional annotations marking supporting evidence may only be\navailable for a minority of training examples (if available at all). In this\npaper, we propose new methods to combine few evidence annotations (strong\nsemi-supervision) with abundant document-level labels (weak supervision) for\nthe task of evidence extraction. Evaluating on two classification tasks that\nfeature evidence annotations, we find that our methods outperform baselines\nadapted from the interpretability literature to our task. Our approach yields\nsubstantial gains with as few as hundred evidence annotations. Code and\ndatasets to reproduce our work are available at\nhttps://github.com/danishpruthi/evidence-extraction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:05:00 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Pruthi", "Danish", ""], ["Dhingra", "Bhuwan", ""], ["Neubig", "Graham", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2011.01460", "submitter": "Yan Jia", "authors": "Yan Jia, Zexin Cai, Murong Ma, Zeqing Zhao, Xuyang Wang, Junjie Wang,\n  Ming Li", "title": "Training Wake Word Detection with Synthesized Speech Data on Confusion\n  Words", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confusing-words are commonly encountered in real-life keyword spotting\napplications, which causes severe degradation of performance due to complex\nspoken terms and various kinds of words that sound similar to the predefined\nkeywords. To enhance the wake word detection system's robustness on such\nscenarios, we investigate two data augmentation setups for training end-to-end\nKWS systems. One is involving the synthesized data from a multi-speaker speech\nsynthesis system, and the other augmentation is performed by adding random\nnoise to the acoustic feature. Experimental results show that augmentations\nhelp improve the system's robustness. Moreover, by augmenting the training set\nwith the synthetic data generated by the multi-speaker text-to-speech system,\nwe achieve a significant improvement regarding confusing words scenario.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:06:04 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Jia", "Yan", ""], ["Cai", "Zexin", ""], ["Ma", "Murong", ""], ["Zhao", "Zeqing", ""], ["Wang", "Xuyang", ""], ["Wang", "Junjie", ""], ["Li", "Ming", ""]]}, {"id": "2011.01464", "submitter": "Liya Wang", "authors": "Liya Wang, Panta Lucic, Keith Campbell, Craig Wanke", "title": "Autoencoding Features for Aviation Machine Learning Problems", "comments": "Paper has been submitted to AIAA conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current practice of manually processing features for high-dimensional and\nheterogeneous aviation data is labor-intensive, does not scale well to new\nproblems, and is prone to information loss, affecting the effectiveness and\nmaintainability of machine learning (ML) procedures. This research explored an\nunsupervised learning method, autoencoder, to extract effective features for\naviation machine learning problems. The study explored variants of autoencoders\nwith the aim of forcing the learned representations of the input to assume\nuseful properties. A flight track anomaly detection autoencoder was developed\nto demonstrate the versatility of the technique. The research results show that\nthe autoencoder can not only automatically extract effective features for the\nflight track data, but also efficiently deep clean data, thereby reducing the\nworkload of data scientists. Moreover, the research leveraged transfer learning\nto efficiently train models for multiple airports. Transfer learning can reduce\nmodel training times from days to hours, as well as improving model\nperformance. The developed applications and techniques are shared with the\nwhole aviation community to improve effectiveness of ongoing and future machine\nlearning studies.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:09:34 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 17:15:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wang", "Liya", ""], ["Lucic", "Panta", ""], ["Campbell", "Keith", ""], ["Wanke", "Craig", ""]]}, {"id": "2011.01472", "submitter": "Narayanan Chatapuram Krishnan", "authors": "Ashish Kumar, Karan Sehgal, Prerna Garg, Vidhya Kamakshi, and\n  Narayanan C Krishnan", "title": "MACE: Model Agnostic Concept Extractor for Explaining Image\n  Classification Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional networks have been quite successful at various image\nclassification tasks. The current methods to explain the predictions of a\npre-trained model rely on gradient information, often resulting in saliency\nmaps that focus on the foreground object as a whole. However, humans typically\nreason by dissecting an image and pointing out the presence of smaller\nconcepts. The final output is often an aggregation of the presence or absence\nof these smaller concepts. In this work, we propose MACE: a Model Agnostic\nConcept Extractor, which can explain the working of a convolutional network\nthrough smaller concepts. The MACE framework dissects the feature maps\ngenerated by a convolution network for an image to extract concept based\nprototypical explanations. Further, it estimates the relevance of the extracted\nconcepts to the pre-trained model's predictions, a critical aspect required for\nexplaining the individual class predictions, missing in existing approaches. We\nvalidate our framework using VGG16 and ResNet50 CNN architectures, and on\ndatasets like Animals With Attributes 2 (AWA2) and Places365. Our experiments\ndemonstrate that the concepts extracted by the MACE framework increase the\nhuman interpretability of the explanations, and are faithful to the underlying\npre-trained black-box model.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:40:49 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kumar", "Ashish", ""], ["Sehgal", "Karan", ""], ["Garg", "Prerna", ""], ["Kamakshi", "Vidhya", ""], ["Krishnan", "Narayanan C", ""]]}, {"id": "2011.01474", "submitter": "Jing Wang", "authors": "Jing Wang, Anna Choromanska", "title": "SGB: Stochastic Gradient Bound Method for Optimizing Partition Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of optimizing partition functions in a\nstochastic learning setting. We propose a stochastic variant of the bound\nmajorization algorithm that relies on upper-bounding the partition function\nwith a quadratic surrogate. The update of the proposed method, that we refer to\nas Stochastic Partition Function Bound (SPFB), resembles scaled stochastic\ngradient descent where the scaling factor relies on a second order term that is\nhowever different from the Hessian. Similarly to quasi-Newton schemes, this\nterm is constructed using the stochastic approximation of the value of the\nfunction and its gradient. We prove sub-linear convergence rate of the proposed\nmethod and show the construction of its low-rank variant (LSPFB). Experiments\non logistic regression demonstrate that the proposed schemes significantly\noutperform SGD. We also discuss how to use quadratic partition function bound\nfor efficient training of deep learning models and in non-convex optimization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:42:51 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Jing", ""], ["Choromanska", "Anna", ""]]}, {"id": "2011.01479", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Hau-Tieng Wu", "title": "Convergence of Graph Laplacian with kNN Self-tuned Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernelized Gram matrix $W$ constructed from data points $\\{x_i\\}_{i=1}^N$ as\n$W_{ij}= k_0( \\frac{ \\| x_i - x_j \\|^2} {\\sigma^2} )$ is widely used in\ngraph-based geometric data analysis and unsupervised learning. An important\nquestion is how to choose the kernel bandwidth $\\sigma$, and a common practice\ncalled self-tuned kernel adaptively sets a $\\sigma_i$ at each point $x_i$ by\nthe $k$-nearest neighbor (kNN) distance. When $x_i$'s are sampled from a\n$d$-dimensional manifold embedded in a possibly high-dimensional space, unlike\nwith fixed-bandwidth kernels, theoretical results of graph Laplacian\nconvergence with self-tuned kernels have been incomplete. This paper proves the\nconvergence of graph Laplacian operator $L_N$ to manifold (weighted-)Laplacian\nfor a new family of kNN self-tuned kernels $W^{(\\alpha)}_{ij} = k_0( \\frac{ \\|\nx_i - x_j \\|^2}{ \\epsilon \\hat{\\rho}(x_i)\n\\hat{\\rho}(x_j)})/\\hat{\\rho}(x_i)^\\alpha \\hat{\\rho}(x_j)^\\alpha$, where\n$\\hat{\\rho}$ is the estimated bandwidth function {by kNN}, and the limiting\noperator is also parametrized by $\\alpha$. When $\\alpha = 1$, the limiting\noperator is the weighted manifold Laplacian $\\Delta_p$. Specifically, we prove\nthe point-wise convergence of $L_N f $ and convergence of the graph Dirichlet\nform with rates. Our analysis is based on first establishing a $C^0$\nconsistency for $\\hat{\\rho}$ which bounds the relative estimation error\n$|\\hat{\\rho} - \\bar{\\rho}|/\\bar{\\rho}$ uniformly with high probability, where\n$\\bar{\\rho} = p^{-1/d}$, and $p$ is the data density function. Our theoretical\nresults reveal the advantage of self-tuned kernel over fixed-bandwidth kernel\nvia smaller variance error in low-density regions. In the algorithm, no prior\nknowledge of $d$ or data density is needed. The theoretical results are\nsupported by numerical experiments on simulated data and hand-written digit\nimage data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:55:33 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 02:17:46 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "2011.01488", "submitter": "Deeksha Sinha", "authors": "Deeksha Sinha, Karthik Abinav Sankararama, Abbas Kazerouni, Vashist\n  Avadhanula", "title": "Multi-armed Bandits with Cost Subsidy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a novel variant of the multi-armed bandit (MAB)\nproblem, MAB with cost subsidy, which models many real-life applications where\nthe learning agent has to pay to select an arm and is concerned about\noptimizing cumulative costs and rewards. We present two applications,\nintelligent SMS routing problem and ad audience optimization problem faced by\nseveral businesses (especially online platforms), and show how our problem\nuniquely captures key features of these applications. We show that naive\ngeneralizations of existing MAB algorithms like Upper Confidence Bound and\nThompson Sampling do not perform well for this problem. We then establish a\nfundamental lower bound on the performance of any online learning algorithm for\nthis problem, highlighting the hardness of our problem in comparison to the\nclassical MAB problem. We also present a simple variant of explore-then-commit\nand establish near-optimal regret bounds for this algorithm. Lastly, we perform\nextensive numerical simulations to understand the behavior of a suite of\nalgorithms for various instances and recommend a practical guide to employ\ndifferent algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 05:38:42 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 19:13:00 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 11:49:38 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Sinha", "Deeksha", ""], ["Sankararama", "Karthik Abinav", ""], ["Kazerouni", "Abbas", ""], ["Avadhanula", "Vashist", ""]]}, {"id": "2011.01506", "submitter": "Narayanan Chatapuram Krishnan", "authors": "Rajat Sharma, Nikhil Reddy, Vidhya Kamakshi, Narayanan C Krishnan,\n  Shweta Jain", "title": "MAIRE -- A Model-Agnostic Interpretable Rule Extraction Procedure for\n  Explaining Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a novel framework for extracting model-agnostic human\ninterpretable rules to explain a classifier's output. The human interpretable\nrule is defined as an axis-aligned hyper-cuboid containing the instance for\nwhich the classification decision has to be explained. The proposed procedure\nfinds the largest (high \\textit{coverage}) axis-aligned hyper-cuboid such that\na high percentage of the instances in the hyper-cuboid have the same class\nlabel as the instance being explained (high \\textit{precision}). Novel\napproximations to the coverage and precision measures in terms of the\nparameters of the hyper-cuboid are defined. They are maximized using\ngradient-based optimizers. The quality of the approximations is rigorously\nanalyzed theoretically and experimentally. Heuristics for simplifying the\ngenerated explanations for achieving better interpretability and a greedy\nselection algorithm that combines the local explanations for creating global\nexplanations for the model covering a large part of the instance space are also\nproposed. The framework is model agnostic, can be applied to any arbitrary\nclassifier, and all types of attributes (including continuous, ordered, and\nunordered discrete). The wide-scale applicability of the framework is validated\non a variety of synthetic and real-world datasets from different domains\n(tabular, text, and image).\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 06:53:06 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Sharma", "Rajat", ""], ["Reddy", "Nikhil", ""], ["Kamakshi", "Vidhya", ""], ["Krishnan", "Narayanan C", ""], ["Jain", "Shweta", ""]]}, {"id": "2011.01512", "submitter": "Soroush Vosoughi Dr", "authors": "Lili Wang, Ying Lu, Chenghan Huang, Soroush Vosoughi", "title": "Embedding Node Structural Role Identity into Hyperbolic Space", "comments": "In Proceedings of the 29th ACM International Conference on\n  Information and Knowledge Management (CIKM '20), October 19-23, 2020, Virtual\n  Event, Ireland", "journal-ref": null, "doi": "10.1145/3340531.3412102", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an interest in embedding networks in hyperbolic\nspace, since hyperbolic space has been shown to work well in capturing\ngraph/network structure as it can naturally reflect some properties of complex\nnetworks. However, the work on network embedding in hyperbolic space has been\nfocused on microscopic node embedding. In this work, we are the first to\npresent a framework to embed the structural roles of nodes into hyperbolic\nspace. Our framework extends struct2vec, a well-known structural role\npreserving embedding method, by moving it to a hyperboloid model. We evaluated\nour method on four real-world and one synthetic network. Our results show that\nhyperbolic space is more effective than euclidean space in learning latent\nrepresentations for the structural role of nodes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:04:39 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Wang", "Lili", ""], ["Lu", "Ying", ""], ["Huang", "Chenghan", ""], ["Vosoughi", "Soroush", ""]]}, {"id": "2011.01516", "submitter": "Gaurush Hiranandani", "authors": "Gaurush Hiranandani, Jatin Mathur, Harikrishna Narasimhan, Oluwasanmi\n  Koyejo", "title": "Quadratic Metric Elicitation with Application to Fairness", "comments": "32 pages, 9 figures, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric elicitation is a recent framework for eliciting performance metrics\nthat best reflect implicit user preferences. This framework enables a\npractitioner to adjust the performance metrics based on the application,\ncontext, and population at hand. However, available elicitation strategies have\nbeen limited to linear (or fractional-linear) functions of predictive rates. In\nthis paper, we develop an approach to elicit from a wider range of complex\nmulticlass metrics defined by quadratic functions of rates by exploiting their\nlocal linear structure. We apply this strategy to elicit quadratic metrics for\ngroup-based fairness, and also discuss how it can be generalized to\nhigher-order polynomials. Our elicitation strategies require only relative\npreference feedback and are robust to both feedback and finite sample noise.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:22:15 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hiranandani", "Gaurush", ""], ["Mathur", "Jatin", ""], ["Narasimhan", "Harikrishna", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "2011.01518", "submitter": "Shen Chen", "authors": "Shen Chen", "title": "ShaneRun System Description to VoxCeleb Speaker Recognition Challenge\n  2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we describe the submission of ShaneRun's team to the VoxCeleb\nSpeaker Recognition Challenge (VoxSRC) 2020. We use ResNet-34 as encoder to\nextract the speaker embeddings, which is referenced from the open-source\nvoxceleb-trainer. We also provide a simple method to implement optimum fusion\nusing t-SNE normalized distance of testing utterance pairs instead of original\nnegative Euclidean distance from the encoder. The final submitted system got\n0.3098 minDCF and 5.076 % ERR for Fixed data track, which outperformed the\nbaseline by 1.3 % minDCF and 2.2 % ERR respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:26:21 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Shen", ""]]}, {"id": "2011.01536", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Constantin Orasan, Ruslan Mitkov", "title": "TransQuest: Translation Quality Estimation with Cross-lingual\n  Transformers", "comments": "Accepted to COLING 2020. arXiv admin note: text overlap with\n  arXiv:2010.05318", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have seen big advances in the field of sentence-level quality\nestimation (QE), largely as a result of using neural-based architectures.\nHowever, the majority of these methods work only on the language pair they are\ntrained on and need retraining for new language pairs. This process can prove\ndifficult from a technical point of view and is usually computationally\nexpensive. In this paper we propose a simple QE framework based on\ncross-lingual transformers, and we use it to implement and evaluate two\ndifferent neural architectures. Our evaluation shows that the proposed methods\nachieve state-of-the-art results outperforming current open-source quality\nestimation frameworks when trained on datasets from WMT. In addition, the\nframework proves very useful in transfer learning settings, especially when\ndealing with low-resourced languages, allowing us to obtain very competitive\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 16:34:44 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 12:20:48 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Orasan", "Constantin", ""], ["Mitkov", "Ruslan", ""]]}, {"id": "2011.01539", "submitter": "Tao Bai", "authors": "Tao Bai, Jinqi Luo, Jun Zhao", "title": "Recent Advances in Understanding Adversarial Robustness of Deep Neural\n  Networks", "comments": "Initial Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inevitable on the road of pervasive applications of\ndeep neural networks (DNN). Imperceptible perturbations applied on natural\nsamples can lead DNN-based classifiers to output wrong prediction with fair\nconfidence score. It is increasingly important to obtain models with high\nrobustness that are resistant to adversarial examples. In this paper, we survey\nrecent advances in how to understand such intriguing property, i.e. adversarial\nrobustness, from different perspectives. We give preliminary definitions on\nwhat adversarial attacks and robustness are. After that, we study\nfrequently-used benchmarks and mention theoretically-proved bounds for\nadversarial robustness. We then provide an overview on analyzing correlations\namong adversarial robustness and other critical indicators of DNN models.\nLastly, we introduce recent arguments on potential costs of adversarial\ntraining which have attracted wide attention from the research community.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 07:42:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Bai", "Tao", ""], ["Luo", "Jinqi", ""], ["Zhao", "Jun", ""]]}, {"id": "2011.01557", "submitter": "Ahmed Mustafa", "authors": "Ahmed Mustafa, Nicola Pia, Guillaume Fuchs", "title": "StyleMelGAN: An Efficient High-Fidelity Adversarial Vocoder with\n  Temporal Adaptive Normalization", "comments": "Accepted to ICASSP2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural vocoders have surpassed classical speech generation\napproaches in naturalness and perceptual quality of the synthesized speech.\nComputationally heavy models like WaveNet and WaveGlow achieve best results,\nwhile lightweight GAN models, e.g. MelGAN and Parallel WaveGAN, remain inferior\nin terms of perceptual quality. We therefore propose StyleMelGAN, a lightweight\nneural vocoder allowing synthesis of high-fidelity speech with low\ncomputational complexity. StyleMelGAN employs temporal adaptive normalization\nto style a low-dimensional noise vector with the acoustic features of the\ntarget speech. For efficient training, multiple random-window discriminators\nadversarially evaluate the speech signal analyzed by a filter bank, with\nregularization provided by a multi-scale spectral reconstruction loss. The\nhighly parallelizable speech generation is several times faster than real-time\non CPUs and GPUs. MUSHRA and P.800 listening tests show that StyleMelGAN\noutperforms prior neural vocoders in copy-synthesis and Text-to-Speech\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 08:28:47 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:21:06 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mustafa", "Ahmed", ""], ["Pia", "Nicola", ""], ["Fuchs", "Guillaume", ""]]}, {"id": "2011.01568", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Lin F. Yang", "title": "Episodic Linear Quadratic Regulators with Low-rank Transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Quadratic Regulators (LQR) achieve enormous successful real-world\napplications. Very recently, people have been focusing on efficient learning\nalgorithms for LQRs when their dynamics are unknown. Existing results\neffectively learn to control the unknown system using number of episodes\ndepending polynomially on the system parameters, including the ambient\ndimension of the states. These traditional approaches, however, become\ninefficient in common scenarios, e.g., when the states are high-resolution\nimages. In this paper, we propose an algorithm that utilizes the intrinsic\nsystem low-rank structure for efficient learning. For problems of rank-$m$, our\nalgorithm achieves a $K$-episode regret bound of order $\\widetilde{O}(m^{3/2}\nK^{1/2})$. Consequently, the sample complexity of our algorithm only depends on\nthe rank, $m$, rather than the ambient dimension, $d$, which can be\norders-of-magnitude larger.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 08:48:31 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 04:40:14 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Wang", "Tianyu", ""], ["Yang", "Lin F.", ""]]}, {"id": "2011.01584", "submitter": "Li-Yang Tan", "authors": "Guy Blanc, Neha Gupta, Jane Lange, Li-Yang Tan", "title": "Estimating decision tree learnability with polylogarithmic sample\n  complexity", "comments": "25 pages, to appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that top-down decision tree learning heuristics are amenable to\nhighly efficient learnability estimation: for monotone target functions, the\nerror of the decision tree hypothesis constructed by these heuristics can be\nestimated with polylogarithmically many labeled examples, exponentially smaller\nthan the number necessary to run these heuristics, and indeed, exponentially\nsmaller than information-theoretic minimum required to learn a good decision\ntree. This adds to a small but growing list of fundamental learning algorithms\nthat have been shown to be amenable to learnability estimation.\n  En route to this result, we design and analyze sample-efficient minibatch\nversions of top-down decision tree learning heuristics and show that they\nachieve the same provable guarantees as the full-batch versions. We further\ngive \"active local\" versions of these heuristics: given a test point $x^\\star$,\nwe show how the label $T(x^\\star)$ of the decision tree hypothesis $T$ can be\ncomputed with polylogarithmically many labeled examples, exponentially smaller\nthan the number necessary to learn $T$.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 09:26:27 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Blanc", "Guy", ""], ["Gupta", "Neha", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2011.01596", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas, Oliver Hamelijnck, Jeremias Knoblauch, Theodoros\n  Damoulas", "title": "Transforming Gaussian Processes With Normalizing Flows", "comments": "AISTATS 2021, camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian Processes (GPs) can be used as flexible, non-parametric function\npriors. Inspired by the growing body of work on Normalizing Flows, we enlarge\nthis class of priors through a parametric invertible transformation that can be\nmade input-dependent. Doing so also allows us to encode interpretable prior\nknowledge (e.g., boundedness constraints). We derive a variational\napproximation to the resulting Bayesian inference problem, which is as fast as\nstochastic variational GP regression (Hensman et al., 2013; Dezfouli and\nBonilla,2015). This makes the model a computationally efficient alternative to\nother hierarchical extensions of GP priors (Lazaro-Gredilla,2012; Damianou and\nLawrence, 2013). The resulting algorithm's computational and inferential\nperformance is excellent, and we demonstrate this on a range of data sets. For\nexample, even with only 5 inducing points and an input-dependent flow, our\nmethod is consistently competitive with a standard sparse GP fitted using 100\ninducing points.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 09:52:37 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 17:19:34 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Maro\u00f1as", "Juan", ""], ["Hamelijnck", "Oliver", ""], ["Knoblauch", "Jeremias", ""], ["Damoulas", "Theodoros", ""]]}, {"id": "2011.01613", "submitter": "Tomas Maul", "authors": "Chen Wen Kang, Chua Meng Hong, Tomas Maul", "title": "Towards a Universal Gating Network for Mixtures of Experts", "comments": "Appl Intell (2021)", "journal-ref": null, "doi": "10.1007/s10489-021-02301-w", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination and aggregation of knowledge from multiple neural networks\ncan be commonly seen in the form of mixtures of experts. However, such\ncombinations are usually done using networks trained on the same tasks, with\nlittle mention of the combination of heterogeneous pre-trained networks,\nespecially in the data-free regime. This paper proposes multiple data-free\nmethods for the combination of heterogeneous neural networks, ranging from the\nutilization of simple output logit statistics, to training specialized gating\nnetworks. The gating networks decide whether specific inputs belong to specific\nnetworks based on the nature of the expert activations generated. The\nexperiments revealed that the gating networks, including the universal gating\napproach, constituted the most accurate approach, and therefore represent a\npragmatic step towards applications with heterogeneous mixtures of experts in a\ndata-free regime. The code for this project is hosted on github at\nhttps://github.com/cwkang1998/network-merging.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:47:21 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Kang", "Chen Wen", ""], ["Hong", "Chua Meng", ""], ["Maul", "Tomas", ""]]}, {"id": "2011.01614", "submitter": "Lucas Fidon", "authors": "Lucas Fidon and Sebastien Ourselin and Tom Vercauteren", "title": "Generalized Wasserstein Dice Score, Distributionally Robust Deep\n  Learning, and Ranger for brain tumor segmentation: BraTS 2020 challenge", "comments": "MICCAI 2020 BrainLes Workshop. Our method ranked fourth out of the\n  693 registered teams for the segmentation task of the BraTS 2020 challenge.\n  v2: Added some clarifications following reviewers' feedback (camera-ready\n  version)", "journal-ref": null, "doi": "10.1007/978-3-030-72087-2_18", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a deep neural network is an optimization problem with four main\ningredients: the design of the deep neural network, the per-sample loss\nfunction, the population loss function, and the optimizer. However, methods\ndeveloped to compete in recent BraTS challenges tend to focus only on the\ndesign of deep neural network architectures, while paying less attention to the\nthree other aspects. In this paper, we experimented with adopting the opposite\napproach. We stuck to a generic and state-of-the-art 3D U-Net architecture and\nexperimented with a non-standard per-sample loss function, the generalized\nWasserstein Dice loss, a non-standard population loss function, corresponding\nto distributionally robust optimization, and a non-standard optimizer, Ranger.\nThose variations were selected specifically for the problem of multi-class\nbrain tumor segmentation. The generalized Wasserstein Dice loss is a per-sample\nloss function that allows taking advantage of the hierarchical structure of the\ntumor regions labeled in BraTS. Distributionally robust optimization is a\ngeneralization of empirical risk minimization that accounts for the presence of\nunderrepresented subdomains in the training dataset. Ranger is a generalization\nof the widely used Adam optimizer that is more stable with small batch size and\nnoisy labels. We found that each of those variations of the optimization of\ndeep neural networks for brain tumor segmentation leads to improvements in\nterms of Dice scores and Hausdorff distances. With an ensemble of three deep\nneural networks trained with various optimization procedures, we achieved\npromising results on the validation dataset of the BraTS 2020 challenge. Our\nensemble ranked fourth out of the 693 registered teams for the segmentation\ntask of the BraTS 2020 challenge.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:50:48 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 11:41:03 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Fidon", "Lucas", ""], ["Ourselin", "Sebastien", ""], ["Vercauteren", "Tom", ""]]}, {"id": "2011.01619", "submitter": "Yonghao Long", "authors": "Yonghao Long, Jie Ying Wu, Bo Lu, Yueming Jin, Mathias Unberath,\n  Yun-Hui Liu, Pheng Ann Heng and Qi Dou", "title": "Relational Graph Learning on Visual and Kinematics Embeddings for\n  Accurate Gesture Recognition in Robotic Surgery", "comments": "Accepted for ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic surgical gesture recognition is fundamentally important to enable\nintelligent cognitive assistance in robotic surgery. With recent advancement in\nrobot-assisted minimally invasive surgery, rich information including surgical\nvideos and robotic kinematics can be recorded, which provide complementary\nknowledge for understanding surgical gestures. However, existing methods either\nsolely adopt uni-modal data or directly concatenate multi-modal\nrepresentations, which can not sufficiently exploit the informative\ncorrelations inherent in visual and kinematics data to boost gesture\nrecognition accuracies. In this regard, we propose a novel online approach of\nmulti-modal relational graph network (i.e., MRG-Net) to dynamically integrate\nvisual and kinematics information through interactive message propagation in\nthe latent feature space. In specific, we first extract embeddings from video\nand kinematics sequences with temporal convolutional networks and LSTM units.\nNext, we identify multi-relations in these multi-modal embeddings and leverage\nthem through a hierarchical relational graph learning module. The effectiveness\nof our method is demonstrated with state-of-the-art results on the public\nJIGSAWS dataset, outperforming current uni-modal and multi-modal methods on\nboth suturing and knot typing tasks. Furthermore, we validated our method on\nin-house visual-kinematics datasets collected with da Vinci Research Kit (dVRK)\nplatforms in two centers, with consistent promising performance achieved.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 11:00:10 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 05:52:38 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Long", "Yonghao", ""], ["Wu", "Jie Ying", ""], ["Lu", "Bo", ""], ["Jin", "Yueming", ""], ["Unberath", "Mathias", ""], ["Liu", "Yun-Hui", ""], ["Heng", "Pheng Ann", ""], ["Dou", "Qi", ""]]}, {"id": "2011.01623", "submitter": "Xu Chen", "authors": "Xu Chen and Siheng Chen and Jiangchao Yao and Huangjie Zheng and Ya\n  Zhang and Ivor W Tsang", "title": "Learning on Attribute-Missing Graphs", "comments": "This paper is to appear in IEEE TRANSACTIONS ON PATTERN ANALYSIS AND\n  MACHINE INTELLIGENCE (TPAMI), 2020", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3032189", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs with complete node attributes have been widely explored recently.\nWhile in practice, there is a graph where attributes of only partial nodes\ncould be available and those of the others might be entirely missing. This\nattribute-missing graph is related to numerous real-world applications and\nthere are limited studies investigating the corresponding learning problems.\nExisting graph learning methods including the popular GNN cannot provide\nsatisfied learning performance since they are not specified for\nattribute-missing graphs. Thereby, designing a new GNN for these graphs is a\nburning issue to the graph learning community. In this paper, we make a\nshared-latent space assumption on graphs and develop a novel distribution\nmatching based GNN called structure-attribute transformer (SAT) for\nattribute-missing graphs. SAT leverages structures and attributes in a\ndecoupled scheme and achieves the joint distribution modeling of structures and\nattributes by distribution matching techniques. It could not only perform the\nlink prediction task but also the newly introduced node attribute completion\ntask. Furthermore, practical measures are introduced to quantify the\nperformance of node attribute completion. Extensive experiments on seven\nreal-world datasets indicate SAT shows better performance than other methods on\nboth link prediction and node attribute completion tasks. Codes and data are\navailable online: https://github.com/xuChenSJTU/SAT-master-online\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 11:09:52 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Xu", ""], ["Chen", "Siheng", ""], ["Yao", "Jiangchao", ""], ["Zheng", "Huangjie", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W", ""]]}, {"id": "2011.01625", "submitter": "Tom Heskes", "authors": "Tom Heskes, Evi Sijben, Ioan Gabriel Bucur, Tom Claassen", "title": "Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual\n  Predictions of Complex Models", "comments": "Accepted at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley values underlie one of the most popular model-agnostic methods within\nexplainable artificial intelligence. These values are designed to attribute the\ndifference between a model's prediction and an average baseline to the\ndifferent features used as input to the model. Being based on solid\ngame-theoretic principles, Shapley values uniquely satisfy several desirable\nproperties, which is why they are increasingly used to explain the predictions\nof possibly complex and highly non-linear machine learning models. Shapley\nvalues are well calibrated to a user's intuition when features are independent,\nbut may lead to undesirable, counterintuitive explanations when the\nindependence assumption is violated.\n  In this paper, we propose a novel framework for computing Shapley values that\ngeneralizes recent work that aims to circumvent the independence assumption. By\nemploying Pearl's do-calculus, we show how these 'causal' Shapley values can be\nderived for general causal graphs without sacrificing any of their desirable\nproperties. Moreover, causal Shapley values enable us to separate the\ncontribution of direct and indirect effects. We provide a practical\nimplementation for computing causal Shapley values based on causal chain graphs\nwhen only partial information is available and illustrate their utility on a\nreal-world example.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 11:11:36 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Heskes", "Tom", ""], ["Sijben", "Evi", ""], ["Bucur", "Ioan Gabriel", ""], ["Claassen", "Tom", ""]]}, {"id": "2011.01631", "submitter": "Vandana Rajan", "authors": "Vandana Rajan, Alessio Brutti, Andrea Cavallaro", "title": "Robust Latent Representations via Cross-Modal Translation and Alignment", "comments": null, "journal-ref": "ICASSP 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal learning relates information across observation modalities of the\nsame physical phenomenon to leverage complementary information. Most\nmulti-modal machine learning methods require that all the modalities used for\ntraining are also available for testing. This is a limitation when the signals\nfrom some modalities are unavailable or are severely degraded by noise. To\naddress this limitation, we aim to improve the testing performance of uni-modal\nsystems using multiple modalities during training only. The proposed\nmulti-modal training framework uses cross-modal translation and\ncorrelation-based latent space alignment to improve the representations of the\nweaker modalities. The translation from the weaker to the stronger modality\ngenerates a multi-modal intermediate encoding that is representative of both\nmodalities. This encoding is then correlated with the stronger modality\nrepresentations in a shared latent space. We validate the proposed approach on\nthe AVEC 2016 dataset for continuous emotion recognition and show the\neffectiveness of the approach that achieves state-of-the-art (uni-modal)\nperformance for weaker modalities.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 11:18:04 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 23:16:30 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Rajan", "Vandana", ""], ["Brutti", "Alessio", ""], ["Cavallaro", "Andrea", ""]]}, {"id": "2011.01647", "submitter": "Alireza Daneshkhah", "authors": "A. Daneshkhah, O. Chatrabgoun, M. Esmaeilbeigi, T. Sedighi, S.\n  Abolfathi", "title": "Uncertainty Quantification of Darcy Flow through Porous Media using Deep\n  Gaussian Process", "comments": "27 pages, 11 figures, presented in SIAM Conference on Uncertainty\n  Quantification (UQ16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational method based on the non-linear Gaussian process (GP), known\nas deep Gaussian processes (deep GPs) for uncertainty quantification &\npropagation in modelling of flow through heterogeneous porous media is\npresented. The method is also used for reducing dimensionality of model output\nand consequently emulating highly complex relationship between hydrogeological\nproperties and reduced order fluid velocity field in a tractable manner. Deep\nGPs are multi-layer hierarchical generalisations of GPs with multiple,\ninfinitely wide hidden layers that are very efficient models for deep learning\nand modelling of high-dimensional complex systems by tackling the complexity\nthrough several hidden layers connected with non-linear mappings. According to\nthis approach, the hydrogeological data is modelled as the output of a\nmultivariate GP whose inputs are governed by another GP such that each single\nlayer is either a standard GP or the Gaussian process latent variable model. A\nvariational approximation framework is used so that the posterior distribution\nof the model outputs associated to given inputs can be analytically\napproximated. In contrast to the other dimensionality reduction, methods that\ndo not provide any information about the dimensionality of each hidden layer,\nthe proposed method automatically selects the dimensionality of each hidden\nlayer and it can be used to propagate uncertainty obtained in each layer across\nthe hierarchy. Using this, dimensionality of the full input space consists of\nboth geometrical parameters of modelling domain and stochastic hydrogeological\nparameters can be simultaneously reduced without the need for any\nsimplifications generally being assumed for stochastic modelling of subsurface\nflow problems. It allows estimation of the flow statistics with greatly reduced\ncomputational efforts compared to other stochastic approaches such as Monte\nCarlo method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 11:57:38 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 11:31:03 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Daneshkhah", "A.", ""], ["Chatrabgoun", "O.", ""], ["Esmaeilbeigi", "M.", ""], ["Sedighi", "T.", ""], ["Abolfathi", "S.", ""]]}, {"id": "2011.01661", "submitter": "Subhadip Maji", "authors": "Indranil Basu and Subhadip Maji", "title": "Multicollinearity Correction and Combined Feature Effect in Shapley\n  Values", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretability is one of the most intriguing problems in most of the\nMachine Learning models, particularly for those that are mathematically\nsophisticated. Computing Shapley Values are arguably the best approach so far\nto find the importance of each feature in a model, at the row level. In other\nwords, Shapley values represent the importance of a feature for a particular\nrow, especially for Classification or Regression problems. One of the biggest\nlimitations of Shapley vales is that, Shapley value calculations assume all the\nfeatures are uncorrelated (independent of each other), this assumption is often\nincorrect. To address this problem, we present a unified framework to calculate\nShapley values with correlated features. To be more specific, we do an\nadjustment (Matrix formulation) of the features while calculating Independent\nShapley values for the rows. Moreover, we have given a Mathematical proof\nagainst the said adjustments. With these adjustments, Shapley values\n(Importance) for the features become independent of the correlations existing\nbetween them. We have also enhanced this adjustment concept for more than\nfeatures. As the Shapley values are additive, to calculate combined effect of\ntwo features, we just have to add their individual Shapley values. This is\nagain not right if one or more of the features (used in the combination) are\ncorrelated with the other features (not in the combination). We have addressed\nthis problem also by extending the correlation adjustment for one feature to\nmultiple features in the said combination for which Shapley values are\ndetermined. Our implementation of this method proves that our method is\ncomputationally efficient also, compared to original Shapley method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 12:28:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Basu", "Indranil", ""], ["Maji", "Subhadip", ""]]}, {"id": "2011.01668", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens", "title": "Towards a Unified Quadrature Framework for Large-Scale Kernel Machines", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a quadrature framework for large-scale kernel\nmachines via a numerical integration representation. Considering that the\nintegration domain and measure of typical kernels, e.g., Gaussian kernels,\narc-cosine kernels, are fully symmetric, we leverage deterministic fully\nsymmetric interpolatory rules to efficiently compute quadrature nodes and\nassociated weights for kernel approximation. The developed interpolatory rules\nare able to reduce the number of needed nodes while retaining a high\napproximation accuracy. Further, we randomize the above deterministic rules by\nthe classical Monte-Carlo sampling and control variates techniques with two\nmerits: 1) The proposed stochastic rules make the dimension of the feature\nmapping flexibly varying, such that we can control the discrepancy between the\noriginal and approximate kernels by tuning the dimnension. 2) Our stochastic\nrules have nice statistical properties of unbiasedness and variance reduction\nwith fast convergence rate. In addition, we elucidate the relationship between\nour deterministic/stochastic interpolatory rules and current quadrature rules\nfor kernel approximation, including the sparse grids quadrature and stochastic\nspherical-radial rules, thereby unifying these methods under our framework.\nExperimental results on several benchmark datasets show that our methods\ncompare favorably with other representative kernel approximation based methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 12:48:07 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 19:29:22 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Fanghui", ""], ["Huang", "Xiaolin", ""], ["Chen", "Yudong", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2011.01681", "submitter": "Chang Liu", "authors": "Chang Liu, Xinwei Sun, Jindong Wang, Haoyue Tang, Tao Li, Tao Qin, Wei\n  Chen, Tie-Yan Liu", "title": "Learning Causal Semantic Representation for Out-of-Distribution\n  Prediction", "comments": "Figures for CSG-ind/DA; model selection highlighted; condition and\n  intuition of identifiability; new version of OOD error bound supporting\n  CSG-ind; improved experiment implementation, with shifted-MNIST and\n  ImageCLEF-DA results updated; MDD and BNM baselines added; results on PACS\n  and VLCS datasets added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional supervised learning methods, especially deep ones, are found to\nbe sensitive to out-of-distribution (OOD) examples, largely because the learned\nrepresentation mixes the semantic factor with the variation factor due to their\ndomain-specific correlation, while only the semantic factor causes the output.\nTo address the problem, we propose a Causal Semantic Generative model (CSG)\nbased on a causal reasoning so that the two factors are modeled separately, and\ndevelop methods for OOD prediction from a single training domain, which is\ncommon and challenging. The methods are based on the causal invariance\nprinciple, with a novel design for both efficient learning and easy prediction.\nTheoretically, we prove that under certain conditions, CSG can identify the\nsemantic factor by fitting training data, and this semantic-identification\nguarantees the boundedness of OOD generalization error and the success of\nadaptation. Empirical study shows improved OOD performance over prevailing\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:16:05 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 12:18:28 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 12:30:03 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 16:17:09 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Liu", "Chang", ""], ["Sun", "Xinwei", ""], ["Wang", "Jindong", ""], ["Tang", "Haoyue", ""], ["Li", "Tao", ""], ["Qin", "Tao", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2011.01689", "submitter": "Misha Kaandorp", "authors": "Misha P.T. Kaandorp, Sebastiano Barbieri, Remy Klaassen, Hanneke W.M.\n  van Laarhoven, Hans Crezee, Peter T. While, Aart J. Nederveen, Oliver J.\n  Gurney-Champion", "title": "Improved unsupervised physics-informed deep learning for intravoxel\n  incoherent motion modeling and evaluation in pancreatic cancer patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ${\\bf Purpose}$: Earlier work showed that IVIM-NET$_{orig}$, an unsupervised\nphysics-informed deep neural network, was more accurate than other\nstate-of-the-art intravoxel-incoherent motion (IVIM) fitting approaches to DWI.\nThis study presents an improved version: IVIM-NET$_{optim}$, and characterizes\nits superior performance in pancreatic ductal adenocarcinoma (PDAC) patients.\n${\\bf Method}$: In simulations (SNR=20), the accuracy, independence and\nconsistency of IVIM-NET were evaluated for combinations of hyperparameters (fit\nS0, constraints, network architecture, # hidden layers, dropout, batch\nnormalization, learning rate), by calculating the NRMSE, Spearman's $\\rho$, and\nthe coefficient of variation (CV$_{NET}$), respectively. The best performing\nnetwork, IVIM-NET$_{optim}$ was compared to least squares (LS) and a Bayesian\napproach at different SNRs. IVIM-NET$_{optim}$'s performance was evaluated in\n23 PDAC patients. 14 of the patients received no treatment between scan\nsessions and 9 received chemoradiotherapy between sessions. Intersession\nwithin-subject standard deviations (wSD) and treatment-induced changes were\nassessed. ${\\bf Results}$: In simulations, IVIM-NET$_{optim}$ outperformed\nIVIM-NET$_{orig}$ in accuracy (NRMSE(D)=0.18 vs 0.20; NMRSE(f)=0.22 vs 0.27;\nNMRSE(D*)=0.39 vs 0.39), independence ($\\rho$(D*,f)=0.22 vs 0.74) and\nconsistency (CV$_{NET}$ (D)=0.01 vs 0.10; CV$_{NET}$ (f)=0.02 vs 0.05;\nCV$_{NET}$ (D*)=0.04 vs 0.11). IVIM-NET$_{optim}$ showed superior performance\nto the LS and Bayesian approaches at SNRs<50. In vivo, IVIM-NET$_{optim}$\nsshowed significantly less noisy parameter maps with lower wSD for D and f than\nthe alternatives. In the treated cohort, IVIM-NET$_{optim}$ detected the most\nindividual patients with significant parameter changes compared to day-to-day\nvariations. ${\\bf Conclusion}$: IVIM-NET$_{optim}$ is recommended for IVIM\nfitting to DWI data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:24:29 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 16:38:11 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Kaandorp", "Misha P. T.", ""], ["Barbieri", "Sebastiano", ""], ["Klaassen", "Remy", ""], ["van Laarhoven", "Hanneke W. M.", ""], ["Crezee", "Hans", ""], ["While", "Peter T.", ""], ["Nederveen", "Aart J.", ""], ["Gurney-Champion", "Oliver J.", ""]]}, {"id": "2011.01695", "submitter": "Ana-Maria Bucur", "authors": "Ana-Maria Bucur and Liviu P. Dinu", "title": "Detecting Early Onset of Depression from Social Media Text using Learned\n  Confidence Scores", "comments": "Accepted at Seventh Italian Conference on Computational Linguistics\n  CLiC-it 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational research on mental health disorders from written texts covers\nan interdisciplinary area between natural language processing and psychology. A\ncrucial aspect of this problem is prevention and early diagnosis, as suicide\nresulted from depression being the second leading cause of death for young\nadults. In this work, we focus on methods for detecting the early onset of\ndepression from social media texts, in particular from Reddit. To that end, we\nexplore the eRisk 2018 dataset and achieve good results with regard to the\nstate of the art by leveraging topic analysis and learned confidence scores to\nguide the decision process.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:34:04 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Bucur", "Ana-Maria", ""], ["Dinu", "Liviu P.", ""]]}, {"id": "2011.01697", "submitter": "Sebastian U. Stich", "authors": "Dmitry Kovalev and Anastasia Koloskova and Martin Jaggi and Peter\n  Richtarik and Sebastian U. Stich", "title": "A Linearly Convergent Algorithm for Decentralized Optimization: Sending\n  Less Bits for Free!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization methods enable on-device training of machine\nlearning models without a central coordinator. In many scenarios communication\nbetween devices is energy demanding and time consuming and forms the bottleneck\nof the entire system.\n  We propose a new randomized first-order method which tackles the\ncommunication bottleneck by applying randomized compression operators to the\ncommunicated messages. By combining our scheme with a new variance reduction\ntechnique that progressively throughout the iterations reduces the adverse\neffect of the injected quantization noise, we obtain the first scheme that\nconverges linearly on strongly convex decentralized problems while using\ncompressed communication only.\n  We prove that our method can solve the problems without any increase in the\nnumber of communications compared to the baseline which does not perform any\ncommunication compression while still allowing for a significant compression\nfactor which depends on the conditioning of the problem and the topology of the\nnetwork. Our key theoretical findings are supported by numerical experiments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:35:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kovalev", "Dmitry", ""], ["Koloskova", "Anastasia", ""], ["Jaggi", "Martin", ""], ["Richtarik", "Peter", ""], ["Stich", "Sebastian U.", ""]]}, {"id": "2011.01704", "submitter": "Fabian Guignard", "authors": "Fabian Guignard, Federico Amato and Mikhail Kanevski", "title": "Uncertainty Quantification in Extreme Learning Machine: Analytical\n  Developments, Variance Estimates and Confidence Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification is crucial to assess prediction quality of a\nmachine learning model. In the case of Extreme Learning Machines (ELM), most\nmethods proposed in the literature make strong assumptions on the data, ignore\nthe randomness of input weights or neglect the bias contribution in confidence\ninterval estimations. This paper presents novel estimations that overcome these\nconstraints and improve the understanding of ELM variability. Analytical\nderivations are provided under general assumptions, supporting the\nidentification and the interpretation of the contribution of different\nvariability sources. Under both homoskedasticity and heteroskedasticity,\nseveral variance estimates are proposed, investigated, and numerically tested,\nshowing their effectiveness in replicating the expected variance behaviours.\nFinally, the feasibility of confidence intervals estimation is discussed by\nadopting a critical approach, hence raising the awareness of ELM users\nconcerning some of their pitfalls. The paper is accompanied with a scikit-learn\ncompatible Python library enabling efficient computation of all estimates\ndiscussed herein.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:45:59 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Guignard", "Fabian", ""], ["Amato", "Federico", ""], ["Kanevski", "Mikhail", ""]]}, {"id": "2011.01706", "submitter": "Yuhao Wang", "authors": "Haotian Zhang, Yuhao Wang, Jianyong Sun, Zongben Xu", "title": "Amortized Variational Deep Q Network", "comments": "Accepted to appear in the Deep Reinforcement Learning Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is one of the most important issues in deep\nreinforcement learning. To address this issue, recent methods consider the\nvalue function parameters as random variables, and resort variational inference\nto approximate the posterior of the parameters. In this paper, we propose an\namortized variational inference framework to approximate the posterior\ndistribution of the action value function in Deep Q Network. We establish the\nequivalence between the loss of the new model and the amortized variational\ninference loss. We realize the balance of exploration and exploitation by\nassuming the posterior as Cauchy and Gaussian, respectively in a two-stage\ntraining process. We show that the amortized framework can results in\nsignificant less learning parameters than existing state-of-the-art method.\nExperimental results on classical control tasks in OpenAI Gym and chain Markov\nDecision Process tasks show that the proposed method performs significantly\nbetter than state-of-art methods and requires much less training time.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:48:18 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zhang", "Haotian", ""], ["Wang", "Yuhao", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2011.01709", "submitter": "Julien Balian", "authors": "Julien Balian, Raffaele Tavarone, Mathieu Poumeyrol, Alice Coucke", "title": "Small footprint Text-Independent Speaker Verification for Embedded\n  Systems", "comments": null, "journal-ref": "Acoustics, Speech and Signal Processing (ICASSP), 2021 IEEE\n  International Conference", "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network approaches to speaker verification have proven\nsuccessful, but typical computational requirements of State-Of-The-Art (SOTA)\nsystems make them unsuited for embedded applications. In this work, we present\na two-stage model architecture orders of magnitude smaller than common\nsolutions (237.5K learning parameters, 11.5MFLOPS) reaching a competitive\nresult of 3.31% Equal Error Rate (EER) on the well established VoxCeleb1\nverification test set. We demonstrate the possibility of running our solution\non small devices typical of IoT systems such as the Raspberry Pi 3B with a\nlatency smaller than 200ms on a 5s long utterance. Additionally, we evaluate\nour model on the acoustically challenging VOiCES corpus. We report a limited\nincrease in EER of 2.6 percentage points with respect to the best scoring model\nof the 2019 VOiCES from a Distance Challenge, against a reduction of 25.6 times\nin the number of learning parameters.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:53:05 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 16:18:53 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Balian", "Julien", ""], ["Tavarone", "Raffaele", ""], ["Poumeyrol", "Mathieu", ""], ["Coucke", "Alice", ""]]}, {"id": "2011.01710", "submitter": "Guang Lin", "authors": "Guang Lin, Jianhai Zhang, Yuxi Liu", "title": "Single Shot Reversible GAN for BCG artifact removal in simultaneous\n  EEG-fMRI", "comments": "8 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous EEG-fMRI acquisition and analysis technology has been widely\nused in various research fields of brain science. However, how to remove the\nballistocardiogram (BCG) artifacts in this scenario remains a huge challenge.\nBecause it is impossible to obtain clean and BCG-contaminated EEG signals at\nthe same time, BCG artifact removal is a typical unpaired signal-to-signal\nproblem. To solve this problem, this paper proposed a new GAN training model -\nSingle Shot Reversible GAN (SSRGAN). The model is allowing bidirectional input\nto better combine the characteristics of the two types of signals, instead of\nusing two independent models for bidirectional conversion as in the past.\nFurthermore, the model is decomposed into multiple independent convolutional\nblocks with specific functions. Through additional training of the blocks, the\nlocal representation ability of the model is improved, thereby improving the\noverall model performance. Experimental results show that, compared with\nexisting methods, the method proposed in this paper can remove BCG artifacts\nmore effectively and retain the useful EEG information.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:54:01 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 01:39:34 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Lin", "Guang", ""], ["Zhang", "Jianhai", ""], ["Liu", "Yuxi", ""]]}, {"id": "2011.01715", "submitter": "Sage Hahn", "authors": "Sage Hahn, Dekang Yuan, Wesley Thompson, Max M Owens, Nicholas\n  Allgaier and Hugh Garavan", "title": "Brain Predictability toolbox: a Python library for neuroimaging based\n  machine learning", "comments": "3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summary Brain Predictability toolbox (BPt) represents a unified framework of\nmachine learning (ML) tools designed to work with both tabulated data (in\nparticular brain, psychiatric, behavioral, and physiological variables) and\nneuroimaging specific derived data (e.g., brain volumes and surfaces). This\npackage is suitable for investigating a wide range of different neuroimaging\nbased ML questions, in particular, those queried from large human datasets.\n  Availability and Implementation BPt has been developed as an open-source\nPython 3.6+ package hosted at https://github.com/sahahn/BPt under MIT License,\nwith documentation provided at https://bpt.readthedocs.io/en/latest/, and\ncontinues to be actively developed. The project can be downloaded through the\ngithub link provided. A web GUI interface based on the same code is currently\nunder development and can be set up through docker with instructions at\nhttps://github.com/sahahn/BPt_app.\n  Contact Please contact Sage Hahn at sahahn@uvm.edu\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:06:43 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hahn", "Sage", ""], ["Yuan", "Dekang", ""], ["Thompson", "Wesley", ""], ["Owens", "Max M", ""], ["Allgaier", "Nicholas", ""], ["Garavan", "Hugh", ""]]}, {"id": "2011.01725", "submitter": "Vincent Valton PhD", "authors": "Vincent Valton, Toby Wise, Oliver J. Robinson", "title": "Recommendations for Bayesian hierarchical model specifications for\n  case-control studies in mental health", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical model fitting has become commonplace for case-control studies of\ncognition and behaviour in mental health. However, these techniques require us\nto formalise assumptions about the data-generating process at the group level,\nwhich may not be known. Specifically, researchers typically must choose whether\nto assume all subjects are drawn from a common population, or to model them as\nderiving from separate populations. These assumptions have profound\nimplications for computational psychiatry, as they affect the resulting\ninference (latent parameter recovery) and may conflate or mask true group-level\ndifferences. To test these assumptions we ran systematic simulations on\nsynthetic multi-group behavioural data from a commonly used multi-armed bandit\ntask (reinforcement learning task). We then examined recovery of group\ndifferences in latent parameter space under the two commonly used generative\nmodelling assumptions: (1) modelling groups under a common shared group-level\nprior (assuming all participants are generated from a common distribution, and\nare likely to share common characteristics); (2) modelling separate groups\nbased on symptomatology or diagnostic labels, resulting in separate group-level\npriors. We evaluated the robustness of these approaches to variations in data\nquality and prior specifications on a variety of metrics. We found that fitting\ngroups separately (assumptions 2), provided the most accurate and robust\ninference across all conditions. Our results suggest that when dealing with\ndata from multiple clinical groups, researchers should analyse patient and\ncontrol groups separately as it provides the most accurate and robust recovery\nof the parameters of interest.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:19:59 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Valton", "Vincent", ""], ["Wise", "Toby", ""], ["Robinson", "Oliver J.", ""]]}, {"id": "2011.01734", "submitter": "Michael Lutter", "authors": "Michael Lutter, Johannes Silberbauer, Joe Watson, Jan Peters", "title": "Differentiable Physics Models for Real-world Offline Model-based\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A limitation of model-based reinforcement learning (MBRL) is the exploitation\nof errors in the learned models. Black-box models can fit complex dynamics with\nhigh fidelity, but their behavior is undefined outside of the data\ndistribution.Physics-based models are better at extrapolating, due to the\ngeneral validity of their informed structure, but underfit in the real world\ndue to the presence of unmodeled phenomena. In this work, we demonstrate\nexperimentally that for the offline model-based reinforcement learning setting,\nphysics-based models can be beneficial compared to high-capacity function\napproximators if the mechanical structure is known. Physics-based models can\nlearn to perform the ball in a cup (BiC) task on a physical manipulator using\nonly 4 minutes of sampled data using offline MBRL. We find that black-box\nmodels consistently produce unviable policies for BiC as all predicted\ntrajectories diverge to physically impossible state, despite having access to\nmore data than the physics-based model. In addition, we generalize the approach\nof physics parameter identification from modeling holonomic multi-body systems\nto systems with nonholonomic dynamics using end-to-end automatic\ndifferentiation.\n  Videos: https://sites.google.com/view/ball-in-a-cup-in-4-minutes/\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:37:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Lutter", "Michael", ""], ["Silberbauer", "Johannes", ""], ["Watson", "Joe", ""], ["Peters", "Jan", ""]]}, {"id": "2011.01737", "submitter": "Deborah Sulem", "authors": "Mihai Cucuringu, Apoorv Vikram Singh, D\\'eborah Sulem, Hemant Tyagi", "title": "Regularized spectral methods for clustering signed networks", "comments": "55 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of $k$-way clustering in signed graphs. Considerable\nattention in recent years has been devoted to analyzing and modeling signed\ngraphs, where the affinity measure between nodes takes either positive or\nnegative values. Recently, Cucuringu et al. [CDGT 2019] proposed a spectral\nmethod, namely SPONGE (Signed Positive over Negative Generalized Eigenproblem),\nwhich casts the clustering task as a generalized eigenvalue problem optimizing\na suitably defined objective function. This approach is motivated by social\nbalance theory, where the clustering task aims to decompose a given network\ninto disjoint groups, such that individuals within the same group are connected\nby as many positive edges as possible, while individuals from different groups\nare mainly connected by negative edges. Through extensive numerical\nsimulations, SPONGE was shown to achieve state-of-the-art empirical\nperformance. On the theoretical front, [CDGT 2019] analyzed SPONGE and the\npopular Signed Laplacian method under the setting of a Signed Stochastic Block\nModel (SSBM), for $k=2$ equal-sized clusters, in the regime where the graph is\nmoderately dense.\n  In this work, we build on the results in [CDGT 2019] on two fronts for the\nnormalized versions of SPONGE and the Signed Laplacian. Firstly, for both\nalgorithms, we extend the theoretical analysis in [CDGT 2019] to the general\nsetting of $k \\geq 2$ unequal-sized clusters in the moderately dense regime.\nSecondly, we introduce regularized versions of both methods to handle sparse\ngraphs -- a regime where standard spectral methods underperform -- and provide\ntheoretical guarantees under the same SSBM model. To the best of our knowledge,\nregularized spectral methods have so far not been considered in the setting of\nclustering signed graphs. We complement our theoretical results with an\nextensive set of numerical experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:40:34 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Singh", "Apoorv Vikram", ""], ["Sulem", "D\u00e9borah", ""], ["Tyagi", "Hemant", ""]]}, {"id": "2011.01753", "submitter": "Anubhav Shrimal", "authors": "Anubhav Shrimal, Tanmoy Chakraborty", "title": "Attention Beam: An Image Captioning Approach", "comments": "5 pages, 6 figures, 1 table, in Proceedings of the 35th AAAI\n  Conference on Artificial Intelligence (AAAI-21) Student Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of image captioning is to generate textual description of a given\nimage. Though seemingly an easy task for humans, it is challenging for machines\nas it requires the ability to comprehend the image (computer vision) and\nconsequently generate a human-like description for the image (natural language\nunderstanding). In recent times, encoder-decoder based architectures have\nachieved state-of-the-art results for image captioning. Here, we present a\nheuristic of beam search on top of the encoder-decoder based architecture that\ngives better quality captions on three benchmark datasets: Flickr8k, Flickr30k\nand MS COCO.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:57:42 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 15:17:56 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shrimal", "Anubhav", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2011.01754", "submitter": "Huajie Shao", "authors": "Huajie Shao, Zhisheng Xiao, Shuochao Yao, Aston Zhang, Shengzhong Liu\n  and Tarek Abdelzaher", "title": "ControlVAE: Tuning, Analytical Properties, and Performance Analysis", "comments": "arXiv admin note: substantial text overlap with arXiv:2004.05988", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the novel concept of controllable variational autoencoder\n(ControlVAE), discusses its parameter tuning to meet application needs, derives\nits key analytic properties, and offers useful extensions and applications.\nControlVAE is a new variational autoencoder (VAE) framework that combines the\nautomatic control theory with the basic VAE to stabilize the KL-divergence of\nVAE models to a specified value. It leverages a non-linear PI controller, a\nvariant of the proportional-integral-derivative (PID) control, to dynamically\ntune the weight of the KL-divergence term in the evidence lower bound (ELBO)\nusing the output KL-divergence as feedback. This allows us to precisely control\nthe KL-divergence to a desired value (set point), which is effective in\navoiding posterior collapse and learning disentangled representations. In order\nto improve the ELBO over the regular VAE, we provide simplified theoretical\nanalysis to inform setting the set point of KL-divergence for ControlVAE. We\nobserve that compared to other methods that seek to balance the two terms in\nVAE's objective, ControlVAE leads to better learning dynamics. In particular,\nit can achieve a good trade-off between reconstruction quality and\nKL-divergence. We evaluate the proposed method on three tasks: image\ngeneration, language modeling and disentangled representation learning. The\nresults show that ControlVAE can achieve much better reconstruction quality\nthan the other methods for comparable disentanglement. On the language modeling\ntask, ControlVAE can avoid posterior collapse (KL vanishing) and improve the\ndiversity of generated text. Moreover, our method can change the optimization\ntrajectory, improving the ELBO and the reconstruction quality for image\ngeneration.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 12:32:39 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Shao", "Huajie", ""], ["Xiao", "Zhisheng", ""], ["Yao", "Shuochao", ""], ["Zhang", "Aston", ""], ["Liu", "Shengzhong", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2011.01755", "submitter": "Frederick Morlock", "authors": "Frederick Morlock, Dingsu Wang", "title": "MAD-VAE: Manifold Awareness Defense Variational Autoencoder", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep generative models such as Defense-GAN and Defense-VAE have made\nsignificant progress in terms of adversarial defenses of image classification\nneural networks, several methods have been found to circumvent these defenses.\nBased on Defense-VAE, in our research we introduce several methods to improve\nthe robustness of defense models. The methods introduced in this paper are\nstraight forward yet show promise over the vanilla Defense-VAE. With extensive\nexperiments on MNIST data set, we have demonstrated the effectiveness of our\nalgorithms against different attacks. Our experiments also include attacks on\nthe latent space of the defensive model. We also discuss the applicability of\nexisting adversarial latent space attacks as they may have a significant flaw.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 09:04:25 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Morlock", "Frederick", ""], ["Wang", "Dingsu", ""]]}, {"id": "2011.01758", "submitter": "Markus Wulfmeier", "authors": "Markus Wulfmeier, Arunkumar Byravan, Tim Hertweck, Irina Higgins,\n  Ankush Gupta, Tejas Kulkarni, Malcolm Reynolds, Denis Teplyashin, Roland\n  Hafner, Thomas Lampe, Martin Riedmiller", "title": "Representation Matters: Improving Perception and Exploration for\n  Robotics", "comments": "Published at ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projecting high-dimensional environment observations into lower-dimensional\nstructured representations can considerably improve data-efficiency for\nreinforcement learning in domains with limited data such as robotics. Can a\nsingle generally useful representation be found? In order to answer this\nquestion, it is important to understand how the representation will be used by\nthe agent and what properties such a 'good' representation should have. In this\npaper we systematically evaluate a number of common learnt and hand-engineered\nrepresentations in the context of three robotics tasks: lifting, stacking and\npushing of 3D blocks. The representations are evaluated in two use-cases: as\ninput to the agent, or as a source of auxiliary tasks. Furthermore, the value\nof each representation is evaluated in terms of three properties:\ndimensionality, observability and disentanglement. We can significantly improve\nperformance in both use-cases and demonstrate that some representations can\nperform commensurate to simulator states as agent inputs. Finally, our results\nchallenge common intuitions by demonstrating that: 1) dimensionality strongly\nmatters for task generation, but is negligible for inputs, 2) observability of\ntask-relevant aspects mostly affects the input representation use-case, and 3)\ndisentanglement leads to better auxiliary tasks, but has only limited benefits\nfor input representations. This work serves as a step towards a more systematic\nunderstanding of what makes a 'good' representation for control in robotics,\nenabling practitioners to make more informed choices for developing new learned\nor hand-engineered representations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:00:36 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 18:31:54 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Wulfmeier", "Markus", ""], ["Byravan", "Arunkumar", ""], ["Hertweck", "Tim", ""], ["Higgins", "Irina", ""], ["Gupta", "Ankush", ""], ["Kulkarni", "Tejas", ""], ["Reynolds", "Malcolm", ""], ["Teplyashin", "Denis", ""], ["Hafner", "Roland", ""], ["Lampe", "Thomas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2011.01761", "submitter": "Maurice Frank", "authors": "Maurice Frank, Maximilian Ilse", "title": "Problems using deep generative models for probabilistic audio source\n  separation", "comments": null, "journal-ref": "1st I Can't Believe It's Not Better Workshop (ICBINB @ NeurIPS\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in deep generative modeling make it possible to learn\nprior distributions from complex data that subsequently can be used for\nBayesian inference. However, we find that distributions learned by deep\ngenerative models for audio signals do not exhibit the right properties that\nare necessary for tasks like audio source separation using a probabilistic\napproach. We observe that the learned prior distributions are either\ndiscriminative and extremely peaked or smooth and non-discriminative. We\nquantify this behavior for two types of deep generative models on two audio\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:01:47 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Frank", "Maurice", ""], ["Ilse", "Maximilian", ""]]}, {"id": "2011.01767", "submitter": "Chen Wu", "authors": "Chen Wu, Xian Yang, Sencun Zhu, Prasenjit Mitra", "title": "Mitigating Backdoor Attacks in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious clients can attack federated learning systems using malicious data,\nincluding backdoor samples, during the training phase. The compromised global\nmodel will perform well on the validation dataset designed for the task, but a\nsmall subset of data with backdoor patterns may trigger the model to make a\nwrong prediction. There has been an arms race between attackers who tried to\nconceal attacks and defenders who tried to detect attacks during the\naggregation stage of training on the server-side. In this work, we propose a\nnew and effective method to mitigate backdoor attacks after the training phase.\nSpecifically, we design a federated pruning method to remove redundant neurons\nin the network and then adjust the model's extreme weight values. Our\nexperiments conducted on distributed Fashion-MNIST show that our method can\nreduce the average attack success rate from 99.7% to 1.9% with a 5.5% loss of\ntest accuracy on the validation dataset. To minimize the pruning influence on\ntest accuracy, we can fine-tune after pruning, and the attack success rate\ndrops to 6.4%, with only a 1.7% loss of test accuracy. Further experiments\nunder Distributed Backdoor Attacks on CIFAR-10 also show promising results that\nthe average attack success rate drops more than 70% with less than 2% loss of\ntest accuracy on the validation dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 18:39:28 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 19:53:17 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wu", "Chen", ""], ["Yang", "Xian", ""], ["Zhu", "Sencun", ""], ["Mitra", "Prasenjit", ""]]}, {"id": "2011.01771", "submitter": "Yuanzhe Geng", "authors": "Yuanzhe Geng, Erwu Liu, Rui Wang and Yiming Liu", "title": "Deep Reinforcement Learning Based Dynamic Route Planning for Minimizing\n  Travel Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Route planning is important in transportation. Existing works focus on\nfinding the shortest path solution or using metrics such as safety and energy\nconsumption to determine the planning. It is noted that most of these studies\nrely on prior knowledge of road network, which may be not available in certain\nsituations. In this paper, we design a route planning algorithm based on deep\nreinforcement learning (DRL) for pedestrians. We use travel time consumption as\nthe metric, and plan the route by predicting pedestrian flow in the road\nnetwork. We put an agent, which is an intelligent robot, on a virtual map.\nDifferent from previous studies, our approach assumes that the agent does not\nneed any prior information about road network, but simply relies on the\ninteraction with the environment. We propose a dynamically adjustable route\nplanning (DARP) algorithm, where the agent learns strategies through a dueling\ndeep Q network to avoid congested roads. Simulation results show that the DARP\nalgorithm saves 52% of the time under congestion condition when compared with\ntraditional shortest path planning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:10:09 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Geng", "Yuanzhe", ""], ["Liu", "Erwu", ""], ["Wang", "Rui", ""], ["Liu", "Yiming", ""]]}, {"id": "2011.01776", "submitter": "Chongyang Wang", "authors": "Chongyang Wang, Yuan Gao, Akhil Mathur, Amanda C. De C. Williams,\n  Nicholas D. Lane, Nadia Bianchi-Berthouze", "title": "Leveraging Activity Recognition to Enable Protective Behavior Detection\n  in Continuous Data", "comments": "Submitted to PACM IMWUT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protective behavior exhibited by people with chronic pain (CP) during\nphysical activities is the key to understanding their physical and emotional\nstates. Existing automatic protective behavior detection (PBD) methods rely on\npre-segmentation of activities predefined by users. However, in real life,\npeople perform activities casually. Therefore, where those activities present\ndifficulties for people with chronic pain, technology-enabled support should be\ndelivered continuously and automatically adapted to activity type and\noccurrence of protective behavior. Hence, to facilitate ubiquitous CP\nmanagement, it becomes critical to enable accurate PBD over continuous data. In\nthis paper, we propose to integrate human activity recognition (HAR) with PBD\nvia a novel hierarchical HAR-PBD architecture comprising graph-convolution and\nlong short-term memory (GC-LSTM) networks, and alleviate class imbalances using\na class-balanced focal categorical-cross-entropy (CFCC) loss. Through in-depth\nevaluation of the approach using a CP patients' dataset, we show that the\nleveraging of HAR, GC-LSTM networks, and CFCC loss leads to clear increase in\nPBD performance against the baseline (macro F1 score of 0.81 vs. 0.66 and\nprecision-recall area-under-the-curve (PR-AUC) of 0.60 vs. 0.44). We conclude\nby discussing possible use cases of the hierarchical architecture in CP\nmanagement and beyond. We also discuss current limitations and ways forward.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:16:51 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 01:58:05 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 14:06:23 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 14:23:26 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Chongyang", ""], ["Gao", "Yuan", ""], ["Mathur", "Akhil", ""], ["Williams", "Amanda C. De C.", ""], ["Lane", "Nicholas D.", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "2011.01783", "submitter": "Tiansheng Huang", "authors": "Tiansheng Huang, Weiwei Lin, Wentai Wu, Ligang He, Keqin Li and Albert\n  Y.Zomaya", "title": "An Efficiency-boosting Client Selection Scheme for Federated Learning\n  with Fairness Guarantee", "comments": "Accepted by IEEE TPDS. DOI: 10.1109/TPDS.2020.3040887", "journal-ref": null, "doi": "10.1109/TPDS.2020.3040887", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of potential privacy leakage during centralized AI's model training\nhas drawn intensive concern from the public. A Parallel and Distributed\nComputing (or PDC) scheme, termed Federated Learning (FL), has emerged as a new\nparadigm to cope with the privacy issue by allowing clients to perform model\ntraining locally, without the necessity to upload their personal sensitive\ndata. In FL, the number of clients could be sufficiently large, but the\nbandwidth available for model distribution and re-upload is quite limited,\nmaking it sensible to only involve part of the volunteers to participate in the\ntraining process. The client selection policy is critical to an FL process in\nterms of training efficiency, the final model's quality as well as fairness. In\nthis paper, we will model the fairness guaranteed client selection as a\nLyapunov optimization problem and then a C2MAB-based method is proposed for\nestimation of the model exchange time between each client and the server, based\non which we design a fairness guaranteed algorithm termed RBCS-F for\nproblem-solving. The regret of RBCS-F is strictly bounded by a finite constant,\njustifying its theoretical feasibility. Barring the theoretical results, more\nempirical data can be derived from our real training experiments on public\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:27:02 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 15:28:10 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 06:27:51 GMT"}, {"version": "v4", "created": "Fri, 21 May 2021 03:36:54 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Huang", "Tiansheng", ""], ["Lin", "Weiwei", ""], ["Wu", "Wentai", ""], ["He", "Ligang", ""], ["Li", "Keqin", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2011.01787", "submitter": "Aniket Maurya", "authors": "Aniket Maurya", "title": "Predicting intubation support requirement of patients using Chest X-ray\n  with Deep Representation Learning", "comments": "This work is in active progress", "journal-ref": null, "doi": "10.13140/RG.2.2.18271.69282", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent developments in medical imaging with Deep Learning presents evidence\nof automated diagnosis and prognosis. It can also be a complement to currently\navailable diagnosis methods. Deep Learning can be leveraged for diagnosis,\nseverity prediction, intubation support prediction and many similar tasks. We\npresent prediction of intubation support requirement for patients from the\nChest X-ray using Deep representation learning. We release our source code\npublicly at https://github.com/aniketmaurya/covid-research.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 19:12:50 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Maurya", "Aniket", ""]]}, {"id": "2011.01797", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Hao Liu, Wenjing Liao, Tuo Zhao", "title": "Doubly Robust Off-Policy Learning on Low-Dimensional Manifolds by Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference explores the causation between actions and the consequent\nrewards on a covariate set. Recently deep learning has achieved a remarkable\nperformance in causal inference, but existing statistical theories cannot well\nexplain such an empirical success, especially when the covariates are\nhigh-dimensional. Most theoretical results in causal inference are asymptotic,\nsuffer from the curse of dimensionality, and only work for the finite-action\nscenario. To bridge such a gap between theory and practice, this paper studies\ndoubly robust off-policy learning by deep neural networks. When the covariates\nlie on a low-dimensional manifold, we prove nonasymptotic regret bounds, which\nconverge at a fast rate depending on the intrinsic dimension of the manifold.\nOur results cover both the finite- and continuous-action scenarios. Our theory\nshows that deep neural networks are adaptive to the low-dimensional geometric\nstructures of the covariates, and partially explains the success of deep\nlearning for causal inference.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:44:42 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chen", "Minshuo", ""], ["Liu", "Hao", ""], ["Liao", "Wenjing", ""], ["Zhao", "Tuo", ""]]}, {"id": "2011.01799", "submitter": "Camille Chapdelaine", "authors": "Sylvaine Picard, Camille Chapdelaine, Cyril Cappi, Laurent Gardes,\n  Eric Jenn, Baptiste Lef\\`evre, Thomas Soumarmon", "title": "Ensuring Dataset Quality for Machine Learning Certification", "comments": null, "journal-ref": "The 10th IEEE International Workshop on Software Certification\n  (WoSoCer 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of dataset quality in the context of\nMachine Learning (ML)-based critical systems. We briefly analyse the\napplicability of some existing standards dealing with data and show that the\nspecificities of the ML context are neither properly captured nor taken into\nac-count. As a first answer to this concerning situation, we propose a dataset\nspecification and verification process, and apply it on a signal recognition\nsystem from the railway domain. In addi-tion, we also give a list of\nrecommendations for the collection and management of datasets. This work is one\nstep towards the dataset engineering process that will be required for ML to be\nused on safety critical systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:45:43 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Picard", "Sylvaine", ""], ["Chapdelaine", "Camille", ""], ["Cappi", "Cyril", ""], ["Gardes", "Laurent", ""], ["Jenn", "Eric", ""], ["Lef\u00e8vre", "Baptiste", ""], ["Soumarmon", "Thomas", ""]]}, {"id": "2011.01805", "submitter": "Ehud Aharoni", "authors": "Ehud Aharoni (1), Allon Adir (1), Moran Baruch (1), Gilad Ezov (1),\n  Ariel Farkash (1), Lev Greenberg (1), Ramy Masalha (1), Dov Murik (1) and\n  Omri Soceanu (1) ((1) IBM Research)", "title": "Tile Tensors: A versatile data structure with descriptive shapes for\n  homomorphic encryption", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Moving from the theoretical promise of Fully Homomorphic Encryption (FHE) to\nreal-world applications with realistic and acceptable time and memory figures\nis an on-going challenge. After choosing an appropriate FHE scheme, and before\nimplementing privacy-preserving analytics, one needs an efficient packing\nmethod that will optimize use of the ciphertext slots, trading-off size,\nlatency, and throughput. We propose a solution to this challenge. We describe a\nmethod for efficiently working with tensors (multi-dimensional arrays) in a\nsystem that imposes tiles, i.e., fixed-size vectors. The tensors are packed\ninto tiles and then manipulated via operations on those tiles. We further show\na novel and concise notation for describing packing details.\n  Our method reinterprets the tiles as multi-dimensional arrays, and combines\nthem to cover enough space to hold the tensor. An efficient summation algorithm\ncan then sum over any dimension of this construct. We propose a descriptive\nnotation for the shape of this data structure that describes both the original\ntensor and how it is packed inside the tiles. Our solution can be used to\noptimize the performance of various algorithms such as consecutive matrix\nmultiplications or neural network inference with varying batch sizes. It can\nalso serve to enhance optimizations done by homomorphic encryption compilers.\nWe describe different applications that take advantage of this data structure\nthrough the proposed notation, experiment to evaluate the advantages through\ndifferent applications, and share our conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:54:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Aharoni", "Ehud", "", "IBM Research"], ["Adir", "Allon", "", "IBM Research"], ["Baruch", "Moran", "", "IBM Research"], ["Ezov", "Gilad", "", "IBM Research"], ["Farkash", "Ariel", "", "IBM Research"], ["Greenberg", "Lev", "", "IBM Research"], ["Masalha", "Ramy", "", "IBM Research"], ["Murik", "Dov", "", "IBM Research"], ["Soceanu", "Omri", "", "IBM Research"]]}, {"id": "2011.01813", "submitter": "Yanqi Gu", "authors": "Kenneth Stewart and Yanqi Gu", "title": "One-Shot Federated Learning with Neuromorphic Processors", "comments": "arXiv admin note: text overlap with arXiv:2008.01151", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being very low power, the use of neuromorphic processors in mobile devices to\nsolve machine learning problems is a promising alternative to traditional Von\nNeumann processors. Federated Learning enables entities such as mobile devices\nto collaboratively learn a shared model while keeping their training data\nlocal. Additionally, federated learning is a secure way of learning because\nonly the model weights need to be shared between models, keeping the data\nprivate. Here we demonstrate the efficacy of federated learning in neuromorphic\nprocessors. Neuromorphic processors benefit from the collaborative learning,\nachieving state of the art accuracy on a one-shot learning gesture recognition\ntask across individual processor models while preserving local data privacy.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 16:47:20 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Stewart", "Kenneth", ""], ["Gu", "Yanqi", ""]]}, {"id": "2011.01815", "submitter": "Zhaolin Ren", "authors": "Zhaolin Ren, Aoxiao Zhong, Na Li", "title": "LQR with Tracking: A Zeroth-order Approach and Its Global Convergence", "comments": "Modified parameterization for policy structure. Revised focus to be\n  on optimization landscape and convergence for the LQR tracking problem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been substantial recent progress on the theoretical understanding\nof model-free approaches to Linear Quadratic Regulator (LQR) problems. Much\nattention has been devoted to the special case when the goal is to drive the\nstate close to a zero target. In this work, we consider the general case where\nthe target is allowed to be arbitrary, which we refer to as the LQR tracking\nproblem. We study the optimization landscape of this problem, and show that\nsimilar to the zero-target LQR problem, the LQR tracking problem also satisfies\ngradient dominance and local smoothness properties. This allows us to develop a\nzeroth-order policy gradient algorithm that achieves global convergence. We\nsupport our arguments with numerical simulations on a linear system.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:13:58 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 17:31:51 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Ren", "Zhaolin", ""], ["Zhong", "Aoxiao", ""], ["Li", "Na", ""]]}, {"id": "2011.01821", "submitter": "Martin Bertran", "authors": "Natalia Martinez, Martin Bertran, Guillermo Sapiro", "title": "Minimax Pareto Fairness: A Multi Objective Perspective", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we formulate and formally characterize group fairness as a\nmulti-objective optimization problem, where each sensitive group risk is a\nseparate objective. We propose a fairness criterion where a classifier achieves\nminimax risk and is Pareto-efficient w.r.t. all groups, avoiding unnecessary\nharm, and can lead to the best zero-gap model if policy dictates so. We provide\na simple optimization algorithm compatible with deep neural networks to satisfy\nthese constraints. Since our method does not require test-time access to\nsensitive attributes, it can be applied to reduce worst-case classification\nerrors between outcomes in unbalanced classification problems. We test the\nproposed methodology on real case-studies of predicting income, ICU patient\nmortality, skin lesions classification, and assessing credit risk,\ndemonstrating how our framework compares favorably to other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:21:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Martinez", "Natalia", ""], ["Bertran", "Martin", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "2011.01843", "submitter": "Inkit Padhi", "authors": "Inkit Padhi, Yair Schiff, Igor Melnyk, Mattia Rigotti, Youssef Mroueh,\n  Pierre Dognin, Jerret Ross, Ravi Nair, Erik Altman", "title": "Tabular Transformers for Modeling Multivariate Time Series", "comments": "Accepted to ICASSP, 2021; https://github.com/IBM/TabFormer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabular datasets are ubiquitous in data science applications. Given their\nimportance, it seems natural to apply state-of-the-art deep learning algorithms\nin order to fully unlock their potential. Here we propose neural network models\nthat represent tabular time series that can optionally leverage their\nhierarchical structure. This results in two architectures for tabular time\nseries: one for learning representations that is analogous to BERT and can be\npre-trained end-to-end and used in downstream tasks, and one that is akin to\nGPT and can be used for generation of realistic synthetic tabular sequences. We\ndemonstrate our models on two datasets: a synthetic credit card transaction\ndataset, where the learned representations are used for fraud detection and\nsynthetic data generation, and on a real pollution dataset, where the learned\nencodings are used to predict atmospheric pollutant concentrations. Code and\ndata are available at https://github.com/IBM/TabFormer.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:58:08 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 22:11:40 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Padhi", "Inkit", ""], ["Schiff", "Yair", ""], ["Melnyk", "Igor", ""], ["Rigotti", "Mattia", ""], ["Mroueh", "Youssef", ""], ["Dognin", "Pierre", ""], ["Ross", "Jerret", ""], ["Nair", "Ravi", ""], ["Altman", "Erik", ""]]}, {"id": "2011.01844", "submitter": "Eden Belouadah", "authors": "Eden Belouadah, Adrian Popescu and Ioannis Kanellos", "title": "A Comprehensive Study of Class Incremental Learning Algorithms for\n  Visual Tasks", "comments": "Accepted for publication in the Elsevier's Neural Networks journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of artificial agents to increment their capabilities when\nconfronted with new data is an open challenge in artificial intelligence. The\nmain challenge faced in such cases is catastrophic forgetting, i.e., the\ntendency of neural networks to underfit past data when new ones are ingested. A\nfirst group of approaches tackles forgetting by increasing deep model capacity\nto accommodate new knowledge. A second type of approaches fix the deep model\nsize and introduce a mechanism whose objective is to ensure a good compromise\nbetween stability and plasticity of the model. While the first type of\nalgorithms were compared thoroughly, this is not the case for methods which\nexploit a fixed size model. Here, we focus on the latter, place them in a\ncommon conceptual and experimental framework and propose the following\ncontributions: (1) define six desirable properties of incremental learning\nalgorithms and analyze them according to these properties, (2) introduce a\nunified formalization of the class-incremental learning problem, (3) propose a\ncommon evaluation framework which is more thorough than existing ones in terms\nof number of datasets, size of datasets, size of bounded memory and number of\nincremental states, (4) investigate the usefulness of herding for past\nexemplars selection, (5) provide experimental evidence that it is possible to\nobtain competitive performance without the use of knowledge distillation to\ntackle catastrophic forgetting and (6) facilitate reproducibility by\nintegrating all tested methods in a common open-source repository. The main\nexperimental finding is that none of the existing algorithms achieves the best\nresults in all evaluated settings. Important differences arise notably if a\nbounded memory of past classes is allowed or not.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:59:21 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 19:16:46 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 13:02:38 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 16:40:55 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Belouadah", "Eden", ""], ["Popescu", "Adrian", ""], ["Kanellos", "Ioannis", ""]]}, {"id": "2011.01845", "submitter": "Heinke Hihn", "authors": "Heinke Hihn and Daniel A. Braun", "title": "Specialization in Hierarchical Learning Systems", "comments": null, "journal-ref": "Neural Processing Letters, 1-34, 2020", "doi": "10.1007/s11063-020-10351-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Joining multiple decision-makers together is a powerful way to obtain more\nsophisticated decision-making systems, but requires to address the questions of\ndivision of labor and specialization. We investigate in how far information\nconstraints in hierarchies of experts not only provide a principled method for\nregularization but also to enforce specialization. In particular, we devise an\ninformation-theoretically motivated on-line learning rule that allows\npartitioning of the problem space into multiple sub-problems that can be solved\nby the individual experts. We demonstrate two different ways to apply our\nmethod: (i) partitioning problems based on individual data samples and (ii)\nbased on sets of data samples representing tasks. Approach (i) equips the\nsystem with the ability to solve complex decision-making problems by finding an\noptimal combination of local expert decision-makers. Approach (ii) leads to\ndecision-makers specialized in solving families of tasks, which equips the\nsystem with the ability to solve meta-learning problems. We show the broad\napplicability of our approach on a range of problems including classification,\nregression, density estimation, and reinforcement learning problems, both in\nthe standard machine learning setup and in a meta-learning setting.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:00:31 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hihn", "Heinke", ""], ["Braun", "Daniel A.", ""]]}, {"id": "2011.01848", "submitter": "Ananda Theertha Suresh", "authors": "Ananda Theertha Suresh", "title": "Robust hypothesis testing and distribution estimation in Hellinger\n  distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple robust hypothesis test that has the same sample\ncomplexity as that of the optimal Neyman-Pearson test up to constants, but\nrobust to distribution perturbations under Hellinger distance. We discuss the\napplicability of such a robust test for estimating distributions in Hellinger\ndistance. We empirically demonstrate the power of the test on canonical\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:09:32 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Suresh", "Ananda Theertha", ""]]}, {"id": "2011.01858", "submitter": "Matteo Spallanzani", "authors": "Gian Paolo Leonardi and Matteo Spallanzani", "title": "Analytical aspects of non-differentiable neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in computational deep learning has directed considerable efforts\ntowards hardware-oriented optimisations for deep neural networks, via the\nsimplification of the activation functions, or the quantization of both\nactivations and weights. The resulting non-differentiability (or even\ndiscontinuity) of the networks poses some challenging problems, especially in\nconnection with the learning process. In this paper, we address several\nquestions regarding both the expressivity of quantized neural networks and\napproximation techniques for non-differentiable networks. First, we answer in\nthe affirmative the question of whether QNNs have the same expressivity as DNNs\nin terms of approximation of Lipschitz functions in the $L^{\\infty}$ norm.\nThen, considering a continuous but not necessarily differentiable network, we\ndescribe a layer-wise stochastic regularisation technique to produce\ndifferentiable approximations, and we show how this approach to regularisation\nprovides elegant quantitative estimates. Finally, we consider networks defined\nby means of Heaviside-type activation functions, and prove for them a pointwise\napproximation result by means of smooth networks under suitable assumptions on\nthe regularised activations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:20:43 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Leonardi", "Gian Paolo", ""], ["Spallanzani", "Matteo", ""]]}, {"id": "2011.01859", "submitter": "Gavin McCracken", "authors": "Gavin McCracken, Colin Daniels, Rosie Zhao, Anna Brandenberger,\n  Prakash Panangaden, Doina Precup", "title": "A Study of Policy Gradient on a Class of Exactly Solvable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are extensively used in reinforcement learning as a\nway to optimize expected return. In this paper, we explore the evolution of the\npolicy parameters, for a special class of exactly solvable POMDPs, as a\ncontinuous-state Markov chain, whose transition probabilities are determined by\nthe gradient of the distribution of the policy's value. Our approach relies\nheavily on random walk theory, specifically on affine Weyl groups. We construct\na class of novel partially observable environments with controllable\nexploration difficulty, in which the value distribution, and hence the policy\nparameter evolution, can be derived analytically. Using these environments, we\nanalyze the probabilistic convergence of policy gradient to different local\nmaxima of the value function. To our knowledge, this is the first approach\ndeveloped to analytically compute the landscape of policy gradient in POMDPs\nfor a class of such environments, leading to interesting insights into the\ndifficulty of this problem.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:27:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["McCracken", "Gavin", ""], ["Daniels", "Colin", ""], ["Zhao", "Rosie", ""], ["Brandenberger", "Anna", ""], ["Panangaden", "Prakash", ""], ["Precup", "Doina", ""]]}, {"id": "2011.01861", "submitter": "Joshua Melton", "authors": "Joshua Melton, Arunkumar Bagavathi, Siddharth Krishnan", "title": "DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection", "comments": "Accepted at ICMLA20 Special Session: Machine Learning for Natural\n  Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online hate speech on social media has become a fast-growing problem in\nrecent times. Nefarious groups have developed large content delivery networks\nacross several main-stream (Twitter and Facebook) and fringe (Gab, 4chan,\n8chan, etc.) outlets to deliver cascades of hate messages directed both at\nindividuals and communities. Thus addressing these issues has become a top\npriority for large-scale social media outlets. Three key challenges in\nautomated detection and classification of hateful content are the lack of\nclearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc.\n- and the lack of baseline models for fringe outlets such as Gab. In this work,\nwe propose a novel framework with three major contributions. (a) We engineer an\nensemble of deep learning models that combines the strengths of\nstate-of-the-art approaches, (b) we incorporate a tuning factor into this\nframework that leverages transfer learning to conduct automated hate speech\nclassification on unlabeled datasets, like Gab, and (c) we develop a weak\nsupervised learning methodology that allows our framework to train on unlabeled\ndata. Our ensemble models achieve an 83% hate recall on the HON dataset,\nsurpassing the performance of the state-of-the-art deep models. We demonstrate\nthat weak supervised training in combination with classifier tuning\nsignificantly increases model performance on unlabeled data from Gab, achieving\na hate recall of 67%.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:32:50 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Melton", "Joshua", ""], ["Bagavathi", "Arunkumar", ""], ["Krishnan", "Siddharth", ""]]}, {"id": "2011.01868", "submitter": "Thinh Doan", "authors": "Thinh T. Doan", "title": "Nonlinear Two-Time-Scale Stochastic Approximation: Convergence and\n  Finite-Time Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-time-scale stochastic approximation, a generalized version of the popular\nstochastic approximation, has found broad applications in many areas including\nstochastic control, optimization, and machine learning. Despite its popularity,\ntheoretical guarantees of this method, especially its finite-time performance,\nare mostly achieved for the linear case while the results for the nonlinear\ncounterpart are very sparse. Motivated by the classic control theory for\nsingularly perturbed systems, we study in this paper the asymptotic convergence\nand finite-time analysis of the nonlinear two-time-scale stochastic\napproximation. Under some fairly standard assumptions, we provide a formula\nthat characterizes the rate of convergence of the main iterates to the desired\nsolutions. In particular, we show that the method achieves a convergence in\nexpectation at a rate $\\mathcal{O}(1/k^{2/3})$, where $k$ is the number of\niterations. The key idea in our analysis is to properly choose the two step\nsizes to characterize the coupling between the fast and slow-time-scale\niterates.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:43:39 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 15:26:28 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 13:44:57 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Doan", "Thinh T.", ""]]}, {"id": "2011.01874", "submitter": "Benoit Descamps", "authors": "Hassan Elhabbak, Beno\\^it Descamps, Elisabeth Fischer, Sakis\n  Athanasiadis", "title": "Contextualisation of eCommerce Users", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A scaleable modelling framework for the consumer intent within the setting of\ne-Commerce is presented. The methodology applies contextualisation through\nembeddings borrowed from Natural Language Processing. By considering the user\nsession journeys throughough the pages of a website as documents, we capture\ncontextual relationships between pages, as well as the topics of the of user\nvisits. Finally, we empirically study the consistency and the stability of the\npresented framework.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2020 19:43:23 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Elhabbak", "Hassan", ""], ["Descamps", "Beno\u00eet", ""], ["Fischer", "Elisabeth", ""], ["Athanasiadis", "Sakis", ""]]}, {"id": "2011.01889", "submitter": "Eric Strobl", "authors": "Eric V. Strobl", "title": "Automated Hyperparameter Selection for the PC Algorithm", "comments": "Under consideration at Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PC algorithm infers causal relations using conditional independence tests\nthat require a pre-specified Type I $\\alpha$ level. PC is however unsupervised,\nso we cannot tune $\\alpha$ using traditional cross-validation. We therefore\npropose AutoPC, a fast procedure that optimizes $\\alpha$ directly for a user\nchosen metric. We in particular force PC to double check its output by\nexecuting a second run on the recovered graph. We choose the final output as\nthe one which maximizes stability between the two runs. AutoPC consistently\noutperforms the state of the art across multiple metrics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:08:55 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 16:01:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Strobl", "Eric V.", ""]]}, {"id": "2011.01891", "submitter": "Ioannis Exarchos", "authors": "Ioannis Exarchos, Yifeng Jiang, Wenhao Yu, C. Karen Liu", "title": "Policy Transfer via Kinematic Domain Randomization and Adaptation", "comments": "Submitted to the 2021 IEEE International Conference on Robotics and\n  Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring reinforcement learning policies trained in physics simulation to\nthe real hardware remains a challenge, known as the \"sim-to-real\" gap. Domain\nrandomization is a simple yet effective technique to address dynamics\ndiscrepancies across source and target domains, but its success generally\ndepends on heuristics and trial-and-error. In this work we investigate the\nimpact of randomized parameter selection on policy transferability across\ndifferent types of domain discrepancies. Contrary to common practice in which\nkinematic parameters are carefully measured while dynamic parameters are\nrandomized, we found that virtually randomizing kinematic parameters (e.g.,\nlink lengths) during training in simulation generally outperforms dynamic\nrandomization. Based on this finding, we introduce a new domain adaptation\nalgorithm that utilizes simulated kinematic parameters variation. Our\nalgorithm, Multi-Policy Bayesian Optimization, trains an ensemble of universal\npolicies conditioned on virtual kinematic parameters and efficiently adapts to\nthe target environment using a limited number of target domain rollouts. We\nshowcase our findings on a simulated quadruped robot in five different target\nenvironments covering different aspects of domain discrepancies.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:09:35 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:14:52 GMT"}, {"version": "v3", "created": "Thu, 1 Apr 2021 19:47:39 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Exarchos", "Ioannis", ""], ["Jiang", "Yifeng", ""], ["Yu", "Wenhao", ""], ["Liu", "C. Karen", ""]]}, {"id": "2011.01901", "submitter": "Shlok Mishra", "authors": "Shlok Mishra, Anshul Shah, Ankan Bansal, Jonghyun Choi, Abhinav\n  Shrivastava, Abhishek Sharma, David Jacobs", "title": "Learning Visual Representations for Transfer Learning by Suppressing\n  Texture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature has shown that features obtained from supervised training\nof CNNs may over-emphasize texture rather than encoding high-level information.\nIn self-supervised learning in particular, texture as a low-level cue may\nprovide shortcuts that prevent the network from learning higher level\nrepresentations. To address these problems we propose to use classic methods\nbased on anisotropic diffusion to augment training using images with suppressed\ntexture. This simple method helps retain important edge information and\nsuppress texture at the same time. We empirically show that our method achieves\nstate-of-the-art results on object detection and image classification with\neight diverse datasets in either supervised or self-supervised learning tasks\nsuch as MoCoV2 and Jigsaw. Our method is particularly effective for transfer\nlearning tasks and we observed improved performance on five standard transfer\nlearning datasets. The large improvements (up to 11.49\\%) on the\nSketch-ImageNet dataset, DTD dataset and additional visual analyses with\nsaliency maps suggest that our approach helps in learning better\nrepresentations that better transfer.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:27:03 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:41:17 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Mishra", "Shlok", ""], ["Shah", "Anshul", ""], ["Bansal", "Ankan", ""], ["Choi", "Jonghyun", ""], ["Shrivastava", "Abhinav", ""], ["Sharma", "Abhishek", ""], ["Jacobs", "David", ""]]}, {"id": "2011.01902", "submitter": "Ezgi Ozyilkan", "authors": "Ezgi Ozyilkan, Mikolaj Jankowski", "title": "Deep Joint Transmission-Recognition for Multi-View Cameras", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose joint transmission-recognition schemes for efficient inference at\nthe wireless edge. Motivated by the surveillance applications with wireless\ncameras, we consider the person classification task over a wireless channel\ncarried out by multi-view cameras operating as edge devices. We introduce deep\nneural network (DNN) based compression schemes which incorporate digital\n(separate) transmission and joint source-channel coding (JSCC) methods. We\nevaluate the proposed device-edge communication schemes under different channel\nSNRs, bandwidth and power constraints. We show that the JSCC schemes not only\nimprove the end-to-end accuracy but also simplify the encoding process and\nprovide graceful degradation with channel quality.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:27:49 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ozyilkan", "Ezgi", ""], ["Jankowski", "Mikolaj", ""]]}, {"id": "2011.01908", "submitter": "Marcos Monteiro", "authors": "Marcos Monteiro, Alceu S. Britto Jr, Jean P. Barddal, Luiz S.\n  Oliveira, Robert Sabourin", "title": "Classifier Pool Generation based on a Two-level Diversity Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a classifier pool generation method guided by the\ndiversity estimated on the data complexity and classifier decisions. First, the\nbehavior of complexity measures is assessed by considering several subsamples\nof the dataset. The complexity measures with high variability across the\nsubsamples are selected for posterior pool adaptation, where an evolutionary\nalgorithm optimizes diversity in both complexity and decision spaces. A robust\nexperimental protocol with 28 datasets and 20 replications is used to evaluate\nthe proposed method. Results show significant accuracy improvements in 69.4% of\nthe experiments when Dynamic Classifier Selection and Dynamic Ensemble\nSelection methods are applied.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:41:53 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Monteiro", "Marcos", ""], ["Britto", "Alceu S.", "Jr"], ["Barddal", "Jean P.", ""], ["Oliveira", "Luiz S.", ""], ["Sabourin", "Robert", ""]]}, {"id": "2011.01921", "submitter": "Pin-Yu Chen", "authors": "Samuel Hoffman, Vijil Chenthamarakshan, Kahini Wadhawan, Pin-Yu Chen,\n  Payel Das", "title": "Optimizing Molecules using Efficient Queries from Property Evaluations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has shown potential for optimizing existing molecules with\nmore desirable properties, a critical step towards accelerating new chemical\ndiscovery. In this work, we propose QMO, a generic query-based molecule\noptimization framework that exploits latent embeddings from a molecule\nautoencoder. QMO improves the desired properties of an input molecule based on\nefficient queries, guided by a set of molecular property predictions and\nevaluation metrics. We show that QMO outperforms existing methods in the\nbenchmark tasks of optimizing molecules for drug likeliness and solubility\nunder similarity constraints. We also demonstrate significant property\nimprovement using QMO on two new and challenging tasks that are also important\nin real-world discovery problems: (i) optimizing existing SARS-CoV-2 Main\nProtease inhibitors toward higher binding affinity; and (ii) improving known\nantimicrobial peptides towards lower toxicity. Results from QMO show high\nconsistency with external validations, suggesting effective means of\nfacilitating molecule optimization problems with design constraints.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:51:18 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hoffman", "Samuel", ""], ["Chenthamarakshan", "Vijil", ""], ["Wadhawan", "Kahini", ""], ["Chen", "Pin-Yu", ""], ["Das", "Payel", ""]]}, {"id": "2011.01922", "submitter": "Baturalp Buyukates", "authors": "Baturalp Buyukates and Emre Ozfatura and Sennur Ulukus and Deniz\n  Gunduz", "title": "Gradient Coding with Dynamic Clustering for Straggler Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed synchronous gradient descent (GD) the main performance\nbottleneck for the per-iteration completion time is the slowest\n\\textit{straggling} workers. To speed up GD iterations in the presence of\nstragglers, coded distributed computation techniques are implemented by\nassigning redundant computations to workers. In this paper, we propose a novel\ngradient coding (GC) scheme that utilizes dynamic clustering, denoted by GC-DC,\nto speed up the gradient calculation. Under time-correlated straggling\nbehavior, GC-DC aims at regulating the number of straggling workers in each\ncluster based on the straggler behavior in the previous iteration. We\nnumerically show that GC-DC provides significant improvements in the average\ncompletion time (of each iteration) with no increase in the communication load\ncompared to the original GC scheme.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:52:15 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Buyukates", "Baturalp", ""], ["Ozfatura", "Emre", ""], ["Ulukus", "Sennur", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2011.01925", "submitter": "Maxime Thibault", "authors": "Sophie-Camille Hogue, Flora Chen, Genevi\\`eve Brassard, Denis Lebel,\n  Jean-Fran\\c{c}ois Bussi\\`eres, Audrey Durand, Maxime Thibault", "title": "Comparison of pharmacist evaluation of medication orders with\n  predictions of a machine learning model", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work was to assess the clinical performance of an\nunsupervised machine learning model aimed at identifying unusual medication\norders and pharmacological profiles. We conducted a prospective study between\nApril 2020 and August 2020 where 25 clinical pharmacists dichotomously (typical\nor atypical) rated 12,471 medication orders and 1,356 pharmacological profiles.\nBased on AUPR, performance was poor for orders, but satisfactory for profiles.\nPharmacists considered the model a useful screening tool.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:57:47 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hogue", "Sophie-Camille", ""], ["Chen", "Flora", ""], ["Brassard", "Genevi\u00e8ve", ""], ["Lebel", "Denis", ""], ["Bussi\u00e8res", "Jean-Fran\u00e7ois", ""], ["Durand", "Audrey", ""], ["Thibault", "Maxime", ""]]}, {"id": "2011.01926", "submitter": "Ke Li", "authors": "Shichong Peng and Ke Li", "title": "Generating Unobserved Alternatives", "comments": "Videos in the article are also available as ancillary files in the\n  previous version (arXiv:2011.01926v3). Website:\n  https://niopeng.github.io/HyperRIM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems where multiple predictions can be considered correct,\nbut only one of them is given as supervision. This setting differs from both\nthe regression and class-conditional generative modelling settings: in the\nformer, there is a unique observed output for each input, which is provided as\nsupervision; in the latter, there are many observed outputs for each input, and\nmany are provided as supervision. Applying either regression methods and\nconditional generative models to the present setting often results in a model\nthat can only make a single prediction for each input. We explore several\nproblems that have this property and develop an approach that can generate\nmultiple high-quality predictions given the same input. As a result, it can be\nused to generate high-quality outputs that are different from the observed\noutput.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:57:57 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 18:03:05 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 08:20:49 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 10:05:52 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Peng", "Shichong", ""], ["Li", "Ke", ""]]}, {"id": "2011.01928", "submitter": "Ayush Jain", "authors": "Ayush Jain, Andrew Szot, Joseph J. Lim", "title": "Generalization to New Actions in Reinforcement Learning", "comments": "ICML 2020. Videos and code:\n  https://sites.google.com/view/action-generalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental trait of intelligence is the ability to achieve goals in the\nface of novel circumstances, such as making decisions from new action choices.\nHowever, standard reinforcement learning assumes a fixed set of actions and\nrequires expensive retraining when given a new action set. To make learning\nagents more adaptable, we introduce the problem of zero-shot generalization to\nnew actions. We propose a two-stage framework where the agent first infers\naction representations from action information acquired separately from the\ntask. A policy flexible to varying action sets is then trained with\ngeneralization objectives. We benchmark generalization on sequential tasks,\nsuch as selecting from an unseen tool-set to solve physical reasoning puzzles\nand stacking towers with novel 3D shapes. Videos and code are available at\nhttps://sites.google.com/view/action-generalization\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:58:39 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Jain", "Ayush", ""], ["Szot", "Andrew", ""], ["Lim", "Joseph J.", ""]]}, {"id": "2011.01929", "submitter": "Alexandros Hollender", "authors": "John Fearnley, Paul W. Goldberg, Alexandros Hollender, Rahul Savani", "title": "The Complexity of Gradient Descent: CLS = PPAD $\\cap$ PLS", "comments": "Updated based on reviewer comments, including a non-computer-assisted\n  proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study search problems that can be solved by performing Gradient Descent on\na bounded convex polytopal domain and show that this class is equal to the\nintersection of two well-known classes: PPAD and PLS. As our main underlying\ntechnical contribution, we show that computing a Karush-Kuhn-Tucker (KKT) point\nof a continuously differentiable function over the domain $[0,1]^2$ is PPAD\n$\\cap$ PLS-complete. This is the first natural problem to be shown complete for\nthis class. Our results also imply that the class CLS (Continuous Local Search)\n- which was defined by Daskalakis and Papadimitriou as a more \"natural\"\ncounterpart to PPAD $\\cap$ PLS and contains many interesting problems - is\nitself equal to PPAD $\\cap$ PLS.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:58:51 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 18:03:30 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 14:51:12 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Fearnley", "John", ""], ["Goldberg", "Paul W.", ""], ["Hollender", "Alexandros", ""], ["Savani", "Rahul", ""]]}, {"id": "2011.01938", "submitter": "Jarrod McClean", "authors": "Hsin-Yuan Huang, Michael Broughton, Masoud Mohseni, Ryan Babbush,\n  Sergio Boixo, Hartmut Neven, Jarrod R. McClean", "title": "Power of data in quantum machine learning", "comments": null, "journal-ref": "Nature Communications, Vol.12, No. 2631 (2021)", "doi": "10.1038/s41467-021-22539-9", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of quantum computing for machine learning is among the most exciting\nprospective applications of quantum technologies. However, machine learning\ntasks where data is provided can be considerably different than commonly\nstudied computational tasks. In this work, we show that some problems that are\nclassically hard to compute can be easily predicted by classical machines\nlearning from data. Using rigorous prediction error bounds as a foundation, we\ndevelop a methodology for assessing potential quantum advantage in learning\ntasks. The bounds are tight asymptotically and empirically predictive for a\nwide range of learning models. These constructions explain numerical results\nshowing that with the help of data, classical machine learning models can be\ncompetitive with quantum models even if they are tailored to quantum problems.\nWe then propose a projected quantum model that provides a simple and rigorous\nquantum speed-up for a learning problem in the fault-tolerant regime. For\nnear-term implementations, we demonstrate a significant prediction advantage\nover some classical models on engineered data sets designed to demonstrate a\nmaximal quantum advantage in one of the largest numerical tests for gate-based\nquantum machine learning to date, up to 30 qubits.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:00:01 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 21:10:03 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Broughton", "Michael", ""], ["Mohseni", "Masoud", ""], ["Babbush", "Ryan", ""], ["Boixo", "Sergio", ""], ["Neven", "Hartmut", ""], ["McClean", "Jarrod R.", ""]]}, {"id": "2011.01961", "submitter": "Alexander Wong", "authors": "Alexander Wong, Andrew Hryniowski, and Xiao Yu Wang", "title": "Insights into Fairness through Trust: Multi-scale Trust Quantification\n  for Financial Deep Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning in recent years have led to a significant\nincrease in interest and prevalence for its adoption to tackle financial\nservices tasks. One particular question that often arises as a barrier to\nadopting deep learning for financial services is whether the developed\nfinancial deep learning models are fair in their predictions, particularly in\nlight of strong governance and regulatory compliance requirements in the\nfinancial services industry. A fundamental aspect of fairness that has not been\nexplored in financial deep learning is the concept of trust, whose variations\nmay point to an egocentric view of fairness and thus provide insights into the\nfairness of models. In this study we explore the feasibility and utility of a\nmulti-scale trust quantification strategy to gain insights into the fairness of\na financial deep learning model, particularly under different scenarios at\ndifferent scales. More specifically, we conduct multi-scale trust\nquantification on a deep neural network for the purpose of credit card default\nprediction to study: 1) the overall trustworthiness of the model 2) the trust\nlevel under all possible prediction-truth relationships, 3) the trust level\nacross the spectrum of possible predictions, 4) the trust level across\ndifferent demographic groups (e.g., age, gender, and education), and 5)\ndistribution of overall trust for an individual prediction scenario. The\ninsights for this proof-of-concept study demonstrate that such a multi-scale\ntrust quantification strategy may be helpful for data scientists and regulators\nin financial services as part of the verification and certification of\nfinancial deep learning solutions to gain insights into fairness and trust of\nthese solutions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:05:07 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Wong", "Alexander", ""], ["Hryniowski", "Andrew", ""], ["Wang", "Xiao Yu", ""]]}, {"id": "2011.01963", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, A. Salman Avestimehr", "title": "A Scalable Approach for Privacy-Preserving Collaborative Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a collaborative learning scenario in which multiple data-owners\nwish to jointly train a logistic regression model, while keeping their\nindividual datasets private from the other parties. We propose COPML, a\nfully-decentralized training framework that achieves scalability and\nprivacy-protection simultaneously. The key idea of COPML is to securely encode\nthe individual datasets to distribute the computation load effectively across\nmany parties and to perform the training computations as well as the model\nupdates in a distributed manner on the securely encoded data. We provide the\nprivacy analysis of COPML and prove its convergence. Furthermore, we\nexperimentally demonstrate that COPML can achieve significant speedup in\ntraining over the benchmark protocols. Our protocol provides strong statistical\nprivacy guarantees against colluding parties (adversaries) with unbounded\ncomputational power, while achieving up to $16\\times$ speedup in the training\ntime against the benchmark protocols.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:09:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2011.01973", "submitter": "Neharika Jali", "authors": "Neharika Jali, Nikhil Karamchandani, and Sharayu Moharir", "title": "Greedy $k$-Center from Noisy Distance Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the canonical $k$-center problem over a set of vertices\nin a metric space, where the underlying distances are apriori unknown. Instead,\nwe can query an oracle which provides noisy/incomplete estimates of the\ndistance between any pair of vertices. We consider two oracle models: Dimension\nSampling where each query to the oracle returns the distance between a pair of\npoints in one dimension; and Noisy Distance Sampling where the oracle returns\nthe true distance corrupted by noise. We propose active algorithms, based on\nideas such as UCB and Thompson sampling developed in the closely related\nMulti-Armed Bandit problem, which adaptively decide which queries to send to\nthe oracle and are able to solve the $k$-center problem within an approximation\nratio of two with high probability. We analytically characterize\ninstance-dependent query complexity of our algorithms and also demonstrate\nsignificant improvements over naive implementations via numerical evaluations\non two real-world datasets (Tiny ImageNet and UT Zappos50K).\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:37:02 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 15:19:50 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Jali", "Neharika", ""], ["Karamchandani", "Nikhil", ""], ["Moharir", "Sharayu", ""]]}, {"id": "2011.01975", "submitter": "Vladlen Koltun", "authors": "Dhruv Batra, Angel X. Chang, Sonia Chernova, Andrew J. Davison, Jia\n  Deng, Vladlen Koltun, Sergey Levine, Jitendra Malik, Igor Mordatch, Roozbeh\n  Mottaghi, Manolis Savva, Hao Su", "title": "Rearrangement: A Challenge for Embodied AI", "comments": "Authors are listed in alphabetical order", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a framework for research and evaluation in Embodied AI. Our\nproposal is based on a canonical task: Rearrangement. A standard task can focus\nthe development of new techniques and serve as a source of trained models that\ncan be transferred to other settings. In the rearrangement task, the goal is to\nbring a given physical environment into a specified state. The goal state can\nbe specified by object poses, by images, by a description in language, or by\nletting the agent experience the environment in the goal state. We characterize\nrearrangement scenarios along different axes and describe metrics for\nbenchmarking rearrangement performance. To facilitate research and exploration,\nwe present experimental testbeds of rearrangement scenarios in four different\nsimulation environments. We anticipate that other datasets will be released and\nnew simulation platforms will be built to support training of rearrangement\nagents and their deployment on physical systems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:42:32 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Batra", "Dhruv", ""], ["Chang", "Angel X.", ""], ["Chernova", "Sonia", ""], ["Davison", "Andrew J.", ""], ["Deng", "Jia", ""], ["Koltun", "Vladlen", ""], ["Levine", "Sergey", ""], ["Malik", "Jitendra", ""], ["Mordatch", "Igor", ""], ["Mottaghi", "Roozbeh", ""], ["Savva", "Manolis", ""], ["Su", "Hao", ""]]}, {"id": "2011.01977", "submitter": "Ali el Hassouni", "authors": "Daniel Lutscher, Ali el Hassouni, Maarten Stol, Mark Hoogendoorn", "title": "Mixing Consistent Deep Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding well-defined clusters in data represents a fundamental challenge for\nmany data-driven applications, and largely depends on good data representation.\nDrawing on literature regarding representation learning, studies suggest that\none key characteristic of good latent representations is the ability to produce\nsemantically mixed outputs when decoding linear interpolations of two latent\nrepresentations. We propose the Mixing Consistent Deep Clustering method which\nencourages interpolations to appear realistic while adding the constraint that\ninterpolations of two data points must look like one of the two inputs. By\napplying this training method to various clustering (non-)specific autoencoder\nmodels we found that using the proposed training method systematically changed\nthe structure of learned representations of a model and it improved clustering\nperformance for the tested ACAI, IDEC, and VAE models on the MNIST, SVHN, and\nCIFAR-10 datasets. These outcomes have practical implications for numerous\nreal-world clustering tasks, as it shows that the proposed method can be added\nto existing autoencoders to further improve clustering performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:47:06 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Lutscher", "Daniel", ""], ["Hassouni", "Ali el", ""], ["Stol", "Maarten", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "2011.01979", "submitter": "Kristjan Greenewald", "authors": "Kristjan Greenewald, Dmitriy Katz-Rogozhnikov, Karthik Shanmugam", "title": "High-Dimensional Feature Selection for Sample Efficient Treatment Effect\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of causal treatment effects from observational data is a\nfundamental problem in causal inference. To avoid bias, the effect estimator\nmust control for all confounders. Hence practitioners often collect data for as\nmany covariates as possible to raise the chances of including the relevant\nconfounders. While this addresses the bias, this has the side effect of\nsignificantly increasing the number of data samples required to accurately\nestimate the effect due to the increased dimensionality. In this work, we\nconsider the setting where out of a large number of covariates $X$ that satisfy\nstrong ignorability, an unknown sparse subset $S$ is sufficient to include to\nachieve zero bias, i.e. $c$-equivalent to $X$. We propose a common objective\nfunction involving outcomes across treatment cohorts with nonconvex joint\nsparsity regularization that is guaranteed to recover $S$ with high probability\nunder a linear outcome model for $Y$ and subgaussian covariates for each of the\ntreatment cohort. This improves the effect estimation sample complexity so that\nit scales with the cardinality of the sparse subset $S$ and $\\log |X|$, as\nopposed to the cardinality of the full set $X$. We validate our approach with\nexperiments on treatment effect estimation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:54:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Greenewald", "Kristjan", ""], ["Katz-Rogozhnikov", "Dmitriy", ""], ["Shanmugam", "Karthik", ""]]}, {"id": "2011.01990", "submitter": "Eddie Pei", "authors": "E. Pei, E. Fokou\\'e", "title": "Graph Enhanced High Dimensional Kernel Regression", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the flexibility, versatility and predictive power of kernel\nregression are combined with now lavishly available network data to create\nregression models with even greater predictive performances. Building from\nprevious work featuring generalized linear models built in the presence of\nnetwork cohesion data, we construct a kernelized extension that captures\nsubtler nonlinearities in extremely high dimensional spaces and also produces\nfar better predictive performances. Applications of seamless yet substantial\nadaptation to simulated and real-life data demonstrate the appeal and strength\nof our work.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:09:36 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Pei", "E.", ""], ["Fokou\u00e9", "E.", ""]]}, {"id": "2011.01991", "submitter": "Zhong Meng", "authors": "Zhong Meng, Sarangarajan Parthasarathy, Eric Sun, Yashesh Gaur,\n  Naoyuki Kanda, Liang Lu, Xie Chen, Rui Zhao, Jinyu Li, Yifan Gong", "title": "Internal Language Model Estimation for Domain-Adaptive End-to-End Speech\n  Recognition", "comments": "8 pages, 2 figures, SLT 2021", "journal-ref": "2021 IEEE Spoken Language Technology Workshop (SLT)", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The external language models (LM) integration remains a challenging task for\nend-to-end (E2E) automatic speech recognition (ASR) which has no clear division\nbetween acoustic and language models. In this work, we propose an internal LM\nestimation (ILME) method to facilitate a more effective integration of the\nexternal LM with all pre-existing E2E models with no additional model training,\nincluding the most popular recurrent neural network transducer (RNN-T) and\nattention-based encoder-decoder (AED) models. Trained with audio-transcript\npairs, an E2E model implicitly learns an internal LM that characterizes the\ntraining data in the source domain. With ILME, the internal LM scores of an E2E\nmodel are estimated and subtracted from the log-linear interpolation between\nthe scores of the E2E model and the external LM. The internal LM scores are\napproximated as the output of an E2E model when eliminating its acoustic\ncomponents. ILME can alleviate the domain mismatch between training and\ntesting, or improve the multi-domain E2E ASR. Experimented with 30K-hour\ntrained RNN-T and AED models, ILME achieves up to 15.5% and 6.8% relative word\nerror rate reductions from Shallow Fusion on out-of-domain LibriSpeech and\nin-domain Microsoft production test sets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:11:04 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Meng", "Zhong", ""], ["Parthasarathy", "Sarangarajan", ""], ["Sun", "Eric", ""], ["Gaur", "Yashesh", ""], ["Kanda", "Naoyuki", ""], ["Lu", "Liang", ""], ["Chen", "Xie", ""], ["Zhao", "Rui", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2011.01993", "submitter": "Arash Einolghozati", "authors": "Arash Einolghozati, Anchit Gupta, Keith Diedrick, Sonal Gupta", "title": "Sound Natural: Content Rephrasing in Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new task of rephrasing for a more natural virtual assistant.\nCurrently, virtual assistants work in the paradigm of intent slot tagging and\nthe slot values are directly passed as-is to the execution engine. However,\nthis setup fails in some scenarios such as messaging when the query given by\nthe user needs to be changed before repeating it or sending it to another user.\nFor example, for queries like 'ask my wife if she can pick up the kids' or\n'remind me to take my pills', we need to rephrase the content to 'can you pick\nup the kids' and 'take your pills' In this paper, we study the problem of\nrephrasing with messaging as a use case and release a dataset of 3000 pairs of\noriginal query and rephrased query. We show that BART, a pre-trained\ntransformers-based masked language model with auto-regressive decoding, is a\nstrong baseline for the task, and show improvements by adding a copy-pointer\nand copy loss to it. We analyze different tradeoffs of BART-based and\nLSTM-based seq2seq models, and propose a distilled LSTM-based seq2seq as the\nbest practical model.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:15:46 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Einolghozati", "Arash", ""], ["Gupta", "Anchit", ""], ["Diedrick", "Keith", ""], ["Gupta", "Sonal", ""]]}, {"id": "2011.02004", "submitter": "Tony Wu", "authors": "Tony C. Wu, Daniel Flam-Shepherd, Al\\'an Aspuru-Guzik", "title": "Bayesian Variational Optimization for Combinatorial Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on Bayesian Optimization in combinatorial spaces. In many\napplications in the natural science. Broad applications include the study of\nmolecules, proteins, DNA, device structures and quantum circuit designs, a on\noptimization over combinatorial categorical spaces is needed to find optimal or\npareto-optimal solutions. However, only a limited amount of methods have been\nproposed to tackle this problem. Many of them depend on employing Gaussian\nProcess for combinatorial Bayesian Optimizations. Gaussian Processes suffer\nfrom scalability issues for large data sizes as their scaling is cubic with\nrespect to the number of data points. This is often impractical for optimizing\nlarge search spaces. Here, we introduce a variational Bayesian optimization\nmethod that combines variational optimization and continuous relaxations to the\noptimization of the acquisition function for Bayesian optimization. Critically,\nthis method allows for gradient-based optimization and has the capability of\noptimizing problems with large data size and data dimensions. We have shown the\nperformance of our method is comparable to state-of-the-art methods while\nmaintaining its scalability advantages. We also applied our method in molecular\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:56:13 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wu", "Tony C.", ""], ["Flam-Shepherd", "Daniel", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "2011.02009", "submitter": "Hoang Tran", "authors": "Hoang Tran and Guannan Zhang", "title": "AdaDGS: An adaptive black-box optimization method with a nonlocal\n  directional Gaussian smoothing gradient", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local gradient points to the direction of the steepest slope in an\ninfinitesimal neighborhood. An optimizer guided by the local gradient is often\ntrapped in local optima when the loss landscape is multi-modal. A directional\nGaussian smoothing (DGS) approach was recently proposed in (Zhang et al., 2020)\nand used to define a truly nonlocal gradient, referred to as the DGS gradient,\nfor high-dimensional black-box optimization. Promising results show that\nreplacing the traditional local gradient with the DGS gradient can\nsignificantly improve the performance of gradient-based methods in optimizing\nhighly multi-modal loss functions. However, the optimal performance of the DGS\ngradient may rely on fine tuning of two important hyper-parameters, i.e., the\nsmoothing radius and the learning rate. In this paper, we present a simple, yet\ningenious and efficient adaptive approach for optimization with the DGS\ngradient, which removes the need of hyper-parameter fine tuning. Since the DGS\ngradient generally points to a good search direction, we perform a line search\nalong the DGS direction to determine the step size at each iteration. The\nlearned step size in turn will inform us of the scale of function landscape in\nthe surrounding area, based on which we adjust the smoothing radius accordingly\nfor the next iteration. We present experimental results on high-dimensional\nbenchmark functions, an airfoil design problem and a game content generation\nproblem. The AdaDGS method has shown superior performance over several the\nstate-of-the-art black-box optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 21:20:25 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Tran", "Hoang", ""], ["Zhang", "Guannan", ""]]}, {"id": "2011.02030", "submitter": "Mario Morvan", "authors": "Mario Morvan, Angelos Tsiaras, Nikolaos Nikolaou and Ingo P. Waldmann", "title": "PyLightcurve-torch: a transit modelling package for deep learning\n  applications in PyTorch", "comments": "7 pages, 3 figures; submission status updated, fig 2 caption added", "journal-ref": null, "doi": "10.1088/1538-3873/abe6e8", "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new open source python package, based on PyLightcurve and\nPyTorch, tailored for efficient computation and automatic differentiation of\nexoplanetary transits. The classes and functions implemented are fully\nvectorised, natively GPU-compatible and differentiable with respect to the\nstellar and planetary parameters. This makes PyLightcurve-torch suitable for\ntraditional forward computation of transits, but also extends the range of\npossible applications with inference and optimisation algorithms requiring\naccess to the gradients of the physical model. This endeavour is aimed at\nfostering the use of deep learning in exoplanets research, motivated by an ever\nincreasing amount of stellar light curves data and various incentives for the\nimprovement of detection and characterisation techniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:05:41 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 17:49:13 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Morvan", "Mario", ""], ["Tsiaras", "Angelos", ""], ["Nikolaou", "Nikolaos", ""], ["Waldmann", "Ingo P.", ""]]}, {"id": "2011.02036", "submitter": "Sandhya Tripathi", "authors": "Sandhya Tripathi, Bradley A. Fritz, Mohamed Abdelhack, Michael S.\n  Avidan, Yixin Chen, Christopher R. King", "title": "(Un)fairness in Post-operative Complication Prediction Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the current ongoing debate about fairness, explainability and\ntransparency of machine learning models, their application in high-impact\nclinical decision-making systems must be scrutinized. We consider a real-life\nexample of risk estimation before surgery and investigate the potential for\nbias or unfairness of a variety of algorithms. Our approach creates transparent\ndocumentation of potential bias so that the users can apply the model\ncarefully. We augment a model-card like analysis using propensity scores with a\ndecision-tree based guide for clinicians that would identify predictable\nshortcomings of the model. In addition to functioning as a guide for users, we\npropose that it can guide the algorithm development and informatics team to\nfocus on data sources and structures that can address these shortcomings.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:11:19 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tripathi", "Sandhya", ""], ["Fritz", "Bradley A.", ""], ["Abdelhack", "Mohamed", ""], ["Avidan", "Michael S.", ""], ["Chen", "Yixin", ""], ["King", "Christopher R.", ""]]}, {"id": "2011.02043", "submitter": "Ariel Barel Dr.", "authors": "Shmuel Y. Hayoun, Elchanan Zwecher, Eran Iceland, Ahavatya Revivo,\n  Sean R. Levy, and Ariel Barel", "title": "Integrating Deep-Learning-Based Image Completion and Motion Planning to\n  Expedite Indoor Mapping", "comments": "submitted to ICRA-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The challenge of autonomous indoor mapping is addressed. The goal is to\nminimize the time required to achieve a predefined percentage of coverage with\nsome desired level of certainty. The use of a pre-trained generative deep\nneural network, acting as a map predictor, in both the motion planning and the\nmap construction is proposed in order to expedite the mapping process. The\nissue of planning under partial observability is tackled by maintaining a\nbelief map of the floorplan, generated by a deep neural network. This allows\nthe agent to shorten the mapping duration, as well as enabling it to make\nbetter-informed decisions. This method is examined in combination with several\nmotion planners for two distinct floorplan datasets. Simulations are run for\nseveral configurations of the integrated map predictor, the results of which\nreveal that by utilizing the prediction a significant reduction in mapping time\nis possible. When the prediction is integrated in both motion planning and map\nconstruction processes it is shown that the mapping time may in some cases be\ncut by over 50%.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:35:25 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Hayoun", "Shmuel Y.", ""], ["Zwecher", "Elchanan", ""], ["Iceland", "Eran", ""], ["Revivo", "Ahavatya", ""], ["Levy", "Sean R.", ""], ["Barel", "Ariel", ""]]}, {"id": "2011.02057", "submitter": "Ryan Self", "authors": "Ryan Self, Kevin Coleman, He Bai, Rushikesh Kamalapurkar", "title": "Online Observer-Based Inverse Reinforcement Learning", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": "10.1109/LCSYS.2020.3046527", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel approach to the output-feedback inverse reinforcement\nlearning (IRL) problem is developed by casting the IRL problem, for linear\nsystems with quadratic cost functions, as a state estimation problem. Two\nobserver-based techniques for IRL are developed, including a novel observer\nmethod that re-uses previous state estimates via history stacks. Theoretical\nguarantees for convergence and robustness are established under appropriate\nexcitation conditions. Simulations demonstrate the performance of the developed\nobservers and filters under noisy and noise-free measurements.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 23:17:32 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 21:22:15 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Self", "Ryan", ""], ["Coleman", "Kevin", ""], ["Bai", "He", ""], ["Kamalapurkar", "Rushikesh", ""]]}, {"id": "2011.02073", "submitter": "Xubo Lyu", "authors": "Xubo Lyu, Site Li, Seth Siriya, Ye Pu, Mo Chen", "title": "MBB: Model-Based Baseline for Efficient Reinforcement Learning", "comments": "Submitted to the 2021 International Conference on Robotics and\n  Automation (ICRA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL) is capable of learning control\npolicies for high-dimensional, complex robotic tasks, but tends to be\ndata-inefficient. Model-based RL and optimal control have been proven to be\nmuch more data-efficient if an accurate model of the system and environment is\nknown, but can be difficult to scale to expressive models for high-dimensional\nproblems. In this paper, we propose a novel approach to alleviate data\ninefficiency of model-free RL by warm-starting the learning process using a\nlower-dimensional model-based solutions. Particularly, we propose a baseline\nfunction that is initialized via supervision from a low-dimensional value\nfunction. Such a lower-dimensional value function can be obtained by applying\nmodel-based techniques on a low-dimensional problem featuring a known\napproximate system model. Therefore, our approach exploits the model priors\nfrom a simplified problem space implicitly and avoids the direct use of\nhigh-dimensional, expressive models. We demonstrate our approach on two\nrepresentative robotic learning tasks and observe significant improvement in\nperformance and efficiency, and analyze our method empirically with a third\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:11:56 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 00:20:04 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lyu", "Xubo", ""], ["Li", "Site", ""], ["Siriya", "Seth", ""], ["Pu", "Ye", ""], ["Chen", "Mo", ""]]}, {"id": "2011.02079", "submitter": "Corinna Hertweck", "authors": "Corinna Hertweck and Christoph Heitz and Michele Loi", "title": "On the Moral Justification of Statistical Parity", "comments": "11 pages, accepted to ACM FAccT 2021", "journal-ref": null, "doi": "10.1145/3442188.3445936", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial but often neglected aspect of algorithmic fairness is the question\nof how we justify enforcing a certain fairness metric from a moral perspective.\nWhen fairness metrics are proposed, they are typically argued for by\nhighlighting their mathematical properties. Rarely are the moral assumptions\nbeneath the metric explained. Our aim in this paper is to consider the moral\naspects associated with the statistical fairness criterion of independence\n(statistical parity). To this end, we consider previous work, which discusses\nthe two worldviews \"What You See Is What You Get\" (WYSIWYG) and \"We're All\nEqual\" (WAE) and by doing so provides some guidance for clarifying the possible\nassumptions in the design of algorithms. We present an extension of this work,\nwhich centers on morality. The most natural moral extension is that\nindependence needs to be fulfilled if and only if differences in predictive\nfeatures (e.g. high school grades and standardized test scores are predictive\nof performance at university) between socio-demographic groups are caused by\nunjust social disparities or measurement errors. Through two counterexamples,\nwe demonstrate that this extension is not universally true. This means that the\nquestion of whether independence should be used or not cannot be satisfactorily\nanswered by only considering the justness of differences in the predictive\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:26:15 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 12:39:36 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Hertweck", "Corinna", ""], ["Heitz", "Christoph", ""], ["Loi", "Michele", ""]]}, {"id": "2011.02081", "submitter": "Matthew Aguirre", "authors": "Matthew Aguirre, Jan Sokol, Guhan Venkataraman, Alexander Ioannidis", "title": "A deep learning classifier for local ancestry inference", "comments": "Accepted to Learning Meaningful Representations of Life (LMRL),\n  Workshop at the 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Local ancestry inference (LAI) identifies the ancestry of each segment of an\nindividual's genome and is an important step in medical and population genetic\nstudies of diverse cohorts. Several techniques have been used for LAI,\nincluding Hidden Markov Models and Random Forests. Here, we formulate the LAI\ntask as an image segmentation problem and develop a new LAI tool using a deep\nconvolutional neural network with an encoder-decoder architecture. We train our\nmodel using complete genome sequences from 982 unadmixed individuals from each\nof five continental ancestry groups, and we evaluate it using simulated admixed\ndata derived from an additional 279 individuals selected from the same\npopulations. We show that our model is able to learn admixture as a zero-shot\ntask, yielding ancestry assignments that are nearly as accurate as those from\nthe existing gold standard tool, RFMix.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:42:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Aguirre", "Matthew", ""], ["Sokol", "Jan", ""], ["Venkataraman", "Guhan", ""], ["Ioannidis", "Alexander", ""]]}, {"id": "2011.02082", "submitter": "Somil Bansal", "authors": "Somil Bansal, Claire Tomlin", "title": "DeepReach: A Deep Learning Approach to High-Dimensional Reachability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamilton-Jacobi (HJ) reachability analysis is an important formal\nverification method for guaranteeing performance and safety properties of\ndynamical control systems. Its advantages include compatibility with general\nnonlinear system dynamics, formal treatment of bounded disturbances, and the\nability to deal with state and input constraints. However, it involves solving\na PDE, whose computational and memory complexity scales exponentially with\nrespect to the number of state variables, limiting its direct use to\nsmall-scale systems. We propose DeepReach, a method that leverages new\ndevelopments in sinusoidal networks to develop a neural PDE solver for\nhigh-dimensional reachability problems. The computational requirements of\nDeepReach do not scale directly with the state dimension, but rather with the\ncomplexity of the underlying reachable tube. DeepReach achieves comparable\nresults to the state-of-the-art reachability methods, does not require any\nexplicit supervision for the PDE solution, can easily handle external\ndisturbances, adversarial inputs, and system constraints, and also provides a\nsafety controller for the system. We demonstrate DeepReach on a 9D\nmulti-vehicle collision problem, and a 10D narrow passage problem, motivated by\nautonomous driving applications.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:47:59 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Bansal", "Somil", ""], ["Tomlin", "Claire", ""]]}, {"id": "2011.02084", "submitter": "Michael Lui", "authors": "Michael Lui, Yavuz Yetim, \\\"Ozg\\\"ur \\\"Ozkan, Zhuoran Zhao, Shin-Yeh\n  Tsai, Carole-Jean Wu, and Mark Hempstead", "title": "Understanding Capacity-Driven Scale-Out Neural Recommendation Inference", "comments": "16 pages + references, 16 Figures. Additive revision to clarify\n  distinction between this work and other DLRM-like models and add\n  Acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning recommendation models have grown to the terabyte scale.\nTraditional serving schemes--that load entire models to a single server--are\nunable to support this scale. One approach to support this scale is with\ndistributed serving, or distributed inference, which divides the memory\nrequirements of a single large model across multiple servers.\n  This work is a first-step for the systems research community to develop novel\nmodel-serving solutions, given the huge system design space. Large-scale deep\nrecommender systems are a novel workload and vital to study, as they consume up\nto 79% of all inference cycles in the data center. To that end, this work\ndescribes and characterizes scale-out deep learning recommendation inference\nusing data-center serving infrastructure. This work specifically explores\nlatency-bounded inference systems, compared to the throughput-oriented training\nsystems of other recent works. We find that the latency and compute overheads\nof distributed inference are largely a result of a model's static embedding\ntable distribution and sparsity of input inference requests. We further\nevaluate three embedding table mapping strategies of three DLRM-like models and\nspecify challenging design trade-offs in terms of end-to-end latency, compute\noverhead, and resource efficiency. Overall, we observe only a marginal latency\noverhead when the data-center scale recommendation models are served with the\ndistributed inference manner--P99 latency is increased by only 1% in the best\ncase configuration. The latency overheads are largely a result of the commodity\ninfrastructure used and the sparsity of embedding tables. Even more\nencouragingly, we also show how distributed inference can account for\nefficiency improvements in data-center scale recommendation serving.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:51:40 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 16:31:05 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Lui", "Michael", ""], ["Yetim", "Yavuz", ""], ["\u00d6zkan", "\u00d6zg\u00fcr", ""], ["Zhao", "Zhuoran", ""], ["Tsai", "Shin-Yeh", ""], ["Wu", "Carole-Jean", ""], ["Hempstead", "Mark", ""]]}, {"id": "2011.02086", "submitter": "Yan Zuo", "authors": "Yan Zuo, Tom Drummond", "title": "Residual Likelihood Forests", "comments": "Accepted at BMVC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel ensemble learning approach called Residual\nLikelihood Forests (RLF). Our weak learners produce conditional likelihoods\nthat are sequentially optimized using global loss in the context of previous\nlearners within a boosting-like framework (rather than probability\ndistributions that are measured from observed data) and are combined\nmultiplicatively (rather than additively). This increases the efficiency of our\nstrong classifier, allowing for the design of classifiers which are more\ncompact in terms of model capacity. We apply our method to several machine\nlearning classification tasks, showing significant improvements in performance.\nWhen compared against several ensemble approaches including Random Forests and\nGradient Boosted Trees, RLFs offer a significant improvement in performance\nwhilst concurrently reducing the required model size.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:59:41 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zuo", "Yan", ""], ["Drummond", "Tom", ""]]}, {"id": "2011.02089", "submitter": "Grace Deng", "authors": "Grace Deng, Cuize Han, David S. Matteson", "title": "Learning to Rank with Missing Data via Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the role of Conditional Generative Adversarial Networks (GAN) in\nimputing missing data and apply GAN imputation on a novel use case in\ne-commerce: a learning-to-rank problem with incomplete training data.\nConventional imputation methods often make assumptions regarding the underlying\ndistribution of the missing data, while GANs offer an alternative framework to\nsidestep approximating intractable distributions. First, we prove that GAN\nimputation offers theoretical guarantees beyond the naive Missing Completely At\nRandom (MCAR) scenario. Next, we show that empirically, the Conditional GAN\nstructure is well suited for data with heterogeneous distributions and across\nunbalanced classes, improving performance metrics such as RMSE. Using an Amazon\nSearch ranking dataset, we produce standard ranking models trained on\nGAN-imputed data that are comparable to training on ground-truth data based on\nstandard ranking quality metrics NDCG and MRR. We also highlight how different\nneural net features such as convolution and dropout layers can improve\nperformance given different missing value settings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 01:15:41 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 20:42:19 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Deng", "Grace", ""], ["Han", "Cuize", ""], ["Matteson", "David S.", ""]]}, {"id": "2011.02110", "submitter": "Lantian Li Mr.", "authors": "Ying Shi, Haolin Chen, Zhiyuan Tang, Lantian Li, Dong Wang and Jiqing\n  Han", "title": "Can We Trust Deep Speech Prior?", "comments": "To be published in IEEE SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, speech enhancement (SE) based on deep speech prior has attracted\nmuch attention, such as the variational auto-encoder with non-negative matrix\nfactorization (VAE-NMF) architecture. Compared to conventional approaches that\nrepresent clean speech by shallow models such as Gaussians with a low-rank\ncovariance, the new approach employs deep generative models to represent the\nclean speech, which often provides a better prior. Despite the clear advantage\nin theory, we argue that deep priors must be used with much caution, since the\nlikelihood produced by a deep generative model does not always coincide with\nthe speech quality. We designed a comprehensive study on this issue and\ndemonstrated that based on deep speech priors, a reasonable SE performance can\nbe achieved, but the results might be suboptimal. A careful analysis showed\nthat this problem is deeply rooted in the disharmony between the flexibility of\ndeep generative models and the nature of the maximum-likelihood (ML) training.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 03:35:21 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Shi", "Ying", ""], ["Chen", "Haolin", ""], ["Tang", "Zhiyuan", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""], ["Han", "Jiqing", ""]]}, {"id": "2011.02112", "submitter": "Zonghe Chua", "authors": "Zonghe Chua, Anthony M. Jarc, Allison M. Okamura", "title": "Toward Force Estimation in Robot-Assisted Surgery using Deep Learning\n  with Vision and Robot State", "comments": "7 pages, 6 figures, submitted to ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of interaction forces during teleoperated robot-assisted surgery\ncould be used to enable force feedback to human operators and evaluate tissue\nhandling skill. However, direct force sensing at the end-effector is\nchallenging because it requires biocompatible, sterilizable, and cost-effective\nsensors. Vision-based deep learning using convolutional neural networks is a\npromising approach for providing useful force estimates, though questions\nremain about generalization to new scenarios and real-time inference. We\npresent a force estimation neural network that uses RGB images and robot state\nas inputs. Using a self-collected dataset, we compared the network to variants\nthat included only a single input type, and evaluated how they generalized to\nnew viewpoints, workspace positions, materials, and tools. We found that\nvision-based networks were sensitive to shifts in viewpoints, while state-only\nnetworks were robust to changes in workspace. The network with both state and\nvision inputs had the highest accuracy for an unseen tool, and was moderately\nrobust to changes in viewpoints. Through feature removal studies, we found that\nusing only position features produced better accuracy than using only force\nfeatures as input. The network with both state and vision inputs outperformed a\nphysics-based baseline model in accuracy. It showed comparable accuracy but\nfaster computation times than a baseline recurrent neural network, making it\nbetter suited for real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 04:00:07 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 01:23:38 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2020 21:42:44 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Chua", "Zonghe", ""], ["Jarc", "Anthony M.", ""], ["Okamura", "Allison M.", ""]]}, {"id": "2011.02122", "submitter": "Rahul Chakwate", "authors": "Rahul Chakwate, Madhan R A", "title": "Analysing Long Short Term Memory Models for Cricket Match Outcome\n  Prediction", "comments": null, "journal-ref": null, "doi": "10.22214/ijraset.2020.28203", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the technology advances, an ample amount of data is collected in sports\nwith the help of advanced sensors. Sports Analytics is the study of this data\nto provide a constructive advantage to the team and its players. The game of\ninternational cricket is popular all across the globe. Recently, various\nmachine learning techniques have been used to analyse the cricket match data\nand predict the match outcome as win or lose. Generally these models make use\nof the overall match level statistics such as teams, venue, average run rate,\nwin margin, etc to predict the match results before the beginning of the match.\nHowever, very few works provide insights based on the ball-by-ball level\nstatistics. Here we propose a novel Recurrent Neural Network model which can\npredict the win probability of a match at regular intervals given the\nball-by-ball statistics. The Long Short Term Memory (LSTM) Model takes as input\nthe ball wise features as well as the match level details available from the\ntraining dataset. It gives a prediction of winning the match at any time stamp\nduring the match. This level of insight will help the team to predict the\nprobability of them winning the match after every ball and help them determine\nthe critical in-game changes they should make in their game strategies.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 04:49:11 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Chakwate", "Rahul", ""], ["A", "Madhan R", ""]]}, {"id": "2011.02141", "submitter": "Jo\\~ao Pedro Ara\\'ujo", "authors": "Jo\\~ao Pedro Ara\\'ujo and M\\'ario A. T. Figueiredo and Miguel Ayala\n  Botto", "title": "Control with adaptive Q-learning", "comments": "29 pages, 13 figures. arXiv admin note: substantial text overlap with\n  arXiv:2007.06741", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper evaluates adaptive Q-learning (AQL) and single-partition adaptive\nQ-learning (SPAQL), two algorithms for efficient model-free episodic\nreinforcement learning (RL), in two classical control problems (Pendulum and\nCartpole). AQL adaptively partitions the state-action space of a Markov\ndecision process (MDP), while learning the control policy, i. e., the mapping\nfrom states to actions. The main difference between AQL and SPAQL is that the\nlatter learns time-invariant policies, where the mapping from states to actions\ndoes not depend explicitly on the time step. This paper also proposes the SPAQL\nwith terminal state (SPAQL-TS), an improved version of SPAQL tailored for the\ndesign of regulators for control problems. The time-invariant policies are\nshown to result in a better performance than the time-variant ones in both\nproblems studied. These algorithms are particularly fitted to RL problems where\nthe action space is finite, as is the case with the Cartpole problem. SPAQL-TS\nsolves the OpenAI Gym Cartpole problem, while also displaying a higher sample\nefficiency than trust region policy optimization (TRPO), a standard RL\nalgorithm for solving control tasks. Moreover, the policies learned by SPAQL\nare interpretable, while TRPO policies are typically encoded as neural\nnetworks, and therefore hard to interpret. Yielding interpretable policies\nwhile being sample-efficient are the major advantages of SPAQL.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 18:58:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ara\u00fajo", "Jo\u00e3o Pedro", ""], ["Figueiredo", "M\u00e1rio A. T.", ""], ["Botto", "Miguel Ayala", ""]]}, {"id": "2011.02143", "submitter": "Alice Coucke", "authors": "St\\'ephane d'Ascoli, Alice Coucke, Francesco Caltagirone, Alexandre\n  Caulier, Marc Lelarge", "title": "Conditioned Text Generation with Transfer for Closed-Domain Dialogue\n  Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.03698", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scarcity of training data for task-oriented dialogue systems is a well known\nproblem that is usually tackled with costly and time-consuming manual data\nannotation. An alternative solution is to rely on automatic text generation\nwhich, although less accurate than human supervision, has the advantage of\nbeing cheap and fast. Our contribution is twofold. First we show how to\noptimally train and control the generation of intent-specific sentences using a\nconditional variational autoencoder. Then we introduce a new protocol called\nquery transfer that allows to leverage a large unlabelled dataset, possibly\ncontaining irrelevant queries, to extract relevant information. Comparison with\ntwo different baselines shows that this method, in the appropriate regime,\nconsistently improves the diversity of the generated queries without\ncompromising their quality. We also demonstrate the effectiveness of our\ngeneration method as a data augmentation technique for language modelling\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:06:10 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["d'Ascoli", "St\u00e9phane", ""], ["Coucke", "Alice", ""], ["Caltagirone", "Francesco", ""], ["Caulier", "Alexandre", ""], ["Lelarge", "Marc", ""]]}, {"id": "2011.02147", "submitter": "Chun-Na Li", "authors": "Jiakou Liu, Xiong Xiong, Pei-Wei Ren, Da Zhao, Chun-Na Li, Yuan-Hai\n  Shao", "title": "Capped norm linear discriminant analysis and its applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical linear discriminant analysis (LDA) is based on squared Frobenious\nnorm and hence is sensitive to outliers and noise. To improve the robustness of\nLDA, in this paper, we introduce capped l_{2,1}-norm of a matrix, which employs\nnon-squared l_2-norm and \"capped\" operation, and further propose a novel capped\nl_{2,1}-norm linear discriminant analysis, called CLDA. Due to the use of\ncapped l_{2,1}-norm, CLDA can effectively remove extreme outliers and suppress\nthe effect of noise data. In fact, CLDA can be also viewed as a weighted LDA.\nCLDA is solved through a series of generalized eigenvalue problems with\ntheoretical convergency. The experimental results on an artificial data set,\nsome UCI data sets and two image data sets demonstrate the effectiveness of\nCLDA.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:15:10 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Liu", "Jiakou", ""], ["Xiong", "Xiong", ""], ["Ren", "Pei-Wei", ""], ["Zhao", "Da", ""], ["Li", "Chun-Na", ""], ["Shao", "Yuan-Hai", ""]]}, {"id": "2011.02149", "submitter": "Chuan Wang", "authors": "Chuan Wang and Kwan-Liu Ma", "title": "HypperSteer: Hypothetical Steering and Data Perturbation in Sequence\n  Prediction with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Recurrent Neural Networks (RNN) continues to find success in predictive\ndecision-making with temporal event sequences. Recent studies have shown the\nimportance and practicality of visual analytics in interpreting deep learning\nmodels for real-world applications. However, very limited work enables\ninteractions with deep learning models and guides practitioners to form\nhypotheticals towards the desired prediction outcomes, especially for sequence\nprediction. Specifically, no existing work has addressed the what-if analysis\nand value perturbation along different time-steps for sequence outcome\nprediction. We present a model-agnostic visual analytics tool, HypperSteer,\nthat steers hypothetical testing and allows users to perturb data for sequence\npredictions interactively. We showcase how HypperSteer helps in steering\npatient data to achieve desired treatment outcomes and discuss how HypperSteer\ncan serve as a comprehensive solution for other practical scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:26:58 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 01:55:39 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wang", "Chuan", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2011.02150", "submitter": "Wei Yuan", "authors": "Wei Yuan and Kai-Xin Gao", "title": "EAdam Optimizer: How $\\epsilon$ Impact Adam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many adaptive optimization methods have been proposed and used in deep\nlearning, in which Adam is regarded as the default algorithm and widely used in\nmany deep learning frameworks. Recently, many variants of Adam, such as\nAdabound, RAdam and Adabelief, have been proposed and show better performance\nthan Adam. However, these variants mainly focus on changing the stepsize by\nmaking differences on the gradient or the square of it. Motivated by the fact\nthat suitable damping is important for the success of powerful second-order\noptimizers, we discuss the impact of the constant $\\epsilon$ for Adam in this\npaper. Surprisingly, we can obtain better performance than Adam simply changing\nthe position of $\\epsilon$. Based on this finding, we propose a new variant of\nAdam called EAdam, which doesn't need extra hyper-parameters or computational\ncosts. We also discuss the relationships and differences between our method and\nAdam. Finally, we conduct extensive experiments on various popular tasks and\nmodels. Experimental results show that our method can bring significant\nimprovement compared with Adam. Our code is available at\nhttps://github.com/yuanwei2019/EAdam-optimizer.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:39:44 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Yuan", "Wei", ""], ["Gao", "Kai-Xin", ""]]}, {"id": "2011.02151", "submitter": "Kwadwo Opong-Mensah", "authors": "Kwadwo Opong-Mensah", "title": "Simulation of Human and Artificial Emotion (SHArE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework for Simulation of Human and Artificial Emotion (SHArE)\ndescribes the architecture of emotion in terms of parameters transferable\nbetween psychology, neuroscience, and artificial intelligence. These parameters\ncan be defined as abstract concepts or granularized down to the voltage levels\nof individual neurons. This model enables emotional trajectory design for\nhumans which may lead to novel therapeutic solutions for various mental health\nconcerns. For artificial intelligence, this work provides a compact notation\nwhich can be applied to neural networks as a means to observe the emotions and\nmotivations of machines.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:45:30 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Opong-Mensah", "Kwadwo", ""]]}, {"id": "2011.02155", "submitter": "Yu-Jen Chen", "authors": "Shao-Cheng Wen, Yu-Jen Chen, Zihao Liu, Wujie Wen, Xiaowei Xu, Yiyu\n  Shi, Tsung-Yi Ho, Qianjun Jia, Meiping Huang, Jian Zhuang", "title": "Do Noises Bother Human and Neural Networks In the Same Way? A Medical\n  Image Analysis Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning had already demonstrated its power in medical images, including\ndenoising, classification, segmentation, etc. All these applications are\nproposed to automatically analyze medical images beforehand, which brings more\ninformation to radiologists during clinical assessment for accuracy\nimprovement. Recently, many medical denoising methods had shown their\nsignificant artifact reduction result and noise removal both quantitatively and\nqualitatively. However, those existing methods are developed around\nhuman-vision, i.e., they are designed to minimize the noise effect that can be\nperceived by human eyes. In this paper, we introduce an application-guided\ndenoising framework, which focuses on denoising for the following neural\nnetworks. In our experiments, we apply the proposed framework to different\ndatasets, models, and use cases. Experimental results show that our proposed\nframework can achieve a better result than human-vision denoising network.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:58:09 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Wen", "Shao-Cheng", ""], ["Chen", "Yu-Jen", ""], ["Liu", "Zihao", ""], ["Wen", "Wujie", ""], ["Xu", "Xiaowei", ""], ["Shi", "Yiyu", ""], ["Ho", "Tsung-Yi", ""], ["Jia", "Qianjun", ""], ["Huang", "Meiping", ""], ["Zhuang", "Jian", ""]]}, {"id": "2011.02159", "submitter": "Niru Maheswaranathan", "authors": "Niru Maheswaranathan, David Sussillo, Luke Metz, Ruoxi Sun, Jascha\n  Sohl-Dickstein", "title": "Reverse engineering learned optimizers reveals known and novel\n  mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned optimizers are algorithms that can themselves be trained to solve\noptimization problems. In contrast to baseline optimizers (such as momentum or\nAdam) that use simple update rules derived from theoretical principles, learned\noptimizers use flexible, high-dimensional, nonlinear parameterizations.\nAlthough this can lead to better performance in certain settings, their inner\nworkings remain a mystery. How is a learned optimizer able to outperform a well\ntuned baseline? Has it learned a sophisticated combination of existing\noptimization techniques, or is it implementing completely new behavior? In this\nwork, we address these questions by careful analysis and visualization of\nlearned optimizers. We study learned optimizers trained from scratch on three\ndisparate tasks, and discover that they have learned interpretable mechanisms,\nincluding: momentum, gradient clipping, learning rate schedules, and a new form\nof learning rate adaptation. Moreover, we show how the dynamics of learned\noptimizers enables these behaviors. Our results help elucidate the previously\nmurky understanding of how learned optimizers work, and establish tools for\ninterpreting future learned optimizers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 07:12:43 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Maheswaranathan", "Niru", ""], ["Sussillo", "David", ""], ["Metz", "Luke", ""], ["Sun", "Ruoxi", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2011.02166", "submitter": "Ning Liu", "authors": "Yushuo Guan, Ning Liu, Pengyu Zhao, Zhengping Che, Kaigui Bian, Yanzhi\n  Wang, Jian Tang", "title": "DAIS: Automatic Channel Pruning via Differentiable Annealing Indicator\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convolutional neural network has achieved great success in fulfilling\ncomputer vision tasks despite large computation overhead against efficient\ndeployment. Structured (channel) pruning is usually applied to reduce the model\nredundancy while preserving the network structure, such that the pruned network\ncan be easily deployed in practice. However, existing structured pruning\nmethods require hand-crafted rules which may lead to tremendous pruning space.\nIn this paper, we introduce Differentiable Annealing Indicator Search (DAIS)\nthat leverages the strength of neural architecture search in the channel\npruning and automatically searches for the effective pruned model with given\nconstraints on computation overhead. Specifically, DAIS relaxes the binarized\nchannel indicators to be continuous and then jointly learns both indicators and\nmodel parameters via bi-level optimization. To bridge the non-negligible\ndiscrepancy between the continuous model and the target binarized model, DAIS\nproposes an annealing-based procedure to steer the indicator convergence\ntowards binarized states. Moreover, DAIS designs various regularizations based\non a priori structural knowledge to control the pruning sparsity and to improve\nmodel performance. Experimental results show that DAIS outperforms\nstate-of-the-art pruning methods on CIFAR-10, CIFAR-100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 07:43:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Guan", "Yushuo", ""], ["Liu", "Ning", ""], ["Zhao", "Pengyu", ""], ["Che", "Zhengping", ""], ["Bian", "Kaigui", ""], ["Wang", "Yanzhi", ""], ["Tang", "Jian", ""]]}, {"id": "2011.02167", "submitter": "Giorgia Azzurra Marson", "authors": "Sebastien Andreina, Giorgia Azzurra Marson, Helen M\\\"ollering, Ghassan\n  Karame", "title": "BaFFLe: Backdoor detection via Feedback-based Federated Learning", "comments": "11 pages, 5 figures; to appear in the 41st IEEE International\n  Conference on Distributed Computing Systems (ICDCS'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that federated learning (FL) is vulnerable to\npoisoning attacks that inject a backdoor into the global model. These attacks\nare effective even when performed by a single client, and undetectable by most\nexisting defensive techniques. In this paper, we propose Backdoor detection via\nFeedback-based Federated Learning (BAFFLE), a novel defense to secure FL\nagainst backdoor attacks. The core idea behind BAFFLE is to leverage data of\nmultiple clients not only for training but also for uncovering model poisoning.\nWe exploit the availability of diverse datasets at the various clients by\nincorporating a feedback loop into the FL process, to integrate the views of\nthose clients when deciding whether a given model update is genuine or not. We\nshow that this powerful construct can achieve very high detection rates against\nstate-of-the-art backdoor attacks, even when relying on straightforward methods\nto validate the model. Through empirical evaluation using the CIFAR-10 and\nFEMNIST datasets, we show that by combining the feedback loop with a method\nthat suspects poisoning attempts by assessing the per-class classification\nperformance of the updated model, BAFFLE reliably detects state-of-the-art\nbackdoor attacks with a detection accuracy of 100% and a false-positive rate\nbelow 5%. Moreover, we show that our solution can detect adaptive attacks aimed\nat bypassing the defense.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 07:44:51 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 13:19:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Andreina", "Sebastien", ""], ["Marson", "Giorgia Azzurra", ""], ["M\u00f6llering", "Helen", ""], ["Karame", "Ghassan", ""]]}, {"id": "2011.02179", "submitter": "Nafiseh Ghoroghchian Ms.", "authors": "Nafiseh Ghoroghchian, David M. Groppe, Roman Genov, Taufik A.\n  Valiante, and Stark C. Draper", "title": "Node-Centric Graph Learning from Data for Brain State Identification", "comments": null, "journal-ref": "IEEE Transactions on Signal and Information Processing over\n  Networks, 6, 120-132 (2020)", "doi": "10.1109/TSIPN.2020.2964230", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven graph learning models a network by determining the strength of\nconnections between its nodes. The data refers to a graph signal which\nassociates a value with each graph node. Existing graph learning methods either\nuse simplified models for the graph signal, or they are prohibitively expensive\nin terms of computational and memory requirements. This is particularly true\nwhen the number of nodes is high or there are temporal changes in the network.\nIn order to consider richer models with a reasonable computational\ntractability, we introduce a graph learning method based on representation\nlearning on graphs. Representation learning generates an embedding for each\ngraph node, taking the information from neighbouring nodes into account. Our\ngraph learning method further modifies the embeddings to compute the graph\nsimilarity matrix. In this work, graph learning is used to examine brain\nnetworks for brain state identification. We infer time-varying brain graphs\nfrom an extensive dataset of intracranial electroencephalographic (iEEG)\nsignals from ten patients. We then apply the graphs as input to a classifier to\ndistinguish seizure vs. non-seizure brain states. Using the binary\nclassification metric of area under the receiver operating characteristic curve\n(AUC), this approach yields an average of 9.13 percent improvement when\ncompared to two widely used brain network modeling methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 08:44:44 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ghoroghchian", "Nafiseh", ""], ["Groppe", "David M.", ""], ["Genov", "Roman", ""], ["Valiante", "Taufik A.", ""], ["Draper", "Stark C.", ""]]}, {"id": "2011.02188", "submitter": "Pawel Plawiak", "authors": "Filip Pa{\\l}ka, Wojciech Ksi\\k{a}\\.zek, Pawe{\\l} P{\\l}awiak, Micha{\\l}\n  Romaszewski, Kamil Ksi\\k{a}\\.zek", "title": "Hyperspectral classification of blood-like substances using machine\n  learning methods combined with genetic algorithms in transductive and\n  inductive scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study is focused on applying genetic algorithms (GA) to model and band\nselection in hyperspectral image classification. We use a forensic-inspired\ndata set of seven hyperspectral images with blood and five visually similar\nsubstances to test GA-optimised classifiers in two scenarios: when the training\nand test data come from the same image and when they come from different\nimages, which is a more challenging task due to significant spectra\ndifferences. In our experiments we compare GA with a classic model optimisation\nthrough grid search. Our results show that GA-based model optimisation can\nreduce the number of bands and create an accurate classifier that outperforms\nthe GS-based reference models, provided that during model optimisation it has\naccess to examples similar to test data. We illustrate this with experiment\nhighlighting the importance of a validation set.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 09:18:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Pa\u0142ka", "Filip", ""], ["Ksi\u0105\u017cek", "Wojciech", ""], ["P\u0142awiak", "Pawe\u0142", ""], ["Romaszewski", "Micha\u0142", ""], ["Ksi\u0105\u017cek", "Kamil", ""]]}, {"id": "2011.02195", "submitter": "Rini Sharon A", "authors": "Rini A Sharon, Hema A Murthy", "title": "Correlation based Multi-phasal models for improved imagined speech EEG\n  recognition", "comments": null, "journal-ref": "Interspeech SMM 2020", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translation of imagined speech electroencephalogram(EEG) into human\nunderstandable commands greatly facilitates the design of naturalistic brain\ncomputer interfaces. To achieve improved imagined speech unit classification,\nthis work aims to profit from the parallel information contained in\nmulti-phasal EEG data recorded while speaking, imagining and performing\narticulatory movements corresponding to specific speech units. A bi-phase\ncommon representation learning module using neural networks is designed to\nmodel the correlation and reproducibility between an analysis phase and a\nsupport phase. The trained Correlation Network is then employed to extract\ndiscriminative features of the analysis phase. These features are further\nclassified into five binary phonological categories using machine learning\nmodels such as Gaussian mixture based hidden Markov model and deep neural\nnetworks. The proposed approach further handles the non-availability of\nmulti-phasal data during decoding. Topographic visualizations along with\nresult-based inferences suggest that the multi-phasal correlation modelling\napproach proposed in the paper enhances imagined-speech EEG recognition\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 09:39:53 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Sharon", "Rini A", ""], ["Murthy", "Hema A", ""]]}, {"id": "2011.02203", "submitter": "Xinwei Sun", "authors": "Xinwei Sun, Botong Wu, Xiangyu Zheng, Chang Liu, Wei Chen, Tao Qin,\n  Tie-yan Liu", "title": "Latent Causal Invariant Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current supervised learning can learn spurious correlation during the\ndata-fitting process, imposing issues regarding interpretability,\nout-of-distribution (OOD) generalization, and robustness. To avoid spurious\ncorrelation, we propose a Latent Causal Invariance Model (LaCIM) which pursues\ncausal prediction. Specifically, we introduce latent variables that are\nseparated into (a) output-causative factors and (b) others that are spuriously\ncorrelated to the output via confounders, to model the underlying causal\nfactors. We further assume the generating mechanisms from latent space to\nobserved data to be causally invariant. We give the identifiable claim of such\ninvariance, particularly the disentanglement of output-causative factors from\nothers, as a theoretical guarantee for precise inference and avoiding spurious\ncorrelation. We propose a Variational-Bayesian-based method for estimation and\nto optimize over the latent space for prediction. The utility of our approach\nis verified by improved interpretability, prediction power on various OOD\nscenarios (including healthcare) and robustness on security.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 10:00:27 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 17:04:41 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 09:54:44 GMT"}, {"version": "v4", "created": "Tue, 27 Apr 2021 23:28:44 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Sun", "Xinwei", ""], ["Wu", "Botong", ""], ["Zheng", "Xiangyu", ""], ["Liu", "Chang", ""], ["Chen", "Wei", ""], ["Qin", "Tao", ""], ["Liu", "Tie-yan", ""]]}, {"id": "2011.02243", "submitter": "Yacine Kessaci", "authors": "Carlos Miranda and Yacine Kessaci", "title": "Hybrid Supervised Reinforced Model for Dialogue Systems", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a recurrent hybrid model and training procedure for\ntask-oriented dialogue systems based on Deep Recurrent Q-Networks (DRQN). The\nmodel copes with both tasks required for Dialogue Management: State Tracking\nand Decision Making. It is based on modeling Human-Machine interaction into a\nlatent representation embedding an interaction context to guide the discussion.\nThe model achieves greater performance, learning speed and robustness than a\nnon-recurrent baseline. Moreover, results allow interpreting and validating the\npolicy evolution and the latent representations information-wise.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:03:12 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Miranda", "Carlos", ""], ["Kessaci", "Yacine", ""]]}, {"id": "2011.02250", "submitter": "Gelareh Mohammadi", "authors": "Nuha Aldausari, Arcot Sowmya, Nadine Marcus, Gelareh Mohammadi", "title": "Video Generative Adversarial Networks: A Review", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing interest in the content creation field in multiple\nsectors such as media, education, and entertainment, there is an increasing\ntrend in the papers that uses AI algorithms to generate content such as images,\nvideos, audio, and text. Generative Adversarial Networks (GANs) in one of the\npromising models that synthesizes data samples that are similar to real data\nsamples. While the variations of GANs models, in general, have been covered to\nsome extent in several survey papers, to the best of our knowledge, this is\namong the first survey papers that reviews the state-of-the-art video GANs\nmodels. This paper first categorized GANs review papers into general GANs\nreview papers, image GANs review papers, and special field GANs review papers\nsuch as anomaly detection, medical imaging, or cybersecurity. The paper then\nsummarizes the main improvements in GANs frameworks that are not initially\ndeveloped for the video domain but have been adopted in multiple video GANs\nvariations. Then, a comprehensive review of video GANs models is provided under\ntwo main divisions according to the presence or non-presence of a condition.\nThe conditional models then further grouped according to the type of condition\ninto audio, text, video, and image. The paper is concluded by highlighting the\nmain challenges and limitations of the current video GANs models. A\ncomprehensive list of datasets, applied loss functions, and evaluation metrics\nis provided in the supplementary material.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:16:05 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Aldausari", "Nuha", ""], ["Sowmya", "Arcot", ""], ["Marcus", "Nadine", ""], ["Mohammadi", "Gelareh", ""]]}, {"id": "2011.02255", "submitter": "Yuzhao Chen", "authors": "Yuzhao Chen, Yatao Bian, Xi Xiao, Yu Rong, Tingyang Xu, Junzhou Huang", "title": "On Self-Distilling Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the teacher-student knowledge distillation framework has\ndemonstrated its potential in training Graph Neural Networks (GNNs). However,\ndue to the difficulty of training over-parameterized GNN models, one may not\neasily obtain a satisfactory teacher model for distillation. Furthermore, the\ninefficient training process of teacher-student knowledge distillation also\nimpedes its applications in GNN models. In this paper, we propose the first\nteacher-free knowledge distillation method for GNNs, termed GNN\nSelf-Distillation (GNN-SD), that serves as a drop-in replacement of the\nstandard training process. The method is built upon the proposed neighborhood\ndiscrepancy rate (NDR), which quantifies the non-smoothness of the embedded\ngraph in an efficient way. Based on this metric, we propose the adaptive\ndiscrepancy retaining (ADR) regularizer to empower the transferability of\nknowledge that maintains high neighborhood discrepancy across GNN layers. We\nalso summarize a generic GNN-SD framework that could be exploited to induce\nother distillation strategies. Experiments further prove the effectiveness and\ngeneralization of our approach, as it brings: 1) state-of-the-art GNN\ndistillation performance with less training cost, 2) consistent and\nconsiderable performance enhancement for various popular backbones.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:29:33 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 04:31:53 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Chen", "Yuzhao", ""], ["Bian", "Yatao", ""], ["Xiao", "Xi", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "2011.02256", "submitter": "Masaaki Imaizumi", "authors": "Masaaki Imaizumi, Kenji Fukumizu", "title": "Advantage of Deep Neural Networks for Estimating Functions with\n  Singularity on Curves", "comments": "Complete version of arXiv:1802.04474", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theory to elucidate the reason that deep neural networks (DNNs)\nperform better than other methods. In terms of the nonparametric regression\nproblem, it is well known that many standard methods attain the minimax optimal\nrate of estimation errors for smooth functions, and thus, it is not\nstraightforward to identify the theoretical advantages of DNNs. This study\nfills this gap by considering the estimation for a class of non-smooth\nfunctions with singularities on smooth curves. Our findings are as follows: (i)\nWe derive the generalization error of a DNN estimator and prove that its\nconvergence rate is almost optimal. (ii) We reveal that a certain class of\ncommon models are sub-optimal, including linear estimators and other harmonic\nanalysis methods such as wavelets and curvelets. This advantage of DNNs comes\nfrom a fact that a shape of singularity can be successfully handled by their\nmulti-layered structure.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:51:14 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Imaizumi", "Masaaki", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2011.02258", "submitter": "Huiming Zhang", "authors": "Huiming Zhang, Song Xi Chen", "title": "Concentration Inequalities for Statistical Inference", "comments": "Invited review article on constants-specified concentration\n  inequalities published in Communications in Mathematical Research", "journal-ref": "Communications in Mathematical Research. 37(1), 1-85 (2021)", "doi": "10.4208/cmr.2020-0041", "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a review of concentration inequalities which are widely\nemployed in non-asymptotical analyses of mathematical statistics in a wide\nrange of settings, from distribution-free to distribution-dependent, from\nsub-Gaussian to sub-exponential, sub-Gamma, and sub-Weibull random variables,\nand from the mean to the maximum concentration. This review provides results in\nthese settings with some fresh new results. Given the increasing popularity of\nhigh-dimensional data and inference, results in the context of high-dimensional\nlinear and Poisson regressions are also provided. We aim to illustrate the\nconcentration inequalities with known constants and to improve existing bounds\nwith sharper constants.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:54:06 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 04:09:05 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 05:30:11 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhang", "Huiming", ""], ["Chen", "Song Xi", ""]]}, {"id": "2011.02260", "submitter": "Fei Sun", "authors": "Shiwen Wu, Fei Sun, Wentao Zhang, Bin Cui", "title": "Graph Neural Networks in Recommender Systems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Owing to the superiority of GNN in learning on graph data and its efficacy in\ncapturing collaborative signals and sequential patterns, utilizing GNN\ntechniques in recommender systems has gain increasing interests in academia and\nindustry. In this survey, we provide a comprehensive review of the most recent\nworks on GNN-based recommender systems. We proposed a classification scheme for\norganizing existing works. For each category, we briefly clarify the main\nissues, and detail the corresponding strategies adopted by the representative\nmodels. We also discuss the advantages and limitations of the existing\nstrategies. Furthermore, we suggest several promising directions for future\nresearches. We hope this survey can provide readers with a general\nunderstanding of the recent progress in this field, and shed some light on\nfuture developments.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:57:47 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 11:41:15 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Wu", "Shiwen", ""], ["Sun", "Fei", ""], ["Zhang", "Wentao", ""], ["Cui", "Bin", ""]]}, {"id": "2011.02266", "submitter": "Ali Araabi", "authors": "Ali Araabi, Christof Monz", "title": "Optimizing Transformer for Low-Resource Neural Machine Translation", "comments": "To be published in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language pairs with limited amounts of parallel data, also known as\nlow-resource languages, remain a challenge for neural machine translation.\nWhile the Transformer model has achieved significant improvements for many\nlanguage pairs and has become the de facto mainstream architecture, its\ncapability under low-resource conditions has not been fully investigated yet.\nOur experiments on different subsets of the IWSLT14 training data show that the\neffectiveness of Transformer under low-resource conditions is highly dependent\non the hyper-parameter settings. Our experiments show that using an optimized\nTransformer for low-resource conditions improves the translation quality up to\n7.3 BLEU points compared to using the Transformer default settings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:12:29 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Araabi", "Ali", ""], ["Monz", "Christof", ""]]}, {"id": "2011.02268", "submitter": "Ilyes Khemakhem", "authors": "Ilyes Khemakhem, Ricardo Pio Monti, Robert Leech, Aapo Hyv\\\"arinen", "title": "Causal Autoregressive Flows", "comments": "Published at AISTATS2021. Code available at\n  https://github.com/piomonti/carefl", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two apparently unrelated fields -- normalizing flows and causality -- have\nrecently received considerable attention in the machine learning community. In\nthis work, we highlight an intrinsic correspondence between a simple family of\nautoregressive normalizing flows and identifiable causal models. We exploit the\nfact that autoregressive flow architectures define an ordering over variables,\nanalogous to a causal ordering, to show that they are well-suited to performing\na range of causal inference tasks, ranging from causal discovery to making\ninterventional and counterfactual predictions. First, we show that causal\nmodels derived from both affine and additive autoregressive flows with fixed\norderings over variables are identifiable, i.e. the true direction of causal\ninfluence can be recovered. This provides a generalization of the additive\nnoise model well-known in causal discovery. Second, we derive a bivariate\nmeasure of causal direction based on likelihood ratios, leveraging the fact\nthat flow models can estimate normalized log-densities of data. Third, we\ndemonstrate that flows naturally allow for direct evaluation of both\ninterventional and counterfactual queries, the latter case being possible due\nto the invertible nature of flows. Finally, throughout a series of experiments\non synthetic and real data, the proposed method is shown to outperform current\napproaches for causal discovery as well as making accurate interventional and\ncounterfactual predictions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:17:35 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 16:35:26 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Khemakhem", "Ilyes", ""], ["Monti", "Ricardo Pio", ""], ["Leech", "Robert", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "2011.02271", "submitter": "Amir Dib", "authors": "Amir Dib", "title": "Quantized Variational Inference", "comments": null, "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Quantized Variational Inference, a new algorithm for Evidence\nLower Bound maximization. We show how Optimal Voronoi Tesselation produces\nvariance free gradients for ELBO optimization at the cost of introducing\nasymptotically decaying bias. Subsequently, we propose a Richardson\nextrapolation type method to improve the asymptotic bound. We show that using\nthe Quantized Variational Inference framework leads to fast convergence for\nboth score function and the reparametrized gradient estimator at a comparable\ncomputational cost. Finally, we propose several experiments to assess the\nperformance of our method and its limitations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:22:50 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Dib", "Amir", ""]]}, {"id": "2011.02272", "submitter": "Mayank Vatsa", "authors": "Richa Singh, Mayank Vatsa, Nalini Ratha", "title": "Trustworthy AI", "comments": "ACM CODS-COMAD 2021 Tutorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern AI systems are reaping the advantage of novel learning methods. With\ntheir increasing usage, we are realizing the limitations and shortfalls of\nthese systems. Brittleness to minor adversarial changes in the input data,\nability to explain the decisions, address the bias in their training data, high\nopacity in terms of revealing the lineage of the system, how they were trained\nand tested, and under which parameters and conditions they can reliably\nguarantee a certain level of performance, are some of the most prominent\nlimitations. Ensuring the privacy and security of the data, assigning\nappropriate credits to data sources, and delivering decent outputs are also\nrequired features of an AI system. We propose the tutorial on Trustworthy AI to\naddress six critical issues in enhancing user and public trust in AI systems,\nnamely: (i) bias and fairness, (ii) explainability, (iii) robust mitigation of\nadversarial attacks, (iv) improved privacy and security in model building, (v)\nbeing decent, and (vi) model attribution, including the right level of credit\nassignment to the data sources, model architectures, and transparency in\nlineage.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:04:18 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Singh", "Richa", ""], ["Vatsa", "Mayank", ""], ["Ratha", "Nalini", ""]]}, {"id": "2011.02273", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela and Maria Perez-Ortiz and Emine Yilmaz and John\n  Shawe-Taylor", "title": "VLEngagement: A Dataset of Scientific Video Lectures for Evaluating\n  Population-based Engagement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the emergence of e-learning and personalised education, the production\nand distribution of digital educational resources have boomed. Video lectures\nhave now become one of the primary modalities to impart knowledge to masses in\nthe current digital age. The rapid creation of video lecture content challenges\nthe currently established human-centred moderation and quality assurance\npipeline, demanding for more efficient, scalable and automatic solutions for\nmanaging learning resources. Although a few datasets related to engagement with\neducational videos exist, there is still an important need for data and\nresearch aimed at understanding learner engagement with scientific video\nlectures. This paper introduces VLEngagement, a novel dataset that consists of\ncontent-based and video-specific features extracted from publicly available\nscientific video lectures and several metrics related to user engagement. We\nintroduce several novel tasks related to predicting and understanding\ncontext-agnostic engagement in video lectures, providing preliminary baselines.\nThis is the largest and most diverse publicly available dataset to our\nknowledge that deals with such tasks. The extraction of Wikipedia topic-based\nfeatures also allows associating more sophisticated Wikipedia based features to\nthe dataset to improve the performance in these tasks. The dataset, helper\ntools and example code snippets are available publicly at\nhttps://github.com/sahanbull/context-agnostic-engagement\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:20:19 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "2011.02280", "submitter": "Luca Magri", "authors": "Nguyen Anh Khoa Doan, Wolfgang Polifke, Luca Magri", "title": "Physics-Informed Echo State Networks", "comments": "10 pages, 11 figures. arXiv admin note: substantial text overlap with\n  arXiv:1906.11122", "journal-ref": "Journal of computational science, 2020", "doi": "10.1016/j.jocs.2020.101237", "report-no": null, "categories": "cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a physics-informed Echo State Network (ESN) to predict the\nevolution of chaotic systems. Compared to conventional ESNs, the\nphysics-informed ESNs are trained to solve supervised learning tasks while\nensuring that their predictions do not violate physical laws. This is achieved\nby introducing an additional loss function during the training, which is based\non the system's governing equations. The additional loss function penalizes\nnon-physical predictions without the need of any additional training data. This\napproach is demonstrated on a chaotic Lorenz system and a truncation of the\nCharney-DeVore system. Compared to the conventional ESNs, the physics-informed\nESNs improve the predictability horizon by about two Lyapunov times. This\napproach is also shown to be robust with regard to noise. The proposed\nframework shows the potential of using machine learning combined with prior\nphysical knowledge to improve the time-accurate prediction of chaotic dynamical\nsystems.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 11:47:33 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Doan", "Nguyen Anh Khoa", ""], ["Polifke", "Wolfgang", ""], ["Magri", "Luca", ""]]}, {"id": "2011.02281", "submitter": "Sebastian Neumayer", "authors": "Johannes Hertrich and Sebastian Neumayer and Gabriele Steidl", "title": "Convolutional Proximal Neural Networks and Plug-and-Play Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce convolutional proximal neural networks (cPNNs),\nwhich are by construction averaged operators. For filters of full length, we\npropose a stochastic gradient descent algorithm on a submanifold of the Stiefel\nmanifold to train cPNNs. In case of filters with limited length, we design\nalgorithms for minimizing functionals that approximate the orthogonality\nconstraints imposed on the operators by penalizing the least squares distance\nto the identity operator. Then, we investigate how scaled cPNNs with a\nprescribed Lipschitz constant can be used for denoising signals and images,\nwhere the achieved quality depends on the Lipschitz constant. Finally, we apply\ncPNN based denoisers within a Plug-and-Play (PnP) framework and provide\nconvergence results for the corresponding PnP forward-backward splitting\nalgorithm based on an oracle construction.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:32:46 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Hertrich", "Johannes", ""], ["Neumayer", "Sebastian", ""], ["Steidl", "Gabriele", ""]]}, {"id": "2011.02282", "submitter": "McKane Andrus", "authors": "McKane Andrus, Elena Spitzer, Jeffrey Brown, Alice Xiang", "title": "\"What We Can't Measure, We Can't Understand\": Challenges to Demographic\n  Data Procurement in the Pursuit of Fairness", "comments": "13 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As calls for fair and unbiased algorithmic systems increase, so too does the\nnumber of individuals working on algorithmic fairness in industry. However,\nthese practitioners often do not have access to the demographic data they feel\nthey need to detect bias in practice. Even with the growing variety of toolkits\nand strategies for working towards algorithmic fairness, they almost invariably\nrequire access to demographic attributes or proxies. We investigated this\ndilemma through semi-structured interviews with 38 practitioners and\nprofessionals either working in or adjacent to algorithmic fairness.\nParticipants painted a complex picture of what demographic data availability\nand use look like on the ground, ranging from not having access to personal\ndata of any kind to being legally required to collect and use demographic data\nfor discrimination assessments. In many domains, demographic data collection\nraises a host of difficult questions, including how to balance privacy and\nfairness, how to define relevant social categories, how to ensure meaningful\nconsent, and whether it is appropriate for private companies to infer someone's\ndemographics. Our research suggests challenges that must be considered by\nbusinesses, regulators, researchers, and community groups in order to enable\npractitioners to address algorithmic bias in practice. Critically, we do not\npropose that the overall goal of future work should be to simply lower the\nbarriers to collecting demographic data. Rather, our study surfaces a swath of\nnormative questions about how, when, and whether this data should be procured,\nand, in cases where it is not, what should still be done to mitigate bias.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 21:06:41 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 01:18:19 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Andrus", "McKane", ""], ["Spitzer", "Elena", ""], ["Brown", "Jeffrey", ""], ["Xiang", "Alice", ""]]}, {"id": "2011.02284", "submitter": "Lena Maier-Hein", "authors": "Lena Maier-Hein, Matthias Eisenmann, Duygu Sarikaya, Keno M\\\"arz, Toby\n  Collins, Anand Malpani, Johannes Fallert, Hubertus Feussner, Stamatia\n  Giannarou, Pietro Mascagni, Hirenkumar Nakawala, Adrian Park, Carla Pugh,\n  Danail Stoyanov, Swaroop S. Vedula, Beat Peter M\\\"uller, Kevin Cleary, Gabor\n  Fichtinger, Germain Forestier, Bernard Gibaud, Teodor Grantcharov, Makoto\n  Hashizume, Hannes Kenngott, Ron Kikinis, Lars M\\\"undermann, Nassir Navab,\n  Sinan Onogur, Raphael Sznitman, Russell Taylor, Minu Dietlinde Tizabi, Martin\n  Wagner, Gregory D. Hager, Thomas Neumuth, Nicolas Padoy, Pierre Jannin,\n  Stefanie Speidel", "title": "Surgical Data Science -- from Concepts to Clinical Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent developments in data science in general and machine learning in\nparticular have transformed the way experts envision the future of surgery.\nSurgical data science is a new research field that aims to improve the quality\nof interventional healthcare through the capture, organization, analysis and\nmodeling of data. While an increasing number of data-driven approaches and\nclinical applications have been studied in the fields of radiological and\nclinical data science, translational success stories are still lacking in\nsurgery. In this publication, we shed light on the underlying reasons and\nprovide a roadmap for future advances in the field. Based on an international\nworkshop involving leading researchers in the field of surgical data science,\nwe review current practice, key achievements and initiatives as well as\navailable standards and tools for a number of topics relevant to the field,\nnamely (1) technical infrastructure for data acquisition, storage and access in\nthe presence of regulatory constraints, (2) data annotation and sharing and (3)\ndata analytics. Drawing from this extensive review, we present current\nchallenges for technology development and (4) describe a roadmap for faster\nclinical translation and exploitation of the full potential of surgical data\nscience.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:20:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Maier-Hein", "Lena", ""], ["Eisenmann", "Matthias", ""], ["Sarikaya", "Duygu", ""], ["M\u00e4rz", "Keno", ""], ["Collins", "Toby", ""], ["Malpani", "Anand", ""], ["Fallert", "Johannes", ""], ["Feussner", "Hubertus", ""], ["Giannarou", "Stamatia", ""], ["Mascagni", "Pietro", ""], ["Nakawala", "Hirenkumar", ""], ["Park", "Adrian", ""], ["Pugh", "Carla", ""], ["Stoyanov", "Danail", ""], ["Vedula", "Swaroop S.", ""], ["M\u00fcller", "Beat Peter", ""], ["Cleary", "Kevin", ""], ["Fichtinger", "Gabor", ""], ["Forestier", "Germain", ""], ["Gibaud", "Bernard", ""], ["Grantcharov", "Teodor", ""], ["Hashizume", "Makoto", ""], ["Kenngott", "Hannes", ""], ["Kikinis", "Ron", ""], ["M\u00fcndermann", "Lars", ""], ["Navab", "Nassir", ""], ["Onogur", "Sinan", ""], ["Sznitman", "Raphael", ""], ["Taylor", "Russell", ""], ["Tizabi", "Minu Dietlinde", ""], ["Wagner", "Martin", ""], ["Hager", "Gregory D.", ""], ["Neumuth", "Thomas", ""], ["Padoy", "Nicolas", ""], ["Jannin", "Pierre", ""], ["Speidel", "Stefanie", ""]]}, {"id": "2011.02287", "submitter": "Wei Xie", "authors": "Hua Zheng, Ilya O. Ryzhov, Wei Xie, and Judy Zhong", "title": "Personalized Multimorbidity Management for Patients with Type 2 Diabetes\n  Using Reinforcement Learning of Electronic Health Records", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Comorbid chronic conditions are common among people with type 2 diabetes. We\ndeveloped an Artificial Intelligence algorithm, based on Reinforcement Learning\n(RL), for personalized diabetes and multi-morbidity management with strong\npotential to improve health outcomes relative to current clinical practice. In\nthis paper, we modeled glycemia, blood pressure and cardiovascular disease\n(CVD) risk as health outcomes using a retrospective cohort of 16,665 patients\nwith type 2 diabetes from New York University Langone Health ambulatory care\nelectronic health records in 2009 to 2017. We trained a RL prescription\nalgorithm that recommends a treatment regimen optimizing patients' cumulative\nhealth outcomes using their individual characteristics and medical history at\neach encounter. The RL recommendations were evaluated on an independent subset\nof patients. The results demonstrate that the proposed personalized\nreinforcement learning prescriptive framework for type 2 diabetes yielded high\nconcordance with clinicians' prescriptions and substantial improvements in\nglycemia, blood pressure, cardiovascular disease risk outcomes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 00:58:27 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zheng", "Hua", ""], ["Ryzhov", "Ilya O.", ""], ["Xie", "Wei", ""], ["Zhong", "Judy", ""]]}, {"id": "2011.02322", "submitter": "Marcelo Zibetti", "authors": "Marcelo V. W. Zibetti and Gabor T. Herman and Ravinder R. Regatte", "title": "Fast Data-Driven Learning of MRI Sampling Pattern for Large Scale\n  Problems", "comments": "18 pages, 7 figures, 1 algorithm. Submitted to Magnetic Resonance in\n  Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: A fast data-driven optimization approach, named bias-accelerated\nsubset selection (BASS), is proposed for learning efficacious sampling patterns\n(SPs) with the purpose of reducing scan time in large-dimensional parallel MRI.\nMethods: BASS is applicable when Cartesian fully-sampled k-space data of\nspecific anatomy is available for training and the reconstruction method is\nspecified, learning which k-space points are more relevant for the specific\nanatomy and reconstruction in recovering the non-sampled points. BASS was\ntested with four reconstruction methods for parallel MRI based on low-rankness\nand sparsity that allow a free choice of the SP. Two datasets were tested, one\nof the brain images for high-resolution imaging and another of knee images for\nquantitative mapping of the cartilage. Results: BASS, with its low\ncomputational cost and fast convergence, obtained SPs 100 times faster than the\ncurrent best greedy approaches. Reconstruction quality increased up to 45\\%\nwith our learned SP over that provided by variable density and Poisson disk\nSPs, considering the same scan time. Optionally, the scan time can be nearly\nhalved without loss of reconstruction quality. Conclusion: Compared with\ncurrent approaches, BASS can be used to rapidly learn effective SPs for various\nreconstruction methods, using larger SP and larger datasets. This enables a\nbetter selection of efficacious sampling-reconstruction pairs for specific MRI\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:42:41 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zibetti", "Marcelo V. W.", ""], ["Herman", "Gabor T.", ""], ["Regatte", "Ravinder R.", ""]]}, {"id": "2011.02323", "submitter": "Kumar Shridhar", "authors": "Kushal Jain, Adwait Deshpande, Kumar Shridhar, Felix Laumann, Ayushman\n  Dash", "title": "Indic-Transformers: An Analysis of Transformer Language Models for\n  Indian Languages", "comments": "Accepted at ML-RSA @ NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language models based on the Transformer architecture have achieved\nstate-of-the-art performance on a wide range of NLP tasks such as text\nclassification, question-answering, and token classification. However, this\nperformance is usually tested and reported on high-resource languages, like\nEnglish, French, Spanish, and German. Indian languages, on the other hand, are\nunderrepresented in such benchmarks. Despite some Indian languages being\nincluded in training multilingual Transformer models, they have not been the\nprimary focus of such work. In order to evaluate the performance on Indian\nlanguages specifically, we analyze these language models through extensive\nexperiments on multiple downstream tasks in Hindi, Bengali, and Telugu\nlanguage. Here, we compare the efficacy of fine-tuning model parameters of\npre-trained models against that of training a language model from scratch.\nMoreover, we empirically argue against the strict dependency between the\ndataset size and model performance, but rather encourage task-specific model\nand method selection. We achieve state-of-the-art performance on Hindi and\nBengali languages for text classification task. Finally, we present effective\nstrategies for handling the modeling of Indian languages and we release our\nmodel checkpoints for the community :\nhttps://huggingface.co/neuralspace-reverie.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:43:43 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Jain", "Kushal", ""], ["Deshpande", "Adwait", ""], ["Shridhar", "Kumar", ""], ["Laumann", "Felix", ""], ["Dash", "Ayushman", ""]]}, {"id": "2011.02327", "submitter": "Huaizheng Zhang", "authors": "Huaizheng Zhang, Yizheng Huang, Yonggang Wen, Jianxiong Yin and Kyle\n  Guan", "title": "InferBench: Understanding Deep Learning Inference Serving with an\n  Automatic Benchmarking System", "comments": "13 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) models have become core modules for many applications.\nHowever, deploying these models without careful performance benchmarking that\nconsiders both hardware and software's impact often leads to poor service and\ncostly operational expenditure. To facilitate DL models' deployment, we\nimplement an automatic and comprehensive benchmark system for DL developers. To\naccomplish benchmark-related tasks, the developers only need to prepare a\nconfiguration file consisting of a few lines of code. Our system, deployed to a\nleader server in DL clusters, will dispatch users' benchmark jobs to follower\nworkers. Next, the corresponding requests, workload, and even models can be\ngenerated automatically by the system to conduct DL serving benchmarks.\nFinally, developers can leverage many analysis tools and models in our system\nto gain insights into the trade-offs of different system configurations. In\naddition, a two-tier scheduler is incorporated to avoid unnecessary\ninterference and improve average job compilation time by up to 1.43x\n(equivalent of 30\\% reduction). Our system design follows the best practice in\nDL clusters operations to expedite day-to-day DL service evaluation efforts by\nthe developers. We conduct many benchmark experiments to provide in-depth and\ncomprehensive evaluations. We believe these results are of great values as\nguidelines for DL service configuration and resource allocation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:56:57 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 03:21:32 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 05:08:16 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Zhang", "Huaizheng", ""], ["Huang", "Yizheng", ""], ["Wen", "Yonggang", ""], ["Yin", "Jianxiong", ""], ["Guan", "Kyle", ""]]}, {"id": "2011.02329", "submitter": "Shlomo Chazan", "authors": "Shlomo E. Chazan, Lior Wolf, Eliya Nachmani, Yossi Adi", "title": "Single channel voice separation for unknown number of speakers under\n  reverberant and noisy settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified network for voice separation of an unknown number of\nspeakers. The proposed approach is composed of several separation heads\noptimized together with a speaker classification branch. The separation is\ncarried out in the time domain, together with parameter sharing between all\nseparation heads. The classification branch estimates the number of speakers\nwhile each head is specialized in separating a different number of speakers. We\nevaluate the proposed model under both clean and noisy reverberant set-tings.\nResults suggest that the proposed approach is superior to the baseline model by\na significant margin. Additionally, we present a new noisy and reverberant\ndataset of up to five different speakers speaking simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 14:59:14 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Chazan", "Shlomo E.", ""], ["Wolf", "Lior", ""], ["Nachmani", "Eliya", ""], ["Adi", "Yossi", ""]]}, {"id": "2011.02336", "submitter": "Kunjin Chen", "authors": "Kunjin Chen, Tom\\'a\\v{s} Vantuch, Yu Zhang, Jun Hu, Jinliang He", "title": "Fault Detection for Covered Conductors With High-Frequency Voltage\n  Signals: From Local Patterns to Global Features", "comments": "To be published in IEEE Transactions on Smart Grid", "journal-ref": null, "doi": "10.1109/TSG.2020.3032527", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection and characterization of partial discharge (PD) are crucial for\nthe insulation diagnosis of overhead lines with covered conductors. With the\nrelease of a large dataset containing thousands of naturally obtained\nhigh-frequency voltage signals, data-driven analysis of fault-related PD\npatterns on an unprecedented scale becomes viable. The high diversity of PD\npatterns and background noise interferences motivates us to design an\ninnovative pulse shape characterization method based on clustering techniques,\nwhich can dynamically identify a set of representative PD-related pulses.\nCapitalizing on those pulses as referential patterns, we construct insightful\nfeatures and develop a novel machine learning model with a superior detection\nperformance for early-stage covered conductor faults. The presented model\noutperforms the winning model in a Kaggle competition and provides the\nstate-of-the-art solution to detect real-time disturbances in the field.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 02:58:19 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Chen", "Kunjin", ""], ["Vantuch", "Tom\u00e1\u0161", ""], ["Zhang", "Yu", ""], ["Hu", "Jun", ""], ["He", "Jinliang", ""]]}, {"id": "2011.02367", "submitter": "Jihong Park", "authors": "Hyowoon Seo, Jihong Park, Seungeun Oh, Mehdi Bennis, Seong-Lyun Kim", "title": "Federated Knowledge Distillation", "comments": "30 pages, 12 figures, 2 tables; This chapter is written for the\n  forthcoming book, Machine Learning and Wireless Communications (Cambridge\n  University Press), edited by H. V. Poor, D. Gunduz, A. Goldsmith, and Y.\n  Eldar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning frameworks often rely on exchanging model parameters\nacross workers, instead of revealing their raw data. A prime example is\nfederated learning that exchanges the gradients or weights of each neural\nnetwork model. Under limited communication resources, however, such a method\nbecomes extremely costly particularly for modern deep neural networks having a\nhuge number of model parameters. In this regard, federated distillation (FD) is\na compelling distributed learning solution that only exchanges the model\noutputs whose dimensions are commonly much smaller than the model sizes (e.g.,\n10 labels in the MNIST dataset). The goal of this chapter is to provide a deep\nunderstanding of FD while demonstrating its communication efficiency and\napplicability to a variety of tasks. To this end, towards demystifying the\noperational principle of FD, the first part of this chapter provides a novel\nasymptotic analysis for two foundational algorithms of FD, namely knowledge\ndistillation (KD) and co-distillation (CD), by exploiting the theory of neural\ntangent kernel (NTK). Next, the second part elaborates on a baseline\nimplementation of FD for a classification task, and illustrates its performance\nin terms of accuracy and communication efficiency compared to FL. Lastly, to\ndemonstrate the applicability of FD to various distributed learning tasks and\nenvironments, the third part presents two selected applications, namely FD over\nasymmetric uplink-and-downlink wireless channels and FD for reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 15:56:13 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Seo", "Hyowoon", ""], ["Park", "Jihong", ""], ["Oh", "Seungeun", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "2011.02389", "submitter": "Kakeru Mitsuno", "authors": "Kakeru Mitsuno and Takio Kurita", "title": "Filter Pruning using Hierarchical Group Sparse Regularization for Deep\n  Convolutional Neural Networks", "comments": "Accepted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the convolutional neural networks are often trained with redundant\nparameters, it is possible to reduce redundant kernels or filters to obtain a\ncompact network without dropping the classification accuracy. In this paper, we\npropose a filter pruning method using the hierarchical group sparse\nregularization. It is shown in our previous work that the hierarchical group\nsparse regularization is effective in obtaining sparse networks in which\nfilters connected to unnecessary channels are automatically close to zero.\nAfter training the convolutional neural network with the hierarchical group\nsparse regularization, the unnecessary filters are selected based on the\nincrease of the classification loss of the randomly selected training samples\nto obtain a compact network. It is shown that the proposed method can reduce\nmore than 50% parameters of ResNet for CIFAR-10 with only 0.3% decrease in the\naccuracy of test samples. Also, 34% parameters of ResNet are reduced for\nTinyImageNet-200 with higher accuracy than the baseline network.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:29:41 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Mitsuno", "Kakeru", ""], ["Kurita", "Takio", ""]]}, {"id": "2011.02390", "submitter": "Kakeru Mitsuno", "authors": "Kakeru Mitsuno, Yuichiro Nomura and Takio Kurita", "title": "Channel Planting for Deep Neural Networks using Knowledge Distillation", "comments": "Accepted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deeper and wider neural networks have shown excellent\nperformance in computer vision tasks, while their enormous amount of parameters\nresults in increased computational cost and overfitting. Several methods have\nbeen proposed to compress the size of the networks without reducing network\nperformance. Network pruning can reduce redundant and unnecessary parameters\nfrom a network. Knowledge distillation can transfer the knowledge of deeper and\nwider networks to smaller networks. The performance of the smaller network\nobtained by these methods is bounded by the predefined network. Neural\narchitecture search has been proposed, which can search automatically the\narchitecture of the networks to break the structure limitation. Also, there is\na dynamic configuration method to train networks incrementally as sub-networks.\nIn this paper, we present a novel incremental training algorithm for deep\nneural networks called planting. Our planting can search the optimal network\narchitecture with smaller number of parameters for improving the network\nperformance by augmenting channels incrementally to layers of the initial\nnetworks while keeping the earlier trained parameters fixed. Also, we propose\nusing the knowledge distillation method for training the channels planted. By\ntransferring the knowledge of deeper and wider networks, we can grow the\nnetworks effectively and efficiently. We evaluate the effectiveness of the\nproposed method on different datasets such as CIFAR-10/100 and STL-10. For the\nSTL-10 dataset, we show that we are able to achieve comparable performance with\nonly 7% parameters compared to the larger network and reduce the overfitting\ncaused by a small amount of the data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:29:59 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Mitsuno", "Kakeru", ""], ["Nomura", "Yuichiro", ""], ["Kurita", "Takio", ""]]}, {"id": "2011.02396", "submitter": "Zhenhuan(Neyo) Yang", "authors": "Zhenhuan Yang, Baojian Zhou, Yunwen Lei, Yiming Ying", "title": "Stochastic Hard Thresholding Algorithms for AUC Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to develop stochastic hard thresholding algorithms for\nthe important problem of AUC maximization in imbalanced classification. The\nmain challenge is the pairwise loss involved in AUC maximization. We overcome\nthis obstacle by reformulating the U-statistics objective function as an\nempirical risk minimization (ERM), from which a stochastic hard thresholding\nalgorithm (\\texttt{SHT-AUC}) is developed. To our best knowledge, this is the\nfirst attempt to provide stochastic hard thresholding algorithms for AUC\nmaximization with a per-iteration cost $\\O(b d)$ where $d$ and $b$ are the\ndimension of the data and the minibatch size, respectively. We show that the\nproposed algorithm enjoys the linear convergence rate up to a tolerance error.\nIn particular, we show, if the data is generated from the Gaussian\ndistribution, then its convergence becomes slower as the data gets more\nimbalanced. We conduct extensive experiments to show the efficiency and\neffectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:49:29 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Yang", "Zhenhuan", ""], ["Zhou", "Baojian", ""], ["Lei", "Yunwen", ""], ["Ying", "Yiming", ""]]}, {"id": "2011.02402", "submitter": "Youssef Mroueh", "authors": "Youssef Mroueh, Truyen Nguyen", "title": "On the Convergence of Gradient Descent in GANs: MMD GAN As a Gradient\n  Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the maximum mean discrepancy ($\\mathrm{MMD}$) GAN problem and\npropose a parametric kernelized gradient flow that mimics the min-max game in\ngradient regularized $\\mathrm{MMD}$ GAN. We show that this flow provides a\ndescent direction minimizing the $\\mathrm{MMD}$ on a statistical manifold of\nprobability distributions. We then derive an explicit condition which ensures\nthat gradient descent on the parameter space of the generator in gradient\nregularized $\\mathrm{MMD}$ GAN is globally convergent to the target\ndistribution. Under this condition, we give non asymptotic convergence results\nof gradient descent in MMD GAN. Another contribution of this paper is the\nintroduction of a dynamic formulation of a regularization of $\\mathrm{MMD}$ and\ndemonstrating that the parametric kernelized descent for $\\mathrm{MMD}$ is the\ngradient flow of this functional with respect to the new Riemannian structure.\nOur obtained theoretical result allows ones to treat gradient flows for quite\ngeneral functionals and thus has potential applications to other types of\nvariational inferences on a statistical manifold beyond GANs. Finally,\nnumerical experiments suggest that our parametric kernelized gradient flow\nstabilizes GAN training and guarantees convergence.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:55:00 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Mroueh", "Youssef", ""], ["Nguyen", "Truyen", ""]]}, {"id": "2011.02403", "submitter": "Xiaosong Jia", "authors": "Xiaosong Jia, Liting Sun, Masayoshi Tomizuka, Wei Zhan", "title": "IDE-Net: Interactive Driving Event and Pattern Extraction from Human\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) need to share the road with multiple, heterogeneous\nroad users in a variety of driving scenarios. It is overwhelming and\nunnecessary to carefully interact with all observed agents, and AVs need to\ndetermine whether and when to interact with each surrounding agent. In order to\nfacilitate the design and testing of prediction and planning modules of AVs,\nin-depth understanding of interactive behavior is expected with proper\nrepresentation, and events in behavior data need to be extracted and\ncategorized automatically. Answers to what are the essential patterns of\ninteractions are also crucial for these motivations in addition to answering\nwhether and when. Thus, learning to extract interactive driving events and\npatterns from human data for tackling the whether-when-what tasks is of\ncritical importance for AVs. There is, however, no clear definition and\ntaxonomy of interactive behavior, and most of the existing works are based on\neither manual labelling or hand-crafted rules and features. In this paper, we\npropose the Interactive Driving event and pattern Extraction Network (IDE-Net),\nwhich is a deep learning framework to automatically extract interaction events\nand patterns directly from vehicle trajectories. In IDE-Net, we leverage the\npower of multi-task learning and proposed three auxiliary tasks to assist the\npattern extraction in an unsupervised fashion. We also design a unique\nspatial-temporal block to encode the trajectory data. Experimental results on\nthe INTERACTION dataset verified the effectiveness of such designs in terms of\nbetter generalizability and effective pattern extraction. We find three\ninterpretable patterns of interactions, bringing insights for driver behavior\nrepresentation, modeling and comprehension. Both objective and subjective\nevaluation metrics are adopted in our analysis of the learned patterns.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:56:12 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Jia", "Xiaosong", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""], ["Zhan", "Wei", ""]]}, {"id": "2011.02407", "submitter": "Jiahao Chen", "authors": "Ashrya Agrawal and Florian Pfisterer and Bernd Bischl and Francois\n  Buet-Golfouse and Srijan Sood and Jiahao Chen and Sameena Shah and Sebastian\n  Vollmer", "title": "Debiasing classifiers: is reality at variance with expectation?", "comments": "13 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical study of debiasing methods for classifiers, showing\nthat debiasers often fail in practice to generalize out-of-sample, and can in\nfact make fairness worse rather than better. A rigorous evaluation of the\ndebiasing treatment effect requires extensive cross-validation beyond what is\nusually done. We demonstrate that this phenomenon can be explained as a\nconsequence of bias-variance trade-off, with an increase in variance\nnecessitated by imposing a fairness constraint. Follow-up experiments validate\nthe theoretical prediction that the estimation variance depends strongly on the\nbase rates of the protected class. Considering fairness--performance trade-offs\njustifies the counterintuitive notion that partial debiasing can actually yield\nbetter results in practice on out-of-sample data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:00:54 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 00:06:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Agrawal", "Ashrya", ""], ["Pfisterer", "Florian", ""], ["Bischl", "Bernd", ""], ["Buet-Golfouse", "Francois", ""], ["Sood", "Srijan", ""], ["Chen", "Jiahao", ""], ["Shah", "Sameena", ""], ["Vollmer", "Sebastian", ""]]}, {"id": "2011.02408", "submitter": "Manuel Nonnenmacher", "authors": "Manuel Nonnenmacher, David Reeb, Ingo Steinwart", "title": "Which Minimizer Does My Neural Network Converge To?", "comments": "27 pages incl. appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss surface of an overparameterized neural network (NN) possesses many\nglobal minima of zero training error. We explain how common variants of the\nstandard NN training procedure change the minimizer obtained. First, we make\nexplicit how the size of the initialization of a strongly overparameterized NN\naffects the minimizer and can deteriorate its final test performance. We\npropose a strategy to limit this effect. Then, we demonstrate that for adaptive\noptimization such as AdaGrad, the obtained minimizer generally differs from the\ngradient descent (GD) minimizer. This adaptive minimizer is changed further by\nstochastic mini-batch training, even though in the non-adaptive case GD and\nstochastic GD result in essentially the same minimizer. Lastly, we explain that\nthese effects remain relevant for less overparameterized NNs. While\noverparameterization has its benefits, our work highlights that it induces\nsources of error absent from underparameterized models, some of which can be\nchallenging to control.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:04:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Nonnenmacher", "Manuel", ""], ["Reeb", "David", ""], ["Steinwart", "Ingo", ""]]}, {"id": "2011.02415", "submitter": "Maysum Panju", "authors": "Maysum Panju, Ali Ghodsi", "title": "A Neuro-Symbolic Method for Solving Differential and Functional\n  Equations", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When neural networks are used to solve differential equations, they usually\nproduce solutions in the form of black-box functions that are not directly\nmathematically interpretable. We introduce a method for generating symbolic\nexpressions to solve differential equations while leveraging deep learning\ntraining methods. Unlike existing methods, our system does not require learning\na language model over symbolic mathematics, making it scalable, compact, and\neasily adaptable for a variety of tasks and configurations. As part of the\nmethod, we propose a novel neural architecture for learning mathematical\nexpressions to optimize a customizable objective. The system is designed to\nalways return a valid symbolic formula, generating a useful approximation when\nan exact analytic solution to a differential equation is not or cannot be\nfound. We demonstrate through examples how our method can be applied on a\nnumber of differential equations, often obtaining symbolic approximations that\nare useful or insightful. Furthermore, we show how the system can be\neffortlessly generalized to find symbolic solutions to other mathematical\ntasks, including integration and functional equations.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:13:25 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Panju", "Maysum", ""], ["Ghodsi", "Ali", ""]]}, {"id": "2011.02417", "submitter": "Tristan Thrush", "authors": "Tristan Thrush, Ethan Wilcox, and Roger Levy", "title": "Investigating Novel Verb Learning in BERT: Selectional Preference\n  Classes and Alternation-Based Syntactic Generalization", "comments": "Accepted to BlackboxNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies investigating the syntactic abilities of deep learning\nmodels have not targeted the relationship between the strength of the\ngrammatical generalization and the amount of evidence to which the model is\nexposed during training. We address this issue by deploying a novel\nword-learning paradigm to test BERT's few-shot learning capabilities for two\naspects of English verbs: alternations and classes of selectional preferences.\nFor the former, we fine-tune BERT on a single frame in a verbal-alternation\npair and ask whether the model expects the novel verb to occur in its sister\nframe. For the latter, we fine-tune BERT on an incomplete selectional network\nof verbal objects and ask whether it expects unattested but plausible\nverb/object pairs. We find that BERT makes robust grammatical generalizations\nafter just one or two instances of a novel word in fine-tuning. For the verbal\nalternation tests, we find that the model displays behavior that is consistent\nwith a transitivity bias: verbs seen few times are expected to take direct\nobjects, but verbs seen with direct objects are not expected to occur\nintransitively.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:17:49 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Thrush", "Tristan", ""], ["Wilcox", "Ethan", ""], ["Levy", "Roger", ""]]}, {"id": "2011.02426", "submitter": "Subramanyam Natarajan", "authors": "Arvind Srinivasan, Aprameya Bharadwaj, Aveek Saha, Subramanyam\n  Natarajan", "title": "Graph Based Temporal Aggregation for Video Retrieval", "comments": "6 pages, 6 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale video retrieval is a field of study with a lot of ongoing\nresearch. Most of the work in the field is on video retrieval through text\nqueries using techniques such as VSE++. However, there is little research done\non video retrieval through image queries, and the work that has been done in\nthis field either uses image queries from within the video dataset or iterates\nthrough videos frame by frame. These approaches are not generalized for queries\nfrom outside the dataset and do not scale well for large video datasets. To\novercome these issues, we propose a new approach for video retrieval through\nimage queries where an undirected graph is constructed from the combined set of\nframes from all videos to be searched. The node features of this graph are used\nin the task of video retrieval. Experimentation is done on the MSR-VTT dataset\nby using query images from outside the dataset. To evaluate this novel approach\nP@5, P@10 and P@20 metrics are calculated. Two different ResNet models namely,\nResNet-152 and ResNet-50 are used in this study.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:23:14 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Srinivasan", "Arvind", ""], ["Bharadwaj", "Aprameya", ""], ["Saha", "Aveek", ""], ["Natarajan", "Subramanyam", ""]]}, {"id": "2011.02436", "submitter": "Ramesh Ragala", "authors": "Ramesh Ragala and Bharadwaja kumar", "title": "Rank Based Pseudoinverse Computation in Extreme Learning Machine for\n  Large Datasets", "comments": null, "journal-ref": "International Journal of Innovative Technology and Exploring\n  Engineering 10(2019) 1341-1346", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme Learning Machine (ELM) is an efficient and effective\nleast-square-based learning algorithm for classification, regression problems\nbased on single hidden layer feed-forward neural network (SLFN). It has been\nshown in the literature that it has faster convergence and good generalization\nability for moderate datasets. But, there is great deal of challenge involved\nin computing the pseudoinverse when there are large numbers of hidden nodes or\nfor large number of instances to train complex pattern recognition problems. To\naddress this problem, a few approaches such as EM-ELM, DF-ELM have been\nproposed in the literature. In this paper, a new rank-based matrix\ndecomposition of the hidden layer matrix is introduced to have the optimal\ntraining time and reduce the computational complexity for a large number of\nhidden nodes in the hidden layer. The results show that it has constant\ntraining time which is closer towards the minimal training time and very far\nfrom worst-case training time of the DF-ELM algorithm that has been shown\nefficient in the recent literature.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:34:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ragala", "Ramesh", ""], ["kumar", "Bharadwaja", ""]]}, {"id": "2011.02462", "submitter": "Jialiang Zhao", "authors": "Jialiang Zhao, Daniel Troniak, Oliver Kroemer", "title": "Towards Robotic Assembly by Predicting Robust, Precise and Task-oriented\n  Grasps", "comments": "Submitted and accepted to 4th Conference on Robot Learning (CoRL2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust task-oriented grasp planning is vital for autonomous robotic precision\nassembly tasks. Knowledge of the objects' geometry and preconditions of the\ntarget task should be incorporated when determining the proper grasp to\nexecute. However, several factors contribute to the challenges of realizing\nthese grasps such as noise when controlling the robot, unknown object\nproperties, and difficulties modeling complex object-object interactions. We\npropose a method that decomposes this problem and optimizes for grasp\nrobustness, precision, and task performance by learning three cascaded\nnetworks. We evaluate our method in simulation on three common assembly tasks:\ninserting gears onto pegs, aligning brackets into corners, and inserting shapes\ninto slots. Our policies are trained using a curriculum based on large-scale\nself-supervised grasp simulations with procedurally generated objects. Finally,\nwe evaluate the performance of the first two tasks with a real robot where our\nmethod achieves 4.28mm error for bracket insertion and 1.44mm error for gear\ninsertion.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 18:29:01 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zhao", "Jialiang", ""], ["Troniak", "Daniel", ""], ["Kroemer", "Oliver", ""]]}, {"id": "2011.02466", "submitter": "Zhao Song", "authors": "Josh Alman, Timothy Chu, Aaron Schild, Zhao Song", "title": "Algorithms and Hardness for Linear Algebra on Geometric Graphs", "comments": "FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  For a function $\\mathsf{K} : \\mathbb{R}^{d} \\times \\mathbb{R}^{d} \\to\n\\mathbb{R}_{\\geq 0}$, and a set $P = \\{ x_1, \\ldots, x_n\\} \\subset\n\\mathbb{R}^d$ of $n$ points, the $\\mathsf{K}$ graph $G_P$ of $P$ is the\ncomplete graph on $n$ nodes where the weight between nodes $i$ and $j$ is given\nby $\\mathsf{K}(x_i, x_j)$. In this paper, we initiate the study of when\nefficient spectral graph theory is possible on these graphs. We investigate\nwhether or not it is possible to solve the following problems in $n^{1+o(1)}$\ntime for a $\\mathsf{K}$-graph $G_P$ when $d < n^{o(1)}$:\n  $\\bullet$ Multiply a given vector by the adjacency matrix or Laplacian matrix\nof $G_P$\n  $\\bullet$ Find a spectral sparsifier of $G_P$\n  $\\bullet$ Solve a Laplacian system in $G_P$'s Laplacian matrix\n  For each of these problems, we consider all functions of the form\n$\\mathsf{K}(u,v) = f(\\|u-v\\|_2^2)$ for a function $f:\\mathbb{R} \\rightarrow\n\\mathbb{R}$. We provide algorithms and comparable hardness results for many\nsuch $\\mathsf{K}$, including the Gaussian kernel, Neural tangent kernels, and\nmore. For example, in dimension $d = \\Omega(\\log n)$, we show that there is a\nparameter associated with the function $f$ for which low parameter values imply\n$n^{1+o(1)}$ time algorithms for all three of these problems and high parameter\nvalues imply the nonexistence of subquadratic time algorithms assuming Strong\nExponential Time Hypothesis ($\\mathsf{SETH}$), given natural assumptions on\n$f$.\n  As part of our results, we also show that the exponential dependence on the\ndimension $d$ in the celebrated fast multipole method of Greengard and Rokhlin\ncannot be improved, assuming $\\mathsf{SETH}$, for a broad class of functions\n$f$. To the best of our knowledge, this is the first formal limitation proven\nabout fast multipole methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 18:35:02 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Alman", "Josh", ""], ["Chu", "Timothy", ""], ["Schild", "Aaron", ""], ["Song", "Zhao", ""]]}, {"id": "2011.02511", "submitter": "Carolin Lawrence", "authors": "Julia Kreutzer, Stefan Riezler, Carolin Lawrence", "title": "Offline Reinforcement Learning from Human Feedback in Real-World\n  Sequence-to-Sequence Tasks", "comments": "5th Workshop on Structured Prediction for NLP at ACL 2021 Previously\n  named \"Learning from Human Feedback: Challenges for Real-World Reinforcement\n  Learning in NLP\" and presented at Challenges of Real-World RL Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large volumes of interaction logs can be collected from NLP systems that are\ndeployed in the real world. How can this wealth of information be leveraged?\nUsing such interaction logs in an offline reinforcement learning (RL) setting\nis a promising approach. However, due to the nature of NLP tasks and the\nconstraints of production systems, a series of challenges arise. We present a\nconcise overview of these challenges and discuss possible solutions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 19:30:46 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 21:27:22 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 07:23:44 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kreutzer", "Julia", ""], ["Riezler", "Stefan", ""], ["Lawrence", "Carolin", ""]]}, {"id": "2011.02521", "submitter": "Yongxin Chen", "authors": "Qinsheng Zhang, Rahul Singh, Yongxin Chen", "title": "Filtering for Aggregate Hidden Markov Models with Continuous\n  Observations", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.SY eess.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of filtering problems for large populations where each\nindividual is modeled by the same hidden Markov model (HMM). In this paper, we\nfocus on aggregate inference problems in HMMs with discrete state space and\ncontinuous observation space. The continuous observations are aggregated in a\nway such that the individuals are indistinguishable from measurements. We\npropose an aggregate inference algorithm called continuous observation\ncollective forward-backward algorithm. It extends the recently proposed\ncollective forward-backward algorithm for aggregate inference in HMMs with\ndiscrete observations to the case of continuous observations. The efficacy of\nthis algorithm is illustrated through several numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 20:05:36 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 04:35:35 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zhang", "Qinsheng", ""], ["Singh", "Rahul", ""], ["Chen", "Yongxin", ""]]}, {"id": "2011.02522", "submitter": "Anuran Makur", "authors": "Ali Jadbabaie and Anuran Makur and Devavrat Shah", "title": "Gradient-Based Empirical Risk Minimization using Local Polynomial\n  Regression", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of empirical risk minimization (ERM)\nof smooth, strongly convex loss functions using iterative gradient-based\nmethods. A major goal of this literature has been to compare different\nalgorithms, such as gradient descent (GD) or stochastic gradient descent (SGD),\nby analyzing their rates of convergence to $\\epsilon$-approximate solutions.\nFor example, the oracle complexity of GD is $O(n\\log(\\epsilon^{-1}))$, where\n$n$ is the number of training samples. When $n$ is large, this can be expensive\nin practice, and SGD is preferred due to its oracle complexity of\n$O(\\epsilon^{-1})$. Such standard analyses only utilize the smoothness of the\nloss function in the parameter being optimized. In contrast, we demonstrate\nthat when the loss function is smooth in the data, we can learn the oracle at\nevery iteration and beat the oracle complexities of both GD and SGD in\nimportant regimes. Specifically, at every iteration, our proposed algorithm\nperforms local polynomial regression to learn the gradient of the loss\nfunction, and then estimates the true gradient of the ERM objective function.\nWe establish that the oracle complexity of our algorithm scales like\n$\\tilde{O}((p \\epsilon^{-1})^{d/(2\\eta)})$ (neglecting sub-dominant factors),\nwhere $d$ and $p$ are the data and parameter space dimensions, respectively,\nand the gradient of the loss function belongs to a $\\eta$-H\\\"{o}lder class with\nrespect to the data. Our proof extends the analysis of local polynomial\nregression in non-parametric statistics to provide interpolation guarantees in\nmultivariate settings, and also exploits tools from the inexact GD literature.\nUnlike GD and SGD, the complexity of our method depends on $d$ and $p$.\nHowever, when $d$ is small and the loss function exhibits modest smoothness in\nthe data, our algorithm beats GD and SGD in oracle complexity for a very broad\nrange of $p$ and $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 20:10:31 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Jadbabaie", "Ali", ""], ["Makur", "Anuran", ""], ["Shah", "Devavrat", ""]]}, {"id": "2011.02526", "submitter": "Hao Fu", "authors": "Hao Fu, Akshaj Kumar Veldanda, Prashanth Krishnamurthy, Siddharth\n  Garg, and Farshad Khorrami", "title": "Detecting Backdoors in Neural Networks Using Novel Feature-Based Anomaly\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new defense against neural network backdooring attacks\nthat are maliciously trained to mispredict in the presence of attacker-chosen\ntriggers. Our defense is based on the intuition that the feature extraction\nlayers of a backdoored network embed new features to detect the presence of a\ntrigger and the subsequent classification layers learn to mispredict when\ntriggers are detected. Therefore, to detect backdoors, the proposed defense\nuses two synergistic anomaly detectors trained on clean validation data: the\nfirst is a novelty detector that checks for anomalous features, while the\nsecond detects anomalous mappings from features to outputs by comparing with a\nseparate classifier trained on validation data. The approach is evaluated on a\nwide range of backdoored networks (with multiple variations of triggers) that\nsuccessfully evade state-of-the-art defenses. Additionally, we evaluate the\nrobustness of our approach on imperceptible perturbations, scalability on\nlarge-scale datasets, and effectiveness under domain shift. This paper also\nshows that the defense can be further improved using data augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 20:33:51 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Fu", "Hao", ""], ["Veldanda", "Akshaj Kumar", ""], ["Krishnamurthy", "Prashanth", ""], ["Garg", "Siddharth", ""], ["Khorrami", "Farshad", ""]]}, {"id": "2011.02538", "submitter": "Jingfeng Wu", "authors": "Jingfeng Wu, Difan Zou, Vladimir Braverman, Quanquan Gu", "title": "Direction Matters: On the Implicit Bias of Stochastic Gradient Descent\n  with Moderate Learning Rate", "comments": "ICLR 2021 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the algorithmic bias of \\emph{stochastic gradient descent}\n(SGD) is one of the key challenges in modern machine learning and deep learning\ntheory. Most of the existing works, however, focus on \\emph{very small or even\ninfinitesimal} learning rate regime, and fail to cover practical scenarios\nwhere the learning rate is \\emph{moderate and annealing}. In this paper, we\nmake an initial attempt to characterize the particular regularization effect of\nSGD in the moderate learning rate regime by studying its behavior for\noptimizing an overparameterized linear regression problem. In this case, SGD\nand GD are known to converge to the unique minimum-norm solution; however, with\nthe moderate and annealing learning rate, we show that they exhibit different\n\\emph{directional bias}: SGD converges along the large eigenvalue directions of\nthe data matrix, while GD goes after the small eigenvalue directions.\nFurthermore, we show that such directional bias does matter when early stopping\nis adopted, where the SGD output is nearly optimal but the GD output is\nsuboptimal. Finally, our theory explains several folk arts in practice used for\nSGD hyperparameter tuning, such as (1) linearly scaling the initial learning\nrate with batch size; and (2) overrunning SGD with high learning rate even when\nthe loss stops decreasing.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:07:52 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 17:24:24 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wu", "Jingfeng", ""], ["Zou", "Difan", ""], ["Braverman", "Vladimir", ""], ["Gu", "Quanquan", ""]]}, {"id": "2011.02551", "submitter": "Rohit Batra", "authors": "Rohit Batra, Hanjun Dai, Tran Doan Huan, Lihua Chen, Chiho Kim, Will\n  R. Gutekunst, Le Song, Rampi Ramprasad", "title": "Polymers for Extreme Conditions Designed Using Syntax-Directed\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design/discovery of new materials is highly non-trivial owing to the\nnear-infinite possibilities of material candidates, and multiple required\nproperty/performance objectives. Thus, machine learning tools are now commonly\nemployed to virtually screen material candidates with desired properties by\nlearning a theoretical mapping from material-to-property space, referred to as\nthe \\emph{forward} problem. However, this approach is inefficient, and severely\nconstrained by the candidates that human imagination can conceive. Thus, in\nthis work on polymers, we tackle the materials discovery challenge by solving\nthe \\emph{inverse} problem: directly generating candidates that satisfy desired\nproperty/performance objectives. We utilize syntax-directed variational\nautoencoders (VAE) in tandem with Gaussian process regression (GPR) models to\ndiscover polymers expected to be robust under three extreme conditions: (1)\nhigh temperatures, (2) high electric field, and (3) high temperature \\emph{and}\nhigh electric field, useful for critical structural, electrical and energy\nstorage applications. This approach to learn from (and augment) human ingenuity\nis general, and can be extended to discover polymers with other targeted\nproperties and performance measures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:36:59 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Batra", "Rohit", ""], ["Dai", "Hanjun", ""], ["Huan", "Tran Doan", ""], ["Chen", "Lihua", ""], ["Kim", "Chiho", ""], ["Gutekunst", "Will R.", ""], ["Song", "Le", ""], ["Ramprasad", "Rampi", ""]]}, {"id": "2011.02552", "submitter": "Fabrizio Sebastiani", "authors": "Alejandro Moreo and Fabrizio Sebastiani", "title": "Re-Assessing the \"Classify and Count\" Quantification Method", "comments": "This is the final version of the paper, identical to the one that is\n  going to appear on the Proceedings of the 43rd European Conference on\n  Information Retrieval (ECIR 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Learning to quantify (a.k.a.\\ quantification) is a task concerned with\ntraining unbiased estimators of class prevalence via supervised learning. This\ntask originated with the observation that \"Classify and Count\" (CC), the\ntrivial method of obtaining class prevalence estimates, is often a biased\nestimator, and thus delivers suboptimal quantification accuracy; following this\nobservation, several methods for learning to quantify have been proposed that\nhave been shown to outperform CC. In this work we contend that previous works\nhave failed to use properly optimised versions of CC. We thus reassess the real\nmerits of CC (and its variants), and argue that, while still inferior to some\ncutting-edge methods, they deliver near-state-of-the-art accuracy once (a)\nhyperparameter optimisation is performed, and (b) this optimisation is\nperformed by using a true quantification loss instead of a standard\nclassification-based loss. Experiments on three publicly available binary\nsentiment classification datasets support these conclusions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:47:39 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 17:32:23 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "2011.02553", "submitter": "Yuanxin Zhong", "authors": "Yuanxin Zhong, Minghan Zhu and Huei Peng", "title": "Uncertainty-Aware Voxel based 3D Object Detection and Tracking with\n  von-Mises Loss", "comments": "Submitted to ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection and tracking is a key task in autonomy. Specifically, 3D\nobject detection and tracking have been an emerging hot topic recently.\nAlthough various methods have been proposed for object detection, uncertainty\nin the 3D detection and tracking tasks has been less explored. Uncertainty\nhelps us tackle the error in the perception system and improve robustness. In\nthis paper, we propose a method for improving target tracking performance by\nadding uncertainty regression to the SECOND detector, which is one of the most\nrepresentative algorithms of 3D object detection. Our method estimates\npositional and dimensional uncertainties with Gaussian Negative Log-Likelihood\n(NLL) Loss for estimation and introduces von-Mises NLL Loss for angular\nuncertainty estimation. We fed the uncertainty output into a classical object\ntracking framework and proved that our method increased the tracking\nperformance compared against the vanilla tracker with constant covariance\nassumption.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:53:31 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Zhong", "Yuanxin", ""], ["Zhu", "Minghan", ""], ["Peng", "Huei", ""]]}, {"id": "2011.02556", "submitter": "Saeed Kargar", "authors": "Saeed Kargar, Heiner Litz, Faisal Nawab", "title": "Predict and Write: Using K-Means Clustering to Extend the Lifetime of\n  NVM Storage", "comments": "ICDE2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-volatile memory (NVM) technologies suffer from limited write endurance.\nTo address this challenge, we propose Predict and Write (PNW), a K/V-store that\nuses a clustering-based machine learning approach to extend the lifetime of\nNVMs. PNW decreases the number of bit flips for PUT/UPDATE operations by\ndetermining the best memory location an updated value should be written to. PNW\nleverages the indirection level of K/V-stores to freely choose the target\nmemory location for any given write based on its value. PNW organizes NVM\naddresses in a dynamic address pool clustered by the similarity of the data\nvalues they refer to. We show that, by choosing the right target memory\nlocation for a given PUT/UPDATE operation, the number of total bit flips and\ncache lines can be reduced by up to 85% and 56% over the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 22:03:09 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kargar", "Saeed", ""], ["Litz", "Heiner", ""], ["Nawab", "Faisal", ""]]}, {"id": "2011.02559", "submitter": "Robert Moss", "authors": "Robert J. Moss, Ritchie Lee, Nicholas Visser, Joachim Hochwarth, James\n  G. Lopez, and Mykel J. Kochenderfer", "title": "Adaptive Stress Testing of Trajectory Predictions in Flight Management\n  Systems", "comments": "10 pages, 10 figures, 6 algorithms. Digital Avionics Systems\n  Conference (DASC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To find failure events and their likelihoods in flight-critical systems, we\ninvestigate the use of an advanced black-box stress testing approach called\nadaptive stress testing. We analyze a trajectory predictor from a developmental\ncommercial flight management system which takes as input a collection of\nlateral waypoints and en-route environmental conditions. Our aim is to search\nfor failure events relating to inconsistencies in the predicted lateral\ntrajectories. The intention of this work is to find likely failures and report\nthem back to the developers so they can address and potentially resolve\nshortcomings of the system before deployment. To improve search performance,\nthis work extends the adaptive stress testing formulation to be applied more\ngenerally to sequential decision-making problems with episodic reward by\ncollecting the state transitions during the search and evaluating at the end of\nthe simulated rollout. We use a modified Monte Carlo tree search algorithm with\nprogressive widening as our adversarial reinforcement learner. The performance\nis compared to direct Monte Carlo simulations and to the cross-entropy method\nas an alternative importance sampling baseline. The goal is to find potential\nproblems otherwise not found by traditional requirements-based testing. Results\nindicate that our adaptive stress testing approach finds more failures and\nfinds failures with higher likelihood relative to the baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 22:05:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Moss", "Robert J.", ""], ["Lee", "Ritchie", ""], ["Visser", "Nicholas", ""], ["Hochwarth", "Joachim", ""], ["Lopez", "James G.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2011.02560", "submitter": "Song Fang", "authors": "Song Fang and Quanyan Zhu", "title": "Independent Gaussian Distributions Minimize the Kullback-Leibler (KL)\n  Divergence from Independent Gaussian Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.SY eess.SP eess.SY math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note is on a property of the Kullback-Leibler (KL) divergence\nwhich indicates that independent Gaussian distributions minimize the KL\ndivergence from given independent Gaussian distributions. The primary purpose\nof this note is for the referencing of papers that need to make use of this\nproperty entirely or partially.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 22:05:45 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 15:54:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Fang", "Song", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2011.02565", "submitter": "Anand Kamat", "authors": "Anand Kamat and Doina Precup", "title": "Diversity-Enriched Option-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal abstraction allows reinforcement learning agents to represent\nknowledge and develop strategies over different temporal scales. The\noption-critic framework has been demonstrated to learn temporally extended\nactions, represented as options, end-to-end in a model-free setting. However,\nfeasibility of option-critic remains limited due to two major challenges,\nmultiple options adopting very similar behavior, or a shrinking set of task\nrelevant options. These occurrences not only void the need for temporal\nabstraction, they also affect performance. In this paper, we tackle these\nproblems by learning a diverse set of options. We introduce an\ninformation-theoretic intrinsic reward, which augments the task reward, as well\nas a novel termination objective, in order to encourage behavioral diversity in\nthe option set. We show empirically that our proposed method is capable of\nlearning options end-to-end on several discrete and continuous control tasks,\noutperforms option-critic by a wide margin. Furthermore, we show that our\napproach sustainably generates robust, reusable, reliable and interpretable\noptions, in contrast to option-critic.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 22:12:54 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Kamat", "Anand", ""], ["Precup", "Doina", ""]]}, {"id": "2011.02574", "submitter": "Andrei Cramariuc", "authors": "Le Chen, Yunke Ao, Florian Tschopp, Andrei Cramariuc, Michel Breyer,\n  Jen Jen Chung, Roland Siegwart, Cesar Cadena", "title": "Learning Trajectories for Visual-Inertial System Calibration via\n  Model-based Heuristic Deep Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 4th Conference on Robot Learning (CoRL) 2020", "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual-inertial systems rely on precise calibrations of both camera\nintrinsics and inter-sensor extrinsics, which typically require manually\nperforming complex motions in front of a calibration target. In this work we\npresent a novel approach to obtain favorable trajectories for visual-inertial\nsystem calibration, using model-based deep reinforcement learning. Our key\ncontribution is to model the calibration process as a Markov decision process\nand then use model-based deep reinforcement learning with particle swarm\noptimization to establish a sequence of calibration trajectories to be\nperformed by a robot arm. Our experiments show that while maintaining similar\nor shorter path lengths, the trajectories generated by our learned policy\nresult in lower calibration errors compared to random or handcrafted\ntrajectories.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 23:20:15 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Chen", "Le", ""], ["Ao", "Yunke", ""], ["Tschopp", "Florian", ""], ["Cramariuc", "Andrei", ""], ["Breyer", "Michel", ""], ["Chung", "Jen Jen", ""], ["Siegwart", "Roland", ""], ["Cadena", "Cesar", ""]]}, {"id": "2011.02592", "submitter": "Ehsan Sadrfaridpour", "authors": "Ehsan Sadrfaridpour, Korey Palmer, Ilya Safro (Clemson University)", "title": "AML-SVM: Adaptive Multilevel Learning with Support Vector Machines", "comments": "10 pages, 5 tables, 3 figures, IEEE BigData 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machines (SVM) is one of the most widely used and\npractical optimization based classification models in machine learning because\nof its interpretability and flexibility to produce high quality results.\nHowever, the big data imposes a certain difficulty to the most sophisticated\nbut relatively slow versions of SVM, namely, the nonlinear SVM. The complexity\nof nonlinear SVM solvers and the number of elements in the kernel matrix\nquadratically increases with the number of samples in training data. Therefore,\nboth runtime and memory requirements are negatively affected. Moreover, the\nparameter fitting has extra kernel parameters to tune, which exacerbate the\nruntime even further. This paper proposes an adaptive multilevel learning\nframework for the nonlinear SVM, which addresses these challenges, improves the\nclassification quality across the refinement process, and leverages\nmulti-threaded parallel processing for better performance. The integration of\nparameter fitting in the hierarchical learning framework and adaptive process\nto stop unnecessary computation significantly reduce the running time while\nincrease the overall performance. The experimental results demonstrate reduced\nvariance on prediction over validation and test data across levels in the\nhierarchy, and significant speedup compared to state-of-the-art nonlinear SVM\nlibraries without a decrease in the classification quality. The code is\naccessible at https://github.com/esadr/amlsvm.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 00:17:02 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Sadrfaridpour", "Ehsan", "", "Clemson University"], ["Palmer", "Korey", "", "Clemson University"], ["Safro", "Ilya", "", "Clemson University"]]}, {"id": "2011.02598", "submitter": "Naoya Otani", "authors": "Naoya Otani, Yosuke Otsubo, Tetsuya Koike, Masashi Sugiyama", "title": "Binary classification with ambiguous training data", "comments": "20 pages, 6 figures, accepted at the 12th Asian Conference on Machine\n  Learning (ACML 2020)", "journal-ref": "Mach Learn 109, 2369-2388 (2020)", "doi": "10.1007/s10994-020-05915-2", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised learning, we often face with ambiguous (A) samples that are\ndifficult to label even by domain experts. In this paper, we consider a binary\nclassification problem in the presence of such A samples. This problem is\nsubstantially different from semi-supervised learning since unlabeled samples\nare not necessarily difficult samples. Also, it is different from 3-class\nclassification with the positive (P), negative (N), and A classes since we do\nnot want to classify test samples into the A class. Our proposed method extends\nbinary classification with reject option, which trains a classifier and a\nrejector simultaneously using P and N samples based on the 0-1-$c$ loss with\nrejection cost $c$. More specifically, we propose to train a classifier and a\nrejector under the 0-1-$c$-$d$ loss using P, N, and A samples, where $d$ is the\nmisclassification penalty for ambiguous samples. In our practical\nimplementation, we use a convex upper bound of the 0-1-$c$-$d$ loss for\ncomputational tractability. Numerical experiments demonstrate that our method\ncan successfully utilize the additional information brought by such A training\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 00:53:58 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Otani", "Naoya", ""], ["Otsubo", "Yosuke", ""], ["Koike", "Tetsuya", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2011.02602", "submitter": "Chin-Chia Michael Yeh", "authors": "Chin-Chia Michael Yeh, Zhongfang Zhuang, Yan Zheng, Liang Wang,\n  Junpeng Wang, Wei Zhang", "title": "Merchant Category Identification Using Credit Card Transactions", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital payment volume has proliferated in recent years with the rapid growth\nof small businesses and online shops. When processing these digital\ntransactions, recognizing each merchant's real identity (i.e., business type)\nis vital to ensure the integrity of payment processing systems. Conventionally,\nthis problem is formulated as a time series classification problem solely using\nthe merchant transaction history. However, with the large scale of the data,\nand changing behaviors of merchants and consumers over time, it is extremely\nchallenging to achieve satisfying performance from off-the-shelf classification\nmethods. In this work, we approach this problem from a multi-modal learning\nperspective, where we use not only the merchant time series data but also the\ninformation of merchant-merchant relationship (i.e., affinity) to verify the\nself-reported business type (i.e., merchant category) of a given merchant.\nSpecifically, we design two individual encoders, where one is responsible for\nencoding temporal information and the other is responsible for affinity\ninformation, and a mechanism to fuse the outputs of the two encoders to\naccomplish the identification task. Our experiments on real-world credit card\ntransaction data between 71,668 merchants and 433,772,755 customers have\ndemonstrated the effectiveness and efficiency of the proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:21:30 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Yeh", "Chin-Chia Michael", ""], ["Zhuang", "Zhongfang", ""], ["Zheng", "Yan", ""], ["Wang", "Liang", ""], ["Wang", "Junpeng", ""], ["Zhang", "Wei", ""]]}, {"id": "2011.02604", "submitter": "Ethan Gordon", "authors": "Ethan K. Gordon, Sumegh Roychowdhury, Tapomayukh Bhattacharjee, Kevin\n  Jamieson, Siddhartha S. Srinivasa", "title": "Leveraging Post Hoc Context for Faster Learning in Bandit Settings with\n  Applications in Robot-Assisted Feeding", "comments": "6 pages + references, 5 figures, to appear in ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous robot-assisted feeding requires the ability to acquire a wide\nvariety of food items. However, it is impossible for such a system to be\ntrained on all types of food in existence. Therefore, a key challenge is\nchoosing a manipulation strategy for a previously unseen food item. Previous\nwork showed that the problem can be represented as a linear bandit with visual\ncontext. However, food has a wide variety of multi-modal properties relevant to\nmanipulation that can be hard to distinguish visually. Our key insight is that\nwe can leverage the haptic context we collect during and after manipulation\n(i.e., \"post hoc\") to learn some of these properties and more quickly adapt our\nvisual model to previously unseen food. In general, we propose a modified\nlinear contextual bandit framework augmented with post hoc context observed\nafter action selection to empirically increase learning speed and reduce\ncumulative regret. Experiments on synthetic data demonstrate that this effect\nis more pronounced when the dimensionality of the context is large relative to\nthe post hoc context or when the post hoc context model is particularly easy to\nlearn. Finally, we apply this framework to the bite acquisition problem and\ndemonstrate the acquisition of 8 previously unseen types of food with 21% fewer\nfailures across 64 attempts.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:28:25 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 22:04:50 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Gordon", "Ethan K.", ""], ["Roychowdhury", "Sumegh", ""], ["Bhattacharjee", "Tapomayukh", ""], ["Jamieson", "Kevin", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "2011.02606", "submitter": "Palakorn Achananuparp", "authors": "V N S Rama Krishna Pinnimty, Matt Zhao, Palakorn Achananuparp, and\n  Ee-Peng Lim", "title": "Transforming Facial Weight of Real Images by Editing Latent Space of\n  StyleGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an invert-and-edit framework to automatically transform facial\nweight of an input face image to look thinner or heavier by leveraging semantic\nfacial attributes encoded in the latent space of Generative Adversarial\nNetworks (GANs). Using a pre-trained StyleGAN as the underlying generator, we\nfirst employ an optimization-based embedding method to invert the input image\ninto the StyleGAN latent space. Then, we identify the facial-weight attribute\ndirection in the latent space via supervised learning and edit the inverted\nlatent code by moving it positively or negatively along the extracted feature\naxis. Our framework is empirically shown to produce high-quality and realistic\nfacial-weight transformations without requiring training GANs with a large\namount of labeled face images from scratch. Ultimately, our framework can be\nutilized as part of an intervention to motivate individuals to make healthier\nfood choices by visualizing the future impacts of their behavior on appearance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:45:18 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pinnimty", "V N S Rama Krishna", ""], ["Zhao", "Matt", ""], ["Achananuparp", "Palakorn", ""], ["Lim", "Ee-Peng", ""]]}, {"id": "2011.02608", "submitter": "Jingxi Xu", "authors": "Huy Ha, Jingxi Xu, Shuran Song", "title": "Learning a Decentralized Multi-arm Motion Planner", "comments": "CoRL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a closed-loop multi-arm motion planner that is scalable and\nflexible with team size. Traditional multi-arm robot systems have relied on\ncentralized motion planners, whose runtimes often scale exponentially with team\nsize, and thus, fail to handle dynamic environments with open-loop control. In\nthis paper, we tackle this problem with multi-agent reinforcement learning,\nwhere a decentralized policy is trained to control one robot arm in the\nmulti-arm system to reach its target end-effector pose given observations of\nits workspace state and target end-effector pose. The policy is trained using\nSoft Actor-Critic with expert demonstrations from a sampling-based motion\nplanning algorithm (i.e., BiRRT). By leveraging classical planning algorithms,\nwe can improve the learning efficiency of the reinforcement learning algorithm\nwhile retaining the fast inference time of neural networks. The resulting\npolicy scales sub-linearly and can be deployed on multi-arm systems with\nvariable team sizes. Thanks to the closed-loop and decentralized formulation,\nour approach generalizes to 5-10 multi-arm systems and dynamic moving targets\n(>90% success rate for a 10-arm system), despite being trained on only 1-4 arm\nplanning tasks with static targets. Code and data links can be found at\nhttps://multiarm.cs.columbia.edu.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:47:23 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ha", "Huy", ""], ["Xu", "Jingxi", ""], ["Song", "Shuran", ""]]}, {"id": "2011.02614", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Jian Peng, Yuan Zhou", "title": "Harnessing Distribution Ratio Estimators for Learning Agents with\n  Quality and Diversity", "comments": "CoRL 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity (QD) is a concept from Neuroevolution with some intriguing\napplications to Reinforcement Learning. It facilitates learning a population of\nagents where each member is optimized to simultaneously accumulate high\ntask-returns and exhibit behavioral diversity compared to other members. In\nthis paper, we build on a recent kernel-based method for training a QD policy\nensemble with Stein variational gradient descent. With kernels based on\n$f$-divergence between the stationary distributions of policies, we convert the\nproblem to that of efficient estimation of the ratio of these stationary\ndistributions. We then study various distribution ratio estimators used\npreviously for off-policy evaluation and imitation and re-purpose them to\ncompute the gradients for policies in an ensemble such that the resultant\npopulation is diverse and of high-quality.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 02:02:44 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Peng", "Jian", ""], ["Zhou", "Yuan", ""]]}, {"id": "2011.02620", "submitter": "Wenying Wen", "authors": "Wenying Wen, Rongxin Tu, Yushu Zhang, Yuming Fang, Yong Yang", "title": "A multi-level approach with visual information for encrypted H.265/HEVC\n  videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-efficiency video coding (HEVC) encryption has been proposed to encrypt\nsyntax elements for the purpose of video encryption. To achieve high video\nsecurity, to the best of our knowledge, almost all of the existing HEVC\nencryption algorithms mainly encrypt the whole video, such that the user\nwithout permissions cannot obtain any viewable information. However, these\nencryption algorithms cannot meet the needs of customers who need part of the\ninformation but not the full information in the video. In many cases, such as\nprofessional paid videos or video meetings, users would like to observe some\nvisible information in the encrypted video of the original video to satisfy\ntheir requirements in daily life. Aiming at this demand, this paper proposes a\nmulti-level encryption scheme that is composed of lightweight encryption,\nmedium encryption and heavyweight encryption, where each encryption level can\nobtain a different amount of visual information. It is found that both\nencrypting the luma intraprediction model (IPM) and scrambling the syntax\nelement of the DCT coefficient sign can achieve the performance of a distorted\nvideo in which there is still residual visual information, while encrypting\nboth of them can implement the intensity of encryption and one cannot gain any\nvisual information. The experimental results meet our expectations\nappropriately, indicating that there is a different amount of visual\ninformation in each encryption level. Meanwhile, users can flexibly choose the\nencryption level according to their various requirements.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 02:20:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Wen", "Wenying", ""], ["Tu", "Rongxin", ""], ["Zhang", "Yushu", ""], ["Fang", "Yuming", ""], ["Yang", "Yong", ""]]}, {"id": "2011.02644", "submitter": "Zhiyang Wang", "authors": "Zhiyang Wang, Mark Eisen and Alejandro Ribeiro", "title": "Unsupervised Learning for Asynchronous Resource Allocation in Ad-hoc\n  Wireless Networks", "comments": "5 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimal resource allocation problems under asynchronous wireless\nnetwork setting. Without explicit model knowledge, we design an unsupervised\nlearning method based on Aggregation Graph Neural Networks (Agg-GNNs).\nDepending on the localized aggregated information structure on each network\nnode, the method can be learned globally and asynchronously while implemented\nlocally. We capture the asynchrony by modeling the activation pattern as a\ncharacteristic of each node and train a policy-based resource allocation\nmethod. We also propose a permutation invariance property which indicates the\ntransferability of the trained Agg-GNN. We finally verify our strategy by\nnumerical simulations compared with baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 03:38:36 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Wang", "Zhiyang", ""], ["Eisen", "Mark", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2011.02664", "submitter": "Siwei Wang", "authors": "Siwei Wang, Longbo Huang, John C.S. Lui", "title": "Restless-UCB, an Efficient and Low-complexity Algorithm for Online\n  Restless Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the online restless bandit problem, where the state of each arm\nevolves according to a Markov chain, and the reward of pulling an arm depends\non both the pulled arm and the current state of the corresponding Markov chain.\nIn this paper, we propose Restless-UCB, a learning policy that follows the\nexplore-then-commit framework. In Restless-UCB, we present a novel method to\nconstruct offline instances, which only requires $O(N)$ time-complexity ($N$ is\nthe number of arms) and is exponentially better than the complexity of existing\nlearning policy. We also prove that Restless-UCB achieves a regret upper bound\nof $\\tilde{O}((N+M^3)T^{2\\over 3})$, where $M$ is the Markov chain state space\nsize and $T$ is the time horizon. Compared to existing algorithms, our result\neliminates the exponential factor (in $M,N$) in the regret upper bound, due to\na novel exploitation of the sparsity in transitions in general restless bandit\nproblems. As a result, our analysis technique can also be adopted to tighten\nthe regret bounds of existing algorithms. Finally, we conduct experiments based\non real-world dataset, to compare the Restless-UCB policy with state-of-the-art\nbenchmarks. Our results show that Restless-UCB outperforms existing algorithms\nin regret, and significantly reduces the running time.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 05:16:04 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 08:00:22 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Wang", "Siwei", ""], ["Huang", "Longbo", ""], ["Lui", "John C. S.", ""]]}, {"id": "2011.02665", "submitter": "Tony Gracious", "authors": "Tony Gracious, Ambedkar Dukkipati", "title": "Adversarial Context Aware Network Embeddings for Textual Networks", "comments": "8 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning of textual networks poses a significant challenge as\nit involves capturing amalgamated information from two modalities: (i)\nunderlying network structure, and (ii) node textual attributes. For this, most\nexisting approaches learn embeddings of text and network structure by enforcing\nembeddings of connected nodes to be similar. Then for achieving a modality\nfusion they use the similarities between text embedding of a node with the\nstructure embedding of its connected node and vice versa. This implies that\nthese approaches require edge information for learning embeddings and they\ncannot learn embeddings of unseen nodes. In this paper we propose an approach\nthat achieves both modality fusion and the capability to learn embeddings of\nunseen nodes. The main feature of our model is that it uses an adversarial\nmechanism between text embedding based discriminator, and structure embedding\nbased generator to learn efficient representations. Then for learning\nembeddings of unseen nodes, we use the supervision provided by the text\nembedding based discriminator. In addition this, we propose a novel\narchitecture for learning text embedding that can combine both mutual attention\nand topological attention mechanism, which give more flexible text embeddings.\nThrough extensive experiments on real-world datasets, we demonstrate that our\nmodel makes substantial gains over several state-of-the-art benchmarks. In\ncomparison with previous state-of-the-art, it gives up to 7% improvement in\nperformance in predicting links among nodes seen in the training and up to 12%\nimprovement in performance in predicting links involving nodes not seen in\ntraining. Further, in the node classification task, it gives up to 2%\nimprovement in performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 05:20:01 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gracious", "Tony", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2011.02669", "submitter": "Weixun Wang", "authors": "Yujing Hu, Weixun Wang, Hangtian Jia, Yixiang Wang, Yingfeng Chen,\n  Jianye Hao, Feng Wu, Changjie Fan", "title": "Learning to Utilize Shaping Rewards: A New Approach of Reward Shaping", "comments": "Accepted by NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward shaping is an effective technique for incorporating domain knowledge\ninto reinforcement learning (RL). Existing approaches such as potential-based\nreward shaping normally make full use of a given shaping reward function.\nHowever, since the transformation of human knowledge into numeric reward values\nis often imperfect due to reasons such as human cognitive bias, completely\nutilizing the shaping reward function may fail to improve the performance of RL\nalgorithms. In this paper, we consider the problem of adaptively utilizing a\ngiven shaping reward function. We formulate the utilization of shaping rewards\nas a bi-level optimization problem, where the lower level is to optimize policy\nusing the shaping rewards and the upper level is to optimize a parameterized\nshaping weight function for true reward maximization. We formally derive the\ngradient of the expected true reward with respect to the shaping weight\nfunction parameters and accordingly propose three learning algorithms based on\ndifferent assumptions. Experiments in sparse-reward cartpole and MuJoCo\nenvironments show that our algorithms can fully exploit beneficial shaping\nrewards, and meanwhile ignore unbeneficial shaping rewards or even transform\nthem into beneficial ones.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 05:34:14 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Hu", "Yujing", ""], ["Wang", "Weixun", ""], ["Jia", "Hangtian", ""], ["Wang", "Yixiang", ""], ["Chen", "Yingfeng", ""], ["Hao", "Jianye", ""], ["Wu", "Feng", ""], ["Fan", "Changjie", ""]]}, {"id": "2011.02671", "submitter": "Liu Shanqi", "authors": "Shanqi Liu, Junjie Cao, Wenzhou Chen, Licheng Wen, Yong Liu", "title": "HILONet: Hierarchical Imitation Learning from Non-Aligned Observations", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging learning from demonstrated observation-only trajectories in\na non-time-aligned environment because most imitation learning methods aim to\nimitate experts by following the demonstration step-by-step. However, aligned\ndemonstrations are seldom obtainable in real-world scenarios. In this work, we\npropose a new imitation learning approach called Hierarchical Imitation\nLearning from Observation(HILONet), which adopts a hierarchical structure to\nchoose feasible sub-goals from demonstrated observations dynamically. Our\nmethod can solve all kinds of tasks by achieving these sub-goals, whether it\nhas a single goal position or not. We also present three different ways to\nincrease sample efficiency in the hierarchical structure. We conduct extensive\nexperiments using several environments. The results show the improvement in\nboth performance and learning efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 05:48:36 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 04:47:16 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liu", "Shanqi", ""], ["Cao", "Junjie", ""], ["Chen", "Wenzhou", ""], ["Wen", "Licheng", ""], ["Liu", "Yong", ""]]}, {"id": "2011.02675", "submitter": "Camilo Pestana", "authors": "Camilo Pestana, Wei Liu, David Glance, Ajmal Mian", "title": "Defense-friendly Images in Adversarial Attacks: Dataset and Metrics for\n  Perturbation Difficulty", "comments": "Paper Accepted at WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset bias is a problem in adversarial machine learning, especially in the\nevaluation of defenses. An adversarial attack or defense algorithm may show\nbetter results on the reported dataset than can be replicated on other\ndatasets. Even when two algorithms are compared, their relative performance can\nvary depending on the dataset. Deep learning offers state-of-the-art solutions\nfor image recognition, but deep models are vulnerable even to small\nperturbations. Research in this area focuses primarily on adversarial attacks\nand defense algorithms. In this paper, we report for the first time, a class of\nrobust images that are both resilient to attacks and that recover better than\nrandom images under adversarial attacks using simple defense techniques. Thus,\na test dataset with a high proportion of robust images gives a misleading\nimpression about the performance of an adversarial attack or defense. We\npropose three metrics to determine the proportion of robust images in a dataset\nand provide scoring to determine the dataset bias. We also provide an\nImageNet-R dataset of 15000+ robust images to facilitate further research on\nthis intriguing phenomenon of image strength under attack. Our dataset,\ncombined with the proposed metrics, is valuable for unbiased benchmarking of\nadversarial attack and defense algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 06:21:24 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 02:57:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Pestana", "Camilo", ""], ["Liu", "Wei", ""], ["Glance", "David", ""], ["Mian", "Ajmal", ""]]}, {"id": "2011.02680", "submitter": "Zhuoran Qiao", "authors": "Zhuoran Qiao, Feizhi Ding, Matthew Welborn, Peter J. Bygrave, Daniel\n  G. A. Smith, Animashree Anandkumar, Frederick R. Manby and Thomas F. Miller\n  III", "title": "Multi-task learning for electronic structure to predict and explore\n  molecular potential energy surfaces", "comments": "Accepted for presentation at the Machine Learning for Molecules\n  workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We refine the OrbNet model to accurately predict energy, forces, and other\nresponse properties for molecules using a graph neural-network architecture\nbased on features from low-cost approximated quantum operators in the\nsymmetry-adapted atomic orbital basis. The model is end-to-end differentiable\ndue to the derivation of analytic gradients for all electronic structure terms,\nand is shown to be transferable across chemical space due to the use of\ndomain-specific features. The learning efficiency is improved by incorporating\nphysically motivated constraints on the electronic structure through multi-task\nlearning. The model outperforms existing methods on energy prediction tasks for\nthe QM9 dataset and for molecular geometry optimizations on conformer datasets,\nat a computational cost that is thousand-fold or more reduced compared to\nconventional quantum-chemistry calculations (such as density functional theory)\nthat offer similar accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 06:48:46 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 23:15:34 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 20:46:02 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 18:28:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Qiao", "Zhuoran", ""], ["Ding", "Feizhi", ""], ["Welborn", "Matthew", ""], ["Bygrave", "Peter J.", ""], ["Smith", "Daniel G. A.", ""], ["Anandkumar", "Animashree", ""], ["Manby", "Frederick R.", ""], ["Miller", "Thomas F.", "III"]]}, {"id": "2011.02683", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski and Peter M. Tian", "title": "Nonparametric Variable Screening with Optimal Decision Stumps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees and their ensembles are endowed with a rich set of diagnostic\ntools for ranking and screening variables in a predictive model. Despite the\nwidespread use of tree based variable importance measures, pinning down their\ntheoretical properties has been challenging and therefore largely unexplored.\nTo address this gap between theory and practice, we derive finite sample\nperformance guarantees for variable selection in nonparametric models using a\nsingle-level CART decision tree (a decision stump). Under standard operating\nassumptions in variable screening literature, we find that the marginal signal\nstrength of each variable and ambient dimensionality can be considerably weaker\nand higher, respectively, than state-of-the-art nonparametric variable\nselection methods. Furthermore, unlike previous marginal screening methods that\nattempt to directly estimate each marginal projection via a truncated basis\nexpansion, the fitted model used here is a simple, parsimonious decision stump,\nthereby eliminating the need for tuning the number of basis terms. Thus,\nsurprisingly, even though decision stumps are highly inaccurate for estimation\npurposes, they can still be used to perform consistent model selection.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 06:56:12 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 00:38:18 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Klusowski", "Jason M.", ""], ["Tian", "Peter M.", ""]]}, {"id": "2011.02696", "submitter": "Aurick Zhou", "authors": "Aurick Zhou, Sergey Levine", "title": "Amortized Conditional Normalized Maximum Likelihood: Reliable Out of\n  Distribution Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks provide good performance for a range of\nchallenging tasks, calibration and uncertainty estimation remain major\nchallenges, especially under distribution shift. In this paper, we propose the\namortized conditional normalized maximum likelihood (ACNML) method as a\nscalable general-purpose approach for uncertainty estimation, calibration, and\nout-of-distribution robustness with deep networks. Our algorithm builds on the\nconditional normalized maximum likelihood (CNML) coding scheme, which has\nminimax optimal properties according to the minimum description length\nprinciple, but is computationally intractable to evaluate exactly for all but\nthe simplest of model classes. We propose to use approximate Bayesian inference\ntechnqiues to produce a tractable approximation to the CNML distribution. Our\napproach can be combined with any approximate inference algorithm that provides\ntractable posterior densities over model parameters. We demonstrate that ACNML\ncompares favorably to a number of prior techniques for uncertainty estimation\nin terms of calibration on out-of-distribution inputs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 08:04:34 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 21:03:05 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Zhou", "Aurick", ""], ["Levine", "Sergey", ""]]}, {"id": "2011.02701", "submitter": "Oren Sar Shalom", "authors": "Rami Cohen, Oren Sar Shalom, Dietmar Jannach and Amihood Amir", "title": "A Black-Box Attack Model for Visually-Aware Recommender Systems", "comments": "Accepted to WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the advances in deep learning, visually-aware recommender systems (RS)\nhave recently attracted increased research interest. Such systems combine\ncollaborative signals with images, usually represented as feature vectors\noutputted by pre-trained image models. Since item catalogs can be huge,\nrecommendation service providers often rely on images that are supplied by the\nitem providers. In this work, we show that relying on such external sources can\nmake an RS vulnerable to attacks, where the goal of the attacker is to unfairly\npromote certain pushed items. Specifically, we demonstrate how a new visual\nattack model can effectively influence the item scores and rankings in a\nblack-box approach, i.e., without knowing the parameters of the model. The main\nunderlying idea is to systematically create small human-imperceptible\nperturbations of the pushed item image and to devise appropriate gradient\napproximation methods to incrementally raise the pushed item's score.\nExperimental evaluations on two datasets show that the novel attack model is\neffective even when the contribution of the visual features to the overall\nperformance of the recommender system is modest.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 08:43:12 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Cohen", "Rami", ""], ["Shalom", "Oren Sar", ""], ["Jannach", "Dietmar", ""], ["Amir", "Amihood", ""]]}, {"id": "2011.02707", "submitter": "Leo Schwinn", "authors": "Leo Schwinn, An Nguyen, Ren\\'e Raab, Dario Zanca, Bjoern Eskofier,\n  Daniel Tenbrinck, Martin Burger", "title": "Dynamically Sampled Nonlocal Gradients for Stronger Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks to small and even imperceptible\nperturbations has become a central topic in deep learning research. Although\nseveral sophisticated defense mechanisms have been introduced, most were later\nshown to be ineffective. However, a reliable evaluation of model robustness is\nmandatory for deployment in safety-critical scenarios. To overcome this problem\nwe propose a simple yet effective modification to the gradient calculation of\nstate-of-the-art first-order adversarial attacks. Normally, the gradient update\nof an attack is directly calculated for the given data point. This approach is\nsensitive to noise and small local optima of the loss function. Inspired by\ngradient sampling techniques from non-convex optimization, we propose\nDynamically Sampled Nonlocal Gradient Descent (DSNGD). DSNGD calculates the\ngradient direction of the adversarial attack as the weighted average over past\ngradients of the optimization history. Moreover, distribution hyperparameters\nthat define the sampling operation are automatically learned during the\noptimization scheme. We empirically show that by incorporating this nonlocal\ngradient information, we are able to give a more accurate estimation of the\nglobal descent direction on noisy and non-convex loss surfaces. In addition, we\nshow that DSNGD-based attacks are on average 35% faster while achieving 0.9% to\n27.1% higher success rates compared to their gradient descent-based\ncounterparts.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 08:55:24 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 10:18:27 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 10:48:56 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Schwinn", "Leo", ""], ["Nguyen", "An", ""], ["Raab", "Ren\u00e9", ""], ["Zanca", "Dario", ""], ["Eskofier", "Bjoern", ""], ["Tenbrinck", "Daniel", ""], ["Burger", "Martin", ""]]}, {"id": "2011.02712", "submitter": "Sabera Talukder", "authors": "Sabera Talukder, Guruprasad Raghavan, Yisong Yue", "title": "Architecture Agnostic Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we explore an alternate method for synthesizing neural network\narchitectures, inspired by the brain's stochastic synaptic pruning. During a\nperson's lifetime, numerous distinct neuronal architectures are responsible for\nperforming the same tasks. This indicates that biological neural networks are,\nto some degree, architecture agnostic. However, artificial networks rely on\ntheir fine-tuned weights and hand-crafted architectures for their remarkable\nperformance. This contrast begs the question: Can we build artificial\narchitecture agnostic neural networks? To ground this study we utilize sparse,\nbinary neural networks that parallel the brain's circuits. Within this sparse,\nbinary paradigm we sample many binary architectures to create families of\narchitecture agnostic neural networks not trained via backpropagation. These\nhigh-performing network families share the same sparsity, distribution of\nbinary weights, and succeed in both static and dynamic tasks. In summation, we\ncreate an architecture manifold search procedure to discover families or\narchitecture agnostic neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 09:04:07 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 05:06:51 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Talukder", "Sabera", ""], ["Raghavan", "Guruprasad", ""], ["Yue", "Yisong", ""]]}, {"id": "2011.02719", "submitter": "Suiyi Ling", "authors": "Kevin Riou, Jingwen Zhu, Suiyi Ling, Mathis Piquet, Vincent Truffault,\n  Patrick Le Callet", "title": "Few-Shot Object Detection in Real Life: Case Study on Auto-Harvest", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confinement during COVID-19 has caused serious effects on agriculture all\nover the world. As one of the efficient solutions, mechanical\nharvest/auto-harvest that is based on object detection and robotic harvester\nbecomes an urgent need. Within the auto-harvest system, robust few-shot object\ndetection model is one of the bottlenecks, since the system is required to deal\nwith new vegetable/fruit categories and the collection of large-scale annotated\ndatasets for all the novel categories is expensive. There are many few-shot\nobject detection models that were developed by the community. Yet whether they\ncould be employed directly for real life agricultural applications is still\nquestionable, as there is a context-gap between the commonly used training\ndatasets and the images collected in real life agricultural scenarios. To this\nend, in this study, we present a novel cucumber dataset and propose two data\naugmentation strategies that help to bridge the context-gap. Experimental\nresults show that 1) the state-of-the-art few-shot object detection model\nperforms poorly on the novel `cucumber' category; and 2) the proposed\naugmentation strategies outperform the commonly used ones.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 09:24:33 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Riou", "Kevin", ""], ["Zhu", "Jingwen", ""], ["Ling", "Suiyi", ""], ["Piquet", "Mathis", ""], ["Truffault", "Vincent", ""], ["Callet", "Patrick Le", ""]]}, {"id": "2011.02738", "submitter": "Lucas Baier", "authors": "Lucas Baier, Vincent Kellner, Niklas K\\\"uhl, Gerhard Satzger", "title": "Switching Scheme: A Novel Approach for Handling Incremental Concept\n  Drift in Real-World Data Sets", "comments": "54th Annual Hawaii International Conference on System Sciences\n  (HICSS-54)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models nowadays play a crucial role for many applications in\nbusiness and industry. However, models only start adding value as soon as they\nare deployed into production. One challenge of deployed models is the effect of\nchanging data over time, which is often described with the term concept drift.\nDue to their nature, concept drifts can severely affect the prediction\nperformance of a machine learning system. In this work, we analyze the effects\nof concept drift in the context of a real-world data set. For efficient concept\ndrift handling, we introduce the switching scheme which combines the two\nprinciples of retraining and updating of a machine learning model. Furthermore,\nwe systematically analyze existing regular adaptation as well as triggered\nadaptation strategies. The switching scheme is instantiated on New York City\ntaxi data, which is heavily influenced by changing demand patterns over time.\nWe can show that the switching scheme outperforms all other baselines and\ndelivers promising prediction results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 10:16:54 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Baier", "Lucas", ""], ["Kellner", "Vincent", ""], ["K\u00fchl", "Niklas", ""], ["Satzger", "Gerhard", ""]]}, {"id": "2011.02761", "submitter": "Kirankumar Shiragur", "authors": "Nima Anari, Moses Charikar, Kirankumar Shiragur, Aaron Sidford", "title": "Instance Based Approximations to Profile Maximum Likelihood", "comments": "Accepted at Thirty-fourth Conference on Neural Information Processing\n  Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a new efficient algorithm for approximately\ncomputing the profile maximum likelihood (PML) distribution, a prominent\nquantity in symmetric property estimation. We provide an algorithm which\nmatches the previous best known efficient algorithms for computing approximate\nPML distributions and improves when the number of distinct observed frequencies\nin the given instance is small. We achieve this result by exploiting new\nsparsity structure in approximate PML distributions and providing a new matrix\nrounding algorithm, of independent interest. Leveraging this result, we obtain\nthe first provable computationally efficient implementation of PseudoPML, a\ngeneral framework for estimating a broad class of symmetric properties.\nAdditionally, we obtain efficient PML-based estimators for distributions with\nsmall profile entropy, a natural instance-based complexity measure. Further, we\nprovide a simpler and more practical PseudoPML implementation that matches the\nbest-known theoretical guarantees of such an estimator and evaluate this method\nempirically.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 11:17:19 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Anari", "Nima", ""], ["Charikar", "Moses", ""], ["Shiragur", "Kirankumar", ""], ["Sidford", "Aaron", ""]]}, {"id": "2011.02763", "submitter": "Zhengping Che", "authors": "Xuanzhao Wang, Zhengping Che, Bo Jiang, Ning Xiao, Ke Yang, Jian Tang,\n  Jieping Ye, Jingyu Wang, Qi Qi", "title": "Robust Unsupervised Video Anomaly Detection by Multi-Path Frame\n  Prediction", "comments": "Paper accepted by IEEE Transactions on Neural Networks and Learning\n  Systems (TNNLS). Article DOI: 10.1109/TNNLS.2021.3083152", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video anomaly detection is commonly used in many applications such as\nsecurity surveillance and is very challenging.A majority of recent video\nanomaly detection approaches utilize deep reconstruction models, but their\nperformance is often suboptimal because of insufficient reconstruction error\ndifferences between normal and abnormal video frames in practice. Meanwhile,\nframe prediction-based anomaly detection methods have shown promising\nperformance. In this paper, we propose a novel and robust unsupervised video\nanomaly detection method by frame prediction with proper design which is more\nin line with the characteristics of surveillance videos. The proposed method is\nequipped with a multi-path ConvGRU-based frame prediction network that can\nbetter handle semantically informative objects and areas of different scales\nand capture spatial-temporal dependencies in normal videos. A noise tolerance\nloss is introduced during training to mitigate the interference caused by\nbackground noise. Extensive experiments have been conducted on the CUHK Avenue,\nShanghaiTech Campus, and UCSD Pedestrian datasets, and the results show that\nour proposed method outperforms existing state-of-the-art approaches.\nRemarkably, our proposed method obtains the frame-level AUROC score of 88.3% on\nthe CUHK Avenue dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 11:34:12 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 05:53:57 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Xuanzhao", ""], ["Che", "Zhengping", ""], ["Jiang", "Bo", ""], ["Xiao", "Ning", ""], ["Yang", "Ke", ""], ["Tang", "Jian", ""], ["Ye", "Jieping", ""], ["Wang", "Jingyu", ""], ["Qi", "Qi", ""]]}, {"id": "2011.02764", "submitter": "Manon Romain", "authors": "Manon Romain and Alexandre d'Aspremont", "title": "A Bregman Method for Structure Learning on Sparse Directed Acyclic\n  Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bregman proximal gradient method for structure learning on\nlinear structural causal models. While the problem is non-convex, has high\ncurvature and is in fact NP-hard, Bregman gradient methods allow us to\nneutralize at least part of the impact of curvature by measuring smoothness\nagainst a highly nonlinear kernel. This allows the method to make longer steps\nand significantly improves convergence. Each iteration requires solving a\nBregman proximal step which is convex and efficiently solvable for our\nparticular choice of kernel. We test our method on various synthetic and real\ndata sets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 11:37:44 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Romain", "Manon", ""], ["d'Aspremont", "Alexandre", ""]]}, {"id": "2011.02785", "submitter": "Yingming Li", "authors": "Dingyi Zhang, Yingming Li, Zhongfei Zhang", "title": "Deep Metric Learning with Spherical Embedding", "comments": "To appear in NeurIPS 2020. Code is available at\n  https://github.com/Dyfine/SphericalEmbedding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep metric learning has attracted much attention in recent years, due to\nseamlessly combining the distance metric learning and deep neural network. Many\nendeavors are devoted to design different pair-based angular loss functions,\nwhich decouple the magnitude and direction information for embedding vectors\nand ensure the training and testing measure consistency. However, these\ntraditional angular losses cannot guarantee that all the sample embeddings are\non the surface of the same hypersphere during the training stage, which would\nresult in unstable gradient in batch optimization and may influence the quick\nconvergence of the embedding learning. In this paper, we first investigate the\neffect of the embedding norm for deep metric learning with angular distance,\nand then propose a spherical embedding constraint (SEC) to regularize the\ndistribution of the norms. SEC adaptively adjusts the embeddings to fall on the\nsame hypersphere and performs more balanced direction update. Extensive\nexperiments on deep metric learning, face recognition, and contrastive\nself-supervised learning show that the SEC-based angular space learning\nstrategy significantly improves the performance of the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 12:32:12 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Zhang", "Dingyi", ""], ["Li", "Yingming", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "2011.02803", "submitter": "Ting Chen", "authors": "Ting Chen and Calvin Luo and Lala Li", "title": "Intriguing Properties of Contrastive Losses", "comments": "Technical report. Code at\n  https://github.com/google-research/simclr/tree/master/colabs/intriguing_properties", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive loss and its variants have become very popular recently for\nlearning visual representations without supervision. In this work, we study\nthree intriguing properties of contrastive learning. We first generalize the\nstandard contrastive loss to a broader family of losses, and we find that\nvarious instantiations of the generalized loss perform similarly under the\npresence of a multi-layer non-linear projection head. We then study if\ninstance-based contrastive learning (such as in SimCLR, MoCo, BYOL, and so on,\nwhich are based on global image representation) can learn well on images with\nmultiple objects present. We find that meaningful hierarchical local features\ncan be learned despite the fact that these objectives operate on global\ninstance-level features.\n  Finally, we study an intriguing phenomenon of feature suppression among\ncompeting features shared across augmented views, such as \"color distribution\"\nvs \"object class\". We construct datasets with explicit and controllable\ncompeting features, and show that, for contrastive learning, a few bits of\neasy-to-learn shared features can suppress, and even fully prevent, the\nlearning of other sets of competing features. In scenarios where there are\nmultiple objects in an image, the dominant object would suppress the learning\nof smaller objects. Existing contrastive learning methods critically rely on\ndata augmentation to favor certain sets of features over others, and face\npotential limitation for scenarios where existing augmentations cannot fully\naddress the feature suppression. This poses open challenges to existing\ncontrastive learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:19:48 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 01:17:22 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Ting", ""], ["Luo", "Calvin", ""], ["Li", "Lala", ""]]}, {"id": "2011.02809", "submitter": "Merlijn Blaauw", "authors": "Jordi Bonada, Merlijn Blaauw", "title": "Semi-supervised Learning for Singing Synthesis Timbre", "comments": "5 pages, 1 figure, submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semi-supervised singing synthesizer, which is able to learn new\nvoices from audio data only, without any annotations such as phonetic\nsegmentation. Our system is an encoder-decoder model with two encoders,\nlinguistic and acoustic, and one (acoustic) decoder. In a first step, the\nsystem is trained in a supervised manner, using a labelled multi-singer\ndataset. Here, we ensure that the embeddings produced by both encoders are\nsimilar, so that we can later use the model with either acoustic or linguistic\ninput features. To learn a new voice in an unsupervised manner, the pretrained\nacoustic encoder is used to train a decoder for the target singer. Finally, at\ninference, the pretrained linguistic encoder is used together with the decoder\nof the new voice, to produce acoustic features from linguistic input. We\nevaluate our system with a listening test and show that the results are\ncomparable to those obtained with an equivalent supervised approach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:33:34 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Bonada", "Jordi", ""], ["Blaauw", "Merlijn", ""]]}, {"id": "2011.02817", "submitter": "Thanasis Lianeas", "authors": "Dimitris Fotakis, Thanasis Lianeas, Georgios Piliouras, Stratis\n  Skoulakis", "title": "Efficient Online Learning of Optimal Rankings: Dimensionality Reduction\n  via Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a natural model of online preference aggregation, where sets of\npreferred items $R_1, R_2, \\ldots, R_t$ along with a demand for $k_t$ items in\neach $R_t$, appear online. Without prior knowledge of $(R_t, k_t)$, the learner\nmaintains a ranking $\\pi_t$ aiming that at least $k_t$ items from $R_t$ appear\nhigh in $\\pi_t$. This is a fundamental problem in preference aggregation with\napplications to, e.g., ordering product or news items in web pages based on\nuser scrolling and click patterns. The widely studied Generalized\nMin-Sum-Set-Cover (GMSSC) problem serves as a formal model for the setting\nabove. GMSSC is NP-hard and the standard application of no-regret online\nlearning algorithms is computationally inefficient, because they operate in the\nspace of rankings. In this work, we show how to achieve low regret for GMSSC in\npolynomial-time. We employ dimensionality reduction from rankings to the space\nof doubly stochastic matrices, where we apply Online Gradient Descent. A key\nstep is to show how subgradients can be computed efficiently, by solving the\ndual of a configuration LP. Using oblivious deterministic and randomized\nrounding schemes, we map doubly stochastic matrices back to rankings with a\nsmall loss in the GMSSC objective.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:52:34 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Fotakis", "Dimitris", ""], ["Lianeas", "Thanasis", ""], ["Piliouras", "Georgios", ""], ["Skoulakis", "Stratis", ""]]}, {"id": "2011.02819", "submitter": "Johannes De Smedt", "authors": "Johannes De Smedt, Jochen De Weerdt, Junichiro Mori and Masanao Ochi", "title": "Predictive Process Model Monitoring using Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of predictive process monitoring focuses on modelling future\ncharacteristics of running business process instances, typically by either\npredicting the outcome of particular objectives (e.g. completion (time), cost),\nor next-in-sequence prediction (e.g. what is the next activity to execute).\nThis paper introduces Processes-As-Movies (PAM), a technique that provides a\nmiddle ground between these predictive monitoring. It does so by capturing\ndeclarative process constraints between activities in various windows of a\nprocess execution trace, which represent a declarative process model at\nsubsequent stages of execution. This high-dimensional representation of a\nprocess model allows the application of predictive modelling on how such\nconstraints appear and vanish throughout a process' execution. Various\nrecurrent neural network topologies tailored to high-dimensional input are used\nto model the process model evolution with windows as time steps, including\nencoder-decoder long short-term memory networks, and convolutional long\nshort-term memory networks. Results show that these topologies are very\neffective in terms of accuracy and precision to predict a process model's\nfuture state, which allows process owners to simultaneously verify what linear\ntemporal logic rules hold in a predicted process window (objective-based), and\nverify what future execution traces are allowed by all the constraints together\n(trace-based).\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:57:33 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 14:15:16 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["De Smedt", "Johannes", ""], ["De Weerdt", "Jochen", ""], ["Mori", "Junichiro", ""], ["Ochi", "Masanao", ""]]}, {"id": "2011.02828", "submitter": "Eduard Gorbunov", "authors": "Eduard Gorbunov, Filip Hanzely, Peter Richt\\'arik", "title": "Local SGD: Unified Theory and New Efficient Methods", "comments": "79 pages, 6 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified framework for analyzing local SGD methods in the convex\nand strongly convex regimes for distributed/federated training of supervised\nmachine learning models. We recover several known methods as a special case of\nour general framework, including Local-SGD/FedAvg, SCAFFOLD, and several\nvariants of SGD not originally designed for federated learning. Our framework\ncovers both the identical and heterogeneous data settings, supports both random\nand deterministic number of local steps, and can work with a wide array of\nlocal stochastic gradient estimators, including shifted estimators which are\nable to adjust the fixed points of local iterations for faster convergence. As\nan application of our framework, we develop multiple novel FL optimizers which\nare superior to existing methods. In particular, we develop the first linearly\nconverging local SGD method which does not require any data homogeneity or\nother strong assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:02:50 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gorbunov", "Eduard", ""], ["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2011.02829", "submitter": "Felipe Kenji Nakano", "authors": "Felipe Kenji Nakano, Konstantinos Pliakos, Celine Vens", "title": "Deep tree-ensembles for multi-output prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have expanded the state-of-art in various\nscientific fields and provided solutions to long standing problems across\nmultiple application domains. Nevertheless, they also suffer from weaknesses\nsince their optimal performance depends on massive amounts of training data and\nthe tuning of an extended number of parameters. As a countermeasure, some\ndeep-forest methods have been recently proposed, as efficient and low-scale\nsolutions. Despite that, these approaches simply employ label classification\nprobabilities as induced features and primarily focus on traditional\nclassification and regression tasks, leaving multi-output prediction\nunder-explored. Moreover, recent work has demonstrated that tree-embeddings are\nhighly representative, especially in structured output prediction. In this\ndirection, we propose a novel deep tree-ensemble (DTE) model, where every layer\nenriches the original feature set with a representation learning component\nbased on tree-embeddings. In this paper, we specifically focus on two\nstructured output prediction tasks, namely multi-label classification and\nmulti-target regression. We conducted experiments using multiple benchmark\ndatasets and the obtained results confirm that our method provides superior\nresults to state-of-the-art methods in both tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 16:25:54 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Nakano", "Felipe Kenji", ""], ["Pliakos", "Konstantinos", ""], ["Vens", "Celine", ""]]}, {"id": "2011.02831", "submitter": "H\\'ector Iv\\'an Garc\\'ia Hern\\'andez", "authors": "H\\'ector Iv\\'an Garc\\'ia Hern\\'andez, Raymundo Torres Ruiz, Guo-Hua\n  Sun", "title": "Image Classification via Quantum Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Computing and especially Quantum Machine Learning, in a short period\nof time, has gained a lot of interest through research groups around the world.\nThis can be seen in the increasing number of proposed models for pattern\nclassification applying quantum principles to a certain degree. Despise the\nincreasing volume of models, there is a void in testing these models on real\ndatasets and not only on synthetic ones. The objective of this work is to\nclassify patterns with binary attributes using a quantum classifier. Specially,\nwe show results of a complete quantum classifier applied to image datasets. The\nexperiments show favorable output while dealing with balanced classification\nproblems as well as with imbalanced classes where the minority class is the\nmost relevant. This is promising in medical areas, where usually the important\nclass is also the minority class.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 05:12:51 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 02:58:33 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Hern\u00e1ndez", "H\u00e9ctor Iv\u00e1n Garc\u00eda", ""], ["Ruiz", "Raymundo Torres", ""], ["Sun", "Guo-Hua", ""]]}, {"id": "2011.02832", "submitter": "Stella Biderman", "authors": "Stella Biderman and Walter J. Scheirer", "title": "Pitfalls in Machine Learning Research: Reexamining the Development Cycle", "comments": "NeurIPS \"I Can't Believe It's Not Better!\" Workshop", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has the potential to fuel further advances in data science,\nbut it is greatly hindered by an ad hoc design process, poor data hygiene, and\na lack of statistical rigor in model evaluation. Recently, these issues have\nbegun to attract more attention as they have caused public and embarrassing\nissues in research and development. Drawing from our experience as machine\nlearning researchers, we follow the machine learning process from algorithm\ndesign to data collection to model evaluation, drawing attention to common\npitfalls and providing practical recommendations for improvements. At each\nstep, case studies are introduced to highlight how these pitfalls occur in\npractice, and where things could be improved.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:58:18 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Biderman", "Stella", ""], ["Scheirer", "Walter J.", ""]]}, {"id": "2011.02833", "submitter": "Angira Sharma", "authors": "Angira Sharma, Edward Kosasih, Jie Zhang, Alexandra Brintrup, Anisoara\n  Calinescu", "title": "Digital Twins: State of the Art Theory and Practice, Challenges, and\n  Open Research Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Twin was introduced over a decade ago, as an innovative\nall-encompassing tool, with perceived benefits including real-time monitoring,\nsimulation and forecasting. However, the theoretical framework and practical\nimplementations of digital twins (DT) are still far from this vision. Although\nsuccessful implementations exist, sufficient implementation details are not\npublicly available, therefore it is difficult to assess their effectiveness,\ndraw comparisons and jointly advance the DT methodology. This work explores the\nvarious DT features and current approaches, the shortcomings and reasons behind\nthe delay in the implementation and adoption of digital twin. Advancements in\nmachine learning, internet of things and big data have contributed hugely to\nthe improvements in DT with regards to its real-time monitoring and forecasting\nproperties. Despite this progress and individual company-based efforts, certain\nresearch gaps exist in the field, which have caused delay in the widespread\nadoption of this concept. We reviewed relevant works and identified that the\nmajor reasons for this delay are the lack of a universal reference framework,\ndomain dependence, security concerns of shared data, reliance of digital twin\non other technologies, and lack of quantitative metrics. We define the\nnecessary components of a digital twin required for a universal reference\nframework, which also validate its uniqueness as a concept compared to similar\nconcepts like simulation, autonomous systems, etc. This work further assesses\nthe digital twin applications in different domains and the current state of\nmachine learning and big data in it. It thus answers and identifies novel\nresearch questions, both of which will help to better understand and advance\nthe theory and practice of digital twins.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 19:08:49 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 10:41:55 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 13:34:23 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sharma", "Angira", ""], ["Kosasih", "Edward", ""], ["Zhang", "Jie", ""], ["Brintrup", "Alexandra", ""], ["Calinescu", "Anisoara", ""]]}, {"id": "2011.02834", "submitter": "Yash Raj Shrestha", "authors": "Yash Raj Shrestha, Vaibhav Krishna, Georg von Krogh", "title": "Augmenting Organizational Decision-Making with Deep Learning Algorithms:\n  Principles, Promises, and Challenges", "comments": null, "journal-ref": "Journal of Business Research 2020", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current expansion of theory and research on artificial intelligence in\nmanagement and organization studies has revitalized the theory and research on\ndecision-making in organizations. In particular, recent advances in deep\nlearning (DL) algorithms promise benefits for decision-making within\norganizations, such as assisting employees with information processing, thereby\naugment their analytical capabilities and perhaps help their transition to more\ncreative work.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 11:05:59 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Shrestha", "Yash Raj", ""], ["Krishna", "Vaibhav", ""], ["von Krogh", "Georg", ""]]}, {"id": "2011.02836", "submitter": "Sek Chai", "authors": "Hengyue Liu, Samyak Parajuli, Jesse Hostetler, Sek Chai, Bir Bhanu", "title": "Dynamically Throttleable Neural Networks (TNN)", "comments": "arXiv admin note: text overlap with arXiv:1905.13179", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional computation for Deep Neural Networks (DNNs) reduce overall\ncomputational load and improve model accuracy by running a subset of the\nnetwork. In this work, we present a runtime throttleable neural network (TNN)\nthat can adaptively self-regulate its own performance target and computing\nresources. We designed TNN with several properties that enable more flexibility\nfor dynamic execution based on runtime context. TNNs are defined as\nthrottleable modules gated with a separately trained controller that generates\na single utilization control parameter. We validate our proposal on a number of\nexperiments, including Convolution Neural Networks (CNNs such as VGG, ResNet,\nResNeXt, DenseNet) using CiFAR-10 and ImageNet dataset, for object\nclassification and recognition tasks. We also demonstrate the effectiveness of\ndynamic TNN execution on a 3D Convolustion Network (C3D) for a hand gesture\ntask. Results show that TNN can maintain peak accuracy performance compared to\nvanilla solutions, while providing a graceful reduction in computational\nrequirement, down to 74% reduction in latency and 52% energy savings.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 20:17:42 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Liu", "Hengyue", ""], ["Parajuli", "Samyak", ""], ["Hostetler", "Jesse", ""], ["Chai", "Sek", ""], ["Bhanu", "Bir", ""]]}, {"id": "2011.02838", "submitter": "Ushnish Sengupta", "authors": "Ushnish Sengupta, Maximilian L. Croci, Matthew P. Juniper", "title": "Real-time parameter inference in reduced-order flame models with\n  heteroscedastic Bayesian neural network ensembles", "comments": null, "journal-ref": "Machine Learning and the Physical Sciences Workshop at the 34th\n  Conference on Neural Information Processing Systems (NeurIPS) 2020", "doi": null, "report-no": null, "categories": "cs.LG physics.flu-dyn stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of model parameters with uncertainties from observed data is a\nubiquitous inverse problem in science and engineering. In this paper, we\nsuggest an inexpensive and easy to implement parameter estimation technique\nthat uses a heteroscedastic Bayesian Neural Network trained using anchored\nensembling. The heteroscedastic aleatoric error of the network models the\nirreducible uncertainty due to parameter degeneracies in our inverse problem,\nwhile the epistemic uncertainty of the Bayesian model captures uncertainties\nwhich may arise from an input observation's out-of-distribution nature. We use\nthis tool to perform real-time parameter inference in a 6 parameter G-equation\nmodel of a ducted, premixed flame from observations of acoustically excited\nflames. We train our networks on a library of 2.1 million simulated flame\nvideos. Results on the test dataset of simulated flames show that the network\nrecovers flame model parameters, with the correlation coefficient between\npredicted and true parameters ranging from 0.97 to 0.99, and well-calibrated\nuncertainty estimates. The trained neural networks are then used to infer model\nparameters from real videos of a premixed Bunsen flame captured using a\nhigh-speed camera in our lab. Re-simulation using inferred parameters shows\nexcellent agreement between the real and simulated flames. Compared to Ensemble\nKalman Filter-based tools that have been proposed for this problem in the\ncombustion literature, our neural network ensemble achieves better\ndata-efficiency and our sub-millisecond inference times represent a savings on\ncomputational costs by several orders of magnitude. This allows us to calibrate\nour reduced-order flame model in real-time and predict the thermoacoustic\ninstability behaviour of the flame more accurately.\n", "versions": [{"version": "v1", "created": "Sun, 11 Oct 2020 15:04:34 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Sengupta", "Ushnish", ""], ["Croci", "Maximilian L.", ""], ["Juniper", "Matthew P.", ""]]}, {"id": "2011.02840", "submitter": "Jordan Colman", "authors": "Jordan Colman, Lei Zhang, Wenting Duan and Xujiong Ye", "title": "DR-Unet104 for Multimodal MRI brain tumor segmentation", "comments": "Part of the Multimodal Brain Tumor Segmentation 2020 Challenge\n  conference proceedings", "journal-ref": "BrainLes 2020. Lecture Notes in Computer Science, vol 12659, pp\n  410-419", "doi": "10.1007/978-3-030-72087-2_36", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a 2D deep residual Unet with 104 convolutional\nlayers (DR-Unet104) for lesion segmentation in brain MRIs. We make multiple\nadditions to the Unet architecture, including adding the 'bottleneck' residual\nblock to the Unet encoder and adding dropout after each convolution block\nstack. We verified the effect of introducing the regularisation of dropout with\nsmall rate (e.g. 0.2) on the architecture, and found a dropout of 0.2 improved\nthe overall performance compared to no dropout, or a dropout of 0.5. We\nevaluated the proposed architecture as part of the Multimodal Brain Tumor\nSegmentation (BraTS) 2020 Challenge and compared our method to DeepLabV3+ with\na ResNet-V2-152 backbone. We found that the DR-Unet104 achieved a mean dice\nscore coefficient of 0.8862, 0.6756 and 0.6721 for validation data, whole\ntumor, enhancing tumor and tumor core respectively, an overall improvement on\n0.8770, 0.65242 and 0.68134 achieved by DeepLabV3+. Our method produced a final\nmean DSC of 0.8673, 0.7514 and 0.7983 on whole tumor, enhancing tumor and tumor\ncore on the challenge's testing data. We produced a competitive lesion\nsegmentation architecture, despite only 2D convolutions, having the added\nbenefit that it can be used on lower power computers than a 3D architecture.\nThe source code and trained model for this work is openly available at\nhttps://github.com/jordan-colman/DR-Unet104.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 01:24:26 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 14:25:49 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Colman", "Jordan", ""], ["Zhang", "Lei", ""], ["Duan", "Wenting", ""], ["Ye", "Xujiong", ""]]}, {"id": "2011.02842", "submitter": "Ziqi Zhang", "authors": "Ziqi Zhang", "title": "Depth Self-Optimized Learning Toward Data Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-stage model called Depth Self-Optimized Learning (DSOL),\nwhich aims to realize ANN depth self-configuration, self-optimization as well\nas ANN training without manual intervention. In the first stage of DSOL, it\nwill configure ANN of specific depth according to a specific dataset. In the\nsecond stage, DSOL will continuously optimize ANN based on Reinforcement\nLearning (RL). Finally, the optimal depth is returned to the first stage of\nDSOL for training, so that DSOL can configure the appropriate ANN depth and\nperform more reasonable optimization when processing similar datasets again. In\nthe experiment, we ran DSOL on the Iris and Boston housing datasets, and the\nresults showed that DSOL performed well. We have uploaded the experiment\nrecords and code to our Github.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 15:43:49 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 11:40:31 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhang", "Ziqi", ""]]}, {"id": "2011.02852", "submitter": "Valentina Candiani", "authors": "Valentina Candiani and Matteo Santacesaria", "title": "Neural networks for classification of strokes in electrical impedance\n  tomography on a 3D head model", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of the detection of brain hemorrhages from\nthree-dimensional (3D) electrical impedance tomography (EIT) measurements. This\nis a condition requiring urgent treatment for which EIT might provide a\nportable and quick diagnosis. We employ two neural network architectures -- a\nfully connected and a convolutional one -- for the classification of\nhemorrhagic and ischemic strokes. The networks are trained on a dataset with\n$40\\,000$ samples of synthetic electrode measurements generated with the\ncomplete electrode model on realistic heads with a 3-layer structure. We\nconsider changes in head anatomy and layers, electrode shape and position,\nmeasurement noise and conductivity values. We then test the networks on several\ndatasets of unseen EIT data, with more complex stroke modeling (different\nshapes and volumes), higher levels of noise and different amounts of electrode\nmisplacement. On most test datasets we achieved $\\geq 90\\%$ average accuracy\nwith fully connected neural networks, while the convolutional ones had worse\nperformances. Despite the use of simple neural network architectures, the\nresults obtained are very promising and motivate the applications of EIT-based\nclassification methods on real phantoms and ultimately on human patients.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 14:22:05 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Candiani", "Valentina", ""], ["Santacesaria", "Matteo", ""]]}, {"id": "2011.02863", "submitter": "Meike Nauta", "authors": "Meike Nauta, Annemarie Jutte, Jesper Provoost, Christin Seifert", "title": "This Looks Like That, Because ... Explaining Prototypes for\n  Interpretable Image Recognition", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image recognition with prototypes is considered an interpretable alternative\nfor black box deep learning models. Classification depends on the extent to\nwhich a test image \"looks like\" a prototype. However, perceptual similarity for\nhumans can be different from the similarity learned by the classification\nmodel. Hence, only visualising prototypes can be insufficient for a user to\nunderstand what a prototype exactly represents, and why the model considers a\nprototype and an image to be similar. We address this ambiguity and argue that\nprototypes should be explained. We improve interpretability by automatically\nenhancing visual prototypes with textual quantitative information about visual\ncharacteristics deemed important by the classification model. Specifically, our\nmethod clarifies the meaning of a prototype by quantifying the influence of\ncolour hue, shape, texture, contrast and saturation and can generate both\nglobal and local explanations. Because of the generality of our approach, it\ncan improve the interpretability of any similarity-based method for\nprototypical image recognition. In our experiments, we apply our method to the\nexisting Prototypical Part Network (ProtoPNet). Our analysis confirms that the\nglobal explanations are generalisable, and often correspond to the visually\nperceptible properties of a prototype. Our explanations are especially relevant\nfor prototypes which might have been interpreted incorrectly otherwise. By\nexplaining such 'misleading' prototypes, we improve the interpretability and\nsimulatability of a prototype-based classification model. We also use our\nmethod to check whether visually similar prototypes have similar explanations,\nand are able to discover redundancy. Code is available at\nhttps://github.com/M-Nauta/Explaining_Prototypes .\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 14:43:07 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 07:13:23 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Nauta", "Meike", ""], ["Jutte", "Annemarie", ""], ["Provoost", "Jesper", ""], ["Seifert", "Christin", ""]]}, {"id": "2011.02872", "submitter": "Sharu Theresa Jose", "authors": "Sharu Theresa Jose, Osvaldo Simeone, Giuseppe Durisi", "title": "Transfer Meta-Learning: Information-Theoretic Bounds and Information\n  Meta-Risk Minimization", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning automatically infers an inductive bias by observing data from a\nnumber of related tasks. The inductive bias is encoded by hyperparameters that\ndetermine aspects of the model class or training algorithm, such as\ninitialization or learning rate. Meta-learning assumes that the learning tasks\nbelong to a task environment, and that tasks are drawn from the same task\nenvironment both during meta-training and meta-testing. This, however, may not\nhold true in practice. In this paper, we introduce the problem of transfer\nmeta-learning, in which tasks are drawn from a target task environment during\nmeta-testing that may differ from the source task environment observed during\nmeta-training. Novel information-theoretic upper bounds are obtained on the\ntransfer meta-generalization gap, which measures the difference between the\nmeta-training loss, available at the meta-learner, and the average loss on\nmeta-test data from a new, randomly selected, task in the target task\nenvironment. The first bound, on the average transfer meta-generalization gap,\ncaptures the meta-environment shift between source and target task environments\nvia the KL divergence between source and target data distributions. The second,\nPAC-Bayesian bound, and the third, single-draw bound, account for this shift\nvia the log-likelihood ratio between source and target task distributions.\nFurthermore, two transfer meta-learning solutions are introduced. For the\nfirst, termed Empirical Meta-Risk Minimization (EMRM), we derive bounds on the\naverage optimality gap. The second, referred to as Information Meta-Risk\nMinimization (IMRM), is obtained by minimizing the PAC-Bayesian bound. IMRM is\nshown via experiments to potentially outperform EMRM.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:55:43 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 23:44:23 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jose", "Sharu Theresa", ""], ["Simeone", "Osvaldo", ""], ["Durisi", "Giuseppe", ""]]}, {"id": "2011.02874", "submitter": "Bruno M Rocha", "authors": "Bruno M. Rocha, Diogo Pessoa, Alda Marques, Paulo Carvalho, Rui Pedro\n  Paiva", "title": "Influence of Event Duration on Automatic Wheeze Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with respiratory conditions typically exhibit adventitious\nrespiratory sounds, such as wheezes. Wheeze events have variable duration. In\nthis work we studied the influence of event duration on wheeze classification,\nnamely how the creation of the non-wheeze class affected the classifiers'\nperformance. First, we evaluated several classifiers on an open access\nrespiratory sound database, with the best one reaching sensitivity and\nspecificity values of 98% and 95%, respectively. Then, by changing one\nparameter in the design of the non-wheeze class, i.e., event duration, the best\nclassifier only reached sensitivity and specificity values of 55% and 76%,\nrespectively. These results demonstrate the importance of experimental design\non the assessment of wheeze classification algorithms' performance.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 11:03:25 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Rocha", "Bruno M.", ""], ["Pessoa", "Diogo", ""], ["Marques", "Alda", ""], ["Carvalho", "Paulo", ""], ["Paiva", "Rui Pedro", ""]]}, {"id": "2011.02876", "submitter": "Sitong Mao", "authors": "Sitong Mao, Xiao Shen, Fu-lai Chung", "title": "Against Adversarial Learning: Naturally Distinguish Known and Unknown in\n  Open Set Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open set domain adaptation refers to the scenario that the target domain\ncontains categories that do not exist in the source domain. It is a more common\nsituation in the reality compared with the typical closed set domain adaptation\nwhere the source domain and the target domain contain the same categories. The\nmain difficulty of open set domain adaptation is that we need to distinguish\nwhich target data belongs to the unknown classes when machine learning models\nonly have concepts about what they know. In this paper, we propose an \"against\nadversarial learning\" method that can distinguish unknown target data and known\ndata naturally without setting any additional hyper parameters and the target\ndata predicted to the known classes can be classified at the same time.\nExperimental results show that the proposed method can make significant\nimprovement in performance compared with several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 10:30:43 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Mao", "Sitong", ""], ["Shen", "Xiao", ""], ["Chung", "Fu-lai", ""]]}, {"id": "2011.02877", "submitter": "Sitong Mao", "authors": "Sitong Mao, Keli Zhang, Fu-lai Chung", "title": "Mixed Set Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the settings of conventional domain adaptation, categories of the source\ndataset are from the same domain (or domains for multi-source domain\nadaptation), which is not always true in reality. In this paper, we propose\n\\textbf{\\textit{Mixed Set Domain Adaptation} (MSDA)}. Under the settings of\nMSDA, different categories of the source dataset are not all collected from the\nsame domain(s). For instance, category $1\\sim k$ are collected from domain\n$\\alpha$ while category $k+1\\sim c$ are collected from domain $\\beta$. Under\nsuch situation, domain adaptation performance will be further influenced\nbecause of the distribution discrepancy inside the source data. A feature\nelement-wise weighting (FEW) method that can reduce distribution discrepancy\nbetween different categories is also proposed for MSDA. Experimental results\nand quality analysis show the significance of solving MSDA problem and the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 10:20:10 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Mao", "Sitong", ""], ["Zhang", "Keli", ""], ["Chung", "Fu-lai", ""]]}, {"id": "2011.02881", "submitter": "Hai Shu", "authors": "Chenggang Lyu, Hai Shu", "title": "A Two-Stage Cascade Model with Variational Autoencoders and Attention\n  Gates for MRI Brain Tumor Segmentation", "comments": null, "journal-ref": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic\n  Brain Injuries (BrainLes 2020)", "doi": "10.1007/978-3-030-72084-1_39", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic MRI brain tumor segmentation is of vital importance for the disease\ndiagnosis, monitoring, and treatment planning. In this paper, we propose a\ntwo-stage encoder-decoder based model for brain tumor subregional segmentation.\nVariational autoencoder regularization is utilized in both stages to prevent\nthe overfitting issue. The second-stage network adopts attention gates and is\ntrained additionally using an expanded dataset formed by the first-stage\noutputs. On the BraTS 2020 validation dataset, the proposed method achieves the\nmean Dice score of 0.9041, 0.8350, and 0.7958, and Hausdorff distance (95%) of\n4.953, 6.299, and 23.608 for the whole tumor, tumor core, and enhancing tumor,\nrespectively. The corresponding results on the BraTS 2020 testing dataset are\n0.8729, 0.8357, and 0.8205 for Dice score, and 11.4288, 19.9690, and 15.6711\nfor Hausdorff distance. The code is publicly available at\nhttps://github.com/shu-hai/two-stage-VAE-Attention-gate-BraTS2020.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 05:55:06 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 06:48:15 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Lyu", "Chenggang", ""], ["Shu", "Hai", ""]]}, {"id": "2011.02883", "submitter": "Yan Huang Dr.", "authors": "Junjie Pang, Jianbo Li, Zhenzhen Xie, Yan Huang, Zhipeng Cai", "title": "Collaborative City Digital Twin For Covid-19 Pandemic: A Federated\n  Learning Solution", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a collaborative city digital twin based on FL, a\nnovel paradigm that allowing multiple city DT to share the local strategy and\nstatus in a timely manner. In particular, an FL central server manages the\nlocal updates of multiple collaborators (city DT), provides a global model\nwhich is trained in multiple iterations at different city DT systems, until the\nmodel gains the correlations between various response plan and infection trend.\nThat means, a collaborative city DT paradigm based on FL techniques can obtain\nknowledge and patterns from multiple DTs, and eventually establish a `global\nview' for city crisis management. Meanwhile, it also helps to improve each city\ndigital twin selves by consolidating other DT's respective data without\nviolating privacy rules. To validate the proposed solution, we take COVID-19\npandemic as a case study. The experimental results on the real dataset with\nvarious response plan validate our proposed solution and demonstrate the\nsuperior performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 15:20:31 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pang", "Junjie", ""], ["Li", "Jianbo", ""], ["Xie", "Zhenzhen", ""], ["Huang", "Yan", ""], ["Cai", "Zhipeng", ""]]}, {"id": "2011.02886", "submitter": "Antonio Carta", "authors": "Antonio Carta, Alessandro Sperduti, Davide Bacciu", "title": "Short-Term Memory Optimization in Recurrent Neural Networks by\n  Autoencoder-based Initialization", "comments": "Accepted at NeurIPS 2020 workshop \"Beyond Backpropagation: Novel\n  Ideas for Training Neural Architectures\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training RNNs to learn long-term dependencies is difficult due to vanishing\ngradients. We explore an alternative solution based on explicit memorization\nusing linear autoencoders for sequences, which allows to maximize the\nshort-term memory and that can be solved with a closed-form solution without\nbackpropagation. We introduce an initialization schema that pretrains the\nweights of a recurrent neural network to approximate the linear autoencoder of\nthe input sequences and we show how such pretraining can better support solving\nhard classification tasks with long sequences. We test our approach on\nsequential and permuted MNIST. We show that the proposed approach achieves a\nmuch lower reconstruction error for long sequences and a better gradient\npropagation during the finetuning phase.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 14:57:16 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Carta", "Antonio", ""], ["Sperduti", "Alessandro", ""], ["Bacciu", "Davide", ""]]}, {"id": "2011.02887", "submitter": "Diego Kozlowski", "authors": "Diego Kozlowski, Jennifer Dusdal, Jun Pang and Andreas Zilian", "title": "Semantic and Relational Spaces in Science of Science: Deep Learning\n  Models for Article Vectorisation", "comments": null, "journal-ref": null, "doi": "10.1007/s11192-021-03984-1", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last century, we observe a steady and exponentially growth of\nscientific publications globally. The overwhelming amount of available\nliterature makes a holistic analysis of the research within a field and between\nfields based on manual inspection impossible. Automatic techniques to support\nthe process of literature review are required to find the epistemic and social\npatterns that are embedded in scientific publications. In computer sciences,\nnew tools have been developed to deal with large volumes of data. In\nparticular, deep learning techniques open the possibility of automated\nend-to-end models to project observations to a new, low-dimensional space where\nthe most relevant information of each observation is highlighted. Using deep\nlearning to build new representations of scientific publications is a growing\nbut still emerging field of research. The aim of this paper is to discuss the\npotential and limits of deep learning for gathering insights about scientific\nresearch articles. We focus on document-level embeddings based on the semantic\nand relational aspects of articles, using Natural Language Processing (NLP) and\nGraph Neural Networks (GNNs). We explore the different outcomes generated by\nthose techniques. Our results show that using NLP we can encode a semantic\nspace of articles, while with GNN we are able to build a relational space where\nthe social practices of a research community are also encoded.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 14:57:41 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kozlowski", "Diego", ""], ["Dusdal", "Jennifer", ""], ["Pang", "Jun", ""], ["Zilian", "Andreas", ""]]}, {"id": "2011.02893", "submitter": "Chaochao Yan", "authors": "Chaochao Yan and Qianggang Ding and Peilin Zhao and Shuangjia Zheng\n  and Jinyu Yang and Yang Yu and Junzhou Huang", "title": "RetroXpert: Decompose Retrosynthesis Prediction like a Chemist", "comments": "17 pages, to appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrosynthesis is the process of recursively decomposing target molecules\ninto available building blocks. It plays an important role in solving problems\nin organic synthesis planning. To automate or assist in the retrosynthesis\nanalysis, various retrosynthesis prediction algorithms have been proposed.\nHowever, most of them are cumbersome and lack interpretability about their\npredictions. In this paper, we devise a novel template-free algorithm for\nautomatic retrosynthetic expansion inspired by how chemists approach\nretrosynthesis prediction. Our method disassembles retrosynthesis into two\nsteps: i) identify the potential reaction center of the target molecule through\na novel graph neural network and generate intermediate synthons, and ii)\ngenerate the reactants associated with synthons via a robust reactant\ngeneration model. While outperforming the state-of-the-art baselines by a\nsignificant margin, our model also provides chemically reasonable\ninterpretation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 04:35:34 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Yan", "Chaochao", ""], ["Ding", "Qianggang", ""], ["Zhao", "Peilin", ""], ["Zheng", "Shuangjia", ""], ["Yang", "Jinyu", ""], ["Yu", "Yang", ""], ["Huang", "Junzhou", ""]]}, {"id": "2011.02909", "submitter": "Luca Pasqualini", "authors": "Luca Pasqualini and Maurizio Parton", "title": "Pseudo Random Number Generation through Reinforcement Learning and\n  Recurrent Neural Networks", "comments": "14 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:1912.11531", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Pseudo-Random Number Generator (PRNG) is any algorithm generating a\nsequence of numbers approximating properties of random numbers. These numbers\nare widely employed in mid-level cryptography and in software applications.\nTest suites are used to evaluate PRNGs quality by checking statistical\nproperties of the generated sequences. These sequences are commonly represented\nbit by bit. This paper proposes a Reinforcement Learning (RL) approach to the\ntask of generating PRNGs from scratch by learning a policy to solve a partially\nobservable Markov Decision Process (MDP), where the full state is the period of\nthe generated sequence and the observation at each time step is the last\nsequence of bits appended to such state. We use a Long-Short Term Memory (LSTM)\narchitecture to model the temporal relationship between observations at\ndifferent time steps, by tasking the LSTM memory with the extraction of\nsignificant features of the hidden portion of the MDP's states. We show that\nmodeling a PRNG with a partially observable MDP and a LSTM architecture largely\nimproves the results of the fully observable feedforward RL approach introduced\nin previous work.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 10:53:23 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 14:55:48 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Pasqualini", "Luca", ""], ["Parton", "Maurizio", ""]]}, {"id": "2011.02917", "submitter": "Alessandro Suglia", "authors": "Alessandro Suglia, Antonio Vergari, Ioannis Konstas, Yonatan Bisk,\n  Emanuele Bastianelli, Andrea Vanzo, Oliver Lemon", "title": "Imagining Grounded Conceptual Representations from Perceptual\n  Information in Situated Guessing Games", "comments": "Accepted to the International Conference on Computational Linguistics\n  (COLING) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In visual guessing games, a Guesser has to identify a target object in a\nscene by asking questions to an Oracle. An effective strategy for the players\nis to learn conceptual representations of objects that are both discriminative\nand expressive enough to ask questions and guess correctly. However, as shown\nby Suglia et al. (2020), existing models fail to learn truly multi-modal\nrepresentations, relying instead on gold category labels for objects in the\nscene both at training and inference time. This provides an unnatural\nperformance advantage when categories at inference time match those at training\ntime, and it causes models to fail in more realistic \"zero-shot\" scenarios\nwhere out-of-domain object categories are involved. To overcome this issue, we\nintroduce a novel \"imagination\" module based on Regularized Auto-Encoders, that\nlearns context-aware and category-aware latent embeddings without relying on\ncategory labels at inference time. Our imagination module outperforms\nstate-of-the-art competitors by 8.26% gameplay accuracy in the CompGuessWhat?!\nzero-shot scenario (Suglia et al., 2020), and it improves the Oracle and\nGuesser accuracy by 2.08% and 12.86% in the GuessWhat?! benchmark, when no gold\ncategories are available at inference time. The imagination module also boosts\nreasoning about object properties and attributes.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 15:42:29 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Suglia", "Alessandro", ""], ["Vergari", "Antonio", ""], ["Konstas", "Ioannis", ""], ["Bisk", "Yonatan", ""], ["Bastianelli", "Emanuele", ""], ["Vanzo", "Andrea", ""], ["Lemon", "Oliver", ""]]}, {"id": "2011.02948", "submitter": "Guy Amir", "authors": "Guy Amir, Haoze Wu, Clark Barrett and Guy Katz", "title": "An SMT-Based Approach for Verifying Binarized Neural Networks", "comments": "This is a preprint version of a paper that will appear at TACAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as an effective approach for creating modern\nsoftware systems, with neural networks often surpassing hand-crafted systems.\nUnfortunately, neural networks are known to suffer from various safety and\nsecurity issues. Formal verification is a promising avenue for tackling this\ndifficulty, by formally certifying that networks are correct. We propose an\nSMT-based technique for verifying Binarized Neural Networks - a popular kind of\nneural network, where some weights have been binarized in order to render the\nneural network more memory and energy efficient, and quicker to evaluate. One\nnovelty of our technique is that it allows the verification of neural networks\nthat include both binarized and non-binarized components. Neural network\nverification is computationally very difficult, and so we propose here various\noptimizations, integrated into our SMT procedure as deduction steps, as well as\nan approach for parallelizing verification queries. We implement our technique\nas an extension to the Marabou framework, and use it to evaluate the approach\non popular binarized neural network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:21:26 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 08:41:37 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Amir", "Guy", ""], ["Wu", "Haoze", ""], ["Barrett", "Clark", ""], ["Katz", "Guy", ""]]}, {"id": "2011.02949", "submitter": "Paul Primus", "authors": "Paul Primus, Verena Haunschmid, Patrick Praher, and Gerhard Widmer", "title": "Anomalous Sound Detection as a Simple Binary Classification Problem with\n  Careful Selection of Proxy Outlier Examples", "comments": "published in DCASE 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised anomalous sound detection is concerned with identifying sounds\nthat deviate from what is defined as 'normal', without explicitly specifying\nthe types of anomalies. A significant obstacle is the diversity and rareness of\noutliers, which typically prevent us from collecting a representative set of\nanomalous sounds. As a consequence, most anomaly detection methods use\nunsupervised rather than supervised machine learning methods. Nevertheless, we\nwill show that anomalous sound detection can be effectively framed as a\nsupervised classification problem if the set of anomalous samples is carefully\nsubstituted with what we call proxy outliers. Candidates for proxy outliers are\navailable in abundance as they potentially include all recordings that are\nneither normal nor abnormal sounds. We experiment with the machine condition\nmonitoring data set of the 2020's DCASE Challenge and find proxy outliers with\nmatching recording conditions and high similarity to the target sounds\nparticularly informative. If no data with similar sounds and matching recording\nconditions is available, data sets with a larger diversity in these two\ndimensions are preferable. Our models based on supervised training with proxy\noutliers achieved rank three in Task 2 of the DCASE2020 Challenge.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:22:46 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Primus", "Paul", ""], ["Haunschmid", "Verena", ""], ["Praher", "Patrick", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2011.02952", "submitter": "Sebastian Buschj\\\"ager", "authors": "Sebastian Buschj\\\"ager, Lukas Pfahler, Katharina Morik", "title": "Generalized Negative Correlation Learning for Deep Ensembling", "comments": "12 (+8) pages, 1(+1) figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble algorithms offer state of the art performance in many machine\nlearning applications. A common explanation for their excellent performance is\ndue to the bias-variance decomposition of the mean squared error which shows\nthat the algorithm's error can be decomposed into its bias and variance. Both\nquantities are often opposed to each other and ensembles offer an effective way\nto manage them as they reduce the variance through a diverse set of base\nlearners while keeping the bias low at the same time. Even though there have\nbeen numerous works on decomposing other loss functions, the exact mathematical\nconnection is rarely exploited explicitly for ensembling, but merely used as a\nguiding principle. In this paper, we formulate a generalized bias-variance\ndecomposition for arbitrary twice differentiable loss functions and study it in\nthe context of Deep Learning. We use this decomposition to derive a Generalized\nNegative Correlation Learning (GNCL) algorithm which offers explicit control\nover the ensemble's diversity and smoothly interpolates between the two\nextremes of independent training and the joint training of the ensemble. We\nshow how GNCL encapsulates many previous works and discuss under which\ncircumstances training of an ensemble of Neural Networks might fail and what\nensembling method should be favored depending on the choice of the individual\nnetworks. We make our code publicly available under\nhttps://github.com/sbuschjaeger/gncl\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:29:22 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 08:19:49 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Buschj\u00e4ger", "Sebastian", ""], ["Pfahler", "Lukas", ""], ["Morik", "Katharina", ""]]}, {"id": "2011.02955", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Florian Henkel, Hamid Eghbal-zadeh, Gerhard Widmer", "title": "Low-Complexity Models for Acoustic Scene Classification Based on\n  Receptive Field Regularization and Frequency Damping", "comments": "Proceedings of the Detection and Classification of Acoustic Scenes\n  and Events 2020 Workshop (DCASE2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks are known to be very demanding in terms of computing and\nmemory requirements. Due to the ever increasing use of embedded systems and\nmobile devices with a limited resource budget, designing low-complexity models\nwithout sacrificing too much of their predictive performance gained great\nimportance. In this work, we investigate and compare several well-known methods\nto reduce the number of parameters in neural networks. We further put these\ninto the context of a recent study on the effect of the Receptive Field (RF) on\na model's performance, and empirically show that we can achieve high-performing\nlow-complexity models by applying specific restrictions on the RFs, in\ncombination with parameter reduction methods. Additionally, we propose a\nfilter-damping technique for regularizing the RF of models, without altering\ntheir architecture and changing their parameter counts. We will show that\nincorporating this technique improves the performance in various low-complexity\nsettings such as pruning and decomposed convolution. Using our proposed filter\ndamping, we achieved the 1st rank at the DCASE-2020 Challenge in the task of\nLow-Complexity Acoustic Scene Classification.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:34:11 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Koutini", "Khaled", ""], ["Henkel", "Florian", ""], ["Eghbal-zadeh", "Hamid", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2011.02956", "submitter": "David Peer", "authors": "David Peer, Sebastian Stabinger, Antonio Rodriguez-Sanchez", "title": "Conflicting Bundles: Adapting Architectures Towards the Improved\n  Training of Deep Neural Networks", "comments": "Accepted at WACV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing neural network architectures is a challenging task and knowing\nwhich specific layers of a model must be adapted to improve the performance is\nalmost a mystery. In this paper, we introduce a novel theory and metric to\nidentify layers that decrease the test accuracy of the trained models, this\nidentification is done as early as at the beginning of training. In the\nworst-case, such a layer could lead to a network that can not be trained at\nall. More precisely, we identified those layers that worsen the performance\nbecause they produce conflicting training bundles as we show in our novel\ntheoretical analysis, complemented by our extensive empirical studies. Based on\nthese findings, a novel algorithm is introduced to remove performance\ndecreasing layers automatically. Architectures found by this algorithm achieve\na competitive accuracy when compared against the state-of-the-art\narchitectures. While keeping such high accuracy, our approach drastically\nreduces memory consumption and inference time for different computer vision\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:41:04 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Peer", "David", ""], ["Stabinger", "Sebastian", ""], ["Rodriguez-Sanchez", "Antonio", ""]]}, {"id": "2011.02962", "submitter": "Ramesha Karunasena", "authors": "Ramesha Karunasena, Mohammad Sarparajul Ambiya, Arunesh Sinha, Ruchit\n  Nagar, Saachi Dalal, Divy Thakkar, Dhyanesh Narayanan, Milind Tambe", "title": "Measuring Data Collection Diligence for Community Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analytics has tremendous potential to provide targeted benefit in\nlow-resource communities, however the availability of high-quality public\nhealth data is a significant challenge in developing countries primarily due to\nnon-diligent data collection by community health workers (CHWs). In this work,\nwe define and test a data collection diligence score. This challenging\nunlabeled data problem is handled by building upon domain expert's guidance to\ndesign a useful data representation of the raw data, using which we design a\nsimple and natural score. An important aspect of the score is relative scoring\nof the CHWs, which implicitly takes into account the context of the local area.\nThe data is also clustered and interpreting these clusters provides a natural\nexplanation of the past behavior of each data collector. We further predict the\ndiligence score for future time steps. Our framework has been validated on the\nground using observations by the field monitors of our partner NGO in India.\nBeyond the successful field test, our work is in the final stages of deployment\nin the state of Rajasthan, India.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:45:03 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 03:51:09 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 10:20:28 GMT"}, {"version": "v4", "created": "Fri, 13 Nov 2020 02:33:28 GMT"}, {"version": "v5", "created": "Wed, 7 Apr 2021 15:16:09 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Karunasena", "Ramesha", ""], ["Ambiya", "Mohammad Sarparajul", ""], ["Sinha", "Arunesh", ""], ["Nagar", "Ruchit", ""], ["Dalal", "Saachi", ""], ["Thakkar", "Divy", ""], ["Narayanan", "Dhyanesh", ""], ["Tambe", "Milind", ""]]}, {"id": "2011.02966", "submitter": "Marco Cerezo Ph.D", "authors": "Arthur Pesah, M. Cerezo, Samson Wang, Tyler Volkoff, Andrew T.\n  Sornborger, Patrick J. Coles", "title": "Absence of Barren Plateaus in Quantum Convolutional Neural Networks", "comments": "9 + 20 pages, 7 + 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-29031", "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum neural networks (QNNs) have generated excitement around the\npossibility of efficiently analyzing quantum data. But this excitement has been\ntempered by the existence of exponentially vanishing gradients, known as barren\nplateau landscapes, for many QNN architectures. Recently, Quantum Convolutional\nNeural Networks (QCNNs) have been proposed, involving a sequence of\nconvolutional and pooling layers that reduce the number of qubits while\npreserving information about relevant data features. In this work we rigorously\nanalyze the gradient scaling for the parameters in the QCNN architecture. We\nfind that the variance of the gradient vanishes no faster than polynomially,\nimplying that QCNNs do not exhibit barren plateaus. This provides an analytical\nguarantee for the trainability of randomly initialized QCNNs, which singles out\nQCNNs as being trainable unlike many other QNN architectures. To derive our\nresults we introduce a novel graph-based method to analyze expectation values\nover Haar-distributed unitaries, which will likely be useful in other contexts.\nFinally, we perform numerical simulations to verify our analytical results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:46:13 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pesah", "Arthur", ""], ["Cerezo", "M.", ""], ["Wang", "Samson", ""], ["Volkoff", "Tyler", ""], ["Sornborger", "Andrew T.", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2011.02970", "submitter": "Mahdi Haghifam", "authors": "Mahdi Haghifam, Gintare Karolina Dziugaite, Shay Moran, Daniel M. Roy", "title": "On the Information Complexity of Proper Learners for VC Classes in the\n  Realizable Case", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a negative resolution to a conjecture of Steinke and Zakynthinou\n(2020a), by showing that their bound on the conditional mutual information\n(CMI) of proper learners of Vapnik--Chervonenkis (VC) classes cannot be\nimproved from $d \\log n +2$ to $O(d)$, where $n$ is the number of i.i.d.\ntraining examples. In fact, we exhibit VC classes for which the CMI of any\nproper learner cannot be bounded by any real-valued function of the VC\ndimension only.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:55:33 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Haghifam", "Mahdi", ""], ["Dziugaite", "Gintare Karolina", ""], ["Moran", "Shay", ""], ["Roy", "Daniel M.", ""]]}, {"id": "2011.02987", "submitter": "Guanghui Lan", "authors": "Georgios Kotsalis, Guanghui Lan, Tianjiao Li", "title": "Simple and optimal methods for stochastic variational inequalities, I:\n  operator extrapolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we first present a novel operator extrapolation (OE) method for\nsolving deterministic variational inequality (VI) problems. Similar to the\ngradient (operator) projection method, OE updates one single search sequence by\nsolving a single projection subproblem in each iteration. We show that OE can\nachieve the optimal rate of convergence for solving a variety of VI problems in\na much simpler way than existing approaches. We then introduce the stochastic\noperator extrapolation (SOE) method and establish its optimal convergence\nbehavior for solving different stochastic VI problems. In particular, SOE\nachieves the optimal complexity for solving a fundamental problem, i.e.,\nstochastic smooth and strongly monotone VI, for the first time in the\nliterature. We also present a stochastic block operator extrapolations (SBOE)\nmethod to further reduce the iteration cost for the OE method applied to\nlarge-scale deterministic VIs with a certain block structure. Numerical\nexperiments have been conducted to demonstrate the potential advantages of the\nproposed algorithms. In fact, all these algorithms are applied to solve\ngeneralized monotone variational inequality (GMVI) problems whose operator is\nnot necessarily monotone. We will also discuss optimal OE-based policy\nevaluation methods for reinforcement learning in a companion paper.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 17:20:19 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 04:12:37 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 00:26:01 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Kotsalis", "Georgios", ""], ["Lan", "Guanghui", ""], ["Li", "Tianjiao", ""]]}, {"id": "2011.02999", "submitter": "Kiwan Maeng", "authors": "Kiwan Maeng, Shivam Bharuka, Isabel Gao, Mark C. Jeffrey, Vikram\n  Saraph, Bor-Yiing Su, Caroline Trippel, Jiyan Yang, Mike Rabbat, Brandon\n  Lucia, Carole-Jean Wu", "title": "CPR: Understanding and Improving Failure Tolerant Training for Deep\n  Learning Recommendation with Partial Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes and optimizes a partial recovery training system, CPR, for\nrecommendation models. CPR relaxes the consistency requirement by enabling\nnon-failed nodes to proceed without loading checkpoints when a node fails\nduring training, improving failure-related overheads. The paper is the first to\nthe extent of our knowledge to perform a data-driven, in-depth analysis of\napplying partial recovery to recommendation models and identified a trade-off\nbetween accuracy and performance. Motivated by the analysis, we present CPR, a\npartial recovery training system that can reduce the training time and maintain\nthe desired level of model accuracy by (1) estimating the benefit of partial\nrecovery, (2) selecting an appropriate checkpoint saving interval, and (3)\nprioritizing to save updates of more frequently accessed parameters. Two\nvariants of CPR, CPR-MFU and CPR-SSU, reduce the checkpoint-related overhead\nfrom 8.2-8.5% to 0.53-0.68% compared to full recovery, on a configuration\nemulating the failure pattern and overhead of a production-scale cluster. While\nreducing overhead significantly, CPR achieves model quality on par with the\nmore expensive full recovery scheme, training the state-of-the-art\nrecommendation model using Criteo's Ads CTR dataset. Our preliminary results\nalso suggest that CPR can speed up training on a real production-scale cluster,\nwithout notably degrading the accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 17:54:35 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Maeng", "Kiwan", ""], ["Bharuka", "Shivam", ""], ["Gao", "Isabel", ""], ["Jeffrey", "Mark C.", ""], ["Saraph", "Vikram", ""], ["Su", "Bor-Yiing", ""], ["Trippel", "Caroline", ""], ["Yang", "Jiyan", ""], ["Rabbat", "Mike", ""], ["Lucia", "Brandon", ""], ["Wu", "Carole-Jean", ""]]}, {"id": "2011.03010", "submitter": "Calvin Luo", "authors": "Calvin Luo, Hossein Mobahi, Samy Bengio", "title": "Data Augmentation via Structured Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a major component of many machine learning methods with\nstate-of-the-art performance. Common augmentation strategies work by drawing\nrandom samples from a space of transformations. Unfortunately, such sampling\napproaches are limited in expressivity, as they are unable to scale to rich\ntransformations that depend on numerous parameters due to the curse of\ndimensionality. Adversarial examples can be considered as an alternative scheme\nfor data augmentation. By being trained on the most difficult modifications of\nthe inputs, the resulting models are then hopefully able to handle other,\npresumably easier, modifications as well. The advantage of adversarial\naugmentation is that it replaces sampling with the use of a single, calculated\nperturbation that maximally increases the loss. The downside, however, is that\nthese raw adversarial perturbations appear rather unstructured; applying them\noften does not produce a natural transformation, contrary to a desirable data\naugmentation technique. To address this, we propose a method to generate\nadversarial examples that maintain some desired natural structure. We first\nconstruct a subspace that only contains perturbations with the desired\nstructure. We then project the raw adversarial gradient onto this space to\nselect a structured transformation that would maximally increase the loss when\napplied. We demonstrate this approach through two types of image\ntransformations: photometric and geometric. Furthermore, we show that training\non such structured adversarial images improves generalization.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:07:55 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Luo", "Calvin", ""], ["Mobahi", "Hossein", ""], ["Bengio", "Samy", ""]]}, {"id": "2011.03028", "submitter": "Razvan Bunescu", "authors": "Patrick Gray and Razvan Bunescu", "title": "From Note-Level to Chord-Level Neural Network Models for Voice\n  Separation in Symbolic Music", "comments": "Paper submitted for publication in August 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music is often experienced as a progression of concurrent streams of notes,\nor voices. The degree to which this happens depends on the position along a\nvoice-leading continuum, ranging from monophonic, to homophonic, to polyphonic,\nwhich complicates the design of automatic voice separation models. We address\nthis continuum by defining voice separation as the task of decomposing music\ninto streams that exhibit both a high degree of external perceptual separation\nfrom the other streams and a high degree of internal perceptual consistency.\nThe proposed voice separation task allows for a voice to diverge to multiple\nvoices and also for multiple voices to converge to the same voice. Equipped\nwith this flexible task definition, we manually annotated a corpus of popular\nmusic and used it to train neural networks that assign notes to voices either\nseparately for each note in a chord (note-level), or jointly to all notes in a\nchord (chord-level). The trained neural models greedily assign notes to voices\nin a left to right traversal of the input chord sequence, using a diverse set\nof perceptually informed input features. When evaluated on the extraction of\nconsecutive within voice note pairs, both models surpass a strong baseline\nbased on an iterative application of an envelope extraction function, with the\nchord-level model consistently edging out the note-level model. The two models\nare also shown to outperform previous approaches on separating the voices in\nBach music.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:39:42 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gray", "Patrick", ""], ["Bunescu", "Razvan", ""]]}, {"id": "2011.03030", "submitter": "Nathan Kallus", "authors": "Yichun Hu, Nathan Kallus, Xiaojie Mao", "title": "Fast Rates for Contextual Linear Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating side observations in decision making can reduce uncertainty and\nboost performance, but it also requires we tackle a potentially complex\npredictive relationship. While one may use off-the-shelf machine learning\nmethods to separately learn a predictive model and plug it in, a variety of\nrecent methods instead integrate estimation and optimization by fitting the\nmodel to directly optimize downstream decision performance. Surprisingly, in\nthe case of contextual linear optimization, we show that the naive plug-in\napproach actually achieves regret convergence rates that are significantly\nfaster than methods that directly optimize downstream decision performance. We\nshow this by leveraging the fact that specific problem instances do not have\narbitrarily bad near-dual-degeneracy. While there are other pros and cons to\nconsider as we discuss and illustrate numerically, our results highlight a\nnuanced landscape for the enterprise to integrate estimation and optimization.\nOur results are overall positive for practice: predictive models are easy and\nfast to train using existing tools, simple to interpret, and, as we show, lead\nto decisions that perform very well.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:43:59 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:53:47 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hu", "Yichun", ""], ["Kallus", "Nathan", ""], ["Mao", "Xiaojie", ""]]}, {"id": "2011.03037", "submitter": "Aniruddh Raghu", "authors": "Aniruddh Raghu, Maithra Raghu, Simon Kornblith, David Duvenaud,\n  Geoffrey Hinton", "title": "Teaching with Commentaries", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective training of deep neural networks can be challenging, and there\nremain many open questions on how to best learn these models. Recently\ndeveloped methods to improve neural network training examine teaching:\nproviding learned information during the training process to improve downstream\nmodel performance. In this paper, we take steps towards extending the scope of\nteaching. We propose a flexible teaching framework using commentaries, learned\nmeta-information helpful for training on a particular task. We present\ngradient-based methods to learn commentaries, leveraging recent work on\nimplicit differentiation for scalability. We explore diverse applications of\ncommentaries, from weighting training examples, to parameterising\nlabel-dependent data augmentation policies, to representing attention masks\nthat highlight salient image regions. We find that commentaries can improve\ntraining speed and/or performance, and provide insights about the dataset and\ntraining process. We also observe that commentaries generalise: they can be\nreused when training new models to obtain performance benefits, suggesting a\nuse-case where commentaries are stored with a dataset and leveraged in future\nfor improved model training.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:52:46 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 00:37:38 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Raghu", "Aniruddh", ""], ["Raghu", "Maithra", ""], ["Kornblith", "Simon", ""], ["Duvenaud", "David", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "2011.03040", "submitter": "Ethan Rudd", "authors": "Ethan M. Rudd and Ahmed Abdallah", "title": "Training Transformers for Information Security Tasks: A Case Study on\n  Malicious URL Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) for information security (InfoSec) utilizes distinct\ndata types and formats which require different treatments during\noptimization/training on raw data. In this paper, we implement a\nmalicious/benign URL predictor based on a transformer architecture that is\ntrained from scratch. We show that in contrast to conventional natural language\nprocessing (NLP) transformers, this model requires a different training\napproach to work well. Specifically, we show that 1) pre-training on a massive\ncorpus of unlabeled URL data for an auto-regressive task does not readily\ntransfer to malicious/benign prediction but 2) that using an auxiliary\nauto-regressive loss improves performance when training from scratch. We\nintroduce a method for mixed objective optimization, which dynamically balances\ncontributions from both loss terms so that neither one of them dominates. We\nshow that this method yields performance comparable to that of several\ntop-performing benchmark classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:58:51 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Rudd", "Ethan M.", ""], ["Abdallah", "Ahmed", ""]]}, {"id": "2011.03043", "submitter": "Nolan Dey", "authors": "Nolan S. Dey and J. Eric Taylor and Bryan P. Tripp and Alexander Wong\n  and Graham W. Taylor", "title": "Identifying and interpreting tuning dimensions in deep networks", "comments": "15 pages, 12 figures, Camera-ready for Shared Visual Representations\n  in Human & Machine Intelligence NeurIPS Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, a tuning dimension is a stimulus attribute that accounts for\nmuch of the activation variance of a group of neurons. These are commonly used\nto decipher the responses of such groups. While researchers have attempted to\nmanually identify an analogue to these tuning dimensions in deep neural\nnetworks, we are unaware of an automatic way to discover them. This work\ncontributes an unsupervised framework for identifying and interpreting \"tuning\ndimensions\" in deep networks. Our method correctly identifies the tuning\ndimensions of a synthetic Gabor filter bank and tuning dimensions of the first\ntwo layers of InceptionV1 trained on ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:26:03 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 00:01:04 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Dey", "Nolan S.", ""], ["Taylor", "J. Eric", ""], ["Tripp", "Bryan P.", ""], ["Wong", "Alexander", ""], ["Taylor", "Graham W.", ""]]}, {"id": "2011.03072", "submitter": "Yuan Shangguan", "authors": "Jay Mahadeokar, Yuan Shangguan, Duc Le, Gil Keren, Hang Su, Thong Le,\n  Ching-Feng Yeh, Christian Fuegen, Michael L. Seltzer", "title": "Alignment Restricted Streaming Recurrent Neural Network Transducer", "comments": "Accepted for presentation at IEEE Spoken Language Technology Workshop\n  (SLT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in the speech community in developing Recurrent\nNeural Network Transducer (RNN-T) models for automatic speech recognition (ASR)\napplications. RNN-T is trained with a loss function that does not enforce\ntemporal alignment of the training transcripts and audio. As a result, RNN-T\nmodels built with uni-directional long short term memory (LSTM) encoders tend\nto wait for longer spans of input audio, before streaming already decoded ASR\ntokens. In this work, we propose a modification to the RNN-T loss function and\ndevelop Alignment Restricted RNN-T (Ar-RNN-T) models, which utilize audio-text\nalignment information to guide the loss computation. We compare the proposed\nmethod with existing works, such as monotonic RNN-T, on LibriSpeech and\nin-house datasets. We show that the Ar-RNN-T loss provides a refined control to\nnavigate the trade-offs between the token emission delays and the Word Error\nRate (WER). The Ar-RNN-T models also improve downstream applications such as\nthe ASR End-pointing by guaranteeing token emissions within any given range of\nlatency. Moreover, the Ar-RNN-T loss allows for bigger batch sizes and 4 times\nhigher throughput for our LSTM model architecture, enabling faster training and\nconvergence on GPUs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 19:38:54 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Mahadeokar", "Jay", ""], ["Shangguan", "Yuan", ""], ["Le", "Duc", ""], ["Keren", "Gil", ""], ["Su", "Hang", ""], ["Le", "Thong", ""], ["Yeh", "Ching-Feng", ""], ["Fuegen", "Christian", ""], ["Seltzer", "Michael L.", ""]]}, {"id": "2011.03080", "submitter": "Momchil Hardalov", "authors": "Momchil Hardalov, Todor Mihaylov, Dimitrina Zlatkova, Yoan Dinkov,\n  Ivan Koychev, Preslav Nakov", "title": "EXAMS: A Multi-Subject High School Examinations Dataset for\n  Cross-Lingual and Multilingual Question Answering", "comments": "EMNLP 2020, 17 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose EXAMS -- a new benchmark dataset for cross-lingual and\nmultilingual question answering for high school examinations. We collected more\nthan 24,000 high-quality high school exam questions in 16 languages, covering 8\nlanguage families and 24 school subjects from Natural Sciences and Social\nSciences, among others.\n  EXAMS offers a fine-grained evaluation framework across multiple languages\nand subjects, which allows precise analysis and comparison of various models.\nWe perform various experiments with existing top-performing multilingual\npre-trained models and we show that EXAMS offers multiple challenges that\nrequire multilingual knowledge and reasoning in multiple domains. We hope that\nEXAMS will enable researchers to explore challenging reasoning and knowledge\ntransfer methods and pre-trained models for school question answering in\nvarious languages which was not possible before. The data, code, pre-trained\nmodels, and evaluation are available at https://github.com/mhardalov/exams-qa.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:06:50 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Hardalov", "Momchil", ""], ["Mihaylov", "Todor", ""], ["Zlatkova", "Dimitrina", ""], ["Dinkov", "Yoan", ""], ["Koychev", "Ivan", ""], ["Nakov", "Preslav", ""]]}, {"id": "2011.03083", "submitter": "Souvik Kundu", "authors": "Souvik Kundu, Mahdi Nazemi, Peter A. Beerel, Massoud Pedram", "title": "A Tunable Robust Pruning Framework Through Dynamic Network Rewiring of\n  DNNs", "comments": "8 pages, 4 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a dynamic network rewiring (DNR) method to generate\npruned deep neural network (DNN) models that are robust against adversarial\nattacks yet maintain high accuracy on clean images. In particular, the\ndisclosed DNR method is based on a unified constrained optimization formulation\nusing a hybrid loss function that merges ultra-high model compression with\nrobust adversarial training. This training strategy dynamically adjusts\ninter-layer connectivity based on per-layer normalized momentum computed from\nthe hybrid loss function. In contrast to existing robust pruning frameworks\nthat require multiple training iterations, the proposed learning strategy\nachieves an overall target pruning ratio with only a single training iteration\nand can be tuned to support both irregular and structured channel pruning. To\nevaluate the merits of DNR, experiments were performed with two widely accepted\nmodels, namely VGG16 and ResNet-18, on CIFAR-10, CIFAR-100 as well as with\nVGG16 on Tiny-ImageNet. Compared to the baseline uncompressed models, DNR\nprovides over20x compression on all the datasets with no significant drop in\neither clean or adversarial classification accuracy. Moreover, our experiments\nshow that DNR consistently finds compressed models with better clean and\nadversarial image classification performance than what is achievable through\nstate-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 19:49:00 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 17:40:52 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kundu", "Souvik", ""], ["Nazemi", "Mahdi", ""], ["Beerel", "Peter A.", ""], ["Pedram", "Massoud", ""]]}, {"id": "2011.03089", "submitter": "Razvan Bunescu", "authors": "Kaiyu Shen, Razvan Bunescu and Sarah E. Wyatt", "title": "Mining Functionally Related Genes with Semi-Supervised Learning", "comments": "Submitted for publication in 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of biological processes can greatly benefit from tools that\nautomatically predict gene functions or directly cluster genes based on shared\nfunctionality. Existing data mining methods predict protein functionality by\nexploiting data obtained from high-throughput experiments or meta-scale\ninformation from public databases. Most existing prediction tools are targeted\nat predicting protein functions that are described in the gene ontology (GO).\nHowever, in many cases biologists wish to discover functionally related genes\nfor which GO terms are inadequate. In this paper, we introduce a rich set of\nfeatures and use them in conjunction with semisupervised learning approaches in\norder to expand an initial set of seed genes to a larger cluster of\nfunctionally related genes. Among all the semi-supervised methods that were\nevaluated, the framework of learning with positive and unlabeled examples (LPU)\nis shown to be especially appropriate for mining functionally related genes.\nWhen evaluated on experimentally validated benchmark data, the LPU approaches1\nsignificantly outperform a standard supervised learning algorithm as well as an\nestablished state-of-the-art method. Given an initial set of seed genes, our\nbest performing approach could be used to mine functionally related genes in a\nwide range of organisms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:34:09 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Shen", "Kaiyu", ""], ["Bunescu", "Razvan", ""], ["Wyatt", "Sarah E.", ""]]}, {"id": "2011.03092", "submitter": "El Moatez Billah Nagoudi", "authors": "El Moatez Billah Nagoudi, AbdelRahim Elmadany, Muhammad Abdul-Mageed,\n  Tariq Alhindi, Hasan Cavusoglu", "title": "Machine Generation and Detection of Arabic Manipulated and Fake News", "comments": "10 pages, accepted in The Fifth Arabic Natural Language Processing\n  Workshop (WANLP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake news and deceptive machine-generated text are serious problems\nthreatening modern societies, including in the Arab world. This motivates work\non detecting false and manipulated stories online. However, a bottleneck for\nthis research is lack of sufficient data to train detection models. We present\na novel method for automatically generating Arabic manipulated (and potentially\nfake) news stories. Our method is simple and only depends on availability of\ntrue stories, which are abundant online, and a part of speech tagger (POS). To\nfacilitate future work, we dispense with both of these requirements altogether\nby providing AraNews, a novel and large POS-tagged news dataset that can be\nused off-the-shelf. Using stories generated based on AraNews, we carry out a\nhuman annotation study that casts light on the effects of machine manipulation\non text veracity. The study also measures human ability to detect Arabic\nmachine manipulated text generated by our method. Finally, we develop the first\nmodels for detecting manipulated Arabic news and achieve state-of-the-art\nresults on Arabic fake news detection (macro F1=70.06). Our models and data are\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 20:50:22 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Nagoudi", "El Moatez Billah", ""], ["Elmadany", "AbdelRahim", ""], ["Abdul-Mageed", "Muhammad", ""], ["Alhindi", "Tariq", ""], ["Cavusoglu", "Hasan", ""]]}, {"id": "2011.03096", "submitter": "Tuan Manh Lai", "authors": "Quan Tran, Nhan Dam, Tuan Lai, Franck Dernoncourt, Trung Le, Nham Le\n  and Dinh Phung", "title": "Explain by Evidence: An Explainable Memory-based Neural Network for\n  Question Answering", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability and explainability of deep neural networks are challenging\ndue to their scale, complexity, and the agreeable notions on which the\nexplaining process rests. Previous work, in particular, has focused on\nrepresenting internal components of neural networks through human-friendly\nvisuals and concepts. On the other hand, in real life, when making a decision,\nhuman tends to rely on similar situations and/or associations in the past.\nHence arguably, a promising approach to make the model transparent is to design\nit in a way such that the model explicitly connects the current sample with the\nseen ones, and bases its decision on these samples. Grounded on that principle,\nwe propose in this paper an explainable, evidence-based memory network\narchitecture, which learns to summarize the dataset and extract supporting\nevidences to make its decision. Our model achieves state-of-the-art performance\non two popular question answering datasets (i.e. TrecQA and WikiQA). Via\nfurther analysis, we show that this model can reliably trace the errors it has\nmade in the validation step to the training instances that might have caused\nthese errors. We believe that this error-tracing capability provides\nsignificant benefit in improving dataset quality in many applications.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:18:21 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Tran", "Quan", ""], ["Dam", "Nhan", ""], ["Lai", "Tuan", ""], ["Dernoncourt", "Franck", ""], ["Le", "Trung", ""], ["Le", "Nham", ""], ["Phung", "Dinh", ""]]}, {"id": "2011.03098", "submitter": "Yongsheng Bai", "authors": "Yongsheng Bai, Halil Sezen, Alper Yilmaz", "title": "End-to-end Deep Learning Methods for Automated Damage Detection in\n  Extreme Events at Various Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust Mask R-CNN (Mask Regional Convolu-tional Neural Network) methods are\nproposed and tested for automatic detection of cracks on structures or their\ncomponents that may be damaged during extreme events, such as earth-quakes. We\ncurated a new dataset with 2,021 labeled images for training and validation and\naimed to find end-to-end deep neural networks for crack detection in the field.\nWith data augmentation and parameters fine-tuning, Path Aggregation Network\n(PANet) with spatial attention mechanisms and High-resolution Network (HRNet)\nare introduced into Mask R-CNNs. The tests on three public datasets with low-\nor high-resolution images demonstrate that the proposed methods can achieve a\nbig improvement over alternative networks, so the proposed method may be\nsufficient for crack detection for a variety of scales in real applications.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:21:19 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Bai", "Yongsheng", ""], ["Sezen", "Halil", ""], ["Yilmaz", "Alper", ""]]}, {"id": "2011.03108", "submitter": "Emily Diana", "authors": "Emily Diana, Wesley Gill, Michael Kearns, Krishnaram Kenthapadi, and\n  Aaron Roth", "title": "Minimax Group Fairness: Algorithms and Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a recently introduced framework in which fairness is measured by\nworst-case outcomes across groups, rather than by the more standard differences\nbetween group outcomes. In this framework we provide provably convergent\noracle-efficient learning algorithms (or equivalently, reductions to non-fair\nlearning) for minimax group fairness. Here the goal is that of minimizing the\nmaximum loss across all groups, rather than equalizing group losses. Our\nalgorithms apply to both regression and classification settings and support\nboth overall error and false positive or false negative rates as the fairness\nmeasure of interest. They also support relaxations of the fairness constraints,\nthus permitting study of the tradeoff between overall accuracy and minimax\nfairness. We compare the experimental behavior and performance of our\nalgorithms across a variety of fairness-sensitive data sets and show empirical\ncases in which minimax fairness is strictly and strongly preferable to equal\noutcome notions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:42:56 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 01:19:11 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Diana", "Emily", ""], ["Gill", "Wesley", ""], ["Kearns", "Michael", ""], ["Kenthapadi", "Krishnaram", ""], ["Roth", "Aaron", ""]]}, {"id": "2011.03115", "submitter": "Bolaji Yusuf", "authors": "Bolaji Yusuf, Lucas Ondel, Lukas Burget, Jan Cernocky, Murat Saraclar", "title": "A Hierarchical Subspace Model for Language-Attuned Acoustic Unit\n  Discovery", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a hierarchical subspace model for acoustic unit\ndiscovery. In this approach, we frame the task as one of learning embeddings on\na low-dimensional phonetic subspace, and simultaneously specify the subspace\nitself as an embedding on a hyper-subspace. We train the hyper-subspace on a\nset of transcribed languages and transfer it to the target language. In the\ntarget language, we infer both the language and unit embeddings in an\nunsupervised manner, and in so doing, we simultaneously learn a subspace of\nunits specific to that language and the units that dwell on it. We conduct our\nexperiments on TIMIT and two low-resource languages: Mboshi and Yoruba. Results\nshow that our model outperforms major acoustic unit discovery techniques, both\nin terms of clustering quality and segmentation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:34:19 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 06:55:48 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Yusuf", "Bolaji", ""], ["Ondel", "Lucas", ""], ["Burget", "Lukas", ""], ["Cernocky", "Jan", ""], ["Saraclar", "Murat", ""]]}, {"id": "2011.03118", "submitter": "Trideba Padhi Dr.", "authors": "Trideba Padhi, Astik Biswas, Febe De Wet, Ewald van der Westhuizen,\n  Thomas Niesler", "title": "Multilingual Bottleneck Features for Improving ASR Performance of\n  Code-Switched Speech in Under-Resourced Languages", "comments": "In Proceedings of The First Workshop on Speech Technologies for\n  Code-Switching in Multilingual Communities", "journal-ref": "http://festvox.org/cedar/WSTCSMC2020.pdf", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we explore the benefits of using multilingual bottleneck\nfeatures (mBNF) in acoustic modelling for the automatic speech recognition of\ncode-switched (CS) speech in African languages. The unavailability of annotated\ncorpora in the languages of interest has always been a primary challenge when\ndeveloping speech recognition systems for this severely under-resourced type of\nspeech. Hence, it is worthwhile to investigate the potential of using speech\ncorpora available for other better-resourced languages to improve speech\nrecognition performance. To achieve this, we train a mBNF extractor using nine\nSouthern Bantu languages that form part of the freely available multilingual\nNCHLT corpus. We append these mBNFs to the existing MFCCs, pitch features and\ni-vectors to train acoustic models for automatic speech recognition (ASR) in\nthe target code-switched languages. Our results show that the inclusion of the\nmBNF features leads to clear performance improvements over a baseline trained\nwithout the mBNFs for code-switched English-isiZulu, English-isiXhosa,\nEnglish-Sesotho and English-Setswana speech.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:51:42 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Padhi", "Trideba", ""], ["Biswas", "Astik", ""], ["De Wet", "Febe", ""], ["van der Westhuizen", "Ewald", ""], ["Niesler", "Thomas", ""]]}, {"id": "2011.03125", "submitter": "Payam Nikdel", "authors": "Payam Nikdel, Richard Vaughan, Mo Chen", "title": "LBGP: Learning Based Goal Planning for Autonomous Following in Front", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a hybrid solution which combines deep reinforcement\nlearning (RL) and classical trajectory planning for the following in front\napplication. Here, an autonomous robot aims to stay ahead of a person as the\nperson freely walks around. Following in front is a challenging problem as the\nuser's intended trajectory is unknown and needs to be estimated, explicitly or\nimplicitly, by the robot. In addition, the robot needs to find a feasible way\nto safely navigate ahead of human trajectory. Our deep RL module implicitly\nestimates human trajectory and produces short-term navigational goals to guide\nthe robot. These goals are used by a trajectory planner to smoothly navigate\nthe robot to the short-term goals, and eventually in front of the user. We\nemploy curriculum learning in the deep RL module to efficiently achieve a high\nreturn. Our system outperforms the state-of-the-art in following ahead and is\nmore reliable compared to end-to-end alternatives in both the simulation and\nreal world experiments. In contrast to a pure deep RL approach, we demonstrate\nzero-shot transfer of the trained policy from simulation to the real world.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 22:29:30 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Nikdel", "Payam", ""], ["Vaughan", "Richard", ""], ["Chen", "Mo", ""]]}, {"id": "2011.03137", "submitter": "Behdad Chalaki", "authors": "Behdad Chalaki and Andreas A. Malikopoulos", "title": "A Hysteretic Q-learning Coordination Framework for Emerging Mobility\n  Systems in Smart Cities", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": "2021 European Control Conference (ECC), 16-21", "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connected and automated vehicles (CAVs) can alleviate traffic congestion, air\npollution, and improve safety. In this paper, we provide a decentralized\ncoordination framework for CAVs at a signal-free intersection to minimize\ntravel time and improve fuel efficiency. We employ a simple yet powerful\nreinforcement learning approach, an off-policy temporal difference learning\ncalled Q-learning, enhanced with a coordination mechanism to address this\nproblem. Then, we integrate a first-in-first-out queuing policy to improve the\nperformance of our system. We demonstrate the efficacy of our proposed approach\nthrough simulation and comparison with the classical optimal control method\nbased on Pontryagin's minimum principle.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 23:30:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chalaki", "Behdad", ""], ["Malikopoulos", "Andreas A.", ""]]}, {"id": "2011.03138", "submitter": "Hao Zhang", "authors": "Hao Zhang and Jae Ro and Richard Sproat", "title": "Semi-supervised URL Segmentation with Recurrent Neural Networks\n  Pre-trained on Knowledge Graph Entities", "comments": null, "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics (2020) 4667--4675", "doi": "10.18653/v1/2020.coling-main.411", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breaking domain names such as openresearch into component words open and\nresearch is important for applications like Text-to-Speech synthesis and web\nsearch. We link this problem to the classic problem of Chinese word\nsegmentation and show the effectiveness of a tagging model based on Recurrent\nNeural Networks (RNNs) using characters as input. To compensate for the lack of\ntraining data, we propose a pre-training method on concatenated entity names in\na large knowledge database. Pre-training improves the model by 33% and brings\nthe sequence accuracy to 85%.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 23:31:00 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Zhang", "Hao", ""], ["Ro", "Jae", ""], ["Sproat", "Richard", ""]]}, {"id": "2011.03143", "submitter": "Cleber Rocco Dr.", "authors": "Vitor Bezzan and Cleber D. Rocco", "title": "Predicting special care during the COVID-19 pandemic: A machine learning\n  approach", "comments": "21 pages, 7 Figures, 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than ever COVID-19 is putting pressure on health systems all around the\nworld, especially in Brazil. In this study we propose an analytical approach\nbased on statistics and machine learning that uses lab exam data coming from\npatients to predict whether patients are going to require special care\n(hospitalisation in regular or special-care units). We also predict the number\nof days the patients will stay under such care. The two-step procedure\ndeveloped uses Bayesian Optimisation to select the best model among several\ncandidates leads us to final models that achieve 0.94 area under ROC curve\nperformance for the first target and 1.87 root mean squared error for the\nsecond target (which is a 77% improvement over the mean baseline), making our\nmodel ready to be deployed as a decision system that could be available for\neveryone interested. The analytical approach can be used in other diseases and\ncan help the planning hospital capacity.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 00:18:27 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bezzan", "Vitor", ""], ["Rocco", "Cleber D.", ""]]}, {"id": "2011.03151", "submitter": "Lindon Roberts", "authors": "Matthias J. Ehrhardt, Lindon Roberts", "title": "Efficient Hyperparameter Tuning with Dynamic Accuracy Derivative-Free\n  Optimization", "comments": "Accepted to the 12th OPT Workshop on Optimization for Machine\n  Learning at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning solutions are framed as optimization problems which\nrely on good hyperparameters. Algorithms for tuning these hyperparameters\nusually assume access to exact solutions to the underlying learning problem,\nwhich is typically not practical. Here, we apply a recent dynamic accuracy\nderivative-free optimization method to hyperparameter tuning, which allows\ninexact evaluations of the learning problem while retaining convergence\nguarantees. We test the method on the problem of learning elastic net weights\nfor a logistic classifier, and demonstrate its robustness and efficiency\ncompared to a fixed accuracy approach. This demonstrates a promising approach\nfor hyperparameter tuning, with both convergence guarantees and practical\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 00:59:51 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Ehrhardt", "Matthias J.", ""], ["Roberts", "Lindon", ""]]}, {"id": "2011.03155", "submitter": "Hock Hung Chieng", "authors": "Hock Hung Chieng, Noorhaniza Wahid and Pauline Ong", "title": "Parametric Flatten-T Swish: An Adaptive Non-linear Activation Function\n  For Deep Learning", "comments": "19 pages", "journal-ref": "Journal of Information and Communication Technology, 20(1), 21-39,\n  2021", "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation function is a key component in deep learning that performs\nnon-linear mappings between the inputs and outputs. Rectified Linear Unit\n(ReLU) has been the most popular activation function across the deep learning\ncommunity. However, ReLU contains several shortcomings that can result in\ninefficient training of the deep neural networks, these are: 1) the negative\ncancellation property of ReLU tends to treat negative inputs as unimportant\ninformation for the learning, resulting in a performance degradation; 2) the\ninherent predefined nature of ReLU is unlikely to promote additional\nflexibility, expressivity, and robustness to the networks; 3) the mean\nactivation of ReLU is highly positive and leads to bias shift effect in network\nlayers; and 4) the multilinear structure of ReLU restricts the non-linear\napproximation power of the networks. To tackle these shortcomings, this paper\nintroduced Parametric Flatten-T Swish (PFTS) as an alternative to ReLU. By\ntaking ReLU as a baseline method, the experiments showed that PFTS improved\nclassification accuracy on SVHN dataset by 0.31%, 0.98%, 2.16%, 17.72%, 1.35%,\n0.97%, 39.99%, and 71.83% on DNN-3A, DNN-3B, DNN-4, DNN- 5A, DNN-5B, DNN-5C,\nDNN-6, and DNN-7, respectively. Besides, PFTS also achieved the highest mean\nrank among the comparison methods. The proposed PFTS manifested higher\nnon-linear approximation power during training and thereby improved the\npredictive performance of the networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 01:50:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Chieng", "Hock Hung", ""], ["Wahid", "Noorhaniza", ""], ["Ong", "Pauline", ""]]}, {"id": "2011.03156", "submitter": "Alexey Miroshnikov", "authors": "Alexey Miroshnikov, Konstandinos Kotsiopoulos, Ryan Franks, Arjun Ravi\n  Kannan", "title": "Wasserstein-based fairness interpretability framework for machine\n  learning models", "comments": "35 pages. submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we introduce a fairness interpretability framework for\nmeasuring and explaining bias in classification and regression models at the\nlevel of a distribution. In our work, motivated by the ideas of Dwork et al.\n(2012), we measure the model bias across sub-population distributions using the\nWasserstein metric. The transport theory characterization of the Wasserstein\nmetric allows us to take into account the sign of the bias across the model\ndistribution which in turn yields the decomposition of the model bias into\npositive and negative components. To understand how predictors contribute to\nthe model bias, we introduce and theoretically characterize bias predictor\nattributions called bias explanations and investigate their stability. We also\nprovide the formulation for the bias explanations that take into account the\nimpact of missing values. In addition, motivated by the works of \\v{S}trumbelj\nand Kononenko (2014) and Lundberg and Lee (2017), we construct additive bias\nexplanations by employing cooperative game theory and investigate their\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 02:01:29 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 19:13:37 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Miroshnikov", "Alexey", ""], ["Kotsiopoulos", "Konstandinos", ""], ["Franks", "Ryan", ""], ["Kannan", "Arjun Ravi", ""]]}, {"id": "2011.03158", "submitter": "Chenwei Wang", "authors": "Yuan Wang, Chenwei Wang, Yinan Ling, Keita Yokoyama, Hsin-Tai Wu, Yi\n  Fang", "title": "Leveraging an Efficient and Semantic Location Embedding to Seek New\n  Ports of Bike Share Services", "comments": "10 pages, 5 figures, 8 tables, to appear in 2020 IEEE International\n  Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For short distance traveling in crowded urban areas, bike share services are\nbecoming popular owing to the flexibility and convenience. To expand the\nservice coverage, one of the key tasks is to seek new service ports, which\nrequires to well understand the underlying features of the existing service\nports. In this paper, we propose a new model, named for Efficient and Semantic\nLocation Embedding (ESLE), which carries both geospatial and semantic\ninformation of the geo-locations. To generate ESLE, we first train a\nmulti-label model with a deep Convolutional Neural Network (CNN) by feeding the\nstatic map-tile images and then extract location embedding vectors from the\nmodel. Compared to most recent relevant literature, ESLE is not only much\ncheaper in computation, but also easier to interpret via a systematic semantic\nanalysis. Finally, we apply ESLE to seek new service ports for NTT DOCOMO's\nbike share services operated in Japan. The initial results demonstrate the\neffectiveness of ESLE, and provide a few insights that might be difficult to\ndiscover by using the conventional approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 02:08:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Wang", "Yuan", ""], ["Wang", "Chenwei", ""], ["Ling", "Yinan", ""], ["Yokoyama", "Keita", ""], ["Wu", "Hsin-Tai", ""], ["Fang", "Yi", ""]]}, {"id": "2011.03164", "submitter": "Jia Guo", "authors": "Jia Guo and Chenyang Yang", "title": "Learning Power Control for Cellular Systems with Heterogeneous Graph\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing power control in multi-cell cellular networks with deep learning\nenables such a non-convex problem to be implemented in real-time. When channels\nare time-varying, the deep neural networks (DNNs) need to be re-trained\nfrequently, which calls for low training complexity. To reduce the number of\ntraining samples and the size of DNN required to achieve good performance, a\npromising approach is to embed the DNNs with priori knowledge. Since cellular\nnetworks can be modelled as a graph, it is natural to employ graph neural\nnetworks (GNNs) for learning, which exhibit permutation invariance (PI) and\nequivalence (PE) properties. Unlike the homogeneous GNNs that have been used\nfor wireless problems, whose outputs are invariant or equivalent to arbitrary\npermutations of vertexes, heterogeneous GNNs (HetGNNs), which are more\nappropriate to model cellular networks, are only invariant or equivalent to\nsome permutations. If the PI or PE properties of the HetGNN do not match the\nproperty of the task to be learned, the performance degrades dramatically. In\nthis paper, we show that the power control policy has a combination of\ndifferent PI and PE properties, and existing HetGNN does not satisfy these\nproperties. We then design a parameter sharing scheme for HetGNN such that the\nlearned relationship satisfies the desired properties. Simulation results show\nthat the sample complexity and the size of designed GNN for learning the\noptimal power control policy in multi-user multi-cell networks are much lower\nthan the existing DNNs, when achieving the same sum rate loss from the\nnumerically obtained solutions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 02:41:38 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Guo", "Jia", ""], ["Yang", "Chenyang", ""]]}, {"id": "2011.03168", "submitter": "Hiroyasu Tsukamoto", "authors": "Hiroyasu Tsukamoto and Soon-Jo Chung and Jean-Jacques E. Slotine", "title": "Neural Stochastic Contraction Metrics for Learning-based Control and\n  Estimation", "comments": "IEEE CONTROL SYSTEMS LETTERS (L-CSS), preprint version, accepted Dec.\n  2020 (DOI: 10.1109/LCSYS.2020.3046529).\n  https://ieeexplore.ieee.org/document/9302618", "journal-ref": null, "doi": "10.1109/LCSYS.2020.3046529", "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Neural Stochastic Contraction Metrics (NSCM), a new design\nframework for provably-stable robust control and estimation for a class of\nstochastic nonlinear systems. It uses a spectrally-normalized deep neural\nnetwork to construct a contraction metric, sampled via simplified convex\noptimization in the stochastic setting. Spectral normalization constrains the\nstate-derivatives of the metric to be Lipschitz continuous, thereby ensuring\nexponential boundedness of the mean squared distance of system trajectories\nunder stochastic disturbances. The NSCM framework allows autonomous agents to\napproximate optimal stable control and estimation policies in real-time, and\noutperforms existing nonlinear control and estimation techniques including the\nstate-dependent Riccati equation, iterative LQR, EKF, and the deterministic\nneural contraction metric, as illustrated in simulation results.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:04:42 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 17:39:43 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 23:43:24 GMT"}, {"version": "v4", "created": "Sun, 3 Jan 2021 14:12:28 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Tsukamoto", "Hiroyasu", ""], ["Chung", "Soon-Jo", ""], ["Slotine", "Jean-Jacques E.", ""]]}, {"id": "2011.03170", "submitter": "Linhang Cai", "authors": "Linhang Cai, Zhulin An, Yongjun Xu", "title": "GHFP: Gradually Hard Filter Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filter pruning is widely used to reduce the computation of deep learning,\nenabling the deployment of Deep Neural Networks (DNNs) in resource-limited\ndevices. Conventional Hard Filter Pruning (HFP) method zeroizes pruned filters\nand stops updating them, thus reducing the search space of the model. On the\ncontrary, Soft Filter Pruning (SFP) simply zeroizes pruned filters, keeping\nupdating them in the following training epochs, thus maintaining the capacity\nof the network. However, SFP, together with its variants, converges much slower\nthan HFP due to its larger search space. Our question is whether SFP-based\nmethods and HFP can be combined to achieve better performance and speed up\nconvergence. Firstly, we generalize SFP-based methods and HFP to analyze their\ncharacteristics. Then we propose a Gradually Hard Filter Pruning (GHFP) method\nto smoothly switch from SFP-based methods to HFP during training and pruning,\nthus maintaining a large search space at first, gradually reducing the capacity\nof the model to ensure a moderate convergence speed. Experimental results on\nCIFAR-10/100 show that our method achieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:09:52 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Cai", "Linhang", ""], ["An", "Zhulin", ""], ["Xu", "Yongjun", ""]]}, {"id": "2011.03172", "submitter": "Salman Jahani", "authors": "Salman Jahani, Shiyu Zhou, Dharmaraj Veeramani and Jeff Schmidt", "title": "Multi-output Gaussian Process Modulated Poisson Processes for Event\n  Prediction", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of events such as part replacement and failure events plays a\ncritical role in reliability engineering. Event stream data are commonly\nobserved in manufacturing and teleservice systems. Designing predictive models\nfor individual units based on such event streams is challenging and an\nunder-explored problem. In this work, we propose a non-parametric prognostic\nframework for individualized event prediction based on the inhomogeneous\nPoisson processes with a multivariate Gaussian convolution process (MGCP) prior\non the intensity functions. The MGCP prior on the intensity functions of the\ninhomogeneous Poisson processes maps data from similar historical units to the\ncurrent unit under study which facilitates sharing of information and allows\nfor analysis of flexible event patterns. To facilitate inference, we derive a\nvariational inference scheme for learning and estimation of parameters in the\nresulting MGCP modulated Poisson process model. Experimental results are shown\non both synthetic data as well as real-world data for fleet based event\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:19:08 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Jahani", "Salman", ""], ["Zhou", "Shiyu", ""], ["Veeramani", "Dharmaraj", ""], ["Schmidt", "Jeff", ""]]}, {"id": "2011.03173", "submitter": "Subha Maity", "authors": "Subha Maity, Debarghya Mukherjee, Mikhail Yurochkin and Yuekai Sun", "title": "There is no trade-off: enforcing fairness can improve accuracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main barriers to the broader adoption of algorithmic fairness in\nmachine learning is the trade-off between fairness and performance of ML\nmodels: many practitioners are unwilling to sacrifice the performance of their\nML model for fairness. In this paper, we show that this trade-off may not be\nnecessary. If the algorithmic biases in an ML model are due to sampling biases\nin the training data, then enforcing algorithmic fairness may improve the\nperformance of the ML model on unbiased test data. We study conditions under\nwhich enforcing algorithmic fairness helps practitioners learn the Bayes\ndecision rule for (unbiased) test data from biased training data. We also\ndemonstrate the practical implications of our theoretical results in real-world\nML tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:22:52 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Maity", "Subha", ""], ["Mukherjee", "Debarghya", ""], ["Yurochkin", "Mikhail", ""], ["Sun", "Yuekai", ""]]}, {"id": "2011.03176", "submitter": "Krishnakumar Balasubramanian", "authors": "Ye He, Krishnakumar Balasubramanian, Murat A. Erdogdu", "title": "On the Ergodicity, Bias and Asymptotic Normality of Randomized Midpoint\n  Sampling Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomized midpoint method, proposed by [SL19], has emerged as an optimal\ndiscretization procedure for simulating the continuous time Langevin\ndiffusions. Focusing on the case of strong-convex and smooth potentials, in\nthis paper, we analyze several probabilistic properties of the randomized\nmidpoint discretization method for both overdamped and underdamped Langevin\ndiffusions. We first characterize the stationary distribution of the discrete\nchain obtained with constant step-size discretization and show that it is\nbiased away from the target distribution. Notably, the step-size needs to go to\nzero to obtain asymptotic unbiasedness. Next, we establish the asymptotic\nnormality for numerical integration using the randomized midpoint method and\nhighlight the relative advantages and disadvantages over other discretizations.\nOur results collectively provide several insights into the behavior of the\nrandomized midpoint discretization method, including obtaining confidence\nintervals for numerical integrations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:39:23 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["He", "Ye", ""], ["Balasubramanian", "Krishnakumar", ""], ["Erdogdu", "Murat A.", ""]]}, {"id": "2011.03178", "submitter": "Chaoqi Wang", "authors": "Chaoqi Wang, Shengyang Sun, Roger Grosse", "title": "Beyond Marginal Uncertainty: How Accurately can Bayesian Regression\n  Models Estimate Posterior Predictive Correlations?", "comments": "AISTATS 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While uncertainty estimation is a well-studied topic in deep learning, most\nsuch work focuses on marginal uncertainty estimates, i.e. the predictive mean\nand variance at individual input locations. But it is often more useful to\nestimate predictive correlations between the function values at different input\nlocations. In this paper, we consider the problem of benchmarking how\naccurately Bayesian models can estimate predictive correlations. We first\nconsider a downstream task which depends on posterior predictive correlations:\ntransductive active learning (TAL). We find that TAL makes better use of\nmodels' uncertainty estimates than ordinary active learning, and recommend this\nas a benchmark for evaluating Bayesian models. Since TAL is too expensive and\nindirect to guide development of algorithms, we introduce two metrics which\nmore directly evaluate the predictive correlations and which can be computed\nefficiently: meta-correlations (i.e. the correlations between the models\ncorrelation estimates and the true values), and cross-normalized likelihoods\n(XLL). We validate these metrics by demonstrating their consistency with TAL\nperformance and obtain insights about the relative performance of current\nBayesian neural net and Gaussian process models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 03:48:59 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 03:05:37 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Wang", "Chaoqi", ""], ["Sun", "Shengyang", ""], ["Grosse", "Roger", ""]]}, {"id": "2011.03180", "submitter": "Ali Abedi", "authors": "Ali Abedi and Shehroz S. Khan", "title": "FedSL: Federated Split Learning on Distributed Sequential Data in\n  Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) and Split Learning (SL) are privacy-preserving\nMachine-Learning (ML) techniques that enable training ML models over data\ndistributed among clients without requiring direct access to their raw data.\nExisting FL and SL approaches work on horizontally or vertically partitioned\ndata and cannot handle sequentially partitioned data where segments of\nmultiple-segment sequential data are distributed across clients. In this paper,\nwe propose a novel federated split learning framework, FedSL, to train models\non distributed sequential data. The most common ML models to train on\nsequential data are Recurrent Neural Networks (RNNs). Since the proposed\nframework is privacy preserving, segments of multiple-segment sequential data\ncannot be shared between clients or between clients and server. To circumvent\nthis limitation, we propose a novel SL approach tailored for RNNs. A RNN is\nsplit into sub-networks, and each sub-network is trained on one client\ncontaining single segments of multiple-segment training sequences. During local\ntraining, the sub-networks on different clients communicate with each other to\ncapture latent dependencies between consecutive segments of multiple-segment\nsequential data on different clients, but without sharing raw data or complete\nmodel parameters. After training local sub-networks with local sequential data\nsegments, all clients send their sub-networks to a federated server where\nsub-networks are aggregated to generate a global model. The experimental\nresults on simulated and real-world datasets demonstrate that the proposed\nmethod successfully train models on distributed sequential data, while\npreserving privacy, and outperforms previous FL and centralized learning\napproaches in terms of achieving higher accuracy in fewer communication rounds.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 04:00:39 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Abedi", "Ali", ""], ["Khan", "Shehroz S.", ""]]}, {"id": "2011.03183", "submitter": "Yilun Du", "authors": "Yilun Du, Joshua Tenenbaum, Tomas Lozano-Perez, Leslie Kaelbling", "title": "Learning an Object-Based Memory System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robot operating in a household makes observations of multiple objects as it\nmoves around over the course of days or weeks. The objects may be moved by\ninhabitants, but not completely at random. The robot may be called upon later\nto retrieve objects and will need a long-term object-based memory in order to\nknow how to find them. In this paper, we combine some aspects of classic\ntechniques for data-association filtering with modern attention-based neural\nnetworks to construct object-based memory systems that consume and produce\nhigh-dimensional observations and hypotheses. We perform end-to-end learning on\nlabeled observation trajectories to learn both necessary internal transition\nand observation models. We demonstrate the system's effectiveness on a sequence\nof problem classes of increasing difficulty and show that it outperforms\nclustering-based methods, classic filters, and unstructured neural approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 04:18:52 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 06:07:34 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Du", "Yilun", ""], ["Tenenbaum", "Joshua", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie", ""]]}, {"id": "2011.03186", "submitter": "Chong Liu", "authors": "Chong Liu, Yuqing Zhu, Kamalika Chaudhuri, and Yu-Xiang Wang", "title": "Revisiting Model-Agnostic Private Learning: Faster Rates and Active\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Private Aggregation of Teacher Ensembles (PATE) framework is one of the\nmost promising recent approaches in differentially private learning. Existing\ntheoretical analysis shows that PATE consistently learns any VC-classes in the\nrealizable setting, but falls short in explaining its success in more general\ncases where the error rate of the optimal classifier is bounded away from zero.\nWe fill in this gap by introducing the Tsybakov Noise Condition (TNC) and\nestablish stronger and more interpretable learning bounds. These bounds provide\nnew insights into when PATE works and improve over existing results even in the\nnarrower realizable setting. We also investigate the compelling idea of using\nactive learning for saving privacy budget. The novel components in the proofs\ninclude a more refined analysis of the majority voting classifier -- which\ncould be of independent interest -- and an observation that the synthetic\n\"student\" learning problem is nearly realizable by construction under the\nTsybakov noise condition.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 04:35:32 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 08:19:15 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Liu", "Chong", ""], ["Zhu", "Yuqing", ""], ["Chaudhuri", "Kamalika", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2011.03189", "submitter": "Lihui Liu", "authors": "Lihui Liu, Boxin Du, Heng Ji, Hanghang Tong", "title": "KompaRe: A Knowledge Graph Comparative Reasoning System", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reasoning is a fundamental capability for harnessing valuable insight,\nknowledge and patterns from knowledge graphs. Existing work has primarily been\nfocusing on point-wise reasoning, including search, link predication, entity\nprediction, subgraph matching and so on. This paper introduces comparative\nreasoning over knowledge graphs, which aims to infer the commonality and\ninconsistency with respect to multiple pieces of clues. We envision that the\ncomparative reasoning will complement and expand the existing point-wise\nreasoning over knowledge graphs. In detail, we develop KompaRe, the first of\nits kind prototype system that provides comparative reasoning capability over\nlarge knowledge graphs. We present both the system architecture and its core\nalgorithms, including knowledge segment extraction, pairwise reasoning and\ncollective reasoning. Empirical evaluations demonstrate the efficacy of the\nproposed KompaRe.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 04:57:37 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Liu", "Lihui", ""], ["Du", "Boxin", ""], ["Ji", "Heng", ""], ["Tong", "Hanghang", ""]]}, {"id": "2011.03195", "submitter": "Het Naik", "authors": "Devam Dave, Het Naik, Smiti Singhal, Pankesh Patel", "title": "Explainable AI meets Healthcare: A Study on Heart Disease Dataset", "comments": "23", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the increasing availability of structured and unstructured data and the\nswift progress of analytical techniques, Artificial Intelligence (AI) is\nbringing a revolution to the healthcare industry. With the increasingly\nindispensable role of AI in healthcare, there are growing concerns over the\nlack of transparency and explainability in addition to potential bias\nencountered by predictions of the model. This is where Explainable Artificial\nIntelligence (XAI) comes into the picture. XAI increases the trust placed in an\nAI system by medical practitioners as well as AI researchers, and thus,\neventually, leads to an increasingly widespread deployment of AI in healthcare.\n  In this paper, we present different interpretability techniques. The aim is\nto enlighten practitioners on the understandability and interpretability of\nexplainable AI systems using a variety of techniques available which can be\nvery advantageous in the health-care domain. Medical diagnosis model is\nresponsible for human life and we need to be confident enough to treat a\npatient as instructed by a black-box model. Our paper contains examples based\non the heart disease dataset and elucidates on how the explainability\ntechniques should be preferred to create trustworthiness while using AI systems\nin healthcare.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 05:18:43 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Dave", "Devam", ""], ["Naik", "Het", ""], ["Singhal", "Smiti", ""], ["Patel", "Pankesh", ""]]}, {"id": "2011.03206", "submitter": "Gautham Krishna Gudur", "authors": "Gautham Krishna Gudur, Bala Shyamala Balaji, Satheesh K. Perepu", "title": "Resource-Constrained Federated Learning with Heterogeneous Labels and\n  Models", "comments": "6 pages, 5 figures, ACM KDD 2020 (The 3rd International Workshop on\n  Artificial Intelligence of Things - AIoT'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various IoT applications demand resource-constrained machine learning\nmechanisms for different applications such as pervasive healthcare, activity\nmonitoring, speech recognition, real-time computer vision, etc. This\nnecessitates us to leverage information from multiple devices with few\ncommunication overheads. Federated Learning proves to be an extremely viable\noption for distributed and collaborative machine learning. Particularly,\non-device federated learning is an active area of research, however, there are\na variety of challenges in addressing statistical (non-IID data) and model\nheterogeneities. In addition, in this paper we explore a new challenge of\ninterest -- to handle label heterogeneities in federated learning. To this end,\nwe propose a framework with simple $\\alpha$-weighted federated aggregation of\nscores which leverages overlapping information gain across labels, while saving\nbandwidth costs in the process. Empirical evaluation on Animals-10 dataset\n(with 4 labels for effective elucidation of results) indicates an average\ndeterministic accuracy increase of at least ~16.7%. We also demonstrate the\non-device capabilities of our proposed framework by experimenting with\nfederated learning and inference across different iterations on a Raspberry Pi\n2, a single-board computing platform.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 06:23:47 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Gudur", "Gautham Krishna", ""], ["Balaji", "Bala Shyamala", ""], ["Perepu", "Satheesh K.", ""]]}, {"id": "2011.03207", "submitter": "Dongseok Shim", "authors": "Dongseok Shim and H. Jin Kim", "title": "Learning a Geometric Representation for Data-Efficient Depth Estimation\n  via Gradient Field and Contrastive Loss", "comments": "IEEE ICRA 2021 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Estimating a depth map from a single RGB image has been investigated widely\nfor localization, mapping, and 3-dimensional object detection. Recent studies\non a single-view depth estimation are mostly based on deep Convolutional neural\nNetworks (ConvNets) which require a large amount of training data paired with\ndensely annotated labels. Depth annotation tasks are both expensive and\ninefficient, so it is inevitable to leverage RGB images which can be collected\nvery easily to boost the performance of ConvNets without depth labels. However,\nmost self-supervised learning algorithms are focused on capturing the semantic\ninformation of images to improve the performance in classification or object\ndetection, not in depth estimation. In this paper, we show that existing\nself-supervised methods do not perform well on depth estimation and propose a\ngradient-based self-supervised learning algorithm with momentum contrastive\nloss to help ConvNets extract the geometric information with unlabeled images.\nAs a result, the network can estimate the depth map accurately with a\nrelatively small amount of annotated data. To show that our method is\nindependent of the model structure, we evaluate our method with two different\nmonocular depth estimation algorithms. Our method outperforms the previous\nstate-of-the-art self-supervised learning algorithms and shows the efficiency\nof labeled data in triple compared to random initialization on the NYU Depth v2\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 06:47:19 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 05:59:46 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Shim", "Dongseok", ""], ["Kim", "H. Jin", ""]]}, {"id": "2011.03208", "submitter": "Leye Wang", "authors": "Leye Wang, Han Yu, Xiao Han", "title": "Federated Crowdsensing: Framework and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsensing is a promising sensing paradigm for smart city applications\n(e.g., traffic and environment monitoring) with the prevalence of smart mobile\ndevices and advanced network infrastructure. Meanwhile, as tasks are performed\nby individuals, privacy protection is one of the key issues in crowdsensing\nsystems. Traditionally, to alleviate users' privacy concerns, noises are added\nto participants' sensitive data (e.g., participants' locations) through\ntechniques such as differential privacy. However, this inevitably results in\nquality loss to the crowdsensing task. Recently, federated learning paradigm\nhas been proposed, which aims to achieve privacy preservation in machine\nlearning while ensuring that the learning quality suffers little or no loss.\nInspired by the federated learning paradigm, this article studies how federated\nlearning may benefit crowdsensing applications. In particular, we first propose\na federated crowdsensing framework, which analyzes the privacy concerns of each\ncrowdsensing stage (i.e., task creation, task assignment, task execution, and\ndata aggregation) and discuss how federated learning techniques may take\neffect. Finally, we summarize key challenges and opportunities in federated\ncrowdsensing.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 06:49:11 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Wang", "Leye", ""], ["Yu", "Han", ""], ["Han", "Xiao", ""]]}, {"id": "2011.03231", "submitter": "Alex Boyd", "authors": "Alex Boyd, Robert Bamler, Stephan Mandt, and Padhraic Smyth", "title": "User-Dependent Neural Sequence Models for Continuous-Time Event Data", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-time event data are common in applications such as individual\nbehavior data, financial transactions, and medical health records. Modeling\nsuch data can be very challenging, in particular for applications with many\ndifferent types of events, since it requires a model to predict the event types\nas well as the time of occurrence. Recurrent neural networks that parameterize\ntime-varying intensity functions are the current state-of-the-art for\npredictive modeling with such data. These models typically assume that all\nevent sequences come from the same data distribution. However, in many\napplications event sequences are generated by different sources, or users, and\ntheir characteristics can be very different. In this paper, we extend the broad\nclass of neural marked point process models to mixtures of latent embeddings,\nwhere each mixture component models the characteristic traits of a given user.\nOur approach relies on augmenting these models with a latent variable that\nencodes user characteristics, represented by a mixture model over user behavior\nthat is trained via amortized variational inference. We evaluate our methods on\nfour large real-world datasets and demonstrate systematic improvements from our\napproach over existing work for a variety of predictive metrics such as\nlog-likelihood, next event ranking, and source-of-sequence identification.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 08:32:57 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Boyd", "Alex", ""], ["Bamler", "Robert", ""], ["Mandt", "Stephan", ""], ["Smyth", "Padhraic", ""]]}, {"id": "2011.03234", "submitter": "Sourin Chakrabarti", "authors": "Sourin Chakrabarti", "title": "Efficient image retrieval using multi neural hash codes and bloom\n  filters", "comments": "2020 IEEE International Conference for Innovation in Technology.\n  Asian Journal for Convergence in Technology(AJCT) Volume VI Issue III", "journal-ref": null, "doi": "10.1109/INOCON50539.2020.9298228", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to deliver an efficient and modified approach for image\nretrieval using multiple neural hash codes and limiting the number of queries\nusing bloom filters by identifying false positives beforehand. Traditional\napproaches involving neural networks for image retrieval tasks tend to use\nhigher layers for feature extraction. But it has been seen that the activations\nof lower layers have proven to be more effective in a number of scenarios. In\nour approach, we have leveraged the use of local deep convolutional neural\nnetworks which combines the powers of both the features of lower and higher\nlayers for creating feature maps which are then compressed using PCA and fed to\na bloom filter after binary sequencing using a modified multi k-means approach.\nThe feature maps obtained are further used in the image retrieval process in a\nhierarchical coarse-to-fine manner by first comparing the images in the higher\nlayers for semantically similar images and then gradually moving towards the\nlower layers searching for structural similarities. While searching, the neural\nhashes for the query image are again calculated and queried in the bloom filter\nwhich tells us whether the query image is absent in the set or maybe present.\nIf the bloom filter doesn't necessarily rule out the query, then it goes into\nthe image retrieval process. This approach can be particularly helpful in cases\nwhere the image store is distributed since the approach supports parallel\nquerying.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 08:46:31 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 12:09:08 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chakrabarti", "Sourin", ""]]}, {"id": "2011.03238", "submitter": "Serkan Budak", "authors": "Serkan Budak, Bahadir Akbal", "title": "Fault Location Estimation by Using Machine Learning Methods in Mixed\n  Transmission Lines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overhead lines are generally used for electrical energy transmission. Also,\nXLPE underground cable lines are generally used in the city center and the\ncrowded areas to provide electrical safety, so high voltage underground cable\nlines are used together with overhead line in the transmission lines, and these\nlines are called as the mixed lines. The distance protection relays are used to\ndetermine the impedance based fault location according to the current and\nvoltage magnitudes in the transmission lines. However, the fault location\ncannot be correctly detected in mixed transmission lines due to different\ncharacteristic impedance per unit length because the characteristic impedance\nof high voltage cable line is significantly different from overhead line. Thus,\ndeterminations of the fault section and location with the distance protection\nrelays are difficult in the mixed transmission lines. In this study, 154 kV\noverhead transmission line and underground cable line are examined as the mixed\ntransmission line for the distance protection relays. Phase to ground faults\nare created in the mixed transmission line, and overhead line section and\nunderground cable section are simulated by using PSCAD. The short circuit fault\nimages are generated in the distance protection relay for the overhead\ntransmission line and underground cable transmission line faults. The images\ninclude the RX impedance diagram of the fault, and the RX impedance diagram\nhave been detected by applying image processing steps. The regression methods\nare used for prediction of the fault location, and the results of image\nprocessing are used as the input parameters for the training process of the\nregression methods. The results of regression methods are compared to select\nthe most suitable method at the end of this study for forecasting of the fault\nlocation in transmission lines.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 08:56:30 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Budak", "Serkan", ""], ["Akbal", "Bahadir", ""]]}, {"id": "2011.03240", "submitter": "Yangchun Yan", "authors": "Yangchun Yan, Rongzuo Guo, Chao Li, Kang Yang, Yongjun Xu", "title": "Channel Pruning via Multi-Criteria based on Weight Dependency", "comments": "8 pages,IJCNN2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel pruning has demonstrated its effectiveness in compressing ConvNets.\nIn many related arts, the importance of an output feature map is only\ndetermined by its associated filter. However, these methods ignore a small part\nof weights in the next layer which disappears as the feature map is removed.\nThey ignore the phenomenon of weight dependency. Besides, many pruning methods\nuse only one criterion for evaluation and find a sweet spot of pruning\nstructure and accuracy in a trial-and-error fashion, which can be\ntime-consuming. In this paper, we proposed a channel pruning algorithm via\nmulti-criteria based on weight dependency, CPMC, which can compress a\npre-trained model directly. CPMC defines channel importance in three aspects,\nincluding its associated weight value, computational cost, and parameter\nquantity. According to the phenomenon of weight dependency, CPMC gets channel\nimportance by assessing its associated filter and the corresponding partial\nweights in the next layer. Then CPMC uses global normalization to achieve\ncross-layer comparison. Finally, CPMC removes less important channels by global\nranking. CPMC can compress various CNN models, including VGGNet, ResNet, and\nDenseNet on various image classification datasets. Extensive experiments have\nshown CPMC outperforms the others significantly.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 09:12:00 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 07:55:59 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 03:20:03 GMT"}, {"version": "v4", "created": "Tue, 20 Apr 2021 07:41:11 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yan", "Yangchun", ""], ["Guo", "Rongzuo", ""], ["Li", "Chao", ""], ["Yang", "Kang", ""], ["Xu", "Yongjun", ""]]}, {"id": "2011.03243", "submitter": "Sourin Chakrabarti", "authors": "Bagesh Kumar, Ayush Sinha, Sourin Chakrabarti, Prof. O.P.Vyas", "title": "A fast learning algorithm for One-Class Slab Support Vector Machines", "comments": "This version of the manuscript has been updated and is being reviewed\n  by https://www.journals.elsevier.com/knowledge-based-systems", "journal-ref": "Knowledge-Based Systems, Volume 228, 27 September 2021, 107267", "doi": "10.1016/j.knosys.2021.107267", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One Class Slab Support Vector Machines (OCSSVM) have turned out to be better\nin terms of accuracy in certain classes of classification problems than the\ntraditional SVMs and One Class SVMs or even other One class classifiers. This\npaper proposes fast training method for One Class Slab SVMs using an updated\nSequential Minimal Optimization (SMO) which divides the multi variable\noptimization problem to smaller sub problems of size two that can then be\nsolved analytically. The results indicate that this training method scales\nbetter to large sets of training data than other Quadratic Programming (QP)\nsolvers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 09:16:39 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 15:08:31 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kumar", "Bagesh", ""], ["Sinha", "Ayush", ""], ["Chakrabarti", "Sourin", ""], ["Vyas", "Prof. O. P.", ""]]}, {"id": "2011.03248", "submitter": "Chaochao Chen", "authors": "Longfei Zheng, Jun Zhou, Chaochao Chen, Bingzhe Wu, Li Wang, Benyu\n  Zhang", "title": "ASFGNN: Automated Separated-Federated Graph Neural Network", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have achieved remarkable performance by taking\nadvantage of graph data. The success of GNN models always depends on rich\nfeatures and adjacent relationships. However, in practice, such data are\nusually isolated by different data owners (clients) and thus are likely to be\nNon-Independent and Identically Distributed (Non-IID). Meanwhile, considering\nthe limited network status of data owners, hyper-parameters optimization for\ncollaborative learning approaches is time-consuming in data isolation\nscenarios. To address these problems, we propose an Automated\nSeparated-Federated Graph Neural Network (ASFGNN) learning paradigm. ASFGNN\nconsists of two main components, i.e., the training of GNN and the tuning of\nhyper-parameters. Specifically, to solve the data Non-IID problem, we first\npropose a separated-federated GNN learning model, which decouples the training\nof GNN into two parts: the message passing part that is done by clients\nseparately, and the loss computing part that is learnt by clients federally. To\nhandle the time-consuming parameter tuning problem, we leverage Bayesian\noptimization technique to automatically tune the hyper-parameters of all the\nclients. We conduct experiments on benchmark datasets and the results\ndemonstrate that ASFGNN significantly outperforms the naive federated GNN, in\nterms of both accuracy and parameter-tuning efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 09:21:34 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zheng", "Longfei", ""], ["Zhou", "Jun", ""], ["Chen", "Chaochao", ""], ["Wu", "Bingzhe", ""], ["Wang", "Li", ""], ["Zhang", "Benyu", ""]]}, {"id": "2011.03255", "submitter": "Tiancheng Qin", "authors": "Tiancheng Qin, S. Rasoul Etesami, C\\'esar A. Uribe", "title": "Communication-efficient Decentralized Local SGD over Undirected Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the distributed learning problem where a network of $n$ agents\nseeks to minimize a global function $F$. Agents have access to $F$ through\nnoisy gradients, and they can locally communicate with their neighbors a\nnetwork. We study the Decentralized Local SDG method, where agents perform a\nnumber of local gradient steps and occasionally exchange information with their\nneighbors. Previous algorithmic analysis efforts have focused on the specific\nnetwork topology (star topology) where a leader node aggregates all agents'\ninformation. We generalize that setting to an arbitrary network by analyzing\nthe trade-off between the number of communication rounds and the computational\neffort of each agent. We bound the expected optimality gap in terms of the\nnumber of iterates $T$, the number of workers $n$, and the spectral gap of the\nunderlying network. Our main results show that by using only $R=\\Omega(n)$\ncommunication rounds, one can achieve an error that scales as $O({1}/{nT})$,\nwhere the number of communication rounds is independent of $T$ and only depends\non the number of agents. Finally, we provide numerical evidence of our\ntheoretical results through experiments on real and synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 09:34:00 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Qin", "Tiancheng", ""], ["Etesami", "S. Rasoul", ""], ["Uribe", "C\u00e9sar A.", ""]]}, {"id": "2011.03274", "submitter": "Dennis Ulmer", "authors": "Dennis Ulmer, Lotta Meijerink and Giovanni Cin\\`a", "title": "Trust Issues: Uncertainty Estimation Does Not Enable Reliable OOD\n  Detection On Medical Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When deploying machine learning models in high-stakes real-world environments\nsuch as health care, it is crucial to accurately assess the uncertainty\nconcerning a model's prediction on abnormal inputs. However, there is a\nscarcity of literature analyzing this problem on medical data, especially on\nmixed-type tabular data such as Electronic Health Records. We close this gap by\npresenting a series of tests including a large variety of contemporary\nuncertainty estimation techniques, in order to determine whether they are able\nto identify out-of-distribution (OOD) patients. In contrast to previous work,\nwe design tests on realistic and clinically relevant OOD groups, and run\nexperiments on real-world medical data. We find that almost all techniques fail\nto achieve convincing results, partly disagreeing with earlier findings.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:41:39 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ulmer", "Dennis", ""], ["Meijerink", "Lotta", ""], ["Cin\u00e0", "Giovanni", ""]]}, {"id": "2011.03277", "submitter": "Samuli Laine", "authors": "Samuli Laine, Janne Hellsten, Tero Karras, Yeongho Seol, Jaakko\n  Lehtinen, Timo Aila", "title": "Modular Primitives for High-Performance Differentiable Rendering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modular differentiable renderer design that yields performance\nsuperior to previous methods by leveraging existing, highly optimized hardware\ngraphics pipelines. Our design supports all crucial operations in a modern\ngraphics pipeline: rasterizing large numbers of triangles, attribute\ninterpolation, filtered texture lookups, as well as user-programmable shading\nand geometry processing, all in high resolutions. Our modular primitives allow\ncustom, high-performance graphics pipelines to be built directly within\nautomatic differentiation frameworks such as PyTorch or TensorFlow. As a\nmotivating application, we formulate facial performance capture as an inverse\nrendering problem and show that it can be solved efficiently using our tools.\nOur results indicate that this simple and straightforward approach achieves\nexcellent geometric correspondence between rendered results and reference\nimagery.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:48:43 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Laine", "Samuli", ""], ["Hellsten", "Janne", ""], ["Karras", "Tero", ""], ["Seol", "Yeongho", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "2011.03281", "submitter": "Tosin Adewumi", "authors": "Tosin P. Adewumi, Foteini Liwicki and Marcus Liwicki", "title": "Corpora Compared: The Case of the Swedish Gigaword & Wikipedia Corpora", "comments": "Presented at the Eighth Swedish Language Technology Conference (SLTC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we show that the difference in performance of embeddings from\ndifferently sourced data for a given language can be due to other factors\nbesides data size. Natural language processing (NLP) tasks usually perform\nbetter with embeddings from bigger corpora. However, broadness of covered\ndomain and noise can play important roles. We evaluate embeddings based on two\nSwedish corpora: The Gigaword and Wikipedia, in analogy (intrinsic) tests and\ndiscover that the embeddings from the Wikipedia corpus generally outperform\nthose from the Gigaword corpus, which is a bigger corpus. Downstream tests will\nbe required to have a definite evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 11:00:47 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Adewumi", "Tosin P.", ""], ["Liwicki", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2011.03303", "submitter": "Siamak Mehrkanoon", "authors": "Jes\\'us Garc\\'ia Fern\\'andez, Ismail Alaoui Abdellaoui, Siamak\n  Mehrkanoon", "title": "Deep coastal sea elements forecasting using U-Net based models", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the development of deep learning techniques applied to satellite\nimagery, weather forecasting that uses remote sensing data has also been the\nsubject of major progress. The present paper investigates multiple steps ahead\nframe prediction for coastal sea elements in the Netherlands using U-Net based\narchitectures. Hourly data from the Copernicus observation programme spanned\nover a period of 2 years has been used to train the models and make the\nforecasting, including seasonal predictions. We propose a variation of the\nU-Net architecture and also extend this novel model using residual connections,\nparallel convolutions and asymmetric convolutions in order to propose three\nadditional architectures. In particular, we show that the architecture equipped\nwith parallel and asymmetric convolutions as well as skip connections is\nparticularly suited for this task, outperforming the other three discussed\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 12:02:31 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Fern\u00e1ndez", "Jes\u00fas Garc\u00eda", ""], ["Abdellaoui", "Ismail Alaoui", ""], ["Mehrkanoon", "Siamak", ""]]}, {"id": "2011.03320", "submitter": "Chieh T Wu", "authors": "Chieh Wu, Aria Masoomi, Arthur Gretton, Jennifer Dy", "title": "Kernel Dependence Network", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.08539", "journal-ref": "NeurIPS2020 Workshop (Beyond Backprop)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a greedy strategy to spectrally train a deep network for\nmulti-class classification. Each layer is defined as a composition of linear\nweights with the feature map of a Gaussian kernel acting as the activation\nfunction. At each layer, the linear weights are learned by maximizing the\ndependence between the layer output and the labels using the Hilbert Schmidt\nIndependence Criterion (HSIC). By constraining the solution space on the\nStiefel Manifold, we demonstrate how our network construct (Kernel Dependence\nNetwork or KNet) can be solved spectrally while leveraging the eigenvalues to\nautomatically find the width and the depth of the network. We theoretically\nguarantee the existence of a solution for the global optimum while providing\ninsight into our network's ability to generalize.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 20:11:24 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 23:27:51 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wu", "Chieh", ""], ["Masoomi", "Aria", ""], ["Gretton", "Arthur", ""], ["Dy", "Jennifer", ""]]}, {"id": "2011.03321", "submitter": "Ben Adlam", "authors": "Ben Adlam and Jeffrey Pennington", "title": "Understanding Double Descent Requires a Fine-Grained Bias-Variance\n  Decomposition", "comments": "Published as a conference paper in the Proceedings of the\n  Thirty-fourth Conference on Neural Information Processing Systems; 54 pages;\n  5 figures. arXiv admin note: text overlap with arXiv:2008.06786", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical learning theory suggests that the optimal generalization\nperformance of a machine learning model should occur at an intermediate model\ncomplexity, with simpler models exhibiting high bias and more complex models\nexhibiting high variance of the predictive function. However, such a simple\ntrade-off does not adequately describe deep learning models that simultaneously\nattain low bias and variance in the heavily overparameterized regime. A primary\nobstacle in explaining this behavior is that deep learning algorithms typically\ninvolve multiple sources of randomness whose individual contributions are not\nvisible in the total variance. To enable fine-grained analysis, we describe an\ninterpretable, symmetric decomposition of the variance into terms associated\nwith the randomness from sampling, initialization, and the labels. Moreover, we\ncompute the high-dimensional asymptotic behavior of this decomposition for\nrandom feature kernel regression, and analyze the strikingly rich phenomenology\nthat arises. We find that the bias decreases monotonically with the network\nwidth, but the variance terms exhibit non-monotonic behavior and can diverge at\nthe interpolation boundary, even in the absence of label noise. The divergence\nis caused by the \\emph{interaction} between sampling and initialization and can\ntherefore be eliminated by marginalizing over samples (i.e. bagging) \\emph{or}\nover the initial parameters (i.e. ensemble learning).\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:04:02 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Adlam", "Ben", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2011.03331", "submitter": "Tobias Skovgaard Jepsen", "authors": "Florian Barth and Stefan Funke and Tobias Skovgaard Jepsen and\n  Claudius Proissl", "title": "Scalable Unsupervised Multi-Criteria Trajectory Segmentation and Driving\n  Preference Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present analysis techniques for large trajectory data sets that aim to\nprovide a semantic understanding of trajectories reaching beyond them being\npoint sequences in time and space. The presented techniques use a driving\npreference model w.r.t. road segment traversal costs, e.g., travel time and\ndistance, to analyze and explain trajectories.\n  In particular, we present trajectory mining techniques that can (a) find\ninteresting points within a trajectory indicating, e.g., a via-point, and (b)\nrecover the driving preferences of a driver based on their chosen trajectory.\nWe evaluate our techniques on the tasks of via-point identification and\npersonalized routing using a data set of more than 1 million vehicle\ntrajectories collected throughout Denmark during a 3-year period. Our\ntechniques can be implemented efficiently and are highly parallelizable,\nallowing them to scale to millions or billions of trajectories.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:32:26 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Barth", "Florian", ""], ["Funke", "Stefan", ""], ["Jepsen", "Tobias Skovgaard", ""], ["Proissl", "Claudius", ""]]}, {"id": "2011.03334", "submitter": "Wissam Bejjani", "authors": "Wissam Bejjani, Wisdom C. Agboh, Mehmet R. Dogar and Matteo Leonetti", "title": "Occlusion-Aware Search for Object Retrieval in Clutter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the manipulation task of retrieving a target object from a\ncluttered shelf. When the target object is hidden, the robot must search\nthrough the clutter for retrieving it. Solving this task requires reasoning\nover the likely locations of the target object. It also requires physics\nreasoning over multi-object interactions and future occlusions. In this work,\nwe present a data-driven approach for generating occlusion-aware actions in\nclosed-loop. We present a hybrid planner that explores likely states generated\nfrom a learned distribution over the location of the target object. The search\nis guided by a heuristic trained with reinforcement learning to evaluate\nobservations with occlusions. We evaluate our approach in different simulation\nand real-world settings. The results validate that our approach can search and\nretrieve a target object in near real time in the real world while only being\ntrained in simulation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 13:15:27 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 22:35:32 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 21:38:34 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Bejjani", "Wissam", ""], ["Agboh", "Wisdom C.", ""], ["Dogar", "Mehmet R.", ""], ["Leonetti", "Matteo", ""]]}, {"id": "2011.03344", "submitter": "Cathal Ryan Mr.", "authors": "Cathal Ryan, Christophe Gu\\'eret, Donagh Berry, Brian Mac Namee", "title": "Can We Detect Mastitis earlier than Farmers?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study was to build a modelling framework that would allow us\nto be able to detect mastitis infections before they would normally be found by\nfarmers through the introduction of machine learning techniques. In the making\nof this we created two different modelling framework's, one that works on the\npremise of detecting Sub Clinical mastitis infections at one Somatic Cell Count\nrecording in advance called SMA and the other tries to detect both Sub Clinical\nmastitis infections aswell as Clinical mastitis infections at any time the cow\nis milked called AMA. We also introduce the idea of two different feature sets\nfor our study, these represent different characteristics that should be taken\ninto account when detecting infections, these were the idea of a cow differing\nto a farm mean and also trends in the lactation. We reported that the results\nfor SMA are better than those created by AMA for Sub Clinical infections yet it\nhas the significant disadvantage of only being able to classify Sub Clinical\ninfections due to how we recorded Sub Clinical infections as being any time a\nSomatic Cell Count measurement went above a certain threshold where as CM could\nappear at any stage of lactation. Thus in some cases the lower accuracy values\nfor AMA might in fact be more beneficial to farmers.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 14:36:01 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Ryan", "Cathal", ""], ["Gu\u00e9ret", "Christophe", ""], ["Berry", "Donagh", ""], ["Mac Namee", "Brian", ""]]}, {"id": "2011.03346", "submitter": "Peter Bj{\\o}rn J{\\o}rgensen", "authors": "Peter Bj{\\o}rn J{\\o}rgensen and Arghya Bhowmik", "title": "DeepDFT: Neural Message Passing Network for Accurate Charge Density\n  Prediction", "comments": "Workshop paper presented at Machine Learning for Molecules Workshop\n  at NeurIPS 2020. Implementation and pretrained model are available at\n  https://github.com/peterbjorgensen/DeepDFT", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DeepDFT, a deep learning model for predicting the electronic\ncharge density around atoms, the fundamental variable in electronic structure\nsimulations from which all ground state properties can be calculated. The model\nis formulated as neural message passing on a graph, consisting of interacting\natom vertices and special query point vertices for which the charge density is\npredicted. The accuracy and scalability of the model are demonstrated for\nmolecules, solids and liquids. The trained model achieves lower average\nprediction errors than the observed variations in charge density obtained from\ndensity functional theory simulations using different exchange correlation\nfunctionals.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:56:08 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["J\u00f8rgensen", "Peter Bj\u00f8rn", ""], ["Bhowmik", "Arghya", ""]]}, {"id": "2011.03350", "submitter": "Haoyue Zhang", "authors": "Haoyue Zhang, Jennifer S Polson, Kambiz Nael, Noriko Salamon, Bryan\n  Yoo, Suzie El-Saden, Fabien Scalzo, William Speier, Corey W Arnold", "title": "Intra-Domain Task-Adaptive Transfer Learning to Determine Acute Ischemic\n  Stroke Onset Time", "comments": null, "journal-ref": "Computerized Medical Imaging and Graphics Volume 90, June 2021,\n  101926", "doi": "10.1016/j.compmedimag.2021.101926", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Treatment of acute ischemic strokes (AIS) is largely contingent upon the time\nsince stroke onset (TSS). However, TSS may not be readily available in up to\n25% of patients with unwitnessed AIS. Current clinical guidelines for patients\nwith unknown TSS recommend the use of MRI to determine eligibility for\nthrombolysis, but radiology assessments have high inter-reader variability. In\nthis work, we present deep learning models that leverage MRI diffusion series\nto classify TSS based on clinically validated thresholds. We propose an\nintra-domain task-adaptive transfer learning method, which involves training a\nmodel on an easier clinical task (stroke detection) and then refining the model\nwith different binary thresholds of TSS. We apply this approach to both 2D and\n3D CNN architectures with our top model achieving an ROC-AUC value of 0.74,\nwith a sensitivity of 0.70 and a specificity of 0.81 for classifying TSS < 4.5\nhours. Our pretrained models achieve better classification metrics than the\nmodels trained from scratch, and these metrics exceed those of previously\npublished models applied to our dataset. Furthermore, our pipeline accommodates\na more inclusive patient cohort than previous work, as we did not exclude\nimaging studies based on clinical, demographic, or image processing criteria.\nWhen applied to this broad spectrum of patients, our deep learning model\nachieves an overall accuracy of 75.78% when classifying TSS < 4.5 hours,\ncarrying potential therapeutic implications for patients with unknown TSS.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:28:54 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Zhang", "Haoyue", ""], ["Polson", "Jennifer S", ""], ["Nael", "Kambiz", ""], ["Salamon", "Noriko", ""], ["Yoo", "Bryan", ""], ["El-Saden", "Suzie", ""], ["Scalzo", "Fabien", ""], ["Speier", "William", ""], ["Arnold", "Corey W", ""]]}, {"id": "2011.03352", "submitter": "Thomas Falconer", "authors": "Thomas Falconer and Letif Mones", "title": "Deep learning architectures for inference of AC-OPF solutions", "comments": "5 pages, 4 tables, 3 figures. Climate Change AI Workshop - Tackling\n  Climate Change with Machine Learning (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a systematic comparison between neural network (NN) architectures\nfor inference of AC-OPF solutions. Using fully connected NNs as a baseline we\ndemonstrate the efficacy of leveraging network topology in the models by\nconstructing abstract representations of electrical grids in the graph domain,\nfor both convolutional and graph NNs. The performance of the NN architectures\nis compared for regression (predicting optimal generator set-points) and\nclassification (predicting the active set of constraints) settings.\nComputational gains for obtaining optimal solutions are also presented.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 13:33:18 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 10:03:18 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Falconer", "Thomas", ""], ["Mones", "Letif", ""]]}, {"id": "2011.03353", "submitter": "Yaroslav Zharov", "authors": "Yaroslav Zharov, Alexey Ershov, Tilo Baumbach", "title": "Self Supervised Learning for Object Localisation in 3D Tomographic\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a lot of work is dedicated to self-supervised learning, most of it is\ndealing with 2D images of natural scenes and objects. In this paper, we focus\non \\textit{volumetric} images obtained by means of the X-Ray Computed\nTomography (CT). We describe two pretext training tasks which are designed\ntaking into account the specific properties of volumetric data. We propose two\nways to transfer a trained network to the downstream task of object\nlocalization with a zero amount of manual markup. Despite its simplicity, the\nproposed method shows its applicability to practical tasks of object\nlocalization and data reduction.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 13:34:00 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zharov", "Yaroslav", ""], ["Ershov", "Alexey", ""], ["Baumbach", "Tilo", ""]]}, {"id": "2011.03372", "submitter": "Lei Cheng", "authors": "Chunhui Zhang, Yongyuan Liang, Xiaoming Yuan, and Lei Cheng", "title": "FDNAS: Improving Data Privacy and Model Diversity in AutoML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To prevent the leakage of private information while enabling automated\nmachine intelligence, there is an emerging trend to integrate federated\nlearning and Neural Architecture Search (NAS). Although promising as it may\nseem, the coupling of difficulties from both two tenets makes the algorithm\ndevelopment quite challenging. In particular, how to efficiently search the\noptimal neural architecture directly from massive non-iid data of clients in a\nfederated manner remains to be a hard nut to crack. To tackle this challenge,\nin this paper, by leveraging the advances in proxy-less NAS, we propose a\nFederated Direct Neural Architecture Search (FDNAS) framework that allows\nhardware-aware NAS from decentralized non-iid data of clients. To further adapt\nfor various data distributions of clients, inspired by meta-learning, a cluster\nFederated Direct Neural Architecture Search (CFDNAS) framework is proposed to\nachieve client-aware NAS, in the sense that each client can learn a tailored\ndeep learning model for its particular data distribution. Extensive experiments\non real-world non-iid datasets show state-of-the-art accuracy-efficiency\ntrade-offs for various hardware and data distributions of clients. Our codes\nwill be released publicly upon paper acceptance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:13:42 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zhang", "Chunhui", ""], ["Liang", "Yongyuan", ""], ["Yuan", "Xiaoming", ""], ["Cheng", "Lei", ""]]}, {"id": "2011.03375", "submitter": "Haoran Zhu", "authors": "Haoran Zhu, Pavankumar Murali, Dzung T. Phan, Lam M. Nguyen, Jayant R.\n  Kalagnanam", "title": "A Scalable MIP-based Method for Learning Optimal Multivariate Decision\n  Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent publications report advances in training optimal decision\ntrees (ODT) using mixed-integer programs (MIP), due to algorithmic advances in\ninteger programming and a growing interest in addressing the inherent\nsuboptimality of heuristic approaches such as CART. In this paper, we propose a\nnovel MIP formulation, based on a 1-norm support vector machine model, to train\na multivariate ODT for classification problems. We provide cutting plane\ntechniques that tighten the linear relaxation of the MIP formulation, in order\nto improve run times to reach optimality. Using 36 data-sets from the\nUniversity of California Irvine Machine Learning Repository, we demonstrate\nthat our formulation outperforms its counterparts in the literature by an\naverage of about 10% in terms of mean out-of-sample testing accuracy across the\ndata-sets. We provide a scalable framework to train multivariate ODT on large\ndata-sets by introducing a novel linear programming (LP) based data selection\nmethod to choose a subset of the data for training. Our method is able to\nroutinely handle large data-sets with more than 7,000 sample points and\noutperform heuristics methods and other MIP based techniques. We present\nresults on data-sets containing up to 245,000 samples. Existing MIP-based\nmethods do not scale well on training data-sets beyond 5,500 samples.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:17:41 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zhu", "Haoran", ""], ["Murali", "Pavankumar", ""], ["Phan", "Dzung T.", ""], ["Nguyen", "Lam M.", ""], ["Kalagnanam", "Jayant R.", ""]]}, {"id": "2011.03381", "submitter": "Siamak Layeghy", "authors": "Seyedeh Faezeh Hosseini Noorbin, Siamak Layeghy, Brano Kusy, Raja\n  Jurdak, Greg Bishop-hurley, Marius Portmann", "title": "Deep Learning-based Cattle Activity Classification Using Joint\n  Time-frequency Data Representation", "comments": "22 pages, 17 figures", "journal-ref": null, "doi": "10.1016/j.compag.2021.106241", "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated cattle activity classification allows herders to continuously\nmonitor the health and well-being of livestock, resulting in increased quality\nand quantity of beef and dairy products. In this paper, a sequential deep\nneural network is used to develop a behavioural model and to classify cattle\nbehaviour and activities. The key focus of this paper is the exploration of a\njoint time-frequency domain representation of the sensor data, which is\nprovided as the input to the neural network classifier. Our exploration is\nbased on a real-world data set with over 3 million samples, collected from\nsensors with a tri-axial accelerometer, magnetometer and gyroscope, attached to\ncollar tags of 10 dairy cows and collected over a one month period. The key\nresults of this paper is that the joint time-frequency data representation,\neven when used in conjunction with a relatively basic neural network\nclassifier, can outperform the best cattle activity classifiers reported in the\nliterature. With a more systematic exploration of neural network classifier\narchitectures and hyper-parameters, there is potential for even further\nimprovements. Finally, we demonstrate that the time-frequency domain data\nrepresentation allows us to efficiently trade-off a large reduction of model\nsize and computational complexity for a very minor reduction in classification\naccuracy. This shows the potential for our classification approach to run on\nresource-constrained embedded and IoT devices.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:24:55 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Noorbin", "Seyedeh Faezeh Hosseini", ""], ["Layeghy", "Siamak", ""], ["Kusy", "Brano", ""], ["Jurdak", "Raja", ""], ["Bishop-hurley", "Greg", ""], ["Portmann", "Marius", ""]]}, {"id": "2011.03384", "submitter": "Chuang Niu", "authors": "Chuang Niu, Fenglei Fan, Qing Lyu, and Ge Wang", "title": "Noise2Sim -- Similarity-based Self-Learning for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its best performance in image denoising, the supervised deep\ndenoising methods require paired noise-clean data, which are often unavailable.\nTo address this challenge, Noise2Noise was designed based on the fact that\npaired noise-clean images can be replaced by paired noise-noise images that are\neasier to collect. However, in many scenarios the collection of paired\nnoise-noise images is still impractical. To bypass labeled images, Noise2Void\nmethods predict masked pixels from their surroundings with single noisy images\nonly and give improved denoising results that still need improvements. An\nobservation on classic denoising methods is that non-local mean (NLM) outcomes\nare typically superior to locally denoised results. In contrast, Noise2Void and\nits variants do not utilize self-similarities in an image as the NLM-based\nmethods do. Here we propose Noise2Sim, an NLM-inspired self-learning method for\nimage denoising. Specifically, Noise2Sim leverages the self-similarity of image\npixels to train the denoising network, requiring single noisy images only. Our\ntheoretical analysis shows that Noise2Sim tends to be equivalent to Noise2Noise\nunder mild conditions. To efficiently manage the computational burden for\nglobally searching similar pixels, we design a two-step procedure to provide\ndata for Noise2Sim training. Extensive experiments demonstrate the superiority\nof Noise2Sim on common benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:31:08 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:23:32 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 01:50:50 GMT"}, {"version": "v4", "created": "Fri, 18 Jun 2021 07:02:58 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Niu", "Chuang", ""], ["Fan", "Fenglei", ""], ["Lyu", "Qing", ""], ["Wang", "Ge", ""]]}, {"id": "2011.03395", "submitter": "Alexander D'Amour", "authors": "Alexander D'Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak\n  Alipanahi, Alex Beutel, Christina Chen, Jonathan Deaton, Jacob Eisenstein,\n  Matthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen\n  Jerfel, Alan Karthikesalingam, Mario Lucic, Yian Ma, Cory McLean, Diana\n  Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan,\n  Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim Ramasamy, Rory\n  Sayres, Jessica Schrouff, Martin Seneviratne, Shannon Sequeira, Harini\n  Suresh, Victor Veitch, Max Vladymyrov, Xuezhi Wang, Kellie Webster, Steve\n  Yadlowsky, Taedong Yun, Xiaohua Zhai, D. Sculley", "title": "Underspecification Presents Challenges for Credibility in Modern Machine\n  Learning", "comments": "Updates: Updated statistical analysis in Section 6; Additional\n  citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML models often exhibit unexpectedly poor behavior when they are deployed in\nreal-world domains. We identify underspecification as a key reason for these\nfailures. An ML pipeline is underspecified when it can return many predictors\nwith equivalently strong held-out performance in the training domain.\nUnderspecification is common in modern ML pipelines, such as those based on\ndeep learning. Predictors returned by underspecified pipelines are often\ntreated as equivalent based on their training domain performance, but we show\nhere that such predictors can behave very differently in deployment domains.\nThis ambiguity can lead to instability and poor model behavior in practice, and\nis a distinct failure mode from previously identified issues arising from\nstructural mismatch between training and deployment domains. We show that this\nproblem appears in a wide variety of practical ML pipelines, using examples\nfrom computer vision, medical imaging, natural language processing, clinical\nrisk prediction based on electronic health records, and medical genomics. Our\nresults show the need to explicitly account for underspecification in modeling\npipelines that are intended for real-world deployment in any domain.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 14:53:13 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 19:16:02 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["D'Amour", "Alexander", ""], ["Heller", "Katherine", ""], ["Moldovan", "Dan", ""], ["Adlam", "Ben", ""], ["Alipanahi", "Babak", ""], ["Beutel", "Alex", ""], ["Chen", "Christina", ""], ["Deaton", "Jonathan", ""], ["Eisenstein", "Jacob", ""], ["Hoffman", "Matthew D.", ""], ["Hormozdiari", "Farhad", ""], ["Houlsby", "Neil", ""], ["Hou", "Shaobo", ""], ["Jerfel", "Ghassen", ""], ["Karthikesalingam", "Alan", ""], ["Lucic", "Mario", ""], ["Ma", "Yian", ""], ["McLean", "Cory", ""], ["Mincu", "Diana", ""], ["Mitani", "Akinori", ""], ["Montanari", "Andrea", ""], ["Nado", "Zachary", ""], ["Natarajan", "Vivek", ""], ["Nielson", "Christopher", ""], ["Osborne", "Thomas F.", ""], ["Raman", "Rajiv", ""], ["Ramasamy", "Kim", ""], ["Sayres", "Rory", ""], ["Schrouff", "Jessica", ""], ["Seneviratne", "Martin", ""], ["Sequeira", "Shannon", ""], ["Suresh", "Harini", ""], ["Veitch", "Victor", ""], ["Vladymyrov", "Max", ""], ["Wang", "Xuezhi", ""], ["Webster", "Kellie", ""], ["Yadlowsky", "Steve", ""], ["Yun", "Taedong", ""], ["Zhai", "Xiaohua", ""], ["Sculley", "D.", ""]]}, {"id": "2011.03424", "submitter": "Sara Latifi", "authors": "Sara Latifi, Noemi Mauro, Dietmar Jannach", "title": "Session-aware Recommendation: A Surprising Quest for the\n  State-of-the-art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are designed to help users in situations of information\noverload. In recent years, we observed increased interest in session-based\nrecommendation scenarios, where the problem is to make item suggestions to\nusers based only on interactions observed in an ongoing session. However, in\ncases where interactions from previous user sessions are available, the\nrecommendations can be personalized according to the users' long-term\npreferences, a process called session-aware recommendation. Today, research in\nthis area is scattered and many existing works only compare session-aware with\nsession-based models. This makes it challenging to understand what represents\nthe state-of-the-art. To close this research gap, we benchmarked recent\nsession-aware algorithms against each other and against a number of\nsession-based recommendation algorithms and trivial extensions thereof. Our\ncomparison, to some surprise, revealed that (i) item simple techniques based on\nnearest neighbors consistently outperform recent neural techniques and that\n(ii) session-aware models were mostly not better than approaches that do not\nuse long-term preference information. Our work therefore not only points to\npotential methodological issues where new methods are compared to weak\nbaselines, but also indicates that there remains a huge potential for more\nsophisticated session-aware recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 15:18:01 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Latifi", "Sara", ""], ["Mauro", "Noemi", ""], ["Jannach", "Dietmar", ""]]}, {"id": "2011.03426", "submitter": "Aswin Sivaraman", "authors": "Aswin Sivaraman and Minje Kim", "title": "Self-Supervised Learning from Contrastive Mixtures for Personalized\n  Speech Enhancement", "comments": "4 pages, 4 figures, submitted for NeurIPS SAS Workshop 2020 and\n  ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores how self-supervised learning can be universally used to\ndiscover speaker-specific features towards enabling personalized speech\nenhancement models. We specifically address the few-shot learning scenario\nwhere access to cleaning recordings of a test-time speaker is limited to a few\nseconds, but noisy recordings of the speaker are abundant. We develop a simple\ncontrastive learning procedure which treats the abundant noisy data as\nmakeshift training targets through pairwise noise injection: the model is\npretrained to maximize agreement between pairs of differently deformed\nidentical utterances and to minimize agreement between pairs of similarly\ndeformed nonidentical utterances. Our experiments compare the proposed\npretraining approach with two baseline alternatives: speaker-agnostic\nfully-supervised pretraining, and speaker-specific self-supervised pretraining\nwithout contrastive loss terms. Of all three approaches, the proposed method\nusing contrastive mixtures is found to be most robust to model compression\n(using 85% fewer parameters) and reduced clean speech (requiring only 3\nseconds).\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 15:21:00 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Sivaraman", "Aswin", ""], ["Kim", "Minje", ""]]}, {"id": "2011.03431", "submitter": "Rickard Karlsson", "authors": "Rickard Karlsson, Laurens Bliek, Sicco Verwer, Mathijs de Weerdt", "title": "Continuous surrogate-based optimization algorithms are well-suited for\n  expensive discrete problems", "comments": "16 pages, 3 figures; added keywords, typos corrected, additional\n  information in Figure 3 but results unchanged", "journal-ref": "Proceedings of BNAIC/BeneLearn (2020), 88-102", "doi": "10.1007/978-3-030-76640-5_4", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One method to solve expensive black-box optimization problems is to use a\nsurrogate model that approximates the objective based on previous observed\nevaluations. The surrogate, which is cheaper to evaluate, is optimized instead\nto find an approximate solution to the original problem. In the case of\ndiscrete problems, recent research has revolved around surrogate models that\nare specifically constructed to deal with discrete structures. A main\nmotivation is that literature considers continuous methods, such as Bayesian\noptimization with Gaussian processes as the surrogate, to be sub-optimal\n(especially in higher dimensions) because they ignore the discrete structure\nby, e.g., rounding off real-valued solutions to integers. However, we claim\nthat this is not true. In fact, we present empirical evidence showing that the\nuse of continuous surrogate models displays competitive performance on a set of\nhigh-dimensional discrete benchmark problems, including a real-life\napplication, against state-of-the-art discrete surrogate-based methods. Our\nexperiments on different discrete structures and time constraints also give\nmore insight into which algorithms work well on which type of problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 15:27:45 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 19:21:54 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Karlsson", "Rickard", ""], ["Bliek", "Laurens", ""], ["Verwer", "Sicco", ""], ["de Weerdt", "Mathijs", ""]]}, {"id": "2011.03435", "submitter": "Revanth Reddy", "authors": "Revanth Gangi Reddy, Md Arafat Sultan, Efsun Sarioglu Kayi, Rong\n  Zhang, Vittorio Castelli, Avirup Sil", "title": "Answer Span Correction in Machine Reading Comprehension", "comments": "Accepted in Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answer validation in machine reading comprehension (MRC) consists of\nverifying an extracted answer against an input context and question pair.\nPrevious work has looked at re-assessing the \"answerability\" of the question\ngiven the extracted answer. Here we address a different problem: the tendency\nof existing MRC systems to produce partially correct answers when presented\nwith answerable questions. We explore the nature of such errors and propose a\npost-processing correction method that yields statistically significant\nperformance improvements over state-of-the-art MRC systems in both monolingual\nand multilingual evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 15:31:07 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Reddy", "Revanth Gangi", ""], ["Sultan", "Md Arafat", ""], ["Kayi", "Efsun Sarioglu", ""], ["Zhang", "Rong", ""], ["Castelli", "Vittorio", ""], ["Sil", "Avirup", ""]]}, {"id": "2011.03442", "submitter": "Martin Reczko", "authors": "Dimitra N. Panou and Martin Reczko", "title": "DeepFoldit -- A Deep Reinforcement Learning Neural Network Folding\n  Proteins", "comments": "108 pages, 66 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite considerable progress, ab initio protein structure prediction remains\nsuboptimal. A crowdsourcing approach is the online puzzle video game Foldit,\nthat provided several useful results that matched or even outperformed\nalgorithmically computed solutions. Using Foldit, the WeFold crowd had several\nsuccessful participations in the Critical Assessment of Techniques for Protein\nStructure Prediction. Based on the recent Foldit standalone version, we trained\na deep reinforcement neural network called DeepFoldit to improve the score\nassigned to an unfolded protein, using the Q-learning method with experience\nreplay. This paper is focused on model improvement through hyperparameter\ntuning. We examined various implementations by examining different model\narchitectures and changing hyperparameter values to improve the accuracy of the\nmodel. The new model hyper-parameters also improved its ability to generalize.\nInitial results, from the latest implementation, show that given a set of small\nunfolded training proteins, DeepFoldit learns action sequences that improve the\nscore both on the training set and on novel test proteins. Our approach\ncombines the intuitive user interface of Foldit with the efficiency of deep\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 16:05:42 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Panou", "Dimitra N.", ""], ["Reczko", "Martin", ""]]}, {"id": "2011.03443", "submitter": "Amir Shanehsazzadeh", "authors": "Amir Shanehsazzadeh, David Belanger, David Dohan", "title": "Is Transfer Learning Necessary for Protein Landscape Prediction?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been great interest in learning how to best represent\nproteins, specifically with fixed-length embeddings. Deep learning has become a\npopular tool for protein representation learning as a model's hidden layers\nproduce potentially useful vector embeddings. TAPE introduced a number of\nbenchmark tasks and showed that semi-supervised learning, via pretraining\nlanguage models on a large protein corpus, improved performance on downstream\ntasks. Two of the tasks (fluorescence prediction and stability prediction)\ninvolve learning fitness landscapes. In this paper, we show that CNN models\ntrained solely using supervised learning both compete with and sometimes\noutperform the best models from TAPE that leverage expensive pretraining on\nlarge protein datasets. These CNN models are sufficiently simple and small that\nthey can be trained using a Google Colab notebook. We also find for the\nfluorescence task that linear regression outperforms our models and the TAPE\nmodels. The benchmarking tasks proposed by TAPE are excellent measures of a\nmodel's ability to predict protein function and should be used going forward.\nHowever, we believe it is important to add baselines from simple models to put\nthe performance of the semi-supervised models that have been reported so far\ninto perspective.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 20:41:36 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Shanehsazzadeh", "Amir", ""], ["Belanger", "David", ""], ["Dohan", "David", ""]]}, {"id": "2011.03452", "submitter": "Xuan Bi", "authors": "Xuan Bi, Gediminas Adomavicius, William Li, Annie Qu", "title": "Improving Sales Forecasting Accuracy: A Tensor Factorization Approach\n  with Demand Awareness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to accessible big data collections from consumers, products, and stores,\nadvanced sales forecasting capabilities have drawn great attention from many\ncompanies especially in the retail business because of its importance in\ndecision making. Improvement of the forecasting accuracy, even by a small\npercentage, may have a substantial impact on companies' production and\nfinancial planning, marketing strategies, inventory controls, supply chain\nmanagement, and eventually stock prices. Specifically, our research goal is to\nforecast the sales of each product in each store in the near future. Motivated\nby tensor factorization methodologies for personalized context-aware\nrecommender systems, we propose a novel approach called the Advanced Temporal\nLatent-factor Approach to Sales forecasting (ATLAS), which achieves accurate\nand individualized prediction for sales by building a single\ntensor-factorization model across multiple stores and products. Our\ncontribution is a combination of: tensor framework (to leverage information\nacross stores and products), a new regularization function (to incorporate\ndemand dynamics), and extrapolation of tensor into future time periods using\nstate-of-the-art statistical (seasonal auto-regressive integrated\nmoving-average models) and machine-learning (recurrent neural networks) models.\nThe advantages of ATLAS are demonstrated on eight product category datasets\ncollected by the Information Resource, Inc., where a total of 165 million\nweekly sales transactions from more than 1,500 grocery stores over 15,560\nproducts are analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:04:40 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bi", "Xuan", ""], ["Adomavicius", "Gediminas", ""], ["Li", "William", ""], ["Qu", "Annie", ""]]}, {"id": "2011.03459", "submitter": "Pasquale Minervini", "authors": "Erik Arakelyan, Daniel Daza, Pasquale Minervini, Michael Cochez", "title": "Complex Query Answering with Neural Link Predictors", "comments": "Proceedings of the Ninth International Conference on Learning\n  Representations (ICLR 2021, oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural link predictors are immensely useful for identifying missing edges in\nlarge scale Knowledge Graphs. However, it is still not clear how to use these\nmodels for answering more complex queries that arise in a number of domains,\nsuch as queries using logical conjunctions ($\\land$), disjunctions ($\\lor$) and\nexistential quantifiers ($\\exists$), while accounting for missing edges. In\nthis work, we propose a framework for efficiently answering complex queries on\nincomplete Knowledge Graphs. We translate each query into an end-to-end\ndifferentiable objective, where the truth value of each atom is computed by a\npre-trained neural link predictor. We then analyse two solutions to the\noptimisation problem, including gradient-based and combinatorial search. In our\nexperiments, the proposed approach produces more accurate results than\nstate-of-the-art methods -- black-box neural models trained on millions of\ngenerated queries -- without the need of training on a large and diverse set of\ncomplex queries. Using orders of magnitude less training data, we obtain\nrelative improvements ranging from 8% up to 40% in Hits@3 across different\nknowledge graphs containing factual information. Finally, we demonstrate that\nit is possible to explain the outcome of our model in terms of the intermediate\nsolutions identified for each of the complex query atoms. All our source code\nand datasets are available online, at https://github.com/uclnlp/cqd.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:20:49 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 21:19:37 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 18:08:30 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 09:42:49 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Arakelyan", "Erik", ""], ["Daza", "Daniel", ""], ["Minervini", "Pasquale", ""], ["Cochez", "Michael", ""]]}, {"id": "2011.03474", "submitter": "Cole Miles", "authors": "Cole Miles, Annabelle Bohrdt, Ruihan Wu, Christie Chiu, Muqing Xu,\n  Geoffrey Ji, Markus Greiner, Kilian Q. Weinberger, Eugene Demler, Eun-Ah Kim", "title": "Correlator Convolutional Neural Networks: An Interpretable Architecture\n  for Image-like Quantum Matter Data", "comments": "7 pages, 4 figures + 13 pages of supplemental material", "journal-ref": null, "doi": "10.1038/s41467-021-23952-w", "report-no": null, "categories": "cond-mat.str-el cond-mat.dis-nn cond-mat.quant-gas cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are a powerful theoretical tool for analyzing data\nfrom quantum simulators, in which results of experiments are sets of snapshots\nof many-body states. Recently, they have been successfully applied to\ndistinguish between snapshots that can not be identified using traditional one\nand two point correlation functions. Thus far, the complexity of these models\nhas inhibited new physical insights from this approach. Here, using a novel set\nof nonlinearities we develop a network architecture that discovers features in\nthe data which are directly interpretable in terms of physical observables. In\nparticular, our network can be understood as uncovering high-order correlators\nwhich significantly differ between the data studied. We demonstrate this new\narchitecture on sets of simulated snapshots produced by two candidate theories\napproximating the doped Fermi-Hubbard model, which is realized in state-of-the\nart quantum gas microscopy experiments. From the trained networks, we uncover\nthat the key distinguishing features are fourth-order spin-charge correlators,\nproviding a means to compare experimental data to theoretical predictions. Our\napproach lends itself well to the construction of simple, end-to-end\ninterpretable architectures and is applicable to arbitrary lattice data, thus\npaving the way for new physical insights from machine learning studies of\nexperimental as well as numerical data.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:04:10 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Miles", "Cole", ""], ["Bohrdt", "Annabelle", ""], ["Wu", "Ruihan", ""], ["Chiu", "Christie", ""], ["Xu", "Muqing", ""], ["Ji", "Geoffrey", ""], ["Greiner", "Markus", ""], ["Weinberger", "Kilian Q.", ""], ["Demler", "Eugene", ""], ["Kim", "Eun-Ah", ""]]}, {"id": "2011.03476", "submitter": "Daniel Park", "authors": "Daniel Park, Hannah Powers, Benji Prashker, Leland Liu and B\\\"ulent\n  Yener", "title": "Towards Obfuscated Malware Detection for Low Powered IoT Devices", "comments": "preprint. to appear at the International Conference on Machine\n  Learning Applications (ICMLA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased deployment of IoT and edge devices into commercial and\nuser networks, these devices have become a new threat vector for malware\nauthors. It is imperative to protect these devices as they become more\nprevalent in commercial and personal networks. However, due to their limited\ncomputational power and storage space, especially in the case of\nbattery-powered devices, it is infeasible to deploy state-of-the-art malware\ndetectors onto these systems. In this work, we propose using and extracting\nfeatures from Markov matrices constructed from opcode traces as a low cost\nfeature for unobfuscated and obfuscated malware detection. We empirically show\nthat our approach maintains a high detection rate while consuming less power\nthan similar work.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:10:26 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Park", "Daniel", ""], ["Powers", "Hannah", ""], ["Prashker", "Benji", ""], ["Liu", "Leland", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2011.03479", "submitter": "Christian B\\\"ohm", "authors": "Christian B\\\"ohm, Claudia Plant", "title": "Massively Parallel Graph Drawing and Representation Learning", "comments": null, "journal-ref": "IEEE BigData 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To fully exploit the performance potential of modern multi-core processors,\nmachine learning and data mining algorithms for big data must be parallelized\nin multiple ways. Today's CPUs consist of multiple cores, each following an\nindependent thread of control, and each equipped with multiple arithmetic units\nwhich can perform the same operation on a vector of multiple data objects.\nGraph embedding, i.e. converting the vertices of a graph into numerical vectors\nis a data mining task of high importance and is useful for graph drawing\n(low-dimensional vectors) and graph representation learning (high-dimensional\nvectors). In this paper, we propose MulticoreGEMPE (Graph Embedding by\nMinimizing the Predictive Entropy), an information-theoretic method which can\ngenerate low and high-dimensional vectors. MulticoreGEMPE applies MIMD\n(Multiple Instructions Multiple Data, using OpenMP) and SIMD (Single\nInstructions Multiple Data, using AVX-512) parallelism. We propose general\nideas applicable in other graph-based algorithms like \\emph{vectorized hashing}\nand \\emph{vectorized reduction}. Our experimental evaluation demonstrates the\nsuperiority of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:18:14 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["B\u00f6hm", "Christian", ""], ["Plant", "Claudia", ""]]}, {"id": "2011.03488", "submitter": "Gustav Sourek", "authors": "Gustav Sourek, Filip Zelezny, Ondrej Kuzelka", "title": "Learning with Molecules beyond Graph Neural Networks", "comments": "accepted to Machine Learning for Molecules Workshop @ NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a deep learning framework which is inherently based in the\nhighly expressive language of relational logic, enabling to, among other\nthings, capture arbitrarily complex graph structures. We show how Graph Neural\nNetworks and similar models can be easily covered in the framework by\nspecifying the underlying propagation rules in the relational logic. The\ndeclarative nature of the used language then allows to easily modify and extend\nthe propagation schemes into complex structures, such as the molecular rings\nwhich we choose for a short demonstration in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:42:42 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Sourek", "Gustav", ""], ["Zelezny", "Filip", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "2011.03490", "submitter": "Taufeq Mohammed Razakh", "authors": "Taufeq Mohammed Razakh, Beibei Wang, Shane Jackson, Rajiv K. Kalia,\n  Aiichiro Nakano, Ken-ichi Nomura, Priya Vashishta", "title": "Physics-informed Neural-Network Software for Molecular Dynamics\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We have developed a novel differential equation solver software called PND\nbased on the physics-informed neural network for molecular dynamics simulators.\nBased on automatic differentiation technique provided by Pytorch, our software\nallows users to flexibly implement equation of atom motions, initial and\nboundary conditions, and conservation laws as loss function to train the\nnetwork. PND comes with a parallel molecular dynamics (MD) engine in order for\nusers to examine and optimize loss function design, and different conservation\nlaws and boundary conditions, and hyperparameters, thereby accelerate the\nPINN-based development for molecular applications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:52:40 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 09:50:19 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 12:40:10 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Razakh", "Taufeq Mohammed", ""], ["Wang", "Beibei", ""], ["Jackson", "Shane", ""], ["Kalia", "Rajiv K.", ""], ["Nakano", "Aiichiro", ""], ["Nomura", "Ken-ichi", ""], ["Vashishta", "Priya", ""]]}, {"id": "2011.03502", "submitter": "Quan Duong", "authors": "Quan Duong, Mika H\\\"am\\\"al\\\"ainen, Simon Hengchen", "title": "An Unsupervised method for OCR Post-Correction and Spelling\n  Normalisation for Finnish", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Historical corpora are known to contain errors introduced by OCR (optical\ncharacter recognition) methods used in the digitization process, often said to\nbe degrading the performance of NLP systems. Correcting these errors manually\nis a time-consuming process and a great part of the automatic approaches have\nbeen relying on rules or supervised machine learning. We build on previous work\non fully automatic unsupervised extraction of parallel data to train a\ncharacter-based sequence-to-sequence NMT (neural machine translation) model to\nconduct OCR error correction designed for English, and adapt it to Finnish by\nproposing solutions that take the rich morphology of the language into account.\nOur new method shows increased performance while remaining fully unsupervised,\nwith the added benefit of spelling normalisation. The source code and models\nare available on GitHub and Zenodo.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 18:19:48 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Duong", "Quan", ""], ["H\u00e4m\u00e4l\u00e4inen", "Mika", ""], ["Hengchen", "Simon", ""]]}, {"id": "2011.03506", "submitter": "Christopher Grimm", "authors": "Christopher Grimm, Andr\\'e Barreto, Satinder Singh, David Silver", "title": "The Value Equivalence Principle for Model-Based Reinforcement Learning", "comments": "NeurIPS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning models of the environment from data is often viewed as an essential\ncomponent to building intelligent reinforcement learning (RL) agents. The\ncommon practice is to separate the learning of the model from its use, by\nconstructing a model of the environment's dynamics that correctly predicts the\nobserved state transitions. In this paper we argue that the limited\nrepresentational resources of model-based RL agents are better used to build\nmodels that are directly useful for value-based planning. As our main\ncontribution, we introduce the principle of value equivalence: two models are\nvalue equivalent with respect to a set of functions and policies if they yield\nthe same Bellman updates. We propose a formulation of the model learning\nproblem based on the value equivalence principle and analyze how the set of\nfeasible solutions is impacted by the choice of policies and functions.\nSpecifically, we show that, as we augment the set of policies and functions\nconsidered, the class of value equivalent models shrinks, until eventually\ncollapsing to a single point corresponding to a model that perfectly describes\nthe environment. In many problems, directly modelling state-to-state\ntransitions may be both difficult and unnecessary. By leveraging the\nvalue-equivalence principle one may find simpler models without compromising\nperformance, saving computation and memory. We illustrate the benefits of\nvalue-equivalent model learning with experiments comparing it against more\ntraditional counterparts like maximum likelihood estimation. More generally, we\nargue that the principle of value equivalence underlies a number of recent\nempirical successes in RL, such as Value Iteration Networks, the Predictron,\nValue Prediction Networks, TreeQN, and MuZero, and provides a first theoretical\nunderpinning of those results.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 18:25:54 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Grimm", "Christopher", ""], ["Barreto", "Andr\u00e9", ""], ["Singh", "Satinder", ""], ["Silver", "David", ""]]}, {"id": "2011.03519", "submitter": "Sanjoy Das", "authors": "A. Khaled Zarabie, Sanjoy Das, and Hongyu Wu", "title": "A Data-Driven Machine Learning Approach for Consumer Modeling with Load\n  Disaggregation", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CE cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While non-parametric models, such as neural networks, are sufficient in the\nload forecasting, separate estimates of fixed and shiftable loads are\nbeneficial to a wide range of applications such as distribution system\noperational planning, load scheduling, energy trading, and utility demand\nresponse programs. A semi-parametric estimation model is usually required,\nwhere cost sensitivities of demands must be known. Existing research work\nconsistently uses somewhat arbitrary parameters that seem to work best. In this\npaper, we propose a generic class of data-driven semiparametric models derived\nfrom consumption data of residential consumers. A two-stage machine learning\napproach is developed. In the first stage, disaggregation of the load into\nfixed and shiftable components is accomplished by means of a hybrid algorithm\nconsisting of non-negative matrix factorization (NMF) and Gaussian mixture\nmodels (GMM), with the latter trained by an expectation-maximization (EM)\nalgorithm. The fixed and shiftable loads are subject to analytic treatment with\neconomic considerations. In the second stage, the model parameters are\nestimated using an L2-norm, epsilon-insensitive regression approach. Actual\nenergy usage data of two residential customers show the validity of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:36:11 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Zarabie", "A. Khaled", ""], ["Das", "Sanjoy", ""], ["Wu", "Hongyu", ""]]}, {"id": "2011.03522", "submitter": "Giulio Vignoli", "authors": "Peng Bai, Giulio Vignoli, Andrea Viezzoli, Jouni Nevalainen, and\n  Giuseppina Vacca", "title": "(Quasi-)Real-Time Inversion of Airborne Time-Domain Electromagnetic Data\n  via Artificial Neural Network", "comments": null, "journal-ref": "Remote Sens. 2020, 12, 3440", "doi": "10.3390/rs12203440", "report-no": null, "categories": "physics.geo-ph cs.LG cs.NA math.NA physics.ins-det", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The possibility to have results very quickly after, or even during, the\ncollection of electromagnetic data would be important, not only for quality\ncheck purposes, but also for adjusting the location of the proposed flight\nlines during an airborne time-domain acquisition. This kind of readiness could\nhave a large impact in terms of optimization of the Value of Information of the\nmeasurements to be acquired. In addition, the importance of having fast tools\nfor retrieving resistivity models from airborne time-domain data is\ndemonstrated by the fact that Conductivity-Depth Imaging methodologies are\nstill the standard in mineral exploration. In fact, they are extremely\ncomputationally efficient, and, at the same time, they preserve a very high\nlateral resolution. For these reasons, they are often preferred to inversion\nstrategies even if the latter approaches are generally more accurate in terms\nof proper reconstruction of the depth of the targets and of reliable retrieval\nof true resistivity values of the subsurface. In this research, we discuss a\nnovel approach, based on neural network techniques, capable of retrieving\nresistivity models with a quality comparable with the inversion strategy, but\nin a fraction of the time. We demonstrate the advantages of the proposed novel\napproach on synthetic and field datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 18:53:37 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bai", "Peng", ""], ["Vignoli", "Giulio", ""], ["Viezzoli", "Andrea", ""], ["Nevalainen", "Jouni", ""], ["Vacca", "Giuseppina", ""]]}, {"id": "2011.03525", "submitter": "Zhuangzhi Chen", "authors": "Zhuangzhi Chen, Hui Cui, Jingyang Xiang, Kunfeng Qiu, Liang Huang,\n  Shilian Zheng, Shichuan Chen, Qi Xuan and Xiaoniu Yang", "title": "SigNet: An Advanced Deep Learning Framework for Radio Signal\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods achieve great success in many areas due to their\npowerful feature extraction capabilities and end-to-end training mechanism, and\nrecently they are also introduced for radio signal modulation classification.\nIn this paper, we propose a novel deep learning framework called SigNet, where\na signal-to-matrix (S2M) operator is adopted to convert the original signal\ninto a square matrix first and is co-trained with a follow-up CNN architecture\nfor classification. This model is further accelerated by integrating 1D\nconvolution operators, leading to the upgraded model SigNet2.0. The experiments\non two signal datasets show that both SigNet and SigNet2.0 outperform a number\nof well-known baselines, achieving the state-of-the-art performance. Notably,\nthey obtain significantly higher accuracy than 1D-ResNet and 2D-CNN (at most\nincreasing 70.5\\%), while much faster than LSTM (at most saving 88.0\\% training\ntime). More interestingly, our proposed models behave extremely well in\nfew-shot learning when a small training data set is provided. They can achieve\na relatively high accuracy even when 1\\% training data are kept, while other\nbaseline models may lose their effectiveness much more quickly as the datasets\nget smaller. Such result suggests that SigNet/SigNet2.0 could be extremely\nuseful in the situations where labeled signal data are difficult to obtain.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 13:37:10 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Chen", "Zhuangzhi", ""], ["Cui", "Hui", ""], ["Xiang", "Jingyang", ""], ["Qiu", "Kunfeng", ""], ["Huang", "Liang", ""], ["Zheng", "Shilian", ""], ["Chen", "Shichuan", ""], ["Xuan", "Qi", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "2011.03526", "submitter": "Camilo Rocha", "authors": "Camila Riccio, Jorge Finke, Camilo Rocha", "title": "Using Overlapping Communities and Network Structure for Identifying\n  Reduced Groups of Stress Responsive Genes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a workflow to identify genes responding to a specific\ntreatment in an organism, such as abiotic stresses, a main cause of extensive\nagricultural production losses worldwide. On input RNA sequencing read counts\n(measured for genotypes under control and treatment conditions) and biological\nreplicates, it outputs a collection of characterized genes, potentially\nrelevant to treatment. Technically, the proposed approach is both a\ngeneralization and an extension of WGCNA; its main goal is to identify specific\nmodules in a network of genes after a sequence of normalization and filtering\nsteps. In this work, module detection is achieved by using Hierarchical Link\nClustering, which can recognize overlapping communities and thus have more\nbiological meaning given the overlapping regulatory domains of systems that\ngenerate co-expression. Additional steps and information are also added to the\nworkflow, where some networks in the intermediate steps are forced to be\nscale-free and LASSO regression is employed to select the most significant\nmodules of phenotypical responses to stress. Finally, the workflow is showcased\nwith a systematic study on rice (Oryza sativa), a major food source that is\nknown to be highly sensitive to salt stress: a total of 6 modules are detected\nas relevant in the response to salt stress in rice; these genes may act as\npotential targets for the improvement of salinity tolerance in rice cultivars.\nThe proposed workflow has the potential to ultimately reduce the search-space\nfor candidate genes responding to a specific treatment, which can considerably\noptimize the effort, time, and money invested by researchers in the\nexperimental validation of stress responsive genes.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 21:14:59 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Riccio", "Camila", ""], ["Finke", "Jorge", ""], ["Rocha", "Camilo", ""]]}, {"id": "2011.03535", "submitter": "Simon Osindero", "authors": "Simon Osindero", "title": "Contrastive Topographic Models: Energy-based density models applied to\n  the understanding of sensory coding and cortical topography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of building theoretical models that help elucidate the\nfunction of the visual brain at computational/algorithmic and\nstructural/mechanistic levels. We seek to understand how the receptive fields\nand topographic maps found in visual cortical areas relate to underlying\ncomputational desiderata. We view the development of sensory systems from the\npopular perspective of probability density estimation; this is motivated by the\nnotion that an effective internal representational scheme is likely to reflect\nthe statistical structure of the environment in which an organism lives. We\napply biologically based constraints on elements of the model.\n  The thesis begins by surveying the relevant literature from the fields of\nneurobiology, theoretical neuroscience, and machine learning. After this review\nwe present our main theoretical and algorithmic developments: we propose a\nclass of probabilistic models, which we refer to as \"energy-based models\", and\nshow equivalences between this framework and various other types of\nprobabilistic model such as Markov random fields and factor graphs; we also\ndevelop and discuss approximate algorithms for performing maximum likelihood\nlearning and inference in our energy based models. The rest of the thesis is\nthen concerned with exploring specific instantiations of such models. By\nperforming constrained optimisation of model parameters to maximise the\nlikelihood of appropriate, naturalistic datasets we are able to qualitatively\nreproduce many of the receptive field and map properties found in vivo, whilst\nsimultaneously learning about statistical regularities in the data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:36:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Osindero", "Simon", ""]]}, {"id": "2011.03544", "submitter": "Ethan Moyer", "authors": "Ethan J. Moyer (1) and Anup Das (PhD) (2) ((1) School of Biomedical\n  Engineering, Science and Health Systems, Drexel University, Philadelphia,\n  Pennsylvania, USA, (2) College of Engineering, Drexel University,\n  Philadelphia, Pennsylvania, USA)", "title": "Machine learning applications to DNA subsequence and restriction site\n  analysis", "comments": "6 pages, 8 Figures. Accepted to 2020 IEEE Signal Processing in\n  Medicine and Biology Symposium, Temple University, Philadelphia, PA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the BioBricks standard, restriction synthesis is a novel catabolic\niterative DNA synthesis method that utilizes endonucleases to synthesize a\nquery sequence from a reference sequence. In this work, the reference sequence\nis built from shorter subsequences by classifying them as applicable or\ninapplicable for the synthesis method using three different machine learning\nmethods: Support Vector Machines (SVMs), random forest, and Convolution Neural\nNetworks (CNNs). Before applying these methods to the data, a series of feature\nselection, curation, and reduction steps are applied to create an accurate and\nrepresentative feature space. Following these preprocessing steps, three\ndifferent pipelines are proposed to classify subsequences based on their\nnucleotide sequence and other relevant features corresponding to the\nrestriction sites of over 200 endonucleases. The sensitivity using SVMs, random\nforest, and CNNs are 94.9%, 92.7%, 91.4%, respectively. Moreover, each method\nscores lower in specificity with SVMs, random forest, and CNNs resulting in\n77.4%, 85.7%, and 82.4%, respectively. In addition to analyzing these results,\nthe misclassifications in SVMs and CNNs are investigated. Across these two\nmodels, different features with a derived nucleotide specificity visually\ncontribute more to classification compared to other features. This observation\nis an important factor when considering new nucleotide sensitivity features for\nfuture studies.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 13:37:10 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 19:03:19 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 18:31:17 GMT"}, {"version": "v4", "created": "Sun, 6 Dec 2020 03:31:08 GMT"}, {"version": "v5", "created": "Fri, 11 Dec 2020 16:03:26 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Moyer", "Ethan J.", "", "PhD"], ["Das", "Anup", "", "PhD"]]}, {"id": "2011.03574", "submitter": "Uri Alon", "authors": "Ben Finkelshtein, Chaim Baskin, Evgenii Zheltonozhskii, Uri Alon", "title": "Single-Node Attack for Fooling Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have shown broad applicability in a variety of\ndomains. Some of these domains, such as social networks and product\nrecommendations, are fertile ground for malicious users and behavior. In this\npaper, we show that GNNs are vulnerable to the extremely limited scenario of a\nsingle-node adversarial example, where the node cannot be picked by the\nattacker. That is, an attacker can force the GNN to classify any target node to\na chosen label by only slightly perturbing another single arbitrary node in the\ngraph, even when not being able to pick that specific attacker node. When the\nadversary is allowed to pick a specific attacker node, the attack is even more\neffective. We show that this attack is effective across various GNN types, such\nas GraphSAGE, GCN, GAT, and GIN, across a variety of real-world datasets, and\nas a targeted and a non-targeted attack. Our code is available at\nhttps://github.com/benfinkelshtein/SINGLE .\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 19:59:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Finkelshtein", "Ben", ""], ["Baskin", "Chaim", ""], ["Zheltonozhskii", "Evgenii", ""], ["Alon", "Uri", ""]]}, {"id": "2011.03577", "submitter": "Philipp Andermatt", "authors": "Philipp Andermatt, Radu Timofte", "title": "A Weakly Supervised Convolutional Network for Change Segmentation and\n  Classification", "comments": "17 pages, 5 figures. Accepted at the Machine Learning and Computing\n  for Visual Semantic Analysis (MLCSA2020) Workshop which is held in\n  conjunction with ACCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully supervised change detection methods require difficult to procure\npixel-level labels, while weakly supervised approaches can be trained with\nimage-level labels. However, most of these approaches require a combination of\nchanged and unchanged image pairs for training. Thus, these methods can not\ndirectly be used for datasets where only changed image pairs are available. We\npresent W-CDNet, a novel weakly supervised change detection network that can be\ntrained with image-level semantic labels. Additionally, W-CDNet can be trained\nwith two different types of datasets, either containing changed image pairs\nonly or a mixture of changed and unchanged image pairs. Since we use\nimage-level semantic labels for training, we simultaneously create a change\nmask and label the changed object for single-label images. W-CDNet employs a\nW-shaped siamese U-net to extract feature maps from an image pair which then\nget compared in order to create a raw change mask. The core part of our model,\nthe Change Segmentation and Classification (CSC) module, learns an accurate\nchange mask at a hidden layer by using a custom Remapping Block and then\nsegmenting the current input image with the change mask. The segmented image is\nused to predict the image-level semantic label. The correct label can only be\npredicted if the change mask actually marks relevant change. This forces the\nmodel to learn an accurate change mask. We demonstrate the segmentation and\nclassification performance of our approach and achieve top results on AICD and\nHRSCD, two public aerial imaging change detection datasets as well as on a Food\nWaste change detection dataset. Our code is available at\nhttps://github.com/PhiAbs/W-CDNet .\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 20:20:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Andermatt", "Philipp", ""], ["Timofte", "Radu", ""]]}, {"id": "2011.03590", "submitter": "Yuxiao Chen", "authors": "Yuxiao Chen, Ugo Rosolia, Chuchu Fan, Aaron D. Ames, and Richard\n  Murray", "title": "Reactive motion planning with probabilistic safety guarantees", "comments": "In the Conference on Robotic Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion planning in environments with multiple agents is critical to many\nimportant autonomous applications such as autonomous vehicles and assistive\nrobots. This paper considers the problem of motion planning, where the\ncontrolled agent shares the environment with multiple uncontrolled agents.\nFirst, a predictive model of the uncontrolled agents is trained to predict all\npossible trajectories within a short horizon based on the scenario. The\nprediction is then fed to a motion planning module based on model predictive\ncontrol. We proved generalization bound for the predictive model using three\ndifferent methods, post-bloating, support vector machine (SVM), and conformal\nanalysis, all capable of generating stochastic guarantees of the correctness of\nthe predictor. The proposed approach is demonstrated in simulation in a\nscenario emulating autonomous highway driving.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 20:37:15 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 00:07:12 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Chen", "Yuxiao", ""], ["Rosolia", "Ugo", ""], ["Fan", "Chuchu", ""], ["Ames", "Aaron D.", ""], ["Murray", "Richard", ""]]}, {"id": "2011.03591", "submitter": "Aleksandra \\'Ciprijanovi\\'c", "authors": "A. \\'Ciprijanovi\\'c and D. Kafkes and S. Jenkins and K. Downey and G.\n  N. Perdue and S. Madireddy and T. Johnston and B. Nord", "title": "Domain adaptation techniques for improved cross-domain study of galaxy\n  mergers", "comments": "Accepted in: Machine Learning and the Physical Sciences - Workshop at\n  the 34th Conference on Neural Information Processing Systems (NeurIPS); final\n  version", "journal-ref": null, "doi": null, "report-no": "FERMILAB-CONF-20-582-SCD", "categories": "astro-ph.IM astro-ph.GA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In astronomy, neural networks are often trained on simulated data with the\nprospect of being applied to real observations. Unfortunately, simply training\na deep neural network on images from one domain does not guarantee satisfactory\nperformance on new images from a different domain. The ability to share\ncross-domain knowledge is the main advantage of modern deep domain adaptation\ntechniques. Here we demonstrate the use of two techniques - Maximum Mean\nDiscrepancy (MMD) and adversarial training with Domain Adversarial Neural\nNetworks (DANN) - for the classification of distant galaxy mergers from the\nIllustris-1 simulation, where the two domains presented differ only due to\ninclusion of observational noise. We show how the addition of either MMD or\nadversarial training greatly improves the performance of the classifier on the\ntarget domain when compared to conventional machine learning algorithms,\nthereby demonstrating great promise for their use in astronomy.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 20:42:32 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 15:48:22 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 23:36:52 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["\u0106iprijanovi\u0107", "A.", ""], ["Kafkes", "D.", ""], ["Jenkins", "S.", ""], ["Downey", "K.", ""], ["Perdue", "G. N.", ""], ["Madireddy", "S.", ""], ["Johnston", "T.", ""], ["Nord", "B.", ""]]}, {"id": "2011.03605", "submitter": "Sameer Kumar", "authors": "Sameer Kumar and Norm Jouppi", "title": "Highly Available Data Parallel ML training on Mesh Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallel ML models can take several days or weeks to train on several\naccelerators. The long duration of training relies on the cluster of resources\nto be available for the job to keep running for the entire duration. On a mesh\nnetwork this is challenging because failures will create holes in the mesh.\nPackets must be routed around the failed chips for full connectivity. In this\npaper, we present techniques to route gradient summation allreduce traffic\naround failed chips on 2-D meshes. We evaluate performance of our fault\ntolerant allreduce techniques via the MLPerf-v0.7 ResNet-50 and BERT\nbenchmarks. Performance results show minimal impact to training throughput on\n512 and 1024 TPU-v3 chips.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 21:36:16 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Kumar", "Sameer", ""], ["Jouppi", "Norm", ""]]}, {"id": "2011.03607", "submitter": "Charlie Dickens", "authors": "Charlie Dickens", "title": "Ridge Regression with Frequent Directions: Statistical and Optimization\n  Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its impressive theory \\& practical performance, Frequent Directions\n(\\acrshort{fd}) has not been widely adopted for large-scale regression tasks.\nPrior work has shown randomized sketches (i) perform worse in estimating the\ncovariance matrix of the data than \\acrshort{fd}; (ii) incur high error when\nestimating the bias and/or variance on sketched ridge regression. We give the\nfirst constant factor relative error bounds on the bias \\& variance for\nsketched ridge regression using \\acrshort{fd}. We complement these statistical\nresults by showing that \\acrshort{fd} can be used in the optimization setting\nthrough an iterative scheme which yields high-accuracy solutions. This improves\non randomized approaches which need to compromise the need for a new sketch\nevery iteration with speed of convergence. In both settings, we also show using\n\\emph{Robust Frequent Directions} further enhances performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 21:40:38 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Dickens", "Charlie", ""]]}, {"id": "2011.03610", "submitter": "Chandler Squires", "authors": "Chandler Squires, Joshua Amaniampong, Caroline Uhler", "title": "Efficient Permutation Discovery in Causal DAGs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of learning a directed acyclic graph (DAG) up to Markov\nequivalence is equivalent to the problem of finding a permutation of the\nvariables that induces the sparsest graph. Without additional assumptions, this\ntask is known to be NP-hard. Building on the minimum degree algorithm for\nsparse Cholesky decomposition, but utilizing DAG-specific problem structure, we\nintroduce an efficient algorithm for finding such sparse permutations. We show\nthat on jointly Gaussian distributions, our method with depth $w$ runs in\n$O(p^{w+3})$ time. We compare our method with $w = 1$ to algorithms for finding\nsparse elimination orderings of undirected graphs, and show that taking\nadvantage of DAG-specific problem structure leads to a significant improvement\nin the discovered permutation. We also compare our algorithm to provably\nconsistent causal structure learning algorithms, such as the PC algorithm, GES,\nand GSP, and show that our method achieves comparable performance with a\nshorter runtime. Thus, our method can be used on its own for causal structure\ndiscovery. Finally, we show that there exist dense graphs on which our method\nachieves almost perfect performance, so that unlike most existing causal\nstructure learning algorithms, the situations in which our algorithm achieves\nboth good performance and good runtime are not limited to sparse graphs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 21:56:41 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Squires", "Chandler", ""], ["Amaniampong", "Joshua", ""], ["Uhler", "Caroline", ""]]}, {"id": "2011.03615", "submitter": "Ekram Hossain", "authors": "Amal Feriani and Ekram Hossain", "title": "Single and Multi-Agent Deep Reinforcement Learning for AI-Enabled\n  Wireless Networks: A Tutorial", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has recently witnessed significant advances\nthat have led to multiple successes in solving sequential decision-making\nproblems in various domains, particularly in wireless communications. The\nfuture sixth-generation (6G) networks are expected to provide scalable,\nlow-latency, ultra-reliable services empowered by the application of\ndata-driven Artificial Intelligence (AI). The key enabling technologies of\nfuture 6G networks, such as intelligent meta-surfaces, aerial networks, and AI\nat the edge, involve more than one agent which motivates the importance of\nmulti-agent learning techniques. Furthermore, cooperation is central to\nestablishing self-organizing, self-sustaining, and decentralized networks. In\nthis context, this tutorial focuses on the role of DRL with an emphasis on deep\nMulti-Agent Reinforcement Learning (MARL) for AI-enabled 6G networks. The first\npart of this paper will present a clear overview of the mathematical frameworks\nfor single-agent RL and MARL. The main idea of this work is to motivate the\napplication of RL beyond the model-free perspective which was extensively\nadopted in recent years. Thus, we provide a selective description of RL\nalgorithms such as Model-Based RL (MBRL) and cooperative MARL and we highlight\ntheir potential applications in 6G wireless networks. Finally, we overview the\nstate-of-the-art of MARL in fields such as Mobile Edge Computing (MEC),\nUnmanned Aerial Vehicles (UAV) networks, and cell-free massive MIMO, and\nidentify promising future research directions. We expect this tutorial to\nstimulate more research endeavors to build scalable and decentralized systems\nbased on MARL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 22:12:40 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Feriani", "Amal", ""], ["Hossain", "Ekram", ""]]}, {"id": "2011.03622", "submitter": "Allen Liu", "authors": "Allen Liu, Ankur Moitra", "title": "Settling the Robust Learnability of Mixtures of Gaussians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work represents a natural coalescence of two important lines of work:\nlearning mixtures of Gaussians and algorithmic robust statistics. In particular\nwe give the first provably robust algorithm for learning mixtures of any\nconstant number of Gaussians. We require only mild assumptions on the mixing\nweights (bounded fractionality) and that the total variation distance between\ncomponents is bounded away from zero. At the heart of our algorithm is a new\nmethod for proving dimension-independent polynomial identifiability through\napplying a carefully chosen sequence of differential operations to certain\ngenerating functions that not only encode the parameters we would like to learn\nbut also the system of polynomial equations we would like to solve. We show how\nthe symbolic identities we derive can be directly used to analyze a natural\nsum-of-squares relaxation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 22:36:00 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 17:49:01 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 20:46:03 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Allen", ""], ["Moitra", "Ankur", ""]]}, {"id": "2011.03623", "submitter": "Ian Covert", "authors": "Ian Covert, Scott Lundberg, Su-In Lee", "title": "Feature Removal Is a Unifying Principle for Model Explanation Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have proposed a wide variety of model explanation approaches, but\nit remains unclear how most methods are related or when one method is\npreferable to another. We examine the literature and find that many methods are\nbased on a shared principle of explaining by removing - essentially, measuring\nthe impact of removing sets of features from a model. These methods vary in\nseveral respects, so we develop a framework for removal-based explanations that\ncharacterizes each method along three dimensions: 1) how the method removes\nfeatures, 2) what model behavior the method explains, and 3) how the method\nsummarizes each feature's influence. Our framework unifies 25 existing methods,\nincluding several of the most widely used approaches (SHAP, LIME, Meaningful\nPerturbations, permutation tests). Exposing the fundamental similarities\nbetween these methods empowers users to reason about which tools to use and\nsuggests promising directions for ongoing research in model explainability.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 22:37:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Covert", "Ian", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "2011.03628", "submitter": "Mert Nakip", "authors": "Mert Nak{\\i}p, Onur \\c{C}opur, C\\\"uneyt G\\\"uzeli\\c{s}", "title": "Curse of Small Sample Size in Forecasting of the Active Cases in\n  COVID-19 Outbreak", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 pandemic, a massive number of attempts on the predictions\nof the number of cases and the other future trends of this pandemic have been\nmade. However, they fail to predict, in a reliable way, the medium and long\nterm evolution of fundamental features of COVID-19 outbreak within acceptable\naccuracy. This paper gives an explanation for the failure of machine learning\nmodels in this particular forecasting problem. The paper shows that simple\nlinear regression models provide high prediction accuracy values reliably but\nonly for a 2-weeks period and that relatively complex machine learning models,\nwhich have the potential of learning long term predictions with low errors,\ncannot achieve to obtain good predictions with possessing a high generalization\nability. It is suggested in the paper that the lack of a sufficient number of\nsamples is the source of low prediction performance of the forecasting models.\nThe reliability of the forecasting results about the active cases is measured\nin terms of the cross-validation prediction errors, which are used as\nexpectations for the generalization errors of the forecasters. To exploit the\ninformation, which is of most relevant with the active cases, we perform\nfeature selection over a variety of variables. We apply different feature\nselection methods, namely the Pairwise Correlation, Recursive Feature\nSelection, and feature selection by using the Lasso regression and compare them\nto each other and also with the models not employing any feature selection.\nFurthermore, we compare Linear Regression, Multi-Layer Perceptron, and\nLong-Short Term Memory models each of which is used for prediction active cases\ntogether with the mentioned feature selection methods. Our results show that\nthe accurate forecasting of the active cases with high generalization ability\nis possible up to 3 days only because of the small sample size of COVID-19\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 23:13:34 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 09:23:51 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Nak\u0131p", "Mert", ""], ["\u00c7opur", "Onur", ""], ["G\u00fczeli\u015f", "C\u00fcneyt", ""]]}, {"id": "2011.03639", "submitter": "Hunter Lang", "authors": "Hunter Lang, David Sontag, Aravindan Vijayaraghavan", "title": "Graph cuts always find a global optimum for Potts models (with a catch)", "comments": "Published at ICML 2021. 18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the $\\alpha$-expansion algorithm for MAP inference always\nreturns a globally optimal assignment for Markov Random Fields with Potts\npairwise potentials, with a catch: the returned assignment is only guaranteed\nto be optimal for an instance within a small perturbation of the original\nproblem instance. In other words, all local minima with respect to expansion\nmoves are global minima to slightly perturbed versions of the problem. On\n\"real-world\" instances, MAP assignments of small perturbations of the problem\nshould be very similar to the MAP assignment(s) of the original problem\ninstance. We design an algorithm that can certify whether this is the case in\npractice. On several MAP inference problem instances from computer vision, this\nalgorithm certifies that MAP solutions to all of these perturbations are very\nclose to solutions of the original instance. These results taken together give\na cohesive explanation for the good performance of \"graph cuts\" algorithms in\npractice. Every local expansion minimum is a global minimum in a small\nperturbation of the problem, and all of these global minima are close to the\noriginal solution.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:01:06 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 01:33:06 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Lang", "Hunter", ""], ["Sontag", "David", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "2011.03641", "submitter": "Sameer Kumar", "authors": "Sameer Kumar and James Bradbury and Cliff Young and Yu Emma Wang and\n  Anselm Levskaya and Blake Hechtman and Dehao Chen and HyoukJoong Lee and\n  Mehmet Deveci and Naveen Kumar and Pankaj Kanwar and Shibo Wang and Skye\n  Wanderman-Milne and Steve Lacy and Tao Wang and Tayo Oguntebi and Yazhou Zu\n  and Yuanzhong Xu and Andy Swing", "title": "Exploring the limits of Concurrency in ML Training on Google TPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in language understanding using neural networks have required\ntraining hardware of unprecedentedscale, with thousands of chips cooperating on\na single training run. This paper presents techniques to scaleML models on the\nGoogle TPU Multipod, a mesh with 4096 TPU-v3 chips. We discuss model\nparallelism toovercome scaling limitations from the fixed batch size in data\nparallelism, communication/collective optimizations,distributed evaluation of\ntraining metrics, and host input processing scaling optimizations. These\ntechniques aredemonstrated in both the TensorFlow and JAX programming\nframeworks. We also present performance resultsfrom the recent Google\nsubmission to the MLPerf-v0.7 benchmark contest, achieving record training\ntimes from16 to 28 seconds in four MLPerf models on the Google TPU-v3 Multipod\nmachine.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:18:43 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 02:42:48 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 19:33:30 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Kumar", "Sameer", ""], ["Bradbury", "James", ""], ["Young", "Cliff", ""], ["Wang", "Yu Emma", ""], ["Levskaya", "Anselm", ""], ["Hechtman", "Blake", ""], ["Chen", "Dehao", ""], ["Lee", "HyoukJoong", ""], ["Deveci", "Mehmet", ""], ["Kumar", "Naveen", ""], ["Kanwar", "Pankaj", ""], ["Wang", "Shibo", ""], ["Wanderman-Milne", "Skye", ""], ["Lacy", "Steve", ""], ["Wang", "Tao", ""], ["Oguntebi", "Tayo", ""], ["Zu", "Yazhou", ""], ["Xu", "Yuanzhong", ""], ["Swing", "Andy", ""]]}, {"id": "2011.03647", "submitter": "Ricardo Gama", "authors": "Ricardo Gama and Hugo L. Fernandes", "title": "A Reinforcement Learning Approach to the Orienteering Problem with Time\n  Windows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Orienteering Problem with Time Windows (OPTW) is a combinatorial\noptimization problem where the goal is to maximize the total score collected\nfrom different visited locations. The application of neural network models to\ncombinatorial optimization has recently shown promising results in dealing with\nsimilar problems, like the Travelling Salesman Problem. A neural network allows\nlearning solutions using reinforcement learning or supervised learning,\ndepending on the available data. After the learning stage, it can be\ngeneralized and quickly fine-tuned to further improve performance and\npersonalization. The advantages are evident since, for real-world applications,\nsolution quality, personalization, and execution times are all important\nfactors that should be taken into account.\n  This study explores the use of Pointer Network models trained using\nreinforcement learning to solve the OPTW problem. We propose a modified\narchitecture that leverages Pointer Networks to better address problems related\nwith dynamic time-dependent constraints. Among its various applications, the\nOPTW can be used to model the Tourist Trip Design Problem (TTDP). We train the\nPointer Network with the TTDP problem in mind, by sampling variables that can\nchange across tourists visiting a particular instance-region: starting\nposition, starting time, available time, and the scores given to each point of\ninterest. Once a model-region is trained, it can infer a solution for a\nparticular tourist using beam search. We based the assessment of our approach\non several existing benchmark OPTW instances. We show that it generalizes\nacross different tourists that visit each region and that it generally\noutperforms the most commonly used heuristic, while computing the solution in\nrealistic times.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:38:06 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 18:37:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gama", "Ricardo", ""], ["Fernandes", "Hugo L.", ""]]}, {"id": "2011.03649", "submitter": "Shashikant Ilager Mr", "authors": "Shashikant Ilager, Kotagiri Ramamohanarao, Rajkumar Buyya", "title": "Thermal Prediction for Efficient Energy Management of Clouds using\n  Machine Learning", "comments": "Under submission at IEEE Transactions on Parallel and Distributed\n  Systems (TPDS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermal management in the hyper-scale cloud data centers is a critical\nproblem. Increased host temperature creates hotspots which significantly\nincreases cooling cost and affects reliability. Accurate prediction of host\ntemperature is crucial for managing the resources effectively. Temperature\nestimation is a non-trivial problem due to thermal variations in the data\ncenter. Existing solutions for temperature estimation are inefficient due to\ntheir computational complexity and lack of accurate prediction. However,\ndata-driven machine learning methods for temperature prediction is a promising\napproach. In this regard, we collect and study data from a private cloud and\nshow the presence of thermal variations. We investigate several machine\nlearning models to accurately predict the host temperature. Specifically, we\npropose a gradient boosting machine learning model for temperature prediction.\nThe experiment results show that our model accurately predicts the temperature\nwith the average RMSE value of 0.05 or an average prediction error of 2.38\ndegree Celsius, which is 6 degree Celsius less as compared to an existing\ntheoretical model. In addition, we propose a dynamic scheduling algorithm to\nminimize the peak temperature of hosts. The results show that our algorithm\nreduces the peak temperature by 6.5 degree Celsius and consumes 34.5% less\nenergy as compared to the baseline algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 00:55:47 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 03:57:01 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 01:14:59 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Ilager", "Shashikant", ""], ["Ramamohanarao", "Kotagiri", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "2011.03654", "submitter": "Jessica Dai", "authors": "Jessica Dai, Sina Fazelpour, Zachary C. Lipton", "title": "Fair Machine Learning Under Partial Compliance", "comments": "Presented at AIES 2021. Previously at the NeurIPS 2020 Workshop on\n  Consequential Decision Making in Dynamic Environments and the NeurIPS 2020\n  Workshop on ML for Economic Policy", "journal-ref": null, "doi": "10.1145/3461702.3462521", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, fair machine learning research focuses on a single decisionmaker\nand assumes that the underlying population is stationary. However, many of the\ncritical domains motivating this work are characterized by competitive\nmarketplaces with many decisionmakers. Realistically, we might expect only a\nsubset of them to adopt any non-compulsory fairness-conscious policy, a\nsituation that political philosophers call partial compliance. This possibility\nraises important questions: how does the strategic behavior of decision\nsubjects in partial compliance settings affect the allocation outcomes? If k%\nof employers were to voluntarily adopt a fairness-promoting intervention,\nshould we expect k% progress (in aggregate) towards the benefits of universal\nadoption, or will the dynamics of partial compliance wash out the hoped-for\nbenefits? How might adopting a global (versus local) perspective impact the\nconclusions of an auditor? In this paper, we propose a simple model of an\nemployment market, leveraging simulation as a tool to explore the impact of\nboth interaction effects and incentive effects on outcomes and auditing\nmetrics. Our key findings are that at equilibrium: (1) partial compliance (k%\nof employers) can result in far less than proportional (k%) progress towards\nthe full compliance outcomes; (2) the gap is more severe when fair employers\nmatch global (vs local) statistics; (3) choices of local vs global statistics\ncan paint dramatically different pictures of the performance vis-a-vis fairness\ndesiderata of compliant versus non-compliant employers; and (4) partial\ncompliance to local parity measures can induce extreme segregation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 01:46:53 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 06:55:54 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 17:17:16 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Dai", "Jessica", ""], ["Fazelpour", "Sina", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2011.03667", "submitter": "Yunhao Yang", "authors": "Yunhao Yang, Andrew Whinston", "title": "Identifying Mislabeled Images in Supervised Learning Utilizing\n  Autoencoder", "comments": "UTCS Tech Report: Honors Thesis. 12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning is based on the assumption that the ground truth in the\ntraining data is accurate. However, this may not be guaranteed in real-world\nsettings. Inaccurate training data will result in some unexpected predictions.\nIn image classification, incorrect labels may cause the classification model to\nbe inaccurate as well. In this paper, I am going to apply unsupervised\ntechniques to the training data before training the classification network. A\nconvolutional autoencoder is applied to encode and reconstruct images. The\nencoder will project the image data on to latent space. In the latent space,\nimage features are preserved in a lower dimension. The assumption is that data\nsamples with similar features are likely to have the same label. Noised samples\ncan be classified in the latent space by the Density-Base Scan (DBSCAN)\nclustering algorithm. These incorrectly labeled data are visualized as outliers\nin the latent space. Therefore, the outliers identified by the DBSCAN algorithm\ncan be classified as incorrectly labeled samples. After the outliers are\ndetected, all the outliers are treated as mislabeled data samples and removed\nfrom the dataset. Thus the training data can be directly used in training the\nsupervised learning network. The algorithm can detect and remove above 67\\% of\nmislabeled data in the experimental dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 03:09:34 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 22:59:44 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Yang", "Yunhao", ""], ["Whinston", "Andrew", ""]]}, {"id": "2011.03683", "submitter": "Shenghua He", "authors": "Shenghua He, Kyaw Thu Minn, Lilianna Solnica-Krezel, Mark A. Anastasio\n  and Hua Li", "title": "Deeply-Supervised Density Regression for Automatic Cell Counting in\n  Microscopy Images", "comments": "Medical Image Analysis 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately counting the number of cells in microscopy images is required in\nmany medical diagnosis and biological studies. This task is tedious,\ntime-consuming, and prone to subjective errors. However, designing automatic\ncounting methods remains challenging due to low image contrast, complex\nbackground, large variance in cell shapes and counts, and significant cell\nocclusions in two-dimensional microscopy images. In this study, we proposed a\nnew density regression-based method for automatically counting cells in\nmicroscopy images. The proposed method processes two innovations compared to\nother state-of-the-art density regression-based methods. First, the density\nregression model (DRM) is designed as a concatenated fully convolutional\nregression network (C-FCRN) to employ multi-scale image features for the\nestimation of cell density maps from given images. Second, auxiliary\nconvolutional neural networks (AuxCNNs) are employed to assist in the training\nof intermediate layers of the designed C-FCRN to improve the DRM performance on\nunseen datasets. Experimental studies evaluated on four datasets demonstrate\nthe superior performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 04:02:47 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 01:57:30 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["He", "Shenghua", ""], ["Minn", "Kyaw Thu", ""], ["Solnica-Krezel", "Lilianna", ""], ["Anastasio", "Mark A.", ""], ["Li", "Hua", ""]]}, {"id": "2011.03687", "submitter": "Jiaheng Wei", "authors": "Jiaheng Wei, Yang Liu", "title": "When Optimizing $f$-divergence is Robust with Label Noise", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show when maximizing a properly defined $f$-divergence measure with\nrespect to a classifier's predictions and the supervised labels is robust with\nlabel noise. Leveraging its variational form, we derive a nice decoupling\nproperty for a family of $f$-divergence measures when label noise presents,\nwhere the divergence is shown to be a linear combination of the variational\ndifference defined on the clean distribution and a bias term introduced due to\nthe noise. The above derivation helps us analyze the robustness of different\n$f$-divergence functions. With established robustness, this family of\n$f$-divergence functions arises as useful metrics for the problem of learning\nwith noisy labels, which do not require the specification of the labels' noise\nrate. When they are possibly not robust, we propose fixes to make them so. In\naddition to the analytical results, we present thorough experimental evidence.\nOur code is available at\nhttps://github.com/UCSC-REAL/Robust-f-divergence-measures.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 04:31:33 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 07:32:28 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Wei", "Jiaheng", ""], ["Liu", "Yang", ""]]}, {"id": "2011.03715", "submitter": "Marzieh Ajirak", "authors": "Marzieh Ajirak, Cassandra Heiselman, Anna Fuchs, Mia Heiligenstein,\n  Kimberly Herrera, Diana Garretto, Petar Djuric", "title": "GP-LVM of categorical data from test-positive COVID-19 pregnant women", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel coronavirus disease 2019 (COVID-19) is rapidly spreading throughout the\nworld and while pregnant women present the same adverse outcome rates, they are\nunderrepresented in clinical research. In this paper, we model categorical\nvariables of 89 test-positive COVID-19 pregnant women within the unsupervised\nBayesian framework. We model the data using latent Gaussian processes for\ndensity estimation of multivariate categorical data. The results show that the\nmodel can find latent patterns in the data, which in turn could provide\nadditional insights into the study of pregnant women that are COVID-19\npositive.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 07:11:29 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ajirak", "Marzieh", ""], ["Heiselman", "Cassandra", ""], ["Fuchs", "Anna", ""], ["Heiligenstein", "Mia", ""], ["Herrera", "Kimberly", ""], ["Garretto", "Diana", ""], ["Djuric", "Petar", ""]]}, {"id": "2011.03722", "submitter": "Md Faisal Mahbub Chowdhury", "authors": "Abhijit Mishra, Md Faisal Mahbub Chowdhury, Sagar Manohar, Dan\n  Gutfreund and Karthik Sankaranarayanan", "title": "Template Controllable keywords-to-text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel neural model for the understudied task of\ngenerating text from keywords. The model takes as input a set of un-ordered\nkeywords, and part-of-speech (POS) based template instructions. This makes it\nideal for surface realization in any NLG setup. The framework is based on the\nencode-attend-decode paradigm, where keywords and templates are encoded first,\nand the decoder judiciously attends over the contexts derived from the encoded\nkeywords and templates to generate the sentences. Training exploits weak\nsupervision, as the model trains on a large amount of labeled data with\nkeywords and POS based templates prepared through completely automatic means.\nQualitative and quantitative performance analyses on publicly available\ntest-data in various domains reveal our system's superiority over baselines,\nbuilt using state-of-the-art neural machine translation and controllable\ntransfer techniques. Our approach is indifferent to the order of input\nkeywords.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 08:05:58 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Mishra", "Abhijit", ""], ["Chowdhury", "Md Faisal Mahbub", ""], ["Manohar", "Sagar", ""], ["Gutfreund", "Dan", ""], ["Sankaranarayanan", "Karthik", ""]]}, {"id": "2011.03729", "submitter": "Aashi Jindal", "authors": "Aashi Jindal, Prashant Gupta, Debarka Sengupta and Jayadeva", "title": "Enhash: A Fast Streaming Algorithm For Concept Drift Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose Enhash, a fast ensemble learner that detects \\textit{concept\ndrift} in a data stream. A stream may consist of abrupt, gradual, virtual, or\nrecurring events, or a mixture of various types of drift. Enhash employs\nprojection hash to insert an incoming sample. We show empirically that the\nproposed method has competitive performance to existing ensemble learners in\nmuch lesser time. Also, Enhash has moderate resource requirements. Experiments\nrelevant to performance comparison were performed on 6 artificial and 4 real\ndata sets consisting of various types of drifts.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:07:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jindal", "Aashi", ""], ["Gupta", "Prashant", ""], ["Sengupta", "Debarka", ""], ["Jayadeva", "", ""]]}, {"id": "2011.03731", "submitter": "Hongyan Chang", "authors": "Hongyan Chang, Reza Shokri", "title": "On the Privacy Risks of Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness and privacy are essential pillars of trustworthy machine\nlearning. Fair machine learning aims at minimizing discrimination against\nprotected groups by, for example, imposing a constraint on models to equalize\ntheir behavior across different groups. This can subsequently change the\ninfluence of training data points on the fair model, in a disproportionate way.\nWe study how this can change the information leakage of the model about its\ntraining data. We analyze the privacy risks of group fairness (e.g., equalized\nodds) through the lens of membership inference attacks: inferring whether a\ndata point is used for training a model. We show that fairness comes at the\ncost of privacy, and this cost is not distributed equally: the information\nleakage of fair models increases significantly on the unprivileged subgroups,\nwhich are the ones for whom we need fair learning. We show that the more biased\nthe training data is, the higher the privacy cost of achieving fairness for the\nunprivileged subgroups will be. We provide comprehensive empirical analysis for\ngeneral machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:15:31 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 01:45:56 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 08:36:27 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 05:43:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Chang", "Hongyan", ""], ["Shokri", "Reza", ""]]}, {"id": "2011.03733", "submitter": "Hwiyeol Jo", "authors": "Jaeseo Lim, Hwiyeol Jo, Byoung-Tak Zhang, Jooyong Park", "title": "Human-Like Active Learning: Machines Simulating the Human Learning\n  Process", "comments": "NeurIPS 2020 Workshop on BabyMind", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the use of active learning to increase learners' engagement has\nrecently been introduced in a variety of methods, empirical experiments are\nlacking. In this study, we attempted to align two experiments in order to (1)\nmake a hypothesis for machine and (2) empirically confirm the effect of active\nlearning on learning. In Experiment 1, we compared the effect of a passive form\nof learning to active form of learning. The results showed that active learning\nhad a greater learning outcomes than passive learning. In the machine\nexperiment based on the human result, we imitated the human active learning as\na form of knowledge distillation. The active learning framework performed\nbetter than the passive learning framework. In the end, we showed not only that\nwe can make build better machine training framework through the human\nexperiment result, but also empirically confirm the result of human experiment\nthrough imitated machine experiments; human-like active learning have crucial\neffect on learning performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:32:49 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Lim", "Jaeseo", ""], ["Jo", "Hwiyeol", ""], ["Zhang", "Byoung-Tak", ""], ["Park", "Jooyong", ""]]}, {"id": "2011.03737", "submitter": "Jun Wen", "authors": "Jun Wen, Changjian Shui, Kun Kuang, Junsong Yuan, Zenan Huang, Zhefeng\n  Gong, Nenggan Zheng", "title": "Interventional Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) aims to transfer discriminative features learned from\nsource domain to target domain. Most of DA methods focus on enhancing feature\ntransferability through domain-invariance learning. However, source-learned\ndiscriminability itself might be tailored to be biased and unsafely\ntransferable by spurious correlations, \\emph{i.e.}, part of source-specific\nfeatures are correlated with category labels. We find that standard\ndomain-invariance learning suffers from such correlations and incorrectly\ntransfers the source-specifics. To address this issue, we intervene in the\nlearning of feature discriminability using unlabeled target data to guide it to\nget rid of the domain-specific part and be safely transferable. Concretely, we\ngenerate counterfactual features that distinguish the domain-specifics from\ndomain-sharable part through a novel feature intervention strategy. To prevent\nthe residence of domain-specifics, the feature discriminability is trained to\nbe invariant to the mutations in the domain-specifics of counterfactual\nfeatures. Experimenting on typical \\emph{one-to-one} unsupervised domain\nadaptation and challenging domain-agnostic adaptation tasks, the consistent\nperformance improvements of our method over state-of-the-art approaches\nvalidate that the learned discriminative features are more safely transferable\nand generalize well to novel domains.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:53:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wen", "Jun", ""], ["Shui", "Changjian", ""], ["Kuang", "Kun", ""], ["Yuan", "Junsong", ""], ["Huang", "Zenan", ""], ["Gong", "Zhefeng", ""], ["Zheng", "Nenggan", ""]]}, {"id": "2011.03749", "submitter": "Pengchao Han", "authors": "Pengchao Han, Jihong Park, Shiqiang Wang, Yejun Liu", "title": "Robustness and Diversity Seeking Data-Free Knowledge Distillation", "comments": "Accepted in IEEE ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) has enabled remarkable progress in model\ncompression and knowledge transfer. However, KD requires a large volume of\noriginal data or their representation statistics that are not usually available\nin practice. Data-free KD has recently been proposed to resolve this problem,\nwherein teacher and student models are fed by a synthetic sample generator\ntrained from the teacher. Nonetheless, existing data-free KD methods rely on\nfine-tuning of weights to balance multiple losses, and ignore the diversity of\ngenerated samples, resulting in limited accuracy and robustness. To overcome\nthis challenge, we propose robustness and diversity seeking data-free KD\n(RDSKD) in this paper. The generator loss function is crafted to produce\nsamples with high authenticity, class diversity, and inter-sample diversity.\nWithout real data, the objectives of seeking high sample authenticity and class\ndiversity often conflict with each other, causing frequent loss fluctuations.\nWe mitigate this by exponentially penalizing loss increments. With MNIST,\nCIFAR-10, and SVHN datasets, our experiments show that RDSKD achieves higher\naccuracy with more robustness over different hyperparameter settings, compared\nto other data-free KD methods such as DAFL, MSKD, ZSKD, and DeepInversion.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 10:57:53 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 03:45:51 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 09:47:13 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Han", "Pengchao", ""], ["Park", "Jihong", ""], ["Wang", "Shiqiang", ""], ["Liu", "Yejun", ""]]}, {"id": "2011.03772", "submitter": "Liangzhi Li", "authors": "Liangzhi Li, Manisha Verma, Bowen Wang, Yuta Nakashima, Ryo Kawasaki,\n  Hajime Nagahara", "title": "Grading the Severity of Arteriolosclerosis from Retinal Arterio-venous\n  Crossing Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The status of retinal arteriovenous crossing is of great significance for\nclinical evaluation of arteriolosclerosis and systemic hypertension. As an\nophthalmology diagnostic criteria, Scheie's classification has been used to\ngrade the severity of arteriolosclerosis. In this paper, we propose a deep\nlearning approach to support the diagnosis process, which, to the best of our\nknowledge, is one of the earliest attempts in medical imaging. The proposed\npipeline is three-fold. First, we adopt segmentation and classification models\nto automatically obtain vessels in a retinal image with the corresponding\nartery/vein labels and find candidate arteriovenous crossing points. Second, we\nuse a classification model to validate the true crossing point. At last, the\ngrade of severity for the vessel crossings is classified. To better address the\nproblem of label ambiguity and imbalanced label distribution, we propose a new\nmodel, named multi-diagnosis team network (MDTNet), in which the sub-models\nwith different structures or different loss functions provide different\ndecisions. MDTNet unifies these diverse theories to give the final decision\nwith high accuracy. Our severity grading method was able to validate crossing\npoints with precision and recall of 96.3% and 96.3%, respectively. Among\ncorrectly detected crossing points, the kappa value for the agreement between\nthe grading by a retina specialist and the estimated score was 0.85, with an\naccuracy of 0.92. The numerical results demonstrate that our method can achieve\na good performance in both arteriovenous crossing validation and severity\ngrading tasks. By the proposed models, we could build a pipeline reproducing\nretina specialist's subjective grading without feature extractions. The code is\navailable for reproducibility.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 13:15:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Li", "Liangzhi", ""], ["Verma", "Manisha", ""], ["Wang", "Bowen", ""], ["Nakashima", "Yuta", ""], ["Kawasaki", "Ryo", ""], ["Nagahara", "Hajime", ""]]}, {"id": "2011.03813", "submitter": "Yiyuan Lee", "authors": "Yiyuan Lee, Panpan Cai, David Hsu", "title": "MAGIC: Learning Macro-Actions for Online POMDP Planning", "comments": "9 pages (+ 2 page references, + 2 page appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partially observable Markov decision process (POMDP) is a principled\ngeneral framework for robot decision making under uncertainty, but POMDP\nplanning suffers from high computational complexity, when long-term planning is\nrequired. While temporally-extended macro-actions help to cut down the\neffective planning horizon and significantly improve computational efficiency,\nhow do we acquire good macro-actions? This paper proposes Macro-Action\nGenerator-Critic (MAGIC), which performs offline learning of macro-actions\noptimized for online POMDP planning. Specifically, MAGIC learns a macro-action\ngenerator end-to-end, using an online planner's performance as the feedback.\nDuring online planning, the generator generates on the fly situation-aware\nmacro-actions conditioned on the robot's belief and the environment context. We\nevaluated MAGIC on several long-horizon planning tasks both in simulation and\non a real robot. The experimental results show that the learned macro-actions\noffer significant benefits in online planning performance, compared with\nprimitive actions and handcrafted macro-actions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 17:18:45 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 12:45:54 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 16:20:56 GMT"}, {"version": "v4", "created": "Thu, 1 Jul 2021 06:04:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lee", "Yiyuan", ""], ["Cai", "Panpan", ""], ["Hsu", "David", ""]]}, {"id": "2011.03842", "submitter": "Brosnan Yuen", "authors": "Brosnan Yuen, Minh Tu Hoang, Xiaodai Dong, and Tao Lu", "title": "Universal Activation Function For Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a Universal Activation Function (UAF) that achieves\nnear optimal performance in quantification, classification, and reinforcement\nlearning (RL) problems. For any given problem, the optimization algorithms are\nable to evolve the UAF to a suitable activation function by tuning the UAF's\nparameters. For the CIFAR-10 classification and VGG-8, the UAF converges to the\nMish like activation function, which has near optimal performance $F_{1} =\n0.9017\\pm0.0040$ when compared to other activation functions. For the\nquantification of simulated 9-gas mixtures in 30 dB signal-to-noise ratio (SNR)\nenvironments, the UAF converges to the identity function, which has near\noptimal root mean square error of $0.4888 \\pm 0.0032$ $\\mu M$. In the\nBipedalWalker-v2 RL dataset, the UAF achieves the 250 reward in $961 \\pm 193$\nepochs, which proves that the UAF converges in the lowest number of epochs.\nFurthermore, the UAF converges to a new activation function in the\nBipedalWalker-v2 RL dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 20:13:31 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Yuen", "Brosnan", ""], ["Hoang", "Minh Tu", ""], ["Dong", "Xiaodai", ""], ["Lu", "Tao", ""]]}, {"id": "2011.03847", "submitter": "Long Nguyen", "authors": "Hoang Long Nguyen, Zhenhe Pan, Hashim Abu-gellban, Fang Jin, Yuanlin\n  Zhang", "title": "Google Trends Analysis of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The World Health Organization (WHO) announced that COVID-19 was a pandemic\ndisease on the 11th of March as there were 118K cases in several countries and\nterritories. Numerous researchers worked on forecasting the number of confirmed\ncases since anticipating the growth of the cases helps governments adopting\nknotty decisions to ease the lockdowns orders for their countries. These orders\nhelp several people who have lost their jobs and support gravely impacted\nbusinesses. Our research aims to investigate the relation between Google search\ntrends and the spreading of the novel coronavirus (COVID-19) over countries\nworldwide, to predict the number of cases. We perform a correlation analysis on\nthe keywords of the related Google search trends according to the number of\nconfirmed cases reported by the WHO. After that, we applied several machine\nlearning techniques (Multiple Linear Regression, Non-negative Integer\nRegression, Deep Neural Network), to forecast the number of confirmed cases\nglobally based on historical data as well as the hybrid data (Google search\ntrends). Our results show that Google search trends are highly associated with\nthe number of reported confirmed cases, where the Deep Learning approach\noutperforms other forecasting techniques. We believe that it is not only a\npromising approach for forecasting the confirmed cases of COVID-19, but also\nfor similar forecasting problems that are associated with the related Google\ntrends.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 20:55:19 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Nguyen", "Hoang Long", ""], ["Pan", "Zhenhe", ""], ["Abu-gellban", "Hashim", ""], ["Jin", "Fang", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "2011.03853", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "A fast randomized incremental gradient method for decentralized\n  non-convex optimization", "comments": "Added more numerical experiments, expanded discussion on technical\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study decentralized non-convex finite-sum minimization problems described\nover a network of nodes, where each node possesses a local batch of data\nsamples. In this context, we analyze a single-timescale randomized incremental\ngradient method, called GT-SAGA. GT-SAGA is computationally efficient as it\nevaluates one component gradient per node per iteration and achieves provably\nfast and robust performance by leveraging node-level variance reduction and\nnetwork-level gradient tracking. For general smooth non-convex problems, we\nshow the almost sure and mean-squared convergence of GT-SAGA to a first-order\nstationary point and further describe regimes of practical significance where\nit outperforms the existing approaches and achieves a network\ntopology-independent iteration complexity respectively. When the global\nfunction satisfies the Polyak-Lojaciewisz condition, we show that GT-SAGA\nexhibits linear convergence to an optimal solution in expectation and describe\nregimes of practical interest where the performance is network\ntopology-independent and improves upon the existing methods. Numerical\nexperiments are included to highlight the main convergence aspects of GT-SAGA\nin non-convex settings.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 21:30:42 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 16:48:23 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2011.03854", "submitter": "Leslie O'Bray", "authors": "Karsten Borgwardt, Elisabetta Ghisu, Felipe Llinares-L\\'opez, Leslie\n  O'Bray, Bastian Rieck", "title": "Graph Kernels: State-of-the-Art and Future Challenges", "comments": "Accepted by Foundations and Trends in Machine Learning, 2020", "journal-ref": null, "doi": "10.1561/2200000076", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data are an integral part of many application domains,\nincluding chemoinformatics, computational biology, neuroimaging, and social\nnetwork analysis. Over the last two decades, numerous graph kernels, i.e.\nkernel functions between graphs, have been proposed to solve the problem of\nassessing the similarity between graphs, thereby making it possible to perform\npredictions in both classification and regression settings. This manuscript\nprovides a review of existing graph kernels, their applications, software plus\ndata resources, and an empirical comparison of state-of-the-art graph kernels.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 21:44:53 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 11:48:53 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Borgwardt", "Karsten", ""], ["Ghisu", "Elisabetta", ""], ["Llinares-L\u00f3pez", "Felipe", ""], ["O'Bray", "Leslie", ""], ["Rieck", "Bastian", ""]]}, {"id": "2011.03856", "submitter": "Christopher Clark", "authors": "Christopher Clark, Mark Yatskar, and Luke Zettlemoyer", "title": "Learning to Model and Ignore Dataset Bias with Mixed Capacity Ensembles", "comments": "In EMNLP Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many datasets have been shown to contain incidental correlations created by\nidiosyncrasies in the data collection process. For example, sentence entailment\ndatasets can have spurious word-class correlations if nearly all contradiction\nsentences contain the word \"not\", and image recognition datasets can have\ntell-tale object-background correlations if dogs are always indoors. In this\npaper, we propose a method that can automatically detect and ignore these kinds\nof dataset-specific patterns, which we call dataset biases. Our method trains a\nlower capacity model in an ensemble with a higher capacity model. During\ntraining, the lower capacity model learns to capture relatively shallow\ncorrelations, which we hypothesize are likely to reflect dataset bias. This\nfrees the higher capacity model to focus on patterns that should generalize\nbetter. We ensure the models learn non-overlapping approaches by introducing a\nnovel method to make them conditionally independent. Importantly, our approach\ndoes not require the bias to be known in advance. We evaluate performance on\nsynthetic datasets, and four datasets built to penalize models that exploit\nknown biases on textual entailment, visual question answering, and image\nrecognition tasks. We show improvement in all settings, including a 10 point\ngain on the visual question answering dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 22:20:03 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Clark", "Christopher", ""], ["Yatskar", "Mark", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2011.03880", "submitter": "Zijie Huang", "authors": "Zijie Huang, Yizhou Sun, Wei Wang", "title": "Learning Continuous System Dynamics from Irregularly-Sampled Partial\n  Observations", "comments": "Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems, such as moving planets, can be considered as\nmulti-agent dynamic systems, where objects interact with each other and\nco-evolve along with the time. Such dynamics is usually difficult to capture,\nand understanding and predicting the dynamics based on observed trajectories of\nobjects become a critical research problem in many domains. Most existing\nalgorithms, however, assume the observations are regularly sampled and all the\nobjects can be fully observed at each sampling time, which is impractical for\nmany applications. In this paper, we propose to learn system dynamics from\nirregularly-sampled partial observations with underlying graph structure for\nthe first time. To tackle the above challenge, we present LG-ODE, a latent\nordinary differential equation generative model for modeling multi-agent\ndynamic system with known graph structure. It can simultaneously learn the\nembedding of high dimensional trajectories and infer continuous latent system\ndynamics. Our model employs a novel encoder parameterized by a graph neural\nnetwork that can infer initial states in an unsupervised way from\nirregularly-sampled partial observations of structural objects and utilizes\nneuralODE to infer arbitrarily complex continuous-time latent dynamics.\nExperiments on motion capture, spring system, and charged particle datasets\ndemonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 01:02:22 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Huang", "Zijie", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "2011.03885", "submitter": "Shlomi Hod", "authors": "Gavin Brown, Shlomi Hod, Iden Kalemaj", "title": "Performative Prediction in a Stateful World", "comments": "Workshop on Consequential Decision Making in Dynamic Environments,\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployed supervised machine learning models make predictions that interact\nwith and influence the world. This phenomenon is called \"performative\nprediction\" by Perdomo et al. (2020), who investigated it in a stateless\nsetting. We generalize their results to the case where the response of the\npopulation to the deployed classifier depends both on the classifier and the\nprevious distribution of the population. We also demonstrate such a setting\nempirically, for the scenario of strategic manipulation.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 01:27:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Brown", "Gavin", ""], ["Hod", "Shlomi", ""], ["Kalemaj", "Iden", ""]]}, {"id": "2011.03890", "submitter": "Roman Levin", "authors": "Emil Noordeh, Roman Levin, Ruochen Jiang, Harris Shadmany", "title": "Echo Chambers in Collaborative Filtering Based Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems underpin the serving of nearly all online content in\nthe modern age. From Youtube and Netflix recommendations, to Facebook feeds and\nGoogle searches, these systems are designed to filter content to the predicted\npreferences of users. Recently, these systems have faced growing criticism with\nrespect to their impact on content diversity, social polarization, and the\nhealth of public discourse. In this work we simulate the recommendations given\nby collaborative filtering algorithms on users in the MovieLens data set. We\nfind that prolonged exposure to system-generated recommendations substantially\ndecreases content diversity, moving individual users into \"echo-chambers\"\ncharacterized by a narrow range of content. Furthermore, our work suggests that\nonce these echo-chambers have been established, it is difficult for an\nindividual user to break out by manipulating solely their own rating vector.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 02:35:47 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Noordeh", "Emil", ""], ["Levin", "Roman", ""], ["Jiang", "Ruochen", ""], ["Shadmany", "Harris", ""]]}, {"id": "2011.03894", "submitter": "Christoforos Mavrogiannis", "authors": "Junha Roh, Christoforos Mavrogiannis, Rishabh Madan, Dieter Fox,\n  Siddhartha S. Srinivasa", "title": "Multimodal Trajectory Prediction via Topological Invariance for\n  Navigation at Uncontrolled Intersections", "comments": "Preprint of a paper with the same title, accepted to the Conference\n  on Robot Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on decentralized navigation among multiple non-communicating\nrational agents at \\emph{uncontrolled} intersections, i.e., street\nintersections without traffic signs or signals. Avoiding collisions in such\ndomains relies on the ability of agents to predict each others' intentions\nreliably, and react quickly. Multiagent trajectory prediction is NP-hard\nwhereas the sample complexity of existing data-driven approaches limits their\napplicability. Our key insight is that the geometric structure of the\nintersection and the incentive of agents to move efficiently and avoid\ncollisions (rationality) reduces the space of likely behaviors, effectively\nrelaxing the problem of trajectory prediction. In this paper, we collapse the\nspace of multiagent trajectories at an intersection into a set of modes\nrepresenting different classes of multiagent behavior, formalized using a\nnotion of topological invariance. Based on this formalism, we design Multiple\nTopologies Prediction (MTP), a data-driven trajectory-prediction mechanism that\nreconstructs trajectory representations of high-likelihood modes in multiagent\nintersection scenes. We show that MTP outperforms a state-of-the-art multimodal\ntrajectory prediction baseline (MFP) in terms of prediction accuracy by 78.24%\non a challenging simulated dataset. Finally, we show that MTP enables our\noptimization-based planner, MTPnav, to achieve collision-free and\ntime-efficient navigation across a variety of challenging intersection\nscenarios on the CARLA simulator.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 02:56:42 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Roh", "Junha", ""], ["Mavrogiannis", "Christoforos", ""], ["Madan", "Rishabh", ""], ["Fox", "Dieter", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "2011.03896", "submitter": "Mark Sellke", "authors": "S\\'ebastien Bubeck, Thomas Budzinski, Mark Sellke", "title": "Cooperative and Stochastic Multi-Player Multi-Armed Bandit: Optimal\n  Regret With Neither Communication Nor Collisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the cooperative multi-player version of the stochastic\nmulti-armed bandit problem. We study the regime where the players cannot\ncommunicate but have access to shared randomness. In prior work by the first\ntwo authors, a strategy for this regime was constructed for two players and\nthree arms, with regret $\\tilde{O}(\\sqrt{T})$, and with no collisions at all\nbetween the players (with very high probability). In this paper we show that\nthese properties (near-optimal regret and no collisions at all) are achievable\nfor any number of players and arms. At a high level, the previous strategy\nheavily relied on a $2$-dimensional geometric intuition that was difficult to\ngeneralize in higher dimensions, while here we take a more combinatorial route\nto build the new strategy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 03:14:19 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Budzinski", "Thomas", ""], ["Sellke", "Mark", ""]]}, {"id": "2011.03900", "submitter": "Yichen Wang", "authors": "T. Tony Cai, Yichen Wang, Linjun Zhang", "title": "The Cost of Privacy in Generalized Linear Models: Algorithms and Minimax\n  Lower Bounds", "comments": "56 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose differentially private algorithms for parameter estimation in both\nlow-dimensional and high-dimensional sparse generalized linear models (GLMs) by\nconstructing private versions of projected gradient descent. We show that the\nproposed algorithms are nearly rate-optimal by characterizing their statistical\nperformance and establishing privacy-constrained minimax lower bounds for GLMs.\nThe lower bounds are obtained via a novel technique, which is based on Stein's\nLemma and generalizes the tracing attack technique for privacy-constrained\nlower bounds. This lower bound argument can be of independent interest as it is\napplicable to general parametric models. Simulated and real data experiments\nare conducted to demonstrate the numerical performance of our algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 04:27:21 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 00:30:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Cai", "T. Tony", ""], ["Wang", "Yichen", ""], ["Zhang", "Linjun", ""]]}, {"id": "2011.03902", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen, Brandon Amos, Maximilian Nickel", "title": "Learning Neural Event Functions for Ordinary Differential Equations", "comments": null, "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing Neural ODE formulation relies on an explicit knowledge of the\ntermination time. We extend Neural ODEs to implicitly defined termination\ncriteria modeled by neural event functions, which can be chained together and\ndifferentiated through. Neural Event ODEs are capable of modeling discrete and\ninstantaneous changes in a continuous-time system, without prior knowledge of\nwhen these changes should occur or how many such changes should exist. We test\nour approach in modeling hybrid discrete- and continuous- systems such as\nswitching dynamical systems and collision in multi-body systems, and we propose\nsimulation-based training of point processes with applications in discrete\ncontrol.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 04:33:54 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 18:36:31 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 00:02:40 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Amos", "Brandon", ""], ["Nickel", "Maximilian", ""]]}, {"id": "2011.03904", "submitter": "Jan Philip G\\\"opfert", "authors": "Jan Philip G\\\"opfert and Heiko Wersing and Barbara Hammer", "title": "Locally Adaptive Nearest Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training automated systems, it has been shown to be beneficial to adapt\nthe representation of data by learning a problem-specific metric. This metric\nis global. We extend this idea and, for the widely used family of k nearest\nneighbors algorithms, develop a method that allows learning locally adaptive\nmetrics. To demonstrate important aspects of how our approach works, we conduct\na number of experiments on synthetic data sets, and we show its usefulness on\nreal-world benchmark data sets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 05:27:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["G\u00f6pfert", "Jan Philip", ""], ["Wersing", "Heiko", ""], ["Hammer", "Barbara", ""]]}, {"id": "2011.03908", "submitter": "Xiaoang Shen", "authors": "Guokai Zhang, Xiaoang Shen, Ye Luo, Jihao Luo, Zeju Wang, Weigang\n  Wang, Binghui Zhao, Jianwei Lu", "title": "Cross-Modal Self-Attention Distillation for Prostate Cancer Segmentation", "comments": "2020 IEEE International Conference on Bioinformatics and Biomedicine\n  (BIBM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic segmentation of the prostate cancer from the multi-modal magnetic\nresonance images is of critical importance for the initial staging and\nprognosis of patients. However, how to use the multi-modal image features more\nefficiently is still a challenging problem in the field of medical image\nsegmentation. In this paper, we develop a cross-modal self-attention\ndistillation network by fully exploiting the encoded information of the\nintermediate layers from different modalities, and the extracted attention maps\nof different modalities enable the model to transfer the significant spatial\ninformation with more details. Moreover, a novel spatial correlated feature\nfusion module is further employed for learning more complementary correlation\nand non-linear information of different modality images. We evaluate our model\nin five-fold cross-validation on 358 MRI with biopsy confirmed. Extensive\nexperiment results demonstrate that our proposed network achieves\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 06:19:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhang", "Guokai", ""], ["Shen", "Xiaoang", ""], ["Luo", "Ye", ""], ["Luo", "Jihao", ""], ["Wang", "Zeju", ""], ["Wang", "Weigang", ""], ["Zhao", "Binghui", ""], ["Lu", "Jianwei", ""]]}, {"id": "2011.03917", "submitter": "Cem Kalkanli", "authors": "Cem Kalkanli, Ayfer Ozgur", "title": "Asymptotic Convergence of Thompson Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling has been shown to be an effective policy across a variety\nof online learning tasks. Many works have analyzed the finite time performance\nof Thompson sampling, and proved that it achieves a sub-linear regret under a\nbroad range of probabilistic settings. However its asymptotic behavior remains\nmostly underexplored. In this paper, we prove an asymptotic convergence result\nfor Thompson sampling under the assumption of a sub-linear Bayesian regret, and\nshow that the actions of a Thompson sampling agent provide a strongly\nconsistent estimator of the optimal action. Our results rely on the martingale\nstructure inherent in Thompson sampling.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 07:36:49 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Kalkanli", "Cem", ""], ["Ozgur", "Ayfer", ""]]}, {"id": "2011.03965", "submitter": "Satwik Bhattamishra", "authors": "Satwik Bhattamishra, Kabir Ahuja, Navin Goyal", "title": "On the Practical Ability of Recurrent Neural Networks to Recognize\n  Hierarchical Languages", "comments": "COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While recurrent models have been effective in NLP tasks, their performance on\ncontext-free languages (CFLs) has been found to be quite weak. Given that CFLs\nare believed to capture important phenomena such as hierarchical structure in\nnatural languages, this discrepancy in performance calls for an explanation. We\nstudy the performance of recurrent models on Dyck-n languages, a particularly\nimportant and well-studied class of CFLs. We find that while recurrent models\ngeneralize nearly perfectly if the lengths of the training and test strings are\nfrom the same range, they perform poorly if the test strings are longer. At the\nsame time, we observe that recurrent models are expressive enough to recognize\nDyck words of arbitrary lengths in finite precision if their depths are\nbounded. Hence, we evaluate our models on samples generated from Dyck languages\nwith bounded depth and find that they are indeed able to generalize to much\nhigher lengths. Since natural language datasets have nested dependencies of\nbounded depth, this may help explain why they perform well in modeling\nhierarchical dependencies in natural language data despite prior works\nindicating poor generalization performance on Dyck languages. We perform\nprobing studies to support our results and provide comparisons with\nTransformers.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 12:15:31 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhattamishra", "Satwik", ""], ["Ahuja", "Kabir", ""], ["Goyal", "Navin", ""]]}, {"id": "2011.03971", "submitter": "Minghe Zhu", "authors": "Minghe Zhu, Tsung-Hui Chang and Mingyi Hong", "title": "Learning to Beamform in Heterogeneous Massive MIMO Networks", "comments": "28 pages,12 figures, submitted to in IEEE transactions on signal\n  processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the problem of finding the optimal beamformers in\nmassive multiple-input multiple-output (MIMO) networks is challenging because\nof its non-convexity, and conventional optimization based algorithms suffer\nfrom high computational costs. While computationally efficient deep learning\nbased methods have been proposed, their complexity heavily relies upon system\nparameters such as the number of transmit antennas, and therefore these methods\ntypically do not generalize well when deployed in heterogeneous scenarios where\nthe base stations (BSs) are equipped with different numbers of transmit\nantennas and have different inter-BS distances. This paper proposes a novel\ndeep learning based beamforming algorithm to address the above challenges.\nSpecifically, we consider the weighted sum rate (WSR) maximization problem in\nmulti-input and single-output (MISO) interference channels, and propose a deep\nneural network architecture by unfolding a parallel gradient projection\nalgorithm. Somewhat surprisingly, by leveraging the low-dimensional structures\nof the optimal beamforming solution, our constructed neural network can be made\nindependent of the numbers of transmit antennas and BSs. Moreover, such a\ndesign can be further extended to a cooperative multicell network. Numerical\nresults based on both synthetic and ray-tracing channel models show that the\nproposed neural network can achieve high WSRs with significantly reduced\nruntime, while exhibiting favorable generalization capability with respect to\nthe antenna number, BS number and the inter-BS distance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 12:48:06 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhu", "Minghe", ""], ["Chang", "Tsung-Hui", ""], ["Hong", "Mingyi", ""]]}, {"id": "2011.03977", "submitter": "Vasileios Gkolemis", "authors": "Vasileios Gkolemis, Michael Gutmann", "title": "Extending the statistical software package Engine for Likelihood-Free\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference is a principled framework for dealing with uncertainty.\nThe practitioner can perform an initial assumption for the physical phenomenon\nthey want to model (prior belief), collect some data and then adjust the\ninitial assumption in the light of the new evidence (posterior belief).\nApproximate Bayesian Computation (ABC) methods, also known as likelihood-free\ninference techniques, are a class of models used for performing inference when\nthe likelihood is intractable. The unique requirement of these models is a\nblack-box sampling machine. Due to the modelling-freedom they provide these\napproaches are particularly captivating. Robust Optimisation Monte Carlo (ROMC)\nis one of the most recent techniques of the specific domain. It approximates\nthe posterior distribution by solving independent optimisation problems. This\ndissertation focuses on the implementation of the ROMC method in the software\npackage Engine for Likelihood-Free Inference (ELFI). In the first chapters, we\nprovide the mathematical formulation and the algorithmic description of the\nROMC approach. In the following chapters, we describe our implementation; (a)\nwe present all the functionalities provided to the user and (b) we demonstrate\nhow to perform inference on some real examples. Our implementation provides a\nrobust and efficient solution to a practitioner who wants to perform inference\non a simulator-based model. Furthermore, it exploits parallel processing for\naccelerating the inference wherever it is possible. Finally, it has been\ndesigned to serve extensibility; the user can easily replace specific subparts\nof the method without significant overhead on the development side. Therefore,\nit can be used by a researcher for further experimentation.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 13:22:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Gkolemis", "Vasileios", ""], ["Gutmann", "Michael", ""]]}, {"id": "2011.03981", "submitter": "Hongkai Ye", "authors": "Lizi Wang, Hongkai Ye, Qianhao Wang, Yuman Gao, Chao Xu and Fei Gao", "title": "Learning-based 3D Occupancy Prediction for Autonomous Navigation in\n  Occluded Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In autonomous navigation of mobile robots, sensors suffer from massive\nocclusion in cluttered environments, leaving significant amount of space\nunknown during planning. In practice, treating the unknown space in optimistic\nor pessimistic ways both set limitations on planning performance, thus\naggressiveness and safety cannot be satisfied at the same time. However, humans\ncan infer the exact shape of the obstacles from only partial observation and\ngenerate non-conservative trajectories that avoid possible collisions in\noccluded space. Mimicking human behavior, in this paper, we propose a method\nbased on deep neural network to predict occupancy distribution of unknown space\nreliably. Specifically, the proposed method utilizes contextual information of\nenvironments and learns from prior knowledge to predict obstacle distributions\nin occluded space. We use unlabeled and no-ground-truth data to train our\nnetwork and successfully apply it to real-time navigation in unseen\nenvironments without any refinement. Results show that our method leverages the\nperformance of a kinodynamic planner by improving security with no reduction of\nspeed in clustered environments.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 13:51:34 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 10:54:16 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wang", "Lizi", ""], ["Ye", "Hongkai", ""], ["Wang", "Qianhao", ""], ["Gao", "Yuman", ""], ["Xu", "Chao", ""], ["Gao", "Fei", ""]]}, {"id": "2011.03984", "submitter": "Zhen Han", "authors": "Zhen Han, Yunpu Ma, Peng Chen, Volker Tresp", "title": "DyERNIE: Dynamic Evolution of Riemannian Manifold Embeddings for\n  Temporal Knowledge Graph Completion", "comments": "16 pages, accepted as long paper at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been increasing interest in learning representations of\ntemporal knowledge graphs (KGs), which record the dynamic relationships between\nentities over time. Temporal KGs often exhibit multiple simultaneous\nnon-Euclidean structures, such as hierarchical and cyclic structures. However,\nexisting embedding approaches for temporal KGs typically learn entity\nrepresentations and their dynamic evolution in the Euclidean space, which might\nnot capture such intrinsic structures very well. To this end, we propose Dy-\nERNIE, a non-Euclidean embedding approach that learns evolving entity\nrepresentations in a product of Riemannian manifolds, where the composed spaces\nare estimated from the sectional curvatures of underlying data. Product\nmanifolds enable our approach to better reflect a wide variety of geometric\nstructures on temporal KGs. Besides, to capture the evolutionary dynamics of\ntemporal KGs, we let the entity representations evolve according to a velocity\nvector defined in the tangent space at each timestamp. We analyze in detail the\ncontribution of geometric spaces to representation learning of temporal KGs and\nevaluate our model on temporal knowledge graph completion tasks. Extensive\nexperiments on three real-world datasets demonstrate significantly improved\nperformance, indicating that the dynamics of multi-relational graph data can be\nmore properly modeled by the evolution of embeddings on Riemannian manifolds.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 14:04:16 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 13:20:02 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Han", "Zhen", ""], ["Ma", "Yunpu", ""], ["Chen", "Peng", ""], ["Tresp", "Volker", ""]]}, {"id": "2011.03996", "submitter": "Marcelo Medeiros", "authors": "Jianqing Fan, Ricardo P. Masini, Marcelo C. Medeiros", "title": "Do We Exploit all Information for Counterfactual Analysis? Benefits of\n  Factor Models and Idiosyncratic Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement of treatment (intervention) effects on a single (or just a\nfew) treated unit(s) based on counterfactuals constructed from artificial\ncontrols has become a popular practice in applied statistics and economics\nsince the proposal of the synthetic control method. In high-dimensional\nsetting, we often use principal component or (weakly) sparse regression to\nestimate counterfactuals. Do we use enough data information? To better estimate\nthe effects of price changes on the sales in our case study, we propose a\ngeneral framework on counterfactual analysis for high dimensional dependent\ndata. The framework includes both principal component regression and sparse\nlinear regression as specific cases. It uses both factor and idiosyncratic\ncomponents as predictors for improved counterfactual analysis, resulting a\nmethod called Factor-Adjusted Regularized Method for Treatment (FarmTreat)\nevaluation. We demonstrate convincingly that using either factors or sparse\nregression is inadequate for counterfactual analysis in many applications and\nthe case for information gain can be made through the use of idiosyncratic\ncomponents. We also develop theory and methods to formally answer the question\nif common factors are adequate for estimating counterfactuals. Furthermore, we\nconsider a simple resampling approach to conduct inference on the treatment\neffect as well as bootstrap test to access the relevance of the idiosyncratic\ncomponents. We apply the proposed method to evaluate the effects of price\nchanges on the sales of a set of products based on a novel large panel of sale\ndata from a major retail chain in Brazil and demonstrate the benefits of using\nadditional idiosyncratic components in the treatment effect evaluations.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:07:48 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 12:27:40 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Fan", "Jianqing", ""], ["Masini", "Ricardo P.", ""], ["Medeiros", "Marcelo C.", ""]]}, {"id": "2011.04000", "submitter": "Ashutosh Modi", "authors": "Ishika Singh and Ahsan Barkati and Tushar Goswamy and Ashutosh Modi", "title": "Adapting a Language Model for Controlled Affective Text Generation", "comments": "15 Pages (9 + 2 (references) + 4 (appendix)), accepted at COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human use language not just to convey information but also to express their\ninner feelings and mental states. In this work, we adapt the state-of-the-art\nlanguage generation models to generate affective (emotional) text. We posit a\nmodel capable of generating affect-driven and topic-focused sentences without\nlosing grammatical correctness as the affect intensity increases. We propose to\nincorporate emotion as prior for the probabilistic state-of-the-art text\ngeneration model such as GPT-2. The model gives a user the flexibility to\ncontrol the category and intensity of emotion as well as the topic of the\ngenerated text. Previous attempts at modelling fine-grained emotions fall out\non grammatical correctness at extreme intensities, but our model is resilient\nto this and delivers robust results at all intensities. We conduct automated\nevaluations and human studies to test the performance of our model and provide\na detailed comparison of the results with other models. In all evaluations, our\nmodel outperforms existing affective text generation models.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:24:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Singh", "Ishika", ""], ["Barkati", "Ahsan", ""], ["Goswamy", "Tushar", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2011.04006", "submitter": "Yi Tay", "authors": "Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri,\n  Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, Donald Metzler", "title": "Long Range Arena: A Benchmark for Efficient Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers do not scale very well to long sequence lengths largely because\nof quadratic self-attention complexity. In the recent months, a wide spectrum\nof efficient, fast Transformers have been proposed to tackle this problem, more\noften than not claiming superior or comparable model quality to vanilla\nTransformer models. To this date, there is no well-established consensus on how\nto evaluate this class of models. Moreover, inconsistent benchmarking on a wide\nspectrum of tasks and datasets makes it difficult to assess relative model\nquality amongst many models. This paper proposes a systematic and unified\nbenchmark, LRA, specifically focused on evaluating model quality under\nlong-context scenarios. Our benchmark is a suite of tasks consisting of\nsequences ranging from $1K$ to $16K$ tokens, encompassing a wide range of data\ntypes and modalities such as text, natural, synthetic images, and mathematical\nexpressions requiring similarity, structural, and visual-spatial reasoning. We\nsystematically evaluate ten well-established long-range Transformer models\n(Reformers, Linformers, Linear Transformers, Sinkhorn Transformers, Performers,\nSynthesizers, Sparse Transformers, and Longformers) on our newly proposed\nbenchmark suite. LRA paves the way towards better understanding this class of\nefficient Transformer models, facilitates more research in this direction, and\npresents new challenging tasks to tackle. Our benchmark code will be released\nat https://github.com/google-research/long-range-arena.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:53:56 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Tay", "Yi", ""], ["Dehghani", "Mostafa", ""], ["Abnar", "Samira", ""], ["Shen", "Yikang", ""], ["Bahri", "Dara", ""], ["Pham", "Philip", ""], ["Rao", "Jinfeng", ""], ["Yang", "Liu", ""], ["Ruder", "Sebastian", ""], ["Metzler", "Donald", ""]]}, {"id": "2011.04018", "submitter": "Botao Hao", "authors": "Botao Hao, Tor Lattimore, Csaba Szepesv\\'ari, Mengdi Wang", "title": "Online Sparse Reinforcement Learning", "comments": "Accepted at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the hardness of online reinforcement learning in fixed\nhorizon, sparse linear Markov decision process (MDP), with a special focus on\nthe high-dimensional regime where the ambient dimension is larger than the\nnumber of episodes. Our contribution is two-fold. First, we provide a lower\nbound showing that linear regret is generally unavoidable in this case, even if\nthere exists a policy that collects well-conditioned data. The lower bound\nconstruction uses an MDP with a fixed number of states while the number of\nactions scales with the ambient dimension. Note that when the horizon is fixed\nto one, the case of linear stochastic bandits, the linear regret can be\navoided. Second, we show that if the learner has oracle access to a policy that\ncollects well-conditioned data then a variant of Lasso fitted Q-iteration\nenjoys a nearly dimension-free regret of $\\tilde{O}( s^{2/3} N^{2/3})$ where\n$N$ is the number of episodes and $s$ is the sparsity level. This shows that in\nthe large-action setting, the difficulty of learning can be attributed to the\ndifficulty of finding a good exploratory policy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:47:42 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 21:18:24 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 15:37:53 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 15:55:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Hao", "Botao", ""], ["Lattimore", "Tor", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Wang", "Mengdi", ""]]}, {"id": "2011.04019", "submitter": "Botao Hao", "authors": "Botao Hao, Yaqi Duan, Tor Lattimore, Csaba Szepesv\\'ari, Mengdi Wang", "title": "Sparse Feature Selection Makes Batch Reinforcement Learning More Sample\n  Efficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a statistical analysis of high-dimensional batch\nReinforcement Learning (RL) using sparse linear function approximation. When\nthere is a large number of candidate features, our result sheds light on the\nfact that sparsity-aware methods can make batch RL more sample efficient. We\nfirst consider the off-policy policy evaluation problem. To evaluate a new\ntarget policy, we analyze a Lasso fitted Q-evaluation method and establish a\nfinite-sample error bound that has no polynomial dependence on the ambient\ndimension. To reduce the Lasso bias, we further propose a post model-selection\nestimator that applies fitted Q-evaluation to the features selected via group\nLasso. Under an additional signal strength assumption, we derive a sharper\ninstance-dependent error bound that depends on a divergence function measuring\nthe distribution mismatch between the data distribution and occupancy measure\nof the target policy. Further, we study the Lasso fitted Q-iteration for batch\npolicy optimization and establish a finite-sample error bound depending on the\nratio between the number of relevant features and restricted minimal eigenvalue\nof the data's covariance. In the end, we complement the results with minimax\nlower bounds for batch-data policy evaluation/optimization that nearly match\nour upper bounds. The results suggest that having well-conditioned data is\ncrucial for sparse batch policy learning.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:48:02 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hao", "Botao", ""], ["Duan", "Yaqi", ""], ["Lattimore", "Tor", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Wang", "Mengdi", ""]]}, {"id": "2011.04020", "submitter": "Botao Hao", "authors": "Botao Hao, Tor Lattimore, Mengdi Wang", "title": "High-Dimensional Sparse Linear Bandits", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic linear bandits with high-dimensional sparse features are a\npractical model for a variety of domains, including personalized medicine and\nonline advertising. We derive a novel $\\Omega(n^{2/3})$ dimension-free minimax\nregret lower bound for sparse linear bandits in the data-poor regime where the\nhorizon is smaller than the ambient dimension and where the feature vectors\nadmit a well-conditioned exploration distribution. This is complemented by a\nnearly matching upper bound for an explore-then-commit algorithm showing that\nthat $\\Theta(n^{2/3})$ is the optimal rate in the data-poor regime. The results\ncomplement existing bounds for the data-rich regime and provide another example\nwhere carefully balancing the trade-off between information and regret is\nnecessary. Finally, we prove a dimension-free $O(\\sqrt{n})$ regret upper bound\nunder an additional assumption on the magnitude of the signal for relevant\nfeatures.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:48:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hao", "Botao", ""], ["Lattimore", "Tor", ""], ["Wang", "Mengdi", ""]]}, {"id": "2011.04021", "submitter": "Jessica Hamrick", "authors": "Jessica B. Hamrick, Abram L. Friesen, Feryal Behbahani, Arthur Guez,\n  Fabio Viola, Sims Witherspoon, Thomas Anthony, Lars Buesing, Petar\n  Veli\\v{c}kovi\\'c, Th\\'eophane Weber", "title": "On the role of planning in model-based deep reinforcement learning", "comments": "Published at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based planning is often thought to be necessary for deep, careful\nreasoning and generalization in artificial agents. While recent successes of\nmodel-based reinforcement learning (MBRL) with deep function approximation have\nstrengthened this hypothesis, the resulting diversity of model-based methods\nhas also made it difficult to track which components drive success and why. In\nthis paper, we seek to disentangle the contributions of recent methods by\nfocusing on three questions: (1) How does planning benefit MBRL agents? (2)\nWithin planning, what choices drive performance? (3) To what extent does\nplanning improve generalization? To answer these questions, we study the\nperformance of MuZero (Schrittwieser et al., 2019), a state-of-the-art MBRL\nalgorithm with strong connections and overlapping components with many other\nMBRL algorithms. We perform a number of interventions and ablations of MuZero\nacross a wide range of environments, including control tasks, Atari, and 9x9\nGo. Our results suggest the following: (1) Planning is most useful in the\nlearning process, both for policy updates and for providing a more useful data\ndistribution. (2) Using shallow trees with simple Monte-Carlo rollouts is as\nperformant as more complex methods, except in the most difficult reasoning\ntasks. (3) Planning alone is insufficient to drive strong generalization. These\nresults indicate where and how to utilize planning in reinforcement learning\nsettings, and highlight a number of open questions for future MBRL research.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 16:55:16 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 11:36:47 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Hamrick", "Jessica B.", ""], ["Friesen", "Abram L.", ""], ["Behbahani", "Feryal", ""], ["Guez", "Arthur", ""], ["Viola", "Fabio", ""], ["Witherspoon", "Sims", ""], ["Anthony", "Thomas", ""], ["Buesing", "Lars", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Weber", "Th\u00e9ophane", ""]]}, {"id": "2011.04026", "submitter": "Alexander Terenin", "authors": "James T. Wilson, Viacheslav Borovitskiy, Alexander Terenin, Peter\n  Mostowsky, and Marc Peter Deisenroth", "title": "Pathwise Conditioning of Gaussian Processes", "comments": null, "journal-ref": "Journal of Machine Learning Research (2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As Gaussian processes are used to answer increasingly complex questions,\nanalytic solutions become scarcer and scarcer. Monte Carlo methods act as a\nconvenient bridge for connecting intractable mathematical expressions with\nactionable estimates via sampling. Conventional approaches for simulating\nGaussian process posteriors view samples as draws from marginal distributions\nof process values at finite sets of input locations. This distribution-centric\ncharacterization leads to generative strategies that scale cubically in the\nsize of the desired random vector. These methods are prohibitively expensive in\ncases where we would, ideally, like to draw high-dimensional vectors or even\ncontinuous sample paths. In this work, we investigate a different line of\nreasoning: rather than focusing on distributions, we articulate Gaussian\nconditionals at the level of random variables. We show how this pathwise\ninterpretation of conditioning gives rise to a general family of approximations\nthat lend themselves to efficiently sampling Gaussian process posteriors.\nStarting from first principles, we derive these methods and analyze the\napproximation errors they introduce. We, then, ground these results by\nexploring the practical implications of pathwise conditioning in various\napplied settings, such as global optimization and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 17:09:37 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:38:11 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wilson", "James T.", ""], ["Borovitskiy", "Viacheslav", ""], ["Terenin", "Alexander", ""], ["Mostowsky", "Peter", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2011.04041", "submitter": "Aijun Zhang", "authors": "Agus Sudjianto, William Knauth, Rahul Singh, Zebin Yang, Aijun Zhang", "title": "Unwrapping The Black Box of Deep ReLU Networks: Interpretability,\n  Diagnostics, and Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep neural networks (DNNs) have achieved great success in learning\ncomplex patterns with strong predictive power, but they are often thought of as\n\"black box\" models without a sufficient level of transparency and\ninterpretability. It is important to demystify the DNNs with rigorous\nmathematics and practical tools, especially when they are used for\nmission-critical applications. This paper aims to unwrap the black box of deep\nReLU networks through local linear representation, which utilizes the\nactivation pattern and disentangles the complex network into an equivalent set\nof local linear models (LLMs). We develop a convenient LLM-based toolkit for\ninterpretability, diagnostics, and simplification of a pre-trained deep ReLU\nnetwork. We propose the local linear profile plot and other visualization\nmethods for interpretation and diagnostics, and an effective merging strategy\nfor network simplification. The proposed methods are demonstrated by simulation\nexamples, benchmark datasets, and a real case study in home lending credit risk\nassessment.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 18:09:36 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Sudjianto", "Agus", ""], ["Knauth", "William", ""], ["Singh", "Rahul", ""], ["Yang", "Zebin", ""], ["Zhang", "Aijun", ""]]}, {"id": "2011.04049", "submitter": "Cecilia Panigutti", "authors": "Cecilia Panigutti, Alan Perotti, Andr\\`e Panisson, Paolo Bajardi and\n  Dino Pedreschi", "title": "FairLens: Auditing Black-box Clinical Decision Support Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive application of algorithmic decision-making is raising concerns\non the risk of unintended bias in AI systems deployed in critical settings such\nas healthcare. The detection and mitigation of biased models is a very delicate\ntask which should be tackled with care and involving domain experts in the\nloop. In this paper we introduce FairLens, a methodology for discovering and\nexplaining biases. We show how our tool can be used to audit a fictional\ncommercial black-box model acting as a clinical decision support system. In\nthis scenario, the healthcare facility experts can use FairLens on their own\nhistorical data to discover the model's biases before incorporating it into the\nclinical decision flow. FairLens first stratifies the available patient data\naccording to attributes such as age, ethnicity, gender and insurance; it then\nassesses the model performance on such subgroups of patients identifying those\nin need of expert evaluation. Finally, building on recent state-of-the-art XAI\n(eXplainable Artificial Intelligence) techniques, FairLens explains which\nelements in patients' clinical history drive the model error in the selected\nsubgroup. Therefore, FairLens allows experts to investigate whether to trust\nthe model and to spotlight group-specific biases that might constitute\npotential fairness issues.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 18:40:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Panigutti", "Cecilia", ""], ["Perotti", "Alan", ""], ["Panisson", "Andr\u00e8", ""], ["Bajardi", "Paolo", ""], ["Pedreschi", "Dino", ""]]}, {"id": "2011.04050", "submitter": "Nader Bouacida", "authors": "Nader Bouacida, Jiahui Hou, Hui Zang and Xin Liu", "title": "Adaptive Federated Dropout: Improving Communication Efficiency and\n  Generalization for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With more regulations tackling users' privacy-sensitive data protection in\nrecent years, access to such data has become increasingly restricted and\ncontroversial. To exploit the wealth of data generated and located at\ndistributed entities such as mobile phones, a revolutionary decentralized\nmachine learning setting, known as Federated Learning, enables multiple clients\nlocated at different geographical locations to collaboratively learn a machine\nlearning model while keeping all their data on-device. However, the scale and\ndecentralization of federated learning present new challenges. Communication\nbetween the clients and the server is considered a main bottleneck in the\nconvergence time of federated learning.\n  In this paper, we propose and study Adaptive Federated Dropout (AFD), a novel\ntechnique to reduce the communication costs associated with federated learning.\nIt optimizes both server-client communications and computation costs by\nallowing clients to train locally on a selected subset of the global model. We\nempirically show that this strategy, combined with existing compression\nmethods, collectively provides up to 57x reduction in convergence time. It also\noutperforms the state-of-the-art solutions for communication efficiency.\nFurthermore, it improves model generalization by up to 1.7%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 18:41:44 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bouacida", "Nader", ""], ["Hou", "Jiahui", ""], ["Zang", "Hui", ""], ["Liu", "Xin", ""]]}, {"id": "2011.04055", "submitter": "Giuseppe Patan\\`e", "authors": "Giuseppe Patan\\`e", "title": "Fourier-based and Rational Graph Filters for Spectral Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data are represented as graphs in a wide range of applications, such as\nComputer Vision (e.g., images) and Graphics (e.g., 3D meshes), network analysis\n(e.g., social networks), and bio-informatics (e.g., molecules). In this\ncontext, our overall goal is the definition of novel Fourier-based and graph\nfilters induced by rational polynomials for graph processing, which generalise\npolynomial filters and the Fourier transform to non-Euclidean domains. For the\nefficient evaluation of discrete spectral Fourier-based and wavelet operators,\nwe introduce a spectrum-free approach, which requires the solution of a small\nset of sparse, symmetric, well-conditioned linear systems and is oblivious of\nthe evaluation of the Laplacian or kernel spectrum. Approximating arbitrary\ngraph filters with rational polynomials provides a more accurate and\nnumerically stable alternative with respect to polynomials. To achieve these\ngoals, we also study the link between spectral operators, wavelets, and\nfiltered convolution with integral operators induced by spectral kernels.\nAccording to our tests, main advantages of the proposed approach are (i) its\ngenerality with respect to the input data (e.g., graphs, 3D shapes),\napplications (e.g., signal reconstruction and smoothing, shape correspondence),\nand filters (e.g., polynomial, rational polynomial), and (ii) a spectrum-free\ncomputation with a generally low computational cost and storage overhead.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 19:02:52 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 21:24:37 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Patan\u00e8", "Giuseppe", ""]]}, {"id": "2011.04057", "submitter": "Shreyas Labhsetwar", "authors": "Shreyas Rajesh Labhsetwar, Alistair Michael Baretto, Raj Sunil Salvi,\n  Piyush Arvind Kolte, Veerasai Subramaniam Venkatesh", "title": "Analysis of Dimensional Influence of Convolutional Neural Networks for\n  Histopathological Cancer Classification", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks can be designed with different levels of\ncomplexity depending upon the task at hand. This paper analyzes the effect of\ndimensional changes to the CNN architecture on its performance on the task of\nHistopathological Cancer Classification. The research starts with a baseline\n10-layer CNN model with (3 X 3) convolution filters. Thereafter, the baseline\narchitecture is scaled in multiple dimensions including width, depth,\nresolution and a combination of all of these. Width scaling involves\ninculcating greater number of neurons per CNN layer, whereas depth scaling\ninvolves deepening the hierarchical layered structure. Resolution scaling is\nperformed by increasing the dimensions of the input image, and compound scaling\ninvolves a hybrid combination of width, depth and resolution scaling. The\nresults indicate that histopathological cancer scans are very complex in nature\nand hence require high resolution images fed to a large hierarchy of\nConvolution, MaxPooling, Dropout and Batch Normalization layers to extract all\nthe intricacies and perform perfect classification. Since compound scaling the\nbaseline model ensures that all the three dimensions: width, depth and\nresolution are scaled, the best performance is obtained with compound scaling.\nThis research shows that better performance of CNN models is achieved by\ncompound scaling of the baseline model for the task of Histopathological Cancer\nClassification.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 19:07:43 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 07:03:38 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Labhsetwar", "Shreyas Rajesh", ""], ["Baretto", "Alistair Michael", ""], ["Salvi", "Raj Sunil", ""], ["Kolte", "Piyush Arvind", ""], ["Venkatesh", "Veerasai Subramaniam", ""]]}, {"id": "2011.04062", "submitter": "Zhongfang Zhuang", "authors": "Zhongfang Zhuang, Xiangnan Kong, Elke Rundensteiner, Jihane Zouaoui,\n  Aditya Arora", "title": "MLAS: Metric Learning on Attributed Sequences", "comments": "Accepted by IEEE Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning has attracted much attention in recent years, where\nthe goal is to learn a distance metric based on user feedback. Conventional\napproaches to metric learning mainly focus on learning the Mahalanobis distance\nmetric on data attributes. Recent research on metric learning has been extended\nto sequential data, where we only have structural information in the sequences,\nbut no attribute is available. However, real-world applications often involve\nattributed sequence data (e.g., clickstreams), where each instance consists of\nnot only a set of attributes (e.g., user session context) but also a sequence\nof categorical items (e.g., user actions). In this paper, we study the problem\nof metric learning on attributed sequences. Unlike previous work on metric\nlearning, we now need to go beyond the Mahalanobis distance metric in the\nattribute feature space while also incorporating the structural information in\nsequences. We propose a deep learning framework, called MLAS (Metric Learning\non Attributed Sequences), to learn a distance metric that effectively measures\ndissimilarities between attributed sequences. Empirical results on real-world\ndatasets demonstrate that the proposed MLAS framework significantly improves\nthe performance of metric learning compared to state-of-the-art methods on\nattributed sequences.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 19:35:42 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhuang", "Zhongfang", ""], ["Kong", "Xiangnan", ""], ["Rundensteiner", "Elke", ""], ["Zouaoui", "Jihane", ""], ["Arora", "Aditya", ""]]}, {"id": "2011.04065", "submitter": "Naman Patel", "authors": "Naman Patel, Prashanth Krishnamurthy, Siddharth Garg, Farshad Khorrami", "title": "Bait and Switch: Online Training Data Poisoning of Autonomous Driving\n  Systems", "comments": "To appear in the NeurIPS 2020 Workshop on Dataset Curation and\n  Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that by controlling parts of a physical environment in which a\npre-trained deep neural network (DNN) is being fine-tuned online, an adversary\ncan launch subtle data poisoning attacks that degrade the performance of the\nsystem. While the attack can be applied in general to any perception task, we\nconsider a DNN based traffic light classifier for an autonomous car that has\nbeen trained in one city and is being fine-tuned online in another city. We\nshow that by injecting environmental perturbations that do not modify the\ntraffic lights themselves or ground-truth labels, the adversary can cause the\ndeep network to learn spurious concepts during the online learning phase. The\nattacker can leverage the introduced spurious concepts in the environment to\ncause the model's accuracy to degrade during operation; therefore, causing the\nsystem to malfunction.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 20:04:43 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 16:29:50 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Patel", "Naman", ""], ["Krishnamurthy", "Prashanth", ""], ["Garg", "Siddharth", ""], ["Khorrami", "Farshad", ""]]}, {"id": "2011.04102", "submitter": "Jie Wang", "authors": "Jie Wang, Rui Gao, Hongyuan Zha", "title": "Reliable Off-policy Evaluation for Reinforcement Learning", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a sequential decision-making problem, off-policy evaluation estimates the\nexpected cumulative reward of a target policy using logged trajectory data\ngenerated from a different behavior policy, without execution of the target\npolicy. Reinforcement learning in high-stake environments, such as healthcare\nand education, is often limited to off-policy settings due to safety or ethical\nconcerns, or inability of exploration. Hence it is imperative to quantify the\nuncertainty of the off-policy estimate before deployment of the target policy.\nIn this paper, we propose a novel framework that provides robust and optimistic\ncumulative reward estimates using one or multiple logged trajectories data.\nLeveraging methodologies from distributionally robust optimization, we show\nthat with proper selection of the size of the distributional uncertainty set,\nthese estimates serve as confidence bounds with non-asymptotic and asymptotic\nguarantees under stochastic or adversarial environments. Our results are also\ngeneralized to batch reinforcement learning and are supported by empirical\nanalysis.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 23:16:19 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 16:34:42 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wang", "Jie", ""], ["Gao", "Rui", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2011.04106", "submitter": "Jieming Zhu", "authors": "Jieming Zhu, Jinyang Liu, Weiqi Li, Jincai Lai, Xiuqiang He, Liang\n  Chen, Zibin Zheng", "title": "Ensembled CTR Prediction via Knowledge Distillation", "comments": "Published in CIKM'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning-based models have been widely studied for\nclick-through rate (CTR) prediction and lead to improved prediction accuracy in\nmany industrial applications. However, current research focuses primarily on\nbuilding complex network architectures to better capture sophisticated feature\ninteractions and dynamic user behaviors. The increased model complexity may\nslow down online inference and hinder its adoption in real-time applications.\nInstead, our work targets at a new model training strategy based on knowledge\ndistillation (KD). KD is a teacher-student learning framework to transfer\nknowledge learned from a teacher model to a student model. The KD strategy not\nonly allows us to simplify the student model as a vanilla DNN model but also\nachieves significant accuracy improvements over the state-of-the-art teacher\nmodels. The benefits thus motivate us to further explore the use of a powerful\nensemble of teachers for more accurate student model training. We also propose\nsome novel techniques to facilitate ensembled CTR prediction, including teacher\ngating and early stopping by distillation loss. We conduct comprehensive\nexperiments against 12 existing models and across three industrial datasets.\nBoth offline and online A/B testing results show the effectiveness of our\nKD-based training strategy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 23:37:58 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhu", "Jieming", ""], ["Liu", "Jinyang", ""], ["Li", "Weiqi", ""], ["Lai", "Jincai", ""], ["He", "Xiuqiang", ""], ["Chen", "Liang", ""], ["Zheng", "Zibin", ""]]}, {"id": "2011.04112", "submitter": "Lars Lindemann", "authors": "Lars Lindemann, Haimin Hu, Alexander Robey, Hanwen Zhang, Dimos V.\n  Dimarogonas, Stephen Tu, and Nikolai Matni", "title": "Learning Hybrid Control Barrier Functions from Data", "comments": "27 pages, Conference on Robot Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the lack of systematic tools to obtain safe control laws for\nhybrid systems, we propose an optimization-based framework for learning\ncertifiably safe control laws from data. In particular, we assume a setting in\nwhich the system dynamics are known and in which data exhibiting safe system\nbehavior is available. We propose hybrid control barrier functions for hybrid\nsystems as a means to synthesize safe control inputs. Based on this notion, we\npresent an optimization-based framework to learn such hybrid control barrier\nfunctions from data. Importantly, we identify sufficient conditions on the data\nsuch that feasibility of the optimization problem ensures correctness of the\nlearned hybrid control barrier functions, and hence the safety of the system.\nWe illustrate our findings in two simulations studies, including a compass gait\nwalker.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 23:55:02 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Lindemann", "Lars", ""], ["Hu", "Haimin", ""], ["Robey", "Alexander", ""], ["Zhang", "Hanwen", ""], ["Dimarogonas", "Dimos V.", ""], ["Tu", "Stephen", ""], ["Matni", "Nikolai", ""]]}, {"id": "2011.04121", "submitter": "Tareq Tayeh", "authors": "Tareq Tayeh, Sulaiman Aburakhia, Ryan Myers, and Abdallah Shami", "title": "Distance-Based Anomaly Detection for Industrial Surfaces Using Triplet\n  Networks", "comments": "6 pages, 8 figures, 2020 IEEE 11th Annual Information Technology,\n  Electronics and Mobile Communication Conference (Best Paper Award in the\n  category of Image Processing and Artificial Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface anomaly detection plays an important quality control role in many\nmanufacturing industries to reduce scrap production. Machine-based visual\ninspections have been utilized in recent years to conduct this task instead of\nhuman experts. In particular, deep learning Convolutional Neural Networks\n(CNNs) have been at the forefront of these image processing-based solutions due\nto their predictive accuracy and efficiency. Training a CNN on a classification\nobjective requires a sufficiently large amount of defective data, which is\noften not available. In this paper, we address that challenge by training the\nCNN on surface texture patches with a distance-based anomaly detection\nobjective instead. A deep residual-based triplet network model is utilized, and\ndefective training samples are synthesized exclusively from non-defective\nsamples via random erasing techniques to directly learn a similarity metric\nbetween the same-class samples and out-of-class samples. Evaluation results\ndemonstrate the approach's strength in detecting different types of anomalies,\nsuch as bent, broken, or cracked surfaces, for known surfaces that are part of\nthe training data and unseen novel surfaces.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 00:35:21 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 04:20:49 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tayeh", "Tareq", ""], ["Aburakhia", "Sulaiman", ""], ["Myers", "Ryan", ""], ["Shami", "Abdallah", ""]]}, {"id": "2011.04122", "submitter": "Yan Zuo", "authors": "Gil Avraham, Yan Zuo and Tom Drummond", "title": "Localising In Complex Scenes Using Balanced Adversarial Adaptation", "comments": "Accepted at 3DV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation and generative modelling have collectively mitigated the\nexpensive nature of data collection and labelling by leveraging the rich\nabundance of accurate, labelled data in simulation environments. In this work,\nwe study the performance gap that exists between representations optimised for\nlocalisation on simulation environments and the application of such\nrepresentations in a real-world setting. Our method exploits the shared\ngeometric similarities between simulation and real-world environments whilst\nmaintaining invariance towards visual discrepancies. This is achieved by\noptimising a representation extractor to project both simulated and real\nrepresentations into a shared representation space. Our method uses a\nsymmetrical adversarial approach which encourages the representation extractor\nto conceal the domain that features are extracted from and simultaneously\npreserves robust attributes between source and target domains that are\nbeneficial for localisation. We evaluate our method by adapting representations\noptimised for indoor Habitat simulated environments (Matterport3D and Replica)\nto a real-world indoor environment (Active Vision Dataset), showing that it\ncompares favourably against fully-supervised approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 00:40:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Avraham", "Gil", ""], ["Zuo", "Yan", ""], ["Drummond", "Tom", ""]]}, {"id": "2011.04125", "submitter": "Nadiia Chepurko", "authors": "Nadiia Chepurko, Kenneth L. Clarkson, Lior Horesh, David P. Woodruff", "title": "Quantum-Inspired Algorithms from Randomized Numerical Linear Algebra", "comments": "The analysis of the sparse gaussian contained a bug. The fix along\n  with applications appears in arXiv:2107.08090 , the quantum data structure\n  results remain unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We create classical (non-quantum) dynamic data structures supporting queries\nfor recommender systems and least-squares regression that are comparable to\ntheir quantum analogues. De-quantizing such algorithms has received a flurry of\nattention in recent years; we obtain sharper bounds for these problems. More\nsignificantly, we achieve these improvements by arguing that the previous\nquantum-inspired algorithms for these problems are doing leverage or\nridge-leverage score sampling in disguise; these are powerful and standard\ntechniques in randomized numerical linear algebra. With this recognition, we\nare able to employ the large body of work in numerical linear algebra to obtain\nalgorithms for these problems that are simpler or faster (or both) than\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:13:07 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 03:18:48 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 23:03:54 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 19:40:46 GMT"}, {"version": "v5", "created": "Tue, 20 Jul 2021 15:40:20 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chepurko", "Nadiia", ""], ["Clarkson", "Kenneth L.", ""], ["Horesh", "Lior", ""], ["Woodruff", "David P.", ""]]}, {"id": "2011.04127", "submitter": "Jake Lee", "authors": "Jake Lee, Junfeng Yang, Zhangyang Wang", "title": "What Does CNN Shift Invariance Look Like? A Visualization Study", "comments": "Presented at the 2020 ECCV Workshop on Real-World Computer Vision\n  from Inputs with Limited Quality (RLQ-TOD 2020), Glasgow, Scotland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction with convolutional neural networks (CNNs) is a popular\nmethod to represent images for machine learning tasks. These representations\nseek to capture global image content, and ideally should be independent of\ngeometric transformations. We focus on measuring and visualizing the shift\ninvariance of extracted features from popular off-the-shelf CNN models. We\npresent the results of three experiments comparing representations of millions\nof images with exhaustively shifted objects, examining both local invariance\n(within a few pixels) and global invariance (across the image frame). We\nconclude that features extracted from popular networks are not globally\ninvariant, and that biases and artifacts exist within this variance.\nAdditionally, we determine that anti-aliased models significantly improve local\ninvariance but do not impact global invariance. Finally, we provide a code\nrepository for experiment reproduction, as well as a website to interact with\nour results at https://jakehlee.github.io/visualize-invariance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:16:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Lee", "Jake", ""], ["Yang", "Junfeng", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2011.04128", "submitter": "Elias Chaibub Neto", "authors": "Elias Chaibub Neto, Phil Snyder, Solveig K Sieberts, Larsson Omberg", "title": "Stable predictions for health related anticausal prediction tasks\n  affected by selection biases: the need to deconfound the test set features", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract. This workshop paper draws some material from arXiv:2001.03998 and\n  arXiv:2004.09466", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In health related machine learning applications, the training data often\ncorresponds to a non-representative sample from the target populations where\nthe learners will be deployed. In anticausal prediction tasks, selection biases\noften make the associations between confounders and the outcome variable\nunstable across different target environments. As a consequence, the\npredictions from confounded learners are often unstable, and might fail to\ngeneralize in shifted test environments. Stable prediction approaches aim to\nsolve this problem by producing predictions that are stable across unknown test\nenvironments. These approaches, however, are sometimes applied to the training\ndata alone with the hope that training an unconfounded model will be enough to\ngenerate stable predictions in shifted test sets. Here, we show that this is\ninsufficient, and that improved stability can be achieved by deconfounding the\ntest set features as well. We illustrate these observations using both\nsynthetic data and real world data from a mobile health study.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:17:58 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Neto", "Elias Chaibub", ""], ["Snyder", "Phil", ""], ["Sieberts", "Solveig K", ""], ["Omberg", "Larsson", ""]]}, {"id": "2011.04141", "submitter": "Glen Chou", "authors": "Glen Chou, Necmiye Ozay, Dmitry Berenson", "title": "Uncertainty-Aware Constraint Learning for Adaptive Safe Motion Planning\n  from Demonstrations", "comments": "4th Conference on Robot Learning (CoRL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning to satisfy uncertain constraints from\ndemonstrations. Our method uses robust optimization to obtain a belief over the\npotentially infinite set of possible constraints consistent with the\ndemonstrations, and then uses this belief to plan trajectories that trade off\nperformance with satisfying the possible constraints. We use these trajectories\nin a closed-loop policy that executes and replans using belief updates, which\nincorporate data gathered during execution. We derive guarantees on the\naccuracy of our constraint belief and probabilistic guarantees on plan safety.\nWe present results on a 7-DOF arm and 12D quadrotor, showing our method can\nlearn to satisfy high-dimensional (up to 30D) uncertain constraints, and\noutperforms baselines in safety and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 01:59:14 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chou", "Glen", ""], ["Ozay", "Necmiye", ""], ["Berenson", "Dmitry", ""]]}, {"id": "2011.04144", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Eric Price, N. V. Vinodchandran", "title": "Near-Optimal Learning of Tree-Structured Distributions by Chow-Liu", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide finite sample guarantees for the classical Chow-Liu algorithm\n(IEEE Trans.~Inform.~Theory, 1968) to learn a tree-structured graphical model\nof a distribution. For a distribution $P$ on $\\Sigma^n$ and a tree $T$ on $n$\nnodes, we say $T$ is an $\\varepsilon$-approximate tree for $P$ if there is a\n$T$-structured distribution $Q$ such that $D(P\\;||\\;Q)$ is at most\n$\\varepsilon$ more than the best possible tree-structured distribution for $P$.\nWe show that if $P$ itself is tree-structured, then the Chow-Liu algorithm with\nthe plug-in estimator for mutual information with $\\widetilde{O}(|\\Sigma|^3\nn\\varepsilon^{-1})$ i.i.d.~samples outputs an $\\varepsilon$-approximate tree\nfor $P$ with constant probability. In contrast, for a general $P$ (which may\nnot be tree-structured), $\\Omega(n^2\\varepsilon^{-2})$ samples are necessary to\nfind an $\\varepsilon$-approximate tree. Our upper bound is based on a new\nconditional independence tester that addresses an open problem posed by\nCanonne, Diakonikolas, Kane, and Stewart~(STOC, 2018): we prove that for three\nrandom variables $X,Y,Z$ each over $\\Sigma$, testing if $I(X; Y \\mid Z)$ is $0$\nor $\\geq \\varepsilon$ is possible with $\\widetilde{O}(|\\Sigma|^3/\\varepsilon)$\nsamples. Finally, we show that for a specific tree $T$, with $\\widetilde{O}\n(|\\Sigma|^2n\\varepsilon^{-1})$ samples from a distribution $P$ over $\\Sigma^n$,\none can efficiently learn the closest $T$-structured distribution in KL\ndivergence by applying the add-1 estimator at each node.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 02:08:56 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 06:37:12 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gayen", "Sutanu", ""], ["Price", "Eric", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "2011.04145", "submitter": "Shuqiang Wang", "authors": "Senrong You and Yong Liu and Baiying Lei and Shuqiang Wang", "title": "Fine Perceptive GANs for Brain MR Image Super-Resolution in Wavelet\n  Domain", "comments": "9 pages, 11figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging plays an important role in computer-aided\ndiagnosis and brain exploration. However, limited by hardware, scanning time\nand cost, it's challenging to acquire high-resolution (HR) magnetic resonance\n(MR) image clinically. In this paper, fine perceptive generative adversarial\nnetworks (FP-GANs) is proposed to produce HR MR images from low-resolution\ncounterparts. It can cope with the detail insensitive problem of the existing\nsuper-resolution model in a divide-and-conquer manner. Specifically, FP-GANs\nfirstly divides an MR image into low-frequency global approximation and\nhigh-frequency anatomical texture in wavelet domain. Then each sub-band\ngenerative adversarial network (sub-band GAN) conquers the super-resolution\nprocedure of each single sub-band image. Meanwhile, sub-band attention is\ndeployed to tune focus between global and texture information. It can focus on\nsub-band images instead of feature maps to further enhance the anatomical\nreconstruction ability of FP-GANs. In addition, inverse discrete wavelet\ntransformation (IDWT) is integrated into model for taking the reconstruction of\nwhole image into account. Experiments on MultiRes_7T dataset demonstrate that\nFP-GANs outperforms the competing methods quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 02:09:44 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["You", "Senrong", ""], ["Liu", "Yong", ""], ["Lei", "Baiying", ""], ["Wang", "Shuqiang", ""]]}, {"id": "2011.04162", "submitter": "Zebang Shen", "authors": "Zebang Shen and Zhenfu Wang and Alejandro Ribeiro and Hamed Hassani", "title": "Sinkhorn Natural Gradient for Generative Models", "comments": "accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a functional over a parametric family\nof probability measures, where the parameterization is characterized via a\npush-forward structure. An important application of this problem is in training\ngenerative adversarial networks. In this regard, we propose a novel Sinkhorn\nNatural Gradient (SiNG) algorithm which acts as a steepest descent method on\nthe probability space endowed with the Sinkhorn divergence. We show that the\nSinkhorn information matrix (SIM), a key component of SiNG, has an explicit\nexpression and can be evaluated accurately in complexity that scales\nlogarithmically with respect to the desired accuracy. This is in sharp contrast\nto existing natural gradient methods that can only be carried out\napproximately. Moreover, in practical applications when only Monte-Carlo type\nintegration is available, we design an empirical estimator for SIM and provide\nthe stability analysis. In our experiments, we quantitatively compare SiNG with\nstate-of-the-art SGD-type solvers on generative tasks to demonstrate its\nefficiency and efficacy of our method.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 02:51:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Shen", "Zebang", ""], ["Wang", "Zhenfu", ""], ["Ribeiro", "Alejandro", ""], ["Hassani", "Hamed", ""]]}, {"id": "2011.04170", "submitter": "Hadi Akbarzadeh Khorshidi", "authors": "Hadi A. Khorshidi and Uwe Aickelin", "title": "Synthetic Over-sampling with the Minority and Majority classes for\n  imbalance problems", "comments": "This work has been submitted to IEEE Transactions on Pattern Analysis\n  and Machine Intelligence (TPAMI) for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance is a substantial challenge in classifying many real-world\ncases. Synthetic over-sampling methods have been effective to improve the\nperformance of classifiers for imbalance problems. However, most synthetic\nover-sampling methods generate non-diverse synthetic instances within the\nconvex hull formed by the existing minority instances as they only concentrate\non the minority class and ignore the vast information provided by the majority\nclass. They also often do not perform well for extremely imbalanced data as the\nfewer the minority instances, the less information to generate synthetic\ninstances. Moreover, existing methods that generate synthetic instances using\ndistributional information of the majority class cannot perform effectively\nwhen the majority class has a multi-modal distribution. We propose a new method\nto generate diverse and adaptable synthetic instances using Synthetic\nOver-sampling with the Minority and Majority classes (SOMM). SOMM generates\nsynthetic instances diversely within the minority data space. It updates the\ngenerated instances adaptively to the neighbourhood including both classes.\nThus, SOMM performs well for both binary and multiclass imbalance problems. We\nexamine the performance of SOMM for binary and multiclass problems using\nbenchmark data sets for different imbalance levels. The empirical results show\nthe superiority of SOMM compared to other existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 03:39:56 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Khorshidi", "Hadi A.", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2011.04176", "submitter": "Xingyu Wu", "authors": "Xingyu Wu, Bingbing Jiang, Yan Zhong, Huanhuan Chen", "title": "Multi-label Causal Variable Discovery: Learning Common Causal Variables\n  and Label-specific Causal Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal variables in Markov boundary (MB) have been widely applied in\nextensive single-label tasks. While few researches focus on the causal variable\ndiscovery in multi-label data due to the complex causal relationships. Since\nsome variables in multi-label scenario might contain causal information about\nmultiple labels, this paper investigates the problem of multi-label causal\nvariable discovery as well as the distinguishing between common causal\nvariables shared by multiple labels and label-specific causal variables\nassociated with some single labels. Considering the multiple MBs under the\nnon-positive joint probability distribution, we explore the relationships\nbetween common causal variables and equivalent information phenomenon, and find\nthat the solutions are influenced by equivalent information following different\nmechanisms with or without existence of label causality. Analyzing these\nmechanisms, we provide the theoretical property of common causal variables,\nbased on which the discovery and distinguishing algorithm is designed to\nidentify these two types of variables. Similar to single-label problem, causal\nvariables for multiple labels also have extensive application prospects. To\ndemonstrate this, we apply the proposed causal mechanism to multi-label feature\nselection and present an interpretable algorithm, which is proved to achieve\nthe minimal redundancy and the maximum relevance. Extensive experiments\ndemonstrate the efficacy of these contributions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:01:03 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wu", "Xingyu", ""], ["Jiang", "Bingbing", ""], ["Zhong", "Yan", ""], ["Chen", "Huanhuan", ""]]}, {"id": "2011.04178", "submitter": "Mostafa Hussien", "authors": "Mostafa Hussien, Kim Khoa Nguyen, Mohamed Cheriet", "title": "PRVNet: Variational Autoencoders for Massive MIMO CSI Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a frequency division duplexing multiple-input multiple-output (FDD-MIMO)\nsystem, the user equipment (UE) send the downlink channel state information\n(CSI) to the base station for performance improvement. However, with the\ngrowing complexity of MIMO systems, this feedback becomes expensive and has a\nnegative impact on the bandwidth. Although this problem has been largely\nstudied in the literature, the noisy nature of the feedback channel is less\nconsidered. In this paper, we introduce PRVNet, a neural architecture based on\nvariational autoencoders (VAE). VAE gained large attention in many fields\n(e.g., image processing, language models, or recommendation system). However,\nit received less attention in the communication domain generally and in CSI\nfeedback problem specifically. We also introduce a different regularization\nparameter for the learning objective, which proved to be crucial for achieving\ncompetitive performance. In addition, we provide an efficient way to tune this\nparameter using KL-annealing. Empirically, we show that the proposed model\nsignificantly outperforms state-of-the-art, including two neural network\napproaches. The proposed model is also proved to be more robust against\ndifferent levels of noise.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:07:45 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hussien", "Mostafa", ""], ["Nguyen", "Kim Khoa", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "2011.04182", "submitter": "Sooyong Jang", "authors": "Sooyong Jang, Insup Lee, James Weimer", "title": "Improving Classifier Confidence using Lossy Label-Invariant\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing reliable model uncertainty estimates is imperative to enabling\nrobust decision making by autonomous agents and humans alike. While recently\nthere have been significant advances in confidence calibration for trained\nmodels, examples with poor calibration persist in most calibrated models.\nConsequently, multiple techniques have been proposed that leverage\nlabel-invariant transformations of the input (i.e., an input manifold) to\nimprove worst-case confidence calibration. However, manifold-based confidence\ncalibration techniques generally do not scale and/or require expensive\nretraining when applied to models with large input spaces (e.g., ImageNet). In\nthis paper, we present the recursive lossy label-invariant calibration (ReCal)\ntechnique that leverages label-invariant transformations of the input that\ninduce a loss of discriminatory information to recursively group (and\ncalibrate) inputs - without requiring model retraining. We show that ReCal\noutperforms other calibration methods on multiple datasets, especially, on\nlarge-scale datasets such as ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:33:48 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jang", "Sooyong", ""], ["Lee", "Insup", ""], ["Weimer", "James", ""]]}, {"id": "2011.04184", "submitter": "Takumi Aoki", "authors": "Takumi Aoki and Shunsuke Kitada and Hitoshi Iyatomi", "title": "Text Classification through Glyph-aware Disentangled Character Embedding\n  and Semantic Sub-character Augmentation", "comments": "6 pages, 3 figures, Accepted at AACL-IJCNLP 2020: Student Research\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new character-based text classification framework for\nnon-alphabetic languages, such as Chinese and Japanese. Our framework consists\nof a variational character encoder (VCE) and character-level text classifier.\nThe VCE is composed of a $\\beta$-variational auto-encoder ($\\beta$-VAE) that\nlearns the proposed glyph-aware disentangled character embedding (GDCE). Since\nour GDCE provides zero-mean unit-variance character embeddings that are\ndimensionally independent, it is applicable for our interpretable data\naugmentation, namely, semantic sub-character augmentation (SSA). In this paper,\nwe evaluated our framework using Japanese text classification tasks at the\ndocument- and sentence-level. We confirmed that our GDCE and SSA not only\nprovided embedding interpretability but also improved the classification\nperformance. Our proposal achieved a competitive result to the state-of-the-art\nmodel while also providing model interpretability. Our code is available on\nhttps://github.com/IyatomiLab/GDCE-SSA\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:38:02 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Aoki", "Takumi", ""], ["Kitada", "Shunsuke", ""], ["Iyatomi", "Hitoshi", ""]]}, {"id": "2011.04185", "submitter": "Zhengling Qi", "authors": "Zhengling Qi, Peng Liao", "title": "Robust Batch Policy Learning in Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sequential decision making problem in Markov decision process\n(MDP) where each policy is evaluated by a set containing average rewards over\ndifferent horizon lengths and with different initial distributions. Given a\npre-collected dataset of multiple trajectories generated by some behavior\npolicy, our goal is to learn a robust policy in a pre-specified policy class\nthat can maximize the smallest value of this set. Leveraging the\nsemi-parametric efficiency theory from statistics, we develop a policy learning\nmethod for estimating the defined robust optimal policy that can efficiently\nbreak the curse of horizon under mild technical conditions. A rate-optimal\nregret bound up to a logarithmic factor is established in terms of the number\nof trajectories and the number of decision points.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:41:21 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 06:04:47 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 03:58:48 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Qi", "Zhengling", ""], ["Liao", "Peng", ""]]}, {"id": "2011.04189", "submitter": "Naveed Tahir", "authors": "Naveed Tahir, Garrett E. Katz", "title": "Numerical Exploration of Training Loss Level-Sets in Deep Neural\n  Networks", "comments": "Code maintained at https://github.com/vanishinggrad/levelsets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational method for empirically characterizing the training\nloss level-sets of deep neural networks. Our method numerically constructs a\npath in parameter space that is constrained to a set with a fixed near-zero\ntraining loss. By measuring regularization functions and test loss at different\npoints within this path, we examine how different points in the parameter space\nwith the same fixed training loss compare in terms of generalization ability.\nWe also compare this method for finding regularized points with the more\ntypical method, that uses objective functions which are weighted sums of\ntraining loss and regularization terms. We apply dimensionality reduction to\nthe traversed paths in order to visualize the loss level sets in a\nwell-regularized region of parameter space. Our results provide new information\nabout the loss landscape of deep neural networks, as well as a new strategy for\nreducing test loss.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:49:33 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 01:22:39 GMT"}, {"version": "v3", "created": "Sat, 24 Apr 2021 17:57:36 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Tahir", "Naveed", ""], ["Katz", "Garrett E.", ""]]}, {"id": "2011.04194", "submitter": "Yoon-Yeong Kim", "authors": "Yoon-Yeong Kim, Kyungwoo Song, JoonHo Jang, Il-Chul Moon", "title": "LADA: Look-Ahead Data Acquisition via Augmentation for Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning effectively collects data instances for training deep\nlearning models when the labeled dataset is limited and the annotation cost is\nhigh. Besides active learning, data augmentation is also an effective technique\nto enlarge the limited amount of labeled instances. However, the potential gain\nfrom virtual instances generated by data augmentation has not been considered\nin the acquisition process of active learning yet. Looking ahead the effect of\ndata augmentation in the process of acquisition would select and generate the\ndata instances that are informative for training the model. Hence, this paper\nproposes Look-Ahead Data Acquisition via augmentation, or LADA, to integrate\ndata acquisition and data augmentation. LADA considers both 1) unlabeled data\ninstance to be selected and 2) virtual data instance to be generated by data\naugmentation, in advance of the acquisition process. Moreover, to enhance the\ninformativeness of the virtual data instances, LADA optimizes the data\naugmentation policy to maximize the predictive acquisition score, resulting in\nthe proposal of InfoMixup and InfoSTN. As LADA is a generalizable framework, we\nexperiment with the various combinations of acquisition and augmentation\nmethods. The performance of LADA shows a significant improvement over the\nrecent augmentation and acquisition baselines which were independently applied\nto the benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 05:21:14 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 14:32:39 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 02:41:16 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kim", "Yoon-Yeong", ""], ["Song", "Kyungwoo", ""], ["Jang", "JoonHo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2011.04218", "submitter": "Fengli Xu", "authors": "Fengli Xu, Quanming Yao, Pan Hui, Yong Li", "title": "Graph Neural Network with Automorphic Equivalence Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network (GNN) has recently been established as an effective\nrepresentation learning framework on graph data. However, the popular message\npassing models rely on local permutation invariant aggregate functions, which\ngives rise to the concerns about their representational power. Here, we\nintroduce the concept of automorphic equivalence to theoretically analyze GNN's\nexpressiveness in differentiating node's structural role. We show that the\nexisting message passing GNNs have limitations in learning expressive\nrepresentations. Moreover, we design a novel GNN class that leverages learnable\nautomorphic equivalence filters to explicitly differentiate the structural\nroles of each node's neighbors, and uses a squeeze-and-excitation module to\nfuse various structural information. We theoretically prove that the proposed\nmodel is expressive in terms of generating distinct representations for nodes\nwith different structural feature. Besides, we empirically validate our model\non eight real-world graph data, including social network, e-commerce\nco-purchase network and citation network, and show that it consistently\noutperforms strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 06:36:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Xu", "Fengli", ""], ["Yao", "Quanming", ""], ["Hui", "Pan", ""], ["Li", "Yong", ""]]}, {"id": "2011.04219", "submitter": "Anay Mehrotra", "authors": "Anay Mehrotra and L. Elisa Celis", "title": "Mitigating Bias in Set Selection with Noisy Protected Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subset selection algorithms are ubiquitous in AI-driven applications,\nincluding, online recruiting portals and image search engines, so it is\nimperative that these tools are not discriminatory on the basis of protected\nattributes such as gender or race. Currently, fair subset selection algorithms\nassume that the protected attributes are known as part of the dataset. However,\nprotected attributes may be noisy due to errors during data collection or if\nthey are imputed (as is often the case in real-world settings). While a wide\nbody of work addresses the effect of noise on the performance of machine\nlearning algorithms, its effect on fairness remains largely unexamined. We find\nthat in the presence of noisy protected attributes, in attempting to increase\nfairness without considering noise, one can, in fact, decrease the fairness of\nthe result!\n  Towards addressing this, we consider an existing noise model in which there\nis probabilistic information about the protected attributes (e.g., [58, 34, 20,\n46]), and ask is fair selection possible under noisy conditions? We formulate a\n``denoised'' selection problem which functions for a large class of fairness\nmetrics; given the desired fairness goal, the solution to the denoised problem\nviolates the goal by at most a small multiplicative amount with high\nprobability. Although this denoised problem turns out to be NP-hard, we give a\nlinear-programming based approximation algorithm for it. We evaluate this\napproach on both synthetic and real-world datasets. Our empirical results show\nthat this approach can produce subsets which significantly improve the fairness\nmetrics despite the presence of noisy protected attributes, and, compared to\nprior noise-oblivious approaches, has better Pareto-tradeoffs between utility\nand fairness.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 06:45:15 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 17:56:05 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mehrotra", "Anay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2011.04221", "submitter": "Dishant Goyal", "authors": "Anup Bhattacharya, Dishant Goyal, Ragesh Jaiswal", "title": "Hardness of Approximation of Euclidean $k$-Median", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CG cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean $k$-median problem is defined in the following manner: given a\nset $\\mathcal{X}$ of $n$ points in $\\mathbb{R}^{d}$, and an integer $k$, find a\nset $C \\subset \\mathbb{R}^{d}$ of $k$ points (called centers) such that the\ncost function $\\Phi(C,\\mathcal{X}) \\equiv \\sum_{x \\in \\mathcal{X}} \\min_{c \\in\nC} \\|x-c\\|_{2}$ is minimized. The Euclidean $k$-means problem is defined\nsimilarly by replacing the distance with squared distance in the cost function.\nVarious hardness of approximation results are known for the Euclidean $k$-means\nproblem. However, no hardness of approximation results were known for the\nEuclidean $k$-median problem. In this work, assuming the unique games\nconjecture (UGC), we provide the first hardness of approximation result for the\nEuclidean $k$-median problem.\n  Furthermore, we study the hardness of approximation for the Euclidean\n$k$-means/$k$-median problems in the bi-criteria setting where an algorithm is\nallowed to choose more than $k$ centers. That is, bi-criteria approximation\nalgorithms are allowed to output $\\beta k$ centers (for constant $\\beta>1$) and\nthe approximation ratio is computed with respect to the optimal\n$k$-means/$k$-median cost. In this setting, we show the first hardness of\napproximation result for the Euclidean $k$-median problem for any $\\beta <\n1.015$, assuming UGC. We also show a similar bi-criteria hardness of\napproximation result for the Euclidean $k$-means problem with a stronger bound\nof $\\beta < 1.28$, again assuming UGC.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 06:50:34 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhattacharya", "Anup", ""], ["Goyal", "Dishant", ""], ["Jaiswal", "Ragesh", ""]]}, {"id": "2011.04232", "submitter": "Kamalesh Palanisamy", "authors": "Kamalesh Palanisamy, Vivek Khimani, Moin Hussain Moti, Dimitris\n  Chatzopoulos", "title": "SplitEasy: A Practical Approach for Training ML models on Mobile Devices", "comments": "7 pages, 4 figures, Accepted at the ACM HotMobile workshop", "journal-ref": null, "doi": "10.1145/3446382.3448362", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern mobile devices, although resourceful, cannot train state-of-the-art\nmachine learning models without the assistance of servers, which require access\nto, potentially, privacy-sensitive user data. Split learning has recently\nemerged as a promising technique for training complex deep learning (DL) models\non low-powered mobile devices. The core idea behind this technique is to train\nthe sensitive layers of a DL model on mobile devices while offloading the\ncomputationally intensive layers to a server. Although a lot of works have\nalready explored the effectiveness of split learning in simulated settings, a\nusable toolkit for this purpose does not exist. In this work, we highlight the\ntheoretical and technical challenges that need to be resolved to develop a\nfunctional framework that trains ML models in mobile devices without\ntransferring raw data to a server. Focusing on these challenges, we propose\nSplitEasy, a framework for training ML models on mobile devices using split\nlearning. Using the abstraction provided by SplitEasy, developers can run\nvarious DL models under split learning setting by making minimal modifications.\nWe provide a detailed explanation of SplitEasy and perform experiments with six\nstate-of-the-art neural networks. We demonstrate how SplitEasy can train models\nthat cannot be trained solely by a mobile device while incurring nearly\nconstant time per data sample.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 07:41:43 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 18:58:24 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Palanisamy", "Kamalesh", ""], ["Khimani", "Vivek", ""], ["Moti", "Moin Hussain", ""], ["Chatzopoulos", "Dimitris", ""]]}, {"id": "2011.04235", "submitter": "Lee Sael", "authors": "Jinhong Jung and Lee Sael", "title": "Fast and Accurate Pseudoinverse with Sparse Matrix Reordering and\n  Incremental Approach", "comments": null, "journal-ref": "Mach Learn (2020) as part of Special Issue of the ACML 2020\n  Journal Track", "doi": "10.1007/s10994-020-05920-5", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we compute the pseudoinverse of a sparse feature matrix efficiently\nand accurately for solving optimization problems? A pseudoinverse is a\ngeneralization of a matrix inverse, which has been extensively utilized as a\nfundamental building block for solving linear systems in machine learning.\nHowever, an approximate computation, let alone an exact computation, of\npseudoinverse is very time-consuming due to its demanding time complexity,\nwhich limits it from being applied to large data. In this paper, we propose\nFastPI (Fast PseudoInverse), a novel incremental singular value decomposition\n(SVD) based pseudoinverse method for sparse matrices. Based on the observation\nthat many real-world feature matrices are sparse and highly skewed, FastPI\nreorders and divides the feature matrix and incrementally computes low-rank SVD\nfrom the divided components. To show the efficacy of proposed FastPI, we apply\nthem in real-world multi-label linear regression problems. Through extensive\nexperiments, we demonstrate that FastPI computes the pseudoinverse faster than\nother approximate methods without loss of accuracy. %and uses much less memory\ncompared to full-rank SVD based approach. Results imply that our method\nefficiently computes the low-rank pseudoinverse of a large and sparse matrix\nthat other existing methods cannot handle with limited time and space.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 07:47:10 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jung", "Jinhong", ""], ["Sael", "Lee", ""]]}, {"id": "2011.04250", "submitter": "Yu Wang", "authors": "Yu Wang, Shu Jiang, Weiman Lin, Yu Cao, Longtao Lin, Jiangtao Hu,\n  Jinghao Miao and Qi Luo", "title": "A Learning-Based Tune-Free Control Framework for Large Scale Autonomous\n  Driving System Deployment", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the design of a tune-free (human-out-of-the-loop\nparameter tuning) control framework, aiming at accelerating large scale\nautonomous driving system deployed on various vehicles and driving\nenvironments. The framework consists of three machine-learning-based\nprocedures, which jointly automate the control parameter tuning for autonomous\ndriving, including: a learning-based dynamic modeling procedure, to enable the\ncontrol-in-the-loop simulation with highly accurate vehicle dynamics for\nparameter tuning; a learning-based open-loop mapping procedure, to solve the\nfeedforward control parameters tuning; and more significantly, a\nBayesian-optimization-based closed-loop parameter tuning procedure, to\nautomatically tune feedback control (PID, LQR, MRAC, MPC, etc.) parameters in\nsimulation environment. The paper shows an improvement in control performance\nwith a significant increase in parameter tuning efficiency, in both simulation\nand road tests. This framework has been validated on different vehicles in US\nand China.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 08:54:36 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Wang", "Yu", ""], ["Jiang", "Shu", ""], ["Lin", "Weiman", ""], ["Cao", "Yu", ""], ["Lin", "Longtao", ""], ["Hu", "Jiangtao", ""], ["Miao", "Jinghao", ""], ["Luo", "Qi", ""]]}, {"id": "2011.04251", "submitter": "Xiaobai Ma Mr.", "authors": "Xiaobai Ma, Jiachen Li, Mykel J. Kochenderfer, David Isele, Kikuo\n  Fujimura", "title": "Reinforcement Learning for Autonomous Driving with Latent State\n  Inference and Spatial-Temporal Relationships", "comments": "ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) provides a promising way for learning\nnavigation in complex autonomous driving scenarios. However, identifying the\nsubtle cues that can indicate drastically different outcomes remains an open\nproblem with designing autonomous systems that operate in human environments.\nIn this work, we show that explicitly inferring the latent state and encoding\nspatial-temporal relationships in a reinforcement learning framework can help\naddress this difficulty. We encode prior knowledge on the latent states of\nother drivers through a framework that combines the reinforcement learner with\na supervised learner. In addition, we model the influence passing between\ndifferent vehicles through graph neural networks (GNNs). The proposed framework\nsignificantly improves performance in the context of navigating T-intersections\ncompared with state-of-the-art baseline approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 08:55:12 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 17:33:45 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Ma", "Xiaobai", ""], ["Li", "Jiachen", ""], ["Kochenderfer", "Mykel J.", ""], ["Isele", "David", ""], ["Fujimura", "Kikuo", ""]]}, {"id": "2011.04254", "submitter": "Wei Chen", "authors": "Xiao Gong, Xi Chen, Wei Chen", "title": "Enhanced Few-shot Learning for Intrusion Detection in Railway Video\n  Surveillance", "comments": "11 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video surveillance is gaining increasing popularity to assist in railway\nintrusion detection in recent years. However, efficient and accurate intrusion\ndetection remains a challenging issue due to: (a) limited sample number: only\nsmall sample size (or portion) of intrusive video frames is available; (b) low\ninter-scene dissimilarity: various railway track area scenes are captured by\ncameras installed in different landforms; (c) high intra-scene similarity: the\nvideo frames captured by an individual camera share a same backgound. In this\npaper, an efficient few-shot learning solution is developed to address the\nabove issues. In particular, an enhanced model-agnostic meta-learner is trained\nusing both the original video frames and segmented masks of track area\nextracted from the video. Moreover, theoretical analysis and engineering\nsolutions are provided to cope with the highly similar video frames in the\nmeta-model training phase. The proposed method is tested on realistic railway\nvideo dataset. Numerical results show that the enhanced meta-learner\nsuccessfully adapts unseen scene with only few newly collected video frame\nsamples, and its intrusion detection accuracy outperforms that of the standard\nrandomly initialized supervised learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 08:59:15 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Gong", "Xiao", ""], ["Chen", "Xi", ""], ["Chen", "Wei", ""]]}, {"id": "2011.04267", "submitter": "Claudio Michaelis", "authors": "Claudio Michaelis, Matthias Bethge, Alexander S. Ecker", "title": "Closing the Generalization Gap in One-Shot Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite substantial progress in object detection and few-shot learning,\ndetecting objects based on a single example - one-shot object detection -\nremains a challenge: trained models exhibit a substantial generalization gap,\nwhere object categories used during training are detected much more reliably\nthan novel ones. Here we show that this generalization gap can be nearly closed\nby increasing the number of object categories used during training. Our results\nshow that the models switch from memorizing individual categories to learning\nobject similarity over the category distribution, enabling strong\ngeneralization at test time. Importantly, in this regime standard methods to\nimprove object detection models like stronger backbones or longer training\nschedules also benefit novel categories, which was not the case for smaller\ndatasets like COCO. Our results suggest that the key to strong few-shot\ndetection models may not lie in sophisticated metric learning approaches, but\ninstead in scaling the number of categories. Future data annotation efforts\nshould therefore focus on wider datasets and annotate a larger number of\ncategories rather than gathering more images or instances per category.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:31:17 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Michaelis", "Claudio", ""], ["Bethge", "Matthias", ""], ["Ecker", "Alexander S.", ""]]}, {"id": "2011.04268", "submitter": "Martin Genzel", "authors": "Martin Genzel and Jan Macdonald and Maximilian M\\\"arz", "title": "Solving Inverse Problems With Deep Neural Networks -- Robustness\n  Included?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past five years, deep learning methods have become state-of-the-art in\nsolving various inverse problems. Before such approaches can find application\nin safety-critical fields, a verification of their reliability appears\nmandatory. Recent works have pointed out instabilities of deep neural networks\nfor several image reconstruction tasks. In analogy to adversarial attacks in\nclassification, it was shown that slight distortions in the input domain may\ncause severe artifacts. The present article sheds new light on this concern, by\nconducting an extensive study of the robustness of deep-learning-based\nalgorithms for solving underdetermined inverse problems. This covers compressed\nsensing with Gaussian measurements as well as image recovery from Fourier and\nRadon measurements, including a real-world scenario for magnetic resonance\nimaging (using the NYU-fastMRI dataset). Our main focus is on computing\nadversarial perturbations of the measurements that maximize the reconstruction\nerror. A distinctive feature of our approach is the quantitative and\nqualitative comparison with total-variation minimization, which serves as a\nprovably robust reference method. In contrast to previous findings, our results\nreveal that standard end-to-end network architectures are not only resilient\nagainst statistical noise, but also against adversarial perturbations. All\nconsidered networks are trained by common deep learning techniques, without\nsophisticated defense strategies.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:33:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Genzel", "Martin", ""], ["Macdonald", "Jan", ""], ["M\u00e4rz", "Maximilian", ""]]}, {"id": "2011.04272", "submitter": "Behrouz Azimian", "authors": "Behrouz Azimian, Reetam Sen Biswas, Anamitra Pal, Lang Tong", "title": "Time Synchronized State Estimation for Incompletely Observed\n  Distribution Systems Using Deep Learning Considering Realistic Measurement\n  Noise", "comments": "5 pages, 5 figures, 2021 IEEE Power and Energy Society General\n  Meeting (PES GM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-synchronized state estimation is a challenge for distribution systems\nbecause of limited real-time observability. This paper addresses this challenge\nby formulating a deep learning (DL)-based approach to perform unbalanced\nthree-phase distribution system state estimation (DSSE). Initially, a\ndata-driven approach for judicious measurement selection to facilitate reliable\nstate estimation is provided. Then, a deep neural network (DNN) is trained to\nperform DSSE for systems that are incompletely observed by synchrophasor\nmeasurement devices (SMDs). Robustness of the proposed methodology is\ndemonstrated by considering realistic measurement error models for SMDs. A\ncomparative study of the DNN-based DSSE with classical linear state estimation\nindicates that the DL-based approach gives better accuracy with a significantly\nsmaller number of SMDs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:45:30 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 19:15:26 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Azimian", "Behrouz", ""], ["Biswas", "Reetam Sen", ""], ["Pal", "Anamitra", ""], ["Tong", "Lang", ""]]}, {"id": "2011.04275", "submitter": "Angelica Sofia Valeriani", "authors": "Angelica Sofia Valeriani", "title": "Runtime Performances Benchmark for Knowledge Graph Embedding Methods", "comments": "arXiv admin note: text overlap with arXiv:1903.11406,\n  arXiv:2002.00819 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper wants to focus on providing a characterization of the runtime\nperformances of state-of-the-art implementations of KGE alghoritms, in terms of\nmemory footprint and execution time. Despite the rapidly growing interest in\nKGE methods, so far little attention has been devoted to their comparison and\nevaluation; in particular, previous work mainly focused on performance in terms\nof accuracy in specific tasks, such as link prediction. To this extent, a\nframework is proposed for evaluating available KGE implementations against\ngraphs with different properties, with a particular focus on the effectiveness\nof the adopted optimization strategies. Graphs and models have been trained\nleveraging different architectures, in order to enlighten features and\nproperties of both models and the architectures they have been trained on. Some\nresults enlightened with experiments in this document are the fact that\nmultithreading is efficient, but benefit deacreases as the number of threads\ngrows in case of CPU. GPU proves to be the best architecture for the given\ntask, even if CPU with some vectorized instructions still behaves well.\nFinally, RAM utilization for the loading of the graph never changes between\ndifferent architectures and depends only on the type of graph, not on the\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 21:58:11 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Valeriani", "Angelica Sofia", ""]]}, {"id": "2011.04282", "submitter": "Mete Tuluhan Akbulut", "authors": "M.Tuluhan Akbulut, Utku Bozdogan, Ahmet Tekden and Emre Ugur", "title": "Reward Conditioned Neural Movement Primitives for Population Based\n  Variational Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The aim of this paper is to study the reward based policy exploration problem\nin a supervised learning approach and enable robots to form complex movement\ntrajectories in challenging reward settings and search spaces. For this, the\nexperience of the robot, which can be bootstrapped from demonstrated\ntrajectories, is used to train a novel Neural Processes-based deep network that\nsamples from its latent space and generates the required trajectories given\ndesired rewards. Our framework can generate progressively improved trajectories\nby sampling them from high reward landscapes, increasing the reward gradually.\nVariational inference is used to create a stochastic latent space to sample\nvarying trajectories in generating population of trajectories given target\nrewards. We benefit from Evolutionary Strategies and propose a novel crossover\noperation, which is applied in the self-organized latent space of the\nindividual policies, allowing blending of the individuals that might address\ndifferent factors in the reward function. Using a number of tasks that require\nsequential reaching to multiple points or passing through gaps between objects,\nwe showed that our method provides stable learning progress and significant\nsample efficiency compared to a number of state-of-the-art robotic\nreinforcement learning methods. Finally, we show the real-world suitability of\nour method through real robot execution involving obstacle avoidance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:53:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Akbulut", "M. Tuluhan", ""], ["Bozdogan", "Utku", ""], ["Tekden", "Ahmet", ""], ["Ugur", "Emre", ""]]}, {"id": "2011.04292", "submitter": "Ryandhimas Zezario", "authors": "Ryandhimas E. Zezario, Szu-Wei Fu, Chiou-Shann Fuh, Yu Tsao, Hsin-Min\n  Wang", "title": "STOI-Net: A Deep Learning based Non-Intrusive Speech Intelligibility\n  Assessment Model", "comments": "Accepted in APSIPA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The calculation of most objective speech intelligibility assessment metrics\nrequires clean speech as a reference. Such a requirement may limit the\napplicability of these metrics in real-world scenarios. To overcome this\nlimitation, we propose a deep learning-based non-intrusive speech\nintelligibility assessment model, namely STOI-Net. The input and output of\nSTOI-Net are speech spectral features and predicted STOI scores, respectively.\nThe model is formed by the combination of a convolutional neural network and\nbidirectional long short-term memory (CNN-BLSTM) architecture with a\nmultiplicative attention mechanism. Experimental results show that the STOI\nscore estimated by STOI-Net has a good correlation with the actual STOI score\nwhen tested with noisy and enhanced speech utterances. The correlation values\nare 0.97 and 0.83, respectively, for the seen test condition (the test speakers\nand noise types are involved in the training set) and the unseen test condition\n(the test speakers and noise types are not involved in the training set). The\nresults confirm the capability of STOI-Net to accurately predict the STOI\nscores without referring to clean speech.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 09:57:10 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zezario", "Ryandhimas E.", ""], ["Fu", "Szu-Wei", ""], ["Fuh", "Chiou-Shann", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "2011.04297", "submitter": "Gurunath Reddy Madhumani", "authors": "Soumava Paul, Gurunath Reddy M, K Sreenivasa Rao and Partha Pratim Das", "title": "Knowledge Distillation for Singing Voice Detection", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Singing Voice Detection (SVD) has been an active area of research in music\ninformation retrieval (MIR). Currently, two deep neural network-based methods,\none based on CNN and the other on RNN, exist in literature that learn optimized\nfeatures for the voice detection (VD) task and achieve state-of-the-art\nperformance on common datasets. Both these models have a huge number of\nparameters (1.4M for CNN and 65.7K for RNN) and hence not suitable for\ndeployment on devices like smartphones or embedded sensors with limited\ncapacity in terms of memory and computation power. The most popular method to\naddress this issue is known as knowledge distillation in deep learning\nliterature (in addition to model compression) where a large pretrained network\nknown as the teacher is used to train a smaller student network. However, to\nthe best of our knowledge, such methods have not been explored yet in the\ndomain of SVD. In this paper, efforts have been made to investigate this issue\nusing both conventional as well as ensemble knowledge distillation techniques.\nThrough extensive experimentation on the publicly available Jamendo dataset, we\nshow that, not only it's possible to achieve comparable accuracies with far\nsmaller models (upto 1000x smaller in terms of parameters), but fascinatingly,\nin some cases, smaller models trained with distillation, even surpass the\ncurrent state-of-the-art models on voice detection performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:14:37 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Paul", "Soumava", ""], ["M", "Gurunath Reddy", ""], ["Rao", "K Sreenivasa", ""], ["Das", "Partha Pratim", ""]]}, {"id": "2011.04298", "submitter": "Sandrine P\\'ech\\'e", "authors": "Sandrine Peche and Vianney Perchet", "title": "Robustness of Community Detection to Random Geometric Perturbations", "comments": "NeurIPS-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the stochastic block model where connection between vertices is\nperturbed by some latent (and unobserved) random geometric graph. The objective\nis to prove that spectral methods are robust to this type of noise, even if\nthey are agnostic to the presence (or not) of the random graph. We provide\nexplicit regimes where the second eigenvector of the adjacency matrix is highly\ncorrelated to the true community vector (and therefore when weak/exact recovery\nis possible). This is possible thanks to a detailed analysis of the spectrum of\nthe latent random graph, of its own interest.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:15:40 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Peche", "Sandrine", ""], ["Perchet", "Vianney", ""]]}, {"id": "2011.04299", "submitter": "Shareef Babu Kalluri", "authors": "Kotra Venkata Sai Ritwik, Shareef Babu Kalluri, Deepu Vijayasenan", "title": "COVID-19 Patient Detection from Telephone Quality Speech Data", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we try to investigate the presence of cues about the COVID-19\ndisease in the speech data. We use an approach that is similar to speaker\nrecognition. Each sentence is represented as super vectors of short term Mel\nfilter bank features for each phoneme. These features are used to learn a\ntwo-class classifier to separate the COVID-19 speech from normal. Experiments\non a small dataset collected from YouTube videos show that an SVM classifier on\nthis dataset is able to achieve an accuracy of 88.6% and an F1-Score of 92.7%.\nFurther investigation reveals that some phone classes, such as nasals, stops,\nand mid vowels can distinguish the two classes better than the others.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:16:08 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ritwik", "Kotra Venkata Sai", ""], ["Kalluri", "Shareef Babu", ""], ["Vijayasenan", "Deepu", ""]]}, {"id": "2011.04312", "submitter": "Vladimir Boza", "authors": "Peter Pere\\v{s}\\'ini, Vladim\\'ir Bo\\v{z}a, Bro\\v{n}a Brejov\\'a,\n  Tom\\'a\\v{s} Vina\\v{r}", "title": "Nanopore Base Calling on the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a new base caller DeepNano-coral for nanopore sequencing, which\nis optimized to run on the Coral Edge Tensor Processing Unit, a small\nUSB-attached hardware accelerator. To achieve this goal, we have designed new\nversions of two key components used in convolutional neural networks for speech\nrecognition and base calling. In our components, we propose a new way of\nfactorization of a full convolution into smaller operations, which decreases\nmemory access operations, memory access being a bottleneck on this device.\nDeepNano-coral achieves real-time base calling during sequencing with the\naccuracy slightly better than the fast mode of the Guppy base caller and is\nextremely energy efficient, using only 10W of power. Availability:\nhttps://github.com/fmfi-compbio/coral-basecaller\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:36:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Pere\u0161\u00edni", "Peter", ""], ["Bo\u017ea", "Vladim\u00edr", ""], ["Brejov\u00e1", "Bro\u0148a", ""], ["Vina\u0159", "Tom\u00e1\u0161", ""]]}, {"id": "2011.04315", "submitter": "Elias Raninen", "authors": "Elias Raninen and Esa Ollila", "title": "Coupled regularized sample covariance matrix estimator for multiple\n  classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of covariance matrices of multiple classes with limited\ntraining data is a difficult problem. The sample covariance matrix (SCM) is\nknown to perform poorly when the number of variables is large compared to the\navailable number of samples. In order to reduce the mean squared error (MSE) of\nthe SCM, regularized (shrinkage) SCM estimators are often used. In this work,\nwe consider regularized SCM (RSCM) estimators for multiclass problems that\ncouple together two different target matrices for regularization: the pooled\n(average) SCM of the classes and the scaled identity matrix. Regularization\ntoward the pooled SCM is beneficial when the population covariances are\nsimilar, whereas regularization toward the identity matrix guarantees that the\nestimators are positive definite. We derive the MSE optimal tuning parameters\nfor the estimators as well as propose a method for their estimation under the\nassumption that the class populations follow (unspecified) elliptical\ndistributions with finite fourth-order moments. The MSE performance of the\nproposed coupled RSCMs are evaluated with simulations and in a regularized\ndiscriminant analysis (RDA) classification set-up on real data. The results\nbased on three different real data sets indicate comparable performance to\ncross-validation but with a significant speed-up in computation time.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:39:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Raninen", "Elias", ""], ["Ollila", "Esa", ""]]}, {"id": "2011.04317", "submitter": "Pooja Gupta", "authors": "Pooja Gupta, Jyoti Maggu, Angshul Majumdar, Emilie Chouzenoux,\n  Giovanni Chierchia", "title": "ConFuse: Convolutional Transform Learning Fusion Framework For\n  Multi-Channel Data Analysis", "comments": "Accepted at EUSIPCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of analyzing multi-channel time series data\n%. In this paper, we by proposing an unsupervised fusion framework based on\n%the recently proposed convolutional transform learning. Each channel is\nprocessed by a separate 1D convolutional transform; the output of all the\nchannels are fused by a fully connected layer of transform learning. The\ntraining procedure takes advantage of the proximal interpretation of activation\nfunctions. We apply the developed framework to multi-channel financial data for\nstock forecasting and trading. We compare our proposed formulation with\nbenchmark deep time series analysis networks. The results show that our method\nyields considerably better results than those compared against.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:41:28 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Gupta", "Pooja", ""], ["Maggu", "Jyoti", ""], ["Majumdar", "Angshul", ""], ["Chouzenoux", "Emilie", ""], ["Chierchia", "Giovanni", ""]]}, {"id": "2011.04328", "submitter": "Paul Schwerdtner", "authors": "Paul Schwerdtner, Florens Gre{\\ss}ner, Nikhil Kapoor, Felix Assion,\n  Ren\\'e Sass, Wiebke G\\\"unther, Fabian H\\\"uger, and Peter Schlicht", "title": "Risk Assessment for Machine Learning Models", "comments": "8 pages, 5 figures, conference workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a framework for assessing the risk associated with\ndeploying a machine learning model in a specified environment. For that we\ncarry over the risk definition from decision theory to machine learning. We\ndevelop and implement a method that allows to define deployment scenarios, test\nthe machine learning model under the conditions specified in each scenario, and\nestimate the damage associated with the output of the machine learning model\nunder test. Using the likelihood of each scenario together with the estimated\ndamage we define \\emph{key risk indicators} of a machine learning model.\n  The definition of scenarios and weighting by their likelihood allows for\nstandardized risk assessment in machine learning throughout multiple domains of\napplication. In particular, in our framework, the robustness of a machine\nlearning model to random input corruptions, distributional shifts caused by a\nchanging environment, and adversarial perturbations can be assessed.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:50:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Schwerdtner", "Paul", ""], ["Gre\u00dfner", "Florens", ""], ["Kapoor", "Nikhil", ""], ["Assion", "Felix", ""], ["Sass", "Ren\u00e9", ""], ["G\u00fcnther", "Wiebke", ""], ["H\u00fcger", "Fabian", ""], ["Schlicht", "Peter", ""]]}, {"id": "2011.04336", "submitter": "Gert-Jan Both", "authors": "Gert-Jan Both, Gijs Vermarien, Remy Kusters", "title": "Sparsely constrained neural networks for model discovery of PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse regression on a library of candidate features has developed as the\nprime method to discover the partial differential equation underlying a\nspatio-temporal data-set. These features consist of higher order derivatives,\nlimiting model discovery to densely sampled data-sets with low noise. Neural\nnetwork-based approaches circumvent this limit by constructing a surrogate\nmodel of the data, but have to date ignored advances in sparse regression\nalgorithms. In this paper we present a modular framework that dynamically\ndetermines the sparsity pattern of a deep-learning based surrogate using any\nsparse regression technique. Using our new approach, we introduce a new\nconstraint on the neural network and show how a different network architecture\nand sparsity estimator improve model discovery accuracy and convergence on\nseveral benchmark examples. Our framework is available at\n\\url{https://github.com/PhIMaL/DeePyMoD}\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:02:40 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 12:23:38 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Both", "Gert-Jan", ""], ["Vermarien", "Gijs", ""], ["Kusters", "Remy", ""]]}, {"id": "2011.04337", "submitter": "Pooja Gupta", "authors": "Pooja Gupta, Jyoti Maggu, Angshul Majumdar, Emilie Chouzenoux,\n  Giovanni Chierchia", "title": "DeConFuse : A Deep Convolutional Transform based Unsupervised Fusion\n  Framework", "comments": "Accepted at EURASIP JASP 2020", "journal-ref": null, "doi": "10.1186/s13634-020-00684-5", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes an unsupervised fusion framework based on deep\nconvolutional transform learning. The great learning ability of convolutional\nfilters for data analysis is well acknowledged. The success of convolutive\nfeatures owes to convolutional neural network (CNN). However, CNN cannot\nperform learning tasks in an unsupervised fashion. In a recent work, we show\nthat such shortcoming can be addressed by adopting a convolutional transform\nlearning (CTL) approach, where convolutional filters are learnt in an\nunsupervised fashion. The present paper aims at (i) proposing a deep version of\nCTL; (ii) proposing an unsupervised fusion formulation taking advantage of the\nproposed deep CTL representation; (iii) developing a mathematically sounded\noptimization strategy for performing the learning task. We apply the proposed\ntechnique, named DeConFuse, on the problem of stock forecasting and trading.\nComparison with state-of-the-art methods (based on CNN and long short-term\nmemory network) shows the superiority of our method for performing a reliable\nfeature extraction.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:04:09 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Gupta", "Pooja", ""], ["Maggu", "Jyoti", ""], ["Majumdar", "Angshul", ""], ["Chouzenoux", "Emilie", ""], ["Chierchia", "Giovanni", ""]]}, {"id": "2011.04345", "submitter": "Tamara AlShammari", "authors": "Tamara Alshammari and Sumudu Samarakoon and Anis Elgabli and Mehdi\n  Bennis", "title": "BayGo: Joint Bayesian Learning and Information-Aware Graph Optimization", "comments": "6 pages, 5 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article deals with the problem of distributed machine learning, in which\nagents update their models based on their local datasets, and aggregate the\nupdated models collaboratively and in a fully decentralized manner. In this\npaper, we tackle the problem of information heterogeneity arising in\nmulti-agent networks where the placement of informative agents plays a crucial\nrole in the learning dynamics. Specifically, we propose BayGo, a novel fully\ndecentralized joint Bayesian learning and graph optimization framework with\nproven fast convergence over a sparse graph. Under our framework, agents are\nable to learn and communicate with the most informative agent to their own\nlearning. Unlike prior works, our framework assumes no prior knowledge of the\ndata distribution across agents nor does it assume any knowledge of the true\nparameter of the system. The proposed alternating minimization based framework\nensures global connectivity in a fully decentralized way while minimizing the\nnumber of communication links. We theoretically show that by optimizing the\nproposed objective function, the estimation error of the posterior probability\ndistribution decreases exponentially at each iteration. Via extensive\nsimulations, we show that our framework achieves faster convergence and higher\naccuracy compared to fully-connected and star topology graphs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:16:55 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 19:47:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Alshammari", "Tamara", ""], ["Samarakoon", "Sumudu", ""], ["Elgabli", "Anis", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2011.04348", "submitter": "Stefano M. Iacus", "authors": "Marcello Carammia, Stefano Maria Iacus, Teddy Wilkin", "title": "Forecasting asylum-related migration flows with machine learning and\n  data at scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effects of the so-called \"refugee crisis\" of 2015-16 continue to dominate\nthe political agenda in Europe. Migration flows were sudden and unexpected,\nleaving governments unprepared and exposing significant shortcomings in the\nfield of migration forecasting. Migration is a complex system typified by\nepisodic variation, underpinned by causal factors that are interacting, highly\ncontext dependent and short-lived. Correspondingly, migration monitoring relies\non scattered data, while approaches to forecasting focus on specific migration\nflows and often have inconsistent results that are difficult to generalise at\nthe regional or global levels.\n  Here we show that adaptive machine learning algorithms that integrate\nofficial statistics and non-traditional data sources at scale can effectively\nforecast asylum-related migration flows. We focus on asylum applications lodged\nin countries of the European Union (EU) by nationals of all countries of origin\nworldwide; the same approach can be applied in any context provided adequate\nmigration or asylum data are available.\n  We exploit three tiers of data - geolocated events and internet searches in\ncountries of origin, detections of irregular crossings at the EU border, and\nasylum recognition rates in countries of destination - to effectively forecast\nindividual asylum-migration flows up to four weeks ahead with high accuracy.\nUniquely, our approach a) monitors potential drivers of migration in countries\nof origin to detect changes early onset; b) models individual\ncountry-to-country migration flows separately and on moving time windows; c)\nestimates the effects of individual drivers, including lagged effects; d)\nprovides forecasts of asylum applications up to four weeks ahead; e) assesses\nhow patterns of drivers shift over time to describe the functioning and change\nof migration systems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:31:17 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 05:42:43 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 13:19:46 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Carammia", "Marcello", ""], ["Iacus", "Stefano Maria", ""], ["Wilkin", "Teddy", ""]]}, {"id": "2011.04359", "submitter": "Shrishti Saha Shetu", "authors": "Shrishti Saha Shetu, Soumitro Chakrabarty and Emanu\\\"el A. P. Habets", "title": "An Empirical Study of Visual Features for DNN based Audio-Visual Speech\n  Enhancement in Multi-talker Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-visual speech enhancement (AVSE) methods use both audio and visual\nfeatures for the task of speech enhancement and the use of visual features has\nbeen shown to be particularly effective in multi-speaker scenarios. In the\nmajority of deep neural network (DNN) based AVSE methods, the audio and visual\ndata are first processed separately using different sub-networks, and then the\nlearned features are fused to utilize the information from both modalities.\nThere have been various studies on suitable audio input features and network\narchitectures, however, to the best of our knowledge, there is no published\nstudy that has investigated which visual features are best suited for this\nspecific task. In this work, we perform an empirical study of the most commonly\nused visual features for DNN based AVSE, the pre-processing requirements for\neach of these features, and investigate their influence on the performance. Our\nstudy shows that despite the overall better performance of embedding-based\nfeatures, their computationally intensive pre-processing make their use\ndifficult in low resource systems. For such systems, optical flow or raw\npixels-based features might be better suited.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:48:14 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Shetu", "Shrishti Saha", ""], ["Chakrabarty", "Soumitro", ""], ["Habets", "Emanu\u00ebl A. P.", ""]]}, {"id": "2011.04364", "submitter": "Pooja Gupta", "authors": "Pooja Gupta, Angshul Majumdar, Emilie Chouzenoux, Giovanni Chierchia", "title": "SuperDeConFuse: A Supervised Deep Convolutional Transform based Fusion\n  Framework for Financial Trading Systems", "comments": "Accepted in Elsevier Expert Systems With Applications 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a supervised multi-channel time-series learning framework\nfor financial stock trading. Although many deep learning models have recently\nbeen proposed in this domain, most of them treat the stock trading time-series\ndata as 2-D image data, whereas its true nature is 1-D time-series data. Since\nthe stock trading systems are multi-channel data, many existing techniques\ntreating them as 1-D time-series data are not suggestive of any technique to\neffectively fusion the information carried by the multiple channels. To\ncontribute towards both of these shortcomings, we propose an end-to-end\nsupervised learning framework inspired by the previously established\n(unsupervised) convolution transform learning framework. Our approach consists\nof processing the data channels through separate 1-D convolution layers, then\nfusing the outputs with a series of fully-connected layers, and finally\napplying a softmax classification layer. The peculiarity of our framework -\nSuperDeConFuse (SDCF), is that we remove the nonlinear activation located\nbetween the multi-channel convolution layers and the fully-connected layers, as\nwell as the one located between the latter and the output layer. We compensate\nfor this removal by introducing a suitable regularization on the aforementioned\nlayer outputs and filters during the training phase. Specifically, we apply a\nlogarithm determinant regularization on the layer filters to break symmetry and\nforce diversity in the learnt transforms, whereas we enforce the non-negativity\nconstraint on the layer outputs to mitigate the issue of dead neurons. This\nresults in the effective learning of a richer set of features and filters with\nrespect to a standard convolutional neural network. Numerical experiments\nconfirm that the proposed model yields considerably better results than\nstate-of-the-art deep learning techniques for real-world problem of stock\ntrading.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 11:58:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Gupta", "Pooja", ""], ["Majumdar", "Angshul", ""], ["Chouzenoux", "Emilie", ""], ["Chierchia", "Giovanni", ""]]}, {"id": "2011.04377", "submitter": "Jingli Wang", "authors": "Huan Qing and Jingli Wang", "title": "Community Detection by Principal Components Clustering Methods", "comments": "33 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the classical Degree Corrected Stochastic Blockmodel (DCSBM) model\nfor network community detection problem, we propose two novel approaches:\nprincipal component clustering (PCC) and normalized principal component\nclustering (NPCC). Without any parameters to be estimated, the PCC method is\nsimple to be implemented. Under mild conditions, we show that PCC yields\nconsistent community detection. NPCC is designed based on the combination of\nthe PCC and the RSC method (Qin & Rohe 2013). Population analysis for NPCC\nshows that NPCC returns perfect clustering for the ideal case under DCSBM. PCC\nand NPCC is illustrated through synthetic and real-world datasets. Numerical\nresults show that NPCC provides a significant improvement compare with PCC and\nRSC. Moreover, NPCC inherits nice properties of PCC and RSC such that NPCC is\ninsensitive to the number of eigenvectors to be clustered and the choosing of\nthe tuning parameter. When dealing with two weak signal networks Simmons and\nCaltech, by considering one more eigenvectors for clustering, we provide two\nrefinements PCC+ and NPCC+ of PCC and NPCC, respectively. Both two refinements\nalgorithms provide improvement performances compared with their original\nalgorithms. Especially, NPCC+ provides satisfactory performances on Simmons and\nCaltech, with error rates of 121/1137 and 96/590, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:24:42 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 02:35:46 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.04391", "submitter": "Tadeu Ferreira", "authors": "Tadeu A. Ferreira", "title": "Reinforced Deep Markov Models With Applications in Automatic Trading", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the developments in deep generative models, we propose a\nmodel-based RL approach, coined Reinforced Deep Markov Model (RDMM), designed\nto integrate desirable properties of a reinforcement learning algorithm acting\nas an automatic trading system. The network architecture allows for the\npossibility that market dynamics are partially visible and are potentially\nmodified by the agent's actions. The RDMM filters incomplete and noisy data, to\ncreate better-behaved input data for RL planning. The policy search\noptimisation also properly accounts for state uncertainty. Due to the\ncomplexity of the RKDF model architecture, we performed ablation studies to\nunderstand the contributions of individual components of the approach better.\nTo test the financial performance of the RDMM we implement policies using\nvariants of Q-Learning, DynaQ-ARIMA and DynaQ-LSTM algorithms. The experiments\nshow that the RDMM is data-efficient and provides financial gains compared to\nthe benchmarks in the optimal execution problem. The performance improvement\nbecomes more pronounced when price dynamics are more complex, and this has been\ndemonstrated using real data sets from the limit order book of Facebook, Intel,\nVodafone and Microsoft.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:46:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Ferreira", "Tadeu A.", ""]]}, {"id": "2011.04392", "submitter": "Jingli Wang", "authors": "Huan Qing and Jingli Wang", "title": "Dual regularized Laplacian spectral clustering methods on community\n  detection", "comments": "43 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering methods are widely used for detecting clusters in\nnetworks for community detection, while a small change on the graph Laplacian\nmatrix could bring a dramatic improvement. In this paper, we propose a dual\nregularized graph Laplacian matrix and then employ it to three classical\nspectral clustering approaches under the degree-corrected stochastic block\nmodel. If the number of communities is known as $K$, we consider more than $K$\nleading eigenvectors and weight them by their corresponding eigenvalues in the\nspectral clustering procedure to improve the performance. Three improved\nspectral clustering methods are dual regularized spectral clustering (DRSC)\nmethod, dual regularized spectral clustering on Ratios-of-eigenvectors\n(DRSCORE) method, and dual regularized symmetrized Laplacian inverse matrix\n(DRSLIM) method. Theoretical analysis of DRSC and DRSLIM show that under mild\nconditions DRSC and DRSLIM yield stable consistent community detection,\nmoreover, DRSCORE returns perfect clustering under the ideal case. We compare\nthe performances of DRSC, DRSCORE and DRSLIM with several spectral methods by\nsubstantial simulated networks and eight real-world networks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 12:49:25 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.04400", "submitter": "Soumajyoti Sarkar Mr.", "authors": "Soumajyoti Sarkar", "title": "Bandits in Matching Markets: Ideas and Proposals for Peer Lending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent applications of sequential decision making in matching\nmarkets, in this paper we attempt at formulating and abstracting market designs\nfor P2P lending. We describe a paradigm to set the stage for how peer to peer\ninvestments can be conceived from a matching market perspective, especially\nwhen both borrower and lender preferences are respected. We model these\nspecialized markets as an optimization problem and consider different utilities\nfor agents on both sides of the market while also understanding the impact of\nequitable allocations to borrowers. We devise a technique based on sequential\ndecision making that allow the lenders to adjust their choices based on the\ndynamics of uncertainty from competition over time and that also impacts the\nrewards in return for their investments. Using simulated experiments we show\nthe dynamics of the regret based on the optimal borrower-lender matching and\nfind that the lender regret depends on the initial preferences set by the\nlenders which could affect their learning over decision making steps.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:12:26 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 09:49:49 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 08:14:30 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 07:46:52 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Sarkar", "Soumajyoti", ""]]}, {"id": "2011.04406", "submitter": "Bo Han", "authors": "Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, Ivor W. Tsang, James T.\n  Kwok and Masashi Sugiyama", "title": "A Survey of Label-noise Representation Learning: Past, Present and\n  Future", "comments": "The draft is kept updating; any comments and suggestions are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Classical machine learning implicitly assumes that labels of the training\ndata are sampled from a clean distribution, which can be too restrictive for\nreal-world scenarios. However, statistical-learning-based methods may not train\ndeep learning models robustly with these noisy labels. Therefore, it is urgent\nto design Label-Noise Representation Learning (LNRL) methods for robustly\ntraining deep models with noisy labels. To fully understand LNRL, we conduct a\nsurvey study. We first clarify a formal definition for LNRL from the\nperspective of machine learning. Then, via the lens of learning theory and\nempirical study, we figure out why noisy labels affect deep models'\nperformance. Based on the theoretical guidance, we categorize different LNRL\nmethods into three directions. Under this unified taxonomy, we provide a\nthorough discussion of the pros and cons of different categories. More\nimportantly, we summarize the essential components of robust LNRL, which can\nspark new directions. Lastly, we propose possible research directions within\nLNRL, such as new datasets, instance-dependent LNRL, and adversarial LNRL. We\nalso envision potential directions beyond LNRL, such as learning with\nfeature-noise, preference-noise, domain-noise, similarity-noise, graph-noise\nand demonstration-noise.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:16:02 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 07:28:12 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Han", "Bo", ""], ["Yao", "Quanming", ""], ["Liu", "Tongliang", ""], ["Niu", "Gang", ""], ["Tsang", "Ivor W.", ""], ["Kwok", "James T.", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2011.04418", "submitter": "Lijing Shao", "authors": "Heming Xia, Lijing Shao, Junjie Zhao, Zhoujian Cao", "title": "Improved deep learning techniques in gravitational-wave data analysis", "comments": "13 pages, 11 figures; accepted by PRD", "journal-ref": "Phys. Rev. D 103, 024040 (2021)", "doi": "10.1103/PhysRevD.103.024040", "report-no": null, "categories": "astro-ph.HE cs.LG gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, convolutional neural network (CNN) and other deep learning\nmodels have been gradually introduced into the area of gravitational-wave (GW)\ndata processing. Compared with the traditional matched-filtering techniques,\nCNN has significant advantages in efficiency in GW signal detection tasks. In\naddition, matched-filtering techniques are based on the template bank of the\nexisting theoretical waveform, which makes it difficult to find GW signals\nbeyond theoretical expectation. In this paper, based on the task of GW\ndetection of binary black holes, we introduce the optimization techniques of\ndeep learning, such as batch normalization and dropout, to CNN models. Detailed\nstudies of model performance are carried out. Through this study, we recommend\nto use batch normalization and dropout techniques in CNN models in GW signal\ndetection tasks. Furthermore, we investigate the generalization ability of CNN\nmodels on different parameter ranges of GW signals. We point out that CNN\nmodels are robust to the variation of the parameter range of the GW waveform.\nThis is a major advantage of deep learning models over matched-filtering\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:40:00 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 23:52:18 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Xia", "Heming", ""], ["Shao", "Lijing", ""], ["Zhao", "Junjie", ""], ["Cao", "Zhoujian", ""]]}, {"id": "2011.04419", "submitter": "Vikas Verma", "authors": "Vikas Verma, Minh-Thang Luong, Kenji Kawaguchi, Hieu Pham, Quoc V. Le", "title": "Towards Domain-Agnostic Contrastive Learning", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent success, most contrastive self-supervised learning methods are\ndomain-specific, relying heavily on data augmentation techniques that require\nknowledge about a particular domain, such as image cropping and rotation. To\novercome such limitation, we propose a novel domain-agnostic approach to\ncontrastive learning, named DACL, that is applicable to domains where\ninvariances, and thus, data augmentation techniques, are not readily available.\nKey to our approach is the use of Mixup noise to create similar and dissimilar\nexamples by mixing data samples differently either at the input or hidden-state\nlevels. To demonstrate the effectiveness of DACL, we conduct experiments across\nvarious domains such as tabular data, images, and graphs. Our results show that\nDACL not only outperforms other domain-agnostic noising methods, such as\nGaussian-noise, but also combines well with domain-specific methods, such as\nSimCLR, to improve self-supervised visual representation learning. Finally, we\ntheoretically analyze our method and show advantages over the Gaussian-noise\nbased contrastive learning approach.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:41:56 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 20:59:14 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Verma", "Vikas", ""], ["Luong", "Minh-Thang", ""], ["Kawaguchi", "Kenji", ""], ["Pham", "Hieu", ""], ["Le", "Quoc V.", ""]]}, {"id": "2011.04422", "submitter": "Alvin Lim", "authors": "Jiefeng Xu and Evren Gul and Alvin Lim", "title": "Maximizing Store Revenues using Tabu Search for Floor Space Optimization", "comments": null, "journal-ref": "International Journal of Revenue Management (IJRM), Vol. 12, No.\n  1/2, 2021", "doi": "10.1504/IJRM.2021.114969", "report-no": null, "categories": "cs.AI cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floor space optimization is a critical revenue management problem commonly\nencountered by retailers. It maximizes store revenue by optimally allocating\nfloor space to product categories which are assigned to their most appropriate\nplanograms. We formulate the problem as a connected multi-choice knapsack\nproblem with an additional global constraint and propose a tabu search based\nmeta-heuristic that exploits the multiple special neighborhood structures. We\nalso incorporate a mechanism to determine how to combine the multiple\nneighborhood moves. A candidate list strategy based on learning from prior\nsearch history is also employed to improve the search quality. The results of\ncomputational testing with a set of test problems show that our tabu search\nheuristic can solve all problems within a reasonable amount of time. Analyses\nof individual contributions of relevant components of the algorithm were\nconducted with computational experiments.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 22:42:54 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Xu", "Jiefeng", ""], ["Gul", "Evren", ""], ["Lim", "Alvin", ""]]}, {"id": "2011.04424", "submitter": "Matthew Praeger", "authors": "Matthew Praeger, Yunhui Xie, James A. Grant-Jacob, Robert W. Eason and\n  Ben Mills", "title": "Playing optical tweezers with deep reinforcement learning: in virtual,\n  physical and augmented environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning was carried out in a simulated environment to learn\ncontinuous velocity control over multiple motor axes. This was then applied to\na real-world optical tweezers experiment with the objective of moving a\nlaser-trapped microsphere to a target location whilst avoiding collisions with\nother free-moving microspheres. The concept of training a neural network in a\nvirtual environment has significant potential in the application of machine\nlearning for experimental optimization and control, as the neural network can\ndiscover optimal methods for problem solving without the risk of damage to\nequipment, and at a speed not limited by movement in the physical environment.\nAs the neural network treats both virtual and physical environments\nequivalently, we show that the network can also be applied to an augmented\nenvironment, where a virtual environment is combined with the physical\nenvironment. This technique may have the potential to unlock capabilities\nassociated with mixed and augmented reality, such as enforcing safety limits\nfor machine motion or as a method of inputting observations from additional\nsensors.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 13:49:55 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 13:07:19 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Praeger", "Matthew", ""], ["Xie", "Yunhui", ""], ["Grant-Jacob", "James A.", ""], ["Eason", "Robert W.", ""], ["Mills", "Ben", ""]]}, {"id": "2011.04426", "submitter": "Rachel Kurchin", "authors": "Rachel C. Kurchin, Eric Muckley, Lance Kavalsky, Vinay Hegde, Dhairya\n  Gandhi, Xiaoyu Sun, Matthew Johnson, Alan Edelman, James Saal, Christopher\n  Vincent Rackauckas, Bryce Meredig, Viral Shah, Venkatasubramanian Viswanathan", "title": "ACED: Accelerated Computational Electrochemical systems Discovery", "comments": "4 pages, 1 figure, accepted to NeurIPS Climate Change and AI Workshop\n  2020, updating acknowledgements and citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale electrification is vital to addressing the climate crisis, but\nmany engineering challenges remain to fully electrifying both the chemical\nindustry and transportation. In both of these areas, new electrochemical\nmaterials and systems will be critical, but developing these systems currently\nrelies heavily on computationally expensive first-principles simulations as\nwell as human-time-intensive experimental trial and error. We propose to\ndevelop an automated workflow that accelerates these computational steps by\nintroducing both automated error handling in generating the first-principles\ntraining data as well as physics-informed machine learning surrogates to\nfurther reduce computational cost. It will also have the capacity to include\nautomated experiments \"in the loop\" in order to dramatically accelerate the\noverall materials discovery pipeline.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 20:45:29 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 18:42:37 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 15:50:32 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Kurchin", "Rachel C.", ""], ["Muckley", "Eric", ""], ["Kavalsky", "Lance", ""], ["Hegde", "Vinay", ""], ["Gandhi", "Dhairya", ""], ["Sun", "Xiaoyu", ""], ["Johnson", "Matthew", ""], ["Edelman", "Alan", ""], ["Saal", "James", ""], ["Rackauckas", "Christopher Vincent", ""], ["Meredig", "Bryce", ""], ["Shah", "Viral", ""], ["Viswanathan", "Venkatasubramanian", ""]]}, {"id": "2011.04437", "submitter": "Akira Imakura", "authors": "Akira Imakura, Hiroaki Inaba, Yukihiko Okada, Tetsuya Sakurai", "title": "Interpretable collaborative data analysis on distributed data", "comments": "16 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an interpretable non-model sharing collaborative data\nanalysis method as one of the federated learning systems, which is an emerging\ntechnology to analyze distributed data. Analyzing distributed data is essential\nin many applications such as medical, financial, and manufacturing data\nanalyses due to privacy, and confidentiality concerns. In addition,\ninterpretability of the obtained model has an important role for practical\napplications of the federated learning systems. By centralizing intermediate\nrepresentations, which are individually constructed in each party, the proposed\nmethod obtains an interpretable model, achieving a collaborative analysis\nwithout revealing the individual data and learning model distributed over local\nparties. Numerical experiments indicate that the proposed method achieves\nbetter recognition performance for artificial and real-world problems than\nindividual analysis.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:59:32 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Imakura", "Akira", ""], ["Inaba", "Hiroaki", ""], ["Okada", "Yukihiko", ""], ["Sakurai", "Tetsuya", ""]]}, {"id": "2011.04446", "submitter": "Tanvirul Alam", "authors": "Tanvirul Alam, Akib Khan and Firoj Alam", "title": "Bangla Text Classification using Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification has been one of the earliest problems in NLP. Over time\nthe scope of application areas has broadened and the difficulty of dealing with\nnew areas (e.g., noisy social media content) has increased. The problem-solving\nstrategy switched from classical machine learning to deep learning algorithms.\nOne of the recent deep neural network architecture is the Transformer. Models\ndesigned with this type of network and its variants recently showed their\nsuccess in many downstream natural language processing tasks, especially for\nresource-rich languages, e.g., English. However, these models have not been\nexplored fully for Bangla text classification tasks. In this work, we fine-tune\nmultilingual transformer models for Bangla text classification tasks in\ndifferent domains, including sentiment analysis, emotion detection, news\ncategorization, and authorship attribution. We obtain the state of the art\nresults on six benchmark datasets, improving upon the previous results by 5-29%\naccuracy across different tasks.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:12:07 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Alam", "Tanvirul", ""], ["Khan", "Akib", ""], ["Alam", "Firoj", ""]]}, {"id": "2011.04447", "submitter": "Vayer Titouan", "authors": "Titouan Vayer", "title": "A contribution to Optimal Transport on incomparable spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Transport is a theory that allows to define geometrical notions of\ndistance between probability distributions and to find correspondences,\nrelationships, between sets of points. Many machine learning applications are\nderived from this theory, at the frontier between mathematics and optimization.\nThis thesis proposes to study the complex scenario in which the different data\nbelong to incomparable spaces. In particular we address the following\nquestions: how to define and apply Optimal Transport between graphs, between\nstructured data? How can it be adapted when the data are varied and not\nembedded in the same metric space? This thesis proposes a set of Optimal\nTransport tools for these different cases. An important part is notably devoted\nto the study of the Gromov-Wasserstein distance whose properties allow to\ndefine interesting transport problems on incomparable spaces. More broadly, we\nanalyze the mathematical properties of the various proposed tools, we establish\nalgorithmic solutions to compute them and we study their applicability in\nnumerous machine learning scenarii which cover, in particular, classification,\nsimplification, partitioning of structured data, as well as heterogeneous\ndomain adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:13:52 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Vayer", "Titouan", ""]]}, {"id": "2011.04451", "submitter": "Alper Ahmeto\\u{g}lu", "authors": "\\c{C}a\\u{g}la Aksoy, Alper Ahmeto\\u{g}lu, Tunga G\\\"ung\\\"or", "title": "Hierarchical Multitask Learning Approach for BERT", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that learning contextualized embeddings for words is\nbeneficial for downstream tasks. BERT is one successful example of this\napproach. It learns embeddings by solving two tasks, which are masked language\nmodel (masked LM) and the next sentence prediction (NSP). The pre-training of\nBERT can also be framed as a multitask learning problem. In this work, we adopt\nhierarchical multitask learning approaches for BERT pre-training. Pre-training\ntasks are solved at different layers instead of the last layer, and information\nfrom the NSP task is transferred to the masked LM task. Also, we propose a new\npre-training task bigram shift to encode word order information. We choose two\ndownstream tasks, one of which requires sentence-level embeddings (textual\nentailment), and the other requires contextualized embeddings of words\n(question answering). Due to computational restrictions, we use the downstream\ntask data instead of a large dataset for the pre-training to see the\nperformance of proposed models when given a restricted dataset. We test their\nperformance on several probing tasks to analyze learned embeddings. Our results\nshow that imposing a task hierarchy in pre-training improves the performance of\nembeddings.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 09:23:04 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Aksoy", "\u00c7a\u011fla", ""], ["Ahmeto\u011flu", "Alper", ""], ["G\u00fcng\u00f6r", "Tunga", ""]]}, {"id": "2011.04452", "submitter": "Eranga De Saa", "authors": "Eranga De Saa and Lochandaka Ranathunga", "title": "Comparison between ARIMA and Deep Learning Models for Temperature\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weather forecasting benefits us in various ways from farmers in cultivation\nand harvesting their crops to airlines to schedule their flights. Weather\nforecasting is a challenging task due to the chaotic nature of the atmosphere.\nTherefore lot of research attention has drawn to obtain the benefits and to\novercome the challenges of weather forecasting. This paper compares ARIMA (Auto\nRegressive Integrated Moving Average) model and deep learning models to\nforecast temperature. The deep learning model consists of one dimensional\nconvolutional layers to extract spatial features and LSTM layers to extract\ntemporal features. Both of these models are applied to hourly temperature data\nset from Szeged, Hungry. According to the experimental results deep learning\nmodel was able to perform better than the traditional ARIMA methodology.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:21:46 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["De Saa", "Eranga", ""], ["Ranathunga", "Lochandaka", ""]]}, {"id": "2011.04456", "submitter": "Wolfgang Mack", "authors": "Fabian H\\\"ubner, Wolfgang Mack, Emanu\\\"el A. P. Habets", "title": "Efficient Training Data Generation for Phase-Based DOA Estimation", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) based direction of arrival (DOA) estimation is an active\nresearch topic and currently represents the state-of-the-art. Usually, DL-based\nDOA estimators are trained with recorded data or computationally expensive\ngenerated data. Both data types require significant storage and excessive time\nto, respectively, record or generate. We propose a low complexity online data\ngeneration method to train DL models with a phase-based feature input. The data\ngeneration method models the phases of the microphone signals in the frequency\ndomain by employing a deterministic model for the direct path and a statistical\nmodel for the late reverberation of the room transfer function. By an\nevaluation using data from measured room impulse responses, we demonstrate that\na model trained with the proposed training data generation method performs\ncomparably to models trained with data generated based on the source-image\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:25:03 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["H\u00fcbner", "Fabian", ""], ["Mack", "Wolfgang", ""], ["Habets", "Emanu\u00ebl A. P.", ""]]}, {"id": "2011.04457", "submitter": "Reka Agnes Kovacs Miss", "authors": "Reka A. Kovacs, Oktay Gunluk, Raphael A. Hauser", "title": "Binary Matrix Factorisation via Column Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying discrete patterns in binary data is an important dimensionality\nreduction tool in machine learning and data mining. In this paper, we consider\nthe problem of low-rank binary matrix factorisation (BMF) under Boolean\narithmetic. Due to the NP-hardness of this problem, most previous attempts rely\non heuristic techniques. We formulate the problem as a mixed integer linear\nprogram and use a large scale optimisation technique of column generation to\nsolve it without the need of heuristic pattern mining. Our approach focuses on\naccuracy and on the provision of optimality guarantees. Experimental results on\nreal world datasets demonstrate that our proposed method is effective at\nproducing highly accurate factorisations and improves on the previously\navailable best known results for 15 out of 24 problem instances.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:27:36 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 15:17:23 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Kovacs", "Reka A.", ""], ["Gunluk", "Oktay", ""], ["Hauser", "Raphael A.", ""]]}, {"id": "2011.04468", "submitter": "Nikolaos Tsilivis", "authors": "Nikos Tsilivis, Anastasios Tsiamis, Petros Maragos", "title": "Sparse Approximate Solutions to Max-Plus Equations with Application to\n  Multivariate Convex Regression", "comments": "20 pages, 5 figures, 5 tables. Introduction revision and typos\n  correction", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.RA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the problem of finding approximate, with minimum\nsupport set, solutions to matrix max-plus equations, which we call sparse\napproximate solutions. We show how one can obtain such solutions efficiently\nand in polynomial time for any $\\ell_p$ approximation error. Based on these\nresults, we propose a novel method for piecewise-linear fitting of convex\nmultivariate functions, with optimality guarantees for the model parameters and\nan approximately minimum number of affine regions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 15:17:00 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 17:54:22 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Tsilivis", "Nikos", ""], ["Tsiamis", "Anastasios", ""], ["Maragos", "Petros", ""]]}, {"id": "2011.04475", "submitter": "Emma Rocheteau", "authors": "Emma Rocheteau, Doyoon Kim", "title": "Deep Transfer Learning for Automated Diagnosis of Skin Lesions from\n  Photographs", "comments": "Machine Learning for Mobile Health (ML4MH) Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Melanoma is not the most common form of skin cancer, but it is the most\ndeadly. Currently, the disease is diagnosed by expert dermatologists, which is\ncostly and requires timely access to medical treatment. Recent advances in deep\nlearning have the potential to improve diagnostic performance, expedite urgent\nreferrals and reduce burden on clinicians. Through smart phones, the technology\ncould reach people who would not normally have access to such healthcare\nservices, e.g. in remote parts of the world, due to financial constraints or in\n2020, COVID-19 cancellations. To this end, we have investigated various\ntransfer learning approaches by leveraging model parameters pre-trained on\nImageNet with finetuning on melanoma detection. We compare EfficientNet,\nMnasNet, MobileNet, DenseNet, SqueezeNet, ShuffleNet, GoogleNet, ResNet,\nResNeXt, VGG and a simple CNN with and without transfer learning. We find the\nmobile network, EfficientNet (with transfer learning) achieves the best mean\nperformance with an area under the receiver operating characteristic curve\n(AUROC) of 0.931$\\pm$0.005 and an area under the precision recall curve (AUPRC)\nof 0.840$\\pm$0.010. This is significantly better than general practitioners\n(0.83$\\pm$0.03 AUROC) and dermatologists (0.91$\\pm$0.02 AUROC).\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:49:40 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 21:21:36 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 14:30:04 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Rocheteau", "Emma", ""], ["Kim", "Doyoon", ""]]}, {"id": "2011.04476", "submitter": "Liya Wang", "authors": "Liya Wang, Amy Mykityshyn, Craig Johnson, Benjamin D. Marple", "title": "Deep Learning for Flight Demand and Delays Forecasting", "comments": "Paper will be submitted to AIAA aviation forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last few years have seen an increased interest in deep learning (DL) due\nto its success in applications such as computer vision, natural language\nprocessing (NLP), and self-driving cars. Inspired by this success, this paper\napplied DL to predict flight demand and delays, which have been a concern for\nairlines and the other stakeholders in the National Airspace System (NAS).\nDemand and delay prediction can be formulated as a supervised learning problem,\nwhere, given an understanding of past historical demand and delays, a deep\nlearning network can examine sequences of historic data to predict current and\nfuture sequences. With that in mind, we applied a well-known DL method,\nsequence to sequence (seq2seq), to solve the problem. Our results show that the\nseq2seq method can reduce demand prediction mean squared error (MSE) by 50%,\ncompared to two classical baseline algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:46:19 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 02:02:55 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Liya", ""], ["Mykityshyn", "Amy", ""], ["Johnson", "Craig", ""], ["Marple", "Benjamin D.", ""]]}, {"id": "2011.04483", "submitter": "Steve Hanneke", "authors": "Olivier Bousquet, Steve Hanneke, Shay Moran, Ramon van Handel, Amir\n  Yehudayoff", "title": "A Theory of Universal Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How quickly can a given class of concepts be learned from examples? It is\ncommon to measure the performance of a supervised machine learning algorithm by\nplotting its \"learning curve\", that is, the decay of the error rate as a\nfunction of the number of training examples. However, the classical theoretical\nframework for understanding learnability, the PAC model of Vapnik-Chervonenkis\nand Valiant, does not explain the behavior of learning curves: the\ndistribution-free PAC model of learning can only bound the upper envelope of\nthe learning curves over all possible data distributions. This does not match\nthe practice of machine learning, where the data source is typically fixed in\nany given scenario, while the learner may choose the number of training\nexamples on the basis of factors such as computational resources and desired\naccuracy.\n  In this paper, we study an alternative learning model that better captures\nsuch practical aspects of machine learning, but still gives rise to a complete\ntheory of the learnable in the spirit of the PAC model. More precisely, we\nconsider the problem of universal learning, which aims to understand the\nperformance of learning algorithms on every data distribution, but without\nrequiring uniformity over the distribution. The main result of this paper is a\nremarkable trichotomy: there are only three possible rates of universal\nlearning. More precisely, we show that the learning curves of any given concept\nclass decay either at an exponential, linear, or arbitrarily slow rates.\nMoreover, each of these cases is completely characterized by appropriate\ncombinatorial parameters, and we exhibit optimal learning algorithms that\nachieve the best possible rate in each case.\n  For concreteness, we consider in this paper only the realizable case, though\nanalogous results are expected to extend to more general learning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:10:32 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bousquet", "Olivier", ""], ["Hanneke", "Steve", ""], ["Moran", "Shay", ""], ["van Handel", "Ramon", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "2011.04501", "submitter": "Yitao Chen", "authors": "Yitao Chen and Deepanshu Vasal", "title": "Multi-Agent Decentralized Belief Propagation on Graphs", "comments": "16 pages. arXiv admin note: text overlap with arXiv:1109.2135,\n  arXiv:1209.1695, arXiv:1802.08757 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of interactive partially observable Markov decision\nprocesses (I-POMDPs), where the agents are located at the nodes of a\ncommunication network. Specifically, we assume a certain message type for all\nmessages. Moreover, each agent makes individual decisions based on the\ninteractive belief states, the information observed locally and the messages\nreceived from its neighbors over the network. Within this setting, the\ncollective goal of the agents is to maximize the globally averaged return over\nthe network through exchanging information with their neighbors. We propose a\ndecentralized belief propagation algorithm for the problem, and prove the\nconvergence of our algorithm. Finally we show multiple applications of our\nframework. Our work appears to be the first study of decentralized belief\npropagation algorithm for networked multi-agent I-POMDPs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 18:16:26 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 02:25:35 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Chen", "Yitao", ""], ["Vasal", "Deepanshu", ""]]}, {"id": "2011.04512", "submitter": "Dongyub Lee", "authors": "Dongyub Lee, Byeongil Ko, Myeong Cheol Shin, Taesun Whang, Daniel Lee,\n  Eun Hwa Kim, EungGyun Kim, and Jaechoon Jo", "title": "Auxiliary Sequence Labeling Tasks for Disfluency Detection", "comments": "Submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting disfluencies in spontaneous speech is an important preprocessing\nstep in natural language processing and speech recognition applications.\nExisting works for disfluency detection have focused on designing a single\nobjective only for disfluency detection, while auxiliary objectives utilizing\nlinguistic information of a word such as named entity or part-of-speech\ninformation can be effective. In this paper, we focus on detecting disfluencies\non spoken transcripts and propose a method utilizing named entity recognition\n(NER) and part-of-speech (POS) as auxiliary sequence labeling (SL) tasks for\ndisfluency detection. First, we investigate cases that utilizing linguistic\ninformation of a word can prevent mispredicting important words and can be\nhelpful for the correct detection of disfluencies. Second, we show that\ntraining a disfluency detection model with auxiliary SL tasks can improve its\nF-score in disfluency detection. Then, we analyze which auxiliary SL tasks are\ninfluential depending on baseline models. Experimental results on the widely\nused English Switchboard dataset show that our method outperforms the previous\nstate-of-the-art in disfluency detection.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 02:51:17 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 13:09:23 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lee", "Dongyub", ""], ["Ko", "Byeongil", ""], ["Shin", "Myeong Cheol", ""], ["Whang", "Taesun", ""], ["Lee", "Daniel", ""], ["Kim", "Eun Hwa", ""], ["Kim", "EungGyun", ""], ["Jo", "Jaechoon", ""]]}, {"id": "2011.04517", "submitter": "Hassan Arbabi", "authors": "Hassan Arbabi and Ioannis Kevrekidis", "title": "Particles to Partial Differential Equations Parsimoniously", "comments": null, "journal-ref": null, "doi": "10.1063/5.0037837", "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equations governing physico-chemical processes are usually known at\nmicroscopic spatial scales, yet one suspects that there exist equations, e.g.\nin the form of Partial Differential Equations (PDEs), that can explain the\nsystem evolution at much coarser, meso- or macroscopic length scales.\nDiscovering those coarse-grained effective PDEs can lead to considerable\nsavings in computation-intensive tasks like prediction or control. We propose a\nframework combining artificial neural networks with multiscale computation, in\nthe form of equation-free numerics, for efficient discovery of such macro-scale\nPDEs directly from microscopic simulations. Gathering sufficient microscopic\ndata for training neural networks can be computationally prohibitive;\nequation-free numerics enable a more parsimonious collection of training data\nby only operating in a sparse subset of the space-time domain. We also propose\nusing a data-driven approach, based on manifold learning and unnormalized\noptimal transport of distributions, to identify macro-scale dependent\nvariable(s) suitable for the data-driven discovery of said PDEs. This approach\ncan corroborate physically motivated candidate variables, or introduce new\ndata-driven variables, in terms of which the coarse-grained effective PDE can\nbe formulated. We illustrate our approach by extracting coarse-grained\nevolution equations from particle-based simulations with a priori unknown\nmacro-scale variable(s), while significantly reducing the requisite data\ncollection computational effort.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:51:24 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Arbabi", "Hassan", ""], ["Kevrekidis", "Ioannis", ""]]}, {"id": "2011.04522", "submitter": "Shen Cai", "authors": "Hui Cao, Jie Wang, Yuqi Liu, Siyu Zhang and Shen Cai", "title": "Fast Hybrid Cascade for Voxel-based 3D Object Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voxel-based 3D object classification has been frequently studied in recent\nyears. The previous methods often directly convert the classic 2D convolution\ninto a 3D form applied to an object with binary voxel representation. In this\npaper, we investigate the reason why binary voxel representation is not very\nsuitable for 3D convolution and how to simultaneously improve the performance\nboth in accuracy and speed. We show that by giving each voxel a signed distance\nvalue, the accuracy will gain about 30% promotion compared with binary voxel\nrepresentation using a two-layer fully connected network. We then propose a\nfast fully connected and convolution hybrid cascade network for voxel-based 3D\nobject classification. This threestage cascade network can divide 3D models\ninto three categories: easy, moderate and hard. Consequently, the mean\ninference time (0.3ms) can speedup about 5x and 2x compared with the\nstate-of-the-art point cloud and voxel based methods respectively, while\nachieving the highest accuracy in the latter category of methods (92%).\nExperiments with ModelNet andMNIST verify the performance of the proposed\nhybrid cascade network.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:58:33 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 12:42:00 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Cao", "Hui", ""], ["Wang", "Jie", ""], ["Liu", "Yuqi", ""], ["Zhang", "Siyu", ""], ["Cai", "Shen", ""]]}, {"id": "2011.04548", "submitter": "Ivan Girardi", "authors": "Chiara Marchiori, Douglas Dykeman, Ivan Girardi, Adam Ivankay, Kevin\n  Thandiackal, Mario Zusag, Andrea Giovannini, Daniel Karpati, Henri Saenz", "title": "Artificial Intelligence Decision Support for Medical Triage", "comments": "10 pages, 5 figures, accepted to AMIA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying state-of-the-art machine learning and natural language processing on\napproximately one million of teleconsultation records, we developed a triage\nsystem, now certified and in use at the largest European telemedicine provider.\nThe system evaluates care alternatives through interactions with patients via a\nmobile application. Reasoning on an initial set of provided symptoms, the\ntriage application generates AI-powered, personalized questions to better\ncharacterize the problem and recommends the most appropriate point of care and\ntime frame for a consultation. The underlying technology was developed to meet\nthe needs for performance, transparency, user acceptance and ease of use,\ncentral aspects to the adoption of AI-based decision support systems. Providing\nsuch remote guidance at the beginning of the chain of care has significant\npotential for improving cost efficiency, patient experience and outcomes. Being\nremote, always available and highly scalable, this service is fundamental in\nhigh demand situations, such as the current COVID-19 outbreak.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:45:01 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Marchiori", "Chiara", ""], ["Dykeman", "Douglas", ""], ["Girardi", "Ivan", ""], ["Ivankay", "Adam", ""], ["Thandiackal", "Kevin", ""], ["Zusag", "Mario", ""], ["Giovannini", "Andrea", ""], ["Karpati", "Daniel", ""], ["Saenz", "Henri", ""]]}, {"id": "2011.04555", "submitter": "Hung Vu", "authors": "Hung V. Vu, Zheyu Liu, Duy H. N. Nguyen, Robert Morawski and Tho\n  Le-Ngoc", "title": "Multi-Agent Reinforcement Learning for Joint Channel Assignment and\n  Power Allocation in Platoon-Based C-V2X Systems", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of joint channel assignment and power allocation in\nunderlaid cellular vehicular-to-everything (C-V2X) systems where multiple\nvehicle-to-infrastructure (V2I) uplinks share the time-frequency resources with\nmultiple vehicle-to-vehicle (V2V) platoons that enable groups of connected and\nautonomous vehicles to travel closely together. Due to the nature of fast\nchannel variant in vehicular environment, traditional centralized optimization\napproach relying on global channel information might not be viable in C-V2X\nsystems with large number of users. Utilizing a reinforcement learning (RL)\napproach, we propose a distributed resource allocation (RA) algorithm to\novercome this challenge. Specifically, we model the RA problem as a multi-agent\nsystem. Based solely on the local channel information, each platoon leader, who\nacts as an agent, collectively interacts with each other and accordingly\nselects the optimal combination of sub-band and power level to transmit its\nsignals. Toward this end, we utilize the double deep Q-learning algorithm to\njointly train the agents under the objectives of simultaneously maximizing the\nV2I sum-rate and satisfying the packet delivery probability of each V2V link in\na desired latency limitation. Simulation results show that our proposed\nRL-based algorithm achieves a close performance compared to that of the\nwell-known exhaustive search algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:55:09 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Vu", "Hung V.", ""], ["Liu", "Zheyu", ""], ["Nguyen", "Duy H. N.", ""], ["Morawski", "Robert", ""], ["Le-Ngoc", "Tho", ""]]}, {"id": "2011.04558", "submitter": "Francesco Sanna Passino", "authors": "Francesco Sanna Passino, Nicholas A. Heard and Patrick Rubin-Delanchy", "title": "Spectral clustering on spherical coordinates under the degree-corrected\n  stochastic blockmodel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a popular method for community detection in networks\nunder the assumption of the standard stochastic blockmodel. Taking a matrix\nrepresentation of the graph such as the adjacency matrix, the nodes are\nclustered on a low dimensional projection obtained from a truncated spectral\ndecomposition of the matrix. Estimating the number of communities and the\ndimension of the reduced latent space well is crucial for good performance of\nspectral clustering algorithms. Real-world networks, such as computer networks\nstudied in cyber-security applications, often present heterogeneous\nwithin-community degree distributions which are better addressed by the\ndegree-corrected stochastic blockmodel. A novel, model-based method is proposed\nin this article for simultaneous and automated selection of the number of\ncommunities and latent dimension for spectral clustering under the\ndegree-corrected stochastic blockmodel. The method is based on a transformation\nto spherical coordinates of the spectral embedding, and on a novel modelling\nassumption in the transformed space, which is then embedded into an existing\nmodel selection framework for estimating the number of communities and the\nlatent dimension. Results show improved performance over competing methods on\nsimulated and real-world computer network data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 16:55:38 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 11:04:22 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Passino", "Francesco Sanna", ""], ["Heard", "Nicholas A.", ""], ["Rubin-Delanchy", "Patrick", ""]]}, {"id": "2011.04573", "submitter": "Dongsheng Luo", "authors": "Dongsheng Luo, Wei Cheng, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng\n  Chen, Xiang Zhang", "title": "Parameterized Explainer for Graph Neural Network", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent progress in Graph Neural Networks (GNNs), explaining\npredictions made by GNNs remains a challenging open problem. The leading method\nindependently addresses the local explanations (i.e., important subgraph\nstructure and node features) to interpret why a GNN model makes the prediction\nfor a single instance, e.g. a node or a graph. As a result, the explanation\ngenerated is painstakingly customized for each instance. The unique explanation\ninterpreting each instance independently is not sufficient to provide a global\nunderstanding of the learned GNN model, leading to a lack of generalizability\nand hindering it from being used in the inductive setting. Besides, as it is\ndesigned for explaining a single instance, it is challenging to explain a set\nof instances naturally (e.g., graphs of a given class). In this study, we\naddress these key challenges and propose PGExplainer, a parameterized explainer\nfor GNNs. PGExplainer adopts a deep neural network to parameterize the\ngeneration process of explanations, which enables PGExplainer a natural\napproach to explaining multiple instances collectively. Compared to the\nexisting work, PGExplainer has better generalization ability and can be\nutilized in an inductive setting easily. Experiments on both synthetic and\nreal-life datasets show highly competitive performance with up to 24.7\\%\nrelative improvement in AUC on explaining graph classification over the leading\nbaseline.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:15:03 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Luo", "Dongsheng", ""], ["Cheng", "Wei", ""], ["Xu", "Dongkuan", ""], ["Yu", "Wenchao", ""], ["Zong", "Bo", ""], ["Chen", "Haifeng", ""], ["Zhang", "Xiang", ""]]}, {"id": "2011.04583", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen, Brandon Amos, Maximilian Nickel", "title": "Neural Spatio-Temporal Point Processes", "comments": null, "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of parameterizations for spatio-temporal point\nprocesses which leverage Neural ODEs as a computational method and enable\nflexible, high-fidelity models of discrete events that are localized in\ncontinuous time and space. Central to our approach is a combination of\ncontinuous-time neural networks with two novel neural architectures, i.e., Jump\nand Attentive Continuous-time Normalizing Flows. This approach allows us to\nlearn complex distributions for both the spatial and temporal domain and to\ncondition non-trivially on the observed event history. We validate our models\non data sets from a wide variety of contexts such as seismology, epidemiology,\nurban mobility, and neuroscience.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:28:23 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 18:40:42 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 00:00:23 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Amos", "Brandon", ""], ["Nickel", "Maximilian", ""]]}, {"id": "2011.04586", "submitter": "Steve Hanneke", "authors": "Steve Hanneke, Aryeh Kontorovich", "title": "Stable Sample Compression Schemes: New Applications and an Optimal SVM\n  Margin Bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a family of supervised learning algorithms based on sample\ncompression schemes that are stable, in the sense that removing points from the\ntraining set which were not selected for the compression set does not alter the\nresulting classifier. We use this technique to derive a variety of novel or\nimproved data-dependent generalization bounds for several learning algorithms.\nIn particular, we prove a new margin bound for SVM, removing a log factor. The\nnew bound is provably optimal. This resolves a long-standing open question\nabout the PAC margin bounds achievable by SVM.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:30:49 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hanneke", "Steve", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "2011.04588", "submitter": "Ankan Dutta", "authors": "Ankan Dutta and Arnab Rakshit", "title": "Geometry Perspective Of Estimating Learning Capability Of Neural\n  Networks", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper uses statistical and differential geometric motivation to acquire\nprior information about the learning capability of an artificial neural network\non a given dataset. The paper considers a broad class of neural networks with\ngeneralized architecture performing simple least square regression with\nstochastic gradient descent (SGD). The system characteristics at two critical\nepochs in the learning trajectory are analyzed. During some epochs of the\ntraining phase, the system reaches equilibrium with the generalization\ncapability attaining a maximum. The system can also be coherent with localized,\nnon-equilibrium states, which is characterized by the stabilization of the\nHessian matrix. The paper proves that neural networks with higher\ngeneralization capability will have a slower convergence rate. The relationship\nbetween the generalization capability with the stability of the neural network\nhas also been discussed. By correlating the principles of high-energy physics\nwith the learning theory of neural networks, the paper establishes a variant of\nthe Complexity-Action conjecture from an artificial neural network perspective.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 12:03:19 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 07:32:38 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Dutta", "Ankan", ""], ["Rakshit", "Arnab", ""]]}, {"id": "2011.04601", "submitter": "Dimitris Spathis", "authors": "Dimitris Spathis, Ignacio Perez-Pozuelo, Soren Brage, Nicholas J.\n  Wareham and Cecilia Mascolo", "title": "Learning Generalizable Physiological Representations from Large-scale\n  Wearable Data", "comments": "Accepted to the Machine Learning for Mobile Health workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, research on sensor-equipped mobile devices has primarily focused on\nthe purely supervised task of human activity recognition (walking, running,\netc), demonstrating limited success in inferring high-level health outcomes\nfrom low-level signals, such as acceleration. Here, we present a novel\nself-supervised representation learning method using activity and heart rate\n(HR) signals without semantic labels. With a deep neural network, we set HR\nresponses as the supervisory signal for the activity data, leveraging their\nunderlying physiological relationship.\n  We evaluate our model in the largest free-living combined-sensing dataset\n(comprising more than 280,000 hours of wrist accelerometer & wearable ECG data)\nand show that the resulting embeddings can generalize in various downstream\ntasks through transfer learning with linear classifiers, capturing\nphysiologically meaningful, personalized information. For instance, they can be\nused to predict (higher than 70 AUC) variables associated with individuals'\nhealth, fitness and demographic characteristics, outperforming unsupervised\nautoencoders and common bio-markers. Overall, we propose the first multimodal\nself-supervised method for behavioral and physiological data with implications\nfor large-scale health and lifestyle monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:56:03 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Spathis", "Dimitris", ""], ["Perez-Pozuelo", "Ignacio", ""], ["Brage", "Soren", ""], ["Wareham", "Nicholas J.", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2011.04602", "submitter": "Julius Berner", "authors": "Julius Berner, Markus Dablander, Philipp Grohs", "title": "Numerically Solving Parametric Families of High-Dimensional Kolmogorov\n  Partial Differential Equations via Deep Learning", "comments": "Accepted at NeurIPS 2020", "journal-ref": "Advances in Neural Information Processing Systems 33, 2020, pp.\n  16615-16627", "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning algorithm for the numerical solution of parametric\nfamilies of high-dimensional linear Kolmogorov partial differential equations\n(PDEs). Our method is based on reformulating the numerical approximation of a\nwhole family of Kolmogorov PDEs as a single statistical learning problem using\nthe Feynman-Kac formula. Successful numerical experiments are presented, which\nempirically confirm the functionality and efficiency of our proposed algorithm\nin the case of heat equations and Black-Scholes option pricing models\nparametrized by affine-linear coefficient functions. We show that a single deep\nneural network trained on simulated data is capable of learning the solution\nfunctions of an entire family of PDEs on a full space-time region. Most\nnotably, our numerical observations and theoretical results also demonstrate\nthat the proposed method does not suffer from the curse of dimensionality,\ndistinguishing it from almost all standard numerical methods for PDEs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:57:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Berner", "Julius", ""], ["Dablander", "Markus", ""], ["Grohs", "Philipp", ""]]}, {"id": "2011.04605", "submitter": "Elias Chaibub Neto", "authors": "Elias Chaibub Neto", "title": "Causality-aware counterfactual confounding adjustment as an alternative\n  to linear residualization in anticausal prediction tasks based on linear\n  learners", "comments": "This paper draws some material from arXiv:2001.03998", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear residualization is a common practice for confounding adjustment in\nmachine learning (ML) applications. Recently, causality-aware predictive\nmodeling has been proposed as an alternative causality-inspired approach for\nadjusting for confounders. The basic idea is to simulate counterfactual data\nthat is free from the spurious associations generated by the observed\nconfounders. In this paper, we compare the linear residualization approach\nagainst the causality-aware confounding adjustment in anticausal prediction\ntasks, and show that the causality-aware approach tends to (asymptotically)\noutperform the residualization adjustment in terms of predictive performance in\nlinear learners. Importantly, our results still holds even when the true model\nis not linear. We illustrate our results in both regression and classification\ntasks, where we compared the causality-aware and residualization approaches\nusing mean squared errors and classification accuracy in synthetic data\nexperiments where the linear regression model is mispecified, as well as, when\nthe linear model is correctly specified. Furthermore, we illustrate how the\ncausality-aware approach is more stable than residualization with respect to\ndataset shifts in the joint distribution of the confounders and outcome\nvariables.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:59:57 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Neto", "Elias Chaibub", ""]]}, {"id": "2011.04622", "submitter": "Zhuoran Yang", "authors": "Zhuoran Yang, Chi Jin, Zhaoran Wang, Mengdi Wang, Michael I. Jordan", "title": "On Function Approximation in Reinforcement Learning: Optimism in the\n  Face of Large State Spaces", "comments": "76 pages. The short version of this work appears in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical theory of reinforcement learning (RL) has focused on tabular\nand linear representations of value functions. Further progress hinges on\ncombining RL with modern function approximators such as kernel functions and\ndeep neural networks, and indeed there have been many empirical successes that\nhave exploited such combinations in large-scale applications. There are\nprofound challenges, however, in developing a theory to support this\nenterprise, most notably the need to take into consideration the\nexploration-exploitation tradeoff at the core of RL in conjunction with the\ncomputational and statistical tradeoffs that arise in modern\nfunction-approximation-based learning systems. We approach these challenges by\nstudying an optimistic modification of the least-squares value iteration\nalgorithm, in the context of the action-value function\n  represented by a kernel function or an overparameterized neural network. We\nestablish both polynomial runtime complexity and polynomial sample complexity\nfor this algorithm, without additional assumptions on the data-generating\nmodel. In particular, we prove that the algorithm incurs an\n$\\tilde{\\mathcal{O}}(\\delta_{\\mathcal{F}} H^2 \\sqrt{T})$ regret, where\n$\\delta_{\\mathcal{F}}$ characterizes the intrinsic complexity of the function\nclass $\\mathcal{F}$, $H$ is the length of each episode, and $T$ is the total\nnumber of episodes. Our regret bounds are independent of the number of states,\na result which exhibits clearly the benefit of function approximation in RL.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:32:22 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 17:24:48 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yang", "Zhuoran", ""], ["Jin", "Chi", ""], ["Wang", "Zhaoran", ""], ["Wang", "Mengdi", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.04627", "submitter": "Jacky Liang", "authors": "Mohit Sharma, Jacky Liang, Jialiang Zhao, Alex LaGrassa, Oliver\n  Kroemer", "title": "Learning to Compose Hierarchical Object-Centric Controllers for Robotic\n  Manipulation", "comments": "Accepted as Plenary Talk at CoRL'20. First two authors contributed\n  equally. For results see\n  https://sites.google.com/view/compositional-object-control/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation tasks can often be decomposed into multiple subtasks performed\nin parallel, e.g., sliding an object to a goal pose while maintaining contact\nwith a table. Individual subtasks can be achieved by task-axis controllers\ndefined relative to the objects being manipulated, and a set of object-centric\ncontrollers can be combined in an hierarchy. In prior works, such combinations\nare defined manually or learned from demonstrations. By contrast, we propose\nusing reinforcement learning to dynamically compose hierarchical object-centric\ncontrollers for manipulation tasks. Experiments in both simulation and real\nworld show how the proposed approach leads to improved sample efficiency,\nzero-shot generalization to novel test environments, and simulation-to-reality\ntransfer without fine-tuning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:38:29 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 20:27:39 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sharma", "Mohit", ""], ["Liang", "Jacky", ""], ["Zhao", "Jialiang", ""], ["LaGrassa", "Alex", ""], ["Kroemer", "Oliver", ""]]}, {"id": "2011.04635", "submitter": "Arnab Bhattacharya", "authors": "Arnab Bhattacharya, Thiagarajan Ramachandran, Sandeep Banik, Chase P.\n  Dowling, Shaunak D. Bopardikar", "title": "Automated Adversary Emulation for Cyber-Physical Systems via\n  Reinforcement Learning", "comments": "To appear in the Proceedings of the 18th IEEE International\n  Conference on Intelligence and Security Informatics (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversary emulation is an offensive exercise that provides a comprehensive\nassessment of a system's resilience against cyber attacks. However, adversary\nemulation is typically a manual process, making it costly and hard to deploy in\ncyber-physical systems (CPS) with complex dynamics, vulnerabilities, and\noperational uncertainties. In this paper, we develop an automated, domain-aware\napproach to adversary emulation for CPS. We formulate a Markov Decision Process\n(MDP) model to determine an optimal attack sequence over a hybrid attack graph\nwith cyber (discrete) and physical (continuous) components and related physical\ndynamics. We apply model-based and model-free reinforcement learning (RL)\nmethods to solve the discrete-continuous MDP in a tractable fashion. As a\nbaseline, we also develop a greedy attack algorithm and compare it with the RL\nprocedures. We summarize our findings through a numerical study on sensor\ndeception attacks in buildings to compare the performance and solution quality\nof the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:44:29 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Bhattacharya", "Arnab", ""], ["Ramachandran", "Thiagarajan", ""], ["Banik", "Sandeep", ""], ["Dowling", "Chase P.", ""], ["Bopardikar", "Shaunak D.", ""]]}, {"id": "2011.04640", "submitter": "Justin Chiu", "authors": "Justin T. Chiu and Alexander M. Rush", "title": "Scaling Hidden Markov Language Models", "comments": "9 pages, accepted as a short paper at EMNLP 2020", "journal-ref": "EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hidden Markov model (HMM) is a fundamental tool for sequence modeling\nthat cleanly separates the hidden state from the emission structure. However,\nthis separation makes it difficult to fit HMMs to large datasets in modern NLP,\nand they have fallen out of use due to very poor performance compared to fully\nobserved models. This work revisits the challenge of scaling HMMs to language\nmodeling datasets, taking ideas from recent approaches to neural modeling. We\npropose methods for scaling HMMs to massive state spaces while maintaining\nefficient exact inference, a compact parameterization, and effective\nregularization. Experiments show that this approach leads to models that are\nmore accurate than previous HMM and n-gram-based methods, making progress\ntowards the performance of state-of-the-art neural models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 18:51:55 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chiu", "Justin T.", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2011.04651", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Discovering Synergistic Drug Combinations for COVID with Biological\n  Bottleneck Models", "comments": "Accepted to NeurIPS 2020 Machine Learning for Molecules Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug combinations play an important role in therapeutics due to its better\nefficacy and reduced toxicity. Recent approaches have applied machine learning\nto identify synergistic combinations for cancer, but they are not applicable to\nnew diseases with limited combination data. Given that drug synergy is closely\ntied to biological targets, we propose a \\emph{biological bottleneck} model\nthat jointly learns drug-target interaction and synergy. The model consists of\ntwo parts: a drug-target interaction and target-disease association module.\nThis design enables the model to \\emph{explain} how a biological target affects\ndrug synergy. By utilizing additional biological information, our model\nachieves 0.78 test AUC in drug synergy prediction using only 90 COVID drug\ncombinations for training. We experimentally tested the model predictions in\nthe U.S. National Center for Advancing Translational Sciences (NCATS)\nfacilities and discovered two novel drug combinations (Remdesivir + Reserpine\nand Remdesivir + IQ-1S) with strong synergy in vitro.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 03:30:44 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 18:53:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2011.04686", "submitter": "Sagar Sudhakara", "authors": "Mukul Gagrani, Sagar Sudhakara, Aditya Mahajan, Ashutosh Nayyar and Yi\n  Ouyang", "title": "Thompson sampling for linear quadratic mean-field teams", "comments": "Submitted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimal control of an unknown multi-agent linear quadratic (LQ)\nsystem where the dynamics and the cost are coupled across the agents through\nthe mean-field (i.e., empirical mean) of the states and controls. Directly\nusing single-agent LQ learning algorithms in such models results in regret\nwhich increases polynomially with the number of agents. We propose a new\nThompson sampling based learning algorithm which exploits the structure of the\nsystem model and show that the expected Bayesian regret of our proposed\nalgorithm for a system with agents of $|M|$ different types at time horizon $T$\nis $\\tilde{\\mathcal{O}} \\big( |M|^{1.5} \\sqrt{T} \\big)$ irrespective of the\ntotal number of agents, where the $\\tilde{\\mathcal{O}}$ notation hides\nlogarithmic factors in $T$. We present detailed numerical experiments to\nillustrate the salient features of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:07:32 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gagrani", "Mukul", ""], ["Sudhakara", "Sagar", ""], ["Mahajan", "Aditya", ""], ["Nayyar", "Ashutosh", ""], ["Ouyang", "Yi", ""]]}, {"id": "2011.04698", "submitter": "Max Tegmark", "authors": "Ziming Liu (MIT), Max Tegmark (MIT)", "title": "AI Poincar\\'e: Machine Learning Conservation Laws from Trajectories", "comments": "Replaced by accepted PRL version; expanded validation, improved\n  presentation, more legible figs", "journal-ref": "Phys. Rev. Lett. 126, 180604 (2021)", "doi": "10.1103/PhysRevLett.126.180604", "report-no": null, "categories": "cs.LG astro-ph.EP nlin.SI physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AI Poincar\\'e, a machine learning algorithm for auto-discovering\nconserved quantities using trajectory data from unknown dynamical systems. We\ntest it on five Hamiltonian systems, including the gravitational 3-body\nproblem, and find that it discovers not only all exactly conserved quantities,\nbut also periodic orbits, phase transitions and breakdown timescales for\napproximate conservation laws.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:23:28 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 13:20:29 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Liu", "Ziming", "", "MIT"], ["Tegmark", "Max", "", "MIT"]]}, {"id": "2011.04709", "submitter": "Tianwei Ni", "authors": "Tianwei Ni, Harshit Sikchi, Yufei Wang, Tejus Gupta, Lisa Lee,\n  Benjamin Eysenbach", "title": "f-IRL: Inverse Reinforcement Learning via State Marginal Matching", "comments": "The first four authors have equal contribution (orders determined by\n  dice rolling), and the last two authors have equal advising. The paper is\n  accepted by Conference on Robot Learning (CoRL) 2020. Project videos and code\n  link are available at https://sites.google.com/view/f-irl/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning is well-suited for robotic tasks where it is difficult to\ndirectly program the behavior or specify a cost for optimal control. In this\nwork, we propose a method for learning the reward function (and the\ncorresponding policy) to match the expert state density. Our main result is the\nanalytic gradient of any f-divergence between the agent and expert state\ndistribution w.r.t. reward parameters. Based on the derived gradient, we\npresent an algorithm, f-IRL, that recovers a stationary reward function from\nthe expert density by gradient descent. We show that f-IRL can learn behaviors\nfrom a hand-designed target state density or implicitly through expert\nobservations. Our method outperforms adversarial imitation learning methods in\nterms of sample efficiency and the required number of expert trajectories on\nIRL benchmarks. Moreover, we show that the recovered reward function can be\nused to quickly solve downstream tasks, and empirically demonstrate its utility\non hard-to-explore tasks and for behavior transfer across changes in dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:37:48 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 11:56:44 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ni", "Tianwei", ""], ["Sikchi", "Harshit", ""], ["Wang", "Yufei", ""], ["Gupta", "Tejus", ""], ["Lee", "Lisa", ""], ["Eysenbach", "Benjamin", ""]]}, {"id": "2011.04717", "submitter": "Zhongxia Zhang", "authors": "Zhongxia Zhang, Meng Wu", "title": "Real-time Locational Marginal Price Forecasting Using Generative\n  Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose a model-free unsupervised learning approach to\nforecast real-time locational marginal prices (RTLMPs) in wholesale electricity\nmarkets. By organizing system-wide hourly RTLMP data into a 3-dimensional (3D)\ntensor consisting of a series of time-indexed matrices, we formulate the RTLMP\nforecasting problem as a problem of generating the next matrix with forecasted\nRTLMPs given the historical RTLMP tensor, and propose a generative adversarial\nnetwork (GAN) model to forecast RTLMPs. The proposed formulation preserves the\nspatio-temporal correlations among system-wide RTLMPs in the format of\nhistorical RTLMP tensor. The proposed GAN model learns the spatio-temporal\ncorrelations using the historical RTLMP tensors and generate RTLMPs that are\nstatistically similar and temporally coherent to the historical RTLMP tensor.\nThe proposed approach forecasts system-wide RTLMPs using only publicly\navailable historical price data, without involving confidential information of\nsystem model, such as system parameters, topology, or operating conditions. The\neffectiveness of the proposed approach is verified through case studies using\nhistorical RTLMP data in Southwest Power Pool (SPP).\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:46:03 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhang", "Zhongxia", ""], ["Wu", "Meng", ""]]}, {"id": "2011.04720", "submitter": "Frithjof Gressmann", "authors": "Frithjof Gressmann, Zach Eaton-Rosen, Carlo Luschi", "title": "Improving Neural Network Training in Low Dimensional Random Bases", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) has proven to be remarkably effective in\noptimizing deep neural networks that employ ever-larger numbers of parameters.\nYet, improving the efficiency of large-scale optimization remains a vital and\nhighly active area of research. Recent work has shown that deep neural networks\ncan be optimized in randomly-projected subspaces of much smaller dimensionality\nthan their native parameter space. While such training is promising for more\nefficient and scalable optimization schemes, its practical application is\nlimited by inferior optimization performance. Here, we improve on recent random\nsubspace approaches as follows: Firstly, we show that keeping the random\nprojection fixed throughout training is detrimental to optimization. We propose\nre-drawing the random subspace at each step, which yields significantly better\nperformance. We realize further improvements by applying independent\nprojections to different parts of the network, making the approximation more\nefficient as network dimensionality grows. To implement these experiments, we\nleverage hardware-accelerated pseudo-random number generation to construct the\nrandom projections on-demand at every optimization step, allowing us to\ndistribute the computation of independent random directions across multiple\nworkers with shared random seeds. This yields significant reductions in memory\nand is up to 10 times faster for the workloads in question.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:50:19 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gressmann", "Frithjof", ""], ["Eaton-Rosen", "Zach", ""], ["Luschi", "Carlo", ""]]}, {"id": "2011.04723", "submitter": "Yen-Yu Chang", "authors": "Yen-Yu Chang, Pan Li, Rok Sosic, M. H. Afifi, Marco Schweighauser,\n  Jure Leskovec", "title": "F-FADE: Frequency Factorization for Anomaly Detection in Edge Streams", "comments": "WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge streams are commonly used to capture interactions in dynamic networks,\nsuch as email, social, or computer networks. The problem of detecting anomalies\nor rare events in edge streams has a wide range of applications. However, it\npresents many challenges due to lack of labels, a highly dynamic nature of\ninteractions, and the entanglement of temporal and structural changes in the\nnetwork. Current methods are limited in their ability to address the above\nchallenges and to efficiently process a large number of interactions. Here, we\npropose F-FADE, a new approach for detection of anomalies in edge streams,\nwhich uses a novel frequency-factorization technique to efficiently model the\ntime-evolving distributions of frequencies of interactions between node-pairs.\nThe anomalies are then determined based on the likelihood of the observed\nfrequency of each incoming interaction. F-FADE is able to handle in an online\nstreaming setting a broad variety of anomalies with temporal and structural\nchanges, while requiring only constant memory. Our experiments on one synthetic\nand six real-world dynamic networks show that F-FADE achieves state of the art\nperformance and may detect anomalies that previous methods are unable to find.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:55:40 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 13:11:09 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Chang", "Yen-Yu", ""], ["Li", "Pan", ""], ["Sosic", "Rok", ""], ["Afifi", "M. H.", ""], ["Schweighauser", "Marco", ""], ["Leskovec", "Jure", ""]]}, {"id": "2011.04726", "submitter": "Pedro Mendes", "authors": "Pedro Mendes, Maria Casimiro, Paolo Romano, David Garlan", "title": "TrimTuner: Efficient Optimization of Machine Learning Jobs in the Cloud\n  via Sub-Sampling", "comments": "Mascots 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work introduces TrimTuner, the first system for optimizing machine\nlearning jobs in the cloud to exploit sub-sampling techniques to reduce the\ncost of the optimization process while keeping into account user-specified\nconstraints. TrimTuner jointly optimizes the cloud and application-specific\nparameters and, unlike state of the art works for cloud optimization, eschews\nthe need to train the model with the full training set every time a new\nconfiguration is sampled. Indeed, by leveraging sub-sampling techniques and\ndata-sets that are up to 60x smaller than the original one, we show that\nTrimTuner can reduce the cost of the optimization process by up to 50x.\nFurther, TrimTuner speeds-up the recommendation process by 65x with respect to\nstate of the art techniques for hyper-parameter optimization that use\nsub-sampling techniques. The reasons for this improvement are twofold: i) a\nnovel domain specific heuristic that reduces the number of configurations for\nwhich the acquisition function has to be evaluated; ii) the adoption of an\nensemble of decision trees that enables boosting the speed of the\nrecommendation process by one additional order of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:06:28 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Mendes", "Pedro", ""], ["Casimiro", "Maria", ""], ["Romano", "Paolo", ""], ["Garlan", "David", ""]]}, {"id": "2011.04728", "submitter": "Dishant Parikh", "authors": "Dishant Parikh, Shambhavi Aggarwal", "title": "Similarity-Based Clustering for Enhancing Image Classification\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional networks are at the center of best in class computer vision\napplications for a wide assortment of undertakings. Since 2014, profound amount\nof work began to make better convolutional architectures, yielding generous\nadditions in different benchmarks. Albeit expanded model size and computational\ncost will, in general, mean prompt quality increases for most undertakings but,\nthe architectures now need to have some additional information to increase the\nperformance. We show empirical evidence that with the amalgamation of\ncontent-based image similarity and deep learning models, we can provide the\nflow of information which can be used in making clustered learning possible. We\nshow how parallel training of sub-dataset clusters not only reduces the cost of\ncomputation but also increases the benchmark accuracies by 5-11 percent.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 17:03:28 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Parikh", "Dishant", ""], ["Aggarwal", "Shambhavi", ""]]}, {"id": "2011.04730", "submitter": "Paulo Henrique Oliveira", "authors": "Paulo H. Oliveira, Daniel S. Kaster, Caetano Traina-Jr., Ihab F. Ilyas", "title": "Batchwise Probabilistic Incremental Data Cleaning", "comments": "29 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of data and data quality issues are among the main bottlenecks that\nprevent further artificial intelligence adoption within many organizations,\npushing data scientists to spend most of their time cleaning data before being\nable to answer analytical questions. Hence, there is a need for more effective\nand efficient data cleaning solutions, which, not surprisingly, is rife with\ntheoretical and engineering problems. This report addresses the problem of\nperforming holistic data cleaning incrementally, given a fixed rule set and an\nevolving categorical relational dataset acquired in sequential batches. To the\nbest of our knowledge, our contributions compose the first incremental\nframework that cleans data (i) independently of user interventions, (ii)\nwithout requiring knowledge about the incoming dataset, such as the number of\nclasses per attribute, and (iii) holistically, enabling multiple error types to\nbe repaired simultaneously, and thus avoiding conflicting repairs. Extensive\nexperiments show that our approach outperforms the competitors with respect to\nrepair quality, execution time, and memory consumption.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:15:02 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Oliveira", "Paulo H.", ""], ["Kaster", "Daniel S.", ""], ["Traina-Jr.", "Caetano", ""], ["Ilyas", "Ihab F.", ""]]}, {"id": "2011.04740", "submitter": "Omkar Ranadive", "authors": "Omkar Ranadive, Suzan van der Lee, Vivian Tang, Kevin Chao", "title": "Applying Machine Learning to Crowd-sourced Data from Earthquake\n  Detective", "comments": "Published in AI for Earth Sciences Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Earthquake Detective dataset - A crowdsourced set of labels on\npotentially triggered (PT) earthquakes and tremors. These events are those\nwhich may have been triggered by large magnitude and often distant earthquakes.\nWe apply Machine Learning to classify these PT seismic events and explore the\nchallenges faced in segregating such low amplitude signals. The data set and\ncode are available online.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 04:00:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Ranadive", "Omkar", ""], ["van der Lee", "Suzan", ""], ["Tang", "Vivian", ""], ["Chao", "Kevin", ""]]}, {"id": "2011.04748", "submitter": "Pragaash Ponnusamy", "authors": "Alireza Roshan-Ghias, Clint Solomon Mathialagan, Pragaash Ponnusamy,\n  Lambert Mathias, Chenlei Guo", "title": "Personalized Query Rewriting in Conversational AI Agents", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spoken language understanding (SLU) systems in conversational AI agents often\nexperience errors in the form of misrecognitions by automatic speech\nrecognition (ASR) or semantic gaps in natural language understanding (NLU).\nThese errors easily translate to user frustrations, particularly so in\nrecurrent events e.g. regularly toggling an appliance, calling a frequent\ncontact, etc. In this work, we propose a query rewriting approach by leveraging\nusers' historically successful interactions as a form of memory. We present a\nneural retrieval model and a pointer-generator network with hierarchical\nattention and show that they perform significantly better at the query\nrewriting task with the aforementioned user memories than without. We also\nhighlight how our approach with the proposed models leverages the structural\nand semantic diversity in ASR's output towards recovering users' intents.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:45:39 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Roshan-Ghias", "Alireza", ""], ["Mathialagan", "Clint Solomon", ""], ["Ponnusamy", "Pragaash", ""], ["Mathias", "Lambert", ""], ["Guo", "Chenlei", ""]]}, {"id": "2011.04749", "submitter": "Edward De Brouwer", "authors": "Edward De Brouwer, Thijs Becker, Yves Moreau, Eva Kubala Havrdova,\n  Maria Trojano, Sara Eichau, Serkan Ozakbas, Marco Onofrj, Pierre Grammond,\n  Jens Kuhle, Ludwig Kappos, Patrizia Sola, Elisabetta Cartechini, Jeannette\n  Lechner-Scott, Raed Alroughani, Oliver Gerlach, Tomas Kalincik, Franco\n  Granella, Francois GrandMaison, Roberto Bergamaschi, Maria Jose Sa, Bart Van\n  Wijmeersch, Aysun Soysal, Jose Luis Sanchez-Menoyo, Claudio Solaro, Cavit\n  Boz, Gerardo Iuliano, Katherine Buzzard, Eduardo Aguera-Morales, Murat Terzi,\n  Tamara Castillo Trivio, Daniele Spitaleri, Vincent Van Pesch, Vahid\n  Shaygannej, Fraser Moore, Celia Oreja Guevara, Davide Maimone, Riadh Gouider,\n  Tunde Csepany, Cristina Ramo-Tello, Liesbet Peeters", "title": "Longitudinal modeling of MS patient trajectories improves predictions of\n  disability progression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Research in Multiple Sclerosis (MS) has recently focused on extracting\nknowledge from real-world clinical data sources. This type of data is more\nabundant than data produced during clinical trials and potentially more\ninformative about real-world clinical practice. However, this comes at the cost\nof less curated and controlled data sets. In this work, we address the task of\noptimally extracting information from longitudinal patient data in the\nreal-world setting with a special focus on the sporadic sampling problem. Using\nthe MSBase registry, we show that with machine learning methods suited for\npatient trajectories modeling, such as recurrent neural networks and tensor\nfactorization, we can predict disability progression of patients in a two-year\nhorizon with an ROC-AUC of 0.86, which represents a 33% decrease in the ranking\npair error (1-AUC) compared to reference methods using static clinical\nfeatures. Compared to the models available in the literature, this work uses\nthe most complete patient history for MS disease progression prediction.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:48:00 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["De Brouwer", "Edward", ""], ["Becker", "Thijs", ""], ["Moreau", "Yves", ""], ["Havrdova", "Eva Kubala", ""], ["Trojano", "Maria", ""], ["Eichau", "Sara", ""], ["Ozakbas", "Serkan", ""], ["Onofrj", "Marco", ""], ["Grammond", "Pierre", ""], ["Kuhle", "Jens", ""], ["Kappos", "Ludwig", ""], ["Sola", "Patrizia", ""], ["Cartechini", "Elisabetta", ""], ["Lechner-Scott", "Jeannette", ""], ["Alroughani", "Raed", ""], ["Gerlach", "Oliver", ""], ["Kalincik", "Tomas", ""], ["Granella", "Franco", ""], ["GrandMaison", "Francois", ""], ["Bergamaschi", "Roberto", ""], ["Sa", "Maria Jose", ""], ["Van Wijmeersch", "Bart", ""], ["Soysal", "Aysun", ""], ["Sanchez-Menoyo", "Jose Luis", ""], ["Solaro", "Claudio", ""], ["Boz", "Cavit", ""], ["Iuliano", "Gerardo", ""], ["Buzzard", "Katherine", ""], ["Aguera-Morales", "Eduardo", ""], ["Terzi", "Murat", ""], ["Trivio", "Tamara Castillo", ""], ["Spitaleri", "Daniele", ""], ["Van Pesch", "Vincent", ""], ["Shaygannej", "Vahid", ""], ["Moore", "Fraser", ""], ["Guevara", "Celia Oreja", ""], ["Maimone", "Davide", ""], ["Gouider", "Riadh", ""], ["Csepany", "Tunde", ""], ["Ramo-Tello", "Cristina", ""], ["Peeters", "Liesbet", ""]]}, {"id": "2011.04750", "submitter": "Mohamed Bakhouya", "authors": "Nadir Maaroufi, Mehdi Najib, Mohamed Bakhouya", "title": "Predicting the Future is like Completing a Painting!", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is an introductory work towards a larger research framework\nrelative to Scientific Prediction. It is a mixed between science and philosophy\nof science, therefore we can talk about Experimental Philosophy of Science. As\na first result, we introduce a new forecasting method based on image\ncompletion, named Forecasting Method by Image Inpainting (FM2I). In fact, time\nseries forecasting is transformed into fully images- and signal-based\nprocessing procedures. After transforming a time series data into its\ncorresponding image, the problem of data forecasting becomes essentially a\nproblem of image inpainting problem, i.e., completing missing data in the\nimage. An extensive experimental evaluation is conducted using a large dataset\nproposed by the well-known M3-competition. Results show that FM2I represents an\nefficient and robust tool for time series forecasting. It has achieved\nprominent results in terms of accuracy and outperforms the best M3 forecasting\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:48:06 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Maaroufi", "Nadir", ""], ["Najib", "Mehdi", ""], ["Bakhouya", "Mohamed", ""]]}, {"id": "2011.04754", "submitter": "Amir Kalev", "authors": "Marco Paini, Amir Kalev, Dan Padilha, and Brendan Ruck", "title": "Estimating expectation values using approximate quantum states", "comments": "8+5 pages; supersedes the general approximate state description\n  section of arXiv:1910.10543 with improved presentation, new experiments and a\n  discussion on related work; Version 2: minor edits; Version 3: Quantum\n  journal version", "journal-ref": "Quantum 5, 413 (2021)", "doi": "10.22331/q-2021-03-16-413", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an approximate description of an $N$-qubit state, which contains\nsufficient information to estimate the expectation value of any observable to a\nprecision that is upper bounded by the ratio of a suitably-defined seminorm of\nthe observable to the square root of the number of the system's identical\npreparations $M$, with no explicit dependence on $N$. We describe an\noperational procedure for constructing the approximate description of the state\nthat requires, besides the quantum state preparation, only single-qubit\nrotations followed by single-qubit measurements. We show that following this\nprocedure, the cardinality of the resulting description of the state grows as\n$3MN$. We test the proposed method on Rigetti's quantum processor unit with 12,\n16 and 25 qubits for random states and random observables, and find an\nexcellent agreement with the theory, despite experimental errors.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 20:57:56 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 14:03:49 GMT"}, {"version": "v3", "created": "Sun, 14 Mar 2021 19:46:42 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Paini", "Marco", ""], ["Kalev", "Amir", ""], ["Padilha", "Dan", ""], ["Ruck", "Brendan", ""]]}, {"id": "2011.04762", "submitter": "Shahine Bouabid", "authors": "Shahine Bouabid, Maxim Chernetskiy, Maxime Rischard and Jevgenij\n  Gamper", "title": "Predicting Landsat Reflectance with Deep Generative Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public satellite missions are commonly bound to a trade-off between spatial\nand temporal resolution as no single sensor provides fine-grained acquisitions\nwith frequent coverage. This hinders their potential to assist vegetation\nmonitoring or humanitarian actions, which require detecting rapid and detailed\nterrestrial surface changes. In this work, we probe the potential of deep\ngenerative models to produce high-resolution optical imagery by fusing products\nwith different spatial and temporal characteristics. We introduce a dataset of\nco-registered Moderate Resolution Imaging Spectroradiometer (MODIS) and Landsat\nsurface reflectance time series and demonstrate the ability of our generative\nmodel to blend coarse daily reflectance information into low-paced finer\nacquisitions. We benchmark our proposed model against state-of-the-art\nreflectance fusion algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:06:04 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Bouabid", "Shahine", ""], ["Chernetskiy", "Maxim", ""], ["Rischard", "Maxime", ""], ["Gamper", "Jevgenij", ""]]}, {"id": "2011.04764", "submitter": "Joshua Romoff", "authors": "Eloi Alonso, Maxim Peter, David Goumard, Joshua Romoff", "title": "Deep Reinforcement Learning for Navigation in AAA Video Games", "comments": "Accepted to the NeurIPS 2020 Challenges of Real-World RL workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In video games, non-player characters (NPCs) are used to enhance the players'\nexperience in a variety of ways, e.g., as enemies, allies, or innocent\nbystanders. A crucial component of NPCs is navigation, which allows them to\nmove from one point to another on the map. The most popular approach for NPC\nnavigation in the video game industry is to use a navigation mesh (NavMesh),\nwhich is a graph representation of the map, with nodes and edges indicating\ntraversable areas. Unfortunately, complex navigation abilities that extend the\ncharacter's capacity for movement, e.g., grappling hooks, jetpacks,\nteleportation, or double-jumps, increases the complexity of the NavMesh, making\nit intractable in many practical scenarios. Game designers are thus constrained\nto only add abilities that can be handled by a NavMesh if they want to have NPC\nnavigation. As an alternative, we propose to use Deep Reinforcement Learning\n(Deep RL) to learn how to navigate 3D maps using any navigation ability. We\ntest our approach on complex 3D environments in the Unity game engine that are\nnotably an order of magnitude larger than maps typically used in the Deep RL\nliterature. One of these maps is directly modeled after a Ubisoft AAA game. We\nfind that our approach performs surprisingly well, achieving at least $90\\%$\nsuccess rate on all tested scenarios. A video of our results is available at\nhttps://youtu.be/WFIf9Wwlq8M.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:07:56 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 19:09:57 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Alonso", "Eloi", ""], ["Peter", "Maxim", ""], ["Goumard", "David", ""], ["Romoff", "Joshua", ""]]}, {"id": "2011.04765", "submitter": "Stefan Richthofer", "authors": "Stefan Richthofer, Laurenz Wiskott", "title": "Singular Sturm-Liouville Problems with Zero Potential (q=0) and Singular\n  Slow Feature Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CA math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Sturm-Liouville problem ($\\lambda wy=(ry')'+qy$) is singular if its domain\nis unbounded or if $r$ or $w$ vanish at the boundary. Then it is difficult to\ntell whether profound results from regular Sturm-Liouville theory apply.\nExisting criteria are often difficult to apply, e.g. because they are\nformulated in terms of the solution function.\n  We study the special case that the potential $q$ is zero under Neumann\nboundary conditions and give simple and explicit criteria, solely in terms of\nthe coefficient functions, to assess whether various properties of the regular\ncase apply. Specifically, these properties are discreteness of the spectrum\n(BD), self-adjointness, oscillation ($i$th solution has $i$ zeros) and that the\n$i$th eigenvalue equals the SFA delta value (the total energy) of the $i$th\nsolution. We further prove that stationary points of each solution strictly\ninterlace with its zeros (in singular or regular case, regardless of the\nboundary condition, for zero potential or if $q < \\lambda w$ everywhere). If\n$\\frac{r}{w}$ is bounded and of bounded variation, the criterion simplifies to\nrequiring $\\frac{|w'|}{w} \\to \\infty$ at singular boundary points.\n  This research is motivated by Slow Feature Analysis (SFA), a data processing\nalgorithm that extracts the slowest uncorrelated signals from a\nhigh-dimensional input signal and has notable success in computer vision,\ncomputational neuroscience and blind source separation. From [Sprekeler et al.,\n2014] it is known that for an important class of scenarios (statistically\nindependent input), an analytic formulation of SFA reduces to a Sturm-Liouville\nproblem with zero potential and Neumann boundary conditions. So far, the\nmathematical SFA theory has only considered the regular case, except for a\nspecial case that is solved by Hermite Polynomials. This work generalizes SFA\ntheory to the singular case, i.e. open-space scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:09:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Richthofer", "Stefan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "2011.04767", "submitter": "Ali Emami Mr.", "authors": "Ali Emami, Adam Trischler, Kaheer Suleman and Jackie Chi Kit Cheung", "title": "An Analysis of Dataset Overlap on Winograd-Style Tasks", "comments": "11 pages with references, accepted at COLING 2020", "journal-ref": "Coling2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Winograd Schema Challenge (WSC) and variants inspired by it have become\nimportant benchmarks for common-sense reasoning (CSR). Model performance on the\nWSC has quickly progressed from chance-level to near-human using neural\nlanguage models trained on massive corpora. In this paper, we analyze the\neffects of varying degrees of overlap between these training corpora and the\ntest instances in WSC-style tasks. We find that a large number of test\ninstances overlap considerably with the corpora on which state-of-the-art\nmodels are (pre)trained, and that a significant drop in classification accuracy\noccurs when we evaluate models on instances with minimal overlap. Based on\nthese results, we develop the KnowRef-60K dataset, which consists of over 60k\npronoun disambiguation problems scraped from web data. KnowRef-60K is the\nlargest corpus to date for WSC-style common-sense reasoning and exhibits a\nsignificantly lower proportion of overlaps with current pretraining corpora.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:11:17 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Emami", "Ali", ""], ["Trischler", "Adam", ""], ["Suleman", "Kaheer", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "2011.04770", "submitter": "Arunesh Mittal", "authors": "Arunesh Mittal, Paul Sajda, John Paisley", "title": "Deep Bayesian Nonparametric Factor Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep generative factor analysis model with beta process prior\nthat can approximate complex non-factorial distributions over the latent codes.\nWe outline a stochastic EM algorithm for scalable inference in a specific\ninstantiation of this model and present some preliminary results.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:14:22 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Mittal", "Arunesh", ""], ["Sajda", "Paul", ""], ["Paisley", "John", ""]]}, {"id": "2011.04776", "submitter": "Siddha Ganju", "authors": "Siddha Ganju, Anirudh Koul, Alexander Lavin, Josh Veitch-Michaelis,\n  Meher Kasam, James Parr", "title": "Learnings from Frontier Development Lab and SpaceML -- AI Accelerators\n  for NASA and ESA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research with AI and ML technologies lives in a variety of settings with\noften asynchronous goals and timelines: academic labs and government\norganizations pursue open-ended research focusing on discoveries with long-term\nvalue, while research in industry is driven by commercial pursuits and hence\nfocuses on short-term timelines and return on investment. The journey from\nresearch to product is often tacit or ad hoc, resulting in technology\ntransition failures, further exacerbated when research and development is\ninterorganizational and interdisciplinary. Even more, much of the ability to\nproduce results remains locked in the private repositories and know-how of the\nindividual researcher, slowing the impact on future research by others and\ncontributing to the ML community's challenges in reproducibility. With research\norganizations focused on an exploding array of fields, opportunities for the\nhandover and maturation of interdisciplinary research reduce. With these\ntensions, we see an emerging need to measure the correctness, impact, and\nrelevance of research during its development to enable better collaboration,\nimproved reproducibility, faster progress, and more trusted outcomes. We\nperform a case study of the Frontier Development Lab (FDL), an AI accelerator\nunder a public-private partnership from NASA and ESA. FDL research follows\nprincipled practices that are grounded in responsible development, conduct, and\ndissemination of AI research, enabling FDL to churn successful\ninterdisciplinary and interorganizational research projects, measured through\nNASA's Technology Readiness Levels. We also take a look at the SpaceML Open\nSource Research Program, which helps accelerate and transition FDL's research\nto deployable projects with wide spread adoption amongst citizen scientists.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:23:03 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ganju", "Siddha", ""], ["Koul", "Anirudh", ""], ["Lavin", "Alexander", ""], ["Veitch-Michaelis", "Josh", ""], ["Kasam", "Meher", ""], ["Parr", "James", ""]]}, {"id": "2011.04779", "submitter": "Mohamed Karim Belaid", "authors": "Mohamed Karim Belaid", "title": "After All, Only The Last Neuron Matters: Comparing Multi-modal Fusion\n  Functions for Scene Graph Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  From object segmentation to word vector representations, Scene Graph\nGeneration (SGG) became a complex task built upon numerous research results. In\nthis paper, we focus on the last module of this model: the fusion function. The\nrole of this latter is to combine three hidden states. We perform an ablation\ntest in order to compare different implementations. First, we reproduce the\nstate-of-the-art results using SUM, and GATE functions. Then we expand the\noriginal solution by adding more model-agnostic functions: an adapted version\nof DIST and a mixture between MFB and GATE. On the basis of the\nstate-of-the-art configuration, DIST performed the best Recall @ K, which makes\nit now part of the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:27:32 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Belaid", "Mohamed Karim", ""]]}, {"id": "2011.04783", "submitter": "Amanda Sofie Rios", "authors": "Amanda Rios and Laurent Itti", "title": "Lifelong Learning Without a Task Oracle", "comments": "Proceedings of the IEEE 32nd International Conference on Tools with\n  Artificial Intelligence (ICTAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep neural networks are known to undergo a sharp decline in the\naccuracy of older tasks when new tasks are learned, termed \"catastrophic\nforgetting\". Many state-of-the-art solutions to continual learning rely on\nbiasing and/or partitioning a model to accommodate successive tasks\nincrementally. However, these methods largely depend on the availability of a\ntask-oracle to confer task identities to each test sample, without which the\nmodels are entirely unable to perform. To address this shortcoming, we propose\nand compare several candidate task-assigning mappers which require very little\nmemory overhead: (1) Incremental unsupervised prototype assignment using either\nnearest means, Gaussian Mixture Models or fuzzy ART backbones; (2) Supervised\nincremental prototype assignment with fast fuzzy ARTMAP; (3) Shallow perceptron\ntrained via a dynamic coreset. Our proposed model variants are trained either\nfrom pre-trained feature extractors or task-dependent feature embeddings of the\nmain classifier network. We apply these pipeline variants to continual learning\nbenchmarks, comprised of either sequences of several datasets or within one\nsingle dataset. Overall, these methods, despite their simplicity and\ncompactness, perform very close to a ground truth oracle, especially in\nexperiments of inter-dataset task assignment. Moreover, best-performing\nvariants only impose an average cost of 1.7% parameter memory increase.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:30:31 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Rios", "Amanda", ""], ["Itti", "Laurent", ""]]}, {"id": "2011.04789", "submitter": "Xianrui Meng", "authors": "Xianrui Meng, Joan Feigenbaum", "title": "Privacy-Preserving XGBoost Inference", "comments": "Extended abstract appears in Privacy-preserving Machine Learning\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although machine learning (ML) is widely used for predictive tasks, there are\nimportant scenarios in which ML cannot be used or at least cannot achieve its\nfull potential. A major barrier to adoption is the sensitive nature of\npredictive queries. Individual users may lack sufficiently rich datasets to\ntrain accurate models locally but also be unwilling to send sensitive queries\nto commercial services that vend such models. One central goal of\nprivacy-preserving machine learning (PPML) is to enable users to submit\nencrypted queries to a remote ML service, receive encrypted results, and\ndecrypt them locally. We aim at developing practical solutions for real-world\nprivacy-preserving ML inference problems. In this paper, we propose a\nprivacy-preserving XGBoost prediction algorithm, which we have implemented and\nevaluated empirically on AWS SageMaker. Experimental results indicate that our\nalgorithm is efficient enough to be used in real ML production environments.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:46:07 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 18:41:34 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 21:42:24 GMT"}, {"version": "v4", "created": "Tue, 24 Nov 2020 18:07:27 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Meng", "Xianrui", ""], ["Feigenbaum", "Joan", ""]]}, {"id": "2011.04798", "submitter": "Ding Zhou", "authors": "Ding Zhou, Xue-Xin Wei", "title": "Learning identifiable and interpretable latent models of\n  high-dimensional neural activity using pi-VAE", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to record activities from hundreds of neurons simultaneously in\nthe brain has placed an increasing demand for developing appropriate\nstatistical techniques to analyze such data. Recently, deep generative models\nhave been proposed to fit neural population responses. While these methods are\nflexible and expressive, the downside is that they can be difficult to\ninterpret and identify. To address this problem, we propose a method that\nintegrates key ingredients from latent models and traditional neural encoding\nmodels. Our method, pi-VAE, is inspired by recent progress on identifiable\nvariational auto-encoder, which we adapt to make appropriate for neuroscience\napplications. Specifically, we propose to construct latent variable models of\nneural activity while simultaneously modeling the relation between the latent\nand task variables (non-neural variables, e.g. sensory, motor, and other\nexternally observable states). The incorporation of task variables results in\nmodels that are not only more constrained, but also show qualitative\nimprovements in interpretability and identifiability. We validate pi-VAE using\nsynthetic data, and apply it to analyze neurophysiological datasets from rat\nhippocampus and macaque motor cortex. We demonstrate that pi-VAE not only fits\nthe data better, but also provides unexpected novel insights into the structure\nof the neural codes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:00:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhou", "Ding", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "2011.04802", "submitter": "Kamran Kowsari", "authors": "Jinghe Zhang, Kamran Kowsari, Mehdi Boukhechba, James Harrison,\n  Jennifer Lobo, Laura Barnes", "title": "Sparse Longitudinal Representations of Electronic Health Record Data for\n  the Early Detection of Chronic Kidney Disease in Diabetic Patients", "comments": "Accepted in IEEE BIBM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.PE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic kidney disease (CKD) is a gradual loss of renal function over time,\nand it increases the risk of mortality, decreased quality of life, as well as\nserious complications. The prevalence of CKD has been increasing in the last\ncouple of decades, which is partly due to the increased prevalence of diabetes\nand hypertension. To accurately detect CKD in diabetic patients, we propose a\nnovel framework to learn sparse longitudinal representations of patients'\nmedical records. The proposed method is also compared with widely used\nbaselines such as Aggregated Frequency Vector and Bag-of-Pattern in Sequences\non real EHR data, and the experimental results indicate that the proposed model\nachieves higher predictive performance. Additionally, the learned\nrepresentations are interpreted and visualized to bring clinical insights.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:07:25 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 18:33:56 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zhang", "Jinghe", ""], ["Kowsari", "Kamran", ""], ["Boukhechba", "Mehdi", ""], ["Harrison", "James", ""], ["Lobo", "Jennifer", ""], ["Barnes", "Laura", ""]]}, {"id": "2011.04803", "submitter": "Ricky T. Q. Chen", "authors": "Ricky T. Q. Chen, Dami Choi, Lukas Balles, David Duvenaud, Philipp\n  Hennig", "title": "Self-Tuning Stochastic Optimization with Curvature-Aware Gradient\n  Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard first-order stochastic optimization algorithms base their updates\nsolely on the average mini-batch gradient, and it has been shown that tracking\nadditional quantities such as the curvature can help de-sensitize common\nhyperparameters. Based on this intuition, we explore the use of exact\nper-sample Hessian-vector products and gradients to construct optimizers that\nare self-tuning and hyperparameter-free. Based on a dynamics model of the\ngradient, we derive a process which leads to a curvature-corrected,\nnoise-adaptive online gradient estimate. The smoothness of our updates makes it\nmore amenable to simple step size selection schemes, which we also base off of\nour estimates quantities. We prove that our model-based procedure converges in\nthe noisy quadratic setting. Though we do not see similar gains in deep\nlearning tasks, we can match the performance of well-tuned optimizers and\nultimately, this is an interesting step for constructing self-tuning\noptimizers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:07:30 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Chen", "Ricky T. Q.", ""], ["Choi", "Dami", ""], ["Balles", "Lukas", ""], ["Duvenaud", "David", ""], ["Hennig", "Philipp", ""]]}, {"id": "2011.04811", "submitter": "Mikhail Krinitskiy Dr.", "authors": "Mikhail Krinitskiy, Polina Verezemskaya, Svyatoslav Elizarov, Sergey\n  Gulev", "title": "Machine learning methods for the detection of polar lows in satellite\n  mosaics: major issues and their solutions", "comments": "11 pages including references. 3 figures and 2 tables. To be\n  published in the Proceedings of the All-Russian conference Climate change:\n  causes, risks, consequences, problems of adaptation and management;\n  CLIMATE-2019, November 26-28, Moscow, Russia; IOP Conference Series, Earth\n  and Environmental Science, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Polar mesocyclones (PMCs) and their intense subclass polar lows (PLs) are\nrelatively small atmospheric vortices that form mostly over the ocean in high\nlatitudes. PLs can strongly influence deep ocean water formation since they are\nassociated with strong surface winds and heat fluxes. Detection and tracking of\nPLs are crucial for understanding the climatological dynamics of PLs and for\nthe analysis of their impacts on other components of the climatic system. At\nthe same time, visual tracking of PLs is a highly time-consuming procedure that\nrequires expert knowledge and extensive examination of source data.\n  There are known procedures involving deep convolutional neural networks\n(DCNNs) for the detection of large-scale atmospheric phenomena in reanalysis\ndata that demonstrate a high quality of detection. However, one cannot apply\nthese procedures to satellite data directly since, unlike reanalyses, satellite\nproducts register all the scales of atmospheric vortices. It is also known that\nDCNNs were originally designed to be scale-invariant. This leads to the problem\nof filtering the scale of detected phenomena. There are other problems to be\nsolved, such as a low signal-to-noise ratio of satellite data and an unbalanced\nnumber of negative (without PLs) and positive (where a PL is presented) classes\nin a satellite dataset.\n  In our study, we propose a deep learning approach for the detection of PLs\nand PMCs in remote sensing data, which addresses class imbalance and scale\nfiltering problems. We also outline potential solutions for other problems,\nalong with promising improvements to the presented approach.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:43:05 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Krinitskiy", "Mikhail", ""], ["Verezemskaya", "Polina", ""], ["Elizarov", "Svyatoslav", ""], ["Gulev", "Sergey", ""]]}, {"id": "2011.04812", "submitter": "Kejun Li", "authors": "Kejun Li, Maegan Tucker, Erdem B{\\i}y{\\i}k, Ellen Novoseller, Joel W.\n  Burdick, Yanan Sui, Dorsa Sadigh, Yisong Yue, Aaron D. Ames", "title": "ROIAL: Region of Interest Active Learning for Characterizing Exoskeleton\n  Gait Preference Landscapes", "comments": "6 pages + 1 page of references; 7 figures; To Appear at ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing what types of exoskeleton gaits are comfortable for users, and\nunderstanding the science of walking more generally, require recovering a\nuser's utility landscape. Learning these landscapes is challenging, as walking\ntrajectories are defined by numerous gait parameters, data collection from\nhuman trials is expensive, and user safety and comfort must be ensured. This\nwork proposes the Region of Interest Active Learning (ROIAL) framework, which\nactively learns each user's underlying utility function over a region of\ninterest that ensures safety and comfort. ROIAL learns from ordinal and\npreference feedback, which are more reliable feedback mechanisms than absolute\nnumerical scores. The algorithm's performance is evaluated both in simulation\nand experimentally for three non-disabled subjects walking inside of a\nlower-body exoskeleton. ROIAL learns Bayesian posteriors that predict each\nexoskeleton user's utility landscape across four exoskeleton gait parameters.\nThe algorithm discovers both commonalities and discrepancies across users' gait\npreferences and identifies the gait parameters that most influenced user\nfeedback. These results demonstrate the feasibility of recovering gait utility\nlandscapes from limited human trials.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:45:58 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 22:59:19 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Li", "Kejun", ""], ["Tucker", "Maegan", ""], ["B\u0131y\u0131k", "Erdem", ""], ["Novoseller", "Ellen", ""], ["Burdick", "Joel W.", ""], ["Sui", "Yanan", ""], ["Sadigh", "Dorsa", ""], ["Yue", "Yisong", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2011.04820", "submitter": "Shuijing Liu", "authors": "Shuijing Liu, Peixin Chang, Weihang Liang, Neeloy Chakraborty,\n  Katherine Driggs-Campbell", "title": "Decentralized Structural-RNN for Robot Crowd Navigation with Deep\n  Reinforcement Learning", "comments": "Published as a conference paper in IEEE International Conference on\n  Robotics and Automation (ICRA), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe and efficient navigation through human crowds is an essential capability\nfor mobile robots. Previous work on robot crowd navigation assumes that the\ndynamics of all agents are known and well-defined. In addition, the performance\nof previous methods deteriorates in partially observable environments and\nenvironments with dense crowds. To tackle these problems, we propose\ndecentralized structural-Recurrent Neural Network (DS-RNN), a novel network\nthat reasons about spatial and temporal relationships for robot decision making\nin crowd navigation. We train our network with model-free deep reinforcement\nlearning without any expert supervision. We demonstrate that our model\noutperforms previous methods in challenging crowd navigation scenarios. We\nsuccessfully transfer the policy learned in the simulator to a real-world\nTurtleBot 2i.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 23:15:31 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 20:53:01 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 15:51:50 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Liu", "Shuijing", ""], ["Chang", "Peixin", ""], ["Liang", "Weihang", ""], ["Chakraborty", "Neeloy", ""], ["Driggs-Campbell", "Katherine", ""]]}, {"id": "2011.04823", "submitter": "Alex Tamkin", "authors": "Alex Tamkin, Dan Jurafsky, Noah Goodman", "title": "Language Through a Prism: A Spectral Approach for Multiscale Language\n  Representations", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language exhibits structure at different scales, ranging from subwords to\nwords, sentences, paragraphs, and documents. To what extent do deep models\ncapture information at these scales, and can we force them to better capture\nstructure across this hierarchy? We approach this question by focusing on\nindividual neurons, analyzing the behavior of their activations at different\ntimescales. We show that signal processing provides a natural framework for\nseparating structure across scales, enabling us to 1) disentangle\nscale-specific information in existing embeddings and 2) train models to learn\nmore about particular scales. Concretely, we apply spectral filters to the\nactivations of a neuron across an input, producing filtered embeddings that\nperform well on part of speech tagging (word-level), dialog speech acts\nclassification (utterance-level), or topic classification (document-level),\nwhile performing poorly on the other tasks. We also present a prism layer for\ntraining models, which uses spectral filters to constrain different neurons to\nmodel structure at different scales. Our proposed BERT + Prism model can better\npredict masked tokens using long-range context and produces multiscale\nrepresentations that perform better at utterance- and document-level tasks. Our\nmethods are general and readily applicable to other domains besides language,\nsuch as images, audio, and video.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 23:17:43 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tamkin", "Alex", ""], ["Jurafsky", "Dan", ""], ["Goodman", "Noah", ""]]}, {"id": "2011.04825", "submitter": "Ramina Ghods", "authors": "Ramina Ghods, William J. Durkin, Jeff Schneider", "title": "Multi-Agent Active Search using Realistic Depth-Aware Noise Model", "comments": "To appear at the 2021 IEEE International Conference on Robotics and\n  Automation (ICRA), extended version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The active search for objects of interest in an unknown environment has many\nrobotics applications including search and rescue, detecting gas leaks or\nlocating animal poachers. Existing algorithms often prioritize the location\naccuracy of objects of interest while other practical issues such as the\nreliability of object detection as a function of distance and lines of sight\nremain largely ignored. Additionally, in many active search scenarios,\ncommunication infrastructure may be unreliable or unestablished, making\ncentralized control of multiple agents impractical. We present an algorithm\ncalled Noise-Aware Thompson Sampling (NATS) that addresses these issues for\nmultiple ground-based robots performing active search considering two sources\nof sensory information from monocular optical imagery and depth maps. By\nutilizing Thompson Sampling, NATS allows for decentralized coordination among\nmultiple agents. NATS also considers object detection uncertainty from depth as\nwell as environmental occlusions and operates while remaining agnostic of the\nnumber of objects of interest. Using simulation results, we show that NATS\nsignificantly outperforms existing methods such as information-greedy policies\nor exhaustive search. We demonstrate the real-world viability of NATS using a\npseudo-realistic environment created in the Unreal Engine 4 game development\nplatform with the AirSim plugin.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 23:20:55 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 16:39:19 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Ghods", "Ramina", ""], ["Durkin", "William J.", ""], ["Schneider", "Jeff", ""]]}, {"id": "2011.04832", "submitter": "Tavor Baharav", "authors": "Govinda M. Kamath and Tavor Z. Baharav and Ilan Shomorony", "title": "Adaptive Learning of Rank-One Models for Efficient Pairwise Sequence\n  Alignment", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pairwise alignment of DNA sequencing data is a ubiquitous task in\nbioinformatics and typically represents a heavy computational burden.\nState-of-the-art approaches to speed up this task use hashing to identify short\nsegments (k-mers) that are shared by pairs of reads, which can then be used to\nestimate alignment scores. However, when the number of reads is large,\naccurately estimating alignment scores for all pairs is still very costly.\nMoreover, in practice, one is only interested in identifying pairs of reads\nwith large alignment scores. In this work, we propose a new approach to\npairwise alignment estimation based on two key new ingredients. The first\ningredient is to cast the problem of pairwise alignment estimation under a\ngeneral framework of rank-one crowdsourcing models, where the workers'\nresponses correspond to k-mer hash collisions. These models can be accurately\nsolved via a spectral decomposition of the response matrix. The second\ningredient is to utilise a multi-armed bandit algorithm to adaptively refine\nthis spectral estimator only for read pairs that are likely to have large\nalignments. The resulting algorithm iteratively performs a spectral\ndecomposition of the response matrix for adaptively chosen subsets of the read\npairs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 23:31:56 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 02:01:40 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kamath", "Govinda M.", ""], ["Baharav", "Tavor Z.", ""], ["Shomorony", "Ilan", ""]]}, {"id": "2011.04843", "submitter": "Congbo Ma", "authors": "Congbo Ma, Wei Emma Zhang, Mingyu Guo, Hu Wang, Quan Z. Sheng", "title": "Multi-document Summarization via Deep Learning Techniques: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-document summarization (MDS) is an effective tool for information\naggregation which generates an informative and concise summary from a cluster\nof topic-related documents. Our survey structurally overviews the recent deep\nlearning based multi-document summarization models via a proposed taxonomy and\nit is the first of its kind. Particularly, we propose a novel mechanism to\nsummarize the design strategies of neural networks and conduct a comprehensive\nsummary of the state-of-the-art. We highlight the differences among various\nobjective functions which are rarely discussed in the existing literature.\nFinally, we propose several future directions pertaining to this new and\nexciting development of the field.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 00:35:46 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 08:01:05 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ma", "Congbo", ""], ["Zhang", "Wei Emma", ""], ["Guo", "Mingyu", ""], ["Wang", "Hu", ""], ["Sheng", "Quan Z.", ""]]}, {"id": "2011.04868", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Bo Ji, Yixin Shi, Tianyu Ding, Biyi Fang, Sheng Yi, Xiao\n  Tu", "title": "Neural Network Compression Via Sparse Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The compression of deep neural networks (DNNs) to reduce inference cost\nbecomes increasingly important to meet realistic deployment requirements of\nvarious applications. There have been a significant amount of work regarding\nnetwork compression, while most of them are heuristic rule-based or typically\nnot friendly to be incorporated into varying scenarios. On the other hand,\nsparse optimization yielding sparse solutions naturally fits the compression\nrequirement, but due to the limited study of sparse optimization in stochastic\nlearning, its extension and application onto model compression is rarely well\nexplored. In this work, we propose a model compression framework based on the\nrecent progress on sparse stochastic optimization. Compared to existing model\ncompression techniques, our method is effective and requires fewer extra\nengineering efforts to incorporate with varying applications, and has been\nnumerically demonstrated on benchmark compression tasks. Particularly, we\nachieve up to 7.2 and 2.9 times FLOPs reduction with the same level of\nevaluation accuracy on VGG16 for CIFAR10 and ResNet50 for ImageNet compared to\nthe baseline heavy models, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 03:03:55 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 06:03:55 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Chen", "Tianyi", ""], ["Ji", "Bo", ""], ["Shi", "Yixin", ""], ["Ding", "Tianyu", ""], ["Fang", "Biyi", ""], ["Yi", "Sheng", ""], ["Tu", "Xiao", ""]]}, {"id": "2011.04891", "submitter": "Yuanzhe Geng", "authors": "Yuanzhe Geng, Erwu Liu, Rui Wang, and Yiming Liu", "title": "Hierarchical Reinforcement Learning for Relay Selection and Power\n  Optimization in Two-Hop Cooperative Relay Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative communication is an effective approach to improve spectrum\nutilization. In order to reduce outage probability of communication system,\nmost studies propose various schemes for relay selection and power allocation,\nwhich are based on the assumption of channel state information (CSI). However,\nit is difficult to get an accurate CSI in practice. In this paper, we study the\noutage probability minimizing problem subjected to a total transmission power\nconstraint in a two-hop cooperative relay network. We use reinforcement\nlearning (RL) methods to learn strategies for relay selection and power\nallocation, which do not need any prior knowledge of CSI but simply rely on the\ninteraction with communication environment. It is noted that conventional RL\nmethods, including most deep reinforcement learning (DRL) methods, cannot\nperform well when the search space is too large. Therefore, we first propose a\nDRL framework with an outage-based reward function, which is then used as a\nbaseline. Then, we further propose a hierarchical reinforcement learning (HRL)\nframework and training algorithm. A key difference from other RL-based methods\nin existing literatures is that, our proposed HRL approach decomposes relay\nselection and power allocation into two hierarchical optimization objectives,\nwhich are trained in different levels. With the simplification of search space,\nthe HRL approach can solve the problem of sparse reward, while the conventional\nRL method fails. Simulation results reveal that compared with traditional DRL\nmethod, the HRL training algorithm can reach convergence 30 training iterations\nearlier and reduce the outage probability by 5% in two-hop relay network with\nthe same outage threshold.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 04:47:41 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 13:10:47 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Geng", "Yuanzhe", ""], ["Liu", "Erwu", ""], ["Wang", "Rui", ""], ["Liu", "Yiming", ""]]}, {"id": "2011.04896", "submitter": "Soroosh Tayebi Arasteh", "authors": "Soroosh Tayebi Arasteh", "title": "Generalized LSTM-based End-to-End Text-Independent Speaker Verification", "comments": "7 pages, 7 tables, 6 figures. Research Internship project at the\n  Pattern Recognition Lab at FAU Erlangen-Nuremberg, as a part of Master's\n  curriculum. Re-implementation of the paper arXiv:1710.10467 by Wan et al", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing amount of available data and more affordable hardware\nsolutions have opened a gate to the realm of Deep Learning (DL). Due to the\nrapid advancements and ever-growing popularity of DL, it has begun to invade\nalmost every field, where machine learning is applicable, by altering the\ntraditional state-of-the-art methods. While many researchers in the speaker\nrecognition area have also started to replace the former state-of-the-art\nmethods with DL techniques, some of the traditional i-vector-based methods are\nstill state-of-the-art in the context of text-independent speaker verification\n(TI-SV). In this paper, we discuss the most recent generalized end-to-end\n(GE2E) DL technique based on Long Short-term Memory (LSTM) units for TI-SV by\nGoogle and compare different scenarios and aspects including utterance\nduration, training time, and accuracy to prove that our method outperforms the\ntraditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:17:06 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 15:50:00 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2020 16:36:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Arasteh", "Soroosh Tayebi", ""]]}, {"id": "2011.04907", "submitter": "Paxton Turner", "authors": "Paxton Turner, Jingbo Liu, Philippe Rigollet", "title": "A Statistical Perspective on Coreset Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Coresets have emerged as a powerful tool to summarize data by selecting a\nsmall subset of the original observations while retaining most of its\ninformation. This approach has led to significant computational speedups but\nthe performance of statistical procedures run on coresets is largely\nunexplored. In this work, we develop a statistical framework to study coresets\nand focus on the canonical task of nonparameteric density estimation. Our\ncontributions are twofold. First, we establish the minimax rate of estimation\nachievable by coreset-based estimators. Second, we show that the practical\ncoreset kernel density estimators are near-minimax optimal over a large class\nof H\\\"{o}lder-smooth densities.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 05:18:43 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 21:05:08 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Turner", "Paxton", ""], ["Liu", "Jingbo", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2011.04910", "submitter": "Kun Wang", "authors": "Kun Wang, Mridul Aanjaneya and Kostas Bekris", "title": "Spring-Rod System Identification via Differentiable Physics Engine", "comments": "Workshop on Differentiable Vision, Graphics, and Physics in Machine\n  Learning at NeurIPS 2020. arXiv admin note: substantial text overlap with\n  arXiv:2004.13859", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel differentiable physics engine for system identification of\ncomplex spring-rod assemblies. Unlike black-box data-driven methods for\nlearning the evolution of a dynamical system \\emph{and} its parameters, we\nmodularize the design of our engine using a discrete form of the governing\nequations of motion, similar to a traditional physics engine. We further reduce\nthe dimension from 3D to 1D for each module, which allows efficient learning of\nsystem parameters using linear regression. The regression parameters correspond\nto physical quantities, such as spring stiffness or the mass of the rod, making\nthe pipeline explainable. The approach significantly reduces the amount of\ntraining data required, and also avoids iterative identification of data\nsampling and model training. We compare the performance of the proposed engine\nwith previous solutions, and demonstrate its efficacy on tensegrity systems,\nsuch as NASA's icosahedron.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:36:22 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Kun", ""], ["Aanjaneya", "Mridul", ""], ["Bekris", "Kostas", ""]]}, {"id": "2011.04917", "submitter": "Ramaravind Kommiya Mothilal", "authors": "Ramaravind Kommiya Mothilal and Divyat Mahajan and Chenhao Tan and\n  Amit Sharma", "title": "Towards Unifying Feature Attribution and Counterfactual Explanations:\n  Different Means to the Same End", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": "10.1145/3461702.3462597", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attributions and counterfactual explanations are popular approaches\nto explain a ML model. The former assigns an importance score to each input\nfeature, while the latter provides input examples with minimal changes to alter\nthe model's predictions. To unify these approaches, we provide an\ninterpretation based on the actual causality framework and present two key\nresults in terms of their use. First, we present a method to generate feature\nattribution explanations from a set of counterfactual examples. These feature\nattributions convey how important a feature is to changing the classification\noutcome of a model, especially on whether a subset of features is necessary\nand/or sufficient for that change, which attribution-based methods are unable\nto provide. Second, we show how counterfactual examples can be used to evaluate\nthe goodness of an attribution-based explanation in terms of its necessity and\nsufficiency. As a result, we highlight the complementarity of these two\napproaches. Our evaluation on three benchmark datasets - Adult-Income,\nLendingClub, and German-Credit - confirms the complementarity. Feature\nattribution methods like LIME and SHAP and counterfactual explanation methods\nlike Wachter et al. and DiCE often do not agree on feature importance rankings.\nIn addition, by restricting the features that can be modified for generating\ncounterfactual examples, we find that the top-k features from LIME or SHAP are\noften neither necessary nor sufficient explanations of a model's prediction.\nFinally, we present a case study of different explanation methods on a\nreal-world hospital triage problem\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 05:41:43 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 12:18:19 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 17:49:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mothilal", "Ramaravind Kommiya", ""], ["Mahajan", "Divyat", ""], ["Tan", "Chenhao", ""], ["Sharma", "Amit", ""]]}, {"id": "2011.04922", "submitter": "Paxton Turner", "authors": "Paxton Turner, Jingbo Liu, and Philippe Rigollet", "title": "Efficient Interpolation of Density Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of space and time efficient evaluation of a\nnonparametric estimator that approximates an unknown density. In the regime\nwhere consistent estimation is possible, we use a piecewise multivariate\npolynomial interpolation scheme to give a computationally efficient\nconstruction that converts the original estimator to a new estimator that can\nbe queried efficiently and has low space requirements, all without adversely\ndeteriorating the original approximation quality. Our result gives a new\nstatistical perspective on the problem of fast evaluation of kernel density\nestimators in the presence of underlying smoothness. As a corollary, we give a\nsuccinct derivation of a classical result of Kolmogorov---Tikhomirov on the\nmetric entropy of H\\\"{o}lder classes of smooth functions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 06:05:00 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Turner", "Paxton", ""], ["Liu", "Jingbo", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2011.04923", "submitter": "Steve Dias Da Cruz", "authors": "Hans-Peter Beise, Steve Dias Da Cruz", "title": "Expressiveness of Neural Networks Having Width Equal or Below the Input\n  Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding about the minimum width of deep neural networks needed to\nensure universal approximation for different activation functions has\nprogressively been extended (Park et al., 2020). In particular, with respect to\napproximation on general compact sets in the input space, a network width less\nthan or equal to the input dimension excludes universal approximation. In this\nwork, we focus on network functions of width less than or equal to the latter\ncritical bound. We prove that in this regime, the exact fit of partially\nconstant functions on disjoint compact sets is still possible for ReLU network\nfunctions under some conditions on the mutual location of these components. We\nshow that with cosine as activation function, a three layer network of width\none is sufficient to approximate any function on arbitrary finite sets.\nConversely, we prove a maximum principle from which we conclude that for all\ncontinuous and monotonic activation functions, universal approximation of\narbitrary continuous functions is impossible on sets that coincide with the\nboundary of an open set plus an inner point.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 06:06:02 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 12:55:09 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 09:18:18 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Beise", "Hans-Peter", ""], ["Da Cruz", "Steve Dias", ""]]}, {"id": "2011.04926", "submitter": "Ruoyu Sun", "authors": "Ruoyu Sun, Tiantian Fang, Alex Schwing", "title": "Towards a Better Global Loss Landscape of GANs", "comments": "Accepted to NeurIPS 2020 (oral). 43 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.IT math.IT math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding of GAN training is still very limited. One major challenge is\nits non-convex-non-concave min-max objective, which may lead to sub-optimal\nlocal minima. In this work, we perform a global landscape analysis of the\nempirical loss of GANs. We prove that a class of separable-GAN, including the\noriginal JS-GAN, has exponentially many bad basins which are perceived as\nmode-collapse. We also study the relativistic pairing GAN (RpGAN) loss which\ncouples the generated samples and the true samples. We prove that RpGAN has no\nbad basins. Experiments on synthetic data show that the predicted bad basin can\nindeed appear in training. We also perform experiments to support our theory\nthat RpGAN has a better landscape than separable-GAN. For instance, we\nempirically show that RpGAN performs better than separable-GAN with relatively\nnarrow neural nets. The code is available at https://github.com/AilsaF/RS-GAN.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 06:10:52 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sun", "Ruoyu", ""], ["Fang", "Tiantian", ""], ["Schwing", "Alex", ""]]}, {"id": "2011.04929", "submitter": "Kun Wang", "authors": "Kun Wang, Mridul Aanjaneya and Kostas Bekris", "title": "Sim2Sim Evaluation of a Novel Data-Efficient Differentiable Physics\n  Engine for Tensegrity Robots", "comments": "Accepted to IROS2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.GR cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning policies in simulation is promising for reducing human effort when\ntraining robot controllers. This is especially true for soft robots that are\nmore adaptive and safe but also more difficult to accurately model and control.\nThe sim2real gap is the main barrier to successfully transfer policies from\nsimulation to a real robot. System identification can be applied to reduce this\ngap but traditional identification methods require a lot of manual tuning.\nData-driven alternatives can tune dynamical models directly from data but are\noften data hungry, which also incorporates human effort in collecting data.\nThis work proposes a data-driven, end-to-end differentiable simulator focused\non the exciting but challenging domain of tensegrity robots. To the best of the\nauthors' knowledge, this is the first differentiable physics engine for\ntensegrity robots that supports cable, contact, and actuation modeling. The aim\nis to develop a reasonably simplified, data-driven simulation, which can learn\napproximate dynamics with limited ground truth data. The dynamics must be\naccurate enough to generate policies that can be transferred back to the\nground-truth system. As a first step in this direction, the current work\ndemonstrates sim2sim transfer, where the unknown physical model of MuJoCo acts\nas a ground truth system. Two different tensegrity robots are used for\nevaluation and learning of locomotion policies, a 6-bar and a 3-bar tensegrity.\nThe results indicate that only 0.25\\% of ground truth data are needed to train\na policy that works on the ground truth system when the differentiable engine\nis used for training against training the policy directly on the ground truth\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 06:19:54 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 23:08:49 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wang", "Kun", ""], ["Aanjaneya", "Mridul", ""], ["Bekris", "Kostas", ""]]}, {"id": "2011.04948", "submitter": "Javad Ghareh Chamani", "authors": "Javad Ghareh Chamani (1), Dimitrios Papadopoulos (1) ((1) Hong Kong\n  University of Science and Technology)", "title": "Mitigating Leakage in Federated Learning with Trusted Hardware", "comments": "Presented at the Privacy Preserving Machine Learning Workshop\n  (PriML/PPML Joint Edition) at the 34th Conference on Neural Information\n  Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In federated learning, multiple parties collaborate in order to train a\nglobal model over their respective datasets. Even though cryptographic\nprimitives (e.g., homomorphic encryption) can help achieve data privacy in this\nsetting, some partial information may still be leaked across parties if this is\ndone non-judiciously. In this work, we study the federated learning framework\nof SecureBoost [Cheng et al., FL@IJCAI'19] as a specific such example,\ndemonstrate a leakage-abuse attack based on its leakage profile, and\nexperimentally evaluate the effectiveness of our attack. We then propose two\nsecure versions relying on trusted execution environments. We implement and\nbenchmark our protocols to demonstrate that they are 1.2-5.4X faster in\ncomputation and need 5-49X less communication than SecureBoost.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 07:22:51 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 16:00:17 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 12:51:55 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Chamani", "Javad Ghareh", ""], ["Papadopoulos", "Dimitrios", ""]]}, {"id": "2011.04998", "submitter": "Lior Kamma", "authors": "Allan Gr{\\o}nlund, Lior Kamma, Kasper Green Larsen", "title": "Margins are Insufficient for Explaining Gradient Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Boosting is one of the most successful ideas in machine learning, achieving\ngreat practical performance with little fine-tuning. The success of boosted\nclassifiers is most often attributed to improvements in margins. The focus on\nmargin explanations was pioneered in the seminal work by Schapire et al. (1998)\nand has culminated in the $k$'th margin generalization bound by Gao and Zhou\n(2013), which was recently proved to be near-tight for some data distributions\n(Gronlund et al. 2019). In this work, we first demonstrate that the $k$'th\nmargin bound is inadequate in explaining the performance of state-of-the-art\ngradient boosters. We then explain the short comings of the $k$'th margin bound\nand prove a stronger and more refined margin-based generalization bound for\nboosted classifiers that indeed succeeds in explaining the performance of\nmodern gradient boosters. Finally, we improve upon the recent generalization\nlower bound by Gr{\\o}nlund et al. (2019).\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:28:03 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gr\u00f8nlund", "Allan", ""], ["Kamma", "Lior", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "2011.04999", "submitter": "Jennifer Grannen", "authors": "Jennifer Grannen, Priya Sundaresan, Brijen Thananjeyan, Jeffrey\n  Ichnowski, Ashwin Balakrishna, Minho Hwang, Vainavi Viswanath, Michael\n  Laskey, Joseph E. Gonzalez, Ken Goldberg", "title": "Untangling Dense Knots by Learning Task-Relevant Keypoints", "comments": "Conference on Robot Learning (CoRL) 2020 Oral. First two authors\n  contributed equally", "journal-ref": "4th Conference on Robot Learning (CoRL 2020)", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Untangling ropes, wires, and cables is a challenging task for robots due to\nthe high-dimensional configuration space, visual homogeneity, self-occlusions,\nand complex dynamics. We consider dense (tight) knots that lack space between\nself-intersections and present an iterative approach that uses learned\ngeometric structure in configurations. We instantiate this into an algorithm,\nHULK: Hierarchical Untangling from Learned Keypoints, which combines\nlearning-based perception with a geometric planner into a policy that guides a\nbilateral robot to untangle knots. To evaluate the policy, we perform\nexperiments both in a novel simulation environment modelling cables with varied\nknot types and textures and in a physical system using the da Vinci surgical\nrobot. We find that HULK is able to untangle cables with dense figure-eight and\noverhand knots and generalize to varied textures and appearances. We compare\ntwo variants of HULK to three baselines and observe that HULK achieves 43.3%\nhigher success rates on a physical system compared to the next best baseline.\nHULK successfully untangles a cable from a dense initial configuration\ncontaining up to two overhand and figure-eight knots in 97.9% of 378 simulation\nexperiments with an average of 12.1 actions per trial. In physical experiments,\nHULK achieves 61.7% untangling success, averaging 8.48 actions per trial.\nSupplementary material, code, and videos can be found at\nhttps://tinyurl.com/y3a88ycu.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:29:01 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Grannen", "Jennifer", ""], ["Sundaresan", "Priya", ""], ["Thananjeyan", "Brijen", ""], ["Ichnowski", "Jeffrey", ""], ["Balakrishna", "Ashwin", ""], ["Hwang", "Minho", ""], ["Viswanath", "Vainavi", ""], ["Laskey", "Michael", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "2011.05001", "submitter": "Jagarlapudi Saketha Nath", "authors": "Piyushi Manupriya (IIT Hyderabad, INDIA), J. Saketha Nath (IIT\n  Hyderabad, INDIA), Pratik Jawanpuria (Microsoft IDC, INDIA)", "title": "Integral Probability Metric based Regularization for Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization in Optimal Transport (OT) problems has been shown to\ncritically affect the associated computational and sample complexities. It also\nhas been observed that regularization effectively helps in handling noisy\nmarginals as well as marginals with unequal masses. However, existing works on\nOT restrict themselves to $\\phi$-divergences based regularization. In this\nwork, we propose and analyze Integral Probability Metric (IPM) based\nregularization in OT problems. While it is expected that the well-established\nadvantages of IPMs are inherited by the IPM-regularized OT variants, we\ninterestingly observe that some useful aspects of $\\phi$-regularization are\npreserved. For example, we show that the OT formulation, where the marginal\nconstraints are relaxed using IPM-regularization, also lifts the ground metric\nto that over (perhaps un-normalized) measures. Infact, the lifted metric turns\nout to be another IPM whose generating set is the intersection of that of the\nIPM employed for regularization and the set of 1-Lipschitz functions under the\nground metric. Also, in the special case where the regularization is squared\nmaximum mean discrepancy based, the proposed OT variant, as well as the\ncorresponding Barycenter formulation, turn out to be those of minimizing a\nconvex quadratic subject to non-negativity/simplex constraints and hence can be\nsolved efficiently. Simulations confirm that the optimal transport plans/maps\nobtained with IPM-regularization are intrinsically different from those\nobtained with $\\phi$-regularization. Empirical results illustrate the efficacy\nof the proposed IPM-regularized OT formulation.\n  This draft contains the main paper and the Appendices.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:32:50 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 09:58:39 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Manupriya", "Piyushi", "", "IIT Hyderabad, INDIA"], ["Nath", "J. Saketha", "", "IIT\n  Hyderabad, INDIA"], ["Jawanpuria", "Pratik", "", "Microsoft IDC, INDIA"]]}, {"id": "2011.05002", "submitter": "Neo Christopher Chung <", "authors": "Lennart Brocki, Neo Christopher Chung", "title": "Input Bias in Rectified Gradients and Modified Saliency Maps", "comments": "2021 IEEE International Conference on Big Data and Smart Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretation and improvement of deep neural networks relies on better\nunderstanding of their underlying mechanisms. In particular, gradients of\nclasses or concepts with respect to the input features (e.g., pixels in images)\nare often used as importance scores or estimators, which are visualized in\nsaliency maps. Thus, a family of saliency methods provide an intuitive way to\nidentify input features with substantial influences on classifications or\nlatent concepts. Several modifications to conventional saliency maps, such as\nRectified Gradients and Layer-wise Relevance Propagation (LRP), have been\nintroduced to allegedly denoise and improve interpretability. While visually\ncoherent in certain cases, Rectified Gradients and other modified saliency maps\nintroduce a strong input bias (e.g., brightness in the RGB space) because of\ninappropriate uses of the input features. We demonstrate that dark areas of an\ninput image are not highlighted by a saliency map using Rectified Gradients,\neven if it is relevant for the class or concept. Even in the scaled images, the\ninput bias exists around an artificial point in color spectrum. Our\nmodification, which simply eliminates multiplication with input features,\nremoves this bias. This showcases how a visual criteria may not align with true\nexplainability of deep learning models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:45:13 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 10:48:06 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 10:34:25 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Brocki", "Lennart", ""], ["Chung", "Neo Christopher", ""]]}, {"id": "2011.05005", "submitter": "Yikai Wang", "authors": "Yikai Wang, Wenbing Huang, Fuchun Sun, Tingyang Xu, Yu Rong, Junzhou\n  Huang", "title": "Deep Multimodal Fusion by Channel Exchanging", "comments": "NeurIPS 2020. Code and models: https://github.com/yikaiw/CEN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep multimodal fusion by using multiple sources of data for classification\nor regression has exhibited a clear advantage over the unimodal counterpart on\nvarious applications. Yet, current methods including aggregation-based and\nalignment-based fusion are still inadequate in balancing the trade-off between\ninter-modal fusion and intra-modal processing, incurring a bottleneck of\nperformance improvement. To this end, this paper proposes\nChannel-Exchanging-Network (CEN), a parameter-free multimodal fusion framework\nthat dynamically exchanges channels between sub-networks of different\nmodalities. Specifically, the channel exchanging process is self-guided by\nindividual channel importance that is measured by the magnitude of\nBatch-Normalization (BN) scaling factor during training. The validity of such\nexchanging process is also guaranteed by sharing convolutional filters yet\nkeeping separate BN layers across modalities, which, as an add-on benefit,\nallows our multimodal architecture to be almost as compact as a unimodal\nnetwork. Extensive experiments on semantic segmentation via RGB-D data and\nimage translation through multi-domain input verify the effectiveness of our\nCEN compared to current state-of-the-art methods. Detailed ablation studies\nhave also been carried out, which provably affirm the advantage of each\ncomponent we propose. Our code is available at https://github.com/yikaiw/CEN.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 09:53:20 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 05:42:46 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Yikai", ""], ["Huang", "Wenbing", ""], ["Sun", "Fuchun", ""], ["Xu", "Tingyang", ""], ["Rong", "Yu", ""], ["Huang", "Junzhou", ""]]}, {"id": "2011.05009", "submitter": "Zechuan Hu", "authors": "Yang Zhou, Yong Jiang, Zechuan Hu, Kewei Tu", "title": "Neural Latent Dependency Model for Sequence Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling is a fundamental problem in machine learning, natural\nlanguage processing and many other fields. A classic approach to sequence\nlabeling is linear chain conditional random fields (CRFs). When combined with\nneural network encoders, they achieve very good performance in many sequence\nlabeling tasks. One limitation of linear chain CRFs is their inability to model\nlong-range dependencies between labels. High order CRFs extend linear chain\nCRFs by modeling dependencies no longer than their order, but the computational\ncomplexity grows exponentially in the order. In this paper, we propose the\nNeural Latent Dependency Model (NLDM) that models dependencies of arbitrary\nlength between labels with a latent tree structure. We develop an end-to-end\ntraining algorithm and a polynomial-time inference algorithm of our model. We\nevaluate our model on both synthetic and real datasets and show that our model\noutperforms strong baselines.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 10:05:21 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhou", "Yang", ""], ["Jiang", "Yong", ""], ["Hu", "Zechuan", ""], ["Tu", "Kewei", ""]]}, {"id": "2011.05013", "submitter": "Lovro Vrcek", "authors": "Lovro Vr\\v{c}ek, Petar Veli\\v{c}kovi\\'c, Mile \\v{S}iki\\'c", "title": "A step towards neural genome assembly", "comments": "NeurIPS 2020 Learning Meets Combinatorial Algorithms Workshop. 5\n  pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  De novo genome assembly focuses on finding connections between a vast amount\nof short sequences in order to reconstruct the original genome. The central\nproblem of genome assembly could be described as finding a Hamiltonian path\nthrough a large directed graph with a constraint that an unknown number of\nnodes and edges should be avoided. However, due to local structures in the\ngraph and biological features, the problem can be reduced to graph\nsimplification, which includes removal of redundant information. Motivated by\nrecent advancements in graph representation learning and neural execution of\nalgorithms, in this work we train the MPNN model with max-aggregator to execute\nseveral algorithms for graph simplification. We show that the algorithms were\nlearned successfully and can be scaled to graphs of sizes up to 20 times larger\nthan the ones used in training. We also test on graphs obtained from real-world\ngenomic data---that of a lambda phage and E. coli.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 10:12:19 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Vr\u010dek", "Lovro", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["\u0160iki\u0107", "Mile", ""]]}, {"id": "2011.05022", "submitter": "Xiatian Zhang", "authors": "Xiatian Zhang, Xunshi He, Nan Wang and Rong Chen", "title": "Distributed Learning with Low Communication Cost via Gradient Boosting\n  Untrained Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For high-dimensional data, there are huge communication costs for distributed\nGBDT because the communication volume of GBDT is related to the number of\nfeatures. To overcome this problem, we propose a novel gradient boosting\nalgorithm, the Gradient Boosting Untrained Neural Network(GBUN). GBUN ensembles\nthe untrained randomly generated neural network that softly distributes data\nsamples to multiple neuron outputs and dramatically reduces the communication\ncosts for distributed learning. To avoid creating huge neural networks for\nhigh-dimensional data, we extend Simhash algorithm to mimic forward calculation\nof the neural network. Our experiments on multiple public datasets show that\nGBUN is as good as conventional GBDT in terms of prediction accuracy and much\nbetter than it in scaling property for distributed learning. Comparing to\nconventional GBDT varieties, GBUN speeds up the training process up to 13 times\non the cluster with 64 machines, and up to 4614 times on the cluster with\n100KB/s network bandwidth. Therefore, GBUN is not only an efficient distributed\nlearning algorithm but also has great potentials for federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 10:26:57 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhang", "Xiatian", ""], ["He", "Xunshi", ""], ["Wang", "Nan", ""], ["Chen", "Rong", ""]]}, {"id": "2011.05025", "submitter": "Baudouin Denis de Senneville PhD", "authors": "Baudouin Denis de Senneville, Pierrick Coup\\'e, Mario Ries, Laurent\n  Facq, Chrit Moonen", "title": "Deep correction of breathing-related artifacts in real-time\n  MR-thermometry", "comments": "21 pages, 9 figures, 1 table", "journal-ref": "Computerized Medical Imaging and Graphics, 2020", "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time MR-imaging has been clinically adapted for monitoring thermal\ntherapies since it can provide on-the-fly temperature maps simultaneously with\nanatomical information. However, proton resonance frequency based thermometry\nof moving targets remains challenging since temperature artifacts are induced\nby the respiratory as well as physiological motion. If left uncorrected, these\nartifacts lead to severe errors in temperature estimates and impair therapy\nguidance. In this study, we evaluated deep learning for on-line correction of\nmotion related errors in abdominal MR-thermometry. For this, a convolutional\nneural network (CNN) was designed to learn the apparent temperature\nperturbation from images acquired during a preparative learning stage prior to\nhyperthermia. The input of the designed CNN is the most recent magnitude image\nand no surrogate of motion is needed. During the subsequent hyperthermia\nprocedure, the recent magnitude image is used as an input for the CNN-model in\norder to generate an on-line correction for the current temperature map. The\nmethod's artifact suppression performance was evaluated on 12 free breathing\nvolunteers and was found robust and artifact-free in all examined cases.\nFurthermore, thermometric precision and accuracy was assessed for in vivo\nablation using high intensity focused ultrasound. All calculations involved at\nthe different stages of the proposed workflow were designed to be compatible\nwith the clinical time constraints of a therapeutic procedure.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 10:30:41 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 12:53:10 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 09:20:21 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["de Senneville", "Baudouin Denis", ""], ["Coup\u00e9", "Pierrick", ""], ["Ries", "Mario", ""], ["Facq", "Laurent", ""], ["Moonen", "Chrit", ""]]}, {"id": "2011.05037", "submitter": "Ife Adebara", "authors": "Ife Adebara, El Moatez Billah Nagoudi, Muhammad Abdul Mageed", "title": "Translating Similar Languages: Role of Mutual Intelligibility in\n  Multilingual Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate different approaches to translate between similar languages\nunder low resource conditions, as part of our contribution to the WMT 2020\nSimilar Languages Translation Shared Task. We submitted Transformer-based\nbilingual and multilingual systems for all language pairs, in the two\ndirections. We also leverage back-translation for one of the language pairs,\nacquiring an improvement of more than 3 BLEU points. We interpret our results\nin light of the degree of mutual intelligibility (based on Jaccard similarity)\nbetween each pair, finding a positive correlation between mutual\nintelligibility and model performance. Our Spanish-Catalan model has the best\nperformance of all the five language pairs. Except for the case of\nHindi-Marathi, our bilingual models achieve better performance than the\nmultilingual models on all pairs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 10:58:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Adebara", "Ife", ""], ["Nagoudi", "El Moatez Billah", ""], ["Mageed", "Muhammad Abdul", ""]]}, {"id": "2011.05041", "submitter": "Lac Tran", "authors": "Gia-Lac Tran, Dimitrios Milios, Pietro Michiardi and Maurizio\n  Filippone", "title": "Sparse within Sparse Gaussian Processes using Neighbor Information", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximations to Gaussian processes based on inducing variables, combined\nwith variational inference techniques, enable state-of-the-art sparse\napproaches to infer GPs at scale through mini batch-based learning. In this\nwork, we address one limitation of sparse GPs, which is due to the challenge in\ndealing with a large number of inducing variables without imposing a special\nstructure on the inducing inputs. In particular, we introduce a novel\nhierarchical prior, which imposes sparsity on the set of inducing variables. We\ntreat our model variationally, and we experimentally show considerable\ncomputational gains compared to standard sparse GPs when sparsity on the\ninducing variables is realized considering the nearest inducing inputs of a\nrandom mini-batch of the data. We perform an extensive experimental validation\nthat demonstrates the effectiveness of our approach compared to the\nstate-of-the-art. Our approach enables the possibility to use sparse GPs using\na large number of inducing points without incurring a prohibitive computational\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:07:53 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 00:22:08 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 05:13:14 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tran", "Gia-Lac", ""], ["Milios", "Dimitrios", ""], ["Michiardi", "Pietro", ""], ["Filippone", "Maurizio", ""]]}, {"id": "2011.05047", "submitter": "Sayan Chakraborty", "authors": "Sayan Chakraborty, Smit Shah, Kiumars Soltani, Anna Swigart, Luyao\n  Yang, Kyle Buckingham", "title": "Building an Automated and Self-Aware Anomaly Detection System", "comments": "11 pages, 5 figures, Accepted to 2020 IEEE International Conference\n  on Big Data (IEEE BigData 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations rely heavily on time series metrics to measure and model key\naspects of operational and business performance. The ability to reliably detect\nissues with these metrics is imperative to identifying early indicators of\nmajor problems before they become pervasive. It can be very challenging to\nproactively monitor a large number of diverse and constantly changing time\nseries for anomalies, so there are often gaps in monitoring coverage, disabled\nor ignored monitors due to false positive alarms, and teams resorting to manual\ninspection of charts to catch problems. Traditionally, variations in the data\ngeneration processes and patterns have required strong modeling expertise to\ncreate models that accurately flag anomalies. In this paper, we describe an\nanomaly detection system that overcomes this common challenge by keeping track\nof its own performance and making changes as necessary to each model without\nrequiring manual intervention. We demonstrate that this novel approach\noutperforms available alternatives on benchmark datasets in many scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:19:07 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Chakraborty", "Sayan", ""], ["Shah", "Smit", ""], ["Soltani", "Kiumars", ""], ["Swigart", "Anna", ""], ["Yang", "Luyao", ""], ["Buckingham", "Kyle", ""]]}, {"id": "2011.05051", "submitter": "Zhibin Wang", "authors": "Zhibin Wang, Jiahang Qiu, Yong Zhou, Yuanming Shi, Liqun Fu, Wei Chen,\n  Khaled B. Lataief", "title": "Federated Learning via Intelligent Reflecting Surface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-the-air computation (AirComp) based federated learning (FL) is capable\nof achieving fast model aggregation by exploiting the waveform superposition\nproperty of multiple access channels. However, the model aggregation\nperformance is severely limited by the unfavorable wireless propagation\nchannels. In this paper, we propose to leverage intelligent reflecting surface\n(IRS) to achieve fast yet reliable model aggregation for AirComp-based FL. To\noptimize the learning performance, we formulate an optimization problem that\njointly optimizes the device selection, the aggregation beamformer at the base\nstation (BS), and the phase shifts at the IRS to maximize the number of devices\nparticipating in the model aggregation of each communication round under\ncertain mean-squared-error (MSE) requirements. To tackle the formulated\nhighly-intractable problem, we propose a two-step optimization framework.\nSpecifically, we induce the sparsity of device selection in the first step,\nfollowed by solving a series of MSE minimization problems to find the maximum\nfeasible device set in the second step. We then propose an alternating\noptimization framework, supported by the difference-of-convex-functions\nprogramming algorithm for low-rank optimization, to efficiently design the\naggregation beamformers at the BS and phase shifts at the IRS. Simulation\nresults will demonstrate that our proposed algorithm and the deployment of an\nIRS can achieve a lower training loss and higher FL prediction accuracy than\nthe baseline algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:29:57 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 01:41:23 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wang", "Zhibin", ""], ["Qiu", "Jiahang", ""], ["Zhou", "Yong", ""], ["Shi", "Yuanming", ""], ["Fu", "Liqun", ""], ["Chen", "Wei", ""], ["Lataief", "Khaled B.", ""]]}, {"id": "2011.05053", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Yingbin Liang", "title": "Sample Complexity Bounds for Two Timescale Value-based Reinforcement\n  Learning Algorithms", "comments": "Submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two timescale stochastic approximation (SA) has been widely used in\nvalue-based reinforcement learning algorithms. In the policy evaluation\nsetting, it can model the linear and nonlinear temporal difference learning\nwith gradient correction (TDC) algorithms as linear SA and nonlinear SA,\nrespectively. In the policy optimization setting, two timescale nonlinear SA\ncan also model the greedy gradient-Q (Greedy-GQ) algorithm. In previous\nstudies, the non-asymptotic analysis of linear TDC and Greedy-GQ has been\nstudied in the Markovian setting, with diminishing or accuracy-dependent\nstepsize. For the nonlinear TDC algorithm, only the asymptotic convergence has\nbeen established. In this paper, we study the non-asymptotic convergence rate\nof two timescale linear and nonlinear TDC and Greedy-GQ under Markovian\nsampling and with accuracy-independent constant stepsize. For linear TDC, we\nprovide a novel non-asymptotic analysis and show that it attains an\n$\\epsilon$-accurate solution with the optimal sample complexity of\n$\\mathcal{O}(\\epsilon^{-1}\\log(1/\\epsilon))$ under a constant stepsize. For\nnonlinear TDC and Greedy-GQ, we show that both algorithms attain\n$\\epsilon$-accurate stationary solution with sample complexity\n$\\mathcal{O}(\\epsilon^{-2})$. It is the first non-asymptotic convergence result\nestablished for nonlinear TDC under Markovian sampling and our result for\nGreedy-GQ outperforms the previous result orderwisely by a factor of\n$\\mathcal{O}(\\epsilon^{-1}\\log(1/\\epsilon))$.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:36:30 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Xu", "Tengyu", ""], ["Liang", "Yingbin", ""]]}, {"id": "2011.05054", "submitter": "Bo Li", "authors": "Bo Li, Sam Leroux, Pieter Simoens", "title": "Decoupled Appearance and Motion Learning for Efficient Anomaly Detection\n  in Surveillance Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating the analysis of surveillance video footage is of great interest\nwhen urban environments or industrial sites are monitored by a large number of\ncameras. As anomalies are often context-specific, it is hard to predefine\nevents of interest and collect labelled training data. A purely unsupervised\napproach for automated anomaly detection is much more suitable. For every\ncamera, a separate algorithm could then be deployed that learns over time a\nbaseline model of appearance and motion related features of the objects within\nthe camera viewport. Anything that deviates from this baseline is flagged as an\nanomaly for further analysis downstream. We propose a new neural network\narchitecture that learns the normal behavior in a purely unsupervised fashion.\nIn contrast to previous work, we use latent code predictions as our anomaly\nmetric. We show that this outperforms reconstruction-based and frame\nprediction-based methods on different benchmark datasets both in terms of\naccuracy and robustness against changing lighting and weather conditions. By\ndecoupling an appearance and a motion model, our model can also process 16 to\n45 times more frames per second than related approaches which makes our model\nsuitable for deploying on the camera itself or on other edge devices.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 11:40:06 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 08:56:57 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Li", "Bo", ""], ["Leroux", "Sam", ""], ["Simoens", "Pieter", ""]]}, {"id": "2011.05064", "submitter": "Herman Ho-Man Yau", "authors": "Herman Yau, Chris Russell, Simon Hadfield,", "title": "What Did You Think Would Happen? Explaining Agent Behaviour Through\n  Intended Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel form of explanation for Reinforcement Learning, based\naround the notion of intended outcome. These explanations describe the outcome\nan agent is trying to achieve by its actions. We provide a simple proof that\ngeneral methods for post-hoc explanations of this nature are impossible in\ntraditional reinforcement learning. Rather, the information needed for the\nexplanations must be collected in conjunction with training the agent. We\nderive approaches designed to extract local explanations based on intention for\nseveral variants of Q-function approximation and prove consistency between the\nexplanations and the Q-values learned. We demonstrate our method on multiple\nreinforcement learning problems, and provide code to help researchers\nintrospecting their RL environments and algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:05:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Yau", "Herman", ""], ["Russell", "Chris", ""], ["Hadfield", "Simon", ""]]}, {"id": "2011.05072", "submitter": "Juliette Achddou", "authors": "Juliette Achddou (VALDA), Olivier Capp\\'e (VALDA), Aur\\'elien Garivier\n  (UMPA-ENSL)", "title": "Efficient Algorithms for Stochastic Repeated Second-price Auctions", "comments": null, "journal-ref": "ALT 2021, Mar 2021, Paris, France", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing efficient sequential bidding strategies for repeated auctions is\nan important practical challenge in various marketing tasks. In this setting,\nthe bidding agent obtains information, on both the value of the item at sale\nand the behavior of the other bidders, only when she wins the auction. Standard\nbandit theory does not apply to this problem due to the presence of\naction-dependent censoring. In this work, we consider second-price auctions and\npropose novel, efficient UCB-like algorithms for this task. These algorithms\nare analyzed in the stochastic setting, assuming regularity of the distribution\nof the opponents' bids. We provide regret upper bounds that quantify the\nimprovement over the baseline algorithm proposed in the literature. The\nimprovement is particularly significant in cases when the value of the\nauctioned item is low, yielding a spectacular reduction in the order of the\nworst-case regret. We further provide the first parametric lower bound for this\nproblem that applies to generic UCB-like strategies. As an alternative, we\npropose more explainable strategies which are reminiscent of the Explore Then\nCommit bandit algorithm. We provide a critical analysis of this class of\nstrategies, showing both important advantages and limitations. In particular,\nwe provide a minimax lower bound and propose a nearly minimax-optimal instance\nof this class.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:45:02 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 08:04:20 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Achddou", "Juliette", "", "VALDA"], ["Capp\u00e9", "Olivier", "", "VALDA"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"]]}, {"id": "2011.05073", "submitter": "Nicolas Chiabaut", "authors": "Nicolas Chiabaut, R\\'emi Faitout", "title": "Traffic congestion and travel time prediction based on historical\n  congestion maps and identification of consensual days", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new practice-ready method for the real-time estimation of\ntraffic conditions and travel times on highways is introduced. First, after a\nprincipal component analysis, observation days of a historical dataset are\nclustered. Two different methods are compared: a Gaussian Mixture Model and a\nk-means algorithm. The clustering results reveal that congestion maps of days\nof the same group have substantial similarity in their traffic conditions and\ndynamic. Such a map is a binary visualization of the congestion propagation on\nthe freeway, giving more importance to the traffic dynamics. Second, a\nconsensus day is identified in each cluster as the most representative day of\nthe community according to the congestion maps. Third, this information\nobtained from the historical data is used to predict traffic congestion\npropagation and travel times. Thus, the first measurements of a new day are\nused to determine which consensual day is the closest to this new day. The past\nobservations recorded for that consensual day are then used to predict future\ntraffic conditions and travel times. This method is tested using ten months of\ndata collected on a French freeway and shows very encouraging results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:46:08 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 16:12:23 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Chiabaut", "Nicolas", ""], ["Faitout", "R\u00e9mi", ""]]}, {"id": "2011.05074", "submitter": "Martin Gubri", "authors": "Martin Gubri, Maxime Cordy, Mike Papadakis, Yves Le Traon", "title": "Efficient and Transferable Adversarial Examples from Bayesian Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An established way to improve the transferability of black-box evasion\nattacks is to craft the adversarial examples on a surrogate ensemble model.\nUnfortunately, such methods involve heavy computation costs to train the models\nforming the ensemble. Based on a state-of-the-art Bayesian Neural Network\ntechnique, we propose a new method to efficiently build such surrogates by\nsampling from the posterior distribution of neural network weights during a\nsingle training process. Our experiments on ImageNet and CIFAR-10 show that our\napproach improves the transfer rates of four state-of-the-art attacks\nsignificantly (between 2.5 and 44.4 percentage points), in both\nintra-architecture and inter-architecture cases. On ImageNet, our approach can\nreach 94% of transfer rate while reducing training time from 387 to 136 hours\non our infrastructure, compared to an ensemble of independently trained DNNs.\nFurthermore, our approach can be combined with test-time techniques improving\ntransferability, further increasing their effectiveness by up to 25.1\npercentage points.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:46:52 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 12:33:17 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Gubri", "Martin", ""], ["Cordy", "Maxime", ""], ["Papadakis", "Mike", ""], ["Traon", "Yves Le", ""]]}, {"id": "2011.05080", "submitter": "Steinar Laenen", "authors": "Steinar Laenen and He Sun", "title": "Higher-Order Spectral Clustering of Directed Graphs", "comments": "24 pages. To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering is an important topic in algorithms, and has a number of\napplications in machine learning, computer vision, statistics, and several\nother research disciplines. Traditional objectives of graph clustering are to\nfind clusters with low conductance. Not only are these objectives just\napplicable for undirected graphs, they are also incapable to take the\nrelationships between clusters into account, which could be crucial for many\napplications. To overcome these downsides, we study directed graphs (digraphs)\nwhose clusters exhibit further \"structural\" information amongst each other.\nBased on the Hermitian matrix representation of digraphs, we present a\nnearly-linear time algorithm for digraph clustering, and further show that our\nproposed algorithm can be implemented in sublinear time under reasonable\nassumptions. The significance of our theoretical work is demonstrated by\nextensive experimental results on the UN Comtrade Dataset: the output\nclustering of our algorithm exhibits not only how the clusters (sets of\ncountries) relate to each other with respect to their import and export\nrecords, but also how these clusters evolve over time, in accordance with known\nfacts in international trade.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:06:37 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Laenen", "Steinar", ""], ["Sun", "He", ""]]}, {"id": "2011.05082", "submitter": "Zhiguo Wang", "authors": "Zhiguo Wang, Jiawei Zhang, Tsung-Hui Chang, Jian Li and Zhi-Quan Luo", "title": "Distributed Stochastic Consensus Optimization with Momentum for\n  Nonconvex Nonsmooth Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many distributed optimization algorithms have been proposed for solving\nsmooth or convex problems over the networks, few of them can handle non-convex\nand non-smooth problems. Based on a proximal primal-dual approach, this paper\npresents a new (stochastic) distributed algorithm with Nesterov momentum for\naccelerated optimization of non-convex and non-smooth problems. Theoretically,\nwe show that the proposed algorithm can achieve an $\\epsilon$-stationary\nsolution under a constant step size with $\\mathcal{O}(1/\\epsilon^2)$\ncomputation complexity and $\\mathcal{O}(1/\\epsilon)$ communication complexity.\nWhen compared to the existing gradient tracking based methods, the proposed\nalgorithm has the same order of computation complexity but lower order of\ncommunication complexity. To the best of our knowledge, the presented result is\nthe first stochastic algorithm with the $\\mathcal{O}(1/\\epsilon)$ communication\ncomplexity for non-convex and non-smooth problems. Numerical experiments for a\ndistributed non-convex regression problem and a deep neural network based\nclassification problem are presented to illustrate the effectiveness of the\nproposed algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:12:21 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Zhiguo", ""], ["Zhang", "Jiawei", ""], ["Chang", "Tsung-Hui", ""], ["Li", "Jian", ""], ["Luo", "Zhi-Quan", ""]]}, {"id": "2011.05097", "submitter": "Manh Tuan Do", "authors": "Manh Tuan Do, Noseong Park, Kijung Shin", "title": "Two-stage Training of Graph Neural Networks for Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks (GNNs) have received massive attention in the field of\nmachine learning on graphs. Inspired by the success of neural networks, a line\nof research has been conducted to train GNNs to deal with various tasks, such\nas node classification, graph classification, and link prediction. In this\nwork, our task of interest is graph classification. Several GNN models have\nbeen proposed and shown great accuracy in this task. However, the question is\nwhether usual training methods fully realize the capacity of the GNN models.\n  In this work, we propose a two-stage training framework based on triplet\nloss. In the first stage, GNN is trained to map each graph to a Euclidean-space\nvector so that graphs of the same class are close while those of different\nclasses are mapped far apart. Once graphs are well-separated based on labels, a\nclassifier is trained to distinguish between different classes. This method is\ngeneric in the sense that it is compatible with any GNN model. By adapting five\nGNN models to our method, we demonstrate the consistent improvement in accuracy\nand utilization of each GNN's allocated capacity over the original training\nmethod of each model up to 5.4\\% points in 12 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:47:28 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 05:07:08 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 05:34:15 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Do", "Manh Tuan", ""], ["Park", "Noseong", ""], ["Shin", "Kijung", ""]]}, {"id": "2011.05110", "submitter": "Jan-Hinrich N\\\"olke", "authors": "Jan-Hinrich N\\\"olke, Tim Adler, Janek Gr\\\"ohl, Thomas Kirchner, Lynton\n  Ardizzone, Carsten Rother, Ullrich K\\\"othe, Lena Maier-Hein", "title": "Invertible Neural Networks for Uncertainty Quantification in\n  Photoacoustic Imaging", "comments": "7 pages, 4 figures, submitted to \"Bildverarbeitung f\\\"ur die Medizin\n  (BVM) 2021\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multispectral photoacoustic imaging (PAI) is an emerging imaging modality\nwhich enables the recovery of functional tissue parameters such as blood\noxygenation. However, the underlying inverse problems are potentially\nill-posed, meaning that radically different tissue properties may - in theory -\nyield comparable measurements. In this work, we present a new approach for\nhandling this specific type of uncertainty by leveraging the concept of\nconditional invertible neural networks (cINNs). Specifically, we propose going\nbeyond commonly used point estimates for tissue oxygenation and converting\nsingle-pixel initial pressure spectra to the full posterior probability\ndensity. This way, the inherent ambiguity of a problem can be encoded with\nmultiple modes in the output. Based on the presented architecture, we\ndemonstrate two use cases which leverage this information to not only detect\nand quantify but also to compensate for uncertainties: (1) photoacoustic device\ndesign and (2) optimization of photoacoustic image acquisition. Our in silico\nstudies demonstrate the potential of the proposed methodology to become an\nimportant building block for uncertainty-aware reconstruction of physiological\nparameters with PAI.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 14:17:18 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 18:11:01 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["N\u00f6lke", "Jan-Hinrich", ""], ["Adler", "Tim", ""], ["Gr\u00f6hl", "Janek", ""], ["Kirchner", "Thomas", ""], ["Ardizzone", "Lynton", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""], ["Maier-Hein", "Lena", ""]]}, {"id": "2011.05112", "submitter": "Xiangrui Zeng", "authors": "Alp Sahin and Xiangrui Zeng", "title": "Feedback-Based Dynamic Feature Selection for Constrained Continuous Data\n  Acquisition", "comments": "to be published in ACC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevant and high-quality data are critical to successful development of\nmachine learning applications. For machine learning applications on dynamic\nsystems equipped with a large number of sensors, such as connected vehicles and\nrobots, how to find relevant and high-quality data features in an efficient way\nis a challenging problem. In this work, we address the problem of feature\nselection in constrained continuous data acquisition. We propose a\nfeedback-based dynamic feature selection algorithm that efficiently decides on\nthe feature set for data collection from a dynamic system in a step-wise\nmanner. We formulate the sequential feature selection procedure as a Markov\nDecision Process. The machine learning model performance feedback with an\nexploration component is used as the reward function in an $\\epsilon$-greedy\naction selection. Our evaluation shows that the proposed feedback-based feature\nselection algorithm has superior performance over constrained baseline methods\nand matching performance with unconstrained baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 14:19:01 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 16:19:24 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sahin", "Alp", ""], ["Zeng", "Xiangrui", ""]]}, {"id": "2011.05126", "submitter": "Feihu Che", "authors": "Feihu Che, Guohua Yang, Dawei Zhang, Jianhua Tao, Pengpeng Shao, Tong\n  Liu", "title": "Self-supervised Graph Representation Learning via Bootstrapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks~(GNNs) apply deep learning techniques to\ngraph-structured data and have achieved promising performance in graph\nrepresentation learning. However, existing GNNs rely heavily on enough labels\nor well-designed negative samples. To address these issues, we propose a new\nself-supervised graph representation method: deep graph bootstrapping~(DGB).\nDGB consists of two neural networks: online and target networks, and the input\nof them are different augmented views of the initial graph. The online network\nis trained to predict the target network while the target network is updated\nwith a slow-moving average of the online network, which means the online and\ntarget networks can learn from each other. As a result, the proposed DGB can\nlearn graph representation without negative examples in an unsupervised manner.\nIn addition, we summarize three kinds of augmentation methods for\ngraph-structured data and apply them to the DGB. Experiments on the benchmark\ndatasets show the DGB performs better than the current state-of-the-art methods\nand how the augmentation methods affect the performances.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 14:47:29 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 01:14:40 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Che", "Feihu", ""], ["Yang", "Guohua", ""], ["Zhang", "Dawei", ""], ["Tao", "Jianhua", ""], ["Shao", "Pengpeng", ""], ["Liu", "Tong", ""]]}, {"id": "2011.05134", "submitter": "Danilo Numeroso", "authors": "Danilo Numeroso, Davide Bacciu", "title": "Explaining Deep Graph Networks with Molecular Counterfactuals", "comments": "6 pages, 6 figures, accepted at NeurIPS2020 Workshop on Machine\n  Learning for Molecules", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to tackle explainability of deep graph networks\nin the context of molecule property prediction tasks, named MEG (Molecular\nExplanation Generator). We generate informative counterfactual explanations for\na specific prediction under the form of (valid) compounds with high structural\nsimilarity and different predicted properties. We discuss preliminary results\nshowing how the model can convey non-ML experts with key insights into the\nlearning model focus in the neighborhood of a molecule.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 13:46:10 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Numeroso", "Danilo", ""], ["Bacciu", "Davide", ""]]}, {"id": "2011.05136", "submitter": "Ankit Singhal", "authors": "Ankit Singhal", "title": "Application and Comparison of Deep Learning Methods in the Prediction of\n  RNA Sequence Degradation and Stability", "comments": "24 pages, 17 figures - Updated Second Version after Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  mRNA vaccines are receiving increased interest as potential alternatives to\nconventional methods for the prevention of several diseases, including\nCovid-19. This paper proposes and evaluates three deep learning models (Long\nShort Term Memory networks, Gated Recurrent Unit networks, and Graph\nConvolutional Networks) as a method to predict the stability/reactivity and\nrisk of degradation of sequences of RNA. These predictions can be very useful\nin the development of mRNA vaccines as they can reduce the number of sequences\nsynthesized and tested by helping to identify the most promising candidates.\nReasonably accurate results were able to be generated with the Graph\nConvolutional Network being the best predictor of reactivity (RMSE = 0.249)\nwhile the Gated Recurrent Unit Network was the best at predicting risks of\ndegradation under various circumstances (RMSE = 0.266). Overall, combining all\ntarget variables, the GRU performed the best with an accuracy value of 76%.\nResults suggest feasibility of applying such methods in mRNA vaccine research\nin the near future.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:42:53 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 14:55:55 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Singhal", "Ankit", ""]]}, {"id": "2011.05138", "submitter": "Srivamshi Pittala", "authors": "Srivamshi Pittala, William Koehler, Jonathan Deans, Daniel Salinas,\n  Martin Bringmann, Katharina Sophia Volz, Berk Kapicioglu", "title": "Relation-weighted Link Prediction for Disease Gene Identification", "comments": "4th Knowledge Representation and Reasoning Meets Machine Learning\n  Workshop (KR2ML), NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of disease genes, which are a set of genes associated with a\ndisease, plays an important role in understanding and curing diseases. In this\npaper, we present a biomedical knowledge graph designed specifically for this\nproblem, propose a novel machine learning method that identifies disease genes\non such graphs by leveraging recent advances in network biology and graph\nrepresentation learning, study the effects of various relation types on\nprediction performance, and empirically demonstrate that our algorithms\noutperform its closest state-of-the-art competitor in disease gene\nidentification by 24.1%. We also show that we achieve higher precision than\nOpen Targets, the leading initiative for target identification, with respect to\npredicting drug targets in clinical trials for Parkinson's disease.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:09:33 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 12:20:31 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 14:48:00 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Pittala", "Srivamshi", ""], ["Koehler", "William", ""], ["Deans", "Jonathan", ""], ["Salinas", "Daniel", ""], ["Bringmann", "Martin", ""], ["Volz", "Katharina Sophia", ""], ["Kapicioglu", "Berk", ""]]}, {"id": "2011.05142", "submitter": "Qingyu Chen", "authors": "Qingyu Chen, Tiarnan D. L. Keenan, Alexis Allot, Yifan Peng, Elvira\n  Agr\\'on, Amitha Domalpally, Caroline C. W. Klaver, Daniel T. Luttikhuizen,\n  Marcus H. Colyer, Catherine A. Cukras, Henry E. Wiley, M. Teresa Magone,\n  Chantal Cousineau-Krieger, Wai T. Wong, Yingying Zhu, Emily Y. Chew, Zhiyong\n  Lu (for the AREDS2 Deep Learning Research Group)", "title": "Multi-modal, multi-task, multi-attention (M3) deep learning detection of\n  reticular pseudodrusen: towards automated and accessible classification of\n  age-related macular degeneration", "comments": "5 figures and 4 tables, To appear in Journal of the American Medical\n  Informatics Association", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective Reticular pseudodrusen (RPD), a key feature of age-related macular\ndegeneration (AMD), are poorly detected by human experts on standard color\nfundus photography (CFP) and typically require advanced imaging modalities such\nas fundus autofluorescence (FAF). The objective was to develop and evaluate the\nperformance of a novel 'M3' deep learning framework on RPD detection. Materials\nand Methods A deep learning framework M3 was developed to detect RPD presence\naccurately using CFP alone, FAF alone, or both, employing >8000 CFP-FAF image\npairs obtained prospectively (Age-Related Eye Disease Study 2). The M3\nframework includes multi-modal (detection from single or multiple image\nmodalities), multi-task (training different tasks simultaneously to improve\ngeneralizability), and multi-attention (improving ensembled feature\nrepresentation) operation. Performance on RPD detection was compared with\nstate-of-the-art deep learning models and 13 ophthalmologists; performance on\ndetection of two other AMD features (geographic atrophy and pigmentary\nabnormalities) was also evaluated. Results For RPD detection, M3 achieved area\nunder receiver operating characteristic (AUROC) 0.832, 0.931, and 0.933 for CFP\nalone, FAF alone, and both, respectively. M3 performance on CFP was very\nsubstantially superior to human retinal specialists (median F1-score 0.644\nversus 0.350). External validation (on Rotterdam Study, Netherlands)\ndemonstrated high accuracy on CFP alone (AUROC 0.965). The M3 framework also\naccurately detected geographic atrophy and pigmentary abnormalities (AUROC\n0.909 and 0.912, respectively), demonstrating its generalizability. Conclusion\nThis study demonstrates the successful development, robust evaluation, and\nexternal validation of a novel deep learning framework that enables accessible,\naccurate, and automated AMD diagnosis and prognosis.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 03:26:38 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 13:26:39 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Chen", "Qingyu", "", "for the AREDS2 Deep Learning Research Group"], ["Keenan", "Tiarnan D. L.", "", "for the AREDS2 Deep Learning Research Group"], ["Allot", "Alexis", "", "for the AREDS2 Deep Learning Research Group"], ["Peng", "Yifan", "", "for the AREDS2 Deep Learning Research Group"], ["Agr\u00f3n", "Elvira", "", "for the AREDS2 Deep Learning Research Group"], ["Domalpally", "Amitha", "", "for the AREDS2 Deep Learning Research Group"], ["Klaver", "Caroline C. W.", "", "for the AREDS2 Deep Learning Research Group"], ["Luttikhuizen", "Daniel T.", "", "for the AREDS2 Deep Learning Research Group"], ["Colyer", "Marcus H.", "", "for the AREDS2 Deep Learning Research Group"], ["Cukras", "Catherine A.", "", "for the AREDS2 Deep Learning Research Group"], ["Wiley", "Henry E.", "", "for the AREDS2 Deep Learning Research Group"], ["Magone", "M. Teresa", "", "for the AREDS2 Deep Learning Research Group"], ["Cousineau-Krieger", "Chantal", "", "for the AREDS2 Deep Learning Research Group"], ["Wong", "Wai T.", "", "for the AREDS2 Deep Learning Research Group"], ["Zhu", "Yingying", "", "for the AREDS2 Deep Learning Research Group"], ["Chew", "Emily Y.", "", "for the AREDS2 Deep Learning Research Group"], ["Lu", "Zhiyong", "", "for the AREDS2 Deep Learning Research Group"]]}, {"id": "2011.05143", "submitter": "Aditi Deokar", "authors": "Aditi Deokar", "title": "Stratification of Systemic Lupus Erythematosus Patients Using Gene\n  Expression Data to Reveal Expression of Distinct Immune Pathways", "comments": null, "journal-ref": null, "doi": "10.1101/2020.08.25.20181578", "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systemic lupus erythematosus (SLE) is the tenth leading cause of death in\nfemales 15-24 years old in the US. The diversity of symptoms and immune\npathways expressed in SLE patients causes difficulties in treating SLE as well\nas in new clinical trials. This study used unsupervised learning on gene\nexpression data from adult SLE patients to separate patients into clusters. The\ndimensionality of the gene expression data was reduced by three separate\nmethods (PCA, UMAP, and a simple linear autoencoder) and the results from each\nof these methods were used to separate patients into six clusters with k-means\nclustering.\n  The clusters revealed three separate immune pathways in the SLE patients that\ncaused SLE. These pathways were: (1) high interferon levels, (2) high\nautoantibody levels, and (3) dysregulation of the mitochondrial apoptosis\npathway. The first two pathways have been extensively studied in SLE. However,\nmitochondrial apoptosis has not been investigated before to the best of our\nknowledge as a standalone cause of SLE, independent of autoantibody production,\nindicating that mitochondrial proteins could lead to a new set of therapeutic\ntargets for SLE in future research.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 00:32:24 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Deokar", "Aditi", ""]]}, {"id": "2011.05149", "submitter": "Eva van Weenen", "authors": "Eva van Weenen and Stefan Feuerriegel", "title": "Estimating Risk-Adjusted Hospital Performance", "comments": "Accepted at the 2020 IEEE International Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of healthcare provided by hospitals is subject to considerable\nvariability. Consequently, accurate measurements of hospital performance are\nessential for various decision-makers, including patients, hospital managers\nand health insurers. Hospital performance is assessed via the health outcomes\nof their patients. However, as the risk profiles of patients between hospitals\nvary, measuring hospital performance requires adjustment for patient risk. This\ntask is formalized in the state-of-the-art procedure through a hierarchical\ngeneralized linear model, that isolates hospital fixed-effects from the effect\nof patient risk on health outcomes. Due to the linear nature of this approach,\nany non-linear relations or interaction terms between risk variables are\nneglected.\n  In this work, we propose a novel method for measuring hospital performance\nadjusted for patient risk. This method captures non-linear relationships as\nwell as interactions among patient risk variables, specifically the effect of\nco-occurring health conditions on health outcomes. For this purpose, we develop\na tailored neural network architecture that is partially interpretable: a\nnon-linear part is used to encode risk factors, while a linear structure models\nhospital fixed-effects, such that the risk-adjusted hospital performance can be\nestimated. We base our evaluation on more than 13 million patient admissions\nacross almost 1,900 US hospitals as provided by the Nationwide Readmissions\nDatabase. Our model improves the ROC-AUC over the state-of-the-art by 4.1\npercent. These findings demonstrate that a large portion of the variance in\nhealth outcomes can be attributed to non-linear relationships between patient\nrisk variables and implicate that the current approach of measuring hospital\nperformance should be expanded.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:14:51 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 10:43:05 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["van Weenen", "Eva", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "2011.05157", "submitter": "Tianjin Huang", "authors": "Tianjin Huang, Vlado Menkovski, Yulong Pei, Mykola Pechenizkiy", "title": "Bridging the Performance Gap between FGSM and PGD Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning achieves state-of-the-art performance in many tasks but exposes\nto the underlying vulnerability against adversarial examples. Across existing\ndefense techniques, adversarial training with the projected gradient decent\nattack (adv.PGD) is considered as one of the most effective ways to achieve\nmoderate adversarial robustness. However, adv.PGD requires too much training\ntime since the projected gradient attack (PGD) takes multiple iterations to\ngenerate perturbations. On the other hand, adversarial training with the fast\ngradient sign method (adv.FGSM) takes much less training time since the fast\ngradient sign method (FGSM) takes one step to generate perturbations but fails\nto increase adversarial robustness. In this work, we extend adv.FGSM to make it\nachieve the adversarial robustness of adv.PGD. We demonstrate that the large\ncurvature along FGSM perturbed direction leads to a large difference in\nperformance of adversarial robustness between adv.FGSM and adv.PGD, and\ntherefore propose combining adv.FGSM with a curvature regularization\n(adv.FGSMR) in order to bridge the performance gap between adv.FGSM and\nadv.PGD. The experiments show that adv.FGSMR has higher training efficiency\nthan adv.PGD. In addition, it achieves comparable performance of adversarial\nrobustness on MNIST dataset under white-box attack, and it achieves better\nperformance than adv.PGD under white-box attack and effectively defends the\ntransferable adversarial attack on CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:08:54 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Huang", "Tianjin", ""], ["Menkovski", "Vlado", ""], ["Pei", "Yulong", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2011.05158", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro", "title": "GANterpretations", "comments": "In 4th Workshop on Machine Learning for Creativity and Design at\n  NeurIPS 2020, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the introduction of Generative Adversarial Networks (GANs) [Goodfellow\net al., 2014] there has been a regular stream of both technical advances (e.g.,\nArjovsky et al. [2017]) and creative uses of these generative models (e.g.,\n[Karras et al., 2019, Zhu et al., 2017, Jin et al., 2017]). In this work we\npropose an approach for using the power of GANs to automatically generate\nvideos to accompany audio recordings by aligning to spectral properties of the\nrecording. This allows musicians to explore new forms of multi-modal creative\nexpression, where musical performance can induce an AI-generated musical video\nthat is guided by said performance, as well as a medium for creating a visual\nnarrative to follow a storyline (similar to what was proposed by Frosst and\nKereliuk [2019]).\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 19:08:40 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Castro", "Pablo Samuel", ""]]}, {"id": "2011.05161", "submitter": "Guanghui Xu", "authors": "Guanghui Xu, Wei Song, Zhengchen Zhang, Chao Zhang, Xiaodong He, Bowen\n  Zhou", "title": "Improving Prosody Modelling with Cross-Utterance BERT Embeddings for\n  End-to-end Speech Synthesis", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite prosody is related to the linguistic information up to the discourse\nstructure, most text-to-speech (TTS) systems only take into account that within\neach sentence, which makes it challenging when converting a paragraph of texts\ninto natural and expressive speech. In this paper, we propose to use the text\nembeddings of the neighboring sentences to improve the prosody generation for\neach utterance of a paragraph in an end-to-end fashion without using any\nexplicit prosody features. More specifically, cross-utterance (CU) context\nvectors, which are produced by an additional CU encoder based on the sentence\nembeddings extracted by a pre-trained BERT model, are used to augment the input\nof the Tacotron2 decoder. Two types of BERT embeddings are investigated, which\nleads to the use of different CU encoder structures. Experimental results on a\nMandarin audiobook dataset and the LJ-Speech English audiobook dataset\ndemonstrate the use of CU information can improve the naturalness and\nexpressiveness of the synthesized speech. Subjective listening testing shows\nmost of the participants prefer the voice generated using the CU encoder over\nthat generated using standard Tacotron2. It is also found that the prosody can\nbe controlled indirectly by changing the neighbouring sentences.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:03:11 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Xu", "Guanghui", ""], ["Song", "Wei", ""], ["Zhang", "Zhengchen", ""], ["Zhang", "Chao", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "2011.05186", "submitter": "Tao Tan", "authors": "Tao Tan, Bipul Das, Ravi Soni, Mate Fejes, Sohan Ranjan, Daniel Attila\n  Szabo, Vikram Melapudi, K S Shriram, Utkarsh Agrawal, Laszlo Rusko, Zita\n  Herczeg, Barbara Darazs, Pal Tegzes, Lehel Ferenczi, Rakesh Mullick, Gopal\n  Avinash", "title": "Pristine annotations-based multi-modal trained artificial intelligence\n  solution to triage chest X-ray for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The COVID-19 pandemic continues to spread and impact the well-being of the\nglobal population. The front-line modalities including computed tomography (CT)\nand X-ray play an important role for triaging COVID patients. Considering the\nlimited access of resources (both hardware and trained personnel) and\ndecontamination considerations, CT may not be ideal for triaging suspected\nsubjects. Artificial intelligence (AI) assisted X-ray based applications for\ntriaging and monitoring require experienced radiologists to identify COVID\npatients in a timely manner and to further delineate the disease region\nboundary are seen as a promising solution. Our proposed solution differs from\nexisting solutions by industry and academic communities, and demonstrates a\nfunctional AI model to triage by inferencing using a single x-ray image, while\nthe deep-learning model is trained using both X-ray and CT data. We report on\nhow such a multi-modal training improves the solution compared to X-ray only\ntraining. The multi-modal solution increases the AUC (area under the receiver\noperating characteristic curve) from 0.89 to 0.93 and also positively impacts\nthe Dice coefficient (0.59 to 0.62) for localizing the pathology. To the best\nour knowledge, it is the first X-ray solution by leveraging multi-modal\ninformation for the development.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:36:08 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tan", "Tao", ""], ["Das", "Bipul", ""], ["Soni", "Ravi", ""], ["Fejes", "Mate", ""], ["Ranjan", "Sohan", ""], ["Szabo", "Daniel Attila", ""], ["Melapudi", "Vikram", ""], ["Shriram", "K S", ""], ["Agrawal", "Utkarsh", ""], ["Rusko", "Laszlo", ""], ["Herczeg", "Zita", ""], ["Darazs", "Barbara", ""], ["Tegzes", "Pal", ""], ["Ferenczi", "Lehel", ""], ["Mullick", "Rakesh", ""], ["Avinash", "Gopal", ""]]}, {"id": "2011.05188", "submitter": "Jupinder Parmar", "authors": "Jupinder Parmar, William Koehler, Martin Bringmann, Katharina Sophia\n  Volz, Berk Kapicioglu", "title": "Biomedical Information Extraction for Disease Gene Prioritization", "comments": "4th Knowledge Representation and Reasoning Meets Machine Learning\n  Workshop (KR2ML), at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a biomedical information extraction (IE) pipeline that extracts\nbiological relationships from text and demonstrate that its components, such as\nnamed entity recognition (NER) and relation extraction (RE), outperform\nstate-of-the-art in BioNLP. We apply it to tens of millions of PubMed abstracts\nto extract protein-protein interactions (PPIs) and augment these extractions to\na biomedical knowledge graph that already contains PPIs extracted from STRING,\nthe leading structured PPI database. We show that, despite already containing\nPPIs from an established structured source, augmenting our own IE-based\nextractions to the graph allows us to predict novel disease-gene associations\nwith a 20% relative increase in hit@30, an important step towards developing\ndrug targets for uncured diseases.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:38:42 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 16:56:12 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Parmar", "Jupinder", ""], ["Koehler", "William", ""], ["Bringmann", "Martin", ""], ["Volz", "Katharina Sophia", ""], ["Kapicioglu", "Berk", ""]]}, {"id": "2011.05194", "submitter": "Jayaraj Poroor", "authors": "Jayaraj Poroor", "title": "MotePy: A domain specific language for low-overhead machine learning and\n  data processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A domain specific language (DSL), named MotePy is presented. The DSL offers a\nhigh level syntax with low overheads for ML/data processing in time constrained\nor memory constrained systems. The DSL-to-C compiler has a novel static memory\nallocator that tracks object lifetimes and reuses the static memory, which we\ncall the compiler-managed heap.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:49:45 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 04:31:29 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Poroor", "Jayaraj", ""]]}, {"id": "2011.05197", "submitter": "Gabriele Sarti", "authors": "Gabriele Sarti", "title": "UmBERTo-MTSA @ AcCompl-It: Improving Complexity and Acceptability\n  Prediction with Multi-task Learning on Self-Supervised Annotations", "comments": "5 pages, Best system award for the AcCompl-It shared task at the\n  EVALITA 2020 workshop", "journal-ref": "Proceedings of the Seventh Evaluation Campaign of Natural Language\n  Processing and Speech Tools for Italian. Final Workshop (EVALITA 2020)", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work describes a self-supervised data augmentation approach used to\nimprove learning models' performances when only a moderate amount of labeled\ndata is available. Multiple copies of the original model are initially trained\non the downstream task. Their predictions are then used to annotate a large set\nof unlabeled examples. Finally, multi-task training is performed on the\nparallel annotations of the resulting training set, and final scores are\nobtained by averaging annotator-specific head predictions. Neural language\nmodels are fine-tuned using this procedure in the context of the AcCompl-it\nshared task at EVALITA 2020, obtaining considerable improvements in prediction\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 15:50:37 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Sarti", "Gabriele", ""]]}, {"id": "2011.05208", "submitter": "Zekarias Tilahun Kefato", "authors": "Zekarias T. Kefato and Sarunas Girdzijauskas and Nasrullah Sheikh and\n  Alberto Montresor", "title": "Dynamic Embeddings for Interaction Prediction", "comments": "Accepted for the International World Wide Web Conference Committee,\n  WWW'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recommender systems (RSs), predicting the next item that a user interacts\nwith is critical for user retention. While the last decade has seen an\nexplosion of RSs aimed at identifying relevant items that match user\npreferences, there is still a range of aspects that could be considered to\nfurther improve their performance. For example, often RSs are centered around\nthe user, who is modeled using her recent sequence of activities. Recent\nstudies, however, have shown the effectiveness of modeling the mutual\ninteractions between users and items using separate user and item embeddings.\nBuilding on the success of these studies, we propose a novel method called\nDeePRed that addresses some of their limitations. In particular, we avoid\nrecursive and costly interactions between consecutive short-term embeddings by\nusing long-term (stationary) embeddings as a proxy. This enable us to train\nDeePRed using simple mini-batches without the overhead of specialized\nmini-batches proposed in previous studies. Moreover, DeePRed's effectiveness\ncomes from the aforementioned design and a multi-way attention mechanism that\ninspects user-item compatibility. Experiments show that DeePRed outperforms the\nbest state-of-the-art approach by at least 14% on next item prediction task,\nwhile gaining more than an order of magnitude speedup over the best performing\nbaselines. Although this study is mainly concerned with temporal interaction\nnetworks, we also show the power and flexibility of DeePRed by adapting it to\nthe case of static interaction networks, substituting the short- and long-term\naspects with local and global ones.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:04:46 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 20:35:36 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kefato", "Zekarias T.", ""], ["Girdzijauskas", "Sarunas", ""], ["Sheikh", "Nasrullah", ""], ["Montresor", "Alberto", ""]]}, {"id": "2011.05217", "submitter": "Hany Abdulsamad", "authors": "Hany Abdulsamad, Peter Nickl, Pascal Klink, Jan Peters", "title": "A Variational Infinite Mixture for Probabilistic Inverse Dynamics\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic regression techniques in control and robotics applications have\nto fulfill different criteria of data-driven adaptability, computational\nefficiency, scalability to high dimensions, and the capacity to deal with\ndifferent modalities in the data. Classical regressors usually fulfill only a\nsubset of these properties. In this work, we extend seminal work on Bayesian\nnonparametric mixtures and derive an efficient variational Bayes inference\ntechnique for infinite mixtures of probabilistic local polynomial models with\nwell-calibrated certainty quantification. We highlight the model's power in\ncombining data-driven complexity adaptation, fast prediction and the ability to\ndeal with discontinuous functions and heteroscedastic noise. We benchmark this\ntechnique on a range of large real inverse dynamics datasets, showing that the\ninfinite mixture formulation is competitive with classical Local Learning\nmethods and regularizes model complexity by adapting the number of components\nbased on data and without relying on heuristics. Moreover, to showcase the\npracticality of the approach, we use the learned models for online inverse\ndynamics control of a Barrett-WAM manipulator, significantly improving the\ntrajectory tracking performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:15:13 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 09:05:11 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 08:51:07 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Abdulsamad", "Hany", ""], ["Nickl", "Peter", ""], ["Klink", "Pascal", ""], ["Peters", "Jan", ""]]}, {"id": "2011.05227", "submitter": "Th\\'eo Ayral", "authors": "Th\\'eo Ayral, Marco Pedersoli, Simon Bacon and Eric Granger", "title": "Temporal Stochastic Softmax for 3D CNNs: An Application in Facial\n  Expression Recognition", "comments": "Accepted to WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep learning models for accurate spatiotemporal recognition of\nfacial expressions in videos requires significant computational resources. For\npractical reasons, 3D Convolutional Neural Networks (3D CNNs) are usually\ntrained with relatively short clips randomly extracted from videos. However,\nsuch uniform sampling is generally sub-optimal because equal importance is\nassigned to each temporal clip. In this paper, we present a strategy for\nefficient video-based training of 3D CNNs. It relies on softmax temporal\npooling and a weighted sampling mechanism to select the most relevant training\nclips. The proposed softmax strategy provides several advantages: a reduced\ncomputational complexity due to efficient clip sampling, and an improved\naccuracy since temporal weighting focuses on more relevant clips during both\ntraining and inference. Experimental results obtained with the proposed method\non several facial expression recognition benchmarks show the benefits of\nfocusing on more informative clips in training videos. In particular, our\napproach improves performance and computational cost by reducing the impact of\ninaccurate trimming and coarse annotation of videos, and heterogeneous\ndistribution of visual information across time.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:40:00 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Ayral", "Th\u00e9o", ""], ["Pedersoli", "Marco", ""], ["Bacon", "Simon", ""], ["Granger", "Eric", ""]]}, {"id": "2011.05231", "submitter": "Elliott Gordon-Rodriguez", "authors": "Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, Geoff Pleiss, John P.\n  Cunningham", "title": "Uses and Abuses of the Cross-Entropy Loss: Case Studies in Modern Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning is primarily an experimental science, in which empirical\nadvances occasionally come at the expense of probabilistic rigor. Here we focus\non one such example; namely the use of the categorical cross-entropy loss to\nmodel data that is not strictly categorical, but rather takes values on the\nsimplex. This practice is standard in neural network architectures with label\nsmoothing and actor-mimic reinforcement learning, amongst others. Drawing on\nthe recently discovered continuous-categorical distribution, we propose\nprobabilistically-inspired alternatives to these models, providing an approach\nthat is more principled and theoretically appealing. Through careful\nexperimentation, including an ablation study, we identify the potential for\noutperformance in these models, thereby highlighting the importance of a proper\nprobabilistic treatment, as well as illustrating some of the failure modes\nthereof.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:44:35 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Gordon-Rodriguez", "Elliott", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Pleiss", "Geoff", ""], ["Cunningham", "John P.", ""]]}, {"id": "2011.05243", "submitter": "Mete Ahishali", "authors": "Mete Ahishali, Serkan Kiranyaz, Turker Ince, Moncef Gabbouj", "title": "Classification of Polarimetric SAR Images Using Compact Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of polarimetric synthetic aperture radar (PolSAR) images is an\nactive research area with a major role in environmental applications. The\ntraditional Machine Learning (ML) methods proposed in this domain generally\nfocus on utilizing highly discriminative features to improve the classification\nperformance, but this task is complicated by the well-known \"curse of\ndimensionality\" phenomena. Other approaches based on deep Convolutional Neural\nNetworks (CNNs) have certain limitations and drawbacks, such as high\ncomputational complexity, an unfeasibly large training set with ground-truth\nlabels, and special hardware requirements. In this work, to address the\nlimitations of traditional ML and deep CNN based methods, a novel and\nsystematic classification framework is proposed for the classification of\nPolSAR images, based on a compact and adaptive implementation of CNNs using a\nsliding-window classification approach. The proposed approach has three\nadvantages. First, there is no requirement for an extensive feature extraction\nprocess. Second, it is computationally efficient due to utilized compact\nconfigurations. In particular, the proposed compact and adaptive CNN model is\ndesigned to achieve the maximum classification accuracy with minimum training\nand computational complexity. This is of considerable importance considering\nthe high costs involved in labelling in PolSAR classification. Finally, the\nproposed approach can perform classification using smaller window sizes than\ndeep CNNs. Experimental evaluations have been performed over the most\ncommonly-used four benchmark PolSAR images: AIRSAR L-Band and RADARSAT-2 C-Band\ndata of San Francisco Bay and Flevoland areas. Accordingly, the best obtained\noverall accuracies range between 92.33 - 99.39% for these benchmark study\nsites.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:09:11 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Ahishali", "Mete", ""], ["Kiranyaz", "Serkan", ""], ["Ince", "Turker", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2011.05244", "submitter": "Marion Ullmo", "authors": "Marion Ullmo, Aur\\'elien Decelle, Nabila Aghanim", "title": "Encoding large scale cosmological structure with Generative Adversarial\n  Networks", "comments": "submitted for publication in A&A, 15 pages", "journal-ref": null, "doi": "10.1051/0004-6361/202039866", "report-no": null, "categories": "astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a type of neural networks called Generative Adversarial Networks\n(GANs) has been proposed as a solution for fast generation of simulation-like\ndatasets, in an attempt to bypass heavy computations and expensive cosmological\nsimulations to run in terms of time and computing power. In the present work,\nwe build and train a GAN to look further into the strengths and limitations of\nsuch an approach. We then propose a novel method in which we make use of a\ntrained GAN to construct a simple autoencoder (AE) as a first step towards\nbuilding a predictive model. Both the GAN and AE are trained on images issued\nfrom two types of N-body simulations, namely 2D and 3D simulations. We find\nthat the GAN successfully generates new images that are statistically\nconsistent with the images it was trained on. We then show that the AE manages\nto efficiently extract information from simulation images, satisfyingly\ninferring the latent encoding of the GAN to generate an image with similar\nlarge scale structures.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:11:14 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ullmo", "Marion", ""], ["Decelle", "Aur\u00e9lien", ""], ["Aghanim", "Nabila", ""]]}, {"id": "2011.05254", "submitter": "Yongwei Wang", "authors": "Yongwei Wang, Mingquan Feng, Rabab Ward, Z. Jane Wang, Lanjun Wang", "title": "Perception Improvement for Free: Exploring Imperceptible Black-box\n  Adversarial Attacks on Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial attacks. White-box\nadversarial attacks can fool neural networks with small adversarial\nperturbations, especially for large size images. However, keeping successful\nadversarial perturbations imperceptible is especially challenging for\ntransfer-based black-box adversarial attacks. Often such adversarial examples\ncan be easily spotted due to their unpleasantly poor visual qualities, which\ncompromises the threat of adversarial attacks in practice. In this study, to\nimprove the image quality of black-box adversarial examples perceptually, we\npropose structure-aware adversarial attacks by generating adversarial images\nbased on psychological perceptual models. Specifically, we allow higher\nperturbations on perceptually insignificant regions, while assigning lower or\nno perturbation on visually sensitive regions. In addition to the proposed\nspatial-constrained adversarial perturbations, we also propose a novel\nstructure-aware frequency adversarial attack method in the discrete cosine\ntransform (DCT) domain. Since the proposed attacks are independent of the\ngradient estimation, they can be directly incorporated with existing\ngradient-based attacks. Experimental results show that, with the comparable\nattack success rate (ASR), the proposed methods can produce adversarial\nexamples with considerably improved visual quality for free. With the\ncomparable perceptual quality, the proposed approaches achieve higher attack\nsuccess rates: particularly for the frequency structure-aware attacks, the\naverage ASR improves more than 10% over the baseline attacks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 07:17:12 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Yongwei", ""], ["Feng", "Mingquan", ""], ["Ward", "Rabab", ""], ["Wang", "Z. Jane", ""], ["Wang", "Lanjun", ""]]}, {"id": "2011.05260", "submitter": "Mohammadreza Baharani", "authors": "Mohammadreza Baharani, Steven Furgurson, Babak Parkhideh, Hamed Tabkhi", "title": "ATCN: Agile Temporal Convolutional Networks for Processing of Time\n  Series on Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a scalable deep learning model called Agile Temporal\nConvolutional Network (ATCN) for high-accurate fast classification and time\nseries prediction in resource-constrained embedded systems. ATCN is primarily\ndesigned for mobile embedded systems with performance and memory constraints\nsuch as wearable biomedical devices and real-time reliability monitoring\nsystems. It makes fundamental improvements over the mainstream temporal\nconvolutional neural networks, including the incorporation of separable\ndepth-wise convolution to reduce the computational complexity of the model and\nresidual connections as time attention machines, increase the network depth and\naccuracy. The result of this configurability makes the ATCN a family of compact\nnetworks with formalized hyper-parameters that allow the model architecture to\nbe configurable and adjusted based on the application requirements. We\ndemonstrate the capabilities of our proposed ATCN on accuracy and performance\ntrade-off on three embedded applications, including transistor reliability\nmonitoring, heartbeat classification of ECG signals, and digit classification.\nOur comparison results against state-of-the-art approaches demonstrate much\nlower computation and memory demand for faster processing with better\nprediction and classification accuracy. The source code of the ATCN model is\npublicly available at https://github.com/TeCSAR-UNCC/ATCN.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:26:49 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 23:30:04 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Baharani", "Mohammadreza", ""], ["Furgurson", "Steven", ""], ["Parkhideh", "Babak", ""], ["Tabkhi", "Hamed", ""]]}, {"id": "2011.05267", "submitter": "Chaoyun Zhang", "authors": "Chaoyun Zhang", "title": "Deep Neural Mobile Networking", "comments": "PhD thesis, University of Edinburgh (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation of mobile networks is set to become increasingly complex,\nas these struggle to accommodate tremendous data traffic demands generated by\never-more connected devices that have diverse performance requirements in terms\nof throughput, latency, and reliability. This makes monitoring and managing the\nmultitude of network elements intractable with existing tools and impractical\nfor traditional machine learning algorithms that rely on hand-crafted feature\nengineering. In this context, embedding machine intelligence into mobile\nnetworks becomes necessary, as this enables systematic mining of valuable\ninformation from mobile big data and automatically uncovering correlations that\nwould otherwise have been too difficult to extract by human experts. In\nparticular, deep learning based solutions can automatically extract features\nfrom raw data, without human expertise. The performance of artificial\nintelligence (AI) has achieved in other domains draws unprecedented interest\nfrom both academia and industry in employing deep learning approaches to\naddress technical challenges in mobile networks. This thesis attacks important\nproblems in the mobile networking area from various perspectives by harnessing\nrecent advances in deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 09:23:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhang", "Chaoyun", ""]]}, {"id": "2011.05268", "submitter": "Hanlin Zhang", "authors": "Wangchunshu Zhou, Jinyi Hu, Hanlin Zhang, Xiaodan Liang, Maosong Sun,\n  Chenyan Xiong, Jian Tang", "title": "Towards Interpretable Natural Language Understanding with Explanations\n  as Latent Variables", "comments": "NeurIPS 2020. The first three authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently generating natural language explanations has shown very promising\nresults in not only offering interpretable explanations but also providing\nadditional information and supervision for prediction. However, existing\napproaches usually require a large set of human annotated explanations for\ntraining while collecting a large set of explanations is not only time\nconsuming but also expensive. In this paper, we develop a general framework for\ninterpretable natural language understanding that requires only a small set of\nhuman annotated explanations for training. Our framework treats natural\nlanguage explanations as latent variables that model the underlying reasoning\nprocess of a neural model. We develop a variational EM framework for\noptimization where an explanation generation module and an\nexplanation-augmented prediction module are alternatively optimized and\nmutually enhance each other. Moreover, we further propose an explanation-based\nself-training method under this framework for semi-supervised learning. It\nalternates between assigning pseudo-labels to unlabeled data and generating new\nexplanations to iteratively improve each other. Experiments on two natural\nlanguage understanding tasks demonstrate that our framework can not only make\neffective predictions in both supervised and semi-supervised settings, but also\ngenerate good natural language explanation.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 02:05:56 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 12:24:08 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Hu", "Jinyi", ""], ["Zhang", "Hanlin", ""], ["Liang", "Xiaodan", ""], ["Sun", "Maosong", ""], ["Xiong", "Chenyan", ""], ["Tang", "Jian", ""]]}, {"id": "2011.05285", "submitter": "Lukas Olson", "authors": "Tirth Shah, Lukas Olson, Aditya Sharma, Nirmal Patel", "title": "Explainable Knowledge Tracing Models for Big Data: Is Ensembling an\n  Answer?", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we describe our Knowledge Tracing model for the 2020 NeurIPS\nEducation Challenge. We used a combination of 22 models to predict whether the\nstudents will answer a given question correctly or not. Our combination of\ndifferent approaches allowed us to get an accuracy higher than any of the\nindividual models, and the variation of our model types gave our solution\nbetter explainability, more alignment with learning science theories, and high\npredictive power.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:06:29 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Shah", "Tirth", ""], ["Olson", "Lukas", ""], ["Sharma", "Aditya", ""], ["Patel", "Nirmal", ""]]}, {"id": "2011.05286", "submitter": "Kelvin Xu", "authors": "Kelvin Xu, Siddharth Verma, Chelsea Finn, Sergey Levine", "title": "Continual Learning of Control Primitives: Skill Discovery via\n  Reset-Games", "comments": "To appear at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning has the potential to automate the acquisition of\nbehavior in complex settings, but in order for it to be successfully deployed,\na number of practical challenges must be addressed. First, in real world\nsettings, when an agent attempts a task and fails, the environment must somehow\n\"reset\" so that the agent can attempt the task again. While easy in simulation,\nthis could require considerable human effort in the real world, especially if\nthe number of trials is very large. Second, real world learning often involves\ncomplex, temporally extended behavior that is often difficult to acquire with\nrandom exploration. While these two problems may at first appear unrelated, in\nthis work, we show how a single method can allow an agent to acquire skills\nwith minimal supervision while removing the need for resets. We do this by\nexploiting the insight that the need to \"reset\" an agent to a broad set of\ninitial states for a learning task provides a natural setting to learn a\ndiverse set of \"reset-skills\". We propose a general-sum game formulation that\nbalances the objectives of resetting and learning skills, and demonstrate that\nthis approach improves performance on reset-free tasks, and additionally show\nthat the skills we obtain can be used to significantly accelerate downstream\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:07:44 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Xu", "Kelvin", ""], ["Verma", "Siddharth", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""]]}, {"id": "2011.05289", "submitter": "Nicholas Vadivelu", "authors": "Nicholas Vadivelu, Mengye Ren, James Tu, Jingkang Wang, Raquel Urtasun", "title": "Learning to Communicate and Correct Pose Errors", "comments": "Conference on Robot Learning (CoRL) 2020. 16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned communication makes multi-agent systems more effective by aggregating\ndistributed information. However, it also exposes individual agents to the\nthreat of erroneous messages they might receive. In this paper, we study the\nsetting proposed in V2VNet, where nearby self-driving vehicles jointly perform\nobject detection and motion forecasting in a cooperative manner. Despite a huge\nperformance boost when the agents solve the task together, the gain is quickly\ndiminished in the presence of pose noise since the communication relies on\nspatial transformations. Hence, we propose a novel neural reasoning framework\nthat learns to communicate, to estimate potential errors, and finally, to reach\na consensus about those errors. Experiments confirm that our proposed framework\nsignificantly improves the robustness of multi-agent self-driving perception\nand motion forecasting systems under realistic and severe localization noise.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:19:40 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Vadivelu", "Nicholas", ""], ["Ren", "Mengye", ""], ["Tu", "James", ""], ["Wang", "Jingkang", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2011.05290", "submitter": "Aditi Krishnapriyan", "authors": "Arnur Nigmetov, Aditi S. Krishnapriyan, Nicole Sanderson, Dmitriy\n  Morozov", "title": "Topological Regularization via Persistence-Sensitive Optimization", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization, a key tool in machine learning and statistics, relies on\nregularization to reduce overfitting. Traditional regularization methods\ncontrol a norm of the solution to ensure its smoothness. Recently, topological\nmethods have emerged as a way to provide a more precise and expressive control\nover the solution, relying on persistent homology to quantify and reduce its\nroughness. All such existing techniques back-propagate gradients through the\npersistence diagram, which is a summary of the topological features of a\nfunction. Their downside is that they provide information only at the critical\npoints of the function. We propose a method that instead builds on\npersistence-sensitive simplification and translates the required changes to the\npersistence diagram into changes on large subsets of the domain, including both\ncritical and regular points. This approach enables a faster and more precise\ntopological regularization, the benefits of which we illustrate with\nexperimental evidence.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:19:43 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Nigmetov", "Arnur", ""], ["Krishnapriyan", "Aditi S.", ""], ["Sanderson", "Nicole", ""], ["Morozov", "Dmitriy", ""]]}, {"id": "2011.05296", "submitter": "Jonathan Passerat-Palmbach", "authors": "Veneta Haralampieva and Daniel Rueckert and Jonathan Passerat-Palmbach", "title": "A Systematic Comparison of Encrypted Machine Learning Solutions for\n  Image Classification", "comments": null, "journal-ref": "PPMLP'20: Proceedings of the 2020 Workshop on Privacy-Preserving\n  Machine Learning in Practice", "doi": "10.1145/3411501.3419432", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This work provides a comprehensive review of existing frameworks based on\nsecure computing techniques in the context of private image classification. The\nin-depth analysis of these approaches is followed by careful examination of\ntheir performance costs, in particular runtime and communication overhead.\n  To further illustrate the practical considerations when using different\nprivacy-preserving technologies, experiments were conducted using four\nstate-of-the-art libraries implementing secure computing at the heart of the\ndata science stack: PySyft and CrypTen supporting private inference via Secure\nMulti-Party Computation, TF-Trusted utilising Trusted Execution Environments\nand HE- Transformer relying on Homomorphic encryption.\n  Our work aims to evaluate the suitability of these frameworks from a\nusability, runtime requirements and accuracy point of view. In order to better\nunderstand the gap between state-of-the-art protocols and what is currently\navailable in practice for a data scientist, we designed three neural network\narchitecture to obtain secure predictions via each of the four aforementioned\nframeworks. Two networks were evaluated on the MNIST dataset and one on the\nMalaria Cell image dataset. We observed satisfying performances for TF-Trusted\nand CrypTen and noted that all frameworks perfectly preserved the accuracy of\nthe corresponding plaintext model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:33:31 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 12:31:55 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Haralampieva", "Veneta", ""], ["Rueckert", "Daniel", ""], ["Passerat-Palmbach", "Jonathan", ""]]}, {"id": "2011.05301", "submitter": "Eda Bayram", "authors": "Eda Bayram and Alberto Garcia-Duran and Robert West", "title": "Node Attribute Completion in Knowledge Graphs with Multi-Relational\n  Propagation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing literature on knowledge graph completion mostly focuses on the\nlink prediction task. However, knowledge graphs have an additional\nincompleteness problem: their nodes possess numerical attributes, whose values\nare often missing. Our approach, denoted as MrAP, imputes the values of missing\nattributes by propagating information across the multi-relational structure of\na knowledge graph. It employs regression functions for predicting one node\nattribute from another depending on the relationship between the nodes and the\ntype of the attributes. The propagation mechanism operates iteratively in a\nmessage passing scheme that collects the predictions at every iteration and\nupdates the value of the node attributes. Experiments over two benchmark\ndatasets show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:36:33 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Bayram", "Eda", ""], ["Garcia-Duran", "Alberto", ""], ["West", "Robert", ""]]}, {"id": "2011.05302", "submitter": "Stefanos Antaris", "authors": "Stefanos Antaris, Dimitrios Rafailidis, Mohammad Aliannejadi", "title": "On Estimating the Training Cost of Conversational Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational recommendation systems have recently gain a lot of attention,\nas users can continuously interact with the system over multiple conversational\nturns. However, conversational recommendation systems are based on complex\nneural architectures, thus the training cost of such models is high. To shed\nlight on the high computational training time of state-of-the art\nconversational models, we examine five representative strategies and\ndemonstrate this issue. Furthermore, we discuss possible ways to cope with the\nhigh training cost following knowledge distillation strategies, where we detail\nthe key challenges to reduce the online inference time of the high number of\nmodel parameters in conversational recommendation systems\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:37:10 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Antaris", "Stefanos", ""], ["Rafailidis", "Dimitrios", ""], ["Aliannejadi", "Mohammad", ""]]}, {"id": "2011.05309", "submitter": "Alexander Ritchie", "authors": "Alexander Ritchie, Laura Balzano, Daniel Kessler, Chandra S. Sripada,\n  Clayton Scott", "title": "Supervised PCA: A Multiobjective Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for supervised principal component analysis (SPCA) aim to incorporate\nlabel information into principal component analysis (PCA), so that the\nextracted features are more useful for a prediction task of interest. Prior\nwork on SPCA has focused primarily on optimizing prediction error, and has\nneglected the value of maximizing variance explained by the extracted features.\nWe propose a new method for SPCA that addresses both of these objectives\njointly, and demonstrate empirically that our approach dominates existing\napproaches, i.e., outperforms them with respect to both prediction error and\nvariation explained. Our approach accommodates arbitrary supervised learning\nlosses and, through a statistical reformulation, provides a novel low-rank\nextension of generalized linear models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:46:58 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 21:15:41 GMT"}, {"version": "v3", "created": "Sat, 13 Mar 2021 18:33:37 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ritchie", "Alexander", ""], ["Balzano", "Laura", ""], ["Kessler", "Daniel", ""], ["Sripada", "Chandra S.", ""], ["Scott", "Clayton", ""]]}, {"id": "2011.05315", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, Samuel Deng, Sanjam Garg, Somesh Jha, Saeed\n  Mahloujifar, Mohammad Mahmoody, Shuang Song, Abhradeep Thakurta, Florian\n  Tramer", "title": "Is Private Learning Possible with Instance Encoding?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A private machine learning algorithm hides as much as possible about its\ntraining data while still preserving accuracy. In this work, we study whether a\nnon-private learning algorithm can be made private by relying on an\ninstance-encoding mechanism that modifies the training inputs before feeding\nthem to a normal learner. We formalize both the notion of instance encoding and\nits privacy by providing two attack models. We first prove impossibility\nresults for achieving a (stronger) model. Next, we demonstrate practical\nattacks in the second (weaker) attack model on InstaHide, a recent proposal by\nHuang, Song, Li and Arora [ICML'20] that aims to use instance encoding for\nprivacy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:55:20 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 01:18:36 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Carlini", "Nicholas", ""], ["Deng", "Samuel", ""], ["Garg", "Sanjam", ""], ["Jha", "Somesh", ""], ["Mahloujifar", "Saeed", ""], ["Mahmoody", "Mohammad", ""], ["Song", "Shuang", ""], ["Thakurta", "Abhradeep", ""], ["Tramer", "Florian", ""]]}, {"id": "2011.05348", "submitter": "Raed Al Kontar", "authors": "Xubo Yue, Maher Nouiehed, Raed Al Kontar", "title": "SALR: Sharpness-aware Learning Rates for Improved Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In an effort to improve generalization in deep learning, we propose SALR: a\nsharpness-aware learning rate update technique designed to recover flat\nminimizers. Our method dynamically updates the learning rate of gradient-based\noptimizers based on the local sharpness of the loss function. This allows\noptimizers to automatically increase learning rates at sharp valleys to\nincrease the chance of escaping them. We demonstrate the effectiveness of SALR\nwhen adopted by various algorithms over a broad range of networks. Our\nexperiments indicate that SALR improves generalization, converges faster, and\ndrives solutions to significantly flatter regions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 19:00:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Yue", "Xubo", ""], ["Nouiehed", "Maher", ""], ["Kontar", "Raed Al", ""]]}, {"id": "2011.05354", "submitter": "Maxime Mulamba Ke Tchomba", "authors": "Maxime Mulamba, Jayanta Mandi, Michelangelo Diligenti, Michele\n  Lombardi, Victor Bucarey, Tias Guns", "title": "Contrastive Losses and Solution Caching for Predict-and-Optimize", "comments": "Accepted at IJCAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decision-making processes involve solving a combinatorial optimization\nproblem with uncertain input that can be estimated from historic data.\nRecently, problems in this class have been successfully addressed via\nend-to-end learning approaches, which rely on solving one optimization problem\nfor each training instance at every epoch. In this context, we provide two\ndistinct contributions. First, we use a Noise Contrastive approach to motivate\na family of surrogate loss functions, based on viewing non-optimal solutions as\nnegative examples. Second, we address a major bottleneck of all\npredict-and-optimize approaches, i.e. the need to frequently recompute optimal\nsolutions at training time. This is done via a solver-agnostic solution caching\nscheme, and by replacing optimization calls with a lookup in the solution\ncache. The method is formally based on an inner approximation of the feasible\nspace and, combined with a cache lookup strategy, provides a controllable\ntrade-off between training time and accuracy of the loss approximation. We\nempirically show that even a very slow growth rate is enough to match the\nquality of state-of-the-art methods, at a fraction of the computational cost.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 19:09:12 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 10:39:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mulamba", "Maxime", ""], ["Mandi", "Jayanta", ""], ["Diligenti", "Michelangelo", ""], ["Lombardi", "Michele", ""], ["Bucarey", "Victor", ""], ["Guns", "Tias", ""]]}, {"id": "2011.05363", "submitter": "Hanjun Dai", "authors": "Hanjun Dai, Rishabh Singh, Bo Dai, Charles Sutton, Dale Schuurmans", "title": "Learning Discrete Energy-based Models via Auxiliary-variable Local\n  Exploration", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete structures play an important role in applications like program\nlanguage modeling and software engineering. Current approaches to predicting\ncomplex structures typically consider autoregressive models for their\ntractability, with some sacrifice in flexibility. Energy-based models (EBMs) on\nthe other hand offer a more flexible and thus more powerful approach to\nmodeling such distributions, but require partition function estimation. In this\npaper we propose ALOE, a new algorithm for learning conditional and\nunconditional EBMs for discrete structured data, where parameter gradients are\nestimated using a learned sampler that mimics local search. We show that the\nenergy function and sampler can be trained efficiently via a new variational\nform of power iteration, achieving a better trade-off between flexibility and\ntractability. Experimentally, we show that learning local search leads to\nsignificant improvements in challenging application domains. Most notably, we\npresent an energy model guided fuzzer for software testing that achieves\ncomparable performance to well engineered fuzzing engines like libfuzzer.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 19:31:29 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Dai", "Hanjun", ""], ["Singh", "Rishabh", ""], ["Dai", "Bo", ""], ["Sutton", "Charles", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2011.05364", "submitter": "Steffen Ridderbusch", "authors": "Steffen Ridderbusch, Christian Offen, Sina Ober-Bl\\\"obaum, Paul\n  Goulart", "title": "Learning ODE Models with Qualitative Structure Using Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in learning techniques have enabled the modelling of\ndynamical systems for scientific and engineering applications directly from\ndata. However, in many contexts explicit data collection is expensive and\nlearning algorithms must be data-efficient to be feasible. This suggests using\nadditional qualitative information about the system, which is often available\nfrom prior experiments or domain knowledge. We propose an approach to learning\na vector field of differential equations using sparse Gaussian Processes that\nallows us to combine data and additional structural information, like Lie Group\nsymmetries and fixed points. We show that this combination improves\nextrapolation performance and long-term behaviour significantly, while also\nreducing the computational cost.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 19:34:07 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 17:28:44 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ridderbusch", "Steffen", ""], ["Offen", "Christian", ""], ["Ober-Bl\u00f6baum", "Sina", ""], ["Goulart", "Paul", ""]]}, {"id": "2011.05369", "submitter": "Jared Willard", "authors": "Jared D. Willard, Jordan S. Read, Alison P. Appling, Samantha K.\n  Oliver, Xiaowei Jia, Vipin Kumar", "title": "Predicting Water Temperature Dynamics of Unmonitored Lakes with Meta\n  Transfer Learning", "comments": "28 pages, 8 figures, Water Resources Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most environmental data come from a minority of well-monitored sites. An\nongoing challenge in the environmental sciences is transferring knowledge from\nmonitored sites to unmonitored sites. Here, we demonstrate a novel transfer\nlearning framework that accurately predicts depth-specific temperature in\nunmonitored lakes (targets) by borrowing models from well-monitored lakes\n(sources). This method, Meta Transfer Learning (MTL), builds a meta-learning\nmodel to predict transfer performance from candidate source models to targets\nusing lake attributes and candidates' past performance. We constructed source\nmodels at 145 well-monitored lakes using calibrated process-based modeling (PB)\nand a recently developed approach called process-guided deep learning (PGDL).\nWe applied MTL to either PB or PGDL source models (PB-MTL or PGDL-MTL,\nrespectively) to predict temperatures in 305 target lakes treated as\nunmonitored in the Upper Midwestern United States. We show significantly\nimproved performance relative to the uncalibrated process-based General Lake\nModel, where the median RMSE for the target lakes is $2.52^{\\circ}C$. PB-MTL\nyielded a median RMSE of $2.43^{\\circ}C$; PGDL-MTL yielded $2.16^{\\circ}C$; and\na PGDL-MTL ensemble of nine sources per target yielded $1.88^{\\circ}C$. For\nsparsely monitored target lakes, PGDL-MTL often outperformed PGDL models\ntrained on the target lakes themselves. Differences in maximum depth between\nthe source and target were consistently the most important predictors. Our\napproach readily scales to thousands of lakes in the Midwestern United States,\ndemonstrating that MTL with meaningful predictor variables and high-quality\nsource models is a promising approach for many kinds of unmonitored systems and\nenvironmental variables.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 19:44:52 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 18:26:43 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Willard", "Jared D.", ""], ["Read", "Jordan S.", ""], ["Appling", "Alison P.", ""], ["Oliver", "Samantha K.", ""], ["Jia", "Xiaowei", ""], ["Kumar", "Vipin", ""]]}, {"id": "2011.05373", "submitter": "Bowen Baker", "authors": "Bowen Baker", "title": "Emergent Reciprocity and Team Formation from Randomized Uncertain Social\n  Preferences", "comments": "to be published in NeurIPS 2020 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) has shown recent success in\nincreasingly complex fixed-team zero-sum environments. However, the real world\nis not zero-sum nor does it have fixed teams; humans face numerous social\ndilemmas and must learn when to cooperate and when to compete. To successfully\ndeploy agents into the human world, it may be important that they be able to\nunderstand and help in our conflicts. Unfortunately, selfish MARL agents\ntypically fail when faced with social dilemmas. In this work, we show evidence\nof emergent direct reciprocity, indirect reciprocity and reputation, and team\nformation when training agents with randomized uncertain social preferences\n(RUSP), a novel environment augmentation that expands the distribution of\nenvironments agents play in. RUSP is generic and scalable; it can be applied to\nany multi-agent environment without changing the original underlying game\ndynamics or objectives. In particular, we show that with RUSP these behaviors\ncan emerge and lead to higher social welfare equilibria in both classic\nabstract social dilemmas like Iterated Prisoner's Dilemma as well in more\ncomplex intertemporal environments.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 20:06:19 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Baker", "Bowen", ""]]}, {"id": "2011.05383", "submitter": "Meghana Madhyastha", "authors": "Meghana Madhyastha, Kunal Lillaney, James Browne, Joshua Vogelstein,\n  Randal Burns", "title": "PACSET (Packed Serialized Trees): Reducing Inference Latency for Tree\n  Ensemble Deployment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present methods to serialize and deserialize tree ensembles that optimize\ninference latency when models are not already loaded into memory. This arises\nwhenever models are larger than memory, but also systematically when models are\ndeployed on low-resource devices, such as in the Internet of Things, or run as\nWeb micro-services where resources are allocated on demand. Our packed\nserialized trees (PACSET) encode reference locality in the layout of a tree\nensemble using principles from external memory algorithms. The layout\ninterleaves correlated nodes across multiple trees, uses leaf cardinality to\ncollocate the nodes on the most popular paths and is optimized for the I/O\nblocksize. The result is that each I/O yields a higher fraction of useful data,\nleading to a 2-6 times reduction in classification latency for interactive\nworkloads.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 20:32:11 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Madhyastha", "Meghana", ""], ["Lillaney", "Kunal", ""], ["Browne", "James", ""], ["Vogelstein", "Joshua", ""], ["Burns", "Randal", ""]]}, {"id": "2011.05384", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu, Georg Menz, Deanna Needell, Christopher Strohmeier", "title": "Applications of Online Nonnegative Matrix Factorization to Image and\n  Time-Series Data", "comments": "9 pages, 8 figures", "journal-ref": "2020 Information Theory and Applications Workshop (ITA)", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online nonnegative matrix factorization (ONMF) is a matrix factorization\ntechnique in the online setting where data are acquired in a streaming fashion\nand the matrix factors are updated each time. This enables factor analysis to\nbe performed concurrently with the arrival of new data samples. In this\narticle, we demonstrate how one can use online nonnegative matrix factorization\nalgorithms to learn joint dictionary atoms from an ensemble of correlated data\nsets. We propose a temporal dictionary learning scheme for time-series data\nsets, based on ONMF algorithms. We demonstrate our dictionary learning\ntechnique in the application contexts of historical temperature data, video\nframes, and color images.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 20:33:20 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Menz", "Georg", ""], ["Needell", "Deanna", ""], ["Strohmeier", "Christopher", ""]]}, {"id": "2011.05389", "submitter": "Dana Fisman", "authors": "Dana Fisman and Hadar Frenkel and Sandra Zilles", "title": "On the Complexity of Symbolic Finite-State Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the complexity of procedures on SFAs (such as intersection,\nemptiness, etc.) and analyze them according to the measures we find suitable\nfor symbolic automata: the number of states, the maximal number of transitions\nexiting a state, and the size of the most complex transition predicate. We pay\nattention to the special forms of SFAs: {normalized SFAs} and {neat SFAs}, as\nwell as to SFAs over a {monotonic} effective Boolean algebra.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 20:55:55 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 21:13:57 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 12:57:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Fisman", "Dana", ""], ["Frenkel", "Hadar", ""], ["Zilles", "Sandra", ""]]}, {"id": "2011.05390", "submitter": "Matthieu Puigt", "authors": "Farouk Yahaya, Matthieu Puigt, Gilles Delmaire and Gilles Roussel", "title": "Gaussian Compression Stream: Principle and Preliminary Results", "comments": "in Proceedings of iTWIST'20, Paper-ID: 11, Nantes, France. December\n  2-4, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projections became popular tools to process big data. In particular,\nwhen applied to Nonnegative Matrix Factorization (NMF), it was shown that\nstructured random projections were far more efficient than classical strategies\nbased on Gaussian compression. However, they remain costly and might not fully\nbenefit from recent fast random projection techniques. In this paper, we thus\ninvestigate an alternative to structured ran-om projections-named Gaussian\ncompression stream-which (i) is based on Gaussian compressions only, (ii) can\nbenefit from the above fast techniques, and (iii) is shown to be well-suited to\nNMF.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 20:56:15 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 16:19:29 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Yahaya", "Farouk", ""], ["Puigt", "Matthieu", ""], ["Delmaire", "Gilles", ""], ["Roussel", "Gilles", ""]]}, {"id": "2011.05399", "submitter": "Zhou Zhou", "authors": "Zhou Zhou, Shashank Jere, Lizhong Zheng, Lingjia Liu", "title": "Learning for Integer-Constrained Optimization through Neural Networks\n  with Limited Training", "comments": null, "journal-ref": "NeurIPS 2020 Workshop on Learning Meets Combinatorial Algorithms", "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a neural network-based learning approach\ntowards solving an integer-constrained programming problem using very limited\ntraining. To be specific, we introduce a symmetric and decomposed neural\nnetwork structure, which is fully interpretable in terms of the functionality\nof its constituent components. By taking advantage of the underlying pattern of\nthe integer constraint, as well as of the affine nature of the objective\nfunction, the introduced neural network offers superior generalization\nperformance with limited training, as compared to other generic neural network\nstructures that do not exploit the inherent structure of the integer\nconstraint. In addition, we show that the introduced decomposed approach can be\nfurther extended to semi-decomposed frameworks. The introduced learning\napproach is evaluated via the classification/symbol detection task in the\ncontext of wireless communication systems where available training sets are\nusually limited. Evaluation results demonstrate that the introduced learning\nstrategy is able to effectively perform the classification/symbol detection\ntask in a wide variety of wireless channel environments specified by the 3GPP\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:17:07 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhou", "Zhou", ""], ["Jere", "Shashank", ""], ["Zheng", "Lizhong", ""], ["Liu", "Lingjia", ""]]}, {"id": "2011.05410", "submitter": "Tomasz Pieciak", "authors": "Azam Hamidinekoo, Tomasz Pieciak, Maryam Afzali, Otar Akanyeti, Yinyin\n  Yuan", "title": "Glioma Classification Using Multimodal Radiology and Histology Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gliomas are brain tumours with a high mortality rate. There are various\ngrades and sub-types of this tumour, and the treatment procedure varies\naccordingly. Clinicians and oncologists diagnose and categorise these tumours\nbased on visual inspection of radiology and histology data. However, this\nprocess can be time-consuming and subjective. The computer-assisted methods can\nhelp clinicians to make better and faster decisions. In this paper, we propose\na pipeline for automatic classification of gliomas into three sub-types:\noligodendroglioma, astrocytoma, and glioblastoma, using both radiology and\nhistopathology images. The proposed approach implements distinct classification\nmodels for radiographic and histologic modalities and combines them through an\nensemble method. The classification algorithm initially carries out tile-level\n(for histology) and slice-level (for radiology) classification via a deep\nlearning method, then tile/slice-level latent features are combined for a\nwhole-slide and whole-volume sub-type prediction. The classification algorithm\nwas evaluated using the data set provided in the CPM-RadPath 2020 challenge.\nThe proposed pipeline achieved the F1-Score of 0.886, Cohen's Kappa score of\n0.811 and Balance accuracy of 0.860. The ability of the proposed model for\nend-to-end learning of diverse features enables it to give a comparable\nprediction of glioma tumour sub-types.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:38:26 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Hamidinekoo", "Azam", ""], ["Pieciak", "Tomasz", ""], ["Afzali", "Maryam", ""], ["Akanyeti", "Otar", ""], ["Yuan", "Yinyin", ""]]}, {"id": "2011.05411", "submitter": "Nguyen Truong", "authors": "Nguyen Truong, Kai Sun, Siyao Wang, Florian Guitton, Yike Guo", "title": "Privacy Preservation in Federated Learning: An insightful survey from\n  the GDPR Perspective", "comments": "21 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Along with the blooming of AI and Machine Learning-based applications and\nservices, data privacy and security have become a critical challenge.\nConventionally, data is collected and aggregated in a data centre on which\nmachine learning models are trained. This centralised approach has induced\nsevere privacy risks to personal data leakage, misuse, and abuse. Furthermore,\nin the era of the Internet of Things and big data in which data is essentially\ndistributed, transferring a vast amount of data to a data centre for processing\nseems to be a cumbersome solution. This is not only because of the difficulties\nin transferring and sharing data across data sources but also the challenges on\ncomplying with rigorous data protection regulations and complicated\nadministrative procedures such as the EU General Data Protection Regulation\n(GDPR). In this respect, Federated learning (FL) emerges as a prospective\nsolution that facilitates distributed collaborative learning without disclosing\noriginal training data whilst naturally complying with the GDPR. Recent\nresearch has demonstrated that retaining data and computation on-device in FL\nis not sufficient enough for privacy-guarantee. This is because ML model\nparameters exchanged between parties in an FL system still conceal sensitive\ninformation, which can be exploited in some privacy attacks. Therefore, FL\nsystems shall be empowered by efficient privacy-preserving techniques to comply\nwith the GDPR. This article is dedicated to surveying on the state-of-the-art\nprivacy-preserving techniques which can be employed in FL in a systematic\nfashion, as well as how these techniques mitigate data security and privacy\nrisks. Furthermore, we provide insights into the challenges along with\nprospective approaches following the GDPR regulatory guidelines that an FL\nsystem shall implement to comply with the GDPR.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:41:25 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 18:06:17 GMT"}, {"version": "v3", "created": "Sat, 23 Jan 2021 02:07:36 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 13:15:01 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 12:32:28 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Truong", "Nguyen", ""], ["Sun", "Kai", ""], ["Wang", "Siyao", ""], ["Guitton", "Florian", ""], ["Guo", "Yike", ""]]}, {"id": "2011.05416", "submitter": "Abhijit Suprem", "authors": "Calton Pu, Abhijit Suprem, and Rodrigo Alves Lima", "title": "Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 04:15:44 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Pu", "Calton", ""], ["Suprem", "Abhijit", ""], ["Lima", "Rodrigo Alves", ""]]}, {"id": "2011.05421", "submitter": "Alan Smeaton", "authors": "Simranjeet Singh and Rajneesh Sharma and Alan F. Smeaton", "title": "Using GANs to Synthesise Minimum Training Data for Deepfake Generation", "comments": "13 pages, 6 figures, 2 tables, appears in Proceedings of 28th Irish\n  Conference on Artificial Intelligence and Cognitive Science AICS2020,\n  December 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many applications of Generative Adversarial Networks (GANs) in\nfields like computer vision, natural language processing, speech synthesis, and\nmore. Undoubtedly the most notable results have been in the area of image\nsynthesis and in particular in the generation of deepfake videos. While\ndeepfakes have received much negative media coverage, they can be a useful\ntechnology in applications like entertainment, customer relations, or even\nassistive care. One problem with generating deepfakes is the requirement for a\nlot of image training data of the subject which is not an issue if the subject\nis a celebrity for whom many images already exist. If there are only a small\nnumber of training images then the quality of the deepfake will be poor. Some\nmedia reports have indicated that a good deepfake can be produced with as few\nas 500 images but in practice, quality deepfakes require many thousands of\nimages, one of the reasons why deepfakes of celebrities and politicians have\nbecome so popular. In this study, we exploit the property of a GAN to produce\nimages of an individual with variable facial expressions which we then use to\ngenerate a deepfake. We observe that with such variability in facial\nexpressions of synthetic GAN-generated training images and a reduced quantity\nof them, we can produce a near-realistic deepfake videos.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:05:38 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Singh", "Simranjeet", ""], ["Sharma", "Rajneesh", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "2011.05424", "submitter": "Maegan Tucker", "authors": "Maegan Tucker, Noel Csomay-Shanklin, Wen-Loong Ma, and Aaron D. Ames", "title": "Preference-Based Learning for User-Guided HZD Gait Generation on Bipedal\n  Walking Robots", "comments": "6 pages + 1 page references; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework that leverages both control theory and\nmachine learning to obtain stable and robust bipedal locomotion without the\nneed for manual parameter tuning. Traditionally, gaits are generated through\ntrajectory optimization methods and then realized experimentally -- a process\nthat often requires extensive tuning due to differences between the models and\nhardware. In this work, the process of gait realization via hybrid zero\ndynamics (HZD) based optimization is formally combined with preference-based\nlearning to systematically realize dynamically stable walking. Importantly,\nthis learning approach does not require a carefully constructed reward\nfunction, but instead utilizes human pairwise preferences. The power of the\nproposed approach is demonstrated through two experiments on a planar biped\nAMBER-3M: the first with rigid point-feet, and the second with induced model\nuncertainty through the addition of springs where the added compliance was not\naccounted for in the gait generation or in the controller. In both experiments,\nthe framework achieves stable, robust, efficient, and natural walking in fewer\nthan 50 iterations with no reliance on a simulation environment. These results\ndemonstrate a promising step in the unification of control theory and learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:15:56 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 18:31:09 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Tucker", "Maegan", ""], ["Csomay-Shanklin", "Noel", ""], ["Ma", "Wen-Loong", ""], ["Ames", "Aaron D.", ""]]}, {"id": "2011.05429", "submitter": "Julius Adebayo", "authors": "Julius Adebayo, Michael Muelly, Ilaria Liccardi, Been Kim", "title": "Debugging Tests for Model Explanations", "comments": "A shorter version of this work will appear at Neurips 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate whether post-hoc model explanations are effective for\ndiagnosing model errors--model debugging. In response to the challenge of\nexplaining a model's prediction, a vast array of explanation methods have been\nproposed. Despite increasing use, it is unclear if they are effective. To\nstart, we categorize \\textit{bugs}, based on their source, into:~\\textit{data,\nmodel, and test-time} contamination bugs. For several explanation methods, we\nassess their ability to: detect spurious correlation artifacts (data\ncontamination), diagnose mislabeled training examples (data contamination),\ndifferentiate between a (partially) re-initialized model and a trained one\n(model contamination), and detect out-of-distribution inputs (test-time\ncontamination). We find that the methods tested are able to diagnose a spurious\nbackground bug, but not conclusively identify mislabeled training examples. In\naddition, a class of methods, that modify the back-propagation algorithm are\ninvariant to the higher layer parameters of a deep network; hence, ineffective\nfor diagnosing model contamination. We complement our analysis with a human\nsubject study, and find that subjects fail to identify defective models using\nattributions, but instead rely, primarily, on model predictions. Taken\ntogether, our results provide guidance for practitioners and researchers\nturning to explanations as tools for model debugging.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:23:25 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Adebayo", "Julius", ""], ["Muelly", "Michael", ""], ["Liccardi", "Ilaria", ""], ["Kim", "Been", ""]]}, {"id": "2011.05431", "submitter": "Nikolaos Stylianou", "authors": "Nikolaos Stylianou, Ioannis Vlahavas", "title": "E.T.: Entity-Transformers. Coreference augmented Neural Language Model\n  for richer mention representations via Entity-Transformer blocks", "comments": "10 pages, 4 figures, 5 tables, accepted at CRAC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, the field of Neural Language Modelling has witnessed\nenormous changes, with the development of novel models through the use of\nTransformer architectures. However, even these models struggle to model long\nsequences due to memory constraints and increasing computational complexity.\nCoreference annotations over the training data can provide context far beyond\nthe modelling limitations of such language models. In this paper we present an\nextension over the Transformer-block architecture used in neural language\nmodels, specifically in GPT2, in order to incorporate entity annotations during\ntraining. Our model, GPT2E, extends the Transformer layers architecture of GPT2\nto Entity-Transformers, an architecture designed to handle coreference\ninformation when present. To that end, we achieve richer representations for\nentity mentions, with insignificant training cost. We show the comparative\nmodel performance between GPT2 and GPT2E in terms of Perplexity on the CoNLL\n2012 and LAMBADA datasets as well as the key differences in the entity\nrepresentations and their effects in downstream tasks such as Named Entity\nRecognition. Furthermore, our approach can be adopted by the majority of\nTransformer-based language models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:28:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Stylianou", "Nikolaos", ""], ["Vlahavas", "Ioannis", ""]]}, {"id": "2011.05435", "submitter": "Yuxiang Wu", "authors": "Yuxiang Wu, Sebastian Riedel, Pasquale Minervini, Pontus Stenetorp", "title": "Don't Read Too Much into It: Adaptive Computation for Open-Domain\n  Question Answering", "comments": "11 pages, 9 figures, presented in EMNLP 2020 main conference and\n  SustaiNLP 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most approaches to Open-Domain Question Answering consist of a light-weight\nretriever that selects a set of candidate passages, and a computationally\nexpensive reader that examines the passages to identify the correct answer.\nPrevious works have shown that as the number of retrieved passages increases,\nso does the performance of the reader. However, they assume all retrieved\npassages are of equal importance and allocate the same amount of computation to\nthem, leading to a substantial increase in computational cost. To reduce this\ncost, we propose the use of adaptive computation to control the computational\nbudget allocated for the passages to be read. We first introduce a technique\noperating on individual passages in isolation which relies on anytime\nprediction and a per-layer estimation of an early exit probability. We then\nintroduce SkylineBuilder, an approach for dynamically deciding on which passage\nto allocate computation at each step, based on a resource allocation policy\ntrained via reinforcement learning. Our results on SQuAD-Open show that\nadaptive computation with global prioritisation improves over several strong\nstatic and adaptive methods, leading to a 4.3x reduction in computation while\nretaining 95% performance of the full model.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:37:56 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wu", "Yuxiang", ""], ["Riedel", "Sebastian", ""], ["Minervini", "Pasquale", ""], ["Stenetorp", "Pontus", ""]]}, {"id": "2011.05446", "submitter": "Sneha Aenugu", "authors": "Sneha Aenugu", "title": "Perturbation-based exploration methods in deep reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on structured exploration placed emphasis on identifying\nnovel states in the state space and incentivizing the agent to revisit them\nthrough intrinsic reward bonuses. In this study, we question whether the\nperformance boost demonstrated through these methods is indeed due to the\ndiscovery of structure in exploratory schedule of the agent or is the benefit\nlargely attributed to the perturbations in the policy and reward space\nmanifested in pursuit of structured exploration. In this study we investigate\nthe effect of perturbations in policy and reward spaces on the exploratory\nbehavior of the agent. We proceed to show that simple acts of perturbing the\npolicy just before the softmax layer and introduction of sporadic reward\nbonuses into the domain can greatly enhance exploration in several domains of\nthe arcade learning environment. In light of these findings, we recommend\nbenchmarking any enhancements to structured exploration research against the\nbackdrop of noisy exploration.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:57:51 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Aenugu", "Sneha", ""]]}, {"id": "2011.05466", "submitter": "Jia Li", "authors": "Jia Li, Xiaowei Jia, Haoyu Yang, Vipin Kumar, Michael Steinbach,\n  Gyorgy Simon", "title": "Teaching deep learning causal effects improves predictive performance", "comments": "9 pages, 8 figures, in the process of SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is a powerful statistical methodology for explanatory\nanalysis and individualized treatment effect (ITE) estimation, a prominent\ncausal inference task that has become a fundamental research problem. ITE\nestimation, when performed naively, tends to produce biased estimates. To\nobtain unbiased estimates, counterfactual information is needed, which is not\ndirectly observable from data. Based on mature domain knowledge, reliable\ntraditional methods to estimate ITE exist. In recent years, neural networks\nhave been widely used in clinical studies. Specifically, recurrent neural\nnetworks (RNN) have been applied to temporal Electronic Health Records (EHR)\ndata analysis. However, RNNs are not guaranteed to automatically discover\ncausal knowledge, correctly estimate counterfactual information, and thus\ncorrectly estimate the ITE. This lack of correct ITE estimates can hinder the\nperformance of the model. In this work we study whether RNNs can be guided to\ncorrectly incorporate ITE-related knowledge and whether this improves\npredictive performance. Specifically, we first describe a Causal-Temporal\nStructure for temporal EHR data; then based on this structure, we estimate\nsequential ITE along the timeline, using sequential Propensity Score Matching\n(PSM); and finally, we propose a knowledge-guided neural network methodology to\nincorporate estimated ITE. We demonstrate on real-world and synthetic data\n(where the actual ITEs are known) that the proposed methodology can\nsignificantly improve the prediction performance of RNN.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 00:01:14 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Li", "Jia", ""], ["Jia", "Xiaowei", ""], ["Yang", "Haoyu", ""], ["Kumar", "Vipin", ""], ["Steinbach", "Michael", ""], ["Simon", "Gyorgy", ""]]}, {"id": "2011.05471", "submitter": "Carla Sofia Carvalho", "authors": "Carla Sofia Carvalho", "title": "A deep-learning classifier for cardiac arrhythmias", "comments": "To appear in the IEEE BIBE 2020 conference proceedings\n  (peer-reviewed)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on a method that classifies heart beats according to a set of 13\nclasses, including cardiac arrhythmias. The method localises the QRS peak\ncomplex to define each heart beat and uses a neural network to infer the\npatterns characteristic of each heart beat class. The best performing neural\nnetwork contains six one-dimensional convolutional layers and four dense\nlayers, with the kernel sizes being multiples of the characteristic scale of\nthe problem, thus resulting a computationally fast and physically motivated\nneural network. For the same number of heart beat classes, our method yields\nbetter results with a considerably smaller neural network than previously\npublished methods, which renders our method competitive for deployment in an\ninternet-of-things solution.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 00:13:15 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Carvalho", "Carla Sofia", ""]]}, {"id": "2011.05476", "submitter": "Seyed Amin Fadaee", "authors": "Seyed Amin Fadaee, Maryam Amir Haeri", "title": "Multi-Label Classification Using Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving classification with graph methods has gained huge popularity in\nrecent years. This is due to the fact that the data can be intuitively modeled\nwith graphs to utilize high level features to aid in solving the classification\nproblem. CULP which is short for Classification Using Link Prediction is a\ngraph-based classifier. This classifier utilizes the graph representation of\nthe data and transforms the problem to that of link prediction where we try to\nfind the link between an unlabeled node and the proper class node for it. CULP\nproved to be highly accurate classifier and it has the power to predict the\nlabels in near constant time. A variant of the classification problem is\nmulti-label classification which tackles this problem for multi-label data\nwhere an instance can have multiple labels associated to it. In this work, we\nextend the CULP algorithm to address this problem. Our proposed extensions\nconveys the powers of CULP and its intuitive representation of the data in to\nthe multi-label domain and in comparison to some of the cutting edge\nmulti-label classifiers, yield competitive results.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 00:20:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Fadaee", "Seyed Amin", ""], ["Haeri", "Maryam Amir", ""]]}, {"id": "2011.05479", "submitter": "Jeremy Irvin", "authors": "Jeremy Irvin, Hao Sheng, Neel Ramachandran, Sonja Johnson-Yu, Sharon\n  Zhou, Kyle Story, Rose Rustowicz, Cooper Elsworth, Kemen Austin, Andrew Y. Ng", "title": "ForestNet: Classifying Drivers of Deforestation in Indonesia using Deep\n  Learning on Satellite Imagery", "comments": "Tackling Climate Change with Machine Learning at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the processes leading to deforestation is critical to the\ndevelopment and implementation of targeted forest conservation and management\npolicies. In this work, we develop a deep learning model called ForestNet to\nclassify the drivers of primary forest loss in Indonesia, a country with one of\nthe highest deforestation rates in the world. Using satellite imagery,\nForestNet identifies the direct drivers of deforestation in forest loss patches\nof any size. We curate a dataset of Landsat 8 satellite images of known forest\nloss events paired with driver annotations from expert interpreters. We use the\ndataset to train and validate the models and demonstrate that ForestNet\nsubstantially outperforms other standard driver classification approaches. In\norder to support future research on automated approaches to deforestation\ndriver classification, the dataset curated in this study is publicly available\nat https://stanfordmlgroup.github.io/projects/forestnet .\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 00:28:40 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Irvin", "Jeremy", ""], ["Sheng", "Hao", ""], ["Ramachandran", "Neel", ""], ["Johnson-Yu", "Sonja", ""], ["Zhou", "Sharon", ""], ["Story", "Kyle", ""], ["Rustowicz", "Rose", ""], ["Elsworth", "Cooper", ""], ["Austin", "Kemen", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "2011.05489", "submitter": "Xinpeng Shen", "authors": "Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, M. Regina Castro, Pedro J.\n  Caraballo, Gyorgy J. Simon", "title": "A novel method for Causal Structure Discovery from EHR data, a\n  demonstration on type-2 diabetes mellitus", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction: The discovery of causal mechanisms underlying diseases enables\nbetter diagnosis, prognosis and treatment selection. Clinical trials have been\nthe gold standard for determining causality, but they are resource intensive,\nsometimes infeasible or unethical. Electronic Health Records (EHR) contain a\nwealth of real-world data that holds promise for the discovery of disease\nmechanisms, yet the existing causal structure discovery (CSD) methods fall\nshort on leveraging them due to the special characteristics of the EHR data. We\npropose a new data transformation method and a novel CSD algorithm to overcome\nthe challenges posed by these characteristics. Materials and methods: We\ndemonstrated the proposed methods on an application to type-2 diabetes\nmellitus. We used a large EHR data set from Mayo Clinic to internally evaluate\nthe proposed transformation and CSD methods and used another large data set\nfrom an independent health system, Fairview Health Services, as external\nvalidation. We compared the performance of our proposed method to Fast Greedy\nEquivalence Search (FGES), a state-of-the-art CSD method in terms of\ncorrectness, stability and completeness. We tested the generalizability of the\nproposed algorithm through external validation. Results and conclusions: The\nproposed method improved over the existing methods by successfully\nincorporating study design considerations, was robust in face of unreliable EHR\ntimestamps and inferred causal effect directions more correctly and reliably.\nThe proposed data transformation successfully improved the clinical correctness\nof the discovered graph and the consistency of edge orientation across\nbootstrap samples. It resulted in superior accuracy, stability, and\ncompleteness.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 00:50:04 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shen", "Xinpeng", ""], ["Ma", "Sisi", ""], ["Vemuri", "Prashanthi", ""], ["Castro", "M. Regina", ""], ["Caraballo", "Pedro J.", ""], ["Simon", "Gyorgy J.", ""]]}, {"id": "2011.05497", "submitter": "Bilge Acun", "authors": "Bilge Acun, Matthew Murphy, Xiaodong Wang, Jade Nie, Carole-Jean Wu,\n  Kim Hazelwood", "title": "Understanding Training Efficiency of Deep Learning Recommendation Models\n  at Scale", "comments": "To appear in IEEE International Symposium on High-Performance\n  Computer Architecture (HPCA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of GPUs has proliferated for machine learning workflows and is now\nconsidered mainstream for many deep learning models. Meanwhile, when training\nstate-of-the-art personal recommendation models, which consume the highest\nnumber of compute cycles at our large-scale datacenters, the use of GPUs came\nwith various challenges due to having both compute-intensive and\nmemory-intensive components. GPU performance and efficiency of these\nrecommendation models are largely affected by model architecture configurations\nsuch as dense and sparse features, MLP dimensions. Furthermore, these models\noften contain large embedding tables that do not fit into limited GPU memory.\nThe goal of this paper is to explain the intricacies of using GPUs for training\nrecommendation models, factors affecting hardware efficiency at scale, and\nlearnings from a new scale-up GPU server design, Zion.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:21:43 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Acun", "Bilge", ""], ["Murphy", "Matthew", ""], ["Wang", "Xiaodong", ""], ["Nie", "Jade", ""], ["Wu", "Carole-Jean", ""], ["Hazelwood", "Kim", ""]]}, {"id": "2011.05506", "submitter": "Mohsen Jafarzadeh", "authors": "Mohsen Jafarzadeh, Touqeer Ahmad, Akshay Raj Dhamija, Chunchun Li,\n  Steve Cruz, Terrance E. Boult", "title": "Automatic Open-World Reliability Assessment", "comments": "2021 IEEE Winter Conference on Applications of Computer Vision (WACV)", "journal-ref": "2021 IEEE Winter Conference on Applications of Computer Vision\n  (WACV)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification in the open-world must handle out-of-distribution (OOD)\nimages. Systems should ideally reject OOD images, or they will map atop of\nknown classes and reduce reliability. Using open-set classifiers that can\nreject OOD inputs can help. However, optimal accuracy of open-set classifiers\ndepend on the frequency of OOD data. Thus, for either standard or open-set\nclassifiers, it is important to be able to determine when the world changes and\nincreasing OOD inputs will result in reduced system reliability. However,\nduring operations, we cannot directly assess accuracy as there are no labels.\nThus, the reliability assessment of these classifiers must be done by human\noperators, made more complex because networks are not 100% accurate, so some\nfailures are to be expected. To automate this process, herein, we formalize the\nopen-world recognition reliability problem and propose multiple automatic\nreliability assessment policies to address this new problem using only the\ndistribution of reported scores/probability data. The distributional algorithms\ncan be applied to both classic classifiers with SoftMax as well as the\nopen-world Extreme Value Machine (EVM) to provide automated reliability\nassessment. We show that all of the new algorithms significantly outperform\ndetection using the mean of SoftMax.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:56:23 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 01:35:18 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jafarzadeh", "Mohsen", ""], ["Ahmad", "Touqeer", ""], ["Dhamija", "Akshay Raj", ""], ["Li", "Chunchun", ""], ["Cruz", "Steve", ""], ["Boult", "Terrance E.", ""]]}, {"id": "2011.05507", "submitter": "Chun-Na Li", "authors": "Yan-Ru Guo, Yan-Qin Bai, Chun-Na Li, Lan Bai, Yuan-Hai Shao", "title": "Two-dimensional Bhattacharyya bound linear discriminant analysis with\n  its applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed L2-norm linear discriminant analysis criterion via the\nBhattacharyya error bound estimation (L2BLDA) is an effective improvement of\nlinear discriminant analysis (LDA) for feature extraction. However, L2BLDA is\nonly proposed to cope with vector input samples. When facing with\ntwo-dimensional (2D) inputs, such as images, it will lose some useful\ninformation, since it does not consider intrinsic structure of images. In this\npaper, we extend L2BLDA to a two-dimensional Bhattacharyya bound linear\ndiscriminant analysis (2DBLDA). 2DBLDA maximizes the matrix-based between-class\ndistance which is measured by the weighted pairwise distances of class means\nand meanwhile minimizes the matrix-based within-class distance. The weighting\nconstant between the between-class and within-class terms is determined by the\ninvolved data that makes the proposed 2DBLDA adaptive. In addition, the\ncriterion of 2DBLDA is equivalent to optimizing an upper bound of the\nBhattacharyya error. The construction of 2DBLDA makes it avoid the small sample\nsize problem while also possess robustness, and can be solved through a simple\nstandard eigenvalue decomposition problem. The experimental results on image\nrecognition and face image reconstruction demonstrate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:56:42 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Guo", "Yan-Ru", ""], ["Bai", "Yan-Qin", ""], ["Li", "Chun-Na", ""], ["Bai", "Lan", ""], ["Shao", "Yuan-Hai", ""]]}, {"id": "2011.05511", "submitter": "Yingtao Luo", "authors": "Yingtao Luo and Xuefeng Zhu", "title": "A Quantum-Inspired Probabilistic Model for the Inverse Design of\n  Meta-Structures", "comments": "Third Workshop on Machine Learning and the Physical Sciences (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.app-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In quantum mechanics, a norm squared wave function can be interpreted as the\nprobability density that describes the likelihood of a particle to be measured\nin a given position or momentum. This statistical property is at the core of\nthe microcosmos. Meanwhile, machine learning inverse design of materials raised\nintensive attention, resulting in various intelligent systems for matter\nengineering. Here, inspired by quantum theory, we propose a probabilistic deep\nlearning paradigm for the inverse design of functional meta-structures. Our\nprobability-density-based neural network (PDN) can accurately capture all\nplausible meta-structures to meet the desired performances. Local maxima in\nprobability density distribution correspond to the most likely candidates. We\nverify this approach by designing multiple meta-structures for each targeted\ntransmission spectrum to enrich design choices.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 02:09:10 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Luo", "Yingtao", ""], ["Zhu", "Xuefeng", ""]]}, {"id": "2011.05516", "submitter": "Yingtao Luo", "authors": "Ying-Tao Luo, Peng-Qi Li, Dong-Ting Li, Yu-Gui Peng, Zhi-Guo Geng,\n  Shu-Huan Xie, Yong Li, Andrea Alu, Jie Zhu, Xue-Feng Zhu", "title": "Probability-Density-Based Deep Learning Paradigm for the Fuzzy Design of\n  Functional Metastructures", "comments": "Published in Research, an AAAS Science Partner Journal", "journal-ref": "Research, vol. 2020, Article ID 8757403, 2020", "doi": "10.34133/2020/8757403", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In quantum mechanics, a norm squared wave function can be interpreted as the\nprobability density that describes the likelihood of a particle to be measured\nin a given position or momentum. This statistical property is at the core of\nthe fuzzy structure of microcosmos. Recently, hybrid neural structures raised\nintense attention, resulting in various intelligent systems with far-reaching\ninfluence. Here, we propose a probability-density-based deep learning paradigm\nfor the fuzzy design of functional meta-structures. In contrast to other\ninverse design methods, our probability-density-based neural network can\nefficiently evaluate and accurately capture all plausible meta-structures in a\nhigh-dimensional parameter space. Local maxima in probability density\ndistribution correspond to the most likely candidates to meet the desired\nperformances. We verify this universally adaptive approach in but not limited\nto acoustics by designing multiple meta-structures for each targeted\ntransmission spectrum, with experiments unequivocally demonstrating the\neffectiveness and generalization of the inverse design.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 02:22:46 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Luo", "Ying-Tao", ""], ["Li", "Peng-Qi", ""], ["Li", "Dong-Ting", ""], ["Peng", "Yu-Gui", ""], ["Geng", "Zhi-Guo", ""], ["Xie", "Shu-Huan", ""], ["Li", "Yong", ""], ["Alu", "Andrea", ""], ["Zhu", "Jie", ""], ["Zhu", "Xue-Feng", ""]]}, {"id": "2011.05519", "submitter": "Dilusha Weeraddana Dr", "authors": "Dilusha Weeraddana, Nguyen Lu Dang Khoa, Lachlan O Neil, Weihong Wang,\n  and Chen Cai", "title": "Energy consumption forecasting using a stacked nonparametric Bayesian\n  approach", "comments": "Conference: ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the process of forecasting household energy consumption is\nstudied within the framework of the nonparametric Gaussian Process (GP), using\nmultiple short time series data. As we begin to use smart meter data to paint a\nclearer picture of residential electricity use, it becomes increasingly\napparent that we must also construct a detailed picture and understanding of\nconsumer's complex relationship with gas consumption. Both electricity and gas\nconsumption patterns are highly dependent on various factors, and the intricate\ninterplay of these factors is sophisticated. Moreover, since typical gas\nconsumption data is low granularity with very few time points, naive\napplication of conventional time-series forecasting techniques can lead to\nsevere over-fitting. Given these considerations, we construct a stacked GP\nmethod where the predictive posteriors of each GP applied to each task are used\nin the prior and likelihood of the next level GP. We apply our model to a\nreal-world dataset to forecast energy consumption in Australian households\nacross several states. We compare intuitively appealing results against other\ncommonly used machine learning techniques. Overall, the results indicate that\nthe proposed stacked GP model outperforms other forecasting techniques that we\ntested, especially when we have a multiple short time-series instances.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 02:27:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Weeraddana", "Dilusha", ""], ["Khoa", "Nguyen Lu Dang", ""], ["Neil", "Lachlan O", ""], ["Wang", "Weihong", ""], ["Cai", "Chen", ""]]}, {"id": "2011.05525", "submitter": "Junwei Zhang", "authors": "Junwei Zhang, Zhenghao Zhang, Shuai Han, Shuai L\\\"u", "title": "Proximal Policy Optimization via Enhanced Exploration Efficiency", "comments": "34 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proximal policy optimization (PPO) algorithm is a deep reinforcement learning\nalgorithm with outstanding performance, especially in continuous control tasks.\nBut the performance of this method is still affected by its exploration\nability. For classical reinforcement learning, there are some schemes that make\nexploration more full and balanced with data exploitation, but they can't be\napplied in complex environments due to the complexity of algorithm. Based on\ncontinuous control tasks with dense reward, this paper analyzes the assumption\nof the original Gaussian action exploration mechanism in PPO algorithm, and\nclarifies the influence of exploration ability on performance. Afterward,\naiming at the problem of exploration, an exploration enhancement mechanism\nbased on uncertainty estimation is designed in this paper. Then, we apply\nexploration enhancement theory to PPO algorithm and propose the proximal policy\noptimization algorithm with intrinsic exploration module (IEM-PPO) which can be\nused in complex environments. In the experimental parts, we evaluate our method\non multiple tasks of MuJoCo physical simulator, and compare IEM-PPO algorithm\nwith curiosity driven exploration algorithm (ICM-PPO) and original algorithm\n(PPO). The experimental results demonstrate that IEM-PPO algorithm needs longer\ntraining time, but performs better in terms of sample efficiency and cumulative\nreward, and has stability and robustness.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 03:03:32 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zhang", "Junwei", ""], ["Zhang", "Zhenghao", ""], ["Han", "Shuai", ""], ["L\u00fc", "Shuai", ""]]}, {"id": "2011.05530", "submitter": "Ramy E. Ali", "authors": "Ramy E. Ali, Jinhyun So, A. Salman Avestimehr", "title": "On Polynomial Approximations for Privacy-Preserving and Verifiable ReLU\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outsourcing neural network inference tasks to an untrusted cloud raises data\nprivacy and integrity concerns. To address these challenges, several\nprivacy-preserving and verifiable inference techniques have been proposed based\non replacing the non-polynomial activation functions such as the rectified\nlinear unit (ReLU) function with polynomial activation functions. Such\ntechniques usually require polynomials with integer coefficients or polynomials\nover finite fields. Motivated by such requirements, several works proposed\nreplacing the ReLU activation function with the square activation function. In\nthis work, we empirically show that the square function is not the best\ndegree-$2$ polynomial that can replace the ReLU function even when restricting\nthe polynomials to have integer coefficients. We instead propose a degree-$2$\npolynomial activation function with a first order term and empirically show\nthat it can lead to much better models. Our experiments on the CIFAR-$10$ and\nCIFAR-$100$ datasets on various architectures show that our proposed activation\nfunction improves the test accuracy by up to $9.4\\%$ compared to the square\nfunction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 03:32:22 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 06:44:17 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 05:14:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Ali", "Ramy E.", ""], ["So", "Jinhyun", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2011.05537", "submitter": "Lucas Rosenblatt", "authors": "Lucas Rosenblatt, Xiaoyan Liu, Samira Pouyanfar, Eduardo de Leon, Anuj\n  Desai, Joshua Allen", "title": "Differentially Private Synthetic Data: Applied Evaluations and\n  Enhancements", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning practitioners frequently seek to leverage the most\ninformative available data, without violating the data owner's privacy, when\nbuilding predictive models. Differentially private data synthesis protects\npersonal details from exposure, and allows for the training of differentially\nprivate machine learning models on privately generated datasets. But how can we\neffectively assess the efficacy of differentially private synthetic data? In\nthis paper, we survey four differentially private generative adversarial\nnetworks for data synthesis. We evaluate each of them at scale on five standard\ntabular datasets, and in two applied industry scenarios. We benchmark with\nnovel metrics from recent literature and other standard machine learning tools.\nOur results suggest some synthesizers are more applicable for different privacy\nbudgets, and we further demonstrate complicating domain-based tradeoffs in\nselecting an approach. We offer experimental learning on applied machine\nlearning scenarios with private internal data to researchers and practioners\nalike. In addition, we propose QUAIL, an ensemble-based modeling approach to\ngenerating synthetic data. We examine QUAIL's tradeoffs, and note circumstances\nin which it outperforms baseline differentially private supervised learning\nmodels under the same budget constraint.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 04:03:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Rosenblatt", "Lucas", ""], ["Liu", "Xiaoyan", ""], ["Pouyanfar", "Samira", ""], ["de Leon", "Eduardo", ""], ["Desai", "Anuj", ""], ["Allen", "Joshua", ""]]}, {"id": "2011.05543", "submitter": "Sagar Kora Venu", "authors": "Sagar Kora Venu", "title": "An ensemble-based approach by fine-tuning the deep transfer learning\n  models to classify pneumonia from chest X-ray images", "comments": null, "journal-ref": "SciTePress 2021", "doi": "10.5220/0010377403900401", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pneumonia is caused by viruses, bacteria, or fungi that infect the lungs,\nwhich, if not diagnosed, can be fatal and lead to respiratory failure. More\nthan 250,000 individuals in the United States, mainly adults, are diagnosed\nwith pneumonia each year, and 50,000 die from the disease. Chest Radiography\n(X-ray) is widely used by radiologists to detect pneumonia. It is not uncommon\nto overlook pneumonia detection for a well-trained radiologist, which triggers\nthe need for improvement in the diagnosis's accuracy. In this work, we propose\nusing transfer learning, which can reduce the neural network's training time\nand minimize the generalization error. We trained, fine-tuned the\nstate-of-the-art deep learning models such as InceptionResNet, MobileNetV2,\nXception, DenseNet201, and ResNet152V2 to classify pneumonia accurately. Later,\nwe created a weighted average ensemble of these models and achieved a test\naccuracy of 98.46%, precision of 98.38%, recall of 99.53%, and f1 score of\n98.96%. These performance metrics of accuracy, precision, and f1 score are at\ntheir highest levels ever reported in the literature, which can be considered a\nbenchmark for the accurate pneumonia classification.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 04:50:06 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Venu", "Sagar Kora", ""]]}, {"id": "2011.05546", "submitter": "Yiren Liu", "authors": "Yiren Liu, Kuan-Ying Lee", "title": "E-commerce Query-based Generation based on User Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of merchandise on e-commerce platforms, users tend\nto refer to reviews of other shoppers to decide which product they should buy.\nHowever, with so many reviews of a product, users often have to spend lots of\ntime browsing through reviews talking about product attributes they do not care\nabout. We want to establish a system that can automatically summarize and\nanswer user's product specific questions.\n  In this study, we propose a novel seq2seq based text generation model to\ngenerate answers to user's question based on reviews posted by previous users.\nGiven a user question and/or target sentiment polarity, we extract aspects of\ninterest and generate an answer that summarizes previous relevant user reviews.\nSpecifically, our model performs attention between input reviews and target\naspects during encoding and is conditioned on both review rating and input\ncontext during decoding. We also incorporate a pre-trained auxiliary rating\nclassifier to improve model performance and accelerate convergence during\ntraining. Experiments using real-world e-commerce dataset show that our model\nachieves improvement in performance compared to previously introduced models.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 04:58:31 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Liu", "Yiren", ""], ["Lee", "Kuan-Ying", ""]]}, {"id": "2011.05552", "submitter": "Alice Xue", "authors": "Alice Xue", "title": "End-to-End Chinese Landscape Painting Creation Using Generative\n  Adversarial Networks", "comments": "This research is an extension of Alice Xue's senior thesis at\n  Princeton University. The paper will be published in the proceedings of IEEE\n  Winter Conference on Applications of Computer Vision (WACV) 2021 and\n  presented at the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current GAN-based art generation methods produce unoriginal artwork due to\ntheir dependence on conditional input. Here, we propose Sketch-And-Paint GAN\n(SAPGAN), the first model which generates Chinese landscape paintings from end\nto end, without conditional input. SAPGAN is composed of two GANs: SketchGAN\nfor generation of edge maps, and PaintGAN for subsequent edge-to-painting\ntranslation. Our model is trained on a new dataset of traditional Chinese\nlandscape paintings never before used for generative research. A 242-person\nVisual Turing Test study reveals that SAPGAN paintings are mistaken as human\nartwork with 55% frequency, significantly outperforming paintings from baseline\nGANs. Our work lays a groundwork for truly machine-original art generation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 05:20:42 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Xue", "Alice", ""]]}, {"id": "2011.05554", "submitter": "Hao Xue", "authors": "Hao Xue and Flora D Salim", "title": "TERMCast: Temporal Relation Modeling for Effective Urban Flow\n  Forecasting", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-75762-5\\_58", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban flow forecasting is a challenging task, given the inherent periodic\ncharacteristics of urban flow patterns. To capture the periodicity, existing\nurban flow prediction approaches are often designed with closeness, period, and\ntrend components extracted from the urban flow sequence. However, these three\ncomponents are often considered separately in the prediction model. These\ncomponents have not been fully explored together and simultaneously\nincorporated in urban flow forecasting models. We introduce a novel urban flow\nforecasting architecture, TERMCast. A Transformer based long-term relation\nprediction module is explicitly designed to discover the periodicity and enable\nthe three components to be jointly modeled This module predicts the periodic\nrelation which is then used to yield the predicted urban flow tensor. To\nmeasure the consistency of the predicted periodic relation vector and the\nrelation vector inferred from the predicted urban flow tensor, we propose a\nconsistency module. A consistency loss is introduced in the training process to\nfurther improve the prediction performance. Through extensive experiments on\nthree real-world datasets, we demonstrate that TERMCast outperforms multiple\nstate-of-the-art methods. The effectiveness of each module in TERMCast has also\nbeen investigated.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 05:33:12 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 01:53:36 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Xue", "Hao", ""], ["Salim", "Flora D", ""]]}, {"id": "2011.05570", "submitter": "Hamed Khorasgani", "authors": "Hamed Khorasgani, Haiyan Wang, Chetan Gupta", "title": "Challenges of Applying Deep Reinforcement Learning in Dynamic\n  Dispatching", "comments": "arXiv admin note: text overlap with arXiv:2008.10713", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic dispatching aims to smartly allocate the right resources to the right\nplace at the right time. Dynamic dispatching is one of the core problems for\noperations optimization in the mining industry. Theoretically, deep\nreinforcement learning (RL) should be a natural fit to solve this problem.\nHowever, the industry relies on heuristics or even human intuitions, which are\noften short-sighted and sub-optimal solutions. In this paper, we review the\nmain challenges in using deep RL to address the dynamic dispatching problem in\nthe mining industry.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:26:45 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Khorasgani", "Hamed", ""], ["Wang", "Haiyan", ""], ["Gupta", "Chetan", ""]]}, {"id": "2011.05577", "submitter": "Penny Chong", "authors": "Penny Chong, Ngai-Man Cheung, Yuval Elovici, Alexander Binder", "title": "Towards Scalable and Unified Example-based Explanation and Outlier\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When neural networks are employed for high-stakes decision making, it is\ndesirable for the neural networks to provide explanation for their prediction\nin order for us to understand the features that have contributed to the\ndecision. At the same time, it is important to flag potential outliers for\nin-depth verification by domain experts. In this work we propose to unify two\ndiffering aspects of explainability with outlier detection. We argue for a\nbroader adoption of prototype-based student networks capable of providing an\nexample-based explanation for its prediction and at the same time identify\nregions of similarity between the predicted sample and the examples. The\nexamples are real prototypical cases sampled from the training set via our\nnovel iterative prototype replacement algorithm. Furthermore, we propose to use\nthe prototype similarity scores for identifying outliers. We compare\nperformances in terms of classification, explanation quality, and outlier\ndetection of our proposed network with other baselines. We show that our\nprototype-based networks beyond similarity kernels deliver meaningful\nexplanation and promising outlier detection results without compromising\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 05:58:17 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 00:53:54 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Chong", "Penny", ""], ["Cheung", "Ngai-Man", ""], ["Elovici", "Yuval", ""], ["Binder", "Alexander", ""]]}, {"id": "2011.05578", "submitter": "Raouf Kerkouche", "authors": "Raouf Kerkouche, Gergely \\'Acs, Claude Castelluccia and Pierre\n  Genev\\`es", "title": "Compression Boosts Differentially Private Federated Learning", "comments": "arXiv admin note: text overlap with arXiv:2010.07808", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows distributed entities to train a common model\ncollaboratively without sharing their own data. Although it prevents data\ncollection and aggregation by exchanging only parameter updates, it remains\nvulnerable to various inference and reconstruction attacks where a malicious\nentity can learn private information about the participants' training data from\nthe captured gradients. Differential Privacy is used to obtain theoretically\nsound privacy guarantees against such inference attacks by noising the\nexchanged update vectors. However, the added noise is proportional to the model\nsize which can be very large with modern neural networks. This can result in\npoor model quality. In this paper, compressive sensing is used to reduce the\nmodel size and hence increase model quality without sacrificing privacy. We\nshow experimentally, using 2 datasets, that our privacy-preserving proposal can\nreduce the communication costs by up to 95% with only a negligible performance\npenalty compared to traditional non-private federated learning schemes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:11:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Kerkouche", "Raouf", ""], ["\u00c1cs", "Gergely", ""], ["Castelluccia", "Claude", ""], ["Genev\u00e8s", "Pierre", ""]]}, {"id": "2011.05585", "submitter": "Jonathan Boigne", "authors": "Jonathan Boigne, Biman Liyanage, Ted \\\"Ostrem", "title": "Recognizing More Emotions with Less Data Using Self-supervised Transfer\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel transfer learning method for speech emotion recognition\nallowing us to obtain promising results when only few training data is\navailable. With as low as 125 examples per emotion class, we were able to reach\na higher accuracy than a strong baseline trained on 8 times more data. Our\nmethod leverages knowledge contained in pre-trained speech representations\nextracted from models trained on a more general self-supervised task which\ndoesn't require human annotations, such as the wav2vec model. We provide\ndetailed insights on the benefits of our approach by varying the training data\nsize, which can help labeling teams to work more efficiently. We compare\nperformance with other popular methods on the IEMOCAP dataset, a\nwell-benchmarked dataset among the Speech Emotion Recognition (SER) research\ncommunity. Furthermore, we demonstrate that results can be greatly improved by\ncombining acoustic and linguistic knowledge from transfer learning. We align\nacoustic pre-trained representations with semantic representations from the\nBERT model through an attention-based recurrent neural network. Performance\nimproves significantly when combining both modalities and scales with the\namount of data. When trained on the full IEMOCAP dataset, we reach a new\nstate-of-the-art of 73.9% unweighted accuracy (UA).\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 06:18:31 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Boigne", "Jonathan", ""], ["Liyanage", "Biman", ""], ["\u00d6strem", "Ted", ""]]}, {"id": "2011.05591", "submitter": "Cunhang Fan", "authors": "Cunhang Fan, Bin Liu, Jianhua Tao, Jiangyan Yi, Zhengqi Wen, Leichao\n  Song", "title": "Deep Time Delay Neural Network for Speech Enhancement with Full Data\n  Learning", "comments": "Accepted by ISCSLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown significant improvements in\nrecent years for speech enhancement. However, the model complexity and\ninference time cost of RNNs are much higher than deep feed-forward neural\nnetworks (DNNs). Therefore, these limit the applications of speech enhancement.\nThis paper proposes a deep time delay neural network (TDNN) for speech\nenhancement with full data learning. The TDNN has excellent potential for\ncapturing long range temporal contexts, which utilizes a modular and\nincremental design. Besides, the TDNN preserves the feed-forward structure so\nthat its inference cost is comparable to standard DNN. To make full use of the\ntraining data, we propose a full data learning method for speech enhancement.\nMore specifically, we not only use the noisy-to-clean (input-to-target) to\ntrain the enhanced model, but also the clean-to-clean and noise-to-silence\ndata. Therefore, all of the training data can be used to train the enhanced\nmodel. Our experiments are conducted on TIMIT dataset. Experimental results\nshow that our proposed method could achieve a better performance than DNN and\ncomparable even better performance than BLSTM. Meanwhile, compared with the\nBLSTM, the proposed method drastically reduce the inference time.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 06:32:37 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Fan", "Cunhang", ""], ["Liu", "Bin", ""], ["Tao", "Jianhua", ""], ["Yi", "Jiangyan", ""], ["Wen", "Zhengqi", ""], ["Song", "Leichao", ""]]}, {"id": "2011.05594", "submitter": "Prithvi Suresh", "authors": "Prithvi Suresh and Abhijith Ragav", "title": "WaDeNet: Wavelet Decomposition based CNN for Speech Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing speech processing systems consist of different modules, individually\noptimized for a specific task such as acoustic modelling or feature extraction.\nIn addition to not assuring optimality of the system, the disjoint nature of\ncurrent speech processing systems make them unsuitable for ubiquitous health\napplications. We propose WaDeNet, an end-to-end model for mobile speech\nprocessing. In order to incorporate spectral features, WaDeNet embeds wavelet\ndecomposition of the speech signal within the architecture. This allows WaDeNet\nto learn from spectral features in an end-to-end manner, thus alleviating the\nneed for feature extraction and successive modules that are currently present\nin speech processing systems. WaDeNet outperforms the current state of the art\nin datasets that involve speech for mobile health applications such as\nnon-invasive emotion recognition. WaDeNet achieves an average increase in\naccuracy of 6.36% when compared to the existing state of the art models.\nAdditionally, WaDeNet is considerably lighter than a simple CNNs with a similar\narchitecture.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 06:43:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Suresh", "Prithvi", ""], ["Ragav", "Abhijith", ""]]}, {"id": "2011.05596", "submitter": "Lawrence Chan", "authors": "Harry Giles, Lawrence Chan", "title": "Accounting for Human Learning when Inferring Human Preferences", "comments": "Accepted to the 2020 NeurIPS HAMLETS workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inverse reinforcement learning (IRL) is a common technique for inferring\nhuman preferences from data. Standard IRL techniques tend to assume that the\nhuman demonstrator is stationary, that is that their policy $\\pi$ doesn't\nchange over time. In practice, humans interacting with a novel environment or\nperforming well on a novel task will change their demonstrations as they learn\nmore about the environment or task. We investigate the consequences of relaxing\nthis assumption of stationarity, in particular by modelling the human as\nlearning. Surprisingly, we find in some small examples that this can lead to\nbetter inference than if the human was stationary. That is, by observing a\ndemonstrator who is themselves learning, a machine can infer more than by\nobserving a demonstrator who is noisily rational. In addition, we find evidence\nthat misspecification can lead to poor inference, suggesting that modelling\nhuman learning is important, especially when the human is facing an unfamiliar\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 06:50:24 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 07:22:07 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Giles", "Harry", ""], ["Chan", "Lawrence", ""]]}, {"id": "2011.05601", "submitter": "Katherine Tsai", "authors": "Katherine Tsai, Mladen Kolar, Oluwasanmi Koyejo", "title": "A Nonconvex Framework for Structured Dynamic Covariance Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a flexible yet interpretable model for high-dimensional data with\ntime-varying second order statistics, motivated and applied to functional\nneuroimaging data. Motivated by the neuroscience literature, we factorize the\ncovariances into sparse spatial and smooth temporal components. While this\nfactorization results in both parsimony and domain interpretability, the\nresulting estimation problem is nonconvex. To this end, we design a two-stage\noptimization scheme with a carefully tailored spectral initialization, combined\nwith iteratively refined alternating projected gradient descent. We prove a\nlinear convergence rate up to a nontrivial statistical error for the proposed\ndescent scheme and establish sample complexity guarantees for the estimator. We\nfurther quantify the statistical error for the multivariate Gaussian case.\nEmpirical results using simulated and real brain imaging data illustrate that\nour approach outperforms existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 07:09:44 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 19:42:15 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 01:46:08 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Tsai", "Katherine", ""], ["Kolar", "Mladen", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "2011.05602", "submitter": "Zheng Zhu", "authors": "Jintao Ke, Siyuan Feng, Zheng Zhu, Hai Yang, Jieping Ye", "title": "Joint predictions of multi-modal ride-hailing demands: a deep multi-task\n  multigraph learning-based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ride-hailing platforms generally provide various service options to\ncustomers, such as solo ride services, shared ride services, etc. It is\ngenerally expected that demands for different service modes are correlated, and\nthe prediction of demand for one service mode can benefit from historical\nobservations of demands for other service modes. Moreover, an accurate joint\nprediction of demands for multiple service modes can help the platforms better\nallocate and dispatch vehicle resources. Although there is a large stream of\nliterature on ride-hailing demand predictions for one specific service mode,\nlittle efforts have been paid towards joint predictions of ride-hailing demands\nfor multiple service modes. To address this issue, we propose a deep multi-task\nmulti-graph learning approach, which combines two components: (1) multiple\nmulti-graph convolutional (MGC) networks for predicting demands for different\nservice modes, and (2) multi-task learning modules that enable knowledge\nsharing across multiple MGC networks. More specifically, two multi-task\nlearning structures are established. The first one is the regularized\ncross-task learning, which builds cross-task connections among the inputs and\noutputs of multiple MGC networks. The second one is the multi-linear\nrelationship learning, which imposes a prior tensor normal distribution on the\nweights of various MGC networks. Although there are no concrete bridges between\ndifferent MGC networks, the weights of these networks are constrained by each\nother and subject to a common prior distribution. Evaluated with the\nfor-hire-vehicle datasets in Manhattan, we show that our propose approach\noutperforms the benchmark algorithms in prediction accuracy for different\nride-hailing modes.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 07:10:50 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Ke", "Jintao", ""], ["Feng", "Siyuan", ""], ["Zhu", "Zheng", ""], ["Yang", "Hai", ""], ["Ye", "Jieping", ""]]}, {"id": "2011.05604", "submitter": "Zechuan Hu", "authors": "Zechuan Hu, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "An Investigation of Potential Function Designs for Neural CRF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural linear-chain CRF model is one of the most widely-used approach to\nsequence labeling. In this paper, we investigate a series of increasingly\nexpressive potential functions for neural CRF models, which not only integrate\nthe emission and transition functions, but also explicitly take the\nrepresentations of the contextual words as input. Our extensive experiments\nshow that the decomposed quadrilinear potential function based on the vector\nrepresentations of two neighboring labels and two neighboring words\nconsistently achieves the best performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 07:32:18 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Hu", "Zechuan", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2011.05605", "submitter": "Tanmay Samak", "authors": "Sivanathan Kandhasamy, Vinayagam Babu Kuppusamy, Tanmay Vilas Samak,\n  Chinmay Vilas Samak", "title": "Decentralized Motion Planning for Multi-Robot Navigation using Deep\n  Reinforcement Learning", "comments": "Accepted at IEEE International Conference on Intelligent Sustainable\n  Systems (ICISS) 2020", "journal-ref": "2020 3rd International Conference on Intelligent Sustainable\n  Systems (ICISS), Thoothukudi, India, 2020, pp. 709-716", "doi": "10.1109/ICISS49785.2020.9316033", "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a decentralized motion planning framework for addressing\nthe task of multi-robot navigation using deep reinforcement learning. A custom\nsimulator was developed in order to experimentally investigate the navigation\nproblem of 4 cooperative non-holonomic robots sharing limited state information\nwith each other in 3 different settings. The notion of decentralized motion\nplanning with common and shared policy learning was adopted, which allowed\nrobust training and testing of this approach in a stochastic environment since\nthe agents were mutually independent and exhibited asynchronous motion\nbehavior. The task was further aggravated by providing the agents with a sparse\nobservation space and requiring them to generate continuous action commands so\nas to efficiently, yet safely navigate to their respective goal locations,\nwhile avoiding collisions with other dynamic peers and static obstacles at all\ntimes. The experimental results are reported in terms of quantitative measures\nand qualitative remarks for both training and deployment phases.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 07:35:21 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 18:19:32 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Kandhasamy", "Sivanathan", ""], ["Kuppusamy", "Vinayagam Babu", ""], ["Samak", "Tanmay Vilas", ""], ["Samak", "Chinmay Vilas", ""]]}, {"id": "2011.05614", "submitter": "Jiangcheng Qin", "authors": "Jiangcheng Qin, Baisong Liu", "title": "A Novel Privacy-Preserved Recommender System Framework based on\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender System (RS) is currently an effective way to solve information\noverload. To meet users' next click behavior, RS needs to collect users'\npersonal information and behavior to achieve a comprehensive and profound user\npreference perception. However, these centrally collected data are\nprivacy-sensitive, and any leakage may cause severe problems to both users and\nservice providers. This paper proposed a novel privacy-preserved recommender\nsystem framework (PPRSF), through the application of federated learning\nparadigm, to enable the recommendation algorithm to be trained and carry out\ninference without centrally collecting users' private data. The PPRSF not only\nable to reduces the privacy leakage risk, satisfies legal and regulatory\nrequirements but also allows various recommendation algorithms to be applied.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 08:07:58 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Qin", "Jiangcheng", ""], ["Liu", "Baisong", ""]]}, {"id": "2011.05617", "submitter": "Yeong-Jia Roger Chu", "authors": "Yeong-Jia Roger Chu, Ting-Han Wei, Jin-Bo Huang, Yuan-Hao Chen, I-Chen\n  Wu", "title": "Sim-To-Real Transfer for Miniature Autonomous Car Racing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sim-to-real, a term that describes where a model is trained in a simulator\nthen transferred to the real world, is a technique that enables faster deep\nreinforcement learning (DRL) training. However, differences between the\nsimulator and the real world often cause the model to perform poorly in the\nreal world. Domain randomization is a way to bridge the sim-to-real gap by\nexposing the model to a wide range of scenarios so that it can generalize to\nreal-world situations. However, following domain randomization to train an\nautonomous car racing model with DRL can lead to undesirable outcomes. Namely,\na model trained with randomization tends to run slower; a higher completion\nrate on the testing track comes at the expense of longer lap times. This paper\naims to boost the robustness of a trained race car model without compromising\nracing lap times. For a training track and a testing track having the same\nshape (and same optimal paths), but with different lighting, background, etc.,\nwe first train a model (teacher model) that overfits the training track, moving\nalong a near optimal path. We then use this model to teach a student model the\ncorrect actions along with randomization. With our method, a model with 18.4\\%\ncompletion rate on the testing track is able to help teach a student model with\n52\\% completion. Moreover, over an average of 50 trials, the student is able to\nfinish a lap 0.23 seconds faster than the teacher. This 0.23 second gap is\nsignificant in tight races, with lap times of about 10 to 12 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 08:17:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Chu", "Yeong-Jia Roger", ""], ["Wei", "Ting-Han", ""], ["Huang", "Jin-Bo", ""], ["Chen", "Yuan-Hao", ""], ["Wu", "I-Chen", ""]]}, {"id": "2011.05627", "submitter": "Hongfeng Li", "authors": "Hongfeng Li, Yini Pan, Jie Zhao and Li Zhang", "title": "Skin disease diagnosis with deep learning: a review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Skin cancer is one of the most threatening diseases worldwide. However,\ndiagnosing skin cancer correctly is challenging. Recently, deep learning\nalgorithms have emerged to achieve excellent performance on various tasks.\nParticularly, they have been applied to the skin disease diagnosis tasks. In\nthis paper, we present a review on deep learning methods and their applications\nin skin disease diagnosis. We first present a brief introduction to skin\ndiseases and image acquisition methods in dermatology, and list several\npublicly available skin datasets for training and testing algorithms. Then, we\nintroduce the conception of deep learning and review popular deep learning\narchitectures. Thereafter, popular deep learning frameworks facilitating the\nimplementation of deep learning algorithms and performance evaluation metrics\nare presented. As an important part of this article, we then review the\nliterature involving deep learning methods for skin disease diagnosis from\nseveral aspects according to the specific tasks. Additionally, we discuss the\nchallenges faced in the area and suggest possible future research directions.\nThe major purpose of this article is to provide a conceptual and systematically\nreview of the recent works on skin disease diagnosis with deep learning. Given\nthe popularity of deep learning, there remains great challenges in the area, as\nwell as opportunities that we can explore in the future.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 08:35:21 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 14:16:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Hongfeng", ""], ["Pan", "Yini", ""], ["Zhao", "Jie", ""], ["Zhang", "Li", ""]]}, {"id": "2011.05632", "submitter": "Ashwin Balakrishna", "authors": "Michael Danielczuk, Ashwin Balakrishna, Daniel S. Brown, Shivin\n  Devgon, Ken Goldberg", "title": "Exploratory Grasping: Asymptotically Optimal Algorithms for Grasping\n  Challenging Polyhedral Objects", "comments": "Conference on Robot Learning (CoRL) 2020. First two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been significant recent work on data-driven algorithms for learning\ngeneral-purpose grasping policies. However, these policies can consistently\nfail to grasp challenging objects which are significantly out of the\ndistribution of objects in the training data or which have very few high\nquality grasps. Motivated by such objects, we propose a novel problem setting,\nExploratory Grasping, for efficiently discovering reliable grasps on an unknown\npolyhedral object via sequential grasping, releasing, and toppling. We\nformalize Exploratory Grasping as a Markov Decision Process, study the\ntheoretical complexity of Exploratory Grasping in the context of reinforcement\nlearning and present an efficient bandit-style algorithm, Bandits for Online\nRapid Grasp Exploration Strategy (BORGES), which leverages the structure of the\nproblem to efficiently discover high performing grasps for each object stable\npose. BORGES can be used to complement any general-purpose grasping algorithm\nwith any grasp modality (parallel-jaw, suction, multi-fingered, etc) to learn\npolicies for objects in which they exhibit persistent failures. Simulation\nexperiments suggest that BORGES can significantly outperform both\ngeneral-purpose grasping pipelines and two other online learning algorithms and\nachieves performance within 5% of the optimal policy within 1000 and 8000\ntimesteps on average across 46 challenging objects from the Dex-Net adversarial\nand EGAD! object datasets, respectively. Initial physical experiments suggest\nthat BORGES can improve grasp success rate by 45% over a Dex-Net baseline with\njust 200 grasp attempts in the real world. See https://tinyurl.com/exp-grasping\nfor supplementary material and videos.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 08:42:30 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 01:21:35 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Danielczuk", "Michael", ""], ["Balakrishna", "Ashwin", ""], ["Brown", "Daniel S.", ""], ["Devgon", "Shivin", ""], ["Goldberg", "Ken", ""]]}, {"id": "2011.05648", "submitter": "Hongfeng Li", "authors": "Hongfeng Li", "title": "Semi-supervised Sparse Representation with Graph Regularization for\n  Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Image classification is a challenging problem for computer in reality. Large\nnumbers of methods can achieve satisfying performances with sufficient labeled\nimages. However, labeled images are still highly limited for certain image\nclassification tasks. Instead, lots of unlabeled images are available and easy\nto be obtained. Therefore, making full use of the available unlabeled data can\nbe a potential way to further improve the performance of current image\nclassification methods. In this paper, we propose a discriminative\nsemi-supervised sparse representation algorithm for image classification. In\nthe algorithm, the classification process is combined with the sparse coding to\nlearn a data-driven linear classifier. To obtain discriminative predictions,\nthe predicted labels are regularized with three graphs, i.e., the global\nmanifold structure graph, the within-class graph and the between-classes graph.\nThe constructed graphs are able to extract structure information included in\nboth the labeled and unlabeled data. Moreover, the proposed method is extended\nto a kernel version for dealing with data that cannot be linearly classified.\nAccordingly, efficient algorithms are developed to solve the corresponding\noptimization problems. Experimental results on several challenging databases\ndemonstrate that the proposed algorithm achieves excellent performances\ncompared with related popular methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 09:16:48 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Li", "Hongfeng", ""]]}, {"id": "2011.05649", "submitter": "Huahuan Zheng", "authors": "Huahuan Zheng, Keyu An, Zhijian Ou", "title": "Efficient Neural Architecture Search for End-to-end Speech Recognition\n  via Straight-Through Gradients", "comments": "Accepted by IEEE SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS), the process of automating architecture\nengineering, is an appealing next step to advancing end-to-end Automatic Speech\nRecognition (ASR), replacing expert-designed networks with learned,\ntask-specific architectures. In contrast to early computational-demanding NAS\nmethods, recent gradient-based NAS methods, e.g., DARTS (Differentiable\nARchiTecture Search), SNAS (Stochastic NAS) and ProxylessNAS, significantly\nimprove the NAS efficiency. In this paper, we make two contributions. First, we\nrigorously develop an efficient NAS method via Straight-Through (ST) gradients,\ncalled ST-NAS. Basically, ST-NAS uses the loss from SNAS but uses ST to\nback-propagate gradients through discrete variables to optimize the loss, which\nis not revealed in ProxylessNAS. Using ST gradients to support sub-graph\nsampling is a core element to achieve efficient NAS beyond DARTS and SNAS.\nSecond, we successfully apply ST-NAS to end-to-end ASR. Experiments over the\nwidely benchmarked 80-hour WSJ and 300-hour Switchboard datasets show that the\nST-NAS induced architectures significantly outperform the human-designed\narchitecture across the two datasets. Strengths of ST-NAS such as architecture\ntransferability and low computation cost in memory and time are also reported.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 09:18:58 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zheng", "Huahuan", ""], ["An", "Keyu", ""], ["Ou", "Zhijian", ""]]}, {"id": "2011.05650", "submitter": "Giuseppe Pirr\\'o", "authors": "Giuseppe Pirr\\`o", "title": "Toward Edge-Centric Network Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing network embedding approaches tackle the problem of learning\nlow-dimensional node representations. However, networks can also be seen in the\nlight of edges interlinking pairs of nodes. The broad goal of this paper is to\nintroduce edge-centric network embeddings. We present an approach called ECNE,\nwhich instead of computing node embeddings directly, computes edge embeddings\nby relying on the notion of line graph coupled with an edge weighting mechanism\nto preserve the dynamic of the original graph in the line graph. We also\npresent a link prediction framework called ECNE-LP, which given a target link\n(u,v) first collects paths between nodes u and v, then directly embeds the\nedges in these paths, and finally aggregates them toward predicting the\nexistence of a link. We show that both ECNE and ECNE-LP bring benefit wrt the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 09:19:27 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Pirr\u00f2", "Giuseppe", ""]]}, {"id": "2011.05661", "submitter": "Ashwin Balakrishna", "authors": "Han Yu Li, Michael Danielczuk, Ashwin Balakrishna, Vishal Satish, Ken\n  Goldberg", "title": "Accelerating Grasp Exploration by Leveraging Learned Priors", "comments": "Conference on Automation Science and Engineering (CASE) 2020. First\n  three authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability of robots to grasp novel objects has industry applications in\ne-commerce order fulfillment and home service. Data-driven grasping policies\nhave achieved success in learning general strategies for grasping arbitrary\nobjects. However, these approaches can fail to grasp objects which have complex\ngeometry or are significantly outside of the training distribution. We present\na Thompson sampling algorithm that learns to grasp a given object with unknown\ngeometry using online experience. The algorithm leverages learned priors from\nthe Dexterity Network robot grasp planner to guide grasp exploration and\nprovide probabilistic estimates of grasp success for each stable pose of the\nnovel object. We find that seeding the policy with the Dex-Net prior allows it\nto more efficiently find robust grasps on these objects. Experiments suggest\nthat the best learned policy attains an average total reward 64.5% higher than\na greedy baseline and achieves within 5.7% of an oracle baseline when evaluated\nover 300,000 training runs across a set of 3000 object poses.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 09:42:56 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Li", "Han Yu", ""], ["Danielczuk", "Michael", ""], ["Balakrishna", "Ashwin", ""], ["Satish", "Vishal", ""], ["Goldberg", "Ken", ""]]}, {"id": "2011.05664", "submitter": "Stefanos Antaris", "authors": "Stefanos Antaris, Dimitrios Rafailidis", "title": "Distill2Vec: Dynamic Graph Representation Learning with Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic graph representation learning strategies are based on different\nneural architectures to capture the graph evolution over time. However, the\nunderlying neural architectures require a large amount of parameters to train\nand suffer from high online inference latency, that is several model parameters\nhave to be updated when new data arrive online. In this study we propose\nDistill2Vec, a knowledge distillation strategy to train a compact model with a\nlow number of trainable parameters, so as to reduce the latency of online\ninference and maintain the model accuracy high. We design a distillation loss\nfunction based on Kullback-Leibler divergence to transfer the acquired\nknowledge from a teacher model trained on offline data, to a small-size student\nmodel for online data. Our experiments with publicly available datasets show\nthe superiority of our proposed model over several state-of-the-art approaches\nwith relative gains up to 5% in the link prediction task. In addition, we\ndemonstrate the effectiveness of our knowledge distillation strategy, in terms\nof number of required parameters, where Distill2Vec achieves a compression\nratio up to 7:100 when compared with baseline approaches. For reproduction\npurposes, our implementation is publicly available at\nhttps://stefanosantaris.github.io/Distill2Vec.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 09:49:24 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Antaris", "Stefanos", ""], ["Rafailidis", "Dimitrios", ""]]}, {"id": "2011.05668", "submitter": "Negar Heidari", "authors": "Negar Heidari and Alexandros Iosifidis", "title": "Progressive Spatio-Temporal Graph Convolutional Network for\n  Skeleton-Based Human Action Recognition", "comments": "Accepted by the 2021 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have been very successful in\nskeleton-based human action recognition where the sequence of skeletons is\nmodeled as a graph. However, most of the GCN-based methods in this area train a\ndeep feed-forward network with a fixed topology that leads to high\ncomputational complexity and restricts their application in low computation\nscenarios. In this paper, we propose a method to automatically find a compact\nand problem-specific topology for spatio-temporal graph convolutional networks\nin a progressive manner. Experimental results on two widely used datasets for\nskeleton-based human action recognition indicate that the proposed method has\ncompetitive or even better classification performance compared to the\nstate-of-the-art methods with much lower computational complexity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 09:57:49 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 20:43:10 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Heidari", "Negar", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2011.05671", "submitter": "Stefanos Antaris", "authors": "Stefanos Antaris, Dimitrios Rafailidis", "title": "VStreamDRLS: Dynamic Graph Representation Learning with Self-Attention\n  for Enterprise Distributed Video Streaming Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Live video streaming has become a mainstay as a standard communication\nsolution for several enterprises worldwide. To efficiently stream high-quality\nlive video content to a large amount of offices, companies employ distributed\nvideo streaming solutions which rely on prior knowledge of the underlying\nevolving enterprise network. However, such networks are highly complex and\ndynamic. Hence, to optimally coordinate the live video distribution, the\navailable network capacity between viewers has to be accurately predicted. In\nthis paper we propose a graph representation learning technique on weighted and\ndynamic graphs to predict the network capacity, that is the weights of\nconnections/links between viewers/nodes. We propose VStreamDRLS, a graph neural\nnetwork architecture with a self-attention mechanism to capture the evolution\nof the graph structure of live video streaming events. VStreamDRLS employs the\ngraph convolutional network (GCN) model over the duration of a live video\nstreaming event and introduces a self-attention mechanism to evolve the GCN\nparameters. In doing so, our model focuses on the GCN weights that are relevant\nto the evolution of the graph and generate the node representation,\naccordingly. We evaluate our proposed approach on the link prediction task on\ntwo real-world datasets, generated by enterprise live video streaming events.\nThe duration of each event lasted an hour. The experimental results demonstrate\nthe effectiveness of VStreamDRLS when compared with state-of-the-art\nstrategies. Our evaluation datasets and implementation are publicly available\nat https://github.com/stefanosantaris/vstreamdrls\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:00:12 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Antaris", "Stefanos", ""], ["Rafailidis", "Dimitrios", ""]]}, {"id": "2011.05674", "submitter": "Alexander Belikov V", "authors": "Fran\\c{c}ois Culi\\`ere, Laetitia Leduc and Alexander Belikov", "title": "Bayesian model of electrical heating disaggregation", "comments": "5th International Workshop on Non-Intrusive Load Monitoring (NILM\n  2020)", "journal-ref": null, "doi": "10.1145/3427771.3427848", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adoption of smart meters is a major milestone on the path of European\ntransition to smart energy. The residential sector in France represents\n$\\approx$35\\% of electricity consumption with $\\approx$40\\% (INSEE) of\nhouseholds using electrical heating. The number of deployed smart meters Linky\nis expected to reach 35M in 2021. In this manuscript we present an analysis of\n676 households with an observation period of at least 6 months, for which we\nhave metadata, such as the year of construction and the type of heating and\npropose a Bayesian model of the electrical consumption conditioned on\ntemperature that allows to disaggregate the heating component from the\nelectrical load curve in an unsupervised manner. In essence the model is a\nmixture of piece-wise linear models, characterised by a temperature threshold,\nbelow which we allow a mixture of two modes to represent the latent state\nhome/away.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:05:15 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Culi\u00e8re", "Fran\u00e7ois", ""], ["Leduc", "Laetitia", ""], ["Belikov", "Alexander", ""]]}, {"id": "2011.05675", "submitter": "Isanka Rajapaksha", "authors": "Isanka Rajapaksha, Chanika Ruchini Mudalige, Dilini Karunarathna,\n  Nisansa de Silva, Gathika Ratnayaka, and Amal Shehan Perera", "title": "Rule-Based Approach for Party-Based Sentiment Analysis in Legal Opinion\n  Texts", "comments": "2 pages, 1 figure, The 20th International Conference on Advances in\n  ICT for Emerging Regions (ICTer2020)", "journal-ref": null, "doi": "10.1109/ICTer51097.2020.9325435", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A document which elaborates opinions and arguments related to the previous\ncourt cases is known as a legal opinion text. Lawyers and legal officials have\nto spend considerable effort and time to obtain the required information\nmanually from those documents when dealing with new legal cases. Hence, it\nprovides much convenience to those individuals if there is a way to automate\nthe process of extracting information from legal opinion texts. Party-based\nsentiment analysis will play a key role in the automation system by identifying\nopinion values with respect to each legal parties in legal texts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:07:14 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 19:33:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Rajapaksha", "Isanka", ""], ["Mudalige", "Chanika Ruchini", ""], ["Karunarathna", "Dilini", ""], ["de Silva", "Nisansa", ""], ["Ratnayaka", "Gathika", ""], ["Perera", "Amal Shehan", ""]]}, {"id": "2011.05684", "submitter": "Sutanu Bera", "authors": "Sutanu Bera, Prabir Kumar Biswas", "title": "Noise Conscious Training of Non Local Neural Network powered by Self\n  Attentive Spectral Normalized Markovian Patch GAN for Low Dose CT Denoising", "comments": null, "journal-ref": "IEEE Transactions on Medical Imaging 2021", "doi": "10.1109/TMI.2021.3094525", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosive rise of the use of Computer tomography (CT) imaging in medical\npractice has heightened public concern over the patient's associated radiation\ndose. However, reducing the radiation dose leads to increased noise and\nartifacts, which adversely degrades the scan's interpretability. Consequently,\nan advanced image reconstruction algorithm to improve the diagnostic\nperformance of low dose ct arose as the primary concern among the researchers,\nwhich is challenging due to the ill-posedness of the problem. In recent times,\nthe deep learning-based technique has emerged as a dominant method for low dose\nCT(LDCT) denoising. However, some common bottleneck still exists, which hinders\ndeep learning-based techniques from furnishing the best performance. In this\nstudy, we attempted to mitigate these problems with three novel accretions.\nFirst, we propose a novel convolutional module as the first attempt to utilize\nneighborhood similarity of CT images for denoising tasks. Our proposed module\nassisted in boosting the denoising by a significant margin. Next, we moved\ntowards the problem of non-stationarity of CT noise and introduced a new noise\naware mean square error loss for LDCT denoising. Moreover, the loss mentioned\nabove also assisted to alleviate the laborious effort required while training\nCT denoising network using image patches. Lastly, we propose a novel\ndiscriminator function for CT denoising tasks. The conventional vanilla\ndiscriminator tends to overlook the fine structural details and focus on the\nglobal agreement. Our proposed discriminator leverage self-attention and\npixel-wise GANs for restoring the diagnostic quality of LDCT images. Our method\nvalidated on a publicly available dataset of the 2016 NIH-AAPM-Mayo Clinic Low\nDose CT Grand Challenge performed remarkably better than the existing state of\nthe art method.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:44:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bera", "Sutanu", ""], ["Biswas", "Prabir Kumar", ""]]}, {"id": "2011.05702", "submitter": "Shidong Wang", "authors": "Shidong Wang, Yi Ren, Gerard Parr, Yu Guan and Ling Shao", "title": "Invariant Deep Compressible Covariance Pooling for Aerial Scene\n  Categorization", "comments": "This article has been accepted for inclusion in a future issue of\n  IEEE Transactions on Geoscience and Remote Sensing. Content is final as\n  presented, with the exception of pagination", "journal-ref": null, "doi": "10.1109/TGRS.2020.3026221", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning discriminative and invariant feature representation is the key to\nvisual image categorization. In this article, we propose a novel invariant deep\ncompressible covariance pooling (IDCCP) to solve nuisance variations in aerial\nscene categorization. We consider transforming the input image according to a\nfinite transformation group that consists of multiple confounding orthogonal\nmatrices, such as the D4 group. Then, we adopt a Siamese-style network to\ntransfer the group structure to the representation space, where we can derive a\ntrivial representation that is invariant under the group action. The linear\nclassifier trained with trivial representation will also be possessed with\ninvariance. To further improve the discriminative power of representation, we\nextend the representation to the tensor space while imposing orthogonal\nconstraints on the transformation matrix to effectively reduce feature\ndimensions. We conduct extensive experiments on the publicly released aerial\nscene image data sets and demonstrate the superiority of this method compared\nwith state-of-the-art methods. In particular, with using ResNet architecture,\nour IDCCP model can reduce the dimension of the tensor representation by about\n98% without sacrificing accuracy (i.e., <0.5%).\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:13:07 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Shidong", ""], ["Ren", "Yi", ""], ["Parr", "Gerard", ""], ["Guan", "Yu", ""], ["Shao", "Ling", ""]]}, {"id": "2011.05704", "submitter": "Ragav Sachdeva", "authors": "Ragav Sachdeva, Filipe R. Cordeiro, Vasileios Belagiannis, Ian Reid,\n  Gustavo Carneiro", "title": "EvidentialMix: Learning with Combined Open-set and Closed-set Noisy\n  Labels", "comments": "Paper accepted at WACV'21: Winter Conference on Applications of\n  Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficacy of deep learning depends on large-scale data sets that have been\ncarefully curated with reliable data acquisition and annotation processes.\nHowever, acquiring such large-scale data sets with precise annotations is very\nexpensive and time-consuming, and the cheap alternatives often yield data sets\nthat have noisy labels. The field has addressed this problem by focusing on\ntraining models under two types of label noise: 1) closed-set noise, where some\ntraining samples are incorrectly annotated to a training label other than their\nknown true class; and 2) open-set noise, where the training set includes\nsamples that possess a true class that is (strictly) not contained in the set\nof known training labels. In this work, we study a new variant of the noisy\nlabel problem that combines the open-set and closed-set noisy labels, and\nintroduce a benchmark evaluation to assess the performance of training\nalgorithms under this setup. We argue that such problem is more general and\nbetter reflects the noisy label scenarios in practice. Furthermore, we propose\na novel algorithm, called EvidentialMix, that addresses this problem and\ncompare its performance with the state-of-the-art methods for both closed-set\nand open-set noise on the proposed benchmark. Our results show that our method\nproduces superior classification results and better feature representations\nthan previous state-of-the-art methods. The code is available at\nhttps://github.com/ragavsachdeva/EvidentialMix.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:15:32 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Sachdeva", "Ragav", ""], ["Cordeiro", "Filipe R.", ""], ["Belagiannis", "Vasileios", ""], ["Reid", "Ian", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "2011.05705", "submitter": "Stefanos Antaris", "authors": "Stefanos Antaris, Dimitrios Rafailidis, Sarunas Girdzijauskas", "title": "EGAD: Evolving Graph Representation Learning with Self-Attention and\n  Knowledge Distillation for Live Video Streaming Events", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, we present a dynamic graph representation learning model on\nweighted graphs to accurately predict the network capacity of connections\nbetween viewers in a live video streaming event. We propose EGAD, a neural\nnetwork architecture to capture the graph evolution by introducing a\nself-attention mechanism on the weights between consecutive graph convolutional\nnetworks. In addition, we account for the fact that neural architectures\nrequire a huge amount of parameters to train, thus increasing the online\ninference latency and negatively influencing the user experience in a live\nvideo streaming event. To address the problem of the high online inference of a\nvast number of parameters, we propose a knowledge distillation strategy. In\nparticular, we design a distillation loss function, aiming to first pretrain a\nteacher model on offline data, and then transfer the knowledge from the teacher\nto a smaller student model with less parameters. We evaluate our proposed model\non the link prediction task on three real-world datasets, generated by live\nvideo streaming events. The events lasted 80 minutes and each viewer exploited\nthe distribution solution provided by the company Hive Streaming AB. The\nexperiments demonstrate the effectiveness of the proposed model in terms of\nlink prediction accuracy and number of required parameters, when evaluated\nagainst state-of-the-art approaches. In addition, we study the distillation\nperformance of the proposed model in terms of compression ratio for different\ndistillation strategies, where we show that the proposed model can achieve a\ncompression ratio up to 15:100, preserving high link prediction accuracy. For\nreproduction purposes, our evaluation datasets and implementation are publicly\navailable at https://stefanosantaris.github.io/EGAD.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:16:52 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Antaris", "Stefanos", ""], ["Rafailidis", "Dimitrios", ""], ["Girdzijauskas", "Sarunas", ""]]}, {"id": "2011.05716", "submitter": "Stefan Dernbach", "authors": "Stefan Dernbach and Don Towsley", "title": "Filtered Manifold Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation is an essential task in transfer learning to leverage data\nin one domain to bolster learning in another domain. In this paper, we present\na new semi-supervised manifold alignment technique based on a two-step approach\nof projecting and filtering the source and target domains to low dimensional\nspaces followed by joining the two spaces. Our proposed approach, filtered\nmanifold alignment (FMA), reduces the computational complexity of previous\nmanifold alignment techniques, is flexible enough to align domains with\ncompletely disparate sets of feature and demonstrates state-of-the-art\nclassification accuracy on multiple benchmark domain adaptation tasks composed\nof classifying real world image datasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:39:05 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Dernbach", "Stefan", ""], ["Towsley", "Don", ""]]}, {"id": "2011.05717", "submitter": "Teguh Santoso Lembono", "authors": "Teguh Santoso Lembono, Emmanuel Pignat, Julius Jankowski, and Sylvain\n  Calinon", "title": "Learning Constrained Distributions of Robot Configurations with\n  Generative Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high dimensional robotic system, the manifold of the valid configuration\nspace often has a complex shape, especially under constraints such as\nend-effector orientation or static stability. We propose a generative\nadversarial network approach to learn the distribution of valid robot\nconfigurations under such constraints. It can generate configurations that are\nclose to the constraint manifold. We present two applications of this method.\nFirst, by learning the conditional distribution with respect to the desired\nend-effector position, we can do fast inverse kinematics even for very high\ndegrees of freedom (DoF) systems. Then, we use it to generate samples in\nsampling-based constrained motion planning algorithms to reduce the necessary\nprojection steps, speeding up the computation. We validate the approach in\nsimulation using the 7-DoF Panda manipulator and the 28-DoF humanoid robot\nTalos.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:43:54 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2021 00:23:57 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Lembono", "Teguh Santoso", ""], ["Pignat", "Emmanuel", ""], ["Jankowski", "Julius", ""], ["Calinon", "Sylvain", ""]]}, {"id": "2011.05723", "submitter": "Ming Gong", "authors": "Shining Liang, Linjun Shou, Jian Pei, Ming Gong, Wanli Zuo, Daxin\n  Jiang", "title": "CalibreNet: Calibration Networks for Multilingual Sequence Labeling", "comments": "Long paper in WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lack of training data in low-resource languages presents huge challenges to\nsequence labeling tasks such as named entity recognition (NER) and machine\nreading comprehension (MRC). One major obstacle is the errors on the boundary\nof predicted answers. To tackle this problem, we propose CalibreNet, which\npredicts answers in two steps. In the first step, any existing sequence\nlabeling method can be adopted as a base model to generate an initial answer.\nIn the second step, CalibreNet refines the boundary of the initial answer. To\ntackle the challenge of lack of training data in low-resource languages, we\ndedicatedly develop a novel unsupervised phrase boundary recovery pre-training\ntask to enhance the multilingual boundary detection capability of CalibreNet.\nExperiments on two cross-lingual benchmark datasets show that the proposed\napproach achieves SOTA results on zero-shot cross-lingual NER and MRC tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 11:59:49 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Liang", "Shining", ""], ["Shou", "Linjun", ""], ["Pei", "Jian", ""], ["Gong", "Ming", ""], ["Zuo", "Wanli", ""], ["Jiang", "Daxin", ""]]}, {"id": "2011.05735", "submitter": "Steffen Czolbe", "authors": "Steffen Czolbe, Oswin Krause, Aasa Feragen", "title": "DeepSim: Semantic similarity metrics for learned image registration", "comments": "Talk given at Medical Imaging Meets NeurIPS, NeurIPS 2020 workshop.\n  Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a semantic similarity metric for image registration. Existing\nmetrics like euclidean distance or normalized cross-correlation focus on\naligning intensity values, giving difficulties with low intensity contrast or\nnoise. Our semantic approach learns dataset-specific features that drive the\noptimization of a learning-based registration model. Comparing to existing\nunsupervised and supervised methods across multiple image modalities and\napplications, we achieve consistently high registration accuracy and faster\nconvergence than state of the art, and the learned invariance to noise gives\nsmoother transformations on low-quality images.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 12:35:07 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Czolbe", "Steffen", ""], ["Krause", "Oswin", ""], ["Feragen", "Aasa", ""]]}, {"id": "2011.05741", "submitter": "Shinya Shiroshita", "authors": "Shinya Shiroshita, Shirou Maruyama, Daisuke Nishiyama, Mario Ynocente\n  Castro, Karim Hamzaoui, Guy Rosman, Jonathan DeCastro, Kuan-Hui Lee, Adrien\n  Gaidon", "title": "Behaviorally Diverse Traffic Simulation via Reinforcement Learning", "comments": "8 pages, 16 figures", "journal-ref": "IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), 2020, pp. 2103-2110", "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic simulators are important tools in autonomous driving development.\nWhile continuous progress has been made to provide developers more options for\nmodeling various traffic participants, tuning these models to increase their\nbehavioral diversity while maintaining quality is often very challenging. This\npaper introduces an easily-tunable policy generation algorithm for autonomous\ndriving agents. The proposed algorithm balances diversity and driving skills by\nleveraging the representation and exploration abilities of deep reinforcement\nlearning via a distinct policy set selector. Moreover, we present an algorithm\nutilizing intrinsic rewards to widen behavioral differences in the training. To\nprovide quantitative assessments, we develop two trajectory-based evaluation\nmetrics which measure the differences among policies and behavioral coverage.\nWe experimentally show the effectiveness of our methods on several challenging\nintersection scenes.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 12:49:11 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Shiroshita", "Shinya", ""], ["Maruyama", "Shirou", ""], ["Nishiyama", "Daisuke", ""], ["Castro", "Mario Ynocente", ""], ["Hamzaoui", "Karim", ""], ["Rosman", "Guy", ""], ["DeCastro", "Jonathan", ""], ["Lee", "Kuan-Hui", ""], ["Gaidon", "Adrien", ""]]}, {"id": "2011.05742", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Huoyu Liu, Aston Zhang, Yue Hu, Ce Zhang, Yumeng Li,\n  Tanchao Zhu, Shaojian He, Wenwu Ou", "title": "Learning User Representations with Hypercuboids for Recommender Systems", "comments": "Accepted by WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling user interests is crucial in real-world recommender systems. In this\npaper, we present a new user interest representation model for personalized\nrecommendation. Specifically, the key novelty behind our model is that it\nexplicitly models user interests as a hypercuboid instead of a point in the\nspace. In our approach, the recommendation score is learned by calculating a\ncompositional distance between the user hypercuboid and the item. This helps to\nalleviate the potential geometric inflexibility of existing collaborative\nfiltering approaches, enabling a greater extent of modeling capability.\nFurthermore, we present two variants of hypercuboids to enhance the capability\nin capturing the diversities of user interests. A neural architecture is also\nproposed to facilitate user hypercuboid learning by capturing the activity\nsequences (e.g., buy and rate) of users. We demonstrate the effectiveness of\nour proposed model via extensive experiments on both public and commercial\ndatasets. Empirical results show that our approach achieves very promising\nresults, outperforming existing state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 12:50:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zhang", "Shuai", ""], ["Liu", "Huoyu", ""], ["Zhang", "Aston", ""], ["Hu", "Yue", ""], ["Zhang", "Ce", ""], ["Li", "Yumeng", ""], ["Zhu", "Tanchao", ""], ["He", "Shaojian", ""], ["Ou", "Wenwu", ""]]}, {"id": "2011.05746", "submitter": "Serkan Budak", "authors": "Umut \\\"Ozkaya, \\c{S}aban \\\"Ozt\\\"urk, Serkan Budak, Farid Melgani,\n  Kemal Polat", "title": "Classification of COVID-19 in Chest CT Images using Convolutional\n  Support Vector Machines", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: Coronavirus 2019 (COVID-19), which emerged in Wuhan, China and\naffected the whole world, has cost the lives of thousands of people. Manual\ndiagnosis is inefficient due to the rapid spread of this virus. For this\nreason, automatic COVID-19 detection studies are carried out with the support\nof artificial intelligence algorithms. Methods: In this study, a deep learning\nmodel that detects COVID-19 cases with high performance is presented. The\nproposed method is defined as Convolutional Support Vector Machine (CSVM) and\ncan automatically classify Computed Tomography (CT) images. Unlike the\npre-trained Convolutional Neural Networks (CNN) trained with the transfer\nlearning method, the CSVM model is trained as a scratch. To evaluate the\nperformance of the CSVM method, the dataset is divided into two parts as\ntraining (%75) and testing (%25). The CSVM model consists of blocks containing\nthree different numbers of SVM kernels. Results: When the performance of\npre-trained CNN networks and CSVM models is assessed, CSVM (7x7, 3x3, 1x1)\nmodel shows the highest performance with 94.03% ACC, 96.09% SEN, 92.01% SPE,\n92.19% PRE, 94.10% F1-Score, 88.15% MCC and 88.07% Kappa metric values.\nConclusion: The proposed method is more effective than other methods. It has\nproven in experiments performed to be an inspiration for combating COVID and\nfor future studies.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 13:04:38 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["\u00d6zkaya", "Umut", ""], ["\u00d6zt\u00fcrk", "\u015eaban", ""], ["Budak", "Serkan", ""], ["Melgani", "Farid", ""], ["Polat", "Kemal", ""]]}, {"id": "2011.05748", "submitter": "Hao Wen", "authors": "Hao Wen, Xiongjie Chen, Georgios Papagiannis, Conghui Hu and Yunpeng\n  Li", "title": "End-To-End Semi-supervised Learning for Differentiable Particle Filters", "comments": "Accepted in ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in incorporating neural networks into particle filters\nprovide the desired flexibility to apply particle filters in large-scale\nreal-world applications. The dynamic and measurement models in this framework\nare learnable through the differentiable implementation of particle filters.\nPast efforts in optimising such models often require the knowledge of true\nstates which can be expensive to obtain or even unavailable in practice. In\nthis paper, in order to reduce the demand for annotated data, we present an\nend-to-end learning objective based upon the maximisation of a\npseudo-likelihood function which can improve the estimation of states when\nlarge portion of true states are unknown. We assess performance of the proposed\nmethod in state estimation tasks in robotics with simulated and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 13:10:11 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 14:15:04 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Wen", "Hao", ""], ["Chen", "Xiongjie", ""], ["Papagiannis", "Georgios", ""], ["Hu", "Conghui", ""], ["Li", "Yunpeng", ""]]}, {"id": "2011.05756", "submitter": "Bj\\\"orn Barz", "authors": "Bj\\\"orn Barz, Kai Schr\\\"oter, Ann-Christin Kra, Joachim Denzler", "title": "Finding Relevant Flood Images on Twitter using Content-based Filters", "comments": "ICPR 2020 Workshop on Machine Learning Advances Environmental Science\n  (MAES)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of natural disasters such as floods in a timely manner often\nsuffers from limited data due to coarsely distributed sensors or sensor\nfailures. At the same time, a plethora of information is buried in an abundance\nof images of the event posted on social media platforms such as Twitter. These\nimages could be used to document and rapidly assess the situation and derive\nproxy-data not available from sensors, e.g., the degree of water pollution.\nHowever, not all images posted online are suitable or informative enough for\nthis purpose. Therefore, we propose an automatic filtering approach using\nmachine learning techniques for finding Twitter images that are relevant for\none of the following information objectives: assessing the flooded area, the\ninundation depth, and the degree of water pollution. Instead of relying on\ntextual information present in the tweet, the filter analyzes the image\ncontents directly. We evaluate the performance of two different approaches and\nvarious features on a case-study of two major flooding events. Our image-based\nfilter is able to enhance the quality of the results substantially compared\nwith a keyword-based filter, improving the mean average precision from 23% to\n53% on average.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 13:16:54 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Barz", "Bj\u00f6rn", ""], ["Schr\u00f6ter", "Kai", ""], ["Kra", "Ann-Christin", ""], ["Denzler", "Joachim", ""]]}, {"id": "2011.05782", "submitter": "Pierre Aumjaud", "authors": "Pierre Aumjaud, David McAuliffe, Francisco Javier Rodr\\'iguez Lera,\n  Philip Cardiff", "title": "Reinforcement Learning Experiments and Benchmark for Solving Robotic\n  Reaching Tasks", "comments": null, "journal-ref": "Advances in Intelligent Systems and Computing, 1285 (2021),\n  318-331", "doi": "10.1007/978-3-030-62579-5_22", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning has shown great promise in robotics thanks to its\nability to develop efficient robotic control procedures through self-training.\nIn particular, reinforcement learning has been successfully applied to solving\nthe reaching task with robotic arms. In this paper, we define a robust,\nreproducible and systematic experimental procedure to compare the performance\nof various model-free algorithms at solving this task. The policies are trained\nin simulation and are then transferred to a physical robotic manipulator. It is\nshown that augmenting the reward signal with the Hindsight Experience Replay\nexploration technique increases the average return of off-policy agents between\n7 and 9 folds when the target position is initialised randomly at the beginning\nof each episode.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:00:49 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Aumjaud", "Pierre", ""], ["McAuliffe", "David", ""], ["Lera", "Francisco Javier Rodr\u00edguez", ""], ["Cardiff", "Philip", ""]]}, {"id": "2011.05785", "submitter": "Tam\\'as Kriv\\'achy", "authors": "Tam\\'as Kriv\\'achy, Yu Cai, Joseph Bowles, Daniel Cavalcanti and\n  Nicolas Brunner", "title": "Fast semidefinite programming with feedforward neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semidefinite programming is an important optimization task, often used in\ntime-sensitive applications. Though they are solvable in polynomial time, in\npractice they can be too slow to be used in online, i.e. real-time\napplications. Here we propose to solve feasibility semidefinite programs using\nartificial neural networks. Given the optimization constraints as an input, a\nneural network outputs values for the optimization parameters such that the\nconstraints are satisfied, both for the primal and the dual formulations of the\ntask. We train the network without having to exactly solve the semidefinite\nprogram even once, thus avoiding the possibly time-consuming task of having to\ngenerate many training samples with conventional solvers. The neural network\nmethod is only inconclusive if both the primal and dual models fail to provide\nfeasible solutions. Otherwise we always obtain a certificate, which guarantees\nfalse positives to be excluded. We examine the performance of the method on a\nhierarchy of quantum information tasks, the Navascu\\'es-Pironio-Ac\\'in\nhierarchy applied to the Bell scenario. We demonstrate that the trained neural\nnetwork gives decent accuracy, while showing orders of magnitude increase in\nspeed compared to a traditional solver.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:01:34 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 10:53:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kriv\u00e1chy", "Tam\u00e1s", ""], ["Cai", "Yu", ""], ["Bowles", "Joseph", ""], ["Cavalcanti", "Daniel", ""], ["Brunner", "Nicolas", ""]]}, {"id": "2011.05790", "submitter": "S.M. Riazul Islam PhD", "authors": "Naira Elazab, Hassan Soliman, Shaker El-Sappagh, S. M. Riazul Islam,\n  and Mohammed Elmogy", "title": "Objective Diagnosis for Histopathological Images Based on Machine\n  Learning Techniques: Classical Approaches and New Trends", "comments": "26 Pages, 5 figures, 4 tables", "journal-ref": "Mathematics 2020, 8(11), 1863", "doi": "10.3390/math8111863", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Histopathology refers to the examination by a pathologist of biopsy samples.\nHistopathology images are captured by a microscope to locate, examine, and\nclassify many diseases, such as different cancer types. They provide a detailed\nview of different types of diseases and their tissue status. These images are\nan essential resource with which to define biological compositions or analyze\ncell and tissue structures. This imaging modality is very important for\ndiagnostic applications. The analysis of histopathology images is a prolific\nand relevant research area supporting disease diagnosis. In this paper, the\nchallenges of histopathology image analysis are evaluated. An extensive review\nof conventional and deep learning techniques which have been applied in\nhistological image analyses is presented. This review summarizes many current\ndatasets and highlights important challenges and constraints with recent deep\nlearning techniques, alongside possible future research avenues. Despite the\nprogress made in this research area so far, it is still a significant area of\nopen research because of the variety of imaging techniques and disease-specific\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 07:31:05 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Elazab", "Naira", ""], ["Soliman", "Hassan", ""], ["El-Sappagh", "Shaker", ""], ["Islam", "S. M. Riazul", ""], ["Elmogy", "Mohammed", ""]]}, {"id": "2011.05791", "submitter": "Pratik Shah", "authors": "Sambuddha Ghosal and Pratik Shah", "title": "Interpretable and synergistic deep learning for visual explanation and\n  statistical estimations of segmentation of disease features from medical\n  images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) models for disease classification or segmentation from\nmedical images are increasingly trained using transfer learning (TL) from\nunrelated natural world images. However, shortcomings and utility of TL for\nspecialized tasks in the medical imaging domain remain unknown and are based on\nassumptions that increasing training data will improve performance. We report\ndetailed comparisons, rigorous statistical analysis and comparisons of widely\nused DL architecture for binary segmentation after TL with ImageNet\ninitialization (TII-models) with supervised learning with only medical\nimages(LMI-models) of macroscopic optical skin cancer, microscopic prostate\ncore biopsy and Computed Tomography (CT) DICOM images. Through visual\ninspection of TII and LMI model outputs and their Grad-CAM counterparts, our\nresults identify several counter intuitive scenarios where automated\nsegmentation of one tumor by both models or the use of individual segmentation\noutput masks in various combinations from individual models leads to 10%\nincrease in performance. We also report sophisticated ensemble DL strategies\nfor achieving clinical grade medical image segmentation and model explanations\nunder low data regimes. For example; estimating performance, explanations and\nreplicability of LMI and TII models described by us can be used for situations\nin which sparsity promotes better learning. A free GitHub repository of TII and\nLMI models, code and more than 10,000 medical images and their Grad-CAM output\nfrom this study can be used as starting points for advanced computational\nmedicine and DL research for biomedical discovery and applications.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:08:17 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Ghosal", "Sambuddha", ""], ["Shah", "Pratik", ""]]}, {"id": "2011.05794", "submitter": "Daniel Andr\\'es D\\'iaz Pach\\'on", "authors": "Daniel Andr\\'es D\\'iaz-Pach\\'on and Juan Pablo S\\'aenz and J. Sunil\n  Rao and Jean-Eudes Dazard", "title": "Mode hunting through active information", "comments": "12 pages", "journal-ref": "Applied Stochastic Models in Business and Industry (35)2, pp.\n  376-393, 2019", "doi": "10.1002/asmb.2430", "report-no": null, "categories": "physics.data-an cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a new method to find modes based on active information. We develop\nan algorithm that, when applied to the whole space, will say whether there are\nany modes present \\textit{and} where they are; this algorithm will reduce the\ndimensionality without resorting to Principal Components; and more importantly,\npopulation-wise, will not detect modes when they are not present.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 01:55:29 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["D\u00edaz-Pach\u00f3n", "Daniel Andr\u00e9s", ""], ["S\u00e1enz", "Juan Pablo", ""], ["Rao", "J. Sunil", ""], ["Dazard", "Jean-Eudes", ""]]}, {"id": "2011.05801", "submitter": "Debanjan Datta", "authors": "Debanjan Datta", "title": "Small Survey Event Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A small survey on event detection using Twitter. This work first defines the\nproblem statement, and then summarizes and collates the different research\nworks towards solving the problem.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 02:24:58 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Datta", "Debanjan", ""]]}, {"id": "2011.05803", "submitter": "Francesco Borra", "authors": "Francesco Borra, Marco Baldovin", "title": "Using machine-learning modelling to understand macroscopic dynamics in a\n  system of coupled maps", "comments": "17 pages, 13 figures", "journal-ref": null, "doi": "10.1063/5.0036809", "report-no": null, "categories": "physics.data-an cond-mat.stat-mech cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques not only offer efficient tools for modelling\ndynamical systems from data, but can also be employed as frontline\ninvestigative instruments for the underlying physics. Nontrivial information\nabout the original dynamics, which would otherwise require sophisticated ad-hoc\ntechniques, can be obtained by a careful usage of such methods. To illustrate\nthis point, we consider as a case study the macroscopic motion emerging from a\nsystem of globally coupled maps. We build a coarse-grained Markov process for\nthe macroscopic dynamics both with a machine learning approach and with a\ndirect numerical computation of the transition probability of the\ncoarse-grained process, and we compare the outcomes of the two analyses. Our\npurpose is twofold: on the one hand, we want to test the ability of the\nstochastic machine learning approach to describe nontrivial evolution laws, as\nthe one considered in our study; on the other hand, we aim at gaining some\ninsight into the physics of the macroscopic dynamics by modulating the\ninformation available to the network, we are able to infer important\ninformation about the effective dimension of the attractor, the persistence of\nmemory effects and the multi-scale structure of the dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:38:12 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Borra", "Francesco", ""], ["Baldovin", "Marco", ""]]}, {"id": "2011.05804", "submitter": "Padraig Corcoran", "authors": "Padraig Corcoran, Bailin Deng", "title": "Regularization of Persistent Homology Gradient Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Persistent homology is a method for computing the topological features\npresent in a given data. Recently, there has been much interest in the\nintegration of persistent homology as a computational step in neural networks\nor deep learning. In order for a given computation to be integrated in such a\nway, the computation in question must be differentiable. Computing the\ngradients of persistent homology is an ill-posed inverse problem with\ninfinitely many solutions. Consequently, it is important to perform\nregularization so that the solution obtained agrees with known priors. In this\nwork we propose a novel method for regularizing persistent homology gradient\ncomputation through the addition of a grouping term. This has the effect of\nhelping to ensure gradients are defined with respect to larger entities and not\nindividual points.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:16:33 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 12:50:13 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Corcoran", "Padraig", ""], ["Deng", "Bailin", ""]]}, {"id": "2011.05806", "submitter": "Maryam Edalati", "authors": "Maryam Edalati", "title": "The Potential of Machine Learning and NLP for Handling Students'\n  Feedback (A Short Survey)", "comments": "10 pages, 3 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a review of the literature of students' feedback papers\npublished in recent years employing data mining techniques. In particular, the\nfocus is to highlight those papers which are using either machine learning or\ndeep learning approaches. Student feedback assessment is a hot topic which has\nattracted a lot of attention in recent times. The importance has increased\nmanyfold due to the recent pandemic outbreak which pushed many colleges and\nuniversities to shift teaching from on-campus physical classes to online via\neLearning platforms and tools including massive open online courses (MOOCs).\nAssessing student feedback is even more important now. This short survey paper,\ntherefore, highlights recent trends in the natural language processing domain\non the topic of automatic student feedback assessment. It presents techniques\ncommonly utilized in this domain and discusses some future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 17:28:40 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Edalati", "Maryam", ""]]}, {"id": "2011.05816", "submitter": "Jie Wang", "authors": "Zhanqiu Zhang, Jianyu Cai, Jie Wang", "title": "Duality-Induced Regularizer for Tensor Factorization Based Knowledge\n  Graph Completion", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tensor factorization based models have shown great power in knowledge graph\ncompletion (KGC). However, their performance usually suffers from the\noverfitting problem seriously. This motivates various regularizers -- such as\nthe squared Frobenius norm and tensor nuclear norm regularizers -- while the\nlimited applicability significantly limits their practical usage. To address\nthis challenge, we propose a novel regularizer -- namely, DUality-induced\nRegulArizer (DURA) -- which is not only effective in improving the performance\nof existing models but widely applicable to various methods. The major novelty\nof DURA is based on the observation that, for an existing tensor factorization\nbased KGC model (primal), there is often another distance based KGC model\n(dual) closely associated with it. Experiments show that DURA yields consistent\nand significant improvements on benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:29:52 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 06:39:44 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Zhang", "Zhanqiu", ""], ["Cai", "Jianyu", ""], ["Wang", "Jie", ""]]}, {"id": "2011.05824", "submitter": "Philipp Kopper", "authors": "Philipp Kopper, Sebastian P\\\"olsterl, Christian Wachinger, Bernd\n  Bischl, Andreas Bender, David R\\\"ugamer", "title": "Semi-Structured Deep Piecewise Exponential Models", "comments": "8 pages, 3 figures, Accepted at the AAAI spring symposium: Survival\n  Prediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a versatile framework for survival analysis that combines advanced\nconcepts from statistics with deep learning. The presented framework is based\non piecewise exponential models and thereby supports various survival tasks,\nsuch as competing risks and multi-state modeling, and further allows for\nestimation of time-varying effects and time-varying features. To also include\nmultiple data sources and higher-order interaction effects into the model, we\nembed the model class in a neural network and thereby enable the simultaneous\nestimation of both inherently interpretable structured regression inputs as\nwell as deep neural network components which can potentially process additional\nunstructured data sources. A proof of concept is provided by using the\nframework to predict Alzheimer's disease progression based on tabular and 3D\npoint cloud data and applying it to synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:41:19 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 20:28:54 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 13:32:38 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kopper", "Philipp", ""], ["P\u00f6lsterl", "Sebastian", ""], ["Wachinger", "Christian", ""], ["Bischl", "Bernd", ""], ["Bender", "Andreas", ""], ["R\u00fcgamer", "David", ""]]}, {"id": "2011.05836", "submitter": "Maxime Vandegar", "authors": "Maxime Vandegar, Michael Kagan, Antoine Wehenkel, Gilles Louppe", "title": "Neural Empirical Bayes: Source Distribution Estimation and its\n  Applications to Simulation-Based Inference", "comments": "Camera-ready version presented at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex hep-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit empirical Bayes in the absence of a tractable likelihood function,\nas is typical in scientific domains relying on computer simulations. We\ninvestigate how the empirical Bayesian can make use of neural density\nestimators first to use all noise-corrupted observations to estimate a prior or\nsource distribution over uncorrupted samples, and then to perform\nsingle-observation posterior inference using the fitted source distribution. We\npropose an approach based on the direct maximization of the log-marginal\nlikelihood of the observations, examining both biased and de-biased estimators,\nand comparing to variational approaches. We find that, up to symmetries, a\nneural empirical Bayes approach recovers ground truth source distributions.\nWith the learned source distribution in hand, we show the applicability to\nlikelihood-free inference and examine the quality of the resulting posterior\nestimates. Finally, we demonstrate the applicability of Neural Empirical Bayes\non an inverse problem from collider physics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 14:59:34 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 22:26:52 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Vandegar", "Maxime", ""], ["Kagan", "Michael", ""], ["Wehenkel", "Antoine", ""], ["Louppe", "Gilles", ""]]}, {"id": "2011.05841", "submitter": "Nicolas Tempelmeier", "authors": "Nicolas Tempelmeier, Elena Demidova", "title": "Linking OpenStreetMap with Knowledge Graphs -- Link Discovery for\n  Schema-Agnostic Volunteered Geographic Information", "comments": null, "journal-ref": "Future Generation Computer Systems 116 (2021) 349-364", "doi": "10.1016/j.future.2020.11.003", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Representations of geographic entities captured in popular knowledge graphs\nsuch as Wikidata and DBpedia are often incomplete. OpenStreetMap (OSM) is a\nrich source of openly available, volunteered geographic information that has a\nhigh potential to complement these representations. However, identity links\nbetween the knowledge graph entities and OSM nodes are still rare. The problem\nof link discovery in these settings is particularly challenging due to the lack\nof a strict schema and heterogeneity of the user-defined node representations\nin OSM. In this article, we propose OSM2KG - a novel link discovery approach to\npredict identity links between OSM nodes and geographic entities in a knowledge\ngraph. The core of the OSM2KG approach is a novel latent, compact\nrepresentation of OSM nodes that captures semantic node similarity in an\nembedding. OSM2KG adopts this latent representation to train a supervised model\nfor link prediction and utilises existing links between OSM and knowledge\ngraphs for training. Our experiments conducted on several OSM datasets, as well\nas the Wikidata and DBpedia knowledge graphs, demonstrate that OSM2KG can\nreliably discover identity links. OSM2KG achieves an F1 score of 92.05% on\nWikidata and of 94.17% on DBpedia on average, which corresponds to a 21.82\npercentage points increase in F1 score on Wikidata compared to the best\nperforming baselines.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 19:03:41 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 10:47:53 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 14:30:43 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Tempelmeier", "Nicolas", ""], ["Demidova", "Elena", ""]]}, {"id": "2011.05847", "submitter": "Florent Forest", "authors": "Florent Forest, Mustapha Lebbah, Hanane Azzag, J\\'er\\^ome Lacaille", "title": "A Survey and Implementation of Performance Metrics for Self-Organized\n  Maps", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Self-Organizing Map algorithms have been used for almost 40 years across\nvarious application domains such as biology, geology, healthcare, industry and\nhumanities as an interpretable tool to explore, cluster and visualize\nhigh-dimensional data sets. In every application, practitioners need to know\nwhether they can \\textit{trust} the resulting mapping, and perform model\nselection to tune algorithm parameters (e.g. the map size). Quantitative\nevaluation of self-organizing maps (SOM) is a subset of clustering validation,\nwhich is a challenging problem as such. Clustering model selection is typically\nachieved by using clustering validity indices. While they also apply to\nself-organized clustering models, they ignore the topology of the map, only\nanswering the question: do the SOM code vectors approximate well the data\ndistribution? Evaluating SOM models brings in the additional challenge of\nassessing their topology: does the mapping preserve neighborhood relationships\nbetween the map and the original data? The problem of assessing the performance\nof SOM models has already been tackled quite thoroughly in literature, giving\nbirth to a family of quality indices incorporating neighborhood constraints,\ncalled \\textit{topographic} indices. Commonly used examples of such metrics are\nthe topographic error, neighborhood preservation or the topographic product.\nHowever, open-source implementations are almost impossible to find. This is the\nissue we try to solve in this work: after a survey of existing SOM performance\nmetrics, we implemented them in Python and widely used numerical libraries, and\nprovide them as an open-source library, SOMperf. This paper introduces each\nmetric available in our module along with usage examples.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 15:28:33 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Forest", "Florent", ""], ["Lebbah", "Mustapha", ""], ["Azzag", "Hanane", ""], ["Lacaille", "J\u00e9r\u00f4me", ""]]}, {"id": "2011.05864", "submitter": "Bohan Li", "authors": "Bohan Li and Hao Zhou and Junxian He and Mingxuan Wang and Yiming Yang\n  and Lei Li", "title": "On the Sentence Embeddings from Pre-trained Language Models", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained contextual representations like BERT have achieved great success\nin natural language processing. However, the sentence embeddings from the\npre-trained language models without fine-tuning have been found to poorly\ncapture semantic meaning of sentences. In this paper, we argue that the\nsemantic information in the BERT embeddings is not fully exploited. We first\nreveal the theoretical connection between the masked language model\npre-training objective and the semantic similarity task theoretically, and then\nanalyze the BERT sentence embeddings empirically. We find that BERT always\ninduces a non-smooth anisotropic semantic space of sentences, which harms its\nperformance of semantic similarity. To address this issue, we propose to\ntransform the anisotropic sentence embedding distribution to a smooth and\nisotropic Gaussian distribution through normalizing flows that are learned with\nan unsupervised objective. Experimental results show that our proposed\nBERT-flow method obtains significant performance gains over the\nstate-of-the-art sentence embeddings on a variety of semantic textual\nsimilarity tasks. The code is available at\nhttps://github.com/bohanli/BERT-flow.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:14:57 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Li", "Bohan", ""], ["Zhou", "Hao", ""], ["He", "Junxian", ""], ["Wang", "Mingxuan", ""], ["Yang", "Yiming", ""], ["Li", "Lei", ""]]}, {"id": "2011.05869", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Yingbin Liang, Guanghui Lan", "title": "CRPO: A New Approach for Safe Reinforcement Learning with Convergence\n  Guarantee", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In safe reinforcement learning (SRL) problems, an agent explores the\nenvironment to maximize an expected total reward and meanwhile avoids violation\nof certain constraints on a number of expected total costs. In general, such\nSRL problems have nonconvex objective functions subject to multiple nonconvex\nconstraints, and hence are very challenging to solve, particularly to provide a\nglobally optimal policy. Many popular SRL algorithms adopt a primal-dual\nstructure which utilizes the updating of dual variables for satisfying the\nconstraints. In contrast, we propose a primal approach, called\nconstraint-rectified policy optimization (CRPO), which updates the policy\nalternatingly between objective improvement and constraint satisfaction. CRPO\nprovides a primal-type algorithmic framework to solve SRL problems, where each\npolicy update can take any variant of policy optimization step. To demonstrate\nthe theoretical performance of CRPO, we adopt natural policy gradient (NPG) for\neach policy update step and show that CRPO achieves an\n$\\mathcal{O}(1/\\sqrt{T})$ convergence rate to the global optimal policy in the\nconstrained policy set and an $\\mathcal{O}(1/\\sqrt{T})$ error bound on\nconstraint satisfaction. This is the first finite-time analysis of primal SRL\nalgorithms with global optimality guarantee. Our empirical results demonstrate\nthat CRPO can outperform the existing primal-dual baseline algorithms\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:05:14 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 21:24:18 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 04:41:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Tengyu", ""], ["Liang", "Yingbin", ""], ["Lan", "Guanghui", ""]]}, {"id": "2011.05873", "submitter": "Giulio Gambardella", "authors": "Ussama Zahid, Giulio Gambardella, Nicholas J. Fraser, Michaela Blott,\n  Kees Vissers", "title": "FAT: Training Neural Networks for Reliable Inference Under Hardware\n  Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are state-of-the-art algorithms for multiple\napplications, spanning from image classification to speech recognition. While\nproviding excellent accuracy, they often have enormous compute and memory\nrequirements. As a result of this, quantized neural networks (QNNs) are\nincreasingly being adopted and deployed especially on embedded devices, thanks\nto their high accuracy, but also since they have significantly lower compute\nand memory requirements compared to their floating point equivalents. QNN\ndeployment is also being evaluated for safety-critical applications, such as\nautomotive, avionics, medical or industrial. These systems require functional\nsafety, guaranteeing failure-free behaviour even in the presence of hardware\nfaults. In general fault tolerance can be achieved by adding redundancy to the\nsystem, which further exacerbates the overall computational demands and makes\nit difficult to meet the power and performance requirements. In order to\ndecrease the hardware cost for achieving functional safety, it is vital to\nexplore domain-specific solutions which can exploit the inherent features of\nDNNs. In this work we present a novel methodology called fault-aware training\n(FAT), which includes error modeling during neural network (NN) training, to\nmake QNNs resilient to specific fault models on the device. Our experiments\nshow that by injecting faults in the convolutional layers during training,\nhighly accurate convolutional neural networks (CNNs) can be trained which\nexhibits much better error tolerance compared to the original. Furthermore, we\nshow that redundant systems which are built from QNNs trained with FAT achieve\nhigher worse-case accuracy at lower hardware cost. This has been validated for\nnumerous classification tasks including CIFAR10, GTSRB, SVHN and ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:09:39 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Zahid", "Ussama", ""], ["Gambardella", "Giulio", ""], ["Fraser", "Nicholas J.", ""], ["Blott", "Michaela", ""], ["Vissers", "Kees", ""]]}, {"id": "2011.05877", "submitter": "Yanbo Xu", "authors": "Yanbo Xu, Divyat Mahajan, Liz Manrao, Amit Sharma and Emre Kiciman", "title": "Split-Treatment Analysis to Rank Heterogeneous Causal Effects for\n  Prospective Interventions", "comments": "To be published in WSDM", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For many kinds of interventions, such as a new advertisement, marketing\nintervention, or feature recommendation, it is important to target a specific\nsubset of people for maximizing its benefits at minimum cost or potential harm.\nHowever, a key challenge is that no data is available about the effect of such\na prospective intervention since it has not been deployed yet. In this work, we\npropose a split-treatment analysis that ranks the individuals most likely to be\npositively affected by a prospective intervention using past observational\ndata. Unlike standard causal inference methods, the split-treatment method does\nnot need any observations of the target treatments themselves. Instead it\nrelies on observations of a proxy treatment that is caused by the target\ntreatment. Under reasonable assumptions, we show that the ranking of\nheterogeneous causal effect based on the proxy treatment is the same as the\nranking based on the target treatment's effect. In the absence of any\ninterventional data for cross-validation, Split-Treatment uses sensitivity\nanalyses for unobserved confounding to select model parameters. We apply\nSplit-Treatment to both a simulated data and a large-scale, real-world\ntargeting task and validate our discovered rankings via a randomized experiment\nfor the latter.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:17:29 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Xu", "Yanbo", ""], ["Mahajan", "Divyat", ""], ["Manrao", "Liz", ""], ["Sharma", "Amit", ""], ["Kiciman", "Emre", ""]]}, {"id": "2011.05885", "submitter": "Xinjian Huang", "authors": "Xinjian Huang and Weiwei Liu and Bo Du", "title": "Matrix Completion with Noise via Leveraged Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many matrix completion methods assume that the data follows the uniform\ndistribution. To address the limitation of this assumption, Chen et al.\n\\cite{Chen20152999} propose to recover the matrix where the data follows the\nspecific biased distribution. Unfortunately, in most real-world applications,\nthe recovery of a data matrix appears to be incomplete, and perhaps even\ncorrupted information. This paper considers the recovery of a low-rank matrix,\nwhere some observed entries are sampled in a \\emph{biased distribution}\nsuitably dependent on \\emph{leverage scores} of a matrix, and some observed\nentries are uniformly corrupted. Our theoretical findings show that we can\nprovably recover an unknown $n\\times n$ matrix of rank $r$ from just about\n$O(nr\\log^2 n)$ entries even when the few observed entries are corrupted with a\nsmall amount of noisy information. Empirical studies verify our theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:25:45 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Huang", "Xinjian", ""], ["Liu", "Weiwei", ""], ["Du", "Bo", ""]]}, {"id": "2011.05895", "submitter": "Vinayaka R Kamath", "authors": "Vinayaka R Kamath, Vishal S, Varun M", "title": "Transferred Fusion Learning using Skipped Networks", "comments": "9 Pages, 7 figures, Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Identification of an entity that is of interest is prominent in any\nintelligent system. The visual intelligence of the model is enhanced when the\ncapability of recognition is added. Several methods such as transfer learning\nand zero shot learning help to reuse the existing models or augment the\nexisting model to achieve improved performance at the task of object\nrecognition. Transferred fusion learning is one such mechanism that intends to\nuse the best of both worlds and build a model that is capable of outperforming\nthe models involved in the system. We propose a novel mechanism to amplify the\nprocess of transfer learning by introducing a student architecture where the\nnetworks learn from each other.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:41:55 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Kamath", "Vinayaka R", ""], ["S", "Vishal", ""], ["M", "Varun", ""]]}, {"id": "2011.05897", "submitter": "Daksha Yadav", "authors": "Daksha Yadav, Naman Kohli, Mayank Vatsa, Richa Singh, Afzel Noore", "title": "Age Gap Reducer-GAN for Recognizing Age-Separated Faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose a novel algorithm for matching faces with temporal\nvariations caused due to age progression. The proposed generative adversarial\nnetwork algorithm is a unified framework that combines facial age estimation\nand age-separated face verification. The key idea of this approach is to learn\nthe age variations across time by conditioning the input image on the subject's\ngender and the target age group to which the face needs to be progressed. The\nloss function accounts for reducing the age gap between the original image and\ngenerated face image as well as preserving the identity. Both visual fidelity\nand quantitative evaluations demonstrate the efficacy of the proposed\narchitecture on different facial age databases for age-separated face\nrecognition.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:43:32 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Yadav", "Daksha", ""], ["Kohli", "Naman", ""], ["Vatsa", "Mayank", ""], ["Singh", "Richa", ""], ["Noore", "Afzel", ""]]}, {"id": "2011.05900", "submitter": "Marta Avalos", "authors": "Marta Avalos-Fernandez and Helene Touchais and Marcela\n  Henriquez-Henriquez", "title": "A decision-making tool to fine-tune abnormal levels in the complete\n  blood count tests", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The complete blood count (CBC) performed by automated hematology analyzers is\none of the most ordered laboratory tests. It is a first-line tool for assessing\na patient's general health status, or diagnosing and monitoring disease\nprogression. When the analysis does not fit an expected setting, technologists\nmanually review a blood smear using a microscope. The International Consensus\nGroup for Hematology Review published in 2005 a set of criteria for reviewing\nCBCs. Commonly, adjustments are locally needed to account for laboratory\nresources and populations characteristics. Our objective is to provide a\ndecision support tool to identify which CBC variables are associated with\nhigher risks of abnormal smear and at which cutoff values. We propose a\ncost-sensitive Lasso-penalized additive logistic regression combined with\nstability selection. Using simulated and real CBC data, we demonstrate that our\ntool correctly identify the true cutoff values, provided that there is enough\navailable data in their neighbourhood.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:47:03 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 16:11:54 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Avalos-Fernandez", "Marta", ""], ["Touchais", "Helene", ""], ["Henriquez-Henriquez", "Marcela", ""]]}, {"id": "2011.05905", "submitter": "Zhichuang Sun", "authors": "Zhichuang Sun, Ruimin Sun, Changming Liu, Amrita Roy Chowdhury, Somesh\n  Jha, Long Lu", "title": "ShadowNet: A Secure and Efficient System for On-device Model Inference", "comments": "single column, 21 pages (29 pages include appendix), 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased usage of AI accelerators on mobile and edge devices,\non-device machine learning (ML) is gaining popularity. Consequently, thousands\nof proprietary ML models are being deployed on billions of untrusted devices.\nThis raises serious security concerns about model privacy. However, protecting\nthe model privacy without losing access to the AI accelerators is a challenging\nproblem. In this paper, we present a novel on-device model inference system,\nShadowNet. ShadowNet protects the model privacy with Trusted Execution\nEnvironment (TEE) while securely outsourcing the heavy linear layers of the\nmodel to the untrusted hardware accelerators. ShadowNet achieves this by\ntransforming the weights of the linear layers before outsourcing them and\nrestoring the results inside the TEE. The nonlinear layers are also kept secure\ninside the TEE. The transformation of the weights and the restoration of the\nresults are designed in a way that can be implemented efficiently. We have\nbuilt a ShadowNet prototype based on TensorFlow Lite and applied it on four\npopular CNNs, namely, MobileNets, ResNet-44, AlexNet and MiniVGG. Our\nevaluation shows that ShadowNet achieves strong security guarantees with\nreasonable performance, offering a practical solution for secure on-device\nmodel inference.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:50:08 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 18:28:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sun", "Zhichuang", ""], ["Sun", "Ruimin", ""], ["Liu", "Changming", ""], ["Chowdhury", "Amrita Roy", ""], ["Jha", "Somesh", ""], ["Lu", "Long", ""]]}, {"id": "2011.05927", "submitter": "Biswadip Dey", "authors": "Udari Madhushani, Biswadip Dey, Naomi Ehrich Leonard, Amit Chakraborty", "title": "Hamiltonian Q-Learning: Leveraging Importance-sampling for Data\n  Efficient RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning (RL), in particular Q-learning is widely\nused to learn optimal policies for a variety of planning and control problems.\nHowever, when the underlying state-transition dynamics are stochastic and\nhigh-dimensional, Q-learning requires a large amount of data and incurs a\nprohibitively high computational cost. In this paper, we introduce Hamiltonian\nQ-Learning, a data efficient modification of the Q-learning approach, which\nadopts an importance-sampling based technique for computing the Q function. To\nexploit stochastic structure of the state-transition dynamics, we employ\nHamiltonian Monte Carlo to update Q function estimates by approximating the\nexpected future rewards using Q values associated with a subset of next states.\nFurther, to exploit the latent low-rank structure of the dynamic system,\nHamiltonian Q-Learning uses a matrix completion algorithm to reconstruct the\nupdated Q function from Q value updates over a much smaller subset of\nstate-action pairs. By providing an efficient way to apply Q-learning in\nstochastic, high-dimensional problems, the proposed approach broadens the scope\nof RL algorithms for real-world applications, including classical control tasks\nand environmental monitoring.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:35:25 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 21:32:44 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Madhushani", "Udari", ""], ["Dey", "Biswadip", ""], ["Leonard", "Naomi Ehrich", ""], ["Chakraborty", "Amit", ""]]}, {"id": "2011.05934", "submitter": "Di Wang", "authors": "Di Wang and Marco Gaboardi and Adam Smith and Jinhui Xu", "title": "Empirical Risk Minimization in the Non-interactive Local Model of\n  Differential Privacy", "comments": "Appeared at Journal of Machine Learning Research. The journal version\n  of arXiv:1802.04085, fixed a bug in arXiv:1812.06825", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we study the Empirical Risk Minimization (ERM) problem in the\nnon-interactive Local Differential Privacy (LDP) model. Previous research on\nthis problem \\citep{smith2017interaction} indicates that the sample complexity,\nto achieve error $\\alpha$, needs to be exponentially depending on the\ndimensionality $p$ for general loss functions. In this paper, we make two\nattempts to resolve this issue by investigating conditions on the loss\nfunctions that allow us to remove such a limit. In our first attempt, we show\nthat if the loss function is $(\\infty, T)$-smooth, by using the Bernstein\npolynomial approximation we can avoid the exponential dependency in the term of\n$\\alpha$. We then propose player-efficient algorithms with $1$-bit\ncommunication complexity and $O(1)$ computation cost for each player. The error\nbound of these algorithms is asymptotically the same as the original one. With\nsome additional assumptions, we also give an algorithm which is more efficient\nfor the server. In our second attempt, we show that for any $1$-Lipschitz\ngeneralized linear convex loss function, there is an $(\\epsilon, \\delta)$-LDP\nalgorithm whose sample complexity for achieving error $\\alpha$ is only linear\nin the dimensionality $p$. Our results use a polynomial of inner product\napproximation technique. Finally, motivated by the idea of using polynomial\napproximation and based on different types of polynomial approximations, we\npropose (efficient) non-interactive locally differentially private algorithms\nfor learning the set of k-way marginal queries and the set of smooth queries.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 17:48:00 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Di", ""], ["Gaboardi", "Marco", ""], ["Smith", "Adam", ""], ["Xu", "Jinhui", ""]]}, {"id": "2011.05944", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Tor Lattimore, Claire Vernade, Csaba Szepesv\\'ari", "title": "Asymptotically Optimal Information-Directed Sampling", "comments": "Accepted at COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and efficient algorithm for stochastic linear bandits\nwith finitely many actions that is asymptotically optimal and (nearly)\nworst-case optimal in finite time. The approach is based on the frequentist\ninformation-directed sampling (IDS) framework, with a surrogate for the\ninformation gain that is informed by the optimization problem that defines the\nasymptotic lower bound. Our analysis sheds light on how IDS balances the\ntrade-off between regret and information and uncovers a surprising connection\nbetween the recently proposed primal-dual methods and the IDS algorithm. We\ndemonstrate empirically that IDS is competitive with UCB in finite-time, and\ncan be significantly better in the asymptotic regime.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:01:59 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 11:45:07 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 13:27:00 GMT"}, {"version": "v4", "created": "Fri, 2 Jul 2021 08:21:07 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kirschner", "Johannes", ""], ["Lattimore", "Tor", ""], ["Vernade", "Claire", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2011.05953", "submitter": "Jeremiah Birrell", "authors": "Jeremiah Birrell, Paul Dupuis, Markos A. Katsoulakis, Yannis Pantazis,\n  Luc Rey-Bellet", "title": "$(f,\\Gamma)$-Divergences: Interpolating between $f$-Divergences and\n  Integral Probability Metrics", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a rigorous and general framework for constructing\ninformation-theoretic divergences that subsume both $f$-divergences and\nintegral probability metrics (IPMs), such as the $1$-Wasserstein distance. We\nprove under which assumptions these divergences, hereafter referred to as\n$(f,\\Gamma)$-divergences, provide a notion of `distance' between probability\nmeasures and show that they can be expressed as a two-stage\nmass-redistribution/mass-transport process. The $(f,\\Gamma)$-divergences\ninherit features from IPMs, such as the ability to compare distributions which\nare not absolutely continuous, as well as from $f$-divergences, namely the\nstrict concavity of their variational representations and the ability to\ncontrol heavy-tailed distributions for particular choices of $f$. When\ncombined, these features establish a divergence with improved properties for\nestimation, statistical learning, and uncertainty quantification applications.\nUsing statistical learning as an example, we demonstrate their advantage in\ntraining generative adversarial networks (GANs) for heavy-tailed,\nnot-absolutely continuous sample distributions and we also show improved\nperformance and stability over gradient-penalized Wasserstein GAN in image\ngeneration.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:17:09 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 19:21:56 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Birrell", "Jeremiah", ""], ["Dupuis", "Paul", ""], ["Katsoulakis", "Markos A.", ""], ["Pantazis", "Yannis", ""], ["Rey-Bellet", "Luc", ""]]}, {"id": "2011.05961", "submitter": "Orpaz Goldstein", "authors": "Orpaz Goldstein, Mohammad Kachuee, Dereck Shiell, Majid Sarrafzadeh", "title": "Real-Time Decentralized knowledge Transfer at the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Proliferation of edge networks creates islands of learning agents working on\nlocal streams of data. Transferring knowledge between these agents in real-time\nwithout exposing private data allows for collaboration to decrease learning\ntime, and increase model confidence. Incorporating knowledge from data that was\nnot seen by a local model creates an ability to debias a local model, or add to\nclassification abilities on data never before seen. Transferring knowledge in a\ndecentralized approach allows for models to retain their local insights, in\nturn allowing for local flavors of a machine learning model. This approach\nsuits the decentralized architecture of edge networks, as a local edge node\nwill serve a community of learning agents that will likely encounter similar\ndata. We propose a method based on knowledge distillation for pairwise\nknowledge transfer pipelines, and compare to other popular knowledge transfer\nmethods. Additionally, we test different scenarios of knowledge transfer\nnetwork construction and show the practicality of our approach. Based on our\nexperiments we show knowledge transfer using our model outperforms common\nmethods in a real time transfer scenario.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:26:57 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 00:16:58 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Goldstein", "Orpaz", ""], ["Kachuee", "Mohammad", ""], ["Shiell", "Dereck", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "2011.05970", "submitter": "Sudeep Dasari", "authors": "Sudeep Dasari, Abhinav Gupta", "title": "Transformers for One-Shot Visual Imitation", "comments": "For code and project video please check our website:\n  https://oneshotfeatures.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans are able to seamlessly visually imitate others, by inferring their\nintentions and using past experience to achieve the same end goal. In other\nwords, we can parse complex semantic knowledge from raw video and efficiently\ntranslate that into concrete motor control. Is it possible to give a robot this\nsame capability? Prior research in robot imitation learning has created agents\nwhich can acquire diverse skills from expert human operators. However,\nexpanding these techniques to work with a single positive example during test\ntime is still an open challenge. Apart from control, the difficulty stems from\nmismatches between the demonstrator and robot domains. For example, objects may\nbe placed in different locations (e.g. kitchen layouts are different in every\nhouse). Additionally, the demonstration may come from an agent with different\nmorphology and physical appearance (e.g. human), so one-to-one action\ncorrespondences are not available. This paper investigates techniques which\nallow robots to partially bridge these domain gaps, using their past\nexperience. A neural network is trained to mimic ground truth robot actions\ngiven context video from another agent, and must generalize to unseen task\ninstances when prompted with new videos during test time. We hypothesize that\nour policy representations must be both context driven and dynamics aware in\norder to perform these tasks. These assumptions are baked into the neural\nnetwork using the Transformers attention mechanism and a self-supervised\ninverse dynamics loss. Finally, we experimentally determine that our method\naccomplishes a $\\sim 2$x improvement in terms of task success rate over prior\nbaselines in a suite of one-shot manipulation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:41:07 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Dasari", "Sudeep", ""], ["Gupta", "Abhinav", ""]]}, {"id": "2011.05973", "submitter": "Daniel Park", "authors": "Daniel Park and B\\\"ulent Yener", "title": "A survey on practical adversarial examples for malware classifiers", "comments": "preprint. to appear in the Reversing and Offensive-oriented Trends\n  Symposium(ROOTS) 2020", "journal-ref": null, "doi": "10.1145/3433667.3433670", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based solutions have been very helpful in solving problems\nthat deal with immense amounts of data, such as malware detection and\nclassification. However, deep neural networks have been found to be vulnerable\nto adversarial examples, or inputs that have been purposefully perturbed to\nresult in an incorrect label. Researchers have shown that this vulnerability\ncan be exploited to create evasive malware samples. However, many proposed\nattacks do not generate an executable and instead generate a feature vector. To\nfully understand the impact of adversarial examples on malware detection, we\nreview practical attacks against malware classifiers that generate executable\nadversarial malware examples. We also discuss current challenges in this area\nof research, as well as suggestions for improvement and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 17:07:34 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Park", "Daniel", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2011.05985", "submitter": "Kamil Adamczewski", "authors": "Kamil Adamczewski, Mijung Park", "title": "Dirichlet Pruning for Neural Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Dirichlet pruning, a novel post-processing technique to\ntransform a large neural network model into a compressed one. Dirichlet pruning\nis a form of structured pruning that assigns the Dirichlet distribution over\neach layer's channels in convolutional layers (or neurons in fully-connected\nlayers) and estimates the parameters of the distribution over these units using\nvariational inference. The learned distribution allows us to remove unimportant\nunits, resulting in a compact architecture containing only crucial features for\na task at hand. The number of newly introduced Dirichlet parameters is only\nlinear in the number of channels, which allows for rapid training, requiring as\nlittle as one epoch to converge. We perform extensive experiments, in\nparticular on larger architectures such as VGG and ResNet (45% and 58%\ncompression rate, respectively) where our method achieves the state-of-the-art\ncompression performance and provides interpretable features as a by-product.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:04:37 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 16:06:04 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 23:37:45 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Adamczewski", "Kamil", ""], ["Park", "Mijung", ""]]}, {"id": "2011.05987", "submitter": "Aaron Tuor", "authors": "Jan Drgona, Aaron R. Tuor, Vikas Chandan and Draguna L. Vrabie", "title": "Physics-constrained Deep Learning of Multi-zone Building Thermal\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a physics-constrained control-oriented deep learning method for\nmodeling building thermal dynamics. The proposed method is based on the\nsystematic encoding of physics-based prior knowledge into a structured\nrecurrent neural architecture. Specifically, our method incorporates structural\npriors from traditional physics-based building modeling into the neural network\nthermal dynamics model structure. Further, we leverage penalty methods to\nprovide inequality constraints, thereby bounding predictions within physically\nrealistic and safe operating ranges. Observing that stable eigenvalues\naccurately characterize the dissipativeness of the system, we additionally use\na constrained matrix parameterization based on the Perron-Frobenius theorem to\nbound the dominant eigenvalues of the building thermal model parameter\nmatrices. We demonstrate the proposed data-driven modeling approach's\neffectiveness and physical interpretability on a dataset obtained from a\nreal-world office building with 20 thermal zones. Using only 10 days'\nmeasurements for training, we demonstrate generalization over 20 consecutive\ndays, significantly improving the accuracy compared to prior state-of-the-art\nresults reported in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 06:39:14 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Drgona", "Jan", ""], ["Tuor", "Aaron R.", ""], ["Chandan", "Vikas", ""], ["Vrabie", "Draguna L.", ""]]}, {"id": "2011.05988", "submitter": "HaiYing Wang", "authors": "HaiYing Wang and Jae Kwang Kim", "title": "Maximum sampled conditional likelihood for informative subsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsampling is a computationally effective approach to extract information\nfrom massive data sets when computing resources are limited. After a subsample\nis taken from the full data, most available methods use an inverse probability\nweighted objective function to estimate the model parameters. This type of\nweighted estimator does not fully utilize information in the selected\nsubsample. In this paper, we propose to use the maximum sampled conditional\nlikelihood estimator (MSCLE) based on the sampled data. We established the\nasymptotic normality of the MSCLE and prove that its asymptotic variance\ncovariance matrix is the smallest among a class of asymptotically unbiased\nestimators, including the inverse probability weighted estimator. We further\ndiscuss the asymptotic results with the L-optimal subsampling probabilities and\nillustrate the estimation procedure with generalized linear models. Numerical\nexperiments are provided to evaluate the practical performance of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:01:17 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 01:38:16 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Wang", "HaiYing", ""], ["Kim", "Jae Kwang", ""]]}, {"id": "2011.05989", "submitter": "Angelica Louren\\c{c}o Oliveira", "authors": "Angelica Louren\\c{c}o Oliveira and Marcos Eduardo Valle", "title": "Linear Dilation-Erosion Perceptron for Binary Classification", "comments": "2 pages, 1 figure, XV Encontro Cient\\'ifico de P\\'os-Graduandos do\n  IMECC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we briefly revise the reduced dilation-erosion perceptron\n(r-DEP) models for binary classification tasks. Then, we present the so-called\nlinear dilation-erosion perceptron (l-DEP), in which a linear transformation is\napplied before the application of the morphological operators. Furthermore, we\npropose to train the l-DEP classifier by minimizing a regularized hinge-loss\nfunction subject to concave-convex restrictions. A simple example is given for\nillustrative purposes.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:35:38 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Oliveira", "Angelica Louren\u00e7o", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "2011.05991", "submitter": "Niall Jeffrey", "authors": "Niall Jeffrey and Benjamin D. Wandelt", "title": "Solving high-dimensional parameter inference: marginal posterior\n  densities & Moment Networks", "comments": "Accepted in the Third Workshop on Machine Learning and the Physical\n  Sciences, NeurIPS 2020, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional probability density estimation for inference suffers from\nthe \"curse of dimensionality\". For many physical inference problems, the full\nposterior distribution is unwieldy and seldom used in practice. Instead, we\npropose direct estimation of lower-dimensional marginal distributions,\nbypassing high-dimensional density estimation or high-dimensional Markov chain\nMonte Carlo (MCMC) sampling. By evaluating the two-dimensional marginal\nposteriors we can unveil the full-dimensional parameter covariance structure.\nWe additionally propose constructing a simple hierarchy of fast neural\nregression models, called Moment Networks, that compute increasing moments of\nany desired lower-dimensional marginal posterior density; these reproduce exact\nresults from analytic posteriors and those obtained from Masked Autoregressive\nFlows. We demonstrate marginal posterior density estimation using\nhigh-dimensional LIGO-like gravitational wave time series and describe\napplications for problems of fundamental cosmology.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:00:00 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Jeffrey", "Niall", ""], ["Wandelt", "Benjamin D.", ""]]}, {"id": "2011.06006", "submitter": "Daniel Park", "authors": "Daniel S. Park, Jaehoon Lee, Daiyi Peng, Yuan Cao and Jascha\n  Sohl-Dickstein", "title": "Towards NNGP-guided Neural Architecture Search", "comments": "13 + 6 pages, 19 figures; open-source code available at\n  https://github.com/google-research/google-research/tree/master/nngp_nas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictions of wide Bayesian neural networks are described by a Gaussian\nprocess, known as the Neural Network Gaussian Process (NNGP). Analytic forms\nfor NNGP kernels are known for many models, but computing the exact kernel for\nconvolutional architectures is prohibitively expensive. One can obtain\neffective approximations of these kernels through Monte-Carlo estimation using\nfinite networks at initialization. Monte-Carlo NNGP inference is\norders-of-magnitude cheaper in FLOPs compared to gradient descent training when\nthe dataset size is small. Since NNGP inference provides a cheap measure of\nperformance of a network architecture, we investigate its potential as a signal\nfor neural architecture search (NAS). We compute the NNGP performance of\napproximately 423k networks in the NAS-bench 101 dataset on CIFAR-10 and\ncompare its utility against conventional performance measures obtained by\nshortened gradient-based training. We carry out a similar analysis on 10k\nrandomly sampled networks in the mobile neural architecture search (MNAS) space\nfor ImageNet. We discover comparative advantages of NNGP-based metrics, and\ndiscuss potential applications. In particular, we propose that NNGP performance\nis an inexpensive signal independent of metrics obtained from training that can\neither be used for reducing big search spaces, or improving training-based\nperformance measures.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:00:06 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Park", "Daniel S.", ""], ["Lee", "Jaehoon", ""], ["Peng", "Daiyi", ""], ["Cao", "Yuan", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2011.06015", "submitter": "Sheng-Min Shih", "authors": "Sheng-Min Shih, Pin-Ju Tien, Zohar Karnin", "title": "GANMEX: One-vs-One Attributions Guided by GAN-based Counterfactual\n  Explanation Baselines", "comments": "International Conference on Machine Learning 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods have been shown as promising approaches for identifying\nkey features that led to learned model predictions. While most existing\nattribution methods rely on a baseline input for performing feature\nperturbations, limited research has been conducted to address the baseline\nselection issues. Poor choices of baselines limit the ability of one-vs-one\n(1-vs-1) explanations for multi-class classifiers, which means the attribution\nmethods were not able to explain why an input belongs to its original class but\nnot the other specified target class. 1-vs-1 explanation is crucial when\ncertain classes are more similar than others, e.g. two bird types among\nmultiple animals, by focusing on key differentiating features rather than\nshared features across classes. In this paper, we present GAN-based Model\nEXplainability (GANMEX), a novel approach applying Generative Adversarial\nNetworks (GAN) by incorporating the to-be-explained classifier as part of the\nadversarial networks. Our approach effectively selects the counterfactual\nbaseline as the closest realistic sample belong to the target class, which\nallows attribution methods to provide true 1-vs-1 explanations. We showed that\nGANMEX baselines improved the saliency maps and led to stronger performance on\nperturbation-based evaluation metrics over the existing baselines. Existing\nattribution results are known for being insensitive to model randomization, and\nwe demonstrated that GANMEX baselines led to better outcome under the cascading\nrandomization of the model.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:05:27 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 20:01:08 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 19:19:41 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 11:28:52 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Shih", "Sheng-Min", ""], ["Tien", "Pin-Ju", ""], ["Karnin", "Zohar", ""]]}, {"id": "2011.06019", "submitter": "Wilpen Gorr", "authors": "Dylan J. Fitzpatrick (1), Wilpen L. Gorr (2), Daniel B. Neill (3) ((1)\n  University of Chicago, (2) Carnegie Mellon University, (3) New York\n  University)", "title": "Policing Chronic and Temporary Hot Spots of Violent Crime: A Controlled\n  Field Experiment", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hot-spot-based policing programs aim to deter crime through increased\nproactive patrols at high-crime locations. While most hot spot programs target\neasily identified chronic hot spots, we introduce models for predicting\ntemporary hot spots to address effectiveness and equity objectives for crime\nprevention, and present findings from a crossover experiment evaluating\napplication of hot spot predictions to prevent serious violent crime in\nPittsburgh, PA. Over a 12-month experimental period, the Pittsburgh Bureau of\nPolice assigned uniformed patrol officers to weekly predicted chronic and\ntemporary hot spots of serious violent crimes comprising 0.5 percent of the\ncity's area. We find statistically and practically significant reductions in\nserious violent crime counts within treatment hot spots as compared to control\nhot spots, with an overall reduction of 25.3 percent in the FBI-classified Part\n1 Violent (P1V) crimes of homicide, rape, robbery, and aggravated assault, and\na 39.7 percent reduction of African-American and other non-white victims of P1V\ncrimes. We find that temporary hot spots increase spatial dispersion of patrols\nand have a greater percentage reduction in P1V crimes than chronic hot spots\nbut fewer total number of crimes prevented. Only foot patrols, not car patrols,\nhad statistically significant crime reductions in hot spots. We find no\nevidence of crime displacement; instead, we find weakly statistically\nsignificant spillover of crime prevention benefits to adjacent areas. In\naddition, we find no evidence that the community-oriented hot spot patrols\nproduced over-policing arrests of minority or other populations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:12:06 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Fitzpatrick", "Dylan J.", ""], ["Gorr", "Wilpen L.", ""], ["Neill", "Daniel B.", ""]]}, {"id": "2011.06022", "submitter": "Neil Abcouwer", "authors": "Neil Abcouwer and Shreyansh Daftry and Siddarth Venkatraman and Tyler\n  del Sesto and Olivier Toupet and Ravi Lanka and Jialin Song and Yisong Yue\n  and Masahiro Ono", "title": "Machine Learning Based Path Planning for Improved Rover Navigation\n  (Pre-Print Version)", "comments": "9 pages, 5 figures, Pre-Print, This work has been submitted to the\n  IEEE for possible publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Enhanced AutoNav (ENav), the baseline surface navigation software for NASA's\nPerseverance rover, sorts a list of candidate paths for the rover to traverse,\nthen uses the Approximate Clearance Evaluation (ACE) algorithm to evaluate\nwhether the most highly ranked paths are safe. ACE is crucial for maintaining\nthe safety of the rover, but is computationally expensive. If the most\npromising candidates in the list of paths are all found to be infeasible, ENav\nmust continue to search the list and run time-consuming ACE evaluations until a\nfeasible path is found. In this paper, we present two heuristics that, given a\nterrain heightmap around the rover, produce cost estimates that more\neffectively rank the candidate paths before ACE evaluation. The first heuristic\nuses Sobel operators and convolution to incorporate the cost of traversing\nhigh-gradient terrain. The second heuristic uses a machine learning (ML) model\nto predict areas that will be deemed untraversable by ACE. We used physics\nsimulations to collect training data for the ML model and to run Monte Carlo\ntrials to quantify navigation performance across a variety of terrains with\nvarious slopes and rock distributions. Compared to ENav's baseline performance,\nintegrating the heuristics can lead to a significant reduction in ACE\nevaluations and average computation time per planning cycle, increase path\nefficiency, and maintain or improve the rate of successful traverses. This\nstrategy of targeting specific bottlenecks with ML while maintaining the\noriginal ACE safety checks provides an example of how ML can be infused into\nplanetary science missions and other safety-critical software.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:18:47 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Abcouwer", "Neil", ""], ["Daftry", "Shreyansh", ""], ["Venkatraman", "Siddarth", ""], ["del Sesto", "Tyler", ""], ["Toupet", "Olivier", ""], ["Lanka", "Ravi", ""], ["Song", "Jialin", ""], ["Yue", "Yisong", ""], ["Ono", "Masahiro", ""]]}, {"id": "2011.06023", "submitter": "Pierre Monnin", "authors": "Pierre Monnin and Chedy Ra\\\"issi and Amedeo Napoli and Adrien Coulet", "title": "Rediscovering alignment relations with Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are concurrently published and edited in the Web of data.\nHence they may overlap, which makes key the task that consists in matching\ntheir content. This task encompasses the identification, within and across\nknowledge graphs, of nodes that are equivalent, more specific, or weakly\nrelated. In this article, we propose to match nodes of a knowledge graph by (i)\nlearning node embeddings with Graph Convolutional Networks such that similar\nnodes have low distances in the embedding space, and (ii) clustering nodes\nbased on their embeddings. We experimented this approach on a biomedical\nknowledge graph and particularly investigated the interplay between formal\nsemantics and GCN models with the two following main focuses. Firstly, we\napplied various inference rules associated with domain knowledge, independently\nor combined, before learning node embeddings, and we measured the improvements\nin matching results. Secondly, while our GCN model is agnostic to the exact\nalignment relations (e.g., equivalence, weak similarity), we observed that\ndistances in the embedding space are coherent with the \"strength\" of these\ndifferent relations (e.g., smaller distances for equivalences), somehow\ncorresponding to their rediscovery by the model.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:19:20 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Monnin", "Pierre", ""], ["Ra\u00efssi", "Chedy", ""], ["Napoli", "Amedeo", ""], ["Coulet", "Adrien", ""]]}, {"id": "2011.06033", "submitter": "Andr\\'e Pedersen", "authors": "Andr\\'e Pedersen, Marit Valla, Anna M. Bofin, Javier P\\'erez de\n  Frutos, Ingerid Reinertsen and Erik Smistad", "title": "FastPathology: An open-source platform for deep learning-based research\n  and decision support in digital pathology", "comments": "12 pages, 4 figures, submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) are the current state-of-the-art\nfor digital analysis of histopathological images. The large size of whole-slide\nmicroscopy images (WSIs) requires advanced memory handling to read, display and\nprocess these images. There are several open-source platforms for working with\nWSIs, but few support deployment of CNN models. These applications use\nthird-party solutions for inference, making them less user-friendly and\nunsuitable for high-performance image analysis. To make deployment of CNNs\nuser-friendly and feasible on low-end machines, we have developed a new\nplatform, FastPathology, using the FAST framework and C++. It minimizes memory\nusage for reading and processing WSIs, deployment of CNN models, and real-time\ninteractive visualization of results. Runtime experiments were conducted on\nfour different use cases, using different architectures, inference engines,\nhardware configurations and operating systems. Memory usage for reading,\nvisualizing, zooming and panning a WSI were measured, using FastPathology and\nthree existing platforms. FastPathology performed similarly in terms of memory\nto the other C++ based application, while using considerably less than the two\nJava-based platforms. The choice of neural network model, inference engine,\nhardware and processors influenced runtime considerably. Thus, FastPathology\nincludes all steps needed for efficient visualization and processing of WSIs in\na single application, including inference of CNNs with real-time display of the\nresults. Source code, binary releases and test data can be found online on\nGitHub at https://github.com/SINTEFMedtek/FAST-Pathology/.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:35:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Pedersen", "Andr\u00e9", ""], ["Valla", "Marit", ""], ["Bofin", "Anna M.", ""], ["de Frutos", "Javier P\u00e9rez", ""], ["Reinertsen", "Ingerid", ""], ["Smistad", "Erik", ""]]}, {"id": "2011.06037", "submitter": "Nadine Behrmann", "authors": "Nadine Behrmann and Juergen Gall and Mehdi Noroozi", "title": "Unsupervised Video Representation Learning by Bidirectional Feature\n  Prediction", "comments": "Accepted at WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method for self-supervised video representation\nlearning via feature prediction. In contrast to the previous methods that focus\non future feature prediction, we argue that a supervisory signal arising from\nunobserved past frames is complementary to one that originates from the future\nframes. The rationale behind our method is to encourage the network to explore\nthe temporal structure of videos by distinguishing between future and past\ngiven present observations. We train our model in a contrastive learning\nframework, where joint encoding of future and past provides us with a\ncomprehensive set of temporal hard negatives via swapping. We empirically show\nthat utilizing both signals enriches the learned representations for the\ndownstream task of action recognition. It outperforms independent prediction of\nfuture and past.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:42:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Behrmann", "Nadine", ""], ["Gall", "Juergen", ""], ["Noroozi", "Mehdi", ""]]}, {"id": "2011.06041", "submitter": "Forrest Laine", "authors": "Forrest Laine and Claire Tomlin", "title": "Testing for Typicality with Respect to an Ensemble of Learned\n  Distributions", "comments": "Written in October 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Methods of performing anomaly detection on high-dimensional data sets are\nneeded, since algorithms which are trained on data are only expected to perform\nwell on data that is similar to the training data. There are theoretical\nresults on the ability to detect if a population of data is likely to come from\na known base distribution, which is known as the goodness-of-fit problem.\nOne-sample approaches to this problem offer significant computational\nadvantages for online testing, but require knowing a model of the base\ndistribution. The ability to correctly reject anomalous data in this setting\nhinges on the accuracy of the model of the base distribution. For high\ndimensional data, learning an accurate-enough model of the base distribution\nsuch that anomaly detection works reliably is very challenging, as many\nresearchers have noted in recent years. Existing methods for the one-sample\ngoodness-of-fit problem do not account for the fact that a model of the base\ndistribution is learned. To address that gap, we offer a theoretically\nmotivated approach to account for the density learning procedure. In\nparticular, we propose training an ensemble of density models, considering data\nto be anomalous if the data is anomalous with respect to any member of the\nensemble. We provide a theoretical justification for this approach, proving\nfirst that a test on typicality is a valid approach to the goodness-of-fit\nproblem, and then proving that for a correctly constructed ensemble of models,\nthe intersection of typical sets of the models lies in the interior of the\ntypical set of the base distribution. We present our method in the context of\nan example on synthetic data in which the effects we consider can easily be\nseen.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:47:46 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Laine", "Forrest", ""], ["Tomlin", "Claire", ""]]}, {"id": "2011.06042", "submitter": "Radoslav Paulen", "authors": "Anwesh Reddy Gottu Mukkula, Michal Mate\\'a\\v{s}, Miroslav Fikar,\n  Radoslav Paulen", "title": "Robust multi-stage model-based design of optimal experiments for\n  nonlinear estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approaches to robust model-based design of experiments in the\ncontext of maximum-likelihood estimation. These approaches provide\nrobustification of model-based methodologies for the design of optimal\nexperiments by accounting for the effect of the parametric uncertainty. We\nstudy the problem of robust optimal design of experiments in the framework of\nnonlinear least-squares parameter estimation using linearized confidence\nregions. We investigate several well-known robustification frameworks in this\nrespect and propose a novel methodology based on multi-stage robust\noptimization. The proposed methodology aims at problems, where the experiments\nare designed sequentially with a possibility of re-estimation in-between the\nexperiments. The multi-stage formalism aids in identifying experiments that are\nbetter conducted in the early phase of experimentation, where parameter\nknowledge is poor. We demonstrate the findings and effectiveness of the\nproposed methodology using four case studies of varying complexity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:50:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Mukkula", "Anwesh Reddy Gottu", ""], ["Mate\u00e1\u0161", "Michal", ""], ["Fikar", "Miroslav", ""], ["Paulen", "Radoslav", ""]]}, {"id": "2011.06043", "submitter": "Joshua Tobin Mr.", "authors": "Joshua Tobin, Mimi Zhang", "title": "Clustering of Big Data with Mixed Features", "comments": "22 pages, 9 figures, for associated Python library, see\n  https://pypi.org/project/CPFcluster/ , submitted to SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering large, mixed data is a central problem in data mining. Many\napproaches adopt the idea of k-means, and hence are sensitive to\ninitialisation, detect only spherical clusters, and require a priori the\nunknown number of clusters. We here develop a new clustering algorithm for\nlarge data of mixed type, aiming at improving the applicability and efficiency\nof the peak-finding technique. The improvements are threefold: (1) the new\nalgorithm is applicable to mixed data; (2) the algorithm is capable of\ndetecting outliers and clusters of relatively lower density values; (3) the\nalgorithm is competent at deciding the correct number of clusters. The\ncomputational complexity of the algorithm is greatly reduced by applying a fast\nk-nearest neighbors method and by scaling down to component sets. We present\nexperimental results to verify that our algorithm works well in practice.\nKeywords: Clustering; Big Data; Mixed Attribute; Density Peaks;\nNearest-Neighbor Graph; Conductance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:54:38 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Tobin", "Joshua", ""], ["Zhang", "Mimi", ""]]}, {"id": "2011.06058", "submitter": "Erik Drysdale", "authors": "Erik Drysdale, Devin Singh, Anna Goldenberg", "title": "Forecasting Emergency Department Capacity Constraints for COVID\n  Isolation Beds", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting patient volumes in a hospital setting is a well-studied\napplication of time series forecasting. Existing tools usually make forecasts\nat the daily or weekly level to assist in planning for staffing requirements.\nPrompted by new COVID-related capacity constraints placed on our pediatric\nhospital's emergency department, we developed an hourly forecasting tool to\nmake predictions over a 24 hour window. These forecasts would give our hospital\nsufficient time to be able to martial resources towards expanding capacity and\naugmenting staff (e.g. transforming wards or bringing in physicians on call).\nUsing Gaussian Process Regressions (GPRs), we obtain strong performance for\nboth point predictions (average R-squared: 82%) as well as classification\naccuracy when predicting the ordinal tiers of our hospital's capacity (average\nprecision/recall: 82%/74%). Compared to traditional regression approaches, GPRs\nnot only obtain consistently higher performance, but are also robust to the\ndataset shifts that have occurred throughout 2020. Hospital stakeholders are\nencouraged by the strength of our results, and we are currently working on\nmoving our tool to a real-time setting with the goal of augmenting the\ncapabilities of our healthcare workers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:35:41 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Drysdale", "Erik", ""], ["Singh", "Devin", ""], ["Goldenberg", "Anna", ""]]}, {"id": "2011.06069", "submitter": "Didier Ch\\'etelat", "authors": "Antoine Prouvost, Justin Dumouchelle, Lara Scavuzzo, Maxime Gasse,\n  Didier Ch\\'etelat, Andrea Lodi", "title": "Ecole: A Gym-like Library for Machine Learning in Combinatorial\n  Optimization Solvers", "comments": "Published at the 1st Workshop on Learning Meets Combinatorial\n  Algorithms @ NeurIPS 2020, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Ecole, a new library to simplify machine learning research for\ncombinatorial optimization. Ecole exposes several key decision tasks arising in\ngeneral-purpose combinatorial optimization solvers as control problems over\nMarkov decision processes. Its interface mimics the popular OpenAI Gym library\nand is both extensible and intuitive to use. We aim at making this library a\nstandardized platform that will lower the bar of entry and accelerate\ninnovation in the field. Documentation and code can be found at\nhttps://www.ecole.ai.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:59:36 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 21:06:00 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Prouvost", "Antoine", ""], ["Dumouchelle", "Justin", ""], ["Scavuzzo", "Lara", ""], ["Gasse", "Maxime", ""], ["Ch\u00e9telat", "Didier", ""], ["Lodi", "Andrea", ""]]}, {"id": "2011.06070", "submitter": "Loek Tonnaer", "authors": "Loek Tonnaer, Luis A. P\\'erez Rey, Vlado Menkovski, Mike Holenderski,\n  Jacobus W. Portegies", "title": "Quantifying and Learning Disentangled Representations with Limited\n  Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning low-dimensional representations that disentangle the underlying\nfactors of variation in data has been posited as an important step towards\ninterpretable machine learning with good generalization. To address the fact\nthat there is no consensus on what disentanglement entails, Higgins et al.\n(2018) propose a formal definition for Linear Symmetry-Based Disentanglement,\nor LSBD, arguing that underlying real-world transformations give exploitable\nstructure to data.\n  Although several works focus on learning LSBD representations, such methods\nrequire supervision on the underlying transformations for the entire dataset,\nand cannot deal with unlabeled data. Moreover, none of these works provide a\nmetric to quantify LSBD.\n  We propose a metric to quantify LSBD representations that is easy to compute\nunder certain well-defined assumptions. Furthermore, we present a method that\ncan leverage unlabeled data, such that LSBD representations can be learned with\nlimited supervision on transformations. Using our LSBD metric, our results show\nthat limited supervision is indeed sufficient to learn LSBD representations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 21:00:21 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 14:32:49 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Tonnaer", "Loek", ""], ["Rey", "Luis A. P\u00e9rez", ""], ["Menkovski", "Vlado", ""], ["Holenderski", "Mike", ""], ["Portegies", "Jacobus W.", ""]]}, {"id": "2011.06080", "submitter": "Anna Malinovskaya", "authors": "Anna Malinovskaya, Philipp Otto and Torben Peters", "title": "Statistical learning for change point and anomaly detection in graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems which can be represented in the form of static and dynamic\ngraphs arise in different fields, e.g. communication, engineering and industry.\nOne of the interesting problems in analysing dynamic network structures is to\nmonitor changes in their development. Statistical learning, which encompasses\nboth methods based on artificial intelligence and traditional statistics, can\nbe used to progress in this research area. However, the majority of approaches\napply only one or the other framework. In this paper, we discuss the\npossibility of bringing together both disciplines in order to create enhanced\nnetwork monitoring procedures focussing on the example of combining statistical\nprocess control and deep learning algorithms. Together with the presentation of\nchange point and anomaly detection in network data, we propose to monitor the\nresponse times of ambulance services, applying jointly the control chart for\nquantile function values and a graph convolutional network.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 17:15:53 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Malinovskaya", "Anna", ""], ["Otto", "Philipp", ""], ["Peters", "Torben", ""]]}, {"id": "2011.06100", "submitter": "Tony Sun", "authors": "Tony Y. Sun, Oliver J. Bear Don't Walk IV, Jennifer L. Chen, Harry\n  Reyes Nieva, No\\'emie Elhadad", "title": "Exploring Gender Disparities in Time to Diagnosis", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sex and gender-based healthcare disparities contribute to differences in\nhealth outcomes. We focus on time to diagnosis (TTD) by conducting two\nlarge-scale, complementary analyses among men and women across 29 phenotypes\nand 195K patients. We first find that women are consistently more likely to\nexperience a longer TTD than men, even when presenting with the same\nconditions. We further explore how TTD disparities affect diagnostic\nperformance between genders, both across and persistent to time, by evaluating\ngender-agnostic disease classifiers across increasing diagnostic information.\nIn both fairness analyses, the diagnostic process favors men over women,\ncontradicting the previous observation that women may demonstrate relevant\nsymptoms earlier than men. These analyses suggest that TTD is an important yet\ncomplex aspect when studying gender disparities, and warrants further\ninvestigation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 22:27:14 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 02:05:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sun", "Tony Y.", ""], ["Walk", "Oliver J. Bear Don't", "IV"], ["Chen", "Jennifer L.", ""], ["Nieva", "Harry Reyes", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "2011.06103", "submitter": "Viska Wei", "authors": "Viska Wei, Nikita Ivkin, Vladimir Braverman, Alexander Szalay", "title": "Sketch and Scale: Geo-distributed tSNE and UMAP", "comments": "IEEE BigData2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running machine learning analytics over geographically distributed datasets\nis a rapidly arising problem in the world of data management policies ensuring\nprivacy and data security. Visualizing high dimensional data using tools such\nas t-distributed Stochastic Neighbor Embedding (tSNE) and Uniform Manifold\nApproximation and Projection (UMAP) became common practice for data scientists.\nBoth tools scale poorly in time and memory. While recent optimizations showed\nsuccessful handling of 10,000 data points, scaling beyond million points is\nstill challenging. We introduce a novel framework: Sketch and Scale (SnS). It\nleverages a Count Sketch data structure to compress the data on the edge nodes,\naggregates the reduced size sketches on the master node, and runs vanilla tSNE\nor UMAP on the summary, representing the densest areas, extracted from the\naggregated sketch. We show this technique to be fully parallel, scale linearly\nin time, logarithmically in memory, and communication, making it possible to\nanalyze datasets with many millions, potentially billions of data points,\nspread across several data centers around the globe. We demonstrate the power\nof our method on two mid-size datasets: cancer data with 52 million 35-band\npixels from multiple images of tumor biopsies; and astrophysics data of 100\nmillion stars with multi-color photometry from the Sloan Digital Sky Survey\n(SDSS).\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 22:32:21 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wei", "Viska", ""], ["Ivkin", "Nikita", ""], ["Braverman", "Vladimir", ""], ["Szalay", "Alexander", ""]]}, {"id": "2011.06104", "submitter": "Arash Mohammadi", "authors": "Elahe Rahimian, Soheil Zabihi, Amir Asif, Dario Farina, Seyed Farokh\n  Atashzar, and Arash Mohammadi", "title": "FS-HGR: Few-shot Learning for Hand Gesture Recognition via\n  ElectroMyography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work is motivated by the recent advances in Deep Neural Networks (DNNs)\nand their widespread applications in human-machine interfaces. DNNs have been\nrecently used for detecting the intended hand gesture through processing of\nsurface electromyogram (sEMG) signals. The ultimate goal of these approaches is\nto realize high-performance controllers for prosthetic. However, although DNNs\nhave shown superior accuracy than conventional methods when large amounts of\ndata are available for training, their performance substantially decreases when\ndata are limited. Collecting large datasets for training may be feasible in\nresearch laboratories, but it is not a practical approach for real-life\napplications. Therefore, there is an unmet need for the design of a modern\ngesture detection technique that relies on minimal training data while\nproviding high accuracy. Here we propose an innovative and novel \"Few-Shot\nLearning\" framework based on the formulation of meta-learning, referred to as\nthe FS-HGR, to address this need. Few-shot learning is a variant of domain\nadaptation with the goal of inferring the required output based on just one or\na few training examples. More specifically, the proposed FS-HGR quickly\ngeneralizes after seeing very few examples from each class. The proposed\napproach led to 85.94% classification accuracy on new repetitions with few-shot\nobservation (5-way 5-shot), 81.29% accuracy on new subjects with few-shot\nobservation (5-way 5-shot), and 73.36% accuracy on new gestures with few-shot\nobservation (5-way 5-shot).\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 22:33:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rahimian", "Elahe", ""], ["Zabihi", "Soheil", ""], ["Asif", "Amir", ""], ["Farina", "Dario", ""], ["Atashzar", "Seyed Farokh", ""], ["Mohammadi", "Arash", ""]]}, {"id": "2011.06125", "submitter": "L\\'eonard Boussioux", "authors": "L\\'eonard Boussioux, Cynthia Zeng, Th\\'eo Gu\\'enais, Dimitris\n  Bertsimas", "title": "Hurricane Forecasting: A Novel Multimodal Machine Learning Framework", "comments": "Under revision by the AMS' Weather and Forecasting journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.ao-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a machine learning (ML) framework for tropical cyclone\nintensity and track forecasting, combining multiple distinct ML techniques and\nutilizing diverse data sources. Our framework, which we refer to as Hurricast\n(HURR), is built upon the combination of distinct data processing techniques\nusing gradient-boosted trees and novel encoder-decoder architectures, including\nCNN, GRU and Transformers components. We propose a deep-feature extractor\nmethodology to mix spatial-temporal data with statistical data efficiently. Our\nmultimodal framework unleashes the potential of making forecasts based on a\nwide range of data sources, including historical storm data, and visual data\nsuch as reanalysis atmospheric images. We evaluate our models with current\noperational forecasts in North Atlantic and Eastern Pacific basins on 2016-2019\nfor 24-hour lead time, and show our models consistently outperform\nstatistical-dynamical models and compete with the best dynamical models, while\ncomputing forecasts in seconds. Furthermore, the inclusion of Hurricast into an\noperational forecast consensus model leads to a significant improvement of 5% -\n15% over NHC's official forecast, thus highlighting the complementary\nproperties with existing approaches. In summary, our work demonstrates that\ncombining different data sources and distinct machine learning methodologies\ncan lead to superior tropical cyclone forecasting. We hope that this work opens\nthe door for further use of machine learning in meteorological forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 23:55:33 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 14:52:05 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Boussioux", "L\u00e9onard", ""], ["Zeng", "Cynthia", ""], ["Gu\u00e9nais", "Th\u00e9o", ""], ["Bertsimas", "Dimitris", ""]]}, {"id": "2011.06128", "submitter": "Mohaddeseh Bastan", "authors": "Mohaddeseh Bastan, Mahnaz Koupaee, Youngseo Son, Richard Sicoli, and\n  Niranjan Balasubramanian", "title": "Author's Sentiment Prediction", "comments": "12 pages, 5 figures, Accepted in COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce PerSenT, a dataset of crowd-sourced annotations of the sentiment\nexpressed by the authors towards the main entities in news articles. The\ndataset also includes paragraph-level sentiment annotations to provide more\nfine-grained supervision for the task. Our benchmarks of multiple strong\nbaselines show that this is a difficult classification task. The results also\nsuggest that simply fine-tuning document-level representations from BERT isn't\nadequate for this task. Making paragraph-level decisions and aggregating them\nover the entire document is also ineffective. We present empirical and\nqualitative analyses that illustrate the specific challenges posed by this\ndataset. We release this dataset with 5.3k documents and 38k paragraphs\ncovering 3.2k unique entities as a challenge in entity sentiment analysis.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:03:26 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Bastan", "Mohaddeseh", ""], ["Koupaee", "Mahnaz", ""], ["Son", "Youngseo", ""], ["Sicoli", "Richard", ""], ["Balasubramanian", "Niranjan", ""]]}, {"id": "2011.06129", "submitter": "Anirudh Joshi", "authors": "Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Jeremy Irvin, Andrew Y.\n  Ng, Matthew Lungren", "title": "CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray\n  Interpretation to Photos of Chest X-rays", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of smartphones to take photographs of chest x-rays represents an\nappealing solution for scaled deployment of deep learning models for chest\nx-ray interpretation. However, the performance of chest x-ray algorithms on\nphotos of chest x-rays has not been thoroughly investigated. In this study, we\nmeasured the diagnostic performance for 8 different chest x-ray models when\napplied to photos of chest x-rays. All models were developed by different\ngroups and submitted to the CheXpert challenge, and re-applied to smartphone\nphotos of x-rays in the CheXphoto dataset without further tuning. We found that\nseveral models had a drop in performance when applied to photos of chest\nx-rays, but even with this drop, some models still performed comparably to\nradiologists. Further investigation could be directed towards understanding how\ndifferent model training procedures may affect model generalization to photos\nof chest x-rays.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:16:51 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rajpurkar", "Pranav", ""], ["Joshi", "Anirudh", ""], ["Pareek", "Anuj", ""], ["Irvin", "Jeremy", ""], ["Ng", "Andrew Y.", ""], ["Lungren", "Matthew", ""]]}, {"id": "2011.06133", "submitter": "Yulia Gryaditskaya Dr", "authors": "Yue Zhong, Yulia Gryaditskaya, Honggang Zhang, Yi-Zhe Song", "title": "Deep Sketch-Based Modeling: Tips and Tricks", "comments": null, "journal-ref": null, "doi": "10.1109/3DV50981.2020.00064", "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep image-based modeling received lots of attention in recent years, yet the\nparallel problem of sketch-based modeling has only been briefly studied, often\nas a potential application. In this work, for the first time, we identify the\nmain differences between sketch and image inputs: (i) style variance, (ii)\nimprecise perspective, and (iii) sparsity. We discuss why each of these\ndifferences can pose a challenge, and even make a certain class of image-based\nmethods inapplicable. We study alternative solutions to address each of the\ndifference. By doing so, we drive out a few important insights: (i) sparsity\ncommonly results in an incorrect prediction of foreground versus background,\n(ii) diversity of human styles, if not taken into account, can lead to very\npoor generalization properties, and finally (iii) unless a dedicated sketching\ninterface is used, one can not expect sketches to match a perspective of a\nfixed viewpoint. Finally, we compare a set of representative deep single-image\nmodeling solutions and show how their performance can be improved to tackle\nsketch input by taking into consideration the identified critical differences.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:34:08 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 13:26:57 GMT"}, {"version": "v3", "created": "Mon, 26 Apr 2021 09:23:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhong", "Yue", ""], ["Gryaditskaya", "Yulia", ""], ["Zhang", "Honggang", ""], ["Song", "Yi-Zhe", ""]]}, {"id": "2011.06144", "submitter": "Farid Khan", "authors": "Farid Khan", "title": "I-POST: Intelligent Point of Sale and Transaction System", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel solution for the cashier problem. Current cashier\nsystem/Point of Sale (POS) terminals can be inefficient, cumbersome and\ntime-consuming for the users. There is a need for a solution dependent on\nmodern technology and ubiquitous computing resources. We present I-POST\n(Intelligent Point of Sale and Transaction) as a software system that uses\nsmart devices, mobile phone and state of the art machine learning algorithms to\nprocess the user transactions in automated and real time manner. I-POST is an\nautomated checkout system that allows the user to walk in a store, collect his\nitems and exit the store. There is no need to stand and wait in a queue. The\nsystem uses object detection and facial recognition algorithm to process the\nauthentication of the client and the state of the object. At point of exit, the\nclassifier sends the data to the backend server which execute the payments. The\nsystem uses Convolution Neural Network (CNN) for the image recognition and\nprocessing. CNN is a supervised learning model that has found major application\nin pattern recognition problem. The current implementation uses two classifiers\nthat work intrinsically to authenticate the user and track the items. The model\naccuracy for object recognition is 97%, the loss is 9.3%. We expect that such\nsystems can bring efficiency to the market and has the potential for broad and\ndiverse applications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 01:06:17 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Khan", "Farid", ""]]}, {"id": "2011.06146", "submitter": "Himabindu Lakkaraju", "authors": "Alexis Ross, Himabindu Lakkaraju, Osbert Bastani", "title": "Ensuring Actionable Recourse via Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning models are increasingly deployed in high-stakes domains\nsuch as legal and financial decision-making, there has been growing interest in\npost-hoc methods for generating counterfactual explanations. Such explanations\nprovide individuals adversely impacted by predicted outcomes (e.g., an\napplicant denied a loan) with \"recourse\" ---i.e., a description of how they can\nchange their features to obtain a positive outcome. We propose a novel\nalgorithm that leverages adversarial training and PAC confidence sets to learn\nmodels that theoretically guarantee recourse to affected individuals with high\nprobability without sacrificing accuracy. To the best of our knowledge, our\napproach is the first to learn models for which recourses are guaranteed with\nhigh probability. Extensive experimentation with real world datasets spanning\nvarious applications including recidivism prediction, bail outcomes, and\nlending demonstrate the efficacy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 01:15:18 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ross", "Alexis", ""], ["Lakkaraju", "Himabindu", ""], ["Bastani", "Osbert", ""]]}, {"id": "2011.06153", "submitter": "Aparna Balagopalan", "authors": "Aparna Balagopalan, Jekaterina Novikova", "title": "Augmenting BERT Carefully with Underrepresented Linguistic Features", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuned Bidirectional Encoder Representations from Transformers\n(BERT)-based sequence classification models have proven to be effective for\ndetecting Alzheimer's Disease (AD) from transcripts of human speech. However,\nprevious research shows it is possible to improve BERT's performance on various\ntasks by augmenting the model with additional information. In this work, we use\nprobing tasks as introspection techniques to identify linguistic information\nnot well-represented in various layers of BERT, but important for the AD\ndetection task. We supplement these linguistic features in which\nrepresentations from BERT are found to be insufficient with hand-crafted\nfeatures externally, and show that jointly fine-tuning BERT in combination with\nthese features improves the performance of AD classification by upto 5\\% over\nfine-tuned BERT alone.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 01:32:41 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Balagopalan", "Aparna", ""], ["Novikova", "Jekaterina", ""]]}, {"id": "2011.06158", "submitter": "Jiafeng Chen", "authors": "Jiafeng Chen and Daniel L. Chen and Greg Lewis", "title": "Mostly Harmless Machine Learning: Learning Optimal Instruments in Linear\n  IV Models", "comments": "NeurIPS 2020 Workshop on Machine Learning for Economic Policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We offer straightforward theoretical results that justify incorporating\nmachine learning in the standard linear instrumental variable setting. The key\nidea is to use machine learning, combined with sample-splitting, to predict the\ntreatment variable from the instrument and any exogenous covariates, and then\nuse this predicted treatment and the covariates as technical instruments to\nrecover the coefficients in the second-stage. This allows the researcher to\nextract non-linear co-variation between the treatment and instrument that may\ndramatically improve estimation precision and robustness by boosting instrument\nstrength. Importantly, we constrain the machine-learned predictions to be\nlinear in the exogenous covariates, thus avoiding spurious identification\narising from non-linear relationships between the treatment and the covariates.\nWe show that this approach delivers consistent and asymptotically normal\nestimates under weak conditions and that it may be adapted to be\nsemiparametrically efficient (Chamberlain, 1992). Our method preserves standard\nintuitions and interpretations of linear instrumental variable methods,\nincluding under weak identification, and provides a simple, user-friendly\nupgrade to the applied economics toolbox. We illustrate our method with an\nexample in law and criminal justice, examining the causal effect of appellate\ncourt reversals on district court sentencing decisions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 01:55:11 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 04:26:23 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 18:26:37 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Jiafeng", ""], ["Chen", "Daniel L.", ""], ["Lewis", "Greg", ""]]}, {"id": "2011.06165", "submitter": "Sean Segal", "authors": "Sean Segal, Eric Kee, Wenjie Luo, Abbas Sadat, Ersin Yumer, Raquel\n  Urtasun", "title": "Universal Embeddings for Spatio-Temporal Tagging of Self-Driving Logs", "comments": "CoRL 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of spatio-temporal tagging of\nself-driving scenes from raw sensor data. Our approach learns a universal\nembedding for all tags, enabling efficient tagging of many attributes and\nfaster learning of new attributes with limited data. Importantly, the embedding\nis spatio-temporally aware, allowing the model to naturally output\nspatio-temporal tag values. Values can then be pooled over arbitrary regions,\nin order to, for example, compute the pedestrian density in front of the SDV,\nor determine if a car is blocking another car at a 4-way intersection. We\ndemonstrate the effectiveness of our approach on a new large scale self-driving\ndataset, SDVScenes, containing 15 attributes relating to vehicle and pedestrian\ndensity, the actions of each actor, the speed of each actor, interactions\nbetween actors, and the topology of the road map.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 02:18:16 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Segal", "Sean", ""], ["Kee", "Eric", ""], ["Luo", "Wenjie", ""], ["Sadat", "Abbas", ""], ["Yumer", "Ersin", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2011.06167", "submitter": "Himabindu Lakkaraju", "authors": "Sean McGrath, Parth Mehta, Alexandra Zytek, Isaac Lage, Himabindu\n  Lakkaraju", "title": "When Does Uncertainty Matter?: Understanding the Impact of Predictive\n  Uncertainty in ML Assisted Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning (ML) models are increasingly being employed to assist\nhuman decision makers, it becomes critical to provide these decision makers\nwith relevant inputs which can help them decide if and how to incorporate model\npredictions into their decision making. For instance, communicating the\nuncertainty associated with model predictions could potentially be helpful in\nthis regard. However, there is little to no research that systematically\nexplores if and how conveying predictive uncertainty impacts decision making.\nIn this work, we carry out user studies to systematically assess how people\nrespond to different types of predictive uncertainty i.e., posterior predictive\ndistributions with different shapes and variances, in the context of ML\nassisted decision making. To the best of our knowledge, this work marks one of\nthe first attempts at studying this question. Our results demonstrate that\npeople are more likely to agree with a model prediction when they observe the\ncorresponding uncertainty associated with the prediction. This finding holds\nregardless of the properties (shape or variance) of predictive uncertainty\n(posterior predictive distribution), suggesting that uncertainty is an\neffective tool for persuading humans to agree with model predictions.\nFurthermore, we also find that other factors such as domain expertise and\nfamiliarity with ML also play a role in determining how someone interprets and\nincorporates predictive uncertainty into their decision making.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 02:23:53 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 18:36:32 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["McGrath", "Sean", ""], ["Mehta", "Parth", ""], ["Zytek", "Alexandra", ""], ["Lage", "Isaac", ""], ["Lakkaraju", "Himabindu", ""]]}, {"id": "2011.06169", "submitter": "Himabindu Lakkaraju", "authors": "Himabindu Lakkaraju, Nino Arsov, Osbert Bastani", "title": "Robust and Stable Black Box Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning black boxes are increasingly being deployed in real-world\napplications, there has been a growing interest in developing post hoc\nexplanations that summarize the behaviors of these black boxes. However,\nexisting algorithms for generating such explanations have been shown to lack\nstability and robustness to distribution shifts. We propose a novel framework\nfor generating robust and stable explanations of black box models based on\nadversarial training. Our framework optimizes a minimax objective that aims to\nconstruct the highest fidelity explanation with respect to the worst-case over\na set of adversarial perturbations. We instantiate this algorithm for\nexplanations in the form of linear models and decision sets by devising the\nrequired optimization procedures. To the best of our knowledge, this work makes\nthe first attempt at generating post hoc explanations that are robust to a\ngeneral class of adversarial perturbations that are of practical interest.\nExperimental evaluation with real-world and synthetic datasets demonstrates\nthat our approach substantially improves robustness of explanations without\nsacrificing their fidelity on the original data distribution.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 02:29:03 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Lakkaraju", "Himabindu", ""], ["Arsov", "Nino", ""], ["Bastani", "Osbert", ""]]}, {"id": "2011.06170", "submitter": "Yajie Cui", "authors": "Changqing Zhang, Yajie Cui, Zongbo Han, Joey Tianyi Zhou, Huazhu Fu\n  and Qinghua Hu", "title": "Deep Partial Multi-View Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although multi-view learning has made signifificant progress over the past\nfew decades, it is still challenging due to the diffificulty in modeling\ncomplex correlations among different views, especially under the context of\nview missing. To address the challenge, we propose a novel framework termed\nCross Partial Multi-View Networks (CPM-Nets), which aims to fully and\nflflexibly take advantage of multiple partial views. We fifirst provide a\nformal defifinition of completeness and versatility for multi-view\nrepresentation and then theoretically prove the versatility of the learned\nlatent representations. For completeness, the task of learning latent\nmulti-view representation is specififically translated to a degradation process\nby mimicking data transmission, such that the optimal tradeoff between\nconsistency and complementarity across different views can be implicitly\nachieved. Equipped with adversarial strategy, our model stably imputes missing\nviews, encoding information from all views for each sample to be encoded into\nlatent representation to further enhance the completeness. Furthermore, a\nnonparametric classifification loss is introduced to produce structured\nrepresentations and prevent overfifitting, which endows the algorithm with\npromising generalization under view-missing cases. Extensive experimental\nresults validate the effectiveness of our algorithm over existing state of the\narts for classifification, representation learning and data imputation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 02:29:29 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Zhang", "Changqing", ""], ["Cui", "Yajie", ""], ["Han", "Zongbo", ""], ["Zhou", "Joey Tianyi", ""], ["Fu", "Huazhu", ""], ["Hu", "Qinghua", ""]]}, {"id": "2011.06175", "submitter": "Juhyeon Kim", "authors": "Juhyeon Kim", "title": "Optimizing Large-Scale Fleet Management on a Road Network using\n  Multi-Agent Deep Reinforcement Learning with Graph Neural Network", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optimizing fleet management is an important issue in ride-hailing service in\nterms of customer's satisfaction and increased revenue for drivers. However\nfinding an optimal strategy in a real environment that demand and supply are\nchanging in real time, is a challenging problem. In this paper, we try to solve\nthis problem by using multi-agent reinforcement learning. Instead of grid which\nwas used in existing works, we use a graph to represent road network more\nrealistically. We model the problem using Markov game and adopt stochastic\npolicy update which can resolve the problem of greedy policy update in\nmulti-agent scheme. We use modified DQN to fit our problem. To approximate Q\nvalues on the graph, we use two basic graph neural networks, GCN and GAT. We\ndesign a simulator using real taxi call data and evaluate the algorithms under\nvarious conditions. The result demonstrates effectiveness of the proposed\nstochastic policy update model with graph neural network.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 03:01:37 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kim", "Juhyeon", ""]]}, {"id": "2011.06176", "submitter": "Yihan Lin", "authors": "Zhenzhi Wu, Hehui Zhang, Yihan Lin, Guoqi Li, Meng Wang, Ye Tang", "title": "LIAF-Net: Leaky Integrate and Analog Fire Network for Lightweight and\n  Efficient Spatiotemporal Information Processing", "comments": "14 pages, 9 figures, submitted to IEEE Transactions on Neural\n  Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks (SNNs) based on Leaky Integrate and Fire (LIF) model\nhave been applied to energy-efficient temporal and spatiotemporal processing\ntasks. Thanks to the bio-plausible neuronal dynamics and simplicity, LIF-SNN\nbenefits from event-driven processing, however, usually faces the embarrassment\nof reduced performance. This may because in LIF-SNN the neurons transmit\ninformation via spikes. To address this issue, in this work, we propose a Leaky\nIntegrate and Analog Fire (LIAF) neuron model, so that analog values can be\ntransmitted among neurons, and a deep network termed as LIAF-Net is built on it\nfor efficient spatiotemporal processing. In the temporal domain, LIAF follows\nthe traditional LIF dynamics to maintain its temporal processing capability. In\nthe spatial domain, LIAF is able to integrate spatial information through\nconvolutional integration or fully-connected integration. As a spatiotemporal\nlayer, LIAF can also be used with traditional artificial neural network (ANN)\nlayers jointly. Experiment results indicate that LIAF-Net achieves comparable\nperformance to Gated Recurrent Unit (GRU) and Long short-term memory (LSTM) on\nbAbI Question Answering (QA) tasks, and achieves state-of-the-art performance\non spatiotemporal Dynamic Vision Sensor (DVS) datasets, including MNIST-DVS,\nCIFAR10-DVS and DVS128 Gesture, with much less number of synaptic weights and\ncomputational overhead compared with traditional networks built by LSTM, GRU,\nConvolutional LSTM (ConvLSTM) or 3D convolution (Conv3D). Compared with\ntraditional LIF-SNN, LIAF-Net also shows dramatic accuracy gain on all these\nexperiments. In conclusion, LIAF-Net provides a framework combining the\nadvantages of both ANNs and SNNs for lightweight and efficient spatiotemporal\ninformation processing.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 03:04:21 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wu", "Zhenzhi", ""], ["Zhang", "Hehui", ""], ["Lin", "Yihan", ""], ["Li", "Guoqi", ""], ["Wang", "Meng", ""], ["Tang", "Ye", ""]]}, {"id": "2011.06182", "submitter": "Mingsheng Long", "authors": "Jincheng Zhong, Ximei Wang, Zhi Kou, Jianmin Wang, Mingsheng Long", "title": "Bi-tuning of Pre-trained Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is common within the deep learning community to first pre-train a deep\nneural network from a large-scale dataset and then fine-tune the pre-trained\nmodel to a specific downstream task. Recently, both supervised and unsupervised\npre-training approaches to learning representations have achieved remarkable\nadvances, which exploit the discriminative knowledge of labels and the\nintrinsic structure of data, respectively. It follows natural intuition that\nboth discriminative knowledge and intrinsic structure of the downstream task\ncan be useful for fine-tuning, however, existing fine-tuning methods mainly\nleverage the former and discard the latter. A question arises: How to fully\nexplore the intrinsic structure of data for boosting fine-tuning? In this\npaper, we propose Bi-tuning, a general learning framework to fine-tuning both\nsupervised and unsupervised pre-trained representations to downstream tasks.\nBi-tuning generalizes the vanilla fine-tuning by integrating two heads upon the\nbackbone of pre-trained representations: a classifier head with an improved\ncontrastive cross-entropy loss to better leverage the label information in an\ninstance-contrast way, and a projector head with a newly-designed categorical\ncontrastive learning loss to fully exploit the intrinsic structure of data in a\ncategory-consistent way. Comprehensive experiments confirm that Bi-tuning\nachieves state-of-the-art results for fine-tuning tasks of both supervised and\nunsupervised pre-trained models by large margins (e.g. 10.7\\% absolute rise in\naccuracy on CUB in low-data regime).\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 03:32:25 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Zhong", "Jincheng", ""], ["Wang", "Ximei", ""], ["Kou", "Zhi", ""], ["Wang", "Jianmin", ""], ["Long", "Mingsheng", ""]]}, {"id": "2011.06186", "submitter": "Yunbei Xu", "authors": "Yunbei Xu, Assaf Zeevi", "title": "Towards Optimal Problem Dependent Generalization Error Bounds in\n  Statistical Learning Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study problem-dependent rates, i.e., generalization errors that scale\nnear-optimally with the variance, the effective loss, or the gradient norms\nevaluated at the \"best hypothesis.\" We introduce a principled framework dubbed\n\"uniform localized convergence,\" and characterize sharp problem-dependent rates\nfor central statistical learning problems. From a methodological viewpoint, our\nframework resolves several fundamental limitations of existing uniform\nconvergence and localization analysis approaches. It also provides improvements\nand some level of unification in the study of localized complexities, one-sided\nuniform inequalities, and sample-based iterative algorithms. In the so-called\n\"slow rate\" regime, we provides the first (moment-penalized) estimator that\nachieves the optimal variance-dependent rate for general \"rich\" classes; we\nalso establish improved loss-dependent rate for standard empirical risk\nminimization. In the \"fast rate\" regime, we establish finite-sample\nproblem-dependent bounds that are comparable to precise asymptotics. In\naddition, we show that iterative algorithms like gradient descent and\nfirst-order Expectation-Maximization can achieve optimal generalization error\nin several representative problems across the areas of non-convex learning,\nstochastic optimization, and learning with missing data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:07:29 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 21:01:35 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 23:01:58 GMT"}, {"version": "v4", "created": "Thu, 24 Dec 2020 03:10:54 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Xu", "Yunbei", ""], ["Zeevi", "Assaf", ""]]}, {"id": "2011.06187", "submitter": "Jiacheng Wang", "authors": "Jiacheng Wang and Weiheng Li", "title": "Atrial Fibrillation Detection and ECG Classification based on CNN-BiLSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging to visually detect heart disease from the\nelectrocardiographic (ECG) signals. Implementing an automated ECG signal\ndetection system can help diagnosis arrhythmia in order to improve the accuracy\nof diagnosis. In this paper, we proposed, implemented, and compared an\nautomated system using two different frameworks of the combination of\nconvolutional neural network (CNN) and long-short term memory (LSTM) for\nclassifying normal sinus signals, atrial fibrillation, and other noisy signals.\nThe dataset we used is from the MIT-BIT Arrhythmia Physionet. Our approach\ndemonstrated that the cascade of two deep learning network has higher\nperformance than the concatenation of them, achieving a weighted f1 score of\n0.82. The experimental results have successfully validated that the cascade of\nCNN and LSTM can achieve satisfactory performance on discriminating ECG\nsignals.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:20:56 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wang", "Jiacheng", ""], ["Li", "Weiheng", ""]]}, {"id": "2011.06188", "submitter": "Michal Lisicki", "authors": "Michal Lisicki, Arash Afkanpour, Graham W. Taylor", "title": "Evaluating Curriculum Learning Strategies in Neural Combinatorial\n  Optimization", "comments": "Presented at Workshop on Learning Meets Combinatorial Algorithms at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural combinatorial optimization (NCO) aims at designing problem-independent\nand efficient neural network-based strategies for solving combinatorial\nproblems. The field recently experienced growth by successfully adapting\narchitectures originally designed for machine translation. Even though the\nresults are promising, a large gap still exists between NCO models and classic\ndeterministic solvers, both in terms of accuracy and efficiency. One of the\ndrawbacks of current approaches is the inefficiency of training on multiple\nproblem sizes. Curriculum learning strategies have been shown helpful in\nincreasing performance in the multi-task setting. In this work, we focus on\ndesigning a curriculum learning-based training procedure that can help existing\narchitectures achieve competitive performance on a large range of problem sizes\nsimultaneously. We provide a systematic investigation of several training\nprocedures and use the insights gained to motivate application of a\npsychologically-inspired approach to improve upon the classic curriculum\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:21:04 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Lisicki", "Michal", ""], ["Afkanpour", "Arash", ""], ["Taylor", "Graham W.", ""]]}, {"id": "2011.06190", "submitter": "Dongseok Shim", "authors": "Dongseok Shim and H. Jin Kim", "title": "Gaussian RAM: Lightweight Image Classification via Stochastic\n  Retina-Inspired Glimpse and Reinforcement Learning", "comments": "ICCAS 2020 Accepted and Student Best Paper Finalist", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies on image classification have mainly focused on the\nperformance of the networks, not on real-time operation or model compression.\nWe propose a Gaussian Deep Recurrent visual Attention Model (GDRAM)- a\nreinforcement learning based lightweight deep neural network for large scale\nimage classification that outperforms the conventional CNN (Convolutional\nNeural Network) which uses the entire image as input. Highly inspired by the\nbiological visual recognition process, our model mimics the stochastic location\nof the retina with Gaussian distribution. We evaluate the model on Large\ncluttered MNIST, Large CIFAR-10 and Large CIFAR-100 datasets which are resized\nto 128 in both width and height.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:27:06 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Shim", "Dongseok", ""], ["Kim", "H. Jin", ""]]}, {"id": "2011.06192", "submitter": "Ayumu Sasagawa", "authors": "Ayumu Sasagawa, Sho Sakaino, and Toshiaki Tsuji", "title": "Motion Generation Using Bilateral Control-Based Imitation Learning with\n  Autoregressive Learning", "comments": "Copyright 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "IEEE Access, Volume 9, Pages 20508-20520, 2021", "doi": "10.1109/ACCESS.2021.3054960", "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots that can execute various tasks automatically on behalf of humans are\nbecoming an increasingly important focus of research in the field of robotics.\nImitation learning has been studied as an efficient and high-performance\nmethod, and imitation learning based on bilateral control has been proposed as\na method that can realize fast motion. However, because this method cannot\nimplement autoregressive learning, this method may not generate desirable\nlong-term behavior. Therefore, in this paper, we propose a method of\nautoregressive learning for bilateral control-based imitation learning. A new\nneural network model for implementing autoregressive learning is proposed. In\nthis study, three types of experiments are conducted to verify the\neffectiveness of the proposed method. The performance is improved compared to\nconventional approaches; the proposed method has the highest rate of success.\nOwing to the structure and autoregressive learning of the proposed model, the\nproposed method can generate the desirable motion for successful tasks and have\na high generalization ability for environmental changes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:35:48 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 06:20:14 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 04:44:28 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 01:46:10 GMT"}, {"version": "v5", "created": "Thu, 4 Feb 2021 07:13:44 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Sasagawa", "Ayumu", ""], ["Sakaino", "Sho", ""], ["Tsuji", "Toshiaki", ""]]}, {"id": "2011.06195", "submitter": "Cheng-I Lai", "authors": "Cheng-I Lai, Jin Cao, Sravan Bodapati, Shang-Wen Li", "title": "Towards Semi-Supervised Semantics Understanding from Speech", "comments": "arXiv admin note: text overlap with arXiv:2010.13826", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much recent work on Spoken Language Understanding (SLU) falls short in at\nleast one of three ways: models were trained on oracle text input and neglected\nthe Automatics Speech Recognition (ASR) outputs, models were trained to predict\nonly intents without the slot values, or models were trained on a large amount\nof in-house data. We proposed a clean and general framework to learn semantics\ndirectly from speech with semi-supervision from transcribed speech to address\nthese. Our framework is built upon pretrained end-to-end (E2E) ASR and\nself-supervised language models, such as BERT, and fine-tuned on a limited\namount of target SLU corpus. In parallel, we identified two inadequate settings\nunder which SLU models have been tested: noise-robustness and E2E semantics\nevaluation. We tested the proposed framework under realistic environmental\nnoises and with a new metric, the slots edit F1 score, on two public SLU\ncorpora. Experiments show that our SLU framework with speech as input can\nperform on par with those with oracle text as input in semantics understanding,\nwhile environmental noises are present, and a limited amount of labeled\nsemantics data is available.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 01:48:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Lai", "Cheng-I", ""], ["Cao", "Jin", ""], ["Bodapati", "Sravan", ""], ["Li", "Shang-Wen", ""]]}, {"id": "2011.06205", "submitter": "Chenye Wu", "authors": "Haoxiang Wang and Jiasheng Zhang and Chenbei Lu and Chenye Wu", "title": "Privacy Preserving in Non-Intrusive Load Monitoring: A Differential\n  Privacy Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart meter devices enable a better understanding of the demand at the\npotential risk of private information leakage. One promising solution to\nmitigating such risk is to inject noises into the meter data to achieve a\ncertain level of differential privacy. In this paper, we cast one-shot\nnon-intrusive load monitoring (NILM) in the compressive sensing framework, and\nbridge the gap between theoretical accuracy of NILM inference and differential\nprivacy's parameters. We then derive the valid theoretical bounds to offer\ninsights on how the differential privacy parameters affect the NILM\nperformance. Moreover, we generalize our conclusions by proposing the\nhierarchical framework to solve the multi-shot NILM problem. Numerical\nexperiments verify our analytical results and offer better physical insights of\ndifferential privacy in various practical scenarios. This also demonstrates the\nsignificance of our work for the general privacy preserving mechanism design.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 05:10:10 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wang", "Haoxiang", ""], ["Zhang", "Jiasheng", ""], ["Lu", "Chenbei", ""], ["Wu", "Chenye", ""]]}, {"id": "2011.06208", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh and Flavio Calmon", "title": "Bottleneck Problems: Information and Estimation-Theoretic View", "comments": null, "journal-ref": null, "doi": "10.3390/e22111325", "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information bottleneck (IB) and privacy funnel (PF) are two closely related\noptimization problems which have found applications in machine learning, design\nof privacy algorithms, capacity problems (e.g., Mrs. Gerber's Lemma), strong\ndata processing inequalities, among others. In this work, we first investigate\nthe functional properties of IB and PF through a unified theoretical framework.\nWe then connect them to three information-theoretic coding problems, namely\nhypothesis testing against independence, noisy source coding and dependence\ndilution. Leveraging these connections, we prove a new cardinality bound for\nthe auxiliary variable in IB, making its computation more tractable for\ndiscrete random variables.\n  In the second part, we introduce a general family of optimization problems,\ntermed as \\textit{bottleneck problems}, by replacing mutual information in IB\nand PF with other notions of mutual information, namely $f$-information and\nArimoto's mutual information. We then argue that, unlike IB and PF, these\nproblems lead to easily interpretable guarantee in a variety of inference tasks\nwith statistical constraints on accuracy and privacy. Although the underlying\noptimization problems are non-convex, we develop a technique to evaluate\nbottleneck problems in closed form by equivalently expressing them in terms of\nlower convex or upper concave envelope of certain functions. By applying this\ntechnique to binary case, we derive closed form expressions for several\nbottleneck problems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 05:16:44 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Calmon", "Flavio", ""]]}, {"id": "2011.06210", "submitter": "Sulaiman Aburakhia", "authors": "Sulaiman Aburakhia, Tareq Tayeh, Ryan Myers, Abdallah Shami", "title": "A Transfer Learning Framework for Anomaly Detection Using Model of\n  Normality", "comments": "7 pages, 4 figures, 2 tables, conference: The 11th Annual IEEE\n  Information Technology, Electronics and Mobile Communication Conference \"IEEE\n  IEMCON\", Vancouver, Canada, November 2020. IEEE IEMCON'20' best paper award\n  in the category of Industrial Automation and Control Systems Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional Neural Network (CNN) techniques have proven to be very useful\nin image-based anomaly detection applications. CNN can be used as deep features\nextractor where other anomaly detection techniques are applied on these\nfeatures. For this scenario, using transfer learning is common since pretrained\nmodels provide deep feature representations that are useful for anomaly\ndetection tasks. Consequentially, anomaly can be detected by applying similarly\nmeasure between extracted features and a defined model of normality. A key\nfactor in such approaches is the decision threshold used for detecting anomaly.\nWhile most of the proposed methods focus on the approach itself, slight\nattention has been paid to address decision threshold settings. In this paper,\nwe tackle this problem and propose a welldefined method to set the\nworking-point decision threshold that improves detection accuracy. We introduce\na transfer learning framework for anomaly detection based on similarity measure\nwith a Model of Normality (MoN) and show that with the proposed threshold\nsettings, a significant performance improvement can be achieved. Moreover, the\nframework has low complexity with relaxed computational requirements.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 05:26:32 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Aburakhia", "Sulaiman", ""], ["Tayeh", "Tareq", ""], ["Myers", "Ryan", ""], ["Shami", "Abdallah", ""]]}, {"id": "2011.06220", "submitter": "Zeke Xie", "authors": "Zeke Xie, Fengxiang He, Shaopeng Fu, Issei Sato, Dacheng Tao, and\n  Masashi Sugiyama", "title": "Artificial Neural Variability for Deep Learning: On Overfitting, Noise\n  Memorization, and Catastrophic Forgetting", "comments": "Accepted by Neural Computation, MIT Press;20 pages; 13 figures; Key\n  Words: Neural Variability, Neuroscience, Deep Learning, Label Noise,\n  Catastrophic Forgetting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is often criticized by two serious issues which rarely exist in\nnatural nervous systems: overfitting and catastrophic forgetting. It can even\nmemorize randomly labelled data, which has little knowledge behind the\ninstance-label pairs. When a deep network continually learns over time by\naccommodating new tasks, it usually quickly overwrites the knowledge learned\nfrom previous tasks. Referred to as the {\\it neural variability}, it is\nwell-known in neuroscience that human brain reactions exhibit substantial\nvariability even in response to the same stimulus. This mechanism balances\naccuracy and plasticity/flexibility in the motor learning of natural nervous\nsystems. Thus it motivates us to design a similar mechanism named {\\it\nartificial neural variability} (ANV), which helps artificial neural networks\nlearn some advantages from ``natural'' neural networks. We rigorously prove\nthat ANV plays as an implicit regularizer of the mutual information between the\ntraining data and the learned model. This result theoretically guarantees ANV a\nstrictly improved generalizability, robustness to label noise, and robustness\nto catastrophic forgetting. We then devise a {\\it neural variable risk\nminimization} (NVRM) framework and {\\it neural variable optimizers} to achieve\nANV for conventional network architectures in practice. The empirical studies\ndemonstrate that NVRM can effectively relieve overfitting, label noise\nmemorization, and catastrophic forgetting at negligible costs. \\footnote{Code:\n\\url{https://github.com/zeke-xie/artificial-neural-variability-for-deep-learning}.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 06:06:33 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 05:01:19 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 12:44:20 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Xie", "Zeke", ""], ["He", "Fengxiang", ""], ["Fu", "Shaopeng", ""], ["Sato", "Issei", ""], ["Tao", "Dacheng", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2011.06223", "submitter": "Saurav Prakash", "authors": "Saurav Prakash, Sagar Dhakal, Mustafa Akdeniz, Yair Yona, Shilpa\n  Talwar, Salman Avestimehr, Nageen Himayat", "title": "Coded Computing for Low-Latency Federated Learning over Wireless Edge\n  Networks", "comments": "Final version to appear in the first issue of the IEEE JSAC Series on\n  Machine Learning for Communications and Networks", "journal-ref": null, "doi": "10.1109/JSAC.2020.3036961", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training a global model from data located at the\nclient nodes, without data sharing and moving client data to a centralized\nserver. Performance of federated learning in a multi-access edge computing\n(MEC) network suffers from slow convergence due to heterogeneity and stochastic\nfluctuations in compute power and communication link qualities across clients.\nWe propose a novel coded computing framework, CodedFedL, that injects\nstructured coding redundancy into federated learning for mitigating stragglers\nand speeding up the training procedure. CodedFedL enables coded computing for\nnon-linear federated learning by efficiently exploiting distributed kernel\nembedding via random Fourier features that transforms the training task into\ncomputationally favourable distributed linear regression. Furthermore, clients\ngenerate local parity datasets by coding over their local datasets, while the\nserver combines them to obtain the global parity dataset. Gradient from the\nglobal parity dataset compensates for straggling gradients during training, and\nthereby speeds up convergence. For minimizing the epoch deadline time at the\nMEC server, we provide a tractable approach for finding the amount of coding\nredundancy and the number of local data points that a client processes during\ntraining, by exploiting the statistical properties of compute as well as\ncommunication delays. We also characterize the leakage in data privacy when\nclients share their local parity datasets with the server. We analyze the\nconvergence rate and iteration complexity of CodedFedL under simplifying\nassumptions, by treating CodedFedL as a stochastic gradient descent algorithm.\nFurthermore, we conduct numerical experiments using practical network\nparameters and benchmark datasets, where CodedFedL speeds up the overall\ntraining time by up to $15\\times$ in comparison to the benchmark schemes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 06:21:59 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 19:46:31 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Prakash", "Saurav", ""], ["Dhakal", "Sagar", ""], ["Akdeniz", "Mustafa", ""], ["Yona", "Yair", ""], ["Talwar", "Shilpa", ""], ["Avestimehr", "Salman", ""], ["Himayat", "Nageen", ""]]}, {"id": "2011.06225", "submitter": "Moloud Abdar", "authors": "Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li\n  Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U\n  Rajendra Acharya, Vladimir Makarenkov, Saeid Nahavandi", "title": "A Review of Uncertainty Quantification in Deep Learning: Techniques,\n  Applications and Challenges", "comments": null, "journal-ref": "2021", "doi": "10.1016/j.inffus.2021.05.008", "report-no": "INFFUS_1411]", "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification (UQ) plays a pivotal role in reduction of\nuncertainties during both optimization and decision making processes. It can be\napplied to solve a variety of real-world applications in science and\nengineering. Bayesian approximation and ensemble learning techniques are two\nmost widely-used UQ methods in the literature. In this regard, researchers have\nproposed different UQ methods and examined their performance in a variety of\napplications such as computer vision (e.g., self-driving cars and object\ndetection), image processing (e.g., image restoration), medical image analysis\n(e.g., medical image classification and segmentation), natural language\nprocessing (e.g., text classification, social media texts and recidivism\nrisk-scoring), bioinformatics, etc. This study reviews recent advances in UQ\nmethods used in deep learning. Moreover, we also investigate the application of\nthese methods in reinforcement learning (RL). Then, we outline a few important\napplications of UQ methods. Finally, we briefly highlight the fundamental\nresearch challenges faced by UQ methods and discuss the future research\ndirections in this field.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 06:41:05 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 13:07:02 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 02:58:51 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2021 01:58:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Abdar", "Moloud", ""], ["Pourpanah", "Farhad", ""], ["Hussain", "Sadiq", ""], ["Rezazadegan", "Dana", ""], ["Liu", "Li", ""], ["Ghavamzadeh", "Mohammad", ""], ["Fieguth", "Paul", ""], ["Cao", "Xiaochun", ""], ["Khosravi", "Abbas", ""], ["Acharya", "U Rajendra", ""], ["Makarenkov", "Vladimir", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "2011.06235", "submitter": "Weiming Zhi", "authors": "Weiming Zhi, Tin Lai, Lionel Ott, Fabio Ramos", "title": "Anticipatory Navigation in Crowds by Probabilistic Prediction of\n  Pedestrian Future Movements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Critical for the coexistence of humans and robots in dynamic environments is\nthe capability for agents to understand each other's actions, and anticipate\ntheir movements. This paper presents Stochastic Process Anticipatory Navigation\n(SPAN), a framework that enables nonholonomic robots to navigate in\nenvironments with crowds, while anticipating and accounting for the motion\npatterns of pedestrians. To this end, we learn a predictive model to predict\ncontinuous-time stochastic processes to model future movement of pedestrians.\nAnticipated pedestrian positions are used to conduct chance constrained\ncollision-checking, and are incorporated into a time-to-collision control\nproblem. An occupancy map is also integrated to allow for probabilistic\ncollision-checking with static obstacles. We demonstrate the capability of SPAN\nin crowded simulation environments, as well as with a real-world pedestrian\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 07:18:20 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Zhi", "Weiming", ""], ["Lai", "Tin", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "2011.06237", "submitter": "Bhanu Prakash Reddy Guda", "authors": "Samarth Aggarwal, Rohin Garg, Abhilasha Sancheti, Bhanu Prakash Reddy\n  Guda, Iftikhar Ahamath Burhanuddin", "title": "Goal-driven Command Recommendations for Analysts", "comments": "14th ACM Conference on Recommender Systems (RecSys 2020)", "journal-ref": null, "doi": "10.1145/3383313.3412255", "report-no": null, "categories": "cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent times have seen data analytics software applications become an\nintegral part of the decision-making process of analysts. The users of these\nsoftware applications generate a vast amount of unstructured log data. These\nlogs contain clues to the user's goals, which traditional recommender systems\nmay find difficult to model implicitly from the log data. With this assumption,\nwe would like to assist the analytics process of a user through command\nrecommendations. We categorize the commands into software and data categories\nbased on their purpose to fulfill the task at hand. On the premise that the\nsequence of commands leading up to a data command is a good predictor of the\nlatter, we design, develop, and validate various sequence modeling techniques.\nIn this paper, we propose a framework to provide goal-driven data command\nrecommendations to the user by leveraging unstructured logs. We use the log\ndata of a web-based analytics software to train our neural network models and\nquantify their performance, in comparison to relevant and competitive\nbaselines. We propose a custom loss function to tailor the recommended data\ncommands according to the goal information provided exogenously. We also\npropose an evaluation metric that captures the degree of goal orientation of\nthe recommendations. We demonstrate the promise of our approach by evaluating\nthe models with the proposed metric and showcasing the robustness of our models\nin the case of adversarial examples, where the user activity is misaligned with\nselected goal, through offline evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 07:26:52 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Aggarwal", "Samarth", ""], ["Garg", "Rohin", ""], ["Sancheti", "Abhilasha", ""], ["Guda", "Bhanu Prakash Reddy", ""], ["Burhanuddin", "Iftikhar Ahamath", ""]]}, {"id": "2011.06252", "submitter": "Md Jahidul Islam", "authors": "Md Jahidul Islam, Ruobing Wang, Karin de Langis and Junaed Sattar", "title": "SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater\n  Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a holistic approach to saliency-guided visual attention\nmodeling (SVAM) for use by autonomous underwater robots. Our proposed model,\nnamed SVAM-Net, integrates deep visual features at various scales and semantics\nfor effective salient object detection (SOD) in natural underwater images. The\nSVAM-Net architecture is configured in a unique way to jointly accommodate\nbottom-up and top-down learning within two separate branches of the network\nwhile sharing the same encoding layers. We design dedicated spatial attention\nmodules (SAMs) along these learning pathways to exploit the coarse-level and\nfine-level semantic features for SOD at four stages of abstractions. The\nbottom-up branch performs a rough yet reasonably accurate saliency estimation\nat a fast rate, whereas the deeper top-down branch incorporates a residual\nrefinement module (RRM) that provides fine-grained localization of the salient\nobjects. Extensive performance evaluation of SVAM-Net on benchmark datasets\nclearly demonstrates its effectiveness for underwater SOD. We also validate its\ngeneralization performance by several ocean trials' data that include test\nimages of diverse underwater scenes and waterbodies, and also images with\nunseen natural objects. Moreover, we analyze its computational feasibility for\nrobotic deployments and demonstrate its utility in several important use cases\nof visual attention modeling.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 08:17:21 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Islam", "Md Jahidul", ""], ["Wang", "Ruobing", ""], ["de Langis", "Karin", ""], ["Sattar", "Junaed", ""]]}, {"id": "2011.06283", "submitter": "Dipankar Sarkar", "authors": "Dipankar Sarkar, Ankur Narang, Sumit Rai", "title": "Fed-Focal Loss for imbalanced data classification in Federated Learning", "comments": "Accepted for the Workshop on Federated Learning for Data Privacy and\n  Confidentiality in Conjunction with IJCAI 2020 (FL-IJCAI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Federated Learning setting has a central server coordinating the training\nof a model on a network of devices. One of the challenges is variable training\nperformance when the dataset has a class imbalance. In this paper, we address\nthis by introducing a new loss function called Fed-Focal Loss. We propose to\naddress the class imbalance by reshaping cross-entropy loss such that it\ndown-weights the loss assigned to well-classified examples along the lines of\nfocal loss. Additionally, by leveraging a tunable sampling framework, we take\ninto account selective client model contributions on the central server to\nfurther focus the detector during training and hence improve its robustness.\nUsing a detailed experimental analysis with the VIRTUAL (Variational Federated\nMulti-Task Learning) approach, we demonstrate consistently superior performance\nin both the balanced and unbalanced scenarios for MNIST, FEMNIST, VSN and HAR\nbenchmarks. We obtain a more than 9% (absolute percentage) improvement in the\nunbalanced MNIST benchmark. We further show that our technique can be adopted\nacross multiple Federated Learning algorithms to get improvements.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 09:52:14 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Sarkar", "Dipankar", ""], ["Narang", "Ankur", ""], ["Rai", "Sumit", ""]]}, {"id": "2011.06294", "submitter": "Zhewei Huang", "authors": "Zhewei Huang, Tianyuan Zhang, Wen Heng, Boxin Shi, Shuchang Zhou", "title": "RIFE: Real-Time Intermediate Flow Estimation for Video Frame\n  Interpolation", "comments": "10 pages, 7 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose RIFE, a Real-time Intermediate Flow Estimation algorithm for Video\nFrame Interpolation (VFI). Most existing flow-based methods first estimate the\nbi-directional optical flows, then scale and reverse them to approximate\nintermediate flows, leading to artifacts on motion boundaries. RIFE uses a\nneural network named IFNet that can directly estimate the intermediate flows\nfrom images with much better speed. Based on our proposed leakage distillation\nloss, RIFE can be trained in an end-to-end fashion. Experiments demonstrate\nthat our method is flexible and can achieve impressive performance on several\npublic benchmarks. The code is available at\nhttps://github.com/hzwer/arXiv2020-RIFE.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:12:06 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 09:33:17 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 12:51:04 GMT"}, {"version": "v4", "created": "Tue, 9 Mar 2021 08:18:05 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 04:40:29 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Huang", "Zhewei", ""], ["Zhang", "Tianyuan", ""], ["Heng", "Wen", ""], ["Shi", "Boxin", ""], ["Zhou", "Shuchang", ""]]}, {"id": "2011.06295", "submitter": "Dominik \\.Zurek", "authors": "Marcin Pietro\\'n Dominik \\.Zurek", "title": "When deep learning models on GPU can be accelerated by taking advantage\n  of unstructured sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is focused on the improvement the efficiency of the sparse\nconvolutional neural networks (CNNs) layers on graphic processing units (GPU).\nThe Nvidia deep neural network (cuDnn) library provides the most effective\nimplementation of deep learning (DL) algorithms for GPUs. GPUs are one of the\nmost efficient and commonly used accelerators for deep learning computations.\nThe modern CNN models need megabytes of coefficients and needed millions MAC\noperations to perform convolution. One of the most common techniques for\ncompressing CNN models is weight pruning. There are two main types of pruning:\nstructural (based on removing whole weight channels) and non-structural\n(removing individual weights). The first enables much easier acceleration, but\nwith this type it is difficult to achieve a sparsity level and accuracy as high\nas that obtained with the second type. Non-structural pruning with retraining\ncan generate a matrix-weight up to $\\sim90\\%$ or more of sparsity in some deep\nCNN models. This work shows when is worth using a direct sparse operation to\nspeed-up the calculation of the convolution layers. The VGG-16, CNN-non-static\nand 1x1 layers from ResNet models were used as a benchmarks. In addition, we\npresent the impact of using reduced precision on time efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:13:48 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 11:26:46 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["\u017burek", "Marcin Pietro\u0144 Dominik", ""]]}, {"id": "2011.06296", "submitter": "Sebastian Schmitt", "authors": "Andrea Castellani, Sebastian Schmitt, Stefano Squartini", "title": "Real-World Anomaly Detection by using Digital Twin Systems and\n  Weakly-Supervised Learning", "comments": "in IEEE Transactions on Industrial Informatics", "journal-ref": "IEEE Transactions on Industrial Informatics, 2020", "doi": "10.1109/TII.2020.3019788", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The continuously growing amount of monitored data in the Industry 4.0 context\nrequires strong and reliable anomaly detection techniques. The advancement of\nDigital Twin technologies allows for realistic simulations of complex\nmachinery, therefore, it is ideally suited to generate synthetic datasets for\nthe use in anomaly detection approaches when compared to actual measurement\ndata. In this paper, we present novel weakly-supervised approaches to anomaly\ndetection for industrial settings. The approaches make use of a Digital Twin to\ngenerate a training dataset which simulates the normal operation of the\nmachinery, along with a small set of labeled anomalous measurement from the\nreal machinery. In particular, we introduce a clustering-based approach, called\nCluster Centers (CC), and a neural architecture based on the Siamese\nAutoencoders (SAE), which are tailored for weakly-supervised settings with very\nfew labeled data samples. The performance of the proposed methods is compared\nagainst various state-of-the-art anomaly detection algorithms on an application\nto a real-world dataset from a facility monitoring system, by using a multitude\nof performance measures. Also, the influence of hyper-parameters related to\nfeature extraction and network architecture is investigated. We find that the\nproposed SAE based solutions outperform state-of-the-art anomaly detection\napproaches very robustly for many different hyper-parameter settings on all\nperformance measures.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:15:56 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Castellani", "Andrea", ""], ["Schmitt", "Sebastian", ""], ["Squartini", "Stefano", ""]]}, {"id": "2011.06301", "submitter": "Kejing Yin", "authors": "Kejing Yin, William K. Cheung, Benjamin C. M. Fung, Jonathan Poon", "title": "Learning Inter-Modal Correspondence and Phenotypes from Multi-Modal\n  Electronic Health Records", "comments": "Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": "10.1109/TKDE.2020.3038211", "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative tensor factorization has been shown a practical solution to\nautomatically discover phenotypes from the electronic health records (EHR) with\nminimal human supervision. Such methods generally require an input tensor\ndescribing the inter-modal interactions to be pre-established; however, the\ncorrespondence between different modalities (e.g., correspondence between\nmedications and diagnoses) can often be missing in practice. Although heuristic\nmethods can be applied to estimate them, they inevitably introduce errors, and\nleads to sub-optimal phenotype quality. This is particularly important for\npatients with complex health conditions (e.g., in critical care) as multiple\ndiagnoses and medications are simultaneously present in the records. To\nalleviate this problem and discover phenotypes from EHR with unobserved\ninter-modal correspondence, we propose the collective hidden interaction tensor\nfactorization (cHITF) to infer the correspondence between multiple modalities\njointly with the phenotype discovery. We assume that the observed matrix for\neach modality is marginalization of the unobserved inter-modal correspondence,\nwhich are reconstructed by maximizing the likelihood of the observed matrices.\nExtensive experiments conducted on the real-world MIMIC-III dataset demonstrate\nthat cHITF effectively infers clinically meaningful inter-modal correspondence,\ndiscovers phenotypes that are more clinically relevant and diverse, and\nachieves better predictive performance compared with a number of\nstate-of-the-art computational phenotyping models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:30:29 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Yin", "Kejing", ""], ["Cheung", "William K.", ""], ["Fung", "Benjamin C. M.", ""], ["Poon", "Jonathan", ""]]}, {"id": "2011.06304", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mahdi Jafari Siavoshani, Amir Hossein Khajepour, Amirmohammad Ziaei,\n  Amir Ali Gatmiri, Ali Taheri", "title": "Machine Learning Interpretability Meets TLS Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Protecting users' privacy over the Internet is of great importance. However,\ndue to the increasing complexity of network protocols and components, it\nbecomes harder and harder to maintain. Therefore, investigating and\nunderstanding how data is leaked from the information transport\nplatform/protocols can lead us to a more secure environment.\n  In this paper, we propose an iterative framework to find the most vulnerable\ninformation fields in a network protocol systematically. To this end, focusing\non the Transport Layer Security (TLS) protocol, we perform different\nmachine-learning-based fingerprinting attacks by collecting data from more than\n70 domains (websites) to understand how and where this information leakage\noccurs in the TLS protocol. Then, by employing the interpretation techniques\ndeveloped in the machine learning community, and using our framework, we find\nthe most vulnerable information fields in the TLS protocol. Our findings\ndemonstrate that the TLS handshake (which is mainly unencrypted), the TLS\nrecord length appears in the TLS application data header, and the\ninitialization vector (IV) field are among the most critical leaker parts in\nthis protocol, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:37:45 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Siavoshani", "Mahdi Jafari", ""], ["Khajepour", "Amir Hossein", ""], ["Ziaei", "Amirmohammad", ""], ["Gatmiri", "Amir Ali", ""], ["Taheri", "Ali", ""]]}, {"id": "2011.06306", "submitter": "Youmna Farag", "authors": "Youmna Farag, Josef Valvoda, Helen Yannakoudakis and Ted Briscoe", "title": "Analyzing Neural Discourse Coherence Models", "comments": null, "journal-ref": "CODI workshop in EMNLP2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we systematically investigate how well current models of\ncoherence can capture aspects of text implicated in discourse organisation. We\ndevise two datasets of various linguistic alterations that undermine coherence\nand test model sensitivity to changes in syntax and semantics. We furthermore\nprobe discourse embedding space and examine the knowledge that is encoded in\nrepresentations of coherence. We hope this study shall provide further insight\ninto how to frame the task and improve models of coherence assessment further.\nFinally, we make our datasets publicly available as a resource for researchers\nto use to test discourse coherence models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:44:41 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Farag", "Youmna", ""], ["Valvoda", "Josef", ""], ["Yannakoudakis", "Helen", ""], ["Briscoe", "Ted", ""]]}, {"id": "2011.06315", "submitter": "Veysel Kocaman Vk", "authors": "Veysel Kocaman and David Talby", "title": "Biomedical Named Entity Recognition at Scale", "comments": "Accepted for presentation and inclusion in CADL 2020 (International\n  Workshop on Computational Aspects of Deep Learning) , organized in\n  conjunction with ICPR 2020, the 25th International Conference on Pattern\n  Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition (NER) is a widely applicable natural language\nprocessing task and building block of question answering, topic modeling,\ninformation retrieval, etc. In the medical domain, NER plays a crucial role by\nextracting meaningful chunks from clinical notes and reports, which are then\nfed to downstream tasks like assertion status detection, entity resolution,\nrelation extraction, and de-identification. Reimplementing a Bi-LSTM-CNN-Char\ndeep learning architecture on top of Apache Spark, we present a single\ntrainable NER model that obtains new state-of-the-art results on seven public\nbiomedical benchmarks without using heavy contextual embeddings like BERT. This\nincludes improving BC4CHEMD to 93.72% (4.1% gain), Species800 to 80.91% (4.6%\ngain), and JNLPBA to 81.29% (5.2% gain). In addition, this model is freely\navailable within a production-grade code base as part of the open-source Spark\nNLP library; can scale up for training and inference in any Spark cluster; has\nGPU support and libraries for popular programming languages such as Python, R,\nScala and Java; and can be extended to support other human languages with no\ncode changes.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:10:17 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kocaman", "Veysel", ""], ["Talby", "David", ""]]}, {"id": "2011.06317", "submitter": "Shuai Yang", "authors": "Shuai Yang, Kui Yu, Fuyuan Cao, Lin Liu, Hao Wang, Jiuyong Li", "title": "Learning causal representations for robust domain adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation solves the learning problem in a target domain by\nleveraging the knowledge in a relevant source domain. While remarkable advances\nhave been made, almost all existing domain adaptation methods heavily require\nlarge amounts of unlabeled target domain data for learning domain invariant\nrepresentations to achieve good generalizability on the target domain. In fact,\nin many real-world applications, target domain data may not always be\navailable. In this paper, we study the cases where at the training phase the\ntarget domain data is unavailable and only well-labeled source domain data is\navailable, called robust domain adaptation. To tackle this problem, under the\nassumption that causal relationships between features and the class variable\nare robust across domains, we propose a novel Causal AutoEncoder (CAE), which\nintegrates deep autoencoder and causal structure learning into a unified model\nto learn causal representations only using data from a single source domain.\nSpecifically, a deep autoencoder model is adopted to learn low-dimensional\nrepresentations, and a causal structure learning model is designed to separate\nthe low-dimensional representations into two groups: causal representations and\ntask-irrelevant representations. Using three real-world datasets the extensive\nexperiments have validated the effectiveness of CAE compared to eleven\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:24:03 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Yang", "Shuai", ""], ["Yu", "Kui", ""], ["Cao", "Fuyuan", ""], ["Liu", "Lin", ""], ["Wang", "Hao", ""], ["Li", "Jiuyong", ""]]}, {"id": "2011.06319", "submitter": "Veysel Kocaman Vk", "authors": "Veysel Kocaman, Ofer M. Shir, Thomas B\\\"ack", "title": "Improving Model Accuracy for Imbalanced Image Classification Tasks by\n  Adding a Final Batch Normalization Layer: An Empirical Study", "comments": "Accepted for presentation and inclusion in ICPR 2020, the 25th\n  International Conference on Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Some real-world domains, such as Agriculture and Healthcare, comprise\nearly-stage disease indications whose recording constitutes a rare event, and\nyet, whose precise detection at that stage is critical. In this type of highly\nimbalanced classification problems, which encompass complex features, deep\nlearning (DL) is much needed because of its strong detection capabilities. At\nthe same time, DL is observed in practice to favor majority over minority\nclasses and consequently suffer from inaccurate detection of the targeted\nearly-stage indications. To simulate such scenarios, we artificially generate\nskewness (99% vs. 1%) for certain plant types out of the PlantVillage dataset\nas a basis for classification of scarce visual cues through transfer learning.\nBy randomly and unevenly picking healthy and unhealthy samples from certain\nplant types to form a training set, we consider a base experiment as\nfine-tuning ResNet34 and VGG19 architectures and then testing the model\nperformance on a balanced dataset of healthy and unhealthy images. We\nempirically observe that the initial F1 test score jumps from 0.29 to 0.95 for\nthe minority class upon adding a final Batch Normalization (BN) layer just\nbefore the output layer in VGG19. We demonstrate that utilizing an additional\nBN layer before the output layer in modern CNN architectures has a considerable\nimpact in terms of minimizing the training time and testing error for minority\nclasses in highly imbalanced data sets. Moreover, when the final BN is\nemployed, minimizing the loss function may not be the best way to assure a high\nF1 test score for minority classes in such problems. That is, the network might\nperform better even if it is not confident enough while making a prediction;\nleading to another discussion about why softmax output is not a good\nuncertainty measure for DL models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:27:40 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kocaman", "Veysel", ""], ["Shir", "Ofer M.", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2011.06326", "submitter": "Chanika Ruchini Mudalige", "authors": "Chanika Ruchini Mudalige, Dilini Karunarathna, Isanka Rajapaksha,\n  Nisansa de Silva, Gathika Ratnayaka, Amal Shehan Perera, Ramesh Pathirana", "title": "SigmaLaw-ABSA: Dataset for Aspect-Based Sentiment Analysis in Legal\n  Opinion Texts", "comments": "6 pages, 2 figures, IEEE International Conference on Industrial and\n  Information Systems(ICIIS) 2020", "journal-ref": null, "doi": "10.1109/ICIIS51140.2020.9342650", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-Based Sentiment Analysis (ABSA) has been prominent and ongoing\nresearch over many different domains, but it is not widely discussed in the\nlegal domain. A number of publicly available datasets for a wide range of\ndomains usually fulfill the needs of researchers to perform their studies in\nthe field of ABSA. To the best of our knowledge, there is no publicly available\ndataset for the Aspect (Party) Based Sentiment Analysis for legal opinion\ntexts. Therefore, creating a publicly available dataset for the research of\nABSA for the legal domain can be considered as a task with significant\nimportance. In this study, we introduce a manually annotated legal opinion text\ndataset (SigmaLaw-ABSA) intended towards facilitating researchers for ABSA\ntasks in the legal domain. SigmaLaw-ABSA consists of legal opinion texts in the\nEnglish language which have been annotated by human judges. This study\ndiscusses the sub-tasks of ABSA relevant to the legal domain and how to use the\ndataset to perform them. This paper also describes the statistics of the\ndataset and as a baseline, we present some results on the performance of some\nexisting deep learning based systems on the SigmaLaw-ABSA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 11:45:47 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Mudalige", "Chanika Ruchini", ""], ["Karunarathna", "Dilini", ""], ["Rajapaksha", "Isanka", ""], ["de Silva", "Nisansa", ""], ["Ratnayaka", "Gathika", ""], ["Perera", "Amal Shehan", ""], ["Pathirana", "Ramesh", ""]]}, {"id": "2011.06335", "submitter": "Lorenzo Steccanella", "authors": "Lorenzo Steccanella, Simone Totaro, Damien Allonsius, Anders Jonsson", "title": "Hierarchical reinforcement learning for efficient exploration and\n  transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sparse-reward domains are challenging for reinforcement learning algorithms\nsince significant exploration is needed before encountering reward for the\nfirst time. Hierarchical reinforcement learning can facilitate exploration by\nreducing the number of decisions necessary before obtaining a reward. In this\npaper, we present a novel hierarchical reinforcement learning framework based\non the compression of an invariant state space that is common to a range of\ntasks. The algorithm introduces subtasks which consist of moving between the\nstate partitions induced by the compression. Results indicate that the\nalgorithm can successfully solve complex sparse-reward domains, and transfer\nknowledge to solve new, previously unseen tasks more quickly.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:09:13 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Steccanella", "Lorenzo", ""], ["Totaro", "Simone", ""], ["Allonsius", "Damien", ""], ["Jonsson", "Anders", ""]]}, {"id": "2011.06337", "submitter": "Jong Chul Ye", "authors": "Gyutaek Oh, Jeong Eun Lee, and Jong Chul Ye", "title": "Unsupervised MR Motion Artifact Deep Learning using Outlier-Rejecting\n  Bootstrap Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, deep learning approaches for MR motion artifact correction have\nbeen extensively studied. Although these approaches have shown high performance\nand reduced computational complexity compared to classical methods, most of\nthem require supervised training using paired artifact-free and\nartifact-corrupted images, which may prohibit its use in many important\nclinical applications. For example, transient severe motion (TSM) due to acute\ntransient dyspnea in Gd-EOB-DTPA-enhanced MR is difficult to control and model\nfor paired data generation. To address this issue, here we propose a novel\nunsupervised deep learning scheme through outlier-rejecting bootstrap\nsubsampling and aggregation. This is inspired by the observation that motions\nusually cause sparse k-space outliers in the phase encoding direction, so\nk-space subsampling along the phase encoding direction can remove some outliers\nand the aggregation step can further improve the results from the\nreconstruction network. Our method does not require any paired data because the\ntraining step only requires artifact-free images. Furthermore, to address the\nsmoothing from potential bias to the artifact-free images, the network is\ntrained in an unsupervised manner using optimal transport driven cycleGAN. We\nverify that our method can be applied for artifact correction from simulated\nmotion as well as real motion from TSM successfully, outperforming existing\nstate-of-the-art deep learning methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:10:58 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Oh", "Gyutaek", ""], ["Lee", "Jeong Eun", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2011.06346", "submitter": "Zhenghao Zhang", "authors": "Zhenghao Zhang, Jianbin Huang and Qinglin Tan", "title": "Multi-View Dynamic Heterogeneous Information Network Embedding", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most existing Heterogeneous Information Network (HIN) embedding methods focus\non static environments while neglecting the evolving characteristic of\nrealworld networks. Although several dynamic embedding methods have been\nproposed, they are merely designed for homogeneous networks and cannot be\ndirectly applied in heterogeneous environment. To tackle above challenges, we\npropose a novel framework for incorporating temporal information into HIN\nembedding, denoted as Multi-View Dynamic HIN Embedding (MDHNE), which can\nefficiently preserve evolution patterns of implicit relationships from\ndifferent views in updating node representations over time. We first transform\nHIN to a series of homogeneous networks corresponding to different views. Then\nour proposed MDHNE applies Recurrent Neural Network (RNN) to incorporate\nevolving pattern of complex network structure and semantic relationships\nbetween nodes into latent embedding spaces, and thus the node representations\nfrom multiple views can be learned and updated when HIN evolves over time.\nMoreover, we come up with an attention based fusion mechanism, which can\nautomatically infer weights of latent representations corresponding to\ndifferent views by minimizing the objective function specific for different\nmining tasks. Extensive experiments clearly demonstrate that our MDHNE model\noutperforms state-of-the-art baselines on three real-world dynamic datasets for\ndifferent network mining tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:33:29 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Zhang", "Zhenghao", ""], ["Huang", "Jianbin", ""], ["Tan", "Qinglin", ""]]}, {"id": "2011.06349", "submitter": "Yara Huleihel", "authors": "Yara Huleihel and Eilam Ben-Dror and Haim H. Permuter", "title": "Low PAPR waveform design for OFDM SYSTEM based on Convolutional\n  Auto-Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces the architecture of a convolutional autoencoder (CAE)\nfor the task of peak-to-average power ratio (PAPR) reduction and waveform\ndesign, for orthogonal frequency division multiplexing (OFDM) systems. The\nproposed architecture integrates a PAPR reduction block and a non-linear high\npower amplifier (HPA) model. We apply gradual loss learning for multi-objective\noptimization. We analyze the models performance by examining the bit error rate\n(BER), the PAPR and the spectral response, and comparing them with common PAPR\nreduction algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:44:30 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Huleihel", "Yara", ""], ["Ben-Dror", "Eilam", ""], ["Permuter", "Haim H.", ""]]}, {"id": "2011.06356", "submitter": "Mounssif Krouka", "authors": "Mounssif Krouka, Anis Elgabli, Mohammed S. Elbamby, Cristina Perfecto,\n  Mehdi Bennis, Vaneet Aggarwal", "title": "Cross Layer Optimization and Distributed Reinforcement Learning Approach\n  for Tile-Based 360 Degree Wireless Video Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wirelessly streaming high quality 360 degree videos is still a challenging\nproblem. When there are many users watching different 360 degree videos and\ncompeting for the computing and communication resources, the streaming\nalgorithm at hand should maximize the average quality of experience (QoE) while\nguaranteeing a minimum rate for each user. In this paper, we propose a\n\\emph{cross layer} optimization approach that maximizes the available rate to\neach user and efficiently uses it to maximize users' QoE. Particularly, we\nconsider a tile based 360 degree video streaming, and we optimize a QoE metric\nthat balances the tradeoff between maximizing each user's QoE and ensuring\nfairness among users. We show that the problem can be decoupled into two\ninterrelated subproblems: (i) a physical layer subproblem whose objective is to\nfind the download rate for each user, and (ii) an application layer subproblem\nwhose objective is to use that rate to find a quality decision per tile such\nthat the user's QoE is maximized. We prove that the physical layer subproblem\ncan be solved optimally with low complexity and an actor-critic deep\nreinforcement learning (DRL) is proposed to leverage the parallel training of\nmultiple independent agents and solve the application layer subproblem.\nExtensive experiments reveal the robustness of our scheme and demonstrate its\nsignificant performance improvement compared to several baseline algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:59:10 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Krouka", "Mounssif", ""], ["Elgabli", "Anis", ""], ["Elbamby", "Mohammed S.", ""], ["Perfecto", "Cristina", ""], ["Bennis", "Mehdi", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2011.06374", "submitter": "Huan Qing", "authors": "Huan Qing and Jingli Wang", "title": "An improved spectral clustering method for community detection under the\n  degree-corrected stochastic blockmodel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For community detection problem, spectral clustering is a widely used method\nfor detecting clusters in networks. In this paper, we propose an improved\nspectral clustering (ISC) approach under the degree corrected stochastic block\nmodel (DCSBM). ISC is designed based on the k-means clustering algorithm on the\nweighted leading K + 1 eigenvectors of a regularized Laplacian matrix where the\nweights are their corresponding eigenvalues. Theoretical analysis of ISC shows\nthat under mild conditions the ISC yields stable consistent community\ndetection. Numerical results show that ISC outperforms classical spectral\nclustering methods for community detection on both simulated and eight\nempirical networks. Especially, ISC provides a significant improvement on two\nweak signal networks Simmons and Caltech, with error rates of 121/1137 and\n96/590, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 13:35:11 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.06378", "submitter": "Fang Kong", "authors": "Shuai Li, Fang Kong, Kejie Tang, Qizhi Li, Wei Chen", "title": "Online Influence Maximization under Linear Threshold Model", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online influence maximization (OIM) is a popular problem in social networks\nto learn influence propagation model parameters and maximize the influence\nspread at the same time. Most previous studies focus on the independent cascade\n(IC) model under the edge-level feedback. In this paper, we address OIM in the\nlinear threshold (LT) model. Because node activations in the LT model are due\nto the aggregated effect of all active neighbors, it is more natural to model\nOIM with the node-level feedback. And this brings new challenge in online\nlearning since we only observe aggregated effect from groups of nodes and the\ngroups are also random. Based on the linear structure in node activations, we\nincorporate ideas from linear bandits and design an algorithm LT-LinUCB that is\nconsistent with the observed feedback. By proving group observation modulated\n(GOM) bounded smoothness property, a novel result of the influence difference\nin terms of the random observations, we provide a regret of order\n$\\tilde{O}(\\mathrm{poly}(m)\\sqrt{T})$, where $m$ is the number of edges and $T$\nis the number of rounds. This is the first theoretical result in such order for\nOIM under the LT model. In the end, we also provide an algorithm OIM-ETC with\nregret bound $O(\\mathrm{poly}(m)\\ T^{2/3})$, which is model-independent, simple\nand has less requirement on online feedback and offline computation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 13:41:37 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 04:45:48 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 04:51:42 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Li", "Shuai", ""], ["Kong", "Fang", ""], ["Tang", "Kejie", ""], ["Li", "Qizhi", ""], ["Chen", "Wei", ""]]}, {"id": "2011.06388", "submitter": "Do Gyun Kim", "authors": "Do Gyun Kim, Jin Young Choi", "title": "An ensemble of Density based Geometric One-Class Classifier and Genetic\n  Algorithm", "comments": "This manuscript contains a wrong definitions and equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most rising issues in recent machine learning research is\nOne-Class Classification which considers data set composed of only one class\nand outliers. It is more reasonable than traditional Multi-Class Classification\nin dealing with some problematic data set or special cases. Generally,\nclassification accuracy and interpretability for user are considered as\ntrade-off in OCC methods. Classifier based on Hyper-Rectangle (H-RTGL) is a\nsort of classifier that can be a remedy for such trade-off and uses H-RTGL\nformulated by conjunction of geometric rules called interval. This interval can\nbe basis of interpretability since it can be easily understood by user.\nHowever, existing H-RTGL based OCC classifiers have limitations that (i) most\nof them cannot reflect density of target class and (ii) that considering\ndensity has primitive interval generation method, and (iii) there exists no\nsystematic procedure for hyperparameter of H-RTGL based OCC classifier, which\ninfluences classification performance of classifier. Based on these remarks, we\nsuggest One-Class Hyper-Rectangle Descriptor based on density (1-HRD_d) with\nmore elaborate interval generation method including parametric and\nnonparametric approaches. In addition, we designed Genetic Algorithm (GA) that\nconsists of chromosome structure and genetic operators for systematic\ngeneration of 1-HRD_d by optimization of hyperparameter. Our work is validated\nthrough a numerical experiment using actual data set with comparison of\nexisting OCC algorithms along with other H-RTGL based classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2020 04:22:03 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 07:29:19 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Kim", "Do Gyun", ""], ["Choi", "Jin Young", ""]]}, {"id": "2011.06391", "submitter": "Md. Khaledur Rahman", "authors": "Md. Khaledur Rahman, Majedul Haque Sujon and Ariful Azad", "title": "FusedMM: A Unified SDDMM-SpMM Kernel for Graph Embedding and Graph\n  Neural Networks", "comments": "11 pages, Under review in IPDPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a fused matrix multiplication kernel that unifies sampled\ndense-dense matrix multiplication and sparse-dense matrix multiplication under\na single operation called FusedMM. By using user-defined functions, FusedMM can\ncapture almost all computational patterns needed by popular graph embedding and\nGNN approaches. FusedMM is an order of magnitude faster than its equivalent\nkernels in Deep Graph Library. The superior performance of FusedMM comes from\nthe low-level vectorized kernels, a suitable load balancing scheme and an\nefficient utilization of the memory bandwidth. FusedMM can tune its performance\nusing a code generator and perform equally well on Intel, AMD and ARM\nprocessors. FusedMM speeds up an end-to-end graph embedding algorithm by up to\n28x on different processors.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 18:06:57 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Rahman", "Md. Khaledur", ""], ["Sujon", "Majedul Haque", ""], ["Azad", "Ariful", ""]]}, {"id": "2011.06392", "submitter": "Hamed Hemati", "authors": "Hamed Hemati, Damian Borth", "title": "Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker\n  Adaptation and Pronunciation Enhancement", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent neural Text-to-Speech (TTS) models have been shown to perform very\nwell when enough data is available. However, fine-tuning them towards a new\nspeaker or a new language is not as straight-forward in a low-resource setup.\nIn this paper, we show that by applying minor changes to a Tacotron model, one\ncan transfer an existing TTS model for a new speaker with the same or a\ndifferent language using only 20 minutes of data. For this purpose, we first\nintroduce a baseline multi-lingual Tacotron with language-agnostic input, then\nshow how transfer learning is done for different scenarios of speaker\nadaptation without exploiting any pre-trained speaker encoder or code-switching\ntechnique. We evaluate the transferred model in both subjective and objective\nways.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 14:05:34 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Hemati", "Hamed", ""], ["Borth", "Damian", ""]]}, {"id": "2011.06393", "submitter": "Lixuan Yang", "authors": "Lixuan Yang, Cedric Beliard, Dario Rossi", "title": "Heterogeneous Data-Aware Federated Learning", "comments": "IJCAI 2020 Federated learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an appealing concept to perform distributed\ntraining of Neural Networks (NN) while keeping data private. With the\nindustrialization of the FL framework, we identify several problems hampering\nits successful deployment, such as presence of non i.i.d data, disjoint\nclasses, signal multi-modality across datasets. In this work, we address these\nproblems by proposing a novel method that not only (1) aggregates generic model\nparameters (e.g. a common set of task generic NN layers) on server (e.g. in\ntraditional FL), but also (2) keeps a set of parameters (e.g, a set of task\nspecific NN layer) specific to each client. We validate our method on the\ntraditionally used public benchmarks (e.g., Femnist) as well as on our\nproprietary collected dataset (i.e., traffic classification). Results show the\nbenefit of our method, with significant advantage on extreme cases.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 14:07:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Yang", "Lixuan", ""], ["Beliard", "Cedric", ""], ["Rossi", "Dario", ""]]}, {"id": "2011.06395", "submitter": "Ruofeng Wen", "authors": "Ruofeng Wen", "title": "Turn-level Dialog Evaluation with Dialog-level Weak Signals for\n  Bot-Human Hybrid Customer Service Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a machine learning approach that quantifies multiple aspects of\nthe success or values in Customer Service contacts, at anytime during the\ninteraction. Specifically, the value/reward function regarding to the\nturn-level behaviors across human agents, chatbots and other hybrid dialog\nsystems is characterized by the incremental information and confidence gain\nbetween sentences, based on the token-level predictions from a multi-task\nneural network trained with only weak signals in dialog-level\nattributes/states. The resulting model, named Value Profiler, serves as a\ngoal-oriented dialog manager that enhances conversations by regulating\nautomated decisions with its reward and state predictions. It supports both\nreal-time monitoring and scalable offline customer experience evaluation, for\nboth bot- and human-handled contacts. We show how it improves Amazon customer\nservice quality in several applications.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 19:36:23 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Wen", "Ruofeng", ""]]}, {"id": "2011.06408", "submitter": "Andrew Browne", "authors": "Stephen McAleer, Alex Fast, Yuntian Xue, Magdalene Seiler, William\n  Tang, Mihaela Balu, Pierre Baldi, Andrew W. Browne", "title": "Deep machine learning-assisted multiphoton microscopy to reduce light\n  exposure and expedite imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Two-photon excitation fluorescence (2PEF) allows imaging of tissue up to\nabout one millimeter in thickness. Typically, reducing fluorescence excitation\nexposure reduces the quality of the image. However, using deep learning super\nresolution techniques, these low-resolution images can be converted to\nhigh-resolution images. This work explores improving human tissue imaging by\napplying deep learning to maximize image quality while reducing fluorescence\nexcitation exposure. We analyze two methods: a method based on U-Net, and a\npatch-based regression method. Both methods are evaluated on a skin dataset and\nan eye dataset. The eye dataset includes 1200 paired high power and low power\nimages of retinal organoids. The skin dataset contains multiple frames of each\nsample of human skin. High-resolution images were formed by averaging 70 frames\nfor each sample and low-resolution images were formed by averaging the first 7\nand 15 frames for each sample. The skin dataset includes 550 images for each of\nthe resolution levels. We track two measures of performance for the two\nmethods: mean squared error (MSE) and structural similarity index measure\n(SSIM). For the eye dataset, the patches method achieves an average MSE of\n27,611 compared to 146,855 for the U-Net method, and an average SSIM of 0.636\ncompared to 0.607 for the U-Net method. For the skin dataset, the patches\nmethod achieves an average MSE of 3.768 compared to 4.032 for the U-Net method,\nand an average SSIM of 0.824 compared to 0.783 for the U-Net method. Despite\nbetter performance on image quality, the patches method is worse than the U-Net\nmethod when comparing the speed of prediction, taking 303 seconds to predict\none image compared to less than one second for the U-Net method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:24:42 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["McAleer", "Stephen", ""], ["Fast", "Alex", ""], ["Xue", "Yuntian", ""], ["Seiler", "Magdalene", ""], ["Tang", "William", ""], ["Balu", "Mihaela", ""], ["Baldi", "Pierre", ""], ["Browne", "Andrew W.", ""]]}, {"id": "2011.06428", "submitter": "Yuan Jin", "authors": "Yuan Jin, Wray Buntine, Francois Petitjean, Geoffrey I. Webb", "title": "Discriminative, Generative and Self-Supervised Approaches for\n  Target-Agnostic Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised learning, characterized by both discriminative and generative\nlearning, seeks to predict the values of single (or sometimes multiple)\npredefined target attributes based on a predefined set of predictor attributes.\nFor applications where the information available and predictions to be made may\nvary from instance to instance, we propose the task of target-agnostic learning\nwhere arbitrary disjoint sets of attributes can be used for each of predictors\nand targets for each to-be-predicted instance. For this task, we survey a wide\nrange of techniques available for handling missing values, self-supervised\ntraining and pseudo-likelihood training, and adapt them to a suite of\nalgorithms that are suitable for the task. We conduct extensive experiments on\nthis suite of algorithms on a large collection of categorical, continuous and\ndiscretized datasets, and report their performance in terms of both\nclassification and regression errors. We also report the training and\nprediction time of these algorithms when handling large-scale datasets. Both\ngenerative and self-supervised learning models are shown to perform well at the\ntask, although their characteristics towards the different types of data are\nquite different. Nevertheless, our derived theorem for the pseudo-likelihood\ntheory also shows that they are related for inferring a joint distribution\nmodel based on the pseudo-likelihood training.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 15:03:40 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Jin", "Yuan", ""], ["Buntine", "Wray", ""], ["Petitjean", "Francois", ""], ["Webb", "Geoffrey I.", ""]]}, {"id": "2011.06445", "submitter": "Ren\\'ata N\\'emeth", "authors": "Anna Farkas and Ren\\'ata N\\'emeth", "title": "How to Measure Gender Bias in Machine Translation: Optimal Translators,\n  Multiple Reference Points", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, as a case study, we present a systematic study of gender bias\nin machine translation with Google Translate. We translated sentences\ncontaining names of occupations from Hungarian, a language with gender-neutral\npronouns, into English. Our aim was to present a fair measure for bias by\ncomparing the translations to an optimal non-biased translator. When assessing\nbias, we used the following reference points: (1) the distribution of men and\nwomen among occupations in both the source and the target language countries,\nas well as (2) the results of a Hungarian survey that examined if certain jobs\nare generally perceived as feminine or masculine. We also studied how expanding\nsentences with adjectives referring to occupations effect the gender of the\ntranslated pronouns. As a result, we found bias against both genders, but\nbiased results against women are much more frequent. Translations are closer to\nour perception of occupations than to objective occupational statistics.\nFinally, occupations have a greater effect on translation than adjectives.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 15:39:22 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Farkas", "Anna", ""], ["N\u00e9meth", "Ren\u00e1ta", ""]]}, {"id": "2011.06446", "submitter": "Yueming Lyu", "authors": "Yueming Lyu, Yuan Yuan and Ivor W. Tsang", "title": "Subgroup-based Rank-1 Lattice Quasi-Monte Carlo", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quasi-Monte Carlo (QMC) is an essential tool for integral approximation,\nBayesian inference, and sampling for simulation in science, etc. In the QMC\narea, the rank-1 lattice is important due to its simple operation, and nice\nproperties for point set construction. However, the construction of the\ngenerating vector of the rank-1 lattice is usually time-consuming because of an\nexhaustive computer search. To address this issue, we propose a simple\nclosed-form rank-1 lattice construction method based on group theory. Our\nmethod reduces the number of distinct pairwise distance values to generate a\nmore regular lattice. We theoretically prove a lower and an upper bound of the\nminimum pairwise distance of any non-degenerate rank-1 lattice. Empirically,\nour methods can generate a near-optimal rank-1 lattice compared with the\nKorobov exhaustive search regarding the $l_1$-norm and $l_2$-norm minimum\ndistance. Moreover, experimental results show that our method achieves superior\napproximation performance on benchmark integration test problems and kernel\napproximation problems.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 03:42:30 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Lyu", "Yueming", ""], ["Yuan", "Yuan", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2011.06461", "submitter": "Saptarshi Chakraborty", "authors": "Debolina Paul, Saptarshi Chakraborty, Swagatam Das and Jason Xu", "title": "Kernel k-Means, By All Means: Algorithms and Strong Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel $k$-means clustering is a powerful tool for unsupervised learning of\nnon-linearly separable data. Since the earliest attempts, researchers have\nnoted that such algorithms often become trapped by local minima arising from\nnon-convexity of the underlying objective function. In this paper, we\ngeneralize recent results leveraging a general family of means to combat\nsub-optimal local solutions to the kernel and multi-kernel settings. Called\nKernel Power $k$-Means, our algorithm makes use of majorization-minimization\n(MM) to better solve this non-convex problem. We show the method implicitly\nperforms annealing in kernel feature space while retaining efficient,\nclosed-form updates, and we rigorously characterize its convergence properties\nboth from computational and statistical points of view. In particular, we\ncharacterize the large sample behavior of the proposed method by establishing\nstrong consistency guarantees. Its merits are thoroughly validated on a suite\nof simulated datasets and real data benchmarks that feature non-linear and\nmulti-view separation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:07:18 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Paul", "Debolina", ""], ["Chakraborty", "Saptarshi", ""], ["Das", "Swagatam", ""], ["Xu", "Jason", ""]]}, {"id": "2011.06464", "submitter": "Xian Zhou", "authors": "Hsiao-Yu Fish Tung, Zhou Xian, Mihir Prabhudesai, Shamit Lal, Katerina\n  Fragkiadaki", "title": "3D-OES: Viewpoint-Invariant Object-Factorized Environment Simulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an action-conditioned dynamics model that predicts scene changes\ncaused by object and agent interactions in a viewpoint-invariant 3D neural\nscene representation space, inferred from RGB-D videos. In this 3D feature\nspace, objects do not interfere with one another and their appearance persists\nover time and across viewpoints. This permits our model to predict future\nscenes long in the future by simply \"moving\" 3D object features based on\ncumulative object motion predictions. Object motion predictions are computed by\na graph neural network that operates over the object features extracted from\nthe 3D neural scene representation. Our model's simulations can be decoded by a\nneural renderer into2D image views from any desired viewpoint, which aids the\ninterpretability of our latent 3D simulation space. We show our model\ngeneralizes well its predictions across varying number and appearances of\ninteracting objects as well as across camera viewpoints, outperforming existing\n2D and 3D dynamics models. We further demonstrate sim-to-real transfer of the\nlearnt dynamics by applying our model trained solely in simulation to\nmodel-based control for pushing objects to desired locations under clutter on a\nreal robotic setup\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:15:52 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Tung", "Hsiao-Yu Fish", ""], ["Xian", "Zhou", ""], ["Prabhudesai", "Mihir", ""], ["Lal", "Shamit", ""], ["Fragkiadaki", "Katerina", ""]]}, {"id": "2011.06465", "submitter": "Chung-Ming Chien", "authors": "Chung-Ming Chien and Hung-yi Lee", "title": "Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis", "comments": "Accepted by SLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prosody modeling is an essential component in modern text-to-speech (TTS)\nframeworks. By explicitly providing prosody features to the TTS model, the\nstyle of synthesized utterances can thus be controlled. However, predicting\nnatural and reasonable prosody at inference time is challenging. In this work,\nwe analyzed the behavior of non-autoregressive TTS models under different\nprosody-modeling settings and proposed a hierarchical architecture, in which\nthe prediction of phoneme-level prosody features are conditioned on the\nword-level prosody features. The proposed method outperforms other competitors\nin terms of audio quality and prosody naturalness in our objective and\nsubjective evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:16:41 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 07:32:51 GMT"}, {"version": "v3", "created": "Sat, 1 May 2021 07:59:07 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chien", "Chung-Ming", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2011.06475", "submitter": "Alessandro Luongo", "authors": "Alessandro Luongo, Changpeng Shao", "title": "Quantum algorithms for spectral sums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose and analyze new quantum algorithms for estimating the most common\nspectral sums of symmetric positive definite (SPD) matrices. For a function $f$\nand a matrix $A \\in \\mathbb{R}^{n\\times n}$, the spectral sum is defined as\n$S_f(A) :=\\text{Tr}[f(A)] = \\sum_j f(\\lambda_j)$, where $\\lambda_j$ are the\neigenvalues. Examples of spectral sums are the von Neumann entropy, the trace\nof inverse, the log-determinant, and the Schatten-$p$ norm, where the latter\ndoes not require the matrix to be SPD. The fastest classical randomized\nalgorithms estimate these quantities have a runtime that depends at least\nlinearly on the number of nonzero components of the matrix. Assuming quantum\naccess to the matrix, our algorithms are sub-linear in the matrix size, and\ndepend at most quadratically on other quantities, like the condition number and\nthe approximation error, and thus can compete with most of the randomized and\ndistributed classical algorithms proposed in recent literature. These\nalgorithms can be used as subroutines for solving many practical problems, for\nwhich the estimation of a spectral sum often represents a computational\nbottleneck.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:29:45 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Luongo", "Alessandro", ""], ["Shao", "Changpeng", ""]]}, {"id": "2011.06485", "submitter": "Robert Adragna", "authors": "Robert Adragna, Elliot Creager, David Madras, Richard Zemel", "title": "Fairness and Robustness in Invariant Learning: A Case Study in Toxicity\n  Classification", "comments": "12 pages, 5 figures. Appears in the NeurIPS 2020 Workshop on\n  Algorithmic Fairness through the Lens of Causality and Interpretability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robustness is of central importance in machine learning and has given rise to\nthe fields of domain generalization and invariant learning, which are concerned\nwith improving performance on a test distribution distinct from but related to\nthe training distribution. In light of recent work suggesting an intimate\nconnection between fairness and robustness, we investigate whether algorithms\nfrom robust ML can be used to improve the fairness of classifiers that are\ntrained on biased data and tested on unbiased data. We apply Invariant Risk\nMinimization (IRM), a domain generalization algorithm that employs a causal\ndiscovery inspired method to find robust predictors, to the task of fairly\npredicting the toxicity of internet comments. We show that IRM achieves better\nout-of-distribution accuracy and fairness than Empirical Risk Minimization\n(ERM) methods, and analyze both the difficulties that arise when applying IRM\nin practice and the conditions under which IRM will likely be effective in this\nscenario. We hope that this work will inspire further studies of how robust\nmachine learning methods relate to algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:42:14 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 02:21:12 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Adragna", "Robert", ""], ["Creager", "Elliot", ""], ["Madras", "David", ""], ["Zemel", "Richard", ""]]}, {"id": "2011.06495", "submitter": "Kerem \\\"Ozfatura", "authors": "Kerem Ozfatura and Emre Ozfatura and Deniz Gunduz", "title": "Distributed Sparse SGD with Majority Voting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning, particularly variants of distributed stochastic\ngradient descent (DSGD), are widely employed to speed up training by leveraging\ncomputational resources of several workers. However, in practise, communication\ndelay becomes a bottleneck due to the significant amount of information that\nneeds to be exchanged between the workers and the parameter server. One of the\nmost efficient strategies to mitigate the communication bottleneck is top-K\nsparsification. However, top-K sparsification requires additional communication\nload to represent the sparsity pattern, and the mismatch between the sparsity\npatterns of the workers prevents exploitation of efficient communication\nprotocols. To address these issues, we introduce a novel majority voting based\nsparse communication strategy, in which the workers first seek a consensus on\nthe structure of the sparse representation. This strategy provides a\nsignificant reduction in the communication load and allows using the same\nsparsity level in both communication directions. Through extensive simulations\non the CIFAR-10 dataset, we show that it is possible to achieve up to x4000\ncompression without any loss in the test accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:06:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ozfatura", "Kerem", ""], ["Ozfatura", "Emre", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2011.06496", "submitter": "Shiv Ram Dubey", "authors": "Roshan Reddy Yedla and Shiv Ram Dubey", "title": "On the Performance of Convolutional Neural Networks under High and Low\n  Frequency Information", "comments": "Accepted in Fifth IAPR International Conference on Computer Vision\n  and Image Processing (CVIP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have shown very promising performance in\nrecent years for different problems, including object recognition, face\nrecognition, medical image analysis, etc. However, generally the trained CNN\nmodels are tested over the test set which is very similar to the trained set.\nThe generalizability and robustness of the CNN models are very important\naspects to make it to work for the unseen data. In this letter, we study the\nperformance of CNN models over the high and low frequency information of the\nimages. We observe that the trained CNN fails to generalize over the high and\nlow frequency images. In order to make the CNN robust against high and low\nfrequency images, we propose the stochastic filtering based data augmentation\nduring training. A satisfactory performance improvement has been observed in\nterms of the high and low frequency generalization and robustness with the\nproposed stochastic filtering based data augmentation approach. The\nexperimentations are performed using ResNet50 model over the CIFAR-10 dataset\nand ResNet101 model over Tiny-ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 17:54:45 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Yedla", "Roshan Reddy", ""], ["Dubey", "Shiv Ram", ""]]}, {"id": "2011.06498", "submitter": "Shubham Agrawal", "authors": "Huy Ha, Shubham Agrawal, Shuran Song", "title": "Fit2Form: 3D Generative Model for Robot Gripper Form Design", "comments": "Conference on Robot Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 3D shape of a robot's end-effector plays a critical role in determining\nit's functionality and overall performance. Many industrial applications rely\non task-specific gripper designs to ensure the system's robustness and\naccuracy. However, the process of manual hardware design is both costly and\ntime-consuming, and the quality of the resulting design is dependent on the\nengineer's experience and domain expertise, which can easily be out-dated or\ninaccurate. The goal of this work is to use machine learning algorithms to\nautomate the design of task-specific gripper fingers. We propose Fit2Form, a 3D\ngenerative design framework that generates pairs of finger shapes to maximize\ndesign objectives (i.e., grasp success, stability, and robustness) for target\ngrasp objects. We model the design objectives by training a Fitness network to\npredict their values for pairs of gripper fingers and their corresponding grasp\nobjects. This Fitness network then provides supervision to a 3D Generative\nnetwork that produces a pair of 3D finger geometries for the target grasp\nobject. Our experiments demonstrate that the proposed 3D generative design\nframework generates parallel jaw gripper finger shapes that achieve more stable\nand robust grasps compared to other general-purpose and task-specific gripper\ndesign algorithms. Video can be found at https://youtu.be/utKHP3qb1bg.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:09:36 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Ha", "Huy", ""], ["Agrawal", "Shubham", ""], ["Song", "Shuran", ""]]}, {"id": "2011.06505", "submitter": "Jack Parker-Holder", "authors": "Jack Parker-Holder, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam\n  Lerer, Alistair Letcher, Alex Peysakhovich, Aldo Pacchiano, Jakob Foerster", "title": "Ridge Rider: Finding Diverse Solutions by Following Eigenvectors of the\n  Hessian", "comments": "Camera-ready version, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, a single algorithm has changed many facets of our lives\n- Stochastic Gradient Descent (SGD). In the era of ever decreasing loss\nfunctions, SGD and its various offspring have become the go-to optimization\ntool in machine learning and are a key component of the success of deep neural\nnetworks (DNNs). While SGD is guaranteed to converge to a local optimum (under\nloose assumptions), in some cases it may matter which local optimum is found,\nand this is often context-dependent. Examples frequently arise in machine\nlearning, from shape-versus-texture-features to ensemble methods and zero-shot\ncoordination. In these settings, there are desired solutions which SGD on\n'standard' loss functions will not find, since it instead converges to the\n'easy' solutions. In this paper, we present a different approach. Rather than\nfollowing the gradient, which corresponds to a locally greedy direction, we\ninstead follow the eigenvectors of the Hessian, which we call \"ridges\". By\niteratively following and branching amongst the ridges, we effectively span the\nloss surface to find qualitatively different solutions. We show both\ntheoretically and experimentally that our method, called Ridge Rider (RR),\noffers a promising direction for a variety of challenging problems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:15:09 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Parker-Holder", "Jack", ""], ["Metz", "Luke", ""], ["Resnick", "Cinjon", ""], ["Hu", "Hengyuan", ""], ["Lerer", "Adam", ""], ["Letcher", "Alistair", ""], ["Peysakhovich", "Alex", ""], ["Pacchiano", "Aldo", ""], ["Foerster", "Jakob", ""]]}, {"id": "2011.06507", "submitter": "Karl Schmeckpeper", "authors": "Karl Schmeckpeper, Oleh Rybkin, Kostas Daniilidis, Sergey Levine,\n  Chelsea Finn", "title": "Reinforcement Learning with Videos: Combining Offline Observations with\n  Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a powerful framework for robots to acquire skills\nfrom experience, but often requires a substantial amount of online data\ncollection. As a result, it is difficult to collect sufficiently diverse\nexperiences that are needed for robots to generalize broadly. Videos of humans,\non the other hand, are a readily available source of broad and interesting\nexperiences. In this paper, we consider the question: can we perform\nreinforcement learning directly on experience collected by humans? This problem\nis particularly difficult, as such videos are not annotated with actions and\nexhibit substantial visual domain shift relative to the robot's embodiment. To\naddress these challenges, we propose a framework for reinforcement learning\nwith videos (RLV). RLV learns a policy and value function using experience\ncollected by humans in combination with data collected by robots. In our\nexperiments, we find that RLV is able to leverage such videos to learn\nchallenging vision-based skills with less than half as many samples as RL\nmethods that learn from scratch.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:15:48 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Schmeckpeper", "Karl", ""], ["Rybkin", "Oleh", ""], ["Daniilidis", "Kostas", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "2011.06512", "submitter": "Angelica Louren\\c{c}o Oliveira", "authors": "Angelica Louren\\c{c}o Oliveira and Marcos Eduardo Valle", "title": "Linear Dilation-Erosion Perceptron Trained Using a Convex-Concave\n  Procedure", "comments": "10 pages, 2 figures, 12th International Conference on Soft Computing\n  and Pattern Recognition, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical morphology (MM) is a theory of non-linear operators used for the\nprocessing and analysis of images. Morphological neural networks (MNNs) are\nneural networks whose neurons compute morphological operators. Dilations and\nerosions are the elementary operators of MM. From an algebraic point of view, a\ndilation and an erosion are operators that commute respectively with the\nsupremum and infimum operations. In this paper, we present the \\textit{linear\ndilation-erosion perceptron} ($\\ell$-DEP), which is given by applying linear\ntransformations before computing a dilation and an erosion. The decision\nfunction of the $\\ell$-DEP model is defined by adding a dilation and an\nerosion. Furthermore, training a $\\ell$-DEP can be formulated as a\nconvex-concave optimization problem. We compare the performance of the\n$\\ell$-DEP model with other machine learning techniques using several\nclassification problems. The computational experiments support the potential\napplication of the proposed $\\ell$-DEP model for binary classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 18:37:07 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Oliveira", "Angelica Louren\u00e7o", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "2011.06528", "submitter": "Evan Munro", "authors": "Evan Munro", "title": "Learning to Personalize Treatments When Agents Are Strategic", "comments": "31 pages, 5 figures. NeurIPS 2020 Workshop on Consequential Decision\n  Making in Dynamic Environments", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing interest in allocating treatments based on observed\nindividual data: examples include heterogeneous pricing, individualized credit\noffers, and targeted social programs. Policy targeting introduces incentives\nfor individuals to modify their behavior to obtain a better treatment. We show\nstandard risk minimization-based estimators are sub-optimal when observed\ncovariates are endogenous to the treatment allocation rule. We propose a\ndynamic experiment that converges to the optimal treatment allocation function\nwithout parametric assumptions on individual strategic behavior, and prove that\nit has regret that decays at a linear rate. We validate the method in\nsimulations and in a small MTurk experiment.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:40:53 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 05:37:03 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 18:03:29 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Munro", "Evan", ""]]}, {"id": "2011.06531", "submitter": "Felix Hensel", "authors": "Sarah C. Br\\\"uningk, Felix Hensel, Catherine R. Jutzeler, Bastian\n  Rieck", "title": "Image analysis for Alzheimer's disease prediction: Embracing\n  pathological hallmarks for model architecture design", "comments": "8 pages, 1 figure, Machine Learning for Health (ML4H) at NeurIPS 2020\n  - Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is associated with local (e.g. brain tissue atrophy)\nand global brain changes (loss of cerebral connectivity), which can be detected\nby high-resolution structural magnetic resonance imaging. Conventionally, these\nchanges and their relation to AD are investigated independently. Here, we\nintroduce a novel, highly-scalable approach that simultaneously captures\n$\\textit{local}$ and $\\textit{global}$ changes in the diseased brain. It is\nbased on a neural network architecture that combines patch-based,\nhigh-resolution 3D-CNNs with global topological features, evaluating\nmulti-scale brain tissue connectivity. Our local-global approach reached\ncompetitive results with an average precision score of $0.95\\pm0.03$ for the\nclassification of cognitively normal subjects and AD patients (prevalence\n$\\approx 55\\%$).\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:42:49 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 13:49:31 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 08:50:41 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Br\u00fcningk", "Sarah C.", ""], ["Hensel", "Felix", ""], ["Jutzeler", "Catherine R.", ""], ["Rieck", "Bastian", ""]]}, {"id": "2011.06539", "submitter": "Thomas Pock", "authors": "Thomas Pinetz and Erich Kobler and Thomas Pock and Alexander Effland", "title": "Shared Prior Learning of Energy-Based Models for Image Reconstruction", "comments": "37 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NA eess.IV math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel learning-based framework for image reconstruction\nparticularly designed for training without ground truth data, which has three\nmajor building blocks: energy-based learning, a patch-based Wasserstein loss\nfunctional, and shared prior learning. In energy-based learning, the parameters\nof an energy functional composed of a learned data fidelity term and a\ndata-driven regularizer are computed in a mean-field optimal control problem.\nIn the absence of ground truth data, we change the loss functional to a\npatch-based Wasserstein functional, in which local statistics of the output\nimages are compared to uncorrupted reference patches. Finally, in shared prior\nlearning, both aforementioned optimal control problems are optimized\nsimultaneously with shared learned parameters of the regularizer to further\nenhance unsupervised image reconstruction. We derive several time\ndiscretization schemes of the gradient flow and verify their consistency in\nterms of Mosco convergence. In numerous numerical experiments, we demonstrate\nthat the proposed method generates state-of-the-art results for various image\nreconstruction applications--even if no ground truth images are available for\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:56:05 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 08:54:13 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Pinetz", "Thomas", ""], ["Kobler", "Erich", ""], ["Pock", "Thomas", ""], ["Effland", "Alexander", ""]]}, {"id": "2011.06550", "submitter": "Elvis Dohmatob", "authors": "Elvis Dohmatob", "title": "Implicit bias of any algorithm: bounding bias via margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider $n$ points $x_1,\\ldots,x_n$ in finite-dimensional euclidean space,\neach having one of two colors. Suppose there exists a separating hyperplane\n(identified with its unit normal vector $w)$ for the points, i.e a hyperplane\nsuch that points of same color lie on the same side of the hyperplane. We\nmeasure the quality of such a hyperplane by its margin $\\gamma(w)$, defined as\nminimum distance between any of the points $x_i$ and the hyperplane. In this\npaper, we prove that the margin function $\\gamma$ satisfies a nonsmooth\nKurdyka-Lojasiewicz inequality with exponent $1/2$. This result has\nfar-reaching consequences. For example, let $\\gamma^{opt}$ be the maximum\npossible margin for the problem and let $w^{opt}$ be the parameter for the\nhyperplane which attains this value. Given any other separating hyperplane with\nparameter $w$, let $d(w):=\\|w-w^{opt}\\|$ be the euclidean distance between $w$\nand $w^{opt}$, also called the bias of $w$. From the previous KL-inequality, we\ndeduce that $(\\gamma^{opt}-\\gamma(w)) / R \\le d(w) \\le\n2\\sqrt{(\\gamma^{opt}-\\gamma(w))/\\gamma^{opt}}$, where $R:=\\max_i \\|x_i\\|$ is\nthe maximum distance of the points $x_i$ from the origin. Consequently, for any\noptimization algorithm (gradient-descent or not), the bias of the iterates\nconverges at least as fast as the square-root of the rate of their convergence\nof the margin. Thus, our work provides a generic tool for analyzing the\nimplicit bias of any algorithm in terms of its margin, in situations where a\nspecialized analysis might not be available: it is sufficient to establish a\ngood rate for converge of the margin, a task which is usually much easier.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:09:46 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 10:52:59 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 18:59:22 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 17:12:06 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Dohmatob", "Elvis", ""]]}, {"id": "2011.06557", "submitter": "Hayden Helm", "authors": "Hayden S. Helm, Ronak D. Mehta, Brandon Duderstadt, Weiwei Yang,\n  Christoper M. White, Ali Geisa, Joshua T. Vogelstein, Carey E. Priebe", "title": "A partition-based similarity for classification distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein we define a measure of similarity between classification distributions\nthat is both principled from the perspective of statistical pattern recognition\nand useful from the perspective of machine learning practitioners. In\nparticular, we propose a novel similarity on classification distributions,\ndubbed task similarity, that quantifies how an optimally-transformed optimal\nrepresentation for a source distribution performs when applied to inference\nrelated to a target distribution. The definition of task similarity allows for\nnatural definitions of adversarial and orthogonal distributions. We highlight\nlimiting properties of representations induced by (universally) consistent\ndecision rules and demonstrate in simulation that an empirical estimate of task\nsimilarity is a function of the decision rule deployed for inference. We\ndemonstrate that for a given target distribution, both transfer efficiency and\nsemantic similarity of candidate source distributions correlate with empirical\ntask similarity.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:21:11 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Helm", "Hayden S.", ""], ["Mehta", "Ronak D.", ""], ["Duderstadt", "Brandon", ""], ["Yang", "Weiwei", ""], ["White", "Christoper M.", ""], ["Geisa", "Ali", ""], ["Vogelstein", "Joshua T.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2011.06572", "submitter": "Kevin Tian", "authors": "Michael B. Cohen, Aaron Sidford, Kevin Tian", "title": "Relative Lipschitzness in Extragradient Methods and a Direct Recipe for\n  Acceleration", "comments": "32 pages. This is the full version of a paper appearing in ITCS 2021.\n  v2 addresses reviewer comments and adds citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that standard extragradient methods (i.e. mirror prox and dual\nextrapolation) recover optimal accelerated rates for first-order minimization\nof smooth convex functions. To obtain this result we provide a fine-grained\ncharacterization of the convergence rates of extragradient methods for solving\nmonotone variational inequalities in terms of a natural condition we call\nrelative Lipschitzness. We further generalize this framework to handle local\nand randomized notions of relative Lipschitzness and thereby recover rates for\nbox-constrained $\\ell_\\infty$ regression based on area convexity and complexity\nbounds achieved by accelerated (randomized) coordinate descent for smooth\nconvex function minimization.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:43:40 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 03:01:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Cohen", "Michael B.", ""], ["Sidford", "Aaron", ""], ["Tian", "Kevin", ""]]}, {"id": "2011.06585", "submitter": "Gleb Novikov", "authors": "Tommaso d'Orsi, Pravesh K. Kothari, Gleb Novikov, David Steurer", "title": "Sparse PCA: Algorithms, Adversarial Perturbations and Certificates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study efficient algorithms for Sparse PCA in standard statistical models\n(spiked covariance in its Wishart form). Our goal is to achieve optimal\nrecovery guarantees while being resilient to small perturbations. Despite a\nlong history of prior works, including explicit studies of perturbation\nresilience, the best known algorithmic guarantees for Sparse PCA are fragile\nand break down under small adversarial perturbations.\n  We observe a basic connection between perturbation resilience and\n\\emph{certifying algorithms} that are based on certificates of upper bounds on\nsparse eigenvalues of random matrices. In contrast to other techniques, such\ncertifying algorithms, including the brute-force maximum likelihood estimator,\nare automatically robust against small adversarial perturbation.\n  We use this connection to obtain the first polynomial-time algorithms for\nthis problem that are resilient against additive adversarial perturbations by\nobtaining new efficient certificates for upper bounds on sparse eigenvalues of\nrandom matrices. Our algorithms are based either on basic semidefinite\nprogramming or on its low-degree sum-of-squares strengthening depending on the\nparameter regimes. Their guarantees either match or approach the best known\nguarantees of \\emph{fragile} algorithms in terms of sparsity of the unknown\nvector, number of samples and the ambient dimension.\n  To complement our algorithmic results, we prove rigorous lower bounds\nmatching the gap between fragile and robust polynomial-time algorithms in a\nnatural computational model based on low-degree polynomials (closely related to\nthe pseudo-calibration technique for sum-of-squares lower bounds) that is known\nto capture the best known guarantees for related statistical estimation\nproblems. The combination of these results provides formal evidence of an\ninherent price to pay to achieve robustness.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 18:58:51 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["d'Orsi", "Tommaso", ""], ["Kothari", "Pravesh K.", ""], ["Novikov", "Gleb", ""], ["Steurer", "David", ""]]}, {"id": "2011.06619", "submitter": "Annie Xie", "authors": "Annie Xie, Dylan P. Losey, Ryan Tolsma, Chelsea Finn, Dorsa Sadigh", "title": "Learning Latent Representations to Influence Multi-Agent Interaction", "comments": "Conference on Robot Learning (CoRL) 2020. Supplementary website at\n  https://sites.google.com/view/latent-strategies/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seamlessly interacting with humans or robots is hard because these agents are\nnon-stationary. They update their policy in response to the ego agent's\nbehavior, and the ego agent must anticipate these changes to co-adapt. Inspired\nby humans, we recognize that robots do not need to explicitly model every\nlow-level action another agent will make; instead, we can capture the latent\nstrategy of other agents through high-level representations. We propose a\nreinforcement learning-based framework for learning latent representations of\nan agent's policy, where the ego agent identifies the relationship between its\nbehavior and the other agent's future strategy. The ego agent then leverages\nthese latent dynamics to influence the other agent, purposely guiding them\ntowards policies suitable for co-adaptation. Across several simulated domains\nand a real-world air hockey game, our approach outperforms the alternatives and\nlearns to influence the other agent.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 19:04:26 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Xie", "Annie", ""], ["Losey", "Dylan P.", ""], ["Tolsma", "Ryan", ""], ["Finn", "Chelsea", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2011.06631", "submitter": "Bojun Huang", "authors": "Huang Bojun", "title": "Steady State Analysis of Episodic Reinforcement Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves that the episodic learning environment of every\nfinite-horizon decision task has a unique steady state under any behavior\npolicy, and that the marginal distribution of the agent's input indeed\nconverges to the steady-state distribution in essentially all episodic learning\nprocesses. This observation supports an interestingly reversed mindset against\nconventional wisdom: While the existence of unique steady states was often\npresumed in continual learning but considered less relevant in episodic\nlearning, it turns out their existence is guaranteed for the latter. Based on\nthis insight, the paper unifies episodic and continual RL around several\nimportant concepts that have been separately treated in these two RL\nformalisms. Practically, the existence of unique and approachable steady state\nenables a general way to collect data in episodic RL tasks, which the paper\napplies to policy gradient algorithms as a demonstration, based on a new\nsteady-state policy gradient theorem. Finally, the paper also proposes and\nexperimentally validates a perturbation method that facilitates rapid\nsteady-state convergence in real-world RL tasks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 19:34:59 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 17:40:34 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Bojun", "Huang", ""]]}, {"id": "2011.06654", "submitter": "Xingfu Wu", "authors": "Xingfu Wu and Valerie Taylor", "title": "Utilizing Ensemble Learning for Performance and Power Modeling and\n  Improvement of Parallel Cancer Deep Learning CANDLE Benchmarks", "comments": "to be published in Cray User Group Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning (ML) continues to grow in importance across nearly all\ndomains and is a natural tool in modeling to learn from data. Often a tradeoff\nexists between a model's ability to minimize bias and variance. In this paper,\nwe utilize ensemble learning to combine linear, nonlinear, and tree-/rule-based\nML methods to cope with the bias-variance tradeoff and result in more accurate\nmodels. Hardware performance counter values are correlated with properties of\napplications that impact performance and power on the underlying system. We use\nthe datasets collected for two parallel cancer deep learning CANDLE benchmarks,\nNT3 (weak scaling) and P1B2 (strong scaling), to build performance and power\nmodels based on hardware performance counters using single-object and\nmultiple-objects ensemble learning to identify the most important counters for\nimprovement. Based on the insights from these models, we improve the\nperformance and energy of P1B2 and NT3 by optimizing the deep learning\nenvironments TensorFlow, Keras, Horovod, and Python under the huge page size of\n8 MB on the Cray XC40 Theta at Argonne National Laboratory. Experimental\nresults show that ensemble learning not only produces more accurate models but\nalso provides more robust performance counter ranking. We achieve up to 61.15%\nperformance improvement and up to 62.58% energy saving for P1B2 and up to\n55.81% performance improvement and up to 52.60% energy saving for NT3 on up to\n24,576 cores.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 21:18:20 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Wu", "Xingfu", ""], ["Taylor", "Valerie", ""]]}, {"id": "2011.06655", "submitter": "Xingfu Wu", "authors": "Xingfu Wu, Valerie Taylor, and Zhiling Lan", "title": "Performance and Power Modeling and Prediction Using MuMMI and Ten\n  Machine Learning Methods", "comments": "to be published in Cray User Group Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we use modeling and prediction tool MuMMI (Multiple Metrics\nModeling Infrastructure) and ten machine learning methods to model and predict\nperformance and power and compare their prediction error rates. We use a\nfault-tolerant linear algebra code and a fault-tolerant heat distribution code\nto conduct our modeling and prediction study on the Cray XC40 Theta and IBM\nBG/Q Mira at Argonne National Laboratory and the Intel Haswell cluster Shepard\nat Sandia National Laboratories. Our experiment results show that the\nprediction error rates in performance and power using MuMMI are less than 10%\nfor most cases. Based on the models for runtime, node power, CPU power, and\nmemory power, we identify the most significant performance counters for\npotential optimization efforts associated with the application characteristics\nand the target architectures, and we predict theoretical outcomes of the\npotential optimizations. When we compare the prediction accuracy using MuMMI\nwith that using 10 machine learning methods, we observe that MuMMI not only\nresults in more accurate prediction in both performance and power but also\npresents how performance counters impact the performance and power models. This\nprovides some insights about how to fine-tune the applications and/or systems\nfor energy efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 21:24:11 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Wu", "Xingfu", ""], ["Taylor", "Valerie", ""], ["Lan", "Zhiling", ""]]}, {"id": "2011.06658", "submitter": "Shuhao Xia", "authors": "Shuhao Xia, Jingyang Zhu, Yuhan Yang, Yong Zhou, Yuanming Shi and Wei\n  Chen", "title": "Fast Convergence Algorithm for Analog Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider federated learning (FL) over a noisy fading\nmultiple access channel (MAC), where an edge server aggregates the local models\ntransmitted by multiple end devices through over-the-air computation (AirComp).\nTo realize efficient analog federated learning over wireless channels, we\npropose an AirComp-based FedSplit algorithm, where a threshold-based device\nselection scheme is adopted to achieve reliable local model uploading. In\nparticular, we analyze the performance of the proposed algorithm and prove that\nthe proposed algorithm linearly converges to the optimal solutions under the\nassumption that the objective function is strongly convex and smooth. We also\ncharacterize the robustness of proposed algorithm to the ill-conditioned\nproblems, thereby achieving fast convergence rates and reducing communication\nrounds. A finite error bound is further provided to reveal the relationship\nbetween the convergence behavior and the channel fading and noise. Our\nalgorithm is theoretically and experimentally verified to be much more robust\nto the ill-conditioned problems with faster convergence compared with other\nbenchmark FL algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 10:59:49 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Xia", "Shuhao", ""], ["Zhu", "Jingyang", ""], ["Yang", "Yuhan", ""], ["Zhou", "Yong", ""], ["Shi", "Yuanming", ""], ["Chen", "Wei", ""]]}, {"id": "2011.06673", "submitter": "Maysum Panju", "authors": "Maysum Panju, Kourosh Parand, Ali Ghodsi", "title": "Symbolically Solving Partial Differential Equations using Deep Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a neural-based method for generating exact or approximate\nsolutions to differential equations in the form of mathematical expressions.\nUnlike other neural methods, our system returns symbolic expressions that can\nbe interpreted directly. Our method uses a neural architecture for learning\nmathematical expressions to optimize a customizable objective, and is scalable,\ncompact, and easily adaptable for a variety of tasks and configurations. The\nsystem has been shown to effectively find exact or approximate symbolic\nsolutions to various differential equations with applications in natural\nsciences. In this work, we highlight how our method applies to partial\ndifferential equations over multiple variables and more complex boundary and\ninitial value conditions.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 22:16:03 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Panju", "Maysum", ""], ["Parand", "Kourosh", ""], ["Ghodsi", "Ali", ""]]}, {"id": "2011.06690", "submitter": "Zhengyu Zhao", "authors": "Zhengyu Zhao and Zhuoran Liu and Martha Larson", "title": "Adversarial Robustness Against Image Color Transformation within\n  Parametric Filter Space", "comments": "Code is available at\n  https://github.com/ZhengyuZhao/ACE/tree/master/Journal_version. This work has\n  been submitted to the IEEE for possible publication. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose Adversarial Color Enhancement (ACE), a novel approach to\ngenerating non-suspicious adversarial images by optimizing a color\ntransformation within a parametric filter space. The filter we use approximates\nhuman-understandable color curve adjustment, constraining ACE with a single,\ncontinuous function. This property gives rise to a principled adversarial\naction space explicitly controlled by filter parameters. Existing color\ntransformation attacks are not guided by a parametric space, and, consequently,\nadditional pixel-related constraints such as regularization and sampling are\nnecessary. These constraints make methodical analysis difficult. In this paper,\nwe carry out a systematic robustness analysis of ACE from both the attack and\ndefense perspectives by varying the bound of the color filter parameters. We\ninvestigate a general formulation of ACE and also a variant targeting\nparticularly appealing color styles, as achieved with popular image filters.\nFrom the attack perspective, we provide extensive experiments on the\nvulnerability of image classifiers, but also explore the vulnerability of\nsegmentation and aesthetic quality assessment algorithms, in both the white-box\nand black-box scenarios. From the defense perspective, more experiments provide\ninsight into the stability of ACE against input transformation-based defenses\nand show the potential of adversarial training for improving model robustness\nagainst ACE.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 23:51:37 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Zhao", "Zhengyu", ""], ["Liu", "Zhuoran", ""], ["Larson", "Martha", ""]]}, {"id": "2011.06698", "submitter": "Bryan Chen", "authors": "Bryan Chen, Alexander Sax, Gene Lewis, Iro Armeni, Silvio Savarese,\n  Amir Zamir, Jitendra Malik, Lerrel Pinto", "title": "Robust Policies via Mid-Level Visual Representations: An Experimental\n  Study in Manipulation and Navigation", "comments": "Extended version of CoRL 2020 camera ready. Supplementary released\n  separately", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based robotics often separates the control loop into one module for\nperception and a separate module for control. It is possible to train the whole\nsystem end-to-end (e.g. with deep RL), but doing it \"from scratch\" comes with a\nhigh sample complexity cost and the final result is often brittle, failing\nunexpectedly if the test environment differs from that of training.\n  We study the effects of using mid-level visual representations (features\nlearned asynchronously for traditional computer vision objectives), as a\ngeneric and easy-to-decode perceptual state in an end-to-end RL framework.\nMid-level representations encode invariances about the world, and we show that\nthey aid generalization, improve sample complexity, and lead to a higher final\nperformance. Compared to other approaches for incorporating invariances, such\nas domain randomization, asynchronously trained mid-level representations scale\nbetter: both to harder problems and to larger domain shifts. In practice, this\nmeans that mid-level representations could be used to successfully train\npolicies for tasks where domain randomization and learning-from-scratch failed.\nWe report results on both manipulation and navigation tasks, and for navigation\ninclude zero-shot sim-to-real experiments on real robots.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 00:16:05 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Chen", "Bryan", ""], ["Sax", "Alexander", ""], ["Lewis", "Gene", ""], ["Armeni", "Iro", ""], ["Savarese", "Silvio", ""], ["Zamir", "Amir", ""], ["Malik", "Jitendra", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2011.06700", "submitter": "Jun Zhang", "authors": "Jun Zhang, Yao-Kun Lei, Zhen Zhang, Xu Han, Maodong Li, Lijiang Yang,\n  Yi Isaac Yang and Yi Qin Gao", "title": "Deep Reinforcement Learning of Transition States", "comments": "version 1", "journal-ref": "Phys. Chem. Chem. Phys., 2021", "doi": "10.1039/D0CP06184K", "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining reinforcement learning (RL) and molecular dynamics (MD)\nsimulations, we propose a machine-learning approach (RL$^\\ddag$) to\nautomatically unravel chemical reaction mechanisms. In RL$^\\ddag$, locating the\ntransition state of a chemical reaction is formulated as a game, where a\nvirtual player is trained to shoot simulation trajectories connecting the\nreactant and product. The player utilizes two functions, one for value\nestimation and the other for policy making, to iteratively improve the chance\nof winning this game. We can directly interpret the reaction mechanism\naccording to the value function. Meanwhile, the policy function enables\nefficient sampling of the transition paths, which can be further used to\nanalyze the reaction dynamics and kinetics. Through multiple experiments, we\nshow that RL{\\ddag} can be trained tabula rasa hence allows us to reveal\nchemical reaction mechanisms with minimal subjective biases.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 00:22:14 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zhang", "Jun", ""], ["Lei", "Yao-Kun", ""], ["Zhang", "Zhen", ""], ["Han", "Xu", ""], ["Li", "Maodong", ""], ["Yang", "Lijiang", ""], ["Yang", "Yi Isaac", ""], ["Gao", "Yi Qin", ""]]}, {"id": "2011.06702", "submitter": "Cheng Chen", "authors": "Cheng Chen, Junjie Yang, Yi Zhou", "title": "Neural Network Training Techniques Regularize Optimization Trajectory:\n  An Empirical Study", "comments": "9 pages, 16 figures, this paper has been accepted as a short paper by\n  the conference of IEEE-bigdata-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural network (DNN) trainings utilize various training\ntechniques, e.g., nonlinear activation functions, batch normalization,\nskip-connections, etc. Despite their effectiveness, it is still mysterious how\nthey help accelerate DNN trainings in practice. In this paper, we provide an\nempirical study of the regularization effect of these training techniques on\nDNN optimization. Specifically, we find that the optimization trajectories of\nsuccessful DNN trainings consistently obey a certain regularity principle that\nregularizes the model update direction to be aligned with the trajectory\ndirection. Theoretically, we show that such a regularity principle leads to a\nconvergence guarantee in nonconvex optimization and the convergence rate\ndepends on a regularization parameter. Empirically, we find that DNN trainings\nthat apply the training techniques achieve a fast convergence and obey the\nregularity principle with a large regularization parameter, implying that the\nmodel updates are well aligned with the trajectory. On the other hand, DNN\ntrainings without the training techniques have slow convergence and obey the\nregularity principle with a small regularization parameter, implying that the\nmodel updates are not well aligned with the trajectory. Therefore, different\ntraining techniques regularize the model update direction via the regularity\nprinciple to facilitate the convergence.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 00:26:43 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Chen", "Cheng", ""], ["Yang", "Junjie", ""], ["Zhou", "Yi", ""]]}, {"id": "2011.06704", "submitter": "Troy Luhman", "authors": "Troy Luhman, Eric Luhman", "title": "Diffusion models for Handwriting Generation", "comments": "17 figures, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a diffusion probabilistic model for handwriting\ngeneration. Diffusion models are a class of generative models where samples\nstart from Gaussian noise and are gradually denoised to produce output. Our\nmethod of handwriting generation does not require using any text-recognition\nbased, writer-style based, or adversarial loss functions, nor does it require\ntraining of auxiliary networks. Our model is able to incorporate writer\nstylistic features directly from image data, eliminating the need for user\ninteraction during sampling. Experiments reveal that our model is able to\ngenerate realistic , high quality images of handwritten text in a similar style\nto a given writer. Our implementation can be found at\nhttps://github.com/tcl9876/Diffusion-Handwriting-Generation\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 00:31:22 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Luhman", "Troy", ""], ["Luhman", "Eric", ""]]}, {"id": "2011.06709", "submitter": "David Krueger", "authors": "David Krueger, Jan Leike, Owain Evans, John Salvatier", "title": "Active Reinforcement Learning: Observing Rewards at a Cost", "comments": "Originally appeared at the NeurIPS 2016 \"Future of Interactive\n  Learning Machines (FILM)\" workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active reinforcement learning (ARL) is a variant on reinforcement learning\nwhere the agent does not observe the reward unless it chooses to pay a query\ncost c > 0. The central question of ARL is how to quantify the long-term value\nof reward information. Even in multi-armed bandits, computing the value of this\ninformation is intractable and we have to rely on heuristics. We propose and\nevaluate several heuristic approaches for ARL in multi-armed bandits and\n(tabular) Markov decision processes, and discuss and illustrate some\nchallenging aspects of the ARL problem.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 01:01:13 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 21:47:29 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Krueger", "David", ""], ["Leike", "Jan", ""], ["Evans", "Owain", ""], ["Salvatier", "John", ""]]}, {"id": "2011.06716", "submitter": "Sha Lu", "authors": "Sha Lu, Lin Liu, Jiuyong Li, Thuc Duy Le, Jixue Liu", "title": "Dependency-based Anomaly Detection: Framework, Methods and Benchmark", "comments": "39 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anomaly detection is an important research problem because anomalies often\ncontain critical insights for understanding the unusual behavior in data. One\ntype of anomaly detection approach is dependency-based, which identifies\nanomalies by examining the violations of the normal dependency among variables.\nThese methods can discover subtle and meaningful anomalies with better\ninterpretation. Existing dependency-based methods adopt different\nimplementations and show different strengths and weaknesses. However, the\ntheoretical fundamentals and the general process behind them have not been well\nstudied. This paper proposes a general framework, DepAD, to provide a unified\nprocess for dependency-based anomaly detection. DepAD decomposes unsupervised\nanomaly detection tasks into feature selection and prediction problems.\nUtilizing off-the-shelf techniques, the DepAD framework can have various\ninstantiations to suit different application domains. Comprehensive experiments\nhave been conducted over one hundred instantiated DepAD methods with 32\nreal-world datasets to evaluate the performance of representative techniques in\nDepAD. To show the effectiveness of DepAD, we compare two DepAD methods with\nnine state-of-the-art anomaly detection methods, and the results show that\nDepAD methods outperform comparison methods in most cases. Through the DepAD\nframework, this paper gives guidance and inspiration for future research of\ndependency-based anomaly detection and provides a benchmark for its evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 01:39:44 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Lu", "Sha", ""], ["Liu", "Lin", ""], ["Li", "Jiuyong", ""], ["Le", "Thuc Duy", ""], ["Liu", "Jixue", ""]]}, {"id": "2011.06718", "submitter": "Jie Shi", "authors": "Jie Shi, Brandon Foggo, Nanpeng Yu", "title": "Power System Event Identification based on Deep Neural Network with\n  Information Loading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online power system event identification and classification is crucial to\nenhancing the reliability of transmission systems. In this paper, we develop a\ndeep neural network (DNN) based approach to identify and classify power system\nevents by leveraging real-world measurements from hundreds of phasor\nmeasurement units (PMUs) and labels from thousands of events. Two innovative\ndesigns are embedded into the baseline model built on convolutional neural\nnetworks (CNNs) to improve the event classification accuracy. First, we propose\na graph signal processing based PMU sorting algorithm to improve the learning\nefficiency of CNNs. Second, we deploy information loading based regularization\nto strike the right balance between memorization and generalization for the\nDNN. Numerical studies results based on real-world dataset from the Eastern\nInterconnection of the U.S power transmission grid show that the combination of\nPMU based sorting and the information loading based regularization techniques\nhelp the proposed DNN approach achieve highly accurate event identification and\nclassification results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 01:53:03 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 21:48:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Shi", "Jie", ""], ["Foggo", "Brandon", ""], ["Yu", "Nanpeng", ""]]}, {"id": "2011.06719", "submitter": "Liyiming Ke", "authors": "Liyiming Ke, Jingqiang Wang, Tapomayukh Bhattacharjee, Byron Boots and\n  Siddhartha Srinivasa", "title": "Grasping with Chopsticks: Combating Covariate Shift in Model-free\n  Imitation Learning for Fine Manipulation", "comments": "Submitted to ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Billions of people use chopsticks, a simple yet versatile tool, for fine\nmanipulation of everyday objects. The small, curved, and slippery tips of\nchopsticks pose a challenge for picking up small objects, making them a\nsuitably complex test case. This paper leverages human demonstrations to\ndevelop an autonomous chopsticks-equipped robotic manipulator. Due to the lack\nof accurate models for fine manipulation, we explore model-free imitation\nlearning, which traditionally suffers from the covariate shift phenomenon that\ncauses poor generalization. We propose two approaches to reduce covariate\nshift, neither of which requires access to an interactive expert or a model,\nunlike previous approaches. First, we alleviate single-step prediction errors\nby applying an invariant operator to increase the data support at critical\nsteps for grasping. Second, we generate synthetic corrective labels by adding\nbounded noise and combining parametric and non-parametric methods to prevent\nerror accumulation. We demonstrate our methods on a real chopstick-equipped\nrobot that we built, and observe the agent's success rate increase from 37.3%\nto 80%, which is comparable to the human expert performance of 82.6%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 01:54:01 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ke", "Liyiming", ""], ["Wang", "Jingqiang", ""], ["Bhattacharjee", "Tapomayukh", ""], ["Boots", "Byron", ""], ["Srinivasa", "Siddhartha", ""]]}, {"id": "2011.06722", "submitter": "Pankaj Roy", "authors": "Pankaj Raj Roy, Guillaume-Alexandre Bilodeau and Lama Seoud", "title": "Local Anomaly Detection in Videos using Object-Centric Adversarial\n  Learning", "comments": "Accepted for The First International Workshop on Deep Learning for\n  Human-Centric Activity Understanding (ICPR2020 workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel unsupervised approach based on a two-stage object-centric\nadversarial framework that only needs object regions for detecting frame-level\nlocal anomalies in videos. The first stage consists in learning the\ncorrespondence between the current appearance and past gradient images of\nobjects in scenes deemed normal, allowing us to either generate the past\ngradient from current appearance or the reverse. The second stage extracts the\npartial reconstruction errors between real and generated images (appearance and\npast gradient) with normal object behaviour, and trains a discriminator in an\nadversarial fashion. In inference mode, we employ the trained image generators\nwith the adversarially learned binary classifier for outputting region-level\nanomaly detection scores. We tested our method on four public benchmarks, UMN,\nUCSD, Avenue and ShanghaiTech and our proposed object-centric adversarial\napproach yields competitive or even superior results compared to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:02:37 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Roy", "Pankaj Raj", ""], ["Bilodeau", "Guillaume-Alexandre", ""], ["Seoud", "Lama", ""]]}, {"id": "2011.06725", "submitter": "Olakunle Ibitoye", "authors": "Olakunle Ibitoye, Ashraf Matrawy, and M. Omair Shafiq", "title": "A GAN-based Approach for Mitigating Inference Attacks in Smart Home\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of smart, connected, always listening devices have\nintroduced significant privacy risks to users in a smart home environment.\nBeyond the notable risk of eavesdropping, intruders can adopt machine learning\ntechniques to infer sensitive information from audio recordings on these\ndevices, resulting in a new dimension of privacy concerns and attack variables\nto smart home users. Techniques such as sound masking and microphone jamming\nhave been effectively used to prevent eavesdroppers from listening in to\nprivate conversations. In this study, we explore the problem of adversaries\nspying on smart home users to infer sensitive information with the aid of\nmachine learning techniques. We then analyze the role of randomness in the\neffectiveness of sound masking for mitigating sensitive information leakage. We\npropose a Generative Adversarial Network (GAN) based approach for privacy\npreservation in smart homes which generates random noise to distort the\nunwanted machine learning-based inference. Our experimental results demonstrate\nthat GANs can be used to generate more effective sound masking noise signals\nwhich exhibit more randomness and effectively mitigate deep learning-based\ninference attacks while preserving the semantics of the audio samples.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:14:32 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ibitoye", "Olakunle", ""], ["Matrawy", "Ashraf", ""], ["Shafiq", "M. Omair", ""]]}, {"id": "2011.06733", "submitter": "Vivswan Shitole", "authors": "Vivswan Shitole, Li Fuxin, Minsuk Kahng, Prasad Tadepalli, Alan Fern", "title": "Structured Attention Graphs for Understanding Deep Image Classifications", "comments": "26 pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention maps are a popular way of explaining the decisions of convolutional\nnetworks for image classification. Typically, for each image of interest, a\nsingle attention map is produced, which assigns weights to pixels based on\ntheir importance to the classification. A single attention map, however,\nprovides an incomplete understanding since there are often many other maps that\nexplain a classification equally well. In this paper, we introduce structured\nattention graphs (SAGs), which compactly represent sets of attention maps for\nan image by capturing how different combinations of image regions impact a\nclassifier's confidence. We propose an approach to compute SAGs and a\nvisualization for SAGs so that deeper insight can be gained into a classifier's\ndecisions. We conduct a user study comparing the use of SAGs to traditional\nattention maps for answering counterfactual questions about image\nclassifications. Our results show that the users are more correct when\nanswering comparative counterfactual questions based on SAGs compared to the\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:51:54 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:56:28 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Shitole", "Vivswan", ""], ["Fuxin", "Li", ""], ["Kahng", "Minsuk", ""], ["Tadepalli", "Prasad", ""], ["Fern", "Alan", ""]]}, {"id": "2011.06735", "submitter": "Ayush Manish Agrawal", "authors": "Ayush Manish Agrawal, Atharva Tendle, Harshvardhan Sikka, Sahib Singh,\n  and Amr Kayid", "title": "Investigating Learning in Deep Neural Networks using Layer-Wise Weight\n  Change", "comments": "14 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the per-layer learning dynamics of deep neural networks is of\nsignificant interest as it may provide insights into how neural networks learn\nand the potential for better training regimens. We investigate learning in Deep\nConvolutional Neural Networks (CNNs) by measuring the relative weight change of\nlayers while training. Several interesting trends emerge in a variety of CNN\narchitectures across various computer vision classification tasks, including\nthe overall increase in relative weight change of later layers as compared to\nearlier ones.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:53:41 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 04:26:29 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Agrawal", "Ayush Manish", ""], ["Tendle", "Atharva", ""], ["Sikka", "Harshvardhan", ""], ["Singh", "Sahib", ""], ["Kayid", "Amr", ""]]}, {"id": "2011.06738", "submitter": "Qian Hu", "authors": "Qian Hu, Huzefa Rangwala", "title": "Metric-Free Individual Fairness with Cooperative Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data mining algorithms are increasingly used in automated decision making\nacross all walks of daily life. Unfortunately, as reported in several studies\nthese algorithms inject bias from data and environment leading to inequitable\nand unfair solutions. To mitigate bias in machine learning, different\nformalizations of fairness have been proposed that can be categorized into\ngroup fairness and individual fairness. Group fairness requires that different\ngroups should be treated similarly which might be unfair to some individuals\nwithin a group. On the other hand, individual fairness requires that similar\nindividuals be treated similarly. However, individual fairness remains\nunderstudied due to its reliance on problem-specific similarity metrics. We\npropose a metric-free individual fairness and a cooperative contextual bandits\n(CCB) algorithm. The CCB algorithm utilizes fairness as a reward and attempts\nto maximize it. The advantage of treating fairness as a reward is that the\nfairness criterion does not need to be differentiable. The proposed algorithm\nis tested on multiple real-world benchmark datasets. The results show the\neffectiveness of the proposed algorithm at mitigating bias and at achieving\nboth individual and group fairness.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 03:10:35 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Hu", "Qian", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2011.06739", "submitter": "Nadee Seneviratne", "authors": "Nadee Seneviratne, Carol Espy-Wilson", "title": "Generalized Dilated CNN Models for Depression Detection Using Inverted\n  Vocal Tract Variables", "comments": "5 pages, Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression detection using vocal biomarkers is a highly researched area.\nArticulatory coordination features (ACFs) are developed based on the changes in\nneuromotor coordination due to psychomotor slowing, a key feature of Major\nDepressive Disorder. However findings of existing studies are mostly validated\non a single database which limits the generalizability of results. Variability\nacross different depression databases adversely affects the results in cross\ncorpus evaluations (CCEs). We propose to develop a generalized classifier for\ndepression detection using a dilated Convolutional Neural Network which is\ntrained on ACFs extracted from two depression databases. We show that ACFs\nderived from Vocal Tract Variables (TVs) show promise as a robust set of\nfeatures for depression detection. Our model achieves relative accuracy\nimprovements of ~10% compared to CCEs performed on models trained on a single\ndatabase. We extend the study to show that fusing TVs and Mel-Frequency\nCepstral Coefficients can further improve the performance of this classifier.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 03:12:36 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 17:23:15 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 04:29:46 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Seneviratne", "Nadee", ""], ["Espy-Wilson", "Carol", ""]]}, {"id": "2011.06741", "submitter": "Liu Leqi", "authors": "Liu Leqi, Fatma Kilinc-Karzan, Zachary C. Lipton, Alan L. Montgomery", "title": "Rebounding Bandits for Modeling Satiation Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of psychological research shows that enjoyment of many goods is\nsubject to satiation, with short-term satisfaction declining after repeated\nexposures to the same item. Nevertheless, proposed algorithms for powering\nrecommender systems seldom model these dynamics, instead proceeding as though\nuser preferences were fixed in time. In this work, we adopt a multi-armed\nbandit setup, modeling satiation dynamics as a time-invariant linear dynamical\nsystem. In our model, the expected rewards for each arm decline monotonically\nwith consecutive exposures to the same item and rebound towards the initial\nreward whenever that arm is not pulled. We analyze this model, showing that\nwhen the arms exhibit identical deterministic dynamics, our problem is\nequivalent to a specific instance of Max K-Cut. In this case, a greedy policy,\nwhich plays the arms in a cyclic order, is optimal. To handle the case when the\nparameters governing the satiation dynamics can vary across arms, we propose a\nlookahead policy that generalizes the greedy policy. When the satiation\ndynamics are stochastic and governed by different (unknown) parameters, we\npropose an algorithm that first uses offline data to identify an affine\ndynamical system specified by the reward model and then plans using the\nlookahead policy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 03:17:29 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 15:56:57 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Leqi", "Liu", ""], ["Kilinc-Karzan", "Fatma", ""], ["Lipton", "Zachary C.", ""], ["Montgomery", "Alan L.", ""]]}, {"id": "2011.06742", "submitter": "Hamidreza Arian", "authors": "Hamidreza Arian, Mehrdad Moghimi, Ehsan Tabatabaei, Shiva Zamani", "title": "Encoded Value-at-Risk: A Predictive Machine for Financial Risk\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring risk is at the center of modern financial risk management. As the\nworld economy is becoming more complex and standard modeling assumptions are\nviolated, the advanced artificial intelligence solutions may provide the right\ntools to analyze the global market. In this paper, we provide a novel approach\nfor measuring market risk called Encoded Value-at-Risk (Encoded VaR), which is\nbased on a type of artificial neural network, called Variational Auto-encoders\n(VAEs). Encoded VaR is a generative model which can be used to reproduce market\nscenarios from a range of historical cross-sectional stock returns, while\nincreasing the signal-to-noise ratio present in the financial data, and\nlearning the dependency structure of the market without any assumptions about\nthe joint distribution of stock returns. We compare Encoded VaR out-of-sample\nresults with eleven other methods and show that it is competitive to many other\nwell-known VaR algorithms presented in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 03:25:35 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Arian", "Hamidreza", ""], ["Moghimi", "Mehrdad", ""], ["Tabatabaei", "Ehsan", ""], ["Zamani", "Shiva", ""]]}, {"id": "2011.06752", "submitter": "Jiajun Fan", "authors": "Jiajun Fan, He Ba, Xian Guo, Jianye Hao", "title": "Critic PI2: Master Continuous Planning via Policy Improvement with Path\n  Integrals and Deep Actor-Critic Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing agents with planning capabilities has long been one of the main\nchallenges in the pursuit of artificial intelligence. Tree-based planning\nmethods from AlphaGo to Muzero have enjoyed huge success in discrete domains,\nsuch as chess and Go. Unfortunately, in real-world applications like robot\ncontrol and inverted pendulum, whose action space is normally continuous, those\ntree-based planning techniques will be struggling. To address those\nlimitations, in this paper, we present a novel model-based reinforcement\nlearning frameworks called Critic PI2, which combines the benefits from\ntrajectory optimization, deep actor-critic learning, and model-based\nreinforcement learning. Our method is evaluated for inverted pendulum models\nwith applicability to many continuous control systems. Extensive experiments\ndemonstrate that Critic PI2 achieved a new state of the art in a range of\nchallenging continuous domains. Furthermore, we show that planning with a\ncritic significantly increases the sample efficiency and real-time performance.\nOur work opens a new direction toward learning the components of a model-based\nplanning system and how to use them.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 04:14:40 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Fan", "Jiajun", ""], ["Ba", "He", ""], ["Guo", "Xian", ""], ["Hao", "Jianye", ""]]}, {"id": "2011.06764", "submitter": "Nishant Mohanty", "authors": "Nishant Mohanty and Suresh Sundaram", "title": "Scaffolding Reflection in Reinforcement Learning Framework for\n  Confinement Escape Problem", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel Scaffolding Reflection in Reinforcement Learning\n(SR2L) is proposed for solving the confinement escape problem (CEP). In CEP, an\nevader's objective is to attempt escaping a confinement region patrolled by\nmultiple pursuers. Meanwhile, the pursuers aim to reach and capture the evader.\nThe inverse solution for pursuers to try and capture has been extensively\nstudied in the literature. However, the problem of evaders escaping from the\nregion is still an open issue. The SR2L employs an actor-critic framework to\nenable the evader to escape the confinement region. A time-varying state\nrepresentation and reward function have been developed for proper convergence.\nThe formulation uses the sensor information about the observable environment\nand prior knowledge of the confinement boundary. The conventional Independent\nActor-Critic (IAC) method fails to converge due to sparseness in the reward.\nThe effect becomes evident when operating in such a dynamic environment with a\nlarge area. In SR2L, along with the developed reward function, we use the\nscaffolding reflection method to improve the convergence significantly while\nincreasing its efficiency. In SR2L, a motion planner is used as a scaffold for\nthe actor-critic network to observe, compare and learn the action-reward pair.\nIt enables the evader to achieve the required objective while using lesser\nresources and time. Convergence studies show that SR2L learns faster and\nconverges to higher rewards as compared to IAC. Extensive Monte-Carlo\nsimulations show that a SR2L consistently outperforms conventional IAC and the\nmotion planner itself as the baselines.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 05:19:22 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 14:32:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Mohanty", "Nishant", ""], ["Sundaram", "Suresh", ""]]}, {"id": "2011.06769", "submitter": "Dong Keun Oh", "authors": "Dong Keun Oh", "title": "Toward the Fully Physics-Informed Echo State Network -- an ODE\n  Approximator Based on Recurrent Artificial Neurons", "comments": "30 pages, 12 figures, research paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Inspired by recent theoretical arguments, physics-informed echo state network\n(ESN) is discussed on the attempt to train a reservoir model absolutely in\nphysics-informed manner. As the plainest work on such a purpose, an ODE\n(ordinary differential equation) approximator is designed to replicate the\nsolution in sequence with respect to the recurrent evaluations. On the\nprincipal invariance of differential equations, the constraint in recurrence\njust takes shape to secure a proper regression method for the ESN-based ODE\napproximator. After then, the actual training process is established on the\nidea of two-pass strategy for regression. Aiming at the fully physics-informed\nreservoir model, a couple of nonlinear dynamical problems are demonstrated as\nthe computations obtained from the proposed method in this study.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 05:43:46 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Oh", "Dong Keun", ""]]}, {"id": "2011.06775", "submitter": "Peide Cai", "authors": "Peide Cai, Hengli Wang, Yuxiang Sun, Ming Liu", "title": "DiGNet: Learning Scalable Self-Driving Policies for Generic Traffic\n  Scenarios with Graph Neural Networks", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional modular self-driving frameworks scale poorly in new scenarios,\nwhich usually require tedious hand-tuning of rules and parameters to maintain\nacceptable performance in all foreseeable occasions. Therefore, robust and safe\nself-driving using traditional frameworks is still challenging, especially in\ncomplex and dynamic environments. Recently, deep-learning based self-driving\nmethods have shown promising results with better generalization capability but\nless hand engineering effort. However, most of the previous learning-based\nmethods are trained and evaluated in limited driving scenarios with scattered\ntasks, such as lane-following, autonomous braking, and conditional driving. In\nthis paper, we propose a graph-based deep network to achieve scalable\nself-driving that can handle massive traffic scenarios. Specifically, more than\n7,000 km of evaluation is conducted in a high-fidelity driving simulator, in\nwhich our method can obey the traffic rules and safely navigate the vehicle in\na large variety of urban, rural, and highway environments, including\nunprotected left turns, narrow roads, roundabouts, and pedestrian-rich\nintersections. The results also show that our method achieves better\nperformance over the baselines in terms of success rate. This work is\naccompanied with some demonstration videos which are available at\nhttps://sites.google.com/view/dignet-self-driving/video-clips/\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 06:13:28 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 07:27:30 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Cai", "Peide", ""], ["Wang", "Hengli", ""], ["Sun", "Yuxiang", ""], ["Liu", "Ming", ""]]}, {"id": "2011.06776", "submitter": "Sung Eun Kim Dr.", "authors": "Sung Eun Kim, Hongkyu Yoon, and Jonghyun Lee", "title": "Fast and Scalable Earth Texture Synthesis using Spatially Assembled\n  Generative Adversarial Neural Networks", "comments": "17 pages, 11 figures, 2 tables, and a table in Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV physics.flu-dyn", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The earth texture with complex morphological geometry and compositions such\nas shale and carbonate rocks, is typically characterized with sparse field\nsamples because of an expensive and time-consuming characterization process.\nAccordingly, generating arbitrary large size of the geological texture with\nsimilar topological structures at a low computation cost has become one of the\nkey tasks for realistic geomaterial reconstruction. Recently, generative\nadversarial neural networks (GANs) have demonstrated a potential of\nsynthesizing input textural images and creating equiprobable geomaterial\nimages. However, the texture synthesis with the GANs framework is often limited\nby the computational cost and scalability of the output texture size. In this\nstudy, we proposed a spatially assembled GANs (SAGANs) that can generate output\nimages of an arbitrary large size regardless of the size of training images\nwith computational efficiency. The performance of the SAGANs was evaluated with\ntwo and three dimensional (2D and 3D) rock image samples widely used in\ngeostatistical reconstruction of the earth texture. We demonstrate SAGANs can\ngenerate the arbitrary large size of statistical realizations with connectivity\nand structural properties similar to training images, and also can generate a\nvariety of realizations even on a single training image. In addition, the\ncomputational time was significantly improved compared to standard GANs\nframeworks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 06:18:09 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Kim", "Sung Eun", ""], ["Yoon", "Hongkyu", ""], ["Lee", "Jonghyun", ""]]}, {"id": "2011.06777", "submitter": "Yufei Wang", "authors": "Yufei Wang, Gautham Narayan Narasimhan, Xingyu Lin, Brian Okorn, David\n  Held", "title": "ROLL: Visual Self-Supervised Reinforcement Learning with Object\n  Reasoning", "comments": "CoRL 2020. The first two authors contributed equally. Project video\n  and code are available at https://sites.google.com/andrew.cmu.edu/roll", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current image-based reinforcement learning (RL) algorithms typically operate\non the whole image without performing object-level reasoning. This leads to\ninefficient goal sampling and ineffective reward functions. In this paper, we\nimprove upon previous visual self-supervised RL by incorporating object-level\nreasoning and occlusion reasoning. Specifically, we use unknown object\nsegmentation to ignore distractors in the scene for better reward computation\nand goal generation; we further enable occlusion reasoning by employing a novel\nauxiliary loss and training scheme. We demonstrate that our proposed algorithm,\nROLL (Reinforcement learning with Object Level Learning), learns dramatically\nfaster and achieves better final performance compared with previous methods in\nseveral simulated visual control tasks. Project video and code are available at\nhttps://sites.google.com/andrew.cmu.edu/roll.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 06:21:56 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Wang", "Yufei", ""], ["Narasimhan", "Gautham Narayan", ""], ["Lin", "Xingyu", ""], ["Okorn", "Brian", ""], ["Held", "David", ""]]}, {"id": "2011.06782", "submitter": "Krishnateja Killamsetty", "authors": "Krishnateja Killamsetty, Changbin Li, Chen Zhao, Rishabh Iyer, Feng\n  Chen", "title": "A Reweighted Meta Learning Framework for Robust Few Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-Agnostic Meta-Learning (MAML) is a popular gradient-based meta-learning\nframework that tries to find an optimal initialization to minimize the expected\nloss across all tasks during meta-training. However, it inherently assumes that\nthe contribution of each instance/task to the meta-learner is equal. Therefore,\nit fails to address the problem of domain differences between base and novel\nclasses in few-shot learning. In this work, we propose a novel and robust\nmeta-learning algorithm, called RW-MAML, which learns to assign weights to\ntraining instances or tasks. We consider these weights to be hyper-parameters.\nHence, we iteratively optimize the weights using a small set of validation\ntasks and an online approximation in a \\emph{bi-bi-level} optimization\nframework, in contrast to the standard bi-level optimization in MAML.\nTherefore, we investigate a practical evaluation setting to demonstrate the\nscalability of our RW-MAML in two scenarios: (1) out-of-distribution tasks and\n(2) noisy labels in the meta-training stage. Extensive experiments on synthetic\nand real-world datasets demonstrate that our framework efficiently mitigates\nthe effects of \"unwanted\" instances, showing that our proposed technique\nsignificantly outperforms state-of-the-art robust meta-learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 06:41:22 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Killamsetty", "Krishnateja", ""], ["Li", "Changbin", ""], ["Zhao", "Chen", ""], ["Iyer", "Rishabh", ""], ["Chen", "Feng", ""]]}, {"id": "2011.06791", "submitter": "Giulia Cisotto", "authors": "Giulia Bressan, Selina C. Wriessnegger, Giulia Cisotto", "title": "Deep learning-based classification of fine hand movements from low\n  frequency EEG", "comments": null, "journal-ref": null, "doi": "10.3390/fi13050103", "report-no": null, "categories": "eess.SP cs.AI cs.HC cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of different fine hand movements from EEG signals\nrepresents a relevant research challenge, e.g., in brain-computer interface\napplications for motor rehabilitation. Here, we analyzed two different datasets\nwhere fine hand movements (touch, grasp, palmar and lateral grasp) were\nperformed in a self-paced modality. We trained and tested a newly proposed\nconvolutional neural network (CNN), and we compared its classification\nperformance into respect to two well-established machine learning models,\nnamely, a shrinked-LDA and a Random Forest. Compared to previous literature, we\ntook advantage of the knowledge of the neuroscience field, and we trained our\nCNN model on the so-called Movement Related Cortical Potentials (MRCPs)s. They\nare EEG amplitude modulations at low frequencies, i.e., (0.3, 3) Hz, that have\nbeen proved to encode several properties of the movements, e.g., type of grasp,\nforce level and speed. We showed that CNN achieved good performance in both\ndatasets and they were similar or superior to the baseline models. Also,\ncompared to the baseline, our CNN requires a lighter and faster pre-processing\nprocedure, paving the way for its possible use in an online modality, e.g., for\nmany brain-computer interface applications.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 07:16:06 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 08:45:45 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Bressan", "Giulia", ""], ["Wriessnegger", "Selina C.", ""], ["Cisotto", "Giulia", ""]]}, {"id": "2011.06794", "submitter": "Gilles Blanchard", "authors": "Hannah Marienwald (TUB), Jean-Baptiste Fermanian (ENS Rennes), Gilles\n  Blanchard (DATASHAPE, LMO, CNRS)", "title": "High-Dimensional Multi-Task Averaging and Application to Kernel Mean\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an improved estimator for the multi-task averaging problem, whose\ngoal is the joint estimation of the means of multiple distributions using\nseparate, independent data sets. The naive approach is to take the empirical\nmean of each data set individually, whereas the proposed method exploits\nsimilarities between tasks, without any related information being known in\nadvance. First, for each data set, similar or neighboring means are determined\nfrom the data by multiple testing. Then each naive estimator is shrunk towards\nthe local average of its neighbors. We prove theoretically that this approach\nprovides a reduction in mean squared error. This improvement can be significant\nwhen the dimension of the input space is large, demonstrating a \"blessing of\ndimensionality\" phenomenon. An application of this approach is the estimation\nof multiple kernel mean embeddings, which plays an important role in many\nmodern applications. The theoretical results are verified on artificial and\nreal world data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 07:31:30 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Marienwald", "Hannah", "", "TUB"], ["Fermanian", "Jean-Baptiste", "", "ENS Rennes"], ["Blanchard", "Gilles", "", "DATASHAPE, LMO, CNRS"]]}, {"id": "2011.06796", "submitter": "Lijing Wang", "authors": "Lijing Wang, Dipanjan Ghosh, Maria Teresa Gonzalez Diaz, Ahmed\n  Farahat, Mahbubul Alam, Chetan Gupta, Jiangzhuo Chen, Madhav Marathe", "title": "Wisdom of the Ensemble: Improving Consistency of Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning classifiers are assisting humans in making decisions and hence\nthe user's trust in these models is of paramount importance. Trust is often a\nfunction of constant behavior. From an AI model perspective it means given the\nsame input the user would expect the same output, especially for correct\noutputs, or in other words consistently correct outputs. This paper studies a\nmodel behavior in the context of periodic retraining of deployed models where\nthe outputs from successive generations of the models might not agree on the\ncorrect labels assigned to the same input. We formally define consistency and\ncorrect-consistency of a learning model. We prove that consistency and\ncorrect-consistency of an ensemble learner is not less than the average\nconsistency and correct-consistency of individual learners and\ncorrect-consistency can be improved with a probability by combining learners\nwith accuracy not less than the average accuracy of ensemble component\nlearners. To validate the theory using three datasets and two state-of-the-art\ndeep learning classifiers we also propose an efficient dynamic snapshot\nensemble method and demonstrate its value.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 07:47:01 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Wang", "Lijing", ""], ["Ghosh", "Dipanjan", ""], ["Diaz", "Maria Teresa Gonzalez", ""], ["Farahat", "Ahmed", ""], ["Alam", "Mahbubul", ""], ["Gupta", "Chetan", ""], ["Chen", "Jiangzhuo", ""], ["Marathe", "Madhav", ""]]}, {"id": "2011.06798", "submitter": "Jiajun Zhang", "authors": "Jiajun Zhang, Pengyuan Ren and Jianmin Li", "title": "Deep Template Matching for Pedestrian Attribute Recognition with the\n  Auxiliary Supervision of Attribute-wise Keypoints", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pedestrian Attribute Recognition (PAR) has aroused extensive attention due to\nits important role in video surveillance scenarios. In most cases, the\nexistence of a particular attribute is strongly related to a partial region.\nRecent works design complicated modules, e.g., attention mechanism and proposal\nof body parts to localize the attribute corresponding region. These works\nfurther prove that localization of attribute specific regions precisely will\nhelp in improving performance. However, these part-information-based methods\nare still not accurate as well as increasing model complexity which makes it\nhard to deploy on realistic applications. In this paper, we propose a Deep\nTemplate Matching based method to capture body parts features with less\ncomputation. Further, we also proposed an auxiliary supervision method that use\nhuman pose keypoints to guide the learning toward discriminative local cues.\nExtensive experiments show that the proposed method outperforms and has lower\ncomputational complexity, compared with the state-of-the-art approaches on\nlarge-scale pedestrian attribute datasets, including PETA, PA-100K, RAP, and\nRAPv2 zs.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 07:52:26 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Zhang", "Jiajun", ""], ["Ren", "Pengyuan", ""], ["Li", "Jianmin", ""]]}, {"id": "2011.06801", "submitter": "Shulei Ji", "authors": "Shulei Ji, Jing Luo, Xinyu Yang", "title": "A Comprehensive Survey on Deep Music Generation: Multi-level\n  Representations, Algorithms, Evaluations, and Future Directions", "comments": "96 pages,this is a draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utilization of deep learning techniques in generating various contents\n(such as image, text, etc.) has become a trend. Especially music, the topic of\nthis paper, has attracted widespread attention of countless researchers.The\nwhole process of producing music can be divided into three stages,\ncorresponding to the three levels of music generation: score generation\nproduces scores, performance generation adds performance characteristics to the\nscores, and audio generation converts scores with performance characteristics\ninto audio by assigning timbre or generates music in audio format directly.\nPrevious surveys have explored the network models employed in the field of\nautomatic music generation. However, the development history, the model\nevolution, as well as the pros and cons of same music generation task have not\nbeen clearly illustrated. This paper attempts to provide an overview of various\ncomposition tasks under different music generation levels, covering most of the\ncurrently popular music generation tasks using deep learning. In addition, we\nsummarize the datasets suitable for diverse tasks, discuss the music\nrepresentations, the evaluation methods as well as the challenges under\ndifferent levels, and finally point out several future directions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 08:01:20 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ji", "Shulei", ""], ["Luo", "Jing", ""], ["Yang", "Xinyu", ""]]}, {"id": "2011.06803", "submitter": "Anna Bogdanova", "authors": "Anna Bogdanova, Akie Nakai, Yukihiko Okada, Akira Imakura, and Tetsuya\n  Sakurai", "title": "Federated Learning System without Model Sharing through Integration of\n  Dimensional Reduced Data Representations", "comments": "6 pages with 4 figures. To be presented at the Workshop on Federated\n  Learning for Data Privacy and Confidentiality in Conjunction with IJCAI 2020\n  (FL-IJCAI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dimensionality Reduction is a commonly used element in a machine learning\npipeline that helps to extract important features from high-dimensional data.\nIn this work, we explore an alternative federated learning system that enables\nintegration of dimensionality reduced representations of distributed data prior\nto a supervised learning task, thus avoiding model sharing among the parties.\nWe compare the performance of this approach on image classification tasks to\nthree alternative frameworks: centralized machine learning, individual machine\nlearning, and Federated Averaging, and analyze potential use cases for a\nfederated learning system without model sharing. Our results show that our\napproach can achieve similar accuracy as Federated Averaging and performs\nbetter than Federated Averaging in a small-user setting.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 08:12:00 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Bogdanova", "Anna", ""], ["Nakai", "Akie", ""], ["Okada", "Yukihiko", ""], ["Imakura", "Akira", ""], ["Sakurai", "Tetsuya", ""]]}, {"id": "2011.06806", "submitter": "Fabio Bonassi", "authors": "Fabio Bonassi, Marcello Farina, Riccardo Scattolini", "title": "On the stability properties of Gated Recurrent Units neural networks", "comments": "Preprint submitted to the Elsevier Systems & Control Letters.\n  Copyright may be transferred without notice", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to provide sufficient conditions for guaranteeing\nthe Input-to-State Stability (ISS) and the Incremental Input-to-State Stability\n({\\delta}ISS) of Gated Recurrent Units (GRUs) neural networks. These\nconditions, devised for both single-layer and multi-layer architectures,\nconsist of nonlinear inequalities on network's weights. They can be employed to\ncheck the stability of trained networks, or can be enforced as constraints\nduring the training procedure of a GRU. The resulting training procedure is\ntested on a Quadruple Tank nonlinear benchmark system, showing satisfactory\nmodeling performances.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 08:25:26 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 11:00:42 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 09:41:48 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 12:21:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bonassi", "Fabio", ""], ["Farina", "Marcello", ""], ["Scattolini", "Riccardo", ""]]}, {"id": "2011.06813", "submitter": "Vladim\\'ir Petr\\'ik", "authors": "Vladim\\'ir Petr\\'ik, Makarand Tapaswi, Ivan Laptev, Josef Sivic", "title": "Learning Object Manipulation Skills via Approximate State Estimation\n  from Real Videos", "comments": "CoRL 2020, code at\n  https://github.com/makarandtapaswi/Real2Sim_CoRL2020, project page at\n  https://data.ciirc.cvut.cz/public/projects/2020Real2Sim/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are adept at learning new tasks by watching a few instructional\nvideos. On the other hand, robots that learn new actions either require a lot\nof effort through trial and error, or use expert demonstrations that are\nchallenging to obtain. In this paper, we explore a method that facilitates\nlearning object manipulation skills directly from videos. Leveraging recent\nadvances in 2D visual recognition and differentiable rendering, we develop an\noptimization based method to estimate a coarse 3D state representation for the\nhand and the manipulated object(s) without requiring any supervision. We use\nthese trajectories as dense rewards for an agent that learns to mimic them\nthrough reinforcement learning. We evaluate our method on simple single- and\ntwo-object actions from the Something-Something dataset. Our approach allows an\nagent to learn actions from single videos, while watching multiple\ndemonstrations makes the policy more robust. We show that policies learned in a\nsimulated environment can be easily transferred to a real robot.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 08:53:47 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Petr\u00edk", "Vladim\u00edr", ""], ["Tapaswi", "Makarand", ""], ["Laptev", "Ivan", ""], ["Sivic", "Josef", ""]]}, {"id": "2011.06819", "submitter": "Jaap Jumelet", "authors": "Jaap Jumelet", "title": "diagNNose: A Library for Neural Activation Analysis", "comments": "Accepted to the Third BlackboxNLP Workshop on Analyzing and\n  Interpreting Neural Networks for NLP, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we introduce diagNNose, an open source library for analysing\nthe activations of deep neural networks. diagNNose contains a wide array of\ninterpretability techniques that provide fundamental insights into the inner\nworkings of neural networks. We demonstrate the functionality of diagNNose with\na case study on subject-verb agreement within language models. diagNNose is\navailable at https://github.com/i-machine-think/diagnnose.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:19:48 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Jumelet", "Jaap", ""]]}, {"id": "2011.06825", "submitter": "Md Saif Hassan Onim", "authors": "Md. Saif Hassan Onim, Aiman Rafeed Ehtesham, Amreen Anbar, A. K. M.\n  Nazrul Islam, A. K. M. Mahbubur Rahman", "title": "LULC classification by semantic segmentation of satellite images using\n  FastFCN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper analyses how well a Fast Fully Convolutional Network (FastFCN)\nsemantically segments satellite images and thus classifies Land Use/Land\nCover(LULC) classes. Fast-FCN was used on Gaofen-2 Image Dataset (GID-2) to\nsegment them in five different classes: BuiltUp, Meadow, Farmland, Water and\nForest. The results showed better accuracy (0.93), precision (0.99), recall\n(0.98) and mean Intersection over Union (mIoU)(0.97) than other approaches like\nusing FCN-8 or eCognition, a readily available software. We presented a\ncomparison between the results. We propose FastFCN to be both faster and more\naccurate automated method than other existing methods for LULC classification.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:33:03 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 19:50:31 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Onim", "Md. Saif Hassan", ""], ["Ehtesham", "Aiman Rafeed", ""], ["Anbar", "Amreen", ""], ["Islam", "A. K. M. Nazrul", ""], ["Rahman", "A. K. M. Mahbubur", ""]]}, {"id": "2011.06833", "submitter": "Taraneh Younesian", "authors": "Taraneh Younesian, Chi Hong, Amirmasoud Ghiassi, Robert Birke, Lydia\n  Y. Chen", "title": "End-to-End Learning from Noisy Crowd to Supervised Machine Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling real-world datasets is time consuming but indispensable for\nsupervised machine learning models. A common solution is to distribute the\nlabeling task across a large number of non-expert workers via crowd-sourcing.\nDue to the varying background and experience of crowd workers, the obtained\nlabels are highly prone to errors and even detrimental to the learning models.\nIn this paper, we advocate using hybrid intelligence, i.e., combining deep\nmodels and human experts, to design an end-to-end learning framework from noisy\ncrowd-sourced data, especially in an on-line scenario. We first summarize the\nstate-of-the-art solutions that address the challenges of noisy labels from\nnon-expert crowd and learn from multiple annotators. We show how label\naggregation can benefit from estimating the annotators' confusion matrices to\nimprove the learning process. Moreover, with the help of an expert labeler as\nwell as classifiers, we cleanse aggregated labels of highly informative samples\nto enhance the final classification accuracy. We demonstrate the effectiveness\nof our strategies on several image datasets, i.e. UCI and CIFAR-10, using SVM\nand deep neural networks. Our evaluation shows that our on-line label\naggregation with confusion matrix estimation reduces the error rate of labels\nby over 30%. Furthermore, relabeling only 10% of the data using the expert's\nresults in over 90% classification accuracy with SVM.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:48:30 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Younesian", "Taraneh", ""], ["Hong", "Chi", ""], ["Ghiassi", "Amirmasoud", ""], ["Birke", "Robert", ""], ["Chen", "Lydia Y.", ""]]}, {"id": "2011.06835", "submitter": "Otmane Sakhi", "authors": "Otmane Sakhi, Louis Faury, Flavian Vasile", "title": "Improving Offline Contextual Bandits with Distributional Robustness", "comments": "In Proceedings of the ACM RecSys Workshop on Reinforcement Learning\n  and Robust Estimators for Recommendation Systems (REVEAL 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper extends the Distributionally Robust Optimization (DRO) approach\nfor offline contextual bandits. Specifically, we leverage this framework to\nintroduce a convex reformulation of the Counterfactual Risk Minimization\nprinciple. Besides relying on convex programs, our approach is compatible with\nstochastic optimization, and can therefore be readily adapted tothe large data\nregime. Our approach relies on the construction of asymptotic confidence\nintervals for offline contextual bandits through the DRO framework. By\nleveraging known asymptotic results of robust estimators, we also show how to\nautomatically calibrate such confidence intervals, which in turn removes the\nburden of hyper-parameter selection for policy optimization. We present\npreliminary empirical results supporting the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:52:16 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Sakhi", "Otmane", ""], ["Faury", "Louis", ""], ["Vasile", "Flavian", ""]]}, {"id": "2011.06841", "submitter": "Zhenzhen Sun", "authors": "Zhenzhen Sun and Yuanlong Yu", "title": "A Homotopy Coordinate Descent Optimization Method for $l_0$-Norm\n  Regularized Least Square Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a homotopy coordinate descent (HCD) method to solve the\n$l_0$-norm regularized least square ($l_0$-LS) problem for compressed sensing,\nwhich combine the homotopy technique with a variant of coordinate descent\nmethod. Differs from the classical coordinate descent algorithms, HCD provides\nthree strategies to speed up the convergence: warm start initialization, active\nset updating, and strong rule for active set initialization. The active set is\npre-selected using a strong rule, then the coordinates of the active set are\nupdated while those of inactive set are unchanged. The homotopy strategy\nprovides a set of warm start initial solutions for a sequence of decreasing\nvalues of the regularization factor, which ensures all iterations along the\nhomotopy solution path are sparse. Computational experiments on simulate\nsignals and natural signals demonstrate effectiveness of the proposed\nalgorithm, in accurately and efficiently reconstructing sparse solutions of the\n$l_0$-LS problem, whether the observation is noisy or not.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:02:06 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Sun", "Zhenzhen", ""], ["Yu", "Yuanlong", ""]]}, {"id": "2011.06846", "submitter": "Thomas Pellegrini", "authors": "Thomas Pellegrini, Romain Zimmer, Timoth\\'ee Masquelier", "title": "Low-activity supervised convolutional spiking neural networks applied to\n  speech commands recognition", "comments": "Accepted to IEEE Spoken Language Technology Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Neural Networks (DNNs) are the current state-of-the-art models in many\nspeech related tasks. There is a growing interest, though, for more\nbiologically realistic, hardware friendly and energy efficient models, named\nSpiking Neural Networks (SNNs). Recently, it has been shown that SNNs can be\ntrained efficiently, in a supervised manner, using backpropagation with a\nsurrogate gradient trick. In this work, we report speech command (SC)\nrecognition experiments using supervised SNNs. We explored the\nLeaky-Integrate-Fire (LIF) neuron model for this task, and show that a model\ncomprised of stacked dilated convolution spiking layers can reach an error rate\nvery close to standard DNNs on the Google SC v1 dataset: 5.5%, while keeping a\nvery sparse spiking activity, below 5%, thank to a new regularization term. We\nalso show that modeling the leakage of the neuron membrane potential is useful,\nsince the LIF model outperformed its non-leaky model counterpart significantly.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:29:35 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Pellegrini", "Thomas", ""], ["Zimmer", "Romain", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "2011.06851", "submitter": "Francisco Pereira", "authors": "Martin Johnsen, Oliver Brandt, Sergio Garrido, Francisco C. Pereira", "title": "Population synthesis for urban resident modeling using deep generative\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The impacts of new real estate developments are strongly associated to its\npopulation distribution (types and compositions of households, incomes, social\ndemographics) conditioned on aspects such as dwelling typology, price,\nlocation, and floor level. This paper presents a Machine Learning based method\nto model the population distribution of upcoming developments of new buildings\nwithin larger neighborhood/condo settings.\n  We use a real data set from Ecopark Township, a real estate development\nproject in Hanoi, Vietnam, where we study two machine learning algorithms from\nthe deep generative models literature to create a population of synthetic\nagents: Conditional Variational Auto-Encoder (CVAE) and Conditional Generative\nAdversarial Networks (CGAN). A large experimental study was performed, showing\nthat the CVAE outperforms both the empirical distribution, a non-trivial\nbaseline model, and the CGAN in estimating the population distribution of new\nreal estate development projects.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:48:19 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Johnsen", "Martin", ""], ["Brandt", "Oliver", ""], ["Garrido", "Sergio", ""], ["Pereira", "Francisco C.", ""]]}, {"id": "2011.06853", "submitter": "Fabiana Di Ciaccio", "authors": "Paolo Russo, Fabiana Di Ciaccio, Salvatore Troisi", "title": "DANAE: a denoising autoencoder for underwater attitude estimation", "comments": "5 pages, 2 figures, Conference paper accepted and presented at the\n  International Workshop on Metrology for the Sea in October 2020, accessible\n  for download from Book od Abstracts, see http://www.metrosea.org/ms2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main issues for underwater robots navigation is their accurate\npositioning, which heavily depends on the orientation estimation phase. The\nsystems employed to this scope are affected by different noise typologies,\nmainly related to the sensors and to the irregular noise of the underwater\nenvironment. Filtering algorithms can reduce their effect if opportunely\nconfigured, but this process usually requires fine techniques and time. In this\npaper we propose DANAE, a deep Denoising AutoeNcoder for Attitude Estimation\nwhich works on Kalman filter IMU/AHRS data integration with the aim of reducing\nany kind of noise, independently of its nature. This deep learning-based\narchitecture showed to be robust and reliable, significantly improving the\nKalman filter results. Further tests could make this method suitable for\nreal-time applications on navigation tasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 10:53:01 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Russo", "Paolo", ""], ["Di Ciaccio", "Fabiana", ""], ["Troisi", "Salvatore", ""]]}, {"id": "2011.06861", "submitter": "Ante Lojic Kapetanovic", "authors": "Petar \\v{S}oli\\'c, Ante Loji\\'c Kapetanovi\\'c, Tomislav\n  \\v{Z}upanovi\\'c, Ivo Kova\\v{c}evi\\'c, Toni Perkovi\\'c, Petar Popovski", "title": "IoT Wallet: Machine Learning-based Sensor Portfolio Application", "comments": "5 pages, 6 figures, in proceedings of the 5th International\n  Conference on Smart and Sustainable Technologies 2020, SpliTech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper an application for building sensor wallet is presented.\nCurrently, given system collects sensor data from The Things Network (TTN)\ncloud system, stores the data into the Influx database and presents the\nprocessed data to the user dashboard. Based on the type of the user, data can\nbe viewed-only, controlled or the top user can register the sensor to the\nsystem. Moreover, the system can notify users based on the rules that can be\nadjusted through the user interface. The special feature of the system is the\nmachine learning service that can be used in various scenarios and is presented\nthroughout the case study that gives a novel approach to estimate soil moisture\nfrom the signal strength of a given underground LoRa beacon node.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 11:12:25 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["\u0160oli\u0107", "Petar", ""], ["Kapetanovi\u0107", "Ante Loji\u0107", ""], ["\u017dupanovi\u0107", "Tomislav", ""], ["Kova\u010devi\u0107", "Ivo", ""], ["Perkovi\u0107", "Toni", ""], ["Popovski", "Petar", ""]]}, {"id": "2011.06868", "submitter": "Weijia Xu", "authors": "Weijia Xu, Marine Carpuat", "title": "EDITOR: an Edit-Based Transformer with Repositioning for Neural Machine\n  Translation with Soft Lexical Constraints", "comments": "TACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an Edit-Based Transformer with Repositioning (EDITOR), which\nmakes sequence generation flexible by seamlessly allowing users to specify\npreferences in output lexical choice. Building on recent models for\nnon-autoregressive sequence generation (Gu et al., 2019), EDITOR generates new\nsequences by iteratively editing hypotheses. It relies on a novel reposition\noperation designed to disentangle lexical choice from word positioning\ndecisions, while enabling efficient oracles for imitation learning and parallel\nedits at decoding time. Empirically, EDITOR uses soft lexical constraints more\neffectively than the Levenshtein Transformer (Gu et al., 2019) while speeding\nup decoding dramatically compared to constrained beam search (Post and Vilar,\n2018). EDITOR also achieves comparable or better translation quality with\nfaster decoding speed than the Levenshtein Transformer on standard\nRomanian-English, English-German, and English-Japanese machine translation\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 11:47:28 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 22:26:02 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Xu", "Weijia", ""], ["Carpuat", "Marine", ""]]}, {"id": "2011.06874", "submitter": "Ali Mottaghi", "authors": "Ali Mottaghi, Prathusha K Sarma, Xavier Amatriain, Serena Yeung,\n  Anitha Kannan", "title": "Medical symptom recognition from patient text: An active learning\n  approach for long-tailed multilabel distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of medical symptoms recognition from patient text, for\nthe purposes of gathering pertinent information from the patient (known as\nhistory-taking). A typical patient text is often descriptive of the symptoms\nthe patient is experiencing and a single instance of such a text can be\n\"labeled\" with multiple symptoms. This makes learning a medical symptoms\nrecognizer challenging on account of i) the lack of availability of voluminous\nannotated data as well as ii) the large unknown universe of multiple symptoms\nthat a single text can map to. Furthermore, patient text is often characterized\nby a long tail in the data (i.e., some labels/symptoms occur more frequently\nthan others for e.g \"fever\" vs \"hematochezia\"). In this paper, we introduce an\nactive learning method that leverages underlying structure of a continually\nrefined, learned latent space to select the most informative examples to label.\nThis enables the selection of the most informative examples that progressively\nincreases the coverage on the universe of symptoms via the learned model,\ndespite the long tail in data distribution.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 05:26:56 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 23:18:32 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mottaghi", "Ali", ""], ["Sarma", "Prathusha K", ""], ["Amatriain", "Xavier", ""], ["Yeung", "Serena", ""], ["Kannan", "Anitha", ""]]}, {"id": "2011.06878", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto", "title": "REPAC: Reliable estimation of phase-amplitude coupling in brain networks", "comments": null, "journal-ref": "2021 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP)", "doi": "10.1109/ICASSP39728.2021.9414749", "report-no": null, "categories": "eess.SP cs.CV cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent evidence has revealed cross-frequency coupling and, particularly,\nphase-amplitude coupling (PAC) as an important strategy for the brain to\naccomplish a variety of high-level cognitive and sensory functions. However,\ndecoding PAC is still challenging. This contribution presents REPAC, a reliable\nand robust algorithm for modeling and detecting PAC events in EEG signals.\nFirst, we explain the synthesis of PAC-like EEG signals, with special attention\nto the most critical parameters that characterize PAC, i.e., SNR, modulation\nindex, duration of coupling. Second, REPAC is introduced in detail. We use\ncomputer simulations to generate a set of random PAC-like EEG signals and test\nthe performance of REPAC with regard to a baseline method. REPAC is shown to\noutperform the baseline method even with realistic values of SNR, e.g., -10 dB.\nThey both reach accuracy levels around 99%, but REPAC leads to a significant\nimprovement of sensitivity, from 20.11% to 65.21%, with comparable specificity\n(around 99%). REPAC is also applied to a real EEG signal showing preliminary\nencouraging results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 12:26:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Cisotto", "Giulia", ""]]}, {"id": "2011.06882", "submitter": "Wei Pan", "authors": "Minghao Han, Yuan Tian, Lixian Zhang, Jun Wang, Wei Pan", "title": "Reinforcement Learning Control of Constrained Dynamic Systems with\n  Uniformly Ultimate Boundedness Stability Guarantee", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) is promising for complicated stochastic nonlinear\ncontrol problems. Without using a mathematical model, an optimal controller can\nbe learned from data evaluated by certain performance criteria through\ntrial-and-error. However, the data-based learning approach is notorious for not\nguaranteeing stability, which is the most fundamental property for any control\nsystem. In this paper, the classic Lyapunov's method is explored to analyze the\nuniformly ultimate boundedness stability (UUB) solely based on data without\nusing a mathematical model. It is further shown how RL with UUB guarantee can\nbe applied to control dynamic systems with safety constraints. Based on the\ntheoretical results, both off-policy and on-policy learning algorithms are\nproposed respectively. As a result, optimal controllers can be learned to\nguarantee UUB of the closed-loop system both at convergence and during\nlearning. The proposed algorithms are evaluated on a series of robotic\ncontinuous control tasks with safety constraints. In comparison with the\nexisting RL algorithms, the proposed method can achieve superior performance in\nterms of maintaining safety. As a qualitative evaluation of stability, our\nmethod shows impressive resilience even in the presence of external\ndisturbances.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 12:41:56 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Han", "Minghao", ""], ["Tian", "Yuan", ""], ["Zhang", "Lixian", ""], ["Wang", "Jun", ""], ["Pan", "Wei", ""]]}, {"id": "2011.06892", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir, Sinem Coleri, Kumar Vijay Mishra", "title": "Hybrid Federated and Centralized Learning", "comments": "5pages4figures. This work has been submitted to the IEEE for\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the machine learning (ML) tasks are focused on centralized learning\n(CL), which requires the transmission of local datasets from the clients to a\nparameter server (PS) leading to a huge communication overhead. Federated\nlearning (FL) overcomes this issue by allowing the clients to send only the\nmodel updates to the PS instead of the whole dataset. In this way, FL brings\nthe learning to edge level, wherein powerful computational resources are\nrequired on the client side. This requirement may not always be satisfied\nbecause of diverse computational capabilities of edge devices. We address this\nthrough a novel hybrid federated and centralized learning (HFCL) framework to\neffectively train a learning model by exploiting the computational capability\nof the clients. In HFCL, only the clients who have sufficient resources employ\nFL; the remaining clients resort to CL by transmitting their local dataset to\nPS. This allows all the clients to collaborate on the learning process\nregardless of their computational resources. We also propose a sequential data\ntransmission approach with HFCL (HFCL-SDT) to reduce the training duration. The\nproposed HFCL frameworks outperform previously proposed non-hybrid FL (CL)\nbased schemes in terms of learning accuracy (communication overhead) since all\nthe clients collaborate on the learning process with their datasets regardless\nof their computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 13:11:04 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 20:28:58 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Coleri", "Sinem", ""], ["Mishra", "Kumar Vijay", ""]]}, {"id": "2011.06916", "submitter": "Amanda Fern\\'andez-Fontelo Dr.", "authors": "Amanda Fern\\'andez-Fontelo, Pascal J. Kieslich, Felix Henninger,\n  Frauke Kreuter and Sonja Greven", "title": "Predicting respondent difficulty in web surveys: A machine-learning\n  approach based on mouse movement features", "comments": "40 pages, 2 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of survey research is to collect robust and reliable data from\nrespondents. However, despite researchers' best efforts in designing\nquestionnaires, respondents may experience difficulty understanding questions'\nintent and therefore may struggle to respond appropriately. If it were possible\nto detect such difficulty, this knowledge could be used to inform real-time\ninterventions through responsive questionnaire design, or to indicate and\ncorrect measurement error after the fact. Previous research in the context of\nweb surveys has used paradata, specifically response times, to detect\ndifficulties and to help improve user experience and data quality. However,\nricher data sources are now available, in the form of the movements respondents\nmake with the mouse, as an additional and far more detailed indicator for the\nrespondent-survey interaction. This paper uses machine learning techniques to\nexplore the predictive value of mouse-tracking data with regard to respondents'\ndifficulty. We use data from a survey on respondents' employment history and\ndemographic information, in which we experimentally manipulate the difficulty\nof several questions. Using features derived from the cursor movements, we\npredict whether respondents answered the easy or difficult version of a\nquestion, using and comparing several state-of-the-art supervised learning\nmethods. In addition, we develop a personalization method that adjusts for\nrespondents' baseline mouse behavior and evaluate its performance. For all\nthree manipulated survey questions, we find that including the full set of\nmouse movement features improved prediction performance over response-time-only\nmodels in nested cross-validation. Accounting for individual differences in\nmouse movements led to further improvements.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 10:54:33 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Fern\u00e1ndez-Fontelo", "Amanda", ""], ["Kieslich", "Pascal J.", ""], ["Henninger", "Felix", ""], ["Kreuter", "Frauke", ""], ["Greven", "Sonja", ""]]}, {"id": "2011.06923", "submitter": "Richard Schoonhoven", "authors": "Richard Schoonhoven, Allard A. Hendriksen, Dani\\\"el M. Pelt, K. Joost\n  Batenburg", "title": "LEAN: graph-based pruning for convolutional neural networks by\n  extracting longest chains", "comments": "8 pages + 2 pages references. Code will be made public via GitHub\n  soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have proven to be highly successful at a\nrange of image-to-image tasks. CNNs can be computationally expensive, which can\nlimit their applicability in practice. Model pruning can improve computational\nefficiency by sparsifying trained networks. Common methods for pruning CNNs\ndetermine what convolutional filters to remove by ranking filters on an\nindividual basis. However, filters are not independent, as CNNs consist of\nchains of convolutions, which can result in sub-optimal filter selection.\n  We propose a novel pruning method, LongEst-chAiN (LEAN) pruning, which takes\nthe interdependency between the convolution operations into account. We propose\nto prune CNNs by using graph-based algorithms to select relevant chains of\nconvolutions. A CNN is interpreted as a graph, with the operator norm of each\nconvolution as distance metric for the edges. LEAN pruning iteratively extracts\nthe highest value path from the graph to keep. In our experiments, we test LEAN\npruning for several image-to-image tasks, including the well-known CamVid\ndataset. LEAN pruning enables us to keep just 0.5%-2% of the convolutions\nwithout significant loss of accuracy. When pruning CNNs with LEAN, we achieve a\nhigher accuracy than pruning filters individually, and different pruned\nsubstructures emerge.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 14:17:51 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Schoonhoven", "Richard", ""], ["Hendriksen", "Allard A.", ""], ["Pelt", "Dani\u00ebl M.", ""], ["Batenburg", "K. Joost", ""]]}, {"id": "2011.06928", "submitter": "MD Tanzil Shahriar", "authors": "Md Tanzil Shahriar, Huyue Li", "title": "A Study of Image Pre-processing for Faster Object Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality of image always plays a vital role in in-creasing object recognition\nor classification rate. A good quality image gives better recognition or\nclassification rate than any unprocessed noisy images. It is more difficult to\nextract features from such unprocessed images which in-turn reduces object\nrecognition or classification rate. To overcome problems occurred due to low\nquality image, typically pre-processing is done before extracting features from\nthe image. Our project proposes an image pre-processing method, so that the\nperformance of selected Machine Learning algorithms or Deep Learning algorithms\nincreases in terms of increased accuracy or reduced the number of training\nimages. In the later part, we compare the performance results by using our\nmethod with the previous used approaches.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 02:55:17 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Shahriar", "Md Tanzil", ""], ["Li", "Huyue", ""]]}, {"id": "2011.06934", "submitter": "Seyed Ali Alavi Bajestan", "authors": "Ali Alavi", "title": "Neural network for estimation of optical characteristics of optically\n  active and turbid scattering media", "comments": "12 pages, presubmission", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One native source of quality deterioration in medical imaging, and especially\nin our case optical coherence tomography (OCT), is the turbid biological media\nin which photon does not take a predictable path and many scattering events\nwould influence the effective path length and change the polarization of\npolarized light. This inherent problem would cause imaging errors even in the\ncase of high resolution of interferometric methods. To address this problem and\nconsidering the inherent random nature of this problem, in the last decades\nsome methods including Monte Carlo simulation for OCT was proposed. In this\napproach simulation would give us a one on one comparison of underlying\nphysical structure and its OCT imaging counterpart. Although its goal was to\ngive the practitioners a better understanding of underlying structure, it lacks\nin providing a comprehensive approach to increase the accuracy and imaging\nquality of OCT imaging and would only provide a set of examples on how imaging\nmethod might falter. To mitigate this problem and to demonstrate a new approach\nto improve the medical imaging without changing any hardware, we introduce a\nnew pipeline consisting of Monte Carlo simulation followed by a deep neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:41:42 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 17:02:59 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Alavi", "Ali", ""]]}, {"id": "2011.06949", "submitter": "Jos\\'e Ignacio Alvarez-Hamelin Phd.", "authors": "Carlos Selmo, Julian F. Martinez, Mariano G. Beir\\'o and J. Ignacio\n  Alvarez-Hamelin", "title": "Learning language variations in news corpora through differential\n  embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is an increasing interest in the NLP community in capturing variations\nin the usage of language, either through time (i.e., semantic drift), across\nregions (as dialects or variants) or in different social contexts (i.e.,\nprofessional or media technolects). Several successful dynamical embeddings\nhave been proposed that can track semantic change through time. Here we show\nthat a model with a central word representation and a slice-dependent\ncontribution can learn word embeddings from different corpora simultaneously.\nThis model is based on a star-like representation of the slices. We apply it to\nThe New York Times and The Guardian newspapers, and we show that it can capture\nboth temporal dynamics in the yearly slices of each corpus, and language\nvariations between US and UK English in a curated multi-source corpus. We\nprovide an extensive evaluation of this methodology.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 14:50:08 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Selmo", "Carlos", ""], ["Martinez", "Julian F.", ""], ["Beir\u00f3", "Mariano G.", ""], ["Alvarez-Hamelin", "J. Ignacio", ""]]}, {"id": "2011.06957", "submitter": "Pierre Gaillard", "authors": "Anant Raj, Pierre Gaillard (SIERRA, Thoth), Christophe Saad (CMU)", "title": "Non-stationary Online Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online forecasting under a changing environment has been a problem of\nincreasing importance in many real-world applications. In this paper, we\nconsider the meta-algorithm presented in \\citet{zhang2017dynamic} combined with\ndifferent subroutines. We show that an expected cumulative error of order\n$\\tilde{O}(n^{1/3} C_n^{2/3})$ can be obtained for non-stationary online linear\nregression where the total variation of parameter sequence is bounded by $C_n$.\nOur paper extends the result of online forecasting of one-dimensional\ntime-series as proposed in \\cite{baby2019online} to general $d$-dimensional\nnon-stationary linear regression. We improve the rate $O(\\sqrt{n C_n})$\nobtained by Zhang et al. 2017 and Besbes et al. 2015. We further extend our\nanalysis to non-stationary online kernel regression. Similar to the\nnon-stationary online regression case, we use the meta-procedure of Zhang et\nal. 2017 combined with Kernel-AWV (Jezequel et al. 2020) to achieve an expected\ncumulative controlled by the effective dimension of the RKHS and the total\nvariation of the sequence. To the best of our knowledge, this work is the first\nextension of non-stationary online regression to non-stationary kernel\nregression. Lastly, we evaluate our method empirically with several existing\nbenchmarks and also compare it with the theoretical bound obtained in this\npaper.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:08:49 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Raj", "Anant", "", "SIERRA, Thoth"], ["Gaillard", "Pierre", "", "SIERRA, Thoth"], ["Saad", "Christophe", "", "CMU"]]}, {"id": "2011.06958", "submitter": "Guillaume Vaudaux-Ruth", "authors": "Guillaume Vaudaux-Ruth, Adrien Chan-Hon-Tong, Catherine Achard", "title": "SALAD: Self-Assessment Learning for Action Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Literature on self-assessment in machine learning mainly focuses on the\nproduction of well-calibrated algorithms through consensus frameworks i.e.\ncalibration is seen as a problem. Yet, we observe that learning to be properly\nconfident could behave like a powerful regularization and thus, could be an\nopportunity to improve performance.Precisely, we show that used within a\nframework of action detection, the learning of a self-assessment score is able\nto improve the whole action localization process.Experimental results show that\nour approach outperforms the state-of-the-art on two action detection\nbenchmarks. On THUMOS14 dataset, the mAP at tIoU@0.5 is improved from 42.8\\% to\n44.6\\%, and from 50.4\\% to 51.7\\% on ActivityNet1.3 dataset. For lower tIoU\nvalues, we achieve even more significant improvements on both datasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:10:40 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Vaudaux-Ruth", "Guillaume", ""], ["Chan-Hon-Tong", "Adrien", ""], ["Achard", "Catherine", ""]]}, {"id": "2011.06959", "submitter": "Edouard Fouch\\'e", "authors": "Edouard Fouch\\'e, Florian Kalinke, Klemens B\\\"ohm", "title": "Efficient Subspace Search in Data Streams", "comments": "Accepted Manuscript to Information Systems, Volume 97, Elsevier.\n  Final authenticated version: https://doi.org/10.1016/j.is.2020.101705", "journal-ref": "In: Information Systems 97 (2021), p. 101705. ISSN: 0306-4379", "doi": "10.1016/j.is.2020.101705", "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, data streams are ubiquitous -- think of network traffic or\nsensor data. Mining patterns, e.g., outliers or clusters, from such data must\ntake place in real time. This is challenging because (1) streams often have\nhigh dimensionality, and (2) the data characteristics may change over time.\nExisting approaches tend to focus on only one aspect, either high\ndimensionality or the specifics of the streaming setting. For static data, a\ncommon approach to deal with high dimensionality -- known as subspace search --\nextracts low-dimensional, `interesting' projections (subspaces), in which\npatterns are easier to find. In this paper, we address both Challenge (1) and\n(2) by generalising subspace search to data streams. Our approach, Streaming\nGreedy Maximum Random Deviation (SGMRD), monitors interesting subspaces in\nhigh-dimensional data streams. It leverages novel multivariate dependency\nestimators and monitoring techniques based on bandit theory. We show that the\nbenefits of SGMRD are twofold: (i) It monitors subspaces efficiently, and (ii)\nthis improves the results of downstream data mining tasks, such as outlier\ndetection. Our experiments, performed against synthetic and real-world data,\ndemonstrate that SGMRD outperforms its competitors by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:13:25 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 11:07:50 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Fouch\u00e9", "Edouard", ""], ["Kalinke", "Florian", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "2011.06961", "submitter": "Daniel Seichter", "authors": "Daniel Seichter, Mona K\\\"ohler, Benjamin Lewandowski, Tim Wengefeld\n  and Horst-Michael Gross", "title": "Efficient RGB-D Semantic Segmentation for Indoor Scene Analysis", "comments": "To be published in IEEE International Conference on Robotics and\n  Automation (ICRA) 2021; fixed reference in Fig. 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing scenes thoroughly is crucial for mobile robots acting in different\nenvironments. Semantic segmentation can enhance various subsequent tasks, such\nas (semantically assisted) person perception, (semantic) free space detection,\n(semantic) mapping, and (semantic) navigation. In this paper, we propose an\nefficient and robust RGB-D segmentation approach that can be optimized to a\nhigh degree using NVIDIA TensorRT and, thus, is well suited as a common initial\nprocessing step in a complex system for scene analysis on mobile robots. We\nshow that RGB-D segmentation is superior to processing RGB images solely and\nthat it can still be performed in real time if the network architecture is\ncarefully designed. We evaluate our proposed Efficient Scene Analysis Network\n(ESANet) on the common indoor datasets NYUv2 and SUNRGB-D and show that we\nreach state-of-the-art performance while enabling faster inference.\nFurthermore, our evaluation on the outdoor dataset Cityscapes shows that our\napproach is suitable for other areas of application as well. Finally, instead\nof presenting benchmark results only, we also show qualitative results in one\nof our indoor application scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:17:31 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 14:25:58 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 14:41:24 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Seichter", "Daniel", ""], ["K\u00f6hler", "Mona", ""], ["Lewandowski", "Benjamin", ""], ["Wengefeld", "Tim", ""], ["Gross", "Horst-Michael", ""]]}, {"id": "2011.06964", "submitter": "Micha\\\"el Fanuel", "authors": "Micha\\\"el Fanuel, Joachim Schreurs, Johan A.K. Suykens", "title": "Determinantal Point Processes Implicitly Regularize Semi-parametric\n  Regression Problems", "comments": "26 pages. Extended results. Typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-parametric regression models are used in several applications which\nrequire comprehensibility without sacrificing accuracy. Typical examples are\nspline interpolation in geophysics, or non-linear time series problems, where\nthe system includes a linear and non-linear component. We discuss here the use\nof a finite Determinantal Point Process (DPP) for approximating semi-parametric\nmodels. Recently, Barthelm\\'e, Tremblay, Usevich, and Amblard introduced a\nnovel representation of some finite DPPs. These authors formulated extended\nL-ensembles that can conveniently represent partial-projection DPPs and suggest\ntheir use for optimal interpolation. With the help of this formalism, we derive\na key identity illustrating the implicit regularization effect of determinantal\nsampling for semi-parametric regression and interpolation. Also, a novel\nprojected Nystr\\\"om approximation is defined and used to derive a bound on the\nexpected risk for the corresponding approximation of semi-parametric\nregression. This work naturally extends similar results obtained for kernel\nridge regression.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:22:16 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 13:47:11 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2011.06977", "submitter": "Abdelrahman Abouelenin", "authors": "Ahmad Beltagy, Abdelrahman Wael, Omar ElSherief", "title": "Arabic Dialect Identification Using BERT-Based Domain Adaptation", "comments": "6 pages, 2 figures , WANLP co-located with COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Arabic is one of the most important and growing languages in the world. With\nthe rise of social media platforms such as Twitter, Arabic spoken dialects have\nbecome more in use. In this paper, we describe our approach on the NADI Shared\nTask 1 that requires us to build a system to differentiate between different 21\nArabic dialects, we introduce a deep learning semi-supervised fashion approach\nalong with pre-processing that was reported on NADI shared Task 1 Corpus. Our\nsystem ranks 4th in NADI's shared task competition achieving a 23.09% F1 macro\naverage score with a simple yet efficient approach to differentiating between\n21 Arabic Dialects given tweets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:52:51 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Beltagy", "Ahmad", ""], ["Wael", "Abdelrahman", ""], ["ElSherief", "Omar", ""]]}, {"id": "2011.06982", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan, Silas {\\O}rting, Erik B Dam", "title": "Multi-layered tensor networks for image classification", "comments": "Updated version with exact computation costs. 6 pages. Accepted to\n  the First Workshop on Quantum Tensor Networks in Machine Learning. In\n  conjunction with 34th NeurIPS, 2020. Source code at\n  https://github.com/raghavian/mltn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recently introduced locally orderless tensor network (LoTeNet) for\nsupervised image classification uses matrix product state (MPS) operations on\ngrids of transformed image patches. The resulting patch representations are\ncombined back together into the image space and aggregated hierarchically using\nmultiple MPS blocks per layer to obtain the final decision rules. In this work,\nwe propose a non-patch based modification to LoTeNet that performs one MPS\noperation per layer, instead of several patch-level operations. The spatial\ninformation in the input images to MPS blocks at each layer is squeezed into\nthe feature dimension, similar to LoTeNet, to maximise retained spatial\ncorrelation between pixels when images are flattened into 1D vectors. The\nproposed multi-layered tensor network (MLTN) is capable of learning linear\ndecision boundaries in high dimensional spaces in a multi-layered setting,\nwhich results in a reduction in the computation cost compared to LoTeNet\nwithout any degradation in performance.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:01:26 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 11:37:15 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Selvan", "Raghavendra", ""], ["\u00d8rting", "Silas", ""], ["Dam", "Erik B", ""]]}, {"id": "2011.07005", "submitter": "Geoffrey Clark", "authors": "Geoffrey Clark, Joseph Campbell, and Heni Ben Amor", "title": "Learning Predictive Models for Ergonomic Control of Prosthetic Devices", "comments": "Accepted to CoRL 2020. Accompanying video presentation:\n  https://www.youtube.com/watch?v=DxQPF3VwuoA&feature=youtu.be", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Model-Predictive Interaction Primitives -- a robot learning\nframework for assistive motion in human-machine collaboration tasks which\nexplicitly accounts for biomechanical impact on the human musculoskeletal\nsystem. First, we extend Interaction Primitives to enable predictive\nbiomechanics: the prediction of future biomechanical states of a human partner\nconditioned on current observations and intended robot control signals. In\nturn, we leverage this capability within a model-predictive control strategy to\nidentify the future ergonomic and biomechanical ramifications of potential\nrobot actions. Optimal control trajectories are selected so as to minimize\nfuture physical impact on the human musculoskeletal system. We empirically\ndemonstrate that our approach minimizes knee or muscle forces via generated\ncontrol actions selected according to biomechanical cost functions. Experiments\nare performed in synthetic and real-world experiments involving powered\nprosthetic devices.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:39:01 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Clark", "Geoffrey", ""], ["Campbell", "Joseph", ""], ["Amor", "Heni Ben", ""]]}, {"id": "2011.07006", "submitter": "Mohammad Bakhtiari", "authors": "Reza Nasirigerdeh, Mohammad Bakhtiari, Reihaneh Torkzadehmahani,\n  Amirhossein Bayat, Markus List, David B. Blumenthal and Jan Baumbach", "title": "Federated Multi-Mini-Batch: An Efficient Training Approach to Federated\n  Learning in Non-IID Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has faced performance and network communication\nchallenges, especially in the environments where the data is not independent\nand identically distributed (IID) across the clients. To address the former\nchallenge, we introduce the federated-centralized concordance property and show\nthat the federated single-mini-batch training approach can achieve comparable\nperformance as the corresponding centralized training in the Non-IID\nenvironments. To deal with the latter, we present the federated\nmulti-mini-batch approach and illustrate that it can establish a trade-off\nbetween the performance and communication efficiency and outperforms federated\naveraging in the Non-IID settings.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:39:27 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 23:07:12 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nasirigerdeh", "Reza", ""], ["Bakhtiari", "Mohammad", ""], ["Torkzadehmahani", "Reihaneh", ""], ["Bayat", "Amirhossein", ""], ["List", "Markus", ""], ["Blumenthal", "David B.", ""], ["Baumbach", "Jan", ""]]}, {"id": "2011.07011", "submitter": "Sayak Mukherjee", "authors": "Sayak Mukherjee, Thanh Long Vu", "title": "Imposing Robust Structured Control Constraint on Reinforcement Learning\n  of Linear Quadratic Regulator", "comments": "16 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2011.01128", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses learning a structured feedback control to obtain\nsufficient robustness to exogenous inputs for linear dynamic systems with\nunknown state matrix. The structural constraint on the controller is necessary\nfor many cyber-physical systems, and our approach presents a design for any\ngeneric structure, paving the way for distributed learning control. The ideas\nfrom reinforcement learning (RL) in conjunction with control-theoretic\nsufficient stability and performance guarantees are used to develop the\nmethodology. First, a model-based framework is formulated using dynamic\nprogramming to embed the structural constraint in the linear quadratic\nregulator (LQR) setting along with sufficient robustness conditions.\nThereafter, we translate these conditions to a data-driven learning-based\nframework - robust structured reinforcement learning (RSRL) that enjoys the\ncontrol-theoretic guarantees on stability and convergence. We validate our\ntheoretical results with a simulation on a multi-agent network with 6 agents.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 00:31:39 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 19:28:13 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mukherjee", "Sayak", ""], ["Vu", "Thanh Long", ""]]}, {"id": "2011.07016", "submitter": "Riad Akrour", "authors": "Riad Akrour, Asma Atamna, Jan Peters", "title": "Convex Optimization with an Interpolation-based Projection and its\n  Application to Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convex optimizers have known many applications as differentiable layers\nwithin deep neural architectures. One application of these convex layers is to\nproject points into a convex set. However, both forward and backward passes of\nthese convex layers are significantly more expensive to compute than those of a\ntypical neural network. We investigate in this paper whether an inexact, but\ncheaper projection, can drive a descent algorithm to an optimum. Specifically,\nwe propose an interpolation-based projection that is computationally cheap and\neasy to compute given a convex, domain defining, function. We then propose an\noptimization algorithm that follows the gradient of the composition of the\nobjective and the projection and prove its convergence for linear objectives\nand arbitrary convex and Lipschitz domain defining inequality constraints. In\naddition to the theoretical contributions, we demonstrate empirically the\npractical interest of the interpolation projection when used in conjunction\nwith neural networks in a reinforcement learning and a supervised learning\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:52:50 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Akrour", "Riad", ""], ["Atamna", "Asma", ""], ["Peters", "Jan", ""]]}, {"id": "2011.07017", "submitter": "Paula Harder", "authors": "Paula Harder, William Jones, Redouane Lguensat, Shahine Bouabid, James\n  Fulton, D\\'anell Quesada-Chac\\'on, Aris Marcolongo, Sofija Stefanovi\\'c,\n  Yuhan Rao, Peter Manshausen, Duncan Watson-Parris", "title": "NightVision: Generating Nighttime Satellite Imagery from Infra-Red\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent explosion in applications of machine learning to satellite imagery\noften rely on visible images and therefore suffer from a lack of data during\nthe night. The gap can be filled by employing available infra-red observations\nto generate visible images. This work presents how deep learning can be applied\nsuccessfully to create those images by using U-Net based architectures. The\nproposed methods show promising results, achieving a structural similarity\nindex (SSIM) up to 86\\% on an independent test set and providing visually\nconvincing output images, generated from infra-red observations.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:55:46 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 15:43:52 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Harder", "Paula", ""], ["Jones", "William", ""], ["Lguensat", "Redouane", ""], ["Bouabid", "Shahine", ""], ["Fulton", "James", ""], ["Quesada-Chac\u00f3n", "D\u00e1nell", ""], ["Marcolongo", "Aris", ""], ["Stefanovi\u0107", "Sofija", ""], ["Rao", "Yuhan", ""], ["Manshausen", "Peter", ""], ["Watson-Parris", "Duncan", ""]]}, {"id": "2011.07018", "submitter": "Theresa Stadler", "authors": "Theresa Stadler, Bristena Oprisanu, Carmela Troncoso", "title": "Synthetic Data -- Anonymisation Groundhog Day", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic data has been advertised as a silver-bullet solution to\nprivacy-preserving data publishing that addresses the shortcomings of\ntraditional anonymisation techniques. The promise is that synthetic data drawn\nfrom generative models preserves the statistical properties of the original\ndataset but, at the same time, provides perfect protection against privacy\nattacks. In this work, we present the first quantitative evaluation of the\nprivacy gain of synthetic data publishing and compare it to that of previous\nanonymisation techniques.\n  Our evaluation of a wide range of state-of-the-art generative models\ndemonstrates that synthetic data either does not prevent inference attacks or\ndoes not retain data utility. In other words, we empirically show that\nsynthetic data suffers from the same limitations as traditional anonymisation\ntechniques.\n  Furthermore, we find that, in contrast to traditional anonymisation, the\nprivacy-utility tradeoff of synthetic data publishing is hard to predict.\nBecause it is impossible to predict what signals a synthetic dataset will\npreserve and what information will be lost, synthetic data leads to a highly\nvariable privacy gain and unpredictable utility loss. In summary, we find that\nsynthetic data is far from the holy grail of privacy-preserving data\npublishing.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:58:42 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 12:24:54 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 15:59:34 GMT"}, {"version": "v4", "created": "Thu, 8 Jul 2021 12:29:00 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Stadler", "Theresa", ""], ["Oprisanu", "Bristena", ""], ["Troncoso", "Carmela", ""]]}, {"id": "2011.07019", "submitter": "Edward Chen", "authors": "Edward Chen and Tejas Sudharshan Mathai and Vinit Sarode and Howie\n  Choset and John Galeotti", "title": "A Study of Domain Generalization on Ultrasound-based Multi-Class\n  Segmentation of Arteries, Veins, Ligaments, and Nerves Using Transfer\n  Learning", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying landmarks in the femoral area is crucial for ultrasound (US)\n-based robot-guided catheter insertion, and their presentation varies when\nimaged with different scanners. As such, the performance of past deep\nlearning-based approaches is also narrowly limited to the training data\ndistribution; this can be circumvented by fine-tuning all or part of the model,\nyet the effects of fine-tuning are seldom discussed. In this work, we study the\nUS-based segmentation of multiple classes through transfer learning by\nfine-tuning different contiguous blocks within the model, and evaluating on a\ngamut of US data from different scanners and settings. We propose a simple\nmethod for predicting generalization on unseen datasets and observe\nstatistically significant differences between the fine-tuning methods while\nworking towards domain generalization.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 16:59:20 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Chen", "Edward", ""], ["Mathai", "Tejas Sudharshan", ""], ["Sarode", "Vinit", ""], ["Choset", "Howie", ""], ["Galeotti", "John", ""]]}, {"id": "2011.07057", "submitter": "Dongsheng Luo", "authors": "Dongsheng Luo, Wei Cheng, Wenchao Yu, Bo Zong, Jingchao Ni, Haifeng\n  Chen, Xiang Zhang", "title": "Learning to Drop: Robust Graph Neural Network via Topological Denoising", "comments": "WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) have shown to be powerful tools for graph\nanalytics. The key idea is to recursively propagate and aggregate information\nalong edges of the given graph. Despite their success, however, the existing\nGNNs are usually sensitive to the quality of the input graph. Real-world graphs\nare often noisy and contain task-irrelevant edges, which may lead to suboptimal\ngeneralization performance in the learned GNN models. In this paper, we propose\nPTDNet, a parameterized topological denoising network, to improve the\nrobustness and generalization performance of GNNs by learning to drop\ntask-irrelevant edges. PTDNet prunes task-irrelevant edges by penalizing the\nnumber of edges in the sparsified graph with parameterized networks. To take\ninto consideration of the topology of the entire graph, the nuclear norm\nregularization is applied to impose the low-rank constraint on the resulting\nsparsified graph for better generalization. PTDNet can be used as a key\ncomponent in GNN models to improve their performances on various tasks, such as\nnode classification and link prediction. Experimental studies on both synthetic\nand benchmark datasets show that PTDNet can improve the performance of GNNs\nsignificantly and the performance gain becomes larger for more noisy datasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 18:53:21 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Luo", "Dongsheng", ""], ["Cheng", "Wei", ""], ["Yu", "Wenchao", ""], ["Zong", "Bo", ""], ["Ni", "Jingchao", ""], ["Chen", "Haifeng", ""], ["Zhang", "Xiang", ""]]}, {"id": "2011.07065", "submitter": "Homayoon Beigi", "authors": "Amith Ananthram, Kailash Karthik Saravanakumar, Jessica Huynh, and\n  Homayoon Beigi", "title": "Multi-Modal Emotion Detection with Transfer Learning", "comments": "11 pages, 7 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": "RTI-20201113-01", "categories": "eess.AS cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated emotion detection in speech is a challenging task due to the\ncomplex interdependence between words and the manner in which they are spoken.\nIt is made more difficult by the available datasets; their small size and\nincompatible labeling idiosyncrasies make it hard to build generalizable\nemotion detection systems. To address these two challenges, we present a\nmulti-modal approach that first transfers learning from related tasks in speech\nand text to produce robust neural embeddings and then uses these embeddings to\ntrain a pLDA classifier that is able to adapt to previously unseen emotions and\ndomains. We begin by training a multilayer TDNN on the task of speaker\nidentification with the VoxCeleb corpora and then fine-tune it on the task of\nemotion identification with the Crema-D corpus. Using this network, we extract\nspeech embeddings for Crema-D from each of its layers, generate and concatenate\ntext embeddings for the accompanying transcripts using a fine-tuned BERT model\nand then train an LDA - pLDA classifier on the resulting dense representations.\nWe exhaustively evaluate the predictive power of every component: the TDNN\nalone, speech embeddings from each of its layers alone, text embeddings alone\nand every combination thereof. Our best variant, trained on only VoxCeleb and\nCrema-D and evaluated on IEMOCAP, achieves an EER of 38.05%. Including a\nportion of IEMOCAP during training produces a 5-fold averaged EER of 25.72%\n(For comparison, 44.71% of the gold-label annotations include at least one\nannotator who disagrees).\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 18:58:59 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Ananthram", "Amith", ""], ["Saravanakumar", "Kailash Karthik", ""], ["Huynh", "Jessica", ""], ["Beigi", "Homayoon", ""]]}, {"id": "2011.07068", "submitter": "Santiago L\\'opez-Tapia", "authors": "Santiago L\\'opez-Tapia and Nicol\\'as P\\'erez de la Blanca", "title": "Fast and Robust Cascade Model for Multiple Degradation Single Image\n  Super-Resolution", "comments": "12 pages and 11 figures (8 figures and 3 tables)", "journal-ref": null, "doi": "10.1109/TIP.2021.3074821", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single Image Super-Resolution (SISR) is one of the low-level computer vision\nproblems that has received increased attention in the last few years. Current\napproaches are primarily based on harnessing the power of deep learning models\nand optimization techniques to reverse the degradation model. Owing to its\nhardness, isotropic blurring or Gaussians with small anisotropic deformations\nhave been mainly considered. Here, we widen this scenario by including large\nnon-Gaussian blurs that arise in real camera movements. Our approach leverages\nthe degradation model and proposes a new formulation of the Convolutional\nNeural Network (CNN) cascade model, where each network sub-module is\nconstrained to solve a specific degradation: deblurring or upsampling. A new\ndensely connected CNN-architecture is proposed where the output of each\nsub-module is restricted using some external knowledge to focus it on its\nspecific task. As far we know this use of domain-knowledge to module-level is a\nnovelty in SISR. To fit the finest model, a final sub-module takes care of the\nresidual errors propagated by the previous sub-modules. We check our model with\nthree state of the art (SOTA) datasets in SISR and compare the results with the\nSOTA models. The results show that our model is the only one able to manage our\nwider set of deformations. Furthermore, our model overcomes all current SOTA\nmethods for a standard set of deformations. In terms of computational load, our\nmodel also improves on the two closest competitors in terms of efficiency.\nAlthough the approach is non-blind and requires an estimation of the blur\nkernel, it shows robustness to blur kernel estimation errors, making it a good\nalternative to blind models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:59:49 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["L\u00f3pez-Tapia", "Santiago", ""], ["de la Blanca", "Nicol\u00e1s P\u00e9rez", ""]]}, {"id": "2011.07089", "submitter": "Guillaume Bellegarda", "authors": "Guillaume Bellegarda and Quan Nguyen", "title": "Robust Quadruped Jumping via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we consider a general task of jumping varying distances and\nheights for a quadrupedal robot in noisy environments, such as off of uneven\nterrain and with variable robot dynamics parameters. To accurately jump in such\nconditions, we propose a framework using deep reinforcement learning to\nleverage the complex solution of nonlinear trajectory optimization for\nquadrupedal jumping. While the standalone optimization limits jumping to\ntake-off from flat ground and requires accurate assumption of robot dynamics,\nour proposed approach improves the robustness to allow jumping off of\nsignificantly uneven terrain with variable robot dynamical parameters. Through\nour method, the quadruped is able to jump distances of up to 1 m and heights of\nup to 0.4 m, while being robust to environment noise of foot disturbances of up\nto 0.1 m in height as well as with 5% variability of its body mass and inertia.\nThis behavior is learned through just a few thousand simulated jumps in\nPyBullet, and we perform a sim-to-sim transfer to Gazebo. Video results can be\nfound at https://youtu.be/jkzvL2o3g-s.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 19:04:24 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 05:22:20 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Bellegarda", "Guillaume", ""], ["Nguyen", "Quan", ""]]}, {"id": "2011.07095", "submitter": "Arman Kazemi", "authors": "Arman Kazemi, Mohammad Mehdi Sharifi, Ann Franchesca Laguna, Franz\n  M\\\"uller, Ramin Rajaei, Ricardo Olivo, Thomas K\\\"ampfe, Michael Niemier, X.\n  Sharon Hu", "title": "In-Memory Nearest Neighbor Search with FeFET Multi-Bit\n  Content-Addressable Memories", "comments": "To be published in DATE'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbor (NN) search is an essential operation in many applications,\nsuch as one/few-shot learning and image classification. As such, fast and\nlow-energy hardware support for accurate NN search is highly desirable. Ternary\ncontent-addressable memories (TCAMs) have been proposed to accelerate NN search\nfor few-shot learning tasks by implementing $L_\\infty$ and Hamming distance\nmetrics, but they cannot achieve software-comparable accuracies. This paper\nproposes a novel distance function that can be natively evaluated with\nmulti-bit content-addressable memories (MCAMs) based on ferroelectric FETs\n(FeFETs) to perform a single-step, in-memory NN search. Moreover, this approach\nachieves accuracies comparable to floating-point precision implementations in\nsoftware for NN classification and one/few-shot learning tasks. As an example,\nthe proposed method achieves a 98.34% accuracy for a 5-way, 5-shot\nclassification task for the Omniglot dataset (only 0.8% lower than\nsoftware-based implementations) with a 3-bit MCAM. This represents a 13%\naccuracy improvement over state-of-the-art TCAM-based implementations at\niso-energy and iso-delay. The presented distance function is resilient to the\neffects of FeFET device-to-device variations. Furthermore, this work\nexperimentally demonstrates a 2-bit implementation of FeFET MCAM using AND\narrays from GLOBALFOUNDRIES to further validate proof of concept.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 19:29:31 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kazemi", "Arman", ""], ["Sharifi", "Mohammad Mehdi", ""], ["Laguna", "Ann Franchesca", ""], ["M\u00fcller", "Franz", ""], ["Rajaei", "Ramin", ""], ["Olivo", "Ricardo", ""], ["K\u00e4mpfe", "Thomas", ""], ["Niemier", "Michael", ""], ["Hu", "X. Sharon", ""]]}, {"id": "2011.07101", "submitter": "David S. Hayden", "authors": "David S. Hayden, Sue Zheng, John W. Fisher III", "title": "Efficient Data Association and Uncertainty Quantification for\n  Multi-Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust data association is critical for analysis of long-term motion\ntrajectories in complex scenes. In its absence, trajectory precision suffers\ndue to periods of kinematic ambiguity degrading the quality of follow-on\nanalysis. Common optimization-based approaches often neglect uncertainty\nquantification arising from these events. Consequently, we propose the Joint\nPosterior Tracker (JPT), a Bayesian multi-object tracking algorithm that\nrobustly reasons over the posterior of associations and trajectories. Novel,\npermutation-based proposals are crafted for exploration of posterior modes that\ncorrespond to plausible association hypotheses. JPT exhibits more accurate\nuncertainty representation of data associations with superior performance on\nstandard metrics when compared to existing baselines. We also show the utility\nof JPT applied to automatic scheduling of user-in-the-loop annotations for\nimproved trajectory quality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 19:36:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hayden", "David S.", ""], ["Zheng", "Sue", ""], ["Fisher", "John W.", "III"]]}, {"id": "2011.07105", "submitter": "Florian Fischer", "authors": "Florian Fischer, Miroslav Bachinski, Markus Klar, Arthur Fleig, J\\\"org\n  M\\\"uller", "title": "Reinforcement Learning Control of a Biomechanical Model of the Upper\n  Extremity", "comments": "20 pages, 7 figures, 6 supporting figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the question whether the assumptions of signal-dependent and\nconstant motor noise in a full skeletal model of the human upper extremity,\ntogether with the objective of movement time minimization, can predict reaching\nmovements. We learn a control policy using a motor babbling approach based on\nreinforcement learning, using aimed movements of the tip of the right index\nfinger towards randomly placed 3D targets of varying size. The reward signal is\nthe negative time to reach the target, implying movement time minimization. Our\nbiomechanical model of the upper extremity uses the skeletal structure of the\nUpper Extremity Dynamic Model, including thorax, right shoulder, arm, and hand.\nThe model has 7 actuated degrees of freedom, including shoulder rotation,\nelevation and elevation plane, elbow flexion, forearm rotation, and wrist\nflexion and deviation. To deal with the curse of dimensionality, we use a\nsimplified second-order muscle model acting at each joint instead of individual\nmuscles. We address the lack of gradient provided by the simple reward function\nthrough an adaptive learning curriculum. Our results demonstrate that the\nassumptions of signal-dependent and constant motor noise, together with the\nobjective of movement time minimization, are sufficient for a state-of-the-art\nskeletal model of the human upper extremity to reproduce complex phenomena of\nhuman movement such as Fitts' Law and the 2/3 Power Law. This result supports\nthe idea that the control of the complex human biomechanical system is\nplausible to be determined by a set of simple assumptions and can be easily\nlearned.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 19:49:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Fischer", "Florian", ""], ["Bachinski", "Miroslav", ""], ["Klar", "Markus", ""], ["Fleig", "Arthur", ""], ["M\u00fcller", "J\u00f6rg", ""]]}, {"id": "2011.07114", "submitter": "Xian Yeow Lee", "authors": "Xian Yeow Lee, Yasaman Esfandiari, Kai Liang Tan, Soumik Sarkar", "title": "Query-based Targeted Action-Space Adversarial Policies on Deep\n  Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in computing resources have resulted in the increasing complexity of\ncyber-physical systems (CPS). As the complexity of CPS evolved, the focus has\nshifted from traditional control methods to deep reinforcement learning-based\n(DRL) methods for control of these systems. This is due to the difficulty of\nobtaining accurate models of complex CPS for traditional control. However, to\nsecurely deploy DRL in production, it is essential to examine the weaknesses of\nDRL-based controllers (policies) towards malicious attacks from all angles. In\nthis work, we investigate targeted attacks in the action-space domain, also\ncommonly known as actuation attacks in CPS literature, which perturbs the\noutputs of a controller. We show that a query-based black-box attack model that\ngenerates optimal perturbations with respect to an adversarial goal can be\nformulated as another reinforcement learning problem. Thus, such an adversarial\npolicy can be trained using conventional DRL methods. Experimental results\nshowed that adversarial policies that only observe the nominal policy's output\ngenerate stronger attacks than adversarial policies that observe the nominal\npolicy's input and output. Further analysis reveals that nominal policies whose\noutputs are frequently at the boundaries of the action space are naturally more\nrobust towards adversarial policies. Lastly, we propose the use of adversarial\ntraining with transfer learning to induce robust behaviors into the nominal\npolicy, which decreases the rate of successful targeted attacks by 50%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:25:48 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 21:28:19 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Lee", "Xian Yeow", ""], ["Esfandiari", "Yasaman", ""], ["Tan", "Kai Liang", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2011.07118", "submitter": "Luis Riera", "authors": "Luis G Riera, Matthew E. Carroll, Zhisheng Zhang, Johnathon M. Shook,\n  Sambuddha Ghosal, Tianshuang Gao, Arti Singh, Sourabh Bhattacharya, Baskar\n  Ganapathysubramanian, Asheesh K. Singh, Soumik Sarkar", "title": "Deep Multi-view Image Fusion for Soybean Yield Estimation in Breeding\n  Applications Deep Multi-view Image Fusion for Soybean Yield Estimation in\n  Breeding Applications", "comments": "18 pages, 8 figures, and 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reliable seed yield estimation is an indispensable step in plant breeding\nprograms geared towards cultivar development in major row crops. The objective\nof this study is to develop a machine learning (ML) approach adept at soybean\n[\\textit{Glycine max} L. (Merr.)] pod counting to enable genotype seed yield\nrank prediction from in-field video data collected by a ground robot. To meet\nthis goal, we developed a multi-view image-based yield estimation framework\nutilizing deep learning architectures. Plant images captured from different\nangles were fused to estimate the yield and subsequently to rank soybean\ngenotypes for application in breeding decisions. We used data from controlled\nimaging environment in field, as well as from plant breeding test plots in\nfield to demonstrate the efficacy of our framework via comparing performance\nwith manual pod counting and yield estimation.\n  Our results demonstrate the promise of ML models in making breeding decisions\nwith significant reduction of time and human effort, and opening new breeding\nmethods avenues to develop cultivars.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:37:04 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Riera", "Luis G", ""], ["Carroll", "Matthew E.", ""], ["Zhang", "Zhisheng", ""], ["Shook", "Johnathon M.", ""], ["Ghosal", "Sambuddha", ""], ["Gao", "Tianshuang", ""], ["Singh", "Arti", ""], ["Bhattacharya", "Sourabh", ""], ["Ganapathysubramanian", "Baskar", ""], ["Singh", "Asheesh K.", ""], ["Sarkar", "Soumik", ""]]}, {"id": "2011.07119", "submitter": "Nicola Bastianello", "authors": "Nicola Bastianello", "title": "tvopt: A Python Framework for Time-Varying Optimization", "comments": "Code available here: https://github.com/nicola-bastianello/tvopt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces tvopt, a Python framework for prototyping and\nbenchmarking time-varying (or online) optimization algorithms. The paper first\ndescribes the theoretical approach that informed the development of tvopt. Then\nit discusses the different components of the framework and their use for\nmodeling and solving time-varying optimization problems. In particular, tvopt\nprovides functionalities for defining both centralized and distributed online\nproblems, and a collection of built-in algorithms to solve them, for example\ngradient-based methods, ADMM and other splitting methods. Moreover, the\nframework implements prediction strategies to improve the accuracy of the\nonline solvers. The paper then proposes some numerical results on a benchmark\nproblem and discusses their implementation using tvopt. The code for tvopt is\navailable at https://github.com/nicola-bastianello/tvopt.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:14:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bastianello", "Nicola", ""]]}, {"id": "2011.07122", "submitter": "Riccardo Grazzi", "authors": "Riccardo Grazzi, Massimiliano Pontil, Saverio Salzo", "title": "Convergence Properties of Stochastic Hypergradients", "comments": "added experiments, a table of notation and some comments. 22 pages", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2021), PMLR 130:3826-3834", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization problems are receiving increasing attention in machine\nlearning as they provide a natural framework for hyperparameter optimization\nand meta-learning. A key step to tackle these problems is the efficient\ncomputation of the gradient of the upper-level objective (hypergradient). In\nthis work, we study stochastic approximation schemes for the hypergradient,\nwhich are important when the lower-level problem is empirical risk minimization\non a large dataset. The method that we propose is a stochastic variant of the\napproximate implicit differentiation approach in (Pedregosa, 2016). We provide\nbounds for the mean square error of the hypergradient approximation, under the\nassumption that the lower-level problem is accessible only through a stochastic\nmapping which is a contraction in expectation. In particular, our main bound is\nagnostic to the choice of the two stochastic solvers employed by the procedure.\nWe provide numerical experiments to support our theoretical analysis and to\nshow the advantage of using stochastic hypergradients in practice.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:50:36 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 10:48:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Grazzi", "Riccardo", ""], ["Pontil", "Massimiliano", ""], ["Salzo", "Saverio", ""]]}, {"id": "2011.07124", "submitter": "Brandon Buncher", "authors": "Brandon Buncher, Awshesh Nath Sharma, Matias Carrasco Kind", "title": "Survey2Survey: A deep learning generative model approach for\n  cross-survey image mapping", "comments": "24 pages, 19 figures. Accepted by MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stab294", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, there has been an explosive growth in survey data and\ndeep learning techniques, both of which have enabled great advances for\nastronomy. The amount of data from various surveys from multiple epochs with a\nwide range of wavelengths, albeit with varying brightness and quality, is\noverwhelming, and leveraging information from overlapping observations from\ndifferent surveys has limitless potential in understanding galaxy formation and\nevolution. Synthetic galaxy image generation using physical models has been an\nimportant tool for survey data analysis, while deep learning generative models\nshow great promise. In this paper, we present a novel approach for robustly\nexpanding and improving survey data through cross survey feature translation.\nWe trained two types of neural networks to map images from the Sloan Digital\nSky Survey (SDSS) to corresponding images from the Dark Energy Survey (DES).\nThis map was used to generate false DES representations of SDSS images,\nincreasing the brightness and S/N while retaining important morphological\ninformation. We substantiate the robustness of our method by generating DES\nrepresentations of SDSS images from outside the overlapping region, showing\nthat the brightness and quality are improved even when the source images are of\nlower quality than the training images. Finally, we highlight several images in\nwhich the reconstruction process appears to have removed large artifacts from\nSDSS images. While only an initial application, our method shows promise as a\nmethod for robustly expanding and improving the quality of optical survey data\nand provides a potential avenue for cross-band reconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:54:42 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 17:31:01 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 18:06:35 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Buncher", "Brandon", ""], ["Sharma", "Awshesh Nath", ""], ["Kind", "Matias Carrasco", ""]]}, {"id": "2011.07125", "submitter": "David Pfau", "authors": "James S. Spencer, David Pfau, Aleksandar Botev, W. M. C. Foulkes", "title": "Better, Faster Fermionic Neural Networks", "comments": "To appear at the 3rd NeurIPS Workshop on Machine Learning and\n  Physical Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fermionic Neural Network (FermiNet) is a recently-developed neural\nnetwork architecture that can be used as a wavefunction Ansatz for\nmany-electron systems, and has already demonstrated high accuracy on small\nsystems. Here we present several improvements to the FermiNet that allow us to\nset new records for speed and accuracy on challenging systems. We find that\nincreasing the size of the network is sufficient to reach chemical accuracy on\natoms as large as argon. Through a combination of implementing FermiNet in JAX\nand simplifying several parts of the network, we are able to reduce the number\nof GPU hours needed to train the FermiNet on large systems by an order of\nmagnitude. This enables us to run the FermiNet on the challenging transition of\nbicyclobutane to butadiene and compare against the PauliNet on the\nautomerization of cyclobutadiene, and we achieve results near the state of the\nart for both.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:55:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Spencer", "James S.", ""], ["Pfau", "David", ""], ["Botev", "Aleksandar", ""], ["Foulkes", "W. M. C.", ""]]}, {"id": "2011.07126", "submitter": "Hoda Eldardiry", "authors": "Jiaying Gong and Hoda Eldardiry", "title": "Zero-shot Learning for Relation Extraction", "comments": "11 pages, 7 figures, submitted to WWW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing supervised and few-shot learning relation extraction methods\nhave relied on labeled training data. However, in real-world scenarios, there\nexist many relations for which there is no available training data. We address\nthis issue from the perspective of zero-shot learning (ZSL) which is similar to\nthe way humans learn and recognize new concepts with no prior knowledge. We\npropose a zero-shot learning relation extraction (ZSLRE) framework, which\nfocuses on recognizing novel relations that have no corresponding labeled data\navailable for training. Our proposed ZSLRE model aims to recognize new\nrelations based on prototypical networks that are modified to utilize side\n(auxiliary) information. The additional use of side information allows those\nmodified prototype networks to recognize novel relations in addition to\nrecognized previously known relations. We construct side information from\nlabels and their synonyms, hypernyms of name entities, and keywords. We build\nan automatic hypernym extraction framework to help get hypernyms of various\nname entities directly from the web. We demonstrate using extensive experiments\non two public datasets (NYT and FewRel) that our proposed model significantly\noutperforms state-of-the-art methods on supervised learning, few-shot learning,\nand zero-shot learning tasks. Our experimental results also demonstrate the\neffectiveness and robustness of our proposed model in a combination scenario.\nOnce accepted for publication, we will publish ZSLRE's source code and datasets\nto enable reproducibility and encourage further research.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 20:57:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gong", "Jiaying", ""], ["Eldardiry", "Hoda", ""]]}, {"id": "2011.07137", "submitter": "Harald Stromfelt Mr", "authors": "Harald Str\\\"omfelt, Luke Dickens, Artur d'Avila Garcez, Alessandra\n  Russo", "title": "On the Transferability of VAE Embeddings using Relational Knowledge with\n  Semi-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new model for relational VAE semi-supervision capable of\nbalancing disentanglement and low complexity modelling of relations with\ndifferent symbolic properties. We compare the relative benefits of\nrelation-decoder complexity and latent space structure on both inductive and\ntransductive transfer learning. Our results depict a complex picture where\nenforcing structure on semi-supervised representations can greatly improve\nzero-shot transductive transfer, but may be less favourable or even impact\nnegatively the capacity for inductive transfer.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 21:40:32 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Str\u00f6mfelt", "Harald", ""], ["Dickens", "Luke", ""], ["Garcez", "Artur d'Avila", ""], ["Russo", "Alessandra", ""]]}, {"id": "2011.07142", "submitter": "Alec Koppel", "authors": "Abhishek Chakraborty, Ketan Rajawat, Alec Koppel", "title": "Sparse Representations of Positive Functions via Projected Pseudo-Mirror\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of expected risk minimization when the population\nloss is strongly convex and the target domain of the decision variable is\nrequired to be nonnegative, motivated by the settings of maximum likelihood\nestimation (MLE) and trajectory optimization. We restrict focus to the case\nthat the decision variable belongs to a nonparametric Reproducing Kernel\nHilbert Space (RKHS). To solve it, we consider stochastic mirror descent that\nemploys (i) pseudo-gradients and (ii) projections. Compressive projections are\nexecuted via kernel orthogonal matching pursuit (KOMP), and overcome the fact\nthat the vanilla RKHS parameterization grows unbounded with time. Moreover,\npseudo-gradients are needed, e.g., when stochastic gradients themselves define\nintegrals over unknown quantities that must be evaluated numerically, as in\nestimating the intensity parameter of an inhomogeneous Poisson Process, and\nmulti-class kernel logistic regression with latent multi-kernels. We establish\ntradeoffs between accuracy of convergence in mean and the projection budget\nparameter under constant step-size and compression budget, as well as\nnon-asymptotic bounds on the model complexity. Experiments demonstrate that we\nachieve state-of-the-art accuracy and complexity tradeoffs for inhomogeneous\nPoisson Process intensity estimation and multi-class kernel logistic\nregression.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 21:54:28 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chakraborty", "Abhishek", ""], ["Rajawat", "Ketan", ""], ["Koppel", "Alec", ""]]}, {"id": "2011.07145", "submitter": "Sayantan Choudhury", "authors": "Sayantan Choudhury, Ankan Dutta and Debisree Ray", "title": "Chaos and Complexity from Quantum Neural Network: A study with Diffusion\n  Metric in Machine Learning", "comments": "42 pages, 9 figures, 1 table, , This project is the part of the\n  non-profit virtual international research consortium \"Quantum Aspects of\n  Space-Time and Matter (QASTM)\". Revised version accepted for publication in\n  Journal of High Energy Physics (JHEP)", "journal-ref": "JHEP 04 (2021) 138", "doi": "10.1007/JHEP04(2021)138", "report-no": null, "categories": "hep-th cond-mat.dis-nn cs.LG nlin.CD quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, our prime objective is to study the phenomena of quantum chaos\nand complexity in the machine learning dynamics of Quantum Neural Network\n(QNN). A Parameterized Quantum Circuits (PQCs) in the hybrid quantum-classical\nframework is introduced as a universal function approximator to perform\noptimization with Stochastic Gradient Descent (SGD). We employ a statistical\nand differential geometric approach to study the learning theory of QNN. The\nevolution of parametrized unitary operators is correlated with the trajectory\nof parameters in the Diffusion metric. We establish the parametrized version of\nQuantum Complexity and Quantum Chaos in terms of physically relevant\nquantities, which are not only essential in determining the stability, but also\nessential in providing a very significant lower bound to the generalization\ncapability of QNN. We explicitly prove that when the system executes limit\ncycles or oscillations in the phase space, the generalization capability of QNN\nis maximized. Finally, we have determined the generalization capability bound\non the variance of parameters of the QNN in a steady state condition using\nCauchy Schwartz Inequality.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 10:41:47 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 14:36:03 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Choudhury", "Sayantan", ""], ["Dutta", "Ankan", ""], ["Ray", "Debisree", ""]]}, {"id": "2011.07158", "submitter": "Nicolas Schreuder", "authors": "Evgenii Chzhen and Nicolas Schreuder", "title": "An example of prediction which complies with Demographic Parity and\n  equalizes group-wise risks in the context of regression", "comments": "Presented at the NeurIPS 2020 Workshop on Algorithmic Fairness\n  through the Lens of Causality and Interpretability", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $(X, S, Y) \\in \\mathbb{R}^p \\times \\{1, 2\\} \\times \\mathbb{R}$ be a\ntriplet following some joint distribution $\\mathbb{P}$ with feature vector $X$,\nsensitive attribute $S$ , and target variable $Y$. The Bayes optimal prediction\n$f^*$ which does not produce Disparate Treatment is defined as $f^*(x) =\n\\mathbb{E}[Y | X = x]$. We provide a non-trivial example of a prediction $x \\to\nf(x)$ which satisfies two common group-fairness notions: Demographic Parity\n\\begin{align} (f(X) | S = 1) &\\stackrel{d}{=} (f(X) | S = 2) \\end{align} and\nEqual Group-Wise Risks \\begin{align}\n  \\mathbb{E}[(f^*(X) - f(X))^2 | S = 1] = \\mathbb{E}[(f^*(X) - f(X))^2 | S =\n2]. \\end{align} To the best of our knowledge this is the first explicit\nconstruction of a non-constant predictor satisfying the above. We discuss\nseveral implications of this result on better understanding of mathematical\nnotions of algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 22:46:05 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chzhen", "Evgenii", ""], ["Schreuder", "Nicolas", ""]]}, {"id": "2011.07160", "submitter": "Nan Wu", "authors": "Nan Wu, Pengcheng Li", "title": "Phoebe: Reuse-Aware Online Caching with Reinforcement Learning for\n  Emerging Storage Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.LG cs.OS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With data durability, high access speed, low power efficiency and byte\naddressability, NVMe and SSD, which are acknowledged representatives of\nemerging storage technologies, have been applied broadly in many areas.\nHowever, one key issue with high-performance adoption of these technologies is\nhow to properly define intelligent cache layers such that the performance gap\nbetween emerging technologies and main memory can be well bridged. To this end,\nwe propose Phoebe, a reuse-aware reinforcement learning framework for the\noptimal online caching that is applicable for a wide range of emerging storage\nmodels. By continuous interacting with the cache environment and the data\nstream, Phoebe is capable to extract critical temporal data dependency and\nrelative positional information from a single trace, becoming ever smarter over\ntime. To reduce training overhead during online learning, we utilize periodical\ntraining to amortize costs. Phoebe is evaluated on a set of Microsoft cloud\nstorage workloads. Experiment results show that Phoebe is able to close the gap\nof cache miss rate from LRU and a state-of-the-art online learning based cache\npolicy to the Belady's optimal policy by 70.3% and 52.6%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 22:55:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wu", "Nan", ""], ["Li", "Pengcheng", ""]]}, {"id": "2011.07168", "submitter": "Omid Askarisichani", "authors": "Omid Askarisichani, Elizabeth Y. Huang, Kekoa S. Sato, Noah E.\n  Friedkin, Francesco Bullo, Ambuj K. Singh", "title": "Expertise and confidence explain how social influence evolves along\n  intellective tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the antecedents of individuals' influence in collaborative\nenvironments is an important, practical, and challenging problem. In this\npaper, we study interpersonal influence in small groups of individuals who\ncollectively execute a sequence of intellective tasks. We observe that along an\nissue sequence with feedback, individuals with higher expertise and social\nconfidence are accorded higher interpersonal influence. We also observe that\nlow-performing individuals tend to underestimate their high-performing\nteammate's expertise. Based on these observations, we introduce three\nhypotheses and present empirical and theoretical support for their validity. We\nreport empirical evidence on longstanding theories of transactive memory\nsystems, social comparison, and confidence heuristics on the origins of social\ninfluence. We propose a cognitive dynamical model inspired by these theories to\ndescribe the process by which individuals adjust interpersonal influences over\ntime. We demonstrate the model's accuracy in predicting individuals' influence\nand provide analytical results on its asymptotic behavior for the case with\nidentically performing individuals. Lastly, we propose a novel approach using\ndeep neural networks on a pre-trained text embedding model for predicting the\ninfluence of individuals. Using message contents, message times, and individual\ncorrectness collected during tasks, we are able to accurately predict\nindividuals' self-reported influence over time. Extensive experiments verify\nthe accuracy of the proposed models compared to baselines such as structural\nbalance and reflected appraisal model. While the neural networks model is the\nmost accurate, the dynamical model is the most interpretable for influence\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 23:48:25 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Askarisichani", "Omid", ""], ["Huang", "Elizabeth Y.", ""], ["Sato", "Kekoa S.", ""], ["Friedkin", "Noah E.", ""], ["Bullo", "Francesco", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "2011.07177", "submitter": "Maria Florina Balcan", "authors": "Maria-Florina Balcan", "title": "Data-driven Algorithm Design", "comments": "Chapter 29 of the book Beyond the Worst-Case Analysis of Algorithms,\n  edited by Tim Roughgarden and published by Cambridge University Press (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data driven algorithm design is an important aspect of modern data science\nand algorithm design. Rather than using off the shelf algorithms that only have\nworst case performance guarantees, practitioners often optimize over large\nfamilies of parametrized algorithms and tune the parameters of these algorithms\nusing a training set of problem instances from their domain to determine a\nconfiguration with high expected performance over future instances. However,\nmost of this work comes with no performance guarantees. The challenge is that\nfor many combinatorial problems of significant importance including\npartitioning, subset selection, and alignment problems, a small tweak to the\nparameters can cause a cascade of changes in the algorithm's behavior, so the\nalgorithm's performance is a discontinuous function of its parameters.\n  In this chapter, we survey recent work that helps put data-driven\ncombinatorial algorithm design on firm foundations. We provide strong\ncomputational and statistical performance guarantees, both for the batch and\nonline scenarios where a collection of typical problem instances from the given\napplication are presented either all at once or in an online fashion,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 00:51:57 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Balcan", "Maria-Florina", ""]]}, {"id": "2011.07179", "submitter": "Huiwen Wu", "authors": "Huiwen Wu and Cen Chen and Li Wang", "title": "A Theoretical Perspective on Differentially Private Federated Multi-task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the era of big data, the need to expand the amount of data through data\nsharing to improve model performance has become increasingly compelling. As a\nresult, effective collaborative learning models need to be developed with\nrespect to both privacy and utility concerns. In this work, we propose a new\nfederated multi-task learning method for effective parameter transfer with\ndifferential privacy to protect gradients at the client level. Specifically,\nthe lower layers of the networks are shared across all clients to capture\ntransferable feature representation, while top layers of the network are\ntask-specific for on-client personalization. Our proposed algorithm naturally\nresolves the statistical heterogeneity problem in federated networks. We are,\nto the best of knowledge, the first to provide both privacy and utility\nguarantees for such a proposed federated algorithm. The convergences are proved\nfor the cases with Lipschitz smooth objective functions under the non-convex,\nconvex, and strongly convex settings. Empirical experiment results on different\ndatasets have been conducted to demonstrate the effectiveness of the proposed\nalgorithm and verify the implications of the theoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 00:53:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wu", "Huiwen", ""], ["Chen", "Cen", ""], ["Wang", "Li", ""]]}, {"id": "2011.07183", "submitter": "Fernando Casta\\~neda", "authors": "Fernando Casta\\~neda, Jason J. Choi, Bike Zhang, Claire J. Tomlin and\n  Koushil Sreenath", "title": "Gaussian Process-based Min-norm Stabilizing Controller for\n  Control-Affine Systems with Uncertain Input Effects and Dynamics", "comments": "The first two authors contributed equally. To appear at the 2021\n  American Control Conference (ACC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method to design a min-norm Control Lyapunov Function\n(CLF)-based stabilizing controller for a control-affine system with uncertain\ndynamics using Gaussian Process (GP) regression. In order to estimate both\nstate and input-dependent model uncertainty, we propose a novel compound kernel\nthat captures the control-affine nature of the problem. Furthermore, by the use\nof GP Upper Confidence Bound analysis, we provide probabilistic bounds of the\nregression error, leading to the formulation of a CLF-based stability chance\nconstraint which can be incorporated in a min-norm optimization problem. We\nshow that this resulting optimization problem is convex, and we call it\nGaussian Process-based Control Lyapunov Function Second-Order Cone Program\n(GP-CLF-SOCP). The data-collection process and the training of the GP\nregression model are carried out in an episodic learning fashion. We validate\nthe proposed algorithm and controller in numerical simulations of an inverted\npendulum and a kinematic bicycle model, resulting in stable trajectories which\nare very similar to the ones obtained if we actually knew the true plant\ndynamics.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 01:27:32 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 07:50:29 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Casta\u00f1eda", "Fernando", ""], ["Choi", "Jason J.", ""], ["Zhang", "Bike", ""], ["Tomlin", "Claire J.", ""], ["Sreenath", "Koushil", ""]]}, {"id": "2011.07191", "submitter": "Sabera Talukder", "authors": "George Barnum, Sabera Talukder, Yisong Yue", "title": "On the Benefits of Early Fusion in Multimodal Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligently reasoning about the world often requires integrating data from\nmultiple modalities, as any individual modality may contain unreliable or\nincomplete information. Prior work in multimodal learning fuses input\nmodalities only after significant independent processing. On the other hand,\nthe brain performs multimodal processing almost immediately. This divide\nbetween conventional multimodal learning and neuroscience suggests that a\ndetailed study of early multimodal fusion could improve artificial multimodal\nrepresentations. To facilitate the study of early multimodal fusion, we create\na convolutional LSTM network architecture that simultaneously processes both\naudio and visual inputs, and allows us to select the layer at which audio and\nvisual information combines. Our results demonstrate that immediate fusion of\naudio and visual inputs in the initial C-LSTM layer results in higher\nperforming networks that are more robust to the addition of white noise in both\naudio and visual inputs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 01:58:41 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Barnum", "George", ""], ["Talukder", "Sabera", ""], ["Yue", "Yisong", ""]]}, {"id": "2011.07193", "submitter": "Kei Ota", "authors": "Kei Ota, Devesh K. Jha, Diego Romeres, Jeroen van Baar, Kevin A.\n  Smith, Takayuki Semitsu, Tomoaki Oiki, Alan Sullivan, Daniel Nikovski, and\n  Joshua B. Tenenbaum", "title": "Data-Efficient Learning for Complex and Real-Time Physical Problem\n  Solving using Augmented Simulation", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans quickly solve tasks in novel systems with complex dynamics, without\nrequiring much interaction. While deep reinforcement learning algorithms have\nachieved tremendous success in many complex tasks, these algorithms need a\nlarge number of samples to learn meaningful policies. In this paper, we present\na task for navigating a marble to the center of a circular maze. While this\nsystem is very intuitive and easy for humans to solve, it can be very difficult\nand inefficient for standard reinforcement learning algorithms to learn\nmeaningful policies. We present a model that learns to move a marble in the\ncomplex environment within minutes of interacting with the real system.\nLearning consists of initializing a physics engine with parameters estimated\nusing data from the real system. The error in the physics engine is then\ncorrected using Gaussian process regression, which is used to model the\nresidual between real observations and physics engine simulations. The physics\nengine augmented with the residual model is then used to control the marble in\nthe maze environment using a model-predictive feedback over a receding horizon.\nTo the best of our knowledge, this is the first time that a hybrid model\nconsisting of a full physics engine along with a statistical function\napproximator has been used to control a complex physical system in real-time\nusing nonlinear model-predictive control (NMPC).\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 02:03:08 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 02:30:59 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Ota", "Kei", ""], ["Jha", "Devesh K.", ""], ["Romeres", "Diego", ""], ["van Baar", "Jeroen", ""], ["Smith", "Kevin A.", ""], ["Semitsu", "Takayuki", ""], ["Oiki", "Tomoaki", ""], ["Sullivan", "Alan", ""], ["Nikovski", "Daniel", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2011.07200", "submitter": "Yingtao Luo", "authors": "Ziyang Zhang and Yingtao Luo", "title": "Deep Spatial Learning with Molecular Vibration", "comments": "NeurIPS 2020 Machine Learning for Molecules Workshop, Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning over-fitting caused by data scarcity greatly limits the\napplication of machine learning for molecules. Due to manufacturing processes\ndifference, big data is not always rendered available through computational\nchemistry methods for some tasks, causing data scarcity problem for machine\nlearning algorithms. Here we propose to extract the natural features of\nmolecular structures and rationally distort them to augment the data\navailability. This method allows a machine learning project to leverage the\npowerful fit of physics-informed augmentation for providing significant boost\nto predictive accuracy. Successfully verified by the prediction of rejection\nrate and flux of thin film polyamide nanofiltration membranes, with the\nrelative error dropping from 16.34% to 6.71% and the coefficient of\ndetermination rising from 0.16 to 0.75, the proposed deep spatial learning with\nmolecular vibration is widely instructive for molecular science. Experimental\ncomparison unequivocally demonstrates its superiority over common learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 02:46:43 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zhang", "Ziyang", ""], ["Luo", "Yingtao", ""]]}, {"id": "2011.07213", "submitter": "Wenxuan Zhou", "authors": "Wenxuan Zhou, Sujay Bajracharya, David Held", "title": "PLAS: Latent Action Space for Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of offline reinforcement learning is to learn a policy from a fixed\ndataset, without further interactions with the environment. This setting will\nbe an increasingly more important paradigm for real-world applications of\nreinforcement learning such as robotics, in which data collection is slow and\npotentially dangerous. Existing off-policy algorithms have limited performance\non static datasets due to extrapolation errors from out-of-distribution\nactions. This leads to the challenge of constraining the policy to select\nactions within the support of the dataset during training. We propose to simply\nlearn the Policy in the Latent Action Space (PLAS) such that this requirement\nis naturally satisfied. We evaluate our method on continuous control benchmarks\nin simulation and a deformable object manipulation task with a physical robot.\nWe demonstrate that our method provides competitive performance consistently\nacross various continuous control tasks and different types of datasets,\noutperforming existing offline reinforcement learning methods with explicit\nconstraints. Videos and code are available at\nhttps://sites.google.com/view/latent-policy.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 03:38:38 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhou", "Wenxuan", ""], ["Bajracharya", "Sujay", ""], ["Held", "David", ""]]}, {"id": "2011.07215", "submitter": "Xingyu Lin", "authors": "Xingyu Lin, Yufei Wang, Jake Olkin, David Held", "title": "SoftGym: Benchmarking Deep Reinforcement Learning for Deformable Object\n  Manipulation", "comments": "Conference on Robot Learning, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulating deformable objects has long been a challenge in robotics due to\nits high dimensional state representation and complex dynamics. Recent success\nin deep reinforcement learning provides a promising direction for learning to\nmanipulate deformable objects with data driven methods. However, existing\nreinforcement learning benchmarks only cover tasks with direct state\nobservability and simple low-dimensional dynamics or with relatively simple\nimage-based environments, such as those with rigid objects. In this paper, we\npresent SoftGym, a set of open-source simulated benchmarks for manipulating\ndeformable objects, with a standard OpenAI Gym API and a Python interface for\ncreating new environments. Our benchmark will enable reproducible research in\nthis important area. Further, we evaluate a variety of algorithms on these\ntasks and highlight challenges for reinforcement learning algorithms, including\ndealing with a state representation that has a high intrinsic dimensionality\nand is partially observable. The experiments and analysis indicate the\nstrengths and limitations of existing methods in the context of deformable\nobject manipulation that can help point the way forward for future methods\ndevelopment. Code and videos of the learned policies can be found on our\nproject website.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 03:46:59 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 04:20:49 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Lin", "Xingyu", ""], ["Wang", "Yufei", ""], ["Olkin", "Jake", ""], ["Held", "David", ""]]}, {"id": "2011.07218", "submitter": "Mohammad Taha Toghani", "authors": "Mohammad Taha Toghani, Genevera I. Allen", "title": "MP-Boost: Minipatch Boosting via Adaptive Feature and Observation\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting methods are among the best general-purpose and off-the-shelf machine\nlearning approaches, gaining widespread popularity. In this paper, we seek to\ndevelop a boosting method that yields comparable accuracy to popular AdaBoost\nand gradient boosting methods, yet is faster computationally and whose solution\nis more interpretable. We achieve this by developing MP-Boost, an algorithm\nloosely based on AdaBoost that learns by adaptively selecting small subsets of\ninstances and features, or what we term minipatches (MP), at each iteration. By\nsequentially learning on tiny subsets of the data, our approach is\ncomputationally faster than other classic boosting algorithms. Also as it\nprogresses, MP-Boost adaptively learns a probability distribution on the\nfeatures and instances that upweight the most important features and\nchallenging instances, hence adaptively selecting the most relevant minipatches\nfor learning. These learned probability distributions also aid in\ninterpretation of our method. We empirically demonstrate the interpretability,\ncomparative accuracy, and computational time of our approach on a variety of\nbinary classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 04:26:13 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Toghani", "Mohammad Taha", ""], ["Allen", "Genevera I.", ""]]}, {"id": "2011.07221", "submitter": "Soufiane Belharbi", "authors": "Soufiane Belharbi, J\\'er\\^ome Rony, Jose Dolz, Ismail Ben Ayed, Luke\n  McCaffrey, Eric Granger", "title": "Deep Interpretable Classification and Weakly-Supervised Segmentation of\n  Histology Images via Max-Min Uncertainty", "comments": "15 pages, 5 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised learning (WSL) has recently triggered substantial interest\nas it mitigates the lack of pixel-wise annotations, while enabling\ninterpretable models. Given global image labels, WSL methods yield pixel-level\npredictions (segmentations). Despite their recent success, mostly with natural\nimages, such methods could be seriously challenged when the foreground and\nbackground regions have similar visual cues, yielding high false-positive rates\nin segmentations, as is the case of challenging histology images. WSL training\nis commonly driven by standard classification losses, which implicitly maximize\nmodel confidence and find the discriminative regions linked to classification\ndecisions. Therefore, they lack mechanisms for modeling explicitly\nnon-discriminative regions and reducing false-positive rates. We propose new\nregularization terms, which enable the model to seek both non-discriminative\nand discriminative regions, while discouraging unbalanced segmentations. We\nintroduce high uncertainty as a criterion to localize non-discriminative\nregions that do not affect classifier decision, and describe it with original\nKullback-Leibler (KL) divergence losses evaluating the deviation of posterior\npredictions from the uniform distribution. Our KL terms encourage high\nuncertainty of the model when the latter takes the latent non-discriminative\nregions as input. Our loss integrates: (i) a cross-entropy seeking a\nforeground, where model confidence about class prediction is high; (ii) a KL\nregularizer seeking a background, where model uncertainty is high; and (iii)\nlog-barrier terms discouraging unbalanced segmentations. Comprehensive\nexperiments and ablation studies over the public GlaS colon cancer data show\nsubstantial improvements over state-of-the-art WSL methods, and confirm the\neffect of our new regularizers. Our code is publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 04:45:07 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Belharbi", "Soufiane", ""], ["Rony", "J\u00e9r\u00f4me", ""], ["Dolz", "Jose", ""], ["Ayed", "Ismail Ben", ""], ["McCaffrey", "Luke", ""], ["Granger", "Eric", ""]]}, {"id": "2011.07225", "submitter": "Chencheng Xu", "authors": "Chencheng Xu, Qiao Liu, Minlie Huang, Tao Jiang", "title": "Reinforced Molecular Optimization with Neighborhood-Controlled Grammars", "comments": "12 pages;two figures; NeurIPS 2020", "journal-ref": "Advances in Neural Information Processing Systems, 33 (2020)", "doi": null, "report-no": null, "categories": "cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in the pharmaceutical industry is to design novel molecules\nwith specific desired properties, especially when the property evaluation is\ncostly. Here, we propose MNCE-RL, a graph convolutional policy network for\nmolecular optimization with molecular neighborhood-controlled embedding\ngrammars through reinforcement learning. We extend the original\nneighborhood-controlled embedding grammars to make them applicable to molecular\ngraph generation and design an efficient algorithm to infer grammatical\nproduction rules from given molecules. The use of grammars guarantees the\nvalidity of the generated molecular structures. By transforming molecular\ngraphs to parse trees with the inferred grammars, the molecular structure\ngeneration task is modeled as a Markov decision process where a policy gradient\nstrategy is utilized. In a series of experiments, we demonstrate that our\napproach achieves state-of-the-art performance in a diverse range of molecular\noptimization tasks and exhibits significant superiority in optimizing molecular\nproperties with a limited number of property evaluations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 05:42:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Xu", "Chencheng", ""], ["Liu", "Qiao", ""], ["Huang", "Minlie", ""], ["Jiang", "Tao", ""]]}, {"id": "2011.07227", "submitter": "Hao Sheng", "authors": "Hao Sheng, Jeremy Irvin, Sasankh Munukutla, Shawn Zhang, Christopher\n  Cross, Kyle Story, Rose Rustowicz, Cooper Elsworth, Zutao Yang, Mark Omara,\n  Ritesh Gautam, Robert B. Jackson, Andrew Y. Ng", "title": "OGNet: Towards a Global Oil and Gas Infrastructure Database using Deep\n  Learning on Remotely Sensed Imagery", "comments": "Tackling Climate Change with Machine Learning at NeurIPS 2020\n  (Spotlight talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At least a quarter of the warming that the Earth is experiencing today is due\nto anthropogenic methane emissions. There are multiple satellites in orbit and\nplanned for launch in the next few years which can detect and quantify these\nemissions; however, to attribute methane emissions to their sources on the\nground, a comprehensive database of the locations and characteristics of\nemission sources worldwide is essential. In this work, we develop deep learning\nalgorithms that leverage freely available high-resolution aerial imagery to\nautomatically detect oil and gas infrastructure, one of the largest\ncontributors to global methane emissions. We use the best algorithm, which we\ncall OGNet, together with expert review to identify the locations of oil\nrefineries and petroleum terminals in the U.S. We show that OGNet detects many\nfacilities which are not present in four standard public datasets of oil and\ngas infrastructure. All detected facilities are associated with characteristics\nknown to contribute to methane emissions, including the infrastructure type and\nthe number of storage tanks. The data curated and produced in this study is\nfreely available at http://stanfordmlgroup.github.io/projects/ognet .\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 06:20:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sheng", "Hao", ""], ["Irvin", "Jeremy", ""], ["Munukutla", "Sasankh", ""], ["Zhang", "Shawn", ""], ["Cross", "Christopher", ""], ["Story", "Kyle", ""], ["Rustowicz", "Rose", ""], ["Elsworth", "Cooper", ""], ["Yang", "Zutao", ""], ["Omara", "Mark", ""], ["Gautam", "Ritesh", ""], ["Jackson", "Robert B.", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "2011.07229", "submitter": "Dipankar Sarkar", "authors": "Dipankar Sarkar, Sumit Rai, Ankur Narang", "title": "CatFedAvg: Optimising Communication-efficiency and Classification\n  Accuracy in Federated Learning", "comments": "Supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Federated learning has allowed the training of statistical models over remote\ndevices without the transfer of raw client data. In practice, training in\nheterogeneous and large networks introduce novel challenges in various aspects\nlike network load, quality of client data, security and privacy. Recent works\nin FL have worked on improving communication efficiency and addressing uneven\nclient data distribution independently, but none have provided a unified\nsolution for both challenges. We introduce a new family of Federated Learning\nalgorithms called CatFedAvg which not only improves the communication\nefficiency but improves the quality of learning using a category coverage\nmaximization strategy.\n  We use the FedAvg framework and introduce a simple and efficient step every\nepoch to collect meta-data about the client's training data structure which the\ncentral server uses to request a subset of weight updates. We explore two\ndistinct variations which allow us to further explore the tradeoffs between\ncommunication efficiency and model accuracy. Our experiments based on a vision\nclassification task have shown that an increase of 10% absolute points in\naccuracy using the MNIST dataset with 70% absolute points lower network\ntransfer over FedAvg. We also run similar experiments with Fashion MNIST,\nKMNIST-10, KMNIST-49 and EMNIST-47. Further, under extreme data imbalance\nexperiments for both globally and individual clients, we see the model\nperforming better than FedAvg. The ablation study further explores its\nbehaviour under varying data and client parameter conditions showcasing the\nrobustness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 06:52:02 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sarkar", "Dipankar", ""], ["Rai", "Sumit", ""], ["Narang", "Ankur", ""]]}, {"id": "2011.07248", "submitter": "Thomas Keller", "authors": "T. Anderson Keller, Jorn W.T. Peters, Priyank Jaini, Emiel Hoogeboom,\n  Patrick Forr\\'e, Max Welling", "title": "Self Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient gradient computation of the Jacobian determinant term is a core\nproblem in many machine learning settings, and especially so in the normalizing\nflow framework. Most proposed flow models therefore either restrict to a\nfunction class with easy evaluation of the Jacobian determinant, or an\nefficient estimator thereof. However, these restrictions limit the performance\nof such density models, frequently requiring significant depth to reach desired\nperformance levels. In this work, we propose Self Normalizing Flows, a flexible\nframework for training normalizing flows by replacing expensive terms in the\ngradient by learned approximate inverses at each layer. This reduces the\ncomputational complexity of each layer's exact update from $\\mathcal{O}(D^3)$\nto $\\mathcal{O}(D^2)$, allowing for the training of flow architectures which\nwere otherwise computationally infeasible, while also providing efficient\nsampling. We show experimentally that such models are remarkably stable and\noptimize to similar data likelihood values as their exact gradient\ncounterparts, while training more quickly and surpassing the performance of\nfunctionally constrained counterparts.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 09:51:51 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 12:14:06 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Keller", "T. Anderson", ""], ["Peters", "Jorn W. T.", ""], ["Jaini", "Priyank", ""], ["Hoogeboom", "Emiel", ""], ["Forr\u00e9", "Patrick", ""], ["Welling", "Max", ""]]}, {"id": "2011.07255", "submitter": "Metod Jazbec", "authors": "Metod Jazbec, Michael Pearce, Vincent Fortuin", "title": "Factorized Gaussian Process Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational autoencoders often assume isotropic Gaussian priors and\nmean-field posteriors, hence do not exploit structure in scenarios where we may\nexpect similarity or consistency across latent variables. Gaussian process\nvariational autoencoders alleviate this problem through the use of a latent\nGaussian process, but lead to a cubic inference time complexity. We propose a\nmore scalable extension of these models by leveraging the independence of the\nauxiliary features, which is present in many datasets. Our model factorizes the\nlatent kernel across these features in different dimensions, leading to a\nsignificant speed-up (in theory and practice), while empirically performing\ncomparably to existing non-scalable approaches. Moreover, our approach allows\nfor additional modeling of global latent information and for more general\nextrapolation to unseen input combinations.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 10:24:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jazbec", "Metod", ""], ["Pearce", "Michael", ""], ["Fortuin", "Vincent", ""]]}, {"id": "2011.07267", "submitter": "Franco Manessi", "authors": "Franco Manessi, Alessandro Rozza", "title": "Graph-Based Neural Network Models with Multiple Self-Supervised\n  Auxiliary Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning is currently gaining a lot of attention, as it\nallows neural networks to learn robust representations from large quantities of\nunlabeled data. Additionally, multi-task learning can further improve\nrepresentation learning by training networks simultaneously on related tasks,\nleading to significant performance improvements. In this paper, we propose\nthree novel self-supervised auxiliary tasks to train graph-based neural network\nmodels in a multi-task fashion. Since Graph Convolutional Networks are among\nthe most promising approaches for capturing relationships among structured data\npoints, we use them as a building block to achieve competitive results on\nstandard semi-supervised graph classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 11:09:51 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 14:37:52 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Manessi", "Franco", ""], ["Rozza", "Alessandro", ""]]}, {"id": "2011.07274", "submitter": "Serkan Sulun", "authors": "Serkan Sulun, Matthew E. P. Davies", "title": "On Filter Generalization for Music Bandwidth Extension Using Deep Neural\n  Networks", "comments": "Qualitative examples on https://serkansulun.com/bwe. Source code on\n  https://github.com/serkansulun/deep-music-enhancer", "journal-ref": null, "doi": "10.1109/JSTSP.2020.3037485", "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address a sub-topic of the broad domain of audio\nenhancement, namely musical audio bandwidth extension. We formulate the\nbandwidth extension problem using deep neural networks, where a band-limited\nsignal is provided as input to the network, with the goal of reconstructing a\nfull-bandwidth output. Our main contribution centers on the impact of the\nchoice of low pass filter when training and subsequently testing the network.\nFor two different state of the art deep architectures, ResNet and U-Net, we\ndemonstrate that when the training and testing filters are matched,\nimprovements in signal-to-noise ratio (SNR) of up to 7dB can be obtained.\nHowever, when these filters differ, the improvement falls considerably and\nunder some training conditions results in a lower SNR than the band-limited\ninput. To circumvent this apparent overfitting to filter shape, we propose a\ndata augmentation strategy which utilizes multiple low pass filters during\ntraining and leads to improved generalization to unseen filtering conditions at\ntest time.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 11:41:28 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 08:45:20 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Sulun", "Serkan", ""], ["Davies", "Matthew E. P.", ""]]}, {"id": "2011.07280", "submitter": "Piyumal Demotte", "authors": "Lahiru Senevirathne, Piyumal Demotte, Binod Karunanayake, Udyogi\n  Munasinghe, Surangika Ranathunga", "title": "Sentiment Analysis for Sinhala Language using Deep Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the high impact of the fast-evolving fields of machine learning and\ndeep learning, Natural Language Processing (NLP) tasks have further obtained\ncomprehensive performances for highly resourced languages such as English and\nChinese. However Sinhala, which is an under-resourced language with a rich\nmorphology, has not experienced these advancements. For sentiment analysis,\nthere exists only two previous research with deep learning approaches, which\nfocused only on document-level sentiment analysis for the binary case. They\nexperimented with only three types of deep learning models. In contrast, this\npaper presents a much comprehensive study on the use of standard sequence\nmodels such as RNN, LSTM, Bi-LSTM, as well as more recent state-of-the-art\nmodels such as hierarchical attention hybrid neural networks, and capsule\nnetworks. Classification is done at document-level but with more granularity by\nconsidering POSITIVE, NEGATIVE, NEUTRAL, and CONFLICT classes. A data set of\n15059 Sinhala news comments, annotated with these four classes and a corpus\nconsists of 9.48 million tokens are publicly released. This is the largest\nsentiment annotated data set for Sinhala so far.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 12:02:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Senevirathne", "Lahiru", ""], ["Demotte", "Piyumal", ""], ["Karunanayake", "Binod", ""], ["Munasinghe", "Udyogi", ""], ["Ranathunga", "Surangika", ""]]}, {"id": "2011.07290", "submitter": "Roxana R\\u{a}dulescu", "authors": "Roxana R\\u{a}dulescu, Timothy Verstraeten, Yijie Zhang, Patrick\n  Mannion, Diederik M. Roijers, Ann Now\\'e", "title": "Opponent Learning Awareness and Modelling in Multi-Objective Normal Form\n  Games", "comments": "Under review since 14 November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world multi-agent interactions consider multiple distinct criteria,\ni.e. the payoffs are multi-objective in nature. However, the same\nmulti-objective payoff vector may lead to different utilities for each\nparticipant. Therefore, it is essential for an agent to learn about the\nbehaviour of other agents in the system. In this work, we present the first\nstudy of the effects of such opponent modelling on multi-objective multi-agent\ninteractions with non-linear utilities. Specifically, we consider two-player\nmulti-objective normal form games with non-linear utility functions under the\nscalarised expected returns optimisation criterion. We contribute novel\nactor-critic and policy gradient formulations to allow reinforcement learning\nof mixed strategies in this setting, along with extensions that incorporate\nopponent policy reconstruction and learning with opponent learning awareness\n(i.e., learning while considering the impact of one's policy when anticipating\nthe opponent's learning step). Empirical results in five different MONFGs\ndemonstrate that opponent learning awareness and modelling can drastically\nalter the learning dynamics in this setting. When equilibria are present,\nopponent modelling can confer significant benefits on agents that implement it.\nWhen there are no Nash equilibria, opponent learning awareness and modelling\nallows agents to still converge to meaningful solutions that approximate\nequilibria.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 12:35:32 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["R\u0103dulescu", "Roxana", ""], ["Verstraeten", "Timothy", ""], ["Zhang", "Yijie", ""], ["Mannion", "Patrick", ""], ["Roijers", "Diederik M.", ""], ["Now\u00e9", "Ann", ""]]}, {"id": "2011.07312", "submitter": "Fabian Beigang", "authors": "Fabian Beigang", "title": "Shortcomings of Counterfactual Fairness and a Proposed Modification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I argue that counterfactual fairness does not constitute a\nnecessary condition for an algorithm to be fair, and subsequently suggest how\nthe constraint can be modified in order to remedy this shortcoming. To this\nend, I discuss a hypothetical scenario in which counterfactual fairness and an\nintuitive judgment of fairness come apart. Then, I turn to the question how the\nconcept of discrimination can be explicated in order to examine the\nshortcomings of counterfactual fairness as a necessary condition of algorithmic\nfairness in more detail. I then incorporate the insights of this analysis into\na novel fairness constraint, causal relevance fairness, which is a modification\nof the counterfactual fairness constraint that seems to circumvent its\nshortcomings.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 14:49:51 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Beigang", "Fabian", ""]]}, {"id": "2011.07313", "submitter": "Kaushil Mangaroliya", "authors": "Kaushil Mangaroliya, Het Patel", "title": "Classification of Reverse-Engineered Class Diagram and\n  Forward-Engineered Class Diagram using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  UML Class diagram is very important to visualize the whole software we are\nworking on and helps understand the whole system in the easiest way possible by\nshowing the system classes, its attributes, methods, and relations with other\nobjects. In the real world, there are two types of Class diagram engineers work\nwith namely 1) Forward Engineered Class Diagram (FwCD) which are hand-made as\npart of the forward-looking development process, and 2). Reverse Engineered\nClass Diagram (RECD) which are those diagrams that are reverse engineered from\nthe source code. In the software industry while working with new open software\nprojects it is important to know which type of class diagram it is. Which UML\ndiagram was used in a particular project is an important factor to be known? To\nsolve this problem, we propose to build a classifier that can classify a UML\ndiagram into FwCD or RECD. We propose to solve this problem by using a\nsupervised Machine Learning technique. The approach in this involves analyzing\nthe features that are useful in classifying class diagrams. Different Machine\nLearning models are used in this process and the Random Forest algorithm has\nproved to be the best out of all. Performance testing was done on 999 Class\ndiagrams.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 14:56:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mangaroliya", "Kaushil", ""], ["Patel", "Het", ""]]}, {"id": "2011.07318", "submitter": "Cristian Bodnar", "authors": "Cristian Bodnar, Karol Hausman, Gabriel Dulac-Arnold, Rico\n  Jonschkowski", "title": "A Geometric Perspective on Self-Supervised Policy Adaptation", "comments": "Contains 17 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging aspects of real-world reinforcement learning (RL)\nis the multitude of unpredictable and ever-changing distractions that could\ndivert an agent from what was tasked to do in its training environment. While\nan agent could learn from reward signals to ignore them, the complexity of the\nreal-world can make rewards hard to acquire, or, at best, extremely sparse. A\nrecent class of self-supervised methods have shown promise that reward-free\nadaptation under challenging distractions is possible. However, previous work\nfocused on a short one-episode adaptation setting. In this paper, we consider a\nlong-term adaptation setup that is more akin to the specifics of the real-world\nand propose a geometric perspective on self-supervised adaptation. We\nempirically describe the processes that take place in the embedding space\nduring this adaptation process, reveal some of its undesirable effects on\nperformance and show how they can be eliminated. Moreover, we theoretically\nstudy how actor-based and actor-free agents can further generalise to the\ntarget environment by manipulating the geometry of the manifolds described by\nthe actor and critic functions.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 15:16:43 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bodnar", "Cristian", ""], ["Hausman", "Karol", ""], ["Dulac-Arnold", "Gabriel", ""], ["Jonschkowski", "Rico", ""]]}, {"id": "2011.07332", "submitter": "Nihal Acharya Adde", "authors": "Nihal Acharya Adde, Thilo Moshagen", "title": "Classification based on invisible features and thereby finding the\n  effect of tuberculosis vaccine on COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the case of clustered data, an artificial neural network with logcosh loss\nfunction learns the bigger cluster rather than the mean of the two. Even more\nso, the ANN when used for regression of a set-valued function, will learn a\nvalue close to one of the choices, in other words, it learns one branch of the\nset-valued function with high accuracy. This work suggests a method that uses\nartificial neural networks with logcosh loss to find the branches of set-valued\nmappings in parameter-outcome sample sets and classifies the samples according\nto those branches. The method not only classifies the data based on these\nbranches but also provides an accurate prediction for the majority cluster. The\nmethod successfully classifies the data based on an invisible feature. A neural\nnetwork was successfully established to predict the total number of cases, the\nlogarithmic total number of cases, deaths, active cases and other relevant data\nof the coronavirus for each German district from a number of input variables.\nAs it has been speculated that the Tuberculosis vaccine provides protection\nagainst the virus and since East Germany was vaccinated before reunification,\nan attempt was made to classify the Eastern and Western German districts by\nconsidering the vaccine information as an invisible feature.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 16:42:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Adde", "Nihal Acharya", ""], ["Moshagen", "Thilo", ""]]}, {"id": "2011.07343", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Vincent Gripon, Antonio Ortega", "title": "Representing Deep Neural Networks Latent Space Geometries with Graphs", "comments": "15 pages, submitted to MDPI Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) has attracted a lot of attention for its ability to reach\nstate-of-the-art performance in many machine learning tasks. The core principle\nof DL methods consists in training composite architectures in an end-to-end\nfashion, where inputs are associated with outputs trained to optimize an\nobjective function. Because of their compositional nature, DL architectures\nnaturally exhibit several intermediate representations of the inputs, which\nbelong to so-called latent spaces. When treated individually, these\nintermediate representations are most of the time unconstrained during the\nlearning process, as it is unclear which properties should be favored. However,\nwhen processing a batch of inputs concurrently, the corresponding set of\nintermediate representations exhibit relations (what we call a geometry) on\nwhich desired properties can be sought. In this work, we show that it is\npossible to introduce constraints on these latent geometries to address various\nproblems. In more details, we propose to represent geometries by constructing\nsimilarity graphs from the intermediate representations obtained when\nprocessing a batch of inputs. By constraining these Latent Geometry Graphs\n(LGGs), we address the three following problems: i) Reproducing the behavior of\na teacher architecture is achieved by mimicking its geometry, ii) Designing\nefficient embeddings for classification is achieved by targeting specific\ngeometries, and iii) Robustness to deviations on inputs is achieved via\nenforcing smooth variation of geometry between consecutive latent spaces. Using\nstandard vision benchmarks, we demonstrate the ability of the proposed\ngeometry-based methods in solving the considered problems.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 17:21:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lassance", "Carlos", ""], ["Gripon", "Vincent", ""], ["Ortega", "Antonio", ""]]}, {"id": "2011.07347", "submitter": "Cheng-I Lai", "authors": "Fan-Keng Sun, Cheng-I Lai", "title": "Conditioned Natural Language Generation using only Unconditioned\n  Language Model: An Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transformer-based language models have shown to be very powerful for natural\nlanguage generation (NLG). However, text generation conditioned on some user\ninputs, such as topics or attributes, is non-trivial. Past approach relies on\neither modifying the original LM architecture, re-training the LM on corpora\nwith attribute labels, or having separately trained `guidance models' to guide\ntext generation in decoding. We argued that the above approaches are not\nnecessary, and the original unconditioned LM is sufficient for conditioned NLG.\nWe evaluated our approaches by the samples' fluency and diversity with\nautomated and human evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 17:45:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sun", "Fan-Keng", ""], ["Lai", "Cheng-I", ""]]}, {"id": "2011.07355", "submitter": "Jamie Hayes", "authors": "Jamie Hayes, Krishnamurthy (Dj) Dvijotham, Yutian Chen, Sander\n  Dieleman, Pushmeet Kohli, Norman Casagrande", "title": "Towards transformation-resilient provenance detection of digital media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in deep generative models have made it possible to synthesize\nimages, videos and audio signals that are difficult to distinguish from natural\nsignals, creating opportunities for potential abuse of these capabilities. This\nmotivates the problem of tracking the provenance of signals, i.e., being able\nto determine the original source of a signal. Watermarking the signal at the\ntime of signal creation is a potential solution, but current techniques are\nbrittle and watermark detection mechanisms can easily be bypassed by applying\npost-processing transformations (cropping images, shifting pitch in the audio\netc.). In this paper, we introduce ReSWAT (Resilient Signal Watermarking via\nAdversarial Training), a framework for learning transformation-resilient\nwatermark detectors that are able to detect a watermark even after a signal has\nbeen through several post-processing transformations. Our detection method can\nbe applied to domains with continuous data representations such as images,\nvideos or sound signals. Experiments on watermarking image and audio signals\nshow that our method can reliably detect the provenance of a signal, even if it\nhas been through several post-processing transformations, and improve upon\nrelated work in this setting. Furthermore, we show that for specific kinds of\ntransformations (perturbations bounded in the L2 norm), we can even get formal\nguarantees on the ability of our model to detect the watermark. We provide\nqualitative examples of watermarked image and audio samples in\nhttps://drive.google.com/open?id=1-yZ0WIGNu2Iez7UpXBjtjVgZu3jJjFga.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 18:08:07 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hayes", "Jamie", "", "Dj"], ["Krishnamurthy", "", "", "Dj"], ["Dvijotham", "", ""], ["Chen", "Yutian", ""], ["Dieleman", "Sander", ""], ["Kohli", "Pushmeet", ""], ["Casagrande", "Norman", ""]]}, {"id": "2011.07357", "submitter": "Andrew Melnik", "authors": "Augustin Harter, Andrew Melnik, Gaurav Kumar, Dhruv Agarwal, Animesh\n  Garg, Helge Ritter", "title": "Solving Physics Puzzles by Reasoning about Paths", "comments": "1st NeurIPS workshop on Interpretable Inductive Biases and Physically\n  Structured Learning (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new deep learning model for goal-driven tasks that require\nintuitive physical reasoning and intervention in the scene to achieve a desired\nend goal. Its modular structure is motivated by hypothesizing a sequence of\nintuitive steps that humans apply when trying to solve such a task. The model\nfirst predicts the path the target object would follow without intervention and\nthe path the target object should follow in order to solve the task. Next, it\npredicts the desired path of the action object and generates the placement of\nthe action object. All components of the model are trained jointly in a\nsupervised way; each component receives its own learning signal but learning\nsignals are also backpropagated through the entire architecture. To evaluate\nthe model we use PHYRE - a benchmark test for goal-driven physical reasoning in\n2D mechanics puzzles.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 18:21:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Harter", "Augustin", ""], ["Melnik", "Andrew", ""], ["Kumar", "Gaurav", ""], ["Agarwal", "Dhruv", ""], ["Garg", "Animesh", ""], ["Ritter", "Helge", ""]]}, {"id": "2011.07365", "submitter": "Arunesh Mittal", "authors": "Arunesh Mittal, Scott Linderman, John Paisley, Paul Sajda", "title": "Bayesian recurrent state space model for rs-fMRI", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a hierarchical Bayesian recurrent state space model for modeling\nswitching network connectivity in resting state fMRI data. Our model allows us\nto uncover shared network patterns across disease conditions. We evaluate our\nmethod on the ADNI2 dataset by inferring latent state patterns corresponding to\naltered neural circuits in individuals with Mild Cognitive Impairment (MCI). In\naddition to states shared across healthy and individuals with MCI, we discover\nlatent states that are predominantly observed in individuals with MCI. Our\nmodel outperforms current state of the art deep learning method on ADNI2\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 18:53:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mittal", "Arunesh", ""], ["Linderman", "Scott", ""], ["Paisley", "John", ""], ["Sajda", "Paul", ""]]}, {"id": "2011.07368", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra, Sebastian Hofstatter, Hamed Zamani and Nick Craswell", "title": "Conformer-Kernel with Query Term Independence at TREC 2020 Deep Learning\n  Track", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We benchmark Conformer-Kernel models under the strict blind evaluation\nsetting of the TREC 2020 Deep Learning track. In particular, we study the\nimpact of incorporating: (i) Explicit term matching to complement matching\nbased on learned representations (i.e., the \"Duet principle\"), (ii) query term\nindependence (i.e., the \"QTI assumption\") to scale the model to the full\nretrieval setting, and (iii) the ORCAS click data as an additional document\ndescription field. We find evidence which supports that all three\naforementioned strategies can lead to improved retrieval quality.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 19:03:24 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 23:57:45 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mitra", "Bhaskar", ""], ["Hofstatter", "Sebastian", ""], ["Zamani", "Hamed", ""], ["Craswell", "Nick", ""]]}, {"id": "2011.07372", "submitter": "Risul Islam", "authors": "Risul Islam, Andrey Lokhov, Nathan Lemons, Michalis Faloutsos", "title": "Mobility Map Inference from Thermal Modeling of a Building", "comments": "8 figures, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We consider the problem of inferring the mobility map, which is the\ndistribution of the building occupants at each timestamp, from the temperatures\nof the rooms. We also want to explore the effects of noise in the temperature\nmeasurement, room layout, etc. in the reconstruction of the movement of people\nwithin the building. Our proposed algorithm tackles down the aforementioned\nchallenges leveraging a parameter learner, the modified Least Square Estimator.\nIn the absence of a complete data set with mobility map, room and ambient\ntemperatures, and HVAC data in the public domain, we simulate a physics-based\nthermal model of the rooms in a building and evaluate the performance of our\ninference algorithm on this simulated data. We find an upper bound of the noise\nstandard deviation (<= 1F) in the input temperature data of our model. Within\nthis bound, our algorithm can reconstruct the mobility map with a reasonable\nreconstruction error. Our work can be used in a wide range of applications, for\nexample, ensuring the physical security of office buildings, elderly and infant\nmonitoring, building resources management, emergency building evacuation, and\nvulnerability assessment of HVAC data. Our work brings together multiple\nresearch areas, Thermal Modeling and Parameter Estimation, towards achieving a\ncommon goal of inferring the distribution of people within a large office\nbuilding.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 19:19:03 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Islam", "Risul", ""], ["Lokhov", "Andrey", ""], ["Lemons", "Nathan", ""], ["Faloutsos", "Michalis", ""]]}, {"id": "2011.07384", "submitter": "Valts Blukis", "authors": "Valts Blukis, Ross A. Knepper, Yoav Artzi", "title": "Few-shot Object Grounding and Mapping for Natural Language Robot\n  Instruction Following", "comments": "4th Conference on Robot Learning (CoRL 2020), Cambridge MA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a robot policy to follow natural language\ninstructions that can be easily extended to reason about new objects. We\nintroduce a few-shot language-conditioned object grounding method trained from\naugmented reality data that uses exemplars to identify objects and align them\nto their mentions in instructions. We present a learned map representation that\nencodes object locations and their instructed use, and construct it from our\nfew-shot grounding output. We integrate this mapping approach into an\ninstruction-following policy, thereby allowing it to reason about previously\nunseen objects at test-time by simply adding exemplars. We evaluate on the task\nof learning to map raw observations and instructions to continuous control of a\nphysical quadcopter. Our approach significantly outperforms the prior state of\nthe art in the presence of new objects, even when the prior approach observes\nall objects during training.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 20:35:20 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Blukis", "Valts", ""], ["Knepper", "Ross A.", ""], ["Artzi", "Yoav", ""]]}, {"id": "2011.07388", "submitter": "Shahriar Iravanian", "authors": "Shahriar Iravanian", "title": "Discovery of the Hidden State in Ionic Models Using a Domain-Specific\n  Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ionic models, the set of ordinary differential equations (ODEs) describing\nthe time evolution of the state of excitable cells, are the cornerstone of\nmodeling in neuro- and cardiac electrophysiology. Modern ionic models can have\ntens of state variables and hundreds of tunable parameters. Fitting ionic\nmodels to experimental data, which usually covers only a limited subset of\nstate variables, remains a challenging problem. In this paper, we describe a\nrecurrent neural network architecture designed specifically to encode ionic\nmodels. The core of the model is a Gating Neural Network (GNN) layer, capturing\nthe dynamics of classic (Hodgkin-Huxley) gating variables. The network is\ntrained in two steps: first, it learns the theoretical model coded in a set of\nODEs, and second, it is retrained on experimental data. The retrained network\nis interpretable, such that its results can be incorporated back into the model\nODEs. We tested the GNN networks using simulated ventricular action potential\nsignals and showed that it could deduce physiologically-feasible alterations of\nionic currents. Such domain-specific neural networks can be employed in the\nexploratory phase of data assimilation before further fine-tuning using\nstandard optimization techniques.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:13:41 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Iravanian", "Shahriar", ""]]}, {"id": "2011.07394", "submitter": "Robert Henderson", "authors": "Robert D. E. Henderson, Xin Yi, Scott J. Adams and Paul Babyn", "title": "Automatic classification of multiple catheters in neonatal radiographs\n  with deep learning", "comments": "10 pages, 5 figures (+1 suppl.), 2 tables (+2 suppl.). Submitted to\n  Journal of Digital Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and evaluate a deep learning algorithm to classify multiple\ncatheters on neonatal chest and abdominal radiographs. A convolutional neural\nnetwork (CNN) was trained using a dataset of 777 neonatal chest and abdominal\nradiographs, with a split of 81%-9%-10% for training-validation-testing,\nrespectively. We employed ResNet-50 (a CNN), pre-trained on ImageNet. Ground\ntruth labelling was limited to tagging each image to indicate the presence or\nabsence of endotracheal tubes (ETTs), nasogastric tubes (NGTs), and umbilical\narterial and venous catheters (UACs, UVCs). The data set included 561 images\ncontaining 2 or more catheters, 167 images with only one, and 49 with none.\nPerformance was measured with average precision (AP), calculated from the area\nunder the precision-recall curve. On our test data, the algorithm achieved an\noverall AP (95% confidence interval) of 0.977 (0.679-0.999) for NGTs, 0.989\n(0.751-1.000) for ETTs, 0.979 (0.873-0.997) for UACs, and 0.937 (0.785-0.984)\nfor UVCs. Performance was similar for the set of 58 test images consisting of 2\nor more catheters, with an AP of 0.975 (0.255-1.000) for NGTs, 0.997\n(0.009-1.000) for ETTs, 0.981 (0.797-0.998) for UACs, and 0.937 (0.689-0.990)\nfor UVCs. Our network thus achieves strong performance in the simultaneous\ndetection of these four catheter types. Radiologists may use such an algorithm\nas a time-saving mechanism to automate reporting of catheters on radiographs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:27:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Henderson", "Robert D. E.", ""], ["Yi", "Xin", ""], ["Adams", "Scott J.", ""], ["Babyn", "Paul", ""]]}, {"id": "2011.07396", "submitter": "Ali Septiandri", "authors": "Ali Akbar Septiandri, Aditiawarman, Roy Tjiong, Erlina Burhan, Anuraj\n  Shankar", "title": "Cost-Sensitive Machine Learning Classification for Mass Tuberculosis\n  Verbal Screening", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score-based algorithms for tuberculosis (TB) verbal screening perform poorly,\ncausing misclassification that leads to missed cases and unnecessary costly\nlaboratory tests for false positives. We compared score-based classification\ndefined by clinicians to machine learning classification such as SVM-RBF,\nlogistic regression, and XGBoost. We restricted our analyses to data from\nadults, the population most affected by TB, and investigated the difference\nbetween untuned and unweighted classifiers to the cost-sensitive ones.\nPredictions were compared with the corresponding GeneXpert MTB/Rif results.\nAfter adjusting the weight of the positive class to 40 for XGBoost, we achieved\n96.64% sensitivity and 35.06% specificity. As such, the sensitivity of our\nidentifier increased by 1.26% while specificity increased by 13.19% in absolute\nvalue compared to the traditional score-based method defined by our clinicians.\nOur approach further demonstrated that only 2000 data points were sufficient to\nenable the model to converge. The results indicate that even with limited data\nwe can actually devise a better method to identify TB suspects from verbal\nscreening.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:41:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Septiandri", "Ali Akbar", ""], ["Aditiawarman", "", ""], ["Tjiong", "Roy", ""], ["Burhan", "Erlina", ""], ["Shankar", "Anuraj", ""]]}, {"id": "2011.07401", "submitter": "Bai Liu", "authors": "Bai Liu, Qiaomin Xie, Eytan Modiano", "title": "RL-QN: A Reinforcement Learning Framework for Optimal Control of\n  Queueing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advance of information technology, network systems have become\nincreasingly complex and hence the underlying system dynamics are often unknown\nor difficult to characterize. Finding a good network control policy is of\nsignificant importance to achieve desirable network performance (e.g., high\nthroughput or low delay). In this work, we consider using model-based\nreinforcement learning (RL) to learn the optimal control policy for queueing\nnetworks so that the average job delay (or equivalently the average queue\nbacklog) is minimized. Traditional approaches in RL, however, cannot handle the\nunbounded state spaces of the network control problem. To overcome this\ndifficulty, we propose a new algorithm, called Reinforcement Learning for\nQueueing Networks (RL-QN), which applies model-based RL methods over a finite\nsubset of the state space, while applying a known stabilizing policy for the\nrest of the states. We establish that the average queue backlog under RL-QN\nwith an appropriately constructed subset can be arbitrarily close to the\noptimal result. We evaluate RL-QN in dynamic server allocation, routing and\nswitching problems. Simulation results show that RL-QN minimizes the average\nqueue backlog effectively.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 22:12:27 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Liu", "Bai", ""], ["Xie", "Qiaomin", ""], ["Modiano", "Eytan", ""]]}, {"id": "2011.07403", "submitter": "Idris Abdulmumin", "authors": "Idris Abdulmumin, Bashir Shehu Galadanci, Abubakar Isa, Ismaila Idris\n  Sinan", "title": "A Hybrid Approach for Improved Low Resource Neural Machine Translation\n  using Monolingual Data", "comments": "14 pages, 4 figures, 9 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many language pairs are low resource, meaning the amount and/or quality of\navailable parallel data is not sufficient to train a neural machine translation\n(NMT) model which can reach an acceptable standard of accuracy. Many works have\nexplored using the readily available monolingual data in either or both of the\nlanguages to improve the standard of translation models in low, and even high,\nresource languages. One of the most successful of such works is the\nback-translation that utilizes the translations of the target language\nmonolingual data to increase the amount of the training data. The quality of\nthe backward model which is trained on the available parallel data has been\nshown to determine the performance of the back-translation approach. Despite\nthis, only the forward model is improved on the monolingual target data in\nstandard back-translation. A previous study proposed an iterative\nback-translation approach for improving both models over several iterations.\nBut unlike in the traditional back-translation, it relied on both the target\nand source monolingual data. This work, therefore, proposes a novel approach\nthat enables both the backward and forward models to benefit from the\nmonolingual target data through a hybrid of self-learning and back-translation\nrespectively. Experimental results have shown the superiority of the proposed\napproach over the traditional back-translation method on English-German low\nresource neural machine translation. We also proposed an iterative\nself-learning approach that outperforms the iterative back-translation while\nalso relying only on the monolingual target data and require the training of\nless models.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 22:18:45 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 15:44:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Abdulmumin", "Idris", ""], ["Galadanci", "Bashir Shehu", ""], ["Isa", "Abubakar", ""], ["Sinan", "Ismaila Idris", ""]]}, {"id": "2011.07406", "submitter": "Ayse Cakmak", "authors": "Ayse S. Cakmak, Nina Thigpen, Garrett Honke, Erick Perez Alday, Ali\n  Bahrami Rad, Rebecca Adaimi, Chia Jung Chang, Qiao Li, Pramod Gupta, Thomas\n  Neylan, Samuel A. McLean, Gari D. Clifford", "title": "Using Convolutional Variational Autoencoders to Predict Post-Trauma\n  Health Outcomes from Actigraphy Data", "comments": "Fixed typo in author affiliations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression and post-traumatic stress disorder (PTSD) are psychiatric\nconditions commonly associated with experiencing a traumatic event. Estimating\nmental health status through non-invasive techniques such as activity-based\nalgorithms can help to identify successful early interventions. In this work,\nwe used locomotor activity captured from 1113 individuals who wore a research\ngrade smartwatch post-trauma. A convolutional variational autoencoder (VAE)\narchitecture was used for unsupervised feature extraction from four weeks of\nactigraphy data. By using VAE latent variables and the participant's pre-trauma\nphysical health status as features, a logistic regression classifier achieved\nan area under the receiver operating characteristic curve (AUC) of 0.64 to\nestimate mental health outcomes. The results indicate that the VAE model is a\npromising approach for actigraphy data analysis for mental health outcomes in\nlong-term studies.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 22:48:12 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 02:52:44 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Cakmak", "Ayse S.", ""], ["Thigpen", "Nina", ""], ["Honke", "Garrett", ""], ["Alday", "Erick Perez", ""], ["Rad", "Ali Bahrami", ""], ["Adaimi", "Rebecca", ""], ["Chang", "Chia Jung", ""], ["Li", "Qiao", ""], ["Gupta", "Pramod", ""], ["Neylan", "Thomas", ""], ["McLean", "Samuel A.", ""], ["Clifford", "Gari D.", ""]]}, {"id": "2011.07407", "submitter": "Daniel Lengyel", "authors": "Daniel Lengyel, Janith Petangoda, Isak Falk, Kate Highnam, Michalis\n  Lazarou, Arinbj\\\"orn Kolbeinsson, Marc Peter Deisenroth, Nicholas R. Jennings", "title": "GENNI: Visualising the Geometry of Equivalences for Neural Network\n  Identifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient algorithm to visualise symmetries in neural networks.\nTypically, models are defined with respect to a parameter space, where\nnon-equal parameters can produce the same input-output map. Our proposed\nmethod, GENNI, allows us to efficiently identify parameters that are\nfunctionally equivalent and then visualise the subspace of the resulting\nequivalence class. By doing so, we are now able to better explore questions\nsurrounding identifiability, with applications to optimisation and\ngeneralizability, for commonly used or newly developed neural network\narchitectures.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 22:53:13 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lengyel", "Daniel", ""], ["Petangoda", "Janith", ""], ["Falk", "Isak", ""], ["Highnam", "Kate", ""], ["Lazarou", "Michalis", ""], ["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Deisenroth", "Marc Peter", ""], ["Jennings", "Nicholas R.", ""]]}, {"id": "2011.07423", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "Declarative Approaches to Counterfactual Explanations for Classification", "comments": "Revised and considerably extended version of journal submission after\n  reviews, by invitation. Based on RuleML-RR'20 paper [arXiv:2004.13237]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose answer-set programs that specify and compute counterfactual\ninterventions on entities that are input on a classification model. In relation\nto the outcome of the model, the resulting counterfactual entities serve as a\nbasis for the definition and computation of causality-based explanation scores\nfor the feature values in the entity under classification, namely\n\"responsibility scores\". The approach and the programs can be applied with\nblack-box models, and also with models that can be specified as logic programs,\nsuch as rule-based classifiers. The main focus of this work is on the\nspecification and computation of \"best\" counterfactual entities, i.e. those\nthat lead to maximum responsibility scores. From them one can read off the\nexplanations as maximum responsibility feature values in the original entity.\nWe also extend the programs to bring into the picture semantic or domain\nknowledge. We show how the approach could be extended by means of probabilistic\nmethods, and how the underlying probability distributions could be modified\nthrough the use of constraints.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 00:44:33 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 01:33:29 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "2011.07424", "submitter": "Zheng Wang", "authors": "Zhanhong Yan, Kaiming Yang, Zheng Wang, Bo Yang, Tsutomu Kaizuka,\n  Kimihiko Nakano", "title": "Intention-Based Lane Changing and Lane Keeping Haptic Guidance Steering\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haptic guidance in a shared steering assistance system has drawn significant\nattention in intelligent vehicle fields, owing to its mutual communication\nability for vehicle control. By exerting continuous torque on the steering\nwheel, both the driver and support system can share lateral control of the\nvehicle. However, current haptic guidance steering systems demonstrate some\ndeficiencies in assisting lane changing. This study explored a new steering\ninteraction method, including the design and evaluation of an intention-based\nhaptic shared steering system. Such an intention-based method can support both\nlane keeping and lane changing assistance, by detecting a driver lane change\nintention. By using a deep learning-based method to model a driver decision\ntiming regarding lane crossing, an adaptive gain control method was proposed\nfor realizing a steering control system. An intention consistency method was\nproposed to detect whether the driver and the system were acting towards the\nsame target trajectories and to accurately capture the driver intention. A\ndriving simulator experiment was conducted to test the system performance.\nParticipants were required to perform six trials with assistive methods and one\ntrial without assistance. The results demonstrated that the supporting system\ndecreased the lane departure risk in the lane keeping tasks and could support a\nfast and stable lane changing maneuver.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 00:55:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yan", "Zhanhong", ""], ["Yang", "Kaiming", ""], ["Wang", "Zheng", ""], ["Yang", "Bo", ""], ["Kaizuka", "Tsutomu", ""], ["Nakano", "Kimihiko", ""]]}, {"id": "2011.07429", "submitter": "Anbu Huang", "authors": "Anbu Huang", "title": "Dynamic backdoor attacks against federated learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a new machine learning framework, which enables\nmillions of participants to collaboratively train machine learning model\nwithout compromising data privacy and security. Due to the independence and\nconfidentiality of each client, FL does not guarantee that all clients are\nhonest by design, which makes it vulnerable to adversarial attack naturally. In\nthis paper, we focus on dynamic backdoor attacks under FL setting, where the\ngoal of the adversary is to reduce the performance of the model on targeted\ntasks while maintaining a good performance on the main task, current existing\nstudies are mainly focused on static backdoor attacks, that is the poison\npattern injected is unchanged, however, FL is an online learning framework, and\nadversarial targets can be changed dynamically by attacker, traditional\nalgorithms require learning a new targeted task from scratch, which could be\ncomputationally expensive and require a large number of adversarial training\nexamples, to avoid this, we bridge meta-learning and backdoor attacks under FL\nsetting, in which case we can learn a versatile model from previous\nexperiences, and fast adapting to new adversarial tasks with a few of examples.\nWe evaluate our algorithm on different datasets, and demonstrate that our\nalgorithm can achieve good results with respect to dynamic backdoor attacks. To\nthe best of our knowledge, this is the first paper that focus on dynamic\nbackdoor attacks research under FL setting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 01:32:58 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Huang", "Anbu", ""]]}, {"id": "2011.07430", "submitter": "Juncheng Li", "authors": "Juncheng B Li, Kaixin Ma, Shuhui Qu, Po-Yao Huang, Florian Metze", "title": "Audio-Visual Event Recognition through the lens of Adversary", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As audio/visual classification models are widely deployed for sensitive tasks\nlike content filtering at scale, it is critical to understand their robustness\nalong with improving the accuracy. This work aims to study several key\nquestions related to multimodal learning through the lens of adversarial\nnoises: 1) The trade-off between early/middle/late fusion affecting its\nrobustness and accuracy 2) How do different frequency/time domain features\ncontribute to the robustness? 3) How do different neural modules contribute to\nthe adversarial noise? In our experiment, we construct adversarial examples to\nattack state-of-the-art neural models trained on Google AudioSet. We compare\nhow much attack potency in terms of adversarial perturbation of size $\\epsilon$\nusing different $L_p$ norms we would need to \"deactivate\" the victim model.\nUsing adversarial noise to ablate multimodal models, we are able to provide\ninsights into what is the best potential fusion strategy to balance the model\nparameters/accuracy and robustness trade-off and distinguish the robust\nfeatures versus the non-robust features that various neural networks model tend\nto learn.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 01:36:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Li", "Juncheng B", ""], ["Ma", "Kaixin", ""], ["Qu", "Shuhui", ""], ["Huang", "Po-Yao", ""], ["Metze", "Florian", ""]]}, {"id": "2011.07431", "submitter": "Yijun Zhao", "authors": "Yao Xiao and Yijun Zhao", "title": "Enhance Gender and Identity Preservation in Face Aging Simulation for\n  Infants and Toddlers", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic age-progressed photos provide invaluable biometric information in a\nwide range of applications. In recent years, deep learning-based approaches\nhave made remarkable progress in modeling the aging process of the human face.\nNevertheless, it remains a challenging task to generate accurate age-progressed\nfaces from infant or toddler photos. In particular, the lack of visually\ndetectable gender characteristics and the drastic appearance changes in early\nlife contribute to the difficulty of the task. We propose a new deep learning\nmethod inspired by the successful Conditional Adversarial Autoencoder (CAAE,\n2017) model. In our approach, we extend the CAAE architecture to 1) incorporate\ngender information, and 2) augment the model's overall architecture with an\nidentity-preserving component based on facial features. We trained our model\nusing the publicly available UTKFace dataset and evaluated our model by\nsimulating up to 100 years of aging on 1,156 male and 1,207 female infant and\ntoddler face photos. Compared to the CAAE approach, our new model demonstrates\nnoticeable visual improvements. Quantitatively, our model exhibits an overall\ngain of 77.0% (male) and 13.8% (female) in gender fidelity measured by a gender\nclassifier for the simulated photos across the age spectrum. Our model also\ndemonstrates a 22.4% gain in identity preservation measured by a facial\nrecognition neural network.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 01:40:36 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Xiao", "Yao", ""], ["Zhao", "Yijun", ""]]}, {"id": "2011.07435", "submitter": "Dan Shiebler", "authors": "Dan Shiebler", "title": "Functorial Manifold Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We adapt previous research on category theory and topological unsupervised\nlearning to develop a functorial perspective on manifold learning. We first\ncharacterize manifold learning algorithms as functors that map pseudometric\nspaces to optimization objectives and factor through hierachical clustering\nfunctors. We then use this characterization to prove refinement bounds on\nmanifold learning loss functions and construct a hierarchy of manifold learning\nalgorithms based on their invariants. We express several popular manifold\nlearning algorithms as functors at different levels of this hierarchy,\nincluding Metric Multidimensional Scaling, IsoMap, and UMAP. Next, we use\ninterleaving distance to study the stability of a broad class of manifold\nlearning algorithms. We present bounds on how closely the embeddings these\nalgorithms produce from noisy data approximate the embeddings they would learn\nfrom noiseless data. Finally, we use our framework to derive a set of novel\nmanifold learning algorithms, which we experimentally demonstrate are\ncompetitive with the state of the art.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 02:30:23 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2021 03:48:38 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 14:45:23 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 14:09:09 GMT"}, {"version": "v5", "created": "Sat, 12 Jun 2021 21:35:14 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Shiebler", "Dan", ""]]}, {"id": "2011.07439", "submitter": "Jincheng Bai", "authors": "Jincheng Bai, Qifan Song, Guang Cheng", "title": "Efficient Variational Inference for Sparse Deep Learning with\n  Theoretical Guarantee", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse deep learning aims to address the challenge of huge storage\nconsumption by deep neural networks, and to recover the sparse structure of\ntarget functions. Although tremendous empirical successes have been achieved,\nmost sparse deep learning algorithms are lacking of theoretical support. On the\nother hand, another line of works have proposed theoretical frameworks that are\ncomputationally infeasible. In this paper, we train sparse deep neural networks\nwith a fully Bayesian treatment under spike-and-slab priors, and develop a set\nof computationally efficient variational inferences via continuous relaxation\nof Bernoulli distribution. The variational posterior contraction rate is\nprovided, which justifies the consistency of the proposed variational Bayes\nmethod. Notably, our empirical results demonstrate that this variational\nprocedure provides uncertainty quantification in terms of Bayesian predictive\ndistribution and is also capable to accomplish consistent variable selection by\ntraining a sparse multi-layer neural network.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 03:27:54 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bai", "Jincheng", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "2011.07442", "submitter": "Yen-Ju Lu", "authors": "Yen-Ju Lu, Chia-Yu Chang, Yu Tsao, Jeih-weih Hung", "title": "Speech enhancement guided by contextual articulatory information", "comments": "Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have confirmed the effectiveness of leveraging articulatory\ninformation to attain improved speech enhancement (SE) performance. By\naugmenting the original acoustic features with the place/manner of articulatory\nfeatures, the SE process can be guided to consider the articulatory properties\nof the input speech when performing enhancement. Hence, we believe that the\ncontextual information of articulatory attributes should include useful\ninformation and can further benefit SE. In this study, we propose an SE system\nthat incorporates contextual articulatory information; such information is\nobtained using broad phone class (BPC) end-to-end automatic speech recognition\n(ASR). Meanwhile, two training strategies are developed to train the SE system\nbased on the BPC-based ASR: multitask-learning and deep-feature training\nstrategies. Experimental results on the TIMIT dataset confirm that the\ncontextual articulatory information facilitates an SE system in achieving\nbetter results. Moreover, in contrast to another SE system that is trained with\nmonophonic ASR, the BPC-based ASR (providing contextual articulatory\ninformation) can improve the SE performance more effectively under different\nsignal-to-noise ratios(SNR).\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 03:56:37 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lu", "Yen-Ju", ""], ["Chang", "Chia-Yu", ""], ["Tsao", "Yu", ""], ["Hung", "Jeih-weih", ""]]}, {"id": "2011.07447", "submitter": "Qinzi Zhang", "authors": "Qinzi Zhang, Lewis Tseng", "title": "Echo-CGC: A Communication-Efficient Byzantine-tolerant Distributed\n  Machine Learning Algorithm in Single-Hop Radio Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on a popular DML framework -- the parameter server\ncomputation paradigm and iterative learning algorithms that proceed in rounds.\nWe aim to reduce the communication complexity of Byzantine-tolerant DML\nalgorithms in the single-hop radio network. Inspired by the CGC filter\ndeveloped by Gupta and Vaidya, PODC 2020, we propose a gradient descent-based\nalgorithm, Echo-CGC. Our main novelty is a mechanism to utilize the broadcast\nproperties of the radio network to avoid transmitting the raw gradients (full\n$d$-dimensional vectors). In the radio network, each worker is able to overhear\nprevious gradients that were transmitted to the parameter server. Roughly\nspeaking, in Echo-CGC, if a worker \"agrees\" with a combination of prior\ngradients, it will broadcast the \"echo message\" instead of the its raw local\ngradient. The echo message contains a vector of coefficients (of size at most\n$n$) and the ratio of the magnitude between two gradients (a float). In\ncomparison, the traditional approaches need to send $n$ local gradients in each\nround, where each gradient is typically a vector in an ultra-high dimensional\nspace ($d\\gg n$). The improvement on communication complexity of our algorithm\ndepends on multiple factors, including number of nodes, number of faulty\nworkers in an execution, and the cost function. We numerically analyze the\nimprovement, and show that with a large number of nodes, Echo-CGC reduces\n$80\\%$ of the communication under standard assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 04:35:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhang", "Qinzi", ""], ["Tseng", "Lewis", ""]]}, {"id": "2011.07451", "submitter": "Baharan Mirzasoleiman", "authors": "Baharan Mirzasoleiman, Kaidi Cao, Jure Leskovec", "title": "Coresets for Robust Training of Neural Networks against Noisy Labels", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks have the capacity to overfit noisy labels frequently\nfound in real-world datasets. Although great progress has been made, existing\ntechniques are limited in providing theoretical guarantees for the performance\nof the neural networks trained with noisy labels. Here we propose a novel\napproach with strong theoretical guarantees for robust training of deep\nnetworks trained with noisy labels. The key idea behind our method is to select\nweighted subsets (coresets) of clean data points that provide an approximately\nlow-rank Jacobian matrix. We then prove that gradient descent applied to the\nsubsets do not overfit the noisy labels. Our extensive experiments corroborate\nour theory and demonstrate that deep networks trained on our subsets achieve a\nsignificantly superior performance compared to state-of-the art, e.g., 6%\nincrease in accuracy on CIFAR-10 with 80% noisy labels, and 7% increase in\naccuracy on mini Webvision.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 04:58:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mirzasoleiman", "Baharan", ""], ["Cao", "Kaidi", ""], ["Leskovec", "Jure", ""]]}, {"id": "2011.07453", "submitter": "Kurtis Evan David", "authors": "Kurtis Evan David, Qiang Liu, Ruth Fong", "title": "Debiasing Convolutional Neural Networks via Meta Orthogonalization", "comments": "Accepted to NeuRIPS 2020 Workshop on Algorithmic Fairness through the\n  Lens of Causality and Interpretability (AFCI). Supplemental materials\n  provided at:\n  https://drive.google.com/drive/folders/1klIAqZDgg3sCVmzFjLw5Y_T-GTc2E3oh?usp=sharing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep learning models often achieve strong task performance, their\nsuccesses are hampered by their inability to disentangle spurious correlations\nfrom causative factors, such as when they use protected attributes (e.g., race,\ngender, etc.) to make decisions. In this work, we tackle the problem of\ndebiasing convolutional neural networks (CNNs) in such instances. Building off\nof existing work on debiasing word embeddings and model interpretability, our\nMeta Orthogonalization method encourages the CNN representations of different\nconcepts (e.g., gender and class labels) to be orthogonal to one another in\nactivation space while maintaining strong downstream task performance. Through\na variety of experiments, we systematically test our method and demonstrate\nthat it significantly mitigates model bias and is competitive against current\nadversarial debiasing methods.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 05:13:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["David", "Kurtis Evan", ""], ["Liu", "Qiang", ""], ["Fong", "Ruth", ""]]}, {"id": "2011.07456", "submitter": "Xuefeng Gao", "authors": "Xuefeng Gao, Zuo Quan Xu, Xun Yu Zhou", "title": "State-Dependent Temperature Control for Langevin Diffusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the temperature control problem for Langevin diffusions in the\ncontext of non-convex optimization. The classical optimal control of such a\nproblem is of the bang-bang type, which is overly sensitive to any errors. A\nremedy is to allow the diffusions to explore other temperature values and hence\nsmooth out the bang-bang control. We accomplish this by a stochastic relaxed\ncontrol formulation incorporating randomization of the temperature control and\nregularizing its entropy. We derive a state-dependent, truncated exponential\ndistribution, which can be used to sample temperatures in a Langevin algorithm.\nWe carry out a numerical experiment to compare the performance of the algorithm\nwith two other available algorithms in search of a global optimum.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 05:51:19 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 05:57:40 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Gao", "Xuefeng", ""], ["Xu", "Zuo Quan", ""], ["Zhou", "Xun Yu", ""]]}, {"id": "2011.07457", "submitter": "Shuo Zhang", "authors": "Shuo Zhang, Yang Liu, Lei Xie", "title": "Molecular Mechanics-Driven Graph Neural Network with Multiplex Graph for\n  Molecular Structures", "comments": "Accepted by the Machine Learning for Structural Biology Workshop\n  (MLSB 2020) and the Machine Learning for Molecules Workshop (ML4Molecules\n  2020) at the 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of physicochemical properties from molecular structures is a\ncrucial task for artificial intelligence aided molecular design. A growing\nnumber of Graph Neural Networks (GNNs) have been proposed to address this\nchallenge. These models improve their expressive power by incorporating\nauxiliary information in molecules while inevitably increase their\ncomputational complexity. In this work, we aim to design a GNN which is both\npowerful and efficient for molecule structures. To achieve such goal, we\npropose a molecular mechanics-driven approach by first representing each\nmolecule as a two-layer multiplex graph, where one layer contains only local\nconnections that mainly capture the covalent interactions and another layer\ncontains global connections that can simulate non-covalent interactions. Then\nfor each layer, a corresponding message passing module is proposed to balance\nthe trade-off of expression power and computational complexity. Based on these\ntwo modules, we build Multiplex Molecular Graph Neural Network (MXMNet). When\nvalidated by the QM9 dataset for small molecules and PDBBind dataset for large\nprotein-ligand complexes, MXMNet achieves superior results to the existing\nstate-of-the-art models under restricted resources.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 05:55:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhang", "Shuo", ""], ["Liu", "Yang", ""], ["Xie", "Lei", ""]]}, {"id": "2011.07458", "submitter": "Zahra Esmaeilbeig", "authors": "Zahra Esmaeilbeig, Shahin Khobahi, Mojtaba Soltanalian", "title": "Deep-RLS: A Model-Inspired Deep Learning Approach to Nonlinear PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the application of model-based deep learning in\nnonlinear principal component analysis (PCA). Inspired by the deep unfolding\nmethodology, we propose a task-based deep learning approach, referred to as\nDeep-RLS, that unfolds the iterations of the well-known recursive least squares\n(RLS) algorithm into the layers of a deep neural network in order to perform\nnonlinear PCA. In particular, we formulate the nonlinear PCA for the blind\nsource separation (BSS) problem and show through numerical analysis that\nDeep-RLS results in a significant improvement in the accuracy of recovering the\nsource signals in BSS when compared to the traditional RLS algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 06:05:51 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 04:45:01 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Esmaeilbeig", "Zahra", ""], ["Khobahi", "Shahin", ""], ["Soltanalian", "Mojtaba", ""]]}, {"id": "2011.07460", "submitter": "Jacob Ouyang", "authors": "Jacob Ouyang, Isaac R Galatzer-Levy, Vidya Koesmahargyo, Li Zhang", "title": "Direct Classification of Emotional Intensity", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a model that can directly predict emotion intensity\nscore from video inputs, instead of deriving from action units. Using a 3d DNN\nincorporated with dynamic emotion information, we train a model using videos of\ndifferent people smiling that outputs an intensity score from 0-10. Each video\nis labeled framewise using a normalized action-unit based intensity score. Our\nmodel then employs an adaptive learning technique to improve performance when\ndealing with new subjects. Compared to other models, our model excels in\ngeneralization between different people as well as provides a new framework to\ndirectly classify emotional intensity.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 06:32:48 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ouyang", "Jacob", ""], ["Galatzer-Levy", "Isaac R", ""], ["Koesmahargyo", "Vidya", ""], ["Zhang", "Li", ""]]}, {"id": "2011.07466", "submitter": "Xin Ding", "authors": "Xin Ding and Yongwei Wang and Zuheng Xu and William J. Welch and Z.\n  Jane Wang", "title": "Continuous Conditional Generative Adversarial Networks for Image\n  Generation: Novel Losses and Label Input Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work proposes the continuous conditional generative adversarial network\n(CcGAN), the first generative model for image generation conditional on\ncontinuous, scalar conditions (termed regression labels). Existing conditional\nGANs (cGANs) are mainly designed for categorical conditions (eg, class labels);\nconditioning on regression labels is mathematically distinct and raises two\nfundamental problems:(P1) Since there may be very few (even zero) real images\nfor some regression labels, minimizing existing empirical versions of cGAN\nlosses (aka empirical cGAN losses) often fails in practice;(P2) Since\nregression labels are scalar and infinitely many, conventional label input\nmethods are not applicable. The proposed CcGAN solves the above problems,\nrespectively, by (S1) reformulating existing empirical cGAN losses to be\nappropriate for the continuous scenario; and (S2) proposing a naive label input\n(NLI) method and an improved label input (ILI) method to incorporate regression\nlabels into the generator and the discriminator. The reformulation in (S1)\nleads to two novel empirical discriminator losses, termed the hard vicinal\ndiscriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL)\nrespectively, and a novel empirical generator loss. The error bounds of a\ndiscriminator trained with HVDL and SVDL are derived under mild assumptions in\nthis work. Two new benchmark datasets (RC-49 and Cell-200) and a novel\nevaluation metric (Sliding Fr\\'echet Inception Distance) are also proposed for\nthis continuous scenario. Our experiments on the Circular 2-D Gaussians, RC-49,\nUTKFace, Cell-200, and Steering Angle datasets show that CcGAN is able to\ngenerate diverse, high-quality samples from the image distribution conditional\non a given regression label. Moreover, in these experiments, CcGAN\nsubstantially outperforms cGAN both visually and quantitatively.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 07:29:41 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 00:05:12 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 22:34:54 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2021 02:33:02 GMT"}, {"version": "v5", "created": "Sun, 9 May 2021 06:30:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ding", "Xin", ""], ["Wang", "Yongwei", ""], ["Xu", "Zuheng", ""], ["Welch", "William J.", ""], ["Wang", "Z. Jane", ""]]}, {"id": "2011.07470", "submitter": "Stefano Rini", "authors": "Stefano Rini and Hirotsugu Hiramatsu", "title": "An efficient label-free analyte detection algorithm for time-resolved\n  spectroscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-resolved spectral techniques play an important analysis tool in many\ncontexts, from physical chemistry to biomedicine. Customarily, the label-free\ndetection of analytes is manually performed by experts through the aid of\nclassic dimensionality-reduction methods, such as Principal Component Analysis\n(PCA) and Non-negative Matrix Factorization (NMF). This fundamental reliance on\nexpert analysis for unknown analyte detection severely hinders the\napplicability and the throughput of these such techniques. For this reason, in\nthis paper, we formulate this detection problem as an unsupervised learning\nproblem and propose a novel machine learning algorithm for label-free analyte\ndetection. To show the effectiveness of the proposed solution, we consider the\nproblem of detecting the amino-acids in Liquid Chromatography coupled with\nRaman spectroscopy (LC-Raman).\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 07:57:03 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Rini", "Stefano", ""], ["Hiramatsu", "Hirotsugu", ""]]}, {"id": "2011.07472", "submitter": "Dolav Nitay", "authors": "Dolav Nitay, Dana Fisman, Michal Ziv-Ukelson", "title": "Learning of Structurally Unambiguous Probabilistic Grammars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of identifying a probabilistic context free grammar has two\naspects: the first is determining the grammar's topology (the rules of the\ngrammar) and the second is estimating probabilistic weights for each rule.\nGiven the hardness results for learning context-free grammars in general, and\nprobabilistic grammars in particular, most of the literature has concentrated\non the second problem. In this work we address the first problem. We restrict\nattention to structurally unambiguous weighted context-free grammars (SUWCFG)\nand provide a query learning algorithm for structurally unambiguous\nprobabilistic context-free grammars (SUPCFG). We show that SUWCFG can be\nrepresented using co-linear multiplicity tree automata (CMTA), and provide a\npolynomial learning algorithm that learns CMTAs. We show that the learned CMTA\ncan be converted into a probabilistic grammar, thus providing a complete\nalgorithm for learning a structurally unambiguous probabilistic context free\ngrammar (both the grammar topology and the probabilistic weights) using\nstructured membership queries and structured equivalence queries. We\ndemonstrate the usefulness of our algorithm in learning PCFGs over genomic\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 08:07:04 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 18:32:52 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Nitay", "Dolav", ""], ["Fisman", "Dana", ""], ["Ziv-Ukelson", "Michal", ""]]}, {"id": "2011.07476", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Stefano Ermon", "title": "Right Decisions from Wrong Predictions: A Mechanism Design Alternative\n  to Individual Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG math.PR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision makers often need to rely on imperfect probabilistic forecasts.\nWhile average performance metrics are typically available, it is difficult to\nassess the quality of individual forecasts and the corresponding utilities. To\nconvey confidence about individual predictions to decision-makers, we propose a\ncompensation mechanism ensuring that the forecasted utility matches the\nactually accrued utility. While a naive scheme to compensate decision-makers\nfor prediction errors can be exploited and might not be sustainable in the long\nrun, we propose a mechanism based on fair bets and online learning that\nprovably cannot be exploited. We demonstrate an application showing how\npassengers could confidently optimize individual travel plans based on flight\ndelay probabilities estimated by an airline.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 08:22:39 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 06:03:57 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Zhao", "Shengjia", ""], ["Ermon", "Stefano", ""]]}, {"id": "2011.07478", "submitter": "Shuai Li", "authors": "Yuxin Wen, Shuai Li, Kui Jia", "title": "Towards Understanding the Regularization of Adversarial Robustness on\n  Neural Networks", "comments": "Published as a conference paper at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adversarial examples has shown that modern Neural Network (NN)\nmodels could be rather fragile. Among the more established techniques to solve\nthe problem, one is to require the model to be {\\it $\\epsilon$-adversarially\nrobust} (AR); that is, to require the model not to change predicted labels when\nany given input examples are perturbed within a certain range. However, it is\nobserved that such methods would lead to standard performance degradation,\ni.e., the degradation on natural examples. In this work, we study the\ndegradation through the regularization perspective. We identify quantities from\ngeneralization analysis of NNs; with the identified quantities we empirically\nfind that AR is achieved by regularizing/biasing NNs towards less confident\nsolutions by making the changes in the feature space (induced by changes in the\ninstance space) of most layers smoother uniformly in all directions; so to a\ncertain extent, it prevents sudden change in prediction w.r.t. perturbations.\nHowever, the end result of such smoothing concentrates samples around decision\nboundaries, resulting in less confident solutions, and leads to worse standard\nperformance. Our studies suggest that one might consider ways that build AR\ninto NNs in a gentler way to avoid the problematic regularization.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 08:32:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wen", "Yuxin", ""], ["Li", "Shuai", ""], ["Jia", "Kui", ""]]}, {"id": "2011.07482", "submitter": "Mehak Aggarwal", "authors": "Mehak Aggarwal, Nishanth Arun, Sharut Gupta, Ashwin Vaswani, Bryan\n  Chen, Matthew Li, Ken Chang, Jay Patel, Katherine Hoebel, Mishka Gidwani,\n  Jayashree Kalpathy-Cramer, Praveer Singh", "title": "Towards Trainable Saliency Maps in Medical Imaging", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While success of Deep Learning (DL) in automated diagnosis can be\ntransformative to the medicinal practice especially for people with little or\nno access to doctors, its widespread acceptability is severely limited by\ninherent black-box decision making and unsafe failure modes. While saliency\nmethods attempt to tackle this problem in non-medical contexts, their apriori\nexplanations do not transfer well to medical usecases. With this study we\nvalidate a model design element agnostic to both architecture complexity and\nmodel task, and show how introducing this element gives an inherently\nself-explanatory model. We compare our results with state of the art\nnon-trainable saliency maps on RSNA Pneumonia Dataset and demonstrate a much\nhigher localization efficacy using our adopted technique. We also compare, with\na fully supervised baseline and provide a reasonable alternative to it's high\ndata labelling overhead. We further investigate the validity of our claims\nthrough qualitative evaluation from an expert reader.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 09:01:55 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Aggarwal", "Mehak", ""], ["Arun", "Nishanth", ""], ["Gupta", "Sharut", ""], ["Vaswani", "Ashwin", ""], ["Chen", "Bryan", ""], ["Li", "Matthew", ""], ["Chang", "Ken", ""], ["Patel", "Jay", ""], ["Hoebel", "Katherine", ""], ["Gidwani", "Mishka", ""], ["Kalpathy-Cramer", "Jayashree", ""], ["Singh", "Praveer", ""]]}, {"id": "2011.07489", "submitter": "Minh Ha Quang", "authors": "Minh Ha Quang", "title": "Entropic regularization of Wasserstein distance between\n  infinite-dimensional Gaussian measures and Gaussian processes", "comments": "revised version, 88 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the entropic regularization formulation of the\n2-Wasserstein distance on an infinite-dimensional Hilbert space, in particular\nfor the Gaussian setting. We first present the Minimum Mutual Information\nproperty, namely the joint measures of two Gaussian measures on Hilbert space\nwith the smallest mutual information are joint Gaussian measures. This is the\ninfinite-dimensional generalization of the Maximum Entropy property of Gaussian\ndensities on Euclidean space. We then give closed form formulas for the optimal\nentropic transport plan, entropic 2-Wasserstein distance, and Sinkhorn\ndivergence between two Gaussian measures on a Hilbert space, along with the\nfixed point equations for the barycenter of a set of Gaussian measures. Our\nformulations fully exploit the regularization aspect of the entropic\nformulation and are valid both in singular and nonsingular settings. In the\ninfinite-dimensional setting, both the entropic 2-Wasserstein distance and\nSinkhorn divergence are Fr\\'echet differentiable, in contrast to the exact\n2-Wasserstein distance, which is not differentiable. Our Sinkhorn barycenter\nequation is new and always has a unique solution. In contrast, the\nfinite-dimensional barycenter equation for the entropic 2-Wasserstein distance\nfails to generalize to the Hilbert space setting. In the setting of reproducing\nkernel Hilbert spaces (RKHS), our distance formulas are given explicitly in\nterms of the corresponding kernel Gram matrices, providing an interpolation\nbetween the kernel Maximum Mean Discrepancy (MMD) and the kernel 2-Wasserstein\ndistance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:03:12 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 02:24:29 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Quang", "Minh Ha", ""]]}, {"id": "2011.07491", "submitter": "Radu Tudor Ionescu", "authors": "Mariana-Iuliana Georgescu, Antonio Barbalau, Radu Tudor Ionescu, Fahad\n  Shahbaz Khan, Marius Popescu, Mubarak Shah", "title": "Anomaly Detection in Video via Self-Supervised and Multi-Task Learning", "comments": "Accepted at CVPR 2021. Main paper and supplementary are both included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in video is a challenging computer vision problem. Due to\nthe lack of anomalous events at training time, anomaly detection requires the\ndesign of learning methods without full supervision. In this paper, we approach\nanomalous event detection in video through self-supervised and multi-task\nlearning at the object level. We first utilize a pre-trained detector to detect\nobjects. Then, we train a 3D convolutional neural network to produce\ndiscriminative anomaly-specific information by jointly learning multiple proxy\ntasks: three self-supervised and one based on knowledge distillation. The\nself-supervised tasks are: (i) discrimination of forward/backward moving\nobjects (arrow of time), (ii) discrimination of objects in\nconsecutive/intermittent frames (motion irregularity) and (iii) reconstruction\nof object-specific appearance information. The knowledge distillation task\ntakes into account both classification and detection information, generating\nlarge prediction discrepancies between teacher and student models when\nanomalies occur. To the best of our knowledge, we are the first to approach\nanomalous event detection in video as a multi-task learning problem,\nintegrating multiple self-supervised and knowledge distillation proxy tasks in\na single architecture. Our lightweight architecture outperforms the\nstate-of-the-art methods on three benchmarks: Avenue, ShanghaiTech and UCSD\nPed2. Additionally, we perform an ablation study demonstrating the importance\nof integrating self-supervised learning and normality-specific distillation in\na multi-task learning setting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:21:28 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 21:14:40 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Georgescu", "Mariana-Iuliana", ""], ["Barbalau", "Antonio", ""], ["Ionescu", "Radu Tudor", ""], ["Khan", "Fahad Shahbaz", ""], ["Popescu", "Marius", ""], ["Shah", "Mubarak", ""]]}, {"id": "2011.07495", "submitter": "Andrija Petrovic", "authors": "Andrija Petrovi\\'c, Mladen Nikoli\\'c, Sandro Radovanovi\\'c, Boris\n  Deliba\\v{s}i\\'c, Milo\\v{s} Jovanovi\\'c", "title": "FAIR: Fair Adversarial Instance Re-weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With growing awareness of societal impact of artificial intelligence,\nfairness has become an important aspect of machine learning algorithms. The\nissue is that human biases towards certain groups of population, defined by\nsensitive features like race and gender, are introduced to the training data\nthrough data collection and labeling. Two important directions of fairness\nensuring research have focused on (i) instance weighting in order to decrease\nthe impact of more biased instances and (ii) adversarial training in order to\nconstruct data representations informative of the target variable, but\nuninformative of the sensitive attributes. In this paper we propose a Fair\nAdversarial Instance Re-weighting (FAIR) method, which uses adversarial\ntraining to learn instance weighting function that ensures fair predictions.\nMerging the two paradigms, it inherits desirable properties from both --\ninterpretability of reweighting and end-to-end trainability of adversarial\ntraining. We propose four different variants of the method and, among other\nthings, demonstrate how the method can be cast in a fully probabilistic\nframework. Additionally, theoretical analysis of FAIR models' properties have\nbeen studied extensively. We compare FAIR models to 7 other related and\nstate-of-the-art models and demonstrate that FAIR is able to achieve a better\ntrade-off between accuracy and unfairness. To the best of our knowledge, this\nis the first model that merges reweighting and adversarial approaches by means\nof a weighting function that can provide interpretable information about\nfairness of individual instances.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:48:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Petrovi\u0107", "Andrija", ""], ["Nikoli\u0107", "Mladen", ""], ["Radovanovi\u0107", "Sandro", ""], ["Deliba\u0161i\u0107", "Boris", ""], ["Jovanovi\u0107", "Milo\u0161", ""]]}, {"id": "2011.07497", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra", "title": "Generating Negative Commonsense Knowledge", "comments": "Preprint, ongoing work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acquisition of commonsense knowledge is an important open challenge in\nartificial intelligence. In this work-in-progress paper, we study the task of\nautomatically augmenting commonsense knowledge bases (KBs) with novel\nstatements. We show empirically that obtaining meaningful negative samples for\nthe completion task is nontrivial, and propose NegatER, a framework for\ngenerating negative commonsense knowledge, to address this challenge. In our\nevaluation we demonstrate the intrinsic value and extrinsic utility of the\nknowledge generated by NegatER, opening up new avenues for future research in\nthis direction.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 10:55:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""]]}, {"id": "2011.07499", "submitter": "M. F. Mridha", "authors": "M. F. Mridha, Abu Quwsar Ohi, M. Ameer Ali, Mazedul Islam Emon,\n  Muhammad Mohsin Kabir", "title": "BanglaWriting: A multi-purpose offline Bangla handwriting dataset", "comments": "Accepted in journal Data in Brief. The dataset is available on\n  https://data.mendeley.com/datasets/r43wkvdk4w/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a Bangla handwriting dataset named BanglaWriting that\ncontains single-page handwritings of 260 individuals of different personalities\nand ages. Each page includes bounding-boxes that bounds each word, along with\nthe unicode representation of the writing. This dataset contains 21,234 words\nand 32,787 characters in total. Moreover, this dataset includes 5,470 unique\nwords of Bangla vocabulary. Apart from the usual words, the dataset comprises\n261 comprehensible overwriting and 450 handwritten strikes and mistakes. All of\nthe bounding-boxes and word labels are manually-generated. The dataset can be\nused for complex optical character/word recognition, writer identification,\nhandwritten word segmentation, and word generation. Furthermore, this dataset\nis suitable for extracting age-based and gender-based variation of handwriting.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 11:08:53 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 09:30:02 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mridha", "M. F.", ""], ["Ohi", "Abu Quwsar", ""], ["Ali", "M. Ameer", ""], ["Emon", "Mazedul Islam", ""], ["Kabir", "Muhammad Mohsin", ""]]}, {"id": "2011.07516", "submitter": "Jonathan Passerat-Palmbach", "authors": "Harry Cai and Daniel Rueckert and Jonathan Passerat-Palmbach", "title": "2CP: Decentralized Protocols to Transparently Evaluate Contributivity in\n  Blockchain Federated Learning Environments", "comments": null, "journal-ref": "IEEE 2nd International Workshop on Advances in Artificial\n  Intelligence for Blockchain (AIChain 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Federated Learning harnesses data from multiple sources to build a single\nmodel. While the initial model might belong solely to the actor bringing it to\nthe network for training, determining the ownership of the trained model\nresulting from Federated Learning remains an open question. In this paper we\nexplore how Blockchains (in particular Ethereum) can be used to determine the\nevolving ownership of a model trained with Federated Learning.\n  Firstly, we use the step-by-step evaluation metric to assess the relative\ncontributivities of participants in a Federated Learning process. Next, we\nintroduce 2CP, a framework comprising two novel protocols for Blockchained\nFederated Learning, which both reward contributors with shares in the final\nmodel based on their relative contributivity. The Crowdsource Protocol allows\nan actor to bring a model forward for training, and use their own data to\nevaluate the contributions made to it. Potential trainers are guaranteed a fair\nshare of the resulting model, even in a trustless setting. The Consortium\nProtocol gives trainers the same guarantee even when no party owns the initial\nmodel and no evaluator is available.\n  We conduct experiments with the MNIST dataset that reveal sound\ncontributivity scores resulting from both Protocols by rewarding larger\ndatasets with greater shares in the model. Our experiments also showed the\nnecessity to pair 2CP with a robust model aggregation mechanism to discard low\nquality inputs coming from model poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 12:59:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Cai", "Harry", ""], ["Rueckert", "Daniel", ""], ["Passerat-Palmbach", "Jonathan", ""]]}, {"id": "2011.07530", "submitter": "Kazuhisa Fujita Dr.", "authors": "Kazuhisa Fujita", "title": "Estimation of the number of clusters on d-dimensional sphere", "comments": null, "journal-ref": "Artificial Intelligence Research, 10, 57-63 (2021)", "doi": "10.5430/air.v10n1p57", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical data is distributed on the sphere. The data appears in various\nfields such as meteorology, biology, and natural language processing. However,\na method for analysis of spherical data does not develop enough yet. One of the\nimportant issues is an estimation of the number of clusters in spherical data.\nTo address the issue, I propose a new method called the Spherical X-means\n(SX-means) that can estimate the number of clusters on d-dimensional sphere.\nThe SX-means is the model-based method assuming that the data is generated from\na mixture of von Mises-Fisher distributions. The present paper explains the\nproposed method and shows its performance of estimation of the number of\nclusters.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 13:42:39 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 15:24:47 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Fujita", "Kazuhisa", ""]]}, {"id": "2011.07537", "submitter": "Fabio Pardo", "authors": "Fabio Pardo", "title": "Tonic: A Deep Reinforcement Learning Library for Fast Prototyping and\n  Benchmarking", "comments": "Code: https://github.com/fabiopardo/tonic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been one of the fastest growing fields of\nmachine learning over the past years and numerous libraries have been open\nsourced to support research. However, most codebases have a steep learning\ncurve or limited flexibility that do not satisfy a need for fast prototyping in\nfundamental research. This paper introduces Tonic, a Python library allowing\nresearchers to quickly implement new ideas and measure their importance by\nproviding: 1) general-purpose configurable modules 2) several baseline agents:\nA2C, TRPO, PPO, MPO, DDPG, D4PG, TD3 and SAC built with these modules 3)\nsupport for TensorFlow 2 and PyTorch 4) support for continuous-control\nenvironments from OpenAI Gym, DeepMind Control Suite and PyBullet 5) scripts to\nexperiment in a reproducible way, plot results, and play with trained agents 6)\na benchmark of the provided agents on 70 continuous-control tasks. Evaluation\nis performed in fair conditions with identical seeds, training and testing\nloops, while sharing general improvements such as non-terminal timeouts and\nobservation normalization. Finally, to demonstrate how Tonic simplifies\nexperimentation, a novel agent called TD4 is implemented and evaluated.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 14:10:37 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 12:28:33 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Pardo", "Fabio", ""]]}, {"id": "2011.07546", "submitter": "Ruchit Agrawal", "authors": "Ruchit Agrawal, Simon Dixon", "title": "Learning Frame Similarity using Siamese networks for Audio-to-Score\n  Alignment", "comments": "Accepted at EUSIPCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Audio-to-score alignment aims at generating an accurate mapping between a\nperformance audio and the score of a given piece. Standard alignment methods\nare based on Dynamic Time Warping (DTW) and employ handcrafted features, which\ncannot be adapted to different acoustic conditions. We propose a method to\novercome this limitation using learned frame similarity for audio-to-score\nalignment. We focus on offline audio-to-score alignment of piano music.\nExperiments on music data from different acoustic conditions demonstrate that\nour method achieves higher alignment accuracy than a standard DTW-based method\nthat uses handcrafted features, and generates robust alignments whilst being\nadaptable to different domains at the same time.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 14:58:03 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Agrawal", "Ruchit", ""], ["Dixon", "Simon", ""]]}, {"id": "2011.07551", "submitter": "Alexey Kurochkin", "authors": "Alexey Kurochkin", "title": "Discovering long term dependencies in noisy time series data using deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series modelling is essential for solving tasks such as predictive\nmaintenance, quality control and optimisation. Deep learning is widely used for\nsolving such problems. When managing complex manufacturing process with neural\nnetworks, engineers need to know why machine learning model made specific\ndecision and what are possible outcomes of following model recommendation. In\nthis paper we develop framework for capturing and explaining temporal\ndependencies in time series data using deep neural networks and test it on\nvarious synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 15:10:57 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kurochkin", "Alexey", ""]]}, {"id": "2011.07553", "submitter": "Zihan Ding", "authors": "Zihan Ding, Pablo Hernandez-Leal, Gavin Weiguang Ding, Changjian Li,\n  Ruitong Huang", "title": "CDT: Cascading Decision Trees for Explainable Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Reinforcement Learning (DRL) has recently achieved significant advances\nin various domains. However, explaining the policy of RL agents still remains\nan open problem due to several factors, one being the complexity of explaining\nneural networks decisions. Recently, a group of works have used\ndecision-tree-based models to learn explainable policies. Soft decision trees\n(SDTs) and discretized differentiable decision trees (DDTs) have been\ndemonstrated to achieve both good performance and share the benefit of having\nexplainable policies. In this work, we further improve the results for\ntree-based explainable RL in both performance and explainability. Our proposal,\nCascading Decision Trees (CDTs) apply representation learning on the decision\npath to allow richer expressivity. Empirical results show that in both\nsituations, where CDTs are used as policy function approximators or as\nimitation learners to explain black-box policies, CDTs can achieve better\nperformances with more succinct and explainable models than SDTs. As a second\ncontribution our study reveals limitations of explaining black-box policies via\nimitation learning with tree-based explainable models, due to its inherent\ninstability.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 15:25:56 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 10:40:38 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Ding", "Zihan", ""], ["Hernandez-Leal", "Pablo", ""], ["Ding", "Gavin Weiguang", ""], ["Li", "Changjian", ""], ["Huang", "Ruitong", ""]]}, {"id": "2011.07577", "submitter": "Harshit Rampal", "authors": "Dhruv Vashisht, Harshit Rampal, Haiguang Liao, Yang Lu, Devika\n  Shanbhag, Elias Fallon, Levent Burak Kara", "title": "Placement in Integrated Circuits using Cyclic Reinforcement Learning and\n  Simulated Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical design and production of Integrated Circuits (IC) is becoming\nincreasingly more challenging as the sophistication in IC technology is\nsteadily increasing. Placement has been one of the most critical steps in IC\nphysical design. Through decades of research, partition-based, analytical-based\nand annealing-based placers have been enriching the placement solution toolbox.\nHowever, open challenges including long run time and lack of ability to\ngeneralize continue to restrict wider applications of existing placement tools.\nWe devise a learning-based placement tool based on cyclic application of\nReinforcement Learning (RL) and Simulated Annealing (SA) by leveraging the\nadvancement of RL. Results show that the RL module is able to provide a better\ninitialization for SA and thus leads to a better final placement design.\nCompared to other recent learning-based placers, our method is majorly\ndifferent with its combination of RL and SA. It leverages the RL model's\nability to quickly get a good rough solution after training and the heuristic's\nability to realize greedy improvements in the solution.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 16:48:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Vashisht", "Dhruv", ""], ["Rampal", "Harshit", ""], ["Liao", "Haiguang", ""], ["Lu", "Yang", ""], ["Shanbhag", "Devika", ""], ["Fallon", "Elias", ""], ["Kara", "Levent Burak", ""]]}, {"id": "2011.07584", "submitter": "Alfredo Kalaitzis", "authors": "Dolores Garcia, Gonzalo Mateo-Garcia, Hannes Bernhardt, Ron\n  Hagensieker, Ignacio G. Lopez Francos, Jonathan Stock, Guy Schumann, Kevin\n  Dobbs, Freddie Kalaitzis", "title": "Pix2Streams: Dynamic Hydrology Maps from Satellite-LiDAR Fusion", "comments": "Work completed during the 2020 Frontier Development Lab research\n  accelerator, a private-public partnership with NASA in the US, and ESA in\n  Europe. Accepted as a spotlight/long oral talk at AI for Earth Sciences\n  Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Where are the Earth's streams flowing right now? Inland surface waters expand\nwith floods and contract with droughts, so there is no one map of our streams.\nCurrent satellite approaches are limited to monthly observations that map only\nthe widest streams. These are fed by smaller tributaries that make up much of\nthe dendritic surface network but whose flow is unobserved. A complete map of\nour daily waters can give us an early warning for where droughts are born: the\nreceding tips of the flowing network. Mapping them over years can give us a map\nof impermanence of our waters, showing where to expect water, and where not to.\nTo that end, we feed the latest high-res sensor data to multiple deep learning\nmodels in order to map these flowing networks every day, stacking the times\nseries maps over many years. Specifically, i) we enhance water segmentation to\n$50$ cm/pixel resolution, a 60$\\times$ improvement over previous\nstate-of-the-art results. Our U-Net trained on 30-40cm WorldView3 images can\ndetect streams as narrow as 1-3m (30-60$\\times$ over SOTA). Our multi-sensor,\nmulti-res variant, WasserNetz, fuses a multi-day window of 3m PlanetScope\nimagery with 1m LiDAR data, to detect streams 5-7m wide. Both U-Nets produce a\nwater probability map at the pixel-level. ii) We integrate this water map over\na DEM-derived synthetic valley network map to produce a snapshot of flow at the\nstream level. iii) We apply this pipeline, which we call Pix2Streams, to a\n2-year daily PlanetScope time-series of three watersheds in the US to produce\nthe first high-fidelity dynamic map of stream flow frequency. The end result is\na new map that, if applied at the national scale, could fundamentally improve\nhow we manage our water resources around the world.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 17:14:28 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Garcia", "Dolores", ""], ["Mateo-Garcia", "Gonzalo", ""], ["Bernhardt", "Hannes", ""], ["Hagensieker", "Ron", ""], ["Francos", "Ignacio G. Lopez", ""], ["Stock", "Jonathan", ""], ["Schumann", "Guy", ""], ["Dobbs", "Kevin", ""], ["Kalaitzis", "Freddie", ""]]}, {"id": "2011.07586", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Javier Antor\\'an, Yunfeng Zhang, Q. Vera Liao, Prasanna\n  Sattigeri, Riccardo Fogliato, Gabrielle Gauthier Melan\\c{c}on, Ranganath\n  Krishnan, Jason Stanley, Omesh Tickoo, Lama Nachman, Rumi Chunara, Madhulika\n  Srikumar, Adrian Weller, Alice Xiang", "title": "Uncertainty as a Form of Transparency: Measuring, Communicating, and\n  Using Uncertainty", "comments": "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society\n  (AIES) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic transparency entails exposing system properties to various\nstakeholders for purposes that include understanding, improving, and contesting\npredictions. Until now, most research into algorithmic transparency has\npredominantly focused on explainability. Explainability attempts to provide\nreasons for a machine learning model's behavior to stakeholders. However,\nunderstanding a model's specific behavior alone might not be enough for\nstakeholders to gauge whether the model is wrong or lacks sufficient knowledge\nto solve the task at hand. In this paper, we argue for considering a\ncomplementary form of transparency by estimating and communicating the\nuncertainty associated with model predictions. First, we discuss methods for\nassessing uncertainty. Then, we characterize how uncertainty can be used to\nmitigate model unfairness, augment decision-making, and build trustworthy\nsystems. Finally, we outline methods for displaying uncertainty to stakeholders\nand recommend how to collect information required for incorporating uncertainty\ninto existing ML pipelines. This work constitutes an interdisciplinary review\ndrawn from literature spanning machine learning, visualization/HCI, design,\ndecision-making, and fairness. We aim to encourage researchers and\npractitioners to measure, communicate, and use uncertainty as a form of\ntransparency.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 17:26:14 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:11:01 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 10:33:03 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bhatt", "Umang", ""], ["Antor\u00e1n", "Javier", ""], ["Zhang", "Yunfeng", ""], ["Liao", "Q. Vera", ""], ["Sattigeri", "Prasanna", ""], ["Fogliato", "Riccardo", ""], ["Melan\u00e7on", "Gabrielle Gauthier", ""], ["Krishnan", "Ranganath", ""], ["Stanley", "Jason", ""], ["Tickoo", "Omesh", ""], ["Nachman", "Lama", ""], ["Chunara", "Rumi", ""], ["Srikumar", "Madhulika", ""], ["Weller", "Adrian", ""], ["Xiang", "Alice", ""]]}, {"id": "2011.07595", "submitter": "Kushal Chakrabarti", "authors": "Kushal Chakrabarti, Nirupam Gupta and Nikhil Chopra", "title": "Accelerating Distributed SGD for Linear Regression using Iterative\n  Pre-Conditioning", "comments": "Changes in the replacement: Application to distributed state\n  estimation problem has been added in Appendix B. Related articles:\n  arXiv:2003.07180v2 [math.OC] and arXiv:2008.02856v1 [math.OC]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the multi-agent distributed linear least-squares\nproblem. The system comprises multiple agents, each agent with a locally\nobserved set of data points, and a common server with whom the agents can\ninteract. The agents' goal is to compute a linear model that best fits the\ncollective data points observed by all the agents. In the server-based\ndistributed settings, the server cannot access the data points held by the\nagents. The recently proposed Iteratively Pre-conditioned Gradient-descent\n(IPG) method has been shown to converge faster than other existing distributed\nalgorithms that solve this problem. In the IPG algorithm, the server and the\nagents perform numerous iterative computations. Each of these iterations relies\non the entire batch of data points observed by the agents for updating the\ncurrent estimate of the solution. Here, we extend the idea of iterative\npre-conditioning to the stochastic settings, where the server updates the\nestimate and the iterative pre-conditioning matrix based on a single randomly\nselected data point at every iteration. We show that our proposed Iteratively\nPre-conditioned Stochastic Gradient-descent (IPSG) method converges linearly in\nexpectation to a proximity of the solution. Importantly, we empirically show\nthat the proposed IPSG method's convergence rate compares favorably to\nprominent stochastic algorithms for solving the linear least-squares problem in\nserver-based networks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 18:09:13 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 08:05:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chakrabarti", "Kushal", ""], ["Gupta", "Nirupam", ""], ["Chopra", "Nikhil", ""]]}, {"id": "2011.07605", "submitter": "Tosin Adewumi", "authors": "Tosin P. Adewumi, Foteini Liwicki and Marcus Liwicki", "title": "The Challenge of Diacritics in Yoruba Embeddings", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The major contributions of this work include the empirical establishment of a\nbetter performance for Yoruba embeddings from undiacritized (normalized)\ndataset and provision of new analogy sets for evaluation. The Yoruba language,\nbeing a tonal language, utilizes diacritics (tonal marks) in written form. We\nshow that this affects embedding performance by creating embeddings from\nexactly the same Wikipedia dataset but with the second one normalized to be\nundiacritized. We further compare average intrinsic performance with two other\nwork (using analogy test set & WordSim) and we obtain the best performance in\nWordSim and corresponding Spearman correlation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 19:02:46 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Adewumi", "Tosin P.", ""], ["Liwicki", "Foteini", ""], ["Liwicki", "Marcus", ""]]}, {"id": "2011.07607", "submitter": "Uri Shaham", "authors": "Uri Shaham, Jonathan Svirsky", "title": "Deep Ordinal Regression using Optimal Transport Loss and Unimodal Output\n  Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for deep ordinal regression, based on unimodal output\ndistribution and optimal transport loss. Despite being seemingly appropriate,\nin many recent works the unimodality requirement is either absent, or\nimplemented using soft targets, which do not guarantee unimodal outputs at\ninference. In addition, we argue that the standard maximum likelihood objective\nis not suitable for ordinal regression problems, and that optimal transport is\nbetter suited for this task, as it naturally captures the order of the classes.\nInspired by the well-known Proportional Odds model, we propose to modify its\ndesign by using an architectural mechanism which guarantees that the model\noutput distribution will be unimodal. We empirically analyze the different\ncomponents of our propose approach and demonstrate their contribution to the\nperformance of the model. Experimental results on three real-world datasets\ndemonstrate that our proposed approach performs on par with several recently\nproposed deep learning approaches for deep ordinal regression with unimodal\noutput probabilities, while having guarantee on the output unimodality. In\naddition, we demonstrate that the level of prediction uncertainty of the model\ncorrelates with its accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 19:19:40 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Shaham", "Uri", ""], ["Svirsky", "Jonathan", ""]]}, {"id": "2011.07613", "submitter": "Swapnil Daga", "authors": "Swapnil Daga, Gokul B. Nair, Anirudha Ramesh, Rahul Sajnani, Junaid\n  Ahmed Ansari and K. Madhava Krishna", "title": "BirdSLAM: Monocular Multibody SLAM in Bird's-Eye View", "comments": "Accepted in VISIGRAPP (VISAPP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present BirdSLAM, a novel simultaneous localization and\nmapping (SLAM) system for the challenging scenario of autonomous driving\nplatforms equipped with only a monocular camera. BirdSLAM tackles challenges\nfaced by other monocular SLAM systems (such as scale ambiguity in monocular\nreconstruction, dynamic object localization, and uncertainty in feature\nrepresentation) by using an orthographic (bird's-eye) view as the configuration\nspace in which localization and mapping are performed. By assuming only the\nheight of the ego-camera above the ground, BirdSLAM leverages single-view\nmetrology cues to accurately localize the ego-vehicle and all other traffic\nparticipants in bird's-eye view. We demonstrate that our system outperforms\nprior work that uses strictly greater information, and highlight the relevance\nof each design decision via an ablation analysis.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 19:37:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Daga", "Swapnil", ""], ["Nair", "Gokul B.", ""], ["Ramesh", "Anirudha", ""], ["Sajnani", "Rahul", ""], ["Ansari", "Junaid Ahmed", ""], ["Krishna", "K. Madhava", ""]]}, {"id": "2011.07616", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Diego Ortego, Kevin McGuinness, Noel E. O'Connor,\n  Xavier Serra", "title": "Unsupervised Contrastive Learning of Sound Event Representations", "comments": "A 4-page version is submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised representation learning can mitigate the limitations in\nrecognition tasks with few manually labeled data but abundant unlabeled\ndata---a common scenario in sound event research. In this work, we explore\nunsupervised contrastive learning as a way to learn sound event\nrepresentations. To this end, we propose to use the pretext task of contrasting\ndifferently augmented views of sound events. The views are computed primarily\nvia mixing of training examples with unrelated backgrounds, followed by other\ndata augmentations. We analyze the main components of our method via ablation\nexperiments. We evaluate the learned representations using linear evaluation,\nand in two in-domain downstream sound event classification tasks, namely, using\nlimited manually labeled data, and using noisy labeled data. Our results\nsuggest that unsupervised contrastive pre-training can mitigate the impact of\ndata scarcity and increase robustness against noisy labels, outperforming\nsupervised baselines.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 19:50:14 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Ortego", "Diego", ""], ["McGuinness", "Kevin", ""], ["O'Connor", "Noel E.", ""], ["Serra", "Xavier", ""]]}, {"id": "2011.07630", "submitter": "Masoud Ebrahimi", "authors": "Roderick Bloem and Hana Chockler and Masoud Ebrahimi and Dana Fisman\n  and Heinz Riener", "title": "Safety Synthesis Sans Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We define the problem of learning a transducer ${S}$ from a target language\n$U$ containing possibly conflicting transducers, using membership queries and\nconjecture queries. The requirement is that the language of ${S}$ be a subset\nof $U$. We argue that this is a natural question in many situations in hardware\nand software verification. We devise a learning algorithm for this problem and\nshow that its time and query complexity is polynomial with respect to the rank\nof the target language, its incompatibility measure, and the maximal length of\na given counterexample. We report on experiments conducted with a prototype\nimplementation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 21:13:17 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 13:25:02 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bloem", "Roderick", ""], ["Chockler", "Hana", ""], ["Ebrahimi", "Masoud", ""], ["Fisman", "Dana", ""], ["Riener", "Heinz", ""]]}, {"id": "2011.07633", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Binghui Wang, Xiaoyu Cao, Hongbin Liu, Neil Zhenqiang\n  Gong", "title": "Almost Tight L0-norm Certified Robustness of Top-k Predictions against\n  Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Top-$k$ predictions are used in many real-world applications such as machine\nlearning as a service, recommender systems, and web searches. $\\ell_0$-norm\nadversarial perturbation characterizes an attack that arbitrarily modifies some\nfeatures of an input such that a classifier makes an incorrect prediction for\nthe perturbed input. $\\ell_0$-norm adversarial perturbation is easy to\ninterpret and can be implemented in the physical world. Therefore, certifying\nrobustness of top-$k$ predictions against $\\ell_0$-norm adversarial\nperturbation is important. However, existing studies either focused on\ncertifying $\\ell_0$-norm robustness of top-$1$ predictions or $\\ell_2$-norm\nrobustness of top-$k$ predictions. In this work, we aim to bridge the gap. Our\napproach is based on randomized smoothing, which builds a provably robust\nclassifier from an arbitrary classifier via randomizing an input. Our major\ntheoretical contribution is an almost tight $\\ell_0$-norm certified robustness\nguarantee for top-$k$ predictions. We empirically evaluate our method on\nCIFAR10 and ImageNet. For instance, our method can build a classifier that\nachieves a certified top-3 accuracy of 69.2\\% on ImageNet when an attacker can\narbitrarily perturb 5 pixels of a testing image.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 21:34:44 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jia", "Jinyuan", ""], ["Wang", "Binghui", ""], ["Cao", "Xiaoyu", ""], ["Liu", "Hongbin", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2011.07635", "submitter": "Ramakanth Pasunuru", "authors": "Ramakanth Pasunuru, Han Guo, Mohit Bansal", "title": "DORB: Dynamically Optimizing Multiple Rewards with Bandits", "comments": "EMNLP 2020 (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradients-based reinforcement learning has proven to be a promising\napproach for directly optimizing non-differentiable evaluation metrics for\nlanguage generation tasks. However, optimizing for a specific metric reward\nleads to improvements in mostly that metric only, suggesting that the model is\ngaming the formulation of that metric in a particular way without often\nachieving real qualitative improvements. Hence, it is more beneficial to make\nthe model optimize multiple diverse metric rewards jointly. While appealing,\nthis is challenging because one needs to manually decide the importance and\nscaling weights of these metric rewards. Further, it is important to consider\nusing a dynamic combination and curriculum of metric rewards that flexibly\nchanges over time. Considering the above aspects, in our work, we automate the\noptimization of multiple metric rewards simultaneously via a multi-armed bandit\napproach (DORB), where at each round, the bandit chooses which metric reward to\noptimize next, based on expected arm gains. We use the Exp3 algorithm for\nbandits and formulate two approaches for bandit rewards: (1) Single\nMulti-reward Bandit (SM-Bandit); (2) Hierarchical Multi-reward Bandit\n(HM-Bandit). We empirically show the effectiveness of our approaches via\nvarious automatic metrics and human evaluation on two important NLG tasks:\nquestion generation and data-to-text generation, including on an unseen-test\ntransfer setup. Finally, we present interpretable analyses of the learned\nbandit curriculum over the optimized rewards.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 21:57:47 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Pasunuru", "Ramakanth", ""], ["Guo", "Han", ""], ["Bansal", "Mohit", ""]]}, {"id": "2011.07640", "submitter": "Jiaju Miao", "authors": "Jiaju Miao, Wei Zhu", "title": "Precision-Recall Curve (PRC) Classification Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of imbalanced data has presented a significant challenge\nfor most well-known classification algorithms that were often designed for data\nwith relatively balanced class distributions. Nevertheless skewed class\ndistribution is a common feature in real world problems. It is especially\nprevalent in certain application domains with great need for machine learning\nand better predictive analysis such as disease diagnosis, fraud detection,\nbankruptcy prediction, and suspect identification. In this paper, we propose a\nnovel tree-based algorithm based on the area under the precision-recall curve\n(AUPRC) for variable selection in the classification context. Our algorithm,\nnamed as the \"Precision-Recall Curve classification tree\", or simply the \"PRC\nclassification tree\" modifies two crucial stages in tree building. The first\nstage is to maximize the area under the precision-recall curve in node variable\nselection. The second stage is to maximize the harmonic mean of recall and\nprecision (F-measure) for threshold selection. We found the proposed PRC\nclassification tree, and its subsequent extension, the PRC random forest, work\nwell especially for class-imbalanced data sets. We have demonstrated that our\nmethods outperform their classic counterparts, the usual CART and random forest\nfor both synthetic and real data. Furthermore, the ROC classification tree\nproposed by our group previously has shown good performance in imbalanced data.\nThe combination of them, the PRC-ROC tree, also shows great promise in\nidentifying the minority class.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 22:31:06 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Miao", "Jiaju", ""], ["Zhu", "Wei", ""]]}, {"id": "2011.07643", "submitter": "Nikolaos Dimitriadis", "authors": "Nikolaos Dimitriadis, Petros Maragos", "title": "Advances in the training, pruning and enforcement of shape constraints\n  of Morphological Neural Networks using Tropical Algebra", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study an emerging class of neural networks based on the\nmorphological operators of dilation and erosion. We explore these networks\nmathematically from a tropical geometry perspective as well as mathematical\nmorphology. Our contributions are threefold. First, we examine the training of\nmorphological networks via Difference-of-Convex programming methods and extend\na binary morphological classifier to multiclass tasks. Second, we focus on the\nsparsity of dense morphological networks trained via gradient descent\nalgorithms and compare their performance to their linear counterparts under\nheavy pruning, showing that the morphological networks cope far better and are\ncharacterized with superior compression capabilities. Our approach incorporates\nthe effect of the training optimizer used and offers quantitative and\nqualitative explanations. Finally, we study how the architectural structure of\na morphological network can affect shape constraints, focusing on monotonicity.\nVia Maslov Dequantization, we obtain a softened version of a known architecture\nand show how this approach can improve training convergence and performance.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 22:44:25 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Dimitriadis", "Nikolaos", ""], ["Maragos", "Petros", ""]]}, {"id": "2011.07656", "submitter": "Vidhi Jain", "authors": "Vidhi Jain, Rohit Jena, Huao Li, Tejus Gupta, Dana Hughes, Michael\n  Lewis, Katia Sycara", "title": "Predicting Human Strategies in Simulated Search and Rescue Task", "comments": "Accepted at NeurIPS 2020; Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response (AI+HADR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a search and rescue scenario, rescuers may have different knowledge of the\nenvironment and strategies for exploration. Understanding what is inside a\nrescuer's mind will enable an observer agent to proactively assist them with\ncritical information that can help them perform their task efficiently. To this\nend, we propose to build models of the rescuers based on their trajectory\nobservations to predict their strategies. In our efforts to model the rescuer's\nmind, we begin with a simple simulated search and rescue task in Minecraft with\nhuman participants. We formulate neural sequence models to predict the triage\nstrategy and the next location of the rescuer. As the neural networks are\ndata-driven, we design a diverse set of artificial \"faux human\" agents for\ntraining, to test them with limited human rescuer trajectory data. To evaluate\nthe agents, we compare it to an evidence accumulation method that explicitly\nincorporates all available background knowledge and provides an intended upper\nbound for the expected performance. Further, we perform experiments where the\nobserver/predictor is human. We show results in terms of prediction accuracy of\nour computational approaches as compared with that of human observers.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 23:24:23 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 23:26:39 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Jain", "Vidhi", ""], ["Jena", "Rohit", ""], ["Li", "Huao", ""], ["Gupta", "Tejus", ""], ["Hughes", "Dana", ""], ["Lewis", "Michael", ""], ["Sycara", "Katia", ""]]}, {"id": "2011.07661", "submitter": "Luca Parisi", "authors": "Luca Parisi, Renfei Ma, Narrendar RaviChandran and Matteo Lanzillotta", "title": "hyper-sinh: An Accurate and Reliable Function from Shallow to Deep\n  Learning in TensorFlow and Keras", "comments": "19 pages, 6 listings/Python code snippets, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the 'hyper-sinh', a variation of the m-arcsinh activation\nfunction suitable for Deep Learning (DL)-based algorithms for supervised\nlearning, such as Convolutional Neural Networks (CNN). hyper-sinh, developed in\nthe open source Python libraries TensorFlow and Keras, is thus described and\nvalidated as an accurate and reliable activation function for both shallow and\ndeep neural networks. Improvements in accuracy and reliability in image and\ntext classification tasks on five (N = 5) benchmark data sets available from\nKeras are discussed. Experimental results demonstrate the overall competitive\nclassification performance of both shallow and deep neural networks, obtained\nvia this novel function. This function is evaluated with respect to gold\nstandard activation functions, demonstrating its overall competitive accuracy\nand reliability for both image and text classification.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 23:38:59 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Parisi", "Luca", ""], ["Ma", "Renfei", ""], ["RaviChandran", "Narrendar", ""], ["Lanzillotta", "Matteo", ""]]}, {"id": "2011.07665", "submitter": "Wook Lee", "authors": "Wook Lee, Frans A. Oliehoek", "title": "Analog Circuit Design with Dyna-Style Reinforcement Learning", "comments": "NeurIPS 2020 Workshop on Machine Learning for Engineering Modeling,\n  Simulation and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a learning based approach to analog circuit design,\nwhere the goal is to optimize circuit performance subject to certain design\nconstraints. One of the aspects that makes this problem challenging to\noptimize, is that measuring the performance of candidate configurations with\nsimulation can be computationally expensive, particularly in the post-layout\ndesign. Additionally, the large number of design constraints and the\ninteraction between the relevant quantities makes the problem complex.\nTherefore, to better facilitate supporting the human designers, it is desirable\nto gain knowledge about the whole space of feasible solutions. In order to\ntackle these challenges, we take inspiration from model-based reinforcement\nlearning and propose a method with two key properties. First, it learns a\nreward model, i.e., surrogate model of the performance approximated by neural\nnetworks, to reduce the required number of simulation. Second, it uses a\nstochastic policy generator to explore the diverse solution space satisfying\nconstraints. Together we combine these in a Dyna-style optimization framework,\nwhich we call DynaOpt, and empirically evaluate the performance on a circuit\nbenchmark of a two-stage operational amplifier. The results show that, compared\nto the model-free method applied with 20,000 circuit simulations to train the\npolicy, DynaOpt achieves even much better performance by learning from scratch\nwith only 500 simulations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 00:19:25 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lee", "Wook", ""], ["Oliehoek", "Frans A.", ""]]}, {"id": "2011.07679", "submitter": "Muhammad Furqon Ariful", "authors": "Muhammad Ariful Furqon, Nina Fadilah Najwa, Endah Septa Sintiya,\n  Erista Maya Safitri, Iqbal Ramadhani Mukhlis", "title": "Critical data analysis of COVID-19 spreading in Indonesia to measure the\n  readiness of new-normal policy", "comments": "13 pages 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  COVID-19 pandemic has become a global issue nowadays. Various efforts have\nbeen made to break the chain of the spread of the COVID-19. Indonesia's\ngovernment issued a large-scale social restrictions policy to prevent the\nspread of the COVID-19. However, large-scale social restrictions policy\nimpacted the economy of the Indonesian. After several considerations, the\nIndonesian government implemented a new-normal policy, which regulates the\nactivities outside the home with strict health protocols. This study's\nobjective is to measure Indonesia's readiness level after the large-scale\nsocial restrictions period towards the new-normal period. To specify the\nreadiness level, the measurement parameters required in the form of statistical\nanalysis and forecasting modeling. Based on the results of statistical analysis\nand forecasting, over the past month, new confirmed cases increased more than\ntwo times. Besides, the growth rate of new confirmed cases dramatically\nincreased rapidly compared to the prediction results. Therefore, the government\nmust review the new-normal policy again and emphasize economic factors and\nthink about health factors\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:42:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Furqon", "Muhammad Ariful", ""], ["Najwa", "Nina Fadilah", ""], ["Sintiya", "Endah Septa", ""], ["Safitri", "Erista Maya", ""], ["Mukhlis", "Iqbal Ramadhani", ""]]}, {"id": "2011.07680", "submitter": "Wenting Xu", "authors": "Wenting Xu, Chang Qi, Zhenghua Xu and Thomas Lukasiewicz", "title": "Reinforced Medical Report Generation with X-Linear Attention and\n  Repetition Penalty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To reduce doctors' workload, deep-learning-based automatic medical report\ngeneration has recently attracted more and more research efforts, where\nattention mechanisms and reinforcement learning are integrated with the classic\nencoder-decoder architecture to enhance the performance of deep models.\nHowever, these state-of-the-art solutions mainly suffer from two shortcomings:\n(i) their attention mechanisms cannot utilize high-order feature interactions,\nand (ii) due to the use of TF-IDF-based reward functions, these methods are\nfragile with generating repeated terms. Therefore, in this work, we propose a\nreinforced medical report generation solution with x-linear attention and\nrepetition penalty mechanisms (ReMRG-XR) to overcome these problems.\nSpecifically, x-linear attention modules are used to explore high-order feature\ninteractions and achieve multi-modal reasoning, while repetition penalty is\nused to apply penalties to repeated terms during the model's training process.\nExtensive experimental studies have been conducted on two public datasets, and\nthe results show that ReMRG-XR greatly outperforms the state-of-the-art\nbaselines in terms of all metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:44:47 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Xu", "Wenting", ""], ["Qi", "Chang", ""], ["Xu", "Zhenghua", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2011.07682", "submitter": "Scott Freitas", "authors": "Scott Freitas, Yuxiao Dong, Joshua Neil, Duen Horng Chau", "title": "A Large-Scale Database for Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid emergence of graph representation learning, the construction\nof new large-scale datasets are necessary to distinguish model capabilities and\naccurately assess the strengths and weaknesses of each technique. By carefully\nanalyzing existing graph databases, we identify 3 critical components important\nfor advancing the field of graph representation learning: (1) large graphs, (2)\nmany graphs, and (3) class diversity. To date, no single graph database offers\nall of these desired properties. We introduce MalNet, the largest public graph\ndatabase ever constructed, representing a large-scale ontology of software\nfunction call graphs. MalNet contains over 1.2 million graphs, averaging over\n17k nodes and 39k edges per graph, across a hierarchy of 47 types and 696\nfamilies. Compared to the popular REDDIT-12K database, MalNet offers 105x more\ngraphs, 44x larger graphs on average, and 63x the classes. We provide a\ndetailed analysis of MalNet, discussing its properties and provenance. The\nunprecedented scale and diversity of MalNet offers exciting opportunities to\nadvance the frontiers of graph representation learning---enabling new\ndiscoveries and research into imbalanced classification, explainability and the\nimpact of class hardness. The database is publically available at\nwww.mal-net.org.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:50:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Freitas", "Scott", ""], ["Dong", "Yuxiao", ""], ["Neil", "Joshua", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2011.07683", "submitter": "Deepak Maurya Mr", "authors": "Deepak Maurya and Balaraman Ravindran", "title": "Hypergraph Partitioning using Tensor Eigenvalue Decomposition", "comments": "22 pages with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hypergraphs have gained increasing attention in the machine learning\ncommunity lately due to their superiority over graphs in capturing super-dyadic\ninteractions among entities. In this work, we propose a novel approach for the\npartitioning of k-uniform hypergraphs. Most of the existing methods work by\nreducing the hypergraph to a graph followed by applying standard graph\npartitioning algorithms. The reduction step restricts the algorithms to\ncapturing only some weighted pairwise interactions and hence loses essential\ninformation about the original hypergraph. We overcome this issue by utilizing\nthe tensor-based representation of hypergraphs, which enables us to capture\nactual super-dyadic interactions. We prove that the hypergraph to graph\nreduction is a special case of tensor contraction. We extend the notion of\nminimum ratio-cut and normalized-cut from graphs to hypergraphs and show the\nrelaxed optimization problem is equivalent to tensor eigenvalue decomposition.\nThis novel formulation also enables us to capture different ways of cutting a\nhyperedge, unlike the existing reduction approaches. We propose a hypergraph\npartitioning algorithm inspired from spectral graph theory that can accommodate\nthis notion of hyperedge cuts. We also derive a tighter upper bound on the\nminimum positive eigenvalue of even-order hypergraph Laplacian tensor in terms\nof its conductance, which is utilized in the partitioning algorithm to\napproximate the normalized cut. The efficacy of the proposed method is\ndemonstrated numerically on simple hypergraphs. We also show improvement for\nthe min-cut solution on 2-uniform hypergraphs (graphs) over the standard\nspectral partitioning algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:55:43 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Maurya", "Deepak", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2011.07687", "submitter": "Mridul Agarwal", "authors": "Mridul Agarwal, Vaneet Aggarwal, Christopher J. Quinn, Abhishek\n  Umrawal", "title": "DART: aDaptive Accept RejecT for non-linear top-K subset identification", "comments": null, "journal-ref": "AAAI 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the bandit problem of selecting $K$ out of $N$ arms at each time\nstep. The reward can be a non-linear function of the rewards of the selected\nindividual arms. The direct use of a multi-armed bandit algorithm requires\nchoosing among $\\binom{N}{K}$ options, making the action space large. To\nsimplify the problem, existing works on combinatorial bandits {typically}\nassume feedback as a linear function of individual rewards. In this paper, we\nprove the lower bound for top-$K$ subset selection with bandit feedback with\npossibly correlated rewards. We present a novel algorithm for the combinatorial\nsetting without using individual arm feedback or requiring linearity of the\nreward function. Additionally, our algorithm works on correlated rewards of\nindividual arms. Our algorithm, aDaptive Accept RejecT (DART), sequentially\nfinds good arms and eliminates bad arms based on confidence bounds. DART is\ncomputationally efficient and uses storage linear in $N$. Further, DART\nachieves a regret bound of $\\tilde{\\mathcal{O}}(K\\sqrt{KNT})$ for a time\nhorizon $T$, which matches the lower bound in bandit feedback up to a factor of\n$\\sqrt{\\log{2NT}}$. When applied to the problem of cross-selling optimization\nand maximizing the mean of individual rewards, the performance of the proposed\nalgorithm surpasses that of state-of-the-art algorithms. We also show that DART\nsignificantly outperforms existing methods for both linear and non-linear joint\nreward environments.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 02:10:06 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""], ["Quinn", "Christopher J.", ""], ["Umrawal", "Abhishek", ""]]}, {"id": "2011.07706", "submitter": "Seungkyu Lee", "authors": "Gahye Lee and Seungkyu Lee", "title": "Mode Penalty Generative Adversarial Network with adapted Auto-encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) are trained to generate sample images\nof interest distribution. To this end, generator network of GAN learns implicit\ndistribution of real data set from the classification with candidate generated\nsamples. Recently, various GANs have suggested novel ideas for stable\noptimizing of its networks. However, in real implementation, sometimes they\nstill represent a only narrow part of true distribution or fail to converge. We\nassume this ill posed problem comes from poor gradient from objective function\nof discriminator, which easily trap the generator in a bad situation. To\naddress this problem, we propose a mode penalty GAN combined with pre-trained\nauto encoder for explicit representation of generated and real data samples in\nthe encoded space. In this space, we make a generator manifold to follow a real\nmanifold by finding entire modes of target distribution. In addition, penalty\nfor uncovered modes of target distribution is given to the generator which\nencourages it to find overall target distribution. We demonstrate that applying\nthe proposed method to GANs helps generator's optimization becoming more stable\nand having faster convergence through experimental evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 03:39:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lee", "Gahye", ""], ["Lee", "Seungkyu", ""]]}, {"id": "2011.07715", "submitter": "Mridul Agarwal", "authors": "Mridul Agarwal, Vaneet Aggarwal", "title": "Blind Decision Making: Reinforcement Learning with Delayed Observations", "comments": null, "journal-ref": "in part in ICAPS 2021", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning typically assumes that the state update from the\nprevious actions happens instantaneously, and thus can be used for making\nfuture decisions. However, this may not always be true. When the state update\nis not available, the decision taken is partly in the blind since it cannot\nrely on the current state information. This paper proposes an approach, where\nthe delay in the knowledge of the state can be used, and the decisions are made\nbased on the available information which may not include the current state\ninformation. One approach could be to include the actions after the last-known\nstate as a part of the state information, however, that leads to an increased\nstate-space making the problem complex and slower in convergence. The proposed\nalgorithm gives an alternate approach where the state space is not enlarged, as\ncompared to the case when there is no delay in the state update. Evaluations on\nthe basic RL environments further illustrate the improved performance of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 04:29:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2011.07720", "submitter": "Udari Madhushani", "authors": "Udari Madhushani and Naomi Ehrich Leonard", "title": "Distributed Bandits: Probabilistic Communication on $d$-regular Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the decentralized multi-agent multi-armed bandit problem for agents\nthat communicate with probability over a network defined by a $d$-regular\ngraph. Every edge in the graph has probabilistic weight $p$ to account for the\n($1\\!-\\!p$) probability of a communication link failure. At each time step,\neach agent chooses an arm and receives a numerical reward associated with the\nchosen arm. After each choice, each agent observes the last obtained reward of\neach of its neighbors with probability $p$. We propose a new Upper Confidence\nBound (UCB) based algorithm and analyze how agent-based strategies contribute\nto minimizing group regret in this probabilistic communication setting. We\nprovide theoretical guarantees that our algorithm outperforms state-of-the-art\nalgorithms. We illustrate our results and validate the theoretical claims using\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 04:53:54 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Madhushani", "Udari", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "2011.07727", "submitter": "Youngsoo Choi", "authors": "Youngkyu Kim and Youngsoo Choi and David Widemann and Tarek Zohdi", "title": "Efficient nonlinear manifold reduced order model", "comments": "10 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2009.11990", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional linear subspace reduced order models (LS-ROMs) are able to\naccelerate physical simulations, in which the intrinsic solution space falls\ninto a subspace with a small dimension, i.e., the solution space has a small\nKolmogorov n-width. However, for physical phenomena not of this type, such as\nadvection-dominated flow phenomena, a low-dimensional linear subspace poorly\napproximates the solution. To address cases such as these, we have developed an\nefficient nonlinear manifold ROM (NM-ROM), which can better approximate\nhigh-fidelity model solutions with a smaller latent space dimension than the\nLS-ROMs. Our method takes advantage of the existing numerical methods that are\nused to solve the corresponding full order models (FOMs). The efficiency is\nachieved by developing a hyper-reduction technique in the context of the\nNM-ROM. Numerical results show that neural networks can learn a more efficient\nlatent space representation on advection-dominated data from 2D Burgers'\nequations with a high Reynolds number. A speed-up of up to 11.7 for 2D Burgers'\nequations is achieved with an appropriate treatment of the nonlinear terms\nthrough a hyper-reduction technique.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 18:46:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kim", "Youngkyu", ""], ["Choi", "Youngsoo", ""], ["Widemann", "David", ""], ["Zohdi", "Tarek", ""]]}, {"id": "2011.07728", "submitter": "Fanyou Wu", "authors": "Fanyou Wu, Yang Liu, Zhiyuan Liu, Xiaobo Qu, Rado Gazo, Eva Haviarova", "title": "TLab: Traffic Map Movie Forecasting Based on HR-NET", "comments": "arXiv admin note: text overlap with arXiv:1911.05699 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The problem of the effective prediction for large-scale spatio-temporal\ntraffic data has long haunted researchers in the field of intelligent\ntransportation. Limited by the quantity of data, citywide traffic state\nprediction was seldom achieved. Hence the complex urban transportation system\nof an entire city cannot be truly understood. Thanks to the efforts of\norganizations like IARAI, the massive open data provided by them has made the\nresearch possible. In our 2020 Competition solution, we further design multiple\nvariants based on HR-NET and UNet. Through feature engineering, the\nhand-crafted features are input into the model in a form of channels. It is\nworth noting that, to learn the inherent attributes of geographical locations,\nwe proposed a novel method called geo-embedding, which contributes to\nsignificant improvement in the accuracy of the model. In addition, we explored\nthe influence of the selection of activation functions and optimizers, as well\nas tricks during model training on the model performance. In terms of\nprediction accuracy, our solution has won 2nd place in NeurIPS 2020,\nTraffic4cast Challenge.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 18:48:13 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 01:55:33 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wu", "Fanyou", ""], ["Liu", "Yang", ""], ["Liu", "Zhiyuan", ""], ["Qu", "Xiaobo", ""], ["Gazo", "Rado", ""], ["Haviarova", "Eva", ""]]}, {"id": "2011.07729", "submitter": "Christos Thrampoulidis", "authors": "Christos Thrampoulidis, Samet Oymak, Mahdi Soltanolkotabi", "title": "Theoretical Insights Into Multiclass Classification: A High-dimensional\n  Asymptotic View", "comments": "To Appear at NeurIPS 2020. 62 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Contemporary machine learning applications often involve classification tasks\nwith many classes. Despite their extensive use, a precise understanding of the\nstatistical properties and behavior of classification algorithms is still\nmissing, especially in modern regimes where the number of classes is rather\nlarge. In this paper, we take a step in this direction by providing the first\nasymptotically precise analysis of linear multiclass classification. Our\ntheoretical analysis allows us to precisely characterize how the test error\nvaries over different training algorithms, data distributions, problem\ndimensions as well as number of classes, inter/intra class correlations and\nclass priors. Specifically, our analysis reveals that the classification\naccuracy is highly distribution-dependent with different algorithms achieving\noptimal performance for different data distributions and/or training/features\nsizes. Unlike linear regression/binary classification, the test error in\nmulticlass classification relies on intricate functions of the trained model\n(e.g., correlation between some of the trained weights) whose asymptotic\nbehavior is difficult to characterize. This challenge is already present in\nsimple classifiers, such as those minimizing a square loss. Our novel\ntheoretical techniques allow us to overcome some of these challenges. The\ninsights gained may pave the way for a precise understanding of other\nclassification algorithms beyond those studied in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 05:17:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Thrampoulidis", "Christos", ""], ["Oymak", "Samet", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "2011.07735", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, Gurneet Arora, Navpreet Kaloty", "title": "iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video\n  Captioning and Video Question Answering", "comments": "13 pages, 6 figures, 4 tables, Project Page:\n  https://iperceive.amanchadha.com", "journal-ref": "IEEE Winter Conference on Applications of Computer Vision (WACV)\n  2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most prior art in visual understanding relies solely on analyzing the \"what\"\n(e.g., event recognition) and \"where\" (e.g., event localization), which in some\ncases, fails to describe correct contextual relationships between events or\nleads to incorrect underlying visual attention. Part of what defines us as\nhuman and fundamentally different from machines is our instinct to seek\ncausality behind any association, say an event Y that happened as a direct\nresult of event X. To this end, we propose iPerceive, a framework capable of\nunderstanding the \"why\" between events in a video by building a common-sense\nknowledge base using contextual cues to infer causal relationships between\nobjects in the video. We demonstrate the effectiveness of our technique using\nthe dense video captioning (DVC) and video question answering (VideoQA) tasks.\nFurthermore, while most prior work in DVC and VideoQA relies solely on visual\ninformation, other modalities such as audio and speech are vital for a human\nobserver's perception of an environment. We formulate DVC and VideoQA tasks as\nmachine translation problems that utilize multiple modalities. By evaluating\nthe performance of iPerceive DVC and iPerceive VideoQA on the ActivityNet\nCaptions and TVQA datasets respectively, we show that our approach furthers the\nstate-of-the-art. Code and samples are available at: iperceive.amanchadha.com.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 05:44:45 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chadha", "Aman", ""], ["Arora", "Gurneet", ""], ["Kaloty", "Navpreet", ""]]}, {"id": "2011.07738", "submitter": "Akshay Mete", "authors": "Akshay Mete, Rahul Singh, Xi Liu and P. R. Kumar", "title": "Reward Biased Maximum Likelihood Estimation for Reinforcement Learning", "comments": "3rd Annual Learning for Dynamics & Control Conference (L4DC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Reward-Biased Maximum Likelihood Estimate (RBMLE) for adaptive control of\nMarkov chains was proposed to overcome the central obstacle of what is\nvariously called the fundamental \"closed-identifiability problem\" of adaptive\ncontrol, the \"dual control problem\", or, contemporaneously, the \"exploration\nvs. exploitation problem\". It exploited the key observation that since the\nmaximum likelihood parameter estimator can asymptotically identify the\nclosed-transition probabilities under a certainty equivalent approach, the\nlimiting parameter estimates must necessarily have an optimal reward that is\nless than the optimal reward attainable for the true but unknown system. Hence\nit proposed a counteracting reverse bias in favor of parameters with larger\noptimal rewards, providing a solution to the fundamental problem alluded to\nabove. It thereby proposed an optimistic approach of favoring parameters with\nlarger optimal rewards, now known as \"optimism in the face of uncertainty\". The\nRBMLE approach has been proved to be long-term average reward optimal in a\nvariety of contexts. However, modern attention is focused on the much finer\nnotion of \"regret\", or finite-time performance. Recent analysis of RBMLE for\nmulti-armed stochastic bandits and linear contextual bandits has shown that it\nnot only has state-of-the-art regret, but it also exhibits empirical\nperformance comparable to or better than the best current contenders, and leads\nto strikingly simple index policies. Motivated by this, we examine the\nfinite-time performance of RBMLE for reinforcement learning tasks that involve\nthe general problem of optimal control of unknown Markov Decision Processes. We\nshow that it has a regret of $\\mathcal{O}( \\log T)$ over a time horizon of $T$\nsteps, similar to state-of-the-art algorithms. Simulation studies show that\nRBMLE outperforms other algorithms such as UCRL2 and Thompson Sampling.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 06:09:56 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 04:24:38 GMT"}, {"version": "v3", "created": "Sat, 15 May 2021 20:47:58 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mete", "Akshay", ""], ["Singh", "Rahul", ""], ["Liu", "Xi", ""], ["Kumar", "P. R.", ""]]}, {"id": "2011.07743", "submitter": "Yu Gu", "authors": "Yu Gu, Sue Kase, Michelle Vanni, Brian Sadler, Percy Liang, Xifeng\n  Yan, Yu Su", "title": "Beyond I.I.D.: Three Levels of Generalization for Question Answering on\n  Knowledge Bases", "comments": "Accepted to TheWebConf 2021 (previously WWW)", "journal-ref": null, "doi": "10.1145/3442381.3449992", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing studies on question answering on knowledge bases (KBQA) mainly\noperate with the standard i.i.d assumption, i.e., training distribution over\nquestions is the same as the test distribution. However, i.i.d may be neither\nreasonably achievable nor desirable on large-scale KBs because 1) true user\ndistribution is hard to capture and 2) randomly sample training examples from\nthe enormous space would be highly data-inefficient. Instead, we suggest that\nKBQA models should have three levels of built-in generalization: i.i.d,\ncompositional, and zero-shot. To facilitate the development of KBQA models with\nstronger generalization, we construct and release a new large-scale,\nhigh-quality dataset with 64,331 questions, GrailQA, and provide evaluation\nsettings for all three levels of generalization. In addition, we propose a\nnovel BERT-based KBQA model. The combination of our dataset and model enables\nus to thoroughly examine and demonstrate, for the first time, the key role of\npre-trained contextual embeddings like BERT in the generalization of KBQA.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 06:36:26 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 03:36:38 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 03:13:37 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 18:48:38 GMT"}, {"version": "v5", "created": "Fri, 19 Feb 2021 04:11:23 GMT"}, {"version": "v6", "created": "Mon, 22 Feb 2021 19:04:45 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Gu", "Yu", ""], ["Kase", "Sue", ""], ["Vanni", "Michelle", ""], ["Sadler", "Brian", ""], ["Liang", "Percy", ""], ["Yan", "Xifeng", ""], ["Su", "Yu", ""]]}, {"id": "2011.07748", "submitter": "Guanya Shi", "authors": "Guanya Shi, Yifeng Zhu, Jonathan Tremblay, Stan Birchfield, Fabio\n  Ramos, Animashree Anandkumar, Yuke Zhu", "title": "Fast Uncertainty Quantification for Deep Object Pose Estimation", "comments": "Video and code are available at https://sites.google.com/view/fastuq", "journal-ref": "International Conferenceon Robotics and Automation (ICRA), 2021", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based object pose estimators are often unreliable and\noverconfident especially when the input image is outside the training domain,\nfor instance, with sim2real transfer. Efficient and robust uncertainty\nquantification (UQ) in pose estimators is critically needed in many robotic\ntasks. In this work, we propose a simple, efficient, and plug-and-play UQ\nmethod for 6-DoF object pose estimation. We ensemble 2-3 pre-trained models\nwith different neural network architectures and/or training data sources, and\ncompute their average pairwise disagreement against one another to obtain the\nuncertainty quantification. We propose four disagreement metrics, including a\nlearned metric, and show that the average distance (ADD) is the best\nlearning-free metric and it is only slightly worse than the learned metric,\nwhich requires labeled target data. Our method has several advantages compared\nto the prior art: 1) our method does not require any modification of the\ntraining process or the model inputs; and 2) it needs only one forward pass for\neach model. We evaluate the proposed UQ method on three tasks where our\nuncertainty quantification yields much stronger correlations with pose\nestimation errors than the baselines. Moreover, in a real robot grasping task,\nour method increases the grasping success rate from 35% to 90%.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 06:51:55 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 20:38:01 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 05:13:32 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Shi", "Guanya", ""], ["Zhu", "Yifeng", ""], ["Tremblay", "Jonathan", ""], ["Birchfield", "Stan", ""], ["Ramos", "Fabio", ""], ["Anandkumar", "Animashree", ""], ["Zhu", "Yuke", ""]]}, {"id": "2011.07770", "submitter": "Min Yang", "authors": "Yufeng Wang, Dan Li, Xiang Li, Min Yang", "title": "PC-GAIN: Pseudo-label Conditional Generative Adversarial Imputation\n  Networks for Incomplete Data", "comments": "18pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets with missing values are very common in real world applications.\nGAIN, a recently proposed deep generative model for missing data imputation,\nhas been proved to outperform many state-of-the-art methods. But GAIN only uses\na reconstruction loss in the generator to minimize the imputation error of the\nnon-missing part, ignoring the potential category information which can reflect\nthe relationship between samples. In this paper, we propose a novel\nunsupervised missing data imputation method named PC-GAIN, which utilizes\npotential category information to further enhance the imputation power.\nSpecifically, we first propose a pre-training procedure to learn potential\ncategory information contained in a subset of low-missing-rate data. Then an\nauxiliary classifier is determined using the synthetic pseudo-labels. Further,\nthis classifier is incorporated into the generative adversarial framework to\nhelp the generator to yield higher quality imputation results. The proposed\nmethod can improve the imputation quality of GAIN significantly. Experimental\nresults on various benchmark datasets show that our method is also superior to\nother baseline approaches. Our code is available at\n\\url{https://github.com/WYu-Feng/pc-gain}.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:08:26 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 08:41:36 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wang", "Yufeng", ""], ["Li", "Dan", ""], ["Li", "Xiang", ""], ["Yang", "Min", ""]]}, {"id": "2011.07780", "submitter": "Wenyan Zhang", "authors": "Wenyan Zhang, Ling Xu, Meng Yan, Ziliang Wang, and Chunlei Fu", "title": "A Probability Distribution and Location-aware ResNet Approach for QoS\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the number of online services has grown rapidly, invoke the\nrequired services through the cloud platform has become the primary trend. How\nto help users choose and recommend high-quality services among huge amounts of\nunused services has become a hot issue in research. Among the existing QoS\nprediction methods, the collaborative filtering(CF) method can only learn\nlow-dimensional linear characteristics, and its effect is limited by sparse\ndata. Although existing deep learning methods could capture high-dimensional\nnonlinear features better, most of them only use the single feature of\nidentity, and the problem of network deepening gradient disappearance is\nserious, so the effect of QoS prediction is unsatisfactory. To address these\nproblems, we propose an advanced probability distribution and location-aware\nResNet approach for QoS Prediction(PLRes). This approach considers the\nhistorical invocations probability distribution and location characteristics of\nusers and services, and first use the ResNet in QoS prediction to reuses the\nfeatures, which alleviates the problems of gradient disappearance and model\ndegradation. A series of experiments are conducted on a real-world web service\ndataset WS-DREAM. The results indicate that PLRes model is effective for QoS\nprediction and at the density of 5%-30%, which means the data is sparse, it\nsignificantly outperforms a state-of-the-art approach LDCF by 12.35%-15.37% in\nterms of MAE.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:22:04 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhang", "Wenyan", ""], ["Xu", "Ling", ""], ["Yan", "Meng", ""], ["Wang", "Ziliang", ""], ["Fu", "Chunlei", ""]]}, {"id": "2011.07782", "submitter": "Haoran Sun", "authors": "Haoran Sun, Wenqiang Pu, Minghe Zhu, Xiao Fu, Tsung-Hui Chang, Mingyi\n  Hong", "title": "Learning to Continuously Optimize Wireless Resource In Episodically\n  Dynamic Environment", "comments": null, "journal-ref": "IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), 2021, pp. 4945-4949", "doi": "10.1109/ICASSP39728.2021.9413503", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a growing interest in developing data-driven and in particular\ndeep neural network (DNN) based methods for modern communication tasks. For a\nfew popular tasks such as power control, beamforming, and MIMO detection, these\nmethods achieve state-of-the-art performance while requiring less computational\nefforts, less channel state information (CSI), etc. However, it is often\nchallenging for these approaches to learn in a dynamic environment where\nparameters such as CSIs keep changing.\n  This work develops a methodology that enables data-driven methods to\ncontinuously learn and optimize in a dynamic environment. Specifically, we\nconsider an ``episodically dynamic\" setting where the environment changes in\n``episodes\", and in each episode the environment is stationary. We propose to\nbuild the notion of continual learning (CL) into the modeling process of\nlearning wireless systems, so that the learning model can incrementally adapt\nto the new episodes, {\\it without forgetting} knowledge learned from the\nprevious episodes. Our design is based on a novel min-max formulation which\nensures certain ``fairness\" across different data samples. We demonstrate the\neffectiveness of the CL approach by customizing it to two popular DNN based\nmodels (one for power control and one for beamforming), and testing using both\nsynthetic and real data sets. These numerical results show that the proposed CL\napproach is not only able to adapt to the new scenarios quickly and seamlessly,\nbut importantly, it maintains high performance over the previously encountered\nscenarios as well.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:24:34 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Sun", "Haoran", ""], ["Pu", "Wenqiang", ""], ["Zhu", "Minghe", ""], ["Fu", "Xiao", ""], ["Chang", "Tsung-Hui", ""], ["Hong", "Mingyi", ""]]}, {"id": "2011.07792", "submitter": "Edoardo Daniele Cannas", "authors": "Luca Bondi, Edoardo Daniele Cannas, Paolo Bestagini, Stefano Tubaro", "title": "Training Strategies and Data Augmentations in CNN-based DeepFake Video\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast and continuous growth in number and quality of deepfake videos calls\nfor the development of reliable detection systems capable of automatically\nwarning users on social media and on the Internet about the potential\nuntruthfulness of such contents. While algorithms, software, and smartphone\napps are getting better every day in generating manipulated videos and swapping\nfaces, the accuracy of automated systems for face forgery detection in videos\nis still quite limited and generally biased toward the dataset used to design\nand train a specific detection system. In this paper we analyze how different\ntraining strategies and data augmentation techniques affect CNN-based deepfake\ndetectors when training and testing on the same dataset or across different\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:50:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Bondi", "Luca", ""], ["Cannas", "Edoardo Daniele", ""], ["Bestagini", "Paolo", ""], ["Tubaro", "Stefano", ""]]}, {"id": "2011.07798", "submitter": "Miao Cheng", "authors": "Miao Cheng, Xinge You", "title": "Adaptive Matching of Kernel Means", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising step, the performance of data analysis and feature learning\nare able to be improved if certain pattern matching mechanism is available. One\nof the feasible solutions can refer to the importance estimation of instances,\nand consequently, kernel mean matching (KMM) has become an important method for\nknowledge discovery and novelty detection in kernel machines. Furthermore, the\nexisting KMM methods have focused on concrete learning frameworks. In this\nwork, a novel approach to adaptive matching of kernel means is proposed, and\nselected data with high importance are adopted to achieve calculation\nefficiency with optimization. In addition, scalable learning can be conducted\nin proposed method as a generalized solution to matching of appended data. The\nexperimental results on a wide variety of real-world data sets demonstrate the\nproposed method is able to give outstanding performance compared with several\nstate-of-the-art methods, while calculation efficiency can be preserved.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:00:14 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Cheng", "Miao", ""], ["You", "Xinge", ""]]}, {"id": "2011.07801", "submitter": "Guannan Hu", "authors": "Guannan Hu, Wu Zhang, Hu Ding, Wenhao Zhu", "title": "Gradient Episodic Memory with a Soft Constraint for Continual Learning", "comments": "20 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting in continual learning is a common destructive\nphenomenon in gradient-based neural networks that learn sequential tasks, and\nit is much different from forgetting in humans, who can learn and accumulate\nknowledge throughout their whole lives. Catastrophic forgetting is the fatal\nshortcoming of a large decrease in performance on previous tasks when the model\nis learning a novel task. To alleviate this problem, the model should have the\ncapacity to learn new knowledge and preserve learned knowledge. We propose an\naverage gradient episodic memory (A-GEM) with a soft constraint $\\epsilon \\in\n[0, 1]$, which is a balance factor between learning new knowledge and\npreserving learned knowledge; our method is called gradient episodic memory\nwith a soft constraint $\\epsilon$ ($\\epsilon$-SOFT-GEM). $\\epsilon$-SOFT-GEM\noutperforms A-GEM and several continual learning benchmarks in a single\ntraining epoch; additionally, it has state-of-the-art average accuracy and\nefficiency for computation and memory, like A-GEM, and provides a better\ntrade-off between the stability of preserving learned knowledge and the\nplasticity of learning new knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:06:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hu", "Guannan", ""], ["Zhang", "Wu", ""], ["Ding", "Hu", ""], ["Zhu", "Wenhao", ""]]}, {"id": "2011.07805", "submitter": "Guoqiang Wu", "authors": "Guoqiang Wu, Jun Zhu", "title": "Multi-label classification: do Hamming loss and subset accuracy really\n  conflict with each other?", "comments": "To Appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various evaluation measures have been developed for multi-label\nclassification, including Hamming Loss (HL), Subset Accuracy (SA) and Ranking\nLoss (RL). However, there is a gap between empirical results and the existing\ntheories: 1) an algorithm often empirically performs well on some measure(s)\nwhile poorly on others, while a formal theoretical analysis is lacking; and 2)\nin small label space cases, the algorithms optimizing HL often have comparable\nor even better performance on the SA measure than those optimizing SA directly,\nwhile existing theoretical results show that SA and HL are conflicting\nmeasures. This paper provides an attempt to fill up this gap by analyzing the\nlearning guarantees of the corresponding learning algorithms on both SA and HL\nmeasures. We show that when a learning algorithm optimizes HL with its\nsurrogate loss, it enjoys an error bound for the HL measure independent of $c$\n(the number of labels), while the bound for the SA measure depends on at most\n$O(c)$. On the other hand, when directly optimizing SA with its surrogate loss,\nit has learning guarantees that depend on $O(\\sqrt{c})$ for both HL and SA\nmeasures. This explains the observation that when the label space is not large,\noptimizing HL with its surrogate loss can have promising performance for SA. We\nfurther show that our techniques are applicable to analyze the learning\nguarantees of algorithms on other measures, such as RL. Finally, the\ntheoretical analyses are supported by experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:13:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wu", "Guoqiang", ""], ["Zhu", "Jun", ""]]}, {"id": "2011.07831", "submitter": "Imanol Schlag", "authors": "Imanol Schlag, Tsendsuren Munkhdalai, J\\\"urgen Schmidhuber", "title": "Learning Associative Inference Using Fast Weight Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans can quickly associate stimuli to solve problems in novel contexts. Our\nnovel neural network model learns state representations of facts that can be\ncomposed to perform such associative inference. To this end, we augment the\nLSTM model with an associative memory, dubbed Fast Weight Memory (FWM). Through\ndifferentiable operations at every step of a given input sequence, the LSTM\nupdates and maintains compositional associations stored in the rapidly changing\nFWM weights. Our model is trained end-to-end by gradient descent and yields\nexcellent performance on compositional language reasoning problems,\nmeta-reinforcement-learning for POMDPs, and small-scale word-level language\nmodelling.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 10:01:23 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 17:00:19 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Schlag", "Imanol", ""], ["Munkhdalai", "Tsendsuren", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2011.07835", "submitter": "Bhagyashree Puranik", "authors": "Bhagyashree Puranik, Upamanyu Madhow, Ramtin Pedarsani", "title": "Adversarially Robust Classification based on GLRT", "comments": "Submitted to the International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial attacks that can often\ncause misclassification by introducing small but well designed perturbations.\nIn this paper, we explore, in the setting of classical composite hypothesis\ntesting, a defense strategy based on the generalized likelihood ratio test\n(GLRT), which jointly estimates the class of interest and the adversarial\nperturbation. We evaluate the GLRT approach for the special case of binary\nhypothesis testing in white Gaussian noise under $\\ell_{\\infty}$ norm-bounded\nadversarial perturbations, a setting for which a minimax strategy optimizing\nfor the worst-case attack is known. We show that the GLRT approach yields\nperformance competitive with that of the minimax approach under the worst-case\nattack, and observe that it yields a better robustness-accuracy trade-off under\nweaker attacks, depending on the values of signal components relative to the\nattack budget. We also observe that the GLRT defense generalizes naturally to\nmore complex models for which optimal minimax classifiers are not known.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 10:16:05 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Puranik", "Bhagyashree", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2011.07866", "submitter": "Benjamin Guedj", "authors": "Arthur Leroy and Pierre Latouche and Benjamin Guedj and Servane Gey", "title": "Cluster-Specific Predictions with Multi-Task Gaussian Processes", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A model involving Gaussian processes (GPs) is introduced to simultaneously\nhandle multi-task learning, clustering, and prediction for multiple functional\ndata. This procedure acts as a model-based clustering method for functional\ndata as well as a learning step for subsequent predictions for new tasks. The\nmodel is instantiated as a mixture of multi-task GPs with common mean\nprocesses. A variational EM algorithm is derived for dealing with the\noptimisation of the hyper-parameters along with the hyper-posteriors'\nestimation of latent variables and processes. We establish explicit formulas\nfor integrating the mean processes and the latent clustering variables within a\npredictive distribution, accounting for uncertainty on both aspects. This\ndistribution is defined as a mixture of cluster-specific GP predictions, which\nenhances the performances when dealing with group-structured data. The model\nhandles irregular grid of observations and offers different hypotheses on the\ncovariance structure for sharing additional information across tasks. The\nperformances on both clustering and prediction tasks are assessed through\nvarious simulated scenarios and real datasets. The overall algorithm, called\nMagmaClust, is publicly available as an R package.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:08:59 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 13:45:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Leroy", "Arthur", ""], ["Latouche", "Pierre", ""], ["Guedj", "Benjamin", ""], ["Gey", "Servane", ""]]}, {"id": "2011.07876", "submitter": "Marco Huber", "authors": "Nadia Burkart and Marco F. Huber", "title": "A Survey on the Explainability of Supervised Machine Learning", "comments": "Accepted for publication at the Journal of Artificial Intelligence\n  Research (JAIR)", "journal-ref": "Journal of Artificial Intelligence Research (JAIR), 70:245-317,\n  2021", "doi": "10.1613/jair.1.12228", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions obtained by, e.g., artificial neural networks have a high\naccuracy but humans often perceive the models as black boxes. Insights about\nthe decision making are mostly opaque for humans. Particularly understanding\nthe decision making in highly sensitive areas such as healthcare or fifinance,\nis of paramount importance. The decision-making behind the black boxes requires\nit to be more transparent, accountable, and understandable for humans. This\nsurvey paper provides essential definitions, an overview of the different\nprinciples and methodologies of explainable Supervised Machine Learning (SML).\nWe conduct a state-of-the-art survey that reviews past and recent explainable\nSML approaches and classifies them according to the introduced definitions.\nFinally, we illustrate principles by means of an explanatory case study and\ndiscuss important future directions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:25:39 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Burkart", "Nadia", ""], ["Huber", "Marco F.", ""]]}, {"id": "2011.07881", "submitter": "Sayak Ray Chowdhury", "authors": "Sayak Ray Chowdhury, Rafael Oliveira", "title": "No-Regret Reinforcement Learning with Value Function Approximation: a\n  Kernel Embedding Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the regret minimization problem in reinforcement learning (RL) in\nthe episodic setting. In many real-world RL environments, the state and action\nspaces are continuous or very large. Existing approaches establish regret\nguarantees by either a low-dimensional representation of the stochastic\ntransition model or an approximation of the $Q$-functions. However, the\nunderstanding of function approximation schemes for state-value functions\nlargely remains missing. In this paper, we propose an online model-based RL\nalgorithm, namely the CME-RL, that learns representations of transition\ndistributions as embeddings in a reproducing kernel Hilbert space while\ncarefully balancing the exploitation-exploration tradeoff. We demonstrate the\nefficiency of our algorithm by proving a frequentist (worst-case) regret bound\nthat is of order $\\tilde{O}\\big(H\\gamma_N\\sqrt{N}\\big)$, where $H$ is the\nepisode length, $N$ is the total number of time steps and $\\gamma_N$ is an\ninformation theoretic quantity relating the effective dimension of the\nstate-action feature space. Our method bypasses the need for estimating\ntransition probabilities and applies to any domain on which kernels can be\ndefined. It also brings new insights into the general theory of kernel methods\nfor approximate inference and RL regret minimization.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:40:55 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 03:16:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chowdhury", "Sayak Ray", ""], ["Oliveira", "Rafael", ""]]}, {"id": "2011.07921", "submitter": "Nikolas Ioannou", "authors": "Thomas Schmied, Diego Didona, Andreas D\\\"oring, Thomas Parnell, and\n  Nikolas Ioannou", "title": "Towards a General Framework for ML-based Self-tuning Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) methods have recently emerged as an effective way to\nperform automated parameter tuning of databases. State-of-the-art approaches\ninclude Bayesian optimization (BO) and reinforcement learning (RL). In this\nwork, we describe our experience when applying these methods to a database not\nyet studied in this context: FoundationDB. Firstly, we describe the challenges\nwe faced, such as unknown valid ranges of configuration parameters and\ncombinations of parameter values that result in invalid runs, and how we\nmitigated them. While these issues are typically overlooked, we argue that they\nare a crucial barrier to the adoption of ML self-tuning techniques in\ndatabases, and thus deserve more attention from the research community.\nSecondly, we present experimental results obtained when tuning FoundationDB\nusing ML methods. Unlike prior work in this domain, we also compare with the\nsimplest of baselines: random search. Our results show that, while BO and RL\nmethods can improve the throughput of FoundationDB by up to 38%, random search\nis a highly competitive baseline, finding a configuration that is only 4% worse\nthan the, vastly more complex, ML methods. We conclude that future work in this\narea may want to focus more on randomized, model-free optimization algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:13:10 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 15:57:04 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Schmied", "Thomas", ""], ["Didona", "Diego", ""], ["D\u00f6ring", "Andreas", ""], ["Parnell", "Thomas", ""], ["Ioannou", "Nikolas", ""]]}, {"id": "2011.07923", "submitter": "Masashi Tsubaki", "authors": "Masashi Tsubaki and Teruyasu Mizoguchi", "title": "Quantum deep field: data-driven wave function, electron density\n  generation, and atomization energy prediction and extrapolation with machine\n  learning", "comments": null, "journal-ref": "Physical Review Letters, 2020", "doi": "10.1103/PhysRevLett.125.206401", "report-no": null, "categories": "physics.chem-ph cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been used to successfully predict molecular\nproperties calculated based on the Kohn--Sham density functional theory\n(KS-DFT). Although this prediction is fast and accurate, we believe that a DNN\nmodel for KS-DFT must not only predict the properties but also provide the\nelectron density of a molecule. This letter presents the quantum deep field\n(QDF), which provides the electron density with an unsupervised but end-to-end\nphysics-informed modeling by learning the atomization energy on a large-scale\ndataset. QDF performed well at atomization energy prediction, generated valid\nelectron density, and demonstrated extrapolation. Our QDF implementation is\navailable at https://github.com/masashitsubaki/QuantumDeepField_molecule.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:15:16 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Tsubaki", "Masashi", ""], ["Mizoguchi", "Teruyasu", ""]]}, {"id": "2011.07925", "submitter": "Panagiotis Petsagkourakis", "authors": "Elton Pan, Panagiotis Petsagkourakis, Max Mowbray, Dongda Zhang,\n  Antonio del Rio-Chanona", "title": "Constrained Model-Free Reinforcement Learning for Process Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) is a control approach that can handle nonlinear\nstochastic optimal control problems. However, despite the promise exhibited, RL\nhas yet to see marked translation to industrial practice primarily due to its\ninability to satisfy state constraints. In this work we aim to address this\nchallenge. We propose an 'oracle'-assisted constrained Q-learning algorithm\nthat guarantees the satisfaction of joint chance constraints with a high\nprobability, which is crucial for safety critical tasks. To achieve this,\nconstraint tightening (backoffs) are introduced and adjusted using Broyden's\nmethod, hence making them self-tuned. This results in a general methodology\nthat can be imbued into approximate dynamic programming-based algorithms to\nensure constraint satisfaction with high probability. Finally, we present case\nstudies that analyze the performance of the proposed approach and compare this\nalgorithm with model predictive control (MPC). The favorable performance of\nthis algorithm signifies a step toward the incorporation of RL into real world\noptimization and control of engineering systems, where constraints are\nessential in ensuring safety.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:16:22 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 12:11:26 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Pan", "Elton", ""], ["Petsagkourakis", "Panagiotis", ""], ["Mowbray", "Max", ""], ["Zhang", "Dongda", ""], ["del Rio-Chanona", "Antonio", ""]]}, {"id": "2011.07929", "submitter": "Masashi Tsubaki", "authors": "Masashi Tsubaki and Teruyasu Mizoguchi", "title": "On the equivalence of molecular graph convolution and molecular wave\n  function with poor basis set", "comments": null, "journal-ref": "Neural Information Processing Systems ((NeurIPS 2020)", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we demonstrate that the linear combination of atomic orbitals\n(LCAO), an approximation of quantum physics introduced by Pauling and\nLennard-Jones in the 1920s, corresponds to graph convolutional networks (GCNs)\nfor molecules. However, GCNs involve unnecessary nonlinearity and deep\narchitecture. We also verify that molecular GCNs are based on a poor basis\nfunction set compared with the standard one used in theoretical calculations or\nquantum chemical simulations. From these observations, we describe the quantum\ndeep field (QDF), a machine learning (ML) model based on an underlying quantum\nphysics, in particular the density functional theory (DFT). We believe that the\nQDF model can be easily understood because it can be regarded as a single\nlinear layer GCN. Moreover, it uses two vanilla feedforward neural networks to\nlearn an energy functional and a Hohenberg--Kohn map that have nonlinearities\ninherent in quantum physics and the DFT. For molecular energy prediction tasks,\nwe demonstrated the viability of an ``extrapolation,'' in which we trained a\nQDF model with small molecules, tested it with large molecules, and achieved\nhigh extrapolation performance. This will lead to reliable and practical\napplications for discovering effective materials. The implementation is\navailable at https://github.com/masashitsubaki/QuantumDeepField_molecule.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:20:35 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Tsubaki", "Masashi", ""], ["Mizoguchi", "Teruyasu", ""]]}, {"id": "2011.07931", "submitter": "Wenshuo Guo", "authors": "Karl Krauth, Sarah Dean, Alex Zhao, Wenshuo Guo, Mihaela Curmei,\n  Benjamin Recht, Michael I. Jordan", "title": "Do Offline Metrics Predict Online Performance in Recommender Systems?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems operate in an inherently dynamical setting. Past\nrecommendations influence future behavior, including which data points are\nobserved and how user preferences change. However, experimenting in production\nsystems with real user dynamics is often infeasible, and existing\nsimulation-based approaches have limited scale. As a result, many\nstate-of-the-art algorithms are designed to solve supervised learning problems,\nand progress is judged only by offline metrics. In this work we investigate the\nextent to which offline metrics predict online performance by evaluating eleven\nrecommenders across six controlled simulated environments. We observe that\noffline metrics are correlated with online performance over a range of\nenvironments. However, improvements in offline metrics lead to diminishing\nreturns in online performance. Furthermore, we observe that the ranking of\nrecommenders varies depending on the amount of initial offline data available.\nWe study the impact of adding exploration strategies, and observe that their\neffectiveness, when compared to greedy recommendation, is highly dependent on\nthe recommendation algorithm. We provide the environments and recommenders\ndescribed in this paper as Reclab: an extensible ready-to-use simulation\nframework at https://github.com/berkeley-reclab/RecLab.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 01:41:13 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Krauth", "Karl", ""], ["Dean", "Sarah", ""], ["Zhao", "Alex", ""], ["Guo", "Wenshuo", ""], ["Curmei", "Mihaela", ""], ["Recht", "Benjamin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.07932", "submitter": "Siyeong Lee", "authors": "Kwanghee Choi and Siyeong Lee", "title": "Regularized Mutual Information Neural Estimation", "comments": "18 pages, 15 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the variational lower bound of mutual information (MI), the estimation\nof MI can be understood as an optimization task via stochastic gradient\ndescent. In this work, we start by showing how Mutual Information Neural\nEstimator (MINE) searches for the optimal function $T$ that maximizes the\nDonsker-Varadhan representation. With our synthetic dataset, we directly\nobserve the neural network outputs during the optimization to investigate why\nMINE succeeds or fails: We discover the drifting phenomenon, where the constant\nterm of $T$ is shifting through the optimization process, and analyze the\ninstability caused by the interaction between the $logsumexp$ and the\ninsufficient batch size. Next, through theoretical and experimental evidence,\nwe propose a novel lower bound that effectively regularizes the neural network\nto alleviate the problems of MINE. We also introduce an averaging strategy that\nproduces an unbiased estimate by utilizing multiple batches to mitigate the\nbatch size limitation. Finally, we show that $L^2$ regularization achieves\nsignificant improvements in both discrete and continuous settings.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:29:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Choi", "Kwanghee", ""], ["Lee", "Siyeong", ""]]}, {"id": "2011.07945", "submitter": "Victor Zuanazzi", "authors": "Victor Zuanazzi", "title": "Do not trust the neighbors! Adversarial Metric Learning for\n  Self-Supervised Scene Flow Estimation", "comments": "Master Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Scene flow is the task of estimating 3D motion vectors to individual points\nof a dynamic 3D scene. Motion vectors have shown to be beneficial for\ndownstream tasks such as action classification and collision avoidance.\nHowever, data collected via LiDAR sensors and stereo cameras are computation\nand labor intensive to precisely annotate for scene flow. We address this\nannotation bottleneck on two ends. We propose a 3D scene flow benchmark and a\nnovel self-supervised setup for training flow models. The benchmark consists of\ndatasets designed to study individual aspects of flow estimation in progressive\norder of complexity, from a single object in motion to real-world scenes.\nFurthermore, we introduce Adversarial Metric Learning for self-supervised flow\nestimation. The flow model is fed with sequences of point clouds to perform\nflow estimation. A second model learns a latent metric to distinguish between\nthe points translated by the flow estimations and the target point cloud. This\nlatent metric is learned via a Multi-Scale Triplet loss, which uses\nintermediary feature vectors for the loss calculation. We use our proposed\nbenchmark to draw insights about the performance of the baselines and of\ndifferent models when trained using our setup. We find that our setup is able\nto keep motion coherence and preserve local geometries, which many\nself-supervised baselines fail to grasp. Dealing with occlusions, on the other\nhand, is still an open challenge.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:41:32 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zuanazzi", "Victor", ""]]}, {"id": "2011.07948", "submitter": "Jos\\'e Solomon", "authors": "Jose Solomon and Francois Charette", "title": "A Follow-the-Leader Strategy using Hierarchical Deep Neural Networks\n  with Grouped Convolutions", "comments": "11 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of following-the-leader is implemented using a hierarchical Deep\nNeural Network (DNN) end-to-end driving model to match the direction and speed\nof a target pedestrian. The model uses a classifier DNN to determine if the\npedestrian is within the field of view of the camera sensor. If the pedestrian\nis present, the image stream from the camera is fed to a regression DNN which\nsimultaneously adjusts the autonomous vehicle's steering and throttle to keep\ncadence with the pedestrian. If the pedestrian is not visible, the vehicle uses\na straightforward exploratory search strategy to reacquire the tracking\nobjective. The classifier and regression DNNs incorporate grouped convolutions\nto boost model performance as well as to significantly reduce parameter count\nand compute latency. The models are trained on the Intelligence Processing Unit\n(IPU) to leverage its fine-grain compute capabilities in order to minimize\ntime-to-train. The results indicate very robust tracking behavior on the part\nof the autonomous vehicle in terms of its steering and throttle profiles, while\nrequiring minimal data collection to produce. The throughput in terms of\nprocessing training samples has been boosted by the use of the IPU in\nconjunction with grouped convolutions by a factor ~3.5 for training of the\nclassifier and a factor of ~7 for the regression network. A recording of the\nvehicle tracking a pedestrian has been produced and is available on the web.\nThis is a preprint of an article published in SN Computer Science. The final\nauthenticated version is available online at:\nhttps://doi.org/https://doi.org/10.1007/s42979-021-00572-1.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 16:04:42 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 18:48:05 GMT"}, {"version": "v3", "created": "Sat, 17 Apr 2021 17:21:00 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 18:43:50 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Solomon", "Jose", ""], ["Charette", "Francois", ""]]}, {"id": "2011.07956", "submitter": "Dong-Ho Lee", "authors": "Wangchunshu Zhou, Dong-Ho Lee, Ravi Kiran Selvam, Seyeon Lee, Bill\n  Yuchen Lin, Xiang Ren", "title": "Pre-training Text-to-Text Transformers for Concept-centric Common Sense", "comments": "15 pages, 4 figures. Code and Data: https://github.com/INK-USC/CALM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (PTLM) have achieved impressive results in a\nrange of natural language understanding (NLU) and generation (NLG) tasks.\nHowever, current pre-training objectives such as masked token prediction (for\nBERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not\nexplicitly model the relational commonsense knowledge about everyday concepts,\nwhich is crucial to many downstream tasks that need common sense to understand\nor generate. To augment PTLMs with concept-centric commonsense knowledge, in\nthis paper, we propose both generative and contrastive objectives for learning\ncommon sense from the text, and use them as intermediate self-supervised\nlearning tasks for incrementally pre-training PTLMs (before task-specific\nfine-tuning on downstream datasets). Furthermore, we develop a joint\npre-training framework to unify generative and contrastive objectives so that\nthey can mutually reinforce each other. Extensive experimental results show\nthat our method, concept-aware language model (CALM), can pack more commonsense\nknowledge into the parameters of a pre-trained text-to-text transformer without\nrelying on external knowledge graphs, yielding better performance on both NLU\nand NLG tasks. We show that while only incrementally pre-trained on a\nrelatively small corpus for a few steps, CALM outperforms baseline methods by a\nconsistent margin and even comparable with some larger PTLMs, which suggests\nthat CALM can serve as a general, plug-and-play method for improving the\ncommonsense reasoning ability of a PTLM.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 07:00:37 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 04:53:38 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Lee", "Dong-Ho", ""], ["Selvam", "Ravi Kiran", ""], ["Lee", "Seyeon", ""], ["Lin", "Bill Yuchen", ""], ["Ren", "Xiang", ""]]}, {"id": "2011.07959", "submitter": "Rahul Yedida", "authors": "Rahul Yedida, Saad Mohammad Abrar, Cleber Melo-Filho, Eugene Muratov,\n  Rada Chirkova, Alexander Tropsha", "title": "Text Mining to Identify and Extract Novel Disease Treatments From\n  Unstructured Datasets", "comments": "initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: We aim to learn potential novel cures for diseases from\nunstructured text sources. More specifically, we seek to extract drug-disease\npairs of potential cures to diseases by a simple reasoning over the structure\nof spoken text.\n  Materials and Methods: We use Google Cloud to transcribe podcast episodes of\nan NPR radio show. We then build a pipeline for systematically pre-processing\nthe text to ensure quality input to the core classification model, which feeds\nto a series of post-processing steps for obtaining filtered results. Our\nclassification model itself uses a language model pre-trained on PubMed text.\nThe modular nature of our pipeline allows for ease of future developments in\nthis area by substituting higher quality components at each stage of the\npipeline. As a validation measure, we use ROBOKOP, an engine over a medical\nknowledge graph with only validated pathways, as a ground truth source for\nchecking the existence of the proposed pairs. For the proposed pairs not found\nin ROBOKOP, we provide further verification using Chemotext.\n  Results: We found 30.4% of our proposed pairs in the ROBOKOP database. For\nexample, our model successfully identified that Omeprazole can help treat\nheartburn.We discuss the significance of this result, showing some examples of\nthe proposed pairs.\n  Discussion and Conclusion: The agreement of our results with the existing\nknowledge source indicates a step in the right direction. Given the\nplug-and-play nature of our framework, it is easy to add, remove, or modify\nparts to improve the model as necessary. We discuss the results showing some\nexamples, and note that this is a potentially new line of research that has\nfurther scope to be explored. Although our approach was originally oriented on\nradio podcast transcripts, it is input-agnostic and could be applied to any\nsource of textual data and to any problem of interest.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 19:52:49 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yedida", "Rahul", ""], ["Abrar", "Saad Mohammad", ""], ["Melo-Filho", "Cleber", ""], ["Muratov", "Eugene", ""], ["Chirkova", "Rada", ""], ["Tropsha", "Alexander", ""]]}, {"id": "2011.07960", "submitter": "Yikang Shen", "authors": "Yikang Shen, Shawn Tan, Alessandro Sordoni, Siva Reddy, Aaron\n  Courville", "title": "Explicitly Modeling Syntax in Language Models with Incremental Parsing\n  and a Dynamic Oracle", "comments": "12 pages, 10 figures", "journal-ref": "NAACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Syntax is fundamental to our thinking about language. Failing to capture the\nstructure of input language could lead to generalization problems and\nover-parametrization. In the present work, we propose a new syntax-aware\nlanguage model: Syntactic Ordered Memory (SOM). The model explicitly models the\nstructure with an incremental parser and maintains the conditional probability\nsetting of a standard language model (left-to-right). To train the incremental\nparser and avoid exposure bias, we also propose a novel dynamic oracle, so that\nSOM is more robust to wrong parsing decisions. Experiments show that SOM can\nachieve strong results in language modeling, incremental parsing and syntactic\ngeneralization tests, while using fewer parameters than other models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Oct 2020 17:39:15 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 18:13:41 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Shen", "Yikang", ""], ["Tan", "Shawn", ""], ["Sordoni", "Alessandro", ""], ["Reddy", "Siva", ""], ["Courville", "Aaron", ""]]}, {"id": "2011.07961", "submitter": "Daniel Spokoyny", "authors": "Daniel Spokoyny, Taylor Berg-Kirkpatrick", "title": "An Empirical Investigation of Contextualized Number Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a large scale empirical investigation of contextualized number\nprediction in running text. Specifically, we consider two tasks: (1)masked\nnumber prediction-predicting a missing numerical value within a sentence, and\n(2)numerical anomaly detection-detecting an errorful numeric value within a\nsentence. We experiment with novel combinations of contextual encoders and\noutput distributions over the real number line. Specifically, we introduce a\nsuite of output distribution parameterizations that incorporate latent\nvariables to add expressivity and better fit the natural distribution of\nnumeric values in running text, and combine them with both recurrent and\ntransformer-based encoder architectures. We evaluate these models on two\nnumeric datasets in the financial and scientific domain. Our findings show that\noutput distributions that incorporate discrete latent variables and allow for\nmultiple modes outperform simple flow-based counterparts on all datasets,\nyielding more accurate numerical prediction and anomaly detection. We also show\nthat our models effectively utilize textual con-text and benefit from\ngeneral-purpose unsupervised pretraining.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 23:12:23 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Spokoyny", "Daniel", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2011.07962", "submitter": "William Hui", "authors": "William Hui", "title": "Performance of Transfer Learning Model vs. Traditional Neural Network in\n  Low System Resource Environment", "comments": "5 pages, testing result, feature engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the use of pre-trained model to build neural network based on\ntransfer learning methodology is increasingly popular. These pre-trained models\npresent the benefit of using less computing resources to train model with\nsmaller amount of training data. The rise of state-of-the-art models such as\nBERT, XLNet and GPT boost accuracy and benefit as a base model for transfer\nleanring. However, these models are still too complex and consume many\ncomputing resource to train for transfer learning with low GPU memory. We will\ncompare the performance and cost between lighter transfer learning model and\npurposely built neural network for NLP application of text classification and\nNER model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 08:12:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hui", "William", ""]]}, {"id": "2011.07964", "submitter": "Martin Hole\\v{c}ek", "authors": "Martin Hole\\v{c}ek", "title": "Learning from similarity and information extraction from structured\n  documents", "comments": "17 pages, 9 figures, manuscript for the IJDAR journal special issue\n  for ICDAR conference", "journal-ref": "Hole\\v{c}ek, M. 2021 Learning from similarity and information\n  extraction from structured documents; International Journal on Document\n  Analysis and Recognition (IJDAR) 2021/06/11", "doi": "10.1007/s10032-021-00375-3", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automation of document processing is gaining recent attention due to the\ngreat potential to reduce manual work through improved methods and hardware.\nNeural networks have been successfully applied before - even though they have\nbeen trained only on relatively small datasets with hundreds of documents so\nfar. To successfully explore deep learning techniques and improve the\ninformation extraction results, a dataset with more than twenty-five thousand\ndocuments has been compiled, anonymized and is published as a part of this\nwork. We will expand our previous work where we proved that convolutions, graph\nconvolutions and self-attention can work together and exploit all the\ninformation present in a structured document. Taking the fully trainable method\none step further, we will now design and examine various approaches to using\nsiamese networks, concepts of similarity, one-shot learning and context/memory\nawareness. The aim is to improve micro F1 of per-word classification on the\nhuge real-world document dataset. The results verify the hypothesis that\ntrainable access to a similar (yet still different) page together with its\nalready known target information improves the information extraction.\nFurthermore, the experiments confirm that all proposed architecture parts are\nall required to beat the previous results. The best model improves the previous\nstate-of-the-art results by an 8.25 gain in F1 score. Qualitative analysis is\nprovided to verify that the new model performs better for all target classes.\nAdditionally, multiple structural observations about the causes of the\nunderperformance of some architectures are revealed. All the source codes,\nparameters and implementation details are published together with the dataset\nin the hope to push the research boundaries since all the techniques used in\nthis work are not problem-specific and can be generalized for other tasks and\ncontexts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Oct 2020 21:34:52 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 21:36:56 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Hole\u010dek", "Martin", ""]]}, {"id": "2011.07980", "submitter": "Sergei Grudinin", "authors": "Ilia Igashov (MIPT, NANO-D), Nikita Pavlichenko (MIPT), Sergei\n  Grudinin (NANO-D)", "title": "Spherical convolutions on molecular graphs for protein model quality\n  assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processing information on 3D objects requires methods stable to rigid-body\ntransformations, in particular rotations, of the input data. In image\nprocessing tasks, convolutional neural networks achieve this property using\nrotation-equivariant operations. However, contrary to images, graphs generally\nhave irregular topology. This makes it challenging to define a\nrotation-equivariant convolution operation on these structures. In this work,\nwe propose Spherical Graph Convolutional Network (S-GCN) that processes 3D\nmodels of proteins represented as molecular graphs. In a protein molecule,\nindividual amino acids have common topological elements. This allows us to\nunambiguously associate each amino acid with a local coordinate system and\nconstruct rotation-equivariant spherical filters that operate on angular\ninformation between graph nodes. Within the framework of the protein model\nquality assessment problem, we demonstrate that the proposed spherical\nconvolution method significantly improves the quality of model assessment\ncompared to the standard message-passing approach. It is also comparable to\nstate-of-the-art methods, as we demonstrate on Critical Assessment of Structure\nPrediction (CASP) benchmarks. The proposed technique operates only on geometric\nfeatures of protein 3D models. This makes it universal and applicable to any\nother geometric-learning task where the graph structure allows constructing\nlocal coordinate systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:22:36 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 14:06:20 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Igashov", "Ilia", "", "MIPT, NANO-D"], ["Pavlichenko", "Nikita", "", "MIPT"], ["Grudinin", "Sergei", "", "NANO-D"]]}, {"id": "2011.07986", "submitter": "Michael Pradel", "authors": "Michael Pradel and Satish Chandra", "title": "Neural Software Analysis", "comments": null, "journal-ref": "Communications of the ACM, 2021", "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many software development problems can be addressed by program analysis\ntools, which traditionally are based on precise, logical reasoning and\nheuristics to ensure that the tools are practical. Recent work has shown\ntremendous success through an alternative way of creating developer tools,\nwhich we call neural software analysis. The key idea is to train a neural\nmachine learning model on numerous code examples, which, once trained, makes\npredictions about previously unseen code. In contrast to traditional program\nanalysis, neural software analysis naturally handles fuzzy information, such as\ncoding conventions and natural language embedded in code, without relying on\nmanually encoded heuristics. This article gives an overview of neural software\nanalysis, discusses when to (not) use it, and presents three example analyses.\nThe analyses address challenging software development problems: bug detection,\ntype prediction, and code completion. The resulting tools complement and\noutperform traditional program analyses, and are used in industrial practice.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:32:09 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 10:04:41 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Pradel", "Michael", ""], ["Chandra", "Satish", ""]]}, {"id": "2011.07989", "submitter": "Alexander Galozy", "authors": "Alexander Galozy, Slawomir Nowaczyk, Mattias Ohlsson", "title": "Corrupted Contextual Bandits with Action Order Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the novel contextual bandit problem with corrupted\ncontext, which we call the contextual bandit problem with corrupted context and\naction correlation, where actions exhibit a relationship structure that can be\nexploited to guide the exploration of viable next decisions. Our setting is\nprimarily motivated by adaptive mobile health interventions and related\napplications, where users might transitions through different stages requiring\nmore targeted action selection approaches. In such settings, keeping user\nengagement is paramount for the success of interventions and therefore it is\nvital to provide relevant recommendations in a timely manner. The context\nprovided by users might not always be informative at every decision point and\nstandard contextual approaches to action selection will incur high regret. We\npropose a meta-algorithm using a referee that dynamically combines the policies\nof a contextual bandit and multi-armed bandit, similar to previous work, as\nwells as a simple correlation mechanism that captures action to action\ntransition probabilities allowing for more efficient exploration of\ntime-correlated actions. We evaluate empirically the performance of said\nalgorithm on a simulation where the sequence of best actions is determined by a\nhidden state that evolves in a Markovian manner. We show that the proposed\nmeta-algorithm improves upon regret in situations where the performance of both\npolicies varies such that one is strictly superior to the other for a given\ntime period. To demonstrate that our setting has relevant practical\napplicability, we evaluate our method on several real world data sets, clearly\nshowing better empirical performance compared to a set of simple algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:35:37 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Galozy", "Alexander", ""], ["Nowaczyk", "Slawomir", ""], ["Ohlsson", "Mattias", ""]]}, {"id": "2011.07995", "submitter": "Mateusz Buda", "authors": "Mateusz Buda, Ashirbani Saha, Ruth Walsh, Sujata Ghate, Nianyi Li,\n  Albert \\'Swi\\k{e}cicki, Joseph Y. Lo, Maciej A. Mazurowski", "title": "Detection of masses and architectural distortions in digital breast\n  tomosynthesis: a publicly available dataset of 5,060 patients and a deep\n  learning model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer screening is one of the most common radiological tasks with\nover 39 million exams performed each year. While breast cancer screening has\nbeen one of the most studied medical imaging applications of artificial\nintelligence, the development and evaluation of the algorithms are hindered due\nto the lack of well-annotated large-scale publicly available datasets. This is\nparticularly an issue for digital breast tomosynthesis (DBT) which is a\nrelatively new breast cancer screening modality. We have curated and made\npublicly available a large-scale dataset of digital breast tomosynthesis\nimages. It contains 22,032 reconstructed DBT volumes belonging to 5,610 studies\nfrom 5,060 patients. This included four groups: (1) 5,129 normal studies, (2)\n280 studies where additional imaging was needed but no biopsy was performed,\n(3) 112 benign biopsied studies, and (4) 89 studies with cancer. Our dataset\nincluded masses and architectural distortions which were annotated by two\nexperienced radiologists. Additionally, we developed a single-phase deep\nlearning detection model and tested it using our dataset to serve as a baseline\nfor future research. Our model reached a sensitivity of 65% at 2 false\npositives per breast. Our large, diverse, and highly-curated dataset will\nfacilitate development and evaluation of AI algorithms for breast cancer\nscreening through providing data for training as well as common set of cases\nfor model validation. The performance of the model developed in our study shows\nthat the task remains challenging and will serve as a baseline for future model\ndevelopment.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 18:33:31 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 12:25:42 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 21:28:21 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Buda", "Mateusz", ""], ["Saha", "Ashirbani", ""], ["Walsh", "Ruth", ""], ["Ghate", "Sujata", ""], ["Li", "Nianyi", ""], ["\u015awi\u0119cicki", "Albert", ""], ["Lo", "Joseph Y.", ""], ["Mazurowski", "Maciej A.", ""]]}, {"id": "2011.08001", "submitter": "Omid Haji Maghsoudi", "authors": "Omid Haji Maghsoudi, Aimilia Gastounioti, Christopher Scott, Lauren\n  Pantalone, Fang-Fang Wu, Eric A. Cohen, Stacey Winham, Emily F. Conant,\n  Celine Vachon, Despina Kontos", "title": "Deep-LIBRA: Artificial intelligence method for robust quantification of\n  breast density with independent validation in breast cancer risk assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Breast density is an important risk factor for breast cancer that also\naffects the specificity and sensitivity of screening mammography. Current\nfederal legislation mandates reporting of breast density for all women\nundergoing breast screening. Clinically, breast density is assessed visually\nusing the American College of Radiology Breast Imaging Reporting And Data\nSystem (BI-RADS) scale. Here, we introduce an artificial intelligence (AI)\nmethod to estimate breast percentage density (PD) from digital mammograms. Our\nmethod leverages deep learning (DL) using two convolutional neural network\narchitectures to accurately segment the breast area. A machine-learning\nalgorithm combining superpixel generation, texture feature analysis, and\nsupport vector machine is then applied to differentiate dense from non-dense\ntissue regions, from which PD is estimated. Our method has been trained and\nvalidated on a multi-ethnic, multi-institutional dataset of 15,661 images\n(4,437 women), and then tested on an independent dataset of 6,368 digital\nmammograms (1,702 women; cases=414) for both PD estimation and discrimination\nof breast cancer. On the independent dataset, PD estimates from Deep-LIBRA and\nan expert reader were strongly correlated (Spearman correlation coefficient =\n0.90). Moreover, Deep-LIBRA yielded a higher breast cancer discrimination\nperformance (area under the ROC curve, AUC = 0.611 [95% confidence interval\n(CI): 0.583, 0.639]) compared to four other widely-used research and commercial\nPD assessment methods (AUCs = 0.528 to 0.588). Our results suggest a strong\nagreement of PD estimates between Deep-LIBRA and gold-standard assessment by an\nexpert reader, as well as improved performance in breast cancer risk assessment\nover state-of-the-art open-source and commercial methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:21:17 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 20:52:48 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Maghsoudi", "Omid Haji", ""], ["Gastounioti", "Aimilia", ""], ["Scott", "Christopher", ""], ["Pantalone", "Lauren", ""], ["Wu", "Fang-Fang", ""], ["Cohen", "Eric A.", ""], ["Winham", "Stacey", ""], ["Conant", "Emily F.", ""], ["Vachon", "Celine", ""], ["Kontos", "Despina", ""]]}, {"id": "2011.08004", "submitter": "Gonzague Henri", "authors": "Gonzague Henri, Tanguy Levent, Avishai Halev, Reda Alami, Philippe\n  Cordier", "title": "pymgrid: An Open-Source Python Microgrid Simulator for Applied\n  Artificial Intelligence Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microgrids, self contained electrical grids that are capable of disconnecting\nfrom the main grid, hold potential in both tackling climate change mitigation\nvia reducing CO2 emissions and adaptation by increasing infrastructure\nresiliency. Due to their distributed nature, microgrids are often\nidiosyncratic; as a result, control of these systems is nontrivial. While\nmicrogrid simulators exist, many are limited in scope and in the variety of\nmicrogrids they can simulate. We propose pymgrid, an open-source Python package\nto generate and simulate a large number of microgrids, and the first\nopen-source tool that can generate more than 600 different microgrids. pymgrid\nabstracts most of the domain expertise, allowing users to focus on control\nalgorithms. In particular, pymgrid is built to be a reinforcement learning (RL)\nplatform, and includes the ability to model microgrids as Markov decision\nprocesses. pymgrid also introduces two pre-computed list of microgrids,\nintended to allow for research reproducibility in the microgrid setting.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 23:05:12 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Henri", "Gonzague", ""], ["Levent", "Tanguy", ""], ["Halev", "Avishai", ""], ["Alami", "Reda", ""], ["Cordier", "Philippe", ""]]}, {"id": "2011.08009", "submitter": "Sek Chai", "authors": "Thu Dinh, Andrey Melnikov, Vasilios Daskalopoulos, Sek Chai", "title": "Subtensor Quantization for Mobilenets", "comments": "Embedded Vision Workshop, 16th European Conference on Computer Vision\n  (ECCV), Aug 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization for deep neural networks (DNN) have enabled developers to deploy\nmodels with less memory and more efficient low-power inference. However, not\nall DNN designs are friendly to quantization. For example, the popular\nMobilenet architecture has been tuned to reduce parameter size and\ncomputational latency with separable depth-wise convolutions, but not all\nquantization algorithms work well and the accuracy can suffer against its float\npoint versions. In this paper, we analyzed several root causes of quantization\nloss and proposed alternatives that do not rely on per-channel or\ntraining-aware approaches. We evaluate the image classification task on\nImageNet dataset, and our post-training quantized 8-bit inference top-1\naccuracy in within 0.7% of the floating point version.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 15:41:47 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Dinh", "Thu", ""], ["Melnikov", "Andrey", ""], ["Daskalopoulos", "Vasilios", ""], ["Chai", "Sek", ""]]}, {"id": "2011.08010", "submitter": "Veda Sunkara", "authors": "Veda Sunkara, Matthew Purri, Bertrand Le Saux, Jennifer Adams", "title": "Street to Cloud: Improving Flood Maps With Crowdsourcing and Semantic\n  Segmentation", "comments": "5 pages, 2 figures, Tackling Climate Change with Machine Learning\n  workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the mounting destruction caused by floods in climate-vulnerable\nregions, we propose Street to Cloud, a machine learning pipeline for\nincorporating crowdsourced ground truth data into the segmentation of satellite\nimagery of floods. We propose this approach as a solution to the\nlabor-intensive task of generating high-quality, hand-labeled training data,\nand demonstrate successes and failures of different plausible crowdsourcing\napproaches in our model. Street to Cloud leverages community reporting and\nmachine learning to generate novel, near-real time insights into the extent of\nfloods to be used for emergency response.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:36:58 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Sunkara", "Veda", ""], ["Purri", "Matthew", ""], ["Saux", "Bertrand Le", ""], ["Adams", "Jennifer", ""]]}, {"id": "2011.08011", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab, Jaydip Sen and Subhasis Dasgupta", "title": "Robust Analysis of Stock Price Time Series Using CNN and LSTM-Based Deep\n  Learning Models", "comments": "The paper is the accepted version of our work in the 4th IEEE\n  International Conference on Electronics, Communication, and Aerospace\n  Technology (ICECA'20), November 5 - 7, 2020, Coimbatore, INDIA, The paper\n  consists of 10 pages. It contains 12 figures and 8 tables", "journal-ref": null, "doi": "10.1109/ICECA49313.2020.9297652", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of stock price and stock price movement patterns has always been a\ncritical area of research. While the well-known efficient market hypothesis\nrules out any possibility of accurate prediction of stock prices, there are\nformal propositions in the literature demonstrating accurate modeling of the\npredictive systems that can enable us to predict stock prices with a very high\nlevel of accuracy. In this paper, we present a suite of deep learning-based\nregression models that yields a very high level of accuracy in stock price\nprediction. To build our predictive models, we use the historical stock price\ndata of a well-known company listed in the National Stock Exchange (NSE) of\nIndia during the period December 31, 2012 to January 9, 2015. The stock prices\nare recorded at five minutes intervals of time during each working day in a\nweek. Using these extremely granular stock price data, we build four\nconvolutional neural network (CNN) and five long- and short-term memory\n(LSTM)-based deep learning models for accurate forecasting of the future stock\nprices. We provide detailed results on the forecasting accuracies of all our\nproposed models based on their execution time and their root mean square error\n(RMSE) values.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 16:07:10 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 08:04:43 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""], ["Dasgupta", "Subhasis", ""]]}, {"id": "2011.08018", "submitter": "Rosana El Jurdi", "authors": "Rosana El Jurdi, Caroline Petitjean, Paul Honeine, Veronika\n  Cheplygina, Fahed Abdallah", "title": "High-level Prior-based Loss Functions for Medical Image Segmentation: A\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, deep convolutional neural networks (CNNs) have demonstrated state of\nthe art performance for supervised medical image segmentation, across various\nimaging modalities and tasks. Despite early success, segmentation networks may\nstill generate anatomically aberrant segmentations, with holes or inaccuracies\nnear the object boundaries. To mitigate this effect, recent research works have\nfocused on incorporating spatial information or prior knowledge to enforce\nanatomically plausible segmentation. If the integration of prior knowledge in\nimage segmentation is not a new topic in classical optimization approaches, it\nis today an increasing trend in CNN based image segmentation, as shown by the\ngrowing literature on the topic. In this survey, we focus on high level prior,\nembedded at the loss function level. We categorize the articles according to\nthe nature of the prior: the object shape, size, topology, and the\ninter-regions constraints. We highlight strengths and limitations of current\napproaches, discuss the challenge related to the design and the integration of\nprior-based losses, and the optimization strategies, and draw future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:12:05 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 22:16:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jurdi", "Rosana El", ""], ["Petitjean", "Caroline", ""], ["Honeine", "Paul", ""], ["Cheplygina", "Veronika", ""], ["Abdallah", "Fahed", ""]]}, {"id": "2011.08021", "submitter": "Edward Raff", "authors": "Nisha Pillai, Edward Raff, Francis Ferraro, Cynthia Matuszek", "title": "Sampling Approach Matters: Active Learning for Robotic Language\n  Acquisition", "comments": "To appear in IEEE Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordering the selection of training data using active learning can lead to\nimprovements in learning efficiently from smaller corpora. We present an\nexploration of active learning approaches applied to three grounded language\nproblems of varying complexity in order to analyze what methods are suitable\nfor improving data efficiency in learning. We present a method for analyzing\nthe complexity of data in this joint problem space, and report on how\ncharacteristics of the underlying task, along with design decisions such as\nfeature selection and classification model, drive the results. We observe that\nrepresentativeness, along with diversity, is crucial in selecting data samples.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:18:10 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Pillai", "Nisha", ""], ["Raff", "Edward", ""], ["Ferraro", "Francis", ""], ["Matuszek", "Cynthia", ""]]}, {"id": "2011.08026", "submitter": "Tristan Aumentado-Armstrong", "authors": "Tristan Aumentado-Armstrong, Alex Levinshtein, Stavros Tsogkas,\n  Konstantinos G. Derpanis, and Allan D. Jepson", "title": "Cycle-Consistent Generative Rendering for 2D-3D Modality Translation", "comments": "3DV 2020 (oral). Project page: https://ttaa9.github.io/genren/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For humans, visual understanding is inherently generative: given a 3D shape,\nwe can postulate how it would look in the world; given a 2D image, we can infer\nthe 3D structure that likely gave rise to it. We can thus translate between the\n2D visual and 3D structural modalities of a given object. In the context of\ncomputer vision, this corresponds to a learnable module that serves two\npurposes: (i) generate a realistic rendering of a 3D object (shape-to-image\ntranslation) and (ii) infer a realistic 3D shape from an image (image-to-shape\ntranslation). In this paper, we learn such a module while being conscious of\nthe difficulties in obtaining large paired 2D-3D datasets. By leveraging\ngenerative domain translation methods, we are able to define a learning\nalgorithm that requires only weak supervision, with unpaired data. The\nresulting model is not only able to perform 3D shape, pose, and texture\ninference from 2D images, but can also generate novel textured 3D shapes and\nrenders, similar to a graphics pipeline. More specifically, our method (i)\ninfers an explicit 3D mesh representation, (ii) utilizes example shapes to\nregularize inference, (iii) requires only an image mask (no keypoints or camera\nextrinsics), and (iv) has generative capabilities. While prior work explores\nsubsets of these properties, their combination is novel. We demonstrate the\nutility of our learned representation, as well as its performance on image\ngeneration and unpaired 3D shape inference tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:23:03 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Aumentado-Armstrong", "Tristan", ""], ["Levinshtein", "Alex", ""], ["Tsogkas", "Stavros", ""], ["Derpanis", "Konstantinos G.", ""], ["Jepson", "Allan D.", ""]]}, {"id": "2011.08035", "submitter": "Venelin Kovatchev", "authors": "Venelin Kovatchev, Phillip Smith, Mark Lee, Imogen Grumley Traynor,\n  Irene Luque Aguilera and Rory T. Devine", "title": "\"What is on your mind?\" Automated Scoring of Mindreading in Childhood\n  and Early Adolescence", "comments": "Accepted in COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present the first work on the automated scoring of\nmindreading ability in middle childhood and early adolescence. We create\nMIND-CA, a new corpus of 11,311 question-answer pairs in English from 1,066\nchildren aged 7 to 14. We perform machine learning experiments and carry out\nextensive quantitative and qualitative evaluation. We obtain promising results,\ndemonstrating the applicability of state-of-the-art NLP solutions to a new\ndomain and task.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:41:45 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Kovatchev", "Venelin", ""], ["Smith", "Phillip", ""], ["Lee", "Mark", ""], ["Traynor", "Imogen Grumley", ""], ["Aguilera", "Irene Luque", ""], ["Devine", "Rory T.", ""]]}, {"id": "2011.08036", "submitter": "Alexey Bochkovskiy", "authors": "Chien-Yao Wang, Alexey Bochkovskiy, Hong-Yuan Mark Liao", "title": "Scaled-YOLOv4: Scaling Cross Stage Partial Network", "comments": "Added references. Corrected typos. The new results are slightly\n  better", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the YOLOv4 object detection neural network based on the CSP\napproach, scales both up and down and is applicable to small and large networks\nwhile maintaining optimal speed and accuracy. We propose a network scaling\napproach that modifies not only the depth, width, resolution, but also\nstructure of the network. YOLOv4-large model achieves state-of-the-art results:\n55.5% AP (73.4% AP50) for the MS COCO dataset at a speed of ~16 FPS on Tesla\nV100, while with the test time augmentation, YOLOv4-large achieves 56.0% AP\n(73.3 AP50). To the best of our knowledge, this is currently the highest\naccuracy on the COCO dataset among any published work. The YOLOv4-tiny model\nachieves 22.0% AP (42.0% AP50) at a speed of 443 FPS on RTX 2080Ti, while by\nusing TensorRT, batch size = 4 and FP16-precision the YOLOv4-tiny achieves 1774\nFPS.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:42:00 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 01:32:18 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Chien-Yao", ""], ["Bochkovskiy", "Alexey", ""], ["Liao", "Hong-Yuan Mark", ""]]}, {"id": "2011.08042", "submitter": "Nicola Landro", "authors": "Nicola Landro, Ignazio Gallo, Riccardo La Grassa", "title": "Mixing ADAM and SGD: a Combined Optimization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimization methods (optimizers) get special attention for the efficient\ntraining of neural networks in the field of deep learning. In literature there\nare many papers that compare neural models trained with the use of different\noptimizers. Each paper demonstrates that for a particular problem an optimizer\nis better than the others but as the problem changes this type of result is no\nlonger valid and we have to start from scratch. In our paper we propose to use\nthe combination of two very different optimizers but when used simultaneously\nthey can overcome the performances of the single optimizers in very different\nproblems. We propose a new optimizer called MAS (Mixing ADAM and SGD) that\nintegrates SGD and ADAM simultaneously by weighing the contributions of both\nthrough the assignment of constant weights. Rather than trying to improve SGD\nor ADAM we exploit both at the same time by taking the best of both. We have\nconducted several experiments on images and text document classification, using\nvarious CNNs, and we demonstrated by experiments that the proposed MAS\noptimizer produces better performance than the single SGD or ADAM optimizers.\nThe source code and all the results of the experiments are available online at\nthe following link https://gitlab.com/nicolalandro/multi\\_optimizer\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:48:38 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Landro", "Nicola", ""], ["Gallo", "Ignazio", ""], ["La Grassa", "Riccardo", ""]]}, {"id": "2011.08046", "submitter": "Qiuyu Zhu", "authors": "Joel Q. L. Chang, Qiuyu Zhu and Vincent Y. F. Tan", "title": "Risk-Constrained Thompson Sampling for CVaR Bandits", "comments": "7 pages main paper with 11 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem\nthat exemplifies the exploration-exploitation tradeoff. Standard formulations\nexclude risk in decision making. Risk notably complicates the basic\nreward-maximising objective, in part because there is no universally agreed\ndefinition of it. In this paper, we consider a popular risk measure in\nquantitative finance known as the Conditional Value at Risk (CVaR). We explore\nthe performance of a Thompson Sampling-based algorithm CVaR-TS under this risk\nmeasure. We provide comprehensive comparisons between our regret bounds with\nstate-of-the-art L/UCB-based algorithms in comparable settings and demonstrate\ntheir clear improvement in performance. We also include numerical simulations\nto empirically verify that CVaR-TS outperforms other L/UCB-based algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:53:22 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 01:59:02 GMT"}, {"version": "v3", "created": "Sun, 20 Dec 2020 14:54:21 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 05:43:04 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Chang", "Joel Q. L.", ""], ["Zhu", "Qiuyu", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2011.08055", "submitter": "Christopher D. Hsu", "authors": "Christopher D. Hsu, Heejin Jeong, George J. Pappas, and Pratik\n  Chaudhari", "title": "Scalable Reinforcement Learning Policies for Multi-Agent Control", "comments": "8 pages, 10 figures, contributed paper at IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a Multi-Agent Reinforcement Learning (MARL) method to learn\nscalable control policies for target tracking. Our method can handle an\narbitrary number of pursuers and targets; we show results for tasks consisting\nup to 1000 pursuers tracking 1000 targets. We use a decentralized,\npartially-observable Markov Decision Process framework to model pursuers as\nagents receiving partial observations (range and bearing) about targets which\nmove using fixed, unknown policies. An attention mechanism is used to\nparameterize the value function of the agents; this mechanism allows us to\nhandle an arbitrary number of targets. Entropy-regularized off-policy RL\nmethods are used to train a stochastic policy, and we discuss how it enables a\nhedging behavior between pursuers that leads to a weak form of cooperation in\nspite of completely decentralized control execution. We further develop a\nmasking heuristic that allows training on smaller problems with few\npursuers-targets and execution on much larger problems. Thorough simulation\nexperiments, ablation studies, and comparisons to state of the art algorithms\nare performed to study the scalability of the approach and robustness of\nperformance to varying numbers of agents and targets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 16:11:12 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 20:19:39 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Hsu", "Christopher D.", ""], ["Jeong", "Heejin", ""], ["Pappas", "George J.", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2011.08065", "submitter": "Debesh Jha", "authors": "Debesh Jha, Sharib Ali, Krister Emanuelsen, Steven A. Hicks,\n  VajiraThambawita, Enrique Garcia-Ceja, Michael A. Riegler, Thomas de Lange,\n  Peter T. Schmidt, H{\\aa}vard D. Johansen, Dag Johansen, and P{\\aa}l Halvorsen", "title": "Kvasir-Instrument: Diagnostic and therapeutic tool segmentation dataset\n  in gastrointestinal endoscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gastrointestinal (GI) pathologies are periodically screened, biopsied, and\nresected using surgical tools. Usually the procedures and the treated or\nresected areas are not specifically tracked or analysed during or after\ncolonoscopies. Information regarding disease borders, development and amount\nand size of the resected area get lost. This can lead to poor follow-up and\nbothersome reassessment difficulties post-treatment. To improve the current\nstandard and also to foster more research on the topic we have released the\n``Kvasir-Instrument'' dataset which consists of $590$ annotated frames\ncontaining GI procedure tools such as snares, balloons and biopsy forceps, etc.\nBeside of the images, the dataset includes ground truth masks and bounding\nboxes and has been verified by two expert GI endoscopists. Additionally, we\nprovide a baseline for the segmentation of the GI tools to promote research and\nalgorithm development. We obtained a dice coefficient score of 0.9158 and a\nJaccard index of 0.8578 using a classical U-Net architecture. A similar dice\ncoefficient score was observed for DoubleUNet. The qualitative results showed\nthat the model did not work for the images with specularity and the frames with\nmultiple instruments, while the best result for both methods was observed on\nall other types of images. Both, qualitative and quantitative results show that\nthe model performs reasonably good, but there is a large potential for further\nimprovements. Benchmarking using the dataset provides an opportunity for\nresearchers to contribute to the field of automatic endoscopic diagnostic and\ntherapeutic tool segmentation for GI endoscopy.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 18:14:36 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jha", "Debesh", ""], ["Ali", "Sharib", ""], ["Emanuelsen", "Krister", ""], ["Hicks", "Steven A.", ""], ["VajiraThambawita", "", ""], ["Garcia-Ceja", "Enrique", ""], ["Riegler", "Michael A.", ""], ["de Lange", "Thomas", ""], ["Schmidt", "Peter T.", ""], ["Johansen", "H\u00e5vard D.", ""], ["Johansen", "Dag", ""], ["Halvorsen", "P\u00e5l", ""]]}, {"id": "2011.08068", "submitter": "Kasyap Chakravadhanula", "authors": "Kasyap Chakravadhanula", "title": "Smartphone-Based Test and Predictive Models for Rapid, Non-Invasive, and\n  Point-of-Care Monitoring of Ocular and Cardiovascular Complications Related\n  to Diabetes", "comments": "25 Pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Among the most impactful diabetic complications are diabetic retinopathy, the\nleading cause of blindness among working class adults, and cardiovascular\ndisease, the leading cause of death worldwide. This study describes the\ndevelopment of improved machine learning based screening of these conditions.\nFirst, a random forest model was developed by retrospectively analyzing the\ninfluence of various risk factors (obtained quickly and non-invasively) on\ncardiovascular risk. Next, a deep-learning model was developed for prediction\nof diabetic retinopathy from retinal fundus images by a modified and re-trained\nInceptionV3 image classification model. The input was simplified by\nautomatically segmenting the blood vessels in the retinal image. The technique\nof transfer learning enables the model to capitalize on existing infrastructure\non the target device, meaning more versatile deployment, especially helpful in\nlow-resource settings. The models were integrated into a smartphone-based\ndevice, combined with an inexpensive 3D-printed retinal imaging attachment.\nAccuracy scores, as well as the receiver operating characteristic curve, the\nlearning curve, and other gauges, were promising. This test is much cheaper and\nfaster, enabling continuous monitoring for two damaging complications of\ndiabetes. It has the potential to replace the manual methods of diagnosing both\ndiabetic retinopathy and cardiovascular risk, which are time consuming and\ncostly processes only done by medical professionals away from the point of\ncare, and to prevent irreversible blindness and heart-related complications\nthrough faster, cheaper, and safer monitoring of diabetic complications. As\nwell, tracking of cardiovascular and ocular complications of diabetes can\nenable improved detection of other diabetic complications, leading to earlier\nand more efficient treatment on a global scale.\n", "versions": [{"version": "v1", "created": "Sun, 25 Oct 2020 00:57:35 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chakravadhanula", "Kasyap", ""]]}, {"id": "2011.08071", "submitter": "Ha Thanh Nguyen", "authors": "Ha-Thanh Nguyen, Hai-Yen Thi Vuong, Phuong Minh Nguyen, Binh Tran\n  Dang, Quan Minh Bui, Sinh Trong Vu, Chau Minh Nguyen, Vu Tran, Ken Satoh,\n  Minh Le Nguyen", "title": "JNLP Team: Deep Learning for Legal Processing in COLIEE 2020", "comments": "Also be published in JURISIN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose deep learning based methods for automatic systems of legal\nretrieval and legal question-answering in COLIEE 2020. These systems are all\ncharacterized by being pre-trained on large amounts of data before being\nfinetuned for the specified tasks. This approach helps to overcome the data\nscarcity and achieve good performance, thus can be useful for tackling related\nproblems in information retrieval, and decision support in the legal domain.\nBesides, the approach can be explored to deal with other domain specific\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:14:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Nguyen", "Ha-Thanh", ""], ["Vuong", "Hai-Yen Thi", ""], ["Nguyen", "Phuong Minh", ""], ["Dang", "Binh Tran", ""], ["Bui", "Quan Minh", ""], ["Vu", "Sinh Trong", ""], ["Nguyen", "Chau Minh", ""], ["Tran", "Vu", ""], ["Satoh", "Ken", ""], ["Nguyen", "Minh Le", ""]]}, {"id": "2011.08072", "submitter": "Swati Padhee", "authors": "Amanuel Alambo, Cori Lohstroh, Erik Madaus, Swati Padhee, Brandy\n  Foster, Tanvi Banerjee, Krishnaprasad Thirunarayan, Michael Raymer", "title": "Topic-Centric Unsupervised Multi-Document Summarization of Scientific\n  and News Articles", "comments": "6 pages, 6 Figures, 8 Tables. Accepted at IEEE Big Data 2020\n  (https://bigdataieee.org/BigData2020/AcceptedPapers.html)", "journal-ref": null, "doi": null, "report-no": "BigD420", "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in natural language processing have enabled automation of a\nwide range of tasks, including machine translation, named entity recognition,\nand sentiment analysis. Automated summarization of documents, or groups of\ndocuments, however, has remained elusive, with many efforts limited to\nextraction of keywords, key phrases, or key sentences. Accurate abstractive\nsummarization has yet to be achieved due to the inherent difficulty of the\nproblem, and limited availability of training data. In this paper, we propose a\ntopic-centric unsupervised multi-document summarization framework to generate\nextractive and abstractive summaries for groups of scientific articles across\n20 Fields of Study (FoS) in Microsoft Academic Graph (MAG) and news articles\nfrom DUC-2004 Task 2. The proposed algorithm generates an abstractive summary\nby developing salient language unit selection and text generation techniques.\nOur approach matches the state-of-the-art when evaluated on automated\nextractive evaluation metrics and performs better for abstractive summarization\non five human evaluation metrics (entailment, coherence, conciseness,\nreadability, and grammar). We achieve a kappa score of 0.68 between two\nco-author linguists who evaluated our results. We plan to publicly share\nMAG-20, a human-validated gold standard dataset of topic-clustered research\narticles and their summaries to promote research in abstractive summarization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:04:21 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Alambo", "Amanuel", ""], ["Lohstroh", "Cori", ""], ["Madaus", "Erik", ""], ["Padhee", "Swati", ""], ["Foster", "Brandy", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Raymer", "Michael", ""]]}, {"id": "2011.08073", "submitter": "Alexandra Luccioni", "authors": "Alexandra Luccioni, Emily Baylor, Nicolas Duchene", "title": "Analyzing Sustainability Reports Using Natural Language Processing", "comments": null, "journal-ref": "Tackling Climate Change with Machine Learning workshop at NeurIPS\n  2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate change is a far-reaching, global phenomenon that will impact many\naspects of our society, including the global stock market\n\\cite{dietz2016climate}. In recent years, companies have increasingly been\naiming to both mitigate their environmental impact and adapt to the changing\nclimate context. This is reported via increasingly exhaustive reports, which\ncover many types of climate risks and exposures under the umbrella of\nEnvironmental, Social, and Governance (ESG). However, given this abundance of\ndata, sustainability analysts are obliged to comb through hundreds of pages of\nreports in order to find relevant information. We leveraged recent progress in\nNatural Language Processing (NLP) to create a custom model, ClimateQA, which\nallows the analysis of financial reports in order to identify climate-relevant\nsections based on a question answering approach. We present this tool and the\nmethodology that we used to develop it in the present article.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 21:22:42 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 17:20:09 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Luccioni", "Alexandra", ""], ["Baylor", "Emily", ""], ["Duchene", "Nicolas", ""]]}, {"id": "2011.08091", "submitter": "Fabrizio Sebastiani", "authors": "Alejandro Moreo and Fabrizio Sebastiani", "title": "Tweet Sentiment Quantification: An Experimental Re-Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment quantification is the task of estimating the relative frequency (or\n\"prevalence\") of sentiment-related classes (such as Positive, Neutral,\nNegative) in a sample of unlabelled texts; this is especially important when\nthese texts are tweets, since most sentiment classification endeavours carried\nout on Twitter data actually have quantification (and not the classification of\nindividual tweets) as their ultimate goal. It is well-known that solving\nquantification via \"classify and count\" (i.e., by classifying all unlabelled\nitems via a standard classifier and counting the items that have been assigned\nto a given class) is suboptimal in terms of accuracy, and that more accurate\nquantification methods exist. In 2016, Gao and Sebastiani carried out a\nsystematic comparison of quantification methods on the task of tweet sentiment\nquantification. In hindsight, we observe that the experimental protocol\nfollowed in that work is flawed, and that its results are thus unreliable. We\nnow re-evaluate those quantification methods on the very same datasets, this\ntime following a now consolidated and much more robust experimental protocol,\nthat involves 5775 as many experiments as run in the original study. Our\nexperimentation yields results dramatically different from those obtained by\nGao and Sebastiani, and thus provide a different, much more solid understanding\nof the relative strengths and weaknesses of different sentiment quantification\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 21:41:34 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 10:49:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Moreo", "Alejandro", ""], ["Sebastiani", "Fabrizio", ""]]}, {"id": "2011.08096", "submitter": "Sharut Gupta", "authors": "Sharut Gupta, Praveer Singh, Ken Chang, Mehak Aggarwal, Nishanth Arun,\n  Liangqiong Qu, Katharina Hoebel, Jay Patel, Mishka Gidwani, Ashwin Vaswani,\n  Daniel L Rubin and Jayashree Kalpathy-Cramer", "title": "The unreasonable effectiveness of Batch-Norm statistics in addressing\n  catastrophic forgetting across medical institutions", "comments": "Accepted as oral presentation in Machine Learning for Health (ML4H)\n  at NeurIPS 2020 - Extended Abstract ; 6 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model brittleness is a primary concern when deploying deep learning models in\nmedical settings owing to inter-institution variations, like patient\ndemographics and intra-institution variation, such as multiple scanner types.\nWhile simply training on the combined datasets is fraught with data privacy\nlimitations, fine-tuning the model on subsequent institutions after training it\non the original institution results in a decrease in performance on the\noriginal dataset, a phenomenon called catastrophic forgetting. In this paper,\nwe investigate trade-off between model refinement and retention of previously\nlearned knowledge and subsequently address catastrophic forgetting for the\nassessment of mammographic breast density. More specifically, we propose a\nsimple yet effective approach, adapting Elastic weight consolidation (EWC)\nusing the global batch normalization (BN) statistics of the original dataset.\nThe results of this study provide guidance for the deployment of clinical deep\nlearning models where continuous learning is needed for domain expansion.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 16:57:05 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gupta", "Sharut", ""], ["Singh", "Praveer", ""], ["Chang", "Ken", ""], ["Aggarwal", "Mehak", ""], ["Arun", "Nishanth", ""], ["Qu", "Liangqiong", ""], ["Hoebel", "Katharina", ""], ["Patel", "Jay", ""], ["Gidwani", "Mishka", ""], ["Vaswani", "Ashwin", ""], ["Rubin", "Daniel L", ""], ["Kalpathy-Cramer", "Jayashree", ""]]}, {"id": "2011.08102", "submitter": "Fabio Carrara PhD", "authors": "Fabio Carrara (1), Giuseppe Amato (1), Luca Brombin, Fabrizio Falchi\n  (1), Claudio Gennaro (1) ((1) ISTI CNR, Pisa, Italy)", "title": "Combining GANs and AutoEncoders for Efficient Anomaly Detection", "comments": "8 pages, 5 figures, 3 tables, pre-print, to be published in the\n  proceedings of the 25th International Conference on Pattern Recognition\n  (ICPR2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose CBiGAN -- a novel method for anomaly detection in\nimages, where a consistency constraint is introduced as a regularization term\nin both the encoder and decoder of a BiGAN. Our model exhibits fairly good\nmodeling power and reconstruction consistency capability. We evaluate the\nproposed method on MVTec AD -- a real-world benchmark for unsupervised anomaly\ndetection on high-resolution images -- and compare against standard baselines\nand state-of-the-art approaches. Experiments show that the proposed method\nimproves the performance of BiGAN formulations by a large margin and performs\ncomparably to expensive state-of-the-art iterative methods while reducing the\ncomputational cost. We also observe that our model is particularly effective in\ntexture-type anomaly detection, as it sets a new state of the art in this\ncategory. Our code is available at https://github.com/fabiocarrara/cbigan-ad/.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 17:07:55 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 16:09:50 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Carrara", "Fabio", "", "ISTI CNR, Pisa, Italy"], ["Amato", "Giuseppe", "", "ISTI CNR, Pisa, Italy"], ["Brombin", "Luca", "", "ISTI CNR, Pisa, Italy"], ["Falchi", "Fabrizio", "", "ISTI CNR, Pisa, Italy"], ["Gennaro", "Claudio", "", "ISTI CNR, Pisa, Italy"]]}, {"id": "2011.08105", "submitter": "Priya Donti", "authors": "Priya L. Donti, Melrose Roderick, Mahyar Fazlyab, J. Zico Kolter", "title": "Enforcing robust control guarantees within neural network policies", "comments": "Code available online: https://github.com/locuslab/robust-nn-control", "journal-ref": "International Conference on Learning Representations 2021", "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When designing controllers for safety-critical systems, practitioners often\nface a challenging tradeoff between robustness and performance. While robust\ncontrol methods provide rigorous guarantees on system stability under certain\nworst-case disturbances, they often yield simple controllers that perform\npoorly in the average (non-worst) case. In contrast, nonlinear control methods\ntrained using deep learning have achieved state-of-the-art performance on many\ncontrol tasks, but often lack robustness guarantees. In this paper, we propose\na technique that combines the strengths of these two approaches: constructing a\ngeneric nonlinear control policy class, parameterized by neural networks, that\nnonetheless enforces the same provable robustness criteria as robust control.\nSpecifically, our approach entails integrating custom convex-optimization-based\nprojection layers into a neural network-based policy. We demonstrate the power\nof this approach on several domains, improving in average-case performance over\nexisting robust control methods and in worst-case stability over (non-robust)\ndeep RL methods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 17:14:59 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 18:25:56 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Donti", "Priya L.", ""], ["Roderick", "Melrose", ""], ["Fazlyab", "Mahyar", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2011.08121", "submitter": "Mingchen Li", "authors": "Yao-Chun Chan, Mingchen Li, Samet Oymak", "title": "On the Marginal Benefit of Active Learning: Does Self-Supervision Eat\n  Its Cake?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is the set of techniques for intelligently labeling large\nunlabeled datasets to reduce the labeling effort. In parallel, recent\ndevelopments in self-supervised and semi-supervised learning (S4L) provide\npowerful techniques, based on data-augmentation, contrastive learning, and\nself-training, that enable superior utilization of unlabeled data which led to\na significant reduction in required labeling in the standard machine learning\nbenchmarks. A natural question is whether these paradigms can be unified to\nobtain superior results. To this aim, this paper provides a novel algorithmic\nframework integrating self-supervised pretraining, active learning, and\nconsistency-regularized self-training. We conduct extensive experiments with\nour framework on CIFAR10 and CIFAR100 datasets. These experiments enable us to\nisolate and assess the benefits of individual components which are evaluated\nusing state-of-the-art methods (e.g.~Core-Set, VAAL, simCLR, FixMatch). Our\nexperiments reveal two key insights: (i) Self-supervised pre-training\nsignificantly improves semi-supervised learning, especially in the few-label\nregime, (ii) The benefit of active learning is undermined and subsumed by S4L\ntechniques. Specifically, we fail to observe any additional benefit of\nstate-of-the-art active learning algorithms when combined with state-of-the-art\nS4L techniques.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 17:34:55 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Chan", "Yao-Chun", ""], ["Li", "Mingchen", ""], ["Oymak", "Samet", ""]]}, {"id": "2011.08127", "submitter": "Akshar Nair", "authors": "Alexandra Gkolia, Nikhil Fernandes, Nicolas Pizzo, James Davenport and\n  Akshar Nair", "title": "The Influence of Domain-Based Preprocessing on Subject-Specific\n  Clustering", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sudden change of moving the majority of teaching online at Universities\ndue to the global Covid-19 pandemic has caused an increased amount of workload\nfor academics. One of the contributing factors is answering a high volume of\nqueries coming from students. As these queries are not limited to the\nsynchronous time frame of a lecture, there is a high chance of many of them\nbeing related or even equivalent. One way to deal with this problem is to\ncluster these questions depending on their topic. In our previous work, we\naimed to find an improved method of clustering that would give us a high\nefficiency, using a recurring LDA model. Our data set contained questions\nposted online from a Computer Science course at the University of Bath. A\nsignificant number of these questions contained code excerpts, which we found\ncaused a problem in clustering, as certain terms were being considered as\ncommon words in the English language and not being recognised as specific code\nterms. To address this, we implemented tagging of these technical terms using\nPython, as part of preprocessing the data set. In this paper, we explore the\nrealms of tagging data sets, focusing on identifying code excerpts and\nproviding empirical results in order to justify our reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 17:47:19 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Gkolia", "Alexandra", ""], ["Fernandes", "Nikhil", ""], ["Pizzo", "Nicolas", ""], ["Davenport", "James", ""], ["Nair", "Akshar", ""]]}, {"id": "2011.08129", "submitter": "Mou-Cheng Xu", "authors": "Mou-Cheng Xu", "title": "Tissue characterization based on the analysis on i3DUS data for\n  diagnosis support in neurosurgery", "comments": "MRes thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain shift makes the pre-operative MRI navigation highly inaccurate hence\nthe intraoperative modalities are adopted in surgical theatre. Due to the\nexcellent economic and portability merits, the Ultrasound imaging is used at\nour collaborating hospital, Charing Cross Hospital, Imperial College London,\nUK. However, it is found that intraoperative diagnosis on Ultrasound images is\nnot straightforward and consistent, even for very experienced clinical experts.\nHence, there is a demand to design a Computer-aided-diagnosis system to provide\na robust second opinion to help the surgeons. The proposed CAD system based on\n\"Mixed-Attention Res-U-net with asymmetric loss function\" achieves the\nstate-of-the-art results comparing to the ground truth by classification at\npixel-level directly, it also outperforms all the current main stream\npixel-level classification methods (e.g. U-net, FCN) in all the evaluation\nmetrices.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2020 10:44:49 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Xu", "Mou-Cheng", ""]]}, {"id": "2011.08138", "submitter": "Hassan Arbabi", "authors": "Hassan Arbabi, Felix P. Kemeth, Tom Bertalan and Ioannis Kevrekidis", "title": "Coarse-grained and emergent distributed parameter systems from data", "comments": "specified the corresponding author", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We explore the derivation of distributed parameter system evolution laws (and\nin particular, partial differential operators and associated partial\ndifferential equations, PDEs) from spatiotemporal data. This is, of course, a\nclassical identification problem; our focus here is on the use of manifold\nlearning techniques (and, in particular, variations of Diffusion Maps) in\nconjunction with neural network learning algorithms that allow us to attempt\nthis task when the dependent variables, and even the independent variables of\nthe PDE are not known a priori and must be themselves derived from the data.\nThe similarity measure used in Diffusion Maps for dependent coarse variable\ndetection involves distances between local particle distribution observations;\nfor independent variable detection we use distances between local short-time\ndynamics. We demonstrate each approach through an illustrative established PDE\nexample. Such variable-free, emergent space identification algorithms connect\nnaturally with equation-free multiscale computation tools.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:02:01 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 02:32:05 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Arbabi", "Hassan", ""], ["Kemeth", "Felix P.", ""], ["Bertalan", "Tom", ""], ["Kevrekidis", "Ioannis", ""]]}, {"id": "2011.08146", "submitter": "Zheyu Wen", "authors": "Zheyu Wen", "title": "Temporal Dynamic Model for Resting State fMRI Data: A Neural Ordinary\n  Differential Equation approach", "comments": "13 pages, 20 figures, preprint work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to provide a temporal dynamic model for\nresting state functional Magnetic Resonance Imaging (fMRI) trajectory to\npredict future brain images based on the given sequence. To this end, we came\nup with the model that takes advantage of representation learning and Neural\nOrdinary Differential Equation (Neural ODE) to compress the fMRI image data\ninto latent representation and learn to predict the trajectory following\ndifferential equation. Latent space was analyzed by Gaussian Mixture Model. The\nlearned fMRI trajectory embedding can be used to explain the variance of the\ntrajectory and predict human traits for each subject. This method achieves\naverage 0.5 spatial correlation for the whole predicted trajectory, and provide\ntrained ODE parameter for further analysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:16:19 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wen", "Zheyu", ""]]}, {"id": "2011.08174", "submitter": "Davide Viviano Mr.", "authors": "Davide Viviano", "title": "Policy choice in experiments with unknown interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses experimental design to estimate welfare-maximizing\npolicies. We consider a setting where units are organized into large, finitely\nmany independent clusters and interact over unobserved dimensions within each\ncluster. The contribution of this paper is two-fold. First, we construct a test\nfor whether a welfare-improving treatment configuration exists and hence worth\nlearning by conducting a larger scale experiment. Second, we introduce an\nadaptive randomization procedure to estimate welfare-maximizing individual\ntreatment allocation rules valid under unobserved interference. We derive\nasymptotic properties of the marginal effects estimators and finite-sample\nregret guarantees of the policy. Finally, we illustrate the method's advantage\nin simulations calibrated to an existing experiment on information diffusion.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:58:54 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 18:57:10 GMT"}, {"version": "v3", "created": "Thu, 21 Jan 2021 18:58:15 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 17:42:04 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Viviano", "Davide", ""]]}, {"id": "2011.08177", "submitter": "Anthony Simeonov", "authors": "Anthony Simeonov, Yilun Du, Beomjoon Kim, Francois R. Hogan, Joshua\n  Tenenbaum, Pulkit Agrawal, Alberto Rodriguez", "title": "A Long Horizon Planning Framework for Manipulating Rigid Pointcloud\n  Objects", "comments": "Conference on Robot Learning (CoRL 2020): Project website:\n  https://anthonysimeonov.github.io/rpo-planning-framework/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for solving long-horizon planning problems involving\nmanipulation of rigid objects that operates directly from a point-cloud\nobservation, i.e. without prior object models. Our method plans in the space of\nobject subgoals and frees the planner from reasoning about robot-object\ninteraction dynamics by relying on a set of generalizable manipulation\nprimitives. We show that for rigid bodies, this abstraction can be realized\nusing low-level manipulation skills that maintain sticking contact with the\nobject and represent subgoals as 3D transformations. To enable generalization\nto unseen objects and improve planning performance, we propose a novel way of\nrepresenting subgoals for rigid-body manipulation and a graph-attention based\nneural network architecture for processing point-cloud inputs. We\nexperimentally validate these choices using simulated and real-world\nexperiments on the YuMi robot. Results demonstrate that our method can\nsuccessfully manipulate new objects into target configurations requiring\nlong-term planning. Overall, our framework realizes the best of the worlds of\ntask-and-motion planning (TAMP) and learning-based approaches. Project website:\nhttps://anthonysimeonov.github.io/rpo-planning-framework/.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:59:33 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Simeonov", "Anthony", ""], ["Du", "Yilun", ""], ["Kim", "Beomjoon", ""], ["Hogan", "Francois R.", ""], ["Tenenbaum", "Joshua", ""], ["Agrawal", "Pulkit", ""], ["Rodriguez", "Alberto", ""]]}, {"id": "2011.08181", "submitter": "Diego Granziol", "authors": "Diego Granziol, Xingchen Wan, Samuel Albanie, Stephen Roberts", "title": "Explaining the Adaptive Generalisation Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conjecture that the inherent difference in generalisation between adaptive\nand non-adaptive gradient methods stems from the increased estimation noise in\nthe flattest directions of the true loss surface. We demonstrate that typical\nschedules used for adaptive methods (with low numerical stability or damping\nconstants) serve to bias relative movement towards flat directions relative to\nsharp directions, effectively amplifying the noise-to-signal ratio and harming\ngeneralisation. We further demonstrate that the numerical stability/damping\nconstant used in these methods can be decomposed into a learning rate reduction\nand linear shrinkage of the estimated curvature matrix. We then demonstrate\nsignificant generalisation improvements by increasing the shrinkage\ncoefficient, closing the generalisation gap entirely in both Logistic\nRegression and Deep Neural Network experiments. Finally, we show that other\npopular modifications to adaptive methods, such as decoupled weight decay and\npartial adaptivity can be shown to calibrate parameter updates to make better\nuse of sharper, more reliable directions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 18:19:42 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 09:37:16 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 12:02:20 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 11:23:25 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Granziol", "Diego", ""], ["Wan", "Xingchen", ""], ["Albanie", "Samuel", ""], ["Roberts", "Stephen", ""]]}, {"id": "2011.08184", "submitter": "Jan Egger", "authors": "Jan Egger, Antonio Pepe, Christina Gsaxner, Jianning Li", "title": "Deep Learning -- A first Meta-Survey of selected Reviews across\n  Scientific Disciplines and their Research Impact", "comments": "39 pages, 5 tables, 80 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning belongs to the field of artificial intelligence, where machines\nperform tasks that typically require some kind of human intelligence. Deep\nlearning tries to achieve this by mimicking the learning of a human brain.\nSimilar to the basic structure of a brain, which consists of (billions of)\nneurons and connections between them, a deep learning algorithm consists of an\nartificial neural network, which resembles the biological brain structure.\nMimicking the learning process of humans with their senses, deep learning\nnetworks are fed with (sensory) data, like texts, images, videos or sounds.\nThese networks outperform the state-of-the-art methods in different tasks and,\nbecause of this, the whole field saw an exponential growth during the last\nyears. This growth resulted in way over 10 000 publications per year in the\nlast years. For example, the search engine PubMed alone, which covers only a\nsub-set of all publications in the medical field, provides over 11 000 results\nfor the search term $'$deep learning$'$ in Q3 2020, and ~90% of these results\nare from the last three years. Consequently, a complete overview over the field\nof deep learning is already impossible to obtain and, in the near future, it\nwill potentially become difficult to obtain an overview over a subfield.\nHowever, there are several review articles about deep learning, which are\nfocused on specific scientific fields or applications, for example deep\nlearning advances in computer vision or in specific tasks like object\ndetection. With these surveys as a foundation, the aim of this contribution is\nto provide a first high-level, categorized meta-analysis of selected reviews on\ndeep learning across different scientific disciplines and outline the research\nimpact that they already have during a short period of time.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:14:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Egger", "Jan", ""], ["Pepe", "Antonio", ""], ["Gsaxner", "Christina", ""], ["Li", "Jianning", ""]]}, {"id": "2011.08191", "submitter": "Johann Brehmer Mr", "authors": "Johann Brehmer, Sebastian Macaluso, Duccio Pappadopulo, Kyle Cranmer", "title": "Hierarchical clustering in particle physics through reinforcement\n  learning", "comments": "Accepted at the Machine Learning and the Physical Sciences workshop\n  at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle physics experiments often require the reconstruction of decay\npatterns through a hierarchical clustering of the observed final-state\nparticles. We show that this task can be phrased as a Markov Decision Process\nand adapt reinforcement learning algorithms to solve it. In particular, we show\nthat Monte-Carlo Tree Search guided by a neural policy can construct\nhigh-quality hierarchical clusterings and outperform established greedy and\nbeam search baselines.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:00:01 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 09:39:44 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Brehmer", "Johann", ""], ["Macaluso", "Sebastian", ""], ["Pappadopulo", "Duccio", ""], ["Cranmer", "Kyle", ""]]}, {"id": "2011.08225", "submitter": "Noy Cohen-Shapira", "authors": "Noy Cohen-Shapira and Lior Rokach", "title": "Automatic selection of clustering algorithms using supervised graph\n  embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The widespread adoption of machine learning (ML) techniques and the extensive\nexpertise required to apply them have led to increased interest in automated ML\nsolutions that reduce the need for human intervention. One of the main\nchallenges in applying ML to previously unseen problems is algorithm selection\n- the identification of high-performing algorithm(s) for a given dataset, task,\nand evaluation measure. This study addresses the algorithm selection challenge\nfor data clustering, a fundamental task in data mining that is aimed at\ngrouping similar objects. We present MARCO-GE, a novel meta-learning approach\nfor the automated recommendation of clustering algorithms. MARCO-GE first\ntransforms datasets into graphs and then utilizes a graph convolutional neural\nnetwork technique to extract their latent representation. Using the embedding\nrepresentations obtained, MARCO-GE trains a ranking meta-model capable of\naccurately recommending top-performing algorithms for a new dataset and\nclustering evaluation measure. Extensive evaluation on 210 datasets, 13\nclustering algorithms, and 10 clustering measures demonstrates the\neffectiveness of our approach and its superiority in terms of predictive and\ngeneralization performance over state-of-the-art clustering meta-learning\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:13:20 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 19:09:22 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Cohen-Shapira", "Noy", ""], ["Rokach", "Lior", ""]]}, {"id": "2011.08243", "submitter": "Chien-Wei Lin", "authors": "Chien-Wei Lin, Vincent Auvray, Daniel Elkind, Arijit Biswas, Maryam\n  Fazel-Zarandi, Nehal Belgamwar, Shubhra Chandra, Matt Zhao, Angeliki\n  Metallinou, Tagyoung Chung, Charlie Shucheng Zhu, Suranjit Adhikari, Dilek\n  Hakkani-Tur", "title": "Dialog Simulation with Realistic Variations for Training Goal-Oriented\n  Conversational Systems", "comments": "To be presented at Human in the Loop Dialogue Systems Workshop,\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-oriented dialog systems enable users to complete specific goals like\nrequesting information about a movie or booking a ticket. Typically the dialog\nsystem pipeline contains multiple ML models, including natural language\nunderstanding, state tracking and action prediction (policy learning). These\nmodels are trained through a combination of supervised or reinforcement\nlearning methods and therefore require collection of labeled domain specific\ndatasets. However, collecting annotated datasets with language and dialog-flow\nvariations is expensive, time-consuming and scales poorly due to human\ninvolvement. In this paper, we propose an approach for automatically creating a\nlarge corpus of annotated dialogs from a few thoroughly annotated sample\ndialogs and the dialog schema. Our approach includes a novel goal-sampling\ntechnique for sampling plausible user goals and a dialog simulation technique\nthat uses heuristic interplay between the user and the system (Alexa), where\nthe user tries to achieve the sampled goal. We validate our approach by\ngenerating data and training three different downstream conversational ML\nmodels. We achieve 18 ? 50% relative accuracy improvements on a held-out test\nset compared to a baseline dialog generation approach that only samples natural\nlanguage and entity value variations from existing catalogs but does not\ngenerate any novel dialog flow variations. We also qualitatively establish that\nthe proposed approach is better than the baseline. Moreover, several different\nconversational experiences have been built using this method, which enables\ncustomers to have a wide variety of conversations with Alexa.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:39:15 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lin", "Chien-Wei", ""], ["Auvray", "Vincent", ""], ["Elkind", "Daniel", ""], ["Biswas", "Arijit", ""], ["Fazel-Zarandi", "Maryam", ""], ["Belgamwar", "Nehal", ""], ["Chandra", "Shubhra", ""], ["Zhao", "Matt", ""], ["Metallinou", "Angeliki", ""], ["Chung", "Tagyoung", ""], ["Zhu", "Charlie Shucheng", ""], ["Adhikari", "Suranjit", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2011.08254", "submitter": "Michael Lash", "authors": "Michael T. Lash and W. Nick Street", "title": "Personalized Cardiovascular Disease Risk Mitigation via Longitudinal\n  Inverse Classification", "comments": "Forthcoming in AIBH 2020 (a BIBM 2020 workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular disease (CVD) is a serious illness affecting millions\nworld-wide and is the leading cause of death in the US. Recent years, however,\nhave seen tremendous growth in the area of personalized medicine, a field of\nmedicine that places the patient at the center of the medical decision-making\nand treatment process. Many CVD-focused personalized medicine innovations focus\non genetic biomarkers, which provide person-specific CVD insights at the\ngenetic level, but do not focus on the practical steps a patient could take to\nmitigate their risk of CVD development. In this work we propose longitudinal\ninverse classification, a recommendation framework that provides personalized\nlifestyle recommendations that minimize the predicted probability of CVD risk.\nOur framework takes into account historical CVD risk, as well as other patient\ncharacteristics, to provide recommendations. Our experiments show that earlier\nadoption of the recommendations elicited from our framework produce significant\nCVD risk reduction.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:23:01 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lash", "Michael T.", ""], ["Street", "W. Nick", ""]]}, {"id": "2011.08261", "submitter": "M. Ali Vosoughi", "authors": "M. Ali Vosoughi, Axel Wismuller", "title": "Large-scale kernelized GRANGER causality to infer topology of directed\n  graphs with applications to brain networks", "comments": "5 pages, 3 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph topology inference of network processes with co-evolving and\ninteracting time-series is crucial for network studies. Vector autoregressive\nmodels (VAR) are popular approaches for topology inference of directed graphs;\nhowever, in large networks with short time-series, topology estimation becomes\nill-posed. The present paper proposes a novel nonlinearity-preserving topology\ninference method for directed networks with co-evolving nodal processes that\nsolves the ill-posedness problem. The proposed method, large-scale kernelized\nGranger causality (lsKGC), uses kernel functions to transform data into a\nlow-dimensional feature space and solves the autoregressive problem in the\nfeature space, then finds the pre-images in the input space to infer the\ntopology. Extensive simulations on synthetic datasets with nonlinear and linear\ndependencies and known ground-truth demonstrate significant improvement in the\nArea Under the receiver operating characteristic Curve ( AUC ) of the receiver\noperating characteristic for network recovery compared to existing methods.\nFurthermore, tests on real datasets from a functional magnetic resonance\nimaging (fMRI) study demonstrate 96.3 percent accuracy in diagnosis tasks of\nschizophrenia patients, which is the highest in the literature with only brain\ntime-series information.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:30:19 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Vosoughi", "M. Ali", ""], ["Wismuller", "Axel", ""]]}, {"id": "2011.08273", "submitter": "Lea Duji\\'c Rodi\\'c  Mrs.", "authors": "Lea Duji\\'c Rodi\\'c, Tomislav \\v{Z}upanovi\\'c, Toni Perkovi\\'c, and\n  Petar \\v{S}oli\\'c (Corresponding Author, University of Split, Croatia), Joel\n  J. P. C. Rodrigues (Federal University of Piau\\'i (UFPI), Teresina - PI,\n  Brazil and Instituto de Telecomunica\\c{c}\\~oes, Portugal)", "title": "Machine Learning and Soil Humidity Sensing: Signal Strength Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IoT vision of ubiquitous and pervasive computing gives rise to future\nsmart irrigation systems comprising physical and digital world. Smart\nirrigation ecosystem combined with Machine Learning can provide solutions that\nsuccessfully solve the soil humidity sensing task in order to ensure optimal\nwater usage. Existing solutions are based on data received from the power\nhungry/expensive sensors that are transmitting the sensed data over the\nwireless channel. Over time, the systems become difficult to maintain,\nespecially in remote areas due to the battery replacement issues with large\nnumber of devices. Therefore, a novel solution must provide an alternative,\ncost and energy effective device that has unique advantage over the existing\nsolutions. This work explores a concept of a novel, low-power, LoRa-based,\ncost-effective system which achieves humidity sensing using Deep learning\ntechniques that can be employed to sense soil humidity with the high accuracy\nsimply by measuring signal strength of the given underground beacon device.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:00:36 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Rodi\u0107", "Lea Duji\u0107", "", "Corresponding Author, University of Split, Croatia"], ["\u017dupanovi\u0107", "Tomislav", "", "Corresponding Author, University of Split, Croatia"], ["Perkovi\u0107", "Toni", "", "Corresponding Author, University of Split, Croatia"], ["\u0160oli\u0107", "Petar", "", "Corresponding Author, University of Split, Croatia"], ["Rodrigues", "Joel J. P. C.", "", "Federal University of Piau\u00ed"]]}, {"id": "2011.08281", "submitter": "Aditya Devarakonda", "authors": "Aditya Devarakonda, James Demmel", "title": "Avoiding Communication in Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic gradient descent (SGD) is one of the most widely used optimization\nmethods for solving various machine learning problems. SGD solves an\noptimization problem by iteratively sampling a few data points from the input\ndata, computing gradients for the selected data points, and updating the\nsolution. However, in a parallel setting, SGD requires interprocess\ncommunication at every iteration. We introduce a new communication-avoiding\ntechnique for solving the logistic regression problem using SGD. This technique\nre-organizes the SGD computations into a form that communicates every $s$\niterations instead of every iteration, where $s$ is a tuning parameter. We\nprove theoretical flops, bandwidth, and latency upper bounds for SGD and its\nnew communication-avoiding variant. Furthermore, we show experimental results\nthat illustrate that the new Communication-Avoiding SGD (CA-SGD) method can\nachieve speedups of up to $4.97\\times$ on a high-performance Infiniband cluster\nwithout altering the convergence behavior or accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:14:39 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Devarakonda", "Aditya", ""], ["Demmel", "James", ""]]}, {"id": "2011.08295", "submitter": "Ziqi Ke", "authors": "Ziqi Ke and Haris Vikalo", "title": "Real-Time Radio Technology and Modulation Classification via an LSTM\n  Auto-Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Identification of the type of communication technology and/or modulation\nscheme based on detected radio signal are challenging problems encountered in a\nvariety of applications including spectrum allocation and radio interference\nmitigation. They are rendered difficult due to a growing number of emitter\ntypes and varied effects of real-world channels upon the radio signal. Existing\nspectrum monitoring techniques are capable of acquiring massive amounts of\nradio and real-time spectrum data using compact sensors deployed in a variety\nof settings. However, state-of-the-art methods that use such data to classify\nemitter types and detect communication schemes struggle to achieve required\nlevels of accuracy at a computational efficiency that would allow their\nimplementation on low-cost computational platforms. In this paper, we present a\nlearning framework based on an LSTM denoising auto-encoder designed to\nautomatically extract stable and robust features from noisy radio signals, and\ninfer modulation or technology type using the learned features. The algorithm\nutilizes a compact neural network architecture readily implemented on a\nlow-cost computational platform while exceeding state-of-the-art accuracy.\nResults on realistic synthetic as well as over-the-air radio data demonstrate\nthat the proposed framework reliably and efficiently classifies received radio\nsignals, often demonstrating superior performance compared to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:41:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ke", "Ziqi", ""], ["Vikalo", "Haris", ""]]}, {"id": "2011.08299", "submitter": "Harrison Wilde", "authors": "Harrison Wilde, Jack Jewson, Sebastian Vollmer and Chris Holmes", "title": "Foundations of Bayesian Learning from Synthetic Data", "comments": "43 pages (10 main text, 33 supplement), 32 figures (4 main text, 28\n  supplement)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is significant growth and interest in the use of synthetic data as an\nenabler for machine learning in environments where the release of real data is\nrestricted due to privacy or availability constraints. Despite a large number\nof methods for synthetic data generation, there are comparatively few results\non the statistical properties of models learnt on synthetic data, and fewer\nstill for situations where a researcher wishes to augment real data with\nanother party's synthesised data. We use a Bayesian paradigm to characterise\nthe updating of model parameters when learning in these settings, demonstrating\nthat caution should be taken when applying conventional learning algorithms\nwithout appropriate consideration of the synthetic data generating process and\nlearning task. Recent results from general Bayesian updating support a novel\nand robust approach to Bayesian synthetic-learning founded on decision theory\nthat outperforms standard approaches across repeated experiments on supervised\nlearning and inference problems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:49:17 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 15:01:22 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wilde", "Harrison", ""], ["Jewson", "Jack", ""], ["Vollmer", "Sebastian", ""], ["Holmes", "Chris", ""]]}, {"id": "2011.08306", "submitter": "Valanarasu Jeya Maria Jose", "authors": "Jeya Maria Jose Valanarasu, Vishal M. Patel", "title": "Overcomplete Deep Subspace Clustering Networks", "comments": "WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Subspace Clustering Networks (DSC) provide an efficient solution to the\nproblem of unsupervised subspace clustering by using an undercomplete deep\nauto-encoder with a fully-connected layer to exploit the self expressiveness\nproperty. This method uses undercomplete representations of the input data\nwhich makes it not so robust and more dependent on pre-training. To overcome\nthis, we propose a simple yet efficient alternative method - Overcomplete Deep\nSubspace Clustering Networks (ODSC) where we use overcomplete representations\nfor subspace clustering. In our proposed method, we fuse the features from both\nundercomplete and overcomplete auto-encoder networks before passing them\nthrough the self-expressive layer thus enabling us to extract a more meaningful\nand robust representation of the input data for clustering. Experimental\nresults on four benchmark datasets show the effectiveness of the proposed\nmethod over DSC and other clustering methods in terms of clustering error. Our\nmethod is also not as dependent as DSC is on where pre-training should be\nstopped to get the best performance and is also more robust to noise. Code -\n\\href{https://github.com/jeya-maria-jose/Overcomplete-Deep-Subspace-Clustering}{https://github.com/jeya-maria-jose/Overcomplete-Deep-Subspace-Clustering\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 22:07:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Valanarasu", "Jeya Maria Jose", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2011.08315", "submitter": "Omid Hajihassani", "authors": "Omid Hajihassani, Omid Ardakanian, Hamzeh Khazaei", "title": "Privacy-preserving Data Analysis through Representation Learning and\n  Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of data from the sensors embedded in mobile and Internet of\nThings (IoT) devices and the remarkable success of deep neural networks in\nuncovering hidden patterns in time series data have led to mounting privacy\nconcerns in recent years. In this paper, we aim to navigate the trade-off\nbetween data utility and privacy by learning low-dimensional representations\nthat are useful for data anonymization. We propose probabilistic\ntransformations in the latent space of a variational autoencoder to synthesize\ntime series data such that intrusive inferences are prevented while desired\ninferences can still be made with a satisfactory level of accuracy. We compare\nour technique with state-of-the-art autoencoder-based anonymization techniques\nand additionally show that it can anonymize data in real time on\nresource-constrained edge devices.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 22:32:30 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hajihassani", "Omid", ""], ["Ardakanian", "Omid", ""], ["Khazaei", "Hamzeh", ""]]}, {"id": "2011.08317", "submitter": "Ehsan Emad Marvasti", "authors": "Ehsan Emad Marvasti, Arash Raftari, Amir Emad Marvasti, Yaser\n  P.Fallah, Rui Guo, Hongsheng Lu", "title": "Feature Sharing and Integration for Cooperative Cognition and Perception\n  with Volumetric Sensors", "comments": "12 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent advancement in computational and communication systems has led to\nthe introduction of high-performing neural networks and high-speed wireless\nvehicular communication networks. As a result, new technologies such as\ncooperative perception and cognition have emerged, addressing the inherent\nlimitations of sensory devices by providing solutions for the detection of\npartially occluded targets and expanding the sensing range. However, designing\na reliable cooperative cognition or perception system requires addressing the\nchallenges caused by limited network resources and discrepancies between the\ndata shared by different sources. In this paper, we examine the requirements,\nlimitations, and performance of different cooperative perception techniques,\nand present an in-depth analysis of the notion of Deep Feature Sharing (DFS).\nWe explore different cooperative object detection designs and evaluate their\nperformance in terms of average precision. We use the Volony dataset for our\nexperimental study. The results confirm that the DFS methods are significantly\nless sensitive to the localization error caused by GPS noise. Furthermore, the\nresults attest that detection gain of DFS methods caused by adding more\ncooperative participants in the scenes is comparable to raw information sharing\ntechnique while DFS enables flexibility in design toward satisfying\ncommunication requirements.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 22:43:44 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 21:18:33 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 17:58:14 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Marvasti", "Ehsan Emad", ""], ["Raftari", "Arash", ""], ["Marvasti", "Amir Emad", ""], ["Fallah", "Yaser P.", ""], ["Guo", "Rui", ""], ["Lu", "Hongsheng", ""]]}, {"id": "2011.08325", "submitter": "Pedro Henrique Silva Souza Barros", "authors": "Pedro H. Barros, Fabiane Queiroz, Flavio Figueredo, Jefersson A. dos\n  Santos, Heitor S. Ramos", "title": "A New Similarity Space Tailored for Supervised Deep Metric Learning", "comments": "47 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel deep metric learning method. Differently from many works\non this area, we defined a novel latent space obtained through an autoencoder.\nThe new space, namely S-space, is divided into different regions that describe\nthe positions where pairs of objects are similar/dissimilar. We locate makers\nto identify these regions. We estimate the similarities between objects through\na kernel-based t-student distribution to measure the markers' distance and the\nnew data representation. In our approach, we simultaneously estimate the\nmarkers' position in the S-space and represent the objects in the same space.\nMoreover, we propose a new regularization function to avoid similar markers to\ncollapse altogether. We present evidences that our proposal can represent\ncomplex spaces, for instance, when groups of similar objects are located in\ndisjoint regions. We compare our proposal to 9 different distance metric\nlearning approaches (four of them are based on deep-learning) on 28 real-world\nheterogeneous datasets. According to the four quantitative metrics used, our\nmethod overcomes all the nine strategies from the literature.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 22:58:06 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 21:24:02 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Barros", "Pedro H.", ""], ["Queiroz", "Fabiane", ""], ["Figueredo", "Flavio", ""], ["Santos", "Jefersson A. dos", ""], ["Ramos", "Heitor S.", ""]]}, {"id": "2011.08341", "submitter": "Li Chen", "authors": "Li Chen, David Yang, Purvi Goel, Ilknur Kabul", "title": "Robust Deep Learning with Active Noise Cancellation for Spatial\n  Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes CANC, a Co-teaching Active Noise Cancellation method,\napplied in spatial computing to address deep learning trained with extreme\nnoisy labels. Deep learning algorithms have been successful in spatial\ncomputing for land or building footprint recognition. However a lot of noise\nexists in ground truth labels due to how labels are collected in spatial\ncomputing and satellite imagery. Existing methods to deal with extreme label\nnoise conduct clean sample selection and do not utilize the remaining samples.\nSuch techniques can be wasteful due to the cost of data retrieval. Our proposed\nCANC algorithm not only conserves high-cost training samples but also provides\nactive label correction to better improve robust deep learning with extreme\nnoisy labels. We demonstrate the effectiveness of CANC for building footprint\nrecognition for spatial computing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 23:56:14 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Chen", "Li", ""], ["Yang", "David", ""], ["Goel", "Purvi", ""], ["Kabul", "Ilknur", ""]]}, {"id": "2011.08345", "submitter": "Jung-Su Ha", "authors": "Jung-Su Ha, Young-Jin Park, Hyeok-Joo Chae, Soon-Seo Park, Han-Lim\n  Choi", "title": "Distilling a Hierarchical Policy for Planning and Control via\n  Representation and Reinforcement Learning", "comments": "ICRA 2021, the first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hierarchical planning and control framework that enables an\nagent to perform various tasks and adapt to a new task flexibly. Rather than\nlearning an individual policy for each particular task, the proposed framework,\nDISH, distills a hierarchical policy from a set of tasks by representation and\nreinforcement learning. The framework is based on the idea of latent variable\nmodels that represent high-dimensional observations using low-dimensional\nlatent variables. The resulting policy consists of two levels of hierarchy: (i)\na planning module that reasons a sequence of latent intentions that would lead\nto an optimistic future and (ii) a feedback control policy, shared across the\ntasks, that executes the inferred intention. Because the planning is performed\nin low-dimensional latent space, the learned policy can immediately be used to\nsolve or adapt to new tasks without additional training. We demonstrate the\nproposed framework can learn compact representations (3- and 1-dimensional\nlatent states and commands for a humanoid with 197- and 36-dimensional state\nfeatures and actions) while solving a small number of imitation tasks, and the\nresulting policy is directly applicable to other types of tasks, i.e.,\nnavigation in cluttered environments. Video: https://youtu.be/HQsQysUWOhg\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 23:58:49 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 14:06:57 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Ha", "Jung-Su", ""], ["Park", "Young-Jin", ""], ["Chae", "Hyeok-Joo", ""], ["Park", "Soon-Seo", ""], ["Choi", "Han-Lim", ""]]}, {"id": "2011.08346", "submitter": "Liu Chen", "authors": "Liu Chen, Meysam Asgari", "title": "Refining Automatic Speech Recognition System for older adults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building a high quality automatic speech recognition (ASR) system with\nlimited training data has been a challenging task particularly for a narrow\ntarget population. Open-sourced ASR systems, trained on sufficient data from\nadults, are susceptible on seniors' speech due to acoustic mismatch between\nadults and seniors. With 12 hours of training data, we attempt to develop an\nASR system for socially isolated seniors (80+ years old) with possible\ncognitive impairments. We experimentally identify that ASR for the adult\npopulation performs poorly on our target population and transfer learning (TL)\ncan boost the system's performance. Standing on the fundamental idea of TL,\ntuning model parameters, we further improve the system by leveraging an\nattention mechanism to utilize the model's intermediate information. Our\napproach achieves 1.58% absolute improvements over the TL model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 00:00:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Chen", "Liu", ""], ["Asgari", "Meysam", ""]]}, {"id": "2011.08356", "submitter": "Henrique Aguiar", "authors": "Henrique Aguiar, Mauro Santos, Peter Watkinson, Tingting Zhu", "title": "Phenotyping Clusters of Patient Trajectories suffering from Chronic\n  Complex Disease", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract. 6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increased focus into the tasks of predicting\nhospital inpatient risk of deterioration and trajectory evolution due to the\navailability of electronic patient data. A common approach to these problems\ninvolves clustering patients time-series information such as vital sign\nobservations) to determine dissimilar subgroups of the patient population. Most\nclustering methods assume time-invariance of vital-signs and are unable to\nprovide interpretability in clusters that is clinically relevant, for instance,\nevent or outcome information. In this work, we evaluate three different\nclustering models on a large hospital dataset of vital-sign observations from\npatients suffering from Chronic Obstructive Pulmonary Disease. We further\npropose novel modifications to deal with unevenly sampled time-series data and\nunbalanced class distribution to improve phenotype separation. Lastly, we\ndiscuss further avenues of investigation for models to learn patient subgroups\nwith distinct behaviour and phenotype.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 01:18:33 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Aguiar", "Henrique", ""], ["Santos", "Mauro", ""], ["Watkinson", "Peter", ""], ["Zhu", "Tingting", ""]]}, {"id": "2011.08360", "submitter": "Yuetian Luo", "authors": "Yuetian Luo, Wen Huang, Xudong Li, Anru R. Zhang", "title": "Recursive Importance Sketching for Rank Constrained Least Squares:\n  Algorithms and High-order Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new {\\it \\underline{R}ecursive} {\\it\n\\underline{I}mportance} {\\it \\underline{S}ketching} algorithm for {\\it\n\\underline{R}ank} constrained least squares {\\it \\underline{O}ptimization}\n(RISRO). As its name suggests, the algorithm is based on a new sketching\nframework, recursive importance sketching. Several existing algorithms in the\nliterature can be reinterpreted under the new sketching framework and RISRO\noffers clear advantages over them. RISRO is easy to implement and\ncomputationally efficient, where the core procedure in each iteration is only\nsolving a dimension reduced least squares problem. Different from numerous\nexisting algorithms with locally geometric convergence rate, we establish the\nlocal quadratic-linear and quadratic rate of convergence for RISRO under some\nmild conditions. In addition, we discover a deep connection of RISRO to\nRiemannian manifold optimization on fixed rank matrices. The effectiveness of\nRISRO is demonstrated in two applications in machine learning and statistics:\nlow-rank matrix trace regression and phase retrieval. Simulation studies\ndemonstrate the superior numerical performance of RISRO.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 01:32:59 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 00:30:34 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Luo", "Yuetian", ""], ["Huang", "Wen", ""], ["Li", "Xudong", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2011.08367", "submitter": "Mingjie Sun", "authors": "Mingjie Sun, Jianguo Li, Changshui Zhang", "title": "Extreme Value Preserving Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent evidence shows that convolutional neural networks (CNNs) are biased\ntowards textures so that CNNs are non-robust to adversarial perturbations over\ntextures, while traditional robust visual features like SIFT (scale-invariant\nfeature transforms) are designed to be robust across a substantial range of\naffine distortion, addition of noise, etc with the mimic of human perception\nnature. This paper aims to leverage good properties of SIFT to renovate CNN\narchitectures towards better accuracy and robustness. We borrow the scale-space\nextreme value idea from SIFT, and propose extreme value preserving networks\n(EVPNets). Experiments demonstrate that EVPNets can achieve similar or better\naccuracy than conventional CNNs, while achieving much better robustness on a\nset of adversarial attacks (FGSM,PGD,etc) even without adversarial training.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 02:06:52 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Sun", "Mingjie", ""], ["Li", "Jianguo", ""], ["Zhang", "Changshui", ""]]}, {"id": "2011.08384", "submitter": "Jasper C.H. Lee", "authors": "Jasper C.H. Lee, Paul Valiant", "title": "Optimal Sub-Gaussian Mean Estimation in $\\mathbb{R}$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of estimating the mean of a real-valued distribution,\npresenting a novel estimator with sub-Gaussian convergence: intuitively, \"our\nestimator, on any distribution, is as accurate as the sample mean is for the\nGaussian distribution of matching variance.\" Crucially, in contrast to prior\nworks, our estimator does not require prior knowledge of the variance, and\nworks across the entire gamut of distributions with bounded variance, including\nthose without any higher moments. Parameterized by the sample size $n$, the\nfailure probability $\\delta$, and the variance $\\sigma^2$, our estimator is\naccurate to within $\\sigma\\cdot(1+o(1))\\sqrt{\\frac{2\\log\\frac{1}{\\delta}}{n}}$,\ntight up to the $1+o(1)$ factor. Our estimator construction and analysis gives\na framework generalizable to other problems, tightly analyzing a sum of\ndependent random variables by viewing the sum implicitly as a 2-parameter\n$\\psi$-estimator, and constructing bounds using mathematical programming and\nduality techniques.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 02:47:24 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lee", "Jasper C. H.", ""], ["Valiant", "Paul", ""]]}, {"id": "2011.08388", "submitter": "Puneet Kumar", "authors": "Puneet Kumar and Balasubramanian Raman", "title": "Domain Adaptation based Technique for Image Emotion Recognition using\n  Pre-trained Facial Expression Recognition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a domain adaptation based technique for recognizing the\nemotions in images containing facial, non-facial, and non-human components has\nbeen proposed. We have also proposed a novel technique to explain the proposed\nsystem's predictions in terms of Intersection Score. Image emotion recognition\nis useful for graphics, gaming, animation, entertainment, and cinematography.\nHowever, well-labeled large scale datasets and pre-trained models are not\navailable for image emotion recognition. To overcome this challenge, we have\nproposed a deep learning approach based on an attentional convolutional network\nthat adapts pre-trained facial expression recognition models. It detects the\nvisual features of an image and performs emotion classification based on them.\nThe experiments have been performed on the Flickr image dataset, and the images\nhave been classified in 'angry,' 'happy,' 'sad,' and 'neutral' emotion classes.\nThe proposed system has demonstrated better performance than the benchmark\nresults with an accuracy of 63.87% for image emotion recognition. We have also\nanalyzed the embedding plots for various emotion classes to explain the\nproposed system's predictions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 02:55:16 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kumar", "Puneet", ""], ["Raman", "Balasubramanian", ""]]}, {"id": "2011.08393", "submitter": "Jinho Choi", "authors": "Jinho Choi", "title": "Data-aided Sensing for Distributed Detection", "comments": "5 pages, 3 figures, to appear in IEEE Wireless Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study data-aided sensing (DAS) for distributed detection in\nwireless sensor networks (WSNs) when sensors' measurements are correlated. In\nparticular, we derive a node selection criterion based on the J-divergence in\nDAS for reliable decision subject to a decision delay constraint. Based on the\nproposed J-divergence based DAS, the nodes can be selected to rapidly increase\nthe log-likelihood ratio (LLR), which leads to a reliable decision with a\nsmaller number of the sensors that upload measurements for a shorter decision\ndelay. From simulation results, it is confirmed that the J-divergence based DAS\ncan provide a reliable decision with a smaller number of sensors compared to\nother approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 03:15:44 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Choi", "Jinho", ""]]}, {"id": "2011.08398", "submitter": "Tong Wang", "authors": "Tong Wang and Maytal Saar-Tsechansky", "title": "Augmented Fairness: An Interpretable Model Augmenting Decision-Makers'\n  Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model-agnostic approach for mitigating the prediction bias of a\nblack-box decision-maker, and in particular, a human decision-maker. Our method\ndetects in the feature space where the black-box decision-maker is biased and\nreplaces it with a few short decision rules, acting as a \"fair surrogate\". The\nrule-based surrogate model is trained under two objectives, predictive\nperformance and fairness. Our model focuses on a setting that is common in\npractice but distinct from other literature on fairness. We only have black-box\naccess to the model, and only a limited set of true labels can be queried under\na budget constraint. We formulate a multi-objective optimization for building a\nsurrogate model, where we simultaneously optimize for both predictive\nperformance and bias. To train the model, we propose a novel training algorithm\nthat combines a nondominated sorting genetic algorithm with active learning. We\ntest our model on public datasets where we simulate various biased \"black-box\"\nclassifiers (decision-makers) and apply our approach for interpretable\naugmented fairness.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 03:25:44 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wang", "Tong", ""], ["Saar-Tsechansky", "Maytal", ""]]}, {"id": "2011.08406", "submitter": "DongNyeong Heo", "authors": "DongNyeong Heo, Doyoung Lee, Hee-Gon Kim, Suhyun Park, Heeyoul Choi", "title": "Reinforcement Learning of Graph Neural Networks for Service Function\n  Chaining", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the management of computer network systems, the service function chaining\n(SFC) modules play an important role by generating efficient paths for network\ntraffic through physical servers with virtualized network functions (VNF). To\nprovide the highest quality of services, the SFC module should generate a valid\npath quickly even in various network topology situations including dynamic VNF\nresources, various requests, and changes of topologies. The previous supervised\nlearning method demonstrated that the network features can be represented by\ngraph neural networks (GNNs) for the SFC task. However, the performance was\nlimited to only the fixed topology with labeled data. In this paper, we apply\nreinforcement learning methods for training models on various network\ntopologies with unlabeled data. In the experiments, compared to the previous\nsupervised learning method, the proposed methods demonstrated remarkable\nflexibility in new topologies without re-designing and re-training, while\npreserving a similar level of performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 03:50:53 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Heo", "DongNyeong", ""], ["Lee", "Doyoung", ""], ["Kim", "Hee-Gon", ""], ["Park", "Suhyun", ""], ["Choi", "Heeyoul", ""]]}, {"id": "2011.08408", "submitter": "Seungkyu Lee", "authors": "Gahye Lee and Seungkyu Lee", "title": "Sub-clusters of Normal Data for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in data analysis is an interesting but still challenging\nresearch topic in real world applications. As the complexity of data dimension\nincreases, it requires to understand the semantic contexts in its description\nfor effective anomaly characterization. However, existing anomaly detection\nmethods show limited performances with high dimensional data such as ImageNet.\nExisting studies have evaluated their performance on low dimensional, clean and\nwell separated data set such as MNIST and CIFAR-10. In this paper, we study\nanomaly detection with high dimensional and complex normal data. Our\nobservation is that, in general, anomaly data is defined by semantically\nexplainable features which are able to be used in defining semantic\nsub-clusters of normal data as well. We hypothesize that if there exists\nreasonably good feature space semantically separating sub-clusters of given\nnormal data, unseen anomaly also can be well distinguished in the space from\nthe normal data. We propose to perform semantic clustering on given normal data\nand train a classifier to learn the discriminative feature space where anomaly\ndetection is finally performed. Based on our careful and extensive experimental\nevaluations with MNIST, CIFAR-10, and ImageNet with various combinations of\nnormal and anomaly data, we show that our anomaly detection scheme outperforms\nstate of the art methods especially with high dimensional real world images.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 03:53:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lee", "Gahye", ""], ["Lee", "Seungkyu", ""]]}, {"id": "2011.08430", "submitter": "Yueyue Dai", "authors": "Yueyue Dai (Member, IEEE), Ke Zhang, Sabita Maharjan (Senior Member,\n  IEEE), and Yan Zhang (Fellow, IEEE)", "title": "Deep Reinforcement Learning for Stochastic Computation Offloading in\n  Digital Twin Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid development of Industrial Internet of Things (IIoT) requires\nindustrial production towards digitalization to improve network efficiency.\nDigital Twin is a promising technology to empower the digital transformation of\nIIoT by creating virtual models of physical objects. However, the provision of\nnetwork efficiency in IIoT is very challenging due to resource-constrained\ndevices, stochastic tasks, and resources heterogeneity. Distributed resources\nin IIoT networks can be efficiently exploited through computation offloading to\nreduce energy consumption while enhancing data processing efficiency. In this\npaper, we first propose a new paradigm Digital Twin Networks (DTN) to build\nnetwork topology and the stochastic task arrival model in IIoT systems. Then,\nwe formulate the stochastic computation offloading and resource allocation\nproblem to minimize the long-term energy efficiency. As the formulated problem\nis a stochastic programming problem, we leverage Lyapunov optimization\ntechnique to transform the original problem into a deterministic per-time slot\nproblem. Finally, we present Asynchronous Actor-Critic (AAC) algorithm to find\nthe optimal stochastic computation offloading policy. Illustrative results\ndemonstrate that our proposed scheme is able to significantly outperforms the\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 05:40:16 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 02:42:44 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Dai", "Yueyue", "", "Member, IEEE"], ["Zhang", "Ke", "", "Senior Member,\n  IEEE"], ["Maharjan", "Sabita", "", "Senior Member,\n  IEEE"], ["Zhang", "Yan", "", "Fellow, IEEE"]]}, {"id": "2011.08432", "submitter": "Hai Pham", "authors": "Quang Minh Hoang, Trong Nghia Hoang, Hai Pham, David P. Woodruff", "title": "Revisiting the Sample Complexity of Sparse Spectrum Approximation of\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new scalable approximation for Gaussian processes with\nprovable guarantees which hold simultaneously over its entire parameter space.\nOur approximation is obtained from an improved sample complexity analysis for\nsparse spectrum Gaussian processes (SSGPs). In particular, our analysis shows\nthat under a certain data disentangling condition, an SSGP's prediction and\nmodel evidence (for training) can well-approximate those of a full GP with low\nsample complexity. We also develop a new auto-encoding algorithm that finds a\nlatent space to disentangle latent input coordinates into well-separated\nclusters, which is amenable to our sample complexity analysis. We validate our\nproposed method on several benchmarks with promising results supporting our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 05:41:50 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hoang", "Quang Minh", ""], ["Hoang", "Trong Nghia", ""], ["Pham", "Hai", ""], ["Woodruff", "David P.", ""]]}, {"id": "2011.08434", "submitter": "Georgios Kotsalis", "authors": "Georgios Kotsalis and Guanghui Lan and Tianjiao Li", "title": "Simple and optimal methods for stochastic variational inequalities, II:\n  Markovian noise and policy evaluation in reinforcement learning", "comments": "arXiv admin note: text overlap with arXiv:2011.02987", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is on stochastic variational inequalities (VI) under\nMarkovian noise. A prominent application of our algorithmic developments is the\nstochastic policy evaluation problem in reinforcement learning. Prior\ninvestigations in the literature focused on temporal difference (TD) learning\nby employing nonsmooth finite time analysis motivated by stochastic subgradient\ndescent leading to certain limitations. These encompass the requirement of\nanalyzing a modified TD algorithm that involves projection to an a-priori\ndefined Euclidean ball, achieving a non-optimal convergence rate and no clear\nway of deriving the beneficial effects of parallel implementation. Our approach\nremedies these shortcomings in the broader context of stochastic VIs and in\nparticular when it comes to stochastic policy evaluation. We developed a\nvariety of simple TD learning type algorithms motivated by its original version\nthat maintain its simplicity, while offering distinct advantages from a\nnon-asymptotic analysis point of view. We first provide an improved analysis of\nthe standard TD algorithm that can benefit from parallel implementation. Then\nwe present versions of a conditional TD algorithm (CTD), that involves periodic\nupdates of the stochastic iterates, which reduce the bias and therefore exhibit\nimproved iteration complexity. This brings us to the fast TD (FTD) algorithm\nwhich combines elements of CTD and the stochastic operator extrapolation method\nof the companion paper. For a novel index resetting policy FTD exhibits the\nbest known convergence rate. We also devised a robust version of the algorithm\nthat is particularly suitable for discounting factors close to 1.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 04:05:22 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 21:46:54 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 02:57:38 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Kotsalis", "Georgios", ""], ["Lan", "Guanghui", ""], ["Li", "Tianjiao", ""]]}, {"id": "2011.08435", "submitter": "Guo-Jun Qi", "authors": "Qianjiang Hu, Xiao Wang, Wei Hu, Guo-Jun Qi", "title": "AdCo: Adversarial Contrast for Efficient Learning of Unsupervised\n  Representations from Self-Trained Negative Adversaries", "comments": "Appendices with more results on symmetric loss, different numbers of\n  negative samples, computing costs is presented. We also discuss \"whether we\n  still need negative examples\" in Appendix C, a question emerging from the\n  comparison with the BYOL. The source code is also available at\n  https://github.com/maple-research-lab/AdCo/", "journal-ref": "IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR), June 19th - June 25th, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning relies on constructing a collection of negative examples\nthat are sufficiently hard to discriminate against positive queries when their\nrepresentations are self-trained. Existing contrastive learning methods either\nmaintain a queue of negative samples over minibatches while only a small\nportion of them are updated in an iteration, or only use the other examples\nfrom the current minibatch as negatives. They could not closely track the\nchange of the learned representation over iterations by updating the entire\nqueue as a whole, or discard the useful information from the past minibatches.\nAlternatively, we present to directly learn a set of negative adversaries\nplaying against the self-trained representation. Two players, the\nrepresentation network and negative adversaries, are alternately updated to\nobtain the most challenging negative examples against which the representation\nof positive queries will be trained to discriminate. We further show that the\nnegative adversaries are updated towards a weighted combination of positive\nqueries by maximizing the adversarial contrastive loss, thereby allowing them\nto closely track the change of representations over time. Experiment results\ndemonstrate the proposed Adversarial Contrastive (AdCo) model not only achieves\nsuperior performances (a top-1 accuracy of 73.2\\% over 200 epochs and 75.7\\%\nover 800 epochs with linear evaluation on ImageNet), but also can be\npre-trained more efficiently with fewer epochs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 05:45:46 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 23:56:08 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 03:01:28 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 08:44:44 GMT"}, {"version": "v5", "created": "Fri, 5 Mar 2021 07:01:19 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hu", "Qianjiang", ""], ["Wang", "Xiao", ""], ["Hu", "Wei", ""], ["Qi", "Guo-Jun", ""]]}, {"id": "2011.08442", "submitter": "Yueyue Dai", "authors": "Yueyue Dai, Ke Zhang, Sabita Maharjan, and Yan Zhang", "title": "Edge Intelligence for Energy-efficient Computation Offloading and\n  Resource Allocation in 5G Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  5G beyond is an end-edge-cloud orchestrated network that can exploit\nheterogeneous capabilities of the end devices, edge servers, and the cloud and\nthus has the potential to enable computation-intensive and delay-sensitive\napplications via computation offloading. However, in multi user wireless\nnetworks, diverse application requirements and the possibility of various radio\naccess modes for communication among devices make it challenging to design an\noptimal computation offloading scheme. In addition, having access to complete\nnetwork information that includes variables such as wireless channel state, and\navailable bandwidth and computation resources, is a major issue. Deep\nReinforcement Learning (DRL) is an emerging technique to address such an issue\nwith limited and less accurate network information. In this paper, we utilize\nDRL to design an optimal computation offloading and resource allocation\nstrategy for minimizing system energy consumption. We first present a\nmulti-user end-edge-cloud orchestrated network where all devices and base\nstations have computation capabilities. Then, we formulate the joint\ncomputation offloading and resource allocation problem as a Markov Decision\nProcess (MDP) and propose a new DRL algorithm to minimize system energy\nconsumption. Numerical results based on a real-world dataset demonstrate that\nthe proposed DRL-based algorithm significantly outperforms the benchmark\npolicies in terms of system energy consumption. Extensive simulations show that\nlearning rate, discount factor, and number of devices have considerable\ninfluence on the performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 05:51:03 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 02:48:08 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Dai", "Yueyue", ""], ["Zhang", "Ke", ""], ["Maharjan", "Sabita", ""], ["Zhang", "Yan", ""]]}, {"id": "2011.08449", "submitter": "Yueyue Dai", "authors": "Yueyue Dai, Du Xu, Ke Zhang, Sabita Maharjan (Senior Member, IEEE) and\n  Yan Zhang (Fellow, IEEE)", "title": "Deep Reinforcement Learning and Permissioned Blockchain for Content\n  Caching in Vehicular Edge Computing and Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vehicular Edge Computing (VEC) is a promising paradigm to enable huge amount\nof data and multimedia content to be cached in proximity to vehicles. However,\nhigh mobility of vehicles and dynamic wireless channel condition make it\nchallenge to design an optimal content caching policy. Further, with much\nsensitive personal information, vehicles may be not willing to caching their\ncontents to an untrusted caching provider. Deep Reinforcement Learning (DRL) is\nan emerging technique to solve the problem with high-dimensional and\ntime-varying features. Permission blockchain is able to establish a secure and\ndecentralized peer-to-peer transaction environment. In this paper, we integrate\nDRL and permissioned blockchain into vehicular networks for intelligent and\nsecure content caching. We first propose a blockchain empowered distributed\ncontent caching framework where vehicles perform content caching and base\nstations maintain the permissioned blockchain. Then, we exploit the advanced\nDRL approach to design an optimal content caching scheme with taking mobility\ninto account. Finally, we propose a new block verifier selection method,\nProof-of-Utility (PoU), to accelerate block verification process. Security\nanalysis shows that our proposed blockchain empowered content caching can\nachieve security and privacy protection. Numerical results based on a real\ndataset from Uber indicate that the DRL-inspired content caching scheme\nsignificantly outperforms two benchmark policies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:04:21 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 15:24:06 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Dai", "Yueyue", "", "Senior Member, IEEE"], ["Xu", "Du", "", "Senior Member, IEEE"], ["Zhang", "Ke", "", "Senior Member, IEEE"], ["Maharjan", "Sabita", "", "Senior Member, IEEE"], ["Zhang", "Yan", "", "Fellow, IEEE"]]}, {"id": "2011.08450", "submitter": "Jianyi Yang", "authors": "Jianyi Yang, Shaolei Ren", "title": "A Quantitative Perspective on Values of Domain Knowledge for Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the exploding popularity of machine learning, domain knowledge in\nvarious forms has been playing a crucial role in improving the learning\nperformance, especially when training data is limited. Nonetheless, there is\nlittle understanding of to what extent domain knowledge can affect a machine\nlearning task from a quantitative perspective. To increase the transparency and\nrigorously explain the role of domain knowledge in machine learning, we study\nthe problem of quantifying the values of domain knowledge in terms of its\ncontribution to the learning performance in the context of informed machine\nlearning. We propose a quantification method based on Shapley value that fairly\nattributes the overall learning performance improvement to different domain\nknowledge. We also present Monte-Carlo sampling to approximate the fair value\nof domain knowledge with a polynomial time complexity. We run experiments of\ninjecting symbolic domain knowledge into semi-supervised learning tasks on both\nMNIST and CIFAR10 datasets, providing quantitative values of different symbolic\nknowledge and rigorously explaining how it affects the machine learning\nperformance in terms of test accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:12:23 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 09:14:56 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Yang", "Jianyi", ""], ["Ren", "Shaolei", ""]]}, {"id": "2011.08461", "submitter": "Andrei Nicolae Ph.D", "authors": "Andrei Nicolae", "title": "Deep Learning Framework From Scratch Using Numpy", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a rigorous development of a complete and general-purpose deep\nlearning framework from the ground up. The fundamental components of deep\nlearning - automatic differentiation and gradient methods of optimizing\nmultivariable scalar functions - are developed from elementary calculus and\nimplemented in a sensible object-oriented approach using only Python and the\nNumpy library. Demonstrations of solved problems using the framework, named\nArrayFlow, include a computer vision classification task, solving for the shape\nof a catenary, and a 2nd order differential equation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:28:05 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Nicolae", "Andrei", ""]]}, {"id": "2011.08463", "submitter": "R\\'emy Portelas", "authors": "R\\'emy Portelas, Cl\\'ement Romac, Katja Hofmann, Pierre-Yves Oudeyer", "title": "Meta Automatic Curriculum Learning", "comments": "This paper extends and generalizes work in arXiv:2004.03168", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in the Deep RL (DRL) community is to train agents able to\ngeneralize their control policy over situations never seen in training.\nTraining on diverse tasks has been identified as a key ingredient for good\ngeneralization, which pushed researchers towards using rich procedural task\ngeneration systems controlled through complex continuous parameter spaces. In\nsuch complex task spaces, it is essential to rely on some form of Automatic\nCurriculum Learning (ACL) to adapt the task sampling distribution to a given\nlearning agent, instead of randomly sampling tasks, as many could end up being\neither trivial or unfeasible. Since it is hard to get prior knowledge on such\ntask spaces, many ACL algorithms explore the task space to detect progress\nniches over time, a costly tabula-rasa process that needs to be performed for\neach new learning agents, although they might have similarities in their\ncapabilities profiles. To address this limitation, we introduce the concept of\nMeta-ACL, and formalize it in the context of black-box RL learners, i.e.\nalgorithms seeking to generalize curriculum generation to an (unknown)\ndistribution of learners. In this work, we present AGAIN, a first instantiation\nof Meta-ACL, and showcase its benefits for curriculum generation over classical\nACL in multiple simulated environments including procedurally generated parkour\nenvironments with learners of varying morphologies. Videos and code are\navailable at https://sites.google.com/view/meta-acl .\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:56:42 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 16:19:46 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Portelas", "R\u00e9my", ""], ["Romac", "Cl\u00e9ment", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2011.08464", "submitter": "Shichao Li", "authors": "Shichao Li, Zengqiang Yan, Hongyang Li, Kwang-Ting Cheng", "title": "Exploring intermediate representation for monocular vehicle pose\n  estimation", "comments": "CVPR 2021 with supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new learning-based framework to recover vehicle pose in SO(3)\nfrom a single RGB image. In contrast to previous works that map from local\nappearance to observation angles, we explore a progressive approach by\nextracting meaningful Intermediate Geometrical Representations (IGRs) to\nestimate egocentric vehicle orientation. This approach features a deep model\nthat transforms perceived intensities to IGRs, which are mapped to a 3D\nrepresentation encoding object orientation in the camera coordinate system.\nCore problems are what IGRs to use and how to learn them more effectively. We\nanswer the former question by designing IGRs based on an interpolated cuboid\nthat derives from primitive 3D annotation readily. The latter question\nmotivates us to incorporate geometry knowledge with a new loss function based\non a projective invariant. This loss function allows unlabeled data to be used\nin the training stage to improve representation learning. Without additional\nlabels, our system outperforms previous monocular RGB-based methods for joint\nvehicle detection and pose estimation on the KITTI benchmark, achieving\nperformance even comparable to stereo methods. Code and pre-trained models are\navailable at this https URL.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:30:51 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 05:02:20 GMT"}, {"version": "v3", "created": "Tue, 16 Mar 2021 07:20:09 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 09:11:57 GMT"}, {"version": "v5", "created": "Mon, 12 Jul 2021 12:09:45 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Li", "Shichao", ""], ["Yan", "Zengqiang", ""], ["Li", "Hongyang", ""], ["Cheng", "Kwang-Ting", ""]]}, {"id": "2011.08465", "submitter": "Cristian Jes\\'us Vaca Rubio", "authors": "Cristian J. Vaca-Rubio, Pablo Ramirez-Espinosa, Kimmo Kansanen,\n  Zheng-Hua Tan, Elisabeth de Carvalho, Petar Popovski", "title": "Assessing Wireless Sensing Potential with Large Intelligent Surfaces", "comments": "arXiv admin note: text overlap with arXiv:2006.06563", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensing capability is one of the most highlighted new feature of future 6G\nwireless networks. This paper addresses the sensing potential of Large\nIntelligent Surfaces (LIS) in an exemplary Industry 4.0 scenario. Besides the\nattention received by LIS in terms of communication aspects, it can offer a\nhigh-resolution rendering of the propagation environment. This is because, in\nan indoor setting, it can be placed in proximity to the sensed phenomena, while\nthe high resolution is offered by densely spaced tiny antennas deployed over a\nlarge area. By treating an LIS as a radio image of the environment relying on\nthe received signal power, we develop techniques to sense the environment, by\nleveraging the tools of image processing and machine learning. Once a\nholographic image is obtained, a Denoising Autoencoder (DAE) network can be\nused for constructing a super-resolution image leading to sensing advantages\nnot available in traditional sensing systems. Also, we derive a statistical\ntest based on the Generalized Likelihood Ratio (GLRT) as a benchmark for the\nmachine learning solution. We test these methods for a scenario where we need\nto detect whether an industrial robot deviates from a predefined route. The\nresults show that the LIS-based sensing offers high precision and has a high\napplication potential in indoor industrial environments.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:50:22 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 11:27:06 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 19:49:36 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Vaca-Rubio", "Cristian J.", ""], ["Ramirez-Espinosa", "Pablo", ""], ["Kansanen", "Kimmo", ""], ["Tan", "Zheng-Hua", ""], ["de Carvalho", "Elisabeth", ""], ["Popovski", "Petar", ""]]}, {"id": "2011.08470", "submitter": "Yinghui Li", "authors": "Yinghui Li, Ruiyang Liu, ZiHao Zhang, Ning Ding, Ying Shen, Linmi Tao,\n  Hai-Tao Zheng", "title": "Towards All-around Knowledge Transferring: Learning From Task-irrelevant\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural models have hitherto achieved significant performances on\nnumerous classification tasks, but meanwhile require sufficient manually\nannotated data. Since it is extremely time-consuming and expensive to annotate\nadequate data for each classification task, learning an empirically effective\nmodel with generalization on small dataset has received increased attention.\nExisting efforts mainly focus on transferring task-relevant knowledge from\nother similar data to tackle the issue. These approaches have yielded\nremarkable improvements, yet neglecting the fact that the task-irrelevant\nfeatures could bring out massive negative transfer effects. To date, no\nlarge-scale studies have been performed to investigate the impact of\ntask-irrelevant features, let alone the utilization of this kind of features.\nIn this paper, we firstly propose Task-Irrelevant Transfer Learning (TIRTL) to\nexploit task-irrelevant features, which mainly are extracted from\ntask-irrelevant labels. Particularly, we suppress the expression of\ntask-irrelevant information and facilitate the learning process of\nclassification. We also provide a theoretical explanation of our method. In\naddition, TIRTL does not conflict with those that have previously exploited\ntask-relevant knowledge and can be well combined to enable the simultaneous\nutilization of task-relevant and task-irrelevant features for the first time.\nIn order to verify the effectiveness of our theory and method, we conduct\nextensive experiments on facial expression recognition and digit recognition\ntasks. Our source code will be also available in the future for\nreproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:43:58 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Li", "Yinghui", ""], ["Liu", "Ruiyang", ""], ["Zhang", "ZiHao", ""], ["Ding", "Ning", ""], ["Shen", "Ying", ""], ["Tao", "Linmi", ""], ["Zheng", "Hai-Tao", ""]]}, {"id": "2011.08472", "submitter": "Amr Alanwar", "authors": "Amr Alanwar, Anne Koch, Frank Allg\\\"ower, Karl Henrik Johansson", "title": "Data-Driven Reachability Analysis Using Matrix Zonotopes", "comments": "Accepted at 3rd Annual Learning for Dynamics & Control Conference\n  (L4DC), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a data-driven reachability analysis approach for\nunknown system dynamics. Reachability analysis is an essential tool for\nguaranteeing safety properties. However, most current reachability analysis\nheavily relies on the existence of a suitable system model, which is often not\ndirectly available in practice. We instead propose a data-driven reachability\nanalysis approach from noisy data. More specifically, we first provide an\nalgorithm for over-approximating the reachable set of a linear time-invariant\nsystem using matrix zonotopes. Then we introduce an extension for Lipschitz\nnonlinear systems. We provide theoretical guarantees in both cases. Numerical\nexamples show the potential and applicability of the introduced methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:48:23 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 09:07:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Alanwar", "Amr", ""], ["Koch", "Anne", ""], ["Allg\u00f6wer", "Frank", ""], ["Johansson", "Karl Henrik", ""]]}, {"id": "2011.08474", "submitter": "Honglin Yuan", "authors": "Honglin Yuan, Manzil Zaheer, Sashank Reddi", "title": "Federated Composite Optimization", "comments": "Accepted to ICML 2021. Code repository see\n  https://github.com/hongliny/FCO-ICML21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a distributed learning paradigm that scales\non-device learning collaboratively and privately. Standard FL algorithms such\nas FedAvg are primarily geared towards smooth unconstrained settings. In this\npaper, we study the Federated Composite Optimization (FCO) problem, in which\nthe loss function contains a non-smooth regularizer. Such problems arise\nnaturally in FL applications that involve sparsity, low-rank, monotonicity, or\nmore general constraints. We first show that straightforward extensions of\nprimal algorithms such as FedAvg are not well-suited for FCO since they suffer\nfrom the \"curse of primal averaging,\" resulting in poor convergence. As a\nsolution, we propose a new primal-dual algorithm, Federated Dual Averaging\n(FedDualAvg), which by employing a novel server dual averaging procedure\ncircumvents the curse of primal averaging. Our theoretical analysis and\nempirical experiments demonstrate that FedDualAvg outperforms the other\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 06:54:06 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 18:46:15 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 06:32:27 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yuan", "Honglin", ""], ["Zaheer", "Manzil", ""], ["Reddi", "Sashank", ""]]}, {"id": "2011.08482", "submitter": "Haimiao Mo", "authors": "Haimiao Mo, Shuai Ding (Member, IEEE), Shanlin Yang, Xi Zheng (Member,\n  IEEE), Athanasios V. Vasilakos", "title": "The Role of Edge Robotics As-a-Service in Monitoring COVID-19 Infection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning technology has been widely used in edge computing. However,\npandemics like covid-19 require deep learning capabilities at mobile devices\n(detect respiratory rate using mobile robotics or conduct CT scan using a\nmobile scanner), which are severely constrained by the limited storage and\ncomputation resources at the device level. To solve this problem, we propose a\nthree-tier architecture, including robot layers, edge layers, and cloud layers.\nWe adopt this architecture to design a non-contact respiratory monitoring\nsystem to break down respiratory rate calculation tasks. Experimental results\nof respiratory rate monitoring show that the proposed approach in this paper\nsignificantly outperforms other approaches. It is supported by computation time\ncosts with 2.26 ms per frame, 27.48 ms per frame, 0.78 seconds for convolution\noperation, similarity calculation, processing one-minute length respiratory\nsignals, respectively. And the computation time costs of our three-tier\narchitecture are less than that of edge+cloud architecture and cloud\narchitecture. Moreover, we use our three-tire architecture for CT image\ndiagnosis task decomposition. The evaluation of a CT image dataset of COVID-19\nproves that our three-tire architecture is useful for resolving tasks on deep\nlearning networks by edge equipment. There are broad application scenarios in\nsmart hospitals in the future.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 07:33:00 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 08:27:02 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 03:16:01 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Mo", "Haimiao", "", "Member, IEEE"], ["Ding", "Shuai", "", "Member, IEEE"], ["Yang", "Shanlin", "", "Member,\n  IEEE"], ["Zheng", "Xi", "", "Member,\n  IEEE"], ["Vasilakos", "Athanasios V.", ""]]}, {"id": "2011.08483", "submitter": "Ali Shahin Shamsabadi", "authors": "Ali Shahin Shamsabadi, Francisco Sep\\'ulveda Teixeira, Alberto Abad,\n  Bhiksha Raj, Andrea Cavallaro, Isabel Trancoso", "title": "FoolHD: Fooling speaker identification by Highly imperceptible\n  adversarial Disturbances", "comments": "https://fsepteixeira.github.io/FoolHD/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker identification models are vulnerable to carefully designed\nadversarial perturbations of their input signals that induce misclassification.\nIn this work, we propose a white-box steganography-inspired adversarial attack\nthat generates imperceptible adversarial perturbations against a speaker\nidentification model. Our approach, FoolHD, uses a Gated Convolutional\nAutoencoder that operates in the DCT domain and is trained with a\nmulti-objective loss function, in order to generate and conceal the adversarial\nperturbation within the original audio files. In addition to hindering speaker\nidentification performance, this multi-objective loss accounts for human\nperception through a frame-wise cosine similarity between MFCC feature vectors\nextracted from the original and adversarial audio files. We validate the\neffectiveness of FoolHD with a 250-speaker identification x-vector network,\ntrained using VoxCeleb, in terms of accuracy, success rate, and\nimperceptibility. Our results show that FoolHD generates highly imperceptible\nadversarial audio files (average PESQ scores above 4.30), while achieving a\nsuccess rate of 99.6% and 99.2% in misleading the speaker identification model,\nfor untargeted and targeted settings, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 07:38:26 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 12:15:25 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Shamsabadi", "Ali Shahin", ""], ["Teixeira", "Francisco Sep\u00falveda", ""], ["Abad", "Alberto", ""], ["Raj", "Bhiksha", ""], ["Cavallaro", "Andrea", ""], ["Trancoso", "Isabel", ""]]}, {"id": "2011.08484", "submitter": "Joseph Lubars", "authors": "Joseph Lubars, Harsh Gupta, Adnan Raja, R. Srikant, Liyun Li, and\n  Xinzhou Wu", "title": "Combining Reinforcement Learning with Model Predictive Control for\n  On-Ramp Merging", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing an algorithm to allow a car to\nautonomously merge on to a highway from an on-ramp. Two broad classes of\ntechniques have been proposed to solve motion planning problems in autonomous\ndriving: Model Predictive Control (MPC) and Reinforcement Learning (RL). In\nthis paper, we first establish the strengths and weaknesses of state-of-the-art\nMPC and RL-based techniques through simulations. We show that the performance\nof the RL agent is worse than that of the MPC solution from the perspective of\nsafety and robustness to out-of-distribution traffic patterns, i.e., traffic\npatterns which were not seen by the RL agent during training. On the other\nhand, the performance of the RL agent is better than that of the MPC solution\nwhen it comes to efficiency and passenger comfort. We subsequently present an\nalgorithm which blends the model-free RL agent with the MPC solution and show\nthat it provides better trade-offs between all metrics -- passenger comfort,\nefficiency, crash rate and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 07:42:11 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lubars", "Joseph", ""], ["Gupta", "Harsh", ""], ["Raja", "Adnan", ""], ["Srikant", "R.", ""], ["Li", "Liyun", ""], ["Wu", "Xinzhou", ""]]}, {"id": "2011.08485", "submitter": "Yao-Yuan Yang", "authors": "Yao-Yuan Yang, Cyrus Rashtchian, Ruslan Salakhutdinov, Kamalika\n  Chaudhuri", "title": "Robustness and Generalization to Nearest Categories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness has emerged as a desirable property for neural\nnetworks. Prior work shows that robust networks perform well in some\nout-of-distribution generalization tasks, such as transfer learning and outlier\ndetection. We uncover a different kind of out-of-distribution generalization\nproperty of such networks, and find that they also do well in a task that we\ncall nearest category generalization (NCG) - given an out-of-distribution\ninput, they tend to predict the same label as that of the closest training\nexample. We empirically show that this happens even when the\nout-of-distribution inputs lie outside the robustness radius of the training\ndata, which suggests that these networks may generalize better along unseen\ndirections on the natural image manifold than arbitrary unseen directions. We\nexamine how performance changes when we change the robustness regions during\ntraining. We then design experiments to investigate the connection between\nout-of-distribution detection and nearest category generalization. Taken\ntogether, our work provides evidence that robust neural networks may resemble\nnearest neighbor classifiers in their behavior on out-of-distribution data. The\ncode is available at\nhttps://github.com/yangarbiter/nearest-category-generalization\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 07:42:27 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 06:38:12 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 20:30:05 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Yang", "Yao-Yuan", ""], ["Rashtchian", "Cyrus", ""], ["Salakhutdinov", "Ruslan", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2011.08492", "submitter": "Utku Ketenci", "authors": "Utku G\\\"orkem Ketenci and Tolga Kurt and Selim \\\"Onal and Cenk Erbil\n  and Sinan Akt\\\"urko\\u{g}lu and Hande \\c{S}erban \\.Ilhan", "title": "A Time-Frequency based Suspicious Activity Detection for Anti-Money\n  Laundering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Money laundering is the crucial mechanism utilized by criminals to inject\nproceeds of crime to the financial system. The primary responsibility of the\ndetection of suspicious activity related to money laundering is with the\nfinancial institutions. Most of the current systems in these institutions are\nrule-based and ineffective. The available data science-based anti-money\nlaundering (AML) models in order to replace the existing rule-based systems\nwork on customer relationship management (CRM) features and time\ncharacteristics of transaction behaviour. However, there is still a challenge\non accuracy and problems around feature engineering due to thousands of\npossible features.\n  Aiming to improve the detection performance of suspicious transaction\nmonitoring systems for AML systems, in this article, we introduce a novel\nfeature set based on time-frequency analysis, that makes use of 2-D\nrepresentations of financial transactions. Random forest is utilized as a\nmachine learning method, and simulated annealing is adopted for hyperparameter\ntuning. The designed algorithm is tested on real banking data, proving the\nefficacy of the results in practically relevant environments. It is shown that\nthe time-frequency characteristics of suspicious and non-suspicious entities\ndifferentiate significantly, which would substantially improve the precision of\ndata science-based transaction monitoring systems looking at only time-series\ntransaction and CRM features.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 08:01:50 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ketenci", "Utku G\u00f6rkem", ""], ["Kurt", "Tolga", ""], ["\u00d6nal", "Selim", ""], ["Erbil", "Cenk", ""], ["Akt\u00fcrko\u011flu", "Sinan", ""], ["\u0130lhan", "Hande \u015eerban", ""]]}, {"id": "2011.08518", "submitter": "Marvin Chanc\\'an", "authors": "Marvin Chanc\\'an, Michael Milford", "title": "DeepSeqSLAM: A Trainable CNN+RNN for Joint Global Description and\n  Sequence-based Place Recognition", "comments": "9 pages, 6 figures, 2 tables", "journal-ref": "NeurIPS 2020 Workshop on Machine Learning for Autonomous Driving\n  (ML4AD)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequence-based place recognition methods for all-weather navigation are\nwell-known for producing state-of-the-art results under challenging day-night\nor summer-winter transitions. These systems, however, rely on complex\nhandcrafted heuristics for sequential matching - which are applied on top of a\npre-computed pairwise similarity matrix between reference and query image\nsequences of a single route - to further reduce false-positive rates compared\nto single-frame retrieval methods. As a result, performing multi-frame place\nrecognition can be extremely slow for deployment on autonomous vehicles or\nevaluation on large datasets, and fail when using relatively short parameter\nvalues such as a sequence length of 2 frames. In this paper, we propose\nDeepSeqSLAM: a trainable CNN+RNN architecture for jointly learning visual and\npositional representations from a single monocular image sequence of a route.\nWe demonstrate our approach on two large benchmark datasets, Nordland and\nOxford RobotCar - recorded over 728 km and 10 km routes, respectively, each\nduring 1 year with multiple seasons, weather, and lighting conditions. On\nNordland, we compare our method to two state-of-the-art sequence-based methods\nacross the entire route under summer-winter changes using a sequence length of\n2 and show that our approach can get over 72% AUC compared to 27% AUC for Delta\nDescriptors and 2% AUC for SeqSLAM; while drastically reducing the deployment\ntime from around 1 hour to 1 minute against both. The framework code and video\nare available at https://mchancan.github.io/deepseqslam\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 09:14:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Chanc\u00e1n", "Marvin", ""], ["Milford", "Michael", ""]]}, {"id": "2011.08528", "submitter": "Hamza Ilhan", "authors": "Hamza Osman Ilhan, Gorkem Serbes, Nizamettin Aydin", "title": "Decision and Feature Level Fusion of Deep Features Extracted from Public\n  COVID-19 Data-sets", "comments": "20 Pages, 9 Figures, 4 Tables and submitted a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Coronavirus (COVID-19), which is an infectious pulmonary disorder, has\naffected millions of people and has been declared as a global pandemic by the\nWHO. Due to highly contagious nature of COVID-19 and its high possibility of\ncausing severe conditions in the patients, the development of rapid and\naccurate diagnostic tools have gained importance. The real-time reverse\ntranscription-polymerize chain reaction (RT-PCR) is used to detect the presence\nof Coronavirus RNA by using the mucus and saliva mixture samples. But, RT-PCR\nsuffers from having low-sensitivity especially in the early stage. Therefore,\nthe usage of chest radiography has been increasing in the early diagnosis of\nCOVID-19 due to its fast imaging speed, significantly low cost and low dosage\nexposure of radiation. In our study, a computer-aided diagnosis system for\nX-ray images based on convolutional neural networks (CNNs), which can be used\nby radiologists as a supporting tool in COVID-19 detection, has been proposed.\nDeep feature sets extracted by using CNNs were concatenated for feature level\nfusion and fed to multiple classifiers in terms of decision level fusion idea\nwith the aim of discriminating COVID-19, pneumonia and no-finding classes. In\nthe decision level fusion idea, a majority voting scheme was applied to the\nresultant decisions of classifiers. The obtained accuracy values and confusion\nmatrix based evaluation criteria were presented for three progressively created\ndata-sets. The aspects of the proposed method that are superior to existing\nCOVID-19 detection studies have been discussed and the fusion performance of\nproposed approach was validated visually by using Class Activation Mapping\ntechnique. The experimental results show that the proposed approach has\nattained high COVID-19 detection performance that was proven by its comparable\naccuracy and superior precision/recall values with the existing studies.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 09:36:21 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ilhan", "Hamza Osman", ""], ["Serbes", "Gorkem", ""], ["Aydin", "Nizamettin", ""]]}, {"id": "2011.08541", "submitter": "Sreejith Balakrishnan", "authors": "Sreejith Balakrishnan, Quoc Phong Nguyen, Bryan Kian Hsiang Low,\n  Harold Soh", "title": "Efficient Exploration of Reward Functions in Inverse Reinforcement\n  Learning via Bayesian Optimization", "comments": "Accepted to 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020). Includes Appendix. 21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of inverse reinforcement learning (IRL) is relevant to a variety\nof tasks including value alignment and robot learning from demonstration.\nDespite significant algorithmic contributions in recent years, IRL remains an\nill-posed problem at its core; multiple reward functions coincide with the\nobserved behavior and the actual reward function is not identifiable without\nprior knowledge or supplementary information. This paper presents an IRL\nframework called Bayesian optimization-IRL (BO-IRL) which identifies multiple\nsolutions that are consistent with the expert demonstrations by efficiently\nexploring the reward function space. BO-IRL achieves this by utilizing Bayesian\nOptimization along with our newly proposed kernel that (a) projects the\nparameters of policy invariant reward functions to a single point in a latent\nspace and (b) ensures nearby points in the latent space correspond to reward\nfunctions yielding similar likelihoods. This projection allows the use of\nstandard stationary kernels in the latent space to capture the correlations\npresent across the reward function space. Empirical results on synthetic and\nreal-world environments (model-free and model-based) show that BO-IRL discovers\nmultiple reward functions while minimizing the number of expensive exact policy\noptimizations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:17:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Balakrishnan", "Sreejith", ""], ["Nguyen", "Quoc Phong", ""], ["Low", "Bryan Kian Hsiang", ""], ["Soh", "Harold", ""]]}, {"id": "2011.08543", "submitter": "Thu Nguyen", "authors": "Thu Nguyen, Duy Phung, Minh Hoai, Thien Huu Nguyen", "title": "Structural and Functional Decomposition for Personality Image Captioning\n  in a Communication Game", "comments": "10 pages, EMNLP-Findings 2020", "journal-ref": "EMNLP-Findings 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Personality image captioning (PIC) aims to describe an image with a natural\nlanguage caption given a personality trait. In this work, we introduce a novel\nformulation for PIC based on a communication game between a speaker and a\nlistener. The speaker attempts to generate natural language captions while the\nlistener encourages the generated captions to contain discriminative\ninformation about the input images and personality traits. In this way, we\nexpect that the generated captions can be improved to naturally represent the\nimages and express the traits. In addition, we propose to adapt the language\nmodel GPT2 to perform caption generation for PIC. This enables the speaker and\nlistener to benefit from the language encoding capacity of GPT2. Our\nexperiments show that the proposed model achieves the state-of-the-art\nperformance for PIC.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:19:27 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Nguyen", "Thu", ""], ["Phung", "Duy", ""], ["Hoai", "Minh", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "2011.08544", "submitter": "Minyoung Kim", "authors": "Minyoung Kim, Vladimir Pavlovic", "title": "Recursive Inference for Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference networks of traditional Variational Autoencoders (VAEs) are\ntypically amortized, resulting in relatively inaccurate posterior approximation\ncompared to instance-wise variational optimization. Recent semi-amortized\napproaches were proposed to address this drawback; however, their iterative\ngradient update procedures can be computationally demanding. To address these\nissues, in this paper we introduce an accurate amortized inference algorithm.\nWe propose a novel recursive mixture estimation algorithm for VAEs that\niteratively augments the current mixture with new components so as to maximally\nreduce the divergence between the variational and the true posteriors. Using\nthe functional gradient approach, we devise an intuitive learning criteria for\nselecting a new mixture component: the new component has to improve the data\nlikelihood (lower bound) and, at the same time, be as divergent from the\ncurrent mixture distribution as possible, thus increasing representational\ndiversity. Compared to recently proposed boosted variational inference (BVI),\nour method relies on amortized inference in contrast to BVI's non-amortized\nsingle optimization instance. A crucial benefit of our approach is that the\ninference at test time requires a single feed-forward pass through the mixture\ninference network, making it significantly faster than the semi-amortized\napproaches. We show that our approach yields higher test data likelihood than\nthe state-of-the-art on several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:22:12 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kim", "Minyoung", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "2011.08545", "submitter": "Lorenzo Valerio", "authors": "Lorenzo Valerio, Franco Maria Nardini, Andrea Passarella and Raffaele\n  Perego", "title": "Dynamic Hard Pruning of Neural Networks at the Edge of the Internet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Networks (NN), although successfully applied to several Artificial\nIntelligence tasks, are often unnecessarily over-parametrized. In fog/edge\ncomputing, this might make their training prohibitive on resource-constrained\ndevices, contrasting with the current trend of decentralising intelligence from\nremote data-centres to local constrained devices. Therefore, we investigate the\nproblem of training effective NN models on constrained devices having a fixed,\npotentially small, memory budget. We target techniques that are both\nresource-efficient and performance effective while enabling significant network\ncompression. Our technique, called Dynamic Hard Pruning (DynHP), incrementally\nprunes the network during training, identifying neurons that marginally\ncontribute to the model accuracy. DynHP enables a tunable size reduction of the\nfinal neural network and reduces the NN memory occupancy during training. Freed\nmemory is reused by a \\emph{dynamic batch sizing} approach to counterbalance\nthe accuracy degradation caused by the hard pruning strategy, improving its\nconvergence and effectiveness. We assess the performance of DynHP through\nreproducible experiments on two public datasets, comparing them against\nreference competitors. Results show that DynHP compresses a NN up to $10$ times\nwithout significant performance drops (up to $5\\%$ relative error w.r.t.\ncompetitors), reducing up to $80\\%$ the training memory occupancy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:23:28 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 07:36:04 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Valerio", "Lorenzo", ""], ["Nardini", "Franco Maria", ""], ["Passarella", "Andrea", ""], ["Perego", "Raffaele", ""]]}, {"id": "2011.08558", "submitter": "Liping Yuan", "authors": "Liping Yuan, Xiaoqing Zheng, Yi Zhou, Cho-Jui Hsieh, Kai-wei Chang,\n  Xuanjing Huang", "title": "Generating universal language adversarial examples by understanding and\n  enhancing the transferability across neural models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural network models are vulnerable to adversarial attacks. In many\ncases, malicious inputs intentionally crafted for one model can fool another\nmodel in the black-box attack setting. However, there is a lack of systematic\nstudies on the transferability of adversarial examples and how to generate\nuniversal adversarial examples. In this paper, we systematically study the\ntransferability of adversarial attacks for text classification models. In\nparticular, we conduct extensive experiments to investigate how various\nfactors, such as network architecture, input format, word embedding, and model\ncapacity, affect the transferability of adversarial attacks. Based on these\nstudies, we then propose universal black-box attack algorithms that can induce\nadversarial examples to attack almost all existing models. These universal\nadversarial examples reflect the defects of the learning process and the bias\nin the training dataset. Finally, we generalize these adversarial examples into\nuniversal word replacement rules that can be used for model diagnostics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 10:45:05 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 02:05:43 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yuan", "Liping", ""], ["Zheng", "Xiaoqing", ""], ["Zhou", "Yi", ""], ["Hsieh", "Cho-Jui", ""], ["Chang", "Kai-wei", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2011.08562", "submitter": "Osman Berke Guney", "authors": "Osman Berke Guney, Muhtasham Oblokulov and Huseyin Ozkan", "title": "A Deep Neural Network for SSVEP-based Brain-Computer Interfaces", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target identification in brain-computer interface (BCI) spellers refers to\nthe electroencephalogram (EEG) classification for predicting the target\ncharacter that the subject intends to spell. When the visual stimulus of each\ncharacter is tagged with a distinct frequency, the EEG records steady-state\nvisually evoked potentials (SSVEP) whose spectrum is dominated by the harmonics\nof the target frequency. In this setting, we address the target identification\nand propose a novel deep neural network (DNN) architecture. The proposed DNN\nprocesses the multi-channel SSVEP with convolutions across the sub-bands of\nharmonics, channels, time, and classifies at the fully connected layer. We test\nwith two publicly available large scale (the benchmark and BETA) datasets\nconsisting of in total 105 subjects with 40 characters. Our first stage\ntraining learns a global model by exploiting the statistical commonalities\namong all subjects, and the second stage fine tunes to each subject separately\nby exploiting the individualities. Our DNN strongly outperforms the\nstate-of-the-art on both datasets, by achieving impressive information transfer\nrates 265.23 bits/min and 196.59 bits/min, respectively, with only 0.4 seconds\nof stimulation. To our best knowledge, our rates are the highest ever reported\nperformance results on these datasets. The code is available for\nreproducibility at https://github.com/osmanberke/Deep-SSVEP-BCI.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:11:19 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 09:36:44 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Guney", "Osman Berke", ""], ["Oblokulov", "Muhtasham", ""], ["Ozkan", "Huseyin", ""]]}, {"id": "2011.08567", "submitter": "Jacobo Ayensa-Jim\\'enez", "authors": "Jacobo Ayensa-Jim\\'enez, Mohamed H. Doweidar, Jose Antonio\n  Sanz-Herrera, Manuel Doblar\\'e", "title": "Identification of state functions by physically-guided neural networks\n  with physically-meaningful internal layers", "comments": "40 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substitution of well-grounded theoretical models by data-driven predictions\nis not as simple in engineering and sciences as it is in social and economic\nfields. Scientific problems suffer most times from paucity of data, while they\nmay involve a large number of variables and parameters that interact in complex\nand non-stationary ways, obeying certain physical laws. Moreover, a\nphysically-based model is not only useful for making predictions, but to gain\nknowledge by the interpretation of its structure, parameters, and mathematical\nproperties. The solution to these shortcomings seems to be the seamless\nblending of the tremendous predictive power of the data-driven approach with\nthe scientific consistency and interpretability of physically-based models. We\nuse here the concept of physically-constrained neural networks (PCNN) to\npredict the input-output relation in a physical system, while, at the same time\nfulfilling the physical constraints. With this goal, the internal hidden state\nvariables of the system are associated with a set of internal neuron layers,\nwhose values are constrained by known physical relations, as well as any\nadditional knowledge on the system. Furthermore, when having enough data, it is\npossible to infer knowledge about the internal structure of the system and, if\nparameterized, to predict the state parameters for a particular input-output\nrelation. We show that this approach, besides getting physically-based\npredictions, accelerates the training process, reduces the amount of data\nrequired to get similar accuracy, filters partly the intrinsic noise in the\nexperimental data and provides improved extrapolation capacity.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:26:37 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ayensa-Jim\u00e9nez", "Jacobo", ""], ["Doweidar", "Mohamed H.", ""], ["Sanz-Herrera", "Jose Antonio", ""], ["Doblar\u00e9", "Manuel", ""]]}, {"id": "2011.08575", "submitter": "Harsh Maheshwari", "authors": "Shreyas S, Harsh Maheshwari, Avijit Saha, Samik Datta, Shashank Jain,\n  Disha Makhija, Anuj Nagpal, Sneha Shukla, Suyash S", "title": "Audience Creation for Consumables -- Simple and Scalable Precision\n  Merchandising for a Growing Marketplace", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Consumable categories, such as grocery and fast-moving consumer goods, are\nquintessential to the growth of e-commerce marketplaces in developing\ncountries. In this work, we present the design and implementation of a\nprecision merchandising system, which creates audience sets from over 10\nmillion consumers and is deployed at Flipkart Supermart, one of the largest\nonline grocery stores in India. We employ temporal point process to model the\nlatent periodicity and mutual-excitation in the purchase dynamics of\nconsumables. Further, we develop a likelihood-free estimation procedure that is\nrobust against data sparsity, censure and noise typical of a growing\nmarketplace. Lastly, we scale the inference by quantizing the triggering\nkernels and exploiting sparse matrix-vector multiplication primitive available\non a commercial distributed linear algebra backend. In operation spanning more\nthan a year, we have witnessed a consistent increase in click-through rate in\nthe range of 25-70% for banner-based merchandising in the storefront, and in\nthe range of 12-26% for push notification-based campaigns.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:46:38 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["S", "Shreyas", ""], ["Maheshwari", "Harsh", ""], ["Saha", "Avijit", ""], ["Datta", "Samik", ""], ["Jain", "Shashank", ""], ["Makhija", "Disha", ""], ["Nagpal", "Anuj", ""], ["Shukla", "Sneha", ""], ["S", "Suyash", ""]]}, {"id": "2011.08579", "submitter": "Burak Hasircioglu", "authors": "Burak Hasircioglu, Deniz Gunduz", "title": "Private Wireless Federated Learning with Anonymous Over-the-Air\n  Computation", "comments": "To appear in IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional federated learning (FL), differential privacy (DP) guarantees\ncan be obtained by injecting additional noise to local model updates before\ntransmitting to the parameter server (PS). In the wireless FL scenario, we show\nthat the privacy of the system can be boosted by exploiting over-the-air\ncomputation (OAC) and anonymizing the transmitting devices. In OAC, devices\ntransmit their model updates simultaneously and in an uncoded fashion,\nresulting in a much more efficient use of the available spectrum. We further\nexploit OAC to provide anonymity for the transmitting devices. The proposed\napproach improves the performance of private wireless FL by reducing the amount\nof noise that must be injected.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:53:58 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 21:37:31 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hasircioglu", "Burak", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2011.08595", "submitter": "Jiyang Xie", "authors": "Jiyang Xie and Zhanyu Ma and Jing-Hao Xue and Guoqiang Zhang and Jun\n  Guo", "title": "DS-UI: Dual-Supervised Mixture of Gaussian Mixture Models for\n  Uncertainty Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a dual-supervised uncertainty inference (DS-UI) framework\nfor improving Bayesian estimation-based uncertainty inference (UI) in deep\nneural network (DNN)-based image recognition. In the DS-UI, we combine the\nclassifier of a DNN, i.e., the last fully-connected (FC) layer, with a mixture\nof Gaussian mixture models (MoGMM) to obtain an MoGMM-FC layer. Unlike existing\nUI methods for DNNs, which only calculate the means or modes of the DNN\noutputs' distributions, the proposed MoGMM-FC layer acts as a probabilistic\ninterpreter for the features that are inputs of the classifier to directly\ncalculate the probability density of them for the DS-UI. In addition, we\npropose a dual-supervised stochastic gradient-based variational Bayes (DS-SGVB)\nalgorithm for the MoGMM-FC layer optimization. Unlike conventional SGVB and\noptimization algorithms in other UI methods, the DS-SGVB not only models the\nsamples in the specific class for each Gaussian mixture model (GMM) in the\nMoGMM, but also considers the negative samples from other classes for the GMM\nto reduce the intra-class distances and enlarge the inter-class margins\nsimultaneously for enhancing the learning ability of the MoGMM-FC layer in the\nDS-UI. Experimental results show the DS-UI outperforms the state-of-the-art UI\nmethods in misclassification detection. We further evaluate the DS-UI in\nopen-set out-of-domain/-distribution detection and find statistically\nsignificant improvements. Visualizations of the feature spaces demonstrate the\nsuperiority of the DS-UI.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 12:35:02 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Xie", "Jiyang", ""], ["Ma", "Zhanyu", ""], ["Xue", "Jing-Hao", ""], ["Zhang", "Guoqiang", ""], ["Guo", "Jun", ""]]}, {"id": "2011.08596", "submitter": "Jonathan Crabb\\'e", "authors": "Jonathan Crabb\\'e, Yao Zhang, William Zame, Mihaela van der Schaar", "title": "Learning outside the Black-Box: The pursuit of interpretable models", "comments": "presented in 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)\n  17838-17849", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning has proved its ability to produce accurate models but the\ndeployment of these models outside the machine learning community has been\nhindered by the difficulties of interpreting these models. This paper proposes\nan algorithm that produces a continuous global interpretation of any given\ncontinuous black-box function. Our algorithm employs a variation of projection\npursuit in which the ridge functions are chosen to be Meijer G-functions,\nrather than the usual polynomial splines. Because Meijer G-functions are\ndifferentiable in their parameters, we can tune the parameters of the\nrepresentation by gradient descent; as a consequence, our algorithm is\nefficient. Using five familiar data sets from the UCI repository and two\nfamiliar machine learning algorithms, we demonstrate that our algorithm\nproduces global interpretations that are both highly accurate and parsimonious\n(involve a small number of terms). Our interpretations permit easy\nunderstanding of the relative importance of features and feature interactions.\nOur interpretation algorithm represents a leap forward from the previous state\nof the art.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 12:39:44 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Crabb\u00e9", "Jonathan", ""], ["Zhang", "Yao", ""], ["Zame", "William", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2011.08605", "submitter": "Roman Kolcun", "authors": "Roman Kolcun (1), Diana Andreea Popescu (2), Vadim Safronov (2),\n  Poonam Yadav (3), Anna Maria Mandalari (1), Yiming Xie (1), Richard Mortier\n  (2) and Hamed Haddadi (1) ((1) Imperial College London, (2) University of\n  Cambridge, (3) University of York)", "title": "The Case for Retraining of ML Models for IoT Device Identification at\n  the Edge", "comments": "13 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet-of-Things (IoT) devices are known to be the source of many security\nproblems, and as such they would greatly benefit from automated management.\nThis requires robustly identifying devices so that appropriate network security\npolicies can be applied. We address this challenge by exploring how to\naccurately identify IoT devices based on their network behavior, using\nresources available at the edge of the network.\n  In this paper, we compare the accuracy of five different machine learning\nmodels (tree-based and neural network-based) for identifying IoT devices by\nusing packet trace data from a large IoT test-bed, showing that all models need\nto be updated over time to avoid significant degradation in accuracy. In order\nto effectively update the models, we find that it is necessary to use data\ngathered from the deployment environment, e.g., the household. We therefore\nevaluate our approach using hardware resources and data sources representative\nof those that would be available at the edge of the network, such as in an IoT\ndeployment. We show that updating neural network-based models at the edge is\nfeasible, as they require low computational and memory resources and their\nstructure is amenable to being updated. Our results show that it is possible to\nachieve device identification and categorization with over 80% and 90% accuracy\nrespectively at the edge.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:01:04 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kolcun", "Roman", ""], ["Popescu", "Diana Andreea", ""], ["Safronov", "Vadim", ""], ["Yadav", "Poonam", ""], ["Mandalari", "Anna Maria", ""], ["Xie", "Yiming", ""], ["Mortier", "Richard", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2011.08611", "submitter": "Changpeng Shao", "authors": "Ashley Montanaro and Changpeng Shao", "title": "Quantum algorithms for learning a hidden graph and beyond", "comments": "24 pages, some typos are fixed, the title is changed a little bit", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of learning an unknown graph provided via an oracle\nusing a quantum algorithm. We consider three query models. In the first model\n(\"OR queries\"), the oracle returns whether a given subset of the vertices\ncontains any edges. In the second (\"parity queries\"), the oracle returns the\nparity of the number of edges in a subset. In the third model, we are given\ncopies of the graph state corresponding to the graph.\n  We give quantum algorithms that achieve speedups over the best possible\nclassical algorithms in the OR and parity query models, for some families of\ngraphs, and give quantum algorithms in the graph state model whose complexity\nis similar to the parity query model. For some parameter regimes, the speedups\ncan be exponential in the parity query model. On the other hand, without any\npromise on the graph, no speedup is possible in the OR query model.\n  A main technique we use is the quantum algorithm for solving the\ncombinatorial group testing problem, for which a query-efficient quantum\nalgorithm was given by Belovs. Here we additionally give a time-efficient\nquantum algorithm for this problem, based on the algorithm of Ambainis et al.\\\nfor a \"gapped\" version of the group testing problem. We also give simple\ntime-efficient quantum algorithms based on Fourier sampling and amplitude\namplification for learning the exact-half and majority functions, which almost\nmatch the optimal complexity of Belovs' algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:12:43 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 10:43:50 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Montanaro", "Ashley", ""], ["Shao", "Changpeng", ""]]}, {"id": "2011.08612", "submitter": "Jing Zhang", "authors": "Jing Zhang and Dacheng Tao", "title": "Empowering Things with Intelligence: A Survey of the Progress,\n  Challenges, and Opportunities in Artificial Intelligence of Things", "comments": "Accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Internet of Things (IoT) era, billions of sensors and devices collect\nand process data from the environment, transmit them to cloud centers, and\nreceive feedback via the internet for connectivity and perception. However,\ntransmitting massive amounts of heterogeneous data, perceiving complex\nenvironments from these data, and then making smart decisions in a timely\nmanner are difficult. Artificial intelligence (AI), especially deep learning,\nis now a proven success in various areas including computer vision, speech\nrecognition, and natural language processing. AI introduced into the IoT\nheralds the era of artificial intelligence of things (AIoT). This paper\npresents a comprehensive survey on AIoT to show how AI can empower the IoT to\nmake it faster, smarter, greener, and safer. Specifically, we briefly present\nthe AIoT architecture in the context of cloud computing, fog computing, and\nedge computing. Then, we present progress in AI research for IoT from four\nperspectives: perceiving, learning, reasoning, and behaving. Next, we summarize\nsome promising applications of AIoT that are likely to profoundly reshape our\nworld. Finally, we highlight the challenges facing AIoT and some potential\nresearch opportunities.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:14:28 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zhang", "Jing", ""], ["Tao", "Dacheng", ""]]}, {"id": "2011.08614", "submitter": "P Aditya Sreekar", "authors": "P Aditya Sreekar, Ujjwal Tiwari and Anoop Namboodiri", "title": "Mutual Information Based Method for Unsupervised Disentanglement of\n  Video Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video Prediction is an interesting and challenging task of predicting future\nframes from a given set context frames that belong to a video sequence. Video\nprediction models have found prospective applications in Maneuver Planning,\nHealth care, Autonomous Navigation and Simulation. One of the major challenges\nin future frame generation is due to the high dimensional nature of visual\ndata. In this work, we propose Mutual Information Predictive Auto-Encoder\n(MIPAE) framework, that reduces the task of predicting high dimensional video\nframes by factorising video representations into content and low dimensional\npose latent variables that are easy to predict. A standard LSTM network is used\nto predict these low dimensional pose representations. Content and the\npredicted pose representations are decoded to generate future frames. Our\napproach leverages the temporal structure of the latent generative factors of a\nvideo and a novel mutual information loss to learn disentangled video\nrepresentations. We also propose a metric based on mutual information gap (MIG)\nto quantitatively access the effectiveness of disentanglement on DSprites and\nMPI3D-real datasets. MIG scores corroborate with the visual superiority of\nframes predicted by MIPAE. We also compare our method quantitatively on\nevaluation metrics LPIPS, SSIM and PSNR.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:16:07 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Sreekar", "P Aditya", ""], ["Tiwari", "Ujjwal", ""], ["Namboodiri", "Anoop", ""]]}, {"id": "2011.08618", "submitter": "Dongxiao Zhang", "authors": "Nanzhe Wang, Haibin Chang, Dongxiao Zhang", "title": "Theory-guided Auto-Encoder for Surrogate Construction and Inverse\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A Theory-guided Auto-Encoder (TgAE) framework is proposed for surrogate\nconstruction and is further used for uncertainty quantification and inverse\nmodeling tasks. The framework is built based on the Auto-Encoder (or\nEncoder-Decoder) architecture of convolutional neural network (CNN) via a\ntheory-guided training process. In order to achieve the theory-guided training,\nthe governing equations of the studied problems can be discretized and the\nfinite difference scheme of the equations can be embedded into the training of\nCNN. The residual of the discretized governing equations as well as the data\nmismatch constitute the loss function of the TgAE. The trained TgAE can be used\nto construct a surrogate that approximates the relationship between the model\nparameters and responses with limited labeled data. In order to test the\nperformance of the TgAE, several subsurface flow cases are introduced. The\nresults show the satisfactory accuracy of the TgAE surrogate and efficiency of\nuncertainty quantification tasks can be improved with the TgAE surrogate. The\nTgAE also shows good extrapolation ability for cases with different correlation\nlengths and variances. Furthermore, the parameter inversion task has been\nimplemented with the TgAE surrogate and satisfactory results can be obtained.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:23:03 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wang", "Nanzhe", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2011.08634", "submitter": "Hamed Damirchi", "authors": "Hamed Damirchi, Rooholla Khorrambakht and Hamid D. Taghirad", "title": "Exploring Self-Attention for Visual Odometry", "comments": "8 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual odometry networks commonly use pretrained optical flow networks in\norder to derive the ego-motion between consecutive frames. The features\nextracted by these networks represent the motion of all the pixels between\nframes. However, due to the existence of dynamic objects and texture-less\nsurfaces in the scene, the motion information for every image region might not\nbe reliable for inferring odometry due to the ineffectiveness of dynamic\nobjects in derivation of the incremental changes in position. Recent works in\nthis area lack attention mechanisms in their structures to facilitate dynamic\nreweighing of the feature maps for extracting more refined egomotion\ninformation. In this paper, we explore the effectiveness of self-attention in\nvisual odometry. We report qualitative and quantitative results against the\nSOTA methods. Furthermore, saliency-based studies alongside specially designed\nexperiments are utilized to investigate the effect of self-attention on VO. Our\nexperiments show that using self-attention allows for the extraction of better\nfeatures while achieving a better odometry performance compared to networks\nthat lack such structures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 13:53:26 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Damirchi", "Hamed", ""], ["Khorrambakht", "Rooholla", ""], ["Taghirad", "Hamid D.", ""]]}, {"id": "2011.08649", "submitter": "Zerong Xi", "authors": "Zerong Xi, Gita Sukthankar", "title": "Leveraging the Variance of Return Sequences for Exploration Policy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a method for constructing an upper bound for\nexploration policy using either the weighted variance of return sequences or\nthe weighted temporal difference (TD) error. We demonstrate that the variance\nof the return sequence for a specific state-action pair is an important\ninformation source that can be leveraged to guide exploration in reinforcement\nlearning. The intuition is that fluctuation in the return sequence indicates\ngreater uncertainty in the near future returns. This divergence occurs because\nof the cyclic nature of value-based reinforcement learning; the evolving value\nfunction begets policy improvements which in turn modify the value function.\nAlthough both variance and TD errors capture different aspects of this\nuncertainty, our analysis shows that both can be valuable to guide exploration.\nWe propose a two-stream network architecture to estimate weighted variance/TD\nerrors within DQN agents for our exploration method and show that it\noutperforms the baseline on a wide range of Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 14:19:22 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Xi", "Zerong", ""], ["Sukthankar", "Gita", ""]]}, {"id": "2011.08651", "submitter": "P Aditya Sreekar", "authors": "P Aditya Sreekar, Ujjwal Tiwari and Anoop Namboodiri", "title": "Reducing the Variance of Variational Estimates of Mutual Information by\n  Limiting the Critic's Hypothesis Space to RKHS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mutual information (MI) is an information-theoretic measure of dependency\nbetween two random variables. Several methods to estimate MI, from samples of\ntwo random variables with unknown underlying probability distributions have\nbeen proposed in the literature. Recent methods realize parametric probability\ndistributions or critic as a neural network to approximate unknown density\nratios. The approximated density ratios are used to estimate different\nvariational lower bounds of MI. While these methods provide reliable estimation\nwhen the true MI is low, they produce high variance estimates in cases of high\nMI. We argue that the high variance characteristic is due to the uncontrolled\ncomplexity of the critic's hypothesis space. In support of this argument, we\nuse the data-driven Rademacher complexity of the hypothesis space associated\nwith the critic's architecture to analyse generalization error bound of\nvariational lower bound estimates of MI. In the proposed work, we show that it\nis possible to negate the high variance characteristics of these estimators by\nconstraining the critic's hypothesis space to Reproducing Hilbert Kernel Space\n(RKHS), which corresponds to a kernel learned using Automated Spectral Kernel\nLearning (ASKL). By analysing the aforementioned generalization error bounds,\nwe augment the overall optimisation objective with effective regularisation\nterm. We empirically demonstrate the efficacy of this regularization in\nenforcing proper bias variance tradeoff on four variational lower bounds,\nnamely NWJ, MINE, JS and SMILE.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 14:32:48 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Sreekar", "P Aditya", ""], ["Tiwari", "Ujjwal", ""], ["Namboodiri", "Anoop", ""]]}, {"id": "2011.08657", "submitter": "Corneel Casert", "authors": "Corneel Casert, Tom Vieijra, Stephen Whitelam, Isaac Tamblyn", "title": "Dynamical large deviations of two-dimensional kinetically constrained\n  models using a neural-network state ansatz", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a neural network ansatz originally designed for the variational\noptimization of quantum systems to study dynamical large deviations in\nclassical ones. We obtain the scaled cumulant-generating function for the\ndynamical activity of the Fredrickson-Andersen model, a prototypical\nkinetically constrained model, in one and two dimensions, and present the first\nsize-scaling analysis of the dynamical activity in two dimensions. These\nresults provide a new route to the study of dynamical large-deviation\nfunctions, and highlight the broad applicability of the neural-network state\nansatz across domains in physics.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 14:39:47 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Casert", "Corneel", ""], ["Vieijra", "Tom", ""], ["Whitelam", "Stephen", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "2011.08663", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley, Ole Kristian Ekseth, Jan Fesl, Seiichi Gohshi,\n  Marc Kurz, Hans-Werner Sehring", "title": "Occams Razor for Big Data? On Detecting Quality in Large Unstructured\n  Datasets", "comments": null, "journal-ref": "Appl. Sci. 2019, 9, 3065", "doi": "10.3390/app9153065", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting quality in large unstructured datasets requires capacities far\nbeyond the limits of human perception and communicability and, as a result,\nthere is an emerging trend towards increasingly complex analytic solutions in\ndata science to cope with this problem. This new trend towards analytic\ncomplexity represents a severe challenge for the principle of parsimony or\nOccams Razor in science. This review article combines insight from various\ndomains such as physics, computational science, data engineering, and cognitive\nscience to review the specific properties of big data. Problems for detecting\ndata quality without losing the principle of parsimony are then highlighted on\nthe basis of specific examples. Computational building block approaches for\ndata clustering can help to deal with large unstructured datasets in minimized\ncomputation time, and meaning can be extracted rapidly from large sets of\nunstructured image or video data parsimoniously through relatively simple\nunsupervised machine learning algorithms. Why we still massively lack in\nexpertise for exploiting big data wisely to extract relevant information for\nspecific tasks, recognize patterns, generate new information, or store and\nfurther process large amounts of sensor data is then reviewed; examples\nillustrating why we need subjective views and pragmatic methods to analyze big\ndata contents are brought forward. The review concludes on how cultural\ndifferences between East and West are likely to affect the course of big data\nanalytics, and the development of increasingly autonomous artificial\nintelligence aimed at coping with the big data deluge in the near future.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 16:06:01 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Dresp-Langley", "Birgitta", ""], ["Ekseth", "Ole Kristian", ""], ["Fesl", "Jan", ""], ["Gohshi", "Seiichi", ""], ["Kurz", "Marc", ""], ["Sehring", "Hans-Werner", ""]]}, {"id": "2011.08671", "submitter": "Dilusha Weeraddana Dr", "authors": "Dilusha Weeraddana, Sudaraka MallawaArachchi, Tharindu Warnakula,\n  Zhidong Li, and Yang Wang", "title": "Long-Term Pipeline Failure Prediction Using Nonparametric Survival\n  Analysis", "comments": "ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Australian water infrastructure is more than a hundred years old, thus has\nbegun to show its age through water main failures. Our work concerns\napproximately half a million pipelines across major Australian cities that\ndeliver water to houses and businesses, serving over five million customers.\nFailures on these buried assets cause damage to properties and water supply\ndisruptions. We applied Machine Learning techniques to find a cost-effective\nsolution to the pipe failure problem in these Australian cities, where on\naverage 1500 of water main failures occur each year. To achieve this objective,\nwe construct a detailed picture and understanding of the behaviour of the water\npipe network by developing a Machine Learning model to assess and predict the\nfailure likelihood of water main breaking using historical failure records,\ndescriptors of pipes and other environmental factors. Our results indicate that\nour system incorporating a nonparametric survival analysis technique called\n\"Random Survival Forest\" outperforms several popular algorithms and expert\nheuristics in long-term prediction. In addition, we construct a statistical\ninference technique to quantify the uncertainty associated with the long-term\npredictions.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 02:31:31 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Weeraddana", "Dilusha", ""], ["MallawaArachchi", "Sudaraka", ""], ["Warnakula", "Tharindu", ""], ["Li", "Zhidong", ""], ["Wang", "Yang", ""]]}, {"id": "2011.08673", "submitter": "Marius Stan", "authors": "Jessica Pan, Joseph A. Libera, Noah H. Paulson and Marius Stan", "title": "Flame Stability Analysis of Flame Spray Pyrolysis by Artificial\n  Intelligence", "comments": "25 pages, 8 figures. International Journal of Advanced Manufacturing\n  Technology 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flame spray pyrolysis (FSP) is a process used to synthesize nanoparticles\nthrough the combustion of an atomized precursor solution; this process has\napplications in catalysts, battery materials, and pigments. Current limitations\nrevolve around understanding how to consistently achieve a stable flame and the\nreliable production of nanoparticles. Machine learning and artificial\nintelligence algorithms that detect unstable flame conditions in real time may\nbe a means of streamlining the synthesis process and improving FSP efficiency.\nIn this study, the FSP flame stability is first quantified by analyzing the\nbrightness of the flame's anchor point. This analysis is then used to label\ndata for both unsupervised and supervised machine learning approaches. The\nunsupervised learning approach allows for autonomous labelling and\nclassification of new data by representing data in a reduced dimensional space\nand identifying combinations of features that most effectively cluster it. The\nsupervised learning approach, on the other hand, requires human labeling of\ntraining and test data, but is able to classify multiple objects of interest\n(such as the burner and pilot flames) within the video feed. The accuracy of\neach of these techniques is compared against the evaluations of human experts.\nBoth the unsupervised and supervised approaches can track and classify FSP\nflame conditions in real time to alert users of unstable flame conditions. This\nresearch has the potential to autonomously track and manage flame spray\npyrolysis as well as other flame technologies by monitoring and classifying the\nflame stability.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 22:52:13 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Pan", "Jessica", ""], ["Libera", "Joseph A.", ""], ["Paulson", "Noah H.", ""], ["Stan", "Marius", ""]]}, {"id": "2011.08674", "submitter": "Xi Zhang", "authors": "Xi Zhang and Xiaolin Wu", "title": "On Numerosity of Deep Neural Networks", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a provocative claim was published that number sense spontaneously\nemerges in a deep neural network trained merely for visual object recognition.\nThis has, if true, far reaching significance to the fields of machine learning\nand cognitive science alike. In this paper, we prove the above claim to be\nunfortunately incorrect. The statistical analysis to support the claim is\nflawed in that the sample set used to identify number-aware neurons is too\nsmall, compared to the huge number of neurons in the object recognition\nnetwork. By this flawed analysis one could mistakenly identify number-sensing\nneurons in any randomly initialized deep neural networks that are not trained\nat all. With the above critique we ask the question what if a deep\nconvolutional neural network is carefully trained for numerosity? Our findings\nare mixed. Even after being trained with number-depicting images, the deep\nlearning approach still has difficulties to acquire the abstract concept of\nnumbers, a cognitive task that preschoolers perform with ease. But on the other\nhand, we do find some encouraging evidences suggesting that deep neural\nnetworks are more robust to distribution shift for small numbers than for large\nnumbers.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 15:30:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Zhang", "Xi", ""], ["Wu", "Xiaolin", ""]]}, {"id": "2011.08676", "submitter": "Talha Bin Masood", "authors": "Wito Engelke, Talha Bin Masood, Jakob Beran, Rodrigo Caballero and\n  Ingrid Hotz", "title": "Topology-Based Feature Design and Tracking for Multi-Center Cyclones", "comments": "13 pages, 9 figures, 8th workshop on Topological Methods in Data\n  Analysis and Visualization (TopoInVis 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a concept to design, track, and compare\napplication-specific feature definitions expressed as sets of critical points.\nOur work has been inspired by the observation that in many applications a large\nvariety of different feature definitions for the same concept are used. Often,\nthese definitions compete with each other and it is unclear which definition\nshould be used in which context. A prominent example is the definition of\ncyclones in climate research. Despite the differences, frequently these feature\ndefinitions can be related to topological concepts.\n  In our approach, we provide a cyclone tracking framework that supports\ninteractive feature definition and comparison based on a precomputed tracking\ngraph that stores all extremal points as well as their temporal correspondents.\nThe framework combines a set of independent building blocks: critical point\nextraction, critical point tracking, feature definition, and track exploration.\nOne of the major advantages of such an approach is the flexibility it provides,\nthat is, each block is exchangeable. Moreover, it also enables us to perform\nthe most expensive analysis, the construction of a full tracking graph, as a\nprepossessing step, while keeping the feature definition interactive. Different\nfeature definitions can be explored and compared interactively based on this\ntracking graph. Features are specified by rules for grouping critical points,\nwhile feature tracking corresponds to filtering and querying the full tracking\ngraph by specific requests. We demonstrate this method for cyclone\nidentification and tracking in the context of climate research.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 17:39:27 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Engelke", "Wito", ""], ["Masood", "Talha Bin", ""], ["Beran", "Jakob", ""], ["Caballero", "Rodrigo", ""], ["Hotz", "Ingrid", ""]]}, {"id": "2011.08692", "submitter": "Nina Varney", "authors": "Nina Varney, Vijayan K. Asari and Quinn Graehling", "title": "Pyramid Point: A Multi-Level Focusing Network for Revisiting Feature\n  Layers", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a method to learn a diverse group of object categories from an\nunordered point set. We propose our Pyramid Point network, which uses a dense\npyramid structure instead of the traditional 'U' shape, typically seen in\nsemantic segmentation networks. This pyramid structure gives a second look,\nallowing the network to revisit different layers simultaneously, increasing the\ncontextual information by creating additional layers with less noise. We\nintroduce a Focused Kernel Point convolution (FKP Conv), which expands on the\ntraditional point convolutions by adding an attention mechanism to the kernel\noutputs. This FKP Conv increases our feature quality and allows us to weigh the\nkernel outputs dynamically. These FKP Convs are the central part of our\nRecurrent FKP Bottleneck block, which makes up the backbone of our encoder.\nWith this distinct network, we demonstrate competitive performance on three\nbenchmark data sets. We also perform an ablation study to show the positive\neffects of each element in our FKP Conv.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:23:27 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 16:35:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Varney", "Nina", ""], ["Asari", "Vijayan K.", ""], ["Graehling", "Quinn", ""]]}, {"id": "2011.08694", "submitter": "Shohin Mukherjee", "authors": "Shohin Mukherjee, Chris Paxton, Arsalan Mousavian, Adam Fishman, Maxim\n  Likhachev, Dieter Fox", "title": "Reactive Long Horizon Task Execution via Visual Skill and Precondition\n  Models", "comments": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot execution of unseen robotic tasks is important to allowing robots\nto perform a wide variety of tasks in human environments, but collecting the\namounts of data necessary to train end-to-end policies in the real-world is\noften infeasible. We describe an approach for sim-to-real training that can\naccomplish unseen robotic tasks using models learned in simulation to ground\ncomponents of a simple task planner. We learn a library of parameterized\nskills, along with a set of predicates-based preconditions and termination\nconditions, entirely in simulation. We explore a block-stacking task because it\nhas a clear structure, where multiple skills must be chained together, but our\nmethods are applicable to a wide range of other problems and domains, and can\ntransfer from simulation to the real-world with no fine tuning. The system is\nable to recognize failures and accomplish long-horizon tasks from perceptual\ninput, which is critical for real-world execution. We evaluate our proposed\napproach in both simulation and in the real-world, showing an increase in\nsuccess rate from 91.6% to 98% in simulation and from 10% to 80% success rate\nin the real-world as compared with naive baselines. For experiment videos\nincluding both real-world and simulation, see:\nhttps://www.youtube.com/playlist?list=PL-oD0xHUngeLfQmpngYkGFZarstfPOXqX\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:24:01 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 14:07:25 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mukherjee", "Shohin", ""], ["Paxton", "Chris", ""], ["Mousavian", "Arsalan", ""], ["Fishman", "Adam", ""], ["Likhachev", "Maxim", ""], ["Fox", "Dieter", ""]]}, {"id": "2011.08698", "submitter": "Zaccharie Ramzi", "authors": "Zaccharie Ramzi, Benjamin Remy, Francois Lanusse, Jean-Luc Starck,\n  Philippe Ciuciu", "title": "Denoising Score-Matching for Uncertainty Quantification in Inverse\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.SP physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have proven extremely efficient at solving a wide\nrangeof inverse problems, but most often the uncertainty on the solution they\nprovideis hard to quantify. In this work, we propose a generic Bayesian\nframework forsolving inverse problems, in which we limit the use of deep neural\nnetworks tolearning a prior distribution on the signals to recover. We adopt\nrecent denoisingscore matching techniques to learn this prior from data, and\nsubsequently use it aspart of an annealed Hamiltonian Monte-Carlo scheme to\nsample the full posteriorof image inverse problems. We apply this framework to\nMagnetic ResonanceImage (MRI) reconstruction and illustrate how this approach\nnot only yields highquality reconstructions but can also be used to assess the\nuncertainty on particularfeatures of a reconstructed image.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:33:06 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ramzi", "Zaccharie", ""], ["Remy", "Benjamin", ""], ["Lanusse", "Francois", ""], ["Starck", "Jean-Luc", ""], ["Ciuciu", "Philippe", ""]]}, {"id": "2011.08704", "submitter": "Gabi Shalev", "authors": "Gabi Shalev and Gal-Lev Shalev and Joseph Keshet", "title": "Redesigning the classification layer by randomizing the class\n  representation vectors", "comments": "11 pages, 9 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural image classification models typically consist of two components. The\nfirst is an image encoder, which is responsible for encoding a given raw image\ninto a representative vector. The second is the classification component, which\nis often implemented by projecting the representative vector onto target class\nvectors. The target class vectors, along with the rest of the model parameters,\nare estimated so as to minimize the loss function. In this paper, we analyze\nhow simple design choices for the classification layer affect the learning\ndynamics. We show that the standard cross-entropy training implicitly captures\nvisual similarities between different classes, which might deteriorate accuracy\nor even prevents some models from converging. We propose to draw the class\nvectors randomly and set them as fixed during training, thus invalidating the\nvisual similarities encoded in these vectors. We analyze the effects of keeping\nthe class vectors fixed and show that it can increase the inter-class\nseparability, intra-class compactness, and the overall model accuracy, while\nmaintaining the robustness to image corruptions and the generalization of the\nlearned concepts.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 13:45:23 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 08:32:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shalev", "Gabi", ""], ["Shalev", "Gal-Lev", ""], ["Keshet", "Joseph", ""]]}, {"id": "2011.08711", "submitter": "Alexander Alemi", "authors": "Alexander A Alemi and Warren R Morningstar and Ben Poole and Ian\n  Fischer and Joshua V Dillon", "title": "VIB is Half Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In discriminative settings such as regression and classification there are\ntwo random variables at play, the inputs X and the targets Y. Here, we\ndemonstrate that the Variational Information Bottleneck can be viewed as a\ncompromise between fully empirical and fully Bayesian objectives, attempting to\nminimize the risks due to finite sampling of Y only. We argue that this\napproach provides some of the benefits of Bayes while requiring only some of\nthe work.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:36:35 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Alemi", "Alexander A", ""], ["Morningstar", "Warren R", ""], ["Poole", "Ben", ""], ["Fischer", "Ian", ""], ["Dillon", "Joshua V", ""]]}, {"id": "2011.08712", "submitter": "Aria Khoshsirat", "authors": "Aria Khoshsirat", "title": "A Simple Framework to Quantify Different Types of Uncertainty in Deep\n  Neural Networks for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantifying uncertainty in a model's predictions is important as it enables\nthe safety of an AI system to be increased by acting on the model's output in\nan informed manner. This is crucial for applications where the cost of an error\nis high, such as in autonomous vehicle control, medical image analysis,\nfinancial estimations or legal fields. Deep Neural Networks are powerful\npredictors that have recently achieved state-of-the-art performance on a wide\nspectrum of tasks. Quantifying predictive uncertainty in DNNs is a challenging\nand yet on-going problem. In this paper we propose a complete framework to\ncapture and quantify three known types of uncertainty in DNNs for the task of\nimage classification. This framework includes an ensemble of CNNs for model\nuncertainty, a supervised reconstruction auto-encoder to capture distributional\nuncertainty and using the output of activation functions in the last layer of\nthe network, to capture data uncertainty. Finally we demonstrate the efficiency\nof our method on popular image datasets for classification.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:36:42 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 07:35:42 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 17:44:35 GMT"}, {"version": "v4", "created": "Thu, 20 May 2021 20:03:34 GMT"}, {"version": "v5", "created": "Fri, 28 May 2021 15:33:37 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Khoshsirat", "Aria", ""]]}, {"id": "2011.08714", "submitter": "Mizu Nishikawa-Toomey", "authors": "Mizu Nishikawa-Toomey, Lewis Smith, Yarin Gal", "title": "Semi-supervised Learning of Galaxy Morphology using Equivariant\n  Transformer Variational Autoencoders", "comments": "Accepted at the workshop for Machine Learning and the Physical\n  Sciences, 34th Conference on Neural Information Processing Systems (NeurIPS)\n  December 11, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growth in the number of galaxy images is much faster than the speed at\nwhich these galaxies can be labelled by humans. However, by leveraging the\ninformation present in the ever growing set of unlabelled images,\nsemi-supervised learning could be an effective way of reducing the required\nlabelling and increasing classification accuracy. We develop a Variational\nAutoencoder (VAE) with Equivariant Transformer layers with a classifier network\nfrom the latent space. We show that this novel architecture leads to\nimprovements in accuracy when used for the galaxy morphology classification\ntask on the Galaxy Zoo data set. In addition we show that pre-training the\nclassifier network as part of the VAE using the unlabelled data leads to higher\naccuracy with fewer labels compared to exiting approaches. This novel VAE has\nthe potential to automate galaxy morphology classification with reduced human\nlabelling efforts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:41:18 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Nishikawa-Toomey", "Mizu", ""], ["Smith", "Lewis", ""], ["Gal", "Yarin", ""]]}, {"id": "2011.08726", "submitter": "Nicolai Dorka", "authors": "Nicolai Dorka, Johannes Meyer, Wolfram Burgard", "title": "Modality-Buffet for Real-Time Object Detection", "comments": "Accepted at the 2020 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time object detection in videos using lightweight hardware is a crucial\ncomponent of many robotic tasks. Detectors using different modalities and with\nvarying computational complexities offer different trade-offs. One option is to\nhave a very lightweight model that can predict from all modalities at once for\neach frame. However, in some situations (e.g., in static scenes) it might be\nbetter to have a more complex but more accurate model and to extrapolate from\nprevious predictions for the frames coming in at processing time. We formulate\nthis task as a sequential decision making problem and use reinforcement\nlearning (RL) to generate a policy that decides from the RGB input which\ndetector out of a portfolio of different object detectors to take for the next\nprediction. The objective of the RL agent is to maximize the accuracy of the\npredictions per image. We evaluate the approach on the Waymo Open Dataset and\nshow that it exceeds the performance of each single detector.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 15:57:06 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Dorka", "Nicolai", ""], ["Meyer", "Johannes", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2011.08728", "submitter": "Fan Yang", "authors": "Fan Yang, Chao Yang, Di Guo, Huaping Liu, Fuchun Sun", "title": "Fault-Aware Robust Control via Adversarial Reinforcement Learning", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robots have limited adaptation ability compared to humans and animals in the\ncase of damage. However, robot damages are prevalent in real-world\napplications, especially for robots deployed in extreme environments. The\nfragility of robots greatly limits their widespread application. We propose an\nadversarial reinforcement learning framework, which significantly increases\nrobot robustness over joint damage cases in both manipulation tasks and\nlocomotion tasks. The agent is trained iteratively under the joint damage cases\nwhere it has poor performance. We validate our algorithm on a three-fingered\nrobot hand and a quadruped robot. Our algorithm can be trained only in\nsimulation and directly deployed on a real robot without any fine-tuning. It\nalso demonstrates exceeding success rates over arbitrary joint damage cases.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:01:06 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 06:30:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yang", "Fan", ""], ["Yang", "Chao", ""], ["Guo", "Di", ""], ["Liu", "Huaping", ""], ["Sun", "Fuchun", ""]]}, {"id": "2011.08734", "submitter": "Johannes P\\\"oppelbaum", "authors": "Johannes P\\\"oppelbaum, Andreas Schwung", "title": "Predicting Rigid Body Dynamics using Dual Quaternion Recurrent Neural\n  Networks with Quaternion Attention", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.20727.65449", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a novel neural network architecture based on dual quaternions\nwhich allow for a compact representation of informations with a main focus on\ndescribing rigid body movements. To cover the dynamic behavior inherent to\nrigid body movements, we propose recurrent architectures in the neural network.\nTo further model the interactions between individual rigid bodies as well as\nexternal inputs efficiently, we incorporate a novel attention mechanism\nemploying dual quaternion algebra. The introduced architecture is trainable by\nmeans of gradient based algorithms. We apply our approach to a parcel\nprediction problem where a rigid body with an initial position, orientation,\nvelocity and angular velocity moves through a fixed simulation environment\nwhich exhibits rich interactions between the parcel and the boundaries.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:10:49 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["P\u00f6ppelbaum", "Johannes", ""], ["Schwung", "Andreas", ""]]}, {"id": "2011.08750", "submitter": "Ignat Georgiev", "authors": "Ignat Georgiev, Christoforos Chatzikomis, Timo V\\\"olkl, Joshua Smith\n  and Michael Mistry", "title": "Iterative Semi-parametric Dynamics Model Learning For Autonomous Racing", "comments": "Accepted at 4th Conference on Robot Learning (CoRL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurately modeling robot dynamics is crucial to safe and efficient motion\ncontrol. In this paper, we develop and apply an iterative learning\nsemi-parametric model, with a neural network, to the task of autonomous racing\nwith a Model Predictive Controller (MPC). We present a novel non-linear\nsemi-parametric dynamics model where we represent the known dynamics with a\nparametric model, and a neural network captures the unknown dynamics. We show\nthat our model can learn more accurately than a purely parametric model and\ngeneralize better than a purely non-parametric model, making it ideal for\nreal-world applications where collecting data from the full state space is not\nfeasible. We present a system where the model is bootstrapped on pre-recorded\ndata and then updated iteratively at run time. Then we apply our iterative\nlearning approach to the simulated problem of autonomous racing and show that\nit can safely adapt to modified dynamics online and even achieve better\nperformance than models trained on data from manual driving.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:24:10 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Georgiev", "Ignat", ""], ["Chatzikomis", "Christoforos", ""], ["V\u00f6lkl", "Timo", ""], ["Smith", "Joshua", ""], ["Mistry", "Michael", ""]]}, {"id": "2011.08753", "submitter": "Xuling Wang", "authors": "Shirly Wang, Seung Eun Yi, Shalmali Joshi, Marzyeh Ghassemi", "title": "Confounding Feature Acquisition for Causal Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable treatment effect estimation from observational data depends on the\navailability of all confounding information. While much work has targeted\ntreatment effect estimation from observational data, there is relatively little\nwork in the setting of confounding variable missingness, where collecting more\ninformation on confounders is often costly or time-consuming. In this work, we\nframe this challenge as a problem of feature acquisition of confounding\nfeatures for causal inference. Our goal is to prioritize acquiring values for a\nfixed and known subset of missing confounders in samples that lead to efficient\naverage treatment effect estimation. We propose two acquisition strategies\nbased on i) covariate balancing (CB), and ii) reducing statistical estimation\nerror on observed factual outcome error (OE). We compare CB and OE on five\ncommon causal effect estimation methods, and demonstrate improved sample\nefficiency of OE over baseline methods under various settings. We also provide\nvisualizations for further analysis on the difference between our proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:28:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Wang", "Shirly", ""], ["Yi", "Seung Eun", ""], ["Joshi", "Shalmali", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2011.08755", "submitter": "Bimal Bhattarai", "authors": "Bimal Bhattarai, Ole-Christoffer Granmo, Lei Jiao", "title": "Measuring the Novelty of Natural Language Text Using the Conjunctive\n  Clauses of a Tsetlin Machine Text Classifier", "comments": "10 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most supervised text classification approaches assume a closed world,\ncounting on all classes being present in the data at training time. This\nassumption can lead to unpredictable behaviour during operation, whenever\nnovel, previously unseen, classes appear. Although deep learning-based methods\nhave recently been used for novelty detection, they are challenging to\ninterpret due to their black-box nature. This paper addresses\n\\emph{interpretable} open-world text classification, where the trained\nclassifier must deal with novel classes during operation. To this end, we\nextend the recently introduced Tsetlin machine (TM) with a novelty scoring\nmechanism. The mechanism uses the conjunctive clauses of the TM to measure to\nwhat degree a text matches the classes covered by the training data. We\ndemonstrate that the clauses provide a succinct interpretable description of\nknown topics, and that our scoring mechanism makes it possible to discern novel\ntopics from the known ones. Empirically, our TM-based approach outperforms\nseven other novelty detection schemes on three out of five datasets, and\nperforms second and third best on the remaining, with the added benefit of an\ninterpretable propositional logic-based representation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:35:21 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bhattarai", "Bimal", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""]]}, {"id": "2011.08756", "submitter": "Tiansheng Huang", "authors": "Tiansheng Huang, Weiwei Lin, Li Shen, Keqin Li, and Albert Y. Zomaya", "title": "Stochastic Client Selection for Federated Learning with Volatile Clients", "comments": "20 pages, 7 figures. Under review by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL), arising as a novel secure learning paradigm, has\nreceived notable attention from the public. In each round of synchronous FL\ntraining, only a fraction of available clients are chosen to participate and\nthe selection decision might have a significant effect on the training\nefficiency, as well as the final model performance. In this paper, we\ninvestigate the client selection problem under a volatile context, in which the\nlocal training of heterogeneous clients is likely to fail due to various kinds\nof reasons and in different levels of frequency. Intuitively, too much training\nfailure might potentially reduce the training efficiency, while too much\nselection on clients with greater stability might introduce bias, and thereby\nresult in degradation of the training effectiveness. To tackle this tradeoff,\nwe in this paper formulate the client selection problem under joint\nconsideration of effective participation and fairness. Further, we propose\nE3CS, a stochastic client selection scheme on the basis of an adversarial\nbandit solution, and we further corroborate its effectiveness by conducting\nreal data-based experiments. According to the experimental results, our\nproposed selection scheme is able to achieve up to 2x faster convergence to a\nfixed model accuracy while maintaining the same level of final model accuracy,\nin comparison to the vanilla selection scheme in FL.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:35:24 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 03:09:36 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Huang", "Tiansheng", ""], ["Lin", "Weiwei", ""], ["Shen", "Li", ""], ["Li", "Keqin", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "2011.08763", "submitter": "Enrico Fontana", "authors": "Enrico Fontana, M. Cerezo, Andrew Arrasmith, Ivan Rungger, Patrick J.\n  Coles", "title": "Optimizing parametrized quantum circuits via noise-induced breaking of\n  symmetries", "comments": "11 + 5 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-29359", "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very little is known about the cost landscape for parametrized Quantum\nCircuits (PQCs). Nevertheless, PQCs are employed in Quantum Neural Networks and\nVariational Quantum Algorithms, which may allow for near-term quantum\nadvantage. Such applications require good optimizers to train PQCs. Recent\nworks have focused on quantum-aware optimizers specifically tailored for PQCs.\nHowever, ignorance of the cost landscape could hinder progress towards such\noptimizers. In this work, we analytically prove two results for PQCs: (1) We\nfind an exponentially large symmetry in PQCs, yielding an exponentially large\ndegeneracy of the minima in the cost landscape. (2) We show that noise\n(specifically non-unital noise) can break these symmetries and lift the\ndegeneracy of minima, making many of them local minima instead of global\nminima. Based on these results, we introduce an optimization method called\nSymmetry-based Minima Hopping (SYMH), which exploits the underlying symmetries\nin PQCs to hop between local minima in the cost landscape. The versatility of\nSYMH allows it to be combined with local optimizers (e.g., gradient descent)\nwith minimal overhead. Our numerical simulations show that SYMH improves the\noverall optimizer performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:43:05 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 17:49:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Fontana", "Enrico", ""], ["Cerezo", "M.", ""], ["Arrasmith", "Andrew", ""], ["Rungger", "Ivan", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2011.08779", "submitter": "Cory Merkel", "authors": "Cory Merkel", "title": "Exploring Energy-Accuracy Tradeoffs in AI Hardware", "comments": "To be published in the proceedings of the 2020 International Green\n  and Sustainable Computing Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) is playing an increasingly significant role in\nour everyday lives. This trend is expected to continue, especially with recent\npushes to move more AI to the edge. However, one of the biggest challenges\nassociated with AI on edge devices (mobile phones, unmanned vehicles, sensors,\netc.) is their associated size, weight, and power constraints. In this work, we\nconsider the scenario where an AI system may need to operate at\nless-than-maximum accuracy in order to meet application-dependent energy\nrequirements. We propose a simple function that divides the cost of using an AI\nsystem into the cost of the decision making process and the cost of decision\nexecution. For simple binary decision problems with convolutional neural\nnetworks, it is shown that minimizing the cost corresponds to using fewer than\nthe maximum number of resources (e.g. convolutional neural network layers and\nfilters). Finally, it is shown that the cost associated with energy can be\nsignificantly reduced by leveraging high-confidence predictions made in\nlower-level layers of the network.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:14:28 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Merkel", "Cory", ""]]}, {"id": "2011.08781", "submitter": "Erick Carvajal Barboza", "authors": "Erick Carvajal Barboza and Sara Jacob and Mahesh Ketkar and Michael\n  Kishinevsky and Paul Gratz and Jiang Hu", "title": "Automatic Microprocessor Performance Bug Detection", "comments": "14 pages, 13 figures, to appear in the 27th International Symposium\n  on High-Performance Computer Architecture (HPCA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Processor design validation and debug is a difficult and complex task, which\nconsumes the lion's share of the design process. Design bugs that affect\nprocessor performance rather than its functionality are especially difficult to\ncatch, particularly in new microarchitectures. This is because, unlike\nfunctional bugs, the correct processor performance of new microarchitectures on\ncomplex, long-running benchmarks is typically not deterministically known.\nThus, when performance benchmarking new microarchitectures, performance teams\nmay assume that the design is correct when the performance of the new\nmicroarchitecture exceeds that of the previous generation, despite significant\nperformance regressions existing in the design. In this work, we present a\ntwo-stage, machine learning-based methodology that is able to detect the\nexistence of performance bugs in microprocessors. Our results show that our\nbest technique detects 91.5% of microprocessor core performance bugs whose\naverage IPC impact across the studied applications is greater than 1% versus a\nbug-free design with zero false positives. When evaluated on memory system\nbugs, our technique achieves 100% detection with zero false positives.\nMoreover, the detection is automatic, requiring very little performance\nengineer time.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:18:45 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 15:39:21 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Barboza", "Erick Carvajal", ""], ["Jacob", "Sara", ""], ["Ketkar", "Mahesh", ""], ["Kishinevsky", "Michael", ""], ["Gratz", "Paul", ""], ["Hu", "Jiang", ""]]}, {"id": "2011.08784", "submitter": "Alexander Tornede", "authors": "Alexander Tornede, Marcel Wever, Eyke H\\\"ullermeier", "title": "Towards Meta-Algorithm Selection", "comments": "Accepted at 4th Workshop on Meta-Learning at NeurIPS 2020, Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Instance-specific algorithm selection (AS) deals with the automatic selection\nof an algorithm from a fixed set of candidates most suitable for a specific\ninstance of an algorithmic problem class, where \"suitability\" often refers to\nan algorithm's runtime. Over the past years, a plethora of algorithm selectors\nhave been proposed. As an algorithm selector is again an algorithm solving a\nspecific problem, the idea of algorithm selection could also be applied to AS\nalgorithms, leading to a meta-AS approach: Given an instance, the goal is to\nselect an algorithm selector, which is then used to select the actual algorithm\nfor solving the problem instance. We elaborate on consequences of applying AS\non a meta-level and identify possible problems. Empirically, we show that\nmeta-algorithm-selection can indeed prove beneficial in some cases. In general,\nhowever, successful AS approaches have problems with solving the meta-level\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:27:33 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Tornede", "Alexander", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2011.08797", "submitter": "Rafael Hanashiro", "authors": "Rafael Hanashiro, Jacob Abernethy", "title": "Linear Separation via Optimism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary linear classification has been explored since the very early days of\nthe machine learning literature. Perhaps the most classical algorithm is the\nPerceptron, where a weight vector used to classify examples is maintained, and\nadditive updates are made as incorrect examples are discovered. The Perceptron\nhas been thoroughly studied and several versions have been proposed over many\ndecades. The key theoretical fact about the Perceptron is that, so long as a\nperfect linear classifier exists with some margin $\\gamma > 0$, the number of\nrequired updates to find such a perfect linear separator is bounded by\n$\\frac{1}{\\gamma^2}$. What has never been fully addressed is: does there exist\nan algorithm that can achieve this with fewer updates? In this paper we answer\nthis in the affirmative: we propose the Optimistic Perceptron algorithm, a\nsimple procedure that finds a separating hyperplane in no more than\n$\\frac{1}{\\gamma}$ updates. We also show experimentally that this procedure can\nsignificantly outperform Perceptron.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:44:40 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hanashiro", "Rafael", ""], ["Abernethy", "Jacob", ""]]}, {"id": "2011.08813", "submitter": "Naresh Nandakumar", "authors": "Naresh Nandakumar, Niharika Shimona D'souza, Komal Manzoor, Jay J.\n  Pillai, Sachin K. Gujar, Haris I. Sair, and Archana Venkataraman", "title": "A Multi-Task Deep Learning Framework to Localize the Eloquent Cortex in\n  Brain Tumor Patients Using Dynamic Functional Connectivity", "comments": "Presented at MLCN 2020 workshop, as a part of MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel deep learning framework that uses dynamic functional\nconnectivity to simultaneously localize the language and motor areas of the\neloquent cortex in brain tumor patients. Our method leverages convolutional\nlayers to extract graph-based features from the dynamic connectivity matrices\nand a long-short term memory (LSTM) attention network to weight the relevant\ntime points during classification. The final stage of our model employs\nmulti-task learning to identify different eloquent subsystems. Our unique\ntraining strategy finds a shared representation between the cognitive networks\nof interest, which enables us to handle missing patient data. We evaluate our\nmethod on resting-state fMRI data from 56 brain tumor patients while using task\nfMRI activations as surrogate ground-truth labels for training and testing. Our\nmodel achieves higher localization accuracies than conventional deep learning\napproaches and can identify bilateral language areas even when trained on\nleft-hemisphere lateralized cases. Hence, our method may ultimately be useful\nfor preoperative mapping in tumor patients.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:18:09 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Nandakumar", "Naresh", ""], ["D'souza", "Niharika Shimona", ""], ["Manzoor", "Komal", ""], ["Pillai", "Jay J.", ""], ["Gujar", "Sachin K.", ""], ["Sair", "Haris I.", ""], ["Venkataraman", "Archana", ""]]}, {"id": "2011.08819", "submitter": "Nikhil Churamani", "authors": "Nikhil Churamani, Sinan Kalkan and Hatice Gunes", "title": "Spatio-Temporal Analysis of Facial Actions using Lifecycle-Aware Capsule\n  Networks", "comments": "Updated Figure 6 and the Acknowledgements. Corrected typos. 11 pages,\n  6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art approaches for Facial Action Unit (AU) detection rely\nupon evaluating facial expressions from static frames, encoding a snapshot of\nheightened facial activity. In real-world interactions, however, facial\nexpressions are usually more subtle and evolve in a temporal manner requiring\nAU detection models to learn spatial as well as temporal information. In this\npaper, we focus on both spatial and spatio-temporal features encoding the\ntemporal evolution of facial AU activation. For this purpose, we propose the\nAction Unit Lifecycle-Aware Capsule Network (AULA-Caps) that performs AU\ndetection using both frame and sequence-level features. While at the\nframe-level the capsule layers of AULA-Caps learn spatial feature primitives to\ndetermine AU activations, at the sequence-level, it learns temporal\ndependencies between contiguous frames by focusing on relevant spatio-temporal\nsegments in the sequence. The learnt feature capsules are routed together such\nthat the model learns to selectively focus more on spatial or spatio-temporal\ninformation depending upon the AU lifecycle. The proposed model is evaluated on\nthe commonly used BP4D and GFT benchmark datasets obtaining state-of-the-art\nresults on both the datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:36:38 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 02:41:43 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Churamani", "Nikhil", ""], ["Kalkan", "Sinan", ""], ["Gunes", "Hatice", ""]]}, {"id": "2011.08820", "submitter": "Jonathan Uesato", "authors": "Ramana Kumar, Jonathan Uesato, Richard Ngo, Tom Everitt, Victoria\n  Krakovna, Shane Legg", "title": "REALab: An Embedded Perspective on Tampering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes REALab, a platform for embedded agency research in\nreinforcement learning (RL). REALab is designed to model the structure of\ntampering problems that may arise in real-world deployments of RL. Standard\nMarkov Decision Process (MDP) formulations of RL and simulated environments\nmirroring the MDP structure assume secure access to feedback (e.g., rewards).\nThis may be unrealistic in settings where agents are embedded and can corrupt\nthe processes producing feedback (e.g., human supervisors, or an implemented\nreward function). We describe an alternative Corrupt Feedback MDP formulation\nand the REALab environment platform, which both avoid the secure feedback\nassumption. We hope the design of REALab provides a useful perspective on\ntampering problems, and that the platform may serve as a unit test for the\npresence of tampering incentives in RL agent designs.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:37:20 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kumar", "Ramana", ""], ["Uesato", "Jonathan", ""], ["Ngo", "Richard", ""], ["Everitt", "Tom", ""], ["Krakovna", "Victoria", ""], ["Legg", "Shane", ""]]}, {"id": "2011.08824", "submitter": "Kimberly Wilber", "authors": "Andreas Veit, Kimberly Wilber", "title": "Improving Calibration in Deep Metric Learning With Cross-Example Softmax", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern image retrieval systems increasingly rely on the use of deep neural\nnetworks to learn embedding spaces in which distance encodes the relevance\nbetween a given query and image. In this setting, existing approaches tend to\nemphasize one of two properties. Triplet-based methods capture top-$k$\nrelevancy, where all top-$k$ scoring documents are assumed to be relevant to a\ngiven query Pairwise contrastive models capture threshold relevancy, where all\ndocuments scoring higher than some threshold are assumed to be relevant. In\nthis paper, we propose Cross-Example Softmax which combines the properties of\ntop-$k$ and threshold relevancy. In each iteration, the proposed loss\nencourages all queries to be closer to their matching images than all queries\nare to all non-matching images. This leads to a globally more calibrated\nsimilarity metric and makes distance more interpretable as an absolute measure\nof relevance. We further introduce Cross-Example Negative Mining, in which each\npair is compared to the hardest negative comparisons across the entire batch.\nEmpirically, we show in a series of experiments on Conceptual Captions and\nFlickr30k, that the proposed method effectively improves global calibration and\nalso retrieval performance.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:47:28 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Veit", "Andreas", ""], ["Wilber", "Kimberly", ""]]}, {"id": "2011.08826", "submitter": "Udaranga Wickramasinghe", "authors": "Udaranga Wickramasinghe and Graham Knott and Pascal Fua", "title": "Deep Active Surface Models", "comments": "11 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Surface Models have a long history of being useful to model complex 3D\nsurfaces but only Active Contours have been used in conjunction with deep\nnetworks, and then only to produce the data term as well as meta-parameter maps\ncontrolling them. In this paper, we advocate a much tighter integration. We\nintroduce layers that implement them that can be integrated seamlessly into\nGraph Convolutional Networks to enforce sophisticated smoothness priors at an\nacceptable computational cost. We will show that the resulting Deep Active\nSurface Models outperform equivalent architectures that use traditional\nregularization loss terms to impose smoothness priors for 3D surface\nreconstruction from 2D images and for 3D volume segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:48:28 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 18:25:58 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 23:19:36 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 21:31:20 GMT"}, {"version": "v5", "created": "Mon, 7 Jun 2021 22:19:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wickramasinghe", "Udaranga", ""], ["Knott", "Graham", ""], ["Fua", "Pascal", ""]]}, {"id": "2011.08827", "submitter": "Jonathan Uesato", "authors": "Jonathan Uesato, Ramana Kumar, Victoria Krakovna, Tom Everitt, Richard\n  Ngo, Shane Legg", "title": "Avoiding Tampering Incentives in Deep RL via Decoupled Approval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we design agents that pursue a given objective when all feedback\nmechanisms are influenceable by the agent? Standard RL algorithms assume a\nsecure reward function, and can thus perform poorly in settings where agents\ncan tamper with the reward-generating mechanism. We present a principled\nsolution to the problem of learning from influenceable feedback, which combines\napproval with a decoupled feedback collection procedure. For a natural class of\ncorruption functions, decoupled approval algorithms have aligned incentives\nboth at convergence and for their local updates. Empirically, they also scale\nto complex 3D environments where tampering is possible.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:48:59 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Uesato", "Jonathan", ""], ["Kumar", "Ramana", ""], ["Krakovna", "Victoria", ""], ["Everitt", "Tom", ""], ["Ngo", "Richard", ""], ["Legg", "Shane", ""]]}, {"id": "2011.08828", "submitter": "Federico Grasselli", "authors": "Giulio Imbalzano, Yongbin Zhuang, Venkat Kapil, Kevin Rossi, Edgar A.\n  Engel, Federico Grasselli, Michele Ceriotti", "title": "Uncertainty estimation for molecular dynamics and sampling", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": "10.1063/5.0036522", "report-no": null, "categories": "physics.chem-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have emerged as a very effective strategy to sidestep\ntime-consuming electronic-structure calculations, enabling accurate simulations\nof greater size, time scale and complexity. Given the interpolative nature of\nthese models, the reliability of predictions depends on the position in phase\nspace, and it is crucial to obtain an estimate of the error that derives from\nthe finite number of reference structures included during the training of the\nmodel. When using a machine-learning potential to sample a finite-temperature\nensemble, the uncertainty on individual configurations translates into an error\non thermodynamic averages, and provides an indication for the loss of accuracy\nwhen the simulation enters a previously unexplored region. Here we discuss how\nuncertainty quantification can be used, together with a baseline energy model,\nor a more robust although less accurate interatomic potential, to obtain more\nresilient simulations and to support active-learning strategies. Furthermore,\nwe introduce an on-the-fly reweighing scheme that makes it possible to estimate\nthe uncertainty in the thermodynamic averages extracted from long trajectories.\nWe present examples covering different types of structural and thermodynamic\nproperties, and systems as diverse as water and liquid gallium.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 00:07:50 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 18:57:03 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Imbalzano", "Giulio", ""], ["Zhuang", "Yongbin", ""], ["Kapil", "Venkat", ""], ["Rossi", "Kevin", ""], ["Engel", "Edgar A.", ""], ["Grasselli", "Federico", ""], ["Ceriotti", "Michele", ""]]}, {"id": "2011.08837", "submitter": "Charles Colley", "authors": "Charles Colley, Huda Nassar, David Gleich", "title": "Addressing Computational Bottlenecks in Higher-Order Graph Matching with\n  Tensor Kronecker Product Structure", "comments": "14 pages, 2 pages Supplemental, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching, also known as network alignment, is the problem of finding a\ncorrespondence between the vertices of two separate graphs with strong\napplications in image correspondence and functional inference in protein\nnetworks. One class of successful techniques is based on tensor Kronecker\nproducts and tensor eigenvectors. A challenge with these techniques are memory\nand computational demands that are quadratic (or worse) in terms of problem\nsize. In this manuscript we present and apply a theory of tensor Kronecker\nproducts to tensor based graph alignment algorithms to reduce their runtime\ncomplexity from quadratic to linear with no appreciable loss of quality. In\nterms of theory, we show that many matrix Kronecker product identities\ngeneralize to straightforward tensor counterparts, which is rare in tensor\nliterature. Improved computation codes for two existing algorithms that utilize\nthis new theory achieve a minimum 10 fold runtime improvement.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:55:48 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Colley", "Charles", ""], ["Nassar", "Huda", ""], ["Gleich", "David", ""]]}, {"id": "2011.08843", "submitter": "Jiaxuan You", "authors": "Jiaxuan You, Rex Ying, Jure Leskovec", "title": "Design Space for Graph Neural Networks", "comments": "NeurIPS 2020 (Spotlight). Typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid evolution of Graph Neural Networks (GNNs) has led to a growing\nnumber of new architectures as well as novel applications. However, current\nresearch focuses on proposing and evaluating specific architectural designs of\nGNNs, as opposed to studying the more general design space of GNNs that\nconsists of a Cartesian product of different design dimensions, such as the\nnumber of layers or the type of the aggregation function. Additionally, GNN\ndesigns are often specialized to a single task, yet few efforts have been made\nto understand how to quickly find the best GNN design for a novel task or a\nnovel dataset. Here we define and systematically study the architectural design\nspace for GNNs which consists of 315,000 different designs over 32 different\npredictive tasks. Our approach features three key innovations: (1) A general\nGNN design space; (2) a GNN task space with a similarity metric, so that for a\ngiven novel task/dataset, we can quickly identify/transfer the best performing\narchitecture; (3) an efficient and effective design space evaluation method\nwhich allows insights to be distilled from a huge number of model-task\ncombinations. Our key results include: (1) A comprehensive set of guidelines\nfor designing well-performing GNNs; (2) while best GNN designs for different\ntasks vary significantly, the GNN task space allows for transferring the best\ndesigns across different tasks; (3) models discovered using our design space\nachieve state-of-the-art performance. Overall, our work offers a principled and\nscalable approach to transition from studying individual GNN designs for\nspecific tasks, to systematically studying the GNN design space and the task\nspace. Finally, we release GraphGym, a powerful platform for exploring\ndifferent GNN designs and tasks. GraphGym features modularized GNN\nimplementation, standardized GNN evaluation, and reproducible and scalable\nexperiment management.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 18:59:27 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 20:37:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["You", "Jiaxuan", ""], ["Ying", "Rex", ""], ["Leskovec", "Jure", ""]]}, {"id": "2011.08848", "submitter": "Georgios Papageorgiou", "authors": "Georgios K. Papageorgiou, Mathini Sellathurai and Yonina C. Eldar", "title": "Deep Networks for Direction-of-Arrival Estimation in Low SNR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider direction-of-arrival (DoA) estimation in the\npresence of extreme noise using Deep Learning (DL). In particular, we introduce\na Convolutional Neural Network (CNN) that is trained from mutli-channel data of\nthe true array manifold matrix and is able to predict angular directions using\nthe sample covariance estimate. We model the problem as a multi-label\nclassification task and train a CNN in the low-SNR regime to predict DoAs\nacross all SNRs. The proposed architecture demonstrates enhanced robustness in\nthe presence of noise, and resilience to a small number of snapshots. Moreover,\nit is able to resolve angles within the grid resolution. Experimental results\ndemonstrate significant performance gains in the low-SNR regime compared to\nstate-of-the-art methods and without the requirement of any parameter tuning.\nWe relax the assumption that the number of sources is known a priori and\npresent a training method, where the CNN learns to infer the number of sources\njointly with the DoAs. Simulation results demonstrate that the proposed CNN can\naccurately estimate off-grid angles in low SNR, while at the same time the\nnumber of sources is successfully inferred for a sufficient number of\nsnapshots. Our robust solution can be applied in several fields, ranging from\nwireless array sensors to acoustic microphones or sonars.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 12:52:18 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Papageorgiou", "Georgios K.", ""], ["Sellathurai", "Mathini", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2011.08881", "submitter": "Andrei Diaconu", "authors": "Andrei Diaconu", "title": "Learning functional programs with function invention and reuse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inductive programming (IP) is a field whose main goal is synthesising\nprograms that respect a set of examples, given some form of background\nknowledge. This paper is concerned with a subfield of IP, inductive functional\nprogramming (IFP). We explore the idea of generating modular functional\nprograms, and how those allow for function reuse, with the aim to reduce the\nsize of the programs. We introduce two algorithms that attempt to solve the\nproblem and explore type based pruning techniques in the context of modular\nprograms. By experimenting with the implementation of one of those algorithms,\nwe show reuse is important (if not crucial) for a variety of problems and\ndistinguished two broad classes of programs that will generally benefit from\nfunction reuse.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:11:00 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Diaconu", "Andrei", ""]]}, {"id": "2011.08891", "submitter": "Rachel Draelos", "authors": "Rachel Lea Draelos, Lawrence Carin", "title": "HiResCAM: Faithful Location Representation in Visual Attention for\n  Explainable 3D Medical Image Classification", "comments": "Paper and supplement: 26 pages, 14 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding model predictions is critical in healthcare, to facilitate\nrapid verification of model correctness and to guard against the use of models\nthat exploit confounding variables. Here we address the challenging new task of\nexplainable multilabel classification of volumetric medical images. We first\nillustrate a previously unrecognized limitation of the popular model\nexplanation method Grad-CAM: as a side effect of the gradient averaging step,\nGrad-CAM sometimes highlights the wrong location. To solve this problem, we\npropose HiResCAM, a novel label-specific attention mechanism that is provably\nguaranteed to highlight only the locations the model used to make each\nprediction. Next, we introduce a mask loss that leverages HiResCAM to encourage\nthe model to predict abnormalities based only on the organs in which those\nabnormalities appear. Our innovations produce a 37% improvement in weakly\nsupervised organ localization of multiple abnormalities in the RAD-ChestCT data\nset of 36,316 CT volumes, resulting in state-of-the-art performance. We also\ndemonstrate on PASCAL VOC 2012 the different properties of HiResCAM and\nGrad-CAM on natural images. Overall, this work advances convolutional neural\nnetwork explanation approaches and the clinical applicability of multiple\nabnormality modeling in volumetric medical images.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:26:14 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 00:07:20 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 19:46:33 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Draelos", "Rachel Lea", ""], ["Carin", "Lawrence", ""]]}, {"id": "2011.08895", "submitter": "Alex Lewandowski", "authors": "Varun Ranganathan, Alex Lewandowski", "title": "ZORB: A Derivative-Free Backpropagation Algorithm for Neural Networks", "comments": "To appear in \"Beyond Backpropagation - Novel Ideas for Training\n  Neural Architectures\" Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient descent and backpropagation have enabled neural networks to achieve\nremarkable results in many real-world applications. Despite ongoing success,\ntraining a neural network with gradient descent can be a slow and strenuous\naffair. We present a simple yet faster training algorithm called Zeroth-Order\nRelaxed Backpropagation (ZORB). Instead of calculating gradients, ZORB uses the\npseudoinverse of targets to backpropagate information. ZORB is designed to\nreduce the time required to train deep neural networks without penalizing\nperformance. To illustrate the speed up, we trained a feed-forward neural\nnetwork with 11 layers on MNIST and observed that ZORB converged 300 times\nfaster than Adam while achieving a comparable error rate, without any\nhyperparameter tuning. We also broaden the scope of ZORB to convolutional\nneural networks, and apply it to subsamples of the CIFAR-10 dataset.\nExperiments on standard classification and regression benchmarks demonstrate\nZORB's advantage over traditional backpropagation with Gradient Descent.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:29:47 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ranganathan", "Varun", ""], ["Lewandowski", "Alex", ""]]}, {"id": "2011.08899", "submitter": "Frederik Pahde", "authors": "Frederik Pahde, Mihai Puscas, Tassilo Klein, Moin Nabi", "title": "Multimodal Prototypical Networks for Few-shot Learning", "comments": "To appear at WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although providing exceptional results for many computer vision tasks,\nstate-of-the-art deep learning algorithms catastrophically struggle in low data\nscenarios. However, if data in additional modalities exist (e.g. text) this can\ncompensate for the lack of data and improve the classification results. To\novercome this data scarcity, we design a cross-modal feature generation\nframework capable of enriching the low populated embedding space in few-shot\nscenarios, leveraging data from the auxiliary modality. Specifically, we train\na generative model that maps text data into the visual feature space to obtain\nmore reliable prototypes. This allows to exploit data from additional\nmodalities (e.g. text) during training while the ultimate task at test time\nremains classification with exclusively visual data. We show that in such cases\nnearest neighbor classification is a viable approach and outperform\nstate-of-the-art single-modal and multimodal few-shot learning methods on the\nCUB-200 and Oxford-102 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:32:59 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Pahde", "Frederik", ""], ["Puscas", "Mihai", ""], ["Klein", "Tassilo", ""], ["Nabi", "Moin", ""]]}, {"id": "2011.08908", "submitter": "Thai Le", "authors": "Thai Le, Noseong Park, Dongwon Lee", "title": "SIENA: Stochastic Multi-Expert Neural Patcher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network (NN) models that are solely trained to maximize the likelihood\nof an observed dataset are often vulnerable to adversarial attacks. Even though\nseveral methods have been proposed to enhance NN models' adversarial\nrobustness, they often require re-training from scratch. This leads to\nredundant computation, especially in the NLP domain where current\nstate-of-the-art models, such as BERT and ROBERTA, require great time and space\nresources. By borrowing ideas from Software Engineering, we, therefore, first\nintroduce the Neural Patching mechanism to improve adversarial robustness by\n\"patching\" only parts of a NN model. Then, we propose a novel neural patching\nalgorithm, SIENA, that transforms a textual NN model into a stochastic ensemble\nof multi-expert predictors by upgrading and re-training its last layer only.\nSIENA forces adversaries to attack not only one but multiple models that are\nspecialized in diverse sub-sets of features, labels, and instances so that the\nensemble model becomes more robust to adversarial attacks. By conducting\ncomprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and\nROBERTA-based textual models, once patched by SIENA, witness an absolute\nincrease of as much as 20% in accuracy on average under 5 different white and\nblack-box attacks, outperforming 6 defensive baselines across 4 public NLP\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:58:03 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Le", "Thai", ""], ["Park", "Noseong", ""], ["Lee", "Dongwon", ""]]}, {"id": "2011.08909", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Ruslan Salakhutdinov, Sergey Levine", "title": "C-Learning: Learning to Achieve Goals via Recursive Classification", "comments": "Accepted at ICLR 2021. Project website with videos\n  (https://ben-eysenbach.github.io/c_learning/) and code\n  (https://github.com/google-research/google-research/tree/master/c_learning)\n  are online", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of predicting and controlling the future state\ndistribution of an autonomous agent. This problem, which can be viewed as a\nreframing of goal-conditioned reinforcement learning (RL), is centered around\nlearning a conditional probability density function over future states. Instead\nof directly estimating this density function, we indirectly estimate this\ndensity function by training a classifier to predict whether an observation\ncomes from the future. Via Bayes' rule, predictions from our classifier can be\ntransformed into predictions over future states. Importantly, an off-policy\nvariant of our algorithm allows us to predict the future state distribution of\na new policy, without collecting new experience. This variant allows us to\noptimize functionals of a policy's future state distribution, such as the\ndensity of reaching a particular goal state. While conceptually similar to\nQ-learning, our work lays a principled foundation for goal-conditioned RL as\ndensity estimation, providing justification for goal-conditioned methods used\nin prior work. This foundation makes hypotheses about Q-learning, including the\noptimal goal-sampling ratio, which we confirm experimentally. Moreover, our\nproposed method is competitive with prior goal-conditioned RL methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:58:56 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 18:33:47 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Salakhutdinov", "Ruslan", ""], ["Levine", "Sergey", ""]]}, {"id": "2011.08922", "submitter": "Rados{\\l}aw Kycia", "authors": "Agnieszka Niemczynowicz, Gabriela Bia{\\l}osk\\'orska, Joanna\n  Nie\\.zurawska-Zaj\\k{a}c, Rados{\\l}aw A. Kycia", "title": "TreeGen -- a Monte Carlo generator for data frames", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The typical problem in Data Science is creating a structure that encodes the\noccurrence frequency of unique elements in rows and relations between different\nrows of a data frame. We present the probability tree abstract data structure,\nan extension of the decision tree, that facilitates more than two choices with\nassigned probabilities. Such a tree represents statistical relations between\ndifferent rows of the data frame. The Probability Tree algorithmic structure is\nsupplied with the Generator module that is a Monte Carlo generator that\ntraverses through the tree. These two components are implemented in TreeGen\nPython package. The package can be used in increasing data multiplicity,\ncompressing data preserving its statistical information, constructing\nhierarchical models, exploring data, and in feature extraction.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 20:22:15 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Niemczynowicz", "Agnieszka", ""], ["Bia\u0142osk\u00f3rska", "Gabriela", ""], ["Nie\u017curawska-Zaj\u0105c", "Joanna", ""], ["Kycia", "Rados\u0142aw A.", ""]]}, {"id": "2011.08930", "submitter": "Jeongmin Chae", "authors": "Jeongmin Chae, Songnam Hong", "title": "Distributed Online Learning with Multiple Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the Internet-of-Things (IoT) systems, there are plenty of informative data\nprovided by a massive number of IoT devices (e.g., sensors). Learning a\nfunction from such data is of great interest in machine learning tasks for IoT\nsystems. Focusing on streaming (or sequential) data, we present a\nprivacy-preserving distributed online learning framework with multiplekernels\n(named DOMKL). The proposed DOMKL is devised by leveraging the principles of an\nonline alternating direction of multipliers (OADMM) and a distributed Hedge\nalgorithm. We theoretically prove that DOMKL over T time slots can achieve an\noptimal sublinear regret, implying that every learned function achieves the\nperformance of the best function in hindsight as in the state-of-the-art\ncentralized online learning method. Moreover, it is ensured that the learned\nfunctions of any two neighboring learners have a negligible difference as T\ngrows, i.e., the so-called consensus constraints hold. Via experimental tests\nwith various real datasets, we verify the effectiveness of the proposed DOMKL\non regression and time-series prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 20:29:00 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Chae", "Jeongmin", ""], ["Hong", "Songnam", ""]]}, {"id": "2011.08932", "submitter": "Max Ehrlich", "authors": "Max Ehrlich, Larry Davis, Ser-Nam Lim, Abhinav Shrivastava", "title": "Analyzing and Mitigating Compression Defects in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of deep learning methods, many computer vision\nproblems which were considered academic are now viable in the consumer setting.\nOne drawback of consumer applications is lossy compression, which is necessary\nfrom an engineering standpoint to efficiently and cheaply store and transmit\nuser images. Despite this, there has been little study of the effect of\ncompression on deep neural networks and benchmark datasets are often losslessly\ncompressed or compressed at high quality. Here we present a unified study of\nthe effects of JPEG compression on a range of common tasks and datasets. We\nshow that there is a significant penalty on common performance metrics for high\ncompression. We test several methods for mitigating this penalty, including a\nnovel method based on artifact correction which requires no labels to train.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 20:32:57 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ehrlich", "Max", ""], ["Davis", "Larry", ""], ["Lim", "Ser-Nam", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "2011.08939", "submitter": "Bin Li", "authors": "Bin Li, Yin Li, Kevin W. Eliceiri", "title": "Dual-stream Multiple Instance Learning Network for Whole Slide Image\n  Classification with Self-supervised Contrastive Learning", "comments": "CVPR 2021, accepted for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenging problem of whole slide image (WSI) classification.\nWSIs have very high resolutions and usually lack localized annotations. WSI\nclassification can be cast as a multiple instance learning (MIL) problem when\nonly slide-level labels are available. We propose a MIL-based method for WSI\nclassification and tumor detection that does not require localized annotations.\nOur method has three major components. First, we introduce a novel MIL\naggregator that models the relations of the instances in a dual-stream\narchitecture with trainable distance measurement. Second, since WSIs can\nproduce large or unbalanced bags that hinder the training of MIL models, we\npropose to use self-supervised contrastive learning to extract good\nrepresentations for MIL and alleviate the issue of prohibitive memory cost for\nlarge bags. Third, we adopt a pyramidal fusion mechanism for multiscale WSI\nfeatures, and further improve the accuracy of classification and localization.\nOur model is evaluated on two representative WSI datasets. The classification\naccuracy of our model compares favorably to fully-supervised methods, with less\nthan 2% accuracy gap across datasets. Our results also outperform all previous\nMIL-based methods. Additional benchmark results on standard MIL datasets\nfurther demonstrate the superior performance of our MIL aggregator on general\nMIL problems. GitHub repository: https://github.com/binli123/dsmil-wsi\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 20:51:15 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 20:09:13 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 16:48:03 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Li", "Bin", ""], ["Li", "Yin", ""], ["Eliceiri", "Kevin W.", ""]]}, {"id": "2011.08954", "submitter": "Zecheng Zhang", "authors": "Eric Chung, Yalchin Efendiev, Wing Tat Leung, Sai-Mang Pun, Zecheng\n  Zhang", "title": "Multi-agent Reinforcement Learning Accelerated MCMC on Multiscale\n  Inversion Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a multi-agent actor-critic reinforcement learning\n(RL) algorithm to accelerate the multi-level Monte Carlo Markov Chain (MCMC)\nsampling algorithms. The policies (actors) of the agents are used to generate\nthe proposal in the MCMC steps; and the critic, which is centralized, is in\ncharge of estimating the long term reward. We verify our proposed algorithm by\nsolving an inverse problem with multiple scales. There are several difficulties\nin the implementation of this problem by using traditional MCMC sampling.\nFirstly, the computation of the posterior distribution involves evaluating the\nforward solver, which is very time consuming for a problem with heterogeneous.\nWe hence propose to use the multi-level algorithm. More precisely, we use the\ngeneralized multiscale finite element method (GMsFEM) as the forward solver in\nevaluating a posterior distribution in the multi-level rejection procedure.\nSecondly, it is hard to find a function which can generate samplings which are\nmeaningful. To solve this issue, we learn an RL policy as the proposal\ngenerator. Our experiments show that the proposed method significantly improves\nthe sampling process\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 21:25:29 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Chung", "Eric", ""], ["Efendiev", "Yalchin", ""], ["Leung", "Wing Tat", ""], ["Pun", "Sai-Mang", ""], ["Zhang", "Zecheng", ""]]}, {"id": "2011.08968", "submitter": "Qiwei Yuan", "authors": "Qiwei Yuan, Weizhe Hua, Yi Zhou, Cunxi Yu", "title": "Contrastive Weight Regularization for Large Minibatch SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minibatch stochastic gradient descent method (SGD) is widely applied in\ndeep learning due to its efficiency and scalability that enable training deep\nnetworks with a large volume of data. Particularly in the distributed setting,\nSGD is usually applied with large batch size. However, as opposed to\nsmall-batch SGD, neural network models trained with large-batch SGD can hardly\ngeneralize well, i.e., the validation accuracy is low. In this work, we\nintroduce a novel regularization technique, namely distinctive regularization\n(DReg), which replicates a certain layer of the deep network and encourages the\nparameters of both layers to be diverse. The DReg technique introduces very\nlittle computation overhead. Moreover, we empirically show that optimizing the\nneural network with DReg using large-batch SGD achieves a significant boost in\nthe convergence and improved generalization performance. We also demonstrate\nthat DReg can boost the convergence of large-batch SGD with momentum. We\nbelieve that DReg can be used as a simple regularization trick to accelerate\nlarge-batch training in deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 22:07:38 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yuan", "Qiwei", ""], ["Hua", "Weizhe", ""], ["Zhou", "Yi", ""], ["Yu", "Cunxi", ""]]}, {"id": "2011.08970", "submitter": "Ben Marinberg", "authors": "Ben Marinberg, Ariel Cohen, Eilam Ben-Dror and Haim Permuter", "title": "A Study on MIMO Channel Estimation by 2D and 3D Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the usage of Convolutional Neural Network (CNN)\nestimators for the task of Multiple-Input-Multiple-Output Orthogonal Frequency\nDivision Multiplexing (MIMO-OFDM) Channel Estimation (CE). Specifically, the\nCNN estimators interpolate the channel values of reference signals for\nestimating the channel of the full OFDM resource element (RE) matrix. We have\ndesigned a 2D CNN architecture based on U-net, and a 3D CNN architecture for\nhandling spatial correlation. We investigate the performance of various CNN\narchitectures fora diverse data set generated according to the 5G NR standard\nand in particular, we investigate the influence of spatial correlation,\nDoppler, and reference signal resource allocation. The CE CNN estimators are\nthen integrated with MIMO detection algorithms for testing their influence on\nthe system level Bit Error Rate(BER) performance.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 12:24:14 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Marinberg", "Ben", ""], ["Cohen", "Ariel", ""], ["Ben-Dror", "Eilam", ""], ["Permuter", "Haim", ""]]}, {"id": "2011.08977", "submitter": "Nemath Ahmed", "authors": "Nemath Ahmed, Aashit Singh, Srivyshnav KS, Gulshan Kumar, Gaurav\n  Parchani, Vibhor Saran", "title": "Classification Of Sleep-Wake State In A Ballistocardiogram System Based\n  On Deep Learning", "comments": "11 Pages, 4 Figues, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep state classification is vital in managing and understanding sleep\npatterns and is generally the first step in identifying acute or chronic sleep\ndisorders. However, it is essential to do this without affecting the natural\nenvironment or conditions of the subject during their sleep. Techniques such as\nPolysomnography(PSG) are obtrusive and are not convenient for regular sleep\nmonitoring. Fortunately, The rise of novel technologies and advanced computing\nhas given a recent resurgence to monitoring sleep techniques. One such\ncontactless and unobtrusive monitoring technique is Ballistocradiography(BCG),\nin which vitals are monitored by measuring the body's reaction to the cardiac\nejection of blood. In this study, we propose a Multi-Head 1D-Convolution based\nDeep Neural Network to classify sleep-wake state and predict sleep-wake time\naccurately using the signals coming from a BCG sensor. Our method achieves a\nsleep-wake classification score of 95.5%, which is on par with researches based\non the PSG system. We further conducted two independent studies in a controlled\nand uncontrolled environment to test the sleep-wake prediction accuracy. We\nachieve a score of 94.16% in a controlled environment on 115 subjects and\n94.90% in an uncontrolled environment on 350 subjects. The high accuracy and\ncontactless nature of the proposed system make it a convenient method for long\nterm monitoring of sleep states.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 03:38:33 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ahmed", "Nemath", ""], ["Singh", "Aashit", ""], ["KS", "Srivyshnav", ""], ["Kumar", "Gulshan", ""], ["Parchani", "Gaurav", ""], ["Saran", "Vibhor", ""]]}, {"id": "2011.08978", "submitter": "Alan Rezazadeh", "authors": "Alan Rezazadeh", "title": "Environmental Pollution Prediction of NOx by Process Analysis and\n  Predictive Modelling in Natural Gas Turbine Power Plants", "comments": "12 pages, 9 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.ao-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of this paper is to propose K-Nearest-Neighbor (KNN)\nalgorithm for predicting NOx emissions from natural gas electrical generation\nturbines. The process of producing electricity is dynamic and rapidly changing\ndue to many factors such as weather and electrical grid requirements. Gas\nturbine equipment are also a dynamic part of the electricity generation since\nthe equipment characteristics and thermodynamics behavior change as the\nturbines age. Regular maintenance of turbines are also another dynamic part of\nthe electrical generation process, affecting the performance of equipment. This\nanalysis discovered using KNN, trained on relatively small dataset produces the\nmost accurate prediction rates. This statement can be logically explained as\nKNN finds the K nearest neighbor to the current input parameters and estimates\na rated average of historically similar observations as prediction.\n  This paper incorporates ambient weather conditions, electrical output as well\nas turbine performance factors to build a machine learning model to predict NOx\nemissions. The model can be used to optimize the operational processes for\nreduction in harmful emissions and increasing overall operational efficiency.\nLatent algorithms such as Principle Component Algorithms (PCA) have been used\nfor monitoring the equipment performance behavior change which deeply\ninfluences process paraments and consequently determines NOx emissions. Typical\nstatistical methods of machine learning performance evaluations such as\nmultivariate analysis, clustering and residual analysis have been used\nthroughout the paper.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:01:58 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 17:41:21 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Rezazadeh", "Alan", ""]]}, {"id": "2011.08981", "submitter": "Xiangyu Gao", "authors": "Xiangyu Gao, Guanbin Xing, Sumit Roy, and Hui Liu", "title": "RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object\n  Recognition", "comments": "15 pages", "journal-ref": "IEEE Sensor Journal, 2020", "doi": "10.1109/JSEN.2020.3036047", "report-no": null, "categories": "eess.SP cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave (mmW) radars are being increasingly integrated into\ncommercial vehicles to support new advanced driver-assistance systems (ADAS) by\nenabling robust and high-performance object detection, localization, as well as\nrecognition - a key component of new environmental perception. In this paper,\nwe propose a novel radar multiple-perspectives convolutional neural network\n(RAMP-CNN) that extracts the location and class of objects based on further\nprocessing of the range-velocity-angle (RVA) heatmap sequences. To bypass the\ncomplexity of 4D convolutional neural networks (NN), we propose to combine\nseveral lower-dimension NN models within our RAMP-CNN model that nonetheless\napproaches the performance upper-bound with lower complexity. The extensive\nexperiments show that the proposed RAMP-CNN model achieves better average\nrecall (AR) and average precision (AP) than prior works in all testing\nscenarios (see Table. III). Besides, the RAMP-CNN model is validated to work\nrobustly under the nighttime, which enables low-cost radars as a potential\nsubstitute for pure optical sensing under severe conditions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 19:12:12 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Gao", "Xiangyu", ""], ["Xing", "Guanbin", ""], ["Roy", "Sumit", ""], ["Liu", "Hui", ""]]}, {"id": "2011.08982", "submitter": "Zaid Bin Tariq", "authors": "Zaid Bin Tariq, Arun Iyengar, Lara Marcuse, Hui Su, B\\\"ulent Yener", "title": "Patient-Specific Seizure Prediction Using Single Seizure\n  Electroencephalography Recording", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalogram (EEG) is a prominent way to measure the brain activity\nfor studying epilepsy, thereby helping in predicting seizures. Seizure\nprediction is an active research area with many deep learning based approaches\ndominating the recent literature for solving this problem. But these models\nrequire a considerable number of patient-specific seizures to be recorded for\nextracting the preictal and interictal EEG data for training a classifier. The\nincrease in sensitivity and specificity for seizure prediction using the\nmachine learning models is noteworthy. However, the need for a significant\nnumber of patient-specific seizures and periodic retraining of the model\nbecause of non-stationary EEG creates difficulties for designing practical\ndevice for a patient. To mitigate this process, we propose a Siamese neural\nnetwork based seizure prediction method that takes a wavelet transformed EEG\ntensor as an input with convolutional neural network (CNN) as the base network\nfor detecting change-points in EEG. Compared to the solutions in the\nliterature, which utilize days of EEG recordings, our method only needs one\nseizure for training which translates to less than ten minutes of preictal and\ninterictal data while still getting comparable results to models which utilize\nmultiple seizures for seizure prediction.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 03:45:17 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Tariq", "Zaid Bin", ""], ["Iyengar", "Arun", ""], ["Marcuse", "Lara", ""], ["Su", "Hui", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2011.08985", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Ankur Handa, Dieter Fox, Fabio Ramos", "title": "A User's Guide to Calibrating Robotics Simulators", "comments": "Accepted at Conference on Robot Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulators are a critical component of modern robotics research. Strategies\nfor both perception and decision making can be studied in simulation first\nbefore deployed to real world systems, saving on time and costs. Despite\nsignificant progress on the development of sim-to-real algorithms, the analysis\nof different methods is still conducted in an ad-hoc manner, without a\nconsistent set of tests and metrics for comparison. This paper fills this gap\nand proposes a set of benchmarks and a framework for the study of various\nalgorithms aimed to transfer models and policies learnt in simulation to the\nreal world. We conduct experiments on a wide range of well known simulated\nenvironments to characterize and offer insights into the performance of\ndifferent algorithms. Our analysis can be useful for practitioners working in\nthis area and can help make informed choices about the behavior and main\nproperties of sim-to-real algorithms. We open-source the benchmark, training\ndata, and trained models, which can be found at\nhttps://github.com/NVlabs/sim-parameter-estimation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 22:24:26 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Mehta", "Bhairav", ""], ["Handa", "Ankur", ""], ["Fox", "Dieter", ""], ["Ramos", "Fabio", ""]]}, {"id": "2011.08992", "submitter": "Jayant Gupta", "authors": "Jayant Gupta (1), Yiqun Xie (1) and Shashi Shekhar (1) ((1) University\n  of Minnesota)", "title": "Towards Spatial Variability Aware Deep Neural Networks (SVANN): A\n  Summary of Results", "comments": "Accepted in 1st ACM SIGKDD Workshop on Deep Learning for\n  Spatiotemporal Data, Applications, and Systems (Deepspatial 2020), San Diego,\n  CA, August 24, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spatial variability has been observed in many geo-phenomena including\nclimatic zones, USDA plant hardiness zones, and terrestrial habitat types\n(e.g., forest, grasslands, wetlands, and deserts). However, current deep\nlearning methods follow a spatial-one-size-fits-all(OSFA) approach to train\nsingle deep neural network models that do not account for spatial variability.\nIn this work, we propose and investigate a spatial-variability aware deep\nneural network(SVANN) approach, where distinct deep neural network models are\nbuilt for each geographic area. We evaluate this approach using aerial imagery\nfrom two geographic areas for the task of mapping urban gardens. The\nexperimental results show that SVANN provides better performance than OSFA in\nterms of precision, recall,and F1-score to identify urban gardens.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 22:52:40 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Gupta", "Jayant", ""], ["Xie", "Yiqun", ""], ["Shekhar", "Shashi", ""]]}, {"id": "2011.09004", "submitter": "Rebecca Russell", "authors": "Aastha Acharya, Rebecca Russell, Nisar R. Ahmed", "title": "Explaining Conditions for Reinforcement Learning Behaviors from Real and\n  Imagined Data", "comments": "Accepted to the Workshop on Challenges of Real-World RL at NeurIPS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of reinforcement learning (RL) in the real world comes with\nchallenges in calibrating user trust and expectations. As a step toward\ndeveloping RL systems that are able to communicate their competencies, we\npresent a method of generating human-interpretable abstract behavior models\nthat identify the experiential conditions leading to different task execution\nstrategies and outcomes. Our approach consists of extracting experiential\nfeatures from state representations, abstracting strategy descriptors from\ntrajectories, and training an interpretable decision tree that identifies the\nconditions most predictive of different RL behaviors. We demonstrate our method\non trajectory data generated from interactions with the environment and on\nimagined trajectory data that comes from a trained probabilistic world model in\na model-based RL setting.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 23:40:47 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Acharya", "Aastha", ""], ["Russell", "Rebecca", ""], ["Ahmed", "Nisar R.", ""]]}, {"id": "2011.09011", "submitter": "Dilin Wang", "authors": "Dilin Wang, Meng Li, Chengyue Gong, Vikas Chandra", "title": "AttentiveNAS: Improving Neural Architecture Search via Attentive\n  Sampling", "comments": "2021 Conference on Computer Vision and Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural architecture search (NAS) has shown great promise in designing\nstate-of-the-art (SOTA) models that are both accurate and efficient. Recently,\ntwo-stage NAS, e.g. BigNAS, decouples the model training and searching process\nand achieves remarkable search efficiency and accuracy. Two-stage NAS requires\nsampling from the search space during training, which directly impacts the\naccuracy of the final searched models. While uniform sampling has been widely\nused for its simplicity, it is agnostic of the model performance Pareto front,\nwhich is the main focus in the search process, and thus, misses opportunities\nto further improve the model accuracy. In this work, we propose AttentiveNAS\nthat focuses on improving the sampling strategy to achieve better performance\nPareto. We also propose algorithms to efficiently and effectively identify the\nnetworks on the Pareto during training. Without extra re-training or\npost-processing, we can simultaneously obtain a large number of networks across\na wide range of FLOPs. Our discovered model family, AttentiveNAS models,\nachieves top-1 accuracy from 77.3% to 80.7% on ImageNet, and outperforms SOTA\nmodels, including BigNAS and Once-for-All networks. We also achieve ImageNet\naccuracy of 80.1% with only 491 MFLOPs. Our training code and pretrained models\nare available at https://github.com/facebookresearch/AttentiveNAS.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 00:15:23 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 19:17:16 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Wang", "Dilin", ""], ["Li", "Meng", ""], ["Gong", "Chengyue", ""], ["Chandra", "Vikas", ""]]}, {"id": "2011.09013", "submitter": "Zhu Liu", "authors": "Xinyu Dou, Cuijuan Liao, Hengqi Wang, Ying Huang, Ying Tu, Xiaomeng\n  Huang, Yiran Peng, Biqing Zhu, Jianguang Tan, Zhu Deng, Nana Wu, Taochun Sun,\n  Piyu Ke, Zhu Liu", "title": "Estimates of daily ground-level NO2 concentrations in China based on big\n  data and machine learning approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nitrogen dioxide (NO2) is one of the most important atmospheric pollutants.\nHowever, current ground-level NO2 concentration data are lack of either\nhigh-resolution coverage or full coverage national wide, due to the poor\nquality of source data and the computing power of the models. To our knowledge,\nthis study is the first to estimate the ground-level NO2 concentration in China\nwith national coverage as well as relatively high spatiotemporal resolution\n(0.25 degree; daily intervals) over the newest past 6 years (2013-2018). We\nadvanced a Random Forest model integrated K-means (RF-K) for the estimates with\nmulti-source parameters. Besides meteorological parameters, satellite\nretrievals parameters, we also, for the first time, introduce socio-economic\nparameters to assess the impact by human activities. The results show that: (1)\nthe RF-K model we developed shows better prediction performance than other\nmodels, with cross-validation R2 = 0.64 (MAPE = 34.78%). (2) The annual average\nconcentration of NO2 in China showed a weak increasing trend . While in the\neconomic zones such as Beijing-Tianjin-Hebei region, Yangtze River Delta, and\nPearl River Delta, the NO2 concentration there even decreased or remained\nunchanged, especially in spring. Our dataset has verified that pollutant\ncontrolling targets have been achieved in these areas. With mapping daily\nnationwide ground-level NO2 concentrations, this study provides timely data\nwith high quality for air quality management for China. We provide a universal\nmodel framework to quickly generate a timely national atmospheric pollutants\nconcentration map with a high spatial-temporal resolution, based on improved\nmachine learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 00:24:40 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Dou", "Xinyu", ""], ["Liao", "Cuijuan", ""], ["Wang", "Hengqi", ""], ["Huang", "Ying", ""], ["Tu", "Ying", ""], ["Huang", "Xiaomeng", ""], ["Peng", "Yiran", ""], ["Zhu", "Biqing", ""], ["Tan", "Jianguang", ""], ["Deng", "Zhu", ""], ["Wu", "Nana", ""], ["Sun", "Taochun", ""], ["Ke", "Piyu", ""], ["Liu", "Zhu", ""]]}, {"id": "2011.09015", "submitter": "Sandipan Das", "authors": "Sandipan Das, Prakash B. Gohain, Alireza M. Javid, Yonina C. Eldar,\n  Saikat Chatterjee", "title": "Statistical model-based evaluation of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using a statistical model-based data generation, we develop an experimental\nsetup for the evaluation of neural networks (NNs). The setup helps to benchmark\na set of NNs vis-a-vis minimum-mean-square-error (MMSE) performance bounds.\nThis allows us to test the effects of training data size, data dimension, data\ngeometry, noise, and mismatch between training and testing conditions. In the\nproposed setup, we use a Gaussian mixture distribution to generate data for\ntraining and testing a set of competing NNs. Our experiments show the\nimportance of understanding the type and statistical conditions of data for\nappropriate application and design of NNs\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 00:33:24 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Das", "Sandipan", ""], ["Gohain", "Prakash B.", ""], ["Javid", "Alireza M.", ""], ["Eldar", "Yonina C.", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "2011.09038", "submitter": "Manuel Florez", "authors": "Manuel A. Florez, Michaelangelo Caporale, Pakpoom Buabthong, Zachary\n  E. Ross, Domniki Asimaki and Men-Andrin Meier", "title": "Data-driven Accelerogram Synthesis using Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust estimation of ground motions generated by scenario earthquakes is\ncritical for many engineering applications. We leverage recent advances in\nGenerative Adversarial Networks (GANs) to develop a new framework for\nsynthesizing earthquake acceleration time histories. Our approach extends the\nWasserstein GAN formulation to allow for the generation of ground-motions\nconditioned on a set of continuous physical variables. Our model is trained to\napproximate the intrinsic probability distribution of a massive set of\nstrong-motion recordings from Japan. We show that the trained generator model\ncan synthesize realistic 3-Component accelerograms conditioned on magnitude,\ndistance, and $V_{s30}$. Our model captures the expected statistical features\nof the acceleration spectra and waveform envelopes. The output seismograms\ndisplay clear P and S-wave arrivals with the appropriate energy content and\nrelative onset timing. The synthesized Peak Ground Acceleration (PGA) estimates\nare also consistent with observations. We develop a set of metrics that allow\nus to assess the training process's stability and tune model hyperparameters.\nWe further show that the trained generator network can interpolate to\nconditions where no earthquake ground motion recordings exist. Our approach\nallows the on-demand synthesis of accelerograms for engineering purposes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:12:14 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Florez", "Manuel A.", ""], ["Caporale", "Michaelangelo", ""], ["Buabthong", "Pakpoom", ""], ["Ross", "Zachary E.", ""], ["Asimaki", "Domniki", ""], ["Meier", "Men-Andrin", ""]]}, {"id": "2011.09039", "submitter": "Demi Guo", "authors": "Demi Guo, Yoon Kim and Alexander M. Rush", "title": "Sequence-Level Mixed Sample Data Augmentation", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite their empirical success, neural networks still have difficulty\ncapturing compositional aspects of natural language. This work proposes a\nsimple data augmentation approach to encourage compositional behavior in neural\nmodels for sequence-to-sequence problems. Our approach, SeqMix, creates new\nsynthetic examples by softly combining input/output sequences from the training\nset. We connect this approach to existing techniques such as SwitchOut and word\ndropout, and show that these techniques are all approximating variants of a\nsingle objective. SeqMix consistently yields approximately 1.0 BLEU improvement\non five different translation datasets over strong Transformer baselines. On\ntasks that require strong compositional generalization such as SCAN and\nsemantic parsing, SeqMix also offers further improvements.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:18:04 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Guo", "Demi", ""], ["Kim", "Yoon", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2011.09052", "submitter": "Naftali Cohen", "authors": "Naftali Cohen, Srijan Sood, Zhen Zeng, Tucker Balch, and Manuela\n  Veloso", "title": "Visual Forecasting of Time Series with Image-to-Image Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is essential for agents to make decisions in many\ndomains. Existing models rely on classical statistical methods to predict\nfuture values based on previously observed numerical information. Yet,\npractitioners often rely on visualizations such as charts and plots to reason\nabout their predictions. Inspired by the end-users, we re-imagine the topic by\ncreating a framework to produce visual forecasts, similar to the way humans\nintuitively do. In this work, we take a novel approach by leveraging advances\nin deep learning to extend the field of time series forecasting to a visual\nsetting. We do this by transforming the numerical analysis problem into the\ncomputer vision domain. Using visualizations of time series data as input, we\ntrain a convolutional autoencoder to produce corresponding visual forecasts. We\nexamine various synthetic and real datasets with diverse degrees of complexity.\nOur experiments show that visual forecasting is effective for cyclic data but\nsomewhat less for irregular data such as stock price. Importantly, we find the\nproposed visual forecasting method to outperform numerical baselines. We\nattribute the success of the visual forecasting approach to the fact that we\nconvert the continuous numerical regression problem into a discrete domain with\nquantization of the continuous target signal into pixel space.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:51:37 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Cohen", "Naftali", ""], ["Sood", "Srijan", ""], ["Zeng", "Zhen", ""], ["Balch", "Tucker", ""], ["Veloso", "Manuela", ""]]}, {"id": "2011.09068", "submitter": "Felix Wolf Hans Erich von Drigalski", "authors": "Felix von Drigalski, Devwrat Joshi, Takayuki Murooka, Kazutoshi\n  Tanaka, Masashi Hamaya and Yoshihisa Ijiri", "title": "An analytical diabolo model for robotic learning and control", "comments": "Video: https://youtu.be/oS-9mCfKIeY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a diabolo model that can be used for training\nagents in simulation to play diabolo, as well as running it on a real dual\nrobot arm system. We first derive an analytical model of the diabolo-string\nsystem and compare its accuracy using data recorded via motion capture, which\nwe release as a public dataset of skilled play with diabolos of different\ndynamics. We show that our model outperforms a deep-learning-based predictor,\nboth in terms of precision and physically consistent behavior. Next, we\ndescribe a method based on optimal control to generate robot trajectories that\nproduce the desired diabolo trajectory, as well as a system to transform\nhigher-level actions into robot motions. Finally, we test our method on a real\nrobot system by playing the diabolo, and throwing it to and catching it from a\nhuman player.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 03:38:12 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["von Drigalski", "Felix", ""], ["Joshi", "Devwrat", ""], ["Murooka", "Takayuki", ""], ["Tanaka", "Kazutoshi", ""], ["Hamaya", "Masashi", ""], ["Ijiri", "Yoshihisa", ""]]}, {"id": "2011.09083", "submitter": "Yizhou Zhao", "authors": "Yizhou Zhao, Song-Chun Zhu", "title": "Weighted Entropy Modification for Soft Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the existing principle of the maximum Shannon entropy in\nreinforcement learning (RL) to weighted entropy by characterizing the\nstate-action pairs with some qualitative weights, which can be connected with\nprior knowledge, experience replay, and evolution process of the policy. We\npropose an algorithm motivated for self-balancing exploration with the\nintroduced weight function, which leads to state-of-the-art performance on\nMujoco tasks despite its simplicity in implementation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 04:36:03 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Zhao", "Yizhou", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2011.09086", "submitter": "Sana Talmoudi", "authors": "Sana Talmoudi (1), Tetsuya Kanada (2) and Yasuhisa Hirata (3) ((1)\n  Department of Robotics, Graduate Faculty of Engineering, Tohoku University,\n  (2) D'isum Inc.)", "title": "Tracking and Visualizing Signs of Degradation for an Early Failure\n  Prediction of a Rolling Bearing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Predictive maintenance, i.e. predicting failure to be few steps ahead of the\nfault, is one of the pillars of Industry 4.0. An effective method for that is\nto track early signs of degradation before a failure happens. This paper\npresents an innovative failure predictive scheme for machines. The proposed\nscheme combines the use of full spectrum of the vibration data caused by the\nmachines and data visualization technologies. This scheme is featured by no\ntraining data required and by quick start after installation. First, we propose\nto use full spectrum (as high-dimensional data vector) with no cropping and no\ncomplex feature extraction and to visualize data behavior by mapping the high\ndimensional vectors into a 2D map. We then can ensure the simplicity of process\nand less possibility of overlooking of important information as well as\nproviding a human-friendly and human-understandable output. Second, we propose\nReal-Time Data Tracker (RTDT) which predicts the failure at an appropriate time\nwith sufficient time for maintenance by plotting real-time frequency spectrum\ndata of the target machine on the 2D map composed from normal data. Third, we\nshow the test results of our proposal using vibration data of bearings from\nreal-world test-to-failure measurements provided by the public dataset, the IMS\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 04:46:15 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Talmoudi", "Sana", ""], ["Kanada", "Tetsuya", ""], ["Hirata", "Yasuhisa", ""]]}, {"id": "2011.09113", "submitter": "Gaurav Kumar Nayak", "authors": "Gaurav Kumar Nayak, Konda Reddy Mopuri, Anirban Chakraborty", "title": "Effectiveness of Arbitrary Transfer Sets for Data-free Knowledge\n  Distillation", "comments": "Accepted in WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation is an effective method to transfer the learning across\ndeep neural networks. Typically, the dataset originally used for training the\nTeacher model is chosen as the \"Transfer Set\" to conduct the knowledge transfer\nto the Student. However, this original training data may not always be freely\navailable due to privacy or sensitivity concerns. In such scenarios, existing\napproaches either iteratively compose a synthetic set representative of the\noriginal training dataset, one sample at a time or learn a generative model to\ncompose such a transfer set. However, both these approaches involve complex\noptimization (GAN training or several backpropagation steps to synthesize one\nsample) and are often computationally expensive. In this paper, as a simple\nalternative, we investigate the effectiveness of \"arbitrary transfer sets\" such\nas random noise, publicly available synthetic, and natural datasets, all of\nwhich are completely unrelated to the original training dataset in terms of\ntheir visual or semantic contents. Through extensive experiments on multiple\nbenchmark datasets such as MNIST, FMNIST, CIFAR-10 and CIFAR-100, we discover\nand validate surprising effectiveness of using arbitrary data to conduct\nknowledge distillation when this dataset is \"target-class balanced\". We believe\nthat this important observation can potentially lead to designing baselines for\nthe data-free knowledge distillation task.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 06:33:20 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Nayak", "Gaurav Kumar", ""], ["Mopuri", "Konda Reddy", ""], ["Chakraborty", "Anirban", ""]]}, {"id": "2011.09126", "submitter": "Michele Starnini", "authors": "Alberto Aleta, Marta Tuninetti, Daniela Paolotti, Yamir Moreno, and\n  Michele Starnini", "title": "Link prediction in multiplex networks via triadic closure", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.04432", "journal-ref": null, "doi": "10.1103/PhysRevResearch.2.042029", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Link prediction algorithms can help to understand the structure and dynamics\nof complex systems, to reconstruct networks from incomplete data sets and to\nforecast future interactions in evolving networks. Available algorithms based\non similarity between nodes are bounded by the limited amount of links present\nin these networks. In this work, we reduce this latter intrinsic limitation and\nshow that different kind of relational data can be exploited to improve the\nprediction of new links. To this aim, we propose a novel link prediction\nalgorithm by generalizing the Adamic-Adar method to multiplex networks composed\nby an arbitrary number of layers, that encode diverse forms of interactions. We\nshow that the new metric outperforms the classical single-layered Adamic-Adar\nscore and other state-of-the-art methods, across several social, biological and\ntechnological systems. As a byproduct, the coefficients that maximize the\nMultiplex Adamic-Adar metric indicate how the information structured in a\nmultiplex network can be optimized for the link prediction task, revealing\nwhich layers are redundant. Interestingly, this effect can be asymmetric with\nrespect to predictions in different layers. Our work paves the way for a deeper\nunderstanding of the role of different relational data in predicting new\ninteractions and provides a new algorithm for link prediction in multiplex\nnetworks that can be applied to a plethora of systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:25:08 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Aleta", "Alberto", ""], ["Tuninetti", "Marta", ""], ["Paolotti", "Daniela", ""], ["Moreno", "Yamir", ""], ["Starnini", "Michele", ""]]}, {"id": "2011.09128", "submitter": "Moshe Eliasof", "authors": "Moshe Eliasof, Jonathan Ephrath, Lars Ruthotto, Eran Treister", "title": "Multigrid-in-Channels Neural Network Architectures", "comments": "This paper supersedes arXiv:2006.06799", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multigrid-in-channels (MGIC) approach that tackles the quadratic\ngrowth of the number of parameters with respect to the number of channels in\nstandard convolutional neural networks (CNNs). It has been shown that there is\na redundancy in standard CNNs, as networks with light or sparse convolution\noperators yield similar performance to full networks. However, the number of\nparameters in the former networks also scales quadratically in width, while in\nthe latter case, the parameters typically have random sparsity patterns,\nhampering hardware efficiency. Our approach for building CNN architectures\nscales linearly with respect to the network's width while retaining full\ncoupling of the channels as in standard CNNs. To this end, we replace each\nconvolution block with its MGIC block utilizing a hierarchy of lightweight\nconvolutions. Our extensive experiments on image classification, segmentation,\nand point cloud classification show that applying this strategy to different\narchitectures like ResNet and MobileNetV3 considerably reduces the number of\nparameters while obtaining similar or better accuracy. For example, we obtain\n76.1% top-1 accuracy on ImageNet with a lightweight network with similar\nparameters and FLOPs to MobileNetV3.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:29:10 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 08:29:31 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Eliasof", "Moshe", ""], ["Ephrath", "Jonathan", ""], ["Ruthotto", "Lars", ""], ["Treister", "Eran", ""]]}, {"id": "2011.09141", "submitter": "Christoph Rist", "authors": "Christoph B. Rist, David Emmerichs, Markus Enzweiler and Dariu M.\n  Gavrila", "title": "Semantic Scene Completion using Local Deep Implicit Functions on LiDAR\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic scene completion is the task of jointly estimating 3D geometry and\nsemantics of objects and surfaces within a given extent. This is a particularly\nchallenging task on real-world data that is sparse and occluded. We propose a\nscene segmentation network based on local Deep Implicit Functions as a novel\nlearning-based method for scene completion. Unlike previous work on scene\ncompletion, our method produces a continuous scene representation that is not\nbased on voxelization. We encode raw point clouds into a latent space locally\nand at multiple spatial resolutions. A global scene completion function is\nsubsequently assembled from the localized function patches. We show that this\ncontinuous representation is suitable to encode geometric and semantic\nproperties of extensive outdoor scenes without the need for spatial\ndiscretization (thus avoiding the trade-off between level of scene detail and\nthe scene extent that can be covered).\n  We train and evaluate our method on semantically annotated LiDAR scans from\nthe Semantic KITTI dataset. Our experiments verify that our method generates a\npowerful representation that can be decoded into a dense 3D description of a\ngiven scene. The performance of our method surpasses the state of the art on\nthe Semantic KITTI Scene Completion Benchmark in terms of geometric completion\nintersection-over-union (IoU).\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 07:39:13 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 08:11:23 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 20:40:12 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Rist", "Christoph B.", ""], ["Emmerichs", "David", ""], ["Enzweiler", "Markus", ""], ["Gavrila", "Dariu M.", ""]]}, {"id": "2011.09148", "submitter": "Ke Wang", "authors": "Ke Wang, Christos Thrampoulidis", "title": "Binary Classification of Gaussian Mixtures: Abundance of Support\n  Vectors, Benign Overfitting and Regularization", "comments": "New results: Extensions to correlated features and\n  ridge-regularization; Additional numerical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep neural networks generalize well despite being exceedingly\noverparameterized and being trained without explicit regularization. This\ncurious phenomenon, often termed benign overfitting, has inspired extensive\nresearch activity in establishing its statistical principles: Under what\nconditions is the phenomenon observed? How do these depend on the data and on\nthe training algorithm? When does regularization benefit generalization? While\nthese questions remain wide open for deep neural nets, recent works have\nattempted gaining insights by studying simpler, often linear, models. Our paper\ncontributes to this growing line of work by examining binary linear\nclassification under the popular generative Gaussian mixture model. Motivated\nby recent results on the implicit bias of gradient descent, we study both\nmax-margin SVM classifiers (corresponding to logistic loss) and min-norm\ninterpolating classifiers (corresponding to least-squares loss). First, we\nleverage an idea introduced in [V. Muthukumar et al., arXiv:2005.08054, (2020)]\nto relate the SVM solution to the least-squares (LS) interpolating solution.\nSecond, we derive novel non-asymptotic bounds on the classification error of\nthe LS solution. Combining the two, we present novel sufficient conditions on\nthe overparameterization ratio and on the signal-to-noise ratio (SNR) for\nbenign overfitting to occur. Contrary to previously studied discriminative data\nmodels, our results emphasize the crucial role of the SNR. Moreover, we\ninvestigate the role of regularization and identify precise conditions under\nwhich the interpolating estimator performs better than the regularized\nestimates. We corroborate our theoretical findings with numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 07:59:55 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 04:35:42 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 01:07:30 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wang", "Ke", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "2011.09153", "submitter": "Yang Fang", "authors": "Yang Fang, Geun-Sik Jo and Chang-Hee Lee", "title": "RSINet: Rotation-Scale Invariant Network for Online Visual Tracking", "comments": "8 pages, 5 figures, the paper has been accepted by international\n  conference on pattern recognition 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most Siamese network-based trackers perform the tracking process without\nmodel update, and cannot learn targetspecific variation adaptively. Moreover,\nSiamese-based trackers infer the new state of tracked objects by generating\naxis-aligned bounding boxes, which contain extra background noise, and are\nunable to accurately estimate the rotation and scale transformation of moving\nobjects, thus potentially reducing tracking performance. In this paper, we\npropose a novel Rotation-Scale Invariant Network (RSINet) to address the above\nproblem. Our RSINet tracker consists of a target-distractor discrimination\nbranch and a rotation-scale estimation branch, the rotation and scale knowledge\ncan be explicitly learned by a multi-task learning method in an end-to-end\nmanner. In addtion, the tracking model is adaptively optimized and updated\nunder spatio-temporal energy control, which ensures model stability and\nreliability, as well as high tracking efficiency. Comprehensive experiments on\nOTB-100, VOT2018, and LaSOT benchmarks demonstrate that our proposed RSINet\ntracker yields new state-of-the-art performance compared with recent trackers,\nwhile running at real-time speed about 45 FPS.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 08:19:14 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Fang", "Yang", ""], ["Jo", "Geun-Sik", ""], ["Lee", "Chang-Hee", ""]]}, {"id": "2011.09161", "submitter": "Yuanjun Xiong", "authors": "Sijie Yan, Yuanjun Xiong, Kaustav Kundu, Shuo Yang, Siqi Deng, Meng\n  Wang, Wei Xia, Stefano Soatto", "title": "Positive-Congruent Training: Towards Regression-Free Model Updates", "comments": "Accepted to CVPR 2021 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing inconsistencies in the behavior of different versions of an AI\nsystem can be as important in practice as reducing its overall error. In image\nclassification, sample-wise inconsistencies appear as \"negative flips\": A new\nmodel incorrectly predicts the output for a test sample that was correctly\nclassified by the old (reference) model. Positive-congruent (PC) training aims\nat reducing error rate while at the same time reducing negative flips, thus\nmaximizing congruency with the reference model only on positive predictions,\nunlike model distillation. We propose a simple approach for PC training, Focal\nDistillation, which enforces congruence with the reference model by giving more\nweights to samples that were correctly classified. We also found that, if the\nreference model itself can be chosen as an ensemble of multiple deep neural\nnetworks, negative flips can be further reduced without affecting the new\nmodel's accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 09:00:44 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 17:00:29 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 20:10:51 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yan", "Sijie", ""], ["Xiong", "Yuanjun", ""], ["Kundu", "Kaustav", ""], ["Yang", "Shuo", ""], ["Deng", "Siqi", ""], ["Wang", "Meng", ""], ["Xia", "Wei", ""], ["Soatto", "Stefano", ""]]}, {"id": "2011.09172", "submitter": "Nontawat Charoenphakdee", "authors": "Nontawat Charoenphakdee, Jayakorn Vongkulbhisal, Nuttapong\n  Chairatanakul, Masashi Sugiyama", "title": "On Focal Loss for Class-Posterior Probability Estimation: A Theoretical\n  Perspective", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focal loss has demonstrated its effectiveness in many real-world\napplications such as object detection and image classification, but its\ntheoretical understanding has been limited so far. In this paper, we first\nprove that the focal loss is classification-calibrated, i.e., its minimizer\nsurely yields the Bayes-optimal classifier and thus the use of the focal loss\nin classification can be theoretically justified. However, we also prove a\nnegative fact that the focal loss is not strictly proper, i.e., the confidence\nscore of the classifier obtained by focal loss minimization does not match the\ntrue class-posterior probability and thus it is not reliable as a\nclass-posterior probability estimator. To mitigate this problem, we next prove\nthat a particular closed-form transformation of the confidence score allows us\nto recover the true class-posterior probability. Through experiments on\nbenchmark datasets, we demonstrate that our proposed transformation\nsignificantly improves the accuracy of class-posterior probability estimation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 09:36:52 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 04:15:40 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Charoenphakdee", "Nontawat", ""], ["Vongkulbhisal", "Jayakorn", ""], ["Chairatanakul", "Nuttapong", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2011.09193", "submitter": "Samson Lasaulce", "authors": "L. Busoniu, V. S. Varma, J. Loheac, A. Codrean, O. Stefan, I.-C.\n  Morarescu, and S. Lasaulce", "title": "Learning control for transmission and navigation with a mobile robot\n  under unknown communication rates", "comments": "Control Engineering Practice, Elsevier, Vol. 100, July 2020, 104460", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In tasks such as surveying or monitoring remote regions, an autonomous robot\nmust move while transmitting data over a wireless network with unknown,\nposition-dependent transmission rates. For such a robot, this paper considers\nthe problem of transmitting a data buffer in minimum time, while possibly also\nnavigating towards a goal position. Two approaches are proposed, each\nconsisting of a machine-learning component that estimates the rate function\nfrom samples; and of an optimal-control component that moves the robot given\nthe current rate function estimate. Simple obstacle avoidance is performed for\nthe case without a goal position. In extensive simulations, these methods\nachieve competitive performance compared to known-rate and unknown-rate\nbaselines. A real indoor experiment is provided in which a Parrot AR.Drone 2\nsuccessfully learns to transmit the buffer.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 10:26:15 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Busoniu", "L.", ""], ["Varma", "V. S.", ""], ["Loheac", "J.", ""], ["Codrean", "A.", ""], ["Stefan", "O.", ""], ["Morarescu", "I. -C.", ""], ["Lasaulce", "S.", ""]]}, {"id": "2011.09216", "submitter": "Nishant Bhattacharya", "authors": "Nishant Bhattacharya and Suresh Sundaram", "title": "CGAP2: Context and gap aware predictive pose framework for early\n  detection of gestures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With a growing interest in autonomous vehicles' operation, there is an\nequally increasing need for efficient anticipatory gesture recognition systems\nfor human-vehicle interaction. Existing gesture-recognition algorithms have\nbeen primarily restricted to historical data. In this paper, we propose a novel\ncontext and gap aware pose prediction framework(CGAP2), which predicts future\npose data for anticipatory recognition of gestures in an online fashion. CGAP2\nimplements an encoder-decoder architecture paired with a pose prediction module\nto anticipate future frames followed by a shallow classifier. CGAP2 pose\nprediction module uses 3D convolutional layers and depends on the number of\npose frames supplied, the time difference between each pose frame, and the\nnumber of predicted pose frames. The performance of CGAP2 is evaluated on the\nHuman3.6M dataset with the MPJPE metric. For pose prediction of 15 frames in\nadvance, an error of 79.0mm is achieved. The pose prediction module consists of\nonly 26M parameters and can run at 50 FPS on the NVidia RTX Titan. Furthermore,\nthe ablation study indicates supplying higher context information to the pose\nprediction module can be detrimental for anticipatory recognition. CGAP2 has a\n1-second time advantage compared to other gesture recognition systems, which\ncan be crucial for autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 11:21:04 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Bhattacharya", "Nishant", ""], ["Sundaram", "Suresh", ""]]}, {"id": "2011.09236", "submitter": "Frank Glavin", "authors": "Preeti Jagdish Sajjan and Frank G. Glavin", "title": "A Multi-class Approach -- Building a Visual Classifier based on Textual\n  Descriptions using Zero-Shot Learning", "comments": "AICS 2020: Irish Conference on Artificial Intelligence and Cognitive\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) techniques for image classification routinely require\nmany labelled images for training the model and while testing, we ought to use\nimages belonging to the same domain as those used for training. In this paper,\nwe overcome the two main hurdles of ML, i.e. scarcity of data and constrained\nprediction of the classification model. We do this by introducing a visual\nclassifier which uses a concept of transfer learning, namely Zero-Shot Learning\n(ZSL), and standard Natural Language Processing techniques. We train a\nclassifier by mapping labelled images to their textual description instead of\ntraining it for specific classes. Transfer learning involves transferring\nknowledge across domains that are similar. ZSL intelligently applies the\nknowledge learned while training for future recognition tasks. ZSL\ndifferentiates classes as two types: seen and unseen classes. Seen classes are\nthe classes upon which we have trained our model and unseen classes are the\nclasses upon which we test our model. The examples from unseen classes have not\nbeen encountered in the training phase. Earlier research in this domain focused\non developing a binary classifier but, in this paper, we present a multi-class\nclassifier with a Zero-Shot Learning approach.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 12:06:55 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Sajjan", "Preeti Jagdish", ""], ["Glavin", "Frank G.", ""]]}, {"id": "2011.09241", "submitter": "Francesco Salvetti", "authors": "Enrico Sutera, Vittorio Mazzia, Francesco Salvetti, Giovanni Fantin\n  and Marcello Chiaberge", "title": "Indoor Point-to-Point Navigation with Deep Reinforcement Learning and\n  Ultra-wideband", "comments": "Accepted by ICAART 2021 - http://www.icaart.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Indoor autonomous navigation requires a precise and accurate localization\nsystem able to guide robots through cluttered, unstructured and dynamic\nenvironments. Ultra-wideband (UWB) technology, as an indoor positioning system,\noffers precise localization and tracking, but moving obstacles and\nnon-line-of-sight occurrences can generate noisy and unreliable signals. That,\ncombined with sensors noise, unmodeled dynamics and environment changes can\nresult in a failure of the guidance algorithm of the robot. We demonstrate how\na power-efficient and low computational cost point-to-point local planner,\nlearnt with deep reinforcement learning (RL), combined with UWB localization\ntechnology can constitute a robust and resilient to noise short-range guidance\nsystem complete solution. We trained the RL agent on a simulated environment\nthat encapsulates the robot dynamics and task constraints and then, we tested\nthe learnt point-to-point navigation policies in a real setting with more than\ntwo-hundred experimental evaluations using UWB localization. Our results show\nthat the computational efficient end-to-end policy learnt in plain simulation,\nthat directly maps low-range sensors signals to robot controls, deployed in\ncombination with ultra-wideband noisy localization in a real environment, can\nprovide a robust, scalable and at-the-edge low-cost navigation system solution.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 12:30:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Sutera", "Enrico", ""], ["Mazzia", "Vittorio", ""], ["Salvetti", "Francesco", ""], ["Fantin", "Giovanni", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2011.09246", "submitter": "Leo Dostal", "authors": "Leo Dostal, Alexej Bespalko, and Daniel A. Duecker", "title": "Experimental Study on Reinforcement Learning-based Control of an Acrobot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present computational and experimental results on how artificial\nintelligence (AI) learns to control an Acrobot using reinforcement learning\n(RL). Thereby the experimental setup is designed as an embedded system, which\nis of interest for robotics and energy harvesting applications. Specifically,\nwe study the control of angular velocity of the Acrobot, as well as control of\nits total energy, which is the sum of the kinetic and the potential energy. By\nthis means the RL algorithm is designed to drive the angular velocity or the\nenergy of the first pendulum of the Acrobot towards a desired value. With this,\nlibration or full rotation of the unactuated pendulum of the Acrobot is\nachieved. Moreover, investigations of the Acrobot control are carried out,\nwhich lead to insights about the influence of the state space discretization,\nthe episode length, the action space or the mass of the driven pendulum on the\nRL control. By further numerous simulations and experiments the effects of\nparameter variations are evaluated.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 12:37:25 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Dostal", "Leo", ""], ["Bespalko", "Alexej", ""], ["Duecker", "Daniel A.", ""]]}, {"id": "2011.09257", "submitter": "Pablo Pino", "authors": "Pablo Pino, Denis Parra, Pablo Messina, Cecilia Besa, Sergio Uribe", "title": "Inspecting state of the art performance and NLP metrics in image-based\n  medical report generation", "comments": "3 pages, 1 figure, 1 table. Accepted in LatinX in AI workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several deep learning architectures have been proposed over the last years to\ndeal with the problem of generating a written report given an imaging exam as\ninput. Most works evaluate the generated reports using standard Natural\nLanguage Processing (NLP) metrics (e.g. BLEU, ROUGE), reporting significant\nprogress. In this article, we contrast this progress by comparing state of the\nart (SOTA) models against weak baselines. We show that simple and even naive\napproaches yield near SOTA performance on most traditional NLP metrics. We\nconclude that evaluation methods in this task should be further studied towards\ncorrectly measuring clinical accuracy, ideally involving physicians to\ncontribute to this end.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:09:12 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 17:58:40 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pino", "Pablo", ""], ["Parra", "Denis", ""], ["Messina", "Pablo", ""], ["Besa", "Cecilia", ""], ["Uribe", "Sergio", ""]]}, {"id": "2011.09264", "submitter": "Luis Haug", "authors": "Luis Haug, Ivan Ovinnikov, Eugene Bykovets", "title": "Inverse Reinforcement Learning via Matching of Optimality Profiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The goal of inverse reinforcement learning (IRL) is to infer a reward\nfunction that explains the behavior of an agent performing a task. The\nassumption that most approaches make is that the demonstrated behavior is\nnear-optimal. In many real-world scenarios, however, examples of truly optimal\nbehavior are scarce, and it is desirable to effectively leverage sets of\ndemonstrations of suboptimal or heterogeneous performance, which are easier to\nobtain. We propose an algorithm that learns a reward function from such\ndemonstrations together with a weak supervision signal in the form of a\ndistribution over rewards collected during the demonstrations (or, more\ngenerally, a distribution over cumulative discounted future rewards). We view\nsuch distributions, which we also refer to as optimality profiles, as summaries\nof the degree of optimality of the demonstrations that may, for example,\nreflect the opinion of a human expert. Given an optimality profile and a small\namount of additional supervision, our algorithm fits a reward function, modeled\nas a neural network, by essentially minimizing the Wasserstein distance between\nthe corresponding induced distribution and the optimality profile. We show that\nour method is capable of learning reward functions such that policies trained\nto optimize them outperform the demonstrations used for fitting the reward\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:23:43 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 08:55:03 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Haug", "Luis", ""], ["Ovinnikov", "Ivan", ""], ["Bykovets", "Eugene", ""]]}, {"id": "2011.09265", "submitter": "Farzad Khalvati", "authors": "Ruqian Hao, Khashayar Namdar, Lin Liu, Farzad Khalvati", "title": "A Transfer Learning Based Active Learning Framework for Brain Tumor\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain tumor is one of the leading causes of cancer-related death globally\namong children and adults. Precise classification of brain tumor grade\n(low-grade and high-grade glioma) at early stage plays a key role in successful\nprognosis and treatment planning. With recent advances in deep learning,\nArtificial Intelligence-enabled brain tumor grading systems can assist\nradiologists in the interpretation of medical images within seconds. The\nperformance of deep learning techniques is, however, highly depended on the\nsize of the annotated dataset. It is extremely challenging to label a large\nquantity of medical images given the complexity and volume of medical data. In\nthis work, we propose a novel transfer learning based active learning framework\nto reduce the annotation cost while maintaining stability and robustness of the\nmodel performance for brain tumor classification. We employed a 2D slice-based\napproach to train and finetune our model on the Magnetic Resonance Imaging\n(MRI) training dataset of 203 patients and a validation dataset of 66 patients\nwhich was used as the baseline. With our proposed method, the model achieved\nArea Under Receiver Operating Characteristic (ROC) Curve (AUC) of 82.89% on a\nseparate test dataset of 66 patients, which was 2.92% higher than the baseline\nAUC while saving at least 40% of labeling cost. In order to further examine the\nrobustness of our method, we created a balanced dataset, which underwent the\nsame procedure. The model achieved AUC of 82% compared with AUC of 78.48% for\nthe baseline, which reassures the robustness and stability of our proposed\ntransfer learning augmented with active learning framework while significantly\nreducing the size of training data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 21:11:40 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Hao", "Ruqian", ""], ["Namdar", "Khashayar", ""], ["Liu", "Lin", ""], ["Khalvati", "Farzad", ""]]}, {"id": "2011.09270", "submitter": "Taufiq Hasan", "authors": "Meemnur Rashid, Kaisar Ahmed Alman, Khaled Hasan, John H.L. Hansen and\n  Taufiq Hasan", "title": "Respiratory Distress Detection from Telephone Speech using Acoustic and\n  Prosodic Features", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the widespread use of telemedicine services, automatic assessment of\nhealth conditions via telephone speech can significantly impact public health.\nThis work summarizes our preliminary findings on automatic detection of\nrespiratory distress using well-known acoustic and prosodic features. Speech\nsamples are collected from de-identified telemedicine phonecalls from a\nhealthcare provider in Bangladesh. The recordings include conversational speech\nsamples of patients talking to doctors showing mild or severe respiratory\ndistress or asthma symptoms. We hypothesize that respiratory distress may alter\nspeech features such as voice quality, speaking pattern, loudness, and\nspeech-pause duration. To capture these variations, we utilize a set of\nwell-known acoustic and prosodic features with a Support Vector Machine (SVM)\nclassifier for detecting the presence of respiratory distress. Experimental\nevaluations are performed using a 3-fold cross-validation scheme, ensuring\npatient-independent data splits. We obtained an overall accuracy of 86.4\\% in\ndetecting respiratory distress from the speech recordings using the acoustic\nfeature set. Correlation analysis reveals that the top-performing features\ninclude loudness, voice rate, voice duration, and pause duration.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 13:32:45 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Rashid", "Meemnur", ""], ["Alman", "Kaisar Ahmed", ""], ["Hasan", "Khaled", ""], ["Hansen", "John H. L.", ""], ["Hasan", "Taufiq", ""]]}, {"id": "2011.09280", "submitter": "Alessandro Lameiras Koerich", "authors": "Thomas Teixeira, Eric Granger, Alessandro Lameiras Koerich", "title": "Continuous Emotion Recognition with Spatiotemporal Convolutional Neural\n  Networks", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial expressions are one of the most powerful ways for depicting specific\npatterns in human behavior and describing human emotional state. Despite the\nimpressive advances of affective computing over the last decade, automatic\nvideo-based systems for facial expression recognition still cannot handle\nproperly variations in facial expression among individuals as well as\ncross-cultural and demographic aspects. Nevertheless, recognizing facial\nexpressions is a difficult task even for humans. In this paper, we investigate\nthe suitability of state-of-the-art deep learning architectures based on\nconvolutional neural networks (CNNs) for continuous emotion recognition using\nlong video sequences captured in-the-wild. This study focuses on deep learning\nmodels that allow encoding spatiotemporal relations in videos considering a\ncomplex and multi-dimensional emotion space, where values of valence and\narousal must be predicted. We have developed and evaluated convolutional\nrecurrent neural networks combining 2D-CNNs and long short term-memory units,\nand inflated 3D-CNN models, which are built by inflating the weights of a\npre-trained 2D-CNN model during fine-tuning, using application-specific videos.\nExperimental results on the challenging SEWA-DB dataset have shown that these\narchitectures can effectively be fine-tuned to encode the spatiotemporal\ninformation from successive raw pixel images and achieve state-of-the-art\nresults on such a dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:42:05 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 14:49:00 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Teixeira", "Thomas", ""], ["Granger", "Eric", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "2011.09288", "submitter": "Ingvar Ziemann", "authors": "Ingvar Ziemann, Henrik Sandberg", "title": "On Uninformative Optimal Policies in Adaptive LQR with Unknown B-Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents local asymptotic minimax regret lower bounds for adaptive\nLinear Quadratic Regulators (LQR). We consider affinely parametrized\n$B$-matrices and known $A$-matrices and aim to understand when logarithmic\nregret is impossible even in the presence of structural side information. After\ndefining the intrinsic notion of an uninformative optimal policy in terms of a\nsingularity condition for Fisher information we obtain local minimax regret\nlower bounds for such uninformative instances of LQR by appealing to van Trees'\ninequality (Bayesian Cram\\'er-Rao) and a representation of regret in terms of a\nquadratic form (Bellman error). It is shown that if the parametrization induces\nan uninformative optimal policy, logarithmic regret is impossible and the rate\nis at least order square root in the time horizon. We explicitly characterize\nthe notion of an uninformative optimal policy in terms of the nullspaces of\nsystem-theoretic quantities and the particular instance parametrization.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 13:50:31 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 11:54:03 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 05:37:21 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Ziemann", "Ingvar", ""], ["Sandberg", "Henrik", ""]]}, {"id": "2011.09294", "submitter": "Tom Ward", "authors": "Tom Ward, Andrew Bolt, Nik Hemmings, Simon Carter, Manuel Sanchez,\n  Ricardo Barreira, Seb Noury, Keith Anderson, Jay Lemmon, Jonathan Coe, Piotr\n  Trochim, Tom Handley, Adrian Bolton", "title": "Using Unity to Help Solve Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the pursuit of artificial general intelligence, our most significant\nmeasurement of progress is an agent's ability to achieve goals in a wide range\nof environments. Existing platforms for constructing such environments are\ntypically constrained by the technologies they are founded on, and are\ntherefore only able to provide a subset of scenarios necessary to evaluate\nprogress. To overcome these shortcomings, we present our use of Unity, a widely\nrecognized and comprehensive game engine, to create more diverse, complex,\nvirtual simulations. We describe the concepts and components developed to\nsimplify the authoring of these environments, intended for use predominantly in\nthe field of reinforcement learning. We also introduce a practical approach to\npackaging and re-distributing environments in a way that attempts to improve\nthe robustness and reproducibility of experiment results. To illustrate the\nversatility of our use of Unity compared to other solutions, we highlight\nenvironments already created using our approach from published papers. We hope\nthat others can draw inspiration from how we adapted Unity to our needs, and\nanticipate increasingly varied and complex environments to emerge from our\napproach as familiarity grows.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 14:04:01 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ward", "Tom", ""], ["Bolt", "Andrew", ""], ["Hemmings", "Nik", ""], ["Carter", "Simon", ""], ["Sanchez", "Manuel", ""], ["Barreira", "Ricardo", ""], ["Noury", "Seb", ""], ["Anderson", "Keith", ""], ["Lemmon", "Jay", ""], ["Coe", "Jonathan", ""], ["Trochim", "Piotr", ""], ["Handley", "Tom", ""], ["Bolton", "Adrian", ""]]}, {"id": "2011.09303", "submitter": "Manvel Avetisian", "authors": "Konstantin Egorov, Elena Sokolova, Manvel Avetisian, Alexander\n  Tuzhilin", "title": "Noise-Resilient Automatic Interpretation of Holter ECG Recordings", "comments": "Accepted for publication on BIOSIGNALS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Holter monitoring, a long-term ECG recording (24-hours and more), contains a\nlarge amount of valuable diagnostic information about the patient. Its\ninterpretation becomes a difficult and time-consuming task for the doctor who\nanalyzes them because every heartbeat needs to be classified, thus requiring\nhighly accurate methods for automatic interpretation. In this paper, we present\na three-stage process for analysing Holter recordings with robustness to noisy\nsignal. First stage is a segmentation neural network (NN) with encoderdecoder\narchitecture which detects positions of heartbeats. Second stage is a\nclassification NN which will classify heartbeats as wide or narrow. Third stage\nin gradient boosting decision trees (GBDT) on top of NN features that\nincorporates patient-wise features and further increases performance of our\napproach. As a part of this work we acquired 5095 Holter recordings of patients\nannotated by an experienced cardiologist. A committee of three cardiologists\nserved as a ground truth annotators for the 291 examples in the test set. We\nshow that the proposed method outperforms the selected baselines, including two\ncommercial-grade software packages and some methods previously published in the\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:15:49 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Egorov", "Konstantin", ""], ["Sokolova", "Elena", ""], ["Avetisian", "Manvel", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2011.09335", "submitter": "Sim Kuan Goh", "authors": "Sim Kuan Goh, Narendra Pratap Singh, Zhi Jun Lim and Sameer Alam", "title": "Learning Interpretable Flight's 4D Landing Parameters Using Tunnel\n  Gaussian Process", "comments": "Under review. 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approach and landing accidents have resulted in a significant number of hull\nlosses worldwide. Technologies (e.g., instrument landing system) and procedures\n(e.g., stabilized approach criteria) have been developed to reduce the risks.\nIn this paper, we propose a data-driven method to learn and interpret flight's\n4D approach and landing parameters to facilitate comprehensible and actionable\ninsights of flight dynamics. Specifically, we develop two variants of tunnel\nGaussian process (TGP) models to elucidate aircraft's approach and landing\ndynamics using advanced surface movement guidance and control system (A-SMGCS)\ndata, which then indicates the stability of flight. TGP hybridizes the\nstrengths of sparse variational Gaussian process and polar Gaussian process to\nlearn from a large amount of data in cylindrical coordinates. We examine TGP\nqualitatively and quantitatively by synthesizing three complex trajectory\ndatasets and compared TGP against existing methods on trajectory learning.\nEmpirically, TGP demonstrates superior modeling performance. When applied to\noperational A-SMGCS data, TGP provides the generative probabilistic description\nof landing dynamics and interpretable 4D tunnel views of approach and landing\nparameters. These 4D tunnel models can facilitate the analysis of procedure\nadherence and augment existing aircrew and air traffic controllers' display\nduring the approach and landing procedures, enabling necessary corrective\nactions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:18:29 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 14:33:47 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Goh", "Sim Kuan", ""], ["Singh", "Narendra Pratap", ""], ["Lim", "Zhi Jun", ""], ["Alam", "Sameer", ""]]}, {"id": "2011.09349", "submitter": "A. Max Reppen", "authors": "A. Max Reppen and H. Mete Soner", "title": "Bias-Variance Trade-off and Overlearning in Dynamic Decision Problems", "comments": "22 pages, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Monte Carlo-type approaches to dynamic decision problems are\nreformulated as empirical loss minimization, allowing direct applications of\nclassical results from statistical machine learning. These computational\nmethods are then analyzed in this framework to demonstrate their effectiveness\nas well as their susceptibility to generalization error. Standard uses of\nclassical results prove potential overlearning, thus bias-variance trade-off,\nby connecting over-trained networks to anticipating controls. On the other\nhand, non-asymptotic estimates based on Rademacher complexity show the\nconvergence of these algorithms for sufficiently large training sets. A\nnumerically studied stylized example illustrates these possibilities, including\nthe importance of problem dimension in the degree of overlearning, and the\neffectiveness of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:36:22 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 16:37:06 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Reppen", "A. Max", ""], ["Soner", "H. Mete", ""]]}, {"id": "2011.09350", "submitter": "Pavlos Papadopoulos", "authors": "Nick Angelou, Ayoub Benaissa, Bogdan Cebere, William Clark, Adam James\n  Hall, Michael A. Hoeh, Daniel Liu, Pavlos Papadopoulos, Robin Roehm, Robert\n  Sandmann, Phillipp Schoppmann, Tom Titcombe", "title": "Asymmetric Private Set Intersection with Applications to Contact Tracing\n  and Private Vertical Federated Machine Learning", "comments": "NeurIPS 2020 Workshop on Privacy Preserving Machine Learning (PPML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a multi-language, cross-platform, open-source library for\nasymmetric private set intersection (PSI) and PSI-Cardinality (PSI-C). Our\nprotocol combines traditional DDH-based PSI and PSI-C protocols with\ncompression based on Bloom filters that helps reduce communication in the\nasymmetric setting. Currently, our library supports C++, C, Go, WebAssembly,\nJavaScript, Python, and Rust, and runs on both traditional hardware (x86) and\nbrowser targets. We further apply our library to two use cases: (i) a\nprivacy-preserving contact tracing protocol that is compatible with existing\napproaches, but improves their privacy guarantees, and (ii) privacy-preserving\nmachine learning on vertically partitioned data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:38:59 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Angelou", "Nick", ""], ["Benaissa", "Ayoub", ""], ["Cebere", "Bogdan", ""], ["Clark", "William", ""], ["Hall", "Adam James", ""], ["Hoeh", "Michael A.", ""], ["Liu", "Daniel", ""], ["Papadopoulos", "Pavlos", ""], ["Roehm", "Robin", ""], ["Sandmann", "Robert", ""], ["Schoppmann", "Phillipp", ""], ["Titcombe", "Tom", ""]]}, {"id": "2011.09359", "submitter": "Nicolas Kourtellis Ph.D.", "authors": "Nicolas Kourtellis and Kleomenis Katevas and Diego Perino", "title": "FLaaS: Federated Learning as a Service", "comments": "7 pages, 4 figures, 7 subfigures, 34 references", "journal-ref": "In 1st Workshop on Distributed Machine Learning\n  (DistributedML'20), Dec. 1, 2020, Barcelona, Spain. ACM, New York, NY, USA, 7\n  pages", "doi": "10.1145/3426745.3431337", "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated Learning (FL) is emerging as a promising technology to build\nmachine learning models in a decentralized, privacy-preserving fashion. Indeed,\nFL enables local training on user devices, avoiding user data to be transferred\nto centralized servers, and can be enhanced with differential privacy\nmechanisms. Although FL has been recently deployed in real systems, the\npossibility of collaborative modeling across different 3rd-party applications\nhas not yet been explored. In this paper, we tackle this problem and present\nFederated Learning as a Service (FLaaS), a system enabling different scenarios\nof 3rd-party application collaborative model building and addressing the\nconsequent challenges of permission and privacy management, usability, and\nhierarchical model training. FLaaS can be deployed in different operational\nenvironments. As a proof of concept, we implement it on a mobile phone setting\nand discuss practical implications of results on simulated and real devices\nwith respect to on-device training CPU cost, memory footprint and power\nconsumed per FL model round. Therefore, we demonstrate FLaaS's feasibility in\nbuilding unique or joint FL models across applications for image object\ndetection in a few hours, across 100 devices.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:56:22 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kourtellis", "Nicolas", ""], ["Katevas", "Kleomenis", ""], ["Perino", "Diego", ""]]}, {"id": "2011.09361", "submitter": "Zina Ibrahim", "authors": "Zina M Ibrahim, Daniel Bean, Thomas Searle, Honghan Wu, Anthony Shek,\n  Zeljko Kraljevic, James Galloway, Sam Norton, James T Teo, Richard JB Dobson", "title": "A Knowledge Distillation Ensemble Framework for Predicting Short and\n  Long-term Hospitalisation Outcomes from Electronic Health Records Data", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to perform accurate prognosis of patients is crucial for\nproactive clinical decision making, informed resource management and\npersonalised care. Existing outcome prediction models suffer from a low recall\nof infrequent positive outcomes. We present a highly-scalable and robust\nmachine learning framework to automatically predict adversity represented by\nmortality and ICU admission from time-series vital signs and laboratory results\nobtained within the first 24 hours of hospital admission. The stacked platform\ncomprises two components: a) an unsupervised LSTM Autoencoder that learns an\noptimal representation of the time-series, using it to differentiate the less\nfrequent patterns which conclude with an adverse event from the majority\npatterns that do not, and b) a gradient boosting model, which relies on the\nconstructed representation to refine prediction, incorporating static features\nof demographics, admission details and clinical summaries. The model is used to\nassess a patient's risk of adversity over time and provides visual\njustifications of its prediction based on the patient's static features and\ndynamic signals. Results of three case studies for predicting mortality and ICU\nadmission show that the model outperforms all existing outcome prediction\nmodels, achieving PR-AUC of 0.891 (95$%$ CI: 0.878 - 0.969) in predicting\nmortality in ICU and general ward settings and 0.908 (95$%$ CI: 0.870-0.935) in\npredicting ICU admission.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:56:28 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 12:10:29 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ibrahim", "Zina M", ""], ["Bean", "Daniel", ""], ["Searle", "Thomas", ""], ["Wu", "Honghan", ""], ["Shek", "Anthony", ""], ["Kraljevic", "Zeljko", ""], ["Galloway", "James", ""], ["Norton", "Sam", ""], ["Teo", "James T", ""], ["Dobson", "Richard JB", ""]]}, {"id": "2011.09362", "submitter": "Owais Sarwar", "authors": "Owais Sarwar and Benjamin Sauk and Nikolaos V. Sahinidis", "title": "A Discussion on Practical Considerations with Sparse Regression\n  Methodologies", "comments": "12 pages", "journal-ref": "Statist. Sci. Volume 35, Number 4 (2020), 593-601", "doi": "10.1214/20-STS806", "report-no": null, "categories": "cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear regression is a vast field and there are many different\nalgorithms available to build models. Two new papers published in Statistical\nScience study the comparative performance of several sparse regression\nmethodologies, including the lasso and subset selection. Comprehensive\nempirical analyses allow the researchers to demonstrate the relative merits of\neach estimator and provide guidance to practitioners. In this discussion, we\nsummarize and compare the two studies and we examine points of agreement and\ndivergence, aiming to provide clarity and value to users. The authors have\nstarted a highly constructive dialogue, our goal is to continue it.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:58:35 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 19:43:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Sarwar", "Owais", ""], ["Sauk", "Benjamin", ""], ["Sahinidis", "Nikolaos V.", ""]]}, {"id": "2011.09364", "submitter": "Hossein Aboutalebi", "authors": "Hossein Aboutalebi, Mohammad Javad Shafiee Alexander Wong", "title": "Self-Gradient Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incredible effectiveness of adversarial attacks on fooling deep neural\nnetworks poses a tremendous hurdle in the widespread adoption of deep learning\nin safety and security-critical domains. While adversarial defense mechanisms\nhave been proposed since the discovery of the adversarial vulnerability issue\nof deep neural networks, there is a long path to fully understand and address\nthis issue. In this study, we hypothesize that part of the reason for the\nincredible effectiveness of adversarial attacks is their ability to implicitly\ntap into and exploit the gradient flow of a deep neural network. This innate\nability to exploit gradient flow makes defending against such attacks quite\nchallenging. Motivated by this hypothesis we argue that if a deep neural\nnetwork architecture can explicitly tap into its own gradient flow during the\ntraining, it can boost its defense capability significantly. Inspired by this\nfact, we introduce the concept of self-gradient networks, a novel deep neural\nnetwork architecture designed to be more robust against adversarial\nperturbations. Gradient flow information is leveraged within self-gradient\nnetworks to achieve greater perturbation stability beyond what can be achieved\nin the standard training process. We conduct a theoretical analysis to gain\nbetter insights into the behaviour of the proposed self-gradient networks to\nillustrate the efficacy of leverage this additional gradient flow information.\nThe proposed self-gradient network architecture enables much more efficient and\neffective adversarial training, leading to faster convergence towards an\nadversarially robust solution by at least 10X. Experimental results demonstrate\nthe effectiveness of self-gradient networks when compared with state-of-the-art\nadversarial learning strategies, with 10% improvement on the CIFAR10 dataset\nunder PGD and CW adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:04:05 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 04:16:05 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Aboutalebi", "Hossein", ""], ["Wong", "Mohammad Javad Shafiee Alexander", ""]]}, {"id": "2011.09384", "submitter": "Dan Feldman PhD", "authors": "Dan Feldman", "title": "Introduction to Core-sets: an Updated Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In optimization or machine learning problems we are given a set of items,\nusually points in some metric space, and the goal is to minimize or maximize an\nobjective function over some space of candidate solutions. For example, in\nclustering problems, the input is a set of points in some metric space, and a\ncommon goal is to compute a set of centers in some other space (points, lines)\nthat will minimize the sum of distances to these points. In database queries,\nwe may need to compute such a some for a specific query set of $k$ centers.\n  However, traditional algorithms cannot handle modern systems that require\nparallel real-time computations of infinite distributed streams from sensors\nsuch as GPS, audio or video that arrive to a cloud, or networks of weaker\ndevices such as smartphones or robots.\n  Core-set is a \"small data\" summarization of the input \"big data\", where every\npossible query has approximately the same answer on both data sets. Generic\ntechniques enable efficient coreset \\changed{maintenance} of streaming,\ndistributed and dynamic data. Traditional algorithms can then be applied on\nthese coresets to maintain the approximated optimal solutions.\n  The challenge is to design coresets with provable tradeoff between their size\nand approximation error. This survey summarizes such constructions in a\nretrospective way, that aims to unified and simplify the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:31:34 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Feldman", "Dan", ""]]}, {"id": "2011.09388", "submitter": "Osman Musa", "authors": "Osman Musa, Peter Jung and Giuseppe Caire", "title": "Plug-And-Play Learned Gaussian-mixture Approximate Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unfolding showed to be a very successful approach for accelerating and\ntuning classical signal processing algorithms. In this paper, we propose\nlearned Gaussian-mixture AMP (L-GM-AMP) - a plug-and-play compressed sensing\n(CS) recovery algorithm suitable for any i.i.d. source prior. Our algorithm\nbuilds upon Borgerding's learned AMP (LAMP), yet significantly improves it by\nadopting a universal denoising function within the algorithm. The robust and\nflexible denoiser is a byproduct of modelling source prior with a\nGaussian-mixture (GM), which can well approximate continuous, discrete, as well\nas mixture distributions. Its parameters are learned using standard\nbackpropagation algorithm. To demonstrate robustness of the proposed algorithm,\nwe conduct Monte-Carlo (MC) simulations for both mixture and discrete\ndistributions. Numerical evaluation shows that the L-GM-AMP algorithm achieves\nstate-of-the-art performance without any knowledge of the source prior.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:40:45 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Musa", "Osman", ""], ["Jung", "Peter", ""], ["Caire", "Giuseppe", ""]]}, {"id": "2011.09393", "submitter": "Nurislam Tursynbek", "authors": "Nurislam Tursynbek, Ilya Vilkoviskiy, Maria Sindeeva, Ivan Oseledets", "title": "Adversarial Turing Patterns from Cellular Automata", "comments": "Published as a conference paper at AAAI 2021 (camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep classifiers are intriguingly vulnerable to universal\nadversarial perturbations: single disturbances of small magnitude that lead to\nmisclassification of most in-puts. This phenomena may potentially result in a\nserious security problem. Despite the extensive research in this area,there is\na lack of theoretical understanding of the structure of these perturbations. In\nimage domain, there is a certain visual similarity between patterns, that\nrepresent these perturbations, and classical Turing patterns, which appear as a\nsolution of non-linear partial differential equations and are underlying\nconcept of many processes in nature. In this paper,we provide a theoretical\nbridge between these two different theories, by mapping a simplified algorithm\nfor crafting universal perturbations to (inhomogeneous) cellular automata,the\nlatter is known to generate Turing patterns. Furthermore,we propose to use\nTuring patterns, generated by cellular automata, as universal perturbations,\nand experimentally show that they significantly degrade the performance of deep\nlearning models. We found this method to be a fast and efficient way to create\na data-agnostic quasi-imperceptible perturbation in the black-box scenario. The\nsource code is available at https://github.com/NurislamT/advTuring.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:50:54 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:51:43 GMT"}, {"version": "v3", "created": "Tue, 6 Apr 2021 08:59:06 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Tursynbek", "Nurislam", ""], ["Vilkoviskiy", "Ilya", ""], ["Sindeeva", "Maria", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2011.09398", "submitter": "Koen Helwegen", "authors": "Tom Bannink, Arash Bakhtiari, Adam Hillier, Lukas Geiger, Tim de\n  Bruin, Leon Overweel, Jelmer Neeven, Koen Helwegen", "title": "Larq Compute Engine: Design, Benchmark, and Deploy State-of-the-Art\n  Binarized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Larq Compute Engine, the world's fastest Binarized Neural\nNetwork (BNN) inference engine, and use this framework to investigate several\nimportant questions about the efficiency of BNNs and to design a new\nstate-of-the-art BNN architecture. LCE provides highly optimized\nimplementations of binary operations and accelerates binary convolutions by 8.5\n- 18.5x compared to their full-precision counterparts on Pixel 1 phones. LCE's\nintegration with Larq and a sophisticated MLIR-based converter allow users to\nmove smoothly from training to deployment. By extending TensorFlow and\nTensorFlow Lite, LCE supports models which combine binary and full-precision\nlayers, and can be easily integrated into existing applications. Using LCE, we\nanalyze the performance of existing BNN computer vision architectures and\ndevelop QuickNet, a simple, easy-to-reproduce BNN that outperforms existing\nbinary networks in terms of latency and accuracy on ImageNet. Furthermore, we\ninvestigate the impact of full-precision shortcuts and the relationship between\nnumber of MACs and model latency. We are convinced that empirical performance\nshould drive BNN architecture design and hope this work will facilitate others\nto design, benchmark and deploy binary models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:56:14 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 22:56:16 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bannink", "Tom", ""], ["Bakhtiari", "Arash", ""], ["Hillier", "Adam", ""], ["Geiger", "Lukas", ""], ["de Bruin", "Tim", ""], ["Overweel", "Leon", ""], ["Neeven", "Jelmer", ""], ["Helwegen", "Koen", ""]]}, {"id": "2011.09414", "submitter": "Burhaneddin Yaman", "authors": "Burhaneddin Yaman, Chetan Shenoy, Zilin Deng, Steen Moeller, Hossam\n  El-Rewaidy, Reza Nezafat, and Mehmet Ak\\c{c}akaya", "title": "Self-Supervised Physics-Guided Deep Learning Reconstruction For\n  High-Resolution 3D LGE CMR", "comments": null, "journal-ref": "Proceedings of IEEE ISBI, 2021", "doi": "10.1109/ISBI48211.2021.9434054", "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Late gadolinium enhancement (LGE) cardiac MRI (CMR) is the clinical standard\nfor diagnosis of myocardial scar. 3D isotropic LGE CMR provides improved\ncoverage and resolution compared to 2D imaging. However, image acceleration is\nrequired due to long scan times and contrast washout. Physics-guided deep\nlearning (PG-DL) approaches have recently emerged as an improved accelerated\nMRI strategy. Training of PG-DL methods is typically performed in supervised\nmanner requiring fully-sampled data as reference, which is challenging in 3D\nLGE CMR. Recently, a self-supervised learning approach was proposed to enable\ntraining PG-DL techniques without fully-sampled data. In this work, we extend\nthis self-supervised learning approach to 3D imaging, while tackling challenges\nrelated to small training database sizes of 3D volumes. Results and a reader\nstudy on prospectively accelerated 3D LGE show that the proposed approach at\n6-fold acceleration outperforms the clinically utilized compressed sensing\napproach at 3-fold acceleration.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:22:21 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Yaman", "Burhaneddin", ""], ["Shenoy", "Chetan", ""], ["Deng", "Zilin", ""], ["Moeller", "Steen", ""], ["El-Rewaidy", "Hossam", ""], ["Nezafat", "Reza", ""], ["Ak\u00e7akaya", "Mehmet", ""]]}, {"id": "2011.09416", "submitter": "Bohdan Kivva", "authors": "Bohdan Kivva and Aaron Potechin", "title": "Exact nuclear norm, completion and decomposition for random overcomplete\n  tensors via degree-4 SOS", "comments": "132 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that simple semidefinite programs inspired by degree\n$4$ SOS can exactly solve the tensor nuclear norm, tensor decomposition, and\ntensor completion problems on tensors with random asymmetric components. More\nprecisely, for tensor nuclear norm and tensor decomposition, we show that\nw.h.p. these semidefinite programs can exactly find the nuclear norm and\ncomponents of an $(n\\times n\\times n)$-tensor $\\mathcal{T}$ with $m\\leq\nn^{3/2}/polylog(n)$ random asymmetric components. For tensor completion, we\nshow that w.h.p. the semidefinite program introduced by Potechin \\& Steurer\n(2017) can exactly recover an $(n\\times n\\times n)$-tensor $\\mathcal{T}$ with\n$m$ random asymmetric components from only $n^{3/2}m\\, polylog(n)$ randomly\nobserved entries. This gives the first theoretical guarantees for exact tensor\ncompletion in the overcomplete regime.\n  This matches the best known results for approximate versions of these\nproblems given by Barak \\& Moitra (2015) for tensor completion, and Ma, Shi \\&\nSteurer (2016) for tensor decomposition.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:27:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kivva", "Bohdan", ""], ["Potechin", "Aaron", ""]]}, {"id": "2011.09418", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Gunjan Verma, Chirag Rao, Ananthram Swami, and\n  Santiago Segarra", "title": "Adaptive Contention Window Design using Deep Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of adaptive contention window (CW) design for\nrandom-access wireless networks. More precisely, our goal is to design an\nintelligent node that can dynamically adapt its minimum CW (MCW) parameter to\nmaximize a network-level utility knowing neither the MCWs of other nodes nor\nhow these change over time. To achieve this goal, we adopt a reinforcement\nlearning (RL) framework where we circumvent the lack of system knowledge with\nlocal channel observations and we reward actions that lead to high utilities.\nTo efficiently learn these preferred actions, we follow a deep Q-learning\napproach, where the Q-value function is parametrized using a multi-layer\nperception. In particular, we implement a rainbow agent, which incorporates\nseveral empirical improvements over the basic deep Q-network. Numerical\nexperiments based on the NS3 simulator reveal that the proposed RL agent\nperforms close to optimal and markedly improves upon existing learning and\nnon-learning based alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:31:18 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kumar", "Abhishek", ""], ["Verma", "Gunjan", ""], ["Rao", "Chirag", ""], ["Swami", "Ananthram", ""], ["Segarra", "Santiago", ""]]}, {"id": "2011.09421", "submitter": "Sebastian Ober", "authors": "David R. Burt, Sebastian W. Ober, Adri\\`a Garriga-Alonso, Mark van der\n  Wilk", "title": "Understanding Variational Inference in Function-Space", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has attempted to directly approximate the `function-space' or\npredictive posterior distribution of Bayesian models, without approximating the\nposterior distribution over the parameters. This is appealing in e.g. Bayesian\nneural networks, where we only need the former, and the latter is hard to\nrepresent. In this work, we highlight some advantages and limitations of\nemploying the Kullback-Leibler divergence in this setting. For example, we show\nthat minimizing the KL divergence between a wide class of parametric\ndistributions and the posterior induced by a (non-degenerate) Gaussian process\nprior leads to an ill-defined objective function. Then, we propose (featurized)\nBayesian linear regression as a benchmark for `function-space' inference\nmethods that directly measures approximation quality. We apply this methodology\nto assess aspects of the objective function and inference scheme considered in\nSun, Zhang, Shi, and Grosse (2018), emphasizing the quality of approximation to\nBayesian inference as opposed to predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:42:01 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Burt", "David R.", ""], ["Ober", "Sebastian W.", ""], ["Garriga-Alonso", "Adri\u00e0", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2011.09426", "submitter": "Javier Fernandez", "authors": "Javier Fernandez (1 and 2), Luke Bornn (3), Daniel Cervone (4) ((1)\n  Polytechnic University of Catalonia, (2) FC Barcelona, (3) Simon Fraser\n  University, (4) Zelus Analytics)", "title": "A framework for the fine-grained evaluation of the instantaneous\n  expected value of soccer possessions", "comments": "35 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expected possession value (EPV) of a soccer possession represents the\nlikelihood of a team scoring or receiving the next goal at any time instance.\nBy decomposing the EPV into a series of subcomponents that are estimated\nseparately, we develop a comprehensive analysis framework providing soccer\npractitioners with the ability to evaluate the impact of both observed and\npotential actions. We show we can obtain calibrated models for all the\ncomponents of EPV, including a set of yet-unexplored problems in soccer. We\nproduce visually-interpretable probability surfaces for potential passes from a\nseries of deep neural network architectures that learn from low-level\nspatiotemporal data. Additionally, we present a series of novel practical\napplications providing coaches with an enriched interpretation of specific game\nsituations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:51:22 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Fernandez", "Javier", "", "1 and 2"], ["Bornn", "Luke", ""], ["Cervone", "Daniel", ""]]}, {"id": "2011.09427", "submitter": "Anthony Bisulco", "authors": "Anthony Bisulco, Fernando Cladera Ojeda, Volkan Isler, Daniel D. Lee", "title": "Fast Motion Understanding with Spatiotemporal Neural Networks and\n  Dynamic Vision Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Dynamic Vision Sensor (DVS) based system for reasoning\nabout high speed motion. As a representative scenario, we consider the case of\na robot at rest reacting to a small, fast approaching object at speeds higher\nthan 15m/s. Since conventional image sensors at typical frame rates observe\nsuch an object for only a few frames, estimating the underlying motion presents\na considerable challenge for standard computer vision systems and algorithms.\nIn this paper we present a method motivated by how animals such as insects\nsolve this problem with their relatively simple vision systems.\n  Our solution takes the event stream from a DVS and first encodes the temporal\nevents with a set of causal exponential filters across multiple time scales. We\ncouple these filters with a Convolutional Neural Network (CNN) to efficiently\nextract relevant spatiotemporal features. The combined network learns to output\nboth the expected time to collision of the object, as well as the predicted\ncollision point on a discretized polar grid. These critical estimates are\ncomputed with minimal delay by the network in order to react appropriately to\nthe incoming object. We highlight the results of our system to a toy dart\nmoving at 23.4m/s with a 24.73{\\deg} error in ${\\theta}$, 18.4mm average\ndiscretized radius prediction error, and 25.03% median time to collision\nprediction error.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 17:55:07 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Bisulco", "Anthony", ""], ["Ojeda", "Fernando Cladera", ""], ["Isler", "Volkan", ""], ["Lee", "Daniel D.", ""]]}, {"id": "2011.09430", "submitter": "Zhongyuan Zhao", "authors": "Zhongyuan Zhao, Gunjan Verma, Chirag Rao, Ananthram Swami, and\n  Santiago Segarra", "title": "Distributed Scheduling using Graph Neural Networks", "comments": "5 pages, 6 figures, accepted to IEEE ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in the design of wireless networks is to efficiently\nschedule transmission in a distributed manner. The main challenge stems from\nthe fact that optimal link scheduling involves solving a maximum weighted\nindependent set (MWIS) problem, which is NP-hard. For practical link scheduling\nschemes, distributed greedy approaches are commonly used to approximate the\nsolution of the MWIS problem. However, these greedy schemes mostly ignore\nimportant topological information of the wireless networks. To overcome this\nlimitation, we propose a distributed MWIS solver based on graph convolutional\nnetworks (GCNs). In a nutshell, a trainable GCN module learns topology-aware\nnode embeddings that are combined with the network weights before calling a\ngreedy solver. In small- to middle-sized wireless networks with tens of links,\neven a shallow GCN-based MWIS scheduler can leverage the topological\ninformation of the graph to reduce in half the suboptimality gap of the\ndistributed greedy solver with good generalizability across graphs and minimal\nincrease in complexity.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:00:45 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 18:56:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhao", "Zhongyuan", ""], ["Verma", "Gunjan", ""], ["Rao", "Chirag", ""], ["Swami", "Ananthram", ""], ["Segarra", "Santiago", ""]]}, {"id": "2011.09439", "submitter": "Yangguang Shi", "authors": "Yuval Emek, Shay Kutten, Yangguang Shi", "title": "Online Paging with a Vanishing Regret", "comments": "25 pages. An extended abstract of this paper is to appear in the 12th\n  Innovations in Theoretical Computer Science conference (ITCS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a variant of the online paging problem, where the online\nalgorithm has access to multiple predictors, each producing a sequence of\npredictions for the page arrival times. The predictors may have occasional\nprediction errors and it is assumed that at least one of them makes a sublinear\nnumber of prediction errors in total. Our main result states that this\nassumption suffices for the design of a randomized online algorithm whose\ntime-average regret with respect to the optimal offline algorithm tends to zero\nas the time tends to infinity. This holds (with different regret bounds) for\nboth the full information access model, where in each round, the online\nalgorithm gets the predictions of all predictors, and the bandit access model,\nwhere in each round, the online algorithm queries a single predictor. While\nonline algorithms that exploit inaccurate predictions have been a topic of\ngrowing interest in the last few years, to the best of our knowledge, this is\nthe first paper that studies this topic in the context of multiple predictors\nfor an online problem with unbounded request sequences. Moreover, to the best\nof our knowledge, this is also the first paper that aims for (and achieves)\nonline algorithms with a vanishing regret for a classic online problem under\nreasonable assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:17:49 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 02:18:08 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Emek", "Yuval", ""], ["Kutten", "Shay", ""], ["Shi", "Yangguang", ""]]}, {"id": "2011.09447", "submitter": "Kelly Geyer", "authors": "Kelly Geyer, Frederick Campbell, Andersen Chang, John Magnotti,\n  Michael Beauchamp, Genevera I. Allen", "title": "Interpretable Visualization and Higher-Order Dimension Reduction for\n  ECoG Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ElectroCOrticoGraphy (ECoG) technology measures electrical activity in the\nhuman brain via electrodes placed directly on the cortical surface during\nneurosurgery. Through its capability to record activity at a fast temporal\nresolution, ECoG experiments have allowed scientists to better understand how\nthe human brain processes speech. By its nature, ECoG data is difficult for\nneuroscientists to directly interpret for two major reasons. Firstly, ECoG data\ntends to be large in size, as each individual experiment yields data up to\nseveral gigabytes. Secondly, ECoG data has a complex, higher-order nature.\nAfter signal processing, this type of data may be organized as a 4-way tensor\nwith dimensions representing trials, electrodes, frequency, and time. In this\npaper, we develop an interpretable dimension reduction approach called\nRegularized Higher Order Principal Components Analysis, as well as an extension\nto Regularized Higher Order Partial Least Squares, that allows neuroscientists\nto explore and visualize ECoG data. Our approach employs a sparse and\nfunctional Candecomp-Parafac (CP) decomposition that incorporates sparsity to\nselect relevant electrodes and frequency bands, as well as smoothness over time\nand frequency, yielding directly interpretable factors. We demonstrate the\nperformance and interpretability of our method with an ECoG case study on audio\nand visual processing of human speech.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 18:19:43 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 01:52:01 GMT"}, {"version": "v3", "created": "Sat, 12 Dec 2020 19:11:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Geyer", "Kelly", ""], ["Campbell", "Frederick", ""], ["Chang", "Andersen", ""], ["Magnotti", "John", ""], ["Beauchamp", "Michael", ""], ["Allen", "Genevera I.", ""]]}, {"id": "2011.09448", "submitter": "Daniel Palomino", "authors": "Daniel Palomino and Jose Ochoa-Luna", "title": "Palomino-Ochoa at SemEval-2020 Task 9: Robust System based on\n  Transformer for Code-Mixed Sentiment Classification", "comments": "Accepted at SemEval-2020, COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a transfer learning system to perform a mixed Spanish-English\nsentiment classification task. Our proposal uses the state-of-the-art language\nmodel BERT and embed it within a ULMFiT transfer learning pipeline. This\ncombination allows us to predict the polarity detection of code-mixed\n(English-Spanish) tweets. Thus, among 29 submitted systems, our approach\n(referred to as dplominop) is ranked 4th on the Sentimix Spanglish test set of\nSemEval 2020 Task 9. In fact, our system yields the weighted-F1 score value of\n0.755 which can be easily reproduced -- the source code and implementation\ndetails are made available.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:25:58 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Palomino", "Daniel", ""], ["Ochoa-Luna", "Jose", ""]]}, {"id": "2011.09458", "submitter": "Austin Dulaney", "authors": "Austin R. Dulaney and John F. Brady", "title": "Machine Learning for Phase Behavior in Active Matter Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that deep learning techniques can be used to predict motility\ninduced phase separation (MIPS) in suspensions of active Brownian particles\n(ABPs) by creating a notion of phase at the particle level. Using a fully\nconnected network in conjunction with a graph neural network we use individual\nparticle features to predict to which phase a particle belongs. From this, we\nare able to compute the fraction of dilute particles to determine if the system\nis in the homogeneous dilute, dense, or coexistence region. Our predictions are\ncompared against the MIPS binodal computed from simulation. The strong\nagreement between the two suggests that machine learning provides an effective\nway to determine the phase behavior of ABPs and could prove useful for\ndetermining more complex phase diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:35:23 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Dulaney", "Austin R.", ""], ["Brady", "John F.", ""]]}, {"id": "2011.09464", "submitter": "Th\\'eophane  Weber", "authors": "Thomas Mesnard, Th\\'eophane Weber, Fabio Viola, Shantanu Thakoor, Alaa\n  Saade, Anna Harutyunyan, Will Dabney, Tom Stepleton, Nicolas Heess, Arthur\n  Guez, Marcus Hutter, Lars Buesing, R\\'emi Munos", "title": "Counterfactual Credit Assignment in Model-Free Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Credit assignment in reinforcement learning is the problem of measuring an\naction influence on future rewards. In particular, this requires separating\nskill from luck, ie. disentangling the effect of an action on rewards from that\nof external factors and subsequent actions. To achieve this, we adapt the\nnotion of counterfactuals from causality theory to a model-free RL setup. The\nkey idea is to condition value functions on future events, by learning to\nextract relevant information from a trajectory. We then propose to use these as\nfuture-conditional baselines and critics in policy gradient algorithms and we\ndevelop a valid, practical variant with provably lower variance, while\nachieving unbiasedness by constraining the hindsight information not to contain\ninformation about the agent actions. We demonstrate the efficacy and validity\nof our algorithm on a number of illustrative problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:41:44 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Mesnard", "Thomas", ""], ["Weber", "Th\u00e9ophane", ""], ["Viola", "Fabio", ""], ["Thakoor", "Shantanu", ""], ["Saade", "Alaa", ""], ["Harutyunyan", "Anna", ""], ["Dabney", "Will", ""], ["Stepleton", "Tom", ""], ["Heess", "Nicolas", ""], ["Guez", "Arthur", ""], ["Hutter", "Marcus", ""], ["Buesing", "Lars", ""], ["Munos", "R\u00e9mi", ""]]}, {"id": "2011.09465", "submitter": "Shintaro Fukushima", "authors": "Shintaro Fukushima and Kenji Yamanishi", "title": "Detecting Hierarchical Changes in Latent Variable Models", "comments": "12pages, Accepted to 20th IEEE International Conference on Data\n  Mining (ICDM2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the issue of detecting hierarchical changes in latent\nvariable models (HCDL) from data streams. There are three different levels of\nchanges for latent variable models: 1) the first level is the change in data\ndistribution for fixed latent variables, 2) the second one is that in the\ndistribution over latent variables, and 3) the third one is that in the number\nof latent variables. It is important to detect these changes because we can\nanalyze the causes of changes by identifying which level a change comes from\n(change interpretability). This paper proposes an information-theoretic\nframework for detecting changes of the three levels in a hierarchical way. The\nkey idea to realize it is to employ the MDL (minimum description length) change\nstatistics for measuring the degree of change, in combination with DNML\n(decomposed normalized maximum likelihood) code-length calculation. We give a\ntheoretical basis for making reliable alarms for changes. Focusing on\nstochastic block models, we employ synthetic and benchmark datasets to\nempirically demonstrate the effectiveness of our framework in terms of change\ninterpretability as well as change detection.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:46:10 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 19:29:55 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 01:34:53 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Fukushima", "Shintaro", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "2011.09468", "submitter": "Mohammad Pezeshki", "authors": "Mohammad Pezeshki, S\\'ekou-Oumar Kaba, Yoshua Bengio, Aaron Courville,\n  Doina Precup, Guillaume Lajoie", "title": "Gradient Starvation: A Learning Proclivity in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify and formalize a fundamental gradient descent phenomenon resulting\nin a learning proclivity in over-parameterized neural networks. Gradient\nStarvation arises when cross-entropy loss is minimized by capturing only a\nsubset of features relevant for the task, despite the presence of other\npredictive features that fail to be discovered. This work provides a\ntheoretical explanation for the emergence of such feature imbalance in neural\nnetworks. Using tools from Dynamical Systems theory, we identify simple\nproperties of learning dynamics during gradient descent that lead to this\nimbalance, and prove that such a situation can be expected given certain\nstatistical structure in training data. Based on our proposed formalism, we\ndevelop guarantees for a novel regularization method aimed at decoupling\nfeature learning dynamics, improving accuracy and robustness in cases hindered\nby gradient starvation. We illustrate our findings with simple and real-world\nout-of-distribution (OOD) generalization experiments.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:52:08 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 18:17:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pezeshki", "Mohammad", ""], ["Kaba", "S\u00e9kou-Oumar", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""], ["Precup", "Doina", ""], ["Lajoie", "Guillaume", ""]]}, {"id": "2011.09471", "submitter": "Leslie Smith", "authors": "Helena E. Liu and Leslie N. Smith", "title": "FROST: Faster and more Robust One-shot Semi-supervised Training", "comments": "Withdrawn because the results reported were due to an error in our\n  code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in one-shot semi-supervised learning have lowered the barrier\nfor deep learning of new applications. However, the state-of-the-art for\nsemi-supervised learning is slow to train and the performance is sensitive to\nthe choices of the labeled data and hyper-parameter values. In this paper, we\npresent a one-shot semi-supervised learning method that trains up to an order\nof magnitude faster and is more robust than state-of-the-art methods.\nSpecifically, we show that by combining semi-supervised learning with a\none-stage, single network version of self-training, our FROST methodology\ntrains faster and is more robust to choices for the labeled samples and changes\nin hyper-parameters. Our experiments demonstrate FROST's capability to perform\nwell when the composition of the unlabeled data is unknown; that is when the\nunlabeled data contain unequal numbers of each class and can contain\nout-of-distribution examples that don't belong to any of the training classes.\nHigh performance, speed of training, and insensitivity to hyper-parameters make\nFROST the most practical method for one-shot semi-supervised training. Our code\nis available at https://github.com/HelenaELiu/FROST.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:56:03 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 11:29:58 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 23:45:56 GMT"}, {"version": "v4", "created": "Fri, 4 Dec 2020 14:04:18 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Liu", "Helena E.", ""], ["Smith", "Leslie N.", ""]]}, {"id": "2011.09497", "submitter": "Alexander Taylor", "authors": "Alex Taylor, Ross Kleiman, Scott Hebbring, Peggy Peissig, David Page", "title": "High-Throughput Approach to Modeling Healthcare Costs Using Electronic\n  Healthcare Records", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Accurate estimation of healthcare costs is crucial for healthcare systems to\nplan and effectively negotiate with insurance companies regarding the coverage\nof patient-care costs. Greater accuracy in estimating healthcare costs would\nprovide mutual benefit for both health systems and the insurers that support\nthese systems by better aligning payment models with patient-care costs. This\nstudy presents the results of a generalizable machine learning approach to\npredicting medical events built from 40 years of data from >860,000 patients\npertaining to >6,700 prescription medications, courtesy of Marshfield Clinic in\nWisconsin. It was found that models built using this approach performed well\nwhen compared to similar studies predicting physician prescriptions of\nindividual medications. In addition to providing a comprehensive predictive\nmodel for all drugs in a large healthcare system, the approach taken in this\nresearch benefits from potential applicability to a wide variety of other\nmedical events.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 19:06:18 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Taylor", "Alex", ""], ["Kleiman", "Ross", ""], ["Hebbring", "Scott", ""], ["Peissig", "Peggy", ""], ["Page", "David", ""]]}, {"id": "2011.09501", "submitter": "Pengcheng Li", "authors": "Yixin Guo, Pengcheng Li, Yingwei Luo, Xiaolin Wang, Zhenlin Wang", "title": "GRAPHSPY: Fused Program Semantic-Level Embedding via Graph Neural\n  Networks for Dead Store Detection", "comments": "9 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Production software oftentimes suffers from the issue of performance\ninefficiencies caused by inappropriate use of data structures, programming\nabstractions, and conservative compiler optimizations. It is desirable to avoid\nunnecessary memory operations. However, existing works often use a\nwhole-program fine-grained monitoring method with incredibly high overhead. To\nthis end, we propose a learning-aided approach to identify unnecessary memory\noperations intelligently with low overhead. By applying several prevalent graph\nneural network models to extract program semantics with respect to program\nstructure, execution order and dynamic states, we present a novel, hybrid\nprogram embedding approach so that to derive unnecessary memory operations\nthrough the embedding. We train our model with tens of thousands of samples\nacquired from a set of real-world benchmarks. Results show that our model\nachieves 90% of accuracy and incurs only around a half of time overhead of the\nstate-of-art tool.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 19:17:15 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Guo", "Yixin", ""], ["Li", "Pengcheng", ""], ["Luo", "Yingwei", ""], ["Wang", "Xiaolin", ""], ["Wang", "Zhenlin", ""]]}, {"id": "2011.09527", "submitter": "Liam Fowl", "authors": "Eitan Borgnia, Valeriia Cherepanova, Liam Fowl, Amin Ghiasi, Jonas\n  Geiping, Micah Goldblum, Tom Goldstein, Arjun Gupta", "title": "Strong Data Augmentation Sanitizes Poisoning and Backdoor Attacks\n  Without an Accuracy Tradeoff", "comments": "Authors ordered alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data poisoning and backdoor attacks manipulate victim models by maliciously\nmodifying training data. In light of this growing threat, a recent survey of\nindustry professionals revealed heightened fear in the private sector regarding\ndata poisoning. Many previous defenses against poisoning either fail in the\nface of increasingly strong attacks, or they significantly degrade performance.\nHowever, we find that strong data augmentations, such as mixup and CutMix, can\nsignificantly diminish the threat of poisoning and backdoor attacks without\ntrading off performance. We further verify the effectiveness of this simple\ndefense against adaptive poisoning methods, and we compare to baselines\nincluding the popular differentially private SGD (DP-SGD) defense. In the\ncontext of backdoors, CutMix greatly mitigates the attack while simultaneously\nincreasing validation accuracy by 9%.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 20:18:50 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Borgnia", "Eitan", ""], ["Cherepanova", "Valeriia", ""], ["Fowl", "Liam", ""], ["Ghiasi", "Amin", ""], ["Geiping", "Jonas", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""], ["Gupta", "Arjun", ""]]}, {"id": "2011.09534", "submitter": "Nicolas Rougier", "authors": "Nicolas P. Rougier and Georgios Is. Detorakis", "title": "Randomized Self Organizing Map", "comments": "32 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a variation of the self organizing map algorithm by considering\nthe random placement of neurons on a two-dimensional manifold, following a blue\nnoise distribution from which various topologies can be derived. These\ntopologies possess random (but controllable) discontinuities that allow for a\nmore flexible self-organization, especially with high-dimensional data. The\nproposed algorithm is tested on one-, two- and three-dimensions tasks as well\nas on the MNIST handwritten digits dataset and validated using spectral\nanalysis and topological data analysis tools. We also demonstrate the ability\nof the randomized self-organizing map to gracefully reorganize itself in case\nof neural lesion and/or neurogenesis.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 20:34:16 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Rougier", "Nicolas P.", ""], ["Detorakis", "Georgios Is.", ""]]}, {"id": "2011.09536", "submitter": "Asadullah Hill Galib", "authors": "Asadullah Hill Galib, Nadia Nahar, and B M Mainul Hossain", "title": "The Influences of Pre-birth Factors in Early Assessment of Child\n  Mortality using Machine Learning Techniques", "comments": "21 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of child mortality is crucial as it pertains to the policy and\nprograms of a country. The early assessment of patterns and trends in causes of\nchild mortality help decision-makers assess needs, prioritize interventions,\nand monitor progress. Post-birth factors of the child, such as real-time\nclinical data, health data of the child, etc. are frequently used in child\nmortality studies. However, in the early assessment of child mortality,\npre-birth factors would be more practical and beneficial than the post-birth\nfactors. This study aims at incorporating pre-birth factors, such as birth\nhistory, maternal history, reproduction history, socioeconomic condition, etc.\nfor classifying child mortality. To assess the relative importance of the\nfeatures, Information Gain (IG) attribute evaluator is employed. For\nclassifying child mortality, four machine learning algorithms are evaluated.\nResults show that the proposed approach achieved an AUC score of 0.947 in\nclassifying child mortality which outperformed the clinical standards. In terms\nof accuracy, precision, recall, and f-1 score, the results are also notable and\nuniform. In developing countries like Bangladesh, the early assessment of child\nmortality using pre-birth factors would be effective and feasible as it avoids\nthe uncertainty of the post-birth factors.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 20:37:55 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Galib", "Asadullah Hill", ""], ["Nahar", "Nadia", ""], ["Hossain", "B M Mainul", ""]]}, {"id": "2011.09545", "submitter": "Bo Xiong", "authors": "Bo Xiong, Yimin Huang, Hanrong Ye, Steffen Staab, Zhenguo Li", "title": "MOFA: Modular Factorial Design for Hyperparameter Optimization", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel and lightweight hyperparameter optimization (HPO)\nmethod, MOdular FActorial Design (MOFA). MOFA pursues several rounds of HPO,\nwhere each round alternates between exploration of hyperparameter space by\nfactorial design and exploitation of evaluation results by factorial analysis.\nEach round first explores the configuration space by constructing a\nlow-discrepancy set of hyperparameters that cover this space well while\nde-correlating hyperparameters, and then exploits evaluation results through\nfactorial analysis that determines which hyperparameters should be further\nexplored and which should become fixed in the next round. We prove that the\ninference of MOFA achieves higher confidence than other sampling schemes. Each\nindividual round is highly parallelizable and hence offers major improvements\nof efficiency compared to model-based methods. Empirical results show that MOFA\nachieves better effectiveness and efficiency compared with state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 20:54:28 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 09:07:44 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Xiong", "Bo", ""], ["Huang", "Yimin", ""], ["Ye", "Hanrong", ""], ["Staab", "Steffen", ""], ["Li", "Zhenguo", ""]]}, {"id": "2011.09550", "submitter": "Mark Matties", "authors": "Mark Alan Matties", "title": "Vector Embeddings with Subvector Permutation Invariance using a Triplet\n  Enhanced Autoencoder", "comments": "19 pages, 18 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of deep neural network (DNN) autoencoders (AEs) has recently exploded\ndue to their wide applicability. However, the embedding representation produced\nby a standard DNN AE that is trained to minimize only the reconstruction error\ndoes not always reveal more subtle patterns in the data. Sometimes, the\nautoencoder needs further direction in the form of one or more additional loss\nfunctions. In this paper, we use an autoencoder enhanced with triplet loss to\npromote the clustering of vectors that are related through permutations of\nconstituent subvectors. With this approach, we can create an embedding of the\nvector that is nearly invariant to such permutations. We can then use these\ninvariant embeddings as inputs to other problems, like classification and\nclustering, and improve detection accuracy in those problems.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 21:24:07 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Matties", "Mark Alan", ""]]}, {"id": "2011.09554", "submitter": "Giuseppe Fenza", "authors": "Giuseppe Fenza, Mariacristina Gallo, Vincenzo Loia, Domenico Marino,\n  Francesco Orciuoli", "title": "A Cognitive Approach based on the Actionable Knowledge Graph for\n  supporting Maintenance Operations", "comments": null, "journal-ref": "2020 IEEE Conference on Evolving and Adaptive Intelligent Systems\n  (EAIS), Bari, Italy, 2020, pp. 1-7", "doi": "10.1109/EAIS48028.2020.9122759", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the era of Industry 4.0, cognitive computing and its enabling technologies\n(Artificial Intelligence, Machine Learning, etc.) allow to define systems able\nto support maintenance by providing relevant information, at the right time,\nretrieved from structured companies' databases, and unstructured documents,\nlike technical manuals, intervention reports, and so on. Moreover, contextual\ninformation plays a crucial role in tailoring the support both during the\nplanning and the execution of interventions. Contextual information can be\ndetected with the help of sensors, wearable devices, indoor and outdoor\npositioning systems, and object recognition capabilities (using fixed or\nwearable cameras), all of which can collect historical data for further\nanalysis. In this work, we propose a cognitive system that learns from past\ninterventions to generate contextual recommendations for improving maintenance\npractices in terms of time, budget, and scope. The system uses formal\nconceptual models, incremental learning, and ranking algorithms to accomplish\nthese objectives.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 21:53:00 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Fenza", "Giuseppe", ""], ["Gallo", "Mariacristina", ""], ["Loia", "Vincenzo", ""], ["Marino", "Domenico", ""], ["Orciuoli", "Francesco", ""]]}, {"id": "2011.09573", "submitter": "Maxim Raginsky", "authors": "Joshua Hanson, Maxim Raginsky, and Eduardo Sontag", "title": "Learning Recurrent Neural Net Models of Nonlinear Systems", "comments": "14 pages; full version of the paper accepted to L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the following learning problem: Given sample pairs of input and\noutput signals generated by an unknown nonlinear system (which is not assumed\nto be causal or time-invariant), we wish to find a continuous-time recurrent\nneural net with hyperbolic tangent activation function that approximately\nreproduces the underlying i/o behavior with high confidence. Leveraging earlier\nwork concerned with matching output derivatives up to a given finite order, we\nreformulate the learning problem in familiar system-theoretic language and\nderive quantitative guarantees on the sup-norm risk of the learned model in\nterms of the number of neurons, the sample size, the number of derivatives\nbeing matched, and the regularity properties of the inputs, the outputs, and\nthe unknown i/o map.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 22:53:41 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 03:43:35 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 21:13:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Hanson", "Joshua", ""], ["Raginsky", "Maxim", ""], ["Sontag", "Eduardo", ""]]}, {"id": "2011.09586", "submitter": "Norman Di Palo", "authors": "Norman Di Palo, Edward Johns", "title": "SAFARI: Safe and Active Robot Imitation Learning with Imagination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main issues in Imitation Learning is the erroneous behavior of an\nagent when facing out-of-distribution situations, not covered by the set of\ndemonstrations given by the expert. In this work, we tackle this problem by\nintroducing a novel active learning and control algorithm, SAFARI. During\ntraining, it allows an agent to request further human demonstrations when these\nout-of-distribution situations are met. At deployment, it combines model-free\nacting using behavioural cloning with model-based planning to reduce\nstate-distribution shift, using future state reconstruction as a test for state\nfamiliarity. We empirically demonstrate how this method increases the\nperformance on a set of manipulation tasks with respect to passive Imitation\nLearning, by gathering more informative demonstrations and by minimizing\nstate-distribution shift at test time. We also show how this method enables the\nagent to autonomously predict failure rapidly and safely.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 23:43:59 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Di Palo", "Norman", ""], ["Johns", "Edward", ""]]}, {"id": "2011.09588", "submitter": "Youngseog Chung", "authors": "Youngseog Chung, Willie Neiswanger, Ian Char, Jeff Schneider", "title": "Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty\n  Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the many ways of quantifying uncertainty in a regression setting,\nspecifying the full quantile function is attractive, as quantiles are amenable\nto interpretation and evaluation. A model that predicts the true conditional\nquantiles for each input, at all quantile levels, presents a correct and\nefficient representation of the underlying uncertainty. To achieve this, many\ncurrent quantile-based methods focus on optimizing the so-called pinball loss.\nHowever, this loss restricts the scope of applicable regression models, limits\nthe ability to target many desirable properties (e.g. calibration, sharpness,\ncentered intervals), and may produce poor conditional quantiles. In this work,\nwe develop new quantile methods that address these shortcomings. In particular,\nwe propose methods that can apply to any class of regression model, allow for\nselecting a trade-off between calibration and sharpness, optimize for\ncalibration of centered intervals, and produce more accurate conditional\nquantiles. We provide a thorough experimental evaluation of our methods, which\nincludes a high dimensional uncertainty quantification task in nuclear fusion.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 23:51:23 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 23:41:04 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 10:10:50 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chung", "Youngseog", ""], ["Neiswanger", "Willie", ""], ["Char", "Ian", ""], ["Schneider", "Jeff", ""]]}, {"id": "2011.09592", "submitter": "Shrijita Bhattacharya", "authors": "Shrijita Bhattacharya, Zihuan Liu, Tapabrata Maiti", "title": "Variational Bayes Neural Network: Posterior Consistency, Classification\n  Accuracy and Computational Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Bayesian neural network models (BNN) have re-surged in recent years due to\nthe advancement of scalable computations and its utility in solving complex\nprediction problems in a wide variety of applications. Despite the popularity\nand usefulness of BNN, the conventional Markov Chain Monte Carlo based\nimplementation suffers from high computational cost, limiting the use of this\npowerful technique in large scale studies. The variational Bayes inference has\nbecome a viable alternative to circumvent some of the computational issues.\nAlthough the approach is popular in machine learning, its application in\nstatistics is somewhat limited. This paper develops a variational Bayesian\nneural network estimation methodology and related statistical theory. The\nnumerical algorithms and their implementational are discussed in detail. The\ntheory for posterior consistency, a desirable property in nonparametric\nBayesian statistics, is also developed. This theory provides an assessment of\nprediction accuracy and guidelines for characterizing the prior distributions\nand variational family. The loss of using a variational posterior over the true\nposterior has also been quantified. The development is motivated by an\nimportant biomedical engineering application, namely building predictive tools\nfor the transition from mild cognitive impairment to Alzheimer's disease. The\npredictors are multi-modal and may involve complex interactive relations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 00:11:27 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Bhattacharya", "Shrijita", ""], ["Liu", "Zihuan", ""], ["Maiti", "Tapabrata", ""]]}, {"id": "2011.09596", "submitter": "Utkarsh Sarawgi", "authors": "Rishab Khincha, Utkarsh Sarawgi, Wazeer Zulfikar, Pattie Maes", "title": "Robustness to Missing Features using Hierarchical Clustering with Split\n  Neural Networks", "comments": "To appear at AAAI 2021 Student Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of missing data has been persistent for a long time and poses a\nmajor obstacle in machine learning and statistical data analysis. Past works in\nthis field have tried using various data imputation techniques to fill in the\nmissing data, or training neural networks (NNs) with the missing data. In this\nwork, we propose a simple yet effective approach that clusters similar input\nfeatures together using hierarchical clustering and then trains proportionately\nsplit neural networks with a joint loss. We evaluate this approach on a series\nof benchmark datasets and show promising improvements even with simple\nimputation techniques. We attribute this to learning through clusters of\nsimilar features in our model architecture. The source code is available at\nhttps://github.com/usarawgi911/Robustness-to-Missing-Features\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 00:35:08 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Khincha", "Rishab", ""], ["Sarawgi", "Utkarsh", ""], ["Zulfikar", "Wazeer", ""], ["Maes", "Pattie", ""]]}, {"id": "2011.09607", "submitter": "Hongyang Yang", "authors": "Xiao-Yang Liu, Hongyang Yang, Qian Chen, Runjia Zhang, Liuqing Yang,\n  Bowen Xiao, Christina Dan Wang", "title": "FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading\n  in Quantitative Finance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep reinforcement learning (DRL) has been recognized as an effective\napproach in quantitative finance, getting hands-on experiences is attractive to\nbeginners. However, to train a practical DRL trading agent that decides where\nto trade, at what price, and what quantity involves error-prone and arduous\ndevelopment and debugging. In this paper, we introduce a DRL library FinRL that\nfacilitates beginners to expose themselves to quantitative finance and to\ndevelop their own stock trading strategies. Along with easily-reproducible\ntutorials, FinRL library allows users to streamline their own developments and\nto compare with existing schemes easily. Within FinRL, virtual environments are\nconfigured with stock market datasets, trading agents are trained with neural\nnetworks, and extensive backtesting is analyzed via trading performance.\nMoreover, it incorporates important trading constraints such as transaction\ncost, market liquidity and the investor's degree of risk-aversion. FinRL is\nfeatured with completeness, hands-on tutorial and reproducibility that favors\nbeginners: (i) at multiple levels of time granularity, FinRL simulates trading\nenvironments across various stock markets, including NASDAQ-100, DJIA, S&P 500,\nHSI, SSE 50, and CSI 300; (ii) organized in a layered architecture with modular\nstructure, FinRL provides fine-tuned state-of-the-art DRL algorithms (DQN,\nDDPG, PPO, SAC, A2C, TD3, etc.), commonly-used reward functions and standard\nevaluation baselines to alleviate the debugging workloads and promote the\nreproducibility, and (iii) being highly extendable, FinRL reserves a complete\nset of user-import interfaces. Furthermore, we incorporated three application\ndemonstrations, namely single stock trading, multiple stock trading, and\nportfolio allocation. The FinRL library will be available on Github at link\nhttps://github.com/AI4Finance-LLC/FinRL-Library.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 01:35:05 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Liu", "Xiao-Yang", ""], ["Yang", "Hongyang", ""], ["Chen", "Qian", ""], ["Zhang", "Runjia", ""], ["Yang", "Liuqing", ""], ["Xiao", "Bowen", ""], ["Wang", "Christina Dan", ""]]}, {"id": "2011.09619", "submitter": "Soroush Ziaeinejad", "authors": "Ali Atghaei, Soroush Ziaeinejad, Mohammad Rahmati", "title": "Abnormal Event Detection in Urban Surveillance Videos Using GAN and\n  Transfer Learning", "comments": "7 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Abnormal event detection (AED) in urban surveillance videos has multiple\nchallenges. Unlike other computer vision problems, the AED is not solely\ndependent on the content of frames. It also depends on the appearance of the\nobjects and their movements in the scene. Various methods have been proposed to\naddress the AED problem. Among those, deep learning based methods show the best\nresults. This paper is based on deep learning methods and provides an effective\nway to detect and locate abnormal events in videos by handling spatio temporal\ndata. This paper uses generative adversarial networks (GANs) and performs\ntransfer learning algorithms on pre trained convolutional neural network (CNN)\nwhich result in an accurate and efficient model. The efficiency of the model is\nfurther improved by processing the optical flow information of the video. This\npaper runs experiments on two benchmark datasets for AED problem (UCSD Peds1\nand UCSD Peds2) and compares the results with other previous methods. The\ncomparisons are based on various criteria such as area under curve (AUC) and\ntrue positive rate (TPR). Experimental results show that the proposed method\ncan effectively detect and locate abnormal events in crowd scenes.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 02:39:35 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Atghaei", "Ali", ""], ["Ziaeinejad", "Soroush", ""], ["Rahmati", "Mohammad", ""]]}, {"id": "2011.09624", "submitter": "Chenglin Xu", "authors": "Meng Ge, Chenglin Xu, Longbiao Wang, Eng Siong Chng, Jianwu Dang,\n  Haizhou Li", "title": "Multi-stage Speaker Extraction with Utterance and Frame-Level Reference\n  Signals", "comments": "Accepted in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker extraction requires a sample speech from the target speaker as the\nreference. However, enrolling a speaker with a long speech is not practical. We\npropose a speaker extraction technique, that performs in multiple stages to\ntake full advantage of short reference speech sample. The extracted speech in\nearly stages is used as the reference speech for late stages. For the first\ntime, we use frame-level sequential speech embedding as the reference for\ntarget speaker. This is a departure from the traditional utterance-based\nspeaker embedding reference. In addition, a signal fusion scheme is proposed to\ncombine the decoded signals in multiple scales with automatically learned\nweights. Experiments on WSJ0-2mix and its noisy versions (WHAM! and WHAMR!)\nshow that SpEx++ consistently outperforms other state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 03:08:04 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 08:38:58 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Ge", "Meng", ""], ["Xu", "Chenglin", ""], ["Wang", "Longbiao", ""], ["Chng", "Eng Siong", ""], ["Dang", "Jianwu", ""], ["Li", "Haizhou", ""]]}, {"id": "2011.09631", "submitter": "Won Jang", "authors": "Won Jang, Dan Lim, Jaesam Yoon", "title": "Universal MelGAN: A Robust Neural Vocoder for High-Fidelity Waveform\n  Generation in Multiple Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Universal MelGAN, a vocoder that synthesizes high-fidelity speech\nin multiple domains. To preserve sound quality when the MelGAN-based structure\nis trained with a dataset of hundreds of speakers, we added multi-resolution\nspectrogram discriminators to sharpen the spectral resolution of the generated\nwaveforms. This enables the model to generate realistic waveforms of\nmulti-speakers, by alleviating the over-smoothing problem in the high frequency\nband of the large footprint model. Our structure generates signals close to\nground-truth data without reducing the inference speed, by discriminating the\nwaveform and spectrogram during training. The model achieved the best mean\nopinion score (MOS) in most scenarios using ground-truth mel-spectrogram as an\ninput. Especially, it showed superior performance in unseen domains with regard\nof speaker, emotion, and language. Moreover, in a multi-speaker text-to-speech\nscenario using mel-spectrogram generated by a transformer model, it synthesized\nhigh-fidelity speech of 4.22 MOS. These results, achieved without external\ndomain information, highlight the potential of the proposed model as a\nuniversal vocoder.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 03:35:45 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 02:00:12 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Jang", "Won", ""], ["Lim", "Dan", ""], ["Yoon", "Jaesam", ""]]}, {"id": "2011.09643", "submitter": "Wei Jin", "authors": "Wei Jin, Tyler Derr, Yiqi Wang, Yao Ma, Zitao Liu and Jiliang Tang", "title": "Node Similarity Preserving Graph Convolutional Networks", "comments": "WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph Neural Networks (GNNs) have achieved tremendous success in various\nreal-world applications due to their strong ability in graph representation\nlearning. GNNs explore the graph structure and node features by aggregating and\ntransforming information within node neighborhoods. However, through\ntheoretical and empirical analysis, we reveal that the aggregation process of\nGNNs tends to destroy node similarity in the original feature space. There are\nmany scenarios where node similarity plays a crucial role. Thus, it has\nmotivated the proposed framework SimP-GCN that can effectively and efficiently\npreserve node similarity while exploiting graph structure. Specifically, to\nbalance information from graph structure and node features, we propose a\nfeature similarity preserving aggregation which adaptively integrates graph\nstructure and node features. Furthermore, we employ self-supervised learning to\nexplicitly capture the complex feature similarity and dissimilarity relations\nbetween nodes. We validate the effectiveness of SimP-GCN on seven benchmark\ndatasets including three assortative and four disassorative graphs. The results\ndemonstrate that SimP-GCN outperforms representative baselines. Further probe\nshows various advantages of the proposed framework. The implementation of\nSimP-GCN is available at \\url{https://github.com/ChandlerBang/SimP-GCN}.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:18:01 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 10:48:14 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Jin", "Wei", ""], ["Derr", "Tyler", ""], ["Wang", "Yiqi", ""], ["Ma", "Yao", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "2011.09645", "submitter": "Weizhi Li", "authors": "Weizhi Li, Gautam Dasarathy, Karthikeyan Natesan Ramamurthy, and Visar\n  Berisha", "title": "Finding the Homology of Decision Boundaries with Active Learning", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurately and efficiently characterizing the decision boundary of\nclassifiers is important for problems related to model selection and\nmeta-learning. Inspired by topological data analysis, the characterization of\ndecision boundaries using their homology has recently emerged as a general and\npowerful tool. In this paper, we propose an active learning algorithm to\nrecover the homology of decision boundaries. Our algorithm sequentially and\nadaptively selects which samples it requires the labels of. We theoretically\nanalyze the proposed framework and show that the query complexity of our active\nlearning algorithm depends naturally on the intrinsic complexity of the\nunderlying manifold. We demonstrate the effectiveness of our framework in\nselecting best-performing machine learning models for datasets just using their\nrespective homological summaries. Experiments on several standard datasets show\nthe sample complexity improvement in recovering the homology and demonstrate\nthe practical utility of the framework for model selection. Source code for our\nalgorithms and experimental results is available at\nhttps://github.com/wayne0908/Active-Learning-Homology.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:22:06 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Li", "Weizhi", ""], ["Dasarathy", "Gautam", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Berisha", "Visar", ""]]}, {"id": "2011.09655", "submitter": "Di Chai", "authors": "Di Chai and Leye Wang and Kai Chen and Qiang Yang", "title": "FedEval: A Benchmark System with a Comprehensive Evaluation Model for\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an innovative solution for privacy-preserving machine learning (ML),\nfederated learning (FL) is attracting much attention from research and industry\nareas. While new technologies proposed in the past few years do evolve the FL\narea, unfortunately, the evaluation results presented in these works fall short\nin integrity and are hardly comparable because of the inconsistent evaluation\nmetrics and the lack of a common platform. In this paper, we propose a\ncomprehensive evaluation framework for FL systems. Specifically, we first\nintroduce the ACTPR model, which defines five metrics that cannot be excluded\nin FL evaluation, including Accuracy, Communication, Time efficiency, Privacy,\nand Robustness. Then we design and implement a benchmarking system called\nFedEval, which enables the systematic evaluation and comparison of existing\nworks under consistent experimental conditions. We then provide an in-depth\nbenchmarking study between the two most widely-used FL mechanisms, FedSGD and\nFedAvg. The benchmarking results show that FedSGD and FedAvg both have\nadvantages and disadvantages under the ACTPR model. For example, FedSGD is\nbarely influenced by the none independent and identically distributed (non-IID)\ndata problem, but FedAvg suffers from a decline in accuracy of up to 9% in our\nexperiments. On the other hand, FedAvg is more efficient than FedSGD regarding\ntime consumption and communication. Lastly, we excavate a set of take-away\nconclusions, which are very helpful for researchers in the FL area.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:59:51 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 16:08:13 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chai", "Di", ""], ["Wang", "Leye", ""], ["Chen", "Kai", ""], ["Yang", "Qiang", ""]]}, {"id": "2011.09658", "submitter": "Xiaoyu Chen", "authors": "Xiaoyu Chen and Rohan Badlani", "title": "Relation Extraction with Contextualized Relation Embedding (CRE)", "comments": "EMNLP 2020 Workshop: Deep Learning Inside Out (DeeLIO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Relation extraction is the task of identifying relation instance between two\nentities given a corpus whereas Knowledge base modeling is the task of\nrepresenting a knowledge base, in terms of relations between entities. This\npaper proposes an architecture for the relation extraction task that integrates\nsemantic information with knowledge base modeling in a novel manner. Existing\napproaches for relation extraction either do not utilize knowledge base\nmodelling or use separately trained KB models for the RE task. We present a\nmodel architecture that internalizes KB modeling in relation extraction. This\nmodel applies a novel approach to encode sentences into contextualized relation\nembeddings, which can then be used together with parameterized entity\nembeddings to score relation instances. The proposed CRE model achieves state\nof the art performance on datasets derived from The New York Times Annotated\nCorpus and FreeBase. The source code has been made available.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 05:19:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Chen", "Xiaoyu", ""], ["Badlani", "Rohan", ""]]}, {"id": "2011.09679", "submitter": "Adam Lerer", "authors": "Lingfan Yu, Jiajun Shen, Jinyang Li, Adam Lerer", "title": "Scalable Graph Neural Networks for Heterogeneous Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks (GNNs) are a popular class of parametric model for\nlearning over graph-structured data. Recent work has argued that GNNs primarily\nuse the graph for feature smoothing, and have shown competitive results on\nbenchmark tasks by simply operating on graph-smoothed node features, rather\nthan using end-to-end learned feature hierarchies that are challenging to scale\nto large graphs. In this work, we ask whether these results can be extended to\nheterogeneous graphs, which encode multiple types of relationship between\ndifferent entities. We propose Neighbor Averaging over Relation Subgraphs\n(NARS), which trains a classifier on neighbor-averaged features for\nrandomly-sampled subgraphs of the \"metagraph\" of relations. We describe\noptimizations to allow these sets of node features to be computed in a\nmemory-efficient way, both at training and inference time. NARS achieves a new\nstate of the art accuracy on several benchmark datasets, outperforming more\nexpensive GNN-based methods\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 06:03:35 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Yu", "Lingfan", ""], ["Shen", "Jiajun", ""], ["Li", "Jinyang", ""], ["Lerer", "Adam", ""]]}, {"id": "2011.09682", "submitter": "Sabrina Enriquez", "authors": "Sabrina Enriquez, Fushing Hsieh", "title": "Categorical exploratory data analysis on goodness-of-fit issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If the aphorism \"All models are wrong\"- George Box, continues to be true in\ndata analysis, particularly when analyzing real-world data, then we should\nannotate this wisdom with visible and explainable data-driven patterns. Such\nannotations can critically shed invaluable light on validity as well as\nlimitations of statistical modeling as a data analysis approach. In an effort\nto avoid holding our real data to potentially unattainable or even unrealistic\ntheoretical structures, we propose to utilize the data analysis paradigm called\nCategorical Exploratory Data Analysis (CEDA). We illustrate the merits of this\nproposal with two real-world data sets from the perspective of goodness-of-fit.\nIn both data sets, the Normal distribution's bell shape seemingly fits rather\nwell by first glance. We apply CEDA to bring out where and how each data fits\nor deviates from the model shape via several important distributional aspects.\nWe also demonstrate that CEDA affords a version of tree-based p-value, and\ncompare it with p-values based on traditional statistical approaches. Along our\ndata analysis, we invest computational efforts in making graphic display to\nilluminate the advantages of using CEDA as one primary way of data analysis in\nData Science education.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 06:11:06 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 01:41:15 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Enriquez", "Sabrina", ""], ["Hsieh", "Fushing", ""]]}, {"id": "2011.09694", "submitter": "Ehsan Zahedinejad Dr.", "authors": "Seyed Shakib Vedaie, Moslem Noori, Jaspreet S. Oberoi, Barry C.\n  Sanders, Ehsan Zahedinejad", "title": "Quantum Multiple Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods play an important role in machine learning applications due to\ntheir conceptual simplicity and superior performance on numerous machine\nlearning tasks. Expressivity of a machine learning model, referring to the\nability of the model to approximate complex functions, has a significant\ninfluence on its performance in these tasks. One approach to enhancing the\nexpressivity of kernel machines is to combine multiple individual kernels to\narrive at a more expressive combined kernel. This approach is referred to as\nmultiple kernel learning (MKL). In this work, we propose an MKL method we refer\nto as quantum MKL, which combines multiple quantum kernels. Our method\nleverages the power of deterministic quantum computing with one qubit (DQC1) to\nestimate the combined kernel for a set of classically intractable individual\nquantum kernels. The combined kernel estimation is achieved without explicitly\ncomputing each individual kernel, while still allowing for the tuning of\nindividual kernels in order to achieve better expressivity. Our simulations on\ntwo binary classification problems---one performed on a synthetic dataset and\nthe other on a German credit dataset---demonstrate the superiority of the\nquantum MKL method over single quantum kernel machines.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 07:19:41 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Vedaie", "Seyed Shakib", ""], ["Noori", "Moslem", ""], ["Oberoi", "Jaspreet S.", ""], ["Sanders", "Barry C.", ""], ["Zahedinejad", "Ehsan", ""]]}, {"id": "2011.09707", "submitter": "Yizhou Qian", "authors": "Yizhou Qian, Mojtaba Forghani, Jonghyun Harry Lee, Matthew Farthing,\n  Tyler Hesser, Peter Kitanidis, Eric Darve", "title": "Application of Deep Learning-based Interpolation Methods to Nearshore\n  Bathymetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nearshore bathymetry, the topography of the ocean floor in coastal zones, is\nvital for predicting the surf zone hydrodynamics and for route planning to\navoid subsurface features. Hence, it is increasingly important for a wide\nvariety of applications, including shipping operations, coastal management, and\nrisk assessment. However, direct high resolution surveys of nearshore\nbathymetry are rarely performed due to budget constraints and logistical\nrestrictions. Another option when only sparse observations are available is to\nuse Gaussian Process regression (GPR), also called Kriging. But GPR has\ndifficulties recognizing patterns with sharp gradients, like those found around\nsand bars and submerged objects, especially when observations are sparse. In\nthis work, we present several deep learning-based techniques to estimate\nnearshore bathymetry with sparse, multi-scale measurements. We propose a Deep\nNeural Network (DNN) to compute posterior estimates of the nearshore\nbathymetry, as well as a conditional Generative Adversarial Network (cGAN) that\nsamples from the posterior distribution. We train our neural networks based on\nsynthetic data generated from nearshore surveys provided by the U.S.\\ Army\nCorps of Engineer Field Research Facility (FRF) in Duck, North Carolina. We\ncompare our methods with Kriging on real surveys as well as surveys with\nartificially added sharp gradients. Results show that direct estimation by DNN\ngives better predictions than Kriging in this application. We use bootstrapping\nwith DNN for uncertainty quantification. We also propose a method, named\nDNN-Kriging, that combines deep learning with Kriging and shows further\nimprovement of the posterior estimates.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:22:00 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Qian", "Yizhou", ""], ["Forghani", "Mojtaba", ""], ["Lee", "Jonghyun Harry", ""], ["Farthing", "Matthew", ""], ["Hesser", "Tyler", ""], ["Kitanidis", "Peter", ""], ["Darve", "Eric", ""]]}, {"id": "2011.09712", "submitter": "Lucas Anquetil", "authors": "Lucas Anquetil, Mike Gartrell, Alain Rakotomamonjy, Ugo Tanielian,\n  Cl\\'ement Calauz\\`enes", "title": "Wasserstein Learning of Determinantal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) have received significant attention as\nan elegant probabilistic model for discrete subset selection. Most prior work\non DPP learning focuses on maximum likelihood estimation (MLE). While efficient\nand scalable, MLE approaches do not leverage any subset similarity information\nand may fail to recover the true generative distribution of discrete data. In\nthis work, by deriving a differentiable relaxation of a DPP sampling algorithm,\nwe present a novel approach for learning DPPs that minimizes the Wasserstein\ndistance between the model and data composed of observed subsets. Through an\nevaluation on a real-world dataset, we show that our Wasserstein learning\napproach provides significantly improved predictive performance on a generative\ntask compared to DPPs trained using MLE.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:30:57 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Anquetil", "Lucas", ""], ["Gartrell", "Mike", ""], ["Rakotomamonjy", "Alain", ""], ["Tanielian", "Ugo", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""]]}, {"id": "2011.09719", "submitter": "Chawin Sitawarin", "authors": "Chawin Sitawarin, Evgenios M. Kornaropoulos, Dawn Song, David Wagner", "title": "Adversarial Examples for $k$-Nearest Neighbor Classifiers Based on\n  Higher-Order Voronoi Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are a widely studied phenomenon in machine learning\nmodels. While most of the attention has been focused on neural networks, other\npractical models also suffer from this issue. In this work, we propose an\nalgorithm for evaluating the adversarial robustness of $k$-nearest neighbor\nclassification, i.e., finding a minimum-norm adversarial example. Diverging\nfrom previous proposals, we take a geometric approach by performing a search\nthat expands outwards from a given input point. On a high level, the search\nradius expands to the nearby Voronoi cells until we find a cell that classifies\ndifferently from the input point. To scale the algorithm to a large $k$, we\nintroduce approximation steps that find perturbations with smaller norm,\ncompared to the baselines, in a variety of datasets. Furthermore, we analyze\nthe structural properties of a dataset where our approach outperforms the\ncompetition.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 08:49:10 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Kornaropoulos", "Evgenios M.", ""], ["Song", "Dawn", ""], ["Wagner", "David", ""]]}, {"id": "2011.09733", "submitter": "Maryam MeshkinKiya", "authors": "Maryam MeshkinKiya, Riccardo Paolini", "title": "Preparing Weather Data for Real-Time Building Energy Simulation", "comments": "eSIM2021 accepted article", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study introduces a framework for quality control of measured weather\ndata, including anomaly detection, and infilling missing values. Weather data\nis a fundamental input to building performance simulations, in which anomalous\nvalues defect the results while missing data lead to an unexpected termination\nof the simulation process. Traditionally, infilling missing values in weather\ndata is performed through periodic or linear interpolations. However, when\nmissing values exceed many consecutive hours, the accuracy of traditional\nmethods is subject to debate. This study demonstrates how Neural Networks can\nincrease the accuracy of data imputation when compared to other supervised\nlearning methods. The framework is validated by predicting missing temperature\nand relative humidity data for an observation site, through a network of nearby\nweather stations in Milan, Italy. Results show that the proposed method can\nfacilitate real-time building simulations with accurate and rapid quality\ncontrol.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:18:07 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["MeshkinKiya", "Maryam", ""], ["Paolini", "Riccardo", ""]]}, {"id": "2011.09741", "submitter": "Rodrigo de Medrano", "authors": "Rodrigo de Medrano, V\\'ictor de Buen Remiro, Jos\\'e L. Aznarte", "title": "SOCAIRE: Forecasting and Monitoring Urban Air Quality in Madrid", "comments": "26 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Air quality has become one of the main issues in public health and urban\nplanning management, due to the proven adverse effects of high pollutant\nconcentrations. Considering the mitigation measures that cities all over the\nworld are taking in order to face frequent low air quality episodes, the\ncapability of foreseeing future pollutant concentrations is of great\nimportance. Through this paper, we present SOCAIRE, an operational tool based\non a Bayesian and spatiotemporal ensemble of neural and statistical nested\nmodels. SOCAIRE integrates endogenous and exogenous information in order to\npredict and monitor future distributions of the concentration for several\npollutants in the city of Madrid. It focuses on modeling each and every\navailable component which might play a role in air quality: past concentrations\nof pollutants, human activity, numerical pollution estimation, and numerical\nweather predictions. This tool is currently in operation in Madrid, producing\ndaily air quality predictions for the next 48 hours and anticipating the\nprobability of the activation of the measures included in the city's official\nair quality \\no protocols through probabilistic inferences about compound\nevents.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:39:10 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["de Medrano", "Rodrigo", ""], ["Remiro", "V\u00edctor de Buen", ""], ["Aznarte", "Jos\u00e9 L.", ""]]}, {"id": "2011.09744", "submitter": "Matteo Lionello", "authors": "Matteo Lionello and Hendrik Purwins", "title": "End-To-End Dilated Variational Autoencoder with Bottleneck\n  Discriminative Loss for Sound Morphing -- A Preliminary Study", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.21572.58240/1", "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a preliminary study on an end-to-end variational autoencoder (VAE)\nfor sound morphing. Two VAE variants are compared: VAE with dilation layers\n(DC-VAE) and VAE only with regular convolutional layers (CC-VAE). We combine\nthe following loss functions: 1) the time-domain mean-squared error for\nreconstructing the input signal, 2) the Kullback-Leibler divergence to the\nstandard normal distribution in the bottleneck layer, and 3) the classification\nloss calculated from the bottleneck representation. On a database of spoken\ndigits, we use 1-nearest neighbor classification to show that the sound classes\nseparate in the bottleneck layer. We introduce the Mel-frequency cepstrum\ncoefficient dynamic time warping (MFCC-DTW) deviation as a measure of how well\nthe VAE decoder projects the class center in the latent (bottleneck) layer to\nthe center of the sounds of that class in the audio domain. In terms of\nMFCC-DTW deviation and 1-NN classification, DC-VAE outperforms CC-VAE. These\nresults for our parametrization and our dataset indicate that DC-VAE is more\nsuitable for sound morphing than CC-VAE, since the DC-VAE decoder better\npreserves the topology when mapping from the audio domain to the latent space.\nExamples are given both for morphing spoken digits and drum sounds.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:47:13 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lionello", "Matteo", ""], ["Purwins", "Hendrik", ""]]}, {"id": "2011.09747", "submitter": "Jernej Hribar Dr.", "authors": "Jernej Hribar, Andrei Marinescu, Alessandro Chiumento, and Luiz A.\n  DaSilva", "title": "Energy Aware Deep Reinforcement Learning Scheduling for Sensors\n  Correlated in Time and Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of battery-powered sensors deployed for monitoring purposes in a\nmultitude of scenarios, e.g., agriculture, smart cities, industry, etc.,\nrequire energy-efficient solutions to prolong their lifetime. When these\nsensors observe a phenomenon distributed in space and evolving in time, it is\nexpected that collected observations will be correlated in time and space. In\nthis paper, we propose a Deep Reinforcement Learning (DRL) based scheduling\nmechanism capable of taking advantage of correlated information. We design our\nsolution using the Deep Deterministic Policy Gradient (DDPG) algorithm. The\nproposed mechanism is capable of determining the frequency with which sensors\nshould transmit their updates, to ensure accurate collection of observations,\nwhile simultaneously considering the energy available. To evaluate our\nscheduling mechanism, we use multiple datasets containing environmental\nobservations obtained in multiple real deployments. The real observations\nenable us to model the environment with which the mechanism interacts as\nrealistically as possible. We show that our solution can significantly extend\nthe sensors' lifetime. We compare our mechanism to an idealized, all-knowing\nscheduler to demonstrate that its performance is near-optimal. Additionally, we\nhighlight the unique feature of our design, energy-awareness, by displaying the\nimpact of sensors' energy levels on the frequency of updates.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 09:53:27 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Hribar", "Jernej", ""], ["Marinescu", "Andrei", ""], ["Chiumento", "Alessandro", ""], ["DaSilva", "Luiz A.", ""]]}, {"id": "2011.09750", "submitter": "Jonathan Lee", "authors": "Jonathan N. Lee, Aldo Pacchiano, Vidya Muthukumar, Weihao Kong, Emma\n  Brunskill", "title": "Online Model Selection for Reinforcement Learning with Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved impressive successes yet often\nrequires a very large amount of interaction data. This result is perhaps\nunsurprising, as using complicated function approximation often requires more\ndata to fit, and early theoretical results on linear Markov decision processes\nprovide regret bounds that scale with the dimension of the linear\napproximation. Ideally, we would like to automatically identify the minimal\ndimension of the approximation that is sufficient to encode an optimal policy.\nTowards this end, we consider the problem of model selection in RL with\nfunction approximation, given a set of candidate RL algorithms with known\nregret guarantees. The learner's goal is to adapt to the complexity of the\noptimal algorithm without knowing it \\textit{a priori}. We present a\nmeta-algorithm that successively rejects increasingly complex models using a\nsimple statistical test. Given at least one candidate that satisfies\nrealizability, we prove the meta-algorithm adapts to the optimal complexity\nwith $\\tilde{O}(L^{5/6} T^{2/3})$ regret compared to the optimal candidate's\n$\\tilde{O}(\\sqrt T)$ regret, where $T$ is the number of episodes and $L$ is the\nnumber of algorithms. The dimension and horizon dependencies remain optimal\nwith respect to the best candidate, and our meta-algorithmic approach is\nflexible to incorporate multiple candidate algorithms and models. Finally, we\nshow that the meta-algorithm automatically admits significantly improved\ninstance-dependent regret bounds that depend on the gaps between the maximal\nvalues attainable by the candidates.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:00:54 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lee", "Jonathan N.", ""], ["Pacchiano", "Aldo", ""], ["Muthukumar", "Vidya", ""], ["Kong", "Weihao", ""], ["Brunskill", "Emma", ""]]}, {"id": "2011.09757", "submitter": "Haozhe Feng", "authors": "Hao-Zhe Feng, Zhaoyang You, Minghao Chen, Tianye Zhang, Minfeng Zhu,\n  Fei Wu, Chao Wu, Wei Chen", "title": "KD3A: Unsupervised Multi-Source Decentralized Domain Adaptation via\n  Knowledge Distillation", "comments": "15 pages, 5 figures, Accepted for presentation at ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional unsupervised multi-source domain adaptation (UMDA) methods\nassume all source domains can be accessed directly. This neglects the\nprivacy-preserving policy, that is, all the data and computations must be kept\ndecentralized. There exists three problems in this scenario: (1) Minimizing the\ndomain distance requires the pairwise calculation of the data from source and\ntarget domains, which is not accessible. (2) The communication cost and privacy\nsecurity limit the application of UMDA methods (e.g., the domain adversarial\ntraining). (3) Since users have no authority to check the data quality, the\nirrelevant or malicious source domains are more likely to appear, which causes\nnegative transfer. In this study, we propose a privacy-preserving UMDA paradigm\nnamed Knowledge Distillation based Decentralized Domain Adaptation (KD3A),\nwhich performs domain adaptation through the knowledge distillation on models\nfrom different source domains. KD3A solves the above problems with three\ncomponents: (1) A multi-source knowledge distillation method named Knowledge\nVote to learn high-quality domain consensus knowledge. (2) A dynamic weighting\nstrategy named Consensus Focus to identify both the malicious and irrelevant\ndomains. (3) A decentralized optimization strategy for domain distance named\nBatchNorm MMD. The extensive experiments on DomainNet demonstrate that KD3A is\nrobust to the negative transfer and brings a 100x reduction of communication\ncost compared with other decentralized UMDA methods. Moreover, our KD3A\nsignificantly outperforms state-of-the-art UMDA approaches.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:26:02 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 03:33:12 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 09:28:44 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2020 07:07:11 GMT"}, {"version": "v5", "created": "Tue, 2 Mar 2021 03:32:18 GMT"}, {"version": "v6", "created": "Sun, 9 May 2021 06:19:40 GMT"}, {"version": "v7", "created": "Tue, 15 Jun 2021 08:22:02 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Feng", "Hao-Zhe", ""], ["You", "Zhaoyang", ""], ["Chen", "Minghao", ""], ["Zhang", "Tianye", ""], ["Zhu", "Minfeng", ""], ["Wu", "Fei", ""], ["Wu", "Chao", ""], ["Chen", "Wei", ""]]}, {"id": "2011.09766", "submitter": "Zhuo Zheng", "authors": "Zhuo Zheng, Yanfei Zhong, Junjue Wang, Ailong Ma", "title": "Foreground-Aware Relation Network for Geospatial Object Segmentation in\n  High Spatial Resolution Remote Sensing Imagery", "comments": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition(CVPR). 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geospatial object segmentation, as a particular semantic segmentation task,\nalways faces with larger-scale variation, larger intra-class variance of\nbackground, and foreground-background imbalance in the high spatial resolution\n(HSR) remote sensing imagery. However, general semantic segmentation methods\nmainly focus on scale variation in the natural scene, with inadequate\nconsideration of the other two problems that usually happen in the large area\nearth observation scene. In this paper, we argue that the problems lie on the\nlack of foreground modeling and propose a foreground-aware relation network\n(FarSeg) from the perspectives of relation-based and optimization-based\nforeground modeling, to alleviate the above two problems. From perspective of\nrelation, FarSeg enhances the discrimination of foreground features via\nforeground-correlated contexts associated by learning foreground-scene\nrelation. Meanwhile, from perspective of optimization, a foreground-aware\noptimization is proposed to focus on foreground examples and hard examples of\nbackground during training for a balanced optimization. The experimental\nresults obtained using a large scale dataset suggest that the proposed method\nis superior to the state-of-the-art general semantic segmentation methods and\nachieves a better trade-off between speed and accuracy. Code has been made\navailable at: \\url{https://github.com/Z-Zheng/FarSeg}.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:57:43 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zheng", "Zhuo", ""], ["Zhong", "Yanfei", ""], ["Wang", "Junjue", ""], ["Ma", "Ailong", ""]]}, {"id": "2011.09769", "submitter": "Marc Goerigk", "authors": "Marc Goerigk and Jannis Kurtz", "title": "Data-Driven Robust Optimization using Unsupervised Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust optimization has been established as a leading methodology to approach\ndecision problems under uncertainty. To derive a robust optimization model, a\ncentral ingredient is to identify a suitable model for uncertainty, which is\ncalled the uncertainty set, containing all scenarios against which we wish to\nprotect. An ongoing challenge in the recent literature is to derive uncertainty\nsets from given historical data.\n  In this paper we use an unsupervised deep learning method to construct\nnon-convex uncertainty sets from data, which have a more complex structure than\nthe typically considered sets. We prove that most of the classical uncertainty\nclasses are special cases of our derived sets and that optimizing over it is\nstrongly NP-hard. Nevertheless we show that the trained neural networks can be\nintegrated into a robust optimization model by formulating the adversarial\nproblem as a convex quadratic mixed-integer program. This allows us to derive\nrobust solutions through an iterative scenario generation process. We prove\nthat our class of uncertainty sets contains In extensive computational\nexperiments, we compare this approach to a similar approach, which derives\nuncertainty sets by kernel-based support vector clustering. We find that\nuncertainty sets derived by the unsupervised deep learning method can give a\nbetter description of data, leading to robust solutions that often outperform\nthe comparison method both with respect to objective value and feasibility.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 11:06:54 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 19:28:39 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Goerigk", "Marc", ""], ["Kurtz", "Jannis", ""]]}, {"id": "2011.09775", "submitter": "Aniruddh Herle Mr.", "authors": "Aniruddh Herle, Janamejaya Channegowda, Dinakar Prabhu", "title": "A Temporal Convolution Network Approach to State-of-Charge Estimation in\n  Li-ion Batteries", "comments": "17th IEEE India Council International Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electric Vehicle (EV) fleets have dramatically expanded over the past several\nyears. There has been significant increase in interest to electrify all modes\nof transportation. EVs are primarily powered by Energy Storage Systems such as\nLithium-ion Battery packs. Total battery pack capacity translates to the\navailable range in an EV. State of Charge (SOC) is the ratio of available\nbattery capacity to total capacity and is expressed in percentages. It is\ncrucial to accurately estimate SOC to determine the available range in an EV\nwhile it is in use. In this paper, a Temporal Convolution Network (TCN)\napproach is taken to estimate SOC. This is the first implementation of TCNs for\nthe SOC estimation task. Estimation is carried out on various drive cycles such\nas HWFET, LA92, UDDS and US06 drive cycles at 1 C and 25 {\\deg}Celsius. It was\nfound that TCN architecture achieved an accuracy of 99.1%.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 11:27:15 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Herle", "Aniruddh", ""], ["Channegowda", "Janamejaya", ""], ["Prabhu", "Dinakar", ""]]}, {"id": "2011.09789", "submitter": "Shangxi Wu", "authors": "Shangxi Wu and Jitao Sang and Xian Zhao and Lizhang Chen", "title": "An Experimental Study of Semantic Continuity for Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models suffer from the problem of semantic discontinuity: small\nperturbations in the input space tend to cause semantic-level interference to\nthe model output. We argue that the semantic discontinuity results from these\ninappropriate training targets and contributes to notorious issues such as\nadversarial robustness, interpretability, etc. We first conduct data analysis\nto provide evidence of semantic discontinuity in existing deep learning models,\nand then design a simple semantic continuity constraint which theoretically\nenables models to obtain smooth gradients and learn semantic-oriented features.\nQualitative and quantitative experiments prove that semantically continuous\nmodels successfully reduce the use of non-semantic information, which further\ncontributes to the improvement in adversarial robustness, interpretability,\nmodel transfer, and machine bias.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 12:23:28 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Wu", "Shangxi", ""], ["Sang", "Jitao", ""], ["Zhao", "Xian", ""], ["Chen", "Lizhang", ""]]}, {"id": "2011.09801", "submitter": "Giulia Silveri Mss", "authors": "Giulia Silveri, Marco Merlo, Luca Restivo, Gianfranco Sinagra,\n  Agostino Accardo", "title": "Novel Classification of Ischemic Heart Disease Using Artificial Neural\n  Network", "comments": null, "journal-ref": "Computing in Cardiology 2020", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Ischemic heart disease (IHD), particularly in its chronic stable form, is a\nsubtle pathology due to its silent behavior before developing in unstable\nangina, myocardial infarction or sudden cardiac death. Machine learning\ntechniques applied to parameters extracted form heart rate variability (HRV)\nsignal seem to be a valuable support in the early diagnosis of some cardiac\ndiseases. However, so far, IHD patients were identified using Artificial Neural\nNetworks (ANNs) applied to a limited number of HRV parameters and only to very\nfew subjects. In this study, we used several linear and non-linear HRV\nparameters applied to ANNs, in order to confirm these results on a large cohort\nof 965 sample of subjects and to identify which features could discriminate IHD\npatients with high accuracy. By using principal component analysis and stepwise\nregression, we reduced the original 17 parameters to five, used as inputs, for\na series of ANNs. The highest accuracy of 82% was achieved using meanRR, LFn,\nSD1, gender and age parameters and two hidden neurons.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:00:06 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Silveri", "Giulia", ""], ["Merlo", "Marco", ""], ["Restivo", "Luca", ""], ["Sinagra", "Gianfranco", ""], ["Accardo", "Agostino", ""]]}, {"id": "2011.09811", "submitter": "Bing Liu", "authors": "Bing Liu and Chuhe Mei", "title": "Lifelong Knowledge Learning in Rule-based Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main weaknesses of current chatbots or dialogue systems is that\nthey do not learn online during conversations after they are deployed. This is\na major loss of opportunity. Clearly, each human user has a great deal of\nknowledge about the world that may be useful to others. If a chatbot can learn\nfrom their users during chatting, it will greatly expand its knowledge base and\nserve its users better. This paper proposes to build such a learning capability\nin a rule-based chatbot so that it can continuously acquire new knowledge in\nits chatting with users. This work is useful because many real-life deployed\nchatbots are rule-based.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:33:12 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Liu", "Bing", ""], ["Mei", "Chuhe", ""]]}, {"id": "2011.09820", "submitter": "Yu Zhang", "authors": "Zhixiong Yue, Baijiong Lin, Xiaonan Huang, Yu Zhang", "title": "Effective, Efficient and Robust Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in adversarial attacks show the vulnerability of deep neural\nnetworks searched by Neural Architecture Search (NAS). Although NAS methods can\nfind network architectures with the state-of-the-art performance, the\nadversarial robustness and resource constraint are often ignored in NAS. To\nsolve this problem, we propose an Effective, Efficient, and Robust Neural\nArchitecture Search (E2RNAS) method to search a neural network architecture by\ntaking the performance, robustness, and resource constraint into consideration.\nThe objective function of the proposed E2RNAS method is formulated as a\nbi-level multi-objective optimization problem with the upper-level problem as a\nmulti-objective optimization problem, which is different from existing NAS\nmethods. To solve the proposed objective function, we integrate the\nmultiple-gradient descent algorithm, a widely studied gradient-based\nmulti-objective optimization algorithm, with the bi-level optimization.\nExperiments on benchmark datasets show that the proposed E2RNAS method can find\nadversarially robust architectures with optimized model size and comparable\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:46:23 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Yue", "Zhixiong", ""], ["Lin", "Baijiong", ""], ["Huang", "Xiaonan", ""], ["Zhang", "Yu", ""]]}, {"id": "2011.09824", "submitter": "Yu Zhang", "authors": "Pengxin Guo, Yuancheng Xu, Baijiong Lin, Yu Zhang", "title": "Multi-Task Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive performance in various areas,\nbut they are shown to be vulnerable to adversarial attacks. Previous works on\nadversarial attacks mainly focused on the single-task setting. However, in real\napplications, it is often desirable to attack several models for different\ntasks simultaneously. To this end, we propose Multi-Task adversarial Attack\n(MTA), a unified framework that can craft adversarial examples for multiple\ntasks efficiently by leveraging shared knowledge among tasks, which helps\nenable large-scale applications of adversarial attacks on real-world systems.\nMore specifically, MTA uses a generator for adversarial perturbations which\nconsists of a shared encoder for all tasks and multiple task-specific decoders.\nThanks to the shared encoder, MTA reduces the storage cost and speeds up the\ninference when attacking multiple tasks simultaneously. Moreover, the proposed\nframework can be used to generate per-instance and universal perturbations for\ntargeted and non-targeted attacks. Experimental results on the Office-31 and\nNYUv2 datasets demonstrate that MTA can improve the quality of attacks when\ncompared with its single-task counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:56:58 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Guo", "Pengxin", ""], ["Xu", "Yuancheng", ""], ["Lin", "Baijiong", ""], ["Zhang", "Yu", ""]]}, {"id": "2011.09833", "submitter": "Sowmya Chandrasekaran", "authors": "Sowmya Chandrasekaran, Margarita Rebolledo, Thomas Bartz-Beielstein", "title": "EventDetectR -- An Open-Source Event Detection System", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  EventDetectR: An efficient Event Detection System (EDS) capable of detecting\nunexpected water quality conditions. This approach uses multiple algorithms to\nmodel the relationship between various multivariate water quality signals. Then\nthe residuals of the models were utilized in constructing the event detection\nalgorithm, which provides a continuous measure of the probability of an event\nat every time step. The proposed framework was tested for water contamination\nevents with industrial data from automated water quality sensors. The results\nshowed that the framework is reliable with better performance and is highly\nsuitable for event detection.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 11:26:17 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Chandrasekaran", "Sowmya", ""], ["Rebolledo", "Margarita", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2011.09839", "submitter": "Rajesh Ramachandran", "authors": "Rishabh Verma, R Rajesh and MS Easwaran", "title": "Modular Multi Target Tracking Using LSTM Networks", "comments": "Submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The process of association and tracking of sensor detections is a key element\nin providing situational awareness. When the targets in the scenario are dense\nand exhibit high maneuverability, Multi-Target Tracking (MTT) becomes a\nchallenging task. The conventional techniques to solve such NP-hard\ncombinatorial optimization problem involves multiple complex models and\nrequires tedious tuning of parameters, failing to provide an acceptable\nperformance within the computational constraints. This paper proposes a model\nfree end-to-end approach for airborne target tracking system using sensor\nmeasurements, integrating all the key elements of multi target tracking --\nassociation, prediction and filtering using deep learning with memory. The\nchallenging task of association is performed using the Bi-Directional Long\nshort-term memory (LSTM) whereas filtering and prediction are done using LSTM\nmodels. The proposed modular blocks can be independently trained and used in\nmultitude of tracking applications including non co-operative (e.g., radar) and\nco-operative sensors (e.g., AIS, IFF, ADS-B). Such modular blocks also enhances\nthe interpretability of the deep learning application. It is shown that\nperformance of the proposed technique outperforms conventional state of the art\ntechnique Joint Probabilistic Data Association with Interacting Multiple Model\n(JPDA-IMM) filter.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:58:49 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Verma", "Rishabh", ""], ["Rajesh", "R", ""], ["Easwaran", "MS", ""]]}, {"id": "2011.09841", "submitter": "Chen Lu", "authors": "Chen Lu, Subhabrata Sen", "title": "Contextual Stochastic Block Model: Sharp Thresholds and Contiguity", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study community detection in the contextual stochastic block model\narXiv:1807.09596 [cs.SI], arXiv:1607.02675 [stat.ME]. In arXiv:1807.09596\n[cs.SI], the second author studied this problem in the setting of sparse graphs\nwith high-dimensional node-covariates. Using the non-rigorous cavity method\nfrom statistical physics, they conjectured the sharp limits for community\ndetection in this setting. Further, the information theoretic threshold was\nverified, assuming that the average degree of the observed graph is large. It\nis expected that the conjecture holds as soon as the average degree exceeds\none, so that the graph has a giant component. We establish this conjecture, and\ncharacterize the sharp threshold for detection and weak recovery.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 16:14:14 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lu", "Chen", ""], ["Sen", "Subhabrata", ""]]}, {"id": "2011.09843", "submitter": "Seshadhri Srinivasan", "authors": "S. Sairam, Seshadhri Srinivasan, G. Marafioti, B. Subathra, G.\n  Mathisen, and Korkut Bekiroglu", "title": "Explainable Incipient Fault Detection Systems for Photovoltaic Panels", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an eXplainable Fault Detection and Diagnosis System\n(XFDDS) for incipient faults in PV panels. The XFDDS is a hybrid approach that\ncombines the model-based and data-driven framework. Model-based FDD for PV\npanels lacks high fidelity models at low irradiance conditions for detecting\nincipient faults. To overcome this, a novel irradiance based three diode model\n(IB3DM) is proposed. It is a nine parameter model that provides higher accuracy\neven at low irradiance conditions, an important aspect for detecting incipient\nfaults from noise. To exploit PV data, extreme gradient boosting (XGBoost) is\nused due to its ability to detecting incipient faults. Lack of explainability,\nfeature variability for sample instances, and false alarms are challenges with\ndata-driven FDD methods. These shortcomings are overcome by hybridization of\nXGBoost and IB3DM, and using eXplainable Artificial Intelligence (XAI)\ntechniques. To combine the XGBoost and IB3DM, a fault-signature metric is\nproposed that helps reducing false alarms and also trigger an explanation on\ndetecting incipient faults. To provide explainability, an eXplainable\nArtificial Intelligence (XAI) application is developed. It uses the local\ninterpretable model-agnostic explanations (LIME) framework and provides\nexplanations on classifier outputs for data instances. These explanations help\nfield engineers/technicians for performing troubleshooting and maintenance\noperations. The proposed XFDDS is illustrated using experiments on different PV\ntechnologies and our results demonstrate the perceived benefits.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 14:26:29 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sairam", "S.", ""], ["Srinivasan", "Seshadhri", ""], ["Marafioti", "G.", ""], ["Subathra", "B.", ""], ["Mathisen", "G.", ""], ["Bekiroglu", "Korkut", ""]]}, {"id": "2011.09846", "submitter": "Ben Saunders", "authors": "Ben Saunders, Necati Cihan Camgoz, Richard Bowden", "title": "Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign\n  Language Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be truly understandable and accepted by Deaf communities, an automatic\nSign Language Production (SLP) system must generate a photo-realistic signer.\nPrior approaches based on graphical avatars have proven unpopular, whereas\nrecent neural SLP works that produce skeleton pose sequences have been shown to\nbe not understandable to Deaf viewers.\n  In this paper, we propose SignGAN, the first SLP model to produce\nphoto-realistic continuous sign language videos directly from spoken language.\nWe employ a transformer architecture with a Mixture Density Network (MDN)\nformulation to handle the translation from spoken language to skeletal pose. A\npose-conditioned human synthesis model is then introduced to generate a\nphoto-realistic sign language video from the skeletal pose sequence. This\nallows the photo-realistic production of sign videos directly translated from\nwritten text.\n  We further propose a novel keypoint-based loss function, which significantly\nimproves the quality of synthesized hand images, operating in the keypoint\nspace to avoid issues caused by motion blur. In addition, we introduce a method\nfor controllable video generation, enabling training on large, diverse sign\nlanguage datasets and providing the ability to control the signer appearance at\ninference.\n  Using a dataset of eight different sign language interpreters extracted from\nbroadcast footage, we show that SignGAN significantly outperforms all baseline\nmethods for quantitative metrics and human perceptual studies.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 14:31:06 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 10:16:24 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2020 13:31:28 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 19:00:34 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Saunders", "Ben", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2011.09848", "submitter": "Pablo Moreno-Munoz", "authors": "Pablo Moreno-Mu\\~noz, Lorena Romero-Medrano, \\'Angela Moreno, Jes\\'us\n  Herrera-L\\'opez, Enrique Baca-Garc\\'ia and Antonio Art\\'es-Rodr\\'iguez", "title": "Passive detection of behavioral shifts for suicide attempt prevention", "comments": "Machine Learning for Mobile Health Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  More than one million people commit suicide every year worldwide. The costs\nof daily cares, social stigma and treatment issues are still hard barriers to\novercome in mental health. Most symptoms of mental disorders are related to the\nbehavioral state of a patient, such as the mobility or social activity.\nMobile-based technologies allow the passive collection of patients data, which\nsupplements conventional assessments that rely on biased questionnaires and\noccasional medical appointments. In this work, we present a non-invasive\nmachine learning (ML) model to detect behavioral shifts in psychiatric patients\nfrom unobtrusive data collected by a smartphone app. Our clinically validated\nresults shed light on the idea of an early detection mobile tool for the task\nof suicide attempt prevention.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 11:44:43 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Romero-Medrano", "Lorena", ""], ["Moreno", "\u00c1ngela", ""], ["Herrera-L\u00f3pez", "Jes\u00fas", ""], ["Baca-Garc\u00eda", "Enrique", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "2011.09849", "submitter": "Ihab Mohammed", "authors": "Ihab Mohammed, Shadha Tabatabai, Ala Al-Fuqaha, Faissal El Bouanani,\n  Junaid Qadir, Basheer Qolomany, Mohsen Guizani", "title": "Budgeted Online Selection of Candidate IoT Clients to Participate in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML), and Deep Learning (DL) in particular, play a vital\nrole in providing smart services to the industry. These techniques however\nsuffer from privacy and security concerns since data is collected from clients\nand then stored and processed at a central location. Federated Learning (FL),\nan architecture in which model parameters are exchanged instead of client data,\nhas been proposed as a solution to these concerns. Nevertheless, FL trains a\nglobal model by communicating with clients over communication rounds, which\nintroduces more traffic on the network and increases the convergence time to\nthe target accuracy. In this work, we solve the problem of optimizing accuracy\nin stateful FL with a budgeted number of candidate clients by selecting the\nbest candidate clients in terms of test accuracy to participate in the training\nprocess. Next, we propose an online stateful FL heuristic to find the best\ncandidate clients. Additionally, we propose an IoT client alarm application\nthat utilizes the proposed heuristic in training a stateful FL global model\nbased on IoT device type classification to alert clients about unauthorized IoT\ndevices in their environment. To test the efficiency of the proposed online\nheuristic, we conduct several experiments using a real dataset and compare the\nresults against state-of-the-art algorithms. Our results indicate that the\nproposed heuristic outperforms the online random algorithm with up to 27% gain\nin accuracy. Additionally, the performance of the proposed online heuristic is\ncomparable to the performance of the best offline algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 06:32:31 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Mohammed", "Ihab", ""], ["Tabatabai", "Shadha", ""], ["Al-Fuqaha", "Ala", ""], ["Bouanani", "Faissal El", ""], ["Qadir", "Junaid", ""], ["Qolomany", "Basheer", ""], ["Guizani", "Mohsen", ""]]}, {"id": "2011.09852", "submitter": "Yusuke Sekikawa", "authors": "Yusuke Sekikawa, Teppei Suzuki", "title": "Irregularly Tabulated MLP for Fast Point Feature Embedding", "comments": "arXiv admin note: substantial text overlap with arXiv:1912.00790", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aiming at drastic speedup for point-feature embeddings at test time, we\npropose a new framework that uses a pair of multi-layer perceptrons (MLP) and a\nlookup table (LUT) to transform point-coordinate inputs into high-dimensional\nfeatures. When compared with PointNet's feature embedding part realized by MLP\nthat requires millions of dot products, the proposed framework at test time\nrequires no such layers of matrix-vector products but requires only looking up\nthe nearest entities from the tabulated MLP followed by interpolation, defined\nover discrete inputs on a 3D lattice that is substantially arranged\nirregularly. We call this framework LUTI-MLP: LUT Interpolation ML that\nprovides a way to train end-to-end irregularly tabulated MLP coupled to a LUT\nin a specific manner without the need for any approximation at test time.\nLUTI-MLP also provides significant speedup for Jacobian computation of the\nembedding function wrt global pose coordinate on Lie algebra $\\mathfrak{se}(3)$\nat test time, which could be used for point-set registration problems. After\nextensive evaluation using the ModelNet40, we confirmed that the LUTI-MLP even\nwith a small (e.g., $4^3$) lattice yields performance comparable to that of the\nMLP while achieving significant speedup: $100\\times$ for the embedding,\n$12\\times$ for the approximate Jacobian, and $860\\times$ for the canonical\nJacobian.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 04:15:57 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sekikawa", "Yusuke", ""], ["Suzuki", "Teppei", ""]]}, {"id": "2011.09853", "submitter": "Hamed Majidifard", "authors": "Hamed Majidifard, Behnam Jahangiri, Punyaslok Rath, Amir H. Alavi,\n  William G. Buttlar", "title": "A Deep Learning Approach to Predict Hamburg Rutting Curve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rutting continues to be one of the principal distresses in asphalt pavements\nworldwide. This type of distress is caused by permanent deformation and shear\nfailure of the asphalt mix under the repetition of heavy loads. The Hamburg\nwheel tracking test (HWTT) is a widely used testing procedure designed to\naccelerate, and to simulate the rutting phenomena in the laboratory. Rut depth,\nas one of the outputs of the HWTT, is dependent on a number of parameters\nrelated to mix design and testing conditions. This study introduces a new model\nfor predicting the rutting depth of asphalt mixtures using a deep learning\ntechnique - the convolution neural network (CNN). A database containing a\ncomprehensive collection of HWTT results was used to develop a CNN-based\nmachine learning prediction model. The database includes 10,000 rutting depth\ndata points measured across a large variety of asphalt mixtures. The model has\nbeen formulated in terms of known influencing mixture variables such as asphalt\nbinder high temperature performance grade, mixture type, aggregate size,\naggregate gradation, asphalt content, total asphalt binder recycling content,\nand testing parameters, including testing temperature and number of wheel\npasses. A rigorous validation process was used to assess the accuracy of the\nmodel to predict total rut depth and the HWTT rutting curve. A sensitivity\nanalysis is presented, which evaluates the effect of the investigated variables\non rutting depth predictions by the CNN model. The model can be used as a tool\nto estimate the rut depth in asphalt mixtures when laboratory testing is not\nfeasible, or for cost saving, pre-design trials.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 22:10:54 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Majidifard", "Hamed", ""], ["Jahangiri", "Behnam", ""], ["Rath", "Punyaslok", ""], ["Alavi", "Amir H.", ""], ["Buttlar", "William G.", ""]]}, {"id": "2011.09854", "submitter": "Sirui Xie", "authors": "Sirui Xie and Feng Gao and Song-Chun Zhu", "title": "Generalized Inverse Planning: Learning Lifted non-Markovian Utility for\n  Generalizable Task Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In searching for a generalizable representation of temporally extended tasks,\nwe spot two necessary constituents: the utility needs to be non-Markovian to\ntransfer temporal relations invariant to a probability shift, the utility also\nneeds to be lifted to abstract out specific grounding objects. In this work, we\nstudy learning such utility from human demonstrations. While inverse\nreinforcement learning (IRL) has been accepted as a general framework of\nutility learning, its fundamental formulation is one concrete Markov Decision\nProcess. Thus the learned reward function does not specify the task\nindependently of the environment. Going beyond that, we define a domain of\ngeneralization that spans a set of planning problems following a schema. We\nhence propose a new quest, Generalized Inverse Planning, for utility learning\nin this domain. We further outline a computational framework, Maximum Entropy\nInverse Planning (MEIP), that learns non-Markovian utility and associated\nconcepts in a generative manner. The learned utility and concepts form a task\nrepresentation that generalizes regardless of probability shift or structural\nchange. Seeing that the proposed generalization problem has not been widely\nstudied yet, we carefully define an evaluation protocol, with which we\nillustrate the effectiveness of MEIP on two proof-of-concept domains and one\nchallenging task: learning to fold from demonstrations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 21:06:26 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Xie", "Sirui", ""], ["Gao", "Feng", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2011.09857", "submitter": "Muhammed Maruf \\\"Ozt\\\"urk MMozturk", "authors": "M.M. Ozturk", "title": "On tuning deep learning models: a data mining perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms vary depending on the underlying connection\nmechanism of nodes of them. They have various hyperparameters that are either\nset via specific algorithms or randomly chosen. Meanwhile, hyperparameters of\ndeep learning algorithms have the potential to help enhance the performance of\nthe machine learning tasks. In this paper, a tuning guideline is provided for\nresearchers who cope with issues originated from hyperparameters of deep\nlearning models. To that end, four types of deep learning algorithms are\ninvestigated in terms of tuning and data mining perspective. Further, common\nsearch methods of hyperparameters are evaluated on four deep learning\nalgorithms. Normalization helps increase the performance of classification,\naccording to the results of this study. The number of features has not\ncontributed to the decline in the accuracy of deep learning algorithms. Even\nthough high sparsity results in low accuracy, a uniform distribution is much\nmore crucial to reach reliable results in terms of data mining.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 14:40:42 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Ozturk", "M. M.", ""]]}, {"id": "2011.09860", "submitter": "Victor Kolev", "authors": "Victor Kolev, Bogdan Georgiev, Svetlin Penkov", "title": "Neural Abstract Reasoner", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract reasoning and logic inference are difficult problems for neural\nnetworks, yet essential to their applicability in highly structured domains. In\nthis work we demonstrate that a well known technique such as spectral\nregularization can significantly boost the capabilities of a neural learner. We\nintroduce the Neural Abstract Reasoner (NAR), a memory augmented architecture\ncapable of learning and using abstract rules. We show that, when trained with\nspectral regularization, NAR achieves $78.8\\%$ accuracy on the Abstraction and\nReasoning Corpus, improving performance 4 times over the best known human\nhand-crafted symbolic solvers. We provide some intuition for the effects of\nspectral regularization in the domain of abstract reasoning based on\ntheoretical generalization bounds and Solomonoff's theory of inductive\ninference.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 20:30:33 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Kolev", "Victor", ""], ["Georgiev", "Bogdan", ""], ["Penkov", "Svetlin", ""]]}, {"id": "2011.09865", "submitter": "Ramon Vilarino", "authors": "Ramon Vilarino, Renato Vicente", "title": "Dissecting Racial Bias in a Credit Scoring System Experimentally\n  Developed for the Brazilian Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We dissect an experimental credit scoring model developed with real data and\ndemonstrate -- without having access to protected attributes -- how the use of\nlocation information introduces racial bias. We analyze the tree gradient\nboosting model with the aid of a game-theoretic ML explainability technique,\ncounterfactual experiments and Brazilian census data. The present experiment\ntestifies to the importance of developing methods and language that goes beyond\nthe need of access to protected attributes when auditing ML models, the\nnecessity of considering regional specifics when reflecting on racial issues,\nand the importance of census data to the AI research community. To the best of\nour knowledge, this is the first documented case of how algorithmic racial bias\nmay easily emerge in a ML credit scoring model built with Brazilian data, a\ncountry with the largest Black population outside Africa.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 02:14:32 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:56:09 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Vilarino", "Ramon", ""], ["Vicente", "Renato", ""]]}, {"id": "2011.09866", "submitter": "Vanja Dosko\\v{c}", "authors": "Julian Berger, Maximilian B\\\"other, Vanja Dosko\\v{c}, Jonathan Gadea\n  Harder, Nicolas Klodt, Timo K\\\"otzing, Winfried L\\\"otzsch, Jannik Peters,\n  Leon Schiller, Lars Seifert, Armin Wells, Simon Wietheger", "title": "Learning Languages with Decidable Hypotheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In language learning in the limit, the most common type of hypothesis is to\ngive an enumerator for a language. This so-called $W$-index allows for naming\narbitrary computably enumerable languages, with the drawback that even the\nmembership problem is undecidable. In this paper we use a different system\nwhich allows for naming arbitrary decidable languages, namely programs for\ncharacteristic functions (called $C$-indices). These indices have the drawback\nthat it is now not decidable whether a given hypothesis is even a legal\n$C$-index.\n  In this first analysis of learning with $C$-indices, we give a structured\naccount of the learning power of various restrictions employing $C$-indices,\nalso when compared with $W$-indices. We establish a hierarchy of learning power\ndepending on whether $C$-indices are required (a) on all outputs; (b) only on\noutputs relevant for the class to be learned and (c) only in the limit as\nfinal, correct hypotheses. Furthermore, all these settings are weaker than\nlearning with $W$-indices (even when restricted to classes of computable\nlanguages). We analyze all these questions also in relation to the mode of data\npresentation.\n  Finally, we also ask about the relation of semantic versus syntactic\nconvergence and derive the map of pairwise relations for these two kinds of\nconvergence coupled with various forms of data presentation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Oct 2020 09:27:47 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Berger", "Julian", ""], ["B\u00f6ther", "Maximilian", ""], ["Dosko\u010d", "Vanja", ""], ["Harder", "Jonathan Gadea", ""], ["Klodt", "Nicolas", ""], ["K\u00f6tzing", "Timo", ""], ["L\u00f6tzsch", "Winfried", ""], ["Peters", "Jannik", ""], ["Schiller", "Leon", ""], ["Seifert", "Lars", ""], ["Wells", "Armin", ""], ["Wietheger", "Simon", ""]]}, {"id": "2011.09867", "submitter": "Hanshuang Tong", "authors": "Hanshuang Tong, Yun Zhou and Zhen Wang", "title": "Exercise Hierarchical Feature Enhanced Knowledge Tracing", "comments": "5 pages, 4 figures, Accepted by AIED 2020. In the 21st International\n  Conference on Artificial Intelligence in Education (AIED 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-52240-7_59", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing is a fundamental task in the computer-aid educational\nsystem. In this paper, we propose a hierarchical exercise feature enhanced\nknowledge tracing framework, which could enhance the ability of knowledge\ntracing by incorporating knowledge distribution, semantic features, and\ndifficulty features from exercise text. Extensive experiments show the high\nperformance of our framework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:16:07 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Tong", "Hanshuang", ""], ["Zhou", "Yun", ""], ["Wang", "Zhen", ""]]}, {"id": "2011.09884", "submitter": "Qing Guo", "authors": "Bing Yu and Hua Qi and Qing Guo and Felix Juefei-Xu and Xiaofei Xie\n  and Lei Ma and Jianjun Zhao", "title": "DeepRepair: Style-Guided Repairing for DNNs in the Real-world\n  Operational Environment", "comments": "14 pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are being widely applied for various real-world\napplications across domains due to their high performance (e.g., high accuracy\non image classification). Nevertheless, a well-trained DNN after deployment\ncould oftentimes raise errors during practical use in the operational\nenvironment due to the mismatching between distributions of the training\ndataset and the potential unknown noise factors in the operational environment,\ne.g., weather, blur, noise etc. Hence, it poses a rather important problem for\nthe DNNs' real-world applications: how to repair the deployed DNNs for\ncorrecting the failure samples (i.e., incorrect prediction) under the deployed\noperational environment while not harming their capability of handling normal\nor clean data. The number of failure samples we can collect in practice, caused\nby the noise factors in the operational environment, is often limited.\nTherefore, It is rather challenging how to repair more similar failures based\non the limited failure samples we can collect.\n  In this paper, we propose a style-guided data augmentation for repairing DNN\nin the operational environment. We propose a style transfer method to learn and\nintroduce the unknown failure patterns within the failure data into the\ntraining data via data augmentation. Moreover, we further propose the\nclustering-based failure data generation for much more effective style-guided\ndata augmentation. We conduct a large-scale evaluation with fifteen degradation\nfactors that may happen in the real world and compare with four\nstate-of-the-art data augmentation methods and two DNN repairing methods,\ndemonstrating that our method can significantly enhance the deployed DNNs on\nthe corrupted data in the operational environment, and with even better\naccuracy on clean datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 15:09:44 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Yu", "Bing", ""], ["Qi", "Hua", ""], ["Guo", "Qing", ""], ["Juefei-Xu", "Felix", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Zhao", "Jianjun", ""]]}, {"id": "2011.09887", "submitter": "Utkarsh Nath", "authors": "Utkarsh Nath, Shikha Asrani, Rahul Katarya", "title": "Similarity-based Distance for Categorical Clustering using Space\n  Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Clustering is spotting pattern in a group of objects and resultantly grouping\nthe similar objects together. Objects have attributes which are not always\nnumerical, sometimes attributes have domain or categories to which they could\nbelong to. Such data is called categorical data. To group categorical data many\nclustering algorithms are used, among which k- modes algorithm has so far given\nthe most significant results. Nevertheless, there is still a lot which could be\nimproved. Algorithms like k-means, fuzzy-c-means or hierarchical have given far\nbetter accuracies with numerical data. In this paper, we have proposed a novel\ndistance metric, similarity-based distance (SBD) to find the distance between\nobjects of categorical data. Experiments have shown that our proposed distance\n(SBD), when used with the SBC (space structure based clustering) type algorithm\nsignificantly outperforms the existing algorithms like k-modes or other SBC\ntype algorithms when used on categorical datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 15:18:26 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Nath", "Utkarsh", ""], ["Asrani", "Shikha", ""], ["Katarya", "Rahul", ""]]}, {"id": "2011.09892", "submitter": "Shideh Shams Amiri", "authors": "Shideh Shams Amiri, Rosina O. Weber, Prateek Goel, Owen Brooks, Archer\n  Gandley, Brian Kitchell, Aaron Zehm", "title": "Data Representing Ground-Truth Explanations to Evaluate XAI Methods", "comments": "Submitted to the AAAI 2021 Explainable Agency in Artificial\n  Intelligence Workshop, 6 pages, 3 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable artificial intelligence (XAI) methods are currently evaluated\nwith approaches mostly originated in interpretable machine learning (IML)\nresearch that focus on understanding models such as comparison against existing\nattribution approaches, sensitivity analyses, gold set of features, axioms, or\nthrough demonstration of images. There are problems with these methods such as\nthat they do not indicate where current XAI approaches fail to guide\ninvestigations towards consistent progress of the field. They do not measure\naccuracy in support of accountable decisions, and it is practically impossible\nto determine whether one XAI method is better than the other or what the\nweaknesses of existing models are, leaving researchers without guidance on\nwhich research questions will advance the field. Other fields usually utilize\nground-truth data and create benchmarks. Data representing ground-truth\nexplanations is not typically used in XAI or IML. One reason is that\nexplanations are subjective, in the sense that an explanation that satisfies\none user may not satisfy another. To overcome these problems, we propose to\nrepresent explanations with canonical equations that can be used to evaluate\nthe accuracy of XAI methods. The contributions of this paper include a\nmethodology to create synthetic data representing ground-truth explanations,\nthree data sets, an evaluation of LIME using these data sets, and a preliminary\nanalysis of the challenges and potential benefits in using these data to\nevaluate existing XAI approaches. Evaluation methods based on human-centric\nstudies are outside the scope of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:54:53 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Amiri", "Shideh Shams", ""], ["Weber", "Rosina O.", ""], ["Goel", "Prateek", ""], ["Brooks", "Owen", ""], ["Gandley", "Archer", ""], ["Kitchell", "Brian", ""], ["Zehm", "Aaron", ""]]}, {"id": "2011.09899", "submitter": "Yuhang Li", "authors": "Yuhang Li, Feng Zhu, Ruihao Gong, Mingzhu Shen, Xin Dong, Fengwei Yu,\n  Shaoqing Lu, Shi Gu", "title": "MixMix: All You Need for Data-Free Compression Are Feature and Data\n  Mixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  User data confidentiality protection is becoming a rising challenge in the\npresent deep learning research. Without access to data, conventional\ndata-driven model compression faces a higher risk of performance degradation.\nRecently, some works propose to generate images from a specific pretrained\nmodel to serve as training data. However, the inversion process only utilizes\nbiased feature statistics stored in one model and is from low-dimension to\nhigh-dimension. As a consequence, it inevitably encounters the difficulties of\ngeneralizability and inexact inversion, which leads to unsatisfactory\nperformance. To address these problems, we propose MixMix based on two simple\nyet effective techniques: (1) Feature Mixing: utilizes various models to\nconstruct a universal feature space for generalized inversion; (2) Data Mixing:\nmixes the synthesized images and labels to generate exact label information. We\nprove the effectiveness of MixMix from both theoretical and empirical\nperspectives. Extensive experiments show that MixMix outperforms existing\nmethods on the mainstream compression tasks, including quantization, knowledge\ndistillation, and pruning. Specifically, MixMix achieves up to 4% and 20%\naccuracy uplift on quantization and pruning, respectively, compared to existing\ndata-free compression work.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 15:33:43 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 07:22:41 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Li", "Yuhang", ""], ["Zhu", "Feng", ""], ["Gong", "Ruihao", ""], ["Shen", "Mingzhu", ""], ["Dong", "Xin", ""], ["Yu", "Fengwei", ""], ["Lu", "Shaoqing", ""], ["Gu", "Shi", ""]]}, {"id": "2011.09900", "submitter": "Tao Huang", "authors": "Tao Huang, Yihan Zhang, Jiajing Wu, Junyuan Fang, Zibin Zheng", "title": "MG-GCN: Fast and Effective Learning with Mix-grained Aggregators for\n  Training Large Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have been employed as a kind of\nsignificant tool on many graph-based applications recently. Inspired by\nconvolutional neural networks (CNNs), GCNs generate the embeddings of nodes by\naggregating the information of their neighbors layer by layer. However, the\nhigh computational and memory cost of GCNs due to the recursive neighborhood\nexpansion across GCN layers makes it infeasible for training on large graphs.\nTo tackle this issue, several sampling methods during the process of\ninformation aggregation have been proposed to train GCNs in a mini-batch\nStochastic Gradient Descent (SGD) manner. Nevertheless, these sampling\nstrategies sometimes bring concerns about insufficient information collection,\nwhich may hinder the learning performance in terms of accuracy and convergence.\nTo tackle the dilemma between accuracy and efficiency, we propose to use\naggregators with different granularities to gather neighborhood information in\ndifferent layers. Then, a degree-based sampling strategy, which avoids the\nexponential complexity, is constructed for sampling a fixed number of nodes.\nCombining the above two mechanisms, the proposed model, named Mix-grained GCN\n(MG-GCN) achieves state-of-the-art performance in terms of accuracy, training\nspeed, convergence speed, and memory cost through a comprehensive set of\nexperiments on four commonly used benchmark datasets and a new Ethereum\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 14:51:57 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Huang", "Tao", ""], ["Zhang", "Yihan", ""], ["Wu", "Jiajing", ""], ["Fang", "Junyuan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2011.09902", "submitter": "Yunlong Lu", "authors": "Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, Yan Zhang", "title": "Low-latency Federated Learning and Blockchain for Edge Association in\n  Digital Twin empowered 6G Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TII.2020.3017668", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emerging technologies such as digital twins and 6th Generation mobile\nnetworks (6G) have accelerated the realization of edge intelligence in\nIndustrial Internet of Things (IIoT). The integration of digital twin and 6G\nbridges the physical system with digital space and enables robust instant\nwireless connectivity. With increasing concerns on data privacy, federated\nlearning has been regarded as a promising solution for deploying distributed\ndata processing and learning in wireless networks. However, unreliable\ncommunication channels, limited resources, and lack of trust among users,\nhinder the effective application of federated learning in IIoT. In this paper,\nwe introduce the Digital Twin Wireless Networks (DTWN) by incorporating digital\ntwins into wireless networks, to migrate real-time data processing and\ncomputation to the edge plane. Then, we propose a blockchain empowered\nfederated learning framework running in the DTWN for collaborative computing,\nwhich improves the reliability and security of the system, and enhances data\nprivacy. Moreover, to balance the learning accuracy and time cost of the\nproposed scheme, we formulate an optimization problem for edge association by\njointly considering digital twin association, training data batch size, and\nbandwidth allocation. We exploit multi-agent reinforcement learning to find an\noptimal solution to the problem. Numerical results on real-world dataset show\nthat the proposed scheme yields improved efficiency and reduced cost compared\nto benchmark learning method.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 04:11:31 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lu", "Yunlong", ""], ["Huang", "Xiaohong", ""], ["Zhang", "Ke", ""], ["Maharjan", "Sabita", ""], ["Zhang", "Yan", ""]]}, {"id": "2011.09903", "submitter": "Brian Liu", "authors": "Brian Liu and Madeleine Udell", "title": "Impact of Accuracy on Model Interpretations", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model interpretations are often used in practice to extract real world\ninsights from machine learning models. These interpretations have a wide range\nof applications; they can be presented as business recommendations or used to\nevaluate model bias. It is vital for a data scientist to choose trustworthy\ninterpretations to drive real world impact. Doing so requires an understanding\nof how the accuracy of a model impacts the quality of standard interpretation\ntools. In this paper, we will explore how a model's predictive accuracy affects\ninterpretation quality. We propose two metrics to quantify the quality of an\ninterpretation and design an experiment to test how these metrics vary with\nmodel accuracy. We find that for datasets that can be modeled accurately by a\nvariety of methods, simpler methods yield higher quality interpretations. We\nalso identify which interpretation method works the best for lower levels of\nmodel accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 19:02:59 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Liu", "Brian", ""], ["Udell", "Madeleine", ""]]}, {"id": "2011.09905", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Andrea Bragagnolo, Attilio Fiandrotti and Marco\n  Grangetto", "title": "LOss-Based SensiTivity rEgulaRization: towards deep sparse neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  LOBSTER (LOss-Based SensiTivity rEgulaRization) is a method for training\nneural networks having a sparse topology. Let the sensitivity of a network\nparameter be the variation of the loss function with respect to the variation\nof the parameter. Parameters with low sensitivity, i.e. having little impact on\nthe loss when perturbed, are shrunk and then pruned to sparsify the network.\nOur method allows to train a network from scratch, i.e. without preliminary\nlearning or rewinding. Experiments on multiple architectures and datasets show\ncompetitive compression ratios with minimal computational overhead.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 18:55:34 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Bragagnolo", "Andrea", ""], ["Fiandrotti", "Attilio", ""], ["Grangetto", "Marco", ""]]}, {"id": "2011.09906", "submitter": "Kevin Haninger", "authors": "Kevin Haninger, Raul Vicente Garcia, Joerg Krueger", "title": "Towards Learning Controllable Representations of Physical Systems", "comments": "10 pages, 8 figures, associated video at\n  https://youtu.be/adHXi58u9qw. Submitted to ICRA 2021. v2 24.Nov.2020:\n  Typographic corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned representations of dynamical systems reduce dimensionality,\npotentially supporting downstream reinforcement learning (RL). However, no\nestablished methods predict a representation's suitability for control and\nevaluation is largely done via downstream RL performance, slowing\nrepresentation design. Towards a principled evaluation of representations for\ncontrol, we consider the relationship between the true state and the\ncorresponding representations, proposing that ideally each representation\ncorresponds to a unique true state. This motivates two metrics: temporal\nsmoothness and high mutual information between true state/representation. These\nmetrics are related to established representation objectives, and studied on\nLagrangian systems where true state, information requirements, and statistical\nproperties of the state can be formalized for a broad class of systems. These\nmetrics are shown to predict reinforcement learning performance in a simulated\npeg-in-hole task when comparing variants of autoencoder-based representations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 17:15:57 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 12:03:21 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Haninger", "Kevin", ""], ["Garcia", "Raul Vicente", ""], ["Krueger", "Joerg", ""]]}, {"id": "2011.09907", "submitter": "Asan Agibetov", "authors": "Asan Agibetov", "title": "Graph embeddings via matrix factorization for link prediction: smoothing\n  or truncating negatives?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Link prediction -- the process of uncovering missing links in a complex\nnetwork -- is an important problem in information sciences, with applications\nranging from social sciences to molecular biology. Recent advances in neural\ngraph embeddings have proposed an end-to-end way of learning latent vector\nrepresentations of nodes, with successful application in link prediction tasks.\nYet, our understanding of the internal mechanisms of such approaches has been\nrather limited, and only very recently we have witnessed the development of a\nvery compelling connection to the mature matrix factorization theory. In this\nwork, we make an important contribution to our understanding of the interplay\nbetween the skip-gram powered neural graph embedding algorithms and the matrix\nfactorization via SVD. In particular, we show that the link prediction accuracy\nof graph embeddings strongly depends on the transformations of the original\ngraph co-occurrence matrix that they decompose, sometimes resulting in\nstaggering boosts of accuracy performance on link prediction tasks. Our\nimproved approach to learning low-rank factorization embeddings that\nincorporate information from unlikely pairs of nodes yields results on par with\nthe state-of-the-art link prediction performance achieved by a complex neural\ngraph embedding model\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 14:23:12 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Agibetov", "Asan", ""]]}, {"id": "2011.09911", "submitter": "Uwe Aickelin", "authors": "Hadi Akbarzadeh Khorshidi, Uwe Aickelin, Gholamreza Haffari, Behrooz\n  Hassani-Mahmooei", "title": "Multi-objective semi-supervised clustering to identify health service\n  patterns for injured patients", "comments": "Health information science and systems, Volume 7, Issue 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study develops a pattern recognition method that identifies patterns\nbased on their similarity and their association with the outcome of interest.\nThe practical purpose of developing this pattern recognition method is to group\npatients, who are injured in transport accidents, in the early stages\npost-injury. This grouping is based on distinctive patterns in health service\nuse within the first week post-injury. The groups also provide predictive\ninformation towards the total cost of medication process. As a result, the\ngroup of patients who have undesirable outcomes are identified as early as\npossible based health service use patterns.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 06:43:21 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Khorshidi", "Hadi Akbarzadeh", ""], ["Aickelin", "Uwe", ""], ["Haffari", "Gholamreza", ""], ["Hassani-Mahmooei", "Behrooz", ""]]}, {"id": "2011.09912", "submitter": "Uwe Aickelin", "authors": "Xuetong Wu, Hadi Akbarzadeh Khorshidi, Uwe Aickelin, Zobaida Edib,\n  Michelle Peate", "title": "Imputation techniques on missing values in breast cancer treatment and\n  fertility data", "comments": "Health Information Science and Systems, Volume 7, Issue 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clinical decision support using data mining techniques offers more\nintelligent way to reduce the decision error in the last few years. However,\nclinical datasets often suffer from high missingness, which adversely impacts\nthe quality of modelling if handled improperly. Imputing missing values\nprovides an opportunity to resolve the issue. Conventional imputation methods\nadopt simple statistical analysis, such as mean imputation or discarding\nmissing cases, which have many limitations and thus degrade the performance of\nlearning. This study examines a series of machine learning based imputation\nmethods and suggests an efficient approach to in preparing a good quality\nbreast cancer (BC) dataset, to find the relationship between BC treatment and\nchemotherapy-related amenorrhoea, where the performance is evaluated with the\naccuracy of the prediction.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 06:28:26 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Wu", "Xuetong", ""], ["Khorshidi", "Hadi Akbarzadeh", ""], ["Aickelin", "Uwe", ""], ["Edib", "Zobaida", ""], ["Peate", "Michelle", ""]]}, {"id": "2011.09926", "submitter": "Andrei Paleyes", "authors": "Andrei Paleyes, Raoul-Gabriel Urma, Neil D. Lawrence", "title": "Challenges in Deploying Machine Learning: a Survey of Case Studies", "comments": "The ML-Retrospectives, Surveys & Meta-Analyses Workshop, NeurIPS\n  2020; v2. updated with typo fixes and new references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has received increased interest both as an\nacademic research field and as a solution for real-world business problems.\nHowever, the deployment of machine learning models in production systems can\npresent a number of issues and concerns. This survey reviews published reports\nof deploying machine learning solutions in a variety of use cases, industries\nand applications and extracts practical considerations corresponding to stages\nof the machine learning deployment workflow. Our survey shows that\npractitioners face challenges at each stage of the deployment. The goal of this\npaper is to layout a research agenda to explore approaches addressing these\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:20:28 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 10:34:53 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Paleyes", "Andrei", ""], ["Urma", "Raoul-Gabriel", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "2011.09928", "submitter": "Haoyu Dong", "authors": "Haoyu Dong, Ze Wang, Qiang Qiu, and Guillermo Sapiro", "title": "Using Text to Teach Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image retrieval relies heavily on the quality of the data modeling and the\ndistance measurement in the feature space. Building on the concept of image\nmanifold, we first propose to represent the feature space of images, learned\nvia neural networks, as a graph. Neighborhoods in the feature space are now\ndefined by the geodesic distance between images, represented as graph vertices\nor manifold samples. When limited images are available, this manifold is\nsparsely sampled, making the geodesic computation and the corresponding\nretrieval harder. To address this, we augment the manifold samples with\ngeometrically aligned text, thereby using a plethora of sentences to teach us\nabout images. In addition to extensive results on standard datasets\nillustrating the power of text to help in image retrieval, a new public dataset\nbased on CLEVR is introduced to quantify the semantic similarity between visual\ndata and text data. The experimental results show that the joint embedding\nmanifold is a robust representation, allowing it to be a better basis to\nperform image retrieval given only an image and a textual instruction on the\ndesired modifications over the image\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 16:09:14 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Dong", "Haoyu", ""], ["Wang", "Ze", ""], ["Qiu", "Qiang", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "2011.09933", "submitter": "Dario Guidotti", "authors": "Dario Guidotti, Luca Pulina, Armando Tacchella", "title": "NeVer 2.0: Learning, Verification and Repair of Deep Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:2003.07636", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an early prototype of NeVer 2.0, a new system for\nautomated synthesis and analysis of deep neural networks.NeVer 2.0borrows its\ndesign philosophy from NeVer, the first package that integrated learning,\nautomated verification and repair of (shallow) neural networks in a single\ntool. The goal of NeVer 2.0 is to provide a similar integration for deep\nnetworks by leveraging a selection of state-of-the-art learning frameworks and\nintegrating them with verification algorithms to ease the scalability challenge\nand make repair of faulty networks possible.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 14:37:33 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Guidotti", "Dario", ""], ["Pulina", "Luca", ""], ["Tacchella", "Armando", ""]]}, {"id": "2011.09941", "submitter": "Lingxi Xie", "authors": "Xinyue Huo, Lingxi Xie, Longhui Wei, Xiaopeng Zhang, Hao Li, Zijie\n  Yang, Wengang Zhou, Houqiang Li, Qi Tian", "title": "Heterogeneous Contrastive Learning: Encoding Spatial Information for\n  Compact Visual Representations", "comments": "10 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning has achieved great success in self-supervised visual\nrepresentation learning, but existing approaches mostly ignored spatial\ninformation which is often crucial for visual representation. This paper\npresents heterogeneous contrastive learning (HCL), an effective approach that\nadds spatial information to the encoding stage to alleviate the learning\ninconsistency between the contrastive objective and strong data augmentation\noperations. We demonstrate the effectiveness of HCL by showing that (i) it\nachieves higher accuracy in instance discrimination and (ii) it surpasses\nexisting pre-training methods in a series of downstream tasks while shrinking\nthe pre-training costs by half. More importantly, we show that our approach\nachieves higher efficiency in visual representations, and thus delivers a key\nmessage to inspire the future research of self-supervised visual representation\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 16:26:25 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Huo", "Xinyue", ""], ["Xie", "Lingxi", ""], ["Wei", "Longhui", ""], ["Zhang", "Xiaopeng", ""], ["Li", "Hao", ""], ["Yang", "Zijie", ""], ["Zhou", "Wengang", ""], ["Li", "Houqiang", ""], ["Tian", "Qi", ""]]}, {"id": "2011.09954", "submitter": "Hui Chen", "authors": "Hui Chen, Deepanway Ghosal, Navonil Majumder, Amir Hussain, Soujanya\n  Poria", "title": "Persuasive Dialogue Understanding: the Baselines and Negative Results", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persuasion aims at forming one's opinion and action via a series of\npersuasive messages containing persuader's strategies. Due to its potential\napplication in persuasive dialogue systems, the task of persuasive strategy\nrecognition has gained much attention lately. Previous methods on user intent\nrecognition in dialogue systems adopt recurrent neural network (RNN) or\nconvolutional neural network (CNN) to model context in conversational history,\nneglecting the tactic history and intra-speaker relation. In this paper, we\ndemonstrate the limitations of a Transformer-based approach coupled with\nConditional Random Field (CRF) for the task of persuasive strategy recognition.\nIn this model, we leverage inter- and intra-speaker contextual semantic\nfeatures, as well as label dependencies to improve the recognition. Despite\nextensive hyper-parameter optimizations, this architecture fails to outperform\nthe baseline methods. We observe two negative results. Firstly, CRF cannot\ncapture persuasive label dependencies, possibly as strategies in persuasive\ndialogues do not follow any strict grammar or rules as the cases in Named\nEntity Recognition (NER) or part-of-speech (POS) tagging. Secondly, the\nTransformer encoder trained from scratch is less capable of capturing\nsequential information in persuasive dialogues than Long Short-Term Memory\n(LSTM). We attribute this to the reason that the vanilla Transformer encoder\ndoes not efficiently consider relative position information of sequence\nelements.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 16:52:43 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 18:27:51 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Hui", ""], ["Ghosal", "Deepanway", ""], ["Majumder", "Navonil", ""], ["Hussain", "Amir", ""], ["Poria", "Soujanya", ""]]}, {"id": "2011.09964", "submitter": "Yukun Yang", "authors": "Yukun Yang", "title": "Temporal Surrogate Back-propagation for Spiking Neural Networks", "comments": "4 pases, 3 figures, 3 tables, 10 eqs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Spiking neural networks (SNN) are usually more energy-efficient as compared\nto Artificial neural networks (ANN), and the way they work has a great\nsimilarity with our brain. Back-propagation (BP) has shown its strong power in\ntraining ANN in recent years. However, since spike behavior is\nnon-differentiable, BP cannot be applied to SNN directly. Although prior works\ndemonstrated several ways to approximate the BP-gradient in both spatial and\ntemporal directions either through surrogate gradient or randomness, they\nomitted the temporal dependency introduced by the reset mechanism between each\nstep. In this article, we target on theoretical completion and investigate the\neffect of the missing term thoroughly. By adding the temporal dependency of the\nreset mechanism, the new algorithm is more robust to learning-rate adjustments\non a toy dataset but does not show much improvement on larger learning tasks\nlike CIFAR-10. Empirically speaking, the benefits of the missing term are not\nworth the additional computational overhead. In many cases, the missing term\ncan be ignored.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 08:22:47 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Yang", "Yukun", ""]]}, {"id": "2011.09969", "submitter": "Huihui Wang", "authors": "Huihui Wang, Ruyang Mo", "title": "Neural network algorithm and its application in reactive distillation", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive distillation is a special distillation technology based on the\ncoupling of chemical reaction and distillation. It has the characteristics of\nlow energy consumption and high separation efficiency. However, because the\ncombination of reaction and separation produces highly nonlinear robust\nbehavior, the control and optimization of the reactive distillation process\ncannot use conventional methods, but must rely on neural network algorithms.\nThis paper briefly describes the characteristics and research progress of\nreactive distillation technology and neural network algorithms, and summarizes\nthe application of neural network algorithms in reactive distillation, aiming\nto provide reference for the development and innovation of industry technology.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 02:18:52 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Wang", "Huihui", ""], ["Mo", "Ruyang", ""]]}, {"id": "2011.09973", "submitter": "Kevin Tian", "authors": "Ilias Diakonikolas, Daniel M. Kane, Daniel Kongsgaard, Jerry Li, Kevin\n  Tian", "title": "List-Decodable Mean Estimation in Nearly-PCA Time", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, robust statistics has focused on designing estimators tolerant\nto a minority of contaminated data. Robust list-decodable learning focuses on\nthe more challenging regime where only a minority $\\frac 1 k$ fraction of the\ndataset is drawn from the distribution of interest, and no assumptions are made\non the remaining data. We study the fundamental task of list-decodable mean\nestimation in high dimensions. Our main result is a new list-decodable mean\nestimation algorithm for bounded covariance distributions with optimal sample\ncomplexity and error rate, running in nearly-PCA time. Assuming the ground\ntruth distribution on $\\mathbb{R}^d$ has bounded covariance, our algorithm\noutputs a list of $O(k)$ candidate means, one of which is within distance\n$O(\\sqrt{k})$ from the truth. Our algorithm runs in time $\\widetilde{O}(ndk)$\nfor all $k = O(\\sqrt{d}) \\cup \\Omega(d)$, where $n$ is the size of the dataset.\nWe also show that a variant of our algorithm has runtime $\\widetilde{O}(ndk)$\nfor all $k$, at the expense of an $O(\\sqrt{\\log k})$ factor in the recovery\nguarantee. This runtime matches up to logarithmic factors the cost of\nperforming a single $k$-PCA on the data, which is a natural bottleneck of known\nalgorithms for (very) special cases of our problem, such as clustering\nwell-separated mixtures. Prior to our work, the fastest list-decodable mean\nestimation algorithms had runtimes $\\widetilde{O}(n^2 d k^2)$ and\n$\\widetilde{O}(nd k^{\\ge 6})$.\n  Our approach builds on a novel soft downweighting method, $\\mathsf{SIFT}$,\nwhich is arguably the simplest known polynomial-time mean estimation technique\nin the list-decodable learning setting. To develop our fast algorithms, we\nboost the computational cost of $\\mathsf{SIFT}$ via a careful \"win-win-win\"\nanalysis of an approximate Ky Fan matrix multiplicative weights procedure we\ndevelop, which we believe may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:21:37 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Kongsgaard", "Daniel", ""], ["Li", "Jerry", ""], ["Tian", "Kevin", ""]]}, {"id": "2011.09986", "submitter": "Raj Kumar Maity", "authors": "Raj Kumar Maity and Cameron Musco", "title": "Estimation of Shortest Path Covariance Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the sample complexity of estimating the covariance matrix\n$\\mathbf{\\Sigma} \\in \\mathbb{R}^{d\\times d}$ of a distribution $\\mathcal D$\nover $\\mathbb{R}^d$ given independent samples, under the assumption that\n$\\mathbf{\\Sigma}$ is graph-structured. In particular, we focus on shortest path\ncovariance matrices, where the covariance between any two measurements is\ndetermined by the shortest path distance in an underlying graph with $d$ nodes.\nSuch matrices generalize Toeplitz and circulant covariance matrices and are\nwidely applied in signal processing applications, where the covariance between\ntwo measurements depends on the (shortest path) distance between them in time\nor space.\n  We focus on minimizing both the vector sample complexity: the number of\nsamples drawn from $\\mathcal{D}$ and the entry sample complexity: the number of\nentries read in each sample. The entry sample complexity corresponds to\nmeasurement equipment costs in signal processing applications. We give a very\nsimple algorithm for estimating $\\mathbf{\\Sigma}$ up to spectral norm error\n$\\epsilon \\left\\|\\mathbf{\\Sigma}\\right\\|_2$ using just $O(\\sqrt{D})$ entry\nsample complexity and $\\tilde O(r^2/\\epsilon^2)$ vector sample complexity,\nwhere $D$ is the diameter of the underlying graph and $r \\le d$ is the rank of\n$\\mathbf{\\Sigma}$. Our method is based on extending the widely applied idea of\nsparse rulers for Toeplitz covariance estimation to the graph setting.\n  In the special case when $\\mathbf{\\Sigma}$ is a low-rank Toeplitz matrix, our\nresult matches the state-of-the-art, with a far simpler proof. We also give an\ninformation theoretic lower bound matching our upper bound up to a factor $D$\nand discuss some directions towards closing this gap.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:37:46 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Maity", "Raj Kumar", ""], ["Musco", "Cameron", ""]]}, {"id": "2011.09994", "submitter": "Mahdi Sani", "authors": "Reza Namazi, Arsham Zolanvari, Mahdi Sani, Seyed Amir Ali Ghafourian\n  Ghahramani", "title": "GL-Coarsener: A Graph representation learning framework to construct\n  coarse grid hierarchy for AMG solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.AI cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many numerical schemes, the computational complexity scales non-linearly\nwith the problem size. Solving a linear system of equations using direct\nmethods or most iterative methods is a typical example. Algebraic multi-grid\n(AMG) methods are numerical methods used to solve large linear systems of\nequations efficiently. One of the main differences between AMG methods is how\nthe coarser grid is constructed from a given fine grid. There are two main\nclasses of AMG methods; graph and aggregation based coarsening methods. Here we\npropose an aggregation-based coarsening framework leveraging graph\nrepresentation learning and clustering algorithms. Our method introduces the\npower of machine learning into the AMG research field and opens a new\nperspective for future researches. The proposed method uses graph\nrepresentation learning techniques to learn latent features of the graph\nobtained from the underlying matrix of coefficients. Using these extracted\nfeatures, we generated a coarser grid from the fine grid. The proposed method\nis highly capable of parallel computations. Our experiments show that the\nproposed method's efficiency in solving large systems is closely comparable\nwith other aggregation-based methods, demonstrating the high capability of\ngraph representation learning in designing multi-grid solvers.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:49:09 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Namazi", "Reza", ""], ["Zolanvari", "Arsham", ""], ["Sani", "Mahdi", ""], ["Ghahramani", "Seyed Amir Ali Ghafourian", ""]]}, {"id": "2011.09996", "submitter": "Jos\\'e M. Moreu Mr.", "authors": "Jos\\'e M. Moreu, Anuradha M. Annaswamy", "title": "A Stable High-order Tuner for General Convex Functions", "comments": "6 pages, 3 figures. This work has been accepted for publication at\n  IEEE Control Systems Letters", "journal-ref": null, "doi": "10.1109/LCSYS.2021.3082875", "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Iterative gradient-based algorithms have been increasingly applied for the\ntraining of a broad variety of machine learning models including large\nneural-nets. In particular, momentum-based methods, with accelerated learning\nguarantees, have received a lot of attention due to their provable guarantees\nof fast learning in certain classes of problems and multiple algorithms have\nbeen derived. However, properties for these methods hold only for constant\nregressors. When time-varying regressors occur, which is commonplace in dynamic\nsystems, many of these momentum-based methods cannot guarantee stability.\nRecently, a new High-order Tuner (HT) was developed for linear regression\nproblems and shown to have 1) stability and asymptotic convergence for\ntime-varying regressors and 2) non-asymptotic accelerated learning guarantees\nfor constant regressors. In this paper, we extend and discuss the results of\nthis same HT for general convex loss functions. Through the exploitation of\nconvexity and smoothness definitions, we establish similar stability and\nasymptotic convergence guarantees. Finally, we provide numerical simulations\nsupporting the satisfactory behavior of the HT algorithm as well as an\naccelerated learning property.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:50:53 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 16:15:13 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 21:56:43 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Moreu", "Jos\u00e9 M.", ""], ["Annaswamy", "Anuradha M.", ""]]}, {"id": "2011.09998", "submitter": "Jiaqi Yang", "authors": "Jiaqi Yang", "title": "Fully Gap-Dependent Bounds for Multinomial Logit Bandit", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multinomial logit (MNL) bandit problem, where at each time step,\nthe seller offers an assortment of size at most $K$ from a pool of $N$ items,\nand the buyer purchases an item from the assortment according to a MNL choice\nmodel. The objective is to learn the model parameters and maximize the expected\nrevenue. We present (i) an algorithm that identifies the optimal assortment\n$S^*$ within $\\widetilde{O}(\\sum_{i = 1}^N \\Delta_i^{-2})$ time steps with high\nprobability, and (ii) an algorithm that incurs $O(\\sum_{i \\notin S^*}\nK\\Delta_i^{-1} \\log T)$ regret in $T$ time steps. To our knowledge, our\nalgorithms are the first to achieve gap-dependent bounds that fully depends on\nthe suboptimality gaps of all items. Our technical contributions include an\nalgorithmic framework that relates the MNL-bandit problem to a variant of the\ntop-$K$ arm identification problem in multi-armed bandits, a generalized\nepoch-based offering procedure, and a layer-based adaptive estimation\nprocedure.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:52:12 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Yang", "Jiaqi", ""]]}, {"id": "2011.09999", "submitter": "Usman Anwar Mr.", "authors": "Usman Anwar, Shehryar Malik, Alireza Aghasi, Ali Ahmed", "title": "Inverse Constrained Reinforcement Learning", "comments": "Camera-ready version for ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real world settings, numerous constraints are present which are hard to\nspecify mathematically. However, for the real world deployment of reinforcement\nlearning (RL), it is critical that RL agents are aware of these constraints, so\nthat they can act safely. In this work, we consider the problem of learning\nconstraints from demonstrations of a constraint-abiding agent's behavior. We\nexperimentally validate our approach and show that our framework can\nsuccessfully learn the most likely constraints that the agent respects. We\nfurther show that these learned constraints are \\textit{transferable} to new\nagents that may have different morphologies and/or reward functions. Previous\nworks in this regard have either mainly been restricted to tabular (discrete)\nsettings, specific types of constraints or assume the environment's transition\ndynamics. In contrast, our framework is able to learn arbitrary\n\\textit{Markovian} constraints in high-dimensions in a completely model-free\nsetting. The code can be found it:\n\\url{https://github.com/shehryar-malik/icrl}.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 17:56:33 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 05:23:03 GMT"}, {"version": "v3", "created": "Fri, 21 May 2021 09:18:14 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Anwar", "Usman", ""], ["Malik", "Shehryar", ""], ["Aghasi", "Alireza", ""], ["Ahmed", "Ali", ""]]}, {"id": "2011.10006", "submitter": "Holden Lee", "authors": "Holden Lee", "title": "Improved rates for identification of partially observed linear dynamical\n  systems", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of a linear time-invariant dynamical system from partial\nobservations is a fundamental problem in control theory. A natural question is\nhow to do so with non-asymptotic statistical rates depending on the inherent\ndimensionality (order) $d$ of the system, rather than on the sufficient rollout\nlength or on $\\frac1{1-\\rho(A)}$, where $\\rho(A)$ is the spectral radius of the\ndynamics matrix. We develop the first algorithm that given a single trajectory\nof length $T$ with gaussian observation noise, achieves a near-optimal rate of\n$\\widetilde O\\left(\\sqrt\\frac{d}{T}\\right)$ in $\\mathcal{H}_2$ error for the\nlearned system. We also give bounds under process noise and improved bounds for\nlearning a realization of the system. Our algorithm is based on low-rank\napproximation of Hankel matrices of geometrically increasing sizes.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:04:18 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lee", "Holden", ""]]}, {"id": "2011.10007", "submitter": "Jiayuan Mao", "authors": "Yikai Li, Jiayuan Mao, Xiuming Zhang, William T. Freeman, Joshua B.\n  Tenenbaum, Noah Snavely, Jiajun Wu", "title": "Multi-Plane Program Induction with 3D Box Priors", "comments": "NeurIPS 2020. First two authors contributed equally. Project page:\n  http://bpi.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two important aspects in understanding and editing images:\nmodeling regular, program-like texture or patterns in 2D planes, and 3D posing\nof these planes in the scene. Unlike prior work on image-based program\nsynthesis, which assumes the image contains a single visible 2D plane, we\npresent Box Program Induction (BPI), which infers a program-like scene\nrepresentation that simultaneously models repeated structure on multiple 2D\nplanes, the 3D position and orientation of the planes, and camera parameters,\nall from a single image. Our model assumes a box prior, i.e., that the image\ncaptures either an inner view or an outer view of a box in 3D. It uses neural\nnetworks to infer visual cues such as vanishing points, wireframe lines to\nguide a search-based algorithm to find the program that best explains the\nimage. Such a holistic, structured scene representation enables 3D-aware\ninteractive image editing operations such as inpainting missing pixels,\nchanging camera parameters, and extrapolate the image contents.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:07:46 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 19:13:03 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Yikai", ""], ["Mao", "Jiayuan", ""], ["Zhang", "Xiuming", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""], ["Snavely", "Noah", ""], ["Wu", "Jiajun", ""]]}, {"id": "2011.10015", "submitter": "Mahmoud Asem", "authors": "Mahmoud Asem", "title": "DiffusionNet: Accelerating the solution of Time-Dependent partial\n  differential equations using deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present our deep learning framework to solve and accelerate the\nTime-Dependent partial differential equation's solution of one and two spatial\ndimensions. We demonstrate DiffusionNet solver by solving the 2D transient heat\nconduction problem with Dirichlet boundary conditions. The model is trained on\nsolution data calculated using the Alternating direction implicit method. We\nshow the model's ability to predict the solution from any combination of seven\nvariables: the starting time step of the solution, initial condition, four\nboundary conditions, and a combined variable of the time step size, diffusivity\nconstant, and grid step size. To improve speed, we exploit our model capability\nto predict the solution of the Time-dependent PDE after multiple time steps at\nonce to improve the speed of solution by dividing the solution into\nparallelizable chunks. We try to build a flexible architecture capable of\nsolving a wide range of partial differential equations with minimal changes. We\ndemonstrate our model flexibility by applying our model with the same network\narchitecture used to solve the transient heat conduction to solve the Inviscid\nBurgers equation and Steady-state heat conduction, then compare our model\nperformance against related studies. We show that our model reduces the error\nof the solution for the investigated problems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:28:42 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Asem", "Mahmoud", ""]]}, {"id": "2011.10024", "submitter": "Avi Singh", "authors": "Avi Singh, Huihan Liu, Gaoyue Zhou, Albert Yu, Nicholas Rhinehart,\n  Sergey Levine", "title": "Parrot: Data-Driven Behavioral Priors for Reinforcement Learning", "comments": "First two authors contributed equally. Project website:\n  https://sites.google.com/view/parrot-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning provides a general framework for flexible decision\nmaking and control, but requires extensive data collection for each new task\nthat an agent needs to learn. In other machine learning fields, such as natural\nlanguage processing or computer vision, pre-training on large, previously\ncollected datasets to bootstrap learning for new tasks has emerged as a\npowerful paradigm to reduce data requirements when learning a new task. In this\npaper, we ask the following question: how can we enable similarly useful\npre-training for RL agents? We propose a method for pre-training behavioral\npriors that can capture complex input-output relationships observed in\nsuccessful trials from a wide range of previously seen tasks, and we show how\nthis learned prior can be used for rapidly learning new tasks without impeding\nthe RL agent's ability to try out novel behaviors. We demonstrate the\neffectiveness of our approach in challenging robotic manipulation domains\ninvolving image observations and sparse reward functions, where our method\noutperforms prior works by a substantial margin.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:47:40 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Singh", "Avi", ""], ["Liu", "Huihan", ""], ["Zhou", "Gaoyue", ""], ["Yu", "Albert", ""], ["Rhinehart", "Nicholas", ""], ["Levine", "Sergey", ""]]}, {"id": "2011.10036", "submitter": "Haoye Lu Mr.", "authors": "Haoye Lu, Yongyi Mao, Amiya Nayak", "title": "On the Dynamics of Training Attention Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The attention mechanism has been widely used in deep neural networks as a\nmodel component. By now, it has become a critical building block in many\nstate-of-the-art natural language models. Despite its great success established\nempirically, the working mechanism of attention has not been investigated at a\nsufficient theoretical depth to date. In this paper, we set up a simple text\nclassification task and study the dynamics of training a simple attention-based\nclassification model using gradient descent. In this setting, we show that, for\nthe discriminative words that the model should attend to, a persisting identity\nexists relating its embedding and the inner product of its key and the query.\nThis allows us to prove that training must converge to attending to the\ndiscriminative words when the attention output is classified by a linear\nclassifier. Experiments are performed, which validate our theoretical analysis\nand provide further insights.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:55:30 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 03:51:05 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Lu", "Haoye", ""], ["Mao", "Yongyi", ""], ["Nayak", "Amiya", ""]]}, {"id": "2011.10043", "submitter": "Han Hu", "authors": "Zhenda Xie and Yutong Lin and Zheng Zhang and Yue Cao and Stephen Lin\n  and Han Hu", "title": "Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised\n  Visual Representation Learning", "comments": "Accepted in CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contrastive learning methods for unsupervised visual representation learning\nhave reached remarkable levels of transfer performance. We argue that the power\nof contrastive learning has yet to be fully unleashed, as current methods are\ntrained only on instance-level pretext tasks, leading to representations that\nmay be sub-optimal for downstream tasks requiring dense pixel predictions. In\nthis paper, we introduce pixel-level pretext tasks for learning dense feature\nrepresentations. The first task directly applies contrastive learning at the\npixel level. We additionally propose a pixel-to-propagation consistency task\nthat produces better results, even surpassing the state-of-the-art approaches\nby a large margin. Specifically, it achieves 60.2 AP, 41.4 / 40.5 mAP and 77.2\nmIoU when transferred to Pascal VOC object detection (C4), COCO object\ndetection (FPN / C4) and Cityscapes semantic segmentation using a ResNet-50\nbackbone network, which are 2.6 AP, 0.8 / 1.0 mAP and 1.0 mIoU better than the\nprevious best methods built on instance-level contrastive learning. Moreover,\nthe pixel-level pretext tasks are found to be effective for pre-training not\nonly regular backbone networks but also head networks used for dense downstream\ntasks, and are complementary to instance-level contrastive methods. These\nresults demonstrate the strong potential of defining pretext tasks at the pixel\nlevel, and suggest a new path forward in unsupervised visual representation\nlearning. Code is available at \\url{https://github.com/zdaxie/PixPro}.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 18:59:45 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 14:29:39 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Xie", "Zhenda", ""], ["Lin", "Yutong", ""], ["Zhang", "Zheng", ""], ["Cao", "Yue", ""], ["Lin", "Stephen", ""], ["Hu", "Han", ""]]}, {"id": "2011.10065", "submitter": "Mathurin Massias", "authors": "Quentin Bertrand and Mathurin Massias", "title": "Anderson acceleration of coordinate descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acceleration of first order methods is mainly obtained via inertial\ntechniques \\`a la Nesterov, or via nonlinear extrapolation. The latter has\nknown a recent surge of interest, with successful applications to gradient and\nproximal gradient techniques. On multiple Machine Learning problems, coordinate\ndescent achieves performance significantly superior to full-gradient methods.\nSpeeding up coordinate descent in practice is not easy: inertially accelerated\nversions of coordinate descent are theoretically accelerated, but might not\nalways lead to practical speed-ups. We propose an accelerated version of\ncoordinate descent using extrapolation, showing considerable speed up in\npractice, compared to inertial accelerated coordinate descent and extrapolated\n(proximal) gradient descent. Experiments on least squares, Lasso, elastic net\nand logistic regression validate the approach.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 19:01:48 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 08:43:43 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Bertrand", "Quentin", ""], ["Massias", "Mathurin", ""]]}, {"id": "2011.10076", "submitter": "Zhe Zhang", "authors": "Zhe Zhang, Guanghui Lan", "title": "Optimal Algorithms for Convex Nested Stochastic Composite Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, convex nested stochastic composite optimization (NSCO) has received\nconsiderable attention for its application in reinforcement learning and\nrisk-averse optimization. However, In the current literature, there exists a\nsignificant gap in the iteration complexities between these NSCO problems and\nother simpler stochastic composite optimization problems (e.g., sum of smooth\nand nonsmooth functions) without the nested structure. In this paper, we close\nthe gap by reformulating a class of convex NSCO problems as \"$\\min\\max\\ldots\n\\max$\" saddle point problems under mild assumptions and proposing two\nprimal-dual type algorithms with the optimal $\\mathcal{O}\\{1/\\epsilon^2\\}$\n(resp., $\\mathcal{O}\\{1/\\epsilon\\}$) complexity for solving nested (resp.,\nstrongly) convex problems. More specifically, for the often-considered\ntwo-layer smooth-nonsmooth problem, we introduce a simple vanilla stochastic\nsequential dual (SSD) algorithm which can be implemented purely in the primal\nform. For the multi-layer problem, we propose a general stochastic sequential\ndual framework. The framework consists of modular dual updates for different\ntypes of functions (smooth, smoothable, and non-smooth, etc.), so that it can\nhandle a more general composition of layer functions. Moreover, we present\nmodular convergence proofs to show that the complexity of the general SSD is\noptimal with respect to nearly all the problem parameters.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 19:22:58 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 04:01:19 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 04:40:57 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 03:44:32 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zhang", "Zhe", ""], ["Lan", "Guanghui", ""]]}, {"id": "2011.10077", "submitter": "Songzhu Zheng", "authors": "Songzhu Zheng, Pengxiang Wu, Aman Goswami, Mayank Goswami, Dimitris\n  Metaxas, Chao Chen", "title": "Error-Bounded Correction of Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  To collect large scale annotated data, it is inevitable to introduce label\nnoise, i.e., incorrect class labels. To be robust against label noise, many\nsuccessful methods rely on the noisy classifiers (i.e., models trained on the\nnoisy training data) to determine whether a label is trustworthy. However, it\nremains unknown why this heuristic works well in practice. In this paper, we\nprovide the first theoretical explanation for these methods. We prove that the\nprediction of a noisy classifier can indeed be a good indicator of whether the\nlabel of a training data is clean. Based on the theoretical result, we propose\na novel algorithm that corrects the labels based on the noisy classifier\nprediction. The corrected labels are consistent with the true Bayesian optimal\nclassifier with high probability. We incorporate our label correction algorithm\ninto the training of deep neural networks and train models that achieve\nsuperior testing performance on multiple public datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 19:23:23 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Zheng", "Songzhu", ""], ["Wu", "Pengxiang", ""], ["Goswami", "Aman", ""], ["Goswami", "Mayank", ""], ["Metaxas", "Dimitris", ""], ["Chen", "Chao", ""]]}, {"id": "2011.10084", "submitter": "Sahand Sharifzadeh", "authors": "Sahand Sharifzadeh, Sina Moayed Baharlou, Volker Tresp", "title": "Classification by Attention: Scene Graph Classification with Prior\n  Knowledge", "comments": "Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in scene graph classification is that the appearance of\nobjects and relations can be significantly different from one image to another.\nPrevious works have addressed this by relational reasoning over all objects in\nan image or incorporating prior knowledge into classification. Unlike previous\nworks, we do not consider separate models for perception and prior knowledge.\nInstead, we take a multi-task learning approach, where we implement the\nclassification as an attention layer. This allows for the prior knowledge to\nemerge and propagate within the perception model. By enforcing the model also\nto represent the prior, we achieve a strong inductive bias. We show that our\nmodel can accurately generate commonsense knowledge and that the iterative\ninjection of this knowledge to scene representations leads to significantly\nhigher classification performance. Additionally, our model can be fine-tuned on\nexternal knowledge given as triples. When combined with self-supervised\nlearning and with 1% of annotated images only, this gives more than 3%\nimprovement in object classification, 26% in scene graph classification, and\n36% in predicate prediction accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 19:54:04 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 11:52:05 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Sharifzadeh", "Sahand", ""], ["Baharlou", "Sina Moayed", ""], ["Tresp", "Volker", ""]]}, {"id": "2011.10098", "submitter": "Odd Erik Gundersen", "authors": "Odd Erik Gundersen", "title": "The Fundamental Principles of Reproducibility", "comments": "Accepted for publication in Philosophical Transactions of the Royal\n  Society A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reproducibility is a confused terminology. In this paper, I take a\nfundamental view on reproducibility rooted in the scientific method. The\nscientific method is analysed and characterised in order to develop the\nterminology required to define reproducibility. Further, the literature on\nreproducibility and replication is surveyed, and experiments are modeled as\ntasks and problem solving methods. Machine learning is used to exemplify the\ndescribed approach. Based on the analysis, reproducibility is defined and three\ndifferent types of reproducibility as well as four degrees of reproducibility\nare specified.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 20:37:58 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 14:01:58 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gundersen", "Odd Erik", ""]]}, {"id": "2011.10100", "submitter": "Gustavo Silva", "authors": "Gustavo Silva, Paul Rodriguez", "title": "Efficient Consensus Model based on Proximal Gradient Method applied to\n  Convolutional Sparse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Convolutional sparse representation (CSR), shift-invariant model for inverse\nproblems, has gained much attention in the fields of signal/image processing,\nmachine learning and computer vision. The most challenging problems in CSR\nimplies the minimization of a composite function of the form $min_x \\sum_i\nf_i(x) + g(x)$, where a direct and low-cost solution can be difficult to\nachieve. However, it has been reported that semi-distributed formulations such\nas ADMM consensus can provide important computational benefits. In the present\nwork, we derive and detail a thorough theoretical analysis of an efficient\nconsensus algorithm based on proximal gradient (PG) approach. The effectiveness\nof the proposed algorithm with respect to its ADMM counterpart is primarily\nassessed in the classic convolutional dictionary learning problem. Furthermore,\nour consensus method, which is generically structured, can be used to solve\nother optimization problems, where a sum of convex functions with a\nregularization term share a single global variable. As an example, the proposed\nalgorithm is also applied to another particular convolutional problem for the\nanomaly detection task.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 20:52:48 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Silva", "Gustavo", ""], ["Rodriguez", "Paul", ""]]}, {"id": "2011.10106", "submitter": "Firoj Alam", "authors": "Md. Arid Hasan, Jannatul Tajrin, Shammur Absar Chowdhury, Firoj Alam", "title": "Sentiment Classification in Bangla Textual Content: A Comparative Study", "comments": "Accepted at ICCIT-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis has been widely used to understand our views on social and\npolitical agendas or user experiences over a product. It is one of the cores\nand well-researched areas in NLP. However, for low-resource languages, like\nBangla, one of the prominent challenge is the lack of resources. Another\nimportant limitation, in the current literature for Bangla, is the absence of\ncomparable results due to the lack of a well-defined train/test split. In this\nstudy, we explore several publicly available sentiment labeled datasets and\ndesigned classifiers using both classical and deep learning algorithms. In our\nstudy, the classical algorithms include SVM and Random Forest, and deep\nlearning algorithms include CNN, FastText, and transformer-based models. We\ncompare these models in terms of model performance and time-resource\ncomplexity. Our finding suggests transformer-based models, which have not been\nexplored earlier for Bangla, outperform all other models. Furthermore, we\ncreated a weighted list of lexicon content based on the valence score per\nclass. We then analyzed the content for high significance entries per class, in\nthe datasets. For reproducibility, we make publicly available data splits and\nthe ranked lexicon list. The presented results can be used for future studies\nas a benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 21:06:28 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Hasan", "Md. Arid", ""], ["Tajrin", "Jannatul", ""], ["Chowdhury", "Shammur Absar", ""], ["Alam", "Firoj", ""]]}, {"id": "2011.10115", "submitter": "Florian Stelzer", "authors": "Florian Stelzer (1, 2 and 4), Andr\\'e R\\\"ohm (3), Raul Vicente (4),\n  Ingo Fischer (3), Serhiy Yanchuk (1) ((1) Institute of Mathematics,\n  Technische Universit\\\"at Berlin, Germany, (2) Department of Mathematics,\n  Humboldt-Universit\\\"at zu Berlin, Germany, (3) Instituto de F\\'isica\n  Interdisciplinar y Sistemas Complejos, IFISC (UIB-CSIC), Spain, (4) Institute\n  of Computer Science, University of Tartu, Estonia)", "title": "Deep Neural Networks using a Single Neuron: Folded-in-Time Architecture\n  using Feedback-Modulated Delay Loops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are among the most widely applied machine learning tools\nshowing outstanding performance in a broad range of tasks. We present a method\nfor folding a deep neural network of arbitrary size into a single neuron with\nmultiple time-delayed feedback loops. This single-neuron deep neural network\ncomprises only a single nonlinearity and appropriately adjusted modulations of\nthe feedback signals. The network states emerge in time as a temporal unfolding\nof the neuron's dynamics. By adjusting the feedback-modulation within the\nloops, we adapt the network's connection weights. These connection weights are\ndetermined via a back-propagation algorithm, where both the delay-induced and\nlocal network connections must be taken into account. Our approach can fully\nrepresent standard Deep Neural Networks (DNN), encompasses sparse DNNs, and\nextends the DNN concept toward dynamical systems implementations. The new\nmethod, which we call Folded-in-time DNN (Fit-DNN), exhibits promising\nperformance in a set of benchmark tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 21:45:58 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 13:37:50 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Stelzer", "Florian", "", "1, 2 and 4"], ["R\u00f6hm", "Andr\u00e9", ""], ["Vicente", "Raul", ""], ["Fischer", "Ingo", ""], ["Yanchuk", "Serhiy", ""]]}, {"id": "2011.10124", "submitter": "Haihao Lu", "authors": "Santiago Balseiro, Haihao Lu, Vahab Mirrokni", "title": "The Best of Many Worlds: Dual Mirror Descent for Online Allocation\n  Problems", "comments": "arXiv admin note: text overlap with arXiv:2002.10421", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online allocation problems with resource constraints are central problems in\nrevenue management and online advertising. In these problems, requests arrive\nsequentially during a finite horizon and, for each request, a decision maker\nneeds to choose an action that consumes a certain amount of resources and\ngenerates reward. The objective is to maximize cumulative rewards subject to a\nconstraint on the total consumption of resources. In this paper, we consider a\ndata-driven setting in which the reward and resource consumption of each\nrequest are generated using an input model that is unknown to the decision\nmaker.\n  We design a general class of algorithms that attain good performance in\nvarious inputs models without knowing which type of input they are facing. In\nparticular, our algorithms are asymptotically optimal under stochastic i.i.d.\ninput model as well as various non-stationary stochastic input models, and they\nattain an asymptotically optimal fixed competitive ratio when the input is\nadversarial. Our algorithms operate in the Lagrangian dual space: they maintain\na dual multiplier for each resource that is updated using online mirror\ndescent. By choosing the reference function accordingly, we recover dual\nsub-gradient descent and dual exponential weights algorithm. The resulting\nalgorithms are simple, fast, and have minimal requirements on the reward\nfunctions, consumption functions and the action space, in contrast to existing\nmethods for online allocation problems. We discuss applications to network\nrevenue management, online bidding in repeated auctions with budget\nconstraints, online proportional matching with high entropy, and personalized\nassortment optimization with limited inventories.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 18:39:17 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 15:51:56 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Balseiro", "Santiago", ""], ["Lu", "Haihao", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "2011.10134", "submitter": "Quanquan Gu", "authors": "Dongruo Zhou and Jiahao Chen and Quanquan Gu", "title": "Provable Multi-Objective Reinforcement Learning with Generative Models", "comments": "10 pages, Workshop on Real-World Reinforcement Learning at the 34th\n  Conference on Neural Information ProcessingSystems (NeurIPS 2020), Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective reinforcement learning (MORL) is an extension of ordinary,\nsingle-objective reinforcement learning (RL) that is applicable to many\nreal-world tasks where multiple objectives exist without known relative costs.\nWe study the problem of single policy MORL, which learns an optimal policy\ngiven the preference of objectives. Existing methods require strong assumptions\nsuch as exact knowledge of the multi-objective Markov decision process, and are\nanalyzed in the limit of infinite data and time. We propose a new algorithm\ncalled model-based envelop value iteration (EVI), which generalizes the\nenveloped multi-objective $Q$-learning algorithm in Yang et al., 2019. Our\nmethod can learn a near-optimal value function with polynomial sample\ncomplexity and linear convergence speed. To the best of our knowledge, this is\nthe first finite-sample analysis of MORL algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 22:35:31 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 07:28:13 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhou", "Dongruo", ""], ["Chen", "Jiahao", ""], ["Gu", "Quanquan", ""]]}, {"id": "2011.10144", "submitter": "Johanna Einsiedler", "authors": "Johanna Einsiedler, Yun Cheng, Franz Papst, Olga Saukh", "title": "Interpretable and Transferable Models to Understand the Impact of\n  Lockdown Measures on Local Air Quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 related lockdown measures offer a unique opportunity to\nunderstand how changes in economic activity and traffic affect ambient air\nquality and how much pollution reduction potential can the society offer\nthrough digitalization and mobilitylimiting policies. In this work, we estimate\npollution reduction over the lockdown period by using the measurements from\nground air pollution monitoring stations, training a long-term prediction model\nand comparing its predictions to measured values over the lockdown month.We\nshow that our models achieve state-of-the-art performance on the data from air\npollution measurement stations in Switzerland and in China: evaluate up to\n-15.8% / +34.4% change in NO2 / PM10 in Zurich; -35.3 % / -3.5 % and -42.4 % /\n-34.7 % in NO2 / PM2.5 in Beijing and Wuhan respectively. Our reduction\nestimates are consistent with recent publications, yet in contrast to prior\nworks, our method takes local weather into account. What can we learn from\npollution emissions during lockdown? The lockdown period was too short to train\nmeaningful models from scratch. To tackle this problem, we use transfer\nlearning to newly fit only traffic-dependent variables. We show that the\nresulting models are accurate, suitable for an analysis of the post-lockdown\nperiod and capable of estimating the future air pollution reduction potential.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 23:09:30 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 08:59:34 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Einsiedler", "Johanna", ""], ["Cheng", "Yun", ""], ["Papst", "Franz", ""], ["Saukh", "Olga", ""]]}, {"id": "2011.10147", "submitter": "Yair Kittenplon", "authors": "Yair Kittenplon, Yonina C. Eldar, Dan Raviv", "title": "FlowStep3D: Model Unrolling for Self-Supervised Scene Flow Estimation", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the 3D motion of points in a scene, known as scene flow, is a core\nproblem in computer vision. Traditional learning-based methods designed to\nlearn end-to-end 3D flow often suffer from poor generalization. Here we present\na recurrent architecture that learns a single step of an unrolled iterative\nalignment procedure for refining scene flow predictions. Inspired by classical\nalgorithms, we demonstrate iterative convergence toward the solution using\nstrong regularization. The proposed method can handle sizeable temporal\ndeformations and suggests a slimmer architecture than competitive all-to-all\ncorrelation approaches. Trained on FlyingThings3D synthetic data only, our\nnetwork successfully generalizes to real scans, outperforming all existing\nmethods by a large margin on the KITTI self-supervised benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 23:23:48 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 14:19:35 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Kittenplon", "Yair", ""], ["Eldar", "Yonina C.", ""], ["Raviv", "Dan", ""]]}, {"id": "2011.10150", "submitter": "Juan Wilches", "authors": "Yongqiang Huang, Juan Wilches, Yu Sun", "title": "Robot Gaining Accurate Pouring Skills through Self-Supervised Learning\n  and Generalization", "comments": "Accepted to RAS - 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pouring is one of the most commonly executed tasks in humans' daily lives,\nwhose accuracy is affected by multiple factors, including the type of material\nto be poured and the geometry of the source and receiving containers. In this\nwork, we propose a self-supervised learning approach that learns the pouring\ndynamics, pouring motion, and outcomes from unsupervised demonstrations for\naccurate pouring. The learned pouring model is then generalized by\nself-supervised practicing to different conditions such as using unaccustomed\npouring cups. We have evaluated the proposed approach first with one container\nfrom the training set and four new but similar containers. The proposed\napproach achieved better pouring accuracy than a regular human with a similar\npouring speed for all five cups. Both the accuracy and pouring speed outperform\nstate-of-the-art works. We have also evaluated the proposed self-supervised\ngeneralization approach using unaccustomed containers that are far different\nfrom the ones in the training set. The self-supervised generalization reduces\nthe pouring error of the unaccustomed containers to the desired accuracy level.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 23:48:43 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Huang", "Yongqiang", ""], ["Wilches", "Juan", ""], ["Sun", "Yu", ""]]}, {"id": "2011.10180", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Jamie Cui, Guanfeng Liu, Jia Wu, Li Wang", "title": "Survey and Open Problems in Privacy Preserving Knowledge Graph: Merging,\n  Query, Representation, Completion and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graph (KG) has attracted more and more companies' attention for its\nability to connect different types of data in meaningful ways and support rich\ndata services. However, the data isolation problem limits the performance of KG\nand prevents its further development. That is, multiple parties have their own\nKGs but they cannot share with each other due to regulation or competition\nreasons. Therefore, how to conduct privacy preserving KG becomes an important\nresearch question to answer. That is, multiple parties conduct KG related tasks\ncollaboratively on the basis of protecting the privacy of multiple KGs. To\ndate, there is few work on solving the above KG isolation problem. In this\npaper, to fill this gap, we summarize the open problems for privacy preserving\nKG in data isolation setting and propose possible solutions for them.\nSpecifically, we summarize the open problems in privacy preserving KG from four\naspects, i.e., merging, query, representation, and completion. We present these\nproblems in details and propose possible technical solutions for them.\nMoreover, we present three privacy preserving KG-aware applications and simply\ndescribe how can our proposed techniques be applied into these applications.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 02:35:47 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Chen", "Chaochao", ""], ["Cui", "Jamie", ""], ["Liu", "Guanfeng", ""], ["Wu", "Jia", ""], ["Wang", "Li", ""]]}, {"id": "2011.10187", "submitter": "Sarkar Snigdha Sarathi Das", "authors": "Md. Ashraful Islam, Mir Mahathir Mohammad, Sarkar Snigdha Sarathi Das,\n  Mohammed Eunus Ali", "title": "A Survey on Deep Learning Based Point-Of-Interest (POI) Recommendations", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location-based Social Networks (LBSNs) enable users to socialize with friends\nand acquaintances by sharing their check-ins, opinions, photos, and reviews.\nHuge volume of data generated from LBSNs opens up a new avenue of research that\ngives birth to a new sub-field of recommendation systems, known as\nPoint-of-Interest (POI) recommendation. A POI recommendation technique\nessentially exploits users' historical check-ins and other multi-modal\ninformation such as POI attributes and friendship network, to recommend the\nnext set of POIs suitable for a user. A plethora of earlier works focused on\ntraditional machine learning techniques by using hand-crafted features from the\ndataset. With the recent surge of deep learning research, we have witnessed a\nlarge variety of POI recommendation works utilizing different deep learning\nparadigms. These techniques largely vary in problem formulations, proposed\ntechniques, used datasets, and features, etc. To the best of our knowledge,\nthis work is the first comprehensive survey of all major deep learning-based\nPOI recommendation works. Our work categorizes and critically analyzes the\nrecent POI recommendation works based on different deep learning paradigms and\nother relevant features. This review can be considered a cookbook for\nresearchers or practitioners working in the area of POI recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 02:55:52 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Islam", "Md. Ashraful", ""], ["Mohammad", "Mir Mahathir", ""], ["Das", "Sarkar Snigdha Sarathi", ""], ["Ali", "Mohammed Eunus", ""]]}, {"id": "2011.10189", "submitter": "Yekai Wang", "authors": "Yekai Wang", "title": "MobileDepth: Efficient Monocular Depth Prediction on Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depth prediction is fundamental for many useful applications on computer\nvision and robotic systems. On mobile phones, the performance of some useful\napplications such as augmented reality, autofocus and so on could be enhanced\nby accurate depth prediction. In this work, an efficient fully convolutional\nnetwork architecture for depth prediction has been proposed, which uses RegNetY\n06 as the encoder and split-concatenate shuffle blocks as decoder. At the same\ntime, an appropriate combination of data augmentation, hyper-parameters and\nloss functions to efficiently train the lightweight network has been provided.\nAlso, an Android application has been developed which can load CNN models to\npredict depth map by the monocular images captured from the mobile camera and\nevaluate the average latency and frame per second of the models. As a result,\nthe network achieves 82.7% {\\delta}1 accuracy on NYU Depth v2 dataset and at\nthe same time, have only 62ms latency on ARM A76 CPUs so that it can predict\nthe depth map from the mobile camera in real-time.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 03:08:54 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wang", "Yekai", ""]]}, {"id": "2011.10208", "submitter": "Eric Nichols", "authors": "Eric Nichols and Leo Gao and Randy Gomez", "title": "Collaborative Storytelling with Large-scale Neural Language Models", "comments": "To appear in Proceedings of the 13th Annual ACM SIGGRAPH Conference\n  on Motion, Interaction and Games (MIG 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Storytelling plays a central role in human socializing and entertainment.\nHowever, much of the research on automatic storytelling generation assumes that\nstories will be generated by an agent without any human interaction. In this\npaper, we introduce the task of collaborative storytelling, where an artificial\nintelligence agent and a person collaborate to create a unique story by taking\nturns adding to it. We present a collaborative storytelling system which works\nwith a human storyteller to create a story by generating new utterances based\non the story so far. We constructed the storytelling system by tuning a\npublicly-available large scale language model on a dataset of writing prompts\nand their accompanying fictional works. We identify generating sufficiently\nhuman-like utterances to be an important technical issue and propose a\nsample-and-rank approach to improve utterance quality. Quantitative evaluation\nshows that our approach outperforms a baseline, and we present qualitative\nevaluation of our system's capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:36:54 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Nichols", "Eric", ""], ["Gao", "Leo", ""], ["Gomez", "Randy", ""]]}, {"id": "2011.10216", "submitter": "Joel Jang", "authors": "Joel Jang, Yoonjeon Kim, Kyoungho Choi, Sungho Suh", "title": "Sequential Targeting: an incremental learning approach for data\n  imbalance in text classification", "comments": "9 pages, 7 figures, submitted to the journal of Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification tasks require a balanced distribution of data to ensure the\nlearner to be trained to generalize over all classes. In real-world datasets,\nhowever, the number of instances vary substantially among classes. This\ntypically leads to a learner that promotes bias towards the majority group due\nto its dominating property. Therefore, methods to handle imbalanced datasets\nare crucial for alleviating distributional skews and fully utilizing the\nunder-represented data, especially in text classification. While addressing the\nimbalance in text data, most methods utilize sampling methods on the numerical\nrepresentation of the data, which limits its efficiency on how effective the\nrepresentation is. We propose a novel training method, Sequential\nTargeting(ST), independent of the effectiveness of the representation method,\nwhich enforces an incremental learning setting by splitting the data into\nmutually exclusive subsets and training the learner adaptively. To address\nproblems that arise within incremental learning, we apply elastic weight\nconsolidation. We demonstrate the effectiveness of our method through\nexperiments on simulated benchmark datasets (IMDB) and data collected from\nNAVER.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:54:00 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 02:33:08 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jang", "Joel", ""], ["Kim", "Yoonjeon", ""], ["Choi", "Kyoungho", ""], ["Suh", "Sungho", ""]]}, {"id": "2011.10218", "submitter": "Ryan Burn", "authors": "Ryan Burn", "title": "Optimizing Approximate Leave-one-out Cross-validation to Tune\n  Hyperparameters", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a large class of regularized models, leave-one-out cross-validation can\nbe efficiently estimated with an approximate leave-one-out formula (ALO). We\nconsider the problem of adjusting hyperparameters so as to optimize ALO. We\nderive efficient formulas to compute the gradient and hessian of ALO and show\nhow to apply a second-order optimizer to find hyperparameters. We demonstrate\nthe usefulness of the proposed approach by finding hyperparameters for\nregularized logistic regression and ridge regression on various real-world data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:57:41 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Burn", "Ryan", ""]]}, {"id": "2011.10219", "submitter": "Xingchao Liu", "authors": "Xingchao Liu, Xing Han, Na Zhang, Qiang Liu", "title": "Certified Monotonic Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning monotonic models with respect to a subset of the inputs is a\ndesirable feature to effectively address the fairness, interpretability, and\ngeneralization issues in practice. Existing methods for learning monotonic\nneural networks either require specifically designed model structures to ensure\nmonotonicity, which can be too restrictive/complicated, or enforce monotonicity\nby adjusting the learning process, which cannot provably guarantee the learned\nmodel is monotonic on selected features. In this work, we propose to certify\nthe monotonicity of the general piece-wise linear neural networks by solving a\nmixed integer linear programming problem.This provides a new general approach\nfor learning monotonic neural networks with arbitrary model structures. Our\nmethod allows us to train neural networks with heuristic monotonicity\nregularizations, and we can gradually increase the regularization magnitude\nuntil the learned network is certified monotonic. Compared to prior works, our\napproach does not require human-designed constraints on the weight space and\nalso yields more accurate approximation. Empirical studies on various datasets\ndemonstrate the efficiency of our approach over the state-of-the-art methods,\nsuch as Deep Lattice Networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 04:58:13 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Liu", "Xingchao", ""], ["Han", "Xing", ""], ["Zhang", "Na", ""], ["Liu", "Qiang", ""]]}, {"id": "2011.10223", "submitter": "Jayadeva", "authors": "Himanshu Pant, Jayadeva and Sumit Soman", "title": "Complexity Controlled Generative Adversarial Networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the issues faced in training Generative Adversarial Nets (GANs) and\ntheir variants is the problem of mode collapse, wherein the training stability\nin terms of the generative loss increases as more training data is used. In\nthis paper, we propose an alternative architecture via the Low-Complexity\nNeural Network (LCNN), which attempts to learn models with low complexity. The\nmotivation is that controlling model complexity leads to models that do not\noverfit the training data. We incorporate the LCNN loss function for GANs, Deep\nConvolutional GANs (DCGANs) and Spectral Normalized GANs (SNGANs), in order to\ndevelop hybrid architectures called the LCNN-GAN, LCNN-DCGAN and LCNN-SNGAN\nrespectively. On various large benchmark image datasets, we show that the use\nof our proposed models results in stable training while avoiding the problem of\nmode collapse, resulting in better training stability. We also show how the\nlearning behavior can be controlled by a hyperparameter in the LCNN functional,\nwhich also provides an improved inception score.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 05:35:55 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Pant", "Himanshu", ""], ["Jayadeva", "", ""], ["Soman", "Sumit", ""]]}, {"id": "2011.10225", "submitter": "Naoya Hatano", "authors": "Naoya Hatano, Masahiro Ikeda, Isao Ishikawa, and Yoshihiro Sawano", "title": "A global universality of two-layer neural networks with ReLU activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present study, we investigate a universality of neural networks, which\nconcerns a density of the set of two-layer neural networks in a function\nspaces. There are many works that handle the convergence over compact sets. In\nthe present paper, we consider a global convergence by introducing a norm\nsuitably, so that our results will be uniform over any compact set.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 05:39:10 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Hatano", "Naoya", ""], ["Ikeda", "Masahiro", ""], ["Ishikawa", "Isao", ""], ["Sawano", "Yoshihiro", ""]]}, {"id": "2011.10227", "submitter": "Yinan Wang", "authors": "Yinan Wang, Diane Oyen, Weihong (Grace) Guo, Anishi Mehta, Cory Braker\n  Scott, Nishant Panda, M. Giselle Fern\\'andez-Godino, Gowri Srinivasan,\n  Xiaowei Yue", "title": "StressNet: Deep Learning to Predict Stress With Fracture Propagation in\n  Brittle Materials", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic failure in brittle materials is often due to the rapid growth\nand coalescence of cracks aided by high internal stresses. Hence, accurate\nprediction of maximum internal stress is critical to predicting time to failure\nand improving the fracture resistance and reliability of materials. Existing\nhigh-fidelity methods, such as the Finite-Discrete Element Model (FDEM), are\nlimited by their high computational cost. Therefore, to reduce computational\ncost while preserving accuracy, a novel deep learning model, \"StressNet,\" is\nproposed to predict the entire sequence of maximum internal stress based on\nfracture propagation and the initial stress data. More specifically, the\nTemporal Independent Convolutional Neural Network (TI-CNN) is designed to\ncapture the spatial features of fractures like fracture path and spall regions,\nand the Bidirectional Long Short-term Memory (Bi-LSTM) Network is adapted to\ncapture the temporal features. By fusing these features, the evolution in time\nof the maximum internal stress can be accurately predicted. Moreover, an\nadaptive loss function is designed by dynamically integrating the Mean Squared\nError (MSE) and the Mean Absolute Percentage Error (MAPE), to reflect the\nfluctuations in maximum internal stress. After training, the proposed model is\nable to compute accurate multi-step predictions of maximum internal stress in\napproximately 20 seconds, as compared to the FDEM run time of 4 hours, with an\naverage MAPE of 2% relative to test data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 05:49:12 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Wang", "Yinan", "", "Grace"], ["Oyen", "Diane", "", "Grace"], ["Weihong", "", "", "Grace"], ["Guo", "", ""], ["Mehta", "Anishi", ""], ["Scott", "Cory Braker", ""], ["Panda", "Nishant", ""], ["Fern\u00e1ndez-Godino", "M. Giselle", ""], ["Srinivasan", "Gowri", ""], ["Yue", "Xiaowei", ""]]}, {"id": "2011.10235", "submitter": "Tobias Schlagenhauf", "authors": "Tobias Schlagenhauf, Chenwei Sun, J\\\"urgen Fleischer", "title": "GAN based ball screw drive picture database enlargement for failure\n  classification", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The lack of reliable large datasets is one of the biggest difficulties of\nusing modern machine learning methods in the field of failure detection in the\nmanufacturing industry. In order to develop the function of failure\nclassification for ball screw surface, sufficient image data of surface\nfailures is necessary. When training a neural network model based on a small\ndataset, the trained model may lack the generalization ability and may perform\npoorly in practice. The main goal of this paper is to generate synthetic images\nbased on the generative adversarial network (GAN) to enlarge the image dataset\nof ball screw surface failures. Pitting failure and rust failure are two\npossible failure types on ball screw surface chosen in this paper to represent\nthe surface failure classes. The quality and diversity of generated images are\nevaluated afterwards using qualitative methods including expert observation,\nt-SNE visualization and the quantitative method of FID score. To verify whether\nthe GAN based generated images can increase failure classification performance,\nthe real image dataset was augmented and replaced by GAN based generated images\nto do the classification task. The authors successfully created GAN based\nimages of ball screw surface failures which showed positive effect on\nclassification test performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 06:49:09 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Schlagenhauf", "Tobias", ""], ["Sun", "Chenwei", ""], ["Fleischer", "J\u00fcrgen", ""]]}, {"id": "2011.10239", "submitter": "Fangrui Liu", "authors": "Fangrui Liu, Zheng Liu", "title": "Shuffle and Learn: Minimizing Mutual Information for Unsupervised\n  Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised binary representation allows fast data retrieval without any\nannotations, enabling practical application like fast person re-identification\nand multimedia retrieval. It is argued that conflicts in binary space are one\nof the major barriers to high-performance unsupervised hashing as current\nmethods failed to capture the precise code conflicts in the full domain. A\nnovel relaxation method called Shuffle and Learn is proposed to tackle code\nconflicts in the unsupervised hash. Approximated derivatives for joint\nprobability and the gradients for the binary layer are introduced to bridge the\nupdate from the hash to the input. Proof on $\\epsilon$-Convergence of joint\nprobability with approximated derivatives is provided to guarantee the\npreciseness on update applied on the mutual information. The proposed algorithm\nis carried out with iterative global updates to minimize mutual information,\ndiverging the code before regular unsupervised optimization. Experiments\nsuggest that the proposed method can relax the code optimization from local\noptimum and help to generate binary representations that are more\ndiscriminative and informative without any annotations. Performance benchmarks\non image retrieval with the unsupervised binary code are conducted on three\nopen datasets, and the model achieves state-of-the-art accuracy on image\nretrieval task for all those datasets. Datasets and reproducible code are\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 07:14:55 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Liu", "Fangrui", ""], ["Liu", "Zheng", ""]]}, {"id": "2011.10254", "submitter": "Xiang Fang", "authors": "Xiang Fang, Yuchong Hu, Pan Zhou, and Dapeng Oliver Wu", "title": "Unbalanced Incomplete Multi-view Clustering via the Scheme of View\n  Evolution: Weak Views are Meat; Strong Views do Eat", "comments": "Accepted by IEEE Transactions on Emerging Topics in Computational\n  Intelligence", "journal-ref": "IEEE Transactions on Emerging Topics in Computational Intelligence\n  2021", "doi": "10.1109/TETCI.2021.3077909", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incomplete multi-view clustering is an important technique to deal with\nreal-world incomplete multi-view data. Previous works assume that all views\nhave the same incompleteness, i.e., balanced incompleteness. However, different\nviews often have distinct incompleteness, i.e., unbalanced incompleteness,\nwhich results in strong views (low-incompleteness views) and weak views\n(high-incompleteness views). The unbalanced incompleteness prevents us from\ndirectly using the previous methods for clustering. In this paper, inspired by\nthe effective biological evolution theory, we design the novel scheme of view\nevolution to cluster strong and weak views. Moreover, we propose an Unbalanced\nIncomplete Multi-view Clustering method (UIMC), which is the first effective\nmethod based on view evolution for unbalanced incomplete multi-view clustering.\nCompared with previous methods, UIMC has two unique advantages: 1) it proposes\nweighted multi-view subspace clustering to integrate these unbalanced\nincomplete views, which effectively solves the unbalanced incomplete multi-view\nproblem; 2) it designs the low-rank and robust representation to recover the\ndata, which diminishes the impact of the incompleteness and noises. Extensive\nexperimental results demonstrate that UIMC improves the clustering performance\nby up to 40% on three evaluation metrics over other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:00:25 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 08:51:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Fang", "Xiang", ""], ["Hu", "Yuchong", ""], ["Zhou", "Pan", ""], ["Wu", "Dapeng Oliver", ""]]}, {"id": "2011.10258", "submitter": "Wenlong Gao", "authors": "Wenlong Gao and Ying Chen and Yong Peng", "title": "Cascade Attentive Dropout for Weakly Supervised Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Weakly supervised object detection (WSOD) aims to classify and locate objects\nwith only image-level supervision. Many WSOD approaches adopt multiple instance\nlearning as the initial model, which is prone to converge to the most\ndiscriminative object regions while ignoring the whole object, and therefore\nreduce the model detection performance. In this paper, a novel cascade\nattentive dropout strategy is proposed to alleviate the part domination\nproblem, together with an improved global context module. We purposely discard\nattentive elements in both channel and space dimensions, and capture the\ninter-pixel and inter-channel dependencies to induce the model to better\nunderstand the global context. Extensive experiments have been conducted on the\nchallenging PASCAL VOC 2007 benchmarks, which achieve 49.8% mAP and 66.0%\nCorLoc, outperforming state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:08:13 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Gao", "Wenlong", ""], ["Chen", "Ying", ""], ["Peng", "Yong", ""]]}, {"id": "2011.10282", "submitter": "Hang Liu", "authors": "Hang Liu, Xiaojun Yuan, Ying-Jun Angela Zhang", "title": "Reconfigurable Intelligent Surface Enabled Federated Learning: A Unified\n  Communication-Learning Design Approach", "comments": "Simulation codes are available at\n  https://github.com/liuhang1994/RIS-FL. This work has been accepted by IEEE\n  Transactions on Wireless Communications. Copyright may be transferred without\n  notice, after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To exploit massive amounts of data generated at mobile edge networks,\nfederated learning (FL) has been proposed as an attractive substitute for\ncentralized machine learning (ML). By collaboratively training a shared\nlearning model at edge devices, FL avoids direct data transmission and thus\novercomes high communication latency and privacy issues as compared to\ncentralized ML. To improve the communication efficiency in FL model\naggregation, over-the-air computation has been introduced to support a large\nnumber of simultaneous local model uploading by exploiting the inherent\nsuperposition property of wireless channels. However, due to the heterogeneity\nof communication capacities among edge devices, over-the-air FL suffers from\nthe straggler issue in which the device with the weakest channel acts as a\nbottleneck of the model aggregation performance. This issue can be alleviated\nby device selection to some extent, but the latter still suffers from a\ntradeoff between data exploitation and model communication. In this paper, we\nleverage the reconfigurable intelligent surface (RIS) technology to relieve the\nstraggler issue in over-the-air FL. Specifically, we develop a learning\nanalysis framework to quantitatively characterize the impact of device\nselection and model aggregation error on the convergence of over-the-air FL.\nThen, we formulate a unified communication-learning optimization problem to\njointly optimize device selection, over-the-air transceiver design, and RIS\nconfiguration. Numerical experiments show that the proposed design achieves\nsubstantial learning accuracy improvement compared with the state-of-the-art\napproaches, especially when channel conditions vary dramatically across edge\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:54:13 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 14:59:36 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 09:25:59 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 14:47:11 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Liu", "Hang", ""], ["Yuan", "Xiaojun", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "2011.10284", "submitter": "Nils Thuerey", "authors": "Marie-Lena Eckert, Kiwon Um, Nils Thuerey", "title": "ScalarFlow: A Large-Scale Volumetric Data Set of Real-world Scalar\n  Transport Flows for Computer Animation and Machine Learning", "comments": "Details and data at:\n  https://ge.in.tum.de/publications/2019-scalarflow-eckert/", "journal-ref": null, "doi": "10.1145/3355089.3356545", "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present ScalarFlow, a first large-scale data set of\nreconstructions of real-world smoke plumes. We additionally propose a framework\nfor accurate physics-based reconstructions from a small number of video\nstreams. Central components of our algorithm are a novel estimation of unseen\ninflow regions and an efficient regularization scheme. Our data set includes a\nlarge number of complex and natural buoyancy-driven flows. The flows transition\nto turbulent flows and contain observable scalar transport processes. As such,\nthe ScalarFlow data set is tailored towards computer graphics, vision, and\nlearning applications. The published data set will contain volumetric\nreconstructions of velocity and density, input image sequences, together with\ncalibration data, code, and instructions how to recreate the commodity hardware\ncapture setup. We further demonstrate one of the many potential application\nareas: a first perceptual evaluation study, which reveals that the complexity\nof the captured flows requires a huge simulation resolution for regular solvers\nin order to recreate at least parts of the natural complexity contained in the\ncaptured data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:55:00 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Eckert", "Marie-Lena", ""], ["Um", "Kiwon", ""], ["Thuerey", "Nils", ""]]}, {"id": "2011.10285", "submitter": "Harshil Shah", "authors": "Harshil Shah and Julien Fauqueur", "title": "Learning Informative Representations of Biomedical Relations with Latent\n  Variable Models", "comments": "SustaiNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extracting biomedical relations from large corpora of scientific documents is\na challenging natural language processing task. Existing approaches usually\nfocus on identifying a relation either in a single sentence (mention-level) or\nacross an entire corpus (pair-level). In both cases, recent methods have\nachieved strong results by learning a point estimate to represent the relation;\nthis is then used as the input to a relation classifier. However, the relation\nexpressed in text between a pair of biomedical entities is often more complex\nthan can be captured by a point estimate. To address this issue, we propose a\nlatent variable model with an arbitrarily flexible distribution to represent\nthe relation between an entity pair. Additionally, our model provides a unified\narchitecture for both mention-level and pair-level relation extraction. We\ndemonstrate that our model achieves results competitive with strong baselines\nfor both tasks while having fewer parameters and being significantly faster to\ntrain. We make our code publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:56:31 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Shah", "Harshil", ""], ["Fauqueur", "Julien", ""]]}, {"id": "2011.10287", "submitter": "Sindy L\\\"owe", "authors": "Sindy L\\\"owe, Klaus Greff, Rico Jonschkowski, Alexey Dosovitskiy,\n  Thomas Kipf", "title": "Learning Object-Centric Video Models by Contrasting Sets", "comments": "NeurIPS 2020 Workshop on Object Representations for Learning and\n  Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive, self-supervised learning of object representations recently\nemerged as an attractive alternative to reconstruction-based training. Prior\napproaches focus on contrasting individual object representations (slots)\nagainst one another. However, a fundamental problem with this approach is that\nthe overall contrastive loss is the same for (i) representing a different\nobject in each slot, as it is for (ii) (re-)representing the same object in all\nslots. Thus, this objective does not inherently push towards the emergence of\nobject-centric representations in the slots. We address this problem by\nintroducing a global, set-based contrastive loss: instead of contrasting\nindividual slot representations against one another, we aggregate the\nrepresentations and contrast the joined sets against one another. Additionally,\nwe introduce attention-based encoders to this contrastive setup which\nsimplifies training and provides interpretable object masks. Our results on two\nsynthetic video datasets suggest that this approach compares favorably against\nprevious contrastive methods in terms of reconstruction, future prediction and\nobject separation performance.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 09:13:42 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["L\u00f6we", "Sindy", ""], ["Greff", "Klaus", ""], ["Jonschkowski", "Rico", ""], ["Dosovitskiy", "Alexey", ""], ["Kipf", "Thomas", ""]]}, {"id": "2011.10298", "submitter": "Matilde Gargiani", "authors": "Matilde Gargiani and Andrea Zanelli and Quoc Tran-Dinh and Moritz\n  Diehl and Frank Hutter", "title": "Convergence Analysis of Homotopy-SGD for non-convex optimization", "comments": "21 pages, 14 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  First-order stochastic methods for solving large-scale non-convex\noptimization problems are widely used in many big-data applications, e.g.\ntraining deep neural networks as well as other complex and potentially\nnon-convex machine learning models. Their inexpensive iterations generally come\ntogether with slow global convergence rate (mostly sublinear), leading to the\nnecessity of carrying out a very high number of iterations before the iterates\nreach a neighborhood of a minimizer. In this work, we present a first-order\nstochastic algorithm based on a combination of homotopy methods and SGD, called\nHomotopy-Stochastic Gradient Descent (H-SGD), which finds interesting\nconnections with some proposed heuristics in the literature, e.g. optimization\nby Gaussian continuation, training by diffusion, mollifying networks. Under\nsome mild assumptions on the problem structure, we conduct a theoretical\nanalysis of the proposed algorithm. Our analysis shows that, with a\nspecifically designed scheme for the homotopy parameter, H-SGD enjoys a global\nlinear rate of convergence to a neighborhood of a minimum while maintaining\nfast and inexpensive iterations. Experimental evaluations confirm the\ntheoretical results and show that H-SGD can outperform standard SGD.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 09:50:40 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Gargiani", "Matilde", ""], ["Zanelli", "Andrea", ""], ["Tran-Dinh", "Quoc", ""], ["Diehl", "Moritz", ""], ["Hutter", "Frank", ""]]}, {"id": "2011.10300", "submitter": "Renyuan Xu", "authors": "Ben Hambly, Renyuan Xu and Huining Yang", "title": "Policy Gradient Methods for the Noisy Linear Quadratic Regulator over a\n  Finite Horizon", "comments": "49 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore reinforcement learning methods for finding the optimal policy in\nthe linear quadratic regulator (LQR) problem. In particular, we consider the\nconvergence of policy gradient methods in the setting of known and unknown\nparameters. We are able to produce a global linear convergence guarantee for\nthis approach in the setting of finite time horizon and stochastic state\ndynamics under weak assumptions. The convergence of a projected policy gradient\nmethod is also established in order to handle problems with constraints. We\nillustrate the performance of the algorithm with two examples. The first\nexample is the optimal liquidation of a holding in an asset. We show results\nfor the case where we assume a model for the underlying dynamics and where we\napply the method to the data directly. The empirical evidence suggests that the\npolicy gradient method can learn the global optimal solution for a larger class\nof stochastic systems containing the LQR framework and that it is more robust\nwith respect to model mis-specification when compared to a model-based\napproach. The second example is an LQR system in a higher dimensional setting\nwith synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 09:51:49 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 18:46:28 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Hambly", "Ben", ""], ["Xu", "Renyuan", ""], ["Yang", "Huining", ""]]}, {"id": "2011.10328", "submitter": "Vitus Benson", "authors": "Vitus Benson and Alexander Ecker", "title": "Assessing out-of-domain generalization for robust building damage\n  detection", "comments": "Published at NeurIPS 2020 Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response (AI+HADR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An important step for limiting the negative impact of natural disasters is\nrapid damage assessment after a disaster occurred. For instance, building\ndamage detection can be automated by applying computer vision techniques to\nsatellite imagery. Such models operate in a multi-domain setting: every\ndisaster is inherently different (new geolocation, unique circumstances), and\nmodels must be robust to a shift in distribution between disaster imagery\navailable for training and the images of the new event. Accordingly, estimating\nreal-world performance requires an out-of-domain (OOD) test set. However,\nbuilding damage detection models have so far been evaluated mostly in the\nsimpler yet unrealistic in-distribution (IID) test setting. Here we argue that\nfuture work should focus on the OOD regime instead. We assess OOD performance\nof two competitive damage detection models and find that existing\nstate-of-the-art models show a substantial generalization gap: their\nperformance drops when evaluated OOD on new disasters not used during training.\nMoreover, IID performance is not predictive of OOD performance, rendering\ncurrent benchmarks uninformative about real-world performance. Code and model\nweights are available at https://github.com/ecker-lab/robust-bdd.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 10:30:43 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Benson", "Vitus", ""], ["Ecker", "Alexander", ""]]}, {"id": "2011.10331", "submitter": "Xiang Fang", "authors": "Xiang Fang, Yuchong Hu, Pan Zhou, and Dapeng Oliver Wu", "title": "ANIMC: A Soft Framework for Auto-weighted Noisy and Incomplete\n  Multi-view Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering has wide applications in many image processing\nscenarios. In these scenarios, original image data often contain missing\ninstances and noises, which is ignored by most multi-view clustering methods.\nHowever, missing instances may make these methods difficult to use directly and\nnoises will lead to unreliable clustering results. In this paper, we propose a\nnovel Auto-weighted Noisy and Incomplete Multi-view Clustering framework\n(ANIMC) via a soft auto-weighted strategy and a doubly soft regular regression\nmodel. Firstly, by designing adaptive semi-regularized nonnegative matrix\nfactorization (adaptive semi-RNMF), the soft auto-weighted strategy assigns a\nproper weight to each view and adds a soft boundary to balance the influence of\nnoises and incompleteness. Secondly, by proposing{\\theta}-norm, the doubly soft\nregularized regression model adjusts the sparsity of our model by choosing\ndifferent{\\theta}. Compared with existing methods, ANIMC has three unique\nadvantages: 1) it is a soft algorithm to adjust our framework in different\nscenarios, thereby improving its generalization ability; 2) it automatically\nlearns a proper weight for each view, thereby reducing the influence of noises;\n3) it performs doubly soft regularized regression that aligns the same\ninstances in different views, thereby decreasing the impact of missing\ninstances. Extensive experimental results demonstrate its superior advantages\nover other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 10:37:27 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 12:17:22 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Fang", "Xiang", ""], ["Hu", "Yuchong", ""], ["Zhou", "Pan", ""], ["Wu", "Dapeng Oliver", ""]]}, {"id": "2011.10334", "submitter": "Tal Shapira", "authors": "Yaniv Fogel, Tal Shapira and Meir Feder", "title": "Efficient Data-Dependent Learnability", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive normalized maximum likelihood (pNML) approach has recently\nbeen proposed as the min-max optimal solution to the batch learning problem\nwhere both the training set and the test data feature are individuals, known\nsequences. This approach has yields a learnability measure that can also be\ninterpreted as a stability measure. This measure has shown some potential in\ndetecting out-of-distribution examples, yet it has considerable computational\ncosts. In this project, we propose and analyze an approximation of the pNML,\nwhich is based on influence functions. Combining both theoretical analysis and\nexperiments, we show that when applied to neural networks, this approximation\ncan detect out-of-distribution examples effectively. We also compare its\nperformance to that achieved by conducting a single gradient step for each\npossible label.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 10:44:55 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Fogel", "Yaniv", ""], ["Shapira", "Tal", ""], ["Feder", "Meir", ""]]}, {"id": "2011.10337", "submitter": "Shivam Pal", "authors": "Shivam Pal, Vipul Arora, Pawan Goyal", "title": "Finding Prerequisite Relations between Concepts using Textbook", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prerequisite is anything that you need to know or understand first before\nattempting to learn or understand something new. In the current work, we\npresent a method of finding prerequisite relations between concepts using\nrelated textbooks. Previous researchers have focused on finding these relations\nusing Wikipedia link structure through unsupervised and supervised learning\napproaches. In the current work, we have proposed two methods, one is\nstatistical method and another is learning-based method. We mine the rich and\nstructured knowledge available in the textbooks to find the content for those\nconcepts and the order in which they are discussed. Using this information,\nproposed statistical method estimates explicit as well as implicit prerequisite\nrelations between concepts. During experiments, we have found performance of\nproposed statistical method is better than the popular RefD method, which uses\nWikipedia link structure. And proposed learning-based method has shown a\nsignificant increase in the efficiency of supervised learning method when\ncompared with graph and text-based learning-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 10:58:31 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Pal", "Shivam", ""], ["Arora", "Vipul", ""], ["Goyal", "Pawan", ""]]}, {"id": "2011.10357", "submitter": "Hawoong Jeong", "authors": "Dong-Kyum Kim, Hawoong Jeong", "title": "Deep reinforcement learning for feedback control in a collective\n  flashing ratchet", "comments": "6 + 4 pages, 3 + 2 figures", "journal-ref": "Phys. Rev. Research 3, 022002 (2021)", "doi": "10.1103/PhysRevResearch.3.L022002", "report-no": null, "categories": "cs.LG cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collective flashing ratchet transports Brownian particles using a spatially\nperiodic, asymmetric, and time-dependent on-off switchable potential. The net\ncurrent of the particles in this system can be substantially increased by\nfeedback control based on the particle positions. Several feedback policies for\nmaximizing the current have been proposed, but optimal policies have not been\nfound for a moderate number of particles. Here, we use deep reinforcement\nlearning (RL) to find optimal policies, with results showing that policies\nbuilt with a suitable neural network architecture outperform the previous\npolicies. Moreover, even in a time-delayed feedback situation where the on-off\nswitching of the potential is delayed, we demonstrate that the policies\nprovided by deep RL provide higher currents than the previous strategies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 11:47:43 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 07:52:31 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 02:02:08 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Kim", "Dong-Kyum", ""], ["Jeong", "Hawoong", ""]]}, {"id": "2011.10359", "submitter": "Benjamin Graham", "authors": "Benjamin Graham, David Novotny", "title": "RidgeSfM: Structure from Motion via Robust Pairwise Matching Under Depth\n  Uncertainty", "comments": "Presenting at 3DV 2020. Source code released at\n  https://github.com/facebookresearch/RidgeSfM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simultaneously estimating a dense depth map and\ncamera pose for a large set of images of an indoor scene. While classical SfM\npipelines rely on a two-step approach where cameras are first estimated using a\nbundle adjustment in order to ground the ensuing multi-view stereo stage, both\nour poses and dense reconstructions are a direct output of an altered bundle\nadjuster. To this end, we parametrize each depth map with a linear combination\nof a limited number of basis \"depth-planes\" predicted in a monocular fashion by\na deep net. Using a set of high-quality sparse keypoint matches, we optimize\nover the per-frame linear combinations of depth planes and camera poses to form\na geometrically consistent cloud of keypoints. Although our bundle adjustment\nonly considers sparse keypoints, the inferred linear coefficients of the basis\nplanes immediately give us dense depth maps. RidgeSfM is able to collectively\nalign hundreds of frames, which is its main advantage over recent memory-heavy\ndeep alternatives that can align at most 10 frames. Quantitative comparisons\nreveal performance superior to a state-of-the-art large-scale SfM pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 11:59:20 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Graham", "Benjamin", ""], ["Novotny", "David", ""]]}, {"id": "2011.10364", "submitter": "Mohamadreza Faridghasemnia", "authors": "Mohamadreza Faridghasemnia, Daniele Nardi, Alessandro Saffiotti", "title": "Towards Abstract Relational Learning in Human Robot Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans have a rich representation of the entities in their environment.\nEntities are described by their attributes, and entities that share attributes\nare often semantically related. For example, if two books have \"Natural\nLanguage Processing\" as the value of their `title' attribute, we can expect\nthat their `topic' attribute will also be equal, namely, \"NLP\". Humans tend to\ngeneralize such observations, and infer sufficient conditions under which the\n`topic' attribute of any entity is \"NLP\". If robots need to interact\nsuccessfully with humans, they need to represent entities, attributes, and\ngeneralizations in a similar way. This ends in a contextualized cognitive agent\nthat can adapt its understanding, where context provides sufficient conditions\nfor a correct understanding. In this work, we address the problem of how to\nobtain these representations through human-robot interaction. We integrate\nvisual perception and natural language input to incrementally build a semantic\nmodel of the world, and then use inductive reasoning to infer logical rules\nthat capture generic semantic relations, true in this model. These relations\ncan be used to enrich the human-robot interaction, to populate a knowledge base\nwith inferred facts, or to remove uncertainty in the robot's sensory inputs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:06:46 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Faridghasemnia", "Mohamadreza", ""], ["Nardi", "Daniele", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "2011.10367", "submitter": "Neus Llop Torrent", "authors": "Neus Llop Torrent (1 and 2), Giorgio Visani (2 and 3), Enrico Bagli\n  (2) ((1) Politecnico di Milano Graduate School of Business, (2) CRIF S.p.A,\n  (3) University of Bologna School of Informatics and Engineering)", "title": "PSD2 Explainable AI Model for Credit Scoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to develop and test advanced analytical methods to\nimprove the prediction accuracy of Credit Risk Models, preserving at the same\ntime the model interpretability. In particular, the project focuses on applying\nan explainable machine learning model to PSD2-related databases. The input data\nwere obtained solely from synthetic account transactions generated from a pool\nof commercial banks from a pool of Italian commercial banks. Over the total\nproven models, CatBoost has shown the highest performance. The algorithm\nimplementation produces a GINI of 0.45 after tuning the hyper-parameters\ncombined with their inherent class-weight resampling method. SHAP package is\nused to provide a global and local interpretation of the model predictions to\nformulate a human-comprehensive approach to understanding the decision-maker\nalgorithm. The 20 most important features are selected using the Shapley values\nto present a full human-understandable model that reveals how the attributes of\nan individual are related to its model prediction.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:12:38 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 14:31:10 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Torrent", "Neus Llop", "", "1 and 2"], ["Visani", "Giorgio", "", "2 and 3"], ["Bagli", "Enrico", ""]]}, {"id": "2011.10381", "submitter": "Oh Kwanseok", "authors": "Kwanseok Oh, Jee Seok Yoon, Heung-Il Suk", "title": "Born Identity Network: Multi-way Counterfactual Map Generation to\n  Explain a Classifier's Decision", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists an apparent negative correlation between performance and\ninterpretability of deep learning models. In an effort to reduce this negative\ncorrelation, we propose a Born Identity Network (BIN), which is a post-hoc\napproach for producing multi-way counterfactual maps. A counterfactual map\ntransforms an input sample to be conditioned and classified as a target label,\nwhich is similar to how humans process knowledge through counterfactual\nthinking. For example, a counterfactual map can localize hypothetical\nabnormalities from a normal brain image that may cause it to be diagnosed with\na disease. Specifically, our proposed BIN consists of two core components:\nCounterfactual Map Generator and Target Attribution Network. The Counterfactual\nMap Generator is a variation of conditional GAN which can synthesize a\ncounterfactual map conditioned on an arbitrary target label. The Target\nAttribution Network provides adequate assistance for generating synthesized\nmaps by conditioning a target label into the Counterfactual Map Generator. We\nhave validated our proposed BIN in qualitative and quantitative analysis on\nMNIST, 3D Shapes, and ADNI datasets, and showed the comprehensibility and\nfidelity of our method from various ablation studies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:43:08 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 06:09:36 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 03:53:20 GMT"}, {"version": "v4", "created": "Thu, 8 Apr 2021 05:24:34 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Oh", "Kwanseok", ""], ["Yoon", "Jee Seok", ""], ["Suk", "Heung-Il", ""]]}, {"id": "2011.10389", "submitter": "Dominik Sisejkovic", "authors": "Dominik Sisejkovic, Farhad Merchant, Lennart M. Reimann, Harshit\n  Srivastava, Ahmed Hallawa and Rainer Leupers", "title": "Challenging the Security of Logic Locking Schemes in the Era of Deep\n  Learning: A Neuroevolutionary Approach", "comments": "25 pages, 17 figures, accepted at ACM JETC", "journal-ref": "ACM J. Emerg. Technol. Comput. Syst. 17, 3, Article 30 (May 2021),\n  26 pages", "doi": "10.1145/3431389", "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic locking is a prominent technique to protect the integrity of hardware\ndesigns throughout the integrated circuit design and fabrication flow. However,\nin recent years, the security of locking schemes has been thoroughly challenged\nby the introduction of various deobfuscation attacks. As in most research\nbranches, deep learning is being introduced in the domain of logic locking as\nwell. Therefore, in this paper we present SnapShot: a novel attack on logic\nlocking that is the first of its kind to utilize artificial neural networks to\ndirectly predict a key bit value from a locked synthesized gate-level netlist\nwithout using a golden reference. Hereby, the attack uses a simpler yet more\nflexible learning model compared to existing work. Two different approaches are\nevaluated. The first approach is based on a simple feedforward fully connected\nneural network. The second approach utilizes genetic algorithms to evolve more\ncomplex convolutional neural network architectures specialized for the given\ntask. The attack flow offers a generic and customizable framework for attacking\nlocking schemes using machine learning techniques. We perform an extensive\nevaluation of SnapShot for two realistic attack scenarios, comprising both\nreference benchmark circuits as well as silicon-proven RISC-V core modules. The\nevaluation results show that SnapShot achieves an average key prediction\naccuracy of 82.60% for the selected attack scenario, with a significant\nperformance increase of 10.49 percentage points compared to the state of the\nart. Moreover, SnapShot outperforms the existing technique on all evaluated\nbenchmarks. The results indicate that the security foundation of common logic\nlocking schemes is build on questionable assumptions. The conclusions of the\nevaluation offer insights into the challenges of designing future logic locking\nschemes that are resilient to machine learning attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:03:19 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 08:49:19 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Sisejkovic", "Dominik", ""], ["Merchant", "Farhad", ""], ["Reimann", "Lennart M.", ""], ["Srivastava", "Harshit", ""], ["Hallawa", "Ahmed", ""], ["Leupers", "Rainer", ""]]}, {"id": "2011.10396", "submitter": "Xiang Fang", "authors": "Xiang Fang, Yuchong Hu", "title": "Double Self-weighted Multi-view Clustering via Adaptive View Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view clustering has been applied in many real-world applications where\noriginal data often contain noises. Some graph-based multi-view clustering\nmethods have been proposed to try to reduce the negative influence of noises.\nHowever, previous graph-based multi-view clustering methods treat all features\nequally even if there are redundant features or noises, which is obviously\nunreasonable. In this paper, we propose a novel multi-view clustering framework\nDouble Self-weighted Multi-view Clustering (DSMC) to overcome the\naforementioned deficiency. DSMC performs double self-weighted operations to\nremove redundant features and noises from each graph, thereby obtaining robust\ngraphs. For the first self-weighted operation, it assigns different weights to\ndifferent features by introducing an adaptive weight matrix, which can\nreinforce the role of the important features in the joint representation and\nmake each graph robust. For the second self-weighting operation, it weights\ndifferent graphs by imposing an adaptive weight factor, which can assign larger\nweights to more robust graphs. Furthermore, by designing an adaptive multiple\ngraphs fusion, we can fuse the features in the different graphs to integrate\nthese graphs for clustering. Experiments on six real-world datasets demonstrate\nits advantages over other state-of-the-art multi-view clustering methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:23:01 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Fang", "Xiang", ""], ["Hu", "Yuchong", ""]]}, {"id": "2011.10406", "submitter": "Alex Bogatu", "authors": "Alex Bogatu, Norman W. Paton, Mark Douthwaite, Stuart Davie, Andre\n  Freitas", "title": "Cost-effective Variational Active Entity Resolution", "comments": null, "journal-ref": "2021 IEEE 37th International Conference on Data Engineering (ICDE)", "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurately identifying different representations of the same real-world\nentity is an integral part of data cleaning and many methods have been proposed\nto accomplish it. The challenges of this entity resolution task that demand so\nmuch research attention are often rooted in the task-specificity and\nuser-dependence of the process. Adopting deep learning techniques has the\npotential to lessen these challenges. In this paper, we set out to devise an\nentity resolution method that builds on the robustness conferred by deep\nautoencoders to reduce human-involvement costs. Specifically, we reduce the\ncost of training deep entity resolution models by performing unsupervised\nrepresentation learning. This unveils a transferability property of the\nresulting model that can further reduce the cost of applying the approach to\nnew datasets by means of transfer learning. Finally, we reduce the cost of\nlabelling training data through an active learning approach that builds on the\nproperties conferred by the use of deep autoencoders. Empirical evaluation\nconfirms the accomplishment of our cost-reduction desideratum while achieving\ncomparable effectiveness with state-of-the-art alternatives.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:47:11 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 19:29:35 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 11:13:27 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Bogatu", "Alex", ""], ["Paton", "Norman W.", ""], ["Douthwaite", "Mark", ""], ["Davie", "Stuart", ""], ["Freitas", "Andre", ""]]}, {"id": "2011.10426", "submitter": "Quoc Hung Ngo", "authors": "Quoc Thai Nguyen, Thoai Linh Nguyen, Ngoc Hoang Luong, and Quoc Hung\n  Ngo", "title": "Fine-Tuning BERT for Sentiment Analysis of Vietnamese Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment analysis is an important task in the field ofNature Language\nProcessing (NLP), in which users' feedbackdata on a specific issue are\nevaluated and analyzed. Manydeep learning models have been proposed to tackle\nthis task, including the recently-introduced Bidirectional Encoder\nRep-resentations from Transformers (BERT) model. In this paper,we experiment\nwith two BERT fine-tuning methods for thesentiment analysis task on datasets of\nVietnamese reviews: 1) a method that uses only the [CLS] token as the input for\nanattached feed-forward neural network, and 2) another methodin which all BERT\noutput vectors are used as the input forclassification. Experimental results on\ntwo datasets show thatmodels using BERT slightly outperform other models\nusingGloVe and FastText. Also, regarding the datasets employed inthis study,\nour proposed BERT fine-tuning method produces amodel with better performance\nthan the original BERT fine-tuning method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 14:45:46 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Nguyen", "Quoc Thai", ""], ["Nguyen", "Thoai Linh", ""], ["Luong", "Ngoc Hoang", ""], ["Ngo", "Quoc Hung", ""]]}, {"id": "2011.10435", "submitter": "Arnaud Fanthomme", "authors": "Arnaud Fanthomme (ENS Paris), R\\'emi Monasson (ENS Paris)", "title": "Low-Dimensional Manifolds Support Multiplexed Integrations in Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the learning dynamics and the representations emerging in Recurrent\nNeural Networks trained to integrate one or multiple temporal signals.\nCombining analytical and numerical investigations, we characterize the\nconditions under which a RNN with n neurons learns to integrate D(n) scalar\nsignals of arbitrary duration. We show, both for linear and ReLU neurons, that\nits internal state lives close to a D-dimensional manifold, whose shape is\nrelated to the activation function. Each neuron therefore carries, to various\ndegrees, information about the value of all integrals. We discuss the deep\nanalogy between our results and the concept of mixed selectivity forged by\ncomputational neuroscientists to interpret cortical recordings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 14:58:47 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Fanthomme", "Arnaud", "", "ENS Paris"], ["Monasson", "R\u00e9mi", "", "ENS Paris"]]}, {"id": "2011.10443", "submitter": "Ali Unlu", "authors": "Ali Unlu, Laurence Aitchison", "title": "Gradient Regularisation as Approximate Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference in Bayesian neural networks is usually performed using\nstochastic sampling which gives very high-variance gradients, and hence slow\nlearning. Here, we show that it is possible to obtain a deterministic\napproximation of the ELBO for a Bayesian neural network by doing a\nTaylor-series expansion around the mean of the current variational\ndistribution. The resulting approximate ELBO is the training-log-likelihood\nplus a squared gradient regulariser. In addition to learning the approximate\nposterior variance, we also consider a uniform-variance approximate posterior,\ninspired by the stationary distribution of SGD. The corresponding approximate\nELBO has a simple form, as the log-likelihood plus a simple squared-gradient\nregulariser. We argue that this squared-gradient regularisation may at the root\nof the excellent empirical performance of SGD.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:16:18 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Unlu", "Ali", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2011.10456", "submitter": "Noemi Mauro", "authors": "Noemi Mauro and Liliana Ardissono and Giovanna Petrone", "title": "User and Item-aware Estimation of Review Helpfulness", "comments": null, "journal-ref": "Information Processing & Management, Volume 58, Issue 1, 2021.\n  ISSN 0306-4573", "doi": "10.1016/j.ipm.2020.102434", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In online review sites, the analysis of user feedback for assessing its\nhelpfulness for decision-making is usually carried out by locally studying the\nproperties of individual reviews. However, global properties should be\nconsidered as well to precisely evaluate the quality of user feedback. In this\npaper we investigate the role of deviations in the properties of reviews as\nhelpfulness determinants with the intuition that \"out of the core\" feedback\nhelps item evaluation. We propose a novel helpfulness estimation model that\nextends previous ones with the analysis of deviations in rating, length and\npolarity with respect to the reviews written by the same person, or concerning\nthe same item. A regression analysis carried out on two large datasets of\nreviews extracted from Yelp social network shows that user-based deviations in\nreview length and rating clearly influence perceived helpfulness. Moreover, an\nexperiment on the same datasets shows that the integration of our helpfulness\nestimation model improves the performance of a collaborative recommender system\nby enhancing the selection of high-quality data for rating estimation. Our\nmodel is thus an effective tool to select relevant user feedback for\ndecision-making.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:35:56 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Mauro", "Noemi", ""], ["Ardissono", "Liliana", ""], ["Petrone", "Giovanna", ""]]}, {"id": "2011.10464", "submitter": "Xinyi Xu Mr", "authors": "Xinyi Xu and Lingjuan Lyu", "title": "A Reputation Mechanism Is All You Need: Collaborative Fairness and\n  Adversarial Robustness in Federated Learning", "comments": "Accepted as Oral presentation at International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2021 (FL-ICML'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging practical framework for effective and\nscalable machine learning among multiple participants, such as end users,\norganizations and companies. However, most existing FL or distributed learning\nframeworks have not well addressed two important issues together: collaborative\nfairness and adversarial robustness (e.g. free-riders and malicious\nparticipants). In conventional FL, all participants receive the global model\n(equal rewards), which might be unfair to the high-contributing participants.\nFurthermore, due to the lack of a safeguard mechanism, free-riders or malicious\nadversaries could game the system to access the global model for free or to\nsabotage it. In this paper, we propose a novel Robust and Fair Federated\nLearning (RFFL) framework to achieve collaborative fairness and adversarial\nrobustness simultaneously via a reputation mechanism. RFFL maintains a\nreputation for each participant by examining their contributions via their\nuploaded gradients (using vector similarity) and thus identifies\nnon-contributing or malicious participants to be removed. Our approach\ndifferentiates itself by not requiring any auxiliary/validation dataset.\nExtensive experiments on benchmark datasets show that RFFL can achieve high\nfairness and is very robust to different types of adversaries while achieving\ncompetitive predictive accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:52:45 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 12:39:59 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Xu", "Xinyi", ""], ["Lyu", "Lingjuan", ""]]}, {"id": "2011.10465", "submitter": "Chen Zuge", "authors": "Wu Kehe, Chen Zuge, Zhang Xiaoliang, Li Wei", "title": "Improvement of Classification in One-Stage Detector", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RetinaNet proposed Focal Loss for classification task and improved one-stage\ndetectors greatly. However, there is still a gap between it and two-stage\ndetectors. We analyze the prediction of RetinaNet and find that the\nmisalignment of classification and localization is the main factor. Most of\npredicted boxes, whose IoU with ground-truth boxes are greater than 0.5, while\ntheir classification scores are lower than 0.5, which shows that the\nclassification task still needs to be optimized. In this paper we proposed an\nobject confidence task for this problem, and it shares features with\nclassification task. This task uses IoUs between samples and ground-truth boxes\nas targets, and it only uses losses of positive samples in training, which can\nincrease loss weight of positive samples in classification task training. Also\nthe joint of classification score and object confidence will be used to guide\nNMS. Our method can not only improve classification task, but also ease\nmisalignment of classification and localization. To evaluate the effectiveness\nof this method, we show our experiments on MS COCO 2017 dataset. Without\nwhistles and bells, our method can improve AP by 0.7% and 1.0% on COCO\nvalidation dataset with ResNet50 and ResNet101 respectively at same training\nconfigs, and it can achieve 38.4% AP with two times training time. Code is at:\nhttp://github.com/chenzuge1/RetinaNet-Conf.git.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:56:44 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Kehe", "Wu", ""], ["Zuge", "Chen", ""], ["Xiaoliang", "Zhang", ""], ["Wei", "Li", ""]]}, {"id": "2011.10469", "submitter": "Sam Davis", "authors": "Sam Davis, Giuseppe Coccia, Sam Gooch, Julian Mack", "title": "Empirical Evaluation of Deep Learning Model Compression Techniques on\n  the WaveNet Vocoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  WaveNet is a state-of-the-art text-to-speech vocoder that remains challenging\nto deploy due to its autoregressive loop. In this work we focus on ways to\naccelerate the original WaveNet architecture directly, as opposed to modifying\nthe architecture, such that the model can be deployed as part of a scalable\ntext-to-speech system. We survey a wide variety of model compression techniques\nthat are amenable to deployment on a range of hardware platforms. In\nparticular, we compare different model sparsity methods and levels, and seven\nwidely used precisions as targets for quantization; and are able to achieve\nmodels with a compression ratio of up to 13.84 without loss in audio fidelity\ncompared to a dense, single-precision floating-point baseline. All techniques\nare implemented using existing open source deep learning frameworks and\nlibraries to encourage their wider adoption.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:01:56 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Davis", "Sam", ""], ["Coccia", "Giuseppe", ""], ["Gooch", "Sam", ""], ["Mack", "Julian", ""]]}, {"id": "2011.10470", "submitter": "Milad Asgari Mehrabadi", "authors": "Milad Asgari Mehrabadi, Seyed Amir Hossein Aqajari, Iman Azimi,\n  Charles A Downs, Nikil Dutt and Amir M Rahmani", "title": "Detection of COVID-19 Using Heart Rate and Blood Pressure: Lessons\n  Learned from Patients with ARDS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world has been affected by COVID-19 coronavirus. At the time of this\nstudy, the number of infected people in the United States is the highest\nglobally (7.9 million infections). Within the infected population, patients\ndiagnosed with acute respiratory distress syndrome (ARDS) are in more\nlife-threatening circumstances, resulting in severe respiratory system failure.\nVarious studies have investigated the infections to COVID-19 and ARDS by\nmonitoring laboratory metrics and symptoms. Unfortunately, these methods are\nmerely limited to clinical settings, and symptom-based methods are shown to be\nineffective. In contrast, vital signs (e.g., heart rate) have been utilized to\nearly-detect different respiratory diseases in ubiquitous health monitoring. We\nposit that such biomarkers are informative in identifying ARDS patients\ninfected with COVID-19. In this study, we investigate the behavior of COVID-19\non ARDS patients by utilizing simple vital signs. We analyze the long-term\ndaily logs of blood pressure and heart rate associated with 70 ARDS patients\nadmitted to five University of California academic health centers (containing\n42506 samples for each vital sign) to distinguish subjects with COVID-19\npositive and negative test results. In addition to the statistical analysis, we\ndevelop a deep neural network model to extract features from the longitudinal\ndata. Using only the first eight days of the data, our deep learning model is\nable to achieve 78.79% accuracy to classify the vital signs of ARDS patients\ninfected with COVID-19 versus other ARDS diagnosed patients.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 19:56:27 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Mehrabadi", "Milad Asgari", ""], ["Aqajari", "Seyed Amir Hossein", ""], ["Azimi", "Iman", ""], ["Downs", "Charles A", ""], ["Dutt", "Nikil", ""], ["Rahmani", "Amir M", ""]]}, {"id": "2011.10475", "submitter": "Jong Chul Ye", "authors": "Eunju Cha, Chanseok Lee, Mooseok Jang, and Jong Chul Ye", "title": "DeepPhaseCut: Deep Relaxation in Phase for Unsupervised Fourier Phase\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier phase retrieval is a classical problem of restoring a signal only\nfrom the measured magnitude of its Fourier transform. Although Fienup-type\nalgorithms, which use prior knowledge in both spatial and Fourier domains, have\nbeen widely used in practice, they can often stall in local minima. Modern\nmethods such as PhaseLift and PhaseCut may offer performance guarantees with\nthe help of convex relaxation. However, these algorithms are usually\ncomputationally intensive for practical use. To address this problem, we\npropose a novel, unsupervised, feed-forward neural network for Fourier phase\nretrieval which enables immediate high quality reconstruction. Unlike the\nexisting deep learning approaches that use a neural network as a regularization\nterm or an end-to-end blackbox model for supervised training, our algorithm is\na feed-forward neural network implementation of PhaseCut algorithm in an\nunsupervised learning framework. Specifically, our network is composed of two\ngenerators: one for the phase estimation using PhaseCut loss, followed by\nanother generator for image reconstruction, all of which are trained\nsimultaneously using a cycleGAN framework without matched data. The link to the\nclassical Fienup-type algorithms and the recent symmetry-breaking learning\napproach is also revealed. Extensive experiments demonstrate that the proposed\nmethod outperforms all existing approaches in Fourier phase retrieval problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:10:08 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Cha", "Eunju", ""], ["Lee", "Chanseok", ""], ["Jang", "Mooseok", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2011.10478", "submitter": "Grigorios G. Anagnostopoulos Dr.", "authors": "Grigorios G. Anagnostopoulos and Alexandros Kalousis", "title": "Analysing the Data-Driven Approach of Dynamically Estimating Positioning\n  Accuracy", "comments": "Author's accepted manuscript version. Accepted for publication in\n  IEEE ICC 2021, IoT and Sensor Networks Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The primary expectation from positioning systems is for them to provide the\nusers with reliable estimates of their position. An additional piece of\ninformation that can greatly help the users utilize position estimates is the\nlevel of uncertainty that a positioning system assigns to the position estimate\nit produced. The concept of dynamically estimating the accuracy of position\nestimates of fingerprinting positioning systems has been sporadically discussed\nover the last decade in the literature of the field, where mainly handcrafted\nrules based on domain knowledge have been proposed. The emergence of IoT\ndevices and the proliferation of data from Low Power Wide Area Networks\n(LPWANs) have facilitated the conceptualization of data-driven methods of\ndetermining the estimated certainty over position estimates. In this work, we\nanalyze the data-driven approach of determining the Dynamic Accuracy Estimation\n(DAE), considering it in the broader context of a positioning system. More\nspecifically, with the use of a public LoRaWAN dataset, the current work\nanalyses: the repartition of the available training set between the tasks of\ndetermining the location estimates and the DAE, the concept of selecting a\nsubset of the most reliable estimates, and the impact that the spatial\ndistribution of the data has to the accuracy of the DAE. The work provides a\nwide overview of the data-driven approach of DAE determination in the context\nof the overall design of a positioning system.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:18:27 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 13:09:10 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Anagnostopoulos", "Grigorios G.", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "2011.10480", "submitter": "Zhongyang Li", "authors": "Zhongyang Li and Fei Lu", "title": "On the coercivity condition in the learning of interacting particle\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the learning of systems of interacting particles or agents, coercivity\ncondition ensures identifiability of the interaction functions, providing the\nfoundation of learning by nonparametric regression. The coercivity condition is\nequivalent to the strictly positive definiteness of an integral kernel arising\nin the learning. We show that for a class of interaction functions such that\nthe system is ergodic, the integral kernel is strictly positive definite, and\nhence the coercivity condition holds true.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:20:06 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Li", "Zhongyang", ""], ["Lu", "Fei", ""]]}, {"id": "2011.10487", "submitter": "Konstantinos Spiliopoulos", "authors": "Jiahui Yu and Konstantinos Spiliopoulos", "title": "Normalization effects on shallow neural networks and related asymptotic\n  expansions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider shallow (single hidden layer) neural networks and characterize\ntheir performance when trained with stochastic gradient descent as the number\nof hidden units $N$ and gradient descent steps grow to infinity. In particular,\nwe investigate the effect of different scaling schemes, which lead to different\nnormalizations of the neural network, on the network's statistical output,\nclosing the gap between the $1/\\sqrt{N}$ and the mean-field $1/N$\nnormalization. We develop an asymptotic expansion for the neural network's\nstatistical output pointwise with respect to the scaling parameter as the\nnumber of hidden units grows to infinity. Based on this expansion, we\ndemonstrate mathematically that to leading order in $N$, there is no\nbias-variance trade off, in that both bias and variance (both explicitly\ncharacterized) decrease as the number of hidden units increases and time grows.\nIn addition, we show that to leading order in $N$, the variance of the neural\nnetwork's statistical output decays as the implied normalization by the scaling\nparameter approaches the mean field normalization. Numerical studies on the\nMNIST and CIFAR10 datasets show that test and train accuracy monotonically\nimprove as the neural network's normalization gets closer to the mean field\nnormalization.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:33:28 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 17:59:19 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yu", "Jiahui", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "2011.10492", "submitter": "Thai Le", "authors": "Thai Le, Noseong Park, Dongwon Lee", "title": "A Sweet Rabbit Hole by DARCY: Using Honeypots to Detect Universal\n  Trigger's Adversarial Attacks", "comments": "Accepted to the 59th Annual Meeting of the Association for\n  Computational Linguistics (ACL) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Universal Trigger (UniTrigger) is a recently-proposed powerful\nadversarial textual attack method. Utilizing a learning-based mechanism,\nUniTrigger generates a fixed phrase that, when added to any benign inputs, can\ndrop the prediction accuracy of a textual neural network (NN) model to near\nzero on a target class. To defend against this attack that can cause\nsignificant harm, in this paper, we borrow the \"honeypot\" concept from the\ncybersecurity community and propose DARCY, a honeypot-based defense framework\nagainst UniTrigger. DARCY greedily searches and injects multiple trapdoors into\nan NN model to \"bait and catch\" potential attacks. Through comprehensive\nexperiments across four public datasets, we show that DARCY detects\nUniTrigger's adversarial attacks with up to 99% TPR and less than 2% FPR in\nmost cases, while maintaining the prediction accuracy (in F1) for clean inputs\nwithin a 1% margin. We also demonstrate that DARCY with multiple trapdoors is\nalso robust to a diverse set of attack scenarios with attackers' varying levels\nof knowledge and skills. Source code will be released upon the acceptance of\nthis paper.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 16:38:28 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 18:14:53 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 20:53:25 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Le", "Thai", ""], ["Park", "Noseong", ""], ["Lee", "Dongwon", ""]]}, {"id": "2011.10505", "submitter": "Leonid Mill", "authors": "Leonid Mill, David Wolff, Nele Gerrits, Patrick Philipp, Lasse Kling,\n  Florian Vollnhals, Andrew Ignatenko, Christian Jaremenko, Yixing Huang,\n  Olivier De Castro, Jean-Nicolas Audinot, Inge Nelissen, Tom Wirtz, Andreas\n  Maier, Silke Christiansen", "title": "Synthetic Image Rendering Solves Annotation Problem in Deep Learning\n  Nanoparticle Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci cs.CV eess.IV physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nanoparticles occur in various environments as a consequence of man-made\nprocesses, which raises concerns about their impact on the environment and\nhuman health. To allow for proper risk assessment, a precise and statistically\nrelevant analysis of particle characteristics (such as e.g. size, shape and\ncomposition) is required that would greatly benefit from automated image\nanalysis procedures. While deep learning shows impressive results in object\ndetection tasks, its applicability is limited by the amount of representative,\nexperimentally collected and manually annotated training data. Here, we present\nan elegant, flexible and versatile method to bypass this costly and tedious\ndata acquisition process. We show that using a rendering software allows to\ngenerate realistic, synthetic training data to train a state-of-the art deep\nneural network. Using this approach, we derive a segmentation accuracy that is\ncomparable to man-made annotations for toxicologically relevant metal-oxide\nnanoparticle ensembles which we chose as examples. Our study paves the way\ntowards the use of deep learning for automated, high-throughput particle\ndetection in a variety of imaging techniques such as microscopies and\nspectroscopies, for a wide variety of studies and applications, including the\ndetection of plastic micro- and nanoparticles.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 17:05:36 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Mill", "Leonid", ""], ["Wolff", "David", ""], ["Gerrits", "Nele", ""], ["Philipp", "Patrick", ""], ["Kling", "Lasse", ""], ["Vollnhals", "Florian", ""], ["Ignatenko", "Andrew", ""], ["Jaremenko", "Christian", ""], ["Huang", "Yixing", ""], ["De Castro", "Olivier", ""], ["Audinot", "Jean-Nicolas", ""], ["Nelissen", "Inge", ""], ["Wirtz", "Tom", ""], ["Maier", "Andreas", ""], ["Christiansen", "Silke", ""]]}, {"id": "2011.10510", "submitter": "M Quamer Nasim", "authors": "M Quamer Nasim, Tannistha Maiti, Ayush Srivastava, Tarry Singh, and\n  Jie Mei", "title": "Seismic Facies Analysis: A Deep Domain Adaptation Approach", "comments": "18 pages, 10 figures, 5 tables, and supplementary material included\n  in the end of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.AI cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural networks (DNNs) can learn accurately from large quantities of\nlabeled input data, but DNNs sometimes fail to generalize to test data sampled\nfrom different input distributions. Unsupervised Deep Domain Adaptation (DDA)\nproves useful when no input labels are available, and distribution shifts are\nobserved in the target domain (TD). Experiments are performed on seismic images\nof the F3 block 3D dataset from offshore Netherlands (source domain; SD) and\nPenobscot 3D survey data from Canada (target domain; TD). Three geological\nclasses from SD and TD that have similar reflection patterns are considered. In\nthe present study, an improved deep neural network architecture named\nEarthAdaptNet (EAN) is proposed to semantically segment the seismic images. We\nspecifically use a transposed residual unit to replace the traditional dilated\nconvolution in the decoder block. The EAN achieved a pixel-level accuracy >84%\nand an accuracy of ~70% for the minority classes, showing improved performance\ncompared to existing architectures. In addition, we introduced the CORAL\n(Correlation Alignment) method to the EAN to create an unsupervised deep domain\nadaptation network (EAN-DDA) for the classification of seismic reflections\nfromF3 and Penobscot. Maximum class accuracy achieved was ~99% for class 2 of\nPenobscot with >50% overall accuracy. Taken together, EAN-DDA has the potential\nto classify target domain seismic facies classes with high accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 17:09:06 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 18:27:06 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Nasim", "M Quamer", ""], ["Maiti", "Tannistha", ""], ["Srivastava", "Ayush", ""], ["Singh", "Tarry", ""], ["Mei", "Jie", ""]]}, {"id": "2011.10518", "submitter": "Amanuel Alambo", "authors": "Amanuel Alambo, Swati Padhee, Tanvi Banerjee, and Krishnaprasad\n  Thirunarayan", "title": "COVID-19 and Mental Health/Substance Use Disorders on Reddit: A\n  Longitudinal Study", "comments": "First workshop on computational & affective intelligence in\n  healthcare applications in conjunction with ICPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic has adversely and disproportionately impacted people\nsuffering from mental health issues and substance use problems. This has been\nexacerbated by social isolation during the pandemic and the social stigma\nassociated with mental health and substance use disorders, making people\nreluctant to share their struggles and seek help. Due to the anonymity and\nprivacy they provide, social media emerged as a convenient medium for people to\nshare their experiences about their day to day struggles. Reddit is a\nwell-recognized social media platform that provides focused and structured\nforums called subreddits, that users subscribe to and discuss their experiences\nwith others. Temporal assessment of the topical correlation between social\nmedia postings about mental health/substance use and postings about Coronavirus\nis crucial to better understand public sentiment on the pandemic and its\nevolving impact, especially related to vulnerable populations. In this study,\nwe conduct a longitudinal topical analysis of postings between subreddits\nr/depression, r/Anxiety, r/SuicideWatch, and r/Coronavirus, and postings\nbetween subreddits r/opiates, r/OpiatesRecovery, r/addiction, and r/Coronavirus\nfrom January 2020 - October 2020. Our results show a high topical correlation\nbetween postings in r/depression and r/Coronavirus in September 2020. Further,\nthe topical correlation between postings on substance use disorders and\nCoronavirus fluctuates, showing the highest correlation in August 2020. By\nmonitoring these trends from platforms such as Reddit, epidemiologists, and\nmental health professionals can gain insights into the challenges faced by\ncommunities for targeted interventions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 17:23:49 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Alambo", "Amanuel", ""], ["Padhee", "Swati", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""]]}, {"id": "2011.10530", "submitter": "Jacob Biamonte D", "authors": "Alexey Uvarov and Jacob Biamonte", "title": "On barren plateaus and cost function locality in variational quantum\n  algorithms", "comments": "26 pages, RevTeX", "journal-ref": "Journal of Physics A: Mathematical and Theoretical 54 (24), 245301\n  (2021)", "doi": "10.1088/1751-8121/abfac7", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational quantum algorithms rely on gradient based optimization to\niteratively minimize a cost function evaluated by measuring output(s) of a\nquantum processor. A barren plateau is the phenomenon of exponentially\nvanishing gradients in sufficiently expressive parametrized quantum circuits.\nIt has been established that the onset of a barren plateau regime depends on\nthe cost function, although the particular behavior has been demonstrated only\nfor certain classes of cost functions. Here we derive a lower bound on the\nvariance of the gradient, which depends mainly on the width of the circuit\ncausal cone of each term in the Pauli decomposition of the cost function. Our\nresult further clarifies the conditions under which barren plateaus can occur.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:00:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Uvarov", "Alexey", ""], ["Biamonte", "Jacob", ""]]}, {"id": "2011.10545", "submitter": "Evaldas Vaiciukynas Dr.", "authors": "Evaldas Vaiciukynas, Paulius Danenas, Vilius Kontrimas, Rimantas\n  Butleris", "title": "Meta-Learning for Time Series Forecasting Ensemble", "comments": "Submitted for review to Journal of Forecasting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amounts of historical data collected increase together with business\nintelligence applicability and demands for automatic forecasting of time\nseries. While no single time series modeling method is universal to all types\nof dynamics, forecasting using ensemble of several methods is often seen as a\ncompromise. Instead of fixing ensemble diversity and size we propose to\nadaptively predict these aspects using meta-learning. Meta-learning here\nconsiders two separate random forest regression models, built on 390 time\nseries features, to rank 22 univariate forecasting methods and to recommend\nensemble size. Forecasting ensemble is consequently formed from methods ranked\nas the best and forecasts are pooled using either simple or weighted average\n(with weight corresponding to reciprocal rank). Proposed approach was tested on\n12561 micro-economic time series (expanded to 38633 for various forecasting\nhorizons) of M4 competition where meta-learning outperformed Theta and Comb\nbenchmarks by relative forecasting errors for all data types and horizons. Best\noverall results were achieved by weighted pooling with symmetric mean absolute\npercentage error of 9.21% versus 11.05% obtained using Theta method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:35:02 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Vaiciukynas", "Evaldas", ""], ["Danenas", "Paulius", ""], ["Kontrimas", "Vilius", ""], ["Butleris", "Rimantas", ""]]}, {"id": "2011.10549", "submitter": "Ankith Mohan", "authors": "Ankith Mohan, Aiichiro Nakano, Emilio Ferrara", "title": "Graph Signal Recovery Using Restricted Boltzmann Machines", "comments": "Paper: 27 pages, 9 figures. Appendix: 5 pages, 12 figures. Submitted\n  to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a model-agnostic pipeline to recover graph signals from an expert\nsystem by exploiting the content addressable memory property of restricted\nBoltzmann machine and the representational ability of a neural network. The\nproposed pipeline requires the deep neural network that is trained on a\ndownward machine learning task with clean data, data which is free from any\nform of corruption or incompletion. We show that denoising the representations\nlearned by the deep neural networks is usually more effective than denoising\nthe data itself. Although this pipeline can deal with noise in any dataset, it\nis particularly effective for graph-structured datasets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:43:53 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Mohan", "Ankith", ""], ["Nakano", "Aiichiro", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2011.10562", "submitter": "Anubhav Guha", "authors": "Anubhav Guha and Anuradha Annaswamy", "title": "MRAC-RL: A Framework for On-Line Policy Adaptation Under Parametric\n  Model Uncertainty", "comments": "Short version submitted to Learning for Dynamics & Control (L4DC)\n  2021 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) algorithms have been successfully used to develop\ncontrol policies for dynamical systems. For many such systems, these policies\nare trained in a simulated environment. Due to discrepancies between the\nsimulated model and the true system dynamics, RL trained policies often fail to\ngeneralize and adapt appropriately when deployed in the real-world environment.\nCurrent research in bridging this sim-to-real gap has largely focused on\nimprovements in simulation design and on the development of improved and\nspecialized RL algorithms for robust control policy generation. In this paper\nwe apply principles from adaptive control and system identification to develop\nthe model-reference adaptive control & reinforcement learning (MRAC-RL)\nframework. We propose a set of novel MRAC algorithms applicable to a broad\nrange of linear and nonlinear systems, and derive the associated control laws.\nThe MRAC-RL framework utilizes an inner-loop adaptive controller that allows a\nsimulation-trained outer-loop policy to adapt and operate effectively in a test\nenvironment, even when parametric model uncertainty exists. We demonstrate that\nthe MRAC-RL approach improves upon state-of-the-art RL algorithms in developing\ncontrol policies that can be applied to systems with modeling errors.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:55:53 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Guha", "Anubhav", ""], ["Annaswamy", "Anuradha", ""]]}, {"id": "2011.10563", "submitter": "Konstantinos Kousias", "authors": "Konstantinos Kousias, Apostolos Pappas, Ozgu Alay, Antonios Argyriou\n  and Michael Riegler", "title": "Long Short Term Memory Networks for Bandwidth Forecasting in Mobile\n  Broadband Networks under Mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bandwidth forecasting in Mobile Broadband (MBB) networks is a challenging\ntask, particularly when coupled with a degree of mobility. In this work, we\nintroduce HINDSIGHT++, an open-source R-based framework for bandwidth\nforecasting experimentation in MBB networks with Long Short Term Memory (LSTM)\nnetworks. We instrument HINDSIGHT++ following an Automated Machine Learning\n(AutoML) paradigm to first, alleviate the burden of data preprocessing, and\nsecond, enhance performance related aspects. We primarily focus on bandwidth\nforecasting for Fifth Generation (5G) networks. In particular, we leverage\n5Gophers, the first open-source attempt to measure network performance on\noperational 5G networks in the US. We further explore the LSTM performance\nboundaries on Fourth Generation (4G) commercial settings using NYU-METS, an\nopen-source dataset comprising of hundreds of bandwidth traces spanning\ndifferent mobility scenarios. Our study aims to investigate the impact of\nhyperparameter optimization on achieving state-of-the-art performance and\nbeyond. Results highlight its significance under 5G scenarios showing an\naverage Mean Absolute Error (MAE) decrease of near 30% when compared to prior\nstate-of-the-art values. Due to its universal design, we argue that HINDSIGHT++\ncan serve as a handy software tool for a multitude of applications in other\nscientific fields.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:59:27 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Kousias", "Konstantinos", ""], ["Pappas", "Apostolos", ""], ["Alay", "Ozgu", ""], ["Argyriou", "Antonios", ""], ["Riegler", "Michael", ""]]}, {"id": "2011.10566", "submitter": "Xinlei Chen", "authors": "Xinlei Chen and Kaiming He", "title": "Exploring Simple Siamese Representation Learning", "comments": "Technical report, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Siamese networks have become a common structure in various recent models for\nunsupervised visual representation learning. These models maximize the\nsimilarity between two augmentations of one image, subject to certain\nconditions for avoiding collapsing solutions. In this paper, we report\nsurprising empirical results that simple Siamese networks can learn meaningful\nrepresentations even using none of the following: (i) negative sample pairs,\n(ii) large batches, (iii) momentum encoders. Our experiments show that\ncollapsing solutions do exist for the loss and structure, but a stop-gradient\noperation plays an essential role in preventing collapsing. We provide a\nhypothesis on the implication of stop-gradient, and further show\nproof-of-concept experiments verifying it. Our \"SimSiam\" method achieves\ncompetitive results on ImageNet and downstream tasks. We hope this simple\nbaseline will motivate people to rethink the roles of Siamese architectures for\nunsupervised representation learning. Code will be made available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 18:59:33 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Chen", "Xinlei", ""], ["He", "Kaiming", ""]]}, {"id": "2011.10568", "submitter": "Nishant Sinha", "authors": "Azhar Shaikh, Nishant Sinha", "title": "Learn to Bind and Grow Neural Structures", "comments": "Accepted to 8th ACM IKDD CODS and 26th COMAD (CODS-COMAD '21)\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Task-incremental learning involves the challenging problem of learning new\ntasks continually, without forgetting past knowledge. Many approaches address\nthe problem by expanding the structure of a shared neural network as tasks\narrive, but struggle to grow optimally, without losing past knowledge. We\npresent a new framework, Learn to Bind and Grow, which learns a neural\narchitecture for a new task incrementally, either by binding with layers of a\nsimilar task or by expanding layers which are more likely to conflict between\ntasks. Central to our approach is a novel, interpretable, parameterization of\nthe shared, multi-task architecture space, which then enables computing\nglobally optimal architectures using Bayesian optimization. Experiments on\ncontinual learning benchmarks show that our framework performs comparably with\nearlier expansion based approaches and is able to flexibly compute multiple\noptimal solutions with performance-size trade-offs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 09:40:26 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shaikh", "Azhar", ""], ["Sinha", "Nishant", ""]]}, {"id": "2011.10575", "submitter": "Ruby Sedgwick", "authors": "Ruby Sedgwick, John Goertz, Molly Stevens, Ruth Misener, Mark van der\n  Wilk", "title": "Design of Experiments for Verifying Biomolecular Networks", "comments": "Comment: Updated to correct typo \"that that\" => \"that\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a growing trend in molecular and synthetic biology of using\nmechanistic (non machine learning) models to design biomolecular networks. Once\ndesigned, these networks need to be validated by experimental results to ensure\nthe theoretical network correctly models the true system. However, these\nexperiments can be expensive and time consuming. We propose a design of\nexperiments approach for validating these networks efficiently. Gaussian\nprocesses are used to construct a probabilistic model of the discrepancy\nbetween experimental results and the designed response, then a Bayesian\noptimization strategy used to select the next sample points. We compare\ndifferent design criteria and develop a stopping criterion based on a metric\nthat quantifies this discrepancy over the whole surface, and its uncertainty.\nWe test our strategy on simulated data from computer models of biochemical\nprocesses.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:39:45 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 10:51:24 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Sedgwick", "Ruby", ""], ["Goertz", "John", ""], ["Stevens", "Molly", ""], ["Misener", "Ruth", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2011.10577", "submitter": "Luisa Lucie-Smith", "authors": "Luisa Lucie-Smith, Hiranya V. Peiris, Andrew Pontzen, Brian Nord,\n  Jeyan Thiyagalingam", "title": "Deep learning insights into cosmological structure formation", "comments": "15 pages, 6 figures, to be submitted to Nature Communications,\n  comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the evolution of linear initial conditions present in the early\nuniverse into extended halos of dark matter at late times can be computed using\ncosmological simulations, a theoretical understanding of this complex process\nremains elusive. Here, we build a deep learning framework to learn this\nnon-linear relationship, and develop techniques to physically interpret the\nlearnt mapping. A three-dimensional convolutional neural network (CNN) is\ntrained to predict the mass of dark matter halos from the initial conditions.\nWe find no change in the predictive accuracy of the model if we retrain the\nmodel removing anisotropic information from the inputs. This suggests that the\nfeatures learnt by the CNN are equivalent to spherical averages over the\ninitial conditions. Our results indicate that interpretable deep learning\nframeworks can provide a powerful tool for extracting insight into cosmological\nstructure formation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 19:00:00 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lucie-Smith", "Luisa", ""], ["Peiris", "Hiranya V.", ""], ["Pontzen", "Andrew", ""], ["Nord", "Brian", ""], ["Thiyagalingam", "Jeyan", ""]]}, {"id": "2011.10596", "submitter": "Armin Lederer", "authors": "Armin Lederer, Alexandre Capone, Thomas Beckers, Jonas Umlauft, Sandra\n  Hirche", "title": "The Value of Data in Learning-Based Control for Training Subset\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the existence of formal guarantees for learning-based control\napproaches, the relationship between data and control performance is still\npoorly understood. In this paper, we present a measure to quantify the value of\ndata within the context of a predefined control task. Our approach is\napplicable to a wide variety of unknown nonlinear systems that are to be\ncontrolled by a generic learning-based control law. We model the unknown\ncomponent of the system using Gaussian processes, which in turn allows us to\ndirectly assess the impact of model uncertainty on control. Results obtained in\nnumerical simulations indicate the efficacy of the proposed measure.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 19:10:01 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lederer", "Armin", ""], ["Capone", "Alexandre", ""], ["Beckers", "Thomas", ""], ["Umlauft", "Jonas", ""], ["Hirche", "Sandra", ""]]}, {"id": "2011.10600", "submitter": "Yasser Dahou", "authors": "Yasser Dahou, Marouane Tliba, Kevin McGuinness, Noel O'Connor", "title": "ATSal: An Attention Based Architecture for Saliency Prediction in 360\n  Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The spherical domain representation of 360 video/image presents many\nchallenges related to the storage, processing, transmission and rendering of\nomnidirectional videos (ODV). Models of human visual attention can be used so\nthat only a single viewport is rendered at a time, which is important when\ndeveloping systems that allow users to explore ODV with head mounted displays\n(HMD). Accordingly, researchers have proposed various saliency models for 360\nvideo/images. This paper proposes ATSal, a novel attention based (head-eye)\nsaliency model for 360\\degree videos. The attention mechanism explicitly\nencodes global static visual attention allowing expert models to focus on\nlearning the saliency on local patches throughout consecutive frames. We\ncompare the proposed approach to other state-of-the-art saliency models on two\ndatasets: Salient360! and VR-EyeTracking. Experimental results on over 80 ODV\nvideos (75K+ frames) show that the proposed method outperforms the existing\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 19:19:48 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Dahou", "Yasser", ""], ["Tliba", "Marouane", ""], ["McGuinness", "Kevin", ""], ["O'Connor", "Noel", ""]]}, {"id": "2011.10605", "submitter": "Junhyeok Ahn", "authors": "Junhyeok Ahn and Luis Sentis", "title": "Nested Mixture of Experts: Cooperative and Competitive Learning of\n  Hybrid Dynamical System", "comments": "Accepted to 2021 L4DC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) algorithms can attain significant\nsample efficiency but require an appropriate network structure to represent\nsystem dynamics. Current approaches include white-box modeling using analytic\nparameterizations and black-box modeling using deep neural networks. However,\nboth can suffer from a bias-variance trade-off in the learning process, and\nneither provides a structured method for injecting domain knowledge into the\nnetwork. As an alternative, gray-box modeling leverages prior knowledge in\nneural network training but only for simple systems. In this paper, we devise a\nnested mixture of experts (NMOE) for representing and learning hybrid dynamical\nsystems. An NMOE combines both white-box and black-box models while optimizing\nbias-variance trade-off. Moreover, an NMOE provides a structured method for\nincorporating various types of prior knowledge by training the associative\nexperts cooperatively or competitively. The prior knowledge includes\ninformation on robots' physical contacts with the environments as well as their\nkinematic and dynamic properties. In this paper, we demonstrate how to\nincorporate prior knowledge into our NMOE in various continuous control\ndomains, including hybrid dynamical systems. We also show the effectiveness of\nour method in terms of data-efficiency, generalization to unseen data, and\nbias-variance trade-off. Finally, we evaluate our NMOE using an MBRL setup,\nwhere the model is integrated with a model-based controller and trained online.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 19:36:45 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 06:08:56 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Ahn", "Junhyeok", ""], ["Sentis", "Luis", ""]]}, {"id": "2011.10607", "submitter": "Christopher Dean", "authors": "Christopher L. Dean, Stephen J. Lee, Jason Pacheco, John W. Fisher III", "title": "Lightweight Data Fusion with Conjugate Mappings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to data fusion that combines the interpretability of\nstructured probabilistic graphical models with the flexibility of neural\nnetworks. The proposed method, lightweight data fusion (LDF), emphasizes\nposterior analysis over latent variables using two types of information:\nprimary data, which are well-characterized but with limited availability, and\nauxiliary data, readily available but lacking a well-characterized statistical\nrelationship to the latent quantity of interest. The lack of a forward model\nfor the auxiliary data precludes the use of standard data fusion approaches,\nwhile the inability to acquire latent variable observations severely limits\ndirect application of most supervised learning methods. LDF addresses these\nissues by utilizing neural networks as conjugate mappings of the auxiliary\ndata: nonlinear transformations into sufficient statistics with respect to the\nlatent variables. This facilitates efficient inference by preserving the\nconjugacy properties of the primary data and leads to compact representations\nof the latent variable posterior distributions. We demonstrate the LDF\nmethodology on two challenging inference problems: (1) learning electrification\nrates in Rwanda from satellite imagery, high-level grid infrastructure, and\nother sources; and (2) inferring county-level homicide rates in the USA by\nintegrating socio-economic data using a mixture model of multiple conjugate\nmappings.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 19:47:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Dean", "Christopher L.", ""], ["Lee", "Stephen J.", ""], ["Pacheco", "Jason", ""], ["Fisher", "John W.", "III"]]}, {"id": "2011.10614", "submitter": "James Stokes", "authors": "Tianchen Zhao, James Stokes, Oliver Knitter, Brian Chen, Shravan\n  Veerapaneni", "title": "Meta Variational Monte Carlo", "comments": "To appear at the Third Workshop on Machine Learning and the Physical\n  Sciences (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An identification is found between meta-learning and the problem of\ndetermining the ground state of a randomly generated Hamiltonian drawn from a\nknown ensemble. A model-agnostic meta-learning approach is proposed to solve\nthe associated learning problem and a preliminary experimental study of random\nMax-Cut problems indicates that the resulting Meta Variational Monte Carlo\naccelerates training and improves convergence.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 20:11:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhao", "Tianchen", ""], ["Stokes", "James", ""], ["Knitter", "Oliver", ""], ["Chen", "Brian", ""], ["Veerapaneni", "Shravan", ""]]}, {"id": "2011.10615", "submitter": "Tom Grimes", "authors": "Tom Grimes, Eric Church, William Pitts, Lynn Wood, Eva Brayfindley,\n  Luke Erikson, Mark Greaves", "title": "Adversarial Training for EM Classification Networks", "comments": "10 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel variant of Domain Adversarial Networks with impactful\nimprovements to the loss functions, training paradigm, and hyperparameter\noptimization. New loss functions are defined for both forks of the DANN\nnetwork, the label predictor and domain classifier, in order to facilitate more\nrapid gradient descent, provide more seamless integration into modern neural\nnetworking frameworks, and allow previously unavailable inferences into network\nbehavior. Using these loss functions, it is possible to extend the concept of\n'domain' to include arbitrary user defined labels applicable to subsets of the\ntraining data, the test data, or both. As such, the network can be operated in\neither 'On the Fly' mode where features provided by the feature extractor\nindicative of differences between 'domain' labels in the training data are\nremoved or in 'Test Collection Informed' mode where features indicative of\ndifference between 'domain' labels in the combined training and test data are\nremoved (without needing to know or provide test activity labels to the\nnetwork). This work also draws heavily from previous works on Robust Training\nwhich draws training examples from a L_inf ball around the training data in\norder to remove fragile features induced by random fluctuations in the data. On\nthese networks we explore the process of hyperparameter optimization for both\nthe domain adversarial and robust hyperparameters. Finally, this network is\napplied to the construction of a binary classifier used to identify the\npresence of EM signal emitted by a turbopump. For this example, the effect of\nthe robust and domain adversarial training is to remove features indicative of\nthe difference in background between instances of operation of the device -\nproviding highly discriminative features on which to construct the classifier.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 20:11:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Grimes", "Tom", ""], ["Church", "Eric", ""], ["Pitts", "William", ""], ["Wood", "Lynn", ""], ["Brayfindley", "Eva", ""], ["Erikson", "Luke", ""], ["Greaves", "Mark", ""]]}, {"id": "2011.10616", "submitter": "Rui Wang", "authors": "Rui Wang, Danielle Maddix, Christos Faloutsos, Yuyang Wang, Rose Yu", "title": "Bridging Physics-based and Data-driven modeling for Learning Dynamical\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can we learn a dynamical system to make forecasts, when some variables\nare unobserved? For instance, in COVID-19, we want to forecast the number of\ninfected and death cases but we do not know the count of susceptible and\nexposed people. While mechanics compartment models are widely used in epidemic\nmodeling, data-driven models are emerging for disease forecasting. We first\nformalize the learning of physics-based models as AutoODE, which leverages\nautomatic differentiation to estimate the model parameters. Through a benchmark\nstudy on COVID-19 forecasting, we notice that physics-based mechanistic models\nsignificantly outperform deep learning. Our method obtains a 57.4% reduction in\nmean absolute errors for 7-day ahead COVID-19 forecasting compared with the\nbest deep learning competitor. Such performance differences highlight the\ngeneralization problem in dynamical system learning due to distribution shift.\nWe identify two scenarios where distribution shift can occur: changes in data\ndomain and changes in parameter domain (system dynamics). Through systematic\nexperiments on several dynamical systems, we found that deep learning models\nfail to forecast well under both scenarios. While much research on distribution\nshift has focused on changes in the data domain, our work calls attention to\nrethink generalization for learning dynamical systems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 20:16:10 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 08:09:56 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wang", "Rui", ""], ["Maddix", "Danielle", ""], ["Faloutsos", "Christos", ""], ["Wang", "Yuyang", ""], ["Yu", "Rose", ""]]}, {"id": "2011.10643", "submitter": "Abolfazl Hashemi", "authors": "Abolfazl Hashemi, Anish Acharya, Rudrajit Das, Haris Vikalo, Sujay\n  Sanghavi, Inderjit Dhillon", "title": "On the Benefits of Multiple Gossip Steps in Communication-Constrained\n  Decentralized Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decentralized optimization, it is common algorithmic practice to have\nnodes interleave (local) gradient descent iterations with gossip (i.e.\naveraging over the network) steps. Motivated by the training of large-scale\nmachine learning models, it is also increasingly common to require that\nmessages be {\\em lossy compressed} versions of the local parameters. In this\npaper, we show that, in such compressed decentralized optimization settings,\nthere are benefits to having {\\em multiple} gossip steps between subsequent\ngradient iterations, even when the cost of doing so is appropriately accounted\nfor e.g. by means of reducing the precision of compressed information. In\nparticular, we show that having $O(\\log\\frac{1}{\\epsilon})$ gradient iterations\n{with constant step size} - and $O(\\log\\frac{1}{\\epsilon})$ gossip steps\nbetween every pair of these iterations - enables convergence to within\n$\\epsilon$ of the optimal value for smooth non-convex objectives satisfying\nPolyak-\\L{}ojasiewicz condition. This result also holds for smooth strongly\nconvex objectives. To our knowledge, this is the first work that derives\nconvergence results for nonconvex optimization under arbitrary communication\ncompression.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:17:32 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Hashemi", "Abolfazl", ""], ["Acharya", "Anish", ""], ["Das", "Rudrajit", ""], ["Vikalo", "Haris", ""], ["Sanghavi", "Sujay", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2011.10650", "submitter": "Rewon Child", "authors": "Rewon Child", "title": "Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them\n  on Images", "comments": "17 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hierarchical VAE that, for the first time, generates samples\nquickly while outperforming the PixelCNN in log-likelihood on all natural image\nbenchmarks. We begin by observing that, in theory, VAEs can actually represent\nautoregressive models, as well as faster, better models if they exist, when\nmade sufficiently deep. Despite this, autoregressive models have historically\noutperformed VAEs in log-likelihood. We test if insufficient depth explains why\nby scaling a VAE to greater stochastic depth than previously explored and\nevaluating it CIFAR-10, ImageNet, and FFHQ. In comparison to the PixelCNN,\nthese very deep VAEs achieve higher likelihoods, use fewer parameters, generate\nsamples thousands of times faster, and are more easily applied to\nhigh-resolution images. Qualitative studies suggest this is because the VAE\nlearns efficient hierarchical visual representations. We release our source\ncode and models at https://github.com/openai/vdvae.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:35:31 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 18:33:19 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Child", "Rewon", ""]]}, {"id": "2011.10652", "submitter": "Aparna Khare", "authors": "Aparna Khare, Srinivas Parthasarathy, Shiva Sundaram", "title": "Self-Supervised learning with cross-modal transformers for emotion\n  recognition", "comments": "To appear in SLT2020", "journal-ref": null, "doi": "10.1109/SLT48900.2021.9383618", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition is a challenging task due to limited availability of\nin-the-wild labeled datasets. Self-supervised learning has shown improvements\non tasks with limited labeled datasets in domains like speech and natural\nlanguage. Models such as BERT learn to incorporate context in word embeddings,\nwhich translates to improved performance in downstream tasks like question\nanswering. In this work, we extend self-supervised training to multi-modal\napplications. We learn multi-modal representations using a transformer trained\non the masked language modeling task with audio, visual and text features. This\nmodel is fine-tuned on the downstream task of emotion recognition. Our results\non the CMU-MOSEI dataset show that this pre-training technique can improve the\nemotion recognition performance by up to 3% compared to the baseline.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:38:34 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Khare", "Aparna", ""], ["Parthasarathy", "Srinivas", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2011.10654", "submitter": "Soumick Chatterjee", "authors": "Dhanunjaya Mitta, Soumick Chatterjee, Oliver Speck and Andreas\n  N\\\"urnberger", "title": "Upgraded W-Net with Attention Gates and its Application in Unsupervised\n  3D Liver Segmentation", "comments": null, "journal-ref": "Proceedings of the 10th International Conference on Pattern\n  Recognition Applications and Methods 2021 - Volume 1", "doi": "10.5220/0010221504880494", "report-no": "ICPRAM, ISBN 978-989-758-486-2, pages 488-494", "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of biomedical images can assist radiologists to make a better\ndiagnosis and take decisions faster by helping in the detection of\nabnormalities, such as tumors. Manual or semi-automated segmentation, however,\ncan be a time-consuming task. Most deep learning based automated segmentation\nmethods are supervised and rely on manually segmented ground-truth. A possible\nsolution for the problem would be an unsupervised deep learning based approach\nfor automated segmentation, which this research work tries to address. We use a\nW-Net architecture and modified it, such that it can be applied to 3D volumes.\nIn addition, to suppress noise in the segmentation we added attention gates to\nthe skip connections. The loss for the segmentation output was calculated using\nsoft N-Cuts and for the reconstruction output using SSIM. Conditional Random\nFields were used as a post-processing step to fine-tune the results. The\nproposed method has shown promising results, with a dice coefficient of 0.88\nfor the liver segmentation compared against manual segmentation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:45:28 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Mitta", "Dhanunjaya", ""], ["Chatterjee", "Soumick", ""], ["Speck", "Oliver", ""], ["N\u00fcrnberger", "Andreas", ""]]}, {"id": "2011.10655", "submitter": "Renu Sharma", "authors": "Renu Sharma and Arun Ross", "title": "Viability of Optical Coherence Tomography for Iris Presentation Attack\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose the use of Optical Coherence Tomography (OCT)\nimaging for the problem of iris presentation attack (PA) detection. We assess\nits viability by comparing its performance with respect to traditional iris\nimaging modalities, viz., near-infrared (NIR) and visible spectrum. OCT imaging\nprovides a cross-sectional view of an eye, whereas traditional imaging provides\n2D iris textural information. PA detection is performed using three\nstate-of-the-art deep architectures (VGG19, ResNet50 and DenseNet121) to\ndifferentiate between bonafide and PA samples for each of the three imaging\nmodalities. Experiments are performed on a dataset of 2,169 bonafide, 177 Van\nDyke eyes and 360 cosmetic contact images acquired using all three imaging\nmodalities under intra-attack (known PAs) and cross-attack (unknown PAs)\nscenarios. We observe promising results demonstrating OCT as a viable solution\nfor iris presentation attack detection.\n", "versions": [{"version": "v1", "created": "Thu, 22 Oct 2020 18:00:51 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sharma", "Renu", ""], ["Ross", "Arun", ""]]}, {"id": "2011.10657", "submitter": "Mohammad Ali Moni", "authors": "Sakifa Aktar, Md. Martuza Ahamad, Md. Rashed-Al-Mahfuz, AKM Azad,\n  Shahadat Uddin, A H M Kamal, Salem A. Alyami, Ping-I Lin, Sheikh Mohammed\n  Shariful Islam, Julian M.W. Quinn, Valsamma Eapen, and Mohammad Ali Moni", "title": "Predicting Patient COVID-19 Disease Severity by means of Statistical and\n  Machine Learning Analysis of Blood Cell Transcriptome Data", "comments": null, "journal-ref": "JMIR Med Inform 2021;9(4):e25884, PMID: 33779565", "doi": "10.2196/25884", "report-no": "JMIR ms#25884", "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introduction: For COVID-19 patients accurate prediction of disease severity\nand mortality risk would greatly improve care delivery and resource allocation.\nThere are many patient-related factors, such as pre-existing comorbidities that\naffect disease severity. Since rapid automated profiling of peripheral blood\nsamples is widely available, we investigated how such data from the peripheral\nblood of COVID-19 patients might be used to predict clinical outcomes.\n  Methods: We thus investigated such clinical datasets from COVID-19 patients\nwith known outcomes by combining statistical comparison and correlation methods\nwith machine learning algorithms; the latter included decision tree, random\nforest, variants of gradient boosting machine, support vector machine,\nK-nearest neighbour and deep learning methods.\n  Results: Our work revealed several clinical parameters measurable in blood\nsamples, which discriminated between healthy people and COVID-19 positive\npatients and showed predictive value for later severity of COVID-19 symptoms.\nWe thus developed a number of analytic methods that showed accuracy and\nprecision for disease severity and mortality outcome predictions that were\nabove 90%.\n  Conclusions: In sum, we developed methodologies to analyse patient routine\nclinical data which enables more accurate prediction of COVID-19 patient\noutcomes. This type of approaches could, by employing standard hospital\nlaboratory analyses of patient blood, be utilised to identify, COVID-19\npatients at high risk of mortality and so enable their treatment to be\noptimised.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:32:46 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Aktar", "Sakifa", ""], ["Ahamad", "Md. Martuza", ""], ["Rashed-Al-Mahfuz", "Md.", ""], ["Azad", "AKM", ""], ["Uddin", "Shahadat", ""], ["Kamal", "A H M", ""], ["Alyami", "Salem A.", ""], ["Lin", "Ping-I", ""], ["Islam", "Sheikh Mohammed Shariful", ""], ["Quinn", "Julian M. W.", ""], ["Eapen", "Valsamma", ""], ["Moni", "Mohammad Ali", ""]]}, {"id": "2011.10660", "submitter": "Uwe Aickelin", "authors": "Chris Roadknight, Prapa Rattadilok, Uwe Aickelin", "title": "Teaching Key Machine Learning Principles Using Anti-learning Datasets", "comments": "2018 IEEE International Conference on Teaching, Assessment, and\n  Learning for Engineering (TALE), Pages 960-964", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of the teaching of machine learning focuses on iterative hill-climbing\napproaches and the use of local knowledge to gain information leading to local\nor global maxima. In this paper we advocate the teaching of alternative methods\nof generalising to the best possible solution, including a method called\nanti-learning. By using simple teaching methods, students can achieve a deeper\nunderstanding of the importance of validation on data excluded from the\ntraining process and that each problem requires its own methods to solve. We\nalso exemplify the requirement to train a model using sufficient data by\nshowing that different granularities of cross-validation can yield very\ndifferent results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 05:43:40 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Roadknight", "Chris", ""], ["Rattadilok", "Prapa", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2011.10666", "submitter": "Lily Xu", "authors": "Rachel Guo, Lily Xu, Drew Cronin, Francis Okeke, Andrew Plumptre,\n  Milind Tambe", "title": "Enhancing Poaching Predictions for Under-Resourced Wildlife Conservation\n  Parks Using Remote Sensing Imagery", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World. 4 pages, 1 page references. 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Illegal wildlife poaching is driving the loss of biodiversity. To combat\npoaching, rangers patrol expansive protected areas for illegal poaching\nactivity. However, rangers often cannot comprehensively search such large\nparks. Thus, the Protection Assistant for Wildlife Security (PAWS) was\nintroduced as a machine learning approach to help identify the areas with\nhighest poaching risk. As PAWS is deployed to parks around the world, we\nrecognized that many parks have limited resources for data collection and\ntherefore have scarce feature sets. To ensure under-resourced parks have access\nto meaningful poaching predictions, we introduce the use of publicly available\nremote sensing data to extract features for parks. By employing this data from\nGoogle Earth Engine, we also incorporate previously unavailable dynamic data to\nenrich predictions with seasonal trends. We automate the entire\ndata-to-deployment pipeline and find that, with only using publicly available\ndata, we recuperate prediction performance comparable to predictions made using\nfeatures manually computed by park specialists. We conclude that the inclusion\nof satellite imagery creates a robust system through which parks of any\nresource level can benefit from poaching risks for years to come.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 22:06:57 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Guo", "Rachel", ""], ["Xu", "Lily", ""], ["Cronin", "Drew", ""], ["Okeke", "Francis", ""], ["Plumptre", "Andrew", ""], ["Tambe", "Milind", ""]]}, {"id": "2011.10668", "submitter": "Hotae Lee", "authors": "Hotae Lee, Monimoy Bujarbaruah, and Francesco Borrelli", "title": "Learning How to Solve Bubble Ball", "comments": "Accepted to L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Bubble Ball\" is a game built on a 2D physics engine, where a finite set of\nobjects can modify the motion of a bubble-like ball. The objective is to choose\nthe set and the initial configuration of the objects, in order to get the ball\nto reach a target flag. The presence of obstacles, friction, contact forces and\ncombinatorial object choices make the game hard to solve. In this paper, we\npropose a hierarchical predictive framework which solves Bubble Ball.\nGeometric, kinematic and dynamic models are used at different levels of the\nhierarchy. At each level of the game, data collected during failed iterations\nare used to update models at all hierarchical level and converge to a feasible\nsolution to the game. The proposed approach successfully solves a large set of\nBubble Ball levels within reasonable number of trials. This proposed framework\ncan also be used to solve other physics-based games, especially with limited\ntraining data from human demonstrations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 22:16:00 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 00:33:29 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lee", "Hotae", ""], ["Bujarbaruah", "Monimoy", ""], ["Borrelli", "Francesco", ""]]}, {"id": "2011.10674", "submitter": "Anton Xue", "authors": "Anton Xue and Nikolai Matni", "title": "Data-Driven System Level Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish data-driven versions of the System Level Synthesis (SLS)\nparameterization of achievable closed-loop system responses for a\nlinear-time-invariant system over a finite-horizon. Inspired by recent work in\ndata-driven control that leverages tools from behavioral theory, we show that\noptimization problems over system-responses can be posed using only libraries\nof past system trajectories, without explicitly identifying a system model. We\nfirst consider the idealized setting of noise free trajectories, and show an\nexact equivalence between traditional and data-driven SLS. We then show that in\nthe case of a system driven by process noise, tools from robust SLS can be used\nto characterize the effects of noise on closed-loop performance, and further\ndraw on tools from matrix concentration to show that a simple trajectory\naveraging technique can be used to mitigate these effects. We end with\nnumerical experiments showing the soundness of our methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 22:52:29 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 08:05:39 GMT"}, {"version": "v3", "created": "Sat, 6 Mar 2021 19:42:49 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Xue", "Anton", ""], ["Matni", "Nikolai", ""]]}, {"id": "2011.10678", "submitter": "Alireza Zareian", "authors": "Alireza Zareian, Kevin Dela Rosa, Derek Hao Hu, Shih-Fu Chang", "title": "Open-Vocabulary Object Detection Using Captions", "comments": "To be presented at CVPR 2021 (oral paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the remarkable accuracy of deep neural networks in object detection,\nthey are costly to train and scale due to supervision requirements.\nParticularly, learning more object categories typically requires proportionally\nmore bounding box annotations. Weakly supervised and zero-shot learning\ntechniques have been explored to scale object detectors to more categories with\nless supervision, but they have not been as successful and widely adopted as\nsupervised models. In this paper, we put forth a novel formulation of the\nobject detection problem, namely open-vocabulary object detection, which is\nmore general, more practical, and more effective than weakly supervised and\nzero-shot approaches. We propose a new method to train object detectors using\nbounding box annotations for a limited set of object categories, as well as\nimage-caption pairs that cover a larger variety of objects at a significantly\nlower cost. We show that the proposed method can detect and localize objects\nfor which no bounding box annotation is provided during training, at a\nsignificantly higher accuracy than zero-shot approaches. Meanwhile, objects\nwith bounding box annotation can be detected almost as accurately as supervised\nmethods, which is significantly better than weakly supervised baselines.\nAccordingly, we establish a new state of the art for scalable object detection.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 23:05:46 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 18:45:04 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zareian", "Alireza", ""], ["Rosa", "Kevin Dela", ""], ["Hu", "Derek Hao", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "2011.10684", "submitter": "Haozhe Feng", "authors": "Hao-Zhe Feng, Kezhi Kong, Minghao Chen, Tianye Zhang, Minfeng Zhu, Wei\n  Chen", "title": "SHOT-VAE: Semi-supervised Deep Generative Models With Label-aware ELBO\n  Approximations", "comments": "12 pages, 6 figures, Accepted for presentation at AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised variational autoencoders (VAEs) have obtained strong results,\nbut have also encountered the challenge that good ELBO values do not always\nimply accurate inference results. In this paper, we investigate and propose two\ncauses of this problem: (1) The ELBO objective cannot utilize the label\ninformation directly. (2) A bottleneck value exists and continuing to optimize\nELBO after this value will not improve inference accuracy. On the basis of the\nexperiment results, we propose SHOT-VAE to address these problems without\nintroducing additional prior knowledge. The SHOT-VAE offers two contributions:\n(1) A new ELBO approximation named smooth-ELBO that integrates the label\npredictive loss into ELBO. (2) An approximation based on optimal interpolation\nthat breaks the ELBO value bottleneck by reducing the margin between ELBO and\nthe data likelihood. The SHOT-VAE achieves good performance with a 25.30% error\nrate on CIFAR-100 with 10k labels and reduces the error rate to 6.11% on\nCIFAR-10 with 4k labels.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:38:31 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 09:27:54 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 07:44:59 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2020 07:04:44 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Feng", "Hao-Zhe", ""], ["Kong", "Kezhi", ""], ["Chen", "Minghao", ""], ["Zhang", "Tianye", ""], ["Zhu", "Minfeng", ""], ["Chen", "Wei", ""]]}, {"id": "2011.10687", "submitter": "Gowri Somanath", "authors": "Gowri Somanath and Daniel Kurz", "title": "HDR Environment Map Estimation for Real-Time Augmented Reality", "comments": "Supplementary video at\n  https://docs-assets.developer.apple.com/ml-research/papers/hdr-environment-map.mp4\n  Code at https://github.com/apple/ml-envmapnet Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to estimate an HDR environment map from a narrow\nfield-of-view LDR camera image in real-time. This enables perceptually\nappealing reflections and shading on virtual objects of any material finish,\nfrom mirror to diffuse, rendered into a real physical environment using\naugmented reality. Our method is based on our efficient convolutional neural\nnetwork architecture, EnvMapNet, trained end-to-end with two novel losses,\nProjectionLoss for the generated image, and ClusterLoss for adversarial\ntraining. Through qualitative and quantitative comparison to state-of-the-art\nmethods, we demonstrate that our algorithm reduces the directional error of\nestimated light sources by more than 50%, and achieves 3.7 times lower Frechet\nInception Distance (FID). We further showcase a mobile application that is able\nto run our neural network model in under 9 ms on an iPhone XS, and render in\nreal-time, visually coherent virtual objects in previously unseen real-world\nenvironments.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 01:01:53 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 19:32:32 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 21:32:49 GMT"}, {"version": "v4", "created": "Tue, 22 Jun 2021 22:15:31 GMT"}, {"version": "v5", "created": "Tue, 27 Jul 2021 20:48:22 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Somanath", "Gowri", ""], ["Kurz", "Daniel", ""]]}, {"id": "2011.10690", "submitter": "Parshan Pakiman", "authors": "Boxiao Chen, Selvaprabu Nadarajah, Parshan Pakiman, Stefanus Jasin", "title": "Self-adapting Robustness in Demand Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study dynamic pricing over a finite number of periods in the presence of\ndemand model ambiguity. Departing from the typical no-regret learning\nenvironment, where price changes are allowed at any time, pricing decisions are\nmade at pre-specified points in time and each price can be applied to a large\nnumber of arrivals. In this environment, which arises in retailing, a pricing\ndecision based on an incorrect demand model can significantly impact cumulative\nrevenue. We develop an adaptively-robust-learning (ARL) pricing policy that\nlearns the true model parameters from the data while actively managing demand\nmodel ambiguity. It optimizes an objective that is robust with respect to a\nself-adapting set of demand models, where a given model is included in this set\nonly if the sales data revealed from prior pricing decisions makes it\n\"probable\". As a result, it gracefully transitions from being robust when\ndemand model ambiguity is high to minimizing regret when this ambiguity\ndiminishes upon receiving more data. We characterize the stochastic behavior of\nARL's self-adapting ambiguity sets and derive a regret bound that highlights\nthe link between the scale of revenue loss and the customer arrival pattern. We\nalso show that ARL, by being conscious of both model ambiguity and revenue,\nbridges the gap between a distributionally robust policy and a\nfollow-the-leader policy, which focus on model ambiguity and revenue,\nrespectively. We numerically find that the ARL policy, or its extension\nthereof, exhibits superior performance compared to distributionally robust,\nfollow-the-leader, and upper-confidence-bound policies in terms of expected\nrevenue and/or value at risk.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 01:15:54 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Boxiao", ""], ["Nadarajah", "Selvaprabu", ""], ["Pakiman", "Parshan", ""], ["Jasin", "Stefanus", ""]]}, {"id": "2011.10695", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Zhenyu Liao, Edgar Dobriban and Michael W.\n  Mahoney", "title": "Sparse sketches with small inversion bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a tall $n\\times d$ matrix $A$ and a random $m\\times n$ sketching matrix\n$S$, the sketched estimate of the inverse covariance matrix $(A^\\top A)^{-1}$\nis typically biased: $E[(\\tilde A^\\top\\tilde A)^{-1}]\\ne(A^\\top A)^{-1}$, where\n$\\tilde A=SA$. This phenomenon, which we call inversion bias, arises, e.g., in\nstatistics and distributed optimization, when averaging multiple independently\nconstructed estimates of quantities that depend on the inverse covariance. We\ndevelop a framework for analyzing inversion bias, based on our proposed concept\nof an $(\\epsilon,\\delta)$-unbiased estimator for random matrices. We show that\nwhen the sketching matrix $S$ is dense and has i.i.d. sub-gaussian entries,\nthen after simple rescaling, the estimator $(\\frac m{m-d}\\tilde A^\\top\\tilde\nA)^{-1}$ is $(\\epsilon,\\delta)$-unbiased for $(A^\\top A)^{-1}$ with a sketch of\nsize $m=O(d+\\sqrt d/\\epsilon)$. This implies that for $m=O(d)$, the inversion\nbias of this estimator is $O(1/\\sqrt d)$, which is much smaller than the\n$\\Theta(1)$ approximation error obtained as a consequence of the subspace\nembedding guarantee for sub-gaussian sketches. We then propose a new sketching\ntechnique, called LEverage Score Sparsified (LESS) embeddings, which uses ideas\nfrom both data-oblivious sparse embeddings as well as data-aware leverage-based\nrow sampling methods, to get $\\epsilon$ inversion bias for sketch size\n$m=O(d\\log d+\\sqrt d/\\epsilon)$ in time $O(\\text{nnz}(A)\\log n+md^2)$, where\nnnz is the number of non-zeros. The key techniques enabling our analysis\ninclude an extension of a classical inequality of Bai and Silverstein for\nrandom quadratic forms, which we call the Restricted Bai-Silverstein\ninequality; and anti-concentration of the Binomial distribution via the\nPaley-Zygmund inequality, which we use to prove a lower bound showing that\nleverage score sampling sketches generally do not achieve small inversion bias.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 01:33:15 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 01:24:51 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Liao", "Zhenyu", ""], ["Dobriban", "Edgar", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2011.10698", "submitter": "Shihong Fang", "authors": "Shihong Fang, Anna Choromanska", "title": "Backdoor Attacks on the DNN Interpretation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is crucial to understand the inner workings of deep neural\nnetworks (DNNs) and many interpretation methods generate saliency maps that\nhighlight parts of the input image that contribute the most to the prediction\nmade by the DNN. In this paper we design a backdoor attack that alters the\nsaliency map produced by the network for an input image only with injected\ntrigger that is invisible to the naked eye while maintaining the prediction\naccuracy. The attack relies on injecting poisoned data with a trigger into the\ntraining data set. The saliency maps are incorporated in the penalty term of\nthe objective function that is used to train a deep model and its influence on\nmodel training is conditioned upon the presence of a trigger. We design two\ntypes of attacks: targeted attack that enforces a specific modification of the\nsaliency map and untargeted attack when the importance scores of the top pixels\nfrom the original saliency map are significantly reduced. We perform empirical\nevaluation of the proposed backdoor attacks on gradient-based and gradient-free\ninterpretation methods for a variety of deep learning architectures. We show\nthat our attacks constitute a serious security threat when deploying deep\nlearning models developed by untrusty sources. Finally, in the Supplement we\ndemonstrate that the proposed methodology can be used in an inverted setting,\nwhere the correct saliency map can be obtained only in the presence of a\ntrigger (key), effectively making the interpretation system available only to\nselected users.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 01:54:45 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 01:49:42 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Fang", "Shihong", ""], ["Choromanska", "Anna", ""]]}, {"id": "2011.10702", "submitter": "Alexander Wong", "authors": "James Ren Hou Lee, Maya Pavlova, Mahmoud Famouri, and Alexander Wong", "title": "CancerNet-SCa: Tailored Deep Neural Network Designs for Detection of\n  Skin Cancer from Dermoscopy Images", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin cancer continues to be the most frequently diagnosed form of cancer in\nthe U.S., with not only significant effects on health and well-being but also\nsignificant economic costs associated with treatment. A crucial step to the\ntreatment and management of skin cancer is effective skin cancer detection due\nto strong prognosis when treated at an early stage, with one of the key\nscreening approaches being dermoscopy examination. Motivated by the advances of\ndeep learning and inspired by the open source initiatives in the research\ncommunity, in this study we introduce CancerNet-SCa, a suite of deep neural\nnetwork designs tailored for the detection of skin cancer from dermoscopy\nimages that is open source and available to the general public as part of the\nCancer-Net initiative. To the best of the authors' knowledge, CancerNet-SCa\ncomprises of the first machine-designed deep neural network architecture\ndesigns tailored specifically for skin cancer detection, one of which\npossessing a self-attention architecture design with attention condensers.\nFurthermore, we investigate and audit the behaviour of CancerNet-SCa in a\nresponsible and transparent manner via explainability-driven model auditing.\nWhile CancerNet-SCa is not a production-ready screening solution, the hope is\nthat the release of CancerNet-SCa in open source, open access form will\nencourage researchers, clinicians, and citizen data scientists alike to\nleverage and build upon them.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 02:17:59 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lee", "James Ren Hou", ""], ["Pavlova", "Maya", ""], ["Famouri", "Mahmoud", ""], ["Wong", "Alexander", ""]]}, {"id": "2011.10704", "submitter": "Weixin Liang", "authors": "Weixin Liang, James Zou", "title": "Neural Group Testing to Accelerate Deep Learning", "comments": "ISIT 2021. Code & data available at\n  https://github.com/Weixin-Liang/NeuralGroupTesting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have made the use of large, deep neural\nnetworks with tens of millions of parameters. The sheer size of these networks\nimposes a challenging computational burden during inference. Existing work\nfocuses primarily on accelerating each forward pass of a neural network.\nInspired by the group testing strategy for efficient disease testing, we\npropose neural group testing, which accelerates by testing a group of samples\nin one forward pass. Groups of samples that test negative are ruled out. If a\ngroup tests positive, samples in that group are then retested adaptively. A key\nchallenge of neural group testing is to modify a deep neural network so that it\ncould test multiple samples in one forward pass. We propose three designs to\nachieve this without introducing any new parameters and evaluate their\nperformances. We applied neural group testing in an image moderation task to\ndetect rare but inappropriate images. We found that neural group testing can\ngroup up to 16 images in one forward pass and reduce the overall computation\ncost by over 73% while improving detection performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 02:23:54 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 23:03:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Liang", "Weixin", ""], ["Zou", "James", ""]]}, {"id": "2011.10712", "submitter": "Lintao Ye", "authors": "Lintao Ye, Aritra Mitra and Shreyas Sundaram", "title": "Near-Optimal Data Source Selection for Bayesian Learning", "comments": "Accepted to L4DC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.IT math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a fundamental problem in Bayesian learning, where the goal is to\nselect a set of data sources with minimum cost while achieving a certain\nlearning performance based on the data streams provided by the selected data\nsources. First, we show that the data source selection problem for Bayesian\nlearning is NP-hard. We then show that the data source selection problem can be\ntransformed into an instance of the submodular set covering problem studied in\nthe literature, and provide a standard greedy algorithm to solve the data\nsource selection problem with provable performance guarantees. Next, we propose\na fast greedy algorithm that improves the running times of the standard greedy\nalgorithm, while achieving performance guarantees that are comparable to those\nof the standard greedy algorithm. The fast greedy algorithm can also be applied\nto solve the general submodular set covering problem with performance\nguarantees. Finally, we validate the theoretical results using numerical\nexamples, and show that the greedy algorithms work well in practice.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 03:12:38 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 15:46:30 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ye", "Lintao", ""], ["Mitra", "Aritra", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "2011.10713", "submitter": "Hussein Sibai", "authors": "Hussein Sibai and Yangge Li and Sayan Mitra", "title": "SceneChecker: Boosting Scenario Verification using Symmetry Abstractions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.FL cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We presentSceneChecker, a tool for verifying scenarios involving vehicles\nexecuting complex plans in large cluttered workspaces. SceneChecker converts\nthe scenario verification problem to a standard hybrid system verification\nproblem, and solves it effectively by exploiting structural properties in the\nplan and the vehicle dynamics. SceneChecker uses symmetry abstractions, a novel\nrefinement algorithm, and importantly, is built to boost the performance of any\nexisting reachability analysis tool as a plug-in subroutine. We evaluated\nSceneChecker on several scenarios involving ground and aerial vehicles with\nnonlinear dynamics and neural network controllers, employing different kinds of\nsymmetries, using different reachability subroutines, and following plans with\nhundreds of way-points in complex workspaces. Compared to two leading tools,\nDryVR and Flow*, SceneChecker shows 20x speedup in verification time, even\nwhile using those very tools as reachability subroutines.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 03:18:55 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 01:39:28 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Sibai", "Hussein", ""], ["Li", "Yangge", ""], ["Mitra", "Sayan", ""]]}, {"id": "2011.10714", "submitter": "Elahe Aghapour", "authors": "Elahe Aghapour, Nora Ayanian", "title": "Double Meta-Learning for Data Efficient Policy Optimization in\n  Non-Stationary Environments", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in learning models of non-stationary environments, which\ncan be framed as a multi-task learning problem. Model-free reinforcement\nlearning algorithms can achieve good asymptotic performance in multi-task\nlearning at a cost of extensive sampling, due to their approach, which requires\nlearning from scratch. While model-based approaches are among the most data\nefficient learning algorithms, they still struggle with complex tasks and model\nuncertainties. Meta-reinforcement learning addresses the efficiency and\ngeneralization challenges on multi task learning by quickly leveraging the\nmeta-prior policy for a new task. In this paper, we propose a\nmeta-reinforcement learning approach to learn the dynamic model of a\nnon-stationary environment to be used for meta-policy optimization later. Due\nto the sample efficiency of model-based learning methods, we are able to\nsimultaneously train both the meta-model of the non-stationary environment and\nthe meta-policy until dynamic model convergence. Then, the meta-learned dynamic\nmodel of the environment will generate simulated data for meta-policy\noptimization. Our experiment demonstrates that our proposed method can\nmeta-learn the policy in a non-stationary environment with the data efficiency\nof model-based learning approaches while achieving the high asymptotic\nperformance of model-free meta-reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 03:19:35 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Aghapour", "Elahe", ""], ["Ayanian", "Nora", ""]]}, {"id": "2011.10715", "submitter": "Kyungmin Kim", "authors": "Seungjae Jung, Kyung-Min Kim, Hanock Kwak and Young-Jin Park", "title": "A Worrying Analysis of Probabilistic Time-series Models for Sales\n  Forecasting", "comments": "NeurIPS 2020 workshop (I Can't Believe It's Not Better,\n  ICBINB@NeurIPS 2020). All authors contributed equally to this research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic time-series models become popular in the forecasting field as\nthey help to make optimal decisions under uncertainty. Despite the growing\ninterest, a lack of thorough analysis hinders choosing what is worth applying\nfor the desired task. In this paper, we analyze the performance of three\nprominent probabilistic time-series models for sales forecasting. To remove the\nrole of random chance in architecture's performance, we make two experimental\nprinciples; 1) Large-scale dataset with various cross-validation sets. 2) A\nstandardized training and hyperparameter selection. The experimental results\nshow that a simple Multi-layer Perceptron and Linear Regression outperform the\nprobabilistic models on RMSE without any feature engineering. Overall, the\nprobabilistic models fail to achieve better performance on point estimation,\nsuch as RMSE and MAPE, than comparably simple baselines. We analyze and discuss\nthe performances of probabilistic time-series models.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 03:31:23 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jung", "Seungjae", ""], ["Kim", "Kyung-Min", ""], ["Kwak", "Hanock", ""], ["Park", "Young-Jin", ""]]}, {"id": "2011.10718", "submitter": "Mohammad Javad Khojasteh", "authors": "Anshuka Rangi, Mohammad Javad Khojasteh and Massimo Franceschetti", "title": "Learning-based attacks in Cyber-Physical Systems: Exploration,\n  Detection, and Control Cost trade-offs", "comments": "To appear in L4DC 2021. First two authors contributed equally", "journal-ref": "Learning for Dynamics and Control 2021, PMLR", "doi": null, "report-no": null, "categories": "eess.SY cs.CR cs.LG cs.MA cs.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning-based attacks in linear systems, where the\ncommunication channel between the controller and the plant can be hijacked by a\nmalicious attacker. We assume the attacker learns the dynamics of the system\nfrom observations, then overrides the controller's actuation signal, while\nmimicking legitimate operation by providing fictitious sensor readings to the\ncontroller. On the other hand, the controller is on a lookout to detect the\npresence of the attacker and tries to enhance the detection performance by\ncarefully crafting its control signals. We study the trade-offs between the\ninformation acquired by the attacker from observations, the detection\ncapabilities of the controller, and the control cost. Specifically, we provide\ntight upper and lower bounds on the expected $\\epsilon$-deception time, namely\nthe time required by the controller to make a decision regarding the presence\nof an attacker with confidence at least $(1-\\epsilon\\log(1/\\epsilon))$. We then\nshow a probabilistic lower bound on the time that must be spent by the attacker\nlearning the system, in order for the controller to have a given expected\n$\\epsilon$-deception time. We show that this bound is also order optimal, in\nthe sense that if the attacker satisfies it, then there exists a learning\nalgorithm with the given order expected deception time. Finally, we show a\nlower bound on the expected energy expenditure required to guarantee detection\nwith confidence at least $1-\\epsilon \\log(1/\\epsilon)$.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 04:08:16 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 02:11:55 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Rangi", "Anshuka", ""], ["Khojasteh", "Mohammad Javad", ""], ["Franceschetti", "Massimo", ""]]}, {"id": "2011.10725", "submitter": "Hau-tieng Wu", "authors": "Xiucai Ding and Hau-Tieng Wu", "title": "Phase transition of graph Laplacian of high dimensional noisy random\n  point cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.SP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We systematically explore the spectral distribution of kernel-based graph\nLaplacian constructed from high dimensional and noisy random point cloud in the\nnonnull setup. An interesting phase transition phenomenon is reported, which is\ncharacterized by the signal-to-noise ratio (SNR). We quantify how the signal\nand noise interact over different SNR regimes; for example, how signal\ninformation pops out the Marchenko-Pastur bulk. Motivated by the analysis, an\nadaptive bandwidth selection algorithm is provided and proved, which coincides\nwith the common practice in real data. Simulated data is provided to support\nthe theoretical findings. Our results paves the way towards a foundation for\nstatistical inference of various kernel-based unsupervised learning algorithms,\nlike eigenmap, diffusion map and their variations, for real data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 05:19:04 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ding", "Xiucai", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "2011.10731", "submitter": "Weixin Liang", "authors": "Weixin Liang, Feiyang Niu, Aishwarya Reganti, Govind Thattai, Gokhan\n  Tur", "title": "LRTA: A Transparent Neural-Symbolic Reasoning Framework with Modular\n  Supervision for Visual Question Answering", "comments": "NeurIPS KR2ML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predominant approach to visual question answering (VQA) relies on\nencoding the image and question with a \"black-box\" neural encoder and decoding\na single token as the answer like \"yes\" or \"no\". Despite this approach's strong\nquantitative results, it struggles to come up with intuitive, human-readable\nforms of justification for the prediction process. To address this\ninsufficiency, we reformulate VQA as a full answer generation task, which\nrequires the model to justify its predictions in natural language. We propose\nLRTA [Look, Read, Think, Answer], a transparent neural-symbolic reasoning\nframework for visual question answering that solves the problem step-by-step\nlike humans and provides human-readable form of justification at each step.\nSpecifically, LRTA learns to first convert an image into a scene graph and\nparse a question into multiple reasoning instructions. It then executes the\nreasoning instructions one at a time by traversing the scene graph using a\nrecurrent neural-symbolic execution module. Finally, it generates a full answer\nto the given question with natural language justifications. Our experiments on\nGQA dataset show that LRTA outperforms the state-of-the-art model by a large\nmargin (43.1% v.s. 28.0%) on the full answer generation task. We also create a\nperturbed GQA test set by removing linguistic cues (attributes and relations)\nin the questions for analyzing whether a model is having a smart guess with\nsuperficial data correlations. We show that LRTA makes a step towards truly\nunderstanding the question while the state-of-the-art model tends to learn\nsuperficial correlations from the training data.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 06:39:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liang", "Weixin", ""], ["Niu", "Feiyang", ""], ["Reganti", "Aishwarya", ""], ["Thattai", "Govind", ""], ["Tur", "Gokhan", ""]]}, {"id": "2011.10737", "submitter": "Jun Ma", "authors": "Zilong Cheng, Jun Ma, Xiaoxue Zhang, Frank L. Lewis, Tong Heng Lee", "title": "Neural Network iLQR: A New Reinforcement Learning Architecture", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a notable machine learning paradigm, the research efforts in the context\nof reinforcement learning have certainly progressed leaps and bounds. When\ncompared with reinforcement learning methods with the given system model, the\nmethodology of the reinforcement learning architecture based on the unknown\nmodel generally exhibits significantly broader universality and applicability.\nIn this work, a new reinforcement learning architecture is developed and\npresented without the requirement of any prior knowledge of the system model,\nwhich is termed as an approach of a \"neural network iterative linear quadratic\nregulator (NNiLQR)\". Depending solely on measurement data, this method yields a\ncompletely new non-parametric routine for the establishment of the optimal\npolicy (without the necessity of system modeling) through iterative refinements\nof the neural network system. Rather importantly, this approach significantly\noutperforms the classical iterative linear quadratic regulator (iLQR) method in\nterms of the given objective function because of the innovative utilization of\nfurther exploration in the methodology. As clearly indicated from the results\nattained in two illustrative examples, these significant merits of the NNiLQR\nmethod are demonstrated rather evidently.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 07:17:28 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Cheng", "Zilong", ""], ["Ma", "Jun", ""], ["Zhang", "Xiaoxue", ""], ["Lewis", "Frank L.", ""], ["Lee", "Tong Heng", ""]]}, {"id": "2011.10741", "submitter": "Kaixin Gao", "authors": "Kai-Xin Gao, Xiao-Lei Liu, Zheng-Hai Huang, Min Wang, Zidong Wang,\n  Dachuan Xu, Fan Yu", "title": "A Trace-restricted Kronecker-Factored Approximation to Natural Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Second-order optimization methods have the ability to accelerate convergence\nby modifying the gradient through the curvature matrix. There have been many\nattempts to use second-order optimization methods for training deep neural\nnetworks. Inspired by diagonal approximations and factored approximations such\nas Kronecker-Factored Approximate Curvature (KFAC), we propose a new\napproximation to the Fisher information matrix (FIM) called Trace-restricted\nKronecker-factored Approximate Curvature (TKFAC) in this work, which can hold\nthe certain trace relationship between the exact and the approximate FIM. In\nTKFAC, we decompose each block of the approximate FIM as a Kronecker product of\ntwo smaller matrices and scaled by a coefficient related to trace. We\ntheoretically analyze TKFAC's approximation error and give an upper bound of\nit. We also propose a new damping technique for TKFAC on convolutional neural\nnetworks to maintain the superiority of second-order optimization methods\nduring training. Experiments show that our method has better performance\ncompared with several state-of-the-art algorithms on some deep network\narchitectures.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 07:47:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Gao", "Kai-Xin", ""], ["Liu", "Xiao-Lei", ""], ["Huang", "Zheng-Hai", ""], ["Wang", "Min", ""], ["Wang", "Zidong", ""], ["Xu", "Dachuan", ""], ["Yu", "Fan", ""]]}, {"id": "2011.10744", "submitter": "Hiroyasu Ando", "authors": "Hiroyasu Ando, T. Okamoto, H. Chang, T. Noguchi, and Shinji Nakaoka", "title": "Computation harvesting in road traffic dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to recent advances in artificial intelligence and internet of things\n(IoT) technologies, collected big data facilitates high computational\nperformance, while its computational resources and energy cost are large.\nMoreover, data are often collected but not used. To solve these problems, we\npropose a framework for a computational model that follows a natural\ncomputational system, such as the human brain, and does not rely heavily on\nelectronic computers. In particular, we propose a methodology based on the\nconcept of `computation harvesting', which uses IoT data collected from rich\nsensors and leaves most of the computational processes to real-world phenomena\nas collected data. This aspect assumes that large-scale computations can be\nfast and resilient. Herein, we perform prediction tasks using real-world road\ntraffic data to show the feasibility of computation harvesting. First, we show\nthat the substantial computation in traffic flow is resilient against sensor\nfailure and real-time traffic changes due to several combinations of harvesting\nfrom spatiotemporal dynamics to synthesize specific patterns. Next, we show the\npracticality of this method as a real-time prediction because of its low\ncomputational cost. Finally, we show that, compared to conventional methods,\nour method requires lower resources while providing a comparable performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 08:22:19 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ando", "Hiroyasu", ""], ["Okamoto", "T.", ""], ["Chang", "H.", ""], ["Noguchi", "T.", ""], ["Nakaoka", "Shinji", ""]]}, {"id": "2011.10753", "submitter": "Avik Pal", "authors": "Avik Pal, Jonah Philion, Yuan-Hong Liao and Sanja Fidler", "title": "Emergent Road Rules In Multi-Agent Driving Environments", "comments": "International Conference on Learning Representations (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For autonomous vehicles to safely share the road with human drivers,\nautonomous vehicles must abide by specific \"road rules\" that human drivers have\nagreed to follow. \"Road rules\" include rules that drivers are required to\nfollow by law -- such as the requirement that vehicles stop at red lights -- as\nwell as more subtle social rules -- such as the implicit designation of fast\nlanes on the highway. In this paper, we provide empirical evidence that\nsuggests that -- instead of hard-coding road rules into self-driving algorithms\n-- a scalable alternative may be to design multi-agent environments in which\nroad rules emerge as optimal solutions to the problem of maximizing traffic\nflow. We analyze what ingredients in driving environments cause the emergence\nof these road rules and find that two crucial factors are noisy perception and\nagents' spatial density. We provide qualitative and quantitative evidence of\nthe emergence of seven social driving behaviors, ranging from obeying traffic\nsignals to following lanes, all of which emerge from training agents to drive\nquickly to destinations without colliding. Our results add empirical support\nfor the social road rules that countries worldwide have agreed on for safe,\nefficient driving.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 09:43:50 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 07:29:41 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Pal", "Avik", ""], ["Philion", "Jonah", ""], ["Liao", "Yuan-Hong", ""], ["Fidler", "Sanja", ""]]}, {"id": "2011.10759", "submitter": "Faizaan Sakib", "authors": "Faizaan Sakib and Tilo Burghardt", "title": "Visual Recognition of Great Ape Behaviours in the Wild", "comments": "4 pages, 4 figures, to be published in the proceedings of ICPR 2020\n  at the Visual observation and analysis of Vertebrate And Insect Behaviour\n  (VAIB) workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a first great ape-specific visual behaviour recognition system\nutilising deep learning that is capable of detecting nine core ape behaviours.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 10:27:21 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sakib", "Faizaan", ""], ["Burghardt", "Tilo", ""]]}, {"id": "2011.10760", "submitter": "Sukrit Mittal", "authors": "Sukrit Mittal and Dhish Kumar Saxena and Kalyanmoy Deb and Erik\n  Goodman", "title": "Enhanced Innovized Repair Operator for Evolutionary Multi- and\n  Many-objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": "COIN Lab Report: 2020020", "categories": "cs.NE cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Innovization\" is a task of learning common relationships among some or all\nof the Pareto-optimal (PO) solutions in multi- and many-objective optimization\nproblems. Recent studies have shown that a chronological sequence of\nnon-dominated solutions obtained in consecutive iterations during an\noptimization run also possess salient patterns that can be used to learn\nproblem features to help create new and improved solutions. In this paper, we\npropose a machine-learning- (ML-) assisted modelling approach that learns the\nmodifications in design variables needed to advance population members towards\nthe Pareto-optimal set. We then propose to use the resulting ML model as an\nadditional innovized repair (IR2) operator to be applied on offspring solutions\ncreated by the usual genetic operators, as a novel mean of improving their\nconvergence properties. In this paper, the well-known random forest (RF) method\nis used as the ML model and is integrated with various evolutionary multi- and\nmany-objective optimization algorithms, including NSGA-II, NSGA-III, and\nMOEA/D. On several test problems ranging from two to five objectives, we\ndemonstrate improvement in convergence behaviour using the proposed IR2-RF\noperator. Since the operator does not demand any additional solution\nevaluations, instead using the history of gradual and progressive improvements\nin solutions over generations, the proposed ML-based optimization opens up a\nnew direction of optimization algorithm development with advances in AI and ML\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 10:29:15 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Mittal", "Sukrit", ""], ["Saxena", "Dhish Kumar", ""], ["Deb", "Kalyanmoy", ""], ["Goodman", "Erik", ""]]}, {"id": "2011.10797", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos and Ryan Murray", "title": "Adversarial Classification: Necessary conditions and geometric flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a version of adversarial classification where an adversary is\nempowered to corrupt data inputs up to some distance $\\varepsilon$, using tools\nfrom variational analysis. In particular, we describe necessary conditions\nassociated with the optimal classifier subject to such an adversary. Using the\nnecessary conditions, we derive a geometric evolution equation which can be\nused to track the change in classification boundaries as $\\varepsilon$ varies.\nThis evolution equation may be described as an uncoupled system of differential\nequations in one dimension, or as a mean curvature type equation in higher\ndimension. In one dimension we rigorously prove that one can use the initial\nvalue problem starting from $\\varepsilon=0$, which is simply the Bayes\nclassifier, in order to solve for the global minimizer of the adversarial\nproblem. Numerical examples illustrating these ideas are also presented.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:14:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""]]}, {"id": "2011.10799", "submitter": "Boris Chidlovskii", "authors": "Leonid Antsfeld, Boris Chidlovskii, Emilio Sansano-Sansano", "title": "Deep Smartphone Sensors-WiFi Fusion for Indoor Positioning and Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the indoor localization problem, where the goal is to predict\nuser's trajectory from the data collected by their smartphone, using inertial\nsensors such as accelerometer, gyroscope and magnetometer, as well as other\nenvironment and network sensors such as barometer and WiFi. Our system\nimplements a deep learning based pedestrian dead reckoning (deep PDR) model\nthat provides a high-rate estimation of the relative position of the user.\nUsing Kalman Filter, we correct the PDR's drift using WiFi that provides a\nprediction of the user's absolute position each time a WiFi scan is received.\nFinally, we adjust Kalman Filter results with a map-free projection method that\ntakes into account the physical constraints of the environment (corridors,\ndoors, etc.) and projects the prediction on the possible walkable paths. We\ntest our pipeline on IPIN'19 Indoor Localization challenge dataset and\ndemonstrate that it improves the winner's results by 20\\% using the challenge\nevaluation protocol.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:20:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Antsfeld", "Leonid", ""], ["Chidlovskii", "Boris", ""], ["Sansano-Sansano", "Emilio", ""]]}, {"id": "2011.10801", "submitter": "Gi-Ren Liu", "authors": "Gi-Ren Liu, Yuan-Chung Sheu, Hau-Tieng Wu", "title": "Central and Non-central Limit Theorems arising from the Scattering\n  Transform and its Neural Activation Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by analyzing complicated and non-stationary time series, we study a\ngeneralization of the scattering transform (ST) that includes broad neural\nactivation functions, which is called neural activation ST (NAST). On the\nwhole, NAST is a transform that comprises a sequence of ``neural processing\nunits'', each of which applies a high pass filter to the input from the\nprevious layer followed by a composition with a nonlinear function as the\noutput to the next neuron. Here, the nonlinear function models how a neuron\ngets excited by the input signal. In addition to showing properties like\nnon-expansion, horizontal translational invariability and insensitivity to\nlocal deformation, the statistical properties of the second order NAST of a\nGaussian process with various dependence and (non-)stationarity structure and\nits interaction with the chosen high pass filters and activation functions are\nexplored and central limit theorem (CLT) and non-CLT results are provided.\nNumerical simulations are also provided. The results explain how NAST processes\ncomplicated and non-stationary time series, and pave a way towards statistical\ninference based on NAST under the non-null case.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:31:57 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liu", "Gi-Ren", ""], ["Sheu", "Yuan-Chung", ""], ["Wu", "Hau-Tieng", ""]]}, {"id": "2011.10824", "submitter": "Adish Singla", "authors": "Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, Adish Singla", "title": "Policy Teaching in Reinforcement Learning via Environment Poisoning\n  Attacks", "comments": "Journal version of ICML'20 paper. New theoretical results for jointly\n  poisoning rewards and transitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a security threat to reinforcement learning where an attacker\npoisons the learning environment to force the agent into executing a target\npolicy chosen by the attacker. As a victim, we consider RL agents whose\nobjective is to find a policy that maximizes reward in infinite-horizon problem\nsettings. The attacker can manipulate the rewards and the transition dynamics\nin the learning environment at training-time, and is interested in doing so in\na stealthy manner. We propose an optimization framework for finding an optimal\nstealthy attack for different measures of attack cost. We provide lower/upper\nbounds on the attack cost, and instantiate our attacks in two settings: (i) an\noffline setting where the agent is doing planning in the poisoned environment,\nand (ii) an online setting where the agent is learning a policy with poisoned\nfeedback. Our results show that the attacker can easily succeed in teaching any\ntarget policy to the victim under mild conditions and highlight a significant\nsecurity threat to reinforcement learning agents in practice.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 16:54:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rakhsha", "Amin", ""], ["Radanovic", "Goran", ""], ["Devidze", "Rati", ""], ["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""]]}, {"id": "2011.10829", "submitter": "Ran Wang", "authors": "Raman Goyal and Suman Chakravorty and Ran Wang and Mohamed Naveed Gul\n  Mohamed", "title": "On the Convergence of Reinforcement Learning in Nonlinear Continuous\n  State Space Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of Reinforcement Learning for nonlinear stochastic\ndynamical systems. We show that in the RL setting, there is an inherent ``Curse\nof Variance\" in addition to Bellman's infamous ``Curse of Dimensionality\", in\nparticular, we show that the variance in the solution grows\nfactorial-exponentially in the order of the approximation. A fundamental\nconsequence is that this precludes the search for anything other than ``local\"\nfeedback solutions in RL, in order to control the explosive variance growth,\nand thus, ensure accuracy. We further show that the deterministic optimal\ncontrol has a perturbation structure, in that the higher order terms do not\naffect the calculation of lower order terms, which can be utilized in RL to get\naccurate local solutions.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 17:41:03 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 21:30:33 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Goyal", "Raman", ""], ["Chakravorty", "Suman", ""], ["Wang", "Ran", ""], ["Mohamed", "Mohamed Naveed Gul", ""]]}, {"id": "2011.10831", "submitter": "AbdElRahman ElSaid", "authors": "AbdElRahman ElSaid, Joshua Karns, Zimeng Lyu, Alexander Ororbia,\n  Travis Desell", "title": "Continuous Ant-Based Neural Topology Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel, nature-inspired neural architecture search\n(NAS) algorithm based on ant colony optimization, Continuous Ant-based Neural\nTopology Search (CANTS), which utilizes synthetic ants that move over a\ncontinuous search space based on the density and distribution of pheromones, is\nstrongly inspired by how ants move in the real world. The paths taken by the\nant agents through the search space are utilized to construct artificial neural\nnetworks (ANNs). This continuous search space allows CANTS to automate the\ndesign of ANNs of any size, removing a key limitation inherent to many current\nNAS algorithms that must operate within structures with a size predetermined by\nthe user. CANTS employs a distributed asynchronous strategy which allows it to\nscale to large-scale high performance computing resources, works with a variety\nof recurrent memory cell structures, and makes use of a communal weight sharing\nstrategy to reduce training time. The proposed procedure is evaluated on three\nreal-world, time series prediction problems in the field of power systems and\ncompared to two state-of-the-art algorithms. Results show that CANTS is able to\nprovide improved or competitive results on all of these problems, while also\nbeing easier to use, requiring half the number of user-specified\nhyper-parameters.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 17:49:44 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["ElSaid", "AbdElRahman", ""], ["Karns", "Joshua", ""], ["Lyu", "Zimeng", ""], ["Ororbia", "Alexander", ""], ["Desell", "Travis", ""]]}, {"id": "2011.10834", "submitter": "Adolfo Almeida", "authors": "A. Almeida, J.P. de Villiers, A. De Freitas, M. Velayudan", "title": "Exploring the multimodal information from video content using deep\n  learning features of appearance, audio and action for video recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the popularisation of media streaming, a number of video streaming\nservices are continuously buying new video content to mine the potential profit\nfrom them. As such, the newly added content has to be handled well to be\nrecommended to suitable users. In this paper, we address the new item\ncold-start problem by exploring the potential of various deep learning features\nto provide video recommendations. The deep learning features investigated\ninclude features that capture the visual-appearance, audio and motion\ninformation from video content. We also explore different fusion methods to\nevaluate how well these feature modalities can be combined to fully exploit the\ncomplementary information captured by them. Experiments on a real-world video\ndataset for movie recommendations show that deep learning features outperform\nhand-crafted features. In particular, recommendations generated with deep\nlearning audio features and action-centric deep learning features are superior\nto MFCC and state-of-the-art iDT features. In addition, the combination of\nvarious deep learning features with hand-crafted features and textual metadata\nyields significant improvement in recommendations compared to combining only\nthe former.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 18:00:28 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Almeida", "A.", ""], ["de Villiers", "J. P.", ""], ["De Freitas", "A.", ""], ["Velayudan", "M.", ""]]}, {"id": "2011.10839", "submitter": "Marco Scarpetta", "authors": "Nicola Giaquinto, Marco Scarpetta, Maurizio Spadavecchia, Gregorio\n  Andria", "title": "Deep Learning-Based Computer Vision for Real Time Intravenous Drip\n  Infusion Monitoring", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": "10.1109/JSEN.2020.3039009", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of deep learning-based computer vision for\nreal-time monitoring of the flow in intravenous (IV) infusions. IV infusions\nare among the most common therapies in hospitalized patients and, given that\nboth over-infusion and under-infusion can cause severe damages, monitoring the\nflow rate of the fluid being administered to patients is very important for\ntheir safety. The proposed system uses a camera to film the IV drip infusion\nkit and a deep learning-based algorithm to classify acquired frames into two\ndifferent states: frames with a drop that has just begun to take shape and\nframes with a well-formed drop. The alternation of these two states is used to\ncount drops and derive a measurement of the flow rate of the drip. The usage of\na camera as sensing element makes the proposed system safe in medical\nenvironments and easier to be integrated into current health facilities.\nExperimental results are reported in the paper that confirm the accuracy of the\nsystem and its capability to produce real-time estimates. The proposed method\ncan be therefore effectively adopted to implement IV infusion monitoring and\ncontrol systems.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 18:26:44 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Giaquinto", "Nicola", ""], ["Scarpetta", "Marco", ""], ["Spadavecchia", "Maurizio", ""], ["Andria", "Gregorio", ""]]}, {"id": "2011.10861", "submitter": "Xiaowei Yue", "authors": "Cheolhei Lee, Jianguo Wu, Wenjia Wang, Xiaowei Yue", "title": "Neural Network Gaussian Process Considering Input Uncertainty for\n  Composite Structures Assembly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing machine learning enabled smart manufacturing is promising for\ncomposite structures assembly process. To improve production quality and\nefficiency of the assembly process, accurate predictive analysis on dimensional\ndeviations and residual stress of the composite structures is required. The\nnovel composite structures assembly involves two challenges: (i) the highly\nnonlinear and anisotropic properties of composite materials; and (ii)\ninevitable uncertainty in the assembly process. To overcome those problems, we\npropose a neural network Gaussian process model considering input uncertainty\nfor composite structures assembly. Deep architecture of our model allows us to\napproximate a complex process better, and consideration of input uncertainty\nenables robust modeling with complete incorporation of the process uncertainty.\nBased on simulation and case study, the NNGPIU can outperform other benchmark\nmethods when the response function is nonsmooth and nonlinear. Although we use\ncomposite structure assembly as an example, the proposed methodology can be\napplicable to other engineering systems with intrinsic uncertainties.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 20:21:28 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lee", "Cheolhei", ""], ["Wu", "Jianguo", ""], ["Wang", "Wenjia", ""], ["Yue", "Xiaowei", ""]]}, {"id": "2011.10867", "submitter": "Can Bakiskan", "authors": "Can Bakiskan, Metehan Cekic, Ahmet Dundar Sezer, Upamanyu Madhow", "title": "A Neuro-Inspired Autoencoding Defense Against Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) are vulnerable to adversarial attacks: carefully\nconstructed perturbations to an image can seriously impair classification\naccuracy, while being imperceptible to humans. While there has been a\nsignificant amount of research on defending against such attacks, most defenses\nbased on systematic design principles have been defeated by appropriately\nmodified attacks. For a fixed set of data, the most effective current defense\nis to train the network using adversarially perturbed examples. In this paper,\nwe investigate a radically different, neuro-inspired defense mechanism,\nstarting from the observation that human vision is virtually unaffected by\nadversarial examples designed for machines. We aim to reject L^inf bounded\nadversarial perturbations before they reach a classifier DNN, using an encoder\nwith characteristics commonly observed in biological vision: sparse\novercomplete representations, randomness due to synaptic noise, and drastic\nnonlinearities. Encoder training is unsupervised, using standard dictionary\nlearning. A CNN-based decoder restores the size of the encoder output to that\nof the original image, enabling the use of a standard CNN for classification.\nOur nominal design is to train the decoder and classifier together in standard\nsupervised fashion, but we also consider unsupervised decoder training based on\na regression objective (as in a conventional autoencoder) with separate\nsupervised training of the classifier. Unlike adversarial training, all\ntraining is based on clean images.\n  Our experiments on the CIFAR-10 show performance competitive with\nstate-of-the-art defenses based on adversarial training, and point to the\npromise of neuro-inspired techniques for the design of robust neural networks.\nIn addition, we provide results for a subset of the Imagenet dataset to verify\nthat our approach scales to larger images.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 21:03:08 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 23:35:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Bakiskan", "Can", ""], ["Cekic", "Metehan", ""], ["Sezer", "Ahmet Dundar", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "2011.10879", "submitter": "Kenric Nelson Ph.D.", "authors": "Kevin R. Chen, Daniel Svoboda, and Kenric P. Nelson", "title": "Use of Student's t-Distribution for the Latent Layer in a Coupled\n  Variational Autoencoder", "comments": "8 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Coupled Variational Autoencoder, which incorporates both a generalized loss\nfunction and latent layer distribution, shows improvement in the accuracy and\nrobustness of generated replicas of MNIST numerals. The latent layer uses a\nStudent's t-distribution to incorporate heavy-tail decay. The loss function\nuses a coupled logarithm, which increases the penalty on images with outlier\nlikelihood. The generalized mean of the generated image's likelihood is used to\nmeasure the performance of the algorithm's decisiveness, accuracy, and\nrobustness.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 21:55:36 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chen", "Kevin R.", ""], ["Svoboda", "Daniel", ""], ["Nelson", "Kenric P.", ""]]}, {"id": "2011.10881", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Shengcao Cao, Yiming Yang, Kris Kitani", "title": "Rethinking Transformer-based Set Prediction for Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DETR is a recently proposed Transformer-based method which views object\ndetection as a set prediction problem and achieves state-of-the-art performance\nbut demands extra-long training time to converge. In this paper, we investigate\nthe causes of the optimization difficulty in the training of DETR. Our\nexaminations reveal several factors contributing to the slow convergence of\nDETR, primarily the issues with the Hungarian loss and the Transformer cross\nattention mechanism. To overcome these issues we propose two solutions, namely,\nTSP-FCOS (Transformer-based Set Prediction with FCOS) and TSP-RCNN\n(Transformer-based Set Prediction with RCNN). Experimental results show that\nthe proposed methods not only converge much faster than the original DETR, but\nalso significantly outperform DETR and other baselines in terms of detection\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 21:59:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sun", "Zhiqing", ""], ["Cao", "Shengcao", ""], ["Yang", "Yiming", ""], ["Kitani", "Kris", ""]]}, {"id": "2011.10883", "submitter": "Jean-Claude Crivello", "authors": "Jean-Claude Crivello, Nataliya Sokolovska, Jean-Marc Joubert", "title": "Supervised deep learning prediction of the formation enthalpy of the\n  full set of configurations in complex phases: the $\\sigma-$phase as an\n  example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) methods are becoming integral to scientific inquiry in\nnumerous disciplines, such as material sciences. In this manuscript, we\ndemonstrate how ML can be used to predict several properties in solid-state\nchemistry, in particular the heat of formation of a given complex\ncrystallographic phase (here the $\\sigma-$phase, $tP30$, $D8_{b}$). Based on an\nindependent and unprecedented large first principles dataset containing about\n10,000 $\\sigma-$compounds with $n=14$ different elements, we used a supervised\nlearning approach, to predict all the $\\sim$500,000 possible configurations\nwithin a mean absolute error of 23 meV/at ($\\sim$2 kJ.mol$^{-1}$) on the heat\nof formation and $\\sim$0.06 Ang. on the tetragonal cell parameters. We showed\nthat neural network regression algorithms provide a significant improvement in\naccuracy of the predicted output compared to traditional regression techniques.\nAdding descriptors having physical nature (atomic radius, number of valence\nelectrons) improves the learning precision. Based on our analysis, the training\ndatabase composed of the only binary-compositions plays a major role in\npredicting the higher degree system configurations. Our result opens a broad\navenue to efficient high-throughput investigations of the combinatorial binary\ncalculation for multicomponent prediction of a complex phase.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 22:07:15 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Crivello", "Jean-Claude", ""], ["Sokolovska", "Nataliya", ""], ["Joubert", "Jean-Marc", ""]]}, {"id": "2011.10893", "submitter": "Hossein Talebi", "authors": "Hossein Talebi, Ehsan Amid, Peyman Milanfar, and Manfred K. Warmuth", "title": "Rank-smoothed Pairwise Learning In Perceptual Quality Assessment", "comments": null, "journal-ref": "IEEE International Conference on Image Processing (ICIP) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conducting pairwise comparisons is a widely used approach in curating human\nperceptual preference data. Typically raters are instructed to make their\nchoices according to a specific set of rules that address certain dimensions of\nimage quality and aesthetics. The outcome of this process is a dataset of\nsampled image pairs with their associated empirical preference probabilities.\nTraining a model on these pairwise preferences is a common deep learning\napproach. However, optimizing by gradient descent through mini-batch learning\nmeans that the \"global\" ranking of the images is not explicitly taken into\naccount. In other words, each step of the gradient descent relies only on a\nlimited number of pairwise comparisons. In this work, we demonstrate that\nregularizing the pairwise empirical probabilities with aggregated rankwise\nprobabilities leads to a more reliable training loss. We show that training a\ndeep image quality assessment model with our rank-smoothed loss consistently\nimproves the accuracy of predicting human preferences.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 23:33:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Talebi", "Hossein", ""], ["Amid", "Ehsan", ""], ["Milanfar", "Peyman", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "2011.10912", "submitter": "Fuxun Yu", "authors": "Fuxun Yu, Dimitrios Stamoulis, Di Wang, Dimitrios Lymberopoulos, Xiang\n  Chen", "title": "Third ArchEdge Workshop: Exploring the Design Space of Efficient Deep\n  Neural Networks", "comments": "Presented in Third ArchEdge Workshop, Co-located with SEC'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper gives an overview of our ongoing work on the design space\nexploration of efficient deep neural networks (DNNs). Specifically, we cover\ntwo aspects: (1) static architecture design efficiency and (2) dynamic model\nexecution efficiency. For static architecture design, different from existing\nend-to-end hardware modeling assumptions, we conduct full-stack profiling at\nthe GPU core level to identify better accuracy-latency trade-offs for DNN\ndesigns. For dynamic model execution, different from prior work that tackles\nmodel redundancy at the DNN-channels level, we explore a new dimension of DNN\nfeature map redundancy to be dynamically traversed at runtime. Last, we\nhighlight several open questions that are poised to draw research attention in\nthe next few years.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 01:56:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yu", "Fuxun", ""], ["Stamoulis", "Dimitrios", ""], ["Wang", "Di", ""], ["Lymberopoulos", "Dimitrios", ""], ["Chen", "Xiang", ""]]}, {"id": "2011.10915", "submitter": "Zhenyu Shou", "authors": "Zhenyu Shou, Xuan Di", "title": "Multi-Agent Reinforcement Learning for Dynamic Routing Games: A Unified\n  Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to develop a unified paradigm that models one's learning\nbehavior and the system's equilibrating processes in a routing game among\natomic selfish agents. Such a paradigm can assist policymakers in devising\noptimal operational and planning countermeasures under both normal and abnormal\ncircumstances. To this end, a multi-agent reinforcement learning (MARL)\nparadigm is proposed in which each agent learns and updates her own en-route\npath choice policy while interacting with others on transportation networks.\nThis paradigm is shown to generalize the classical notion of dynamic user\nequilibrium (DUE) to model-free and data-driven scenarios. We also illustrate\nthat the equilibrium outcomes computed from our developed MARL paradigm\ncoincide with DUE and dynamic system optimal (DSO), respectively, when rewards\nare set differently. In addition, with the goal to optimize some systematic\nobjective (e.g., overall traffic condition) of city planners, we formulate a\nbilevel optimization problem with the upper level as city planners and the\nlower level as a multi-agent system where each rational and selfish traveler\naims to minimize her travel cost. We demonstrate the effect of two\nadministrative measures, namely tolling and signal control, on the behavior of\ntravelers and show that the systematic objective of city planners can be\noptimized by a proper control. The results show that on the Braess network, the\noptimal toll charge on the central link is greater or equal to 25, with which\nthe average travel time of selfish agents is minimized and the emergence of\nBraess paradox could be avoided. In a large-sized real-world road network with\n69 nodes and 166 links, the optimal offset for signal control on Broadway is\nderived as 4 seconds, with which the average travel time of all controllable\nagents is minimized.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 02:31:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shou", "Zhenyu", ""], ["Di", "Xuan", ""]]}, {"id": "2011.10916", "submitter": "Kunjal Panchal", "authors": "Kunjal Panchal", "title": "Hierachical Delta-Attention Method for Multimodal Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In vision and linguistics; the main input modalities are facial expressions,\nspeech patterns, and the words uttered. The issue with analysis of any one mode\nof expression (Visual, Verbal or Vocal) is that lot of contextual information\ncan get lost. This asks researchers to inspect multiple modalities to get a\nthorough understanding of the cross-modal dependencies and temporal context of\nthe situation to analyze the expression. This work attempts at preserving the\nlong-range dependencies within and across different modalities, which would be\nbottle-necked by the use of recurrent networks and adds the concept of\ndelta-attention to focus on local differences per modality to capture the\nidiosyncrasy of different people. We explore a cross-attention fusion technique\nto get the global view of the emotion expressed through these\ndelta-self-attended modalities, in order to fuse all the local nuances and\nglobal context together. The addition of attention is new to the multi-modal\nfusion field and currently being scrutinized for on what stage the attention\nmechanism should be used, this work achieves competitive accuracy for overall\nand per-class classification which is close to the current state-of-the-art\nwith almost half number of parameters.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 02:45:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Panchal", "Kunjal", ""]]}, {"id": "2011.10919", "submitter": "Kazem Jahanbakhsh", "authors": "Kazem Jahanbakhsh", "title": "Applying Multi-armed Bandit Algorithms to Computational Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last two decades, we have seen extensive industrial research in the\narea of computational advertising. In this paper, our goal is to study the\nperformance of various online learning algorithms to identify and display the\nbest ads/offers with the highest conversion rates to web users. We formulate\nour ad-selection problem as a Multi-Armed Bandit problem which is a classical\nparadigm in Machine Learning. We have been applying machine learning, data\nmining, probability, and statistics to analyze big data in the ad-tech space\nand devise efficient ad selection strategies. This article highlights some of\nour findings in the area of computational advertising from 2011 to 2015.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 03:23:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jahanbakhsh", "Kazem", ""]]}, {"id": "2011.10925", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Locally Linear Embedding and its Variants: Tutorial and Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper for Locally Linear Embedding (LLE) and\nits variants. The idea of LLE is fitting the local structure of manifold in the\nembedding space. In this paper, we first cover LLE, kernel LLE, inverse LLE,\nand feature fusion with LLE. Then, we cover out-of-sample embedding using\nlinear reconstruction, eigenfunctions, and kernel mapping. Incremental LLE is\nexplained for embedding streaming data. Landmark LLE methods using the Nystrom\napproximation and locally linear landmarks are explained for big data\nembedding. We introduce the methods for parameter selection of number of\nneighbors using residual variance, Procrustes statistics, preservation\nneighborhood error, and local neighborhood selection. Afterwards, Supervised\nLLE (SLLE), enhanced SLLE, SLLE projection, probabilistic SLLE, supervised\nguided LLE (using Hilbert-Schmidt independence criterion), and semi-supervised\nLLE are explained for supervised and semi-supervised embedding. Robust LLE\nmethods using least squares problem and penalty functions are also introduced\nfor embedding in the presence of outliers and noise. Then, we introduce fusion\nof LLE with other manifold learning methods including Isomap (i.e., ISOLLE),\nprincipal component analysis, Fisher discriminant analysis, discriminant LLE,\nand Isotop. Finally, we explain weighted LLE in which the distances,\nreconstruction weights, or the embeddings are adjusted for better embedding; we\ncover weighted LLE for deformed distributed data, weighted LLE using\nprobability of occurrence, SLLE by adjusting weights, modified LLE, and\niterative LLE.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 03:44:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2011.10931", "submitter": "Feiran Zhao", "authors": "Feiran Zhao, Keyou You", "title": "Primal-dual Learning for the Model-free Risk-constrained Linear\n  Quadratic Regulator", "comments": "To appear in the Annual Conference on Learning for Dynamics and\n  Control (L4DC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Risk-aware control, though with promise to tackle unexpected events, requires\na known exact dynamical model. In this work, we propose a model-free framework\nto learn a risk-aware controller with a focus on the linear system. We\nformulate it as a discrete-time infinite-horizon LQR problem with a state\npredictive variance constraint. To solve it, we parameterize the policy with a\nfeedback gain pair and leverage primal-dual methods to optimize it by solely\nusing data. We first study the optimization landscape of the Lagrangian\nfunction and establish the strong duality in spite of its non-convex nature.\nAlongside, we find that the Lagrangian function enjoys an important local\ngradient dominance property, which is then exploited to develop a convergent\nrandom search algorithm to learn the dual function. Furthermore, we propose a\nprimal-dual algorithm with global convergence to learn the optimal\npolicy-multiplier pair. Finally, we validate our results via simulations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 04:40:15 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 02:18:16 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 03:37:12 GMT"}, {"version": "v4", "created": "Sun, 30 May 2021 14:11:51 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhao", "Feiran", ""], ["You", "Keyou", ""]]}, {"id": "2011.10944", "submitter": "Haizhou Shi", "authors": "Haizhou Shi, Dongliang Luo, Siliang Tang, Jian Wang, Yueting Zhuang", "title": "Run Away From your Teacher: Understanding BYOL by a Novel\n  Self-Supervised Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a newly proposed self-supervised framework Bootstrap Your Own\nLatent (BYOL) seriously challenges the necessity of negative samples in\ncontrastive learning frameworks. BYOL works like a charm despite the fact that\nit discards the negative samples completely and there is no measure to prevent\ncollapse in its training objective. In this paper, we suggest understanding\nBYOL from the view of our proposed interpretable self-supervised learning\nframework, Run Away From your Teacher (RAFT). RAFT optimizes two objectives at\nthe same time: (i) aligning two views of the same data to similar\nrepresentations and (ii) running away from the model's Mean Teacher (MT, the\nexponential moving average of the history models) instead of BYOL's running\ntowards it. The second term of RAFT explicitly prevents the representation\ncollapse and thus makes RAFT a more conceptually reliable framework. We provide\nbasic benchmarks of RAFT on CIFAR10 to validate the effectiveness of our\nmethod. Furthermore, we prove that BYOL is equivalent to RAFT under certain\nconditions, providing solid reasoning for BYOL's counter-intuitive success.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 05:49:50 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shi", "Haizhou", ""], ["Luo", "Dongliang", ""], ["Tang", "Siliang", ""], ["Wang", "Jian", ""], ["Zhuang", "Yueting", ""]]}, {"id": "2011.10949", "submitter": "Zhicheng Yan", "authors": "Zhicheng Yan, Xiaoliang Dai, Peizhao Zhang, Yuandong Tian, Bichen Wu,\n  Matt Feiszli", "title": "FP-NAS: Fast Probabilistic Neural Architecture Search", "comments": "CVPR 2021 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Neural Architecture Search (NAS) requires all layer choices to\nbe held in memory simultaneously; this limits the size of both search space and\nfinal architecture. In contrast, Probabilistic NAS, such as PARSEC, learns a\ndistribution over high-performing architectures, and uses only as much memory\nas needed to train a single model. Nevertheless, it needs to sample many\narchitectures, making it computationally expensive for searching in an\nextensive space. To solve these problems, we propose a sampling method adaptive\nto the distribution entropy, drawing more samples to encourage explorations at\nthe beginning, and reducing samples as learning proceeds. Furthermore, to\nsearch fast in the multi-variate space, we propose a coarse-to-fine strategy by\nusing a factorized distribution at the beginning which can reduce the number of\narchitecture parameters by over an order of magnitude. We call this method Fast\nProbabilistic NAS (FP-NAS). Compared with PARSEC, it can sample 64% fewer\narchitectures and search 2.1x faster. Compared with FBNetV2, FP-NAS is 1.9x -\n3.5x faster, and the searched models outperform FBNetV2 models on ImageNet.\nFP-NAS allows us to expand the giant FBNetV2 space to be wider (i.e. larger\nchannel choices) and deeper (i.e. more blocks), while adding Split-Attention\nblock and enabling the search over the number of splits. When searching a model\nof size 0.4G FLOPS, FP-NAS is 132x faster than EfficientNet, and the searched\nFP-NAS-L0 model outperforms EfficientNet-B0 by 0.7% accuracy. Without using any\narchitecture surrogate or scaling tricks, we directly search large models up to\n1.0G FLOPS. Our FP-NAS-L2 model with simple distillation outperforms BigNAS-XL\nwith advanced in-place distillation by 0.7% accuracy using similar FLOPS.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 06:10:05 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 06:48:03 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 17:21:49 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Yan", "Zhicheng", ""], ["Dai", "Xiaoliang", ""], ["Zhang", "Peizhao", ""], ["Tian", "Yuandong", ""], ["Wu", "Bichen", ""], ["Feiszli", "Matt", ""]]}, {"id": "2011.10951", "submitter": "Li Liu", "authors": "Runkai Zheng, Zhijia Yu, Yinqi Zhang, Chris Ding, Hei Victor Cheng, Li\n  Liu", "title": "Learning Class Unique Features in Fine-Grained Visual Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major challenge in Fine-Grained Visual Classification (FGVC) is\ndistinguishing various categories with high inter-class similarity by learning\nthe feature that differentiate the details. Conventional cross entropy trained\nConvolutional Neural Network (CNN) fails this challenge as it may suffer from\nproducing inter-class invariant features in FGVC. In this work, we innovatively\npropose to regularize the training of CNN by enforcing the uniqueness of the\nfeatures to each category from an information theoretic perspective. To achieve\nthis goal, we formulate a minimax loss based on a game theoretic framework,\nwhere a Nash equilibria is proved to be consistent with this regularization\nobjective. Besides, to prevent from a feasible solution of minimax loss that\nmay produce redundant features, we present a Feature Redundancy Loss (FRL)\nbased on normalized inner product between each selected feature map pair to\ncomplement the proposed minimax loss. Superior experimental results on several\ninfluential benchmarks along with visualization show that our method gives full\nplay to the performance of the baseline model without additional computation\nand achieves comparable results with state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 06:20:47 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 13:43:02 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zheng", "Runkai", ""], ["Yu", "Zhijia", ""], ["Zhang", "Yinqi", ""], ["Ding", "Chris", ""], ["Cheng", "Hei Victor", ""], ["Liu", "Li", ""]]}, {"id": "2011.10981", "submitter": "Pratik Ratadiya", "authors": "Pratik Ratadiya, Khushi Asawa, Omkar Nikhal", "title": "A decentralized aggregation mechanism for training deep learning models\n  using smart contract system for bank loan prediction", "comments": "Accepted at the Workshop on AI and Blockchains at the 29th\n  International Joint Conference on Artificial Intelligence (IJCAI-PRICAI),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data privacy and sharing has always been a critical issue when trying to\nbuild complex deep learning-based systems to model data. Facilitation of a\ndecentralized approach that could take benefit from data across multiple nodes\nwhile not needing to merge their data contents physically has been an area of\nactive research. In this paper, we present a solution to benefit from a\ndistributed data setup in the case of training deep learning architectures by\nmaking use of a smart contract system. Specifically, we propose a mechanism\nthat aggregates together the intermediate representations obtained from local\nANN models over a blockchain. Training of local models takes place on their\nrespective data. The intermediate representations derived from them, when\ncombined and trained together on the host node, helps to get a more accurate\nsystem. While federated learning primarily deals with the same features of data\nwhere the number of samples being distributed on multiple nodes, here we are\ndealing with the same number of samples but with their features being\ndistributed on multiple nodes. We consider the task of bank loan prediction\nwherein the personal details of an individual and their bank-specific details\nmay not be available at the same place. Our aggregation mechanism helps to\ntrain a model on such existing distributed data without having to share and\nconcatenate together the actual data values. The obtained performance, which is\nbetter than that of individual nodes, and is at par with that of a centralized\ndata setup makes a strong case for extending our technique across other\narchitectures and tasks. The solution finds its application in organizations\nthat want to train deep learning models on vertically partitioned data.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 10:47:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ratadiya", "Pratik", ""], ["Asawa", "Khushi", ""], ["Nikhal", "Omkar", ""]]}, {"id": "2011.10988", "submitter": "Hoang Nt", "authors": "Hoang NT and Takanori Maehara and Tsuyoshi Murata", "title": "Stacked Graph Filter", "comments": "Source code is provided at github.com/gear/sgf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study Graph Convolutional Networks (GCN) from the graph signal processing\nviewpoint by addressing a difference between learning graph filters with fully\nconnected weights versus trainable polynomial coefficients. We find that by\nstacking graph filters with learnable polynomial parameters, we can build a\nhighly adaptive and robust vertex classification model. Our treatment here\nrelaxes the low-frequency (or equivalently, high homophily) assumptions in\nexisting vertex classification models, resulting a more ubiquitous solution in\nterms of spectral properties. Empirically, by using only one hyper-parameter\nsetting, our model achieves strong results on most benchmark datasets across\nthe frequency spectrum.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 11:20:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["NT", "Hoang", ""], ["Maehara", "Takanori", ""], ["Murata", "Tsuyoshi", ""]]}, {"id": "2011.10996", "submitter": "Antoine Guillaume", "authors": "Antoine Guillaume, Christel Vrain, Elloumi Wael", "title": "Time series classification for predictive maintenance on event logs", "comments": "19 pages, 9 figures, submitted to ECMLPKDD 2021 Journal Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Time series classification (TSC) gained a lot of attention in the past decade\nand number of methods for representing and classifying time series have been\nproposed. Nowadays, methods based on convolutional networks and ensemble\ntechniques represent the state of the art for time series classification.\nTechniques transforming time series to image or text also provide reliable ways\nto extract meaningful features or representations of time series. We compare\nthe state-of-the-art representation and classification methods on a specific\napplication, that is predictive maintenance from sequences of event logs. The\ncontributions of this paper are twofold: introducing a new data set for\npredictive maintenance on automated teller machines (ATMs) log data and\ncomparing the performance of different representation methods for predicting\nthe occurrence of a breakdown. The problem is difficult since unlike the\nclassic case of predictive maintenance via signals from sensors, we have\nsequences of discrete event logs occurring at any time and the lengths of the\nsequences, corresponding to life cycles, vary a lot.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 12:12:14 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 08:23:45 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 16:33:52 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Guillaume", "Antoine", ""], ["Vrain", "Christel", ""], ["Wael", "Elloumi", ""]]}, {"id": "2011.10998", "submitter": "Maja Tr\\k{e}bacz", "authors": "Maja Tr\\k{e}bacz, Zohreh Shams, Mateja Jamnik, Paul Scherer, Nikola\n  Simidjievski, Helena Andres Terre, Pietro Li\\`o", "title": "Using ontology embeddings for structural inductive bias in gene\n  expression data analysis", "comments": "4 pages + 2 page references, 15th Machine Learning in Computational\n  Biology (MLCB) meeting, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stratifying cancer patients based on their gene expression levels allows\nimproving diagnosis, survival analysis and treatment planning. However, such\ndata is extremely highly dimensional as it contains expression values for over\n20000 genes per patient, and the number of samples in the datasets is low. To\ndeal with such settings, we propose to incorporate prior biological knowledge\nabout genes from ontologies into the machine learning system for the task of\npatient classification given their gene expression data. We use ontology\nembeddings that capture the semantic similarities between the genes to direct a\nGraph Convolutional Network, and therefore sparsify the network connections. We\nshow this approach provides an advantage for predicting clinical targets from\nhigh-dimensional low-sample data.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 12:13:29 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Tr\u0119bacz", "Maja", ""], ["Shams", "Zohreh", ""], ["Jamnik", "Mateja", ""], ["Scherer", "Paul", ""], ["Simidjievski", "Nikola", ""], ["Terre", "Helena Andres", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2011.11001", "submitter": "Jiang Zhang", "authors": "Jiang Zhang, Ivan Beschastnikh, Sergey Mechtaev, Abhik Roychoudhury", "title": "Fairness-guided SMT-based Rectification of Decision Trees and Random\n  Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven decision making is gaining prominence with the popularity of\nvarious machine learning models. Unfortunately, real-life data used in machine\nlearning training may capture human biases, and as a result the learned models\nmay lead to unfair decision making. In this paper, we provide a solution to\nthis problem for decision trees and random forests. Our approach converts any\ndecision tree or random forest into a fair one with respect to a specific data\nset, fairness criteria, and sensitive attributes. The \\emph{FairRepair} tool,\nbuilt based on our approach, is inspired by automated program repair techniques\nfor traditional programs. It uses an SMT solver to decide which paths in the\ndecision tree could have their outcomes flipped to improve the fairness of the\nmodel. Our experiments on the well-known adult dataset from UC Irvine\ndemonstrate that FairRepair scales to realistic decision trees and random\nforests. Furthermore, FairRepair provides formal guarantees about soundness and\ncompleteness of finding a repair. Since our fairness-guided repair technique\nrepairs decision trees and random forests obtained from a given (unfair)\ndata-set, it can help to identify and rectify biases in decision-making in an\norganisation.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 12:30:27 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhang", "Jiang", ""], ["Beschastnikh", "Ivan", ""], ["Mechtaev", "Sergey", ""], ["Roychoudhury", "Abhik", ""]]}, {"id": "2011.11004", "submitter": "Haifeng Li", "authors": "Jiawei Zhu, Chao Tao, Hanhan Deng, Ling Zhao, Pu Wang, Tao Lin,\n  Haifeng Li", "title": "AST-GCN: Attribute-Augmented Spatiotemporal Graph Convolutional Network\n  for Traffic Forecasting", "comments": "11 pages, 17 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Traffic forecasting is a fundamental and challenging task in the field of\nintelligent transportation. Accurate forecasting not only depends on the\nhistorical traffic flow information but also needs to consider the influence of\na variety of external factors, such as weather conditions and surrounding POI\ndistribution. Recently, spatiotemporal models integrating graph convolutional\nnetworks and recurrent neural networks have become traffic forecasting research\nhotspots and have made significant progress. However, few works integrate\nexternal factors. Therefore, based on the assumption that introducing external\nfactors can enhance the spatiotemporal accuracy in predicting traffic and\nimproving interpretability, we propose an attribute-augmented spatiotemporal\ngraph convolutional network (AST-GCN). We model the external factors as dynamic\nattributes and static attributes and design an attribute-augmented unit to\nencode and integrate those factors into the spatiotemporal graph convolution\nmodel. Experiments on real datasets show the effectiveness of considering\nexternal information on traffic forecasting tasks when compared to traditional\ntraffic prediction methods. Moreover, under different attribute-augmented\nschemes and prediction horizon settings, the forecasting accuracy of the\nAST-GCN is higher than that of the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 12:49:55 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhu", "Jiawei", ""], ["Tao", "Chao", ""], ["Deng", "Hanhan", ""], ["Zhao", "Ling", ""], ["Wang", "Pu", ""], ["Lin", "Tao", ""], ["Li", "Haifeng", ""]]}, {"id": "2011.11012", "submitter": "Mohammad Reza Samsami", "authors": "Mohammad Reza Samsami, Hossein Alimadad", "title": "Distributed Deep Reinforcement Learning: An Overview", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning (DRL) is a very active research area. However,\nseveral technical and scientific issues require to be addressed, amongst which\nwe can mention data inefficiency, exploration-exploitation trade-off, and\nmulti-task learning. Therefore, distributed modifications of DRL were\nintroduced; agents that could be run on many machines simultaneously. In this\narticle, we provide a survey of the role of the distributed approaches in DRL.\nWe overview the state of the field, by studying the key research works that\nhave a significant impact on how we can use distributed methods in DRL. We\nchoose to overview these papers, from the perspective of distributed learning,\nand not the aspect of innovations in reinforcement learning algorithms. Also,\nwe evaluate these methods on different tasks and compare their performance with\neach other and with single actor and learner agents.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 13:24:35 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Samsami", "Mohammad Reza", ""], ["Alimadad", "Hossein", ""]]}, {"id": "2011.11013", "submitter": "Shenglan Liu", "authors": "Shenglan Liu, Yang Yu", "title": "Angular Embedding: A New Angular Robust Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a widely used method in machine learning, principal component analysis\n(PCA) shows excellent properties for dimensionality reduction. It is a serious\nproblem that PCA is sensitive to outliers, which has been improved by numerous\nRobust PCA (RPCA) versions. However, the existing state-of-the-art RPCA\napproaches cannot easily remove or tolerate outliers by a non-iterative manner.\nTo tackle this issue, this paper proposes Angular Embedding (AE) to formulate a\nstraightforward RPCA approach based on angular density, which is improved for\nlarge scale or high-dimensional data. Furthermore, a trimmed AE (TAE) is\nintroduced to deal with data with large scale outliers. Extensive experiments\non both synthetic and real-world datasets with vector-level or pixel-level\noutliers demonstrate that the proposed AE/TAE outperforms the state-of-the-art\nRPCA based methods.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 13:36:56 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Liu", "Shenglan", ""], ["Yu", "Yang", ""]]}, {"id": "2011.11015", "submitter": "Brett Roads", "authors": "Brett D. Roads, Bradley C. Love", "title": "Enriching ImageNet with Human Similarity Judgments and Psychological\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in object recognition flourished in part because of the availability\nof high-quality datasets and associated benchmarks. However, these\nbenchmarks---such as ILSVRC---are relatively task-specific, focusing\npredominately on predicting class labels. We introduce a publicly-available\ndataset that embodies the task-general capabilities of human perception and\nreasoning. The Human Similarity Judgments extension to ImageNet (ImageNet-HSJ)\nis composed of human similarity judgments that supplement the ILSVRC validation\nset. The new dataset supports a range of task and performance metrics,\nincluding the evaluation of unsupervised learning algorithms. We demonstrate\ntwo methods of assessment: using the similarity judgments directly and using a\npsychological embedding trained on the similarity judgments. This embedding\nspace contains an order of magnitude more points (i.e., images) than previous\nefforts based on human judgments. Scaling to the full 50,000 image set was made\npossible through a selective sampling process that used variational Bayesian\ninference and model ensembles to sample aspects of the embedding space that\nwere most uncertain. This methodological innovation not only enables scaling,\nbut should also improve the quality of solutions by focusing sampling where it\nis needed. To demonstrate the utility of ImageNet-HSJ, we used the similarity\nratings and the embedding space to evaluate how well several popular models\nconform to human similarity judgments. One finding is that more complex models\nthat perform better on task-specific benchmarks do not better conform to human\nsemantic judgments. In addition to the human similarity judgments, pre-trained\npsychological embeddings and code for inferring variational embeddings are made\npublicly available. Collectively, ImageNet-HSJ assets support the appraisal of\ninternal representations and the development of more human-like models.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 13:41:54 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Roads", "Brett D.", ""], ["Love", "Bradley C.", ""]]}, {"id": "2011.11020", "submitter": "Alberto Bartesaghi", "authors": "Qinwen Huang, Ye Zhou, Xiaochen Du, Reed Chen, Jianyou Wang, Cynthia\n  Rudin, Alberto Bartesaghi", "title": "Cryo-ZSSR: multiple-image super-resolution based on deep internal\n  learning", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-particle cryo-electron microscopy (cryo-EM) is an emerging imaging\nmodality capable of visualizing proteins and macro-molecular complexes at\nnear-atomic resolution. The low electron-doses used to prevent sample radiation\ndamage, result in images where the power of the noise is 100 times greater than\nthe power of the signal. To overcome the low-SNRs, hundreds of thousands of\nparticle projections acquired over several days of data collection are averaged\nin 3D to determine the structure of interest. Meanwhile, recent image\nsuper-resolution (SR) techniques based on neural networks have shown state of\nthe art performance on natural images. Building on these advances, we present a\nmultiple-image SR algorithm based on deep internal learning designed\nspecifically to work under low-SNR conditions. Our approach leverages the\ninternal image statistics of cryo-EM movies and does not require training on\nground-truth data. When applied to a single-particle dataset of apoferritin, we\nshow that the resolution of 3D structures obtained from SR micrographs can\nsurpass the limits imposed by the imaging system. Our results indicate that the\ncombination of low magnification imaging with image SR has the potential to\naccelerate cryo-EM data collection without sacrificing resolution.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 14:04:54 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Huang", "Qinwen", ""], ["Zhou", "Ye", ""], ["Du", "Xiaochen", ""], ["Chen", "Reed", ""], ["Wang", "Jianyou", ""], ["Rudin", "Cynthia", ""], ["Bartesaghi", "Alberto", ""]]}, {"id": "2011.11048", "submitter": "Zhihua Jin", "authors": "Zhihua Jin, Yong Wang, Qianwen Wang, Yao Ming, Tengfei Ma, Huamin Qu", "title": "GNNVis: A Visual Analytics Approach for Prediction Error Diagnosis of\n  Graph Neural Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) aim to extend deep learning techniques to graph\ndata and have achieved significant progress in graph analysis tasks (e.g., node\nclassification) in recent years. However, similar to other deep neural networks\nlike Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs),\nGNNs behave like a black box with their details hidden from model developers\nand users. It is therefore difficult to diagnose possible errors of GNNs.\nDespite many visual analytics studies being done on CNNs and RNNs, little\nresearch has addressed the challenges for GNNs. This paper fills the research\ngap with an interactive visual analysis tool, GNNVis, to assist model\ndevelopers and users in understanding and analyzing GNNs. Specifically,\nParallel Sets View and Projection View enable users to quickly identify and\nvalidate error patterns in the set of wrong predictions; Graph View and Feature\nMatrix View offer a detailed analysis of individual nodes to assist users in\nforming hypotheses about the error patterns. Since GNNs jointly model the graph\nstructure and the node features, we reveal the relative influences of the two\ntypes of information by comparing the predictions of three models: GNN,\nMulti-Layer Perceptron (MLP), and GNN Without Using Features (GNNWUF). Two case\nstudies and interviews with domain experts demonstrate the effectiveness of\nGNNVis in facilitating the understanding of GNN models and their errors.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 16:09:08 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 03:57:35 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 11:28:14 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Jin", "Zhihua", ""], ["Wang", "Yong", ""], ["Wang", "Qianwen", ""], ["Ming", "Yao", ""], ["Ma", "Tengfei", ""], ["Qu", "Huamin", ""]]}, {"id": "2011.11057", "submitter": "Zhaozhou Li", "authors": "Zhao-Zhou Li, Lu Li, Zhengyi Shao", "title": "Robust Gaussian Process Regression Based on Iterative Trimming", "comments": "major revision, 11 pages, 8 figures, 2 tables; accepted by Astronomy\n  and Computing; code available at https://github.com/syrte/robustgp/", "journal-ref": null, "doi": "10.1016/j.ascom.2021.100483", "report-no": null, "categories": "cs.LG astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian process (GP) regression can be severely biased when the data are\ncontaminated by outliers. This paper presents a new robust GP regression\nalgorithm that iteratively trims the most extreme data points. While the new\nalgorithm retains the attractive properties of the standard GP as a\nnonparametric and flexible regression method, it can greatly improve the model\naccuracy for contaminated data even in the presence of extreme or abundant\noutliers. It is also easier to implement compared with previous robust GP\nvariants that rely on approximate inference. Applied to a wide range of\nexperiments with different contamination levels, the proposed method\nsignificantly outperforms the standard GP and the popular robust GP variant\nwith the Student-t likelihood in most test cases. In addition, as a practical\nexample in the astrophysical study, we show that this method can precisely\ndetermine the main-sequence ridge line in the color-magnitude diagram of star\nclusters.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 16:43:35 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 13:49:02 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Zhao-Zhou", ""], ["Li", "Lu", ""], ["Shao", "Zhengyi", ""]]}, {"id": "2011.11062", "submitter": "Eduardo Bezerra", "authors": "Marcello Serqueira, Pedro Gonz\\'alez, Eduardo Bezerra", "title": "A Population-based Hybrid Approach to Hyperparameter Optimization for\n  Neural Networks", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, large amounts of data have been generated, and computer\npower has kept growing. This scenario has led to a resurgence in the interest\nin artificial neural networks. One of the main challenges in training effective\nneural network models is finding the right combination of hyperparameters to be\nused. Indeed, the choice of an adequate approach to search the hyperparameter\nspace directly influences the accuracy of the resulting neural network model.\nCommon approaches for hyperparameter optimization are Grid Search, Random\nSearch, and Bayesian Optimization. There are also population-based methods such\nas CMA-ES. In this paper, we present HBRKGA, a new population-based approach\nfor hyperparameter optimization. HBRKGA is a hybrid approach that combines the\nBiased Random Key Genetic Algorithm with a Random Walk technique to search the\nhyperparameter space efficiently. Several computational experiments on eight\ndifferent datasets were performed to assess the effectiveness of the proposed\napproach. Results showed that HBRKGA could find hyperparameter configurations\nthat outperformed (in terms of predictive quality) the baseline methods in six\nout of eight datasets while showing a reasonable execution time.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:12:31 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 12:58:40 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Serqueira", "Marcello", ""], ["Gonz\u00e1lez", "Pedro", ""], ["Bezerra", "Eduardo", ""]]}, {"id": "2011.11063", "submitter": "Eli Sennesh", "authors": "Eli Sennesh", "title": "Learning a Deep Generative Model like a Program: the Free Category Prior", "comments": null, "journal-ref": "AAAI Symposium on Conceptual Abstraction and Analogy in Natural\n  and Artificial Intelligence, Fall 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans surpass the cognitive abilities of most other animals in our ability\nto \"chunk\" concepts into words, and then combine the words to combine the\nconcepts. In this process, we make \"infinite use of finite means\", enabling us\nto learn new concepts quickly and nest concepts within each-other. While\nprogram induction and synthesis remain at the heart of foundational theories of\nartificial intelligence, only recently has the community moved forward in\nattempting to use program learning as a benchmark task itself. The cognitive\nscience community has thus often assumed that if the brain has simulation and\nreasoning capabilities equivalent to a universal computer, then it must employ\na serialized, symbolic representation. Here we confront that assumption, and\nprovide a counterexample in which compositionality is expressed via network\nstructure: the free category prior over programs. We show how our formalism\nallows neural networks to serve as primitives in probabilistic programs. We\nlearn both program structure and model parameters end-to-end.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:16:17 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sennesh", "Eli", ""]]}, {"id": "2011.11066", "submitter": "Nicolas Nadisic", "authors": "Nicolas Nadisic, Arnaud Vandaele, Nicolas Gillis", "title": "A Homotopy-based Algorithm for Sparse Multiple Right-hand Sides\n  Nonnegative Least Squares", "comments": "20 pages + 7 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative least squares (NNLS) problems arise in models that rely on\nadditive linear combinations. In particular, they are at the core of\nnonnegative matrix factorization (NMF) algorithms. The nonnegativity constraint\nis known to naturally favor sparsity, that is, solutions with few non-zero\nentries. However, it is often useful to further enhance this sparsity, as it\nimproves the interpretability of the results and helps reducing noise. While\nthe $\\ell_0$-\"norm\", equal to the number of non-zeros entries in a vector, is a\nnatural sparsity measure, its combinatorial nature makes it difficult to use in\npractical optimization schemes. Most existing approaches thus rely either on\nits convex surrogate, the $\\ell_1$-norm, or on heuristics such as greedy\nalgorithms. In the case of multiple right-hand sides NNLS (MNNLS), which are\nused within NMF algorithms, sparsity is often enforced column- or row-wise, and\nthe fact that the solution is a matrix is not exploited. In this paper, we\nfirst introduce a novel formulation for sparse MNNLS, with a matrix-wise\n$\\ell_0$ sparsity constraint. Then, we present a two-step algorithm to tackle\nthis problem. The first step uses a homotopy algorithm to produce the whole\nregularization path for all the $\\ell_1$-penalized NNLS problems arising in\nMNNLS, that is, to produce a set of solutions representing different tradeoffs\nbetween reconstruction error and sparsity. The second step selects solutions\namong these paths in order to build a sparsity-constrained matrix that\nminimizes the reconstruction error. We illustrate the advantages of our\nproposed algorithm for the unmixing of facial and hyperspectral images.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:21:16 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 08:11:36 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Nadisic", "Nicolas", ""], ["Vandaele", "Arnaud", ""], ["Gillis", "Nicolas", ""]]}, {"id": "2011.11070", "submitter": "Caroline Weis", "authors": "Stefan Groha, Caroline Weis, Alexander Gusev, Bastian Rieck", "title": "Topological Data Analysis of copy number alterations in cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying subgroups and properties of cancer biopsy samples is a crucial\nstep towards obtaining precise diagnoses and being able to perform personalized\ntreatment of cancer patients. Recent data collections provide a comprehensive\ncharacterization of cancer cell data, including genetic data on copy number\nalterations (CNAs). We explore the potential to capture information contained\nin cancer genomic information using a novel topology-based approach that\nencodes each cancer sample as a persistence diagram of topological features,\ni.e., high-dimensional voids represented in the data. We find that this\ntechnique has the potential to extract meaningful low-dimensional\nrepresentations in cancer somatic genetic data and demonstrate the viability of\nsome applications on finding substructures in cancer data as well as comparing\nsimilarity of cancer types.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:31:23 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 17:28:37 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Groha", "Stefan", ""], ["Weis", "Caroline", ""], ["Gusev", "Alexander", ""], ["Rieck", "Bastian", ""]]}, {"id": "2011.11074", "submitter": "Simon Gabay", "authors": "Simon Gabay (UNIGE), Thibault Cl\\'erice (ENC), Jean-Baptiste Camps\n  (ENC), Jean-Baptiste Tanguy (SU), Matthias Gille-Levenson (ENS Lyon)", "title": "Standardizing linguistic data: method and tools for annotating\n  (pre-orthographic) French", "comments": null, "journal-ref": "Proceedings of the 2nd International Digital Tools & Uses Congress\n  (DTUC '20), Oct 2020, Hammamet, Tunisia", "doi": "10.1145/3423603.3423996", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of big corpora of various periods, it becomes crucial to\nstandardise linguistic annotation (e.g. lemmas, POS tags, morphological\nannotation) to increase the interoperability of the data produced, despite\ndiachronic variations. In the present paper, we describe both methodologically\n(by proposing annotation principles) and technically (by creating the required\ntraining data and the relevant models) the production of a linguistic tagger\nfor (early) modern French (16-18th c.), taking as much as possible into account\nalready existing standards for contemporary and, especially, medieval French.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:39:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Gabay", "Simon", "", "UNIGE"], ["Cl\u00e9rice", "Thibault", "", "ENC"], ["Camps", "Jean-Baptiste", "", "ENC"], ["Tanguy", "Jean-Baptiste", "", "SU"], ["Gille-Levenson", "Matthias", "", "ENS Lyon"]]}, {"id": "2011.11081", "submitter": "Limin Yu", "authors": "Junli Cao, B.S., Junyan Wu, M.S., Jing W. Zhang, M.D., Ph.D., Jay J.\n  Ye, M.D., Ph.D., Limin Yu, M.D., M.S", "title": "Deep learning model trained on mobile phone-acquired frozen section\n  images effectively detects basal cell carcinoma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Margin assessment of basal cell carcinoma using the frozen\nsection is a common task of pathology intraoperative consultation. Although\nfrequently straight-forward, the determination of the presence or absence of\nbasal cell carcinoma on the tissue sections can sometimes be challenging. We\nexplore if a deep learning model trained on mobile phone-acquired frozen\nsection images can have adequate performance for future deployment. Materials\nand Methods: One thousand two hundred and forty-one (1241) images of frozen\nsections performed for basal cell carcinoma margin status were acquired using\nmobile phones. The photos were taken at 100x magnification (10x objective). The\nimages were downscaled from a 4032 x 3024 pixel resolution to 576 x 432 pixel\nresolution. Semantic segmentation algorithm Deeplab V3 with Xception backbone\nwas used for model training. Results: The model uses an image as input and\nproduces a 2-dimensional black and white output of prediction of the same\ndimension; the areas determined to be basal cell carcinoma were displayed with\nwhite color, in a black background. Any output with the number of white pixels\nexceeding 0.5% of the total number of pixels is deemed positive for basal cell\ncarcinoma. On the test set, the model achieves area under curve of 0.99 for\nreceiver operator curve and 0.97 for precision-recall curve at the pixel level.\nThe accuracy of classification at the slide level is 96%. Conclusions: The deep\nlearning model trained with mobile phone images shows satisfactory performance\ncharacteristics, and thus demonstrates the potential for deploying as a mobile\nphone app to assist in frozen section interpretation in real time.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 18:30:23 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Cao", "Junli", ""], ["S.", "B.", ""], ["Wu", "Junyan", ""], ["S.", "M.", ""], ["Zhang", "Jing W.", ""], ["D.", "M.", ""], ["D.", "Ph.", ""], ["Ye", "Jay J.", ""], ["D.", "M.", ""], ["D.", "Ph.", ""], ["Yu", "Limin", ""], ["D.", "M.", ""], ["S", "M.", ""]]}, {"id": "2011.11088", "submitter": "Hamza Saad", "authors": "Hamza Saad and Nagendra Nagarur", "title": "Data Mining Techniques in Predicting Breast Cancer", "comments": "9 pages, 4 figures, paper published in journal", "journal-ref": "J. Applied Sci., 20 (4): 124-133, 2020", "doi": "10.3923/jas.2020.124.133", "report-no": null, "categories": "q-bio.QM cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and Objective: Breast cancer, which accounts for 23% of all\ncancers, is threatening the communities of developing countries because of poor\nawareness and treatment. Early diagnosis helps a lot in the treatment of the\ndisease. The present study conducted in order to improve the prediction process\nand extract the main causes impacted the breast cancer. Materials and Methods:\nData were collected based on eight attributes for 130 Libyan women in the\nclinical stages infected with this disease. Data mining was used by applying\nsix algorithms to predict disease based on clinical stages. All the algorithms\ngain high accuracy, but the decision tree provides the highest accuracy-diagram\nof decision tree utilized to build rules from each leafnode. Ranking variables\napplied to extract significant variables and support final rules to predict\ndisease. Results: All applied algorithms were gained a high prediction with\ndifferent accuracies. Rules 1, 3, 4, 5 and 9 provided a pure subset to be\nconfirmed as significant rules. Only five input variables contributed to\nbuilding rules, but not all variables have a significant impact. Conclusion:\nTumor size plays a vital role in constructing all rules with a significant\nimpact. Variables of inheritance, breast side and menopausal status have an\ninsignificant impact in analysis, but they may consider remarkable findings\nusing a different strategy of data analysis.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 19:12:15 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Saad", "Hamza", ""], ["Nagarur", "Nagendra", ""]]}, {"id": "2011.11096", "submitter": "Braxton Osting", "authors": "Ryeongkyung Yoon, Harish S. Bhat, Braxton Osting", "title": "A non-autonomous equation discovery method for time signal\n  classification", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Certain neural network architectures, in the infinite-layer limit, lead to\nsystems of nonlinear differential equations. Motivated by this idea, we develop\na framework for analyzing time signals based on non-autonomous dynamical\nequations. We view the time signal as a forcing function for a dynamical system\nthat governs a time-evolving hidden variable. As in equation discovery, the\ndynamical system is represented using a dictionary of functions and the\ncoefficients are learned from data. This framework is applied to the time\nsignal classification problem. We show how gradients can be efficiently\ncomputed using the adjoint method, and we apply methods from dynamical systems\nto establish stability of the classifier. Through a variety of experiments, on\nboth synthetic and real datasets, we show that the proposed method uses orders\nof magnitude fewer parameters than competing methods, while achieving\ncomparable accuracy. We created the synthetic datasets using dynamical systems\nof increasing complexity; though the ground truth vector fields are often\npolynomials, we find consistently that a Fourier dictionary yields the best\nresults. We also demonstrate how the proposed method yields graphical\ninterpretability in the form of phase portraits.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 20:03:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yoon", "Ryeongkyung", ""], ["Bhat", "Harish S.", ""], ["Osting", "Braxton", ""]]}, {"id": "2011.11117", "submitter": "El Mehdi Saad", "authors": "El Mehdi Saad, Gilles Blanchard, Sylvain Arlot", "title": "Online Orthogonal Matching Pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy algorithms for feature selection are widely used for recovering sparse\nhigh-dimensional vectors in linear models. In classical procedures, the main\nemphasis was put on the sample complexity, with little or no consideration of\nthe computation resources required. We present a novel online algorithm: Online\nOrthogonal Matching Pursuit (OOMP) for online support recovery in the random\ndesign setting of sparse linear regression. Our procedure selects features\nsequentially, alternating between allocation of samples only as needed to\ncandidate features, and optimization over the selected set of variables to\nestimate the regression coefficients. Theoretical guarantees about the output\nof this algorithm are proven and its computational complexity is analysed.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 21:59:05 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 12:44:51 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Saad", "El Mehdi", ""], ["Blanchard", "Gilles", ""], ["Arlot", "Sylvain", ""]]}, {"id": "2011.11124", "submitter": "Li Wang", "authors": "Li Wang, Lei-Hong Zhang, Chungen Shen, and Ren-Cang Li", "title": "Uncorrelated Semi-paired Subspace Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view datasets are increasingly collected in many real-world\napplications, and we have seen better learning performance by existing\nmulti-view learning methods than by conventional single-view learning methods\napplied to each view individually. But, most of these multi-view learning\nmethods are built on the assumption that at each instance no view is missing\nand all data points from all views must be perfectly paired. Hence they cannot\nhandle unpaired data but ignore them completely from their learning process.\nHowever, unpaired data can be more abundant in reality than paired ones and\nsimply ignoring all unpaired data incur tremendous waste in resources. In this\npaper, we focus on learning uncorrelated features by semi-paired subspace\nlearning, motivated by many existing works that show great successes of\nlearning uncorrelated features. Specifically, we propose a generalized\nuncorrelated multi-view subspace learning framework, which can naturally\nintegrate many proven learning criteria on the semi-paired data. To showcase\nthe flexibility of the framework, we instantiate five new semi-paired models\nfor both unsupervised and semi-supervised learning. We also design a successive\nalternating approximation (SAA) method to solve the resulting optimization\nproblem and the method can be combined with the powerful Krylov subspace\nprojection technique if needed. Extensive experimental results on multi-view\nfeature extraction and multi-modality classification show that our proposed\nmodels perform competitively to or better than the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 22:14:20 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Li", ""], ["Zhang", "Lei-Hong", ""], ["Shen", "Chungen", ""], ["Li", "Ren-Cang", ""]]}, {"id": "2011.11128", "submitter": "Junhua Li", "authors": "Shu Gong, Kaibo Xing, Andrzej Cichocki, Junhua Li", "title": "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period", "comments": "Accepted for publication in the IEEE Transactions on Cognitive and\n  Developmental Systems", "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems, 2021", "doi": "10.1109/TCDS.2021.3079712", "report-no": null, "categories": "eess.SP cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has achieved excellent performance in a wide range of domains,\nespecially in speech recognition and computer vision. Relatively less work has\nbeen done for EEG, but there is still significant progress attained in the last\ndecade. Due to the lack of a comprehensive and topic widely covered survey for\ndeep learning in EEG, we attempt to summarize recent progress to provide an\noverview, as well as perspectives for future developments. We first briefly\nmention the artifacts removal for EEG signal and then introduce deep learning\nmodels that have been utilized in EEG processing and classification.\nSubsequently, the applications of deep learning in EEG are reviewed by\ncategorizing them into groups such as brain-computer interface, disease\ndetection, and emotion recognition. They are followed by the discussion, in\nwhich the pros and cons of deep learning are presented and future directions\nand challenges for deep learning in EEG are proposed. We hope that this paper\ncould serve as a summary of past work for deep learning in EEG and the\nbeginning of further developments and achievements of EEG studies based on deep\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 22:34:26 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 17:43:53 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 19:24:56 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Gong", "Shu", ""], ["Xing", "Kaibo", ""], ["Cichocki", "Andrzej", ""], ["Li", "Junhua", ""]]}, {"id": "2011.11134", "submitter": "Yuanxin Zhong", "authors": "Yuanxin Zhong", "title": "Differentiable Computational Geometry for 2D and 3D machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the growth of machine learning algorithms with geometry primitives, a\nhigh-efficiency library with differentiable geometric operators are desired. We\npresent an optimized Differentiable Geometry Algorithm Library (DGAL) loaded\nwith implementations of differentiable operators for geometric primitives like\nlines and polygons. The library is a header-only templated C++ library with GPU\nsupport. We discuss the internal design of the library and benchmark its\nperformance on some tasks with other implementations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 23:22:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhong", "Yuanxin", ""]]}, {"id": "2011.11136", "submitter": "Amir Mohammad Esmaieeli Sikaroudi", "authors": "Amir Mohammad Esmaieeli Sikaroudi, Md Habibor Rahman", "title": "Predictive process mining by network of classifiers and clusterers: the\n  PEDF model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this research, a model is proposed to learn from event log and predict\nfuture events of a system. The proposed PEDF model learns based on events'\nsequences, durations, and extra features. The PEDF model is built by a network\nmade of standard clusterers and classifiers, and it has high flexibility to\nupdate the model iteratively. The model requires to extract two sets of data\nfrom log files i.e., transition differences, and cumulative features. The model\nhas one layer of memory which means that each transition is dependent on both\nthe current event and the previous event. To evaluate the performance of the\nproposed model, it is compared to the Recurrent Neural Network and Sequential\nPrediction models, and it outperforms them. Since there is missing performance\nmeasure for event log prediction models, three measures are proposed.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 23:27:19 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Sikaroudi", "Amir Mohammad Esmaieeli", ""], ["Rahman", "Md Habibor", ""]]}, {"id": "2011.11150", "submitter": "Ignavier Ng", "authors": "Ignavier Ng, S\\'ebastien Lachapelle, Nan Rosemary Ke, Simon\n  Lacoste-Julien", "title": "On the Convergence of Continuous Constrained Optimization for Structure\n  Learning", "comments": "NeurIPS 2020 Workshop on Causal Discovery and Causality-Inspired\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure learning of directed acyclic graphs (DAGs) is a fundamental problem\nin many scientific endeavors. A new line of work, based on NOTEARS (Zheng et\nal., 2018), reformulates the structure learning problem as a continuous\noptimization one by leveraging an algebraic characterization of DAG constraint.\nThe constrained problem is typically solved using the augmented Lagrangian\nmethod (ALM) which is often preferred to the quadratic penalty method (QPM) by\nvirtue of its convergence result that does not require the penalty coefficient\nto go to infinity, hence avoiding ill-conditioning. In this work, we review the\nstandard convergence result of the ALM and show that the required conditions\nare not satisfied in the recent continuous constrained formulation for learning\nDAGs. We demonstrate empirically that its behavior is akin to that of the QPM\nwhich is prone to ill-conditioning, thus motivating the use of second-order\nmethod in this setting. We also establish the convergence guarantee of QPM to a\nDAG solution, under mild conditions, based on a property of the DAG constraint\nterm.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 00:29:37 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 21:04:44 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Ng", "Ignavier", ""], ["Lachapelle", "S\u00e9bastien", ""], ["Ke", "Nan Rosemary", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2011.11151", "submitter": "Zeyd Boukhers", "authors": "Zeyd Boukhers, Danniene Wete and Steffen Staab", "title": "LaHAR: Latent Human Activity Recognition using LDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Processing sequential multi-sensor data becomes important in many tasks due\nto the dramatic increase in the availability of sensors that can acquire\nsequential data over time. Human Activity Recognition (HAR) is one of the\nfields which are actively benefiting from this availability. Unlike most of the\napproaches addressing HAR by considering predefined activity classes, this\npaper proposes a novel approach to discover the latent HAR patterns in\nsequential data. To this end, we employed Latent Dirichlet Allocation (LDA),\nwhich is initially a topic modelling approach used in text analysis. To make\nthe data suitable for LDA, we extract the so-called \"sensory words\" from the\nsequential data. We carried out experiments on a challenging HAR dataset,\ndemonstrating that LDA is capable of uncovering underlying structures in\nsequential data, which provide a human-understandable representation of the\ndata. The extrinsic evaluations reveal that LDA is capable of accurately\nclustering HAR data sequences compared to the labelled activities.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 00:33:01 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Boukhers", "Zeyd", ""], ["Wete", "Danniene", ""], ["Staab", "Steffen", ""]]}, {"id": "2011.11152", "submitter": "Zeke Xie", "authors": "Zeke Xie, Issei Sato, Masashi Sugiyama", "title": "Stable Weight Decay Regularization", "comments": "20 pages, 18 figures, Weight Decay", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight decay is a popular regularization technique for training of deep\nneural networks. Modern deep learning libraries mainly use $L_{2}$\nregularization as the default implementation of weight decay.\n\\citet{loshchilov2018decoupled} demonstrated that $L_{2}$ regularization is not\nidentical to weight decay for adaptive gradient methods, such as Adaptive\nMomentum Estimation (Adam), and proposed Adam with Decoupled Weight Decay\n(AdamW). However, we found that the popular implementations of weight decay,\nincluding $L_{2}$ regularization and decoupled weight decay, in modern deep\nlearning libraries usually damage performance. First, the $L_{2}$\nregularization is unstable weight decay for all optimizers that use Momentum,\nsuch as stochastic gradient descent (SGD). Second, decoupled weight decay is\nhighly unstable for all adaptive gradient methods. We further propose the\nStable Weight Decay (SWD) method to fix the unstable weight decay problem from\na dynamical perspective. The proposed SWD method makes significant improvements\nover $L_{2}$ regularization and decoupled weight decay in our experiments.\nSimply fixing weight decay in Adam by SWD, with no extra hyperparameter, can\nusually outperform complex Adam variants, which have more hyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 00:39:49 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 05:09:37 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 04:47:42 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Xie", "Zeke", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2011.11160", "submitter": "Hong Lin", "authors": "Hong Lin, Lidan Shou, Ke Chen, Gang Chen, Sai Wu", "title": "LINDT: Tackling Negative Federated Learning with Local Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a promising distributed learning paradigm, which\nallows a number of data owners (also called clients) to collaboratively learn a\nshared model without disclosing each client's data. However, FL may fail to\nproceed properly, amid a state that we call negative federated learning (NFL).\nThis paper addresses the problem of negative federated learning. We formulate a\nrigorous definition of NFL and analyze its essential cause. We propose a novel\nframework called LINDT for tackling NFL in run-time. The framework can\npotentially work with any neural-network-based FL systems for NFL detection and\nrecovery. Specifically, we introduce a metric for detecting NFL from the\nserver. On occasion of NFL recovery, the framework makes adaptation to the\nfederated model on each client's local data by learning a Layer-wise\nIntertwined Dual-model. Experiment results show that the proposed approach can\nsignificantly improve the performance of FL on local data in various scenarios\nof NFL.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 01:31:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lin", "Hong", ""], ["Shou", "Lidan", ""], ["Chen", "Ke", ""], ["Chen", "Gang", ""], ["Wu", "Sai", ""]]}, {"id": "2011.11181", "submitter": "Sitan Chen", "authors": "Sitan Chen, Xiaoxiao Li, Zhao Song, Danyang Zhuo", "title": "On InstaHide, Phase Retrieval, and Sparse Matrix Factorization", "comments": "30 pages, to appear in ICLR 2021, v2: updated discussion of follow-up\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we examine the security of InstaHide, a scheme recently\nproposed by [Huang, Song, Li and Arora, ICML'20] for preserving the security of\nprivate datasets in the context of distributed learning. To generate a\nsynthetic training example to be shared among the distributed learners,\nInstaHide takes a convex combination of private feature vectors and randomly\nflips the sign of each entry of the resulting vector with probability 1/2. A\nsalient question is whether this scheme is secure in any provable sense,\nperhaps under a plausible hardness assumption and assuming the distributions\ngenerating the public and private data satisfy certain properties.\n  We show that the answer to this appears to be quite subtle and closely\nrelated to the average-case complexity of a new multi-task, missing-data\nversion of the classic problem of phase retrieval. Motivated by this\nconnection, we design a provable algorithm that can recover private vectors\nusing only the public vectors and synthetic vectors generated by InstaHide,\nunder the assumption that the private and public vectors are isotropic\nGaussian.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:47:08 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 00:08:38 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Xiaoxiao", ""], ["Song", "Zhao", ""], ["Zhuo", "Danyang", ""]]}, {"id": "2011.11183", "submitter": "Junnan Li Dr", "authors": "Junnan Li, Caiming Xiong, Steven Hoi", "title": "CoMatch: Semi-supervised Learning with Contrastive Graph Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning has been an effective paradigm for leveraging\nunlabeled data to reduce the reliance on labeled data. We propose CoMatch, a\nnew semi-supervised learning method that unifies dominant approaches and\naddresses their limitations. CoMatch jointly learns two representations of the\ntraining data, their class probabilities and low-dimensional embeddings. The\ntwo representations interact with each other to jointly evolve. The embeddings\nimpose a smoothness constraint on the class probabilities to improve the\npseudo-labels, whereas the pseudo-labels regularize the structure of the\nembeddings through graph-based contrastive learning. CoMatch achieves\nstate-of-the-art performance on multiple datasets. It achieves substantial\naccuracy improvements on the label-scarce CIFAR-10 and STL-10. On ImageNet with\n1% labels, CoMatch achieves a top-1 accuracy of 66.0%, outperforming FixMatch\nby 12.6%. Furthermore, CoMatch achieves better representation learning\nperformance on downstream tasks, outperforming both supervised learning and\nself-supervised learning. Code and pre-trained models are available at\nhttps://github.com/salesforce/CoMatch.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:54:57 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 01:58:15 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Li", "Junnan", ""], ["Xiong", "Caiming", ""], ["Hoi", "Steven", ""]]}, {"id": "2011.11188", "submitter": "Stanimire Tomov", "authors": "Rick Archibald, Edmond Chow, Eduardo D'Azevedo, Jack Dongarra, Markus\n  Eisenbach, Rocco Febbo, Florent Lopez, Daniel Nichols, Stanimire Tomov, Kwai\n  Wong, and Junqi Yin", "title": "Integrating Deep Learning in Domain Sciences at Exascale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents some of the current challenges in designing deep learning\nartificial intelligence (AI) and integrating it with traditional\nhigh-performance computing (HPC) simulations. We evaluate existing packages for\ntheir ability to run deep learning models and applications on large-scale HPC\nsystems efficiently, identify challenges, and propose new asynchronous\nparallelization and optimization techniques for current large-scale\nheterogeneous systems and upcoming exascale systems. These developments, along\nwith existing HPC AI software capabilities, have been integrated into MagmaDNN,\nan open-source HPC deep learning framework. Many deep learning frameworks are\ntargeted at data scientists and fall short in providing quality integration\ninto existing HPC workflows. This paper discusses the necessities of an HPC\ndeep learning framework and how those needs can be provided (e.g., as in\nMagmaDNN) through a deep integration with existing HPC libraries, such as MAGMA\nand its modular memory management, MPI, CuBLAS, CuDNN, MKL, and HIP.\nAdvancements are also illustrated through the use of algorithmic enhancements\nin reduced- and mixed-precision, as well as asynchronous optimization methods.\nFinally, we present illustrations and potential solutions for enhancing\ntraditional compute- and data-intensive applications at ORNL and UTK with AI.\nThe approaches and future challenges are illustrated in materials science,\nimaging, and climate applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 03:09:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Archibald", "Rick", ""], ["Chow", "Edmond", ""], ["D'Azevedo", "Eduardo", ""], ["Dongarra", "Jack", ""], ["Eisenbach", "Markus", ""], ["Febbo", "Rocco", ""], ["Lopez", "Florent", ""], ["Nichols", "Daniel", ""], ["Tomov", "Stanimire", ""], ["Wong", "Kwai", ""], ["Yin", "Junqi", ""]]}, {"id": "2011.11194", "submitter": "Xiang Fang", "authors": "Xiang Fang, Yuchong Hu, Pan Zhou, Dapeng Oliver Wu", "title": "V3H: View Variation and View Heredity for Incomplete Multi-view\n  Clustering", "comments": "Publisheded in IEEE Transactions on Artificial Intelligence", "journal-ref": "IEEE Transactions on Artificial Intelligence 2020", "doi": "10.1109/TAI.2021.3052425", "report-no": "vol. 1, no. 3, pp. 233-247, Dec. 2020", "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real data often appear in the form of multiple incomplete views. Incomplete\nmulti-view clustering is an effective method to integrate these incomplete\nviews. Previous methods only learn the consistent information between different\nviews and ignore the unique information of each view, which limits their\nclustering performance and generalizations. To overcome this limitation, we\npropose a novel View Variation and View Heredity approach (V3H). Inspired by\nthe variation and the heredity in genetics, V3H first decomposes each subspace\ninto a variation matrix for the corresponding view and a heredity matrix for\nall the views to represent the unique information and the consistent\ninformation respectively. Then, by aligning different views based on their\ncluster indicator matrices, V3H integrates the unique information from\ndifferent views to improve the clustering performance. Finally, with the help\nof the adjustable low-rank representation based on the heredity matrix, V3H\nrecovers the underlying true data structure to reduce the influence of the\nlarge incompleteness. More importantly, V3H presents possibly the first work to\nintroduce genetics to clustering algorithms for learning simultaneously the\nconsistent information and the unique information from incomplete multi-view\ndata. Extensive experimental results on fifteen benchmark datasets validate its\nsuperiority over other state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 03:24:48 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 16:47:52 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 08:34:39 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Fang", "Xiang", ""], ["Hu", "Yuchong", ""], ["Zhou", "Pan", ""], ["Wu", "Dapeng Oliver", ""]]}, {"id": "2011.11197", "submitter": "Haobo Wang", "authors": "Weiwei Liu, Xiaobo Shen, Haobo Wang, Ivor W. Tsang", "title": "The Emerging Trends of Multi-Label Learning", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exabytes of data are generated daily by humans, leading to the growing need\nfor new efforts in dealing with the grand challenges for multi-label learning\nbrought by big data. For example, extreme multi-label classification is an\nactive and rapidly growing research area that deals with classification tasks\nwith an extremely large number of classes or labels; utilizing massive data\nwith limited supervision to build a multi-label classification model becomes\nvaluable for practical applications, etc. Besides these, there are tremendous\nefforts on how to harvest the strong learning capability of deep learning to\nbetter capture the label dependencies in multi-label learning, which is the key\nfor deep learning to address real-world classification tasks. However, it is\nnoted that there has been a lack of systemic studies that focus explicitly on\nanalyzing the emerging trends and new challenges of multi-label learning in the\nera of big data. It is imperative to call for a comprehensive survey to fulfill\nthis mission and delineate future research directions and new applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 03:36:00 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 09:10:59 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Liu", "Weiwei", ""], ["Shen", "Xiaobo", ""], ["Wang", "Haobo", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2011.11199", "submitter": "Mehrdad Farajtabar", "authors": "Mehrdad Farajtabar, Andrew Lee, Yuanjian Feng, Vishal Gupta, Peter\n  Dolan, Harish Chandran, Martin Szummer", "title": "Balance Regularized Neural Network Models for Causal Effect Estimation", "comments": "Causal Discovery & Causality-Inspired Machine Learning Workshop at\n  Neural Information Processing Systems, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating individual and average treatment effects from observational data\nis an important problem in many domains such as healthcare and e-commerce. In\nthis paper, we advocate balance regularization of multi-head neural network\narchitectures. Our work is motivated by representation learning techniques to\nreduce differences between treated and untreated distributions that potentially\narise due to confounding factors. We further regularize the model by\nencouraging it to predict control outcomes for individuals in the treatment\ngroup that are similar to control outcomes in the control group. We empirically\nstudy the bias-variance trade-off between different weightings of the\nregularizers, as well as between inductive and transductive inference.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:03:55 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Farajtabar", "Mehrdad", ""], ["Lee", "Andrew", ""], ["Feng", "Yuanjian", ""], ["Gupta", "Vishal", ""], ["Dolan", "Peter", ""], ["Chandran", "Harish", ""], ["Szummer", "Martin", ""]]}, {"id": "2011.11200", "submitter": "Yandong Li", "authors": "Yandong Li, Xuhui Jia, Ruoxin Sang, Yukun Zhu, Bradley Green, Liqiang\n  Wang, Boqing Gong", "title": "Ranking Neural Checkpoints", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned with ranking many pre-trained deep neural networks\n(DNNs), called checkpoints, for the transfer learning to a downstream task.\nThanks to the broad use of DNNs, we may easily collect hundreds of checkpoints\nfrom various sources. Which of them transfers the best to our downstream task\nof interest? Striving to answer this question thoroughly, we establish a neural\ncheckpoint ranking benchmark (NeuCRaB) and study some intuitive ranking\nmeasures. These measures are generic, applying to the checkpoints of different\noutput types without knowing how the checkpoints are pre-trained on which\ndataset. They also incur low computation cost, making them practically\nmeaningful. Our results suggest that the linear separability of the features\nextracted by the checkpoints is a strong indicator of transferability. We also\narrive at a new ranking measure, NLEEP, which gives rise to the best\nperformance in the experiments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:05:46 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 15:21:40 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 15:39:25 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Li", "Yandong", ""], ["Jia", "Xuhui", ""], ["Sang", "Ruoxin", ""], ["Zhu", "Yukun", ""], ["Green", "Bradley", ""], ["Wang", "Liqiang", ""], ["Gong", "Boqing", ""]]}, {"id": "2011.11201", "submitter": "Wei Yu", "authors": "Wei Yu, Wenxin Chen, Songhenh Yin, Steve Easterbrook, Animesh Garg", "title": "Concept Grounding with Modular Action-Capsules in Semantic Video\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent works in video prediction have mainly focused on passive forecasting\nand low-level action-conditional prediction, which sidesteps the learning of\ninteraction between agents and objects. We introduce the task of semantic\naction-conditional video prediction, which uses semantic action labels to\ndescribe those interactions and can be regarded as an inverse problem of action\nrecognition. The challenge of this new task primarily lies in how to\neffectively inform the model of semantic action information. To bridge vision\nand language, we utilize the idea of capsule and propose a novel video\nprediction model, Modular Action Capsule Network (MAC). Our method is evaluated\non two newly designed synthetic datasets, CLEVR-Building-Blocks and\nSapien-Kitchen, and one real-world dataset called TowerCreation. Experiments\nshow that given different action labels, MAC can correctly condition on\ninstructions and generate corresponding future frames without need of bounding\nboxes. We further demonstrate that the trained model can make\nout-of-distribution generalization, be quickly adapted to new object categories\nand exploit its learnt features for object detection, showing the progression\ntowards higher-level cognitive abilities.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:12:22 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 17:56:03 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Yu", "Wei", ""], ["Chen", "Wenxin", ""], ["Yin", "Songhenh", ""], ["Easterbrook", "Steve", ""], ["Garg", "Animesh", ""]]}, {"id": "2011.11202", "submitter": "Marcel Keller", "authors": "Marcel Keller and Ke Sun", "title": "Effectiveness of MPC-friendly Softmax Replacement", "comments": "6 pages, PPML/PriML workshop at NeurIPS 2020; updated accuracy\n  figures after bug fix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Softmax is widely used in deep learning to map some representation to a\nprobability distribution. As it is based on exp/log functions that are\nrelatively expensive in multi-party computation, Mohassel and Zhang (2017)\nproposed a simpler replacement based on ReLU to be used in secure computation.\nHowever, we could not reproduce the accuracy they reported for training on\nMNIST with three fully connected layers. Later works (e.g., Wagh et al., 2019\nand 2021) used the softmax replacement not for computing the output probability\ndistribution but for approximating the gradient in back-propagation. In this\nwork, we analyze the two uses of the replacement and compare them to softmax,\nboth in terms of accuracy and cost in multi-party computation. We found that\nthe replacement only provides a significant speed-up for a one-layer network\nwhile it always reduces accuracy, sometimes significantly. Thus we conclude\nthat its usefulness is limited and one should use the original softmax function\ninstead.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:14:32 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 12:32:48 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Keller", "Marcel", ""], ["Sun", "Ke", ""]]}, {"id": "2011.11203", "submitter": "Reza Babanezhad Harikandeh", "authors": "Reza Babanezhad and Simon Lacoste-Julien", "title": "Geometry-Aware Universal Mirror-Prox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Mirror-prox (MP) is a well-known algorithm to solve variational inequality\n(VI) problems. VI with a monotone operator covers a large group of settings\nsuch as convex minimization, min-max or saddle point problems. To get a\nconvergent algorithm, the step-size of the classic MP algorithm relies heavily\non the problem dependent knowledge of the operator such as its smoothness\nparameter which is hard to estimate. Recently, a universal variant of MP for\nsmooth/bounded operators has been introduced that depends only on the norm of\nupdates in MP. In this work, we relax the dependence to evaluating the norm of\nupdates to Bregman divergence between updates. This relaxation allows us to\nextends the analysis of universal MP to the settings where the operator is not\nsmooth or bounded. Furthermore, we analyse the VI problem with a stochastic\nmonotone operator in different settings and obtain an optimal rate up to a\nlogarithmic factor.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:17:08 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Babanezhad", "Reza", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2011.11222", "submitter": "Lalit Jain", "authors": "Kwang-Sung Jun, Lalit Jain, Blake Mason, Houssam Nassif", "title": "Improved Confidence Bounds for the Linear Logistic Model and\n  Applications to Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose improved fixed-design confidence bounds for the linear logistic\nmodel. Our bounds significantly improve upon the state-of-the-art bound by Li\net al. (2017) via recent developments of the self-concordant analysis of the\nlogistic loss (Faury et al., 2020). Specifically, our confidence bound avoids a\ndirect dependence on $1/\\kappa$, where $\\kappa$ is the minimal variance over\nall arms' reward distributions. In general, $1/\\kappa$ scales exponentially\nwith the norm of the unknown linear parameter $\\theta^*$. Instead of relying on\nthis worst-case quantity, our confidence bound for the reward of any given arm\ndepends directly on the variance of that arm's reward distribution. We present\ntwo applications of our novel bounds to pure exploration and regret\nminimization logistic bandits improving upon state-of-the-art performance\nguarantees. For pure exploration, we also provide a lower bound highlighting a\ndependence on $1/\\kappa$ for a family of instances.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 05:44:26 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 04:45:43 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Jun", "Kwang-Sung", ""], ["Jain", "Lalit", ""], ["Mason", "Blake", ""], ["Nassif", "Houssam", ""]]}, {"id": "2011.11226", "submitter": "Sushma Ravichandran", "authors": "Ankit Murarka, Balaji Radhakrishnan, Sushma Ravichandran", "title": "Detection and Classification of mental illnesses on social media using\n  RoBERTa", "comments": "8 pages, 1 figure, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the current social distancing regulations across the world, social\nmedia has become the primary mode of communication for most people. This has\nresulted in the isolation of many people suffering from mental illnesses who\nare unable to receive assistance in person. They have increasingly turned to\nsocial media to express themselves and to look for guidance in dealing with\ntheir illnesses. Keeping this in mind, we propose a solution to detect and\nclassify mental illness posts on social media thereby enabling users to seek\nappropriate help. In this work, we detect and classify five prominent kinds of\nmental illnesses: depression, anxiety, bipolar disorder, ADHD and PTSD by\nanalyzing unstructured user data on social media platforms. In addition, we are\nsharing a new high-quality dataset to drive research on this topic. We believe\nthat our work is the first multi-class model that uses a Transformer-based\narchitecture such as RoBERTa to analyze people's emotions and psychology. We\nalso demonstrate how we stress-test our model using behavioral testing. With\nthis research, we hope to be able to contribute to the public health system by\nautomating some of the detection and classification process.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 05:54:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Murarka", "Ankit", ""], ["Radhakrishnan", "Balaji", ""], ["Ravichandran", "Sushma", ""]]}, {"id": "2011.11233", "submitter": "Xiangxiang Chu", "authors": "Xiaoxing Wang and Xiangxiang Chu and Yuda Fan and Zhexi Zhang and\n  Xiaolin Wei and Junchi Yan and Xiaokang Yang", "title": "ROME: Robustifying Memory-Efficient NAS via Topology Disentanglement and\n  Gradients Accumulation", "comments": "Observe new collapse in memory efficient NAS and address it using\n  ROME", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-path based differentiable neural architecture search has great\nstrengths for its low computational cost and memory-friendly nature. However,\nwe surprisingly discover that it suffers from severe searching instability\nwhich has been primarily ignored, posing a potential weakness for a wider\napplication. In this paper, we delve into its performance collapse issue and\npropose a new algorithm called RObustifying Memory-Efficient NAS (ROME).\nSpecifically, 1) for consistent topology in the search and evaluation stage, we\ninvolve separate parameters to disentangle the topology from the operations of\nthe architecture. In such a way, we can independently sample connections and\noperations without interference; 2) to discount sampling unfairness and\nvariance, we enforce fair sampling for weight update and apply a gradient\naccumulation mechanism for architecture parameters. Extensive experiments\ndemonstrate that our proposed method has strong performance and robustness,\nwhere it mostly achieves state-of-the-art results on a large number of standard\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 06:34:07 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Xiaoxing", ""], ["Chu", "Xiangxiang", ""], ["Fan", "Yuda", ""], ["Zhang", "Zhexi", ""], ["Wei", "Xiaolin", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""]]}, {"id": "2011.11235", "submitter": "Taylor Killian", "authors": "Taylor W. Killian, Haoran Zhang, Jayakumar Subramanian, Mehdi Fatemi,\n  Marzyeh Ghassemi", "title": "An Empirical Study of Representation Learning for Reinforcement Learning\n  in Healthcare", "comments": "To appear in proceedings of the 2020 Machine Learning for Health\n  workshop at NeurIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement Learning (RL) has recently been applied to sequential\nestimation and prediction problems identifying and developing hypothetical\ntreatment strategies for septic patients, with a particular focus on offline\nlearning with observational data. In practice, successful RL relies on\ninformative latent states derived from sequential observations to develop\noptimal treatment strategies. To date, how best to construct such states in a\nhealthcare setting is an open question. In this paper, we perform an empirical\nstudy of several information encoding architectures using data from septic\npatients in the MIMIC-III dataset to form representations of a patient state.\nWe evaluate the impact of representation dimension, correlations with\nestablished acuity scores, and the treatment policies derived from them. We\nfind that sequentially formed state representations facilitate effective policy\nlearning in batch settings, validating a more thoughtful approach to\nrepresentation learning that remains faithful to the sequential and partial\nnature of healthcare data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 06:37:08 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Killian", "Taylor W.", ""], ["Zhang", "Haoran", ""], ["Subramanian", "Jayakumar", ""], ["Fatemi", "Mehdi", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "2011.11236", "submitter": "Rahul Singh", "authors": "Rahul Singh, Qinsheng Zhang, Yongxin Chen", "title": "Learning Hidden Markov Models from Aggregate Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.IV eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an algorithm for estimating the parameters of a\ntime-homogeneous hidden Markov model from aggregate observations. This problem\narises when only the population level counts of the number of individuals at\neach time step are available, from which one seeks to learn the individual\nhidden Markov model. Our algorithm is built upon expectation-maximization and\nthe recently proposed aggregate inference algorithm, the Sinkhorn belief\npropagation. As compared with existing methods such as expectation-maximization\nwith non-linear belief propagation, our algorithm exhibits convergence\nguarantees. Moreover, our learning framework naturally reduces to the standard\nBaum-Welch learning algorithm when observations corresponding to a single\nindividual are recorded. We further extend our learning algorithm to handle\nHMMs with continuous observations. The efficacy of our algorithm is\ndemonstrated on a variety of datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 06:41:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Singh", "Rahul", ""], ["Zhang", "Qinsheng", ""], ["Chen", "Yongxin", ""]]}, {"id": "2011.11248", "submitter": "Morgane Austern", "authors": "Morgane Austern, Vasilis Syrgkanis", "title": "Asymptotics of the Empirical Bootstrap Method Beyond Asymptotic\n  Normality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most commonly used methods for forming confidence intervals for\nstatistical inference is the empirical bootstrap, which is especially expedient\nwhen the limiting distribution of the estimator is unknown. However, despite\nits ubiquitous role, its theoretical properties are still not well understood\nfor non-asymptotically normal estimators. In this paper, under stability\nconditions, we establish the limiting distribution of the empirical bootstrap\nestimator, derive tight conditions for it to be asymptotically consistent, and\nquantify the speed of convergence. Moreover, we propose three alternative ways\nto use the bootstrap method to build confidence intervals with coverage\nguarantees. Finally, we illustrate the generality and tightness of our results\nby a series of examples, including uniform confidence bands, two-sample kernel\ntests, minmax stochastic programs and the empirical risk of stacked estimators.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 07:14:30 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Austern", "Morgane", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "2011.11256", "submitter": "Ziang Long", "authors": "Ziang Long, Penghang Yin, Jack Xin", "title": "Learning Quantized Neural Nets by Coarse Gradient Method for Non-linear\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantized or low-bit neural networks are attractive due to their inference\nefficiency. However, training deep neural networks with quantized activations\ninvolves minimizing a discontinuous and piecewise constant loss function. Such\na loss function has zero gradients almost everywhere (a.e.), which makes the\nconventional gradient-based algorithms inapplicable. To this end, we study a\nnovel class of \\emph{biased} first-order oracle, termed coarse gradient, for\novercoming the vanished gradient issue. A coarse gradient is generated by\nreplacing the a.e. zero derivatives of quantized (i.e., stair-case) ReLU\nactivation composited in the chain rule with some heuristic proxy derivative\ncalled straight-through estimator (STE). Although having been widely used in\ntraining quantized networks empirically, fundamental questions like when and\nwhy the ad-hoc STE trick works, still lacks theoretical understanding. In this\npaper, we propose a class of STEs with certain monotonicity, and consider their\napplications to the training of a two-linear-layer network with quantized\nactivation functions for non-linear multi-category classification. We establish\nperformance guarantees for the proposed STEs by showing that the corresponding\ncoarse gradient methods converge to the global minimum, which leads to a\nperfect classification. Lastly, we present experimental results on synthetic\ndata as well as MNIST dataset to verify our theoretical findings and\ndemonstrate the effectiveness of our proposed STEs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 07:50:09 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 04:00:20 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Long", "Ziang", ""], ["Yin", "Penghang", ""], ["Xin", "Jack", ""]]}, {"id": "2011.11257", "submitter": "Lars Ankile", "authors": "Lars Lien Ankile, Morgan Feet Heggland, Kjartan Krange", "title": "Application of Facial Recognition using Convolutional Neural Networks\n  for Entry Access Control", "comments": "10 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this paper is to design a solution to the problem of facial\nrecognition by use of convolutional neural networks, with the intention of\napplying the solution in a camera-based home-entry access control system. More\nspecifically, the paper focuses on solving the supervised classification\nproblem of taking images of people as input and classifying the person in the\nimage as one of the authors or not. Two approaches are proposed: (1) building\nand training a neural network called WoodNet from scratch and (2) leveraging\ntransfer learning by utilizing a network pre-trained on the ImageNet database\nand adapting it to this project's data and classes. In order to train the\nmodels to recognize the authors, a dataset containing more than 150 000 images\nhas been created, balanced over the authors and others. Image extraction from\nvideos and image augmentation techniques were instrumental for dataset\ncreation. The results are two models classifying the individuals in the dataset\nwith high accuracy, achieving over 99% accuracy on held-out test data. The\npre-trained model fitted significantly faster than WoodNet, and seems to\ngeneralize better. However, these results come with a few caveats. Because of\nthe way the dataset was compiled, as well as the high accuracy, one has reason\nto believe the models over-fitted to the data to some degree. An added\nconsequence of the data compilation method is that the test dataset may not be\nsufficiently different from the training data, limiting its ability to validate\ngeneralization of the models. However, utilizing the models in a web-cam based\nsystem, classifying faces in real-time, shows promising results and indicates\nthat the models generalized fairly well for at least some of the classes (see\nthe accompanying video).\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 07:55:24 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ankile", "Lars Lien", ""], ["Heggland", "Morgan Feet", ""], ["Krange", "Kjartan", ""]]}, {"id": "2011.11259", "submitter": "Francesco Zamponi", "authors": "Pierre Barrat-Charlaix, Anna Paola Muntoni, Kai Shimagaki, Martin\n  Weigt, Francesco Zamponi", "title": "Sparse generative modeling via parameter-reduction of Boltzmann\n  machines: application to protein-sequence families", "comments": "7 pages, 5 figures, plus Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines (BM) are widely used as generative models. For example,\npairwise Potts models (PM), which are instances of the BM class, provide\naccurate statistical models of families of evolutionarily related protein\nsequences. Their parameters are the local fields, which describe site-specific\npatterns of amino-acid conservation, and the two-site couplings, which mirror\nthe coevolution between pairs of sites. This coevolution reflects structural\nand functional constraints acting on protein sequences during evolution. The\nmost conservative choice to describe the coevolution signal is to include all\npossible two-site couplings into the PM. This choice, typical of what is known\nas Direct Coupling Analysis, has been successful for predicting residue\ncontacts in the three-dimensional structure, mutational effects, and in\ngenerating new functional sequences. However, the resulting PM suffers from\nimportant over-fitting effects: many couplings are small, noisy and hardly\ninterpretable; the PM is close to a critical point, meaning that it is highly\nsensitive to small parameter perturbations. In this work, we introduce a\ngeneral parameter-reduction procedure for BMs, via a controlled iterative\ndecimation of the less statistically significant couplings, identified by an\ninformation-based criterion that selects either weak or statistically\nunsupported couplings. For several protein families, our procedure allows one\nto remove more than $90\\%$ of the PM couplings, while preserving the predictive\nand generative properties of the original dense PM, and the resulting model is\nfar away from criticality, hence more robust to noise.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 08:01:09 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 17:00:00 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Barrat-Charlaix", "Pierre", ""], ["Muntoni", "Anna Paola", ""], ["Shimagaki", "Kai", ""], ["Weigt", "Martin", ""], ["Zamponi", "Francesco", ""]]}, {"id": "2011.11261", "submitter": "Zehua Zhang", "authors": "Zehua Zhang and David Crandall", "title": "Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised\n  Video Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel way for self-supervised video representation learning by:\n(a) decoupling the learning objective into two contrastive subtasks\nrespectively emphasizing spatial and temporal features, and (b) performing it\nhierarchically to encourage multi-scale understanding. Motivated by their\neffectiveness in supervised learning, we first introduce spatial-temporal\nfeature learning decoupling and hierarchical learning to the context of\nunsupervised video learning. In particular, our method directs the network to\nseparately capture spatial and temporal features on the basis of contrastive\nlearning via manipulating augmentations as regularization, and further solve\nsuch proxy tasks hierarchically by optimizing towards a compound contrastive\nloss. Experiments show that our proposed Hierarchically Decoupled\nSpatial-Temporal Contrast (HDC) achieves substantial gains over directly\nlearning spatial-temporal features as a whole and significantly outperforms\nother state-of-the-art unsupervised methods on downstream action recognition\nbenchmarks on UCF101 and HMDB51. We will release our code and pretrained\nweights.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 08:05:39 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhang", "Zehua", ""], ["Crandall", "David", ""]]}, {"id": "2011.11263", "submitter": "Raviraj Joshi", "authors": "Ramchandra Joshi, Raviraj Joshi", "title": "Evaluating Input Representation for Language Identification in\n  Hindi-English Code Mixed Text", "comments": "Accepted at ICDSMLA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) techniques have become mainstream in the\nrecent decade. Most of these advances are attributed to the processing of a\nsingle language. More recently, with the extensive growth of social media\nplatforms focus has shifted to code-mixed text. The code-mixed text comprises\ntext written in more than one language. People naturally tend to combine local\nlanguage with global languages like English. To process such texts, current NLP\ntechniques are not sufficient. As a first step, the text is processed to\nidentify the language of the words in the text. In this work, we focus on\nlanguage identification in code-mixed sentences for Hindi-English mixed text.\nThe task of language identification is formulated as a token classification\ntask. In the supervised setting, each word in the sentence has an associated\nlanguage label. We evaluate different deep learning models and input\nrepresentation combinations for this task. Mainly, character, sub-word, and\nword embeddings are considered in combination with CNN and LSTM based models.\nWe show that sub-word representation along with the LSTM model gives the best\nresults. In general sub-word representations perform significantly better than\nother input representations. We report the best accuracy of 94.52% using a\nsingle layer LSTM model on the standard SAIL ICON 2017 test set.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 08:08:09 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 13:22:04 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Joshi", "Ramchandra", ""], ["Joshi", "Raviraj", ""]]}, {"id": "2011.11266", "submitter": "Miao Yang", "authors": "Miao Yang, Akitanoshou Wong, Hongbin Zhu, Haifeng Wang, Hua Qian", "title": "Federated learning with class imbalance reduction", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising technique that enables a large amount\nof edge computing devices to collaboratively train a global learning model. Due\nto privacy concerns, the raw data on devices could not be available for\ncentralized server. Constrained by the spectrum limitation and computation\ncapacity, only a subset of devices can be engaged to train and transmit the\ntrained model to centralized server for aggregation. Since the local data\ndistribution varies among all devices, class imbalance problem arises along\nwith the unfavorable client selection, resulting in a slow converge rate of the\nglobal model. In this paper, an estimation scheme is designed to reveal the\nclass distribution without the awareness of raw data. Based on the scheme, a\ndevice selection algorithm towards minimal class imbalance is proposed, thus\ncan improve the convergence performance of the global model. Simulation results\ndemonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 08:13:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yang", "Miao", ""], ["Wong", "Akitanoshou", ""], ["Zhu", "Hongbin", ""], ["Wang", "Haifeng", ""], ["Qian", "Hua", ""]]}, {"id": "2011.11270", "submitter": "Zhuo Xu", "authors": "Zhuo Xu, Wenhao Yu, Alexander Herzog, Wenlong Lu, Chuyuan Fu,\n  Masayoshi Tomizuka, Yunfei Bai, C. Karen Liu, Daniel Ho", "title": "COCOI: Contact-aware Online Context Inference for Generalizable\n  Non-planar Pushing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General contact-rich manipulation problems are long-standing challenges in\nrobotics due to the difficulty of understanding complicated contact physics.\nDeep reinforcement learning (RL) has shown great potential in solving robot\nmanipulation tasks. However, existing RL policies have limited adaptability to\nenvironments with diverse dynamics properties, which is pivotal in solving many\ncontact-rich manipulation tasks. In this work, we propose Contact-aware Online\nCOntext Inference (COCOI), a deep RL method that encodes a context embedding of\ndynamics properties online using contact-rich interactions. We study this\nmethod based on a novel and challenging non-planar pushing task, where the\nrobot uses a monocular camera image and wrist force torque sensor reading to\npush an object to a goal location while keeping it upright. We run extensive\nexperiments to demonstrate the capability of COCOI in a wide range of settings\nand dynamics properties in simulation, and also in a sim-to-real transfer\nscenario on a real robot (Video: https://youtu.be/nrmJYksh1Kc)\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 08:20:21 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Xu", "Zhuo", ""], ["Yu", "Wenhao", ""], ["Herzog", "Alexander", ""], ["Lu", "Wenlong", ""], ["Fu", "Chuyuan", ""], ["Tomizuka", "Masayoshi", ""], ["Bai", "Yunfei", ""], ["Liu", "C. Karen", ""], ["Ho", "Daniel", ""]]}, {"id": "2011.11271", "submitter": "Furao Shen", "authors": "Junyi An, Fengshan Liu, Jian Zhao and Furao Shen", "title": "IC Neuron: An Efficient Unit to Construct Neural Networks", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a popular machine learning method, neural networks can be used to solve\nmany complex tasks. Their strong generalization ability comes from the\nrepresentation ability of the basic neuron model. The most popular neuron is\nthe MP neuron, which uses a linear transformation and a non-linear activation\nfunction to process the input successively. Inspired by the elastic collision\nmodel in physics, we propose a new neuron model that can represent more complex\ndistributions. We term it Inter-layer collision (IC) neuron. The IC neuron\ndivides the input space into multiple subspaces used to represent different\nlinear transformations. This operation enhanced non-linear representation\nability and emphasizes some useful input features for the given task. We build\nthe IC networks by integrating the IC neurons into the fully-connected (FC),\nconvolutional, and recurrent structures. The IC networks outperform the\ntraditional networks in a wide range of experiments. We believe that the IC\nneuron can be a basic unit to build network structures.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 08:36:48 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["An", "Junyi", ""], ["Liu", "Fengshan", ""], ["Zhao", "Jian", ""], ["Shen", "Furao", ""]]}, {"id": "2011.11284", "submitter": "Kai Hou Yip", "authors": "Kai Hou Yip, Quentin Changeat, Nikolaos Nikolaou, Mario Morvan, Billy\n  Edwards, Ingo P. Waldmann, Giovanna Tinetti", "title": "Peeking inside the Black Box: Interpreting Deep Learning Models for\n  Exoplanet Atmospheric Retrievals", "comments": "32 pages, 22 figures. Submitted to AJ. Accepted July 20, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning algorithms are growing in popularity in the field of\nexoplanetary science due to their ability to model highly non-linear relations\nand solve interesting problems in a data-driven manner. Several works have\nattempted to perform fast retrievals of atmospheric parameters with the use of\nmachine learning algorithms like deep neural networks (DNNs). Yet, despite\ntheir high predictive power, DNNs are also infamous for being 'black boxes'. It\nis their apparent lack of explainability that makes the astrophysics community\nreluctant to adopt them. What are their predictions based on? How confident\nshould we be in them? When are they wrong and how wrong can they be? In this\nwork, we present a number of general evaluation methodologies that can be\napplied to any trained model and answer questions like these. In particular, we\ntrain three different popular DNN architectures to retrieve atmospheric\nparameters from exoplanet spectra and show that all three achieve good\npredictive performance. We then present an extensive analysis of the\npredictions of DNNs, which can inform us - among other things - of the\ncredibility limits for atmospheric parameters for a given instrument and model.\nFinally, we perform a perturbation-based sensitivity analysis to identify to\nwhich features of the spectrum the outcome of the retrieval is most sensitive.\nWe conclude that for different molecules, the wavelength ranges to which the\nDNN's predictions are most sensitive, indeed coincide with their characteristic\nabsorption regions. The methodologies presented in this work help to improve\nthe evaluation of DNNs and to grant interpretability to their predictions.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 09:00:03 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 15:46:39 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yip", "Kai Hou", ""], ["Changeat", "Quentin", ""], ["Nikolaou", "Nikolaos", ""], ["Morvan", "Mario", ""], ["Edwards", "Billy", ""], ["Waldmann", "Ingo P.", ""], ["Tinetti", "Giovanna", ""]]}, {"id": "2011.11288", "submitter": "Yaoman Li", "authors": "Yaoman Li and Irwin King", "title": "AutoGraph: Automated Graph Neural Network", "comments": "Accepted by ICONIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graphs play an important role in many applications. Recently, Graph Neural\nNetworks (GNNs) have achieved promising results in graph analysis tasks. Some\nstate-of-the-art GNN models have been proposed, e.g., Graph Convolutional\nNetworks (GCNs), Graph Attention Networks (GATs), etc. Despite these successes,\nmost of the GNNs only have shallow structure. This causes the low expressive\npower of the GNNs. To fully utilize the power of the deep neural network, some\ndeep GNNs have been proposed recently. However, the design of deep GNNs\nrequires significant architecture engineering. In this work, we propose a\nmethod to automate the deep GNNs design. In our proposed method, we add a new\ntype of skip connection to the GNNs search space to encourage feature reuse and\nalleviate the vanishing gradient problem. We also allow our evolutionary\nalgorithm to increase the layers of GNNs during the evolution to generate\ndeeper networks. We evaluate our method in the graph node classification task.\nThe experiments show that the GNNs generated by our method can obtain\nstate-of-the-art results in Cora, Citeseer, Pubmed and PPI datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 09:04:17 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Yaoman", ""], ["King", "Irwin", ""]]}, {"id": "2011.11293", "submitter": "Rasmus Berg Palm", "authors": "Thor V.A.N. Olesen, Dennis T.T. Nguyen, Rasmus Berg Palm, Sebastian\n  Risi", "title": "Evolutionary Planning in Latent Space", "comments": "Code to reproduce the experiments are available at\n  https://github.com/two2tee/WorldModelPlanning Video of driving performance is\n  available at https://youtu.be/3M39QgeF27U", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning is a powerful approach to reinforcement learning with several\ndesirable properties. However, it requires a model of the world, which is not\nreadily available in many real-life problems. In this paper, we propose to\nlearn a world model that enables Evolutionary Planning in Latent Space (EPLS).\nWe use a Variational Auto Encoder (VAE) to learn a compressed latent\nrepresentation of individual observations and extend a Mixture Density\nRecurrent Neural Network (MDRNN) to learn a stochastic, multi-modal forward\nmodel of the world that can be used for planning. We use the Random Mutation\nHill Climbing (RMHC) to find a sequence of actions that maximize expected\nreward in this learned model of the world. We demonstrate how to build a model\nof the world by bootstrapping it with rollouts from a random policy and\niteratively refining it with rollouts from an increasingly accurate planning\npolicy using the learned world model. After a few iterations of this\nrefinement, our planning agents are better than standard model-free\nreinforcement learning approaches demonstrating the viability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 09:21:30 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Olesen", "Thor V. A. N.", ""], ["Nguyen", "Dennis T. T.", ""], ["Palm", "Rasmus Berg", ""], ["Risi", "Sebastian", ""]]}, {"id": "2011.11307", "submitter": "Aur\\'elien Decelle", "authors": "Aur\\'elien Decelle and Cyril Furtlehner", "title": "Restricted Boltzmann Machine, recent advances and mean-field theory", "comments": "44 pages, 13 figures. Accepted for CPB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review deals with Restricted Boltzmann Machine (RBM) under the light of\nstatistical physics. The RBM is a classical family of Machine learning (ML)\nmodels which played a central role in the development of deep learning. Viewing\nit as a Spin Glass model and exhibiting various links with other models of\nstatistical physics, we gather recent results dealing with mean-field theory in\nthis context. First the functioning of the RBM can be analyzed via the phase\ndiagrams obtained for various statistical ensembles of RBM leading in\nparticular to identify a {\\it compositional phase} where a small number of\nfeatures or modes are combined to form complex patterns. Then we discuss recent\nworks either able to devise mean-field based learning algorithms; either able\nto reproduce generic aspects of the learning process from some {\\it ensemble\ndynamics equations} or/and from linear stability arguments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 10:08:53 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 08:32:54 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Decelle", "Aur\u00e9lien", ""], ["Furtlehner", "Cyril", ""]]}, {"id": "2011.11344", "submitter": "Michael Mommert", "authors": "Michael Mommert, Mario Sigel, Marcel Neuhausler, Linus Scheibenreif,\n  Damian Borth", "title": "Characterization of Industrial Smoke Plumes from Remote Sensing Data", "comments": "To be presented at the \"Tackling Climate Change with Machine\n  Learning\" workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The major driver of global warming has been identified as the anthropogenic\nrelease of greenhouse gas (GHG) emissions from industrial activities. The\nquantitative monitoring of these emissions is mandatory to fully understand\ntheir effect on the Earth's climate and to enforce emission regulations on a\nlarge scale. In this work, we investigate the possibility to detect and\nquantify industrial smoke plumes from globally and freely available multi-band\nimage data from ESA's Sentinel-2 satellites. Using a modified ResNet-50, we can\ndetect smoke plumes of different sizes with an accuracy of 94.3%. The model\ncorrectly ignores natural clouds and focuses on those imaging channels that are\nrelated to the spectral absorption from aerosols and water vapor, enabling the\nlocalization of smoke. We exploit this localization ability and train a U-Net\nsegmentation model on a labeled sub-sample of our data, resulting in an\nIntersection-over-Union (IoU) metric of 0.608 and an overall accuracy for the\ndetection of any smoke plume of 94.0%; on average, our model can reproduce the\narea covered by smoke in an image to within 5.6%. The performance of our model\nis mostly limited by occasional confusion with surface objects, the inability\nto identify semi-transparent smoke, and human limitations to properly identify\nsmoke based on RGB-only images. Nevertheless, our results enable us to reliably\ndetect and qualitatively estimate the level of smoke activity in order to\nmonitor activity in industrial plants across the globe. Our data set and code\nbase are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 11:54:32 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Mommert", "Michael", ""], ["Sigel", "Mario", ""], ["Neuhausler", "Marcel", ""], ["Scheibenreif", "Linus", ""], ["Borth", "Damian", ""]]}, {"id": "2011.11347", "submitter": "Chenguang Fang", "authors": "Chenguang Fang, Chen Wang", "title": "Time Series Data Imputation: A Survey on Deep Learning Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are all around in real-world applications. However, unexpected\naccidents for example broken sensors or missing of the signals will cause\nmissing values in time series, making the data hard to be utilized. It then\ndoes harm to the downstream applications such as traditional classification or\nregression, sequential data integration and forecasting tasks, thus raising the\ndemand for data imputation. Currently, time series data imputation is a\nwell-studied problem with different categories of methods. However, these works\nrarely take the temporal relations among the observations and treat the time\nseries as normal structured data, losing the information from the time data. In\nrecent, deep learning models have raised great attention. Time series methods\nbased on deep learning have made progress with the usage of models like RNN,\nsince it captures time information from data. In this paper, we mainly focus on\ntime series imputation technique with deep learning methods, which recently\nmade progress in this field. We will review and discuss their model\narchitectures, their pros and cons as well as their effects to show the\ndevelopment of the time series imputation methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 11:57:27 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Fang", "Chenguang", ""], ["Wang", "Chen", ""]]}, {"id": "2011.11369", "submitter": "Yilun Lin", "authors": "Yilun Lin, Chaochao Chen, Cen Chen and Li Wang", "title": "Improving Federated Relational Data Modeling via Basis Alignment and\n  Weight Penalty", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) has attracted increasing attention in recent years.\nAs a privacy-preserving collaborative learning paradigm, it enables a broader\nrange of applications, especially for computer vision and natural language\nprocessing tasks. However, to date, there is limited research of federated\nlearning on relational data, namely Knowledge Graph (KG). In this work, we\npresent a modified version of the graph neural network algorithm that performs\nfederated modeling over KGs across different participants. Specifically, to\ntackle the inherent data heterogeneity issue and inefficiency in algorithm\nconvergence, we propose a novel optimization algorithm, named FedAlign, with 1)\noptimal transportation (OT) for on-client personalization and 2) weight\nconstraint to speed up the convergence. Extensive experiments have been\nconducted on several widely used datasets. Empirical results show that our\nproposed method outperforms the state-of-the-art FL methods, such as FedAVG and\nFedProx, with better convergence.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 12:52:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Lin", "Yilun", ""], ["Chen", "Chaochao", ""], ["Chen", "Cen", ""], ["Wang", "Li", ""]]}, {"id": "2011.11371", "submitter": "Ying Zhu", "authors": "Ying Zhu, Mozhgan Mirzaei", "title": "Classes of ODE solutions: smoothness, covering numbers, implications for\n  noisy function fitting, and the curse of smoothness phenomenon", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many numerical methods for recovering ODE solutions from data rely on\napproximating the solutions using basis functions or kernel functions under a\nleast square criterion. The accuracy of this approach hinges on the smoothness\nof the solutions. This paper provides a theoretical foundation for these\nmethods by establishing novel results on the smoothness and covering numbers of\nODE solution classes (as a measure of their \"size\"). Our results provide\nanswers to \"how do the degree of smoothness and the \"size\" of a class of ODEs\naffect the \"size\" of the associated class of solutions?\" We show that: (1) for\n$y^{'}=f\\left(y\\right)$ and $y^{'}=f\\left(x,\\,y\\right)$, if the absolute values\nof all $k$th ($k\\leq\\beta+1$) order derivatives of $f$ are bounded by $1$, then\nthe solution can end up with the $(k+1)$th derivative whose magnitude grows\nfactorially fast in $k$ -- \"a curse of smoothness\"; (2) our upper bounds for\nthe covering numbers of the $(\\beta+2)-$degree smooth solution classes are\ngreater than those of the \"standard\" $(\\beta+2)-$degree smooth class of\nunivariate functions; (3) the mean squared error of least squares fitting for\nnoisy recovery has a convergence rate no larger than\n$\\left(\\frac{1}{n}\\right)^{\\frac{2\\left(\\beta+2\\right)}{2\\left(\\beta+2\\right)+1}}$\nif\n$n=\\Omega\\left(\\left(\\beta\\sqrt{\\log\\left(\\beta\\vee1\\right)}\\right)^{4\\beta+10}\\right)$,\nand under this condition, the rate\n$\\left(\\frac{1}{n}\\right)^{\\frac{2\\left(\\beta+2\\right)}{2\\left(\\beta+2\\right)+1}}$\nis minimax optimal in the case of $y^{'}=f\\left(x,\\,y\\right)$; (4) more\ngenerally, for the higher order Picard type ODEs,\n$y^{\\left(m\\right)}=f\\left(x,\\,y,\\,y^{'},\\,...,y^{\\left(m-1\\right)}\\right)$,\nthe covering number of the solution class is bounded from above by the product\nof the covering number of the class $\\mathcal{F}$ that $f$ ranges over and the\ncovering number of the set where initial values lie.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 12:54:54 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 10:49:36 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 23:48:37 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zhu", "Ying", ""], ["Mirzaei", "Mozhgan", ""]]}, {"id": "2011.11376", "submitter": "Jacobo Ayensa-Jim\\'enez", "authors": "Jacobo Ayensa-Jim\\'enez, Mohamed H. Doweidar, Jose A. Sanz-Herrera,\n  Manuel Doblar\\'e", "title": "On the application of Physically-Guided Neural Networks with Internal\n  Variables to Continuum Problems", "comments": "40 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive Physics has been historically based upon the development of\nmathematical models that describe the evolution of a system under certain\nexternal stimuli and constraints. The structure of such mathematical models\nrelies on a set of hysical hypotheses that are assumed to be fulfilled by the\nsystem within a certain range of environmental conditions. A new perspective is\nnow raising that uses physical knowledge to inform the data prediction\ncapability of artificial neural networks. A particular extension of this\ndata-driven approach is Physically-Guided Neural Networks with Internal\nVariables (PGNNIV): universal physical laws are used as constraints in the\nneural network, in such a way that some neuron values can be interpreted as\ninternal state variables of the system. This endows the network with unraveling\ncapacity, as well as better predictive properties such as faster convergence,\nfewer data needs and additional noise filtering. Besides, only observable data\nare used to train the network, and the internal state equations may be\nextracted as a result of the training processes, so there is no need to make\nexplicit the particular structure of the internal state model. We extend this\nnew methodology to continuum physical problems, showing again its predictive\nand explanatory capacities when only using measurable values in the training\nset. We show that the mathematical operators developed for image analysis in\ndeep learning approaches can be used and extended to consider standard\nfunctional operators in continuum Physics, thus establishing a common framework\nfor both. The methodology presented demonstrates its ability to discover the\ninternal constitutive state equation for some problems, including heterogeneous\nand nonlinear features, while maintaining its predictive ability for the whole\ndataset coverage, with the cost of a single evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 13:06:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ayensa-Jim\u00e9nez", "Jacobo", ""], ["Doweidar", "Mohamed H.", ""], ["Sanz-Herrera", "Jose A.", ""], ["Doblar\u00e9", "Manuel", ""]]}, {"id": "2011.11383", "submitter": "Atis Elsts", "authors": "Maksims Ivanovs, Roberts Kadikis, Martins Lulla, Aleksejs Rutkovskis,\n  and Atis Elsts", "title": "Automated Quality Assessment of Hand Washing Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Washing hands is one of the most important ways to prevent infectious\ndiseases, including COVID-19. Unfortunately, medical staff does not always\nfollow the World Health Organization (WHO) hand washing guidelines in their\neveryday work. To this end, we present neural networks for automatically\nrecognizing the different washing movements defined by the WHO. We train the\nneural network on a part of a large (2000+ videos) real-world labeled dataset\nwith the different washing movements. The preliminary results show that using\npre-trained neural network models such as MobileNetV2 and Xception for the\ntask, it is possible to achieve >64 % accuracy in recognizing the different\nwashing movements. We also describe the collection and the structure of the\nabove open-access dataset created as part of this work. Finally, we describe\nhow the neural network can be used to construct a mobile phone application for\nautomatic quality control and real-time feedback for medical professionals.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 13:22:53 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 16:05:27 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ivanovs", "Maksims", ""], ["Kadikis", "Roberts", ""], ["Lulla", "Martins", ""], ["Rutkovskis", "Aleksejs", ""], ["Elsts", "Atis", ""]]}, {"id": "2011.11410", "submitter": "Nima Safari", "authors": "Nima Safari, George Price, Chi Yung Chung", "title": "Analysis of Empirical Mode Decomposition-based Load and Renewable Time\n  Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The empirical mode decomposition (EMD) method and its variants have been\nextensively employed in the load and renewable forecasting literature. Using\nthis multiresolution decomposition, time series (TS) related to the historical\nload and renewable generation are decomposed into several intrinsic mode\nfunctions (IMFs), which are less non-stationary and non-linear. As such, the\nprediction of the components can theoretically be carried out with notably\nhigher precision. The EMD method is prone to several issues, including modal\naliasing and boundary effect problems, but the TS decomposition-based load and\nrenewable generation forecasting literature primarily focuses on comparing the\nperformance of different decomposition approaches from the forecast accuracy\nstandpoint; as a result, these problems have rarely been scrutinized.\nUnderestimating these issues can lead to poor performance of the forecast model\nin real-time applications. This paper examines these issues and their\nimportance in the model development stage. Using real-world data, EMD-based\nmodels are presented, and the impact of the boundary effect is illustrated.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 14:08:39 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Safari", "Nima", ""], ["Price", "George", ""], ["Chung", "Chi Yung", ""]]}, {"id": "2011.11421", "submitter": "Mohammadhadi Shateri", "authors": "Mohammadhadi Shateri, Francisco Messina, Pablo Piantanida, Fabrice\n  Labeau", "title": "Deep Directed Information-Based Learning for Privacy-Preserving Smart\n  Meter Data Release", "comments": "to appear in IEEESmartGridComm 2019. arXiv admin note: substantial\n  text overlap with arXiv:1906.06427", "journal-ref": null, "doi": "10.1109/SmartGridComm.2019.8909813", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The explosion of data collection has raised serious privacy concerns in users\ndue to the possibility that sharing data may also reveal sensitive information.\nThe main goal of a privacy-preserving mechanism is to prevent a malicious third\nparty from inferring sensitive information while keeping the shared data\nuseful. In this paper, we study this problem in the context of time series data\nand smart meters (SMs) power consumption measurements in particular. Although\nMutual Information (MI) between private and released variables has been used as\na common information-theoretic privacy measure, it fails to capture the causal\ntime dependencies present in the power consumption time series data. To\novercome this limitation, we introduce the Directed Information (DI) as a more\nmeaningful measure of privacy in the considered setting and propose a novel\nloss function. The optimization is then performed using an adversarial\nframework where two Recurrent Neural Networks (RNNs), referred to as the\nreleaser and the adversary, are trained with opposite goals. Our empirical\nstudies on real-world data sets from SMs measurements in the worst-case\nscenario where an attacker has access to all the training data set used by the\nreleaser, validate the proposed method and show the existing trade-offs between\nprivacy and utility.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:41:11 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shateri", "Mohammadhadi", ""], ["Messina", "Francisco", ""], ["Piantanida", "Pablo", ""], ["Labeau", "Fabrice", ""]]}, {"id": "2011.11430", "submitter": "Ta-Chu Kao", "authors": "Ta-Chu Kao and Guillaume Hennequin", "title": "Automatic differentiation of Sylvester, Lyapunov, and algebraic Riccati\n  equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sylvester, Lyapunov, and algebraic Riccati equations are the bread and butter\nof control theorists. They are used to compute infinite-horizon Gramians, solve\noptimal control problems in continuous or discrete time, and design observers.\nWhile popular numerical computing frameworks (e.g., scipy) provide efficient\nsolvers for these equations, these solvers are still largely missing from most\nautomatic differentiation libraries. Here, we derive the forward and\nreverse-mode derivatives of the solutions to all three types of equations, and\nshowcase their application on an inverse control problem.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 14:33:31 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 10:53:43 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kao", "Ta-Chu", ""], ["Hennequin", "Guillaume", ""]]}, {"id": "2011.11441", "submitter": "Fengqi You", "authors": "Chao Ning, Fengqi You", "title": "Online Learning Based Risk-Averse Stochastic MPC of Constrained Linear\n  Uncertain Systems", "comments": null, "journal-ref": "Automatica, Volume 125, March 2021, 109402", "doi": "10.1016/j.automatica.2020.109402", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of designing data-driven stochastic Model\nPredictive Control (MPC) for linear time-invariant systems under additive\nstochastic disturbance, whose probability distribution is unknown but can be\npartially inferred from data. We propose a novel online learning based\nrisk-averse stochastic MPC framework in which Conditional Value-at-Risk (CVaR)\nconstraints on system states are required to hold for a family of distributions\ncalled an ambiguity set. The ambiguity set is constructed from disturbance data\nby leveraging a Dirichlet process mixture model that is self-adaptive to the\nunderlying data structure and complexity. Specifically, the structural property\nof multimodality is exploit-ed, so that the first- and second-order moment\ninformation of each mixture component is incorporated into the ambiguity set. A\nnovel constraint tightening strategy is then developed based on an equivalent\nreformulation of distributionally ro-bust CVaR constraints over the proposed\nambiguity set. As more data are gathered during the runtime of the controller,\nthe ambiguity set is updated online using real-time disturbance data, which\nenables the risk-averse stochastic MPC to cope with time-varying disturbance\ndistributions. The online variational inference algorithm employed does not\nrequire all collected data be learned from scratch, and therefore the proposed\nMPC is endowed with the guaranteed computational complexity of online learning.\nThe guarantees on recursive feasibility and closed-loop stability of the\nproposed MPC are established via a safe update scheme. Numerical examples are\nused to illustrate the effectiveness and advantages of the proposed MPC.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 13:00:28 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ning", "Chao", ""], ["You", "Fengqi", ""]]}, {"id": "2011.11456", "submitter": "Gauthier Guinet", "authors": "Gauthier Guinet, Valerio Perrone and C\\'edric Archambeau", "title": "Pareto-efficient Acquisition Functions for Cost-Aware Bayesian\n  Optimization", "comments": "11 pages, 9 figures, 4th Workshop on Meta-Learning at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a popular method to optimize expensive\nblack-box functions. It efficiently tunes machine learning algorithms under the\nimplicit assumption that hyperparameter evaluations cost approximately the\nsame. In reality, the cost of evaluating different hyperparameters, be it in\nterms of time, dollars or energy, can span several orders of magnitude of\ndifference. While a number of heuristics have been proposed to make BO\ncost-aware, none of these have been proven to work robustly. In this work, we\nreformulate cost-aware BO in terms of Pareto efficiency and introduce the cost\nPareto Front, a mathematical object allowing us to highlight the shortcomings\nof commonly used acquisition functions. Based on this, we propose a novel\nPareto-efficient adaptation of the expected improvement. On 144 real-world\nblack-box function optimization problems we show that our Pareto-efficient\nacquisition functions significantly outperform previous solutions, bringing up\nto 50% speed-ups while providing finer control over the cost-accuracy\ntrade-off. We also revisit the common choice of Gaussian process cost models,\nshowing that simple, low-variance cost models predict training times\neffectively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:06:07 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 14:50:28 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Guinet", "Gauthier", ""], ["Perrone", "Valerio", ""], ["Archambeau", "C\u00e9dric", ""]]}, {"id": "2011.11459", "submitter": "Matias Valdenegro-Toro", "authors": "Lauren Michelle Pfeifer and Matias Valdenegro-Toro", "title": "Automatic Detection and Classification of Tick-borne Skin Lesions using\n  Deep Learning", "comments": "2 pages, 8 figures, with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Around the globe, ticks are the culprit of transmitting a variety of\nbacterial, viral and parasitic diseases. The incidence of tick-borne diseases\nhas drastically increased within the last decade, with annual cases of Lyme\ndisease soaring to an estimated 300,000 in the United States alone. As a\nresult, more efforts in improving lesion identification approaches and\ndiagnostics for tick-borne illnesses is critical. The objective for this study\nis to build upon the approach used by Burlina et al. by using a variety of\nconvolutional neural network models to detect tick-borne skin lesions. We\nexpanded the data inputs by acquiring images from Google in seven different\nlanguages to test if this would diversify training data and improve the\naccuracy of skin lesion detection. The final dataset included nearly 6,080\nimages and was trained on a combination of architectures (ResNet 34, ResNet 50,\nVGG 19, and Dense Net 121). We obtained an accuracy of 80.72% with our model\ntrained on the DenseNet 121 architecture.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:16:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Pfeifer", "Lauren Michelle", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "2011.11461", "submitter": "Matias Valdenegro-Toro", "authors": "Octavio Arriaga and Matias Valdenegro-Toro", "title": "Unsupervised Difficulty Estimation with Action Scores", "comments": "2 pages, 6 figures, with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating difficulty and biases in machine learning models has become of\nextreme importance as current models are now being applied in real-world\nsituations. In this paper we present a simple method for calculating a\ndifficulty score based on the accumulation of losses for each sample during\ntraining. We call this the action score. Our proposed method does not require\nany modification of the model neither any external supervision, as it can be\nimplemented as callback that gathers information from the training process. We\ntest and analyze our approach in two different settings: image classification,\nand object detection, and we show that in both settings the action score can\nprovide insights about model and dataset biases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:18:44 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Arriaga", "Octavio", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "2011.11472", "submitter": "Jonathan Raiman", "authors": "Jonathan Raiman", "title": "Generative Adversarial Simulator", "comments": "Presented at the Beyond \"Tabula Rasa\" in Reinforcement Learning\n  (BeTR-RL): Agents that remember, adapt, and generalize ICLR 2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Knowledge distillation between machine learning models has opened many new\navenues for parameter count reduction, performance improvements, or amortizing\ntraining time when changing architectures between the teacher and student\nnetwork. In the case of reinforcement learning, this technique has also been\napplied to distill teacher policies to students. Until now, policy distillation\nrequired access to a simulator or real world trajectories.\n  In this paper we introduce a simulator-free approach to knowledge\ndistillation in the context of reinforcement learning. A key challenge is\nhaving the student learn the multiplicity of cases that correspond to a given\naction. While prior work has shown that data-free knowledge distillation is\npossible with supervised learning models by generating synthetic examples,\nthese approaches to are vulnerable to only producing a single prototype example\nfor each class. We propose an extension to explicitly handle multiple\nobservations per output class that seeks to find as many exemplars as possible\nfor a given output class by reinitializing our data generator and making use of\nan adversarial loss.\n  To the best of our knowledge, this is the first demonstration of\nsimulator-free knowledge distillation between a teacher and a student policy.\nThis new approach improves over the state of the art on data-free learning of\nstudent networks on benchmark datasets (MNIST, Fashion-MNIST, CIFAR-10), and we\nalso demonstrate that it specifically tackles issues with multiple input modes.\nWe also identify open problems when distilling agents trained in high\ndimensional environments such as Pong, Breakout, or Seaquest.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:31:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Raiman", "Jonathan", ""]]}, {"id": "2011.11477", "submitter": "Soledad Villar", "authors": "Ningyuan Huang and David W. Hogg and Soledad Villar", "title": "Dimensionality reduction, regularization, and generalization in\n  overparameterized regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterization in deep learning is powerful: Very large models fit the\ntraining data perfectly and yet generalize well. This realization brought back\nthe study of linear models for regression, including ordinary least squares\n(OLS), which, like deep learning, shows a \"double descent\" behavior. This\ninvolves two features: (1) The risk (out-of-sample prediction error) can grow\narbitrarily when the number of samples $n$ approaches the number of parameters\n$p$, and (2) the risk decreases with $p$ at $p>n$, sometimes achieving a lower\nvalue than the lowest risk at $p<n$. The divergence of the risk for OLS at\n$p\\approx n$ is related to the condition number of the empirical covariance in\nthe feature set. For this reason, it can be avoided with regularization. In\nthis work we show that it can also be avoided with a PCA-based dimensionality\nreduction. We provide a finite upper bound for the risk of the PCA-based\nestimator. This result is in contrast to recent work that shows that a\ndifferent form of dimensionality reduction -- one based on the population\ncovariance instead of the empirical covariance -- does not avoid the\ndivergence. We connect these results to an analysis of adversarial attacks,\nwhich become more effective as they raise the condition number of the empirical\ncovariance of the features. We show that OLS is arbitrarily susceptible to\ndata-poisoning attacks in the overparameterized regime -- unlike the\nunderparameterized regime -- and that regularization and dimensionality\nreduction improve the robustness.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 15:38:50 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Huang", "Ningyuan", ""], ["Hogg", "David W.", ""], ["Villar", "Soledad", ""]]}, {"id": "2011.11483", "submitter": "Vik Shirvaikar", "authors": "Vik Shirvaikar and Choudur Lakshminarayan", "title": "Social Determinants of Recidivism: A Machine Learning Solution", "comments": "12 main pages, 5 appendix pages, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In criminal justice analytics, the widely-studied problem of recidivism\nprediction (forecasting re-offenses after release or parole) is fraught with\nethical missteps. In particular, Machine Learning (ML) models rely on\nhistorical patterns of behavior to predict future outcomes, engendering a\nvicious feedback loop of recidivism and incarceration. This paper repurposes ML\nto instead identify social factors that can serve as levers to prevent\nrecidivism. Our contributions are along three dimensions. (1) Recidivism models\ntypically agglomerate individuals into one dataset, but we invoke unsupervised\nlearning to extract homogeneous subgroups with similar features. (2) We then\napply subgroup-level supervised learning to determine factors correlated to\nrecidivism. (3) We therefore shift the focus from predicting which individuals\nwill re-offend to identifying broader underlying factors that explain\nrecidivism, with the goal of informing preventative policy intervention. We\ndemonstrate that this approach can guide the ethical application of ML using\nreal-world data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:15:41 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 18:25:26 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 18:43:01 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shirvaikar", "Vik", ""], ["Lakshminarayan", "Choudur", ""]]}, {"id": "2011.11484", "submitter": "Mingyong Zhou", "authors": "Mingyong Zhou", "title": "A Theory on AI Uncertainty Based on Rademacher Complexity and Shannon\n  Entropy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a theoretical discussion on AI deep learning neural\nnetwork uncertainty investigation based on the classical Rademacher complexity\nand Shannon entropy. First it is shown that the classical Rademacher complexity\nand Shannon entropy is closely related by quantity by definitions. Secondly\nbased on the Shannon mathematical theory on communication [3], we derive a\ncriteria to ensure AI correctness and accuracy in classifications problems.\nLast but not the least based on Peter Barlette's work, we show both a relaxing\ncondition and a stricter condition to guarantee the correctness and accuracy in\nAI classification . By elucidating in this paper criteria condition in terms of\nShannon entropy based on Shannon theory, it becomes easier to explore other\ncriteria in terms of other complexity measurements such as Vapnik-Cheronenkis,\nGaussian complexity by taking advantage of the relations studies results in\nother references. A close to 0.5 criteria on Shannon entropy is derived in this\npaper for the theoretical investigation of AI accuracy and correctness for\nclassification problems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:34:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhou", "Mingyong", ""]]}, {"id": "2011.11486", "submitter": "Luke Darlow", "authors": "Luke Darlow, Stanis{\\l}aw Jastrz\\k{e}bski, Amos Storkey", "title": "Latent Adversarial Debiasing: Mitigating Collider Bias in Deep Neural\n  Networks", "comments": "10 pages, 4 figures, submitted to AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collider bias is a harmful form of sample selection bias that neural networks\nare ill-equipped to handle. This bias manifests itself when the underlying\ncausal signal is strongly correlated with other confounding signals due to the\ntraining data collection procedure. In the situation where the confounding\nsignal is easy-to-learn, deep neural networks will latch onto this and the\nresulting model will generalise poorly to in-the-wild test scenarios. We argue\nherein that the cause of failure is a combination of the deep structure of\nneural networks and the greedy gradient-driven learning process used - one that\nprefers easy-to-compute signals when available. We show it is possible to\nmitigate against this by generating bias-decoupled training data using latent\nadversarial debiasing (LAD), even when the confounding signal is present in\n100% of the training data. By training neural networks on these adversarial\nexamples,we can improve their generalisation in collider bias settings.\nExperiments show state-of-the-art performance of LAD in label-free debiasing\nwith gains of 76.12% on background coloured MNIST, 35.47% on fore-ground\ncoloured MNIST, and 8.27% on corrupted CIFAR-10.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:53:45 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Darlow", "Luke", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["Storkey", "Amos", ""]]}, {"id": "2011.11500", "submitter": "Luca Corinzia", "authors": "Luca Corinzia and Paolo Penna and Wojciech Szpankowski and Joachim M.\n  Buhmann", "title": "Statistical and computational thresholds for the planted $k$-densest\n  sub-hypergraph problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we consider the problem of recovery a planted $k$-densest\nsub-hypergraph on $d$-uniform hypergraphs. This fundamental problem appears in\ndifferent contexts, e.g., community detection, average-case complexity, and\nneuroscience applications as a structural variant of tensor-PCA problem. We\nprovide tight \\emph{information-theoretic} upper and lower bounds for the exact\nrecovery threshold by the maximum-likelihood estimator, as well as\n\\emph{algorithmic} bounds based on approximate message passing algorithms. The\nproblem exhibits a typical statistical-to-computational gap observed in\nanalogous sparse settings that widen with increasing sparsity of the problem.\nThe bounds show that the signal structure impacts the location of the\nstatistical and computational phase transition that the known existing bounds\nfor the tensor-PCA model do not capture. This effect is due to the generic\nplanted signal prior that this latter model addresses.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:02:12 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 13:21:05 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Corinzia", "Luca", ""], ["Penna", "Paolo", ""], ["Szpankowski", "Wojciech", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "2011.11503", "submitter": "Timothy Chu", "authors": "Timothy Chu, Gary Miller, Shyam Narayanan, Mark Sellke", "title": "Functions that Preserve Manhattan Distances", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG math.MG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What functions, when applied to the pairwise Manhattan distances between any\n$n$ points, result in the Manhattan distances between another set of $n$\npoints? In this paper, we show that a function has this property if and only if\nit is Bernstein. This class of functions admits several classical analytic\ncharacterizations and includes $f(x) = x^s$ for $0 \\leq s \\leq 1$ as well as\n$f(x) = 1-e^{-xt}$ for any $t \\geq 0$. While it was previously known that\nBernstein functions had this property, it was not known that these were the\nonly such functions.\n  Our results are a natural extension of the work of Schoenberg from 1938, who\naddressed this question for Euclidean distances. Schoenberg's work has been\napplied in probability theory, harmonic analysis, machine learning, theoretical\ncomputer science, and more.\n  We additionally show that if and only if $f$ is completely monotone, there\nexists \\mbox{$F:\\ell_1 \\rightarrow \\mathbb{R}^n$} for any $x_1, \\ldots x_n \\in\n\\ell_1$ such that $f(\\|x_i - x_j\\|_1) = \\langle F(x_i), F(x_j) \\rangle$.\nPreviously, it was known that completely monotone functions had this property,\nbut it was not known they were the only such functions. The same result but\nwith negative type distances instead of $\\ell_1$ is the foundation of all\nkernel methods in machine learning, and was proven by Schoenberg in 1942.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:03:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Chu", "Timothy", ""], ["Miller", "Gary", ""], ["Narayanan", "Shyam", ""], ["Sellke", "Mark", ""]]}, {"id": "2011.11507", "submitter": "Yu-Li Ni", "authors": "HyeongChan Jo (1), Juhyun Kim (2), Tzu-Chen Huang (3), Yu-Li Ni (1)\n  ((1) Division of Biology and Biological Engineering, Caltech, (2) The\n  Division of Physics Mathematics and Astronomy, Caltech, (3) Walter Burke\n  Institute for Theoretical Physics, Caltech)", "title": "condLSTM-Q: A novel deep learning model for predicting Covid-19\n  mortality in fine geographical Scale", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive models with a focus on different spatial-temporal scales benefit\ngovernments and healthcare systems to combat the COVID-19 pandemic. Here we\npresent the conditional Long Short-Term Memory networks with Quantile output\n(condLSTM-Q), a well-performing model for making quantile predictions on\nCOVID-19 death tolls at the county level with a two-week forecast window. This\nfine geographical scale is a rare but useful feature in publicly available\npredictive models, which would especially benefit state-level officials to\ncoordinate resources within the state. The quantile predictions from condLSTM-Q\ninform people about the distribution of the predicted death tolls, allowing\nbetter evaluation of possible trajectories of the severity. Given the\nscalability and generalizability of neural network models, this model could\nincorporate additional data sources with ease, and could be further developed\nto generate other useful predictions such as new cases or hospitalizations\nintuitively.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:14:48 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Jo", "HyeongChan", ""], ["Kim", "Juhyun", ""], ["Huang", "Tzu-Chen", ""], ["Ni", "Yu-Li", ""]]}, {"id": "2011.11521", "submitter": "Yang Zhou", "authors": "Yang Zhou and Shiliang Sun", "title": "Manifold Partition Discriminant Analysis", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics 47.4 (2016): 830-840", "doi": "10.1109/TCYB.2016.2529299", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for supervised dimensionality reduction named\nManifold Partition Discriminant Analysis (MPDA). It aims to find a linear\nembedding space where the within-class similarity is achieved along the\ndirection that is consistent with the local variation of the data manifold,\nwhile nearby data belonging to different classes are well separated. By\npartitioning the data manifold into a number of linear subspaces and utilizing\nthe first-order Taylor expansion, MPDA explicitly parameterizes the connections\nof tangent spaces and represents the data manifold in a piecewise manner. While\ngraph Laplacian methods capture only the pairwise interaction between data\npoints, our method capture both pairwise and higher order interactions (using\nregional consistency) between data points. This manifold representation can\nhelp to improve the measure of within-class similarity, which further leads to\nimproved performance of dimensionality reduction. Experimental results on\nmultiple real-world data sets demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:33:23 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhou", "Yang", ""], ["Sun", "Shiliang", ""]]}, {"id": "2011.11538", "submitter": "Kunal Banerjee", "authors": "Kunal Banerjee, Vishak Prasad C, Rishi Raj Gupta, Karthik Vyas,\n  Anushree H, Biswajit Mishra", "title": "Exploring Alternatives to Softmax Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Softmax function is widely used in artificial neural networks for multiclass\nclassification, multilabel classification, attention mechanisms, etc. However,\nits efficacy is often questioned in literature. The log-softmax loss has been\nshown to belong to a more generic class of loss functions, called spherical\nfamily, and its member log-Taylor softmax loss is arguably the best alternative\nin this class. In another approach which tries to enhance the discriminative\nnature of the softmax function, soft-margin softmax (SM-softmax) has been\nproposed to be the most suitable alternative. In this work, we investigate\nTaylor softmax, SM-softmax and our proposed SM-Taylor softmax, an amalgamation\nof the earlier two functions, as alternatives to softmax function. Furthermore,\nwe explore the effect of expanding Taylor softmax up to ten terms (original\nwork proposed expanding only to two terms) along with the ramifications of\nconsidering Taylor softmax to be a finite or infinite series during\nbackpropagation. Our experiments for the image classification task on different\ndatasets reveal that there is always a configuration of the SM-Taylor softmax\nfunction that outperforms the normal softmax function and its other\nalternatives.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:50:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Banerjee", "Kunal", ""], ["C", "Vishak Prasad", ""], ["Gupta", "Rishi Raj", ""], ["Vyas", "Karthik", ""], ["H", "Anushree", ""], ["Mishra", "Biswajit", ""]]}, {"id": "2011.11542", "submitter": "Chi Ian Tang", "authors": "Chi Ian Tang, Ignacio Perez-Pozuelo, Dimitris Spathis, Cecilia Mascolo", "title": "Exploring Contrastive Learning in Human Activity Recognition for\n  Healthcare", "comments": "Presented at Machine Learning for Mobile Health Workshop at NeurIPS\n  2020, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Activity Recognition (HAR) constitutes one of the most important tasks\nfor wearable and mobile sensing given its implications in human well-being and\nhealth monitoring. Motivated by the limitations of labeled datasets in HAR,\nparticularly when employed in healthcare-related applications, this work\nexplores the adoption and adaptation of SimCLR, a contrastive learning\ntechnique for visual representations, to HAR. The use of contrastive learning\nobjectives causes the representations of corresponding views to be more\nsimilar, and those of non-corresponding views to be more different. After an\nextensive evaluation exploring 64 combinations of different signal\ntransformations for augmenting the data, we observed significant performance\ndifferences owing to the order and the function thereof. In particular,\npreliminary results indicated an improvement over supervised and unsupervised\nlearning methods when using fine-tuning and random rotation for augmentation,\nhowever, future work should explore under which conditions SimCLR is beneficial\nfor HAR systems and other healthcare-related applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:55:22 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 00:12:54 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 05:41:43 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Tang", "Chi Ian", ""], ["Perez-Pozuelo", "Ignacio", ""], ["Spathis", "Dimitris", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2011.11554", "submitter": "Subhrajit Roy", "authors": "Emily Alsentzer, Matthew B. A. McDermott, Fabian Falck, Suproteem K.\n  Sarkar, Subhrajit Roy, Stephanie L. Hyland", "title": "ML4H Abstract Track 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A collection of the accepted abstracts for the Machine Learning for Health\n(ML4H) workshop at NeurIPS 2020. This index is not complete, as some accepted\nabstracts chose to opt-out of inclusion.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 22:06:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Alsentzer", "Emily", ""], ["McDermott", "Matthew B. A.", ""], ["Falck", "Fabian", ""], ["Sarkar", "Suproteem K.", ""], ["Roy", "Subhrajit", ""], ["Hyland", "Stephanie L.", ""]]}, {"id": "2011.11566", "submitter": "Quanquan Gu", "authors": "Jiafan He and Dongruo Zhou and Quanquan Gu", "title": "Logarithmic Regret for Reinforcement Learning with Linear Function\n  Approximation", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) with linear function approximation has received\nincreasing attention recently. However, existing work has focused on obtaining\n$\\sqrt{T}$-type regret bound, where $T$ is the number of interactions with the\nMDP. In this paper, we show that logarithmic regret is attainable under two\nrecently proposed linear MDP assumptions provided that there exists a positive\nsub-optimality gap for the optimal action-value function. More specifically,\nunder the linear MDP assumption (Jin et al. 2019), the LSVI-UCB algorithm can\nachieve $\\tilde{O}(d^{3}H^5/\\text{gap}_{\\text{min}}\\cdot \\log(T))$ regret; and\nunder the linear mixture MDP assumption (Ayoub et al. 2020), the UCRL-VTR\nalgorithm can achieve $\\tilde{O}(d^{2}H^5/\\text{gap}_{\\text{min}}\\cdot\n\\log^3(T))$ regret, where $d$ is the dimension of feature mapping, $H$ is the\nlength of episode, $\\text{gap}_{\\text{min}}$ is the minimal sub-optimality gap,\nand $\\tilde O$ hides all logarithmic terms except $\\log(T)$. To the best of our\nknowledge, these are the first logarithmic regret bounds for RL with linear\nfunction approximation. We also establish gap-dependent lower bounds for the\ntwo linear MDP models.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:25:00 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 16:35:54 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["He", "Jiafan", ""], ["Zhou", "Dongruo", ""], ["Gu", "Quanquan", ""]]}, {"id": "2011.11576", "submitter": "James Brooks", "authors": "J.P. Brooks and D.J. Edwards and C.E. Larson and N. Van Cleemput", "title": "Conjecturing-Based Computational Discovery of Patterns in Data", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern machine learning methods are designed to exploit complex patterns in\ndata regardless of their form, while not necessarily revealing them to the\ninvestigator. Here we demonstrate situations where modern machine learning\nmethods are ill-equipped to reveal feature interaction effects and other\nnonlinear relationships. We propose the use of a conjecturing machine that\ngenerates feature relationships in the form of bounds for numerical features\nand boolean expressions for nominal features that are ignored by machine\nlearning algorithms. The proposed framework is demonstrated for a\nclassification problem with an interaction effect and a nonlinear regression\nproblem. In both settings, true underlying relationships are revealed and\ngeneralization performance improves. The framework is then applied to\npatient-level data regarding COVID-19 outcomes to suggest possible risk\nfactors.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:38:16 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Brooks", "J. P.", ""], ["Edwards", "D. J.", ""], ["Larson", "C. E.", ""], ["Van Cleemput", "N.", ""]]}, {"id": "2011.11579", "submitter": "Megan Johnson", "authors": "Megan Johnson, Jae-Hun Jung", "title": "The Interconnectivity Vector: A Finite-Dimensional Vector Representation\n  of Persistent Homology", "comments": "28 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Persistent Homology (PH) is a useful tool to study the underlying structure\nof a data set. Persistence Diagrams (PDs), which are 2D multisets of points,\nare a concise summary of the information found by studying the PH of a data\nset. However, PDs are difficult to incorporate into a typical machine learning\nworkflow. To that end, two main methods for representing PDs have been\ndeveloped: kernel methods and vectorization methods. In this paper we propose a\nnew finite-dimensional vector, called the interconnectivity vector,\nrepresentation of a PD adapted from Bag-of-Words (BoW). This new representation\nis constructed to demonstrate the connections between the homological features\nof a data set. This initial definition of the interconnectivity vector proves\nto be unstable, but we introduce a stabilized version of the vector and prove\nits stability with respect to small perturbations in the inputs. We evaluate\nboth versions of the presented vectorization on several data sets and show\ntheir high discriminative power.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:43:06 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Johnson", "Megan", ""], ["Jung", "Jae-Hun", ""]]}, {"id": "2011.11580", "submitter": "Sabee Grewal", "authors": "Dax Enshan Koh, Sabee Grewal", "title": "Classical Shadows with Noise", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical shadows protocol, recently introduced by Huang, Keung, and\nPreskill [Nat. Phys. 16, 1050 (2020)], is a hybrid quantum-classical protocol\nthat is used to predict target functions of an unknown quantum state. Unlike\nfull quantum state tomography, the protocol requires only a few quantum\nmeasurements to make many predictions with a high success probability, and is\ntherefore more amenable to implementation on near-term quantum hardware. In\nthis paper, we study the effects of noise on the classical shadows protocol. In\nparticular, we consider the scenario in which the quantum circuits involved in\nthe protocol are subject to various known noise channels and derive an\nanalytical upper bound for the sample complexity in terms of a generalized\nshadow norm for both local and global noise. Additionally, by modifying the\nclassical post-processing step of the noiseless protocol, we define an\nestimator that remains unbiased in the presence of noise. As applications, we\nshow that our results can be used to prove rigorous sample complexity upper\nbounds in the cases of depolarizing noise and amplitude damping.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:43:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Koh", "Dax Enshan", ""], ["Grewal", "Sabee", ""]]}, {"id": "2011.11600", "submitter": "Vitor Fortes Rey", "authors": "Vitor Fortes Rey, Kamalveer Kaur Garewal, Paul Lukowicz", "title": "Yet it moves: Learning from Generic Motions to Generate IMU data from\n  YouTube videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human activity recognition (HAR) using wearable sensors has benefited much\nless from recent advances in Machine Learning than fields such as computer\nvision and natural language processing. This is to a large extent due to the\nlack of large scale repositories of labeled training data. In our research we\naim to facilitate the use of online videos, which exists in ample quantity for\nmost activities and are much easier to label than sensor data, to simulate\nlabeled wearable motion sensor data. In previous work we already demonstrate\nsome preliminary results in this direction focusing on very simple, activity\nspecific simulation models and a single sensor modality (acceleration\nnorm)\\cite{10.1145/3341162.3345590}. In this paper we show how we can train a\nregression model on generic motions for both accelerometer and gyro signals and\nthen apply it to videos of the target activities to generate synthetic IMU data\n(acceleration and gyro norms) that can be used to train and/or improve HAR\nmodels. We demonstrate that systems trained on simulated data generated by our\nregression model can come to within around 10% of the mean F1 score of a system\ntrained on real sensor data. Furthermore we show that by either including a\nsmall amount of real sensor data for model calibration or simply leveraging the\nfact that (in general) we can easily generate much more simulated data from\nvideo than we can collect in terms of real sensor data the advantage of real\nsensor data can be eventually equalized.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:16:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rey", "Vitor Fortes", ""], ["Garewal", "Kamalveer Kaur", ""], ["Lukowicz", "Paul", ""]]}, {"id": "2011.11602", "submitter": "Anthony Rhodes", "authors": "Anthony D. Rhodes, Manan Goel", "title": "High Fidelity Interactive Video Segmentation Using Tensor Decomposition\n  Boundary Loss Convolutional Tessellations and Context Aware Skip Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a high fidelity deep learning algorithm (HyperSeg) for interactive\nvideo segmentation tasks using a convolutional network with context-aware skip\nconnections, and compressed, hypercolumn image features combined with a\nconvolutional tessellation procedure. In order to maintain high output\nfidelity, our model crucially processes and renders all image features in high\nresolution, without utilizing downsampling or pooling procedures. We maintain\nthis consistent, high grade fidelity efficiently in our model chiefly through\ntwo means: (1) We use a statistically-principled tensor decomposition procedure\nto modulate the number of hypercolumn features and (2) We render these features\nin their native resolution using a convolutional tessellation technique. For\nimproved pixel level segmentation results, we introduce a boundary loss\nfunction; for improved temporal coherence in video data, we include temporal\nimage information in our model. Through experiments, we demonstrate the\nimproved accuracy of our model against baseline models for interactive\nsegmentation tasks using high resolution video data. We also introduce a\nbenchmark video segmentation dataset, the VFX Segmentation Dataset, which\ncontains over 27,046 high resolution video frames, including greenscreen and\nvarious composited scenes with corresponding, hand crafted, pixel level\nsegmentations. Our work presents an extension to improvement to state of the\nart segmentation fidelity with high resolution data and can be used across a\nbroad range of application domains, including VFX pipelines and medical imaging\ndisciplines.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:21:42 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rhodes", "Anthony D.", ""], ["Goel", "Manan", ""]]}, {"id": "2011.11603", "submitter": "Zhonghao Wang", "authors": "Zhonghao Wang, Mo Yu, Kai Wang, Jinjun Xiong, Wen-mei Hwu, Mark\n  Hasegawa-Johnson, Humphrey Shi", "title": "Interpretable Visual Reasoning via Induced Symbolic Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of concept induction in visual reasoning, i.e.,\nidentifying concepts and their hierarchical relationships from question-answer\npairs associated with images; and achieve an interpretable model via working on\nthe induced symbolic concept space. To this end, we first design a new\nframework named object-centric compositional attention model (OCCAM) to perform\nthe visual reasoning task with object-level visual features. Then, we come up\nwith a method to induce concepts of objects and relations using clues from the\nattention patterns between objects' visual features and question words.\nFinally, we achieve a higher level of interpretability by imposing OCCAM on the\nobjects represented in the induced symbolic concept space. Experiments on the\nCLEVR dataset demonstrate: 1) our OCCAM achieves a new state of the art without\nhuman-annotated functional programs; 2) our induced concepts are both accurate\nand sufficient as OCCAM achieves an on-par performance on objects represented\neither in visual features or in the induced symbolic concept space.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:21:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Wang", "Zhonghao", ""], ["Yu", "Mo", ""], ["Wang", "Kai", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""], ["Hasegawa-Johnson", "Mark", ""], ["Shi", "Humphrey", ""]]}, {"id": "2011.11610", "submitter": "Rutwik Palaskar", "authors": "Rutwik Palaskar, Renu Vyas, Vilas Khedekar, Sangeeta Palaskar, Pranjal\n  Sahu", "title": "Transfer Learning for Oral Cancer Detection using Microscopic Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oral cancer has more than 83% survival rate if detected in its early stages,\nhowever, only 29% of cases are currently detected early. Deep learning\ntechniques can detect patterns of oral cancer cells and can aid in its early\ndetection. In this work, we present the first results of neural networks for\noral cancer detection using microscopic images. We compare numerous\nstate-of-the-art models via transfer learning approach and collect and release\nan augmented dataset of high-quality microscopic images of oral cancer. We\npresent a comprehensive study of different models and report their performance\non this type of data. Overall, we obtain a 10-15% absolute improvement with\ntransfer learning methods compared to a simple Convolutional Neural Network\nbaseline. Ablation studies show the added benefit of data augmentation\ntechniques with finetuning for this task.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:35:59 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 18:41:26 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Palaskar", "Rutwik", ""], ["Vyas", "Renu", ""], ["Khedekar", "Vilas", ""], ["Palaskar", "Sangeeta", ""], ["Sahu", "Pranjal", ""]]}, {"id": "2011.11619", "submitter": "Dustin Mixon", "authors": "Dustin G. Mixon, Hans Parshall, Jianzong Pi", "title": "Neural collapse with unconstrained features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural collapse is an emergent phenomenon in deep learning that was recently\ndiscovered by Papyan, Han and Donoho. We propose a simple \"unconstrained\nfeatures model\" in which neural collapse also emerges empirically. By studying\nthis model, we provide some explanation for the emergence of neural collapse in\nterms of the landscape of empirical risk.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:49:36 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Mixon", "Dustin G.", ""], ["Parshall", "Hans", ""], ["Pi", "Jianzong", ""]]}, {"id": "2011.11631", "submitter": "Tsung-Yu Hsieh", "authors": "Tsung-Yu Hsieh, Suhang Wang, Yiwei Sun, Vasant Honavar", "title": "Explainable Multivariate Time Series Classification: A Deep Neural\n  Network Which Learns To Attend To Important Variables As Well As Informative\n  Time Intervals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data is prevalent in a wide variety of real-world applications\nand it calls for trustworthy and explainable models for people to understand\nand fully trust decisions made by AI solutions. We consider the problem of\nbuilding explainable classifiers from multi-variate time series data. A key\ncriterion to understand such predictive models involves elucidating and\nquantifying the contribution of time varying input variables to the\nclassification. Hence, we introduce a novel, modular, convolution-based feature\nextraction and attention mechanism that simultaneously identifies the variables\nas well as time intervals which determine the classifier output. We present\nresults of extensive experiments with several benchmark data sets that show\nthat the proposed method outperforms the state-of-the-art baseline methods on\nmulti-variate time series classification task. The results of our case studies\ndemonstrate that the variables and time intervals identified by the proposed\nmethod make sense relative to available domain knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:16:46 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Hsieh", "Tsung-Yu", ""], ["Wang", "Suhang", ""], ["Sun", "Yiwei", ""], ["Honavar", "Vasant", ""]]}, {"id": "2011.11632", "submitter": "Faiq Khalid", "authors": "Faiq Khalid, Syed Rafay Hasan, Sara Zia, Osman Hasan, Falah Awwad,\n  Muhammad Shafique", "title": "MacLeR: Machine Learning-based Run-Time Hardware Trojan Detection in\n  Resource-Constrained IoT Edge Devices", "comments": null, "journal-ref": "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems ( Volume: 39, Issue: 11, Nov. 2020)", "doi": "10.1109/TCAD.2020.3012236", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional learning-based approaches for run-time Hardware Trojan detection\nrequire complex and expensive on-chip data acquisition frameworks and thus\nincur high area and power overhead. To address these challenges, we propose to\nleverage the power correlation between the executing instructions of a\nmicroprocessor to establish a machine learning-based run-time Hardware Trojan\n(HT) detection framework, called MacLeR. To reduce the overhead of data\nacquisition, we propose a single power-port current acquisition block using\ncurrent sensors in time-division multiplexing, which increases accuracy while\nincurring reduced area overhead. We have implemented a practical solution by\nanalyzing multiple HT benchmarks inserted in the RTL of a system-on-chip (SoC)\nconsisting of four LEON3 processors integrated with other IPs like vga_lcd,\nRSA, AES, Ethernet, and memory controllers. Our experimental results show that\ncompared to state-of-the-art HT detection techniques, MacLeR achieves 10\\%\nbetter HT detection accuracy (i.e., 96.256%) while incurring a 7x reduction in\narea and power overhead (i.e., 0.025% of the area of the SoC and <0.07% of the\npower of the SoC). In addition, we also analyze the impact of process variation\nand aging on the extracted power profiles and the HT detection accuracy of\nMacLeR. Our analysis shows that variations in fine-grained power profiles due\nto the HTs are significantly higher compared to the variations in fine-grained\npower profiles caused by the process variations (PV) and aging effects.\nMoreover, our analysis demonstrates that, on average, the HT detection accuracy\ndrop in MacLeR is less than 1% and 9% when considering only PV and PV with\nworst-case aging, respectively, which is ~10x less than in the case of the\nstate-of-the-art ML-based HT detection technique.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:45:25 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Khalid", "Faiq", ""], ["Hasan", "Syed Rafay", ""], ["Zia", "Sara", ""], ["Hasan", "Osman", ""], ["Awwad", "Falah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2011.11637", "submitter": "Ilia Shumailov", "authors": "Yiren Zhao, Ilia Shumailov, Robert Mullins and Ross Anderson", "title": "Nudge Attacks on Point-Cloud DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The wide adaption of 3D point-cloud data in safety-critical applications such\nas autonomous driving makes adversarial samples a real threat. Existing\nadversarial attacks on point clouds achieve high success rates but modify a\nlarge number of points, which is usually difficult to do in real-life\nscenarios. In this paper, we explore a family of attacks that only perturb a\nfew points of an input point cloud, and name them nudge attacks. We demonstrate\nthat nudge attacks can successfully flip the results of modern point-cloud\nDNNs. We present two variants, gradient-based and decision-based, showing their\neffectiveness in white-box and grey-box scenarios. Our extensive experiments\nshow nudge attacks are effective at generating both targeted and untargeted\nadversarial point clouds, by changing a few points or even a single point from\nthe entire point-cloud input. We find that with a single point we can reliably\nthwart predictions in 12--80% of cases, whereas 10 points allow us to further\nincrease this to 37--95%. Finally, we discuss the possible defenses against\nsuch attacks, and explore their limitations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 18:04:02 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Zhao", "Yiren", ""], ["Shumailov", "Ilia", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "2011.11660", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er and Dan Boneh", "title": "Differentially Private Learning Needs Better Features (or Much More\n  Data)", "comments": "ICLR 2021. Code available at\n  https://github.com/ftramer/Handcrafted-DP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that differentially private machine learning has not yet\nreached its \"AlexNet moment\" on many canonical vision tasks: linear models\ntrained on handcrafted features significantly outperform end-to-end deep neural\nnetworks for moderate privacy budgets. To exceed the performance of handcrafted\nfeatures, we show that private learning requires either much more private data,\nor access to features learned on public data from a similar domain. Our work\nintroduces simple yet strong baselines for differentially private learning that\ncan inform the evaluation of future progress in this area.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:00:52 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 18:17:16 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 02:56:42 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Boneh", "Dan", ""]]}, {"id": "2011.11679", "submitter": "Matej Petkovi\\'c", "authors": "Matej Petkovi\\'c, Dragi Kocev, Bla\\v{z} \\v{S}krlj, Sa\\v{s}o\n  D\\v{z}eroski", "title": "Ensemble- and Distance-Based Feature Ranking for Unsupervised Learning", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we propose two novel (groups of) methods for unsupervised\nfeature ranking and selection. The first group includes feature ranking scores\n(Genie3 score, RandomForest score) that are computed from ensembles of\npredictive clustering trees. The second method is URelief, the unsupervised\nextension of the Relief family of feature ranking algorithms. Using 26\nbenchmark data sets and 5 baselines, we show that both the Genie3 score\n(computed from the ensemble of extra trees) and the URelief method outperform\nthe existing methods and that Genie3 performs best overall, in terms of\npredictive power of the top-ranked features. Additionally, we analyze the\ninfluence of the hyper-parameters of the proposed methods on their performance,\nand show that for the Genie3 score the highest quality is achieved by the most\nefficient parameter configuration. Finally, we propose a way of discovering the\nlocation of the features in the ranking, which are the most relevant in\nreality.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:17:24 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Petkovi\u0107", "Matej", ""], ["Kocev", "Dragi", ""], ["\u0160krlj", "Bla\u017e", ""], ["D\u017eeroski", "Sa\u0161o", ""]]}, {"id": "2011.11682", "submitter": "Xiaohui Yu", "authors": "Zhaoyue Chen, Nick Koudas, Zhe Zhang, Xiaohui Yu", "title": "Efficient Construction of Nonlinear Models over Normalized Data", "comments": "Accepted at IEEE International Conference on Data Engineering (ICDE\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) applications are proliferating in the enterprise.\nRelational data which are prevalent in enterprise applications are typically\nnormalized; as a result, data has to be denormalized via primary/foreign-key\njoins to be provided as input to ML algorithms. In this paper, we study the\nimplementation of popular nonlinear ML models, Gaussian Mixture Models (GMM)\nand Neural Networks (NN), over normalized data addressing both cases of binary\nand multi-way joins over normalized relations.\n  For the case of GMM, we show how it is possible to decompose computation in a\nsystematic way both for binary joins and for multi-way joins to construct\nmixture models. We demonstrate that by factoring the computation, one can\nconduct the training of the models much faster compared to other applicable\napproaches, without any loss in accuracy.\n  For the case of NN, we propose algorithms to train the network taking\nnormalized data as the input. Similarly, we present algorithms that can conduct\nthe training of the network in a factorized way and offer performance\nadvantages. The redundancy introduced by denormalization can be exploited for\ncertain types of activation functions. However, we demonstrate that attempting\nto explore this redundancy is helpful up to a certain point; exploring\nredundancy at higher layers of the network will always result in increased\ncosts and is not recommended.\n  We present the results of a thorough experimental evaluation, varying several\nparameters of the input relations involved and demonstrate that our proposals\nfor the training of GMM and NN yield drastic performance improvements typically\nstarting at 100%, which become increasingly higher as parameters of the\nunderlying data vary, without any loss in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:20:03 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 14:55:06 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Chen", "Zhaoyue", ""], ["Koudas", "Nick", ""], ["Zhang", "Zhe", ""], ["Yu", "Xiaohui", ""]]}, {"id": "2011.11693", "submitter": "Rika Antonova", "authors": "Rika Antonova, Anastasiia Varava, Peiyang Shi, J. Frederico Carvalho,\n  Danica Kragic", "title": "Sequential Topological Representations for Predictive Models of\n  Deformable Objects", "comments": "To appear in PMLR (Proceedings of Machine Learning Research) as part\n  of L4DC (Learning for Dynamics and Control) conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deformable objects present a formidable challenge for robotic manipulation\ndue to the lack of canonical low-dimensional representations and the difficulty\nof capturing, predicting, and controlling such objects. We construct compact\ntopological representations to capture the state of highly deformable objects\nthat are topologically nontrivial. We develop an approach that tracks the\nevolution of this topological state through time. Under several mild\nassumptions, we prove that the topology of the scene and its evolution can be\nrecovered from point clouds representing the scene. Our further contribution is\na method to learn predictive models that take a sequence of past point cloud\nobservations as input and predict a sequence of topological states, conditioned\non target/future control actions. Our experiments with highly deformable\nobjects in simulation show that the proposed multistep predictive models yield\nmore precise results than those obtained from computational topology libraries.\nThese models can leverage patterns inferred across various objects and offer\nfast multistep predictions suitable for real-time applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:45:15 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 20:31:42 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Antonova", "Rika", ""], ["Varava", "Anastasiia", ""], ["Shi", "Peiyang", ""], ["Carvalho", "J. Frederico", ""], ["Kragic", "Danica", ""]]}, {"id": "2011.11713", "submitter": "Boyu Zhang", "authors": "Fuchang Gao and Boyu Zhang", "title": "A Use of Even Activation Functions in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite broad interest in applying deep learning techniques to scientific\ndiscovery, learning interpretable formulas that accurately describe scientific\ndata is very challenging because of the vast landscape of possible functions\nand the \"black box\" nature of deep neural networks. The key to success is to\neffectively integrate existing knowledge or hypotheses about the underlying\nstructure of the data into the architecture of deep learning models to guide\nmachine learning. Currently, such integration is commonly done through\ncustomization of the loss functions. Here we propose an alternative approach to\nintegrate existing knowledge or hypotheses of data structure by constructing\ncustom activation functions that reflect this structure. Specifically, we study\na common case when the multivariate target function $f$ to be learned from the\ndata is partially exchangeable, \\emph{i.e.} $f(u,v,w)=f(v,u,w)$ for $u,v\\in\n\\mathbb{R}^d$. For instance, these conditions are satisfied for the\nclassification of images that is invariant under left-right flipping. Through\ntheoretical proof and experimental verification, we show that using an even\nactivation function in one of the fully connected layers improves neural\nnetwork performance. In our experimental 9-dimensional regression problems,\nreplacing one of the non-symmetric activation functions with the designated\n\"Seagull\" activation function $\\log(1+x^2)$ results in substantial improvement\nin network performance. Surprisingly, even activation functions are seldom used\nin neural networks. Our results suggest that customized activation functions\nhave great potential in neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:33:13 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Gao", "Fuchang", ""], ["Zhang", "Boyu", ""]]}, {"id": "2011.11715", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Linda Liu, Ankur Gandhe, Yile Gu, Anirudh Raju,\n  Denis Filimonov, Ivan Bulyko", "title": "Multi-task Language Modeling for Improving Speech Recognition of Rare\n  Words", "comments": "Preprint. Submitted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end automatic speech recognition (ASR) systems are increasingly\npopular due to their relative architectural simplicity and competitive\nperformance. However, even though the average accuracy of these systems may be\nhigh, the performance on rare content words often lags behind hybrid ASR\nsystems. To address this problem, second-pass rescoring is often applied\nleveraging upon language modeling. In this paper, we propose a second-pass\nsystem with multi-task learning, utilizing semantic targets (such as intent and\nslot prediction) to improve speech recognition performance. We show that our\nrescoring model trained with these additional tasks outperforms the baseline\nrescoring model, trained with only the language modeling task, by 1.4% on a\ngeneral test and by 2.6% on a rare word test set in terms of word-error-rate\nrelative (WERR).\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:40:44 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 03:12:54 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 20:31:00 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Liu", "Linda", ""], ["Gandhe", "Ankur", ""], ["Gu", "Yile", ""], ["Raju", "Anirudh", ""], ["Filimonov", "Denis", ""], ["Bulyko", "Ivan", ""]]}, {"id": "2011.11717", "submitter": "Onofrio M. Marag\\`o", "authors": "Laura Natali, Saga Helgadottir, Onofrio M. Marago, and Giovanni Volpe", "title": "Improving epidemic testing and containment strategies using machine\n  learning", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Containment of epidemic outbreaks entails great societal and economic costs.\nCost-effective containment strategies rely on efficiently identifying infected\nindividuals, making the best possible use of the available testing resources.\nTherefore, quickly identifying the optimal testing strategy is of critical\nimportance. Here, we demonstrate that machine learning can be used to identify\nwhich individuals are most beneficial to test, automatically and dynamically\nadapting the testing strategy to the characteristics of the disease outbreak.\nSpecifically, we simulate an outbreak using the archetypal\nsusceptible-infectious-recovered (SIR) model and we use data about the first\nconfirmed cases to train a neural network that learns to make predictions about\nthe rest of the population. Using these prediction, we manage to contain the\noutbreak more effectively and more quickly than with standard approaches.\nFurthermore, we demonstrate how this method can be used also when there is a\npossibility of reinfection (SIRS model) to efficiently eradicate an endemic\ndisease.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:46:01 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Natali", "Laura", ""], ["Helgadottir", "Saga", ""], ["Marago", "Onofrio M.", ""], ["Volpe", "Giovanni", ""]]}, {"id": "2011.11722", "submitter": "Deepali Jain", "authors": "Deepali Jain, Atil Iscen, Ken Caluwaerts", "title": "From Pixels to Legs: Hierarchical Learning of Quadruped Locomotion", "comments": null, "journal-ref": "4th Conference on Robot Learning (CoRL 2020), Cambridge MA, USA", "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Legged robots navigating crowded scenes and complex terrains in the real\nworld are required to execute dynamic leg movements while processing visual\ninput for obstacle avoidance and path planning. We show that a quadruped robot\ncan acquire both of these skills by means of hierarchical reinforcement\nlearning (HRL). By virtue of their hierarchical structure, our policies learn\nto implicitly break down this joint problem by concurrently learning High Level\n(HL) and Low Level (LL) neural network policies. These two levels are connected\nby a low dimensional hidden layer, which we call latent command. HL receives a\nfirst-person camera view, whereas LL receives the latent command from HL and\nthe robot's on-board sensors to control its actuators. We train policies to\nwalk in two different environments: a curved cliff and a maze. We show that\nhierarchical policies can concurrently learn to locomote and navigate in these\nenvironments, and show they are more efficient than non-hierarchical neural\nnetwork policies. This architecture also allows for knowledge reuse across\ntasks. LL networks trained on one task can be transferred to a new task in a\nnew environment. Finally HL, which processes camera images, can be evaluated at\nmuch lower and varying frequencies compared to LL, thus reducing computation\ntimes and bandwidth requirements.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:55:54 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jain", "Deepali", ""], ["Iscen", "Atil", ""], ["Caluwaerts", "Ken", ""]]}, {"id": "2011.11725", "submitter": "Jinho Choi", "authors": "Jinho Choi", "title": "Data-aided Sensing for Gaussian Process Regression in IoT Systems", "comments": "10 pages, 8 figures, to appear in IEEE IoTJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, for efficient data collection with limited bandwidth,\ndata-aided sensing is applied to Gaussian process regression that is used to\nlearn data sets collected from sensors in Internet-of-Things systems. We focus\non the interpolation of sensors' measurements from a small number of\nmeasurements uploaded by a fraction of sensors using Gaussian process\nregression with data-aided sensing. Thanks to active sensor selection, it is\nshown that Gaussian process regression with data-aided sensing can provide a\ngood estimate of a complete data set compared to that with random selection.\nWith multichannel ALOHA, data-aided sensing is generalized for distributed\nselective uploading when sensors can have feedback of predictions of their\nmeasurements so that each sensor can decide whether or not it uploads by\ncomparing its measurement with the predicted one. Numerical results show that\nmodified multichannel ALOHA with predictions can help improve the performance\nof Gaussian process regression with data-aided sensing compared to conventional\nmultichannel ALOHA with equal uploading probability.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:59:51 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Choi", "Jinho", ""]]}, {"id": "2011.11732", "submitter": "Yun Liu", "authors": "Boris Babenko, Akinori Mitani, Ilana Traynis, Naho Kitade, Preeti\n  Singh, April Maa, Jorge Cuadros, Greg S. Corrado, Lily Peng, Dale R. Webster,\n  Avinash Varadarajan, Naama Hammel, Yun Liu", "title": "Detecting hidden signs of diabetes in external eye photographs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes-related retinal conditions can be detected by examining the\nposterior of the eye. By contrast, examining the anterior of the eye can reveal\nconditions affecting the front of the eye, such as changes to the eyelids,\ncornea, or crystalline lens. In this work, we studied whether external\nphotographs of the front of the eye can reveal insights into both diabetic\nretinal diseases and blood glucose control. We developed a deep learning system\n(DLS) using external eye photographs of 145,832 patients with diabetes from 301\ndiabetic retinopathy (DR) screening sites in one US state, and evaluated the\nDLS on three validation sets containing images from 198 sites in 18 other US\nstates. In validation set A (n=27,415 patients, all undilated), the DLS\ndetected poor blood glucose control (HbA1c > 9%) with an area under receiver\noperating characteristic curve (AUC) of 70.2; moderate-or-worse DR with an AUC\nof 75.3; diabetic macular edema with an AUC of 78.0; and vision-threatening DR\nwith an AUC of 79.4. For all 4 prediction tasks, the DLS's AUC was higher\n(p<0.001) than using available self-reported baseline characteristics (age,\nsex, race/ethnicity, years with diabetes). In terms of positive predictive\nvalue, the predicted top 5% of patients had a 67% chance of having HbA1c > 9%,\nand a 20% chance of having vision threatening diabetic retinopathy. The results\ngeneralized to dilated pupils (validation set B, 5,058 patients) and to a\ndifferent screening service (validation set C, 10,402 patients). Our results\nindicate that external eye photographs contain information useful for\nhealthcare providers managing patients with diabetes, and may help prioritize\npatients for in-person screening. Further work is needed to validate these\nfindings on different devices and patient populations (those without diabetes)\nto evaluate its utility for remote diagnosis and management.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 21:14:34 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Babenko", "Boris", ""], ["Mitani", "Akinori", ""], ["Traynis", "Ilana", ""], ["Kitade", "Naho", ""], ["Singh", "Preeti", ""], ["Maa", "April", ""], ["Cuadros", "Jorge", ""], ["Corrado", "Greg S.", ""], ["Peng", "Lily", ""], ["Webster", "Dale R.", ""], ["Varadarajan", "Avinash", ""], ["Hammel", "Naama", ""], ["Liu", "Yun", ""]]}, {"id": "2011.11735", "submitter": "Varnith Chordia", "authors": "Varnith Chordia, Vijay Kumar BG", "title": "Large Scale Multimodal Classification Using an Ensemble of Transformer\n  Models and Co-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient product classification is significant for E-commerce\napplications, as it enables various downstream tasks such as recommendation,\nretrieval, and pricing. Items often contain textual and visual information, and\nutilizing both modalities usually outperforms classification utilizing either\nmode alone. In this paper we describe our methodology and results for the SIGIR\neCom Rakuten Data Challenge. We employ a dual attention technique to model\nimage-text relationships using pretrained language and image embeddings. While\ndual attention has been widely used for Visual Question Answering(VQA) tasks,\nours is the first attempt to apply the concept for multimodal classification.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 21:22:54 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Chordia", "Varnith", ""], ["BG", "Vijay Kumar", ""]]}, {"id": "2011.11736", "submitter": "Hamed Dashti", "authors": "Rassa Ghavami Modegh (1,2), Mehrab Hamidi (1,2), Saeed Masoudian (1),\n  Amir Mohseni (1), Hamzeh Lotfalinezhad (1), Mohammad Ali Kazemi (3), Behnaz\n  Moradi (3), Mahyar Ghafoori (4), Omid Motamedi (4), Omid Pournik (4), Kiara\n  Rezaei-Kalantari (5), Amirreza Manteghinezhad (6,7), Shaghayegh Haghjooy\n  Javanmard (6,7), Fateme Abdoli Nezhad (8), Ahmad Enhesari (8), Mohammad Saeed\n  Kheyrkhah (9), Razieh Eghtesadi (10), Javid Azadbakht (11), Akbar\n  Aliasgharzadeh (10), Mohammad Reza Sharif (12), Ali Khaleghi (13), Abbas\n  Foroutan (14), Hossein Ghanaati (3), Hamed Dashti (1), Hamid R. Rabiee (1,2)\n  ((1) AI-Med Group, AI Innovation Center, Sharif University of Technology,\n  Tehran, Iran, (2) DML Lab, Department of Computer Engineering, Sharif\n  University of Technology, Tehran, Iran, (3) Department of Radiology, Tehran\n  University of Medical Sciences, Tehran, Iran, (4) Preventive Medicine and\n  Public Health Research Center, Psychosocial Health Research Institute,\n  Community and Family Medicine Department, School of Medicine, Iran University\n  of Medical Sciences, Tehran, Iran, (5) Cardiovascular Medical and Research\n  Center, Iran University of Medical Sciences, Tehran, Iran, (6) Applied\n  Physiology Research Center, Isfahan Cardiovascular Research Institute,\n  Isfahan, Iran, (7) University of Medical Science, Isfahan, Iran, (8) Kerman\n  University of Medical Sciences, Kerman, Iran, (9) Research Institute of\n  Animal Embryo Technology, Shahrekord University, Shahrekord, Iran, (10)\n  Kashan University of Medical Sciences, Kashan, Iran, (11) Department of\n  Radiology, Kashan University of Medical Sciences, Kashan, Iran, (12)\n  Department of Pediatrics, Kashan University of Medical Sciences, Kashan,\n  Iran, (13) Department of Computer Engineering, Imam Khomeini International\n  University, Qazvin, Iran, (14) Shaheed Beheshti University of Medical\n  Sciences, Medical Academy of Science, Tehran, Iran)", "title": "Accurate and Rapid Diagnosis of COVID-19 Pneumonia with Batch Effect\n  Removal of Chest CT-Scans and Interpretable Artificial Intelligence", "comments": "27 pages, 4 figures. Some minor changes have been applied to the\n  text, some fomulae are added to help the descriptions become more clear, two\n  names and two names are corrected (The full version of the names are\n  included)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  COVID-19 is a virus with high transmission rate that demands rapid\nidentification of the infected patients to reduce the spread of the disease.\nThe current gold-standard test, Reverse-Transcription Polymerase Chain Reaction\n(RT-PCR), has a high rate of false negatives. Diagnosing from CT-scan images as\na more accurate alternative has the challenge of distinguishing COVID-19 from\nother pneumonia diseases. Artificial intelligence can help radiologists and\nphysicians to accelerate the process of diagnosis, increase its accuracy, and\nmeasure the severity of the disease. We designed a new interpretable deep\nneural network to distinguish healthy people, patients with COVID-19, and\npatients with other pneumonia diseases from axial lung CT-scan images. Our\nmodel also detects the infected areas and calculates the percentage of the\ninfected lung volume. We first preprocessed the images to eliminate the batch\neffects of different devices, and then adopted a weakly supervised method to\ntrain the model without having any tags for the infected parts. We trained and\nevaluated the model on a large dataset of 3359 samples from 6 different medical\ncenters. The model reached sensitivities of 97.75% and 98.15%, and\nspecificities of 87% and 81.03% in separating healthy people from the diseased\nand COVID-19 from other diseases, respectively. It also demonstrated similar\nperformance for 1435 samples from 6 different medical centers which proves its\ngeneralizability. The performance of the model on a large diverse dataset, its\ngeneralizability, and interpretability makes it suitable to be used as a\nreliable diagnostic system.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 21:23:55 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 07:08:00 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Modegh", "Rassa Ghavami", ""], ["Hamidi", "Mehrab", ""], ["Masoudian", "Saeed", ""], ["Mohseni", "Amir", ""], ["Lotfalinezhad", "Hamzeh", ""], ["Kazemi", "Mohammad Ali", ""], ["Moradi", "Behnaz", ""], ["Ghafoori", "Mahyar", ""], ["Motamedi", "Omid", ""], ["Pournik", "Omid", ""], ["Rezaei-Kalantari", "Kiara", ""], ["Manteghinezhad", "Amirreza", ""], ["Javanmard", "Shaghayegh Haghjooy", ""], ["Nezhad", "Fateme Abdoli", ""], ["Enhesari", "Ahmad", ""], ["Kheyrkhah", "Mohammad Saeed", ""], ["Eghtesadi", "Razieh", ""], ["Azadbakht", "Javid", ""], ["Aliasgharzadeh", "Akbar", ""], ["Sharif", "Mohammad Reza", ""], ["Khaleghi", "Ali", ""], ["Foroutan", "Abbas", ""], ["Ghanaati", "Hossein", ""], ["Dashti", "Hamed", ""], ["Rabiee", "Hamid R.", ""]]}, {"id": "2011.11740", "submitter": "Charilaos Mylonas Mr.", "authors": "Charilaos Mylonas and Eleni Chatzi", "title": "Remaining Useful Life Estimation Under Uncertainty with Causal GraphNets", "comments": "A preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, a novel approach for the construction and training of time\nseries models is presented that deals with the problem of learning on large\ntime series with non-equispaced observations, which at the same time may\npossess features of interest that span multiple scales. The proposed method is\nappropriate for constructing predictive models for non-stationary stochastic\ntime series.The efficacy of the method is demonstrated on a simulated\nstochastic degradation dataset and on a real-world accelerated life testing\ndataset for ball-bearings. The proposed method, which is based on GraphNets,\nimplicitly learns a model that describes the evolution of the system at the\nlevel of a state-vector rather than of a raw observation. The proposed approach\nis compared to a recurrent network with a temporal convolutional feature\nextractor head (RNN-tCNN) which forms a known viable alternative for the\nproblem context considered. Finally, by taking advantage of recent advances in\nthe computation of reparametrization gradients for learning probability\ndistributions, a simple yet effective technique for representing prediction\nuncertainty as a Gamma distribution over remaining useful life predictions is\nemployed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 21:28:03 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mylonas", "Charilaos", ""], ["Chatzi", "Eleni", ""]]}, {"id": "2011.11743", "submitter": "Chenyang Xu", "authors": "Thomas Lavastida, Benjamin Moseley, R. Ravi and Chenyang Xu", "title": "Learnable and Instance-Robust Predictions for Online Matching, Flows and\n  Load Balancing", "comments": "To appear in ESA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for augmenting algorithms with predictions by\nrequiring that they are formally learnable and instance robust. Learnability\nensures that predictions can be efficiently constructed from a reasonable\namount of past data. Instance robustness ensures that the prediction is robust\nto modest changes in the problem input, where the measure of the change may be\nproblem specific. Instance robustness insists on a smooth degradation in\nperformance as a function of the change. Ideally, the performance is never\nworse than worst-case bounds. This also allows predictions to be objectively\ncompared.\n  We design online algorithms with predictions for a network flow allocation\nproblem and restricted assignment makespan minimization. For both problems, two\nkey properties are established: high quality predictions can be learned from a\nsmall sample of prior instances and these predictions are robust to errors that\nsmoothly degrade as the underlying problem instance changes.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 21:38:57 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 01:59:10 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Lavastida", "Thomas", ""], ["Moseley", "Benjamin", ""], ["Ravi", "R.", ""], ["Xu", "Chenyang", ""]]}, {"id": "2011.11754", "submitter": "Sourangsu Banerji", "authors": "Sourangsu Banerji, Apratim Majumder, Alex Hamrick, Rajesh Menon, and\n  Berardi Sensale-Rodriguez", "title": "Machine Learning enables Ultra-Compact Integrated Photonics through\n  Silicon-Nanopattern Digital Metamaterials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG physics.app-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we demonstrate three ultra-compact integrated-photonics\ndevices, which are designed via a machine-learning algorithm coupled with\nfinite-difference time-domain (FDTD) modeling. Through digitizing the design\ndomain into \"binary pixels\" these digital metamaterials are readily\nmanufacturable as well. By showing a variety of devices (beamsplitters and\nwaveguide bends), we showcase the generality of our approach. With an area\nfootprint smaller than ${\\lambda_0}^2$, our designs are amongst the smallest\nreported to-date. Our method combines machine learning with digital\nmetamaterials to enable ultra-compact, manufacturable devices, which could\npower a new \"Photonics Moore's Law.\"\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 22:00:20 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 17:28:59 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Banerji", "Sourangsu", ""], ["Majumder", "Apratim", ""], ["Hamrick", "Alex", ""], ["Menon", "Rajesh", ""], ["Sensale-Rodriguez", "Berardi", ""]]}, {"id": "2011.11760", "submitter": "Gabriel Huang", "authors": "Gabriel Huang, Bo Pang, Zhenhai Zhu, Clara Rivera, Radu Soricut", "title": "Multimodal Pretraining for Dense Video Captioning", "comments": "AACL-IJCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning specific hands-on skills such as cooking, car maintenance, and home\nrepairs increasingly happens via instructional videos. The user experience with\nsuch videos is known to be improved by meta-information such as time-stamped\nannotations for the main steps involved. Generating such annotations\nautomatically is challenging, and we describe here two relevant contributions.\nFirst, we construct and release a new dense video captioning dataset, Video\nTimeline Tags (ViTT), featuring a variety of instructional videos together with\ntime-stamped annotations. Second, we explore several multimodal\nsequence-to-sequence pretraining strategies that leverage large unsupervised\ndatasets of videos and caption-like texts. We pretrain and subsequently\nfinetune dense video captioning models using both YouCook2 and ViTT. We show\nthat such models generalize well and are robust over a wide variety of\ninstructional videos.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 21:49:14 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Huang", "Gabriel", ""], ["Pang", "Bo", ""], ["Zhu", "Zhenhai", ""], ["Rivera", "Clara", ""], ["Soricut", "Radu", ""]]}, {"id": "2011.11761", "submitter": "Florent Pled", "authors": "Florent Pled (MSME), Christophe Desceliers (MSME), Tianyu Zhang (MSME)", "title": "A robust solution of a statistical inverse problem in multiscale\n  computational mechanics using an artificial neural network", "comments": null, "journal-ref": "Computer Methods in Applied Mechanics and Engineering, Elsevier,\n  2021, 373, pp.113540", "doi": "10.1016/j.cma.2020.113540", "report-no": null, "categories": "cs.LG eess.SP physics.class-ph physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the inverse identification of apparent elastic properties\nof random heterogeneous materials using machine learning based on artificial\nneural networks. The proposed neural network-based identification method\nrequires the construction of a database from which an artificial neural network\ncan be trained to learn the nonlinear relationship between the hyperparameters\nof a prior stochastic model of the random compliance field and some relevant\nquantities of interest of an ad hoc multiscale computational model. An initial\ndatabase made up with input and target data is first generated from the\ncomputational model, from which a processed database is deduced by conditioning\nthe input data with respect to the target data using the nonparametric\nstatistics. Two-and three-layer feedforward artificial neural networks are then\ntrained from each of the initial and processed databases to construct an\nalgebraic representation of the nonlinear mapping between the hyperparameters\n(network outputs) and the quantities of interest (network inputs). The\nperformances of the trained artificial neural networks are analyzed in terms of\nmean squared error, linear regression fit and probability distribution between\nnetwork outputs and targets for both databases. An ad hoc probabilistic model\nof the input random vector is finally proposed in order to take into account\nuncertainties on the network input and to perform a robustness analysis of the\nnetwork output with respect to the input uncertainties level. The capability of\nthe proposed neural network-based identification method to efficiently solve\nthe underlying statistical inverse problem is illustrated through two numerical\nexamples developed within the framework of 2D plane stress linear elasticity,\nnamely a first validation example on synthetic data obtained through\ncomputational simulations and a second application example on real experimental\ndata obtained through a physical experiment monitored by digital image\ncorrelation on a real heterogeneous biological material (beef cortical bone).\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 09:37:27 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:36:36 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Pled", "Florent", "", "MSME"], ["Desceliers", "Christophe", "", "MSME"], ["Zhang", "Tianyu", "", "MSME"]]}, {"id": "2011.11765", "submitter": "Tri Huynh", "authors": "Tri Huynh, Simon Kornblith, Matthew R. Walter, Michael Maire, Maryam\n  Khademi", "title": "Boosting Contrastive Self-Supervised Learning with False Negative\n  Cancellation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning has witnessed significant leaps\nfueled by recent progress in Contrastive learning, which seeks to learn\ntransformations that embed positive input pairs nearby, while pushing negative\npairs far apart. While positive pairs can be generated reliably (e.g., as\ndifferent views of the same image), it is difficult to accurately establish\nnegative pairs, defined as samples from different images regardless of their\nsemantic content or visual features. A fundamental problem in contrastive\nlearning is mitigating the effects of false negatives. Contrasting false\nnegatives induces two critical issues in representation learning: discarding\nsemantic information and slow convergence. In this paper, we study this problem\nin detail and propose novel approaches to mitigate the effects of false\nnegatives. The proposed methods exhibit consistent and significant improvements\nover existing contrastive learning-based models. They achieve new\nstate-of-the-art performance on ImageNet evaluations, achieving 5.8% absolute\nimprovement in top-1 accuracy over the previous state-of-the-art when\nfinetuning with 1% labels, as well as transferring to downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 22:17:21 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Huynh", "Tri", ""], ["Kornblith", "Simon", ""], ["Walter", "Matthew R.", ""], ["Maire", "Michael", ""], ["Khademi", "Maryam", ""]]}, {"id": "2011.11779", "submitter": "Chengyue Gong", "authors": "Chengyue Gong, Dilin Wang, Qiang Liu", "title": "AlphaMatch: Improving Consistency for Semi-supervised Learning with\n  Alpha-divergence", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semi-supervised learning (SSL) is a key approach toward more data-efficient\nmachine learning by jointly leverage both labeled and unlabeled data. We\npropose AlphaMatch, an efficient SSL method that leverages data augmentations,\nby efficiently enforcing the label consistency between the data points and the\naugmented data derived from them. Our key technical contribution lies on: 1)\nusing alpha-divergence to prioritize the regularization on data with high\nconfidence, achieving a similar effect as FixMatch but in a more flexible\nfashion, and 2) proposing an optimization-based, EM-like algorithm to enforce\nthe consistency, which enjoys better convergence than iterative regularization\nprocedures used in recent SSL methods such as FixMatch, UDA, and MixMatch.\nAlphaMatch is simple and easy to implement, and consistently outperforms prior\narts on standard benchmarks, e.g. CIFAR-10, SVHN, CIFAR-100, STL-10.\nSpecifically, we achieve 91.3% test accuracy on CIFAR-10 with just 4 labelled\ndata per class, substantially improving over the previously best 88.7% accuracy\nachieved by FixMatch.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 22:43:45 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Gong", "Chengyue", ""], ["Wang", "Dilin", ""], ["Liu", "Qiang", ""]]}, {"id": "2011.11785", "submitter": "Carlos Henrique Caloete Pena", "authors": "Carlos H. C. Pena, Mateus G. Machado, Mariana S. Barros, Jos\\'e D. P.\n  Silva, Lucas D. Maciel, Tsang Ing Ren, Edna N. S. Barros, Pedro H. M. Braga,\n  Hansenclever F. Bassani", "title": "An analysis of Reinforcement Learning applied to Coach task in IEEE Very\n  Small Size Soccer", "comments": "6 pages, 9 figures, to be published in Latin American Robotics\n  Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The IEEE Very Small Size Soccer (VSSS) is a robot soccer competition in which\ntwo teams of three small robots play against each other. Traditionally, a\ndeterministic coach agent will choose the most suitable strategy and formation\nfor each adversary's strategy. Therefore, the role of a coach is of great\nimportance to the game. In this sense, this paper proposes an end-to-end\napproach for the coaching task based on Reinforcement Learning (RL). The\nproposed system processes the information during the simulated matches to learn\nan optimal policy that chooses the current formation, depending on the opponent\nand game conditions. We trained two RL policies against three different teams\n(balanced, offensive, and heavily offensive) in a simulated environment. Our\nresults were assessed against one of the top teams of the VSSS league, showing\npromising results after achieving a win/loss ratio of approximately 2.0.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 23:10:06 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Pena", "Carlos H. C.", ""], ["Machado", "Mateus G.", ""], ["Barros", "Mariana S.", ""], ["Silva", "Jos\u00e9 D. P.", ""], ["Maciel", "Lucas D.", ""], ["Ren", "Tsang Ing", ""], ["Barros", "Edna N. S.", ""], ["Braga", "Pedro H. M.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "2011.11804", "submitter": "Xia Li", "authors": "Mariam Alaverdian, William Gilroy, Veronica Kirgios, Xia Li, Carolina\n  Matuk, Daniel Mckenzie, Tachin Ruangkriengsin, Andrea Bertozzi, and Jeffrey\n  Brantingham", "title": "Who killed Lilly Kane? A case study in applying knowledge graphs to\n  crime fiction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a preliminary study of a knowledge graph created from season one\nof the television show Veronica Mars, which follows the eponymous young private\ninvestigator as she attempts to solve the murder of her best friend Lilly Kane.\nWe discuss various techniques for mining the knowledge graph for clues and\npotential suspects. We also discuss best practice for collaboratively\nconstructing knowledge graphs from television shows.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:26:07 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Alaverdian", "Mariam", ""], ["Gilroy", "William", ""], ["Kirgios", "Veronica", ""], ["Li", "Xia", ""], ["Matuk", "Carolina", ""], ["Mckenzie", "Daniel", ""], ["Ruangkriengsin", "Tachin", ""], ["Bertozzi", "Andrea", ""], ["Brantingham", "Jeffrey", ""]]}, {"id": "2011.11805", "submitter": "Andrew O'Brien", "authors": "Edward Kim, Connor Onweller, Andrew O'Brien, Kathleen McCoy", "title": "The Interpretable Dictionary in Sparse Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs), specifically deep learning networks, have\noften been labeled as black boxes due to the fact that the internal\nrepresentation of the data is not easily interpretable. In our work, we\nillustrate that an ANN, trained using sparse coding under specific sparsity\nconstraints, yields a more interpretable model than the standard deep learning\nmodel. The dictionary learned by sparse coding can be more easily understood\nand the activations of these elements creates a selective feature output. We\ncompare and contrast our sparse coding model with an equivalent feed forward\nconvolutional autoencoder trained on the same data. Our results show both\nqualitative and quantitative benefits in the interpretation of the learned\nsparse coding dictionary as well as the internal activation representations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:26:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kim", "Edward", ""], ["Onweller", "Connor", ""], ["O'Brien", "Andrew", ""], ["McCoy", "Kathleen", ""]]}, {"id": "2011.11818", "submitter": "Quan Wang", "authors": "Yiling Huang, Yutian Chen, Jason Pelecanos, Quan Wang", "title": "Synth2Aug: Cross-domain speaker recognition with TTS synthesized speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Text-To-Speech (TTS) has been used as a data augmentation\ntechnique for speech recognition to help complement inadequacies in the\ntraining data. Correspondingly, we investigate the use of a multi-speaker TTS\nsystem to synthesize speech in support of speaker recognition. In this study we\nfocus the analysis on tasks where a relatively small number of speakers is\navailable for training. We observe on our datasets that TTS synthesized speech\nimproves cross-domain speaker recognition performance and can be combined\neffectively with multi-style training. Additionally, we explore the\neffectiveness of different types of text transcripts used for TTS synthesis.\nResults suggest that matching the textual content of the target domain is a\ngood practice, and if that is not feasible, a transcript with a sufficiently\nlarge vocabulary is recommended.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:48:54 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Huang", "Yiling", ""], ["Chen", "Yutian", ""], ["Pelecanos", "Jason", ""], ["Wang", "Quan", ""]]}, {"id": "2011.11819", "submitter": "Ming Ding Dr.", "authors": "Bo Liu, Ming Ding, Sina Shaham, Wenny Rahayu, Farhad Farokhi, Zihuai\n  Lin", "title": "When Machine Learning Meets Privacy: A Survey and Outlook", "comments": "This work is accepted by ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The newly emerged machine learning (e.g. deep learning) methods have become a\nstrong driving force to revolutionize a wide range of industries, such as smart\nhealthcare, financial technology, and surveillance systems. Meanwhile, privacy\nhas emerged as a big concern in this machine learning-based artificial\nintelligence era. It is important to note that the problem of privacy\npreservation in the context of machine learning is quite different from that in\ntraditional data privacy protection, as machine learning can act as both friend\nand foe. Currently, the work on the preservation of privacy and machine\nlearning (ML) is still in an infancy stage, as most existing solutions only\nfocus on privacy problems during the machine learning process. Therefore, a\ncomprehensive study on the privacy preservation problems and machine learning\nis required. This paper surveys the state of the art in privacy issues and\nsolutions for machine learning. The survey covers three categories of\ninteractions between privacy and machine learning: (i) private machine\nlearning, (ii) machine learning aided privacy protection, and (iii) machine\nlearning-based privacy attack and corresponding protection schemes. The current\nresearch progress in each category is reviewed and the key challenges are\nidentified. Finally, based on our in-depth analysis of the area of privacy and\nmachine learning, we point out future research directions in this field.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:52:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Liu", "Bo", ""], ["Ding", "Ming", ""], ["Shaham", "Sina", ""], ["Rahayu", "Wenny", ""], ["Farokhi", "Farhad", ""], ["Lin", "Zihuai", ""]]}, {"id": "2011.11820", "submitter": "Benjamin Guedj", "authors": "Florent Dewez and Benjamin Guedj and Arthur Talpaert and Vincent\n  Vandewalle", "title": "An end-to-end data-driven optimisation framework for constrained\n  trajectories", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many real-world problems require to optimise trajectories under constraints.\nClassical approaches are based on optimal control methods but require an exact\nknowledge of the underlying dynamics, which could be challenging or even out of\nreach. In this paper, we leverage data-driven approaches to design a new\nend-to-end framework which is dynamics-free for optimised and realistic\ntrajectories. We first decompose the trajectories on function basis, trading\nthe initial infinite dimension problem on a multivariate functional space for a\nparameter optimisation problem. A maximum \\emph{a posteriori} approach which\nincorporates information from data is used to obtain a new optimisation problem\nwhich is regularised. The penalised term focuses the search on a region\ncentered on data and includes estimated linear constraints in the problem. We\napply our data-driven approach to two settings in aeronautics and sailing\nroutes optimisation, yielding commanding results. The developed approach has\nbeen implemented in the Python library PyRotor.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 00:54:17 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 09:24:54 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Dewez", "Florent", ""], ["Guedj", "Benjamin", ""], ["Talpaert", "Arthur", ""], ["Vandewalle", "Vincent", ""]]}, {"id": "2011.11826", "submitter": "Yanshi Wang", "authors": "Yanshi Wang, Jie Zhang, Qing Da, Anxiang Zeng", "title": "Delayed Feedback Modeling for the Entire Space Conversion Rate\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Estimating post-click conversion rate (CVR) accurately is crucial in\nE-commerce. However, CVR prediction usually suffers from three major challenges\nin practice: i) data sparsity: compared with impressions, conversion samples\nare often extremely scarce; ii) sample selection bias: conventional CVR models\nare trained with clicked impressions while making inference on the entire space\nof all impressions; iii) delayed feedback: many conversions can only be\nobserved after a relatively long and random delay since clicks happened,\nresulting in many false negative labels during training. Previous studies\nmainly focus on one or two issues while ignoring the others. In this paper, we\npropose a novel neural network framework ESDF to tackle the above three\nchallenges simultaneously. Unlike existing methods, ESDF models the CVR\nprediction from a perspective of entire space, and combines the advantage of\nuser sequential behavior pattern and the time delay factor. Specifically, ESDF\nutilizes sequential behavior of user actions on the entire space with all\nimpressions to alleviate the sample selection bias problem. By sharing the\nembedding parameters between CTR and CVR networks, data sparsity problem is\ngreatly relieved. Different from conventional delayed feedback methods, ESDF\ndoes not make any special assumption about the delay distribution. We\ndiscretize the delay time by day slot and model the probability based on\nsurvival analysis with deep neural network, which is more practical and\nsuitable for industrial situations. Extensive experiments are conducted to\nevaluate the effectiveness of our method. To the best of our knowledge, ESDF is\nthe first attempt to unitedly solve the above three challenges in CVR\nprediction area.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 01:14:03 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wang", "Yanshi", ""], ["Zhang", "Jie", ""], ["Da", "Qing", ""], ["Zeng", "Anxiang", ""]]}, {"id": "2011.11827", "submitter": "Yunzhe Tao", "authors": "Yunzhe Tao, Sahika Genc, Jonathan Chung, Tao Sun, Sunil Mallya", "title": "REPAINT: Knowledge Transfer in Deep Reinforcement Learning", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating learning processes for complex tasks by leveraging previously\nlearned tasks has been one of the most challenging problems in reinforcement\nlearning, especially when the similarity between source and target tasks is\nlow. This work proposes REPresentation And INstance Transfer (REPAINT)\nalgorithm for knowledge transfer in deep reinforcement learning. REPAINT not\nonly transfers the representation of a pre-trained teacher policy in the\non-policy learning, but also uses an advantage-based experience selection\napproach to transfer useful samples collected following the teacher policy in\nthe off-policy learning. Our experimental results on several benchmark tasks\nshow that REPAINT significantly reduces the total training time in generic\ncases of task similarity. In particular, when the source tasks are dissimilar\nto, or sub-tasks of, the target tasks, REPAINT outperforms other baselines in\nboth training-time reduction and asymptotic performance of return scores.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 01:18:32 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 18:57:25 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 05:25:23 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Tao", "Yunzhe", ""], ["Genc", "Sahika", ""], ["Chung", "Jonathan", ""], ["Sun", "Tao", ""], ["Mallya", "Sunil", ""]]}, {"id": "2011.11829", "submitter": "Zhiwen Xiao", "authors": "Zhiwen Xiao, Xin Xu, Huanlai Xing, Shouxi Luo, Penglin Dai, Dawei Zhan", "title": "RTFN: A Robust Temporal Feature Network for Time Series Classification", "comments": "41pages, 7figures, Revised Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data usually contains local and global patterns. Most of the\nexisting feature networks pay more attention to local features rather than the\nrelationships among them. The latter is, however, also important yet more\ndifficult to explore. To obtain sufficient representations by a feature network\nis still challenging. To this end, we propose a novel robust temporal feature\nnetwork (RTFN) for feature extraction in time series classification, containing\na temporal feature network (TFN) and an LSTM-based attention network (LSTMaN).\nTFN is a residual structure with multiple convolutional layers. It functions as\na local-feature extraction network to mine sufficient local features from data.\nLSTMaN is composed of two identical layers, where attention and long short-term\nmemory (LSTM) networks are hybridized. This network acts as a relation\nextraction network to discover the intrinsic relationships among the extracted\nfeatures at different positions in sequential data. In experiments, we embed\nRTFN into a supervised structure as a feature extractor and into an\nunsupervised structure as an encoder, respectively. The results show that the\nRTFN-based structures achieve excellent supervised and unsupervised performance\non a large number of UCR2018 and UEA2018 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 01:24:04 GMT"}, {"version": "v2", "created": "Tue, 29 Dec 2020 02:23:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Xiao", "Zhiwen", ""], ["Xu", "Xin", ""], ["Xing", "Huanlai", ""], ["Luo", "Shouxi", ""], ["Dai", "Penglin", ""], ["Zhan", "Dawei", ""]]}, {"id": "2011.11835", "submitter": "Miao Yang", "authors": "Miao Yang, Hongbin Zhu, Hua Qian, Yevgeni Koucheryavy, Konstantin\n  Samouylov, and Haifeng Wang", "title": "Peer Offloading with Delayed Feedback in Fog Networks", "comments": "12 pages, 11 figures, accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing to cloud computing, fog computing performs computation and services\nat the edge of networks, thus relieving the computation burden of the data\ncenter and reducing the task latency of end devices. Computation latency is a\ncrucial performance metric in fog computing, especially for real-time\napplications. In this paper, we study a peer computation offloading problem for\na fog network with unknown dynamics. In this scenario, each fog node (FN) can\noffload their computation tasks to neighboring FNs in a time slot manner. The\noffloading latency, however, could not be fed back to the task dispatcher\ninstantaneously due to the uncertainty of the processing time in peer FNs.\nBesides, peer competition occurs when different FNs offload tasks to one FN at\nthe same time. To tackle the above difficulties, we model the computation\noffloading problem as a sequential FN selection problem with delayed\ninformation feedback. Using adversarial multi-arm bandit framework, we\nconstruct an online learning policy to deal with delayed information feedback.\nDifferent contention resolution approaches are considered to resolve peer\ncompetition. Performance analysis shows that the regret of the proposed\nalgorithm, or the performance loss with suboptimal FN selections, achieves a\nsub-linear order, suggesting an optimal FN selection policy. In addition, we\nprove that the proposed strategy can result in a Nash equilibrium (NE) with all\nFNs playing the same policy. Simulation results validate the effectiveness of\nthe proposed policy.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:03:48 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 07:30:59 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Yang", "Miao", ""], ["Zhu", "Hongbin", ""], ["Qian", "Hua", ""], ["Koucheryavy", "Yevgeni", ""], ["Samouylov", "Konstantin", ""], ["Wang", "Haifeng", ""]]}, {"id": "2011.11840", "submitter": "Omobayode Fagbohungbe", "authors": "Omobayode Fagbohungbe, Lijun Qian", "title": "Benchmarking Inference Performance of Deep Learning Models on Analog\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analog hardware implemented deep learning models are promising for\ncomputation and energy constrained systems such as edge computing devices.\nHowever, the analog nature of the device and the associated many noise sources\nwill cause changes to the value of the weights in the trained deep learning\nmodels deployed on such devices. In this study, systematic evaluation of the\ninference performance of trained popular deep learning models for image\nclassification deployed on analog devices has been carried out, where additive\nwhite Gaussian noise has been added to the weights of the trained models during\ninference. It is observed that deeper models and models with more redundancy in\ndesign such as VGG are more robust to the noise in general. However, the\nperformance is also affected by the design philosophy of the model, the\ndetailed structure of the model, the exact machine learning task, as well as\nthe datasets.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:14:39 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 22:04:52 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Fagbohungbe", "Omobayode", ""], ["Qian", "Lijun", ""]]}, {"id": "2011.11844", "submitter": "Naoya Takahashi", "authors": "Naoya Takahashi, Yuki Mitsufuji", "title": "Densely connected multidilated convolutional networks for dense\n  prediction tasks", "comments": "Accepted to CVPR 2021. arXiv admin note: text overlap with\n  arXiv:2010.01733", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Tasks that involve high-resolution dense prediction require a modeling of\nboth local and global patterns in a large input field. Although the local and\nglobal structures often depend on each other and their simultaneous modeling is\nimportant, many convolutional neural network (CNN)-based approaches interchange\nrepresentations in different resolutions only a few times. In this paper, we\nclaim the importance of a dense simultaneous modeling of multiresolution\nrepresentation and propose a novel CNN architecture called densely connected\nmultidilated DenseNet (D3Net). D3Net involves a novel multidilated convolution\nthat has different dilation factors in a single layer to model different\nresolutions simultaneously. By combining the multidilated convolution with the\nDenseNet architecture, D3Net incorporates multiresolution learning with an\nexponentially growing receptive field in almost all layers, while avoiding the\naliasing problem that occurs when we naively incorporate the dilated\nconvolution in DenseNet. Experiments on the image semantic segmentation task\nusing Cityscapes and the audio source separation task using MUSDB18 show that\nthe proposed method has superior performance over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 05:15:12 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 00:31:49 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Takahashi", "Naoya", ""], ["Mitsufuji", "Yuki", ""]]}, {"id": "2011.11846", "submitter": "Tien Dung Nguyen", "authors": "Tien-Dung Nguyen, Bogdan Gabrys and Katarzyna Musial", "title": "AutoWeka4MCPS-AVATAR: Accelerating Automated Machine Learning Pipeline\n  Composition and Optimisation", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.11158", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automated machine learning pipeline (ML) composition and optimisation aim at\nautomating the process of finding the most promising ML pipelines within\nallocated resources (i.e., time, CPU and memory). Existing methods, such as\nBayesian-based and genetic-based optimisation, which are implemented in\nAuto-Weka, Auto-sklearn and TPOT, evaluate pipelines by executing them.\nTherefore, the pipeline composition and optimisation of these methods\nfrequently require a tremendous amount of time that prevents them from\nexploring complex pipelines to find better predictive models. To further\nexplore this research challenge, we have conducted experiments showing that\nmany of the generated pipelines are invalid in the first place, and attempting\nto execute them is a waste of time and resources. To address this issue, we\npropose a novel method to evaluate the validity of ML pipelines, without their\nexecution, using a surrogate model (AVATAR). The AVATAR generates a knowledge\nbase by automatically learning the capabilities and effects of ML algorithms on\ndatasets' characteristics. This knowledge base is used for a simplified mapping\nfrom an original ML pipeline to a surrogate model which is a Petri net based\npipeline. Instead of executing the original ML pipeline to evaluate its\nvalidity, the AVATAR evaluates its surrogate model constructed by capabilities\nand effects of the ML pipeline components and input/output simplified mappings.\nEvaluating this surrogate model is less resource-intensive than the execution\nof the original pipeline. As a result, the AVATAR enables the pipeline\ncomposition and optimisation methods to evaluate more pipelines by quickly\nrejecting invalid pipelines. We integrate the AVATAR into the sequential\nmodel-based algorithm configuration (SMAC). Our experiments show that when SMAC\nemploys AVATAR, it finds better solutions than on its own.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 14:05:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Nguyen", "Tien-Dung", ""], ["Gabrys", "Bogdan", ""], ["Musial", "Katarzyna", ""]]}, {"id": "2011.11850", "submitter": "Soham Uday Gadgil", "authors": "Soham Gadgil, Yunfeng Xin, Chengzhe Xu", "title": "Solving The Lunar Lander Problem under Uncertainty using Reinforcement\n  Learning", "comments": null, "journal-ref": "SoutheastCon 2020", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement Learning (RL) is an area of machine learning concerned with\nenabling an agent to navigate an environment with uncertainty in order to\nmaximize some notion of cumulative long-term reward. In this paper, we\nimplement and analyze two different RL techniques, Sarsa and Deep QLearning, on\nOpenAI Gym's LunarLander-v2 environment. We then introduce additional\nuncertainty to the original problem to test the robustness of the mentioned\ntechniques. With our best models, we are able to achieve average rewards of\n170+ with the Sarsa agent and 200+ with the Deep Q-Learning agent on the\noriginal problem. We also show that these techniques are able to overcome the\nadditional uncertainities and achieve positive average rewards of 100+ with\nboth agents. We then perform a comparative analysis of the two techniques to\nconclude which agent peforms better.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:35:21 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Gadgil", "Soham", ""], ["Xin", "Yunfeng", ""], ["Xu", "Chengzhe", ""]]}, {"id": "2011.11852", "submitter": "Joao Paulo Jansch-Porto", "authors": "Joao Paulo Jansch-Porto, Bin Hu, Geir Dullerud", "title": "Policy Optimization for Markovian Jump Linear Quadratic Control:\n  Gradient-Based Methods and Global Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, policy optimization for control purposes has received renewed\nattention due to the increasing interest in reinforcement learning. In this\npaper, we investigate the global convergence of gradient-based policy\noptimization methods for quadratic optimal control of discrete-time Markovian\njump linear systems (MJLS). First, we study the optimization landscape of\ndirect policy optimization for MJLS, with static state feedback controllers and\nquadratic performance costs. Despite the non-convexity of the resultant\nproblem, we are still able to identify several useful properties such as\ncoercivity, gradient dominance, and almost smoothness. Based on these\nproperties, we show global convergence of three types of policy optimization\nmethods: the gradient descent method; the Gauss-Newton method; and the natural\npolicy gradient method. We prove that all three methods converge to the optimal\nstate feedback controller for MJLS at a linear rate if initialized at a\ncontroller which is mean-square stabilizing. Some numerical examples are\npresented to support the theory. This work brings new insights for\nunderstanding the performance of policy gradient methods on the Markovian jump\nlinear quadratic control problem.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:39:38 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Jansch-Porto", "Joao Paulo", ""], ["Hu", "Bin", ""], ["Dullerud", "Geir", ""]]}, {"id": "2011.11857", "submitter": "J\\'er\\^ome Rony", "authors": "J\\'er\\^ome Rony, Eric Granger, Marco Pedersoli, Ismail Ben Ayed", "title": "Augmented Lagrangian Adversarial Attacks", "comments": "Code available at\n  https://github.com/jeromerony/augmented_lagrangian_adversarial_attacks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack algorithms are dominated by penalty methods, which are\nslow in practice, or more efficient distance-customized methods, which are\nheavily tailored to the properties of the considered distance. We propose a\nwhite-box attack algorithm to generate minimally perturbed adversarial examples\nbased on Augmented Lagrangian principles. We bring several non-trivial\nalgorithmic modifications, which have a crucial effect on performance. Our\nattack enjoys the generality of penalty methods and the computational\nefficiency of distance-customized algorithms, and can be readily used for a\nwide set of distances. We compare our attack to state-of-the-art methods on\nthree datasets and several models, and consistently obtain competitive\nperformances with similar or lower computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:51:08 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Rony", "J\u00e9r\u00f4me", ""], ["Granger", "Eric", ""], ["Pedersoli", "Marco", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "2011.11858", "submitter": "Hexin Bai", "authors": "Hexin Bai, Wensheng Cheng, Peng Chu, Juehuan Liu, Kai Zhang, Haibin\n  Ling", "title": "GMOT-40: A Benchmark for Generic Multiple Object Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Object Tracking (MOT) has witnessed remarkable advances in recent\nyears. However, existing studies dominantly request prior knowledge of the\ntracking target, and hence may not generalize well to unseen categories. In\ncontrast, Generic Multiple Object Tracking (GMOT), which requires little prior\ninformation about the target, is largely under-explored. In this paper, we make\ncontributions to boost the study of GMOT in three aspects. First, we construct\nthe first public GMOT dataset, dubbed GMOT-40, which contains 40 carefully\nannotated sequences evenly distributed among 10 object categories. In addition,\ntwo tracking protocols are adopted to evaluate different characteristics of\ntracking algorithms. Second, by noting the lack of devoted tracking algorithms,\nwe have designed a series of baseline GMOT algorithms. Third, we perform a\nthorough evaluation on GMOT-40, involving popular MOT algorithms (with\nnecessary modifications) and the proposed baselines. We will release the\nGMOT-40 benchmark, the evaluation results, as well as the baseline algorithm to\nthe public upon the publication of the paper.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:51:46 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 17:40:03 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 19:13:00 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Bai", "Hexin", ""], ["Cheng", "Wensheng", ""], ["Chu", "Peng", ""], ["Liu", "Juehuan", ""], ["Zhang", "Kai", ""], ["Ling", "Haibin", ""]]}, {"id": "2011.11860", "submitter": "Yixin Liu", "authors": "Zhao Li, Yixin Liu, Zhen Zhang, Shirui Pan, Jianliang Gao, Jiajun Bu", "title": "Cyclic Label Propagation for Graph Semi-supervised Learning", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have emerged as effective approaches for graph\nanalysis, especially in the scenario of semi-supervised learning. Despite its\nsuccess, GNN often suffers from over-smoothing and over-fitting problems, which\naffects its performance on node classification tasks. We analyze that an\nalternative method, the label propagation algorithm (LPA), avoids the\naforementioned problems thus it is a promising choice for graph semi-supervised\nlearning. Nevertheless, the intrinsic limitations of LPA on feature\nexploitation and relation modeling make propagating labels become less\neffective. To overcome these limitations, we introduce a novel framework for\ngraph semi-supervised learning termed as Cyclic Label Propagation (CycProp for\nabbreviation), which integrates GNNs into the process of label propagation in a\ncyclic and mutually reinforcing manner to exploit the advantages of both GNNs\nand LPA. In particular, our proposed CycProp updates the node embeddings\nlearned by GNN module with the augmented information by label propagation,\nwhile fine-tunes the weighted graph of label propagation with the help of node\nembedding in turn. After the model converges, reliably predicted labels and\ninformative node embeddings are obtained with the LPA and GNN modules\nrespectively. Extensive experiments on various real-world datasets are\nconducted, and the experimental results empirically demonstrate that the\nproposed CycProp model can achieve relatively significant gains over the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 02:55:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Li", "Zhao", ""], ["Liu", "Yixin", ""], ["Zhang", "Zhen", ""], ["Pan", "Shirui", ""], ["Gao", "Jianliang", ""], ["Bu", "Jiajun", ""]]}, {"id": "2011.11866", "submitter": "Gurcan Comert", "authors": "Gurcan Comert", "title": "Gaussian Processes for Traffic Speed Prediction at Different Aggregation\n  Levels", "comments": "13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic behavior of traffic adversely affect the performance of the\nprediction models in intelligent transportation applications. This study\napplies Gaussian processes (GPs) to traffic speed prediction. Such predictions\ncan be used by various transportation applications, such as real-time route\nguidance, ramp metering, congestion pricing and special events traffic\nmanagement. One-step predictions with various aggregation levels (1 to\n60-minute) are tested for performance of the generated models. Univariate and\nmultivariate GPs are compared with several other linear, nonlinear time series,\nand Grey system models using loop and Inrix probe vehicle datasets from\nCalifornia, Portland, and Virginia freeways respectively. Based on the test\ndata samples, results are promising that GP models are able to consistently\noutperform compared models with similar computational times.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 03:05:01 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Comert", "Gurcan", ""]]}, {"id": "2011.11877", "submitter": "Ruizhe Zhang", "authors": "Baihe Huang, Zhao Song, Runzhou Tao, Ruizhe Zhang, Danyang Zhuo", "title": "InstaHide's Sample Complexity When Mixing Two Private Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.CR cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inspired by InstaHide challenge [Huang, Song, Li and Arora'20], [Chen, Song\nand Zhuo'20] recently provides one mathematical formulation of InstaHide attack\nproblem under Gaussian images distribution. They show that it suffices to use\n$O(n_{\\mathsf{priv}}^{k_{\\mathsf{priv}} - 2/(k_{\\mathsf{priv}} + 1)})$ samples\nto recover one private image in $n_{\\mathsf{priv}}^{O(k_{\\mathsf{priv}})} +\n\\mathrm{poly}(n_{\\mathsf{pub}})$ time for any integer $k_{\\mathsf{priv}}$,\nwhere $n_{\\mathsf{priv}}$ and $n_{\\mathsf{pub}}$ denote the number of images\nused in the private and the public dataset to generate a mixed image sample.\n  Under the current setup for the InstaHide challenge of mixing two private\nimages ($k_{\\mathsf{priv}} = 2$), this means $n_{\\mathsf{priv}}^{4/3}$ samples\nare sufficient to recover a private image. In this work, we show that\n$n_{\\mathsf{priv}} \\log ( n_{\\mathsf{priv}} )$ samples are sufficient\n(information-theoretically) for recovering all the private images.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 03:41:03 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Huang", "Baihe", ""], ["Song", "Zhao", ""], ["Tao", "Runzhou", ""], ["Zhang", "Ruizhe", ""], ["Zhuo", "Danyang", ""]]}, {"id": "2011.11878", "submitter": "Hyemi Kim", "authors": "Hyemi Kim, Seungjae Shin, JoonHo Jang, Kyungwoo Song, Weonyoung Joo,\n  Wanmo Kang, Il-Chul Moon", "title": "Counterfactual Fairness with Disentangled Causal Effect Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of fair classification can be mollified if we develop a method to\nremove the embedded sensitive information from the classification features.\nThis line of separating the sensitive information is developed through the\ncausal inference, and the causal inference enables the counterfactual\ngenerations to contrast the what-if case of the opposite sensitive attribute.\nAlong with this separation with the causality, a frequent assumption in the\ndeep latent causal model defines a single latent variable to absorb the entire\nexogenous uncertainty of the causal graph. However, we claim that such\nstructure cannot distinguish the 1) information caused by the intervention\n(i.e., sensitive variable) and 2) information correlated with the intervention\nfrom the data. Therefore, this paper proposes Disentangled Causal Effect\nVariational Autoencoder (DCEVAE) to resolve this limitation by disentangling\nthe exogenous uncertainty into two latent variables: either 1) independent to\ninterventions or 2) correlated to interventions without causality.\nParticularly, our disentangling approach preserves the latent variable\ncorrelated to interventions in generating counterfactual examples. We show that\nour method estimates the total effect and the counterfactual effect without a\ncomplete causal graph. By adding a fairness regularization, DCEVAE generates a\ncounterfactual fair dataset while losing less original information. Also,\nDCEVAE generates natural counterfactual images by only flipping sensitive\ninformation. Additionally, we theoretically show the differences in the\ncovariance structures of DCEVAE and prior works from the perspective of the\nlatent disentanglement.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 03:43:59 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 09:46:14 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Kim", "Hyemi", ""], ["Shin", "Seungjae", ""], ["Jang", "JoonHo", ""], ["Song", "Kyungwoo", ""], ["Joo", "Weonyoung", ""], ["Kang", "Wanmo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2011.11879", "submitter": "Cheng Jiang", "authors": "Cheng Jiang (1), Jun Liao (1), Pei Dong (1), Zhaoxuan Ma (1), De Cai\n  (1), Guoan Zheng (2), Yueping Liu (3), Hong Bu (4 and 5) and Jianhua Yao (1)\n  ((1) Tencent AI Lab, Shenzhen, China,(2) Department of Biomedical\n  Engineering, University of Connecticut, Storrs, CT, USA,(3) Department of\n  Pathology, The Fourth Hospital of Hebei Medical University, Hebei, China,(4)\n  Department of Pathology, West China Hospital, Sichuan University, Chengdu,\n  China,(5) Laboratory of Pathology, Clinical Research Centre for Breast, West\n  China Hospital, Sichuan University, Chengdu, China.)", "title": "Blind deblurring for microscopic pathology images using deep learning\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI)-powered pathology is a revolutionary step in the\nworld of digital pathology and shows great promise to increase both diagnosis\naccuracy and efficiency. However, defocus and motion blur can obscure tissue or\ncell characteristics hence compromising AI algorithms'accuracy and robustness\nin analyzing the images. In this paper, we demonstrate a deep-learning-based\napproach that can alleviate the defocus and motion blur of a microscopic image\nand output a sharper and cleaner image with retrieved fine details without\nprior knowledge of the blur type, blur extent and pathological stain. In this\napproach, a deep learning classifier is first trained to identify the image\nblur type. Then, two encoder-decoder networks are trained and used alone or in\ncombination to deblur the input image. It is an end-to-end approach and\nintroduces no corrugated artifacts as traditional blind deconvolution methods\ndo. We test our approach on different types of pathology specimens and\ndemonstrate great performance on image blur correction and the subsequent\nimprovement on the diagnosis outcome of AI algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 03:52:45 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Jiang", "Cheng", "", "4 and 5"], ["Liao", "Jun", "", "4 and 5"], ["Dong", "Pei", "", "4 and 5"], ["Ma", "Zhaoxuan", "", "4 and 5"], ["Cai", "De", "", "4 and 5"], ["Zheng", "Guoan", "", "4 and 5"], ["Liu", "Yueping", "", "4 and 5"], ["Bu", "Hong", "", "4 and 5"], ["Yao", "Jianhua", ""]]}, {"id": "2011.11884", "submitter": "Trang Tran", "authors": "Trang H. Tran, Lam M. Nguyen, Quoc Tran-Dinh", "title": "SMG: A Shuffling Gradient-Based Method with Momentum", "comments": "The 38th International Conference on Machine Learning (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine two advanced ideas widely used in optimization for machine\nlearning: shuffling strategy and momentum technique to develop a novel\nshuffling gradient-based method with momentum, coined Shuffling Momentum\nGradient (SMG), for non-convex finite-sum optimization problems. While our\nmethod is inspired by momentum techniques, its update is fundamentally\ndifferent from existing momentum-based methods. We establish state-of-the-art\nconvergence rates of SMG for any shuffling strategy using either constant or\ndiminishing learning rate under standard assumptions (i.e.$L$-smoothness and\nbounded variance). When the shuffling strategy is fixed, we develop another new\nalgorithm that is similar to existing momentum methods, and prove the same\nconvergence rates for this algorithm under the $L$-smoothness and bounded\ngradient assumptions. We demonstrate our algorithms via numerical simulations\non standard datasets and compare them with existing shuffling methods. Our\ntests have shown encouraging performance of the new algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 04:12:35 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:08:20 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 13:50:24 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Tran", "Trang H.", ""], ["Nguyen", "Lam M.", ""], ["Tran-Dinh", "Quoc", ""]]}, {"id": "2011.11891", "submitter": "Zehao Jin", "authors": "Zehao Jin, Joshua Yao-Yu Lin, Siao-Fong Li", "title": "Learning Principle of Least Action with Reinforcement Learning", "comments": "4 pages, 4 figures, preprint. Comments welcome!!!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.class-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nature provides a way to understand physics with reinforcement learning since\nnature favors the economical way for an object to propagate. In the case of\nclassical mechanics, nature favors the object to move along the path according\nto the integral of the Lagrangian, called the action $\\mathcal{S}$. We consider\nsetting the reward/penalty as a function of $\\mathcal{S}$, so the agent could\nlearn the physical trajectory of particles in various kinds of environments\nwith reinforcement learning. In this work, we verified the idea by using a\nQ-Learning based algorithm on learning how light propagates in materials with\ndifferent refraction indices, and show that the agent could recover the\nminimal-time path equivalent to the solution obtained by Snell's law or\nFermat's Principle. We also discuss the similarity of our reinforcement\nlearning approach to the path integral formalism.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 04:38:38 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 08:35:40 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Jin", "Zehao", ""], ["Lin", "Joshua Yao-Yu", ""], ["Li", "Siao-Fong", ""]]}, {"id": "2011.11904", "submitter": "Xiangyu Niu", "authors": "Xiangyu Niu, Yifan Sun, Jinyuan Sun", "title": "Latent Group Structured Multi-task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task learning (MTL), we improve the performance of key machine\nlearning algorithms by training various tasks jointly. When the number of tasks\nis large, modeling task structure can further refine the task relationship\nmodel. For example, often tasks can be grouped based on metadata, or via simple\npreprocessing steps like K-means. In this paper, we present our group\nstructured latent-space multi-task learning model, which encourages group\nstructured tasks defined by prior information. We use an alternating\nminimization method to learn the model parameters. Experiments are conducted on\nboth synthetic and real-world datasets, showing competitive performance over\nsingle-task learning (where each group is trained separately) and other MTL\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 05:38:58 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Niu", "Xiangyu", ""], ["Sun", "Yifan", ""], ["Sun", "Jinyuan", ""]]}, {"id": "2011.11922", "submitter": "Jiachen Sun", "authors": "Jiachen Sun, Karl Koenig, Yulong Cao, Qi Alfred Chen, Z. Morley Mao", "title": "On Adversarial Robustness of 3D Point Cloud Classification under\n  Adaptive Attacks", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D point clouds play pivotal roles in various safety-critical applications,\nsuch as autonomous driving, which desires the underlying deep neural networks\nto be robust to adversarial perturbations. Though a few defenses against\nadversarial point cloud classification have been proposed, it remains unknown\nwhether they are truly robust to adaptive attacks. To this end, we perform the\nfirst security analysis of state-of-the-art defenses and design adaptive\nevaluations on them. Our 100% adaptive attack success rates show that current\ncountermeasures are still vulnerable. Since adversarial training (AT) is\nbelieved as the most robust defense, we present the first in-depth study\nshowing how AT behaves in point cloud classification and identify that the\nrequired symmetric function (pooling operation) is paramount to the 3D model's\nrobustness under AT. Through our systematic analysis, we find that the\ndefault-used fixed pooling (e.g., MAX pooling) generally weakens AT's\neffectiveness in point cloud classification. Interestingly, we further discover\nthat sorting-based parametric pooling can significantly improve the models'\nrobustness. Based on above insights, we propose DeepSym, a deep symmetric\npooling operation, to architecturally advance the robustness to 47.0% under AT\nwithout sacrificing nominal accuracy, outperforming the original design and a\nstrong baseline by 28.5% ($\\sim 2.6 \\times$) and 6.5%, respectively, in\nPointNet.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 06:46:38 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 18:36:44 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Sun", "Jiachen", ""], ["Koenig", "Karl", ""], ["Cao", "Yulong", ""], ["Chen", "Qi Alfred", ""], ["Mao", "Z. Morley", ""]]}, {"id": "2011.11933", "submitter": "Xiupeng Shi Dr", "authors": "Xiupeng Shi, Yiik Diew Wong, Chen Chai, Michael Zhi-Feng Li, Tianyi\n  Chen, Zeng Zeng", "title": "Automatic Clustering for Unsupervised Risk Diagnosis of Vehicle Driving\n  for Smart Road", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early risk diagnosis and driving anomaly detection from vehicle stream are of\ngreat benefits in a range of advanced solutions towards Smart Road and crash\nprevention, although there are intrinsic challenges, especially lack of ground\ntruth, definition of multiple risk exposures. This study proposes a\ndomain-specific automatic clustering (termed Autocluster) to self-learn the\noptimal models for unsupervised risk assessment, which integrates key steps of\nrisk clustering into an auto-optimisable pipeline, including feature and\nalgorithm selection, hyperparameter auto-tuning. Firstly, based on surrogate\nconflict measures, indicator-guided feature extraction is conducted to\nconstruct temporal-spatial and kinematical risk features. Then we develop an\nelimination-based model reliance importance (EMRI) method to\nunsupervised-select the useful features. Secondly, we propose balanced\nSilhouette Index (bSI) to evaluate the internal quality of imbalanced\nclustering. A loss function is designed that considers the clustering\nperformance in terms of internal quality, inter-cluster variation, and model\nstability. Thirdly, based on Bayesian optimisation, the algorithm selection and\nhyperparameter auto-tuning are self-learned to generate the best clustering\npartitions. Various algorithms are comprehensively investigated. Herein, NGSIM\nvehicle trajectory data is used for test-bedding. Findings show that\nAutocluster is reliable and promising to diagnose multiple distinct risk\nexposures inherent to generalised driving behaviour. Besides, we also delve\ninto risk clustering, such as, algorithms heterogeneity, Silhouette analysis,\nhierarchical clustering flows, etc. Meanwhile, the Autocluster is also a method\nfor unsupervised multi-risk data labelling and indicator threshold calibration.\nFurthermore, Autocluster is useful to tackle the challenges in imbalanced\nclustering without ground truth or priori knowledge\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 07:15:03 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Shi", "Xiupeng", ""], ["Wong", "Yiik Diew", ""], ["Chai", "Chen", ""], ["Li", "Michael Zhi-Feng", ""], ["Chen", "Tianyi", ""], ["Zeng", "Zeng", ""]]}, {"id": "2011.11938", "submitter": "Junyou He", "authors": "Junyou He, Guibao Mei, Feng Xing, Xiaorui Yang, Yongjun Bao, Weipeng\n  Yan", "title": "DADNN: Multi-Scene CTR Prediction via Domain-Aware Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click through rate(CTR) prediction is a core task in advertising systems. The\nbooming e-commerce business in our company, results in a growing number of\nscenes. Most of them are so-called long-tail scenes, which means that the\ntraffic of a single scene is limited, but the overall traffic is considerable.\nTypical studies mainly focus on serving a single scene with a well designed\nmodel. However, this method brings excessive resource consumption both on\noffline training and online serving. Besides, simply training a single model\nwith data from multiple scenes ignores the characteristics of their own. To\naddress these challenges, we propose a novel but practical model named\nDomain-Aware Deep Neural Network(DADNN) by serving multiple scenes with only\none model. Specifically, shared bottom block among all scenes is applied to\nlearn a common representation, while domain-specific heads maintain the\ncharacteristics of every scene. Besides, knowledge transfer is introduced to\nenhance the opportunity of knowledge sharing among different scenes. In this\npaper, we study two instances of DADNN where its shared bottom block is\nmultilayer perceptron(MLP) and Multi-gate Mixture-of-Experts(MMoE)\nrespectively, for which we denote as DADNN-MLP and DADNN-MMoE.Comprehensive\noffline experiments on a real production dataset from our company show that\nDADNN outperforms several state-of-the-art methods for multi-scene CTR\nprediction. Extensive online A/B tests reveal that DADNN-MLP contributes up to\n6.7% CTR and 3.0% CPM(Cost Per Mille) promotion compared with a well-engineered\nDCN model. Furthermore, DADNN-MMoE outperforms DADNN-MLP with a relative\nimprovement of 2.2% and 2.7% on CTR and CPM respectively. More importantly,\nDADNN utilizes a single model for multiple scenes which saves a lot of offline\ntraining and online serving resources.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 07:30:52 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["He", "Junyou", ""], ["Mei", "Guibao", ""], ["Xing", "Feng", ""], ["Yang", "Xiaorui", ""], ["Bao", "Yongjun", ""], ["Yan", "Weipeng", ""]]}, {"id": "2011.11944", "submitter": "Yulai Zhang", "authors": "Yaru Li, Yulai Zhang", "title": "Hyper-parameter estimation method with particle swarm optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle swarm optimization (PSO) method cannot be directly used in the\nproblem of hyper-parameter estimation since the mathematical formulation of the\nmapping from hyper-parameters to loss function or generalization accuracy is\nunclear. Bayesian optimization (BO) framework is capable of converting the\noptimization of the hyper-parameters into the optimization of an acquisition\nfunction. The acquisition function is non-convex and multi-peak. So the problem\ncan be better solved by the PSO. The proposed method in this paper uses the\nparticle swarm method to optimize the acquisition function in the BO framework\nto get better hyper-parameters. The performances of proposed method in both of\nthe classification and regression models are evaluated and demonstrated. The\nresults on several benchmark problems are improved.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 07:51:51 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 04:16:34 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Li", "Yaru", ""], ["Zhang", "Yulai", ""]]}, {"id": "2011.11946", "submitter": "Martin Humenberger", "authors": "No\\'e Pion, Martin Humenberger, Gabriela Csurka, Yohann Cabon, Torsten\n  Sattler", "title": "Benchmarking Image Retrieval for Visual Localization", "comments": "International Conference on 3D Vision, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual localization, i.e., camera pose estimation in a known scene, is a core\ncomponent of technologies such as autonomous driving and augmented reality.\nState-of-the-art localization approaches often rely on image retrieval\ntechniques for one of two tasks: (1) provide an approximate pose estimate or\n(2) determine which parts of the scene are potentially visible in a given query\nimage. It is common practice to use state-of-the-art image retrieval algorithms\nfor these tasks. These algorithms are often trained for the goal of retrieving\nthe same landmark under a large range of viewpoint changes. However, robustness\nto viewpoint changes is not necessarily desirable in the context of visual\nlocalization. This paper focuses on understanding the role of image retrieval\nfor multiple visual localization tasks. We introduce a benchmark setup and\ncompare state-of-the-art retrieval representations on multiple datasets. We\nshow that retrieval performance on classical landmark retrieval/recognition\ntasks correlates only for some but not all tasks to localization performance.\nThis indicates a need for retrieval approaches specifically designed for\nlocalization tasks. Our benchmark and evaluation protocols are available at\nhttps://github.com/naver/kapture-localization.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 07:59:52 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 07:19:03 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Pion", "No\u00e9", ""], ["Humenberger", "Martin", ""], ["Csurka", "Gabriela", ""], ["Cabon", "Yohann", ""], ["Sattler", "Torsten", ""]]}, {"id": "2011.11950", "submitter": "Nikitha Rao", "authors": "Nikitha Rao, Chetan Bansal and Joe Guan", "title": "Search4Code: Code Search Intent Classification Using Weak Supervision", "comments": "Dataset for this paper is available here:\n  https://github.com/microsoft/Search4Code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers use search for various tasks such as finding code, documentation,\ndebugging information, etc. In particular, web search is heavily used by\ndevelopers for finding code examples and snippets during the coding process.\nRecently, natural language based code search has been an active area of\nresearch. However, the lack of real-world large-scale datasets is a significant\nbottleneck. In this work, we propose a weak supervision based approach for\ndetecting code search intent in search queries for C# and Java programming\nlanguages. We evaluate the approach against several baselines on a real-world\ndataset comprised of over 1 million queries mined from Bing web search engine\nand show that the CNN based model can achieve an accuracy of 77% and 76% for C#\nand Java respectively. Furthermore, we are also releasing Search4Code, the\nfirst large-scale real-world dataset of code search queries mined from Bing web\nsearch engine. We hope that the dataset will aid future research on code\nsearch.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 08:06:53 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 01:54:17 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 15:01:41 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Rao", "Nikitha", ""], ["Bansal", "Chetan", ""], ["Guan", "Joe", ""]]}, {"id": "2011.11959", "submitter": "Chih-Hong Cheng", "authors": "Chih-Hong Cheng", "title": "Provably-Robust Runtime Monitoring of Neuron Activation Patterns", "comments": "Work-in-progress report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  For deep neural networks (DNNs) to be used in safety-critical autonomous\ndriving tasks, it is desirable to monitor in operation time if the input for\nthe DNN is similar to the data used in DNN training. While recent results in\nmonitoring DNN activation patterns provide a sound guarantee due to building an\nabstraction out of the training data set, reducing false positives due to\nslight input perturbation has been an issue towards successfully adapting the\ntechniques. We address this challenge by integrating formal symbolic reasoning\ninside the monitor construction process. The algorithm performs a sound\nworst-case estimate of neuron values with inputs (or features) subject to\nperturbation, before the abstraction function is applied to build the monitor.\nThe provable robustness is further generalized to cases where monitoring a\nsingle neuron can use more than one bit, implying that one can record\nactivation patterns with a fine-grained decision on the neuron value interval.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 08:37:18 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Cheng", "Chih-Hong", ""]]}, {"id": "2011.11966", "submitter": "Nicolas Gillis", "authors": "Christophe Kervazo, Nicolas Gillis, Nicolas Dobigeon", "title": "Provably robust blind source separation of linear-quadratic\n  near-separable mixtures", "comments": "23 pages + 24 pages of Appendix containing the proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the problem of blind source separation (BSS) by\ndeparting from the usual linear model and focusing on the linear-quadratic (LQ)\nmodel. We propose two provably robust and computationally tractable algorithms\nto tackle this problem under separability assumptions which require the sources\nto appear as samples in the data set. The first algorithm generalizes the\nsuccessive nonnegative projection algorithm (SNPA), designed for linear BSS,\nand is referred to as SNPALQ. By explicitly modeling the product terms inherent\nto the LQ model along the iterations of the SNPA scheme, the nonlinear\ncontributions of the mixing are mitigated, thus improving the separation\nquality. SNPALQ is shown to be able to recover the ground truth factors that\ngenerated the data, even in the presence of noise. The second algorithm is a\nbrute-force (BF) algorithm, which is used as a post-processing step for SNPALQ.\nIt enables to discard the spurious (mixed) samples extracted by SNPALQ, thus\nbroadening its applicability. The BF is in turn shown to be robust to noise\nunder easier-to-check and milder conditions than SNPALQ. We show that SNPALQ\nwith and without the BF postprocessing is relevant in realistic numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 08:53:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kervazo", "Christophe", ""], ["Gillis", "Nicolas", ""], ["Dobigeon", "Nicolas", ""]]}, {"id": "2011.11981", "submitter": "Dongxiao Zhang", "authors": "Hao Xu, Dongxiao Zhang, Nanzhe Wang", "title": "Deep-learning based discovery of partial differential equations in\n  integral form from sparse and noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Data-driven discovery of partial differential equations (PDEs) has attracted\nincreasing attention in recent years. Although significant progress has been\nmade, certain unresolved issues remain. For example, for PDEs with high-order\nderivatives, the performance of existing methods is unsatisfactory, especially\nwhen the data are sparse and noisy. It is also difficult to discover\nheterogeneous parametric PDEs where heterogeneous parameters are embedded in\nthe partial differential operators. In this work, a new framework combining\ndeep-learning and integral form is proposed to handle the above-mentioned\nproblems simultaneously, and improve the accuracy and stability of PDE\ndiscovery. In the framework, a deep neural network is firstly trained with\nobservation data to generate meta-data and calculate derivatives. Then, a\nunified integral form is defined, and the genetic algorithm is employed to\ndiscover the best structure. Finally, the value of parameters is calculated,\nand whether the parameters are constants or variables is identified. Numerical\nexperiments proved that our proposed algorithm is more robust to noise and more\naccurate compared with existing methods due to the utilization of integral\nform. Our proposed algorithm is also able to discover PDEs with high-order\nderivatives or heterogeneous parameters accurately with sparse and noisy data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 09:18:39 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""], ["Wang", "Nanzhe", ""]]}, {"id": "2011.11983", "submitter": "Fuping Chu", "authors": "Xiang Yu, Fuping Chu, Junqi Wu, Bo Huang", "title": "WeiPS: a symmetric fusion model framework for large-scale online\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recommendation system is an important commercial application of machine\nlearning, where billions of feed views in the information flow every day. In\nreality, the interaction between user and item usually makes user's interest\nchanging over time, thus many companies (e.g. ByteDance, Baidu, Alibaba, and\nWeibo) employ online learning as an effective way to quickly capture user\ninterests. However, hundreds of billions of model parameters present online\nlearning with challenges for real-time model deployment. Besides, model\nstability is another key point for online learning. To this end, we design and\nimplement a symmetric fusion online learning system framework called WeiPS,\nwhich integrates model training and model inference. Specifically, WeiPS\ncarries out second level model deployment by streaming update mechanism to\nsatisfy the consistency requirement. Moreover, it uses multi-level fault\ntolerance and real-time domino degradation to achieve high availability\nrequirement.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 09:25:39 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Yu", "Xiang", ""], ["Chu", "Fuping", ""], ["Wu", "Junqi", ""], ["Huang", "Bo", ""]]}, {"id": "2011.11985", "submitter": "Mingrui Liu", "authors": "Mingrui Liu, Wei Zhang, Francesco Orabona, Tianbao Yang", "title": "Adam$^+$: A Stochastic Method with Adaptive Variance Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adam is a widely used stochastic optimization method for deep learning\napplications. While practitioners prefer Adam because it requires less\nparameter tuning, its use is problematic from a theoretical point of view since\nit may not converge. Variants of Adam have been proposed with provable\nconvergence guarantee, but they tend not be competitive with Adam on the\npractical performance. In this paper, we propose a new method named Adam$^+$\n(pronounced as Adam-plus). Adam$^+$ retains some of the key components of Adam\nbut it also has several noticeable differences: (i) it does not maintain the\nmoving average of second moment estimate but instead computes the moving\naverage of first moment estimate at extrapolated points; (ii) its adaptive step\nsize is formed not by dividing the square root of second moment estimate but\ninstead by dividing the root of the norm of first moment estimate. As a result,\nAdam$^+$ requires few parameter tuning, as Adam, but it enjoys a provable\nconvergence guarantee. Our analysis further shows that Adam$^+$ enjoys adaptive\nvariance reduction, i.e., the variance of the stochastic gradient estimator\nreduces as the algorithm converges, hence enjoying an adaptive convergence. We\nalso propose a more general variant of Adam$^+$ with different adaptive step\nsizes and establish their fast convergence rate. Our empirical studies on\nvarious deep learning tasks, including image classification, language modeling,\nand automatic speech recognition, demonstrate that Adam$^+$ significantly\noutperforms Adam and achieves comparable performance with best-tuned SGD and\nmomentum SGD.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 09:28:53 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Liu", "Mingrui", ""], ["Zhang", "Wei", ""], ["Orabona", "Francesco", ""], ["Yang", "Tianbao", ""]]}, {"id": "2011.11991", "submitter": "Shirou Maruyama", "authors": "Daisuke Nishiyama, Mario Ynocente Castro, Shirou Maruyama, Shinya\n  Shiroshita, Karim Hamzaoui, Yi Ouyang, Guy Rosman, Jonathan DeCastro,\n  Kuan-Hui Lee, Adrien Gaidon", "title": "Discovering Avoidable Planner Failures of Autonomous Vehicles using\n  Counterfactual Analysis in Behaviorally Diverse Simulation", "comments": "8 pages, 8 figures", "journal-ref": "The 23rd IEEE International Conference on Intelligent\n  Transportation Systems (ITSC2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Vehicles require exhaustive testing in simulation to detect as many\nsafety-critical failures as possible before deployment on public roads. In this\nwork, we focus on the core decision-making component of autonomous robots:\ntheir planning algorithm. We introduce a planner testing framework that\nleverages recent progress in simulating behaviorally diverse traffic\nparticipants. Using large scale search, we generate, detect, and characterize\ndynamic scenarios leading to collisions. In particular, we propose methods to\ndistinguish between unavoidable and avoidable accidents, focusing especially on\nautomatically finding planner-specific defects that must be corrected before\ndeployment. Through experiments in complex multi-agent intersection scenarios,\nwe show that our method can indeed find a wide range of critical planner\nfailures.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 09:44:23 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Nishiyama", "Daisuke", ""], ["Castro", "Mario Ynocente", ""], ["Maruyama", "Shirou", ""], ["Shiroshita", "Shinya", ""], ["Hamzaoui", "Karim", ""], ["Ouyang", "Yi", ""], ["Rosman", "Guy", ""], ["DeCastro", "Jonathan", ""], ["Lee", "Kuan-Hui", ""], ["Gaidon", "Adrien", ""]]}, {"id": "2011.12010", "submitter": "Carolin Lawrence", "authors": "Cheng Wang and Carolin Lawrence and Mathias Niepert", "title": "Uncertainty Estimation and Calibration with Finite-State Probabilistic\n  RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification is crucial for building reliable and trustable\nmachine learning systems. We propose to estimate uncertainty in recurrent\nneural networks (RNNs) via stochastic discrete state transitions over recurrent\ntimesteps. The uncertainty of the model can be quantified by running a\nprediction several times, each time sampling from the recurrent state\ntransition distribution, leading to potentially different results if the model\nis uncertain. Alongside uncertainty quantification, our proposed method offers\nseveral advantages in different settings. The proposed method can (1) learn\ndeterministic and probabilistic automata from data, (2) learn well-calibrated\nmodels on real-world classification tasks, (3) improve the performance of\nout-of-distribution detection, and (4) control the exploration-exploitation\ntrade-off in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 10:35:28 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wang", "Cheng", ""], ["Lawrence", "Carolin", ""], ["Niepert", "Mathias", ""]]}, {"id": "2011.12022", "submitter": "Junzhe Zhu", "authors": "Junzhe Zhu, Raymond Yeh, Mark Hasegawa-Johnson", "title": "Multi-Decoder DPRNN: High Accuracy Source Counting and Separation", "comments": "Project Page: https://junzhejosephzhu.github.io/Multi-Decoder-DPRNN/\n  Submitted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end trainable approach to single-channel speech\nseparation with unknown number of speakers. Our approach extends the MulCat\nsource separation backbone with additional output heads: a count-head to infer\nthe number of speakers, and decoder-heads for reconstructing the original\nsignals. Beyond the model, we also propose a metric on how to evaluate source\nseparation with variable number of speakers. Specifically, we cleared up the\nissue on how to evaluate the quality when the ground-truth hasmore or less\nspeakers than the ones predicted by the model. We evaluate our approach on the\nWSJ0-mix datasets, with mixtures up to five speakers. We demonstrate that our\napproach outperforms state-of-the-art in counting the number of speakers and\nremains competitive in quality of reconstructed signals.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:00:21 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 16:56:04 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhu", "Junzhe", ""], ["Yeh", "Raymond", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "2011.12026", "submitter": "Ivan Skorokhodov", "authors": "Ivan Skorokhodov, Savva Ignatyev, Mohamed Elhoseiny", "title": "Adversarial Generation of Continuous Images", "comments": "19 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In most existing learning systems, images are typically viewed as 2D pixel\narrays. However, in another paradigm gaining popularity, a 2D image is\nrepresented as an implicit neural representation (INR) - an MLP that predicts\nan RGB pixel value given its (x,y) coordinate. In this paper, we propose two\nnovel architectural techniques for building INR-based image decoders:\nfactorized multiplicative modulation and multi-scale INRs, and use them to\nbuild a state-of-the-art continuous image GAN. Previous attempts to adapt INRs\nfor image generation were limited to MNIST-like datasets and do not scale to\ncomplex real-world data. Our proposed INR-GAN architecture improves the\nperformance of continuous image generators by several times, greatly reducing\nthe gap between continuous image GANs and pixel-based ones. Apart from that, we\nexplore several exciting properties of the INR-based decoders, like\nout-of-the-box superresolution, meaningful image-space interpolation,\naccelerated inference of low-resolution images, an ability to extrapolate\noutside of image boundaries, and strong geometric prior. The project page is\nlocated at https://universome.github.io/inr-gan.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:06:40 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 09:00:05 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Skorokhodov", "Ivan", ""], ["Ignatyev", "Savva", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "2011.12043", "submitter": "Lukas Mauch", "authors": "Lukas Mauch, Stephen Tiedemann, Javier Alonso Garcia, Bac Nguyen Cong,\n  Kazuki Yoshiyama, Fabien Cardinaux, Thomas Kemp", "title": "Efficient Sampling for Predictor-Based Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, predictor-based algorithms emerged as a promising approach for\nneural architecture search (NAS). For NAS, we typically have to calculate the\nvalidation accuracy of a large number of Deep Neural Networks (DNNs), what is\ncomputationally complex. Predictor-based NAS algorithms address this problem.\nThey train a proxy model that can infer the validation accuracy of DNNs\ndirectly from their network structure. During optimization, the proxy can be\nused to narrow down the number of architectures for which the true validation\naccuracy must be computed, what makes predictor-based algorithms sample\nefficient. Usually, we compute the proxy for all DNNs in the network search\nspace and pick those that maximize the proxy as candidates for optimization.\nHowever, that is intractable in practice, because the search spaces are often\nvery large and contain billions of network architectures. The contributions of\nthis paper are threefold: 1) We define a sample efficiency gain to compare\ndifferent predictor-based NAS algorithms. 2) We conduct experiments on the\nNASBench-101 dataset and show that the sample efficiency of predictor-based\nalgorithms decreases dramatically if the proxy is only computed for a subset of\nthe search space. 3) We show that if we choose the subset of the search space\non which the proxy is evaluated in a smart way, the sample efficiency of the\noriginal predictor-based algorithm that has access to the full search space can\nbe regained. This is an important step to make predictor-based NAS algorithms\nuseful, in practice.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:36:36 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mauch", "Lukas", ""], ["Tiedemann", "Stephen", ""], ["Garcia", "Javier Alonso", ""], ["Cong", "Bac Nguyen", ""], ["Yoshiyama", "Kazuki", ""], ["Cardinaux", "Fabien", ""], ["Kemp", "Thomas", ""]]}, {"id": "2011.12046", "submitter": "Yuhan Wang", "authors": "Yuhan Wang, Zijian Lei, Liang Lan", "title": "Effective and Sparse Count-Sketch via k-means clustering", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Count-sketch is a popular matrix sketching algorithm that can produce a\nsketch of an input data matrix X in O(nnz(X))time where nnz(X) denotes the\nnumber of non-zero entries in X. The sketched matrix will be much smaller than\nX while preserving most of its properties. Therefore, count-sketch is widely\nused for addressing high-dimensionality challenge in machine learning. However,\nthere are two main limitations of count-sketch: (1) The sketching matrix used\ncount-sketch is generated randomly which does not consider any intrinsic data\nproperties of X. This data-oblivious matrix sketching method could produce a\nbad sketched matrix which will result in low accuracy for subsequent machine\nlearning tasks (e.g.classification); (2) For highly sparse input data,\ncount-sketch could produce a dense sketched data matrix. This dense sketch\nmatrix could make the subsequent machine learning tasks more computationally\nexpensive than on the original sparse data X. To address these two limitations,\nwe first show an interesting connection between count-sketch and k-means\nclustering by analyzing the reconstruction error of the count-sketch method.\nBased on our analysis, we propose to reduce the reconstruction error of\ncount-sketch by using k-means clustering algorithm to obtain the\nlow-dimensional sketched matrix. In addition, we propose to solve k-mean\nclustering using gradient descent with -L1 ball projection to produce a sparse\nsketched matrix. Our experimental results based on six real-life classification\ndatasets have demonstrated that our proposed method achieves higher accuracy\nthan the original count-sketch and other popular matrix sketching algorithms.\nOur results also demonstrate that our method produces a sparser sketched data\nmatrix than other methods and therefore the prediction cost of our method will\nbe smaller than other matrix sketching methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:44:02 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 06:20:43 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wang", "Yuhan", ""], ["Lei", "Zijian", ""], ["Lan", "Liang", ""]]}, {"id": "2011.12087", "submitter": "Hayk Asatryan", "authors": "Hayk Asatryan, Hanno Gottschalk, Marieke Lippert and Matthias Rottmann", "title": "A Convenient Infinite Dimensional Framework for Generative Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, generative adversarial networks (GANs) have demonstrated\nimpressive experimental results while there are only a few works that foster\nstatistical learning theory for GANs. In this work, we propose an infinite\ndimensional theoretical framework for generative adversarial learning. Assuming\nthe class of uniformly bounded $k$-times $\\alpha$-H\\\"older differentiable and\nuniformly positive densities, we show that the Rosenblatt transformation\ninduces an optimal generator, which is realizable in the hypothesis space of\n$\\alpha$-H\\\"older differentiable generators. With a consistent definition of\nthe hypothesis space of discriminators, we further show that in our framework\nthe Jensen-Shannon divergence between the distribution induced by the generator\nfrom the adversarial learning procedure and the data generating distribution\nconverges to zero. Under sufficiently strict regularity assumptions on the\ndensity of the data generating process, we also provide rates of convergence\nbased on concentration and chaining.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 13:45:17 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 17:17:46 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Asatryan", "Hayk", ""], ["Gottschalk", "Hanno", ""], ["Lippert", "Marieke", ""], ["Rottmann", "Matthias", ""]]}, {"id": "2011.12090", "submitter": "Alex Glushkovsky", "authors": "Alex Glushkovsky", "title": "AI Discovering a Coordinate System of Chemical Elements: Dual\n  Representation by Variational Autoencoders", "comments": "18 pages, 15 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The periodic table is a fundamental representation of chemical elements that\nplays essential theoretical and practical roles. The research article discusses\nthe experiences of unsupervised training of neural networks to represent\nelements on the 2D latent space based on their electron configurations while\nforcing disentanglement. To emphasize chemical properties of the elements, the\noriginal data of electron configurations has been realigned towards the\noutermost valence orbitals. Recognizing seven shells and four subshells, the\ninput data has been arranged as (7x4) images. Latent space representation has\nbeen performed using a convolutional beta variational autoencoder (beta-VAE).\nDespite discrete and sparse input data, the beta-VAE disentangles elements of\ndifferent periods, blocks, groups, and types, while retaining the order along\natomic numbers. In addition, it isolates outliers on the latent space that\nturned out to be known cases of Madelung's rule violations for lanthanide and\nactinide elements. Considering the generative capabilities of beta-VAE and\ndiscrete input data, the supervised machine learning has been set to find out\nif there are insightful patterns distinguishing electron configurations between\nreal elements and decoded artificial ones. Also, the article addresses the\ncapability of dual representation by autoencoders. Conventionally, autoencoders\nrepresent observations of input data on the latent space. However, by\ntransposing and duplicating original input data, it is possible to represent\nvariables on the latent space as well. The latest can lead to the discovery of\nmeaningful patterns among input variables. Applying that unsupervised learning\nfor transposed data of electron configurations, the order of input variables\nthat has been arranged by the encoder on the latent space has turned out to\nexactly match the sequence of Madelung's rule.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 13:54:23 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 00:24:44 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 19:45:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Glushkovsky", "Alex", ""]]}, {"id": "2011.12091", "submitter": "Xirong Li", "authors": "Xirong Li and Fangming Zhou and Chaoxi Xu and Jiaqi Ji and Gang Yang", "title": "SEA: Sentence Encoder Assembly for Video Retrieval by Textual Queries", "comments": "accepted for publication as a REGULAR paper in the IEEE Transactions\n  on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Retrieving unlabeled videos by textual queries, known as Ad-hoc Video Search\n(AVS), is a core theme in multimedia data management and retrieval. The success\nof AVS counts on cross-modal representation learning that encodes both query\nsentences and videos into common spaces for semantic similarity computation.\nInspired by the initial success of previously few works in combining multiple\nsentence encoders, this paper takes a step forward by developing a new and\ngeneral method for effectively exploiting diverse sentence encoders. The\nnovelty of the proposed method, which we term Sentence Encoder Assembly (SEA),\nis two-fold. First, different from prior art that use only a single common\nspace, SEA supports text-video matching in multiple encoder-specific common\nspaces. Such a property prevents the matching from being dominated by a\nspecific encoder that produces an encoding vector much longer than other\nencoders. Second, in order to explore complementarities among the individual\ncommon spaces, we propose multi-space multi-loss learning. As extensive\nexperiments on four benchmarks (MSR-VTT, TRECVID AVS 2016-2019, TGIF and MSVD)\nshow, SEA surpasses the state-of-the-art. In addition, SEA is extremely ease to\nimplement. All this makes SEA an appealing solution for AVS and promising for\ncontinuously advancing the task by harvesting new sentence encoders.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 13:54:28 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Li", "Xirong", ""], ["Zhou", "Fangming", ""], ["Xu", "Chaoxi", ""], ["Ji", "Jiaqi", ""], ["Yang", "Gang", ""]]}, {"id": "2011.12100", "submitter": "Michael Niemeyer", "authors": "Michael Niemeyer, Andreas Geiger", "title": "GIRAFFE: Representing Scenes as Compositional Generative Neural Feature\n  Fields", "comments": "Accepted to CVPR 2021 (oral). Project page:\n  http://bit.ly/giraffe-project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models allow for photorealistic image synthesis at high\nresolutions. But for many applications, this is not enough: content creation\nalso needs to be controllable. While several recent works investigate how to\ndisentangle underlying factors of variation in the data, most of them operate\nin 2D and hence ignore that our world is three-dimensional. Further, only few\nworks consider the compositional nature of scenes. Our key hypothesis is that\nincorporating a compositional 3D scene representation into the generative model\nleads to more controllable image synthesis. Representing scenes as\ncompositional generative neural feature fields allows us to disentangle one or\nmultiple objects from the background as well as individual objects' shapes and\nappearances while learning from unstructured and unposed image collections\nwithout any additional supervision. Combining this scene representation with a\nneural rendering pipeline yields a fast and realistic image synthesis model. As\nevidenced by our experiments, our model is able to disentangle individual\nobjects and allows for translating and rotating them in the scene as well as\nchanging the camera pose.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 14:14:15 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 14:46:36 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Niemeyer", "Michael", ""], ["Geiger", "Andreas", ""]]}, {"id": "2011.12107", "submitter": "Neeraj Wagh", "authors": "Neeraj Wagh, Yogatheesan Varatharajah", "title": "EEG-GCNN: Augmenting Electroencephalogram-based Neurological Disease\n  Diagnosis using a Domain-guided Graph Convolutional Neural Network", "comments": "Accepted for publication (with an oral spotlight) at ML4H Workshop,\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents a novel graph convolutional neural network (GCNN)-based\napproach for improving the diagnosis of neurological diseases using\nscalp-electroencephalograms (EEGs). Although EEG is one of the main tests used\nfor neurological-disease diagnosis, the sensitivity of EEG-based expert visual\ndiagnosis remains at $\\sim$50\\%. This indicates a clear need for advanced\nmethodology to reduce the false negative rate in detecting abnormal scalp-EEGs.\nIn that context, we focus on the problem of distinguishing the abnormal scalp\nEEGs of patients with neurological diseases, which were originally classified\nas 'normal' by experts, from the scalp EEGs of healthy individuals. The\ncontributions of this paper are three-fold: 1) we present EEG-GCNN, a novel\nGCNN model for EEG data that captures both the spatial and functional\nconnectivity between the scalp electrodes, 2) using EEG-GCNN, we perform the\nfirst large-scale evaluation of the aforementioned hypothesis, and 3) using two\nlarge scalp-EEG databases, we demonstrate that EEG-GCNN significantly\noutperforms the human baseline and classical machine learning (ML) baselines,\nwith an AUC of 0.90.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 20:25:28 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Wagh", "Neeraj", ""], ["Varatharajah", "Yogatheesan", ""]]}, {"id": "2011.12111", "submitter": "Vincent Talbo", "authors": "Vincent Talbo, Mehdi Haddab, Derek Aubert, Redha Moulla", "title": "Wavelet-based clustering for time-series trend detection", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a method performing clustering of time-series on\nthe basis of their trend (increasing, stagnating/decreasing, and seasonal\nbehavior). The clustering is performed using $k$-means method on a selection of\ncoefficients obtained by discrete wavelet transform, reducing drastically the\ndimensionality. The method is applied on an use case for the clustering of a\n864 daily sales revenue time-series for 61 retail shops. The results are\npresented for different mother wavelets. The importance of each wavelet\ncoefficient and its level is discussed thanks to a principal component analysis\nalong with a reconstruction of the signal from the selected wavelet\ncoefficients.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 09:41:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Talbo", "Vincent", ""], ["Haddab", "Mehdi", ""], ["Aubert", "Derek", ""], ["Moulla", "Redha", ""]]}, {"id": "2011.12117", "submitter": "Aleksei Shpilman", "authors": "Nina Lukashina, Alisa Alenicheva, Elizaveta Vlasova, Artem Kondiukov,\n  Aigul Khakimova, Emil Magerramov, Nikita Churikov, Aleksei Shpilman", "title": "Lipophilicity Prediction with Multitask Learning and Molecular\n  Substructures Representation", "comments": "Accepted to Machine Learning for Molecules Workshop at NeurIPS'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Lipophilicity is one of the factors determining the permeability of the cell\nmembrane to a drug molecule. Hence, accurate lipophilicity prediction is an\nessential step in the development of new drugs. In this paper, we introduce a\nnovel approach to encoding additional graph information by extracting molecular\nsubstructures. By adding a set of generalized atomic features of these\nsubstructures to an established Direct Message Passing Neural Network (D-MPNN)\nwe were able to achieve a new state-of-the-art result at the task of prediction\nof two main lipophilicity coefficients, namely logP and logD descriptors. We\nfurther improve our approach by employing a multitask approach to predict logP\nand logD values simultaneously. Additionally, we present a study of the model\nperformance on symmetric and asymmetric molecules, that may yield insight for\nfurther research.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 14:27:39 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Lukashina", "Nina", ""], ["Alenicheva", "Alisa", ""], ["Vlasova", "Elizaveta", ""], ["Kondiukov", "Artem", ""], ["Khakimova", "Aigul", ""], ["Magerramov", "Emil", ""], ["Churikov", "Nikita", ""], ["Shpilman", "Aleksei", ""]]}, {"id": "2011.12121", "submitter": "Dimitris Spathis", "authors": "Dimitris Spathis, Ignacio Perez-Pozuelo, Soren Brage, Nicholas J.\n  Wareham and Cecilia Mascolo", "title": "Self-supervised transfer learning of physiological representations from\n  free-living wearable data", "comments": "9 pages, 3 figures (long version of extended abstract\n  arXiv:2011.04601)", "journal-ref": null, "doi": "10.1145/3450439.3451863", "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices such as smartwatches are becoming increasingly popular tools\nfor objectively monitoring physical activity in free-living conditions. To\ndate, research has primarily focused on the purely supervised task of human\nactivity recognition, demonstrating limited success in inferring high-level\nhealth outcomes from low-level signals. Here, we present a novel\nself-supervised representation learning method using activity and heart rate\n(HR) signals without semantic labels. With a deep neural network, we set HR\nresponses as the supervisory signal for the activity data, leveraging their\nunderlying physiological relationship. In addition, we propose a custom\nquantile loss function that accounts for the long-tailed HR distribution\npresent in the general population.\n  We evaluate our model in the largest free-living combined-sensing dataset\n(comprising >280k hours of wrist accelerometer & wearable ECG data). Our\ncontributions are two-fold: i) the pre-training task creates a model that can\naccurately forecast HR based only on cheap activity sensors, and ii) we\nleverage the information captured through this task by proposing a simple\nmethod to aggregate the learnt latent representations (embeddings) from the\nwindow-level to user-level. Notably, we show that the embeddings can generalize\nin various downstream tasks through transfer learning with linear classifiers,\ncapturing physiologically meaningful, personalized information. For instance,\nthey can be used to predict variables associated with individuals' health,\nfitness and demographic characteristics, outperforming unsupervised\nautoencoders and common bio-markers. Overall, we propose the first multimodal\nself-supervised method for behavioral and physiological data with implications\nfor large-scale health and lifestyle monitoring.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 23:21:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Spathis", "Dimitris", ""], ["Perez-Pozuelo", "Ignacio", ""], ["Brage", "Soren", ""], ["Wareham", "Nicholas J.", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2011.12130", "submitter": "Soorena Salari", "authors": "Soorena Salari and Nasser Sadati", "title": "A Generalizable Model for Fault Detection in Offshore Wind Turbines\n  Based on Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new deep learning-based model for fault detection in\noffshore wind turbines. To design a generalizable model for fault detection, we\nuse 5 sensors and a sliding window to exploit the inherent temporal information\ncontained in the raw time-series data obtained from sensors. The proposed model\nuses the nonlinear relationships among multiple sensor variables and the\ntemporal dependency of each sensor on others that considerably increases the\nperformance of fault detection model. A 10-fold cross-validation is used to\nverify the generalization of the model and evaluate the classification metrics.\nTo evaluate the performance of the model, simulated data from a benchmark\nfloating offshore wind turbine (FOWT) with supervisory control and data\nacquisition (SCADA) are used. The results illustrate that the proposed model\nwould accurately disclose and classify more than 99% of the faults. Moreover,\nit is generalizable and can be used to detect faults for different types of\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 14:35:19 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 09:20:35 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Salari", "Soorena", ""], ["Sadati", "Nasser", ""]]}, {"id": "2011.12131", "submitter": "Enrique Mariano Lizarraga", "authors": "Enrique Lizarraga and Walter Herrera", "title": "A Reusable Framework Based on Reinforcement Learning to Design Antennas\n  for Curved Surfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The design and implementation of low-profile antennas has been analyzed in\npast decades from different perspectives while the purpose is to have a small\nsize in the device, and an adequate electromagnetic behavior. This work pursues\na methodology to identify small antennas and consequently presents some\nsimilarities. Meanwhile, curved surfaces are considered for a certain variety\nof antennas with reduced size. The so-called deep reinforcement learning\ntechnique is used as an assistance against morphological variations that are\nspecifically taken into account in this work. The objective is to identify\nantennas that can be efficiently mounted on the surface of metal tubes such as\nthose frequently present in public infrastructure (e.g. traffic lights and\nluminaries). The motivation is to reduce the visual impact and optimize the\nradiation pattern of the antenna. It is analyzed that if changes in variables\nsuch as the radius of curvature, or the electromagnetic properties of the\nmaterials appear, an automatic identification of the underlying characteristics\nof the problem (by means of machine learning techniques) can readjust the\ndesign efficiently. The results obtained in this work are analyzed based on\nvariables that are typically used to characterize antennas, such as their\nimpedance and radiation pattern.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 14:35:23 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Lizarraga", "Enrique", ""], ["Herrera", "Walter", ""]]}, {"id": "2011.12137", "submitter": "Luke Hicks", "authors": "Luke Hicks, Ariel Ruiz-Garcia, Vasile Palade, Ibrahim Almakky", "title": "Self-Supervised Transformers for Activity Classification using Ambient\n  Sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing care for ageing populations is an onerous task, and as life\nexpectancy estimates continue to rise, the number of people that require senior\ncare is growing rapidly. This paper proposes a methodology based on Transformer\nNeural Networks to classify the activities of a resident within an ambient\nsensor based environment. We also propose a methodology to pre-train\nTransformers in a self-supervised manner, as a hybrid autoencoder-classifier\nmodel instead of using contrastive loss. The social impact of the research is\nconsidered with wider benefits of the approach and next steps for identifying\ntransitions in human behaviour. In recent years there has been an increasing\ndrive for integrating sensor based technologies within care facilities for data\ncollection. This allows for employing machine learning for many aspects\nincluding activity recognition and anomaly detection. Due to the sensitivity of\nhealthcare environments, some methods of data collection used in current\nresearch are considered to be intrusive within the senior care industry,\nincluding cameras for image based activity recognition, and wearables for\nactivity tracking, but recent studies have shown that using these methods\ncommonly result in poor data quality due to the lack of resident interest in\nparticipating in data gathering. This has led to a focus on ambient sensors,\nsuch as binary PIR motion, connected domestic appliances, and electricity and\nwater metering. By having consistency in ambient data collection, the quality\nof data is considerably more reliable, presenting the opportunity to perform\nclassification with enhanced accuracy. Therefore, in this research we looked to\nfind an optimal way of using deep learning to classify human activity with\nambient sensor data.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 20:46:25 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Hicks", "Luke", ""], ["Ruiz-Garcia", "Ariel", ""], ["Palade", "Vasile", ""], ["Almakky", "Ibrahim", ""]]}, {"id": "2011.12138", "submitter": "Mohammad Reza Mohebbian", "authors": "Mohammad Reza Mohebbian, Seyed Shahim Vedaei, Khan A. Wahid, Anh Dinh,\n  Hamid Reza Marateb, Kouhyar Tavakolian", "title": "Fetal ECG Extraction from Maternal ECG using Attention-based CycleGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-invasive fetal electrocardiogram (FECG) is used to monitor the electrical\npulse of the fetal heart. Decomposing the FECG signal from maternal ECG (MECG)\nis a blind source separation problem, which is hard due to the low amplitude of\nFECG, the overlap of R waves, and the potential exposure to noise from\ndifferent sources. Traditional decomposition techniques, such as adaptive\nfilters, require tuning, alignment, or pre-configuration, such as modeling the\nnoise or desired signal. to map MECG to FECG efficiently. The high correlation\nbetween maternal and fetal ECG parts decreases the performance of convolution\nlayers. Therefore, the masking region of interest using the attention mechanism\nis performed for improving signal generators' precision. The sine activation\nfunction is also used since it could retain more details when converting two\nsignal domains. Three available datasets from the Physionet, including A&D\nFECG, NI-FECG, and NI-FECG challenge, and one synthetic dataset using FECGSYN\ntoolbox, are used to evaluate the performance. The proposed method could map\nabdominal MECG to scalp FECG with an average 98% R-Square [CI 95%: 97%, 99%] as\nthe goodness of fit on A&D FECG dataset. Moreover, it achieved 99.7 % F1-score\n[CI 95%: 97.8-99.9], 99.6% F1-score [CI 95%: 98.2%, 99.9%] and 99.3% F1-score\n[CI 95%: 95.3%, 99.9%] for fetal QRS detection on, A&D FECG, NI-FECG and\nNI-FECG challenge datasets, respectively. These results are comparable to the\nstate-of-the-art; thus, the proposed algorithm has the potential of being used\nfor high-performance signal-to-signal conversion.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 19:49:21 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 22:02:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Mohebbian", "Mohammad Reza", ""], ["Vedaei", "Seyed Shahim", ""], ["Wahid", "Khan A.", ""], ["Dinh", "Anh", ""], ["Marateb", "Hamid Reza", ""], ["Tavakolian", "Kouhyar", ""]]}, {"id": "2011.12143", "submitter": "Lukun Zheng", "authors": "Yuhang Jiang, Lukun Zheng", "title": "Deep learning for video game genre classification", "comments": "21 pages, 6 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:2011.07658", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video game genre classification based on its cover and textual description\nwould be utterly beneficial to many modern identification, collocation, and\nretrieval systems. At the same time, it is also an extremely challenging task\ndue to the following reasons: First, there exists a wide variety of video game\ngenres, many of which are not concretely defined. Second, video game covers\nvary in many different ways such as colors, styles, textual information, etc,\neven for games of the same genre. Third, cover designs and textual descriptions\nmay vary due to many external factors such as country, culture, target reader\npopulations, etc. With the growing competitiveness in the video game industry,\nthe cover designers and typographers push the cover designs to its limit in the\nhope of attracting sales. The computer-based automatic video game genre\nclassification systems become a particularly exciting research topic in recent\nyears. In this paper, we propose a multi-modal deep learning framework to solve\nthis problem. The contribution of this paper is four-fold. First, we compiles a\nlarge dataset consisting of 50,000 video games from 21 genres made of cover\nimages, description text, and title text and the genre information. Second,\nimage-based and text-based, state-of-the-art models are evaluated thoroughly\nfor the task of genre classification for video games. Third, we developed an\nefficient and salable multi-modal framework based on both images and texts.\nFourth, a thorough analysis of the experimental results is given and future\nworks to improve the performance is suggested. The results show that the\nmulti-modal framework outperforms the current state-of-the-art image-based or\ntext-based models. Several challenges are outlined for this task. More efforts\nand resources are needed for this classification task in order to reach a\nsatisfactory level.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 22:31:43 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Jiang", "Yuhang", ""], ["Zheng", "Lukun", ""]]}, {"id": "2011.12149", "submitter": "Sheng Ao", "authors": "Sheng Ao, Qingyong Hu, Bo Yang, Andrew Markham, Yulan Guo", "title": "SpinNet: Learning a General Surface Descriptor for 3D Point Cloud\n  Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting robust and general 3D local features is key to downstream tasks\nsuch as point cloud registration and reconstruction. Existing learning-based\nlocal descriptors are either sensitive to rotation transformations, or rely on\nclassical handcrafted features which are neither general nor representative. In\nthis paper, we introduce a new, yet conceptually simple, neural architecture,\ntermed SpinNet, to extract local features which are rotationally invariant\nwhilst sufficiently informative to enable accurate registration. A Spatial\nPoint Transformer is first introduced to map the input local surface into a\ncarefully designed cylindrical space, enabling end-to-end optimization with\nSO(2) equivariant representation. A Neural Feature Extractor which leverages\nthe powerful point-based and 3D cylindrical convolutional neural layers is then\nutilized to derive a compact and representative descriptor for matching.\nExtensive experiments on both indoor and outdoor datasets demonstrate that\nSpinNet outperforms existing state-of-the-art techniques by a large margin.\nMore critically, it has the best generalization ability across unseen scenarios\nwith different sensor modalities. The code is available at\nhttps://github.com/QingyongHu/SpinNet.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:00:56 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 16:42:19 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ao", "Sheng", ""], ["Hu", "Qingyong", ""], ["Yang", "Bo", ""], ["Markham", "Andrew", ""], ["Guo", "Yulan", ""]]}, {"id": "2011.12151", "submitter": "Heejune Sheen", "authors": "Heejune Sheen, Xiaonan Zhu, Yao Xie", "title": "Tensor Kernel Recovery for Spatio-Temporal Hawkes Processes", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the general influence functions for spatio-temporal Hawkes\nprocesses using a tensor recovery approach by formulating the location\ndependent influence function that captures the influence of historical events\nas a tensor kernel. We assume a low-rank structure for the tensor kernel and\ncast the estimation problem as a convex optimization problem using the Fourier\ntransformed nuclear norm (TNN). We provide theoretical performance guarantees\nfor our approach and present an algorithm to solve the optimization problem.\nMoreover, we demonstrate the efficiency of our estimation with numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:05:26 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 12:46:55 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sheen", "Heejune", ""], ["Zhu", "Xiaonan", ""], ["Xie", "Yao", ""]]}, {"id": "2011.12160", "submitter": "Prathamesh Mayekar", "authors": "Prathamesh Mayekar, Ananda Theertha Suresh, and Himanshu Tyagi", "title": "Wyner-Ziv Estimators: Efficient Distributed Mean Estimation with Side\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Communication efficient distributed mean estimation is an important primitive\nthat arises in many distributed learning and optimization scenarios such as\nfederated learning. Without any probabilistic assumptions on the underlying\ndata, we study the problem of distributed mean estimation where the server has\naccess to side information. We propose \\emph{Wyner-Ziv estimators}, which are\ncommunication and computationally efficient and near-optimal when an upper\nbound for the distance between the side information and the data is known. As a\ncorollary, we also show that our algorithms provide efficient schemes for the\nclassic Wyner-Ziv problem in information theory. In a different direction, when\nthere is no knowledge assumed about the distance between side information and\nthe data, we present an alternative Wyner-Ziv estimator that uses correlated\nsampling. This latter setting offers {\\em universal recovery guarantees}, and\nperhaps will be of interest in practice when the number of users is large and\nkeeping track of the distances between the data and the side information may\nnot be possible.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:19:55 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mayekar", "Prathamesh", ""], ["Suresh", "Ananda Theertha", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "2011.12165", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Christopher Brix and Hermann Ney", "title": "Two-Way Neural Machine Translation: A Proof of Concept for Bidirectional\n  Translation Modeling using a Two-Dimensional Grid", "comments": "6 pages, accepted at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural translation models have proven to be effective in capturing sufficient\ninformation from a source sentence and generating a high-quality target\nsentence. However, it is not easy to get the best effect for bidirectional\ntranslation, i.e., both source-to-target and target-to-source translation using\na single model. If we exclude some pioneering attempts, such as multilingual\nsystems, all other bidirectional translation approaches are required to train\ntwo individual models. This paper proposes to build a single end-to-end\nbidirectional translation model using a two-dimensional grid, where the\nleft-to-right decoding generates source-to-target, and the bottom-to-up\ndecoding creates target-to-source output. Instead of training two models\nindependently, our approach encourages a single network to jointly learn to\ntranslate in both directions. Experiments on the WMT 2018\nGerman$\\leftrightarrow$English and Turkish$\\leftrightarrow$English translation\ntasks show that the proposed model is capable of generating a good translation\nquality and has sufficient potential to direct the research.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:42:32 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Bahar", "Parnia", ""], ["Brix", "Christopher", ""], ["Ney", "Hermann", ""]]}, {"id": "2011.12167", "submitter": "Parnia Bahar", "authors": "Parnia Bahar, Tobias Bieschke, Ralf Schl\\\"uter and Hermann Ney", "title": "Tight Integrated End-to-End Training for Cascaded Speech Translation", "comments": "8 pages, accepted at SLT2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A cascaded speech translation model relies on discrete and non-differentiable\ntranscription, which provides a supervision signal from the source side and\nhelps the transformation between source speech and target text. Such modeling\nsuffers from error propagation between ASR and MT models. Direct speech\ntranslation is an alternative method to avoid error propagation; however, its\nperformance is often behind the cascade system. To use an intermediate\nrepresentation and preserve the end-to-end trainability, previous studies have\nproposed using two-stage models by passing the hidden vectors of the recognizer\ninto the decoder of the MT model and ignoring the MT encoder. This work\nexplores the feasibility of collapsing the entire cascade components into a\nsingle end-to-end trainable model by optimizing all parameters of ASR and MT\nmodels jointly without ignoring any learned parameters. It is a tightly\nintegrated method that passes renormalized source word posterior distributions\nas a soft decision instead of one-hot vectors and enables backpropagation.\nTherefore, it provides both transcriptions and translations and achieves strong\nconsistency between them. Our experiments on four tasks with different data\nscenarios show that the model outperforms cascade models up to 1.8% in BLEU and\n2.0% in TER and is superior compared to direct models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:43:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Bahar", "Parnia", ""], ["Bieschke", "Tobias", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2011.12177", "submitter": "Anwesh Bhattacharya", "authors": "Bhattacharya, Anwesh, Saha, Snehanshu, Das, Mousumi", "title": "Detection of Double-Nuclei Galaxies in SDSS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.GA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is now well established that galaxy interactions and mergers play a\ncrucial role in the hierarchical growth of structure in our universe. Galaxy\nmergers can lead to the formation of elliptical galaxies and larger disk\ngalaxies, as well as drive galaxy evolution through star formation and nuclear\nactivity. During mergers, the nuclei of the individual galaxies come closer and\nfinally form a double nuclei galaxy. Although mergers are common, the detection\nof double-nuclei galaxies (DNGs) is rare and fairly serendipitous. Their\ndetection is very important as their properties can help us understand the\nformation of supermassive black hole (SMBH) binaries, dual active galactic\nnuclei (DAGN), and the associated feedback effects. There is thus a need for an\nautomatic/systematic survey of data for the discovery of double nuclei\ngalaxies. Using the Sloan digital sky survey (SDSS) as the target catalog, we\nhave introduced a novel algorithm \"Gothic\" (Graph-bOosTed iterated HIll\nClimbing) that detects whether a given image of a galaxy has characteristic\nfeatures of a DNG (ASCL entry 2707). We have tested the algorithm on a random\nsample of 100,000 galaxies from the Stripe 82 region in SDSS and obtained a\nmaximum detection rate of 4.2% with a careful choice of the input catalog.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:58:10 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Bhattacharya", "", ""], ["Anwesh", "", ""], ["Saha", "", ""], ["Snehanshu", "", ""], ["Das", "", ""], ["Mousumi", "", ""]]}, {"id": "2011.12193", "submitter": "Susie Xi Rao", "authors": "Susie Xi Rao, Shuai Zhang, Zhichao Han, Zitao Zhang, Wei Min, Zhiyao\n  Chen, Yinan Shan, Yang Zhao, Ce Zhang", "title": "xFraud: Explainable Fraud Transaction Detection on Heterogeneous Graphs", "comments": "15 pages, 3 figures, under review in WWW2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  At online retail platforms, it is crucial to actively detect risks of\nfraudulent transactions to improve our customer experience, minimize loss, and\nprevent unauthorized chargebacks. Traditional rule-based methods and simple\nfeature-based models are either inefficient or brittle and uninterpretable. The\ngraph structure that exists among the heterogeneous typed entities of the\ntransaction logs is informative and difficult to fake. To utilize the\nheterogeneous graph relationships and enrich the explainability, we present\nxFraud, an explainable Fraud transaction prediction system. xFraud is composed\nof a predictor which learns expressive representations for malicious\ntransaction detection from the heterogeneous transaction graph via a\nself-attentive heterogeneous graph neural network, and an explainer that\ngenerates meaningful and human understandable explanations from graphs to\nfacilitate further process in business unit. In our experiments with xFraud on\ntwo real transaction networks with up to ten millions transactions, we are able\nto achieve an area under a curve (AUC) score that outperforms baseline models\nand graph embedding methods. In addition, we show how the explainer could\nbenefit the understanding towards model predictions and enhance model\ntrustworthiness for real-world fraud transaction cases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 16:37:15 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Rao", "Susie Xi", ""], ["Zhang", "Shuai", ""], ["Han", "Zhichao", ""], ["Zhang", "Zitao", ""], ["Min", "Wei", ""], ["Chen", "Zhiyao", ""], ["Shan", "Yinan", ""], ["Zhao", "Yang", ""], ["Zhang", "Ce", ""]]}, {"id": "2011.12203", "submitter": "Aneesh Pappu", "authors": "Aneesh Pappu, Brooks Paige", "title": "Making Graph Neural Networks Worth It for Low-Data Molecular Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks have become very popular for machine learning on\nmolecules due to the expressive power of their learnt representations. However,\nmolecular machine learning is a classically low-data regime and it isn't clear\nthat graph neural networks can avoid overfitting in low-resource settings. In\ncontrast, fingerprint methods are the traditional standard for low-data\nenvironments due to their reduced number of parameters and manually engineered\nfeatures. In this work, we investigate whether graph neural networks are\ncompetitive in small data settings compared to the parametrically 'cheaper'\nalternative of fingerprint methods. When we find that they are not, we explore\npretraining and the meta-learning method MAML (and variants FO-MAML and ANIL)\nfor improving graph neural network performance by transfer learning from\nrelated tasks. We find that MAML and FO-MAML do enable the graph neural network\nto outperform models based on fingerprints, providing a path to using graph\nneural networks even in settings with severely restricted data availability. In\ncontrast to previous work, we find ANIL performs worse that other meta-learning\napproaches in this molecule setting. Our results suggest two reasons: molecular\nmachine learning tasks may require significant task-specific adaptation, and\ndistribution shifts in test tasks relative to train tasks may contribute to\nworse ANIL performance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 16:52:04 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Pappu", "Aneesh", ""], ["Paige", "Brooks", ""]]}, {"id": "2011.12208", "submitter": "Pratik K. Mishra", "authors": "Pratik K. Mishra, Chandan Gautam, Aruna Tiwari", "title": "Minimum Variance Embedded Auto-associative Kernel Extreme Learning\n  Machine for One-class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-class classification (OCC) needs samples from only a single class to\ntrain the classifier. Recently, an auto-associative kernel extreme learning\nmachine was developed for the OCC task. This paper introduces a novel extension\nof this classifier by embedding minimum variance information within its\narchitecture and is referred to as VAAKELM. The minimum variance embedding\nforces the network output weights to focus in regions of low variance and\nreduces the intra-class variance. This leads to a better separation of target\nsamples and outliers, resulting in an improvement in the generalization\nperformance of the classifier. The proposed classifier follows a\nreconstruction-based approach to OCC and minimizes the reconstruction error by\nusing the kernel extreme learning machine as the base classifier. It uses the\ndeviation in reconstruction error to identify the outliers. We perform\nexperiments on 15 small-size and 10 medium-size one-class benchmark datasets to\ndemonstrate the efficiency of the proposed classifier. We compare the results\nwith 13 existing one-class classifiers by considering the mean F1 score as the\ncomparison metric. The experimental results show that VAAKELM consistently\nperforms better than the existing classifiers, making it a viable alternative\nfor the OCC task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:00:30 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Mishra", "Pratik K.", ""], ["Gautam", "Chandan", ""], ["Tiwari", "Aruna", ""]]}, {"id": "2011.12215", "submitter": "Feng Ruan", "authors": "Keli Liu and Feng Ruan", "title": "A Self-Penalizing Objective Function for Scalable Interaction Detection", "comments": "34 pages; the Appendix can be found on the authors' personal websites\n  (the url is in the pdf)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of nonparametric variable selection with a focus on\ndiscovering interactions between variables. With $p$ variables there are\n$O(p^s)$ possible order-$s$ interactions making exhaustive search infeasible.\nIt is nonetheless possible to identify the variables involved in interactions\nwith only linear computation cost, $O(p)$. The trick is to maximize a class of\nparametrized nonparametric dependence measures which we call metric learning\nobjectives; the landscape of these nonconvex objective functions is sensitive\nto interactions but the objectives themselves do not explicitly model\ninteractions. Three properties make metric learning objectives highly\nattractive:\n  (a) The stationary points of the objective are automatically sparse (i.e.\nperforms selection) -- no explicit $\\ell_1$ penalization is needed.\n  (b) All stationary points of the objective exclude noise variables with high\nprobability.\n  (c) Guaranteed recovery of all signal variables without needing to reach the\nobjective's global maxima or special stationary points.\n  The second and third properties mean that all our theoretical results apply\nin the practical case where one uses gradient ascent to maximize the metric\nlearning objective. While not all metric learning objectives enjoy good\nstatistical power, we design an objective based on $\\ell_1$ kernels that does\nexhibit favorable power: it recovers (i) main effects with $n \\sim \\log p$\nsamples, (ii) hierarchical interactions with $n \\sim \\log p$ samples and (iii)\norder-$s$ pure interactions with $n \\sim p^{2(s-1)}\\log p$ samples.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:07:49 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 00:14:34 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "Keli", ""], ["Ruan", "Feng", ""]]}, {"id": "2011.12216", "submitter": "Shuang Li", "authors": "Shuang Li, Yilun Du, Gido M. van de Ven, Igor Mordatch", "title": "Energy-Based Models for Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate Energy-Based Models (EBMs) as a promising model class for\ncontinual learning problems. Instead of tackling continual learning via the use\nof external memory, growing models, or regularization, EBMs have a natural way\nto support a dynamically-growing number of tasks or classes that causes less\ninterference with previously learned information. Our proposed version of EBMs\nfor continual learning is simple, efficient and outperforms baseline methods by\na large margin on several benchmarks. Moreover, our proposed contrastive\ndivergence based training objective can be applied to other continual learning\nmethods, resulting in substantial boosts in their performance. We also show\nthat EBMs are adaptable to a more general continual learning setting where the\ndata distribution changes without the notion of explicitly delineated tasks.\nThese observations point towards EBMs as a class of models naturally inclined\ntowards the continual learning regime.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:08:13 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 05:00:33 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Li", "Shuang", ""], ["Du", "Yilun", ""], ["van de Ven", "Gido M.", ""], ["Mordatch", "Igor", ""]]}, {"id": "2011.12228", "submitter": "Haoteng Yin", "authors": "Haoteng Yin, Yanbang Wang, Pan Li", "title": "Revisiting graph neural networks and distance encoding from a practical\n  view", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are widely used in the applications based on\ngraph structured data, such as node classification and link prediction.\nHowever, GNNs are often used as a black-box tool and rarely get in-depth\ninvestigated regarding whether they fit certain applications that may have\nvarious properties. A recently proposed technique distance encoding (DE) (Li et\nal. 2020) magically makes GNNs work well in many applications, including node\nclassification and link prediction. The theory provided in (Li et al. 2020)\nsupports DE by proving that DE improves the representation power of GNNs.\nHowever, it is not obvious how the theory assists the applications accordingly.\nHere, we revisit GNNs and DE from a more practical point of view. We want to\nexplain how DE makes GNNs fit for node classification and link prediction.\nSpecifically, for link prediction, DE can be viewed as a way to establish\ncorrelations between a pair of node representations. For node classification,\nthe problem becomes more complicated as different classification tasks may hold\nnode labels that indicate different physical meanings. We focus on the most\nwidely-considered node classification scenarios and categorize the node labels\ninto two types, community type and structure type, and then analyze different\nmechanisms that GNNs adopt to predict these two types of labels. We also run\nextensive experiments to compare eight different configurations of GNNs paired\nwith DE to predict node labels over eight real-world graphs. The results\ndemonstrate the uniform effectiveness of DE to predict structure-type labels.\nLastly, we reach three pieces of conclusions on how to use GNNs and DE properly\nin tasks of node classification.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 22:04:37 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 05:31:33 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 19:31:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yin", "Haoteng", ""], ["Wang", "Yanbang", ""], ["Li", "Pan", ""]]}, {"id": "2011.12233", "submitter": "Youbang Sun", "authors": "Youbang Sun, Shahin Shahrampour", "title": "Linear Convergence of Distributed Mirror Descent with Integral Feedback\n  for Strongly Convex Problems", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization often requires finding the minimum of a global\nobjective function written as a sum of local functions. A group of agents work\ncollectively to minimize the global function. We study a continuous-time\ndecentralized mirror descent algorithm that uses purely local gradient\ninformation to converge to the global optimal solution. The algorithm enforces\nconsensus among agents using the idea of integral feedback. Recently, Sun and\nShahrampour (2020) studied the asymptotic convergence of this algorithm for\nwhen the global function is strongly convex but local functions are convex.\nUsing control theory tools, in this work, we prove that the algorithm indeed\nachieves (local) exponential convergence. We also provide a numerical\nexperiment on a real data-set as a validation of the convergence speed of our\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:27:27 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Sun", "Youbang", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2011.12236", "submitter": "Ariel Ruiz-Garcia", "authors": "Ariel Ruiz-Garcia, Ibrahim Almakky, Vasile Palade, Luke Hicks", "title": "Generative Adversarial Stacked Autoencoders", "comments": "arXiv admin note: text overlap with arXiv:2007.09790", "journal-ref": "Proceedings of the LatinX in AI Research Workshop at at the 34th\n  Conference on Neural Information Processing Systems (NeurIPS 2020),\n  Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) have become predominant in image\ngeneration tasks. Their success is attributed to the training regime which\nemploys two models: a generator G and discriminator D that compete in a minimax\nzero sum game. Nonetheless, GANs are difficult to train due to their\nsensitivity to hyperparameter and parameter initialisation, which often leads\nto vanishing gradients, non-convergence, or mode collapse, where the generator\nis unable to create samples with different variations. In this work, we propose\na novel Generative Adversarial Stacked Convolutional Autoencoder(GASCA) model\nand a generative adversarial gradual greedy layer-wise learning algorithm\nde-signed to train Adversarial Autoencoders in an efficient and incremental\nmanner. Our training approach produces images with significantly lower\nreconstruction error than vanilla joint training.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:51:59 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Ruiz-Garcia", "Ariel", ""], ["Almakky", "Ibrahim", ""], ["Palade", "Vasile", ""], ["Hicks", "Luke", ""]]}, {"id": "2011.12239", "submitter": "Jingli Wang", "authors": "Huan Qing and Jingli Wang", "title": "Estimating network memberships by mixed regularized spectral clustering", "comments": "17 pages; 2 figures; 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed membership community detection is a challenge problem in network\nanalysis. Here, under the degree-corrected mixed membership (DCMM) model, we\npropose an efficient approach called mixed regularized spectral clustering\n(Mixed-RSC for short) to estimate the memberships. Mixed-RSC is an extension of\nthe RSC method (Qin and Rohe, 2013) to deal with the mixed membership community\ndetection problem. We show that the algorithm is asymptotically consistent\nunder mild conditions. The approach is successfully applied to a small scale of\nsimulations and substantial empirical networks with encouraging results\ncompared to a number of benchmark methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 02:30:53 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Qing", "Huan", ""], ["Wang", "Jingli", ""]]}, {"id": "2011.12245", "submitter": "Andrew Arrasmith", "authors": "Andrew Arrasmith, M. Cerezo, Piotr Czarnik, Lukasz Cincio, Patrick J.\n  Coles", "title": "Effect of barren plateaus on gradient-free optimization", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-20-29699", "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Barren plateau landscapes correspond to gradients that vanish exponentially\nin the number of qubits. Such landscapes have been demonstrated for variational\nquantum algorithms and quantum neural networks with either deep circuits or\nglobal cost functions. For obvious reasons, it is expected that gradient-based\noptimizers will be significantly affected by barren plateaus. However, whether\nor not gradient-free optimizers are impacted is a topic of debate, with some\narguing that gradient-free approaches are unaffected by barren plateaus. Here\nwe show that, indeed, gradient-free optimizers do not solve the barren plateau\nproblem. Our main result proves that cost function differences, which are the\nbasis for making decisions in a gradient-free optimization, are exponentially\nsuppressed in a barren plateau. Hence, without exponential precision,\ngradient-free optimizers will not make progress in the optimization. We\nnumerically confirm this by training in a barren plateau with several\ngradient-free optimizers (Nelder-Mead, Powell, and COBYLA algorithms), and show\nthat the numbers of shots required in the optimization grows exponentially with\nthe number of qubits.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:41:13 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Arrasmith", "Andrew", ""], ["Cerezo", "M.", ""], ["Czarnik", "Piotr", ""], ["Cincio", "Lukasz", ""], ["Coles", "Patrick J.", ""]]}, {"id": "2011.12247", "submitter": "Micha{\\l} Kozielski", "authors": "Joanna Henzel, Joanna Tobiasz, Micha{\\l} Kozielski, Ma{\\l}gorzata\n  Bach, Pawe{\\l} Foszner, Aleksandra Gruca, Mateusz Kania, Justyna Mika, Anna\n  Papiez, Aleksandra Werner, Joanna Zyla, and Jerzy Jaroszewicz, Joanna\n  Polanska, Marek Sikora", "title": "Classification supporting COVID-19 diagnostics based on patient survey\n  data", "comments": "39 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distinguishing COVID-19 from other flu-like illnesses can be difficult due to\nambiguous symptoms and still an initial experience of doctors. Whereas, it is\ncrucial to filter out those sick patients who do not need to be tested for\nSARS-CoV-2 infection, especially in the event of the overwhelming increase in\ndisease. As a part of the presented research, logistic regression and XGBoost\nclassifiers, that allow for effective screening of patients for COVID-19, were\ngenerated. Each of the methods was tuned to achieve an assumed acceptable\nthreshold of negative predictive values during classification. Additionally, an\nexplanation of the obtained classification models was presented. The\nexplanation enables the users to understand what was the basis of the decision\nmade by the model. The obtained classification models provided the basis for\nthe DECODE service (decode.polsl.pl), which can serve as support in screening\npatients with COVID-19 disease. Moreover, the data set constituting the basis\nfor the analyses performed is made available to the research community. This\ndata set consisting of more than 3,000 examples is based on questionnaires\ncollected at a hospital in Poland.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 17:44:01 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Henzel", "Joanna", ""], ["Tobiasz", "Joanna", ""], ["Kozielski", "Micha\u0142", ""], ["Bach", "Ma\u0142gorzata", ""], ["Foszner", "Pawe\u0142", ""], ["Gruca", "Aleksandra", ""], ["Kania", "Mateusz", ""], ["Mika", "Justyna", ""], ["Papiez", "Anna", ""], ["Werner", "Aleksandra", ""], ["Zyla", "Joanna", ""], ["Jaroszewicz", "Jerzy", ""], ["Polanska", "Joanna", ""], ["Sikora", "Marek", ""]]}, {"id": "2011.12256", "submitter": "Ali Babolhavaeji", "authors": "Ali Babolhavaeji and Mohammad Fanaei", "title": "Multi-Stage CNN-Based Monocular 3D Vehicle Localization and Orientation\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to design a 3D object detection model from 2D images taken by\nmonocular cameras by combining the estimated bird's-eye view elevation map and\nthe deep representation of object features. The proposed model has a\npre-trained ResNet-50 network as its backend network and three more branches.\nThe model first builds a bird's-eye view elevation map to estimate the depth of\nthe object in the scene and by using that estimates the object's 3D bounding\nboxes. We have trained and evaluate it on two major datasets: a syntactic\ndataset and the KIITI dataset.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 18:01:57 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Babolhavaeji", "Ali", ""], ["Fanaei", "Mohammad", ""]]}, {"id": "2011.12257", "submitter": "Abraar Chaudhry", "authors": "Amir Ali Ahmadi, Abraar Chaudhry, Vikas Sindhwani, Stephen Tu", "title": "Safely Learning Dynamical Systems from Short Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in learning to control an unknown dynamical system is\nto reduce model uncertainty by making measurements while maintaining safety. In\nthis work, we formulate a mathematical definition of what it means to safely\nlearn a dynamical system by sequentially deciding where to initialize the next\ntrajectory. In our framework, the state of the system is required to stay\nwithin a given safety region under the (possibly repeated) action of all\ndynamical systems that are consistent with the information gathered so far. For\nour first two results, we consider the setting of safely learning linear\ndynamics. We present a linear programming-based algorithm that either safely\nrecovers the true dynamics from trajectories of length one, or certifies that\nsafe learning is impossible. We also give an efficient semidefinite\nrepresentation of the set of initial conditions whose resulting trajectories of\nlength two are guaranteed to stay in the safety region. For our final result,\nwe study the problem of safely learning a nonlinear dynamical system. We give a\nsecond-order cone programming based representation of the set of initial\nconditions that are guaranteed to remain in the safety region after one\napplication of the system dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 18:06:10 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Ahmadi", "Amir Ali", ""], ["Chaudhry", "Abraar", ""], ["Sindhwani", "Vikas", ""], ["Tu", "Stephen", ""]]}, {"id": "2011.12288", "submitter": "Srinivasan Sridharan", "authors": "Srinivasan Sridharan", "title": "Machine Learning (ML) In a 5G Standalone (SA) Self Organizing Network\n  (SON)", "comments": "5G, Machine learning (ML), Self-organizing Networks (SONs), 5G\n  Standalone, Artificial Intelligence (AI)", "journal-ref": null, "doi": "10.14445/22312803/IJCTT-V68I11P105", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is included in Self-organizing Networks (SONs) that are\nkey drivers for enhancing the Operations, Administration, and Maintenance (OAM)\nactivities. It is included in the 5G Standalone (SA) system is one of the 5G\ncommunication tracks that transforms 4G networking to next-generation\ntechnology that is based on mobile applications. The research's main aim is to\nan overview of machine learning (ML) in 5G standalone core networks. 5G\nStandalone is considered a key enabler by the service providers as it improves\nthe efficacy of the throughput that edges the network. It also assists in\nadvancing new cellular use cases like ultra-reliable low latency communications\n(URLLC) that supports combinations of frequencies.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 18:57:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Sridharan", "Srinivasan", ""]]}, {"id": "2011.12289", "submitter": "Dongdong Chen", "authors": "Yunsheng Li and Yinpeng Chen and Xiyang Dai and Dongdong Chen and\n  Mengchen Liu and Lu Yuan and Zicheng Liu and Lei Zhang and Nuno Vasconcelos", "title": "MicroNet: Towards Image Recognition with Extremely Low FLOPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present MicroNet, which is an efficient convolutional\nneural network using extremely low computational cost (e.g. 6 MFLOPs on\nImageNet classification). Such a low cost network is highly desired on edge\ndevices, yet usually suffers from a significant performance degradation. We\nhandle the extremely low FLOPs based upon two design principles: (a) avoiding\nthe reduction of network width by lowering the node connectivity, and (b)\ncompensating for the reduction of network depth by introducing more complex\nnon-linearity per layer. Firstly, we propose Micro-Factorized convolution to\nfactorize both pointwise and depthwise convolutions into low rank matrices for\na good tradeoff between the number of channels and input/output connectivity.\nSecondly, we propose a new activation function, named Dynamic Shift-Max, to\nimprove the non-linearity via maxing out multiple dynamic fusions between an\ninput feature map and its circular channel shift. The fusions are dynamic as\ntheir parameters are adapted to the input. Building upon Micro-Factorized\nconvolution and dynamic Shift-Max, a family of MicroNets achieve a significant\nperformance gain over the state-of-the-art in the low FLOP regime. For\ninstance, MicroNet-M1 achieves 61.1% top-1 accuracy on ImageNet classification\nwith 12 MFLOPs, outperforming MobileNetV3 by 11.3%.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 18:59:39 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Li", "Yunsheng", ""], ["Chen", "Yinpeng", ""], ["Dai", "Xiyang", ""], ["Chen", "Dongdong", ""], ["Liu", "Mengchen", ""], ["Yuan", "Lu", ""], ["Liu", "Zicheng", ""], ["Zhang", "Lei", ""], ["Vasconcelos", "Nuno", ""]]}, {"id": "2011.12328", "submitter": "Noel Loo", "authors": "Noel Loo, Siddharth Swaroop, Richard E. Turner", "title": "Generalized Variational Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning deals with training models on new tasks and datasets in an\nonline fashion. One strand of research has used probabilistic regularization\nfor continual learning, with two of the main approaches in this vein being\nOnline Elastic Weight Consolidation (Online EWC) and Variational Continual\nLearning (VCL). VCL employs variational inference, which in other settings has\nbeen improved empirically by applying likelihood-tempering. We show that\napplying this modification to VCL recovers Online EWC as a limiting case,\nallowing for interpolation between the two approaches. We term the general\nalgorithm Generalized VCL (GVCL). In order to mitigate the observed overpruning\neffect of VI, we take inspiration from a common multi-task architecture, neural\nnetworks with task-specific FiLM layers, and find that this addition leads to\nsignificant performance gains, specifically for variational methods. In the\nsmall-data regime, GVCL strongly outperforms existing baselines. In larger\ndatasets, GVCL with FiLM layers outperforms or is competitive with existing\nbaselines in terms of accuracy, whilst also providing significantly better\ncalibration.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 19:07:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Loo", "Noel", ""], ["Swaroop", "Siddharth", ""], ["Turner", "Richard E.", ""]]}, {"id": "2011.12341", "submitter": "Cheik Traor\\'e", "authors": "Cheik Traor\\'e and Edouard Pauwels", "title": "Sequential convergence of AdaGrad algorithm for smooth convex\n  optimization", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the iterates produced by, either the scalar step size variant,\nor the coordinatewise variant of AdaGrad algorithm, are convergent sequences\nwhen applied to convex objective functions with Lipschitz gradient. The key\ninsight is to remark that such AdaGrad sequences satisfy a variable metric\nquasi-Fej\\'er monotonicity property, which allows to prove convergence.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 19:49:41 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 12:44:56 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 16:00:21 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Traor\u00e9", "Cheik", ""], ["Pauwels", "Edouard", ""]]}, {"id": "2011.12344", "submitter": "Luiz F. O. Chamon", "authors": "Luiz F. O. Chamon and Santiago Paternain and Alejandro Ribeiro", "title": "Trust but Verify: Assigning Prediction Credibility by Counterfactual\n  Constrained Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction credibility measures, in the form of confidence intervals or\nprobability distributions, are fundamental in statistics and machine learning\nto characterize model robustness, detect out-of-distribution samples\n(outliers), and protect against adversarial attacks. To be effective, these\nmeasures should (i) account for the wide variety of models used in practice,\n(ii) be computable for trained models or at least avoid modifying established\ntraining procedures, (iii) forgo the use of data, which can expose them to the\nsame robustness issues and attacks as the underlying model, and (iv) be\nfollowed by theoretical guarantees. These principles underly the framework\ndeveloped in this work, which expresses the credibility as a risk-fit\ntrade-off, i.e., a compromise between how much can fit be improved by\nperturbing the model input and the magnitude of this perturbation (risk). Using\na constrained optimization formulation and duality theory, we analyze this\ncompromise and show that this balance can be determined counterfactually,\nwithout having to test multiple perturbations. This results in an unsupervised,\na posteriori method of assigning prediction credibility for any (possibly\nnon-convex) differentiable model, from RKHS-based solutions to any architecture\nof (feedforward, convolutional, graph) neural network. Its use is illustrated\nin data filtering and defense against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 19:52:38 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Chamon", "Luiz F. O.", ""], ["Paternain", "Santiago", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2011.12348", "submitter": "Hamza Saad", "authors": "Hamza Saad", "title": "The Application of Data Mining in the Production Processes", "comments": "8 pages, 3 figures, 1 table", "journal-ref": null, "doi": "10.11648/j.ie.20180201.14", "report-no": null, "categories": "econ.GN cs.LG q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional statistical and measurements are unable to solve all industrial\ndata in the right way and appropriate time. Open markets mean the customers are\nincreased, and production must increase to provide all customer requirements.\nNowadays, large data generated daily from different production processes and\ntraditional statistical or limited measurements are not enough to handle all\ndaily data. Improve production and quality need to analyze data and extract the\nimportant information about the process how to improve. Data mining applied\nsuccessfully in the industrial processes and some algorithms such as mining\nassociation rules, and decision tree recorded high professional results in\ndifferent industrial and production fields. The study applied seven algorithms\nto analyze production data and extract the best result and algorithm in the\nindustry field. KNN, Tree, SVM, Random Forests, ANN, Na\\\"ive Bayes, and\nAdaBoost applied to classify data based on three attributes without neglect any\nvariables whether this variable is numerical or categorical. The best results\nof accuracy and area under the curve (ROC) obtained from Decision tree and its\nensemble algorithms (Random Forest and AdaBoost). Thus, a decision tree is an\nappropriate algorithm to handle manufacturing and production data especially\nthis algorithm can handle numerical and categorical data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:00:59 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Saad", "Hamza", ""]]}, {"id": "2011.12349", "submitter": "Batuhan Bardak", "authors": "Batuhan Bardak and Mehmet Tan", "title": "Improving Clinical Outcome Predictions Using Convolution over Medical\n  Entities with Multimodal Learning", "comments": "21 pages, 2 figures, Submitted to Elsevier (Artificial Intelligence\n  in Medicine)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early prediction of mortality and length of stay(LOS) of a patient is vital\nfor saving a patient's life and management of hospital resources. Availability\nof electronic health records(EHR) makes a huge impact on the healthcare domain\nand there has seen several works on predicting clinical problems. However, many\nstudies did not benefit from the clinical notes because of the sparse, and high\ndimensional nature. In this work, we extract medical entities from clinical\nnotes and use them as additional features besides time-series features to\nimprove our predictions. We propose a convolution based multimodal\narchitecture, which not only learns effectively combining medical entities and\ntime-series ICU signals of patients, but also allows us to compare the effect\nof different embedding techniques such as Word2vec, FastText on medical\nentities. In the experiments, our proposed method robustly outperforms all\nother baseline models including different multimodal architectures for all\nclinical tasks. The code for the proposed method is available at\nhttps://github.com/tanlab/ConvolutionMedicalNer.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:08:39 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 09:40:41 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bardak", "Batuhan", ""], ["Tan", "Mehmet", ""]]}, {"id": "2011.12351", "submitter": "Kenny Young", "authors": "Kenny Young", "title": "Hindsight Network Credit Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Hindsight Network Credit Assignment (HNCA), a novel learning\nmethod for stochastic neural networks, which works by assigning credit to each\nneuron's stochastic output based on how it influences the output of its\nimmediate children in the network. We prove that HNCA provides unbiased\ngradient estimates while reducing variance compared to the REINFORCE estimator.\nWe also experimentally demonstrate the advantage of HNCA over REINFORCE in a\ncontextual bandit version of MNIST. The computational complexity of HNCA is\nsimilar to that of backpropagation. We believe that HNCA can help stimulate new\nways of thinking about credit assignment in stochastic compute graphs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:16:45 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Young", "Kenny", ""]]}, {"id": "2011.12353", "submitter": "Tristan Ballard", "authors": "Tristan Ballard and Gopal Erinjippurath", "title": "FireSRnet: Geoscience-Driven Super-Resolution of Future Fire Risk from\n  Climate Change", "comments": "9 pages, 7 figures, 2 tables. To be published in Tackling Climate\n  Change with Machine Learning workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With fires becoming increasingly frequent and severe across the globe in\nrecent years, understanding climate change's role in fire behavior is critical\nfor quantifying current and future fire risk. However, global climate models\ntypically simulate fire behavior at spatial scales too coarse for local risk\nassessments. Therefore, we propose a novel approach towards super-resolution\n(SR) enhancement of fire risk exposure maps that incorporates not only 2000 to\n2020 monthly satellite observations of active fires but also local information\non land cover and temperature. Inspired by SR architectures, we propose an\nefficient deep learning model trained for SR on fire risk exposure maps. We\nevaluate this model on resolution enhancement and find it outperforms standard\nimage interpolation techniques at both 4x and 8x enhancement while having\ncomparable performance at 2x enhancement. We then demonstrate the\ngeneralizability of this SR model over northern California and New South Wales,\nAustralia. We conclude with a discussion and application of our proposed model\nto climate model simulations of fire risk in 2040 and 2100, illustrating the\npotential for SR enhancement of fire risk maps from the latest state-of-the-art\nclimate models.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:19:51 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ballard", "Tristan", ""], ["Erinjippurath", "Gopal", ""]]}, {"id": "2011.12355", "submitter": "Eyal Perry", "authors": "Eyal Perry", "title": "Lethean Attack: An Online Data Poisoning Technique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data poisoning is an adversarial scenario where an attacker feeds a specially\ncrafted sequence of samples to an online model in order to subvert learning. We\nintroduce Lethean Attack, a novel data poisoning technique that induces\ncatastrophic forgetting on an online model. We apply the attack in the context\nof Test-Time Training, a modern online learning framework aimed for\ngeneralization under distribution shifts. We present the theoretical rationale\nand empirically compare it against other sample sequences that naturally induce\nforgetting. Our results demonstrate that using lethean attacks, an adversary\ncould revert a test-time training model back to coin-flip accuracy performance\nusing a short sample sequence.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:23:12 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Perry", "Eyal", ""]]}, {"id": "2011.12363", "submitter": "Gabriel Loaiza-Ganem", "authors": "Panteha Naderian, Gabriel Loaiza-Ganem, Harry J. Braviner, Anthony L.\n  Caterini, Jesse C. Cresswell, Tong Li, Animesh Garg", "title": "C-Learning: Horizon-Aware Cumulative Accessibility Estimation", "comments": "Accepted at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-goal reaching is an important problem in reinforcement learning needed\nto achieve algorithmic generalization. Despite recent advances in this field,\ncurrent algorithms suffer from three major challenges: high sample complexity,\nlearning only a single way of reaching the goals, and difficulties in solving\ncomplex motion planning tasks. In order to address these limitations, we\nintroduce the concept of cumulative accessibility functions, which measure the\nreachability of a goal from a given state within a specified horizon. We show\nthat these functions obey a recurrence relation, which enables learning from\noffline interactions. We also prove that optimal cumulative accessibility\nfunctions are monotonic in the planning horizon. Additionally, our method can\ntrade off speed and reliability in goal-reaching by suggesting multiple paths\nto a single goal depending on the provided horizon. We evaluate our approach on\na set of multi-goal discrete and continuous control tasks. We show that our\nmethod outperforms state-of-the-art goal-reaching algorithms in success rate,\nsample complexity, and path optimality. Our code is available at\nhttps://github.com/layer6ai-labs/CAE, and additional visualizations can be\nfound at https://sites.google.com/view/learning-cae/.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:34:31 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 18:20:47 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 03:05:38 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Naderian", "Panteha", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Braviner", "Harry J.", ""], ["Caterini", "Anthony L.", ""], ["Cresswell", "Jesse C.", ""], ["Li", "Tong", ""], ["Garg", "Animesh", ""]]}, {"id": "2011.12372", "submitter": "Will Price", "authors": "Will Price and Dima Damen", "title": "Play Fair: Frame Attributions in Video Models", "comments": "Code available at: https://github.com/willprice/play-fair/ and\n  supporting website at: https://play-fair.willprice.dev/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an attribution method for explaining action\nrecognition models. Such models fuse information from multiple frames within a\nvideo, through score aggregation or relational reasoning. We break down a\nmodel's class score into the sum of contributions from each frame, fairly. Our\nmethod adapts an axiomatic solution to fair reward distribution in cooperative\ngames, known as the Shapley value, for elements in a variable-length sequence,\nwhich we call the Element Shapley Value (ESV). Critically, we propose a\ntractable approximation of ESV that scales linearly with the number of frames\nin the sequence. We employ ESV to explain two action recognition models (TRN\nand TSN) on the fine-grained dataset Something-Something. We offer detailed\nanalysis of supporting/distracting frames, and the relationships of ESVs to the\nframe's position, class prediction, and sequence length. We compare ESV to\nnaive baselines and two commonly used feature attribution methods: Grad-CAM and\nIntegrated-Gradients.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:45:29 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Price", "Will", ""], ["Damen", "Dima", ""]]}, {"id": "2011.12378", "submitter": "Qiyao Wang", "authors": "Qiyao Wang, Haiyan Wang, Chetan Gupta, Aniruddha Rajendra Rao, Hamed\n  Khorasgani", "title": "A Non-linear Function-on-Function Model for Regression with Time Series\n  Data", "comments": "Accepted by IEEE Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last few decades, building regression models for non-scalar variables,\nincluding time series, text, image, and video, has attracted increasing\ninterests of researchers from the data analytic community. In this paper, we\nfocus on a multivariate time series regression problem. Specifically, we aim to\nlearn mathematical mappings from multiple chronologically measured numerical\nvariables within a certain time interval S to multiple numerical variables of\ninterest over time interval T. Prior arts, including the multivariate\nregression model, the Seq2Seq model, and the functional linear models, suffer\nfrom several limitations. The first two types of models can only handle\nregularly observed time series. Besides, the conventional multivariate\nregression models tend to be biased and inefficient, as they are incapable of\nencoding the temporal dependencies among observations from the same time\nseries. The sequential learning models explicitly use the same set of\nparameters along time, which has negative impacts on accuracy. The\nfunction-on-function linear model in functional data analysis (a branch of\nstatistics) is insufficient to capture complex correlations among the\nconsidered time series and suffer from underfitting easily. In this paper, we\npropose a general functional mapping that embraces the function-on-function\nlinear model as a special case. We then propose a non-linear\nfunction-on-function model using the fully connected neural network to learn\nthe mapping from data, which addresses the aforementioned concerns in the\nexisting approaches. For the proposed model, we describe in detail the\ncorresponding numerical implementation procedures. The effectiveness of the\nproposed model is demonstrated through the application to two real-world\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:51:27 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Qiyao", ""], ["Wang", "Haiyan", ""], ["Gupta", "Chetan", ""], ["Rao", "Aniruddha Rajendra", ""], ["Khorasgani", "Hamed", ""]]}, {"id": "2011.12379", "submitter": "Claudia Shi", "authors": "Claudia Shi, Victor Veitch, David Blei", "title": "Invariant Representation Learning for Treatment Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The defining challenge for causal inference from observational data is the\npresence of `confounders', covariates that affect both treatment assignment and\nthe outcome. To address this challenge, practitioners collect and adjust for\nthe covariates, hoping that they adequately correct for confounding. However,\nincluding every observed covariate in the adjustment runs the risk of including\n`bad controls', variables that induce bias when they are conditioned on. The\nproblem is that we do not always know which variables in the covariate set are\nsafe to adjust for and which are not. To address this problem, we develop\nNearly Invariant Causal Estimation (NICE). NICE uses invariant risk\nminimization (IRM) [Arj19] to learn a representation of the covariates that,\nunder some assumptions, strips out bad controls but preserves sufficient\ninformation to adjust for confounding. Adjusting for the learned\nrepresentation, rather than the covariates themselves, avoids the induced bias\nand provides valid causal inferences. We evaluate NICE on both synthetic and\nsemi-synthetic data. When the covariates contain unknown collider variables and\nother bad controls, NICE performs better than adjusting for all the covariates.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:53:24 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 06:45:08 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Shi", "Claudia", ""], ["Veitch", "Victor", ""], ["Blei", "David", ""]]}, {"id": "2011.12380", "submitter": "Walid Hafiane", "authors": "Walid Hafiane, Joel Legrand, Yannick Toussaint and Adrien Coulet", "title": "Experiments on transfer learning architectures for biomedical relation\n  extraction", "comments": "12 pages, 2 figures,Extraction et Gestion des Connaissances (EGC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relation extraction (RE) consists in identifying and structuring\nautomatically relations of interest from texts. Recently, BERT improved the top\nperformances for several NLP tasks, including RE. However, the best way to use\nBERT, within a machine learning architecture, and within a transfer learning\nstrategy is still an open question since it is highly dependent on each\nspecific task and domain. Here, we explore various BERT-based architectures and\ntransfer learning strategies (i.e., frozen or fine-tuned) for the task of\nbiomedical RE on two corpora. Among tested architectures and strategies, our\n*BERT-segMCNN with finetuning reaches performances higher than the\nstate-of-the-art on the two corpora (1.73 % and 32.77 % absolute improvement on\nChemProt and PGxCorpus corpora respectively). More generally, our experiments\nillustrate the expected interest of fine-tuning with BERT, but also the\nunexplored advantage of using structural information (with sentence\nsegmentation), in addition to the context classically leveraged by BERT.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 20:56:47 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Hafiane", "Walid", ""], ["Legrand", "Joel", ""], ["Toussaint", "Yannick", ""], ["Coulet", "Adrien", ""]]}, {"id": "2011.12392", "submitter": "Gersende Fort", "authors": "Gersende Fort (IMT), Eric Moulines (X-DEP-MATHAPP), Hoi-To Wai", "title": "Geom-SPIDER-EM: Faster Variance Reduced Stochastic Expectation\n  Maximization for Nonconvex Finite-Sum Optimization", "comments": "Submitted to an International conference, with reviewing process", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation Maximization (EM) algorithm is a key reference for inference\nin latent variable models; unfortunately, its computational cost is prohibitive\nin the large scale learning setting. In this paper, we propose an extension of\nthe Stochastic Path-Integrated Differential EstimatoR EM (SPIDER-EM) and derive\ncomplexity bounds for this novel algorithm, designed to solve smooth nonconvex\nfinite-sum optimization problems. We show that it reaches the same state of the\nart complexity bounds as SPIDER-EM; and provide conditions for a linear rate of\nconvergence. Numerical results support our findings.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 21:20:53 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Fort", "Gersende", "", "IMT"], ["Moulines", "Eric", "", "X-DEP-MATHAPP"], ["Wai", "Hoi-To", ""]]}, {"id": "2011.12398", "submitter": "Anthony Kelly", "authors": "Anthony Kelly", "title": "Distribution Conditional Denoising: A Flexible Discriminative Image\n  Denoiser", "comments": "10 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A flexible discriminative image denoiser is introduced in which multi-task\nlearning methods are applied to a densoising FCN based on U-Net. The\nactivations of the U-Net model are modified by affine transforms that are a\nlearned function of conditioning inputs. The learning procedure for multiple\nnoise types and levels involves applying a distribution of noise parameters\nduring training to the conditioning inputs, with the same noise parameters\napplied to a noise generating layer at the input (similar to the approach taken\nin a denoising autoencoder). It is shown that this flexible denoising model\nachieves state of the art performance on images corrupted with Gaussian and\nPoisson noise. It has also been shown that this conditional training method can\ngeneralise a fixed noise level U-Net denoiser to a variety of noise levels.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 21:27:18 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Kelly", "Anthony", ""]]}, {"id": "2011.12408", "submitter": "Sahand Hajifar", "authors": "Sahand Hajifar and Hongyue Sun", "title": "Online Domain Adaptation for Continuous Cross-Subject Liver Viability\n  Evaluation Based on Irregular Thermal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate evaluation of liver viability during its procurement is a\nchallenging issue and has traditionally been addressed by taking invasive\nbiopsy on liver. Recently, people have started to investigate on the\nnon-invasive evaluation of liver viability during its procurement using the\nliver surface thermal images. However, existing works include the background\nnoise in the thermal images and do not consider the cross-subject heterogeneity\nof livers, thus the viability evaluation accuracy can be affected. In this\npaper, we propose to use the irregular thermal data of the pure liver region,\nand the cross-subject liver evaluation information (i.e., the available\nviability label information in cross-subject livers), for the real-time\nevaluation of a new liver's viability. To achieve this objective, we extract\nfeatures of irregular thermal data based on tools from graph signal processing\n(GSP), and propose an online domain adaptation (DA) and classification\nframework using the GSP features of cross-subject livers. A multiconvex block\ncoordinate descent based algorithm is designed to jointly learn the\ndomain-invariant features during online DA and learn the classifier. Our\nproposed framework is applied to the liver procurement data, and classifies the\nliver viability accurately.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 21:42:19 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Hajifar", "Sahand", ""], ["Sun", "Hongyue", ""]]}, {"id": "2011.12413", "submitter": "Leonardo Zepeda-N\\'u\\~nez", "authors": "Matthew Li and Laurent Demanet and Leonardo Zepeda-N\\'u\\~nez", "title": "Wide-band butterfly network: stable and efficient inversion via\n  multi-frequency neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an end-to-end deep learning architecture called the wide-band\nbutterfly network (WideBNet) for approximating the inverse scattering map from\nwide-band scattering data. This architecture incorporates tools from\ncomputational harmonic analysis, such as the butterfly factorization, and\ntraditional multi-scale methods, such as the Cooley-Tukey FFT algorithm, to\ndrastically reduce the number of trainable parameters to match the inherent\ncomplexity of the problem. As a result WideBNet is efficient: it requires fewer\ntraining points than off-the-shelf architectures, and has stable training\ndynamics, thus it can rely on standard weight initialization strategies. The\narchitecture automatically adapts to the dimensions of the data with only a few\nhyper-parameters that the user must specify. WideBNet is able to produce images\nthat are competitive with optimization-based approaches, but at a fraction of\nthe cost, and we also demonstrate numerically that it learns to super-resolve\nscatterers in the full aperture scattering setup.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 21:48:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Li", "Matthew", ""], ["Demanet", "Laurent", ""], ["Zepeda-N\u00fa\u00f1ez", "Leonardo", ""]]}, {"id": "2011.12423", "submitter": "Hatem Hajri", "authors": "Manon C\\'esaire, Hatem Hajri, Sylvain Lamprier, and Patrick Gallinari", "title": "Stochastic sparse adversarial attacks", "comments": "The link to the codes is given:\n  https://github.com/SSAA3/stochastic-sparse-adv-attacks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces stochastic sparse adversarial attacks (SSAA), simple,\nfast and purely noise-based targeted and untargeted $L_0$ attacks of neural\nnetwork classifiers (NNC). SSAA are devised by exploiting a simple small-time\nexpansion idea widely used for Markov processes and offer new examples of $L_0$\nattacks whose studies have been limited. They are designed to solve the known\nscalability issue of the family of Jacobian-based saliency maps attacks to\nlarge datasets and they succeed in solving it. Experiments on small and large\ndatasets (CIFAR-10 and ImageNet) illustrate further advantages of SSAA in\ncomparison with the-state-of-the-art methods. For instance, in the untargeted\ncase, our method called Voting Folded Gaussian Attack (VFGA) scales efficiently\nto ImageNet and achieves a significantly lower $L_0$ score than SparseFool (up\nto $\\frac{2}{5}$ lower) while being faster. Moreover, VFGA achieves better\n$L_0$ scores on ImageNet than Sparse-RS when both attacks are fully successful\non a large number of samples. Codes are publicly available through the link\nhttps://github.com/SSAA3/stochastic-sparse-adv-attacks\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:07:51 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 22:02:27 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 10:51:29 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["C\u00e9saire", "Manon", ""], ["Hajri", "Hatem", ""], ["Lamprier", "Sylvain", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2011.12424", "submitter": "Yang Li", "authors": "Yang Li", "title": "Interpretable Models in ANNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial neural networks are often very complex and too deep for a human to\nunderstand. As a result, they are usually referred to as black boxes. For a lot\nof real-world problems, the underlying pattern itself is very complicated, such\nthat an analytic solution does not exist. However, in some cases, laws of\nphysics, for example, the pattern can be described by relatively simple\nmathematical expressions. In that case, we want to get a readable equation\nrather than a black box. In this paper, we try to find a way to explain a\nnetwork and extract a human-readable equation that describes the model.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:09:10 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Li", "Yang", ""]]}, {"id": "2011.12428", "submitter": "Sebastian Goldt", "authors": "Maria Refinetti, St\\'ephane d'Ascoli, Ruben Ohana, Sebastian Goldt", "title": "Align, then memorise: the dynamics of learning with feedback alignment", "comments": "The accompanying code for this paper is available at\n  https://github.com/sdascoli/dfa-dynamics", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning (ICML), PMLR 139, 2021", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct Feedback Alignment (DFA) is emerging as an efficient and biologically\nplausible alternative to the ubiquitous backpropagation algorithm for training\ndeep neural networks. Despite relying on random feedback weights for the\nbackward pass, DFA successfully trains state-of-the-art models such as\nTransformers. On the other hand, it notoriously fails to train convolutional\nnetworks. An understanding of the inner workings of DFA to explain these\ndiverging results remains elusive. Here, we propose a theory for the success of\nDFA. We first show that learning in shallow networks proceeds in two steps: an\nalignment phase, where the model adapts its weights to align the approximate\ngradient with the true gradient of the loss function, is followed by a\nmemorisation phase, where the model focuses on fitting the data. This two-step\nprocess has a degeneracy breaking effect: out of all the low-loss solutions in\nthe landscape, a network trained with DFA naturally converges to the solution\nwhich maximises gradient alignment. We also identify a key quantity underlying\nalignment in deep linear networks: the conditioning of the alignment matrices.\nThe latter enables a detailed understanding of the impact of data structure on\nalignment, and suggests a simple explanation for the well-known failure of DFA\nto train convolutional neural networks. Numerical experiments on MNIST and\nCIFAR10 clearly demonstrate degeneracy breaking in deep non-linear networks and\nshow that the align-then-memorise process occurs sequentially from the bottom\nlayers of the network to the top.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:21:27 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 14:20:37 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Refinetti", "Maria", ""], ["d'Ascoli", "St\u00e9phane", ""], ["Ohana", "Ruben", ""], ["Goldt", "Sebastian", ""]]}, {"id": "2011.12429", "submitter": "Zeynettin Akkus", "authors": "Mohamed Y. Elwazir, Zeynettin Akkus, Didem Oguz, Jae K. Oh", "title": "Fully Automated Mitral Inflow Doppler Analysis Using Deep Learning", "comments": null, "journal-ref": "IEEE BIBE 2020 Proceedings", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echocardiography (echo) is an indispensable tool in a cardiologist's\ndiagnostic armamentarium. To date, almost all echocardiographic parameters\nrequire time-consuming manual labeling and measurements by an experienced\nechocardiographer and exhibit significant variability, owing to the noisy and\nartifact-laden nature of echo images. For example, mitral inflow (MI) Doppler\nis used to assess left ventricular (LV) diastolic function, which is of\nparamount clinical importance to distinguish between different cardiac\ndiseases. In the current work we present a fully automated workflow which\nleverages deep learning to a) label MI Doppler images acquired in an echo\nstudy, b) detect the envelope of MI Doppler signal, c) extract early and late\nfiling (E and A wave) flow velocities and E-wave deceleration time from the\nenvelope. We trained a variety of convolutional neural networks (CNN) models on\n5544 images of 140 patients for predicting 24 image classes including MI\nDoppler images and obtained overall accuracy of 0.97 on 1737 images of 40\npatients. Automated E and A wave velocity showed excellent correlation (Pearson\nR 0.99 and 0.98 respectively) and Bland Altman agreement (mean difference 0.06\nand 0.05 m/s respectively and SD 0.03 for both) with the operator measurements.\nDeceleration time also showed good but lower correlation (Pearson R 0.82) and\nBland-Altman agreement (mean difference: 34.1ms, SD: 30.9ms). These results\ndemonstrate feasibility of Doppler echocardiography measurement automation and\nthe promise of a fully automated echocardiography measurement package.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:27:14 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Elwazir", "Mohamed Y.", ""], ["Akkus", "Zeynettin", ""], ["Oguz", "Didem", ""], ["Oh", "Jae K.", ""]]}, {"id": "2011.12433", "submitter": "Yeshwanth Cherapanamjeri", "authors": "Yeshwanth Cherapanamjeri, Nilesh Tripuraneni, Peter L. Bartlett,\n  Michael I. Jordan", "title": "Optimal Mean Estimation without a Variance", "comments": "Fixed typographical errors in Theorem 1.2, Lemmas 4.3 and C.8", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of heavy-tailed mean estimation in settings where the\nvariance of the data-generating distribution does not exist. Concretely, given\na sample $\\mathbf{X} = \\{X_i\\}_{i = 1}^n$ from a distribution $\\mathcal{D}$\nover $\\mathbb{R}^d$ with mean $\\mu$ which satisfies the following\n\\emph{weak-moment} assumption for some ${\\alpha \\in [0, 1]}$: \\begin{equation*}\n\\forall \\|v\\| = 1: \\mathbb{E}_{X \\thicksim \\mathcal{D}}[\\lvert \\langle X - \\mu,\nv\\rangle \\rvert^{1 + \\alpha}] \\leq 1, \\end{equation*} and given a target\nfailure probability, $\\delta$, our goal is to design an estimator which attains\nthe smallest possible confidence interval as a function of $n,d,\\delta$. For\nthe specific case of $\\alpha = 1$, foundational work of Lugosi and Mendelson\nexhibits an estimator achieving subgaussian confidence intervals, and\nsubsequent work has led to computationally efficient versions of this\nestimator. Here, we study the case of general $\\alpha$, and establish the\nfollowing information-theoretic lower bound on the optimal attainable\nconfidence interval: \\begin{equation*} \\Omega \\left(\\sqrt{\\frac{d}{n}} +\n\\left(\\frac{d}{n}\\right)^{\\frac{\\alpha}{(1 + \\alpha)}} + \\left(\\frac{\\log 1 /\n\\delta}{n}\\right)^{\\frac{\\alpha}{(1 + \\alpha)}}\\right). \\end{equation*}\nMoreover, we devise a computationally-efficient estimator which achieves this\nlower bound.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:39:21 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 20:31:46 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Cherapanamjeri", "Yeshwanth", ""], ["Tripuraneni", "Nilesh", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2011.12466", "submitter": "Alexander Partin", "authors": "Alexander Partin (1 and 2), Thomas Brettin (2 and 3), Yvonne A. Evrard\n  (4), Yitan Zhu (1 and 2), Hyunseung Yoo (1 and 2), Fangfang Xia (1 and 2),\n  Songhao Jiang (7), Austin Clyde (1 and 7), Maulik Shukla (1 and 2), Michael\n  Fonstein (5), James H. Doroshow (6), Rick Stevens (3 and 7) ((1) Division of\n  Data Science and Learning, Argonne National Laboratory, Argonne, IL, USA, (2)\n  University of Chicago Consortium for Advanced Science and Engineering,\n  University of Chicago, Chicago, IL, USA, (3) Computing, Environment and Life\n  Sciences, Argonne National Laboratory, Lemont, IL, USA, (4) Frederick\n  National Laboratory for Cancer Research, Leidos Biomedical Research, Inc.\n  Frederick, MD, USA, (5) Biosciences Division, Argonne National Laboratory,\n  Lemont, IL, USA, (6) Division of Cancer Therapeutics and Diagnosis, National\n  Cancer Institute, Bethesda, MD, USA, (7) Department of Computer Science, The\n  University of Chicago, Chicago, IL, USA)", "title": "Learning Curves for Drug Response Prediction in Cancer Cell Lines", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the size of cell line drug sensitivity data, researchers have\nbeen developing machine learning (ML) models for predicting drug response to\nadvance cancer treatment. As drug sensitivity studies continue generating data,\na common question is whether the proposed predictors can further improve the\ngeneralization performance with more training data. We utilize empirical\nlearning curves for evaluating and comparing the data scaling properties of two\nneural networks (NNs) and two gradient boosting decision tree (GBDT) models\ntrained on four drug screening datasets. The learning curves are accurately\nfitted to a power law model, providing a framework for assessing the data\nscaling behavior of these predictors. The curves demonstrate that no single\nmodel dominates in terms of prediction performance across all datasets and\ntraining sizes, suggesting that the shape of these curves depends on the unique\nmodel-dataset pair. The multi-input NN (mNN), in which gene expressions and\nmolecular drug descriptors are input into separate subnetworks, outperforms a\nsingle-input NN (sNN), where the cell and drug features are concatenated for\nthe input layer. In contrast, a GBDT with hyperparameter tuning exhibits\nsuperior performance as compared with both NNs at the lower range of training\nsizes for two of the datasets, whereas the mNN performs better at the higher\nrange of training sizes. Moreover, the trajectory of the curves suggests that\nincreasing the sample size is expected to further improve prediction scores of\nboth NNs. These observations demonstrate the benefit of using learning curves\nto evaluate predictors, providing a broader perspective on the overall data\nscaling characteristics. The fitted power law curves provide a forward-looking\nperformance metric and can serve as a co-design tool to guide experimental\nbiologists and computational scientists in the design of future experiments.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 01:08:05 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Partin", "Alexander", "", "1 and 2"], ["Brettin", "Thomas", "", "2 and 3"], ["Evrard", "Yvonne A.", "", "1 and 2"], ["Zhu", "Yitan", "", "1 and 2"], ["Yoo", "Hyunseung", "", "1 and 2"], ["Xia", "Fangfang", "", "1 and 2"], ["Jiang", "Songhao", "", "1 and 7"], ["Clyde", "Austin", "", "1 and 7"], ["Shukla", "Maulik", "", "1 and 2"], ["Fonstein", "Michael", "", "3 and 7"], ["Doroshow", "James H.", "", "3 and 7"], ["Stevens", "Rick", "", "3 and 7"]]}, {"id": "2011.12468", "submitter": "Chandra Maddila", "authors": "Chandra Maddila, Sai Surya Upadrasta, Chetan Bansal, Nachiappan\n  Nagappan, Georgios Gousios, Arie van Deursen", "title": "Nudge: Accelerating Overdue Pull Requests Towards Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pull requests are a key part of the collaborative software development and\ncode review process today. However, pull requests can also slow down the\nsoftware development process when the reviewer(s) or the author do not actively\nengage with the pull request. In this work, we design an end-to-end service,\nNudge, for accelerating overdue pull requests towards completion by reminding\nthe author or the reviewer(s) to engage with their overdue pull requests.\nFirst, we use models based on effort estimation and machine learning to predict\nthe completion time for a given pull request. Second, we use activity detection\nto reduce false positives. Lastly, we use dependency determination to\nunderstand the blocker of the pull request and nudge the appropriate\nactor(author or reviewer(s)). We also do a correlation analysis to understand\nthe statistical relationship between the pull request completion times and\nvarious pull request and developer related attributes. Nudge has been deployed\non 147 repositories at Microsoft since 2019. We do a large scale evaluation\nbased on the implicit and explicit feedback we received from sending the Nudge\nnotifications on 8,500 pull requests. We observe significant reduction in\ncompletion time, by over 60%, for pull requests which were nudged thus\nincreasing the efficiency of the code review process and accelerating the pull\nrequest progression.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 01:22:29 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 17:06:22 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Maddila", "Chandra", ""], ["Upadrasta", "Sai Surya", ""], ["Bansal", "Chetan", ""], ["Nagappan", "Nachiappan", ""], ["Gousios", "Georgios", ""], ["van Deursen", "Arie", ""]]}, {"id": "2011.12469", "submitter": "Minh N. H. Nguyen Dr.", "authors": "Minh N. H. Nguyen, Nguyen H. Tran, Yan Kyaw Tun, Zhu Han, Choong Seon\n  Hong", "title": "Toward Multiple Federated Learning Services Resource Sharing in Mobile\n  Edge Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Federated Learning is a new learning scheme for collaborative training a\nshared prediction model while keeping data locally on participating devices. In\nthis paper, we study a new model of multiple federated learning services at the\nmulti-access edge computing server. Accordingly, the sharing of CPU resources\namong learning services at each mobile device for the local training process\nand allocating communication resources among mobile devices for exchanging\nlearning information must be considered. Furthermore, the convergence\nperformance of different learning services depends on the hyper-learning rate\nparameter that needs to be precisely decided. Towards this end, we propose a\njoint resource optimization and hyper-learning rate control problem, namely\nMS-FEDL, regarding the energy consumption of mobile devices and overall\nlearning time. We design a centralized algorithm based on the block coordinate\ndescent method and a decentralized JP-miADMM algorithm for solving the MS-FEDL\nproblem. Different from the centralized approach, the decentralized approach\nrequires many iterations to obtain but it allows each learning service to\nindependently manage the local resource and learning process without revealing\nthe learning service information. Our simulation results demonstrate the\nconvergence performance of our proposed algorithms and the superior performance\nof our proposed algorithms compared to the heuristic strategy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 01:29:41 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Nguyen", "Minh N. H.", ""], ["Tran", "Nguyen H.", ""], ["Tun", "Yan Kyaw", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2011.12478", "submitter": "Ery Arias-Castro", "authors": "Ery Arias-Castro and Phong Alain Chau", "title": "Minimax Estimation of Distances on a Surface and Minimax Manifold\n  Learning in the Isometric-to-Convex Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We start by considering the problem of estimating intrinsic distances on a\nsmooth surface. We show that sharper estimates can be obtained via a\nreconstruction of the surface, and discuss the use of the tangential Delaunay\ncomplex for that purpose. We further show that the resulting approximation rate\nis in fact optimal in an information-theoretic (minimax) sense. We then turn to\nmanifold learning and argue that a variant of Isomap where the distances are\ninstead computed on a reconstructed surface is minimax optimal for the problem\nof isometric manifold embedding.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 01:57:51 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Chau", "Phong Alain", ""]]}, {"id": "2011.12482", "submitter": "Luca D'Alessio", "authors": "Luca D'Alessio and Mehrtash Babadi", "title": "CellSegmenter: unsupervised representation learning and instance\n  segmentation of modular images", "comments": "9 + 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce CellSegmenter, a structured deep generative model and an\namortized inference framework for unsupervised representation learning and\ninstance segmentation tasks. The proposed inference algorithm is convolutional\nand parallelized, without any recurrent mechanisms, and is able to resolve\nobject-object occlusion while simultaneously treating distant non-occluding\nobjects independently. This leads to extremely fast training times while\nallowing extrapolation to arbitrary number of instances. We further introduce a\ntransparent posterior regularization strategy that encourages scene\nreconstructions with fewest localized objects and a low-complexity background.\nWe evaluate our method on a challenging synthetic multi-MNIST dataset with a\nstructured background and achieve nearly perfect accuracy with only a few\nhundred training epochs. Finally, we show segmentation results obtained for a\ncell nuclei imaging dataset, demonstrating the ability of our method to provide\nhigh-quality segmentations while also handling realistic use cases involving\nlarge number of instances.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 02:10:58 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["D'Alessio", "Luca", ""], ["Babadi", "Mehrtash", ""]]}, {"id": "2011.12508", "submitter": "Xueying Ding", "authors": "Ye Yuan, Xueying Ding, Ziv Bar-Joseph", "title": "Causal inference using deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference from observation data is a core problem in many scientific\nfields. Here we present a general supervised deep learning framework that\ninfers causal interactions by transforming the input vectors to an image-like\nrepresentation for every pair of inputs. Given a training dataset we first\nconstruct a normalized empirical probability density distribution (NEPDF)\nmatrix. We then train a convolutional neural network (CNN) on NEPDFs for\ncausality predictions. We tested the method on several different simulated and\nreal world data and compared it to prior methods for causal inference. As we\nshow, the method is general, can efficiently handle very large datasets and\nimproves upon prior methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:22:14 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Yuan", "Ye", ""], ["Ding", "Xueying", ""], ["Bar-Joseph", "Ziv", ""]]}, {"id": "2011.12509", "submitter": "Aniruddha Rajendra Rao", "authors": "Aniruddha Rajendra Rao, Matthew Reimherr", "title": "Modern Multiple Imputation with Functional Data", "comments": "7 figures (including supplementary material), 8 tables (including\n  supplementary material), 14 pages (including supplementary material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work considers the problem of fitting functional models with sparsely\nand irregularly sampled functional data. It overcomes the limitations of the\nstate-of-the-art methods, which face major challenges in the fitting of more\ncomplex non-linear models. Currently, many of these models cannot be\nconsistently estimated unless the number of observed points per curve grows\nsufficiently quickly with the sample size, whereas, we show numerically that a\nmodified approach with more modern multiple imputation methods can produce\nbetter estimates in general. We also propose a new imputation approach that\ncombines the ideas of {\\it MissForest} with {\\it Local Linear Forest} and\ncompare their performance with {\\it PACE} and several other multivariate\nmultiple imputation methods. This work is motivated by a longitudinal study on\nsmoking cessation, in which the Electronic Health Records (EHR) from Penn State\nPaTH to Health allow for the collection of a great deal of data, with highly\nvariable sampling. To illustrate our approach, we explore the relation between\nrelapse and diastolic blood pressure. We also consider a variety of simulation\nschemes with varying levels of sparsity to validate our methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:22:30 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Rao", "Aniruddha Rajendra", ""], ["Reimherr", "Matthew", ""]]}, {"id": "2011.12511", "submitter": "Sen Lin", "authors": "Sen Lin, Li Yang, Zhezhi He, Deliang Fan, Junshan Zhang", "title": "MetaGater: Fast Learning of Conditional Channel Gated Networks via\n  Federated Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has achieved phenomenal successes in many AI\napplications, its enormous model size and intensive computation requirements\npose a formidable challenge to the deployment in resource-limited nodes. There\nhas recently been an increasing interest in computationally-efficient learning\nmethods, e.g., quantization, pruning and channel gating. However, most existing\ntechniques cannot adapt to different tasks quickly. In this work, we advocate a\nholistic approach to jointly train the backbone network and the channel gating\nwhich enables dynamical selection of a subset of filters for more efficient\nlocal computation given the data input. Particularly, we develop a federated\nmeta-learning approach to jointly learn good meta-initializations for both\nbackbone networks and gating modules, by making use of the model similarity\nacross learning tasks on different nodes. In this way, the learnt meta-gating\nmodule effectively captures the important filters of a good meta-backbone\nnetwork, based on which a task-specific conditional channel gated network can\nbe quickly adapted, i.e., through one-step gradient descent, from the\nmeta-initializations in a two-stage procedure using new samples of that task.\nThe convergence of the proposed federated meta-learning algorithm is\nestablished under mild conditions. Experimental results corroborate the\neffectiveness of our method in comparison to related work.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:26:23 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 16:29:36 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lin", "Sen", ""], ["Yang", "Li", ""], ["He", "Zhezhi", ""], ["Fan", "Deliang", ""], ["Zhang", "Junshan", ""]]}, {"id": "2011.12532", "submitter": "Hiroyuki Kasai", "authors": "Mitsuhiko Horie and Hiroyuki Kasai", "title": "Consistency-aware and Inconsistency-aware Graph-based Multi-view\n  Clustering", "comments": "Accepted in EUSIPCO2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-view data analysis has gained increasing popularity because multi-view\ndata are frequently encountered in machine learning applications. A simple but\npromising approach for clustering of multi-view data is multi-view clustering\n(MVC), which has been developed extensively to classify given subjects into\nsome clustered groups by learning latent common features that are shared across\nmulti-view data. Among existing approaches, graph-based multi-view clustering\n(GMVC) achieves state-of-the-art performance by leveraging a shared graph\nmatrix called the unified matrix. However, existing methods including GMVC do\nnot explicitly address inconsistent parts of input graph matrices.\nConsequently, they are adversely affected by unacceptable clustering\nperformance. To this end, this paper proposes a new GMVC method that\nincorporates consistent and inconsistent parts lying across multiple views.\nThis proposal is designated as CI-GMVC. Numerical evaluations of real-world\ndatasets demonstrate the effectiveness of the proposed CI-GMVC.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:00:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Horie", "Mitsuhiko", ""], ["Kasai", "Hiroyuki", ""]]}, {"id": "2011.12538", "submitter": "Tengteng Wen", "authors": "Tengteng Wen, Zhuofeng Mo, Jingshan Li, Qi Liu, Liming Wu and Dehan\n  Luo", "title": "An Odor Labeling Convolutional Encoder-Decoder for Odor Sensing in\n  Machine Olfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have been widely applied to visual and acoustic\ntechnology. In this paper, we proposed an odor labeling convolutional\nencoder-decoder (OLCE) for odor identification in machine olfaction. OLCE\ncomposes a convolutional neural network encoder and decoder where the encoder\noutput is constrained to odor labels. An electronic nose was used for the data\ncollection of gas responses followed by a normative experimental procedure.\nSeveral evaluation indexes were calculated to evaluate the algorithm\neffectiveness: accuracy 92.57%, precision 92.29%, recall rate 92.06%, F1-Score\n91.96%, and Kappa coefficient 90.76%. We also compared the model with some\nalgorithms used in machine olfaction. The comparison result demonstrated that\nOLCE had the best performance among these algorithms. In the paper, some\nperspectives of machine olfactions have been also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:22:02 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 06:58:33 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Wen", "Tengteng", ""], ["Mo", "Zhuofeng", ""], ["Li", "Jingshan", ""], ["Liu", "Qi", ""], ["Wu", "Liming", ""], ["Luo", "Dehan", ""]]}, {"id": "2011.12539", "submitter": "Yingying Li", "authors": "Yingying Li and Na Li", "title": "Leveraging Predictions in Smoothed Online Convex Optimization via\n  Gradient-based Algorithms", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online convex optimization with time-varying stage costs and\nadditional switching costs. Since the switching costs introduce coupling across\nall stages, multi-step-ahead (long-term) predictions are incorporated to\nimprove the online performance. However, longer-term predictions tend to suffer\nfrom lower quality. Thus, a critical question is: how to reduce the impact of\nlong-term prediction errors on the online performance? To address this\nquestion, we introduce a gradient-based online algorithm, Receding Horizon\nInexact Gradient (RHIG), and analyze its performance by dynamic regrets in\nterms of the temporal variation of the environment and the prediction errors.\nRHIG only considers at most $W$-step-ahead predictions to avoid being misled by\nworse predictions in the longer term. The optimal choice of $W$ suggested by\nour regret bounds depends on the tradeoff between the variation of the\nenvironment and the prediction accuracy. Additionally, we apply RHIG to a\nwell-established stochastic prediction error model and provide expected regret\nand concentration bounds under correlated prediction errors. Lastly, we\nnumerically test the performance of RHIG on quadrotor tracking problems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:25:51 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Li", "Yingying", ""], ["Li", "Na", ""]]}, {"id": "2011.12542", "submitter": "Hiroyuki Kasai", "authors": "Takumi Fukunaga, Hiroyuki Kasai", "title": "Wasserstein k-means with sparse simplex projection", "comments": "Accepted in ICPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a proposal of a faster Wasserstein $k$-means algorithm\nfor histogram data by reducing Wasserstein distance computations and exploiting\nsparse simplex projection. We shrink data samples, centroids, and the ground\ncost matrix, which leads to considerable reduction of the computations used to\nsolve optimal transport problems without loss of clustering quality.\nFurthermore, we dynamically reduced the computational complexity by removing\nlower-valued data samples and harnessing sparse simplex projection while\nkeeping the degradation of clustering quality lower. We designate this proposed\nalgorithm as sparse simplex projection based Wasserstein $k$-means, or SSPW\n$k$-means. Numerical evaluations conducted with comparison to results obtained\nusing Wasserstein $k$-means algorithm demonstrate the effectiveness of the\nproposed SSPW $k$-means for real-world datasets\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:37:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Fukunaga", "Takumi", ""], ["Kasai", "Hiroyuki", ""]]}, {"id": "2011.12547", "submitter": "Wei Huang", "authors": "Wei Huang, Weitao Du, Richard Yi Da Xu, and Chunrui Liu", "title": "Implicit bias of deep linear networks in the large learning rate phase", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most theoretical studies explaining the regularization effect in deep\nlearning have only focused on gradient descent with a sufficient small learning\nrate or even gradient flow (infinitesimal learning rate). Such researches,\nhowever, have neglected a reasonably large learning rate applied in most\npractical applications. In this work, we characterize the implicit bias effect\nof deep linear networks for binary classification using the logistic loss in\nthe large learning rate regime, inspired by the seminal work by Lewkowycz et\nal. [26] in a regression setting with squared loss. They found a learning rate\nregime with a large stepsize named the catapult phase, where the loss grows at\nthe early stage of training and eventually converges to a minimum that is\nflatter than those found in the small learning rate regime. We claim that\ndepending on the separation conditions of data, the gradient descent iterates\nwill converge to a flatter minimum in the catapult phase. We rigorously prove\nthis claim under the assumption of degenerate data by overcoming the difficulty\nof the non-constant Hessian of logistic loss and further characterize the\nbehavior of loss and Hessian for non-separable data. Finally, we demonstrate\nthat flatter minima in the space spanned by non-separable data along with the\nlearning rate in the catapult phase can lead to better generalization\nempirically.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 06:50:30 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 13:38:29 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Huang", "Wei", ""], ["Du", "Weitao", ""], ["Da Xu", "Richard Yi", ""], ["Liu", "Chunrui", ""]]}, {"id": "2011.12574", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh and Liang Zheng", "title": "Enhanced Scene Specificity with Sparse Dynamic Value Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-scene reinforcement learning involves training the RL agent across\nmultiple scenes / levels from the same task, and has become essential for many\ngeneralization applications. However, the inclusion of multiple scenes leads to\nan increase in sample variance for policy gradient computations, often\nresulting in suboptimal performance with the direct application of traditional\nmethods (e.g. PPO, A3C). One strategy for variance reduction is to consider\neach scene as a distinct Markov decision process (MDP) and learn a joint value\nfunction dependent on both state (s) and MDP (M). However, this is non-trivial\nas the agent is usually unaware of the underlying level at train / test times\nin multi-scene RL. Recently, Singh et al. [1] tried to address this by\nproposing a dynamic value estimation approach that models the true joint value\nfunction distribution as a Gaussian mixture model (GMM). In this paper, we\nargue that the error between the true scene-specific value function and the\npredicted dynamic estimate can be further reduced by progressively enforcing\nsparse cluster assignments once the agent has explored most of the state space.\nThe resulting agents not only show significant improvements in the final reward\nscore across a range of OpenAI ProcGen environments, but also exhibit increased\nnavigation efficiency while completing a game level.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:35:16 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2011.12581", "submitter": "Yunfei Teng", "authors": "Yunfei Teng, Anna Choromanska, Murray Campbell", "title": "Continual learning with direction-constrained optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a new design of the optimization algorithm for training\ndeep learning models with a fixed architecture of the classification network in\na continual learning framework, where the training data is non-stationary and\nthe non-stationarity is imposed by a sequence of distinct tasks. This setting\nimplies the existence of a manifold of network parameters that correspond to\ngood performance of the network on all tasks. Our algorithm is derived from the\ngeometrical properties of this manifold. We first analyze a deep model trained\non only one learning task in isolation and identify a region in network\nparameter space, where the model performance is close to the recovered optimum.\nWe provide empirical evidence that this region resembles a cone that expands\nalong the convergence direction. We study the principal directions of the\ntrajectory of the optimizer after convergence and show that traveling along a\nfew top principal directions can quickly bring the parameters outside the cone\nbut this is not the case for the remaining directions. We argue that\ncatastrophic forgetting in a continual learning setting can be alleviated when\nthe parameters are constrained to stay within the intersection of the plausible\ncones of individual tasks that were so far encountered during training.\nEnforcing this is equivalent to preventing the parameters from moving along the\ntop principal directions of convergence corresponding to the past tasks. For\neach task we introduce a new linear autoencoder to approximate its\ncorresponding top forbidden principal directions. They are then incorporated\ninto the loss function in the form of a regularization term for the purpose of\nlearning the coming tasks without forgetting. We empirically demonstrate that\nour algorithm performs favorably compared to other state-of-art\nregularization-based continual learning methods, including EWC and SI.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:45:21 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Teng", "Yunfei", ""], ["Choromanska", "Anna", ""], ["Campbell", "Murray", ""]]}, {"id": "2011.12582", "submitter": "Deheng Ye", "authors": "Deheng Ye, Guibin Chen, Peilin Zhao, Fuhao Qiu, Bo Yuan, Wen Zhang,\n  Sheng Chen, Mingfei Sun, Xiaoqian Li, Siqin Li, Jing Liang, Zhenjie Lian, Bei\n  Shi, Liang Wang, Tengfei Shi, Qiang Fu, Wei Yang, Lanxiao Huang", "title": "Supervised Learning Achieves Human-Level Performance in MOBA Games: A\n  Case Study of Honor of Kings", "comments": "IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3029475", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present JueWu-SL, the first supervised-learning-based artificial\nintelligence (AI) program that achieves human-level performance in playing\nmultiplayer online battle arena (MOBA) games. Unlike prior attempts, we\nintegrate the macro-strategy and the micromanagement of MOBA-game-playing into\nneural networks in a supervised and end-to-end manner. Tested on Honor of\nKings, the most popular MOBA at present, our AI performs competitively at the\nlevel of High King players in standard 5v5 games.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:45:55 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Ye", "Deheng", ""], ["Chen", "Guibin", ""], ["Zhao", "Peilin", ""], ["Qiu", "Fuhao", ""], ["Yuan", "Bo", ""], ["Zhang", "Wen", ""], ["Chen", "Sheng", ""], ["Sun", "Mingfei", ""], ["Li", "Xiaoqian", ""], ["Li", "Siqin", ""], ["Liang", "Jing", ""], ["Lian", "Zhenjie", ""], ["Shi", "Bei", ""], ["Wang", "Liang", ""], ["Shi", "Tengfei", ""], ["Fu", "Qiang", ""], ["Yang", "Wei", ""], ["Huang", "Lanxiao", ""]]}, {"id": "2011.12589", "submitter": "Jaskirat Singh", "authors": "Jaskirat Singh and Liang Zheng", "title": "Combining Semantic Guidance and Deep Reinforcement Learning For\n  Generating Human Level Paintings", "comments": null, "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2021, pp. 16387-16396", "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generation of stroke-based non-photorealistic imagery, is an important\nproblem in the computer vision community. As an endeavor in this direction,\nsubstantial recent research efforts have been focused on teaching machines \"how\nto paint\", in a manner similar to a human painter. However, the applicability\nof previous methods has been limited to datasets with little variation in\nposition, scale and saliency of the foreground object. As a consequence, we\nfind that these methods struggle to cover the granularity and diversity\npossessed by real world images. To this end, we propose a Semantic Guidance\npipeline with 1) a bi-level painting procedure for learning the distinction\nbetween foreground and background brush strokes at training time. 2) We also\nintroduce invariance to the position and scale of the foreground object through\na neural alignment model, which combines object localization and spatial\ntransformer networks in an end to end manner, to zoom into a particular\nsemantic instance. 3) The distinguishing features of the in-focus object are\nthen amplified by maximizing a novel guided backpropagation based focus reward.\nThe proposed agent does not require any supervision on human stroke-data and\nsuccessfully handles variations in foreground object attributes, thus,\nproducing much higher quality canvases for the CUB-200 Birds and Stanford\nCars-196 datasets. Finally, we demonstrate the further efficacy of our method\non complex datasets with multiple foreground object instances by evaluating an\nextension of our method on the challenging Virtual-KITTI dataset. Source code\nand models are available at https://github.com/1jsingh/semantic-guidance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 09:00:04 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 00:39:15 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Singh", "Jaskirat", ""], ["Zheng", "Liang", ""]]}, {"id": "2011.12598", "submitter": "Shama Islam", "authors": "Devinder Kaur, Shama Naz Islam, Md. Apel Mahmud, and ZhaoYang Dong", "title": "Energy Forecasting in Smart Grid Systems: A Review of the\n  State-of-the-art Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Energy forecasting has a vital role to play in smart grid (SG) systems\ninvolving various applications such as demand-side management, load shedding,\nand optimum dispatch. Managing efficient forecasting while ensuring the least\npossible prediction error is one of the main challenges posed in the grid\ntoday, considering the uncertainty and granularity in SG data. This paper\npresents a comprehensive and application-oriented review of state-of-the-art\nforecasting methods for SG systems along with recent developments in\nprobabilistic deep learning (PDL) considering different models and\narchitectures. Traditional point forecasting methods including statistical,\nmachine learning (ML), and deep learning (DL) are extensively investigated in\nterms of their applicability to energy forecasting. In addition, the\nsignificance of hybrid and data pre-processing techniques to support\nforecasting performance is also studied. A comparative case study using the\nVictorian electricity consumption and American electric power (AEP) datasets is\nconducted to analyze the performance of point and probabilistic forecasting\nmethods. The analysis demonstrates higher accuracy of the long-short term\nmemory (LSTM) models with appropriate hyper-parameter tuning among point\nforecasting methods especially when sample sizes are larger and involve\nnonlinear patterns with long sequences. Furthermore, Bayesian bidirectional\nLSTM (BLSTM) as a probabilistic method exhibit the highest accuracy in terms of\nleast pinball score and root mean square error (RMSE).\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 09:17:07 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 05:27:22 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kaur", "Devinder", ""], ["Islam", "Shama Naz", ""], ["Mahmud", "Md. Apel", ""], ["Dong", "ZhaoYang", ""]]}, {"id": "2011.12615", "submitter": "Andres Bustos", "authors": "A. Bustos and E. Ascasibar and A.Cappa and R. Mayo-Garcia", "title": "Automatic Identification of MHD Modes in Magnetic Fluctuations\n  Spectrograms using Deep Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.plasm-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The control and mitigation of MHD oscillations modes is an open problem in\nfusion science because they can contribute to the outward particle/energy flux\nand can drive the device away from ignition conditions. It is then of general\ninterest to extract the mode information from large experimental databases in a\nfast and reliable way. We present a software tool based on Deep Learning that\ncan identify these oscillations modes taking Mirnov coil spectrograms as input\ndata. It uses Convolutional Neural Networks that we trained with manually\nannotated spectrograms from the TJ-II stellarator database. We have tested\nseveral detector architectures, resultingin a detector AUC score of 0.99 on the\ntest set. Finally, it is applied to find MHD modes in our spectrograms to show\nhow this new software tool can be used to mine other databases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:04:35 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 11:10:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Bustos", "A.", ""], ["Ascasibar", "E.", ""], ["Cappa", "A.", ""], ["Mayo-Garcia", "R.", ""]]}, {"id": "2011.12618", "submitter": "John Chen", "authors": "John Chen, Samarth Sinha, Anastasios Kyrillidis", "title": "StackMix: A complementary Mix algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques combining multiple images as input/output have proven to be\neffective data augmentations for training convolutional neural networks. In\nthis paper, we present StackMix: Each input is presented as a concatenation of\ntwo images, and the label is the mean of the two one-hot labels. On its own,\nStackMix rivals other widely used methods in the \"Mix\" line of work. More\nimportantly, unlike previous work, significant gains across a variety of\nbenchmarks are achieved by combining StackMix with existing Mix augmentation,\neffectively mixing more than two images. E.g., by combining StackMix with\nCutMix, test error in the supervised setting is improved across a variety of\nsettings over CutMix, including 0.8\\% on ImageNet, 3\\% on Tiny ImageNet, 2\\% on\nCIFAR-100, 0.5\\% on CIFAR-10, and 1.5\\% on STL-10. Similar results are achieved\nwith Mixup.We further show that gains hold for robustness to common input\ncorruptions and perturbations at varying severities with a 0.7\\% improvement on\nCIFAR-100-C, by combining StackMix with AugMix over AugMix. On its own,\nimprovements with StackMix hold across different number of labeled samples on\nCIFAR-100, maintaining approximately a 2\\% gap in test accuracy -- down to\nusing only 5\\% of the whole dataset -- and is effective in the semi-supervised\nsetting with a 2\\% improvement with the standard benchmark $\\Pi$-model.\nFinally, we perform an extensive ablation study to better understand the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:15:24 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 16:49:41 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Chen", "John", ""], ["Sinha", "Samarth", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2011.12636", "submitter": "Prateek Katiyar Dr.", "authors": "Prateek Katiyar, Anna Khoreva", "title": "Improving Augmentation and Evaluation Schemes for Semantic Image\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite data augmentation being a de facto technique for boosting the\nperformance of deep neural networks, little attention has been paid to\ndeveloping augmentation strategies for generative adversarial networks (GANs).\nTo this end, we introduce a novel augmentation scheme designed specifically for\nGAN-based semantic image synthesis models. We propose to randomly warp object\nshapes in the semantic label maps used as an input to the generator. The local\nshape discrepancies between the warped and non-warped label maps and images\nenable the GAN to learn better the structural and geometric details of the\nscene and thus to improve the quality of generated images. While benchmarking\nthe augmented GAN models against their vanilla counterparts, we discover that\nthe quantification metrics reported in the previous semantic image synthesis\nstudies are strongly biased towards specific semantic classes as they are\nderived via an external pre-trained segmentation network. We therefore propose\nto improve the established semantic image synthesis evaluation scheme by\nanalyzing separately the performance of generated images on the biased and\nunbiased classes for the given segmentation network. Finally, we show strong\nquantitative and qualitative improvements obtained with our augmentation\nscheme, on both class splits, using state-of-the-art semantic image synthesis\nmodels across three different datasets. On average across COCO-Stuff, ADE20K\nand Cityscapes datasets, the augmented models outperform their vanilla\ncounterparts by ~3 mIoU and ~10 FID points.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:55:26 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 16:22:06 GMT"}, {"version": "v3", "created": "Sat, 30 Jan 2021 09:43:15 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Katiyar", "Prateek", ""], ["Khoreva", "Anna", ""]]}, {"id": "2011.12643", "submitter": "Christian Wallraven", "authors": "Bj\\\"orn Browatzki, J\\\"orn-Philipp Lies, Christian Wallraven", "title": "The Unreasonable Effectiveness of Encoder-Decoder Networks for Retinal\n  Vessel Segmentation", "comments": null, "journal-ref": "In: Fu H., Garvin M.K., MacGillivray T., Xu Y., Zheng Y. (eds)\n  Ophthalmic Medical Image Analysis. OMIA 2020. Lecture Notes in Computer\n  Science, vol 12069. Springer, Cham", "doi": "10.1007/978-3-030-63419-3_5", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose an encoder-decoder framework for the segmentation of blood vessels\nin retinal images that relies on the extraction of large-scale patches at\nmultiple image-scales during training. Experiments on three fundus image\ndatasets demonstrate that this approach achieves state-of-the-art results and\ncan be implemented using a simple and efficient fully-convolutional network\nwith a parameter count of less than 0.8M. Furthermore, we show that this\nframework - called VLight - avoids overfitting to specific training images and\ngeneralizes well across different datasets, which makes it highly suitable for\nreal-world applications where robustness, accuracy as well as low inference\ntime on high-resolution fundus images is required.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:10:37 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Browatzki", "Bj\u00f6rn", ""], ["Lies", "J\u00f6rn-Philipp", ""], ["Wallraven", "Christian", ""]]}, {"id": "2011.12651", "submitter": "Stefan Klus", "authors": "Patrick Gel{\\ss}, Stefan Klus, Ingmar Schuster, Christof Sch\\\"utte", "title": "Feature space approximation for kernel-based supervised learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2021.106935", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for the approximation of high- or even\ninfinite-dimensional feature vectors, which play an important role in\nsupervised learning. The goal is to reduce the size of the training data,\nresulting in lower storage consumption and computational complexity.\nFurthermore, the method can be regarded as a regularization technique, which\nimproves the generalizability of learned target functions. We demonstrate\nsignificant improvements in comparison to the computation of data-driven\npredictions involving the full training data set. The method is applied to\nclassification and regression problems from different application areas such as\nimage recognition, system identification, and oceanographic time series\nanalysis.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:23:58 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:06:34 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gel\u00df", "Patrick", ""], ["Klus", "Stefan", ""], ["Schuster", "Ingmar", ""], ["Sch\u00fctte", "Christof", ""]]}, {"id": "2011.12659", "submitter": "Francesco Tonin", "authors": "Francesco Tonin, Panagiotis Patrinos, Johan A. K. Suykens", "title": "Unsupervised learning of disentangled representations in deep restricted\n  kernel machines with orthogonality constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Constr-DRKM, a deep kernel method for the unsupervised learning\nof disentangled data representations. We propose augmenting the original deep\nrestricted kernel machine formulation for kernel PCA by orthogonality\nconstraints on the latent variables to promote disentanglement and to make it\npossible to carry out optimization without first defining a stabilized\nobjective. After illustrating an end-to-end training procedure based on a\nquadratic penalty optimization algorithm with warm start, we quantitatively\nevaluate the proposed method's effectiveness in disentangled feature learning.\nWe demonstrate on four benchmark datasets that this approach performs similarly\noverall to $\\beta$-VAE on a number of disentanglement metrics when few training\npoints are available, while being less sensitive to randomness and\nhyperparameter selection than $\\beta$-VAE. We also present a deterministic\ninitialization of Constr-DRKM's training algorithm that significantly improves\nthe reproducibility of the results. Finally, we empirically evaluate and\ndiscuss the role of the number of layers in the proposed methodology, examining\nthe influence of each principal component in every layer and showing that\ncomponents in lower layers act as local feature detectors capturing the broad\ntrends of the data distribution, while components in deeper layers use the\nrepresentation learned by previous layers and more accurately reproduce\nhigher-level features.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:40:10 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Tonin", "Francesco", ""], ["Patrinos", "Panagiotis", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2011.12661", "submitter": "Jay Santokhi", "authors": "Jay Santokhi, Pankaj Daga, Joned Sarwar, Anna Jordan, Emil Hewage", "title": "Temporal Autoencoder with U-Net Style Skip-Connections for Frame\n  Prediction", "comments": "7 pages, 3 figures, 3 tables, 4 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Finding sustainable and novel solutions to predict city-wide mobility\nbehaviour is an ever-growing problem given increased urban complexity and\ngrowing populations. This paper seeks to address this by describing a traffic\nframe prediction approach that uses Convolutional LSTMs to create a Temporal\nAutoencoder with U-Net style skip-connections that marry together recurrent and\ntraditional computer vision techniques to capture spatio-temporal dependencies\nat different scales without losing topological details of a given city.\nUtilisation of Cyclical Learning Rates is also presented, improving training\nefficiency by achieving lower loss scores in fewer epochs than standard\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:41:36 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Santokhi", "Jay", ""], ["Daga", "Pankaj", ""], ["Sarwar", "Joned", ""], ["Jordan", "Anna", ""], ["Hewage", "Emil", ""]]}, {"id": "2011.12672", "submitter": "Mattia Segu", "authors": "Mattia Segu, Alessio Tonioni, Federico Tombari", "title": "Batch Normalization Embeddings for Deep Domain Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization aims at training machine learning models to perform\nrobustly across different and unseen domains. Several recent methods use\nmultiple datasets to train models to extract domain-invariant features, hoping\nto generalize to unseen domains. Instead, first we explicitly train\ndomain-dependant representations by using ad-hoc batch normalization layers to\ncollect independent domain's statistics. Then, we propose to use these\nstatistics to map domains in a shared latent space, where membership to a\ndomain can be measured by means of a distance function. At test time, we\nproject samples from an unknown domain into the same space and infer properties\nof their domain as a linear combination of the known ones. We apply the same\nmapping strategy at training and test time, learning both a latent\nrepresentation and a powerful but lightweight ensemble model. We show a\nsignificant increase in classification accuracy over current state-of-the-art\ntechniques on popular domain generalization benchmarks: PACS, Office-31 and\nOffice-Caltech.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 12:02:57 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 17:05:19 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 09:58:12 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Segu", "Mattia", ""], ["Tonioni", "Alessio", ""], ["Tombari", "Federico", ""]]}, {"id": "2011.12684", "submitter": "Lucas Chaves Lima", "authors": "Lucas Chaves Lima, Casper Hansen, Christian Hansen, Dongsheng Wang,\n  Maria Maistro, Birger Larsen, Jakob Grue Simonsen and Christina Lioma", "title": "Denmark's Participation in the Search Engine TREC COVID-19 Challenge:\n  Lessons Learned about Searching for Precise Biomedical Scientific Information\n  on COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report describes the participation of two Danish universities,\nUniversity of Copenhagen and Aalborg University, in the international search\nengine competition on COVID-19 (the 2020 TREC-COVID Challenge) organised by the\nU.S. National Institute of Standards and Technology (NIST) and its Text\nRetrieval Conference (TREC) division. The aim of the competition was to find\nthe best search engine strategy for retrieving precise biomedical scientific\ninformation on COVID-19 from the largest, at that point in time, dataset of\ncurated scientific literature on COVID-19 -- the COVID-19 Open Research Dataset\n(CORD-19). CORD-19 was the result of a call to action to the tech community by\nthe U.S. White House in March 2020, and was shortly thereafter posted on Kaggle\nas an AI competition by the Allen Institute for AI, the Chan Zuckerberg\nInitiative, Georgetown University's Center for Security and Emerging\nTechnology, Microsoft, and the National Library of Medicine at the US National\nInstitutes of Health. CORD-19 contained over 200,000 scholarly articles (of\nwhich more than 100,000 were with full text) about COVID-19, SARS-CoV-2, and\nrelated coronaviruses, gathered from curated biomedical sources. The TREC-COVID\nchallenge asked for the best way to (a) retrieve accurate and precise\nscientific information, in response to some queries formulated by biomedical\nexperts, and (b) rank this information decreasingly by its relevance to the\nquery.\n  In this document, we describe the TREC-COVID competition setup, our\nparticipation to it, and our resulting reflections and lessons learned about\nthe state-of-art technology when faced with the acute task of retrieving\nprecise scientific information from a rapidly growing corpus of literature, in\nresponse to highly specialised queries, in the middle of a pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 12:30:38 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 12:42:21 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Lima", "Lucas Chaves", ""], ["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["Wang", "Dongsheng", ""], ["Maistro", "Maria", ""], ["Larsen", "Birger", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""]]}, {"id": "2011.12690", "submitter": "Bas van der Heijden", "authors": "Bas van der Heijden, Laura Ferranti, Jens Kober, Robert Babuska", "title": "DeepKoCo: Efficient latent planning with a robust Koopman representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents DeepKoCo, a novel model-based agent that learns a latent\nKoopman representation from images. This representation allows DeepKoCo to plan\nefficiently using linear control methods, such as linear model predictive\ncontrol. Compared to traditional agents, DeepKoCo is robust to task-irrelevant\ndynamics, thanks to the use of a tailored lossy autoencoder network that allows\nDeepKoCo to learn latent dynamics that reconstruct and predict only observed\ncosts, rather than all observed dynamics. As our results show, DeepKoCo\nachieves a similar final performance as traditional model-free methods on\ncomplex control tasks, while being considerably more robust to distractor\ndynamics, making the proposed agent more amenable for real-life applications.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 12:46:55 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 07:52:13 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["van der Heijden", "Bas", ""], ["Ferranti", "Laura", ""], ["Kober", "Jens", ""], ["Babuska", "Robert", ""]]}, {"id": "2011.12692", "submitter": "Deheng Ye", "authors": "Deheng Ye, Guibin Chen, Wen Zhang, Sheng Chen, Bo Yuan, Bo Liu, Jia\n  Chen, Zhao Liu, Fuhao Qiu, Hongsheng Yu, Yinyuting Yin, Bei Shi, Liang Wang,\n  Tengfei Shi, Qiang Fu, Wei Yang, Lanxiao Huang, Wei Liu", "title": "Towards Playing Full MOBA Games with Deep Reinforcement Learning", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MOBA games, e.g., Honor of Kings, League of Legends, and Dota 2, pose grand\nchallenges to AI systems such as multi-agent, enormous state-action space,\ncomplex action control, etc. Developing AI for playing MOBA games has raised\nmuch attention accordingly. However, existing work falls short in handling the\nraw game complexity caused by the explosion of agent combinations, i.e.,\nlineups, when expanding the hero pool in case that OpenAI's Dota AI limits the\nplay to a pool of only 17 heroes. As a result, full MOBA games without\nrestrictions are far from being mastered by any existing AI system. In this\npaper, we propose a MOBA AI learning paradigm that methodologically enables\nplaying full MOBA games with deep reinforcement learning. Specifically, we\ndevelop a combination of novel and existing learning techniques, including\ncurriculum self-play learning, policy distillation, off-policy adaption,\nmulti-head value estimation, and Monte-Carlo tree-search, in training and\nplaying a large pool of heroes, meanwhile addressing the scalability issue\nskillfully. Tested on Honor of Kings, a popular MOBA game, we show how to build\nsuperhuman AI agents that can defeat top esports players. The superiority of\nour AI is demonstrated by the first large-scale performance test of MOBA AI\nagent in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 12:52:33 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 03:30:08 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 11:58:54 GMT"}, {"version": "v4", "created": "Thu, 31 Dec 2020 13:25:17 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ye", "Deheng", ""], ["Chen", "Guibin", ""], ["Zhang", "Wen", ""], ["Chen", "Sheng", ""], ["Yuan", "Bo", ""], ["Liu", "Bo", ""], ["Chen", "Jia", ""], ["Liu", "Zhao", ""], ["Qiu", "Fuhao", ""], ["Yu", "Hongsheng", ""], ["Yin", "Yinyuting", ""], ["Shi", "Bei", ""], ["Wang", "Liang", ""], ["Shi", "Tengfei", ""], ["Fu", "Qiang", ""], ["Yang", "Wei", ""], ["Huang", "Lanxiao", ""], ["Liu", "Wei", ""]]}, {"id": "2011.12696", "submitter": "Deniz Gunceler", "authors": "Manuel Giollo, Deniz Gunceler, Yulan Liu, Daniel Willett", "title": "Bootstrap an end-to-end ASR system by multilingual training, transfer\n  learning, text-to-text mapping and synthetic audio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrapping speech recognition on limited data resources has been an area\nof active research for long. The recent transition to all-neural models and\nend-to-end (E2E) training brought along particular challenges as these models\nare known to be data hungry, but also came with opportunities around\nlanguage-agnostic representations derived from multilingual data as well as\nshared word-piece output representations across languages that share script and\nroots. We investigate here the effectiveness of different strategies to\nbootstrap an RNN-Transducer (RNN-T) based automatic speech recognition (ASR)\nsystem in the low resource regime, while exploiting the abundant resources\navailable in other languages as well as the synthetic audio from a\ntext-to-speech (TTS) engine. Our experiments demonstrate that transfer learning\nfrom a multilingual model, using a post-ASR text-to-text mapping and synthetic\naudio deliver additive improvements, allowing us to bootstrap a model for a new\nlanguage with a fraction of the data that would otherwise be needed. The best\nsystem achieved a 46% relative word error rate (WER) reduction compared to the\nmonolingual baseline, among which 25% relative WER improvement is attributed to\nthe post-ASR text-to-text mappings and the TTS synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:11:32 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 12:12:44 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Giollo", "Manuel", ""], ["Gunceler", "Deniz", ""], ["Liu", "Yulan", ""], ["Willett", "Daniel", ""]]}, {"id": "2011.12706", "submitter": "Johanna Rock", "authors": "Johanna Rock, Wolfgang Roth, Paul Meissner, Franz Pernkopf", "title": "Quantized Neural Networks for Radar Interference Mitigation", "comments": "ITEM Workshop at ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Radar sensors are crucial for environment perception of driver assistance\nsystems as well as autonomous vehicles. Key performance factors are weather\nresistance and the possibility to directly measure velocity. With a rising\nnumber of radar sensors and the so far unregulated automotive radar frequency\nband, mutual interference is inevitable and must be dealt with. Algorithms and\nmodels operating on radar data in early processing stages are required to run\ndirectly on specialized hardware, i.e. the radar sensor. This specialized\nhardware typically has strict resource-constraints, i.e. a low memory capacity\nand low computational power. Convolutional Neural Network (CNN)-based\napproaches for denoising and interference mitigation yield promising results\nfor radar processing in terms of performance. However, these models typically\ncontain millions of parameters, stored in hundreds of megabytes of memory, and\nrequire additional memory during execution. In this paper we investigate\nquantization techniques for CNN-based denoising and interference mitigation of\nradar signals. We analyze the quantization potential of different CNN-based\nmodel architectures and sizes by considering (i) quantized weights and (ii)\npiecewise constant activation functions, which results in reduced memory\nrequirements for model storage and during the inference step respectively.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:18:06 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 08:48:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Rock", "Johanna", ""], ["Roth", "Wolfgang", ""], ["Meissner", "Paul", ""], ["Pernkopf", "Franz", ""]]}, {"id": "2011.12707", "submitter": "Girmaw Abebe Tadesse", "authors": "Girmaw Abebe Tadesse, Celia Cintas, Skyler Speakman, Komminist\n  Weldemariam", "title": "Prediction of neonatal mortality in Sub-Saharan African countries using\n  data-level linkage of multiple surveys", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing datasets available to address crucial problems, such as child\nmortality and family planning discontinuation in developing countries, are not\nample for data-driven approaches. This is partly due to disjoint data\ncollection efforts employed across locations, times, and variations of\nmodalities. On the other hand, state-of-the-art methods for small data problem\nare confined to image modalities. In this work, we proposed a data-level\nlinkage of disjoint surveys across Sub-Saharan African countries to improve\nprediction performance of neonatal death and provide cross-domain\nexplainability.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:18:28 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Tadesse", "Girmaw Abebe", ""], ["Cintas", "Celia", ""], ["Speakman", "Skyler", ""], ["Weldemariam", "Komminist", ""]]}, {"id": "2011.12713", "submitter": "Nima Safari", "authors": "N. Safari, S.M. Mazhari, C.Y. Chung, S.B. Ko", "title": "A Secure Deep Probabilistic Dynamic Thermal Line Rating Prediction", "comments": "The work is accepted for publication in Journal of Modern Power\n  Systems and Clean Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurate short-term prediction of overhead line (OHL) transmission ampacity\ncan directly affect the efficiency of power system operation and planning. Any\noverestimation of the dynamic thermal line rating (DTLR) can lead to lifetime\ndegradation and failure of OHLs, safety hazards, etc. This paper presents a\nsecure yet sharp probabilistic prediction model for the hour-ahead forecasting\nof the DTLR. The security of the proposed DTLR limits the frequency of DTLR\nprediction exceeding the actual DTLR. The model is based on an augmented deep\nlearning architecture that makes use of a wide range of predictors, including\nhistorical climatology data and latent variables obtained during DTLR\ncalculation. Furthermore, by introducing a customized cost function, the deep\nneural network is trained to consider the DTLR security based on the required\nprobability of exceedance while minimizing deviations of the predicted DTLRs\nfrom the actual values. The proposed probabilistic DTLR is developed and\nverified using recorded experimental data. The simulation results validate the\nsuperiority of the proposed DTLR compared to state-of-the-art prediction models\nusing well-known evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 23:20:58 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Safari", "N.", ""], ["Mazhari", "S. M.", ""], ["Chung", "C. Y.", ""], ["Ko", "S. B.", ""]]}, {"id": "2011.12715", "submitter": "Jayant A. Gupchup", "authors": "Jayant Gupchup, Ashkan Aazami, Yaran Fan, Senja Filipi, Tom Finley,\n  Scott Inglis, Marcus Asteborg, Luke Caroll, Rajan Chari, Markus Cozowicz,\n  Vishak Gopal, Vinod Prakash, Sasikanth Bendapudi, Jack Gerrits, Eric Lau,\n  Huazhou Liu, Marco Rossi, Dima Slobodianyk, Dmitri Birjukov, Matty Cooper,\n  Nilesh Javar, Dmitriy Perednya, Sriram Srinivasan, John Langford, Ross\n  Cutler, Johannes Gehrke", "title": "Resonance: Replacing Software Constants with Context-Aware Models in\n  Real-time Communication", "comments": "Workshop on ML for Systems at NeurIPS 2020, Accepted", "journal-ref": "ML for Systems, NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NI cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large software systems tune hundreds of 'constants' to optimize their runtime\nperformance. These values are commonly derived through intuition, lab tests, or\nA/B tests. A 'one-size-fits-all' approach is often sub-optimal as the best\nvalue depends on runtime context. In this paper, we provide an experimental\napproach to replace constants with learned contextual functions for Skype - a\nwidely used real-time communication (RTC) application. We present Resonance, a\nsystem based on contextual bandits (CB). We describe experiences from three\nreal-world experiments: applying it to the audio, video, and transport\ncomponents in Skype. We surface a unique and practical challenge of performing\nmachine learning (ML) inference in large software systems written using\nencapsulation principles. Finally, we open-source FeatureBroker, a library to\nreduce the friction in adopting ML models in such development environments\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 00:34:56 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Gupchup", "Jayant", ""], ["Aazami", "Ashkan", ""], ["Fan", "Yaran", ""], ["Filipi", "Senja", ""], ["Finley", "Tom", ""], ["Inglis", "Scott", ""], ["Asteborg", "Marcus", ""], ["Caroll", "Luke", ""], ["Chari", "Rajan", ""], ["Cozowicz", "Markus", ""], ["Gopal", "Vishak", ""], ["Prakash", "Vinod", ""], ["Bendapudi", "Sasikanth", ""], ["Gerrits", "Jack", ""], ["Lau", "Eric", ""], ["Liu", "Huazhou", ""], ["Rossi", "Marco", ""], ["Slobodianyk", "Dima", ""], ["Birjukov", "Dmitri", ""], ["Cooper", "Matty", ""], ["Javar", "Nilesh", ""], ["Perednya", "Dmitriy", ""], ["Srinivasan", "Sriram", ""], ["Langford", "John", ""], ["Cutler", "Ross", ""], ["Gehrke", "Johannes", ""]]}, {"id": "2011.12719", "submitter": "Michael Luo Zhiyu", "authors": "Eric Liang, Zhanghao Wu, Michael Luo, Sven Mika, Ion Stoica", "title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem", "comments": "9 pages, 1 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researchers and practitioners in the field of reinforcement learning (RL)\nfrequently leverage parallel computation, which has led to a plethora of new\nalgorithms and systems in the last few years. In this paper, we re-examine the\nchallenges posed by distributed RL and try to view it through the lens of an\nold idea: distributed dataflow. We show that viewing RL as a dataflow problem\nleads to highly composable and performant implementations. We propose RLlib\nflow, a hybrid actor-dataflow programming model for distributed RL, and\nvalidate its practicality by porting the full suite of algorithms in RLlib, a\nwidely-adopted distributed RL library.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:28:16 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 04:55:36 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 01:10:06 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Liang", "Eric", ""], ["Wu", "Zhanghao", ""], ["Luo", "Michael", ""], ["Mika", "Sven", ""], ["Stoica", "Ion", ""]]}, {"id": "2011.12720", "submitter": "Rui Shu", "authors": "Rui Shu, Tianpei Xia, Laurie Williams, Tim Menzies", "title": "Omni: Automated Ensemble with Unexpected Models against Adversarial\n  Evasion Attack", "comments": "Submitted to EMSE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BACKGROUND: Machine learning-based security detection models have become\nprevalent in modern malware and intrusion detection systems. However, previous\nstudies show that such models are susceptible to adversarial evasion attacks.\nIn this type of attack, inputs (i.e., adversarial examples) are specially\ncrafted by intelligent malicious adversaries, with the aim of being\nmisclassified by existing state-of-the-art models (e.g., deep neural networks).\nOnce the attackers can fool a classifier to think that a malicious input is\nactually benign, they can render a machine learning-based malware or intrusion\ndetection system ineffective.\n  GOAL: To help security practitioners and researchers build a more robust\nmodel against adversarial evasion attack through the use of ensemble learning.\n  METHOD: We propose an approach called OMNI, the main idea of which is to\nexplore methods that create an ensemble of \"unexpected models\"; i.e., models\nwhose control hyperparameters have a large distance to the hyperparameters of\nan adversary's target model, with which we then make an optimized weighted\nensemble prediction.\n  RESULTS: In studies with five adversarial evasion attacks (FGSM, BIM, JSMA,\nDeepFool and Carlini-Wagner) on five security datasets (NSL-KDD, CIC-IDS-2017,\nCSE-CIC-IDS2018, CICAndMal2017 and the Contagio PDF dataset), we show that the\nimprovement rate of OMNI's prediction accuracy over attack accuracy is about\n53% (median value) across all datasets, with about 18% (median value) loss rate\nwhen comparing pre-attack accuracy and OMNI's prediction accuracy.\n  CONCLUSIONWhen using ensemble learning as a defense method against\nadversarial evasion attacks, we suggest to create ensemble with unexpected\nmodels who are distant from the attacker's expected model (i.e., target model)\nthrough methods such as hyperparameter optimization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:02:40 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Shu", "Rui", ""], ["Xia", "Tianpei", ""], ["Williams", "Laurie", ""], ["Menzies", "Tim", ""]]}, {"id": "2011.12722", "submitter": "Bing Liu", "authors": "Anzhu Yu, Wenyue Guo, Bing Liu, Xin Chen, Xin Wang, Xuefeng Cao,\n  Bingchuan Jiang", "title": "Attention Aware Cost Volume Pyramid Based Multi-view Stereo Network for\n  3D Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an efficient multi-view stereo (MVS) network for 3D reconstruction\nfrom multiview images. While previous learning based reconstruction approaches\nperformed quite well, most of them estimate depth maps at a fixed resolution\nusing plane sweep volumes with a fixed depth hypothesis at each plane, which\nrequires densely sampled planes for desired accuracy and therefore is difficult\nto achieve high resolution depth maps. In this paper we introduce a\ncoarseto-fine depth inference strategy to achieve high resolution depth. This\nstrategy estimates the depth map at coarsest level, while the depth maps at\nfiner levels are considered as the upsampled depth map from previous level with\npixel-wise depth residual. Thus, we narrow the depth searching range with\npriori information from previous level and construct new cost volumes from the\npixel-wise depth residual to perform depth map refinement. Then the final depth\nmap could be achieved iteratively since all the parameters are shared between\ndifferent levels. At each level, the self-attention layer is introduced to the\nfeature extraction block for capturing the long range dependencies for depth\ninference task, and the cost volume is generated using similarity measurement\ninstead of the variance based methods used in previous work. Experiments were\nconducted on both the DTU benchmark dataset and recently released BlendedMVS\ndataset. The results demonstrated that our model could outperform most\nstate-of-the-arts (SOTA) methods. The codebase of this project is at\nhttps://github.com/ArthasMil/AACVP-MVSNet.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:34:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yu", "Anzhu", ""], ["Guo", "Wenyue", ""], ["Liu", "Bing", ""], ["Chen", "Xin", ""], ["Wang", "Xin", ""], ["Cao", "Xuefeng", ""], ["Jiang", "Bingchuan", ""]]}, {"id": "2011.12735", "submitter": "Victor Saase", "authors": "Victor Saase, Holger Wenz, Thomas Ganslandt, Christoph Groden,\n  M\\'at\\'e E. Maros", "title": "Simple statistical methods for unsupervised brain anomaly detection on\n  MRI are competitive to deep learning methods", "comments": "20 pages, 7 figures, to be submitted to Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Statistical analysis of magnetic resonance imaging (MRI) can help\nradiologists to detect pathologies that are otherwise likely to be missed. Deep\nlearning (DL) has shown promise in modeling complex spatial data for brain\nanomaly detection. However, DL models have major deficiencies: they need large\namounts of high-quality training data, are difficult to design and train and\nare sensitive to subtle changes in scanning protocols and hardware. Here, we\nshow that also simple statistical methods such as voxel-wise (baseline and\ncovariance) models and a linear projection method using spatial patterns can\nachieve DL-equivalent (3D convolutional autoencoder) performance in\nunsupervised pathology detection. All methods were trained (N=395) and compared\n(N=44) on a novel, expert-curated multiparametric (8 sequences) head MRI\ndataset of healthy and pathological cases, respectively. We show that these\nsimple methods can be more accurate in detecting small lesions and are\nconsiderably easier to train and comprehend. The methods were quantitatively\ncompared using AUC and average precision and evaluated qualitatively on\nclinical use cases comprising brain atrophy, tumors (small metastases) and\nmovement artefacts. Our results demonstrate that while DL methods may be\nuseful, they should show a sufficiently large performance improvement over\nsimpler methods to justify their usage. Thus, simple statistical methods should\nprovide the baseline for benchmarks. Source code and trained models are\navailable on GitHub (https://github.com/vsaase/simpleBAD).\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:45:11 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Saase", "Victor", ""], ["Wenz", "Holger", ""], ["Ganslandt", "Thomas", ""], ["Groden", "Christoph", ""], ["Maros", "M\u00e1t\u00e9 E.", ""]]}, {"id": "2011.12737", "submitter": "Carlos Eduardo Rosar Kos Lassance", "authors": "Carlos Lassance, Louis B\\'ethune, Myriam Bontonou, Mounia Hamidouche,\n  Vincent Gripon", "title": "Ranking Deep Learning Generalization using Label Variation in Latent\n  Geometry Graphs", "comments": "Short paper describing submission that got the 3rd place on the\n  NeurIPS 2020 Predicting Generalization in Deep Learning (PGDL) competition.\n  We hope to update this with more analysis when the full data is made\n  available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the generalization performance of a Deep Neural Network (DNN)\nwithout relying on a validation set is a difficult task. In this work, we\npropose exploiting Latent Geometry Graphs (LGGs) to represent the latent spaces\nof trained DNN architectures. Such graphs are obtained by connecting samples\nthat yield similar latent representations at a given layer of the considered\nDNN. We then obtain a generalization score by looking at how strongly connected\nare samples of distinct classes in LGGs. This score allowed us to rank 3rd on\nthe NeurIPS 2020 Predicting Generalization in Deep Learning (PGDL) competition.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:49:21 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Lassance", "Carlos", ""], ["B\u00e9thune", "Louis", ""], ["Bontonou", "Myriam", ""], ["Hamidouche", "Mounia", ""], ["Gripon", "Vincent", ""]]}, {"id": "2011.12747", "submitter": "Gregor Simm", "authors": "Gregor N. C. Simm, Robert Pinsler, G\\'abor Cs\\'anyi and Jos\\'e Miguel\n  Hern\\'andez-Lobato", "title": "Symmetry-Aware Actor-Critic for 3D Molecular Design", "comments": null, "journal-ref": "International Conference on Learning Representations, 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating molecular design using deep reinforcement learning (RL) has the\npotential to greatly accelerate the search for novel materials. Despite recent\nprogress on leveraging graph representations to design molecules, such methods\nare fundamentally limited by the lack of three-dimensional (3D) information. In\nlight of this, we propose a novel actor-critic architecture for 3D molecular\ndesign that can generate molecular structures unattainable with previous\napproaches. This is achieved by exploiting the symmetries of the design process\nthrough a rotationally covariant state-action representation based on a\nspherical harmonics series expansion. We demonstrate the benefits of our\napproach on several 3D molecular design tasks, where we find that building in\nsuch symmetries significantly improves generalization and the quality of\ngenerated molecules.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 14:04:33 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Simm", "Gregor N. C.", ""], ["Pinsler", "Robert", ""], ["Cs\u00e1nyi", "G\u00e1bor", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2011.12750", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "AI virtues -- The missing link in putting AI ethics into practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several seminal ethics initiatives have stipulated sets of principles and\nstandards for good technology development in the AI sector. However, widespread\ncriticism has pointed out a lack of practical realization of these principles.\nFollowing that, AI ethics underwent a practical turn, but without deviating\nfrom the principled approach and the many shortcomings associated with it. This\npaper proposes a different approach. It defines four basic AI virtues, namely\njustice, honesty, responsibility and care, all of which represent specific\nmotivational settings that constitute the very precondition for ethical\ndecision making in the AI field. Moreover, it defines two second-order AI\nvirtues, prudence and fortitude, that bolster achieving the basic virtues by\nhelping with overcoming bounded ethicality or the many hidden psychological\nforces that impair ethical decision making and that are hitherto disregarded in\nAI ethics. Lastly, the paper describes measures for successfully cultivating\nthe mentioned virtues in organizations dealing with AI research and\ndevelopment.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 14:14:47 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 10:23:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "2011.12785", "submitter": "Gautam Goel", "authors": "Gautam Goel, Babak Hassibi", "title": "Regret-optimal measurement-feedback control", "comments": "arXiv admin note: text overlap with arXiv:2010.10473", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider measurement-feedback control in linear dynamical systems from the\nperspective of regret minimization. Unlike most prior work in this area, we\nfocus on the problem of designing an online controller which competes with the\noptimal dynamic sequence of control actions selected in hindsight, instead of\nthe best controller in some specific class of controllers. This formulation of\nregret is attractive when the environment changes over time and no single\ncontroller achieves good performance over the entire time horizon. We show that\nin the measurement-feedback setting, unlike in the full-information setting,\nthere is no single offline controller which outperforms every other offline\ncontroller on every disturbance, and propose a new $H_2$-optimal offline\ncontroller as a benchmark for the online controller to compete against. We show\nthat the corresponding regret-optimal online controller can be found via a\nnovel reduction to the classical Nehari problem from robust control and present\na tight data-dependent bound on its regret.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 01:36:48 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 23:14:47 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Goel", "Gautam", ""], ["Hassibi", "Babak", ""]]}, {"id": "2011.12799", "submitter": "Dani Lischinski", "authors": "Zongze Wu, Dani Lischinski, Eli Shechtman", "title": "StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation", "comments": "25 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore and analyze the latent style space of StyleGAN2, a\nstate-of-the-art architecture for image generation, using models pretrained on\nseveral different datasets. We first show that StyleSpace, the space of\nchannel-wise style parameters, is significantly more disentangled than the\nother intermediate latent spaces explored by previous works. Next, we describe\na method for discovering a large collection of style channels, each of which is\nshown to control a distinct visual attribute in a highly localized and\ndisentangled manner. Third, we propose a simple method for identifying style\nchannels that control a specific attribute, using a pretrained classifier or a\nsmall number of example images. Manipulation of visual attributes via these\nStyleSpace controls is shown to be better disentangled than via those proposed\nin previous works. To show this, we make use of a newly proposed Attribute\nDependency metric. Finally, we demonstrate the applicability of StyleSpace\ncontrols to the manipulation of real images. Our findings pave the way to\nsemantically meaningful and well-disentangled image manipulations via simple\nand intuitive interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:00:33 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 17:30:00 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wu", "Zongze", ""], ["Lischinski", "Dani", ""], ["Shechtman", "Eli", ""]]}, {"id": "2011.12807", "submitter": "Thibault Maho", "authors": "Thibault Maho, Teddy Furon, Erwan Le Merrer", "title": "SurFree: a fast surrogate-free black-box attack", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning classifiers are critically prone to evasion attacks.\nAdversarial examples are slightly modified inputs that are then misclassified,\nwhile remaining perceptively close to their originals. Last couple of years\nhave witnessed a striking decrease in the amount of queries a black box attack\nsubmits to the target classifier, in order to forge adversarials. This\nparticularly concerns the black-box score-based setup, where the attacker has\naccess to top predicted probabilites: the amount of queries went from to\nmillions of to less than a thousand. This paper presents SurFree, a geometrical\napproach that achieves a similar drastic reduction in the amount of queries in\nthe hardest setup: black box decision-based attacks (only the top-1 label is\navailable). We first highlight that the most recent attacks in that setup,\nHSJA, QEBA and GeoDA all perform costly gradient surrogate estimations. SurFree\nproposes to bypass these, by instead focusing on careful trials along diverse\ndirections, guided by precise indications of geometrical properties of the\nclassifier decision boundaries. We motivate this geometric approach before\nperforming a head-to-head comparison with previous attacks with the amount of\nqueries as a first class citizen. We exhibit a faster distortion decay under\nlow query amounts (few hundreds to a thousand), while remaining competitive at\nhigher query budgets.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:08:19 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Maho", "Thibault", ""], ["Furon", "Teddy", ""], ["Merrer", "Erwan Le", ""]]}, {"id": "2011.12815", "submitter": "Tianlin Liu", "authors": "Tianlin Liu, Anadi Chaman, David Belius, and Ivan Dokmani\\'c", "title": "Interpreting U-Nets via Task-Driven Multiscale Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  U-Nets have been tremendously successful in many imaging inverse problems. In\nan effort to understand the source of this success, we show that one can reduce\na U-Net to a tractable, well-understood sparsity-driven dictionary model while\nretaining its strong empirical performance. We achieve this by extracting a\ncertain multiscale convolutional dictionary from the standard U-Net. This\ndictionary imitates the structure of the U-Net in its convolution,\nscale-separation, and skip connection aspects, while doing away with the\nnonlinear parts. We show that this model can be trained in a task-driven\ndictionary learning framework and yield comparable results to standard U-Nets\non a number of relevant tasks, including CT and MRI reconstruction. These\nresults suggest that the success of the U-Net may be explained mainly by its\nmultiscale architecture and the induced sparse representation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:18:00 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Liu", "Tianlin", ""], ["Chaman", "Anadi", ""], ["Belius", "David", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "2011.12820", "submitter": "Kangway Chuang", "authors": "Kangway V. Chuang, Michael J. Keiser", "title": "Attention-Based Learning on Molecular Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The three-dimensional shape and conformation of small-molecule ligands are\ncritical for biomolecular recognition, yet encoding 3D geometry has not\nimproved ligand-based virtual screening approaches. We describe an end-to-end\ndeep learning approach that operates directly on small-molecule conformational\nensembles and identifies key conformational poses of small-molecules. Our\nnetworks leverage two levels of representation learning: 1) individual\nconformers are first encoded as spatial graphs using a graph neural network,\nand 2) sampled conformational ensembles are represented as sets using an\nattention mechanism to aggregate over individual instances. We demonstrate the\nfeasibility of this approach on a simple task based on bidentate coordination\nof biaryl ligands, and show how attention-based pooling can elucidate key\nconformational poses in tasks based on molecular geometry. This work\nillustrates how set-based learning approaches may be further developed for\nsmall molecule-based virtual screening.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:23:52 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chuang", "Kangway V.", ""], ["Keiser", "Michael J.", ""]]}, {"id": "2011.12829", "submitter": "Simone Rossi", "authors": "Ba-Hien Tran and Simone Rossi and Dimitrios Milios and Maurizio\n  Filippone", "title": "All You Need is a Good Functional Prior for Bayesian Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Bayesian treatment of neural networks dictates that a prior distribution\nis specified over their weight and bias parameters. This poses a challenge\nbecause modern neural networks are characterized by a large number of\nparameters, and the choice of these priors has an uncontrolled effect on the\ninduced functional prior, which is the distribution of the functions obtained\nby sampling the parameters from their prior distribution. We argue that this is\na hugely limiting aspect of Bayesian deep learning, and this work tackles this\nlimitation in a practical and effective way. Our proposal is to reason in terms\nof functional priors, which are easier to elicit, and to \"tune\" the priors of\nneural network parameters in a way that they reflect such functional priors.\nGaussian processes offer a rigorous framework to define prior distributions\nover functions, and we propose a novel and robust framework to match their\nprior with the functional prior of neural networks based on the minimization of\ntheir Wasserstein distance. We provide vast experimental evidence that coupling\nthese priors with scalable Markov chain Monte Carlo sampling offers\nsystematically large performance improvements over alternative choices of\npriors and state-of-the-art approximate Bayesian deep learning approaches. We\nconsider this work a considerable step in the direction of making the\nlong-standing challenge of carrying out a fully Bayesian treatment of neural\nnetworks, including convolutional neural networks, a concrete possibility.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:36:16 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Tran", "Ba-Hien", ""], ["Rossi", "Simone", ""], ["Milios", "Dimitrios", ""], ["Filippone", "Maurizio", ""]]}, {"id": "2011.12831", "submitter": "Angelique Dremeau", "authors": "Cl\\'ement Dorffer, Thomas Paviet-Salomon, Gilles Le Chenadec and\n  Ang\\'elique Dr\\'emeau", "title": "Learning sparse structures for physics-inspired compressed sensing", "comments": "in Proceedings of iTWIST'20, Paper-ID: 23, Nantes, France, December,\n  2-4, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In underwater acoustics, shallow water environments act as modal dispersive\nwaveguides when considering low-frequency sources. In this context, propagating\nsignals can be described as a sum of few modal components, each of them\npropagating according to its own wavenumber. Estimating these wavenumbers is of\nkey interest to understand the propagating environment as well as the emitting\nsource. To solve this problem, we proposed recently a Bayesian approach\nexploiting a sparsity-inforcing prior. When dealing with broadband sources,\nthis model can be further improved by integrating the particular dependence\nlinking the wavenumbers from one frequency to the other. In this contribution,\nwe propose to resort to a new approach relying on a restricted Boltzmann\nmachine, exploited as a generic structured sparsity-inforcing model. This\nmodel, derived from deep Bayesian networks, can indeed be efficiently learned\non physically realistic simulated data using well-known and proven algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:37:43 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 09:16:36 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dorffer", "Cl\u00e9ment", ""], ["Paviet-Salomon", "Thomas", ""], ["Chenadec", "Gilles Le", ""], ["Dr\u00e9meau", "Ang\u00e9lique", ""]]}, {"id": "2011.12847", "submitter": "Anis Sarker", "authors": "Qianwei Cheng, AKM Mahbubur Rahman, Anis Sarker, Abu Bakar Siddik\n  Nayem, Ovi Paul, Amin Ahsan Ali, M Ashraful Amin, Ryosuke Shibasaki and\n  Moinul Zaber", "title": "Deep-learning coupled with novel classification method to classify the\n  urban environment of the developing world", "comments": "Accepted paper at 2nd International Conference on Signal Processing\n  and Machine Learning (SIGML 2021); 20 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid globalization and the interdependence of humanity that engender\ntremendous in-flow of human migration towards the urban spaces. With advent of\nhigh definition satellite images, high resolution data, computational methods\nsuch as deep neural network, capable hardware; urban planning is seeing a\nparadigm shift. Legacy data on urban environments are now being complemented\nwith high-volume, high-frequency data. In this paper we propose a novel\nclassification method that is readily usable for machine analysis and show\napplicability of the methodology on a developing world setting. The\nstate-of-the-art is mostly dominated by classification of building structures,\nbuilding types etc. and largely represents the developed world which are\ninsufficient for developing countries such as Bangladesh where the surrounding\nis crucial for the classification. Moreover, the traditional methods propose\nsmall-scale classifications, which give limited information with poor\nscalability and are slow to compute. We categorize the urban area in terms of\ninformal and formal spaces taking the surroundings into account. 50 km x 50 km\nGoogle Earth image of Dhaka, Bangladesh was visually annotated and categorized\nby an expert. The classification is based broadly on two dimensions:\nurbanization and the architectural form of urban environment. Consequently, the\nurban space is divided into four classes: 1) highly informal; 2) moderately\ninformal; 3) moderately formal; and 4) highly formal areas. In total 16\nsub-classes were identified. For semantic segmentation, Google's DeeplabV3+\nmodel was used which increases the field of view of the filters to incorporate\nlarger context. Image encompassing 70% of the urban space was used for training\nand the remaining 30% was used for testing and validation. The model is able to\nsegment with 75% accuracy and 60% Mean IoU.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 16:08:07 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 18:19:44 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Cheng", "Qianwei", ""], ["Rahman", "AKM Mahbubur", ""], ["Sarker", "Anis", ""], ["Nayem", "Abu Bakar Siddik", ""], ["Paul", "Ovi", ""], ["Ali", "Amin Ahsan", ""], ["Amin", "M Ashraful", ""], ["Shibasaki", "Ryosuke", ""], ["Zaber", "Moinul", ""]]}, {"id": "2011.12854", "submitter": "Wolfgang Stammer", "authors": "Wolfgang Stammer, Patrick Schramowski and Kristian Kersting", "title": "Right for the Right Concept: Revising Neuro-Symbolic Concepts by\n  Interacting with their Explanations", "comments": null, "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2021, p. 3619-3629", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most explanation methods in deep learning map importance estimates for a\nmodel's prediction back to the original input space. These \"visual\"\nexplanations are often insufficient, as the model's actual concept remains\nelusive. Moreover, without insights into the model's semantic concept, it is\ndifficult -- if not impossible -- to intervene on the model's behavior via its\nexplanations, called Explanatory Interactive Learning. Consequently, we propose\nto intervene on a Neuro-Symbolic scene representation, which allows one to\nrevise the model on the semantic level, e.g. \"never focus on the color to make\nyour decision\". We compiled a novel confounded visual scene data set, the\nCLEVR-Hans data set, capturing complex compositions of different objects. The\nresults of our experiments on CLEVR-Hans demonstrate that our semantic\nexplanations, i.e. compositional explanations at a per-object level, can\nidentify confounders that are not identifiable using \"visual\" explanations\nonly. More importantly, feedback on this semantic level makes it possible to\nrevise the model from focusing on these factors.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 16:23:26 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 10:46:44 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 16:09:33 GMT"}, {"version": "v4", "created": "Fri, 12 Mar 2021 19:15:00 GMT"}, {"version": "v5", "created": "Tue, 16 Mar 2021 13:40:04 GMT"}, {"version": "v6", "created": "Mon, 21 Jun 2021 08:25:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Stammer", "Wolfgang", ""], ["Schramowski", "Patrick", ""], ["Kersting", "Kristian", ""]]}, {"id": "2011.12895", "submitter": "Peng Sun", "authors": "Peng Sun, Jiechao Xiong, Lei Han, Xinghai Sun, Shuxing Li, Jiawei Xu,\n  Meng Fang, Zhengyou Zhang", "title": "TLeague: A Framework for Competitive Self-Play based Distributed\n  Multi-Agent Reinforcement Learning", "comments": "21 pages, 3 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Competitive Self-Play (CSP) based Multi-Agent Reinforcement Learning (MARL)\nhas shown phenomenal breakthroughs recently. Strong AIs are achieved for\nseveral benchmarks, including Dota 2, Glory of Kings, Quake III, StarCraft II,\nto name a few. Despite the success, the MARL training is extremely data\nthirsty, requiring typically billions of (if not trillions of) frames be seen\nfrom the environment during training in order for learning a high performance\nagent. This poses non-trivial difficulties for researchers or engineers and\nprevents the application of MARL to a broader range of real-world problems. To\naddress this issue, in this manuscript we describe a framework, referred to as\nTLeague, that aims at large-scale training and implements several main-stream\nCSP-MARL algorithms. The training can be deployed in either a single machine or\na cluster of hybrid machines (CPUs and GPUs), where the standard Kubernetes is\nsupported in a cloud native manner. TLeague achieves a high throughput and a\nreasonable scale-up when performing distributed training. Thanks to the modular\ndesign, it is also easy to extend for solving other multi-agent problems or\nimplementing and verifying MARL algorithms. We present experiments over\nStarCraft II, ViZDoom and Pommerman to show the efficiency and effectiveness of\nTLeague. The code is open-sourced and available at\nhttps://github.com/tencent-ailab/tleague_projpage\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 17:24:20 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 03:23:36 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sun", "Peng", ""], ["Xiong", "Jiechao", ""], ["Han", "Lei", ""], ["Sun", "Xinghai", ""], ["Li", "Shuxing", ""], ["Xu", "Jiawei", ""], ["Fang", "Meng", ""], ["Zhang", "Zhengyou", ""]]}, {"id": "2011.12906", "submitter": "Mohsen Jafarzadeh", "authors": "Mohsen Jafarzadeh, Akshay Raj Dhamija, Steve Cruz, Chunchun Li,\n  Touqeer Ahmad, Terrance E. Boult", "title": "Open-World Learning Without Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-world learning is a problem where an autonomous agent detects things\nthat it does not know and learns them over time from a non-stationary and\nnever-ending stream of data; in an open-world environment, the training data\nand objective criteria are never available at once. The agent should grasp new\nknowledge from learning without forgetting acquired prior knowledge.\nResearchers proposed a few open-world learning agents for image classification\ntasks that operate in complex scenarios. However, all prior work on open-world\nlearning has all labeled data to learn the new classes from the stream of\nimages. In scenarios where autonomous agents should respond in near real-time\nor work in areas with limited communication infrastructure, human labeling of\ndata is not possible. Therefore, supervised open-world learning agents are not\nscalable solutions for such applications. Herein, we propose a new framework\nthat enables agents to learn new classes from a stream of unlabeled data in an\nunsupervised manner. Also, we study the robustness and learning speed of such\nagents with supervised and unsupervised feature representation. We also\nintroduce a new metric for open-world learning without labels. We anticipate\nour theories and method to be a starting point for developing autonomous true\nopen-world never-ending learning agents.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 17:41:03 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 01:39:54 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Jafarzadeh", "Mohsen", ""], ["Dhamija", "Akshay Raj", ""], ["Cruz", "Steve", ""], ["Li", "Chunchun", ""], ["Ahmad", "Touqeer", ""], ["Boult", "Terrance E.", ""]]}, {"id": "2011.12913", "submitter": "Yoshitomo Matsubara", "authors": "Yoshitomo Matsubara", "title": "torchdistill: A Modular, Configuration-Driven Framework for Knowledge\n  Distillation", "comments": "Accepted to the 3rd Workshop on Reproducible Research in Pattern\n  Recognition at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While knowledge distillation (transfer) has been attracting attentions from\nthe research community, the recent development in the fields has heightened the\nneed for reproducible studies and highly generalized frameworks to lower\nbarriers to such high-quality, reproducible deep learning research. Several\nresearchers voluntarily published frameworks used in their knowledge\ndistillation studies to help other interested researchers reproduce their\noriginal work. Such frameworks, however, are usually neither well generalized\nnor maintained, thus researchers are still required to write a lot of code to\nrefactor/build on the frameworks for introducing new methods, models, datasets\nand designing experiments. In this paper, we present our developed open-source\nframework built on PyTorch and dedicated for knowledge distillation studies.\nThe framework is designed to enable users to design experiments by declarative\nPyYAML configuration files, and helps researchers complete the recently\nproposed ML Code Completeness Checklist. Using the developed framework, we\ndemonstrate its various efficient training strategies, and implement a variety\nof knowledge distillation methods. We also reproduce some of their original\nexperimental results on the ImageNet and COCO datasets presented at major\nmachine learning conferences such as ICLR, NeurIPS, CVPR and ECCV, including\nrecent state-of-the-art methods. All the source code, configurations, log files\nand trained model weights are publicly available at\nhttps://github.com/yoshitomo-matsubara/torchdistill .\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 17:51:30 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 19:13:21 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Matsubara", "Yoshitomo", ""]]}, {"id": "2011.12916", "submitter": "Peter Holderrieth", "authors": "Peter Holderrieth, Michael Hutchinson, Yee Whye Teh", "title": "Equivariant Learning of Stochastic Fields: Gaussian Processes and\n  Steerable Conditional Neural Processes", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by objects such as electric fields or fluid streams, we study the\nproblem of learning stochastic fields, i.e. stochastic processes whose samples\nare fields like those occurring in physics and engineering. Considering general\ntransformations such as rotations and reflections, we show that spatial\ninvariance of stochastic fields requires an inference model to be equivariant.\nLeveraging recent advances from the equivariance literature, we study\nequivariance in two classes of models. Firstly, we fully characterise\nequivariant Gaussian processes. Secondly, we introduce Steerable Conditional\nNeural Processes (SteerCNPs), a new, fully equivariant member of the Neural\nProcess family. In experiments with Gaussian process vector fields, images, and\nreal-world weather data, we observe that SteerCNPs significantly improve the\nperformance of previous models and equivariance leads to improvements in\ntransfer learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:00:40 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 22:11:32 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 13:09:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Holderrieth", "Peter", ""], ["Hutchinson", "Michael", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2011.12919", "submitter": "Keshav Ganapathy", "authors": "David Tran, Alex Valtchanov, Keshav Ganapathy, Raymond Feng, Eric\n  Slud, Micah Goldblum, Tom Goldstein", "title": "Analyzing the Machine Learning Conference Review Process", "comments": "NeurIPS Workshop on Navigating the Broader Impacts of AI Research.\n  Full version at arXiv:2010.05137", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mainstream machine learning conferences have seen a dramatic increase in the\nnumber of participants, along with a growing range of perspectives, in recent\nyears. Members of the machine learning community are likely to overhear\nallegations ranging from randomness of acceptance decisions to institutional\nbias. In this work, we critically analyze the review process through a\ncomprehensive study of papers submitted to ICLR between 2017 and 2020. We\nquantify reproducibility/randomness in review scores and acceptance decisions,\nand examine whether scores correlate with paper impact. Our findings suggest\nstrong institutional bias in accept/reject decisions, even after controlling\nfor paper quality. Furthermore, we find evidence for a gender gap, with female\nauthors receiving lower scores, lower acceptance rates, and fewer citations per\npaper than their male counterparts. We conclude our work with recommendations\nfor future conference organizers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:40:27 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 01:34:24 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Tran", "David", ""], ["Valtchanov", "Alex", ""], ["Ganapathy", "Keshav", ""], ["Feng", "Raymond", ""], ["Slud", "Eric", ""], ["Goldblum", "Micah", ""], ["Goldstein", "Tom", ""]]}, {"id": "2011.12930", "submitter": "Anand Gopalakrishnan", "authors": "Anand Gopalakrishnan, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Unsupervised Object Keypoint Learning using Local Spatial Predictability", "comments": "Accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose PermaKey, a novel approach to representation learning based on\nobject keypoints. It leverages the predictability of local image regions from\nspatial neighborhoods to identify salient regions that correspond to object\nparts, which are then converted to keypoints. Unlike prior approaches, it\nutilizes predictability to discover object keypoints, an intrinsic property of\nobjects. This ensures that it does not overly bias keypoints to focus on\ncharacteristics that are not unique to objects, such as movement, shape, colour\netc. We demonstrate the efficacy of PermaKey on Atari where it learns keypoints\ncorresponding to the most salient object parts and is robust to certain visual\ndistractors. Further, on downstream RL tasks in the Atari domain we demonstrate\nhow agents equipped with our keypoints outperform those using competing\nalternatives, even on challenging environments with moving backgrounds or\ndistractor objects.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:27:05 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 15:10:29 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Gopalakrishnan", "Anand", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2011.12942", "submitter": "Itamar Winter", "authors": "Itamar Winter, Daphna Weinshall", "title": "Multiclass non-Adversarial Image Synthesis, with Application to\n  Classification from Very Small Sample", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of synthetic images is currently being dominated by Generative\nAdversarial Networks (GANs). Despite their outstanding success in generating\nrealistic looking images, they still suffer from major drawbacks, including an\nunstable and highly sensitive training procedure, mode-collapse and\nmode-mixture, and dependency on large training sets. In this work we present a\nnovel non-adversarial generative method - Clustered Optimization of LAtent\nspace (COLA), which overcomes some of the limitations of GANs, and outperforms\nGANs when training data is scarce. In the full data regime, our method is\ncapable of generating diverse multi-class images with no supervision,\nsurpassing previous non-adversarial methods in terms of image quality and\ndiversity. In the small-data regime, where only a small sample of labeled\nimages is available for training with no access to additional unlabeled data,\nour results surpass state-of-the-art GAN models trained on the same amount of\ndata. Finally, when utilizing our model to augment small datasets, we surpass\nthe state-of-the-art performance in small-sample classification tasks on\nchallenging datasets, including CIFAR-10, CIFAR-100, STL-10 and Tiny-ImageNet.\nA theoretical analysis supporting the essence of the method is presented.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:47:27 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 10:29:21 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Winter", "Itamar", ""], ["Weinshall", "Daphna", ""]]}, {"id": "2011.12945", "submitter": "Nimit Sohoni", "authors": "Nimit S. Sohoni, Jared A. Dunnmon, Geoffrey Angus, Albert Gu,\n  Christopher R\\'e", "title": "No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained\n  Classification Problems", "comments": "39 pages. Accepted as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world classification tasks, each class often comprises multiple\nfiner-grained \"subclasses.\" As the subclass labels are frequently unavailable,\nmodels trained using only the coarser-grained class labels often exhibit highly\nvariable performance across different subclasses. This phenomenon, known as\nhidden stratification, has important consequences for models deployed in\nsafety-critical applications such as medicine. We propose GEORGE, a method to\nboth measure and mitigate hidden stratification even when subclass labels are\nunknown. We first observe that unlabeled subclasses are often separable in the\nfeature space of deep models, and exploit this fact to estimate subclass labels\nfor the training data via clustering techniques. We then use these approximate\nsubclass labels as a form of noisy supervision in a distributionally robust\noptimization objective. We theoretically characterize the performance of GEORGE\nin terms of the worst-case generalization error across any subclass. We\nempirically validate GEORGE on a mix of real-world and benchmark image\nclassification datasets, and show that our approach boosts worst-case subclass\naccuracy by up to 22 percentage points compared to standard training\ntechniques, without requiring any information about the subclasses.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:50:32 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sohoni", "Nimit S.", ""], ["Dunnmon", "Jared A.", ""], ["Angus", "Geoffrey", ""], ["Gu", "Albert", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2011.12956", "submitter": "Bernardo Cortez", "authors": "Bernardo Cortez", "title": "Reinforcement Learning for Robust Missile Autopilot Design", "comments": "Masters Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing missiles' autopilot controllers has been a complex task, given the\nextensive flight envelope and the nonlinear flight dynamics. A solution that\ncan excel both in nominal performance and in robustness to uncertainties is\nstill to be found. While Control Theory often debouches into parameters'\nscheduling procedures, Reinforcement Learning has presented interesting results\nin ever more complex tasks, going from videogames to robotic tasks with\ncontinuous action domains. However, it still lacks clearer insights on how to\nfind adequate reward functions and exploration strategies. To the best of our\nknowledge, this work is pioneer in proposing Reinforcement Learning as a\nframework for flight control. In fact, it aims at training a model-free agent\nthat can control the longitudinal flight of a missile, achieving optimal\nperformance and robustness to uncertainties. To that end, under TRPO's\nmethodology, the collected experience is augmented according to HER, stored in\na replay buffer and sampled according to its significance. Not only does this\nwork enhance the concept of prioritized experience replay into BPER, but it\nalso reformulates HER, activating them both only when the training progress\nconverges to suboptimal policies, in what is proposed as the SER methodology.\nBesides, the Reward Engineering process is carefully detailed. The results show\nthat it is possible both to achieve the optimal performance and to improve the\nagent's robustness to uncertainties (with low damage on nominal performance) by\nfurther training it in non-nominal environments, therefore validating the\nproposed approach and encouraging future research in this field.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:30:04 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Cortez", "Bernardo", ""]]}, {"id": "2011.12957", "submitter": "Ahmed Mohammed", "authors": "A. Mohammed, I. Farup, M. Pedersen, S. Yildirim, and {\\O} Hovde", "title": "PS-DeVCEM: Pathology-sensitive deep learning model for video capsule\n  endoscopy based on weakly labeled data", "comments": null, "journal-ref": "Computer Vision and Image Understanding 201 (2020): 103062", "doi": "10.1016/j.cviu.2020.103062", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel pathology-sensitive deep learning model (PS-DeVCEM) for\nframe-level anomaly detection and multi-label classification of different colon\ndiseases in video capsule endoscopy (VCE) data. Our proposed model is capable\nof coping with the key challenge of colon apparent heterogeneity caused by\nseveral types of diseases. Our model is driven by attention-based deep multiple\ninstance learning and is trained end-to-end on weakly labeled data using video\nlabels instead of detailed frame-by-frame annotation. The spatial and temporal\nfeatures are obtained through ResNet50 and residual Long short-term memory\n(residual LSTM) blocks, respectively. Additionally, the learned temporal\nattention module provides the importance of each frame to the final label\nprediction. Moreover, we developed a self-supervision method to maximize the\ndistance between classes of pathologies. We demonstrate through qualitative and\nquantitative experiments that our proposed weakly supervised learning model\ngives superior precision and F1-score reaching, 61.6% and 55.1%, as compared to\nthree state-of-the-art video analysis methods respectively. We also show our\nmodel's ability to temporally localize frames with pathologies, without frame\nannotation information during training. Furthermore, we collected and annotated\nthe first and largest VCE dataset with only video labels. The dataset contains\n455 short video segments with 28,304 frames and 14 classes of colorectal\ndiseases and artifacts. Dataset and code supporting this publication will be\nmade available on our home page.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 15:33:37 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Mohammed", "A.", ""], ["Farup", "I.", ""], ["Pedersen", "M.", ""], ["Yildirim", "S.", ""], ["Hovde", "\u00d8", ""]]}, {"id": "2011.12960", "submitter": "Lars Ankile", "authors": "Lars Lien Ankile, Morgan Feet Heggland, Kjartan Krange", "title": "Deep Convolutional Neural Networks: A survey of the foundations,\n  selected improvements, and some current applications", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within the world of machine learning there exists a wide range of different\nmethods with respective advantages and applications. This paper seeks to\npresent and discuss one such method, namely Convolutional Neural Networks\n(CNNs). CNNs are deep neural networks that use a special linear operation\ncalled convolution. This operation represents a key and distinctive element of\nCNNs, and will therefore be the focus of this method paper. The discussion\nstarts with the theoretical foundations that underlie convolutions and CNNs.\nThen, the discussion proceeds to discuss some improvements and augmentations\nthat can be made to adapt the method to estimate a wider set of function\nclasses. The paper mainly investigates two ways of improving the method: by\nusing locally connected layers, which can make the network less invariant to\ntranslation, and tiled convolution, which allows for the learning of more\ncomplex invariances than standard convolution. Furthermore, the use of the Fast\nFourier Transform can improve the computational efficiency of convolution.\nSubsequently, this paper discusses two applications of convolution that have\nproven to be very effective in practice. First, the YOLO architecture is a\nstate of the art neural network for image object classification, which\naccurately predicts bounding boxes around objects in images. Second, tumor\ndetection in mammography may be performed using CNNs, accomplishing 7.2% higher\nspecificity than actual doctors with only .3% less sensitivity. Finally, the\ninvention of technology that outperforms humans in different fields also raises\ncertain ethical and regulatory questions that are briefly discussed.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 19:03:23 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ankile", "Lars Lien", ""], ["Heggland", "Morgan Feet", ""], ["Krange", "Kjartan", ""]]}, {"id": "2011.12985", "submitter": "Bichen Wu", "authors": "Bichen Wu, Qing He, Peizhao Zhang, Thilo Koehler, Kurt Keutzer, Peter\n  Vajda", "title": "FBWave: Efficient and Scalable Neural Vocoders for Streaming\n  Text-To-Speech on the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays more and more applications can benefit from edge-based\ntext-to-speech (TTS). However, most existing TTS models are too computationally\nexpensive and are not flexible enough to be deployed on the diverse variety of\nedge devices with their equally diverse computational capacities. To address\nthis, we propose FBWave, a family of efficient and scalable neural vocoders\nthat can achieve optimal performance-efficiency trade-offs for different edge\ndevices. FBWave is a hybrid flow-based generative model that combines the\nadvantages of autoregressive and non-autoregressive models. It produces high\nquality audio and supports streaming during inference while remaining highly\ncomputationally efficient. Our experiments show that FBWave can achieve similar\naudio quality to WaveRNN while reducing MACs by 40x. More efficient variants of\nFBWave can achieve up to 109x fewer MACs while still delivering acceptable\naudio quality. Audio demos are available at\nhttps://bichenwu09.github.io/vocoder_demos.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 19:09:49 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wu", "Bichen", ""], ["He", "Qing", ""], ["Zhang", "Peizhao", ""], ["Koehler", "Thilo", ""], ["Keutzer", "Kurt", ""], ["Vajda", "Peter", ""]]}, {"id": "2011.12988", "submitter": "Shahana Ibrahim", "authors": "Shahana Ibrahim, Xiao Fu", "title": "Mixed Membership Graph Clustering via Systematic Edge Query", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers clustering nodes of a largely incomplete graph. Under the\nproblem setting, only a small amount of queries about the edges can be made,\nbut the entire graph is not observable. This problem finds applications in\nlarge-scale data clustering using limited annotations, community detection\nunder restricted survey resources, and graph topology inference under\nhidden/removed node interactions. Prior works tackled this problem from various\nperspectives, e.g., convex programming-based low-rank matrix completion and\nactive query-based clique finding. Nonetheless, many existing methods are\ndesigned for estimating the single-cluster membership of the nodes, but nodes\nmay often have mixed (i.e., multi-cluster) membership in practice. Some query\nand computational paradigms, e.g., the random query patterns and nuclear\nnorm-based optimization advocated in the convex approaches, may give rise to\nscalability and implementation challenges. This work aims at learning mixed\nmembership of nodes using queried edges. The proposed method is developed\ntogether with a systematic query principle that can be controlled and adjusted\nby the system designers to accommodate implementation challenges -- e.g., to\navoid querying edges that are physically hard to acquire. Our framework also\nfeatures a lightweight and scalable algorithm with membership learning\nguarantees. Real-data experiments on crowdclustering and community detection\nare used to showcase the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 19:19:05 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 04:07:43 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ibrahim", "Shahana", ""], ["Fu", "Xiao", ""]]}, {"id": "2011.13000", "submitter": "Reena Elangovan", "authors": "Reena Elangovan, Shubham Jain, Anand Raghunathan", "title": "Ax-BxP: Approximate Blocked Computation for Precision-Reconfigurable\n  Deep Neural Network Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision scaling has emerged as a popular technique to optimize the compute\nand storage requirements of Deep Neural Networks (DNNs). Efforts toward\ncreating ultra-low-precision (sub-8-bit) DNNs suggest that the minimum\nprecision required to achieve a given network-level accuracy varies\nconsiderably across networks, and even across layers within a network,\nrequiring support for variable precision in DNN hardware. Previous proposals\nsuch as bit-serial hardware incur high overheads, significantly diminishing the\nbenefits of lower precision. To efficiently support precision\nre-configurability in DNN accelerators, we introduce an approximate computing\nmethod wherein DNN computations are performed block-wise (a block is a group of\nbits) and re-configurability is supported at the granularity of blocks. Results\nof block-wise computations are composed in an approximate manner to enable\nefficient re-configurability. We design a DNN accelerator that embodies\napproximate blocked computation and propose a method to determine a suitable\napproximation configuration for a given DNN. By varying the approximation\nconfigurations across DNNs, we achieve 1.17x-1.73x and 1.02x-2.04x improvement\nin system energy and performance respectively, over an 8-bit fixed-point (FxP8)\nbaseline, with negligible loss in classification accuracy. Further, by varying\nthe approximation configurations across layers and data-structures within DNNs,\nwe achieve 1.25x-2.42x and 1.07x-2.95x improvement in system energy and\nperformance respectively, with negligible accuracy loss.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 20:00:38 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 15:35:56 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Elangovan", "Reena", ""], ["Jain", "Shubham", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2011.13006", "submitter": "Mervyn OLuing Mr", "authors": "Mervyn O'Luing, Steven Prestwich, S. Armagan Tarim", "title": "A Simulated Annealing Algorithm for Joint Stratification and Sample\n  Allocation Designs", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study combined simulated annealing with delta evaluation to solve the\njoint stratification and sample allocation problem. In this problem, atomic\nstrata are partitioned into mutually exclusive and collectively exhaustive\nstrata. Each stratification is a solution, the quality of which is measured by\nits cost. The Bell number of possible solutions is enormous for even a moderate\nnumber of atomic strata and an additional layer of complexity is added with the\nevaluation time of each solution. Many larger scale combinatorial optimisation\nproblems cannot be solved to optimality because the search for an optimum\nsolution requires a prohibitive amount of computation time; a number of local\nsearch heuristic algorithms have been designed for this problem but these can\nbecome trapped in local minima preventing any further improvements. We add to\nthe existing suite of local search algorithms with a simulated annealing\nalgorithm that allows for an escape from local minima and uses delta evaluation\nto exploit the similarity between consecutive solutions and thereby reduce the\nevaluation time.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 20:27:49 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["O'Luing", "Mervyn", ""], ["Prestwich", "Steven", ""], ["Tarim", "S. Armagan", ""]]}, {"id": "2011.13011", "submitter": "Tianyu Han", "authors": "Tianyu Han, Sven Nebelung, Federico Pedersoli, Markus Zimmermann,\n  Maximilian Schulze-Hagen, Michael Ho, Christoph Haarburger, Fabian Kiessling,\n  Christiane Kuhl, Volkmar Schulz, Daniel Truhn", "title": "Advancing diagnostic performance and clinical usability of neural\n  networks via adversarial training and dual batch normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmasking the decision-making process of machine learning models is essential\nfor implementing diagnostic support systems in clinical practice. Here, we\ndemonstrate that adversarially trained models can significantly enhance the\nusability of pathology detection as compared to their standard counterparts. We\nlet six experienced radiologists rate the interpretability of saliency maps in\ndatasets of X-rays, computed tomography, and magnetic resonance imaging scans.\nSignificant improvements were found for our adversarial models, which could be\nfurther improved by the application of dual batch normalization. Contrary to\nprevious research on adversarially trained models, we found that the accuracy\nof such models was equal to standard models when sufficiently large datasets\nand dual batch norm training were used. To ensure transferability, we\nadditionally validated our results on an external test set of 22,433 X-rays.\nThese findings elucidate that different paths for adversarial and real images\nare needed during training to achieve state of the art results with superior\nclinical interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 20:41:01 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Han", "Tianyu", ""], ["Nebelung", "Sven", ""], ["Pedersoli", "Federico", ""], ["Zimmermann", "Markus", ""], ["Schulze-Hagen", "Maximilian", ""], ["Ho", "Michael", ""], ["Haarburger", "Christoph", ""], ["Kiessling", "Fabian", ""], ["Kuhl", "Christiane", ""], ["Schulz", "Volkmar", ""], ["Truhn", "Daniel", ""]]}, {"id": "2011.13026", "submitter": "Davis Wertheimer", "authors": "Davis Wertheimer, Omid Poursaeed and Bharath Hariharan", "title": "Augmentation-Interpolative AutoEncoders for Unsupervised Few-Shot Image\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We aim to build image generation models that generalize to new domains from\nfew examples. To this end, we first investigate the generalization properties\nof classic image generators, and discover that autoencoders generalize\nextremely well to new domains, even when trained on highly constrained data. We\nleverage this insight to produce a robust, unsupervised few-shot image\ngeneration algorithm, and introduce a novel training procedure based on\nrecovering an image from data augmentations. Our Augmentation-Interpolative\nAutoEncoders synthesize realistic images of novel objects from only a few\nreference images, and outperform both prior interpolative models and supervised\nfew-shot image generators. Our procedure is simple and lightweight, generalizes\nbroadly, and requires no category labels or other supervision during training.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 21:18:55 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wertheimer", "Davis", ""], ["Poursaeed", "Omid", ""], ["Hariharan", "Bharath", ""]]}, {"id": "2011.13032", "submitter": "Grace Abuhamad", "authors": "Grace Abuhamad and Claudel Rheault", "title": "Like a Researcher Stating Broader Impact For the Very First Time", "comments": "Navigating the Broader Impacts of AI Research Workshop at the 34th\n  Conference on Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In requiring that a statement of broader impact accompany all submissions for\nthis year's conference, the NeurIPS program chairs made ethics part of the\nstake in groundbreaking AI research. While there is precedent from other fields\nand increasing awareness within the NeurIPS community, this paper seeks to\nanswer the question of how individual researchers reacted to the new\nrequirement, including not just their views, but also their experience in\ndrafting and their reflections after paper acceptances. We present survey\nresults and considerations to inform the next iteration of the broader impact\nrequirement should it remain a requirement for future NeurIPS conferences.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 21:32:29 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Abuhamad", "Grace", ""], ["Rheault", "Claudel", ""]]}, {"id": "2011.13034", "submitter": "Jingfeng Wu", "authors": "Jingfeng Wu, Vladimir Braverman, Lin F. Yang", "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity\n  for Multi-Objective Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider multi-objective reinforcement learning where the\nobjectives are balanced using preferences. In practice, the preferences are\noften given in an adversarial manner, e.g., customers can be picky in many\napplications. We formalize this problem as an episodic learning problem on a\nMarkov decision process, where transitions are unknown and a reward function is\nthe inner product of a preference vector with pre-specified multi-objective\nreward functions. We consider two settings. In the online setting, the agent\nreceives a (adversarial) preference every episode and proposes policies to\ninteract with the environment. We provide a model-based algorithm that achieves\na nearly minimax optimal regret bound\n$\\widetilde{\\mathcal{O}}\\bigl(\\sqrt{\\min\\{d,S\\}\\cdot H^2 SAK}\\bigr)$, where $d$\nis the number of objectives, $S$ is the number of states, $A$ is the number of\nactions, $H$ is the length of the horizon, and $K$ is the number of episodes.\nFurthermore, we consider preference-free exploration, i.e., the agent first\ninteracts with the environment without specifying any preference and then is\nable to accommodate arbitrary preference vector up to $\\epsilon$ error. Our\nproposed algorithm is provably efficient with a nearly optimal trajectory\ncomplexity $\\widetilde{\\mathcal{O}}\\bigl({\\min\\{d,S\\}\\cdot H^3\nSA}/{\\epsilon^2}\\bigr)$. This result partly resolves an open problem raised by\n\\citet{jin2020reward}.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 21:45:04 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 01:33:11 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wu", "Jingfeng", ""], ["Braverman", "Vladimir", ""], ["Yang", "Lin F.", ""]]}, {"id": "2011.13042", "submitter": "Cheng-Hao Liu", "authors": "Cheng-Hao Liu, Maksym Korablyov, Stanis{\\l}aw Jastrz\\k{e}bski,\n  Pawe{\\l} W{\\l}odarczyk-Pruszy\\'nski, Yoshua Bengio, Marwin H. S. Segler", "title": "RetroGNN: Approximating Retrosynthesis by Graph Neural Networks for De\n  Novo Drug Design", "comments": "Machine Learning for Molecules Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo molecule generation often results in chemically unfeasible molecules.\nA natural idea to mitigate this problem is to bias the search process towards\nmore easily synthesizable molecules using a proxy for synthetic accessibility.\nHowever, using currently available proxies still results in highly unrealistic\ncompounds. We investigate the feasibility of training deep graph neural\nnetworks to approximate the outputs of a retrosynthesis planning software, and\ntheir use to bias the search process. We evaluate our method on a benchmark\ninvolving searching for drug-like molecules with antibiotic properties.\nCompared to enumerating over five million existing molecules from the ZINC\ndatabase, our approach finds molecules predicted to be more likely to be\nantibiotics while maintaining good drug-like properties and being easily\nsynthesizable. Importantly, our deep neural network can successfully filter out\nhard to synthesize molecules while achieving a $10^5$ times speed-up over using\nthe retrosynthesis planning software.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 22:04:16 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Liu", "Cheng-Hao", ""], ["Korablyov", "Maksym", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""], ["W\u0142odarczyk-Pruszy\u0144ski", "Pawe\u0142", ""], ["Bengio", "Yoshua", ""], ["Segler", "Marwin H. S.", ""]]}, {"id": "2011.13045", "submitter": "Homer Walke", "authors": "Homer Walke, R. Kenny Jones, Daniel Ritchie", "title": "Learning to Infer Shape Programs Using Latent Execution Self Training", "comments": "15 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring programs which generate 2D and 3D shapes is important for reverse\nengineering, enabling shape editing, and more. Supervised learning is hard to\napply to this problem, as paired (program, shape) data rarely exists. Recent\napproaches use supervised pre-training with randomly-generated programs and\nthen refine using self-supervised learning. But self-supervised learning either\nrequires that the program execution process be differentiable or relies on\nreinforcement learning, which is unstable and slow to converge. In this paper,\nwe present a new approach for learning to infer shape programs, which we call\nlatent execution self training (LEST). As with recent prior work, LEST starts\nby training on randomly-generated (program, shape) pairs. As its name implies,\nit is based on the idea of self-training: running a model on unlabeled input\nshapes, treating the predicted programs as ground truth latent labels, and\ntraining again. Self-training is known to be susceptible to local minima. LEST\ncircumvents this problem by leveraging the fact that predicted latent programs\nare executable: for a given shape $\\mathbf{x}^* \\in S^*$ and its predicted\nprogram $\\mathbf{z} \\in P$, we execute $\\mathbf{z}$ to obtain a shape\n$\\mathbf{x} \\in S$ and train on $(\\mathbf{z} \\in P, \\mathbf{x} \\in S)$ pairs,\nrather than $(\\mathbf{z} \\in P, \\mathbf{x}^* \\in S^*)$ pairs. Experiments show\nthat the distribution of executed shapes $S$ converges toward the distribution\nof real shapes $S^*$. We establish connections between LEST and algorithms for\nlearning generative models, including variational Bayes, wake sleep, and\nexpectation maximization. For constructive solid geometry and assembly-based\nmodeling, LEST's inferred programs converge to high reconstruction accuracy\nsignificantly faster than those of reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 22:10:32 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Walke", "Homer", ""], ["Jones", "R. Kenny", ""], ["Ritchie", "Daniel", ""]]}, {"id": "2011.13052", "submitter": "Haohan Wang", "authors": "Haohan Wang, Zeyi Huang, Xindi Wu, Eric P. Xing", "title": "Squared $\\ell_2$ Norm as Consistency Loss for Leveraging Augmented Data\n  to Learn Robust and Invariant Representations", "comments": "12 pages and an additional 9 pages as appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data augmentation is one of the most popular techniques for improving the\nrobustness of neural networks. In addition to directly training the model with\noriginal samples and augmented samples, a torrent of methods regularizing the\ndistance between embeddings/representations of the original samples and their\naugmented counterparts have been introduced. In this paper, we explore these\nvarious regularization choices, seeking to provide a general understanding of\nhow we should regularize the embeddings. Our analysis suggests the ideal\nchoices of regularization correspond to various assumptions. With an invariance\ntest, we argue that regularization is important if the model is to be used in a\nbroader context than the accuracy-driven setting because non-regularized\napproaches are limited in learning the concept of invariance, despite equally\nhigh accuracy. Finally, we also show that the generic approach we identified\n(squared $\\ell_2$ norm regularized augmentation) outperforms several recent\nmethods, which are each specially designed for one task and significantly more\ncomplicated than ours, over three different tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 22:40:09 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wang", "Haohan", ""], ["Huang", "Zeyi", ""], ["Wu", "Xindi", ""], ["Xing", "Eric P.", ""]]}, {"id": "2011.13071", "submitter": "Shrikanth N.C.", "authors": "N.C. Shrikanth, Suvodeep Majumder and Tim Menzies", "title": "Early Life Cycle Software Defect Prediction. Why? How?", "comments": "12 pages (To appear ICSE 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers assume that, for software analytics, \"more data is better.\"\nWe write to show that, at least for learning defect predictors, this may not be\ntrue. To demonstrate this, we analyzed hundreds of popular GitHub projects.\nThese projects ran for 84 months and contained 3,728 commits (median values).\nAcross these projects, most of the defects occur very early in their life\ncycle. Hence, defect predictors learned from the first 150 commits and four\nmonths perform just as well as anything else. This means that, at least for the\nprojects studied here, after the first few months, we need not continually\nupdate our defect prediction models. We hope these results inspire other\nresearchers to adopt a \"simplicity-first\" approach to their work. Some domains\nrequire a complex and data-hungry analysis. But before assuming complexity, it\nis prudent to check the raw data looking for \"short cuts\" that can simplify the\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 00:13:52 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 16:36:50 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 01:13:15 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Shrikanth", "N. C.", ""], ["Majumder", "Suvodeep", ""], ["Menzies", "Tim", ""]]}, {"id": "2011.13073", "submitter": "Rafael Lima Goncalves de", "authors": "Rafael Lima", "title": "Hawkes Processes Modeling, Inference and Control: An Overview", "comments": "Fixed typos. Included pseudocodes for simulation algorithms. Improved\n  figures. Included tables with complexity and performance comparisons.\n  Included new sections on Current Challenges and Application Examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hawkes Processes are a type of point process which models self-excitement\namong time events. It has been used in a myriad of applications, ranging from\nfinance and earthquakes to crime rates and social network activity\nanalysis.Recently, a surge of different tools and algorithms have showed their\nway up to top-tier Machine Learning conferences. This work aims to give a broad\nview of the recent advances on the Hawkes Processes modeling and inference to a\nnewcomer to the field.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 00:28:58 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 18:34:54 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Lima", "Rafael", ""]]}, {"id": "2011.13074", "submitter": "Peng Zhou", "authors": "Peng Zhou, Lingxi Xie, Bingbing Ni, Cong Geng, Qi Tian", "title": "Omni-GAN: On the Secrets of cGANs and Beyond", "comments": "Introducing Omni-INR-GAN, which can extrapolate low-resolution images\n  to arbitrary resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional generative adversarial network (cGAN) is a powerful tool of\ngenerating high-quality images, but existing approaches mostly suffer\nunsatisfying performance or the risk of mode collapse. This paper presents\nOmni-GAN, a variant of cGAN that reveals the devil in designing a proper\ndiscriminator for training the model. The key is to ensure that the\ndiscriminator receives strong supervision to perceive the concepts and moderate\nregularization to avoid collapse. Omni-GAN is easily implemented and freely\nintegrated with off-the-shelf encoding methods (e.g., implicit neural\nrepresentation, INR). Experiments validate the superior performance of Omni-GAN\nand Omni-INR-GAN in a wide range of image generation and restoration tasks. In\nparticular, Omni-INR-GAN sets new records on the ImageNet dataset with\nimpressive Inception scores of 262.85 and 343.22 for the image sizes of 128 and\n256, respectively, surpassing the previous records by 100+ points. Moreover,\nleveraging the generator prior, Omni-INR-GAN can extrapolate low-resolution\nimages to arbitrary resolution, even up to x60+ higher resolution. Code is\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 00:30:20 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 05:33:05 GMT"}, {"version": "v3", "created": "Mon, 29 Mar 2021 03:00:44 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhou", "Peng", ""], ["Xie", "Lingxi", ""], ["Ni", "Bingbing", ""], ["Geng", "Cong", ""], ["Tian", "Qi", ""]]}, {"id": "2011.13077", "submitter": "Jordan Trinka", "authors": "Jordan Trinka and Hossein Haghbin and Mehdi Maadooliat", "title": "Functional Time Series Forecasting: Functional Singular Spectrum\n  Analysis Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose two nonparametric methods used in the forecasting\nof functional time-dependent data, namely functional singular spectrum analysis\nrecurrent forecasting and vector forecasting. Both algorithms utilize the\nresults of functional singular spectrum analysis and past observations in order\nto predict future data points where recurrent forecasting predicts one function\nat a time and the vector forecasting makes predictions using functional\nvectors. We compare our forecasting methods to a gold standard algorithm used\nin the prediction of functional, time-dependent data by way of simulation and\nreal data and we find our techniques do better for periodic stochastic\nprocesses.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 00:36:57 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 05:41:48 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 19:25:31 GMT"}, {"version": "v4", "created": "Tue, 26 Jan 2021 20:38:44 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Trinka", "Jordan", ""], ["Haghbin", "Hossein", ""], ["Maadooliat", "Mehdi", ""]]}, {"id": "2011.13093", "submitter": "Sanghwa Lee", "authors": "Sanghwa Lee, Jaeyoung Lee, Ichiro Hasuo", "title": "Predictive PER: Balancing Priority and Diversity towards Stable Deep\n  Reinforcement Learning", "comments": "Presented at Deep Reinforcement Learning Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prioritized experience replay (PER) samples important transitions, rather\nthan uniformly, to improve the performance of a deep reinforcement learning\nagent. We claim that such prioritization has to be balanced with sample\ndiversity for making the DQN stabilized and preventing forgetting. Our proposed\nimprovement over PER, called Predictive PER (PPER), takes three countermeasures\n(TDInit, TDClip, TDPred) to (i) eliminate priority outliers and explosions and\n(ii) improve the sample diversity and distributions, weighted by priorities,\nboth leading to stabilizing the DQN. The most notable among the three is the\nintroduction of the second DNN called TDPred to generalize the in-distribution\npriorities. Ablation study and full experiments with Atari games show that each\ncountermeasure by its own way and PPER contribute to successfully enhancing\nstability and thus performance over PER.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 02:12:31 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Lee", "Sanghwa", ""], ["Lee", "Jaeyoung", ""], ["Hasuo", "Ichiro", ""]]}, {"id": "2011.13094", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Minsu Cho, Seungjin Choi", "title": "Combinatorial Bayesian Optimization with Random Mapping Functions to\n  Convex Polytope", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a popular method for solving the problem of global\noptimization of an expensive-to-evaluate black-box function. It relies on a\nprobabilistic surrogate model of the objective function, upon which an\nacquisition function is built to determine where next to evaluate the objective\nfunction. In general, Bayesian optimization with Gaussian process regression\noperates on a continuous space. When input variables are categorical or\ndiscrete, an extra care is needed. A common approach is to use one-hot encoded\nor Boolean representation for categorical variables which might yield a {\\em\ncombinatorial explosion} problem. In this paper we present a method for\nBayesian optimization in a combinatorial space, which can operate well in a\nlarge combinatorial space. The main idea is to use a random mapping which\nembeds the combinatorial space into a convex polytope in a continuous space, on\nwhich all essential process is performed to determine a solution to the\nblack-box optimization in the combinatorial space. We describe our {\\em\ncombinatorial Bayesian optimization} algorithm and present its regret analysis.\nNumerical experiments demonstrate that our method outperforms existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 02:22:41 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kim", "Jungtaek", ""], ["Cho", "Minsu", ""], ["Choi", "Seungjin", ""]]}, {"id": "2011.13101", "submitter": "Stephen Tu", "authors": "Nicholas M. Boffi and Stephen Tu and Jean-Jacques E. Slotine", "title": "Regret Bounds for Adaptive Nonlinear Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of adaptively controlling a known discrete-time\nnonlinear system subject to unmodeled disturbances. We prove the first\nfinite-time regret bounds for adaptive nonlinear control with matched\nuncertainty in the stochastic setting, showing that the regret suffered by\ncertainty equivalence adaptive control, compared to an oracle controller with\nperfect knowledge of the unmodeled disturbances, is upper bounded by\n$\\widetilde{O}(\\sqrt{T})$ in expectation. Furthermore, we show that when the\ninput is subject to a $k$ timestep delay, the regret degrades to\n$\\widetilde{O}(k \\sqrt{T})$. Our analysis draws connections between classical\nstability notions in nonlinear control theory (Lyapunov stability and\ncontraction theory) and modern regret analysis from online convex optimization.\nThe use of stability theory allows us to analyze the challenging\ninfinite-horizon single trajectory setting.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 03:01:09 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Boffi", "Nicholas M.", ""], ["Tu", "Stephen", ""], ["Slotine", "Jean-Jacques E.", ""]]}, {"id": "2011.13113", "submitter": "David Romain Djoumbissie", "authors": "Djoumbissie David Romain", "title": "Predicting S&P500 Index direction with Transfer Learning and a Causal\n  Graph as main Input", "comments": "Revised description in section II", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified multi-tasking framework to represent the complex and\nuncertain causal process of financial market dynamics, and then to predict the\nmovement of any type of index with an application on the monthly direction of\nthe S&P500 index. our solution is based on three main pillars: (i) the use of\ntransfer learning to share knowledge and feature (representation, learning)\nbetween all financial markets, increase the size of the training sample and\npreserve the stability between training, validation and test sample. (ii) The\ncombination of multidisciplinary knowledge (Financial economics, behavioral\nfinance, market microstructure and portfolio construction theories) to\nrepresent a global top-down dynamics of any financial market, through a graph.\n(iii) The integration of forward looking unstructured data, different types of\ncontexts (long, medium and short term) through latent variables/nodes and then,\nuse a unique VAE network (parameter sharing) to learn simultaneously their\ndistributional representation. We obtain Accuracy, F1-score, and Matthew\nCorrelation of 74.3 %, 67 % and 0.42 above the industry and other benchmark on\n12 years test period which include three unstable and difficult sub-period to\npredict.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 03:45:51 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 23:44:32 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Romain", "Djoumbissie David", ""]]}, {"id": "2011.13120", "submitter": "Jeonghoon Park", "authors": "Jeonghoon Park, Kyungmin Jo, Daehoon Gwak, Jimin Hong, Jaegul Choo,\n  Edward Choi", "title": "Evaluation of Out-of-Distribution Detection Performance of\n  Self-Supervised Learning in a Controllable Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the out-of-distribution (OOD) detection performance of\nself-supervised learning (SSL) techniques with a new evaluation framework.\nUnlike the previous evaluation methods, the proposed framework adjusts the\ndistance of OOD samples from the in-distribution samples. We evaluate an\nextensive combination of OOD detection algorithms on three different\nimplementations of the proposed framework using simulated samples, images, and\ntext. SSL methods consistently demonstrated the improved OOD detection\nperformance in all evaluation settings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 04:11:48 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Park", "Jeonghoon", ""], ["Jo", "Kyungmin", ""], ["Gwak", "Daehoon", ""], ["Hong", "Jimin", ""], ["Choo", "Jaegul", ""], ["Choi", "Edward", ""]]}, {"id": "2011.13132", "submitter": "Xing Yan", "authors": "Xiangqian Sun, Xing Yan, Qi Wu", "title": "Generative Learning of Heterogeneous Tail Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multivariate generative model to capture the complex dependence\nstructure often encountered in business and financial data. Our model features\nheterogeneous and asymmetric tail dependence between all pairs of individual\ndimensions while also allowing heterogeneity and asymmetry in the tails of the\nmarginals. A significant merit of our model structure is that it is not prone\nto error propagation in the parameter estimation process, hence very scalable,\nas the dimensions of datasets grow large. However, the likelihood methods are\ninfeasible for parameter estimation in our case due to the lack of a\nclosed-form density function. Instead, we devise a novel moment learning\nalgorithm to learn the parameters. To demonstrate the effectiveness of the\nmodel and its estimator, we test them on simulated as well as real-world\ndatasets. Results show that this framework gives better finite-sample\nperformance compared to the copula-based benchmarks as well as recent similar\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 05:34:31 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Sun", "Xiangqian", ""], ["Yan", "Xing", ""], ["Wu", "Qi", ""]]}, {"id": "2011.13137", "submitter": "Yifan Gao", "authors": "Yifan Gao, Henghui Zhu, Patrick Ng, Cicero Nogueira dos Santos, Zhiguo\n  Wang, Feng Nan, Dejiao Zhang, Ramesh Nallapati, Andrew O. Arnold, Bing Xiang", "title": "Answering Ambiguous Questions through Generative Evidence Fusion and\n  Round-Trip Prediction", "comments": "ACL 2021 main conference, 14 pages, 7 figures. Code will be released\n  at https://github.com/amzn/refuel-open-domain-qa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In open-domain question answering, questions are highly likely to be\nambiguous because users may not know the scope of relevant topics when\nformulating them. Therefore, a system needs to find possible interpretations of\nthe question, and predict one or multiple plausible answers. When multiple\nplausible answers are found, the system should rewrite the question for each\nanswer to resolve the ambiguity. In this paper, we present a model that\naggregates and combines evidence from multiple passages to adaptively predict a\nsingle answer or a set of question-answer pairs for ambiguous questions. In\naddition, we propose a novel round-trip prediction approach to iteratively\ngenerate additional interpretations that our model fails to find in the first\npass, and then verify and filter out the incorrect question-answer pairs to\narrive at the final disambiguated output. Our model, named Refuel, achieves a\nnew state-of-the-art performance on the AmbigQA dataset, and shows competitive\nperformance on NQ-Open and TriviaQA. The proposed round-trip prediction is a\nmodel-agnostic general approach for answering ambiguous open-domain questions,\nwhich improves our Refuel as well as several baseline models. We release source\ncode for our models and experiments at\nhttps://github.com/amzn/refuel-open-domain-qa.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 05:48:55 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 07:07:19 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gao", "Yifan", ""], ["Zhu", "Henghui", ""], ["Ng", "Patrick", ""], ["Santos", "Cicero Nogueira dos", ""], ["Wang", "Zhiguo", ""], ["Nan", "Feng", ""], ["Zhang", "Dejiao", ""], ["Nallapati", "Ramesh", ""], ["Arnold", "Andrew O.", ""], ["Xiang", "Bing", ""]]}, {"id": "2011.13149", "submitter": "Shichong Peng", "authors": "Ke Li, Shichong Peng, Kailas Vodrahalli, Jitendra Malik", "title": "Better Knowledge Retention through Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In continual learning, new categories may be introduced over time, and an\nideal learning system should perform well on both the original categories and\nthe new categories. While deep neural nets have achieved resounding success in\nthe classical supervised setting, they are known to forget about knowledge\nacquired in prior episodes of learning if the examples encountered in the\ncurrent episode of learning are drastically different from those encountered in\nprior episodes. In this paper, we propose a new method that can both leverage\nthe expressive power of deep neural nets and is resilient to forgetting when\nnew categories are introduced. We found the proposed method can reduce\nforgetting by 2.3x to 6.9x on CIFAR-10 compared to existing methods and by 1.8x\nto 2.7x on ImageNet compared to an oracle baseline.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 06:28:40 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Li", "Ke", ""], ["Peng", "Shichong", ""], ["Vodrahalli", "Kailas", ""], ["Malik", "Jitendra", ""]]}, {"id": "2011.13150", "submitter": "Jong Chul Ye", "authors": "Serin Yang, Eung Yeop Kim, and Jong Chul Ye", "title": "Continuous Conversion of CT Kernel using Switchable CycleGAN with AdaIN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  X-ray computed tomography (CT) uses different filter kernels to highlight\ndifferent structures. Since the raw sinogram data is usually removed after the\nreconstruction, in case there are additional need for other types of kernel\nimages that were not previously generated, the patient may need to be scanned\nagain. Accordingly, there exists increasing demand for post-hoc image domain\nconversion from one kernel to another without sacrificing the image quality. In\nthis paper, we propose a novel unsupervised continuous kernel conversion method\nusing cycle-consistent generative adversarial network (cycleGAN) with adaptive\ninstance normalization (AdaIN). Even without paired training data, not only can\nour network translate the images between two different kernels, but it can also\nconvert images along the interpolation path between the two kernel domains. We\nalso show that the quality of generated images can be further improved if\nintermediate kernel domain images are available. Experimental results confirm\nthat our method not only enables accurate kernel conversion that is comparable\nto supervised learning methods, but also generates intermediate kernel images\nin the unseen domain that are useful for hypopharyngeal cancer diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 06:35:57 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 00:51:33 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Yang", "Serin", ""], ["Kim", "Eung Yeop", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2011.13160", "submitter": "Xin Hong", "authors": "Xin Hong, Yanyan Lan, Liang Pang, Jiafeng Guo and Xueqi Cheng", "title": "Transformation Driven Visual Reasoning", "comments": "Accepted to CVPR 2021. Resources including the TRANCE dataset and the\n  code can be found at our homepage https://hongxin2019.github.io/TVR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a new visual reasoning paradigm by introducing an\nimportant factor, i.e.~transformation. The motivation comes from the fact that\nmost existing visual reasoning tasks, such as CLEVR in VQA, are solely defined\nto test how well the machine understands the concepts and relations within\nstatic settings, like one image. We argue that this kind of \\textbf{state\ndriven visual reasoning} approach has limitations in reflecting whether the\nmachine has the ability to infer the dynamics between different states, which\nhas been shown as important as state-level reasoning for human cognition in\nPiaget's theory. To tackle this problem, we propose a novel\n\\textbf{transformation driven visual reasoning} task. Given both the initial\nand final states, the target is to infer the corresponding single-step or\nmulti-step transformation, represented as a triplet (object, attribute, value)\nor a sequence of triplets, respectively. Following this definition, a new\ndataset namely TRANCE is constructed on the basis of CLEVR, including three\nlevels of settings, i.e.~Basic (single-step transformation), Event (multi-step\ntransformation), and View (multi-step transformation with variant views).\nExperimental results show that the state-of-the-art visual reasoning models\nperform well on Basic, but are still far from human-level intelligence on Event\nand View. We believe the proposed new paradigm will boost the development of\nmachine visual reasoning. More advanced methods and real data need to be\ninvestigated in this direction. The resource of TVR is available at\nhttps://hongxin2019.github.io/TVR.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 07:11:31 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 06:25:46 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Hong", "Xin", ""], ["Lan", "Yanyan", ""], ["Pang", "Liang", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2011.13174", "submitter": "Penglei Gao", "authors": "Penglei Gao, Xi Yang, Rui Zhang, Kaizhu Huang", "title": "Explainable Tensorized Neural Ordinary Differential Equations\n  forArbitrary-step Time Series Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a continuous neural network architecture, termed Explainable\nTensorized Neural Ordinary Differential Equations (ETN-ODE), for multi-step\ntime series prediction at arbitrary time points. Unlike the existing\napproaches, which mainly handle univariate time series for multi-step\nprediction or multivariate time series for single-step prediction, ETN-ODE\ncould model multivariate time series for arbitrary-step prediction. In\naddition, it enjoys a tandem attention, w.r.t. temporal attention and variable\nattention, being able to provide explainable insights into the data.\nSpecifically, ETN-ODE combines an explainable Tensorized Gated Recurrent Unit\n(Tensorized GRU or TGRU) with Ordinary Differential Equations (ODE). The\nderivative of the latent states is parameterized with a neural network. This\ncontinuous-time ODE network enables a multi-step prediction at arbitrary time\npoints. We quantitatively and qualitatively demonstrate the effectiveness and\nthe interpretability of ETN-ODE on five different multi-step prediction tasks\nand one arbitrary-step prediction task. Extensive experiments show that ETN-ODE\ncan lead to accurate predictions at arbitrary time points while attaining best\nperformance against the baseline methods in standard multi-step time series\nprediction.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 08:29:50 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Gao", "Penglei", ""], ["Yang", "Xi", ""], ["Zhang", "Rui", ""], ["Huang", "Kaizhu", ""]]}, {"id": "2011.13181", "submitter": "Genki Osada", "authors": "Genki Osada, Budrul Ahsan, Revoti Prasad Bora, Takashi Nishide", "title": "Regularization with Latent Space Virtual Adversarial Training", "comments": "Accepted at ECCV 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Virtual Adversarial Training (VAT) has shown impressive results among\nrecently developed regularization methods called consistency regularization.\nVAT utilizes adversarial samples, generated by injecting perturbation in the\ninput space, for training and thereby enhances the generalization ability of a\nclassifier. However, such adversarial samples can be generated only within a\nvery small area around the input data point, which limits the adversarial\neffectiveness of such samples. To address this problem we propose LVAT (Latent\nspace VAT), which injects perturbation in the latent space instead of the input\nspace. LVAT can generate adversarial samples flexibly, resulting in more\nadverse effects and thus more effective regularization. The latent space is\nbuilt by a generative model, and in this paper, we examine two different type\nof models: variational auto-encoder and normalizing flow, specifically Glow. We\nevaluated the performance of our method in both supervised and semi-supervised\nlearning scenarios for an image classification task using SVHN and CIFAR-10\ndatasets. In our evaluation, we found that our method outperforms VAT and other\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 08:51:38 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Osada", "Genki", ""], ["Ahsan", "Budrul", ""], ["Bora", "Revoti Prasad", ""], ["Nishide", "Takashi", ""]]}, {"id": "2011.13194", "submitter": "Morteza Hosseini", "authors": "Morteza Hosseini, Haoran Ren, Hasib-Al Rashid, Arnab Neelim Mazumder,\n  Bharat Prakash, and Tinoosh Mohsenin", "title": "Neural Networks for Pulmonary Disease Diagnosis using Auditory and\n  Demographic Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pulmonary diseases impact millions of lives globally and annually. The recent\noutbreak of the pandemic of the COVID-19, a novel pulmonary infection, has more\nthan ever brought the attention of the research community to the machine-aided\ndiagnosis of respiratory problems. This paper is thus an effort to exploit\nmachine learning for classification of respiratory problems and proposes a\nframework that employs as much correlated information (auditory and demographic\ninformation in this work) as a dataset provides to increase the sensitivity and\nspecificity of a diagnosing system. First, we use deep convolutional neural\nnetworks (DCNNs) to process and classify a publicly released pulmonary auditory\ndataset, and then we take advantage of the existing demographic information\nwithin the dataset and show that the accuracy of the pulmonary classification\nincreases by 5% when trained on the auditory information in conjunction with\nthe demographic information. Since the demographic data can be extracted using\ncomputer vision, we suggest using another parallel DCNN to estimate the\ndemographic information of the subject under test visioned by the processing\ncomputer. Lastly, as a proposition to bring the healthcare system to users'\nfingertips, we measure deployment characteristics of the auditory DCNN model\nonto processing components of an NVIDIA TX2 development board.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:14:40 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hosseini", "Morteza", ""], ["Ren", "Haoran", ""], ["Rashid", "Hasib-Al", ""], ["Mazumder", "Arnab Neelim", ""], ["Prakash", "Bharat", ""], ["Mohsenin", "Tinoosh", ""]]}, {"id": "2011.13202", "submitter": "Soroosh Poorgholi", "authors": "Soroosh Poorgholi, Osman Semih Kayhan and Jan C. van Gemert", "title": "t-EVA: Time-Efficient t-SNE Video Annotation", "comments": "ICPR 2020 (HCAU)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Video understanding has received more attention in the past few years due to\nthe availability of several large-scale video datasets. However, annotating\nlarge-scale video datasets are cost-intensive. In this work, we propose a\ntime-efficient video annotation method using spatio-temporal feature similarity\nand t-SNE dimensionality reduction to speed up the annotation process\nmassively. Placing the same actions from different videos near each other in\nthe two-dimensional space based on feature similarity helps the annotator to\ngroup-label video clips. We evaluate our method on two subsets of the\nActivityNet (v1.3) and a subset of the Sports-1M dataset. We show that t-EVA\ncan outperform other video annotation tools while maintaining test accuracy on\nvideo classification.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:56:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Poorgholi", "Soroosh", ""], ["Kayhan", "Osman Semih", ""], ["van Gemert", "Jan C.", ""]]}, {"id": "2011.13205", "submitter": "Emanuele Bastianelli", "authors": "Emanuele Bastianelli, Andrea Vanzo, Pawel Swietojanski, Verena Rieser", "title": "SLURP: A Spoken Language Understanding Resource Package", "comments": "Published at the 2020 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spoken Language Understanding infers semantic meaning directly from audio\ndata, and thus promises to reduce error propagation and misunderstandings in\nend-user applications. However, publicly available SLU resources are limited.\nIn this paper, we release SLURP, a new SLU package containing the following:\n(1) A new challenging dataset in English spanning 18 domains, which is\nsubstantially bigger and linguistically more diverse than existing datasets;\n(2) Competitive baselines based on state-of-the-art NLU and ASR systems; (3) A\nnew transparent metric for entity labelling which enables a detailed error\nanalysis for identifying potential areas of improvement. SLURP is available at\nhttps: //github.com/pswietojanski/slurp.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:58:20 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bastianelli", "Emanuele", ""], ["Vanzo", "Andrea", ""], ["Swietojanski", "Pawel", ""], ["Rieser", "Verena", ""]]}, {"id": "2011.13210", "submitter": "Emanuele Bastianelli", "authors": "Emanuele Bastianelli, Andrea Vanzo, Oliver Lemon", "title": "Encoding Syntactic Constituency Paths for Frame-Semantic Parsing with\n  Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of integrating syntactic information from constituency\ntrees into a neural model in Frame-semantic parsing sub-tasks, namely Target\nIdentification (TI), FrameIdentification (FI), and Semantic Role Labeling\n(SRL). We use a Graph Convolutional Network to learn specific representations\nof constituents, such that each constituent is profiled as the production\ngrammar rule it corresponds to. We leverage these representations to build\nsyntactic features for each word in a sentence, computed as the sum of all the\nconstituents on the path between a word and a task-specific node in the tree,\ne.g. the target predicate for SRL. Our approach improves state-of-the-art\nresults on the TI and SRL of ~1%and~3.5% points, respectively (+2.5% additional\npoints are gained with BERT as input), when tested on FrameNet 1.5, while\nyielding comparable results on the CoNLL05 dataset to other syntax-aware\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:10:57 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bastianelli", "Emanuele", ""], ["Vanzo", "Andrea", ""], ["Lemon", "Oliver", ""]]}, {"id": "2011.13219", "submitter": "Qingbiao Li", "authors": "Qingbiao Li, Weizhe Lin, Zhe Liu, Amanda Prorok", "title": "Message-Aware Graph Attention Networks for Large-Scale Multi-Robot Path\n  Planning", "comments": "This work has been accepted to the IEEE Robotics and Automation\n  Letters (RA-L) for publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The domains of transport and logistics are increasingly relying on autonomous\nmobile robots for the handling and distribution of passengers or resources. At\nlarge system scales, finding decentralized path planning and coordination\nsolutions is key to efficient system performance. Recently, Graph Neural\nNetworks (GNNs) have become popular due to their ability to learn communication\npolicies in decentralized multi-agent systems. Yet, vanilla GNNs rely on\nsimplistic message aggregation mechanisms that prevent agents from prioritizing\nimportant information. To tackle this challenge, in this paper, we extend our\nprevious work that utilizes GNNs in multi-agent path planning by incorporating\na novel mechanism to allow for message-dependent attention. Our Message-Aware\nGraph Attention neTwork (MAGAT) is based on a key-query-like mechanism that\ndetermines the relative importance of features in the messages received from\nvarious neighboring robots. We show that MAGAT is able to achieve a performance\nclose to that of a coupled centralized expert algorithm. Further, ablation\nstudies and comparisons to several benchmark models show that our attention\nmechanism is very effective across different robot densities and performs\nstably in different constraints in communication bandwidth. Experiments\ndemonstrate that our model is able to generalize well in previously unseen\nproblem instances, and that it achieves a 47\\% improvement over the benchmark\nsuccess rate, even in very large-scale instances that are $\\times$100 larger\nthan the training instances.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:37:13 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 11:40:52 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Li", "Qingbiao", ""], ["Lin", "Weizhe", ""], ["Liu", "Zhe", ""], ["Prorok", "Amanda", ""]]}, {"id": "2011.13220", "submitter": "Jihyeon Roh", "authors": "Jihyeon Roh, Sang-Hoon Oh, Soo-Young Lee", "title": "Unigram-Normalized Perplexity as a Language Model Performance Measure\n  with Different Vocabulary Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Perplexity is a widely used performance metric for language models,\nthe values are highly dependent upon the number of words in the corpus and is\nuseful to compare performance of the same corpus only. In this paper, we\npropose a new metric that can be used to evaluate language model performance\nwith different vocabulary sizes. The proposed unigram-normalized Perplexity\nactually presents the performance improvement of the language models from that\nof simple unigram model, and is robust on the vocabulary size. Both theoretical\nanalysis and computational experiments are reported.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:39:03 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Roh", "Jihyeon", ""], ["Oh", "Sang-Hoon", ""], ["Lee", "Soo-Young", ""]]}, {"id": "2011.13227", "submitter": "Felix B\\\"unning", "authors": "Felix B\\\"unning, Adrian Schalbetter, Ahmed Aboudonia, Mathias Hudoba\n  de Badyn, Philipp Heer, John Lygeros", "title": "Input Convex Neural Networks for Building MPC", "comments": "11 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model Predictive Control in buildings can significantly reduce their energy\nconsumption. The cost and effort necessary for creating and maintaining first\nprinciple models for buildings make data-driven modelling an attractive\nalternative in this domain. In MPC the models form the basis for an\noptimization problem whose solution provides the control signals to be applied\nto the system. The fact that this optimization problem has to be solved\nrepeatedly in real-time implies restrictions on the learning architectures that\ncan be used. Here, we adapt Input Convex Neural Networks that are generally\nonly convex for one-step predictions, for use in building MPC. We introduce\nadditional constraints to their structure and weights to achieve a convex\ninput-output relationship for multistep ahead predictions. We assess the\nconsequences of the additional constraints for the model accuracy and test the\nmodels in a real-life MPC experiment in an apartment in Switzerland. In two\nfive-day cooling experiments, MPC with Input Convex Neural Networks is able to\nkeep room temperatures within comfort constraints while minimizing cooling\nenergy consumption.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:51:50 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["B\u00fcnning", "Felix", ""], ["Schalbetter", "Adrian", ""], ["Aboudonia", "Ahmed", ""], ["de Badyn", "Mathias Hudoba", ""], ["Heer", "Philipp", ""], ["Lygeros", "John", ""]]}, {"id": "2011.13230", "submitter": "Mohamed Ahmed", "authors": "Benedek Fabian, Thomas Edlich, H\\'el\\'ena Gaspar, Marwin Segler,\n  Joshua Meyers, Marco Fiscato, Mohamed Ahmed", "title": "Molecular representation learning with language models and\n  domain-relevant auxiliary tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply a Transformer architecture, specifically BERT, to learn flexible and\nhigh quality molecular representations for drug discovery problems. We study\nthe impact of using different combinations of self-supervised tasks for\npre-training, and present our results for the established Virtual Screening and\nQSAR benchmarks. We show that: i) The selection of appropriate self-supervised\ntask(s) for pre-training has a significant impact on performance in subsequent\ndownstream tasks such as Virtual Screening. ii) Using auxiliary tasks with more\ndomain relevance for Chemistry, such as learning to predict calculated\nmolecular properties, increases the fidelity of our learnt representations.\niii) Finally, we show that molecular representations learnt by our model\n`MolBert' improve upon the current state of the art on the benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 10:55:05 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fabian", "Benedek", ""], ["Edlich", "Thomas", ""], ["Gaspar", "H\u00e9l\u00e9na", ""], ["Segler", "Marwin", ""], ["Meyers", "Joshua", ""], ["Fiscato", "Marco", ""], ["Ahmed", "Mohamed", ""]]}, {"id": "2011.13244", "submitter": "Abdullah Hamdi", "authors": "Abdullah Hamdi, Silvio Giancola, Bernard Ghanem", "title": "MVTN: Multi-View Transformation Network for 3D Shape Recognition", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-view projection methods have demonstrated their ability to reach\nstate-of-the-art performance on 3D shape recognition. Those methods learn\ndifferent ways to aggregate information from multiple views. However, the\ncamera view-points for those views tend to be heuristically set and fixed for\nall shapes. To circumvent the lack of dynamism of current multi-view methods,\nwe propose to learn those view-points. In particular, we introduce the\nMulti-View Transformation Network (MVTN) that regresses optimal view-points for\n3D shape recognition, building upon advances in differentiable rendering. As a\nresult, MVTN can be trained end-to-end along with any multi-view network for 3D\nshape classification. We integrate MVTN in a novel adaptive multi-view pipeline\nthat can render either 3D meshes or point clouds. MVTN exhibits clear\nperformance gains in the tasks of 3D shape classification and 3D shape\nretrieval without the need for extra training supervision. In these tasks, MVTN\nachieves state-of-the-art performance on ModelNet40, ShapeNet Core55, and the\nmost recent and realistic ScanObjectNN dataset (up to 6% improvement).\nInterestingly, we also show that MVTN can provide network robustness against\nrotation and occlusion in the 3D domain.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 11:33:53 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 23:50:13 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Hamdi", "Abdullah", ""], ["Giancola", "Silvio", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2011.13246", "submitter": "Dawood Al Chanti", "authors": "Dawood Al Chanti, Vanessa Gonzalez Duque, Marion Crouzier, Antoine\n  Nordez, Lilian Lacourpaille, and Diana Mateus", "title": "IFSS-Net: Interactive Few-Shot Siamese Network for Faster Muscle\n  Segmentation and Propagation in Volumetric Ultrasound", "comments": "14 pages, 18 figures, 10 Tables", "journal-ref": null, "doi": "10.1109/TMI.2021.3058303", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an accurate, fast and efficient method for segmentation and muscle\nmask propagation in 3D freehand ultrasound data, towards accurate volume\nquantification. A deep Siamese 3D Encoder-Decoder network that captures the\nevolution of the muscle appearance and shape for contiguous slices is deployed.\nWe uses it to propagate a reference mask annotated by a clinical expert. To\nhandle longer changes of the muscle shape over the entire volume and to provide\nan accurate propagation, we devise a Bidirectional Long Short Term Memory\nmodule. Also, to train our model with a minimal amount of training samples, we\npropose a strategy combining learning from few annotated 2D ultrasound slices\nwith sequential pseudo-labeling of the unannotated slices. We introduce a\ndecremental update of the objective function to guide the model convergence in\nthe absence of large amounts of annotated data. After training with a small\nnumber of volumes, the decremental update transitions from a weakly-supervised\ntraining to a few-shot setting. Finally, to handle the class-imbalance between\nforeground and background muscle pixels, we propose a parametric Tversky loss\nfunction that learns to adaptively penalize false positives and false\nnegatives. We validate our approach for the segmentation, label propagation,\nand volume computation of the three low-limb muscles on a dataset of 61600\nimages from 44 subjects. We achieve a Dice score coefficient of over $95~\\%$\nand a volumetric error \\textcolor{black}{of} $1.6035 \\pm 0.587~\\%$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 11:37:25 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 11:40:48 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Chanti", "Dawood Al", ""], ["Duque", "Vanessa Gonzalez", ""], ["Crouzier", "Marion", ""], ["Nordez", "Antoine", ""], ["Lacourpaille", "Lilian", ""], ["Mateus", "Diana", ""]]}, {"id": "2011.13253", "submitter": "Sundeep Teki", "authors": "Rutvik Vijjali, Prathyush Potluri, Siddharth Kumar, Sundeep Teki", "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 11:50:45 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Vijjali", "Rutvik", ""], ["Potluri", "Prathyush", ""], ["Kumar", "Siddharth", ""], ["Teki", "Sundeep", ""]]}, {"id": "2011.13265", "submitter": "Sandesh Ramesh", "authors": "Sandesh Ramesh, Anirudh Hebbar, Varun Yadav, Thulasiram Gunta, and A\n  Balachandra", "title": "CYPUR-NN: Crop Yield Prediction Using Regression and Neural Networks", "comments": "Advances in Intelligent Systems and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Our recent study using historic data of paddy yield and associated conditions\ninclude humidity, luminescence, and temperature. By incorporating regression\nmodels and neural networks (NN), one can produce highly satisfactory\nforecasting of paddy yield. Simulations indicate that our model can predict\npaddy yield with high accuracy while concurrently detecting diseases that may\nexist and are oblivious to the human eye. Crop Yield Prediction Using\nRegression and Neural Networks (CYPUR-NN) is developed here as a system that\nwill facilitate agriculturists and farmers to predict yield from a picture or\nby entering values via a web interface. CYPUR-NN has been tested on stock\nimages and the experimental results are promising.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 12:50:58 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ramesh", "Sandesh", ""], ["Hebbar", "Anirudh", ""], ["Yadav", "Varun", ""], ["Gunta", "Thulasiram", ""], ["Balachandra", "A", ""]]}, {"id": "2011.13305", "submitter": "Carsten Hahn", "authors": "Carsten Hahn, Sebastian Feld, Hannes Schroter", "title": "Predictive Collision Management for Time and Risk Dependent Path\n  Planning", "comments": "Extended version of the SIGSPATIAL '20 paper", "journal-ref": "Proceedings of the 28th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems (SIGSPATIAL '20), 2020, Pages\n  405-408", "doi": "10.1145/3397536.3422252", "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents such as self-driving cars or parcel robots need to\nrecognize and avoid possible collisions with obstacles in order to move\nsuccessfully in their environment. Humans, however, have learned to predict\nmovements intuitively and to avoid obstacles in a forward-looking way. The task\nof collision avoidance can be divided into a global and a local level.\nRegarding the global level, we propose an approach called \"Predictive Collision\nManagement Path Planning\" (PCMP). At the local level, solutions for collision\navoidance are used that prevent an inevitable collision. Therefore, the aim of\nPCMP is to avoid unnecessary local collision scenarios using predictive\ncollision management. PCMP is a graph-based algorithm with a focus on the time\ndimension consisting of three parts: (1) movement prediction, (2) integration\nof movement prediction into a time-dependent graph, and (3) time and\nrisk-dependent path planning. The algorithm combines the search for a shortest\npath with the question: is the detour worth avoiding a possible collision\nscenario? We evaluate the evasion behavior in different simulation scenarios\nand the results show that a risk-sensitive agent can avoid 47.3% of the\ncollision scenarios while making a detour of 1.3%. A risk-averse agent avoids\nup to 97.3% of the collision scenarios with a detour of 39.1%. Thus, an agent's\nevasive behavior can be controlled actively and risk-dependent using PCMP.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 14:15:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hahn", "Carsten", ""], ["Feld", "Sebastian", ""], ["Schroter", "Hannes", ""]]}, {"id": "2011.13306", "submitter": "Loek Tonnaer", "authors": "Luis A. P\\'erez Rey, Loek Tonnaer, Vlado Menkovski, Mike Holenderski,\n  Jacobus W. Portegies", "title": "A Metric for Linear Symmetry-Based Disentanglement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The definition of Linear Symmetry-Based Disentanglement (LSBD) proposed by\n(Higgins et al., 2018) outlines the properties that should characterize a\ndisentangled representation that captures the symmetries of data. However, it\nis not clear how to measure the degree to which a data representation fulfills\nthese properties. We propose a metric for the evaluation of the level of LSBD\nthat a data representation achieves. We provide a practical method to evaluate\nthis metric and use it to evaluate the disentanglement of the data\nrepresentations obtained for three datasets with underlying $SO(2)$ symmetries.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 14:19:08 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Rey", "Luis A. P\u00e9rez", ""], ["Tonnaer", "Loek", ""], ["Menkovski", "Vlado", ""], ["Holenderski", "Mike", ""], ["Portegies", "Jacobus W.", ""]]}, {"id": "2011.13311", "submitter": "Ashwin Samudre", "authors": "Ashwin Samudre, Lijo George, Mahak Bansal, Yogesh Wadadekar", "title": "Data-Efficient Classification of Radio Galaxies", "comments": "Submitted to MNRAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The continuum emission from radio galaxies can be generally classified into\ndifferent classes like FRI, FRII, Bent, or Compact. In this paper, we explore\nthe task of radio galaxy classification based on morphology using deep learning\nmethods with a focus on using a small scale dataset (~ 2000 samples). We apply\nfew-shot learning techniques based on Siamese Networks and transfer learning\ntechniques using a pre-trained DenseNet model with advanced techniques like\ncyclical learning rate, discriminative learning to train the model rapidly. We\nachieve a classification accuracy of over 92% using our best performing model\nwith the biggest source of confusion being between Bent and FRII type galaxies.\nOur results show that focusing on a small but curated dataset along with the\nuse of best practices to train the neural network can lead to good results.\nAutomated classification techniques will be crucial for upcoming surveys with\nnext generation radio telescopes which are expected to detect thousands of new\nradio galaxies in the future.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 14:28:19 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Samudre", "Ashwin", ""], ["George", "Lijo", ""], ["Bansal", "Mahak", ""], ["Wadadekar", "Yogesh", ""]]}, {"id": "2011.13320", "submitter": "Amil Khanzada", "authors": "Gunvant Chaudhari, Xinyi Jiang, Ahmed Fakhry, Asriel Han, Jaclyn Xiao,\n  Sabrina Shen, Amil Khanzada", "title": "Virufy: Global Applicability of Crowdsourced and Clinical Datasets for\n  AI Detection of COVID-19 from Cough", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rapid and affordable methods of testing for COVID-19 infections are essential\nto reduce infection rates and prevent medical facilities from becoming\noverwhelmed. Current approaches of detecting COVID-19 require in-person testing\nwith expensive kits that are not always easily accessible. This study\ndemonstrates that crowdsourced cough audio samples recorded and acquired on\nsmartphones from around the world can be used to develop an AI-based method\nthat accurately predicts COVID-19 infection with an ROC-AUC of 77.1%\n(75.2%-78.3%). Furthermore, we show that our method is able to generalize to\ncrowdsourced audio samples from Latin America and clinical samples from South\nAsia, without further training using the specific samples from those regions.\nAs more crowdsourced data is collected, further development can be implemented\nusing various respiratory audio samples to create a cough analysis-based\nmachine learning (ML) solution for COVID-19 detection that can likely\ngeneralize globally to all demographic groups in both clinical and non-clinical\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 14:38:19 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 17:00:46 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 15:08:57 GMT"}, {"version": "v4", "created": "Sat, 9 Jan 2021 05:23:19 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Chaudhari", "Gunvant", ""], ["Jiang", "Xinyi", ""], ["Fakhry", "Ahmed", ""], ["Han", "Asriel", ""], ["Xiao", "Jaclyn", ""], ["Shen", "Sabrina", ""], ["Khanzada", "Amil", ""]]}, {"id": "2011.13322", "submitter": "Zhen Huang", "authors": "Zhen Huang, Xu Shen, Xinmei Tian, Houqiang Li, Jianqiang Huang and\n  Xian-Sheng Hua", "title": "Spatio-Temporal Inception Graph Convolutional Networks for\n  Skeleton-Based Action Recognition", "comments": "ACMMM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Skeleton-based human action recognition has attracted much attention with the\nprevalence of accessible depth sensors. Recently, graph convolutional networks\n(GCNs) have been widely used for this task due to their powerful capability to\nmodel graph data. The topology of the adjacency graph is a key factor for\nmodeling the correlations of the input skeletons. Thus, previous methods mainly\nfocus on the design/learning of the graph topology. But once the topology is\nlearned, only a single-scale feature and one transformation exist in each layer\nof the networks. Many insights, such as multi-scale information and multiple\nsets of transformations, that have been proven to be very effective in\nconvolutional neural networks (CNNs), have not been investigated in GCNs. The\nreason is that, due to the gap between graph-structured skeleton data and\nconventional image/video data, it is very challenging to embed these insights\ninto GCNs. To overcome this gap, we reinvent the split-transform-merge strategy\nin GCNs for skeleton sequence processing. Specifically, we design a simple and\nhighly modularized graph convolutional network architecture for skeleton-based\naction recognition. Our network is constructed by repeating a building block\nthat aggregates multi-granularity information from both the spatial and\ntemporal paths. Extensive experiments demonstrate that our network outperforms\nstate-of-the-art methods by a significant margin with only 1/5 of the\nparameters and 1/10 of the FLOPs.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 14:43:04 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Huang", "Zhen", ""], ["Shen", "Xu", ""], ["Tian", "Xinmei", ""], ["Li", "Houqiang", ""], ["Huang", "Jianqiang", ""], ["Hua", "Xian-Sheng", ""]]}, {"id": "2011.13350", "submitter": "Santiago Cortes", "authors": "Santiago Cortes and Yullys M. Quintero", "title": "Unsupervised learning for economic risk evaluation in the context of\n  Covid-19 pandemic", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Justifying draconian measures during the Covid-19 pandemic was difficult not\nonly because of the restriction of individual rights, but also because of its\neconomic impact. The objective of this work is to present a machine learning\napproach to identify regions that should implement similar health policies. For\nthat end, we successfully developed a system that gives a notion of economic\nimpact given the prediction of new incidental cases through unsupervised\nlearning and time series forecasting. This system was built taking into account\ncomputational restrictions and low maintenance requirements in order to improve\nthe system's resilience. Finally this system was deployed as part of a web\napplication for simulation and data analysis of COVID-19, in Colombia,\navailable at (https://covid19.dis.eafit.edu.co).\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 15:31:06 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Cortes", "Santiago", ""], ["Quintero", "Yullys M.", ""]]}, {"id": "2011.13356", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Xiaohang Zhan and Xiaolin Wei", "title": "Beyond Single Instance Multi-view Unsupervised Representation Learning", "comments": "A plug-in approach with minimal modification to existing methods\n  based on instance discrimination", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent unsupervised contrastive representation learning follows a Single\nInstance Multi-view (SIM) paradigm where positive pairs are usually constructed\nwith intra-image data augmentation. In this paper, we propose an effective\napproach called Beyond Single Instance Multi-view (BSIM). Specifically, we\nimpose more accurate instance discrimination capability by measuring the joint\nsimilarity between two randomly sampled instances and their mixture, namely\nspurious-positive pairs. We believe that learning joint similarity helps to\nimprove the performance when encoded features are distributed more evenly in\nthe latent space. We apply it as an orthogonal improvement for unsupervised\ncontrastive representation learning, including current outstanding methods\nSimCLR, MoCo, and BYOL. We evaluate our learned representations on many\ndownstream benchmarks like linear classification on ImageNet-1k and PASCAL VOC\n2007, object detection on MS COCO 2017 and VOC, etc. We obtain substantial\ngains with a large margin almost on all these tasks compared with prior arts.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 15:43:27 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhan", "Xiaohang", ""], ["Wei", "Xiaolin", ""]]}, {"id": "2011.13360", "submitter": "Samadhi Poornima Kumarasinghe Wickrama Arachchilage", "authors": "S. W. Arachchilage, E. Izquierdo", "title": "ClusterFace: Joint Clustering and Classification for Set-Based Face\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning technology has enabled successful modeling of complex facial\nfeatures when high quality images are available. Nonetheless, accurate modeling\nand recognition of human faces in real world scenarios `on the wild' or under\nadverse conditions remains an open problem. When unconstrained faces are mapped\ninto deep features, variations such as illumination, pose, occlusion, etc., can\ncreate inconsistencies in the resultant feature space. Hence, deriving\nconclusions based on direct associations could lead to degraded performance.\nThis rises the requirement for a basic feature space analysis prior to face\nrecognition. This paper devises a joint clustering and classification scheme\nwhich learns deep face associations in an easy-to-hard way. Our method is based\non hierarchical clustering where the early iterations tend to preserve high\nreliability. The rationale of our method is that a reliable clustering result\ncan provide insights on the distribution of the feature space, that can guide\nthe classification that follows. Experimental evaluations on three tasks, face\nverification, face identification and rank-order search, demonstrates better or\ncompetitive performance compared to the state-of-the-art, on all three\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 15:55:27 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Arachchilage", "S. W.", ""], ["Izquierdo", "E.", ""]]}, {"id": "2011.13361", "submitter": "Samadhi Poornima Kumarasinghe Wickrama Arachchilage", "authors": "S. W. Arachchilage, E. Izquierdo", "title": "SSDL: Self-Supervised Domain Learning for Improved Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Face recognition in unconstrained environments is challenging due to\nvariations in illumination, quality of sensing, motion blur and etc. An\nindividual's face appearance can vary drastically under different conditions\ncreating a gap between train (source) and varying test (target) data. The\ndomain gap could cause decreased performance levels in direct knowledge\ntransfer from source to target. Despite fine-tuning with domain specific data\ncould be an effective solution, collecting and annotating data for all domains\nis extremely expensive. To this end, we propose a self-supervised domain\nlearning (SSDL) scheme that trains on triplets mined from unlabelled data. A\nkey factor in effective discriminative learning, is selecting informative\ntriplets. Building on most confident predictions, we follow an \"easy-to-hard\"\nscheme of alternate triplet mining and self-learning. Comprehensive experiments\non four different benchmarks show that SSDL generalizes well on different\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 15:55:59 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Arachchilage", "S. W.", ""], ["Izquierdo", "E.", ""]]}, {"id": "2011.13365", "submitter": "Eivind B{\\o}hn", "authors": "Eivind B{\\o}hn, Sebastien Gros, Signe Moe, Tor Arne Johansen", "title": "Optimization of the Model Predictive Control Update Interval Using\n  Reinforcement Learning", "comments": "Submitted to 3rd Annual Learning for Dynamics and Control Conference\n  (L4DC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In control applications there is often a compromise that needs to be made\nwith regards to the complexity and performance of the controller and the\ncomputational resources that are available. For instance, the typical hardware\nplatform in embedded control applications is a microcontroller with limited\nmemory and processing power, and for battery powered applications the control\nsystem can account for a significant portion of the energy consumption. We\npropose a controller architecture in which the computational cost is explicitly\noptimized along with the control objective. This is achieved by a three-part\narchitecture where a high-level, computationally expensive controller generates\nplans, which a computationally simpler controller executes by compensating for\nprediction errors, while a recomputation policy decides when the plan should be\nrecomputed. In this paper, we employ model predictive control (MPC) as the\nhigh-level plan-generating controller, a linear state feedback controller as\nthe simpler compensating controller, and reinforcement learning (RL) to learn\nthe recomputation policy. Simulation results for two examples showcase the\narchitecture's ability to improve upon the MPC approach and find reasonable\ncompromises weighing the performance on the control objective and the\ncomputational resources expended.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:01:52 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["B\u00f8hn", "Eivind", ""], ["Gros", "Sebastien", ""], ["Moe", "Signe", ""], ["Johansen", "Tor Arne", ""]]}, {"id": "2011.13374", "submitter": "Huy Kang Kim", "authors": "Eunji Park, Kyung Ho Park, Huy Kang Kim", "title": "Understand Watchdogs: Discover How Game Bot Get Discovered", "comments": "9 pages, 3 figures, 3 tables, this paper is accepted in ICAART 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The game industry has long been troubled by malicious activities utilizing\ngame bots. The game bots disturb other game players and destroy the\nenvironmental system of the games. For these reasons, the game industry put\ntheir best efforts to detect the game bots among players' characters using the\nlearning-based detections. However, one problem with the detection\nmethodologies is that they do not provide rational explanations about their\ndecisions. To resolve this problem, in this work, we investigate the\nexplainabilities of the game bot detection. We develop the XAI model using a\ndataset from the Korean MMORPG, AION, which includes game logs of human players\nand game bots. More than one classification model has been applied to the\ndataset to be analyzed by applying interpretable models. This provides us\nexplanations about the game bots' behavior, and the truthfulness of the\nexplanations has been evaluated. Besides, interpretability contributes to\nminimizing false detection, which imposes unfair restrictions on human players.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:34:31 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 12:29:53 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Park", "Eunji", ""], ["Park", "Kyung Ho", ""], ["Kim", "Huy Kang", ""]]}, {"id": "2011.13375", "submitter": "Ashish Hooda", "authors": "Athena Sayles, Ashish Hooda, Mohit Gupta, Rahul Chatterjee, Earlence\n  Fernandes", "title": "Invisible Perturbations: Physical Adversarial Examples Exploiting the\n  Rolling Shutter Effect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical adversarial examples for camera-based computer vision have so far\nbeen achieved through visible artifacts -- a sticker on a Stop sign, colorful\nborders around eyeglasses or a 3D printed object with a colorful texture. An\nimplicit assumption here is that the perturbations must be visible so that a\ncamera can sense them. By contrast, we contribute a procedure to generate, for\nthe first time, physical adversarial examples that are invisible to human eyes.\nRather than modifying the victim object with visible artifacts, we modify light\nthat illuminates the object. We demonstrate how an attacker can craft a\nmodulated light signal that adversarially illuminates a scene and causes\ntargeted misclassifications on a state-of-the-art ImageNet deep learning model.\nConcretely, we exploit the radiometric rolling shutter effect in commodity\ncameras to create precise striping patterns that appear on images. To human\neyes, it appears like the object is illuminated, but the camera creates an\nimage with stripes that will cause ML models to output the attacker-desired\nclassification. We conduct a range of simulation and physical experiments with\nLEDs, demonstrating targeted attack rates up to 84%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:34:47 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 02:36:24 GMT"}, {"version": "v3", "created": "Sun, 18 Apr 2021 16:21:42 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sayles", "Athena", ""], ["Hooda", "Ashish", ""], ["Gupta", "Mohit", ""], ["Chatterjee", "Rahul", ""], ["Fernandes", "Earlence", ""]]}, {"id": "2011.13380", "submitter": "Chaopeng Shen", "authors": "Dapeng Feng, Kathryn Lawson and Chaopeng Shen", "title": "Prediction in ungauged regions with sparse flow duration curves and\n  input-selection ensemble modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While long short-term memory (LSTM) models have demonstrated stellar\nperformance with streamflow predictions, there are major risks in applying\nthese models in contiguous regions with no gauges, or predictions in ungauged\nregions (PUR) problems. However, softer data such as the flow duration curve\n(FDC) may be already available from nearby stations, or may become available.\nHere we demonstrate that sparse FDC data can be migrated and assimilated by an\nLSTM-based network, via an encoder. A stringent region-based holdout test\nshowed a median Kling-Gupta efficiency (KGE) of 0.62 for a US dataset,\nsubstantially higher than previous state-of-the-art global-scale ungauged basin\ntests. The baseline model without FDC was already competitive (median KGE\n0.56), but integrating FDCs had substantial value. Because of the inaccurate\nrepresentation of inputs, the baseline models might sometimes produce\ncatastrophic results. However, model generalizability was further meaningfully\nimproved by compiling an ensemble based on models with different input\nselections.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:40:22 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Feng", "Dapeng", ""], ["Lawson", "Kathryn", ""], ["Shen", "Chaopeng", ""]]}, {"id": "2011.13384", "submitter": "Shuchin Aeron", "authors": "Ruijie Jiang, Julia Gouvea, David Hammer, Eric Miller, Shuchin Aeron", "title": "Automatic coding of students' writing via Contrastive Representation\n  Learning in the Wasserstein space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Qualitative analysis of verbal data is of central importance in the learning\nsciences. It is labor-intensive and time-consuming, however, which limits the\namount of data researchers can include in studies. This work is a step towards\nbuilding a statistical machine learning (ML) method for achieving an automated\nsupport for qualitative analyses of students' writing, here specifically in\nscore laboratory reports in introductory biology for sophistication of\nargumentation and reasoning. We start with a set of lab reports from an\nundergraduate biology course, scored by a four-level scheme that considers the\ncomplexity of argument structure, the scope of evidence, and the care and\nnuance of conclusions. Using this set of labeled data, we show that a popular\nnatural language modeling processing pipeline, namely vector representation of\nwords, a.k.a word embeddings, followed by Long Short Term Memory (LSTM) model\nfor capturing language generation as a state-space model, is able to\nquantitatively capture the scoring, with a high Quadratic Weighted Kappa (QWK)\nprediction score, when trained in via a novel contrastive learning set-up. We\nshow that the ML algorithm approached the inter-rater reliability of human\nanalysis. Ultimately, we conclude, that machine learning (ML) for natural\nlanguage processing (NLP) holds promise for assisting learning sciences\nresearchers in conducting qualitative studies at much larger scales than is\ncurrently possible.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:52:48 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 17:01:35 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Jiang", "Ruijie", ""], ["Gouvea", "Julia", ""], ["Hammer", "David", ""], ["Miller", "Eric", ""], ["Aeron", "Shuchin", ""]]}, {"id": "2011.13388", "submitter": "Mattia Segu", "authors": "Mattia Segu, Margarita Grinvald, Roland Siegwart, Federico Tombari", "title": "3DSNet: Unsupervised Shape-to-Shape 3D Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring the style from one image onto another is a popular and widely\nstudied task in computer vision. Yet, style transfer in the 3D setting remains\na largely unexplored problem. To our knowledge, we propose the first\nlearning-based approach for style transfer between 3D objects based on\ndisentangled content and style representations. The proposed method can\nsynthesize new 3D shapes both in the form of point clouds and meshes, combining\nthe content and style of a source and target 3D model to generate a novel shape\nthat resembles in style the target while retaining the source content.\nFurthermore, we extend our technique to implicitly learn the multimodal style\ndistribution of the chosen domains. By sampling style codes from the learned\ndistributions, we increase the variety of styles that our model can confer to\nan input shape. Experimental results validate the effectiveness of the proposed\n3D style transfer method on a number of benchmarks. The implementation of our\nframework will be released upon acceptance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:59:12 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 08:45:55 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 09:29:34 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 09:17:13 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Segu", "Mattia", ""], ["Grinvald", "Margarita", ""], ["Siegwart", "Roland", ""], ["Tombari", "Federico", ""]]}, {"id": "2011.13389", "submitter": "Nicklas Hansen", "authors": "Nicklas Hansen, Xiaolong Wang", "title": "Generalization in Reinforcement Learning by Soft Data Augmentation", "comments": "Website: https://nicklashansen.github.io/SODA/ Code:\n  https://github.com/nicklashansen/dmcontrol-generalization-benchmark.\n  Presented at International Conference on Robotics and Automation (ICRA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive efforts have been made to improve the generalization ability of\nReinforcement Learning (RL) methods via domain randomization and data\naugmentation. However, as more factors of variation are introduced during\ntraining, optimization becomes increasingly challenging, and empirically may\nresult in lower sample efficiency and unstable training. Instead of learning\npolicies directly from augmented data, we propose SOft Data Augmentation\n(SODA), a method that decouples augmentation from policy learning.\nSpecifically, SODA imposes a soft constraint on the encoder that aims to\nmaximize the mutual information between latent representations of augmented and\nnon-augmented data, while the RL optimization process uses strictly\nnon-augmented data. Empirical evaluations are performed on diverse tasks from\nDeepMind Control suite as well as a robotic manipulation task, and we find SODA\nto significantly advance sample efficiency, generalization, and stability in\ntraining over state-of-the-art vision-based RL methods.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 17:00:34 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 02:29:17 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Hansen", "Nicklas", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2011.13399", "submitter": "Mattia Segu", "authors": "Mattia Segu, Federico Pirovano, Gianmario Fumagalli, Amedeo Fabris", "title": "Depth-Aware Action Recognition: Pose-Motion Encoding through Temporal\n  Heatmaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most state-of-the-art methods for action recognition rely only on 2D spatial\nfeatures encoding appearance, motion or pose. However, 2D data lacks the depth\ninformation, which is crucial for recognizing fine-grained actions. In this\npaper, we propose a depth-aware volumetric descriptor that encodes pose and\nmotion information in a unified representation for action classification\nin-the-wild. Our framework is robust to many challenges inherent to action\nrecognition, e.g. variation in viewpoint, scene, clothing and body shape. The\nkey component of our method is the Depth-Aware Pose Motion representation\n(DA-PoTion), a new video descriptor that encodes the 3D movement of semantic\nkeypoints of the human body. Given a video, we produce human joint heatmaps for\neach frame using a state-of-the-art 3D human pose regressor and we give each of\nthem a unique color code according to the relative time in the clip. Then, we\naggregate such 3D time-encoded heatmaps for all human joints to obtain a\nfixed-size descriptor (DA-PoTion), which is suitable for classifying actions\nusing a shallow 3D convolutional neural network (CNN). The DA-PoTion alone\ndefines a new state-of-the-art on the Penn Action Dataset. Moreover, we\nleverage the intrinsic complementarity of our pose motion descriptor with\nappearance based approaches by combining it with Inflated 3D ConvNet (I3D) to\ndefine a new state-of-the-art on the JHMDB Dataset.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 17:26:42 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Segu", "Mattia", ""], ["Pirovano", "Federico", ""], ["Fumagalli", "Gianmario", ""], ["Fabris", "Amedeo", ""]]}, {"id": "2011.13426", "submitter": "Michael P. Kim", "authors": "Cynthia Dwork and Michael P. Kim and Omer Reingold and Guy N. Rothblum\n  and Gal Yona", "title": "Outcome Indistinguishability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction algorithms assign numbers to individuals that are popularly\nunderstood as individual \"probabilities\" -- what is the probability of 5-year\nsurvival after cancer diagnosis? -- and which increasingly form the basis for\nlife-altering decisions. Drawing on an understanding of computational\nindistinguishability developed in complexity theory and cryptography, we\nintroduce Outcome Indistinguishability. Predictors that are Outcome\nIndistinguishable yield a generative model for outcomes that cannot be\nefficiently refuted on the basis of the real-life observations produced by\nNature. We investigate a hierarchy of Outcome Indistinguishability definitions,\nwhose stringency increases with the degree to which distinguishers may access\nthe predictor in question. Our findings reveal that Outcome\nIndistinguishability behaves qualitatively differently than previously studied\nnotions of indistinguishability. First, we provide constructions at all levels\nof the hierarchy. Then, leveraging recently-developed machinery for proving\naverage-case fine-grained hardness, we obtain lower bounds on the complexity of\nthe more stringent forms of Outcome Indistinguishability. This hardness result\nprovides the first scientific grounds for the political argument that, when\ninspecting algorithmic risk prediction instruments, auditors should be granted\noracle access to the algorithm, not simply historical predictions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 18:33:19 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Dwork", "Cynthia", ""], ["Kim", "Michael P.", ""], ["Reingold", "Omer", ""], ["Rothblum", "Guy N.", ""], ["Yona", "Gal", ""]]}, {"id": "2011.13429", "submitter": "Ihsan Ullah", "authors": "hsan Ullah, Andre Rios, Vaibhav Gala and Susan Mckeever", "title": "Explaining Deep Learning Models for Structured Data using Layer-Wise\n  Relevance Propagation", "comments": "13 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Trust and credibility in machine learning models is bolstered by the ability\nof a model to explain itsdecisions. While explainability of deep learning\nmodels is a well-known challenge, a further chal-lenge is clarity of the\nexplanation itself, which must be interpreted by downstream users.\nLayer-wiseRelevance Propagation (LRP), an established explainability technique\ndeveloped for deep models incomputer vision, provides intuitive human-readable\nheat maps of input images. We present the novelapplication of LRP for the first\ntime with structured datasets using a deep neural network (1D-CNN),for Credit\nCard Fraud detection and Telecom Customer Churn prediction datasets. We show\nhow LRPis more effective than traditional explainability concepts of Local\nInterpretable Model-agnostic Ex-planations (LIME) and Shapley Additive\nExplanations (SHAP) for explainability. This effectivenessis both local to a\nsample level and holistic over the whole testing set. We also discuss the\nsignificantcomputational time advantage of LRP (1-2s) over LIME (22s) and SHAP\n(108s), and thus its poten-tial for real time application scenarios. In\naddition, our validation of LRP has highlighted features forenhancing model\nperformance, thus opening up a new area of research of using XAI as an\napproachfor feature subset selection\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 18:34:21 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ullah", "hsan", ""], ["Rios", "Andre", ""], ["Gala", "Vaibhav", ""], ["Mckeever", "Susan", ""]]}, {"id": "2011.13439", "submitter": "Niko Moritz", "authors": "Sameer Khurana, Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Unsupervised Domain Adaptation for Speech Recognition via Uncertainty\n  Driven Self-Training", "comments": "ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of automatic speech recognition (ASR) systems typically\ndegrades significantly when the training and test data domains are mismatched.\nIn this paper, we show that self-training (ST) combined with an\nuncertainty-based pseudo-label filtering approach can be effectively used for\ndomain adaptation. We propose DUST, a dropout-based uncertainty-driven\nself-training technique which uses agreement between multiple predictions of an\nASR system obtained for different dropout settings to measure the model's\nuncertainty about its prediction. DUST excludes pseudo-labeled data with high\nuncertainties from the training, which leads to substantially improved ASR\nresults compared to ST without filtering, and accelerates the training time due\nto a reduced training data set. Domain adaptation experiments using WSJ as a\nsource domain and TED-LIUM 3 as well as SWITCHBOARD as the target domains show\nthat up to 80% of the performance of a system trained on ground-truth data can\nbe recovered.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 18:51:26 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:00:46 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Khurana", "Sameer", ""], ["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2011.13452", "submitter": "Sahil Verma", "authors": "Sahil Verma and Zhendong Su", "title": "ShapeFlow: Dynamic Shape Interpreter for TensorFlow", "comments": "14 pages, 9 figures. Work done about one and half year before the\n  submission to Arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ShapeFlow, a dynamic abstract interpreter for TensorFlow which\nquickly catches tensor shape incompatibility errors, one of the most common\nbugs in deep learning code. ShapeFlow shares the same APIs as TensorFlow but\nonly captures and emits tensor shapes, its abstract domain. ShapeFlow\nconstructs a custom shape computational graph, similar to the computational\ngraph used by TensorFlow. ShapeFlow requires no code annotation or code\nmodification by the programmer, and therefore is convenient to use. We evaluate\nShapeFlow on 52 programs collected by prior empirical studies to show how fast\nand accurately it can catch shape incompatibility errors compared to\nTensorFlow. We use two baselines: a worst-case training dataset size and a more\nrealistic dataset size. ShapeFlow detects shape incompatibility errors highly\naccurately -- with no false positives and a single false negative -- and highly\nefficiently -- with an average speed-up of 499X and 24X for the first and\nsecond baseline, respectively. We believe ShapeFlow is a practical tool that\nbenefits machine learning developers. We will open-source ShapeFlow on GitHub\nto make it publicly available to both the developer and research communities.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 19:27:25 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Verma", "Sahil", ""], ["Su", "Zhendong", ""]]}, {"id": "2011.13456", "submitter": "Yang Song", "authors": "Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar,\n  Stefano Ermon and Ben Poole", "title": "Score-Based Generative Modeling through Stochastic Differential\n  Equations", "comments": "ICLR 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating noise from data is easy; creating data from noise is generative\nmodeling. We present a stochastic differential equation (SDE) that smoothly\ntransforms a complex data distribution to a known prior distribution by slowly\ninjecting noise, and a corresponding reverse-time SDE that transforms the prior\ndistribution back into the data distribution by slowly removing the noise.\nCrucially, the reverse-time SDE depends only on the time-dependent gradient\nfield (\\aka, score) of the perturbed data distribution. By leveraging advances\nin score-based generative modeling, we can accurately estimate these scores\nwith neural networks, and use numerical SDE solvers to generate samples. We\nshow that this framework encapsulates previous approaches in score-based\ngenerative modeling and diffusion probabilistic modeling, allowing for new\nsampling procedures and new modeling capabilities. In particular, we introduce\na predictor-corrector framework to correct errors in the evolution of the\ndiscretized reverse-time SDE. We also derive an equivalent neural ODE that\nsamples from the same distribution as the SDE, but additionally enables exact\nlikelihood computation, and improved sampling efficiency. In addition, we\nprovide a new way to solve inverse problems with score-based models, as\ndemonstrated with experiments on class-conditional generation, image\ninpainting, and colorization. Combined with multiple architectural\nimprovements, we achieve record-breaking performance for unconditional image\ngeneration on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a\ncompetitive likelihood of 2.99 bits/dim, and demonstrate high fidelity\ngeneration of 1024 x 1024 images for the first time from a score-based\ngenerative model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 19:39:10 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 18:17:04 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Song", "Yang", ""], ["Sohl-Dickstein", "Jascha", ""], ["Kingma", "Diederik P.", ""], ["Kumar", "Abhishek", ""], ["Ermon", "Stefano", ""], ["Poole", "Ben", ""]]}, {"id": "2011.13465", "submitter": "Simon Tindemans", "authors": "Medha Subramanian, Jan Viebahn, Simon H. Tindemans, Benjamin Donnot,\n  Antoine Marot", "title": "Exploring grid topology reconfiguration using a simple deep\n  reinforcement learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System operators are faced with increasingly volatile operating conditions.\nIn order to manage system reliability in a cost-effective manner, control room\noperators are turning to computerised decision support tools based on AI and\nmachine learning. Specifically, Reinforcement Learning (RL) is a promising\ntechnique to train agents that suggest grid control actions to operators. In\nthis paper, a simple baseline approach is presented using RL to represent an\nartificial control room operator that can operate a IEEE 14-bus test case for a\nduration of 1 week. This agent takes topological switching actions to control\npower flows on the grid, and is trained on only a single well-chosen scenario.\nThe behaviour of this agent is tested on different time-series of generation\nand demand, demonstrating its ability to operate the grid successfully in 965\nout of 1000 scenarios. The type and variability of topologies suggested by the\nagent are analysed across the test scenarios, demonstrating efficient and\ndiverse agent behaviour.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 20:22:08 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 12:31:41 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Subramanian", "Medha", ""], ["Viebahn", "Jan", ""], ["Tindemans", "Simon H.", ""], ["Donnot", "Benjamin", ""], ["Marot", "Antoine", ""]]}, {"id": "2011.13466", "submitter": "Salvatore Rappoccio", "authors": "Garvita Agarwal, Lauren Hay, Ia Iashvili, Benjamin Mannix, Christine\n  McLean, Margaret Morris, Salvatore Rappoccio, Ulrich Schubert", "title": "Explainable AI for ML jet taggers using expert variables and layerwise\n  relevance propagation", "comments": "38 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG hep-ex hep-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A framework is presented to extract and understand decision-making\ninformation from a deep neural network (DNN) classifier of jet substructure\ntagging techniques. The general method studied is to provide expert variables\nthat augment inputs (\"eXpert AUGmented\" variables, or XAUG variables), then\napply layerwise relevance propagation (LRP) to networks both with and without\nXAUG variables. The XAUG variables are concatenated with the intermediate\nlayers after network-specific operations (such as convolution or recurrence),\nand used in the final layers of the network. The results of comparing networks\nwith and without the addition of XAUG variables show that XAUG variables can be\nused to interpret classifier behavior, increase discrimination ability when\ncombined with low-level features, and in some cases capture the behavior of the\nclassifier completely. The LRP technique can be used to find relevant\ninformation the network is using, and when combined with the XAUG variables,\ncan be used to rank features, allowing one to find a reduced set of features\nthat capture part of the network performance. In the studies presented, adding\nXAUG variables to low-level DNNs increased the efficiency of classifiers by as\nmuch as 30-40\\%. In addition to performance improvements, an approach to\nquantify numerical uncertainties in the training of these DNNs is presented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 20:36:08 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 17:52:54 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 19:38:06 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Agarwal", "Garvita", ""], ["Hay", "Lauren", ""], ["Iashvili", "Ia", ""], ["Mannix", "Benjamin", ""], ["McLean", "Christine", ""], ["Morris", "Margaret", ""], ["Rappoccio", "Salvatore", ""], ["Schubert", "Ulrich", ""]]}, {"id": "2011.13470", "submitter": "Tuan Manh Lai", "authors": "Nham Le, Tuan Lai, Trung Bui and Doo Soon Kim", "title": "AutoNLU: An On-demand Cloud-based Natural Language Understanding System\n  for Enterprises", "comments": "Accepted to AACL 2020 (Demo)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the renaissance of deep learning, neural networks have achieved\npromising results on many natural language understanding (NLU) tasks. Even\nthough the source codes of many neural network models are publicly available,\nthere is still a large gap from open-sourced models to solving real-world\nproblems in enterprises. Therefore, to fill this gap, we introduce AutoNLU, an\non-demand cloud-based system with an easy-to-use interface that covers all\ncommon use-cases and steps in developing an NLU model. AutoNLU has supported\nmany product teams within Adobe with different use-cases and datasets, quickly\ndelivering them working models. To demonstrate the effectiveness of AutoNLU, we\npresent two case studies. i) We build a practical NLU model for handling\nvarious image-editing requests in Photoshop. ii) We build powerful keyphrase\nextraction models that achieve state-of-the-art results on two public\nbenchmarks. In both cases, end users only need to write a small amount of code\nto convert their datasets into a common format used by AutoNLU.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 20:51:57 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Le", "Nham", ""], ["Lai", "Tuan", ""], ["Bui", "Trung", ""], ["Kim", "Doo Soon", ""]]}, {"id": "2011.13477", "submitter": "Nicholas Roberts", "authors": "Nicholas Roberts, Davis Liang, Graham Neubig, Zachary C. Lipton", "title": "Decoding and Diversity in Machine Translation", "comments": "Presented at the Resistance AI Workshop, 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) systems are typically evaluated using\nautomated metrics that assess the agreement between generated translations and\nground truth candidates. To improve systems with respect to these metrics, NLP\nresearchers employ a variety of heuristic techniques, including searching for\nthe conditional mode (vs. sampling) and incorporating various training\nheuristics (e.g., label smoothing). While search strategies significantly\nimprove BLEU score, they yield deterministic outputs that lack the diversity of\nhuman translations. Moreover, search tends to bias the distribution of\ntranslated gender pronouns. This makes human-level BLEU a misleading benchmark\nin that modern MT systems cannot approach human-level BLEU while simultaneously\nmaintaining human-level translation diversity. In this paper, we characterize\ndistributional differences between generated and real translations, examining\nthe cost in diversity paid for the BLEU scores enjoyed by NMT. Moreover, our\nstudy implicates search as a salient source of known bias when translating\ngender pronouns.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 21:09:38 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Roberts", "Nicholas", ""], ["Liang", "Davis", ""], ["Neubig", "Graham", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2011.13487", "submitter": "Federico Visi", "authors": "Federico Ghelli Visi and Atau Tanaka", "title": "Interactive Machine Learning of Musical Gesture", "comments": "Author's accepted manuscript, to appear as a chapter in \"Handbook of\n  Artificial Intelligence for Music: Foundations, Advanced Approaches, and\n  Developments for Creativity\", edited by E. R. Miranda. Cham: Springer Nature,\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This chapter presents an overview of Interactive Machine Learning (IML)\ntechniques applied to the analysis and design of musical gestures. We go\nthrough the main challenges and needs related to capturing, analysing, and\napplying IML techniques to human bodily gestures with the purpose of performing\nwith sound synthesis systems. We discuss how different algorithms may be used\nto accomplish different tasks, including interacting with complex synthesis\ntechniques and exploring interaction possibilities by means of Reinforcement\nLearning (RL) in an interaction paradigm we developed called Assisted\nInteractive Machine Learning (AIML). We conclude the chapter with a description\nof how some of these techniques were employed by the authors for the\ndevelopment of four musical pieces, thus outlining the implications that IML\nhave for musical practice.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 22:44:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Visi", "Federico Ghelli", ""], ["Tanaka", "Atau", ""]]}, {"id": "2011.13491", "submitter": "Zhiyao Xie", "authors": "Zhiyao Xie, Hai Li, Xiaoqing Xu, Jiang Hu, Yiran Chen", "title": "Fast IR Drop Estimation with Machine Learning", "comments": null, "journal-ref": "2020 International Conference On Computer Aided Design (ICCAD\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  IR drop constraint is a fundamental requirement enforced in almost all chip\ndesigns. However, its evaluation takes a long time, and mitigation techniques\nfor fixing violations may require numerous iterations. As such, fast and\naccurate IR drop prediction becomes critical for reducing design turnaround\ntime. Recently, machine learning (ML) techniques have been actively studied for\nfast IR drop estimation due to their promise and success in many fields. These\nstudies target at various design stages with different emphasis, and\naccordingly, different ML algorithms are adopted and customized. This paper\nprovides a review to the latest progress in ML-based IR drop estimation\ntechniques. It also serves as a vehicle for discussing some general challenges\nfaced by ML applications in electronics design automation (EDA), and\ndemonstrating how to integrate ML models with conventional techniques for the\nbetter efficiency of EDA tools.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 23:12:37 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Xie", "Zhiyao", ""], ["Li", "Hai", ""], ["Xu", "Xiaoqing", ""], ["Hu", "Jiang", ""], ["Chen", "Yiran", ""]]}, {"id": "2011.13492", "submitter": "Aaron Tuor", "authors": "Jan Drgona, Elliott Skomski, Soumya Vasisht, Aaron Tuor, Draguna\n  Vrabie", "title": "Spectral Analysis and Stability of Deep Neural Dynamics", "comments": "Submitted to 3rd Annual Learning for Dynamics & Control Conference.\n  10 pages. 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our modern history of deep learning follows the arc of famous emergent\ndisciplines in engineering (e.g. aero- and fluid dynamics) when theory lagged\nbehind successful practical applications. Viewing neural networks from a\ndynamical systems perspective, in this work, we propose a novel\ncharacterization of deep neural networks as pointwise affine maps, making them\naccessible to a broader range of analysis methods to help close the gap between\ntheory and practice. We begin by showing the equivalence of neural networks\nwith parameter-varying affine maps parameterized by the state (feature) vector.\nAs the paper's main results, we provide necessary and sufficient conditions for\nthe global stability of generic deep feedforward neural networks. Further, we\nidentify links between the spectral properties of layer-wise weight\nparametrizations, different activation functions, and their effect on the\noverall network's eigenvalue spectra. We analyze a range of neural networks\nwith varying weight initializations, activation functions, bias terms, and\ndepths. Our view of neural networks as affine parameter varying maps allows us\nto \"crack open the black box\" of global neural network dynamical behavior\nthrough visualization of stationary points, regions of attraction, state-space\npartitioning, eigenvalue spectra, and stability properties. Our analysis covers\nneural networks both as an end-to-end function and component-wise without\nsimplifying assumptions or approximations. The methods we develop here provide\ntools to establish relationships between global neural dynamical properties and\ntheir constituent components which can aid in the principled design of neural\nnetworks for dynamics modeling and optimal control.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 23:13:16 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Drgona", "Jan", ""], ["Skomski", "Elliott", ""], ["Vasisht", "Soumya", ""], ["Tuor", "Aaron", ""], ["Vrabie", "Draguna", ""]]}, {"id": "2011.13493", "submitter": "Zhiyao Xie", "authors": "Zhiyao Xie, Guan-Qi Fang, Yu-Hung Huang, Haoxing Ren, Yanqing Zhang,\n  Brucek Khailany, Shao-Yun Fang, Jiang Hu, Yiran Chen, Erick Carvajal Barboza", "title": "FIST: A Feature-Importance Sampling and Tree-Based Method for Automatic\n  Design Flow Parameter Tuning", "comments": null, "journal-ref": "2020 Asia and South Pacific Design Automation Conference (ASP-DAC\n  2020)", "doi": "10.1109/ASP-DAC47756.2020.9045201", "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Design flow parameters are of utmost importance to chip design quality and\nrequire a painfully long time to evaluate their effects. In reality, flow\nparameter tuning is usually performed manually based on designers' experience\nin an ad hoc manner. In this work, we introduce a machine learning-based\nautomatic parameter tuning methodology that aims to find the best design\nquality with a limited number of trials. Instead of merely plugging in machine\nlearning engines, we develop clustering and approximate sampling techniques for\nimproving tuning efficiency. The feature extraction in this method can reuse\nknowledge from prior designs. Furthermore, we leverage a state-of-the-art\nXGBoost model and propose a novel dynamic tree technique to overcome\noverfitting. Experimental results on benchmark circuits show that our approach\nachieves 25% improvement in design quality or 37% reduction in sampling cost\ncompared to random forest method, which is the kernel of a highly cited\nprevious work. Our approach is further validated on two industrial designs. By\nsampling less than 0.02% of possible parameter sets, it reduces area by 1.83%\nand 1.43% compared to the best solutions hand-tuned by experienced designers.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 23:13:42 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Xie", "Zhiyao", ""], ["Fang", "Guan-Qi", ""], ["Huang", "Yu-Hung", ""], ["Ren", "Haoxing", ""], ["Zhang", "Yanqing", ""], ["Khailany", "Brucek", ""], ["Fang", "Shao-Yun", ""], ["Hu", "Jiang", ""], ["Chen", "Yiran", ""], ["Barboza", "Erick Carvajal", ""]]}, {"id": "2011.13494", "submitter": "Zhiyao Xie", "authors": "Zhiyao Xie, Haoxing Ren, Brucek Khailany, Ye Sheng, Santosh Santosh,\n  Jiang Hu, Yiran Chen", "title": "PowerNet: Transferable Dynamic IR Drop Estimation via Maximum\n  Convolutional Neural Network", "comments": null, "journal-ref": "2020 Asia and South Pacific Design Automation Conference (ASP-DAC\n  2020)", "doi": "10.1109/ASP-DAC47756.2020.9045574", "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  IR drop is a fundamental constraint required by almost all chip designs.\nHowever, its evaluation usually takes a long time that hinders mitigation\ntechniques for fixing its violations. In this work, we develop a fast dynamic\nIR drop estimation technique, named PowerNet, based on a convolutional neural\nnetwork (CNN). It can handle both vector-based and vectorless IR analyses.\nMoreover, the proposed CNN model is general and transferable to different\ndesigns. This is in contrast to most existing machine learning (ML) approaches,\nwhere a model is applicable only to a specific design. Experimental results\nshow that PowerNet outperforms the latest ML method by 9% in accuracy for the\nchallenging case of vectorless IR drop and achieves a 30 times speedup compared\nto an accurate IR drop commercial tool. Further, a mitigation tool guided by\nPowerNet reduces IR drop hotspots by 26% and 31% on two industrial designs,\nrespectively, with very limited modification on their power grids.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 23:14:17 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Xie", "Zhiyao", ""], ["Ren", "Haoxing", ""], ["Khailany", "Brucek", ""], ["Sheng", "Ye", ""], ["Santosh", "Santosh", ""], ["Hu", "Jiang", ""], ["Chen", "Yiran", ""]]}, {"id": "2011.13509", "submitter": "Junghyo Jo", "authors": "Juno Hwang and Wonseok Hwang and Junghyo Jo", "title": "Tractable loss function and color image generation of multinary\n  restricted Boltzmann machine", "comments": "NueRIPS 2020 DiffCVGP workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The restricted Boltzmann machine (RBM) is a representative generative model\nbased on the concept of statistical mechanics. In spite of the strong merit of\ninterpretability, unavailability of backpropagation makes it less competitive\nthan other generative models. Here we derive differentiable loss functions for\nboth binary and multinary RBMs. Then we demonstrate their learnability and\nperformance by generating colored face images.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 00:50:59 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hwang", "Juno", ""], ["Hwang", "Wonseok", ""], ["Jo", "Junghyo", ""]]}, {"id": "2011.13511", "submitter": "Sina Amini Niaki", "authors": "Sina Amini Niaki, Ehsan Haghighat, Trevor Campbell, Anoush Poursartip,\n  Reza Vaziri", "title": "Physics-Informed Neural Network for Modelling the Thermochemical Curing\n  Process of Composite-Tool Systems During Manufacture", "comments": null, "journal-ref": "CMAME 384 (2021) 113959", "doi": "10.1016/j.cma.2021.113959", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Physics-Informed Neural Network (PINN) to simulate the\nthermochemical evolution of a composite material on a tool undergoing cure in\nan autoclave. In particular, we solve the governing coupled system of\ndifferential equations -- including conductive heat transfer and resin cure\nkinetics -- by optimizing the parameters of a deep neural network (DNN) using a\nphysics-based loss function. To account for the vastly different behaviour of\nthermal conduction and resin cure, we design a PINN consisting of two\ndisconnected subnetworks, and develop a sequential training algorithm that\nmitigates instability present in traditional training methods. Further, we\nincorporate explicit discontinuities into the DNN at the composite-tool\ninterface and enforce known physical behaviour directly in the loss function to\nimprove the solution near the interface. We train the PINN with a technique\nthat automatically adapts the weights on the loss terms corresponding to PDE,\nboundary, interface, and initial conditions. Finally, we demonstrate that one\ncan include problem parameters as an input to the model -- resulting in a\nsurrogate that provides real-time simulation for a range of problem settings --\nand that one can use transfer learning to significantly reduce the training\ntime for problem settings similar to that of an initial trained model. The\nperformance of the proposed PINN is demonstrated in multiple scenarios with\ndifferent material thicknesses and thermal boundary conditions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 00:56:15 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 22:11:45 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Niaki", "Sina Amini", ""], ["Haghighat", "Ehsan", ""], ["Campbell", "Trevor", ""], ["Poursartip", "Anoush", ""], ["Vaziri", "Reza", ""]]}, {"id": "2011.13518", "submitter": "Matheus Mendon\\c{c}a M.Sc", "authors": "Matheus R. F. Mendon\\c{c}a, Andr\\'e M. S. Barreto, Artur Ziviani", "title": "Efficient Information Diffusion in Time-Varying Graphs through Deep\n  Reinforcement Learning", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network seeding for efficient information diffusion over time-varying\ngraphs~(TVGs) is a challenging task with many real-world applications. There\nare several ways to model this spatio-temporal influence maximization problem,\nbut the ultimate goal is to determine the best moment for a node to start the\ndiffusion process. In this context, we propose Spatio-Temporal Influence\nMaximization~(STIM), a model trained with Reinforcement Learning and Graph\nEmbedding over a set of artificial TVGs that is capable of learning the\ntemporal behavior and connectivity pattern of each node, allowing it to predict\nthe best moment to start a diffusion through the TVG. We also develop a special\nset of artificial TVGs used for training that simulate a stochastic diffusion\nprocess in TVGs, showing that the STIM network can learn an efficient policy\neven over a non-deterministic environment. STIM is also evaluated with a\nreal-world TVG, where it also manages to efficiently propagate information\nthrough the nodes. Finally, we also show that the STIM model has a time\ncomplexity of $O(|E|)$. STIM, therefore, presents a novel approach for\nefficient information diffusion in TVGs, being highly versatile, where one can\nchange the goal of the model by simply changing the adopted reward function.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 01:29:24 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Mendon\u00e7a", "Matheus R. F.", ""], ["Barreto", "Andr\u00e9 M. S.", ""], ["Ziviani", "Artur", ""]]}, {"id": "2011.13522", "submitter": "Zhiyao Xie", "authors": "Zhiyao Xie, Rongjian Liang, Xiaoqing Xu, Jiang Hu, Yixiao Duan, Yiran\n  Chen", "title": "Net2: A Graph Attention Network Method Customized for Pre-Placement Net\n  Length Estimation", "comments": null, "journal-ref": "2021 Asia and South Pacific Design Automation Conference (ASP-DAC\n  2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Net length is a key proxy metric for optimizing timing and power across\nvarious stages of a standard digital design flow. However, the bulk of net\nlength information is not available until cell placement, and hence it is a\nsignificant challenge to explicitly consider net length optimization in design\nstages prior to placement, such as logic synthesis. This work addresses this\nchallenge by proposing a graph attention network method with customization,\ncalled Net2, to estimate individual net length before cell placement. Its\naccuracy-oriented version Net2a achieves about 15% better accuracy than several\nprevious works in identifying both long nets and long critical paths. Its fast\nversion Net2f is more than 1000 times faster than placement while still\noutperforms previous works and other neural network techniques in terms of\nvarious accuracy metrics.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 01:47:19 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Xie", "Zhiyao", ""], ["Liang", "Rongjian", ""], ["Xu", "Xiaoqing", ""], ["Hu", "Jiang", ""], ["Duan", "Yixiao", ""], ["Chen", "Yiran", ""]]}, {"id": "2011.13526", "submitter": "Meng Shen", "authors": "Meng Shen, Hao Yu, Liehuang Zhu, Ke Xu, Qi Li, Xiaojiang Du", "title": "Robust Attacks on Deep Learning Face Recognition in the Physical World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been increasingly used in face recognition\n(FR) systems. Recent studies, however, show that DNNs are vulnerable to\nadversarial examples, which can potentially mislead the FR systems using DNNs\nin the physical world. Existing attacks on these systems either generate\nperturbations working merely in the digital world, or rely on customized\nequipments to generate perturbations and are not robust in varying physical\nenvironments. In this paper, we propose FaceAdv, a physical-world attack that\ncrafts adversarial stickers to deceive FR systems. It mainly consists of a\nsticker generator and a transformer, where the former can craft several\nstickers with different shapes and the latter transformer aims to digitally\nattach stickers to human faces and provide feedbacks to the generator to\nimprove the effectiveness of stickers. We conduct extensive experiments to\nevaluate the effectiveness of FaceAdv on attacking 3 typical FR systems (i.e.,\nArcFace, CosFace and FaceNet). The results show that compared with a\nstate-of-the-art attack, FaceAdv can significantly improve success rate of both\ndodging and impersonating attacks. We also conduct comprehensive evaluations to\ndemonstrate the robustness of FaceAdv.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 02:24:43 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Shen", "Meng", ""], ["Yu", "Hao", ""], ["Zhu", "Liehuang", ""], ["Xu", "Ke", ""], ["Li", "Qi", ""], ["Du", "Xiaojiang", ""]]}, {"id": "2011.13527", "submitter": "Chun-Hsing Lin", "authors": "Chun-Hsing Lin, Siang-Ruei Wu, Hung-Yi Lee, Yun-Nung Chen", "title": "TaylorGAN: Neighbor-Augmented Policy Update for Sample-Efficient Natural\n  Language Generation", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score function-based natural language generation (NLG) approaches such as\nREINFORCE, in general, suffer from low sample efficiency and training\ninstability problems. This is mainly due to the non-differentiable nature of\nthe discrete space sampling and thus these methods have to treat the\ndiscriminator as a black box and ignore the gradient information. To improve\nthe sample efficiency and reduce the variance of REINFORCE, we propose a novel\napproach, TaylorGAN, which augments the gradient estimation by off-policy\nupdate and the first-order Taylor expansion. This approach enables us to train\nNLG models from scratch with smaller batch size -- without maximum likelihood\npre-training, and outperforms existing GAN-based methods on multiple metrics of\nquality and diversity. The source code and data are available at\nhttps://github.com/MiuLab/TaylorGAN\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 02:26:15 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Lin", "Chun-Hsing", ""], ["Wu", "Siang-Ruei", ""], ["Lee", "Hung-Yi", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2011.13529", "submitter": "Huang Zhuo", "authors": "Zhuo Huang, Ying Tai, Chengjie Wang, Jian Yang, Chen Gong", "title": "They are Not Completely Useless: Towards Recycling Transferable\n  Unlabeled Data for Class-Mismatched Semi-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-Supervised Learning (SSL) with mismatched classes deals with the problem\nthat the classes-of-interests in the limited labeled data is only a subset of\nthe classes in massive unlabeled data. As a result, the classes only possessed\nby the unlabeled data may mislead the classifier training and thus hindering\nthe realistic landing of various SSL methods. To solve this problem, existing\nmethods usually divide unlabeled data to in-distribution (ID) data and\nout-of-distribution (OOD) data, and directly discard or weaken the OOD data to\navoid their adverse impact. In other words, they treat OOD data as completely\nuseless and thus the potential valuable information for classification\ncontained by them is totally ignored. To remedy this defect, this paper\nproposes a \"Transferable OOD data Recycling\" (TOOR) method which properly\nutilizes ID data as well as the \"recyclable\" OOD data to enrich the information\nfor conducting class-mismatched SSL. Specifically, TOOR firstly attributes all\nunlabeled data to ID data or OOD data, among which the ID data are directly\nused for training. Then we treat the OOD data that have a close relationship\nwith ID data and labeled data as recyclable, and employ adversarial domain\nadaptation to project them to the space of ID data and labeled data. In other\nwords, the recyclability of an OOD datum is evaluated by its transferability,\nand the recyclable OOD data are transferred so that they are compatible with\nthe distribution of known classes-of-interests. Consequently, our TOOR method\nextracts more information from unlabeled data than existing approaches, so it\ncan achieve the improved performance which is demonstrated by the experiments\non typical benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 02:29:35 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 08:59:19 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 01:28:31 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Huang", "Zhuo", ""], ["Tai", "Ying", ""], ["Wang", "Chengjie", ""], ["Yang", "Jian", ""], ["Gong", "Chen", ""]]}, {"id": "2011.13534", "submitter": "Nishant Subramani", "authors": "Nishant Subramani and Alexandre Matton and Malcolm Greaves and Adrian\n  Lam", "title": "A Survey of Deep Learning Approaches for OCR and Document Understanding", "comments": "Accepted to the ML-RSA Workshop at NeurIPS2020. 15 pages (10 +\n  References)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Documents are a core part of many businesses in many fields such as law,\nfinance, and technology among others. Automatic understanding of documents such\nas invoices, contracts, and resumes is lucrative, opening up many new avenues\nof business. The fields of natural language processing and computer vision have\nseen tremendous progress through the development of deep learning such that\nthese methods have started to become infused in contemporary document\nunderstanding systems. In this survey paper, we review different techniques for\ndocument understanding for documents written in English and consolidate\nmethodologies present in literature to act as a jumping-off point for\nresearchers exploring this area.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 03:05:59 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 23:48:39 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Subramani", "Nishant", ""], ["Matton", "Alexandre", ""], ["Greaves", "Malcolm", ""], ["Lam", "Adrian", ""]]}, {"id": "2011.13538", "submitter": "Yilun Jin", "authors": "Yilun Jin, Lixin Fan, Kam Woh Ng, Ce Ju, Qiang Yang", "title": "Rethinking Uncertainty in Deep Learning: Whether and How it Improves\n  Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep neural networks (DNNs) are known to be prone to adversarial attacks, for\nwhich many remedies are proposed. While adversarial training (AT) is regarded\nas the most robust defense, it suffers from poor performance both on clean\nexamples and under other types of attacks, e.g. attacks with larger\nperturbations. Meanwhile, regularizers that encourage uncertain outputs, such\nas entropy maximization (EntM) and label smoothing (LS) can maintain accuracy\non clean examples and improve performance under weak attacks, yet their ability\nto defend against strong attacks is still in doubt. In this paper, we revisit\nuncertainty promotion regularizers, including EntM and LS, in the field of\nadversarial learning. We show that EntM and LS alone provide robustness only\nunder small perturbations. Contrarily, we show that uncertainty promotion\nregularizers complement AT in a principled manner, consistently improving\nperformance on both clean examples and under various attacks, especially\nattacks with large perturbations. We further analyze how uncertainty promotion\nregularizers enhance the performance of AT from the perspective of Jacobian\nmatrices $\\nabla_X f(X;\\theta)$, and find out that EntM effectively shrinks the\nnorm of Jacobian matrices and hence promotes robustness.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 03:22:50 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Jin", "Yilun", ""], ["Fan", "Lixin", ""], ["Ng", "Kam Woh", ""], ["Ju", "Ce", ""], ["Yang", "Qiang", ""]]}, {"id": "2011.13548", "submitter": "Haoyi Fan", "authors": "Haoyi Fan, Fengbin Zhang, Yue Gao", "title": "Self-Supervised Time Series Representation Learning by Inter-Intra\n  Relational Reasoning", "comments": "19 pages, 10 figures, under review at ICLR2021. The source code and\n  dataset are available at https://haoyfan.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised learning achieves superior performance in many domains by\nextracting useful representations from the unlabeled data. However, most of\ntraditional self-supervised methods mainly focus on exploring the inter-sample\nstructure while less efforts have been concentrated on the underlying\nintra-temporal structure, which is important for time series data. In this\npaper, we present SelfTime: a general self-supervised time series\nrepresentation learning framework, by exploring the inter-sample relation and\nintra-temporal relation of time series to learn the underlying structure\nfeature on the unlabeled time series. Specifically, we first generate the\ninter-sample relation by sampling positive and negative samples of a given\nanchor sample, and intra-temporal relation by sampling time pieces from this\nanchor. Then, based on the sampled relation, a shared feature extraction\nbackbone combined with two separate relation reasoning heads are employed to\nquantify the relationships of the sample pairs for inter-sample relation\nreasoning, and the relationships of the time piece pairs for intra-temporal\nrelation reasoning, respectively. Finally, the useful representations of time\nseries are extracted from the backbone under the supervision of relation\nreasoning heads. Experimental results on multiple real-world time series\ndatasets for time series classification task demonstrate the effectiveness of\nthe proposed method. Code and data are publicly available at\nhttps://haoyfan.github.io/.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 04:04:17 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fan", "Haoyi", ""], ["Zhang", "Fengbin", ""], ["Gao", "Yue", ""]]}, {"id": "2011.13550", "submitter": "Pasin Manurangsi", "authors": "Surbhi Goel, Adam Klivans, Pasin Manurangsi, Daniel Reichman", "title": "Tight Hardness Results for Training Depth-2 ReLU Networks", "comments": "To appear in ITCS'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove several hardness results for training depth-2 neural networks with\nthe ReLU activation function; these networks are simply weighted sums (that may\ninclude negative coefficients) of ReLUs. Our goal is to output a depth-2 neural\nnetwork that minimizes the square loss with respect to a given training set. We\nprove that this problem is NP-hard already for a network with a single ReLU. We\nalso prove NP-hardness for outputting a weighted sum of $k$ ReLUs minimizing\nthe squared error (for $k>1$) even in the realizable setting (i.e., when the\nlabels are consistent with an unknown depth-2 ReLU network). We are also able\nto obtain lower bounds on the running time in terms of the desired additive\nerror $\\epsilon$. To obtain our lower bounds, we use the Gap Exponential Time\nHypothesis (Gap-ETH) as well as a new hypothesis regarding the hardness of\napproximating the well known Densest $\\kappa$-Subgraph problem in\nsubexponential time (these hypotheses are used separately in proving different\nlower bounds). For example, we prove that under reasonable hardness\nassumptions, any proper learning algorithm for finding the best fitting ReLU\nmust run in time exponential in $1/\\epsilon^2$. Together with a previous work\nregarding improperly learning a ReLU (Goel et al., COLT'17), this implies the\nfirst separation between proper and improper algorithms for learning a ReLU. We\nalso study the problem of properly learning a depth-2 network of ReLUs with\nbounded weights giving new (worst-case) upper bounds on the running time needed\nto learn such networks both in the realizable and agnostic settings. Our upper\nbounds on the running time essentially matches our lower bounds in terms of the\ndependency on $\\epsilon$.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 04:18:00 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Goel", "Surbhi", ""], ["Klivans", "Adam", ""], ["Manurangsi", "Pasin", ""], ["Reichman", "Daniel", ""]]}, {"id": "2011.13557", "submitter": "Stephan Eismann", "authors": "Stephan Eismann, Patricia Suriana, Bowen Jing, Raphael J.L. Townshend,\n  Ron O. Dror", "title": "Protein model quality assessment using rotation-equivariant,\n  hierarchical neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proteins are miniature machines whose function depends on their\nthree-dimensional (3D) structure. Determining this structure computationally\nremains an unsolved grand challenge. A major bottleneck involves selecting the\nmost accurate structural model among a large pool of candidates, a task\naddressed in model quality assessment. Here, we present a novel deep learning\napproach to assess the quality of a protein model. Our network builds on a\npoint-based representation of the atomic structure and rotation-equivariant\nconvolutions at different levels of structural resolution. These combined\naspects allow the network to learn end-to-end from entire protein structures.\nOur method achieves state-of-the-art results in scoring protein models\nsubmitted to recent rounds of CASP, a blind prediction community experiment.\nParticularly striking is that our method does not use physics-inspired energy\nterms and does not rely on the availability of additional information (beyond\nthe atomic structure of the individual protein model), such as sequence\nalignments of multiple proteins.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 05:03:53 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Eismann", "Stephan", ""], ["Suriana", "Patricia", ""], ["Jing", "Bowen", ""], ["Townshend", "Raphael J. L.", ""], ["Dror", "Ron O.", ""]]}, {"id": "2011.13560", "submitter": "Mingfu Xue", "authors": "Mingfu Xue, Shichang Sun, Zhiyu Wu, Can He, Jian Wang, Weiqiang Liu", "title": "SocialGuard: An Adversarial Example Based Privacy-Preserving Technique\n  for Social Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of various social platforms has prompted more people to share\ntheir routine photos online. However, undesirable privacy leakages occur due to\nsuch online photo sharing behaviors. Advanced deep neural network (DNN) based\nobject detectors can easily steal users' personal information exposed in shared\nphotos. In this paper, we propose a novel adversarial example based\nprivacy-preserving technique for social images against object detectors based\nprivacy stealing. Specifically, we develop an Object Disappearance Algorithm to\ncraft two kinds of adversarial social images. One can hide all objects in the\nsocial images from being detected by an object detector, and the other can make\nthe customized sensitive objects be incorrectly classified by the object\ndetector. The Object Disappearance Algorithm constructs perturbation on a clean\nsocial image. After being injected with the perturbation, the social image can\neasily fool the object detector, while its visual quality will not be degraded.\nWe use two metrics, privacy-preserving success rate and privacy leakage rate,\nto evaluate the effectiveness of the proposed method. Experimental results show\nthat, the proposed method can effectively protect the privacy of social images.\nThe privacy-preserving success rates of the proposed method on MS-COCO and\nPASCAL VOC 2007 datasets are high up to 96.1% and 99.3%, respectively, and the\nprivacy leakage rates on these two datasets are as low as 0.57% and 0.07%,\nrespectively. In addition, compared with existing image processing methods (low\nbrightness, noise, blur, mosaic and JPEG compression), the proposed method can\nachieve much better performance in privacy protection and image visual quality\nmaintenance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 05:12:47 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Xue", "Mingfu", ""], ["Sun", "Shichang", ""], ["Wu", "Zhiyu", ""], ["He", "Can", ""], ["Wang", "Jian", ""], ["Liu", "Weiqiang", ""]]}, {"id": "2011.13570", "submitter": "Yekyung Kim", "authors": "Yekyung Kim", "title": "Deep Active Learning for Sequence Labeling Based on Diversity and\n  Uncertainty in Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies have investigated active learning (AL) for natural\nlanguage processing tasks to alleviate data dependency. However, for query\nselection, most of these studies mainly rely on uncertainty-based sampling,\nwhich generally does not exploit the structural information of the unlabeled\ndata. This leads to a sampling bias in the batch active learning setting, which\nselects several samples at once. In this work, we demonstrate that the amount\nof labeled training data can be reduced using active learning when it\nincorporates both uncertainty and diversity in the sequence labeling task. We\nexamined the effects of our sequence-based approach by selecting weighted\ndiverse in the gradient embedding approach across multiple tasks, datasets,\nmodels, and consistently outperform classic uncertainty-based sampling and\ndiversity-based sampling.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 06:03:27 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kim", "Yekyung", ""]]}, {"id": "2011.13574", "submitter": "Jun Kuang", "authors": "Yixin Cao, Jun Kuang, Ming Gao, Aoying Zhou, Yonggang Wen, Tat-Seng\n  Chua", "title": "Learning Relation Prototype from Unlabeled Texts for Long-tail Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Relation Extraction (RE) is a vital step to complete Knowledge Graph (KG) by\nextracting entity relations from texts.However, it usually suffers from the\nlong-tail issue. The training data mainly concentrates on a few types of\nrelations, leading to the lackof sufficient annotations for the remaining types\nof relations. In this paper, we propose a general approach to learn relation\nprototypesfrom unlabeled texts, to facilitate the long-tail relation extraction\nby transferring knowledge from the relation types with sufficient trainingdata.\nWe learn relation prototypes as an implicit factor between entities, which\nreflects the meanings of relations as well as theirproximities for transfer\nlearning. Specifically, we construct a co-occurrence graph from texts, and\ncapture both first-order andsecond-order entity proximities for embedding\nlearning. Based on this, we further optimize the distance from entity pairs\ntocorresponding prototypes, which can be easily adapted to almost arbitrary RE\nframeworks. Thus, the learning of infrequent or evenunseen relation types will\nbenefit from semantically proximate relations through pairs of entities and\nlarge-scale textual information.We have conducted extensive experiments on two\npublicly available datasets: New York Times and Google Distant\nSupervision.Compared with eight state-of-the-art baselines, our proposed model\nachieves significant improvements (4.1% F1 on average). Furtherresults on\nlong-tail relations demonstrate the effectiveness of the learned relation\nprototypes. We further conduct an ablation study toinvestigate the impacts of\nvarying components, and apply it to four basic relation extraction models to\nverify the generalization ability.Finally, we analyze several example cases to\ngive intuitive impressions as qualitative analysis. Our codes will be released\nlater.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 06:21:12 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Cao", "Yixin", ""], ["Kuang", "Jun", ""], ["Gao", "Ming", ""], ["Zhou", "Aoying", ""], ["Wen", "Yonggang", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2011.13577", "submitter": "Katherine Malan Prof", "authors": "Belinda Stapelberg and Katherine M. Malan", "title": "A survey of benchmarking frameworks for reinforcement learning", "comments": null, "journal-ref": null, "doi": "10.18489/sacj.v32i2.746", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reinforcement learning has recently experienced increased prominence in the\nmachine learning community. There are many approaches to solving reinforcement\nlearning problems with new techniques developed constantly. When solving\nproblems using reinforcement learning, there are various difficult challenges\nto overcome. To ensure progress in the field, benchmarks are important for\ntesting new algorithms and comparing with other approaches. The reproducibility\nof results for fair comparison is therefore vital in ensuring that improvements\nare accurately judged. This paper provides an overview of different\ncontributions to reinforcement learning benchmarking and discusses how they can\nassist researchers to address the challenges facing reinforcement learning. The\ncontributions discussed are the most used and recent in the literature. The\npaper discusses the contributions in terms of implementation, tasks and\nprovided algorithm implementations with benchmarks. The survey aims to bring\nattention to the wide range of reinforcement learning benchmarking tasks\navailable and to encourage research to take place in a standardised manner.\nAdditionally, this survey acts as an overview for researchers not familiar with\nthe different tasks that can be used to develop and test new reinforcement\nlearning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 06:32:09 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Stapelberg", "Belinda", ""], ["Malan", "Katherine M.", ""]]}, {"id": "2011.13584", "submitter": "Siwei Chen", "authors": "Jeffrey Fong, Siwei Chen, Kaiqi Chen", "title": "Improving Layer-wise Adaptive Rate Methods using Trust Ratio Clipping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training neural networks with large batch is of fundamental significance to\ndeep learning. Large batch training remarkably reduces the amount of training\ntime but has difficulties in maintaining accuracy. Recent works have put\nforward optimization methods such as LARS and LAMB to tackle this issue through\nadaptive layer-wise optimization using trust ratios. Though prevailing, such\nmethods are observed to still suffer from unstable and extreme trust ratios\nwhich degrades performance. In this paper, we propose a new variant of LAMB,\ncalled LAMBC, which employs trust ratio clipping to stabilize its magnitude and\nprevent extreme values. We conducted experiments on image classification tasks\nsuch as ImageNet and CIFAR-10 and our empirical results demonstrate promising\nimprovements across different batch sizes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 07:20:08 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fong", "Jeffrey", ""], ["Chen", "Siwei", ""], ["Chen", "Kaiqi", ""]]}, {"id": "2011.13588", "submitter": "Yafu Tian", "authors": "Yafu Tian, Alexander Carballo, Ruifeng Li and Kazuya Takeda", "title": "Road Scene Graph: A Semantic Graph-Based Scene Representation Dataset\n  for Intelligent Vehicles", "comments": "8 pages, 8 figures, under review ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rich semantic information extraction plays a vital role on next-generation\nintelligent vehicles. Currently there is great amount of research focusing on\nfundamental applications such as 6D pose detection, road scene semantic\nsegmentation, etc. And this provides us a great opportunity to think about how\nshall these data be organized and exploited.\n  In this paper we propose road scene graph,a special scene-graph for\nintelligent vehicles. Different to classical data representation, this graph\nprovides not only object proposals but also their pair-wise relationships. By\norganizing them in a topological graph, these data are explainable,\nfully-connected, and could be easily processed by GCNs (Graph Convolutional\nNetworks). Here we apply scene graph on roads using our Road Scene Graph\ndataset, including the basic graph prediction model. This work also includes\nexperimental evaluations using the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 07:33:11 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Tian", "Yafu", ""], ["Carballo", "Alexander", ""], ["Li", "Ruifeng", ""], ["Takeda", "Kazuya", ""]]}, {"id": "2011.13591", "submitter": "Shengran Hu", "authors": "Shengran Hu, Ran Cheng, Cheng He, Zhichao Lu", "title": "Multi-objective Neural Architecture Search with Almost No Training", "comments": "EMO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the recent past, neural architecture search (NAS) has attracted increasing\nattention from both academia and industries. Despite the steady stream of\nimpressive empirical results, most existing NAS algorithms are computationally\nprohibitive to execute due to the costly iterations of stochastic gradient\ndescent (SGD) training. In this work, we propose an effective alternative,\ndubbed Random-Weight Evaluation (RWE), to rapidly estimate the performance of\nnetwork architectures. By just training the last linear classification layer,\nRWE reduces the computational cost of evaluating an architecture from hours to\nseconds. When integrated within an evolutionary multi-objective algorithm, RWE\nobtains a set of efficient architectures with state-of-the-art performance on\nCIFAR-10 with less than two hours' searching on a single GPU card. Ablation\nstudies on rank-order correlations and transfer learning experiments to\nImageNet have further validated the effectiveness of RWE.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 07:39:17 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hu", "Shengran", ""], ["Cheng", "Ran", ""], ["He", "Cheng", ""], ["Lu", "Zhichao", ""]]}, {"id": "2011.13609", "submitter": "Kaixin Gao", "authors": "Kai-Xin Gao, Xiao-Lei Liu, Zheng-Hai Huang, Min Wang, Shuangling Wang,\n  Zidong Wang, Dachuan Xu, Fan Yu", "title": "Eigenvalue-corrected Natural Gradient Based on a New Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Using second-order optimization methods for training deep neural networks\n(DNNs) has attracted many researchers. A recently proposed method,\nEigenvalue-corrected Kronecker Factorization (EKFAC) (George et al., 2018),\nproposes an interpretation of viewing natural gradient update as a diagonal\nmethod, and corrects the inaccurate re-scaling factor in the Kronecker-factored\neigenbasis. Gao et al. (2020) considers a new approximation to the natural\ngradient, which approximates the Fisher information matrix (FIM) to a constant\nmultiplied by the Kronecker product of two matrices and keeps the trace equal\nbefore and after the approximation. In this work, we combine the ideas of these\ntwo methods and propose Trace-restricted Eigenvalue-corrected Kronecker\nFactorization (TEKFAC). The proposed method not only corrects the inexact\nre-scaling factor under the Kronecker-factored eigenbasis, but also considers\nthe new approximation method and the effective damping technique proposed in\nGao et al. (2020). We also discuss the differences and relationships among the\nKronecker-factored approximations. Empirically, our method outperforms SGD with\nmomentum, Adam, EKFAC and TKFAC on several DNNs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 08:57:29 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Gao", "Kai-Xin", ""], ["Liu", "Xiao-Lei", ""], ["Huang", "Zheng-Hai", ""], ["Wang", "Min", ""], ["Wang", "Shuangling", ""], ["Wang", "Zidong", ""], ["Xu", "Dachuan", ""], ["Yu", "Fan", ""]]}, {"id": "2011.13629", "submitter": "Pengfei Wei", "authors": "Pengfei Wei and Tze Yun Leong", "title": "Randomized Transferable Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Feature-based transfer is one of the most effective methodologies for\ntransfer learning. Existing studies usually assume that the learned new feature\nrepresentation is truly \\emph{domain-invariant}, and thus directly train a\ntransfer model $\\mathcal{M}$ on source domain. In this paper, we consider a\nmore realistic scenario where the new feature representation is suboptimal and\nsmall divergence still exists across domains. We propose a new learning\nstrategy with a transfer model called Randomized Transferable Machine (RTM).\nMore specifically, we work on source data with the new feature representation\nlearned from existing feature-based transfer methods. The key idea is to\nenlarge source training data populations by randomly corrupting source data\nusing some noises, and then train a transfer model $\\widetilde{\\mathcal{M}}$\nthat performs well on all the corrupted source data populations. In principle,\nthe more corruptions are made, the higher the probability of the target data\ncan be covered by the constructed source populations, and thus better transfer\nperformance can be achieved by $\\widetilde{\\mathcal{M}}$. An ideal case is with\ninfinite corruptions, which however is infeasible in reality. We develop a\nmarginalized solution with linear regression model and dropout noise. With a\nmarginalization trick, we can train an RTM that is equivalently to training\nusing infinite source noisy populations without truly conducting any\ncorruption. More importantly, such an RTM has a closed-form solution, which\nenables very fast and efficient training. Extensive experiments on various\nreal-world transfer tasks show that RTM is a promising transfer model.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 09:37:01 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Wei", "Pengfei", ""], ["Leong", "Tze Yun", ""]]}, {"id": "2011.13634", "submitter": "Apostolos Avranas Mr", "authors": "Apostolos Avranas (EURECOM), Marios Kountouris (EURECOM), Philippe\n  Ciblat (T\\'el\\'ecom Paris)", "title": "Deep Reinforcement Learning for Wireless Scheduling with Multiclass\n  Services", "comments": "Corrected typos on formulas, Header removed, Corrected a misplaced\n  paragraph on B.1.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we investigate the problem of scheduling and resource\nallocation over a time varying set of clients with heterogeneous demands.In\nthis context, a service provider has to schedule traffic destined to users with\ndifferent classes of requirements and to allocate bandwidth resources over time\nas a means to efficiently satisfy service demands within a limited time\nhorizon. This is a highly intricate problem, in particular in wireless\ncommunication systems, and solutions may involve tools stemming from diverse\nfields, including combinatorics and constrained optimization. Although recent\nwork has successfully proposed solutions based on Deep Reinforcement Learning\n(DRL), the challenging setting of heterogeneous user traffic and demands has\nnot been addressed. We propose a deep deterministic policy gradient algorithm\nthat combines state-of-the-art techniques, namely Distributional RL and Deep\nSets, to train a model for heterogeneous traffic scheduling. We test on diverse\nscenarios with different time dependence dynamics, users' requirements, and\nresources available, demonstrating consistent results using both synthetic and\nreal data. We evaluate the algorithm on a wireless communication setting using\nboth synthetic and real data and show significant gains in terms of Quality of\nService (QoS) defined by the classes, against state-of-the-art conventional\nalgorithms from combinatorics, optimization and scheduling metric(e.g.\nKnapsack, Integer Linear Programming, Frank-Wolfe, Exponential Rule).\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 09:49:38 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:07:06 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Avranas", "Apostolos", "", "EURECOM"], ["Kountouris", "Marios", "", "EURECOM"], ["Ciblat", "Philippe", "", "T\u00e9l\u00e9com Paris"]]}, {"id": "2011.13647", "submitter": "Kanjirangat Vani", "authors": "Simone Mellace, K Vani, Alessandro Antonucci", "title": "Relation Clustering in Narrative Knowledge Graphs", "comments": "Accepted for AI4Narratives Workshop at 29th International Joint\n  Conference on Artificial Intelligence and the 17th Pacific Rim International\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When coping with literary texts such as novels or short stories, the\nextraction of structured information in the form of a knowledge graph might be\nhindered by the huge number of possible relations between the entities\ncorresponding to the characters in the novel and the consequent hurdles in\ngathering supervised information about them. Such issue is addressed here as an\nunsupervised task empowered by transformers: relational sentences in the\noriginal text are embedded (with SBERT) and clustered in order to merge\ntogether semantically similar relations. All the sentences in the same cluster\nare finally summarized (with BART) and a descriptive label extracted from the\nsummary. Preliminary tests show that such clustering might successfully detect\nsimilar relations, and provide a valuable preprocessing for semi-supervised\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 10:43:04 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Mellace", "Simone", ""], ["Vani", "K", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "2011.13704", "submitter": "J\\\"org L\\\"ucke", "authors": "Enrico Guiraud, Jakob Drefs, J\\\"org L\\\"ucke", "title": "Direct Evolutionary Optimization of Variational Autoencoders With Binary\n  Latents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discrete latent variables are considered important for real world data, which\nhas motivated research on Variational Autoencoders (VAEs) with discrete\nlatents. However, standard VAE-training is not possible in this case, which has\nmotivated different strategies to manipulate discrete distributions in order to\ntrain discrete VAEs similarly to conventional ones. Here we ask if it is also\npossible to keep the discrete nature of the latents fully intact by applying a\ndirect discrete optimization for the encoding model. The approach is\nconsequently strongly diverting from standard VAE-training by sidestepping\nsampling approximation, reparameterization trick and amortization. Discrete\noptimization is realized in a variational setting using truncated posteriors in\nconjunction with evolutionary algorithms. For VAEs with binary latents, we (A)\nshow how such a discrete variational method ties into gradient ascent for\nnetwork weights, and (B) how the decoder is used to select latent states for\ntraining. Conventional amortized training is more efficient and applicable to\nlarge neural networks. However, using smaller networks, we here find direct\ndiscrete optimization to be efficiently scalable to hundreds of latents. More\nimportantly, we find the effectiveness of direct optimization to be highly\ncompetitive in `zero-shot' learning. In contrast to large supervised networks,\nthe here investigated VAEs can, e.g., denoise a single image without previous\ntraining on clean data and/or training on large image datasets. More generally,\nthe studied approach shows that training of VAEs is indeed possible without\nsampling-based approximation and reparameterization, which may be interesting\nfor the analysis of VAE-training in general. For `zero-shot' settings a direct\noptimization, furthermore, makes VAEs competitive where they have previously\nbeen outperformed by non-generative approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 12:42:12 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Guiraud", "Enrico", ""], ["Drefs", "Jakob", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "2011.13714", "submitter": "Aishwarya Jadhav", "authors": "Aishwarya Jadhav", "title": "Detection of Malaria Vector Breeding Habitats using Topographic Models", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Treatment of stagnant water bodies that act as a breeding site for malarial\nvectors is a fundamental step in most malaria elimination campaigns. However,\nidentification of such water bodies over large areas is expensive,\nlabour-intensive and time-consuming and hence, challenging in countries with\nlimited resources. Practical models that can efficiently locate water bodies\ncan target the limited resources by greatly reducing the area that needs to be\nscanned by the field workers. To this end, we propose a practical topographic\nmodel based on easily available, global, high-resolution DEM data to predict\nlocations of potential vector-breeding water sites. We surveyed the Obuasi\nregion of Ghana to assess the impact of various topographic features on\ndifferent types of water bodies and uncover the features that significantly\ninfluence the formation of aquatic habitats. We further evaluate the\neffectiveness of multiple models. Our best model significantly outperforms\nearlier attempts that employ topographic variables for detection of small water\nsites, even the ones that utilize additional satellite imagery data and\ndemonstrates robustness across different settings.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 12:59:55 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Jadhav", "Aishwarya", ""]]}, {"id": "2011.13719", "submitter": "Ran Wang", "authors": "Haojing Shen, Sihong Chen, Ran Wang", "title": "A Study on the Uncertainty of Convolutional Layers in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper shows a Min-Max property existing in the connection weights of the\nconvolutional layers in a neural network structure, i.e., the LeNet.\nSpecifically, the Min-Max property means that, during the back\npropagation-based training for LeNet, the weights of the convolutional layers\nwill become far away from their centers of intervals, i.e., decreasing to their\nminimum or increasing to their maximum. From the perspective of uncertainty, we\ndemonstrate that the Min-Max property corresponds to minimizing the fuzziness\nof the model parameters through a simplified formulation of convolution. It is\nexperimentally confirmed that the model with the Min-Max property has a\nstronger adversarial robustness, thus this property can be incorporated into\nthe design of loss function. This paper points out a changing tendency of\nuncertainty in the convolutional layers of LeNet structure, and gives some\ninsights to the interpretability of convolution.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 13:06:36 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Shen", "Haojing", ""], ["Chen", "Sihong", ""], ["Wang", "Ran", ""]]}, {"id": "2011.13726", "submitter": "Keun-Young Kim", "authors": "Mugeon Song, Maverick S. H. Oh, Yongjun Ahn, and Keun-Young Kim", "title": "AdS/Deep-Learning made easy: simple examples", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.class-ph cs.LG hep-th", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning has been widely and actively used in various research areas.\nRecently, in the gauge/gravity duality, a new deep learning technique so-called\nthe AdS/Deep-Learning (DL) has been proposed [1, 2]. The goal of this paper is\nto describe the essence of the AdS/DL in the simplest possible setups, for\nthose who want to apply it to the subject of emergent spacetime as a neural\nnetwork. For prototypical examples, we choose simple classical mechanics\nproblems. This method is a little different from standard deep learning\ntechniques in the sense that not only do we have the right final answers but\nalso obtain a physical understanding of learning parameters.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 13:23:18 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 16:39:56 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Song", "Mugeon", ""], ["Oh", "Maverick S. H.", ""], ["Ahn", "Yongjun", ""], ["Kim", "Keun-Young", ""]]}, {"id": "2011.13728", "submitter": "Niladri Shekhar Dutt", "authors": "Niladri Shekhar Dutt, Sunil Patel", "title": "A study of traits that affect learnability in GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks GANs are algorithmic architectures that use\ntwo neural networks, pitting one against the opposite so as to come up with\nnew, synthetic instances of data that can pass for real data. Training a GAN is\na challenging problem which requires us to apply advanced techniques like\nhyperparameter tuning, architecture engineering etc. Many different losses,\nregularization and normalization schemes, network architectures have been\nproposed to solve this challenging problem for different types of datasets. It\nbecomes necessary to understand the experimental observations and deduce a\nsimple theory for it. In this paper, we perform empirical experiments using\nparameterized synthetic datasets to probe what traits affect learnability.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 13:31:37 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Dutt", "Niladri Shekhar", ""], ["Patel", "Sunil", ""]]}, {"id": "2011.13729", "submitter": "Lei Han", "authors": "Lei Han, Jiechao Xiong, Peng Sun, Xinghai Sun, Meng Fang, Qingwei Guo,\n  Qiaobo Chen, Tengfei Shi, Hongsheng Yu, Xipeng Wu, Zhengyou Zhang", "title": "TStarBot-X: An Open-Sourced and Comprehensive Study for Efficient League\n  Training in StarCraft II Full Game", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  StarCraft, one of the most difficult esport games with long-standing history\nof professional tournaments, has attracted generations of players and fans, and\nalso, intense attentions in artificial intelligence research. Recently,\nGoogle's DeepMind announced AlphaStar, a grandmaster level AI in StarCraft II\nthat can play with humans using comparable action space and operations. In this\npaper, we introduce a new AI agent, named TStarBot-X, that is trained under\norders of less computations and can play competitively with expert human\nplayers. TStarBot-X takes advantage of important techniques introduced in\nAlphaStar, and also benefits from substantial innovations including new league\ntraining methods, novel multi-agent roles, rule-guided policy search,\nstabilized policy improvement, lightweight neural network architecture, and\nimportance sampling in imitation learning, etc. We show that with orders of\nless computation scale, a faithful reimplementation of AlphaStar's methods can\nnot succeed and the proposed techniques are necessary to ensure TStarBot-X's\ncompetitive performance. We reveal all technical details that are complementary\nto those mentioned in AlphaStar, showing the most sensitive parts in league\ntraining, reinforcement learning and imitation learning that affect the\nperformance of the agents. Most importantly, this is an open-sourced study that\nall codes and resources (including the trained model parameters) are publicly\naccessible via \\url{https://github.com/tencent-ailab/tleague_projpage}. We\nexpect this study could be beneficial for both academic and industrial future\nresearch in solving complex problems like StarCraft, and also, might provide a\nsparring partner for all StarCraft II players and other AI agents.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 13:31:49 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 08:31:32 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Han", "Lei", ""], ["Xiong", "Jiechao", ""], ["Sun", "Peng", ""], ["Sun", "Xinghai", ""], ["Fang", "Meng", ""], ["Guo", "Qingwei", ""], ["Chen", "Qiaobo", ""], ["Shi", "Tengfei", ""], ["Yu", "Hongsheng", ""], ["Wu", "Xipeng", ""], ["Zhang", "Zhengyou", ""]]}, {"id": "2011.13741", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul, Puranjay Mohan, Stuti Sehgal", "title": "Rethinking Generalization in American Sign Language Prediction for Edge\n  Devices with Extremely Low Memory Footprint", "comments": "6 pages, Published in IEEE RAICS 2020, see https://raics.in", "journal-ref": "2020 IEEE Recent Advances in Intelligent Computational Systems\n  (RAICS), 2020, pp. 147-152", "doi": "10.1109/RAICS51191.2020.9332480", "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the boom in technical compute in the last few years, the world has\nseen massive advances in artificially intelligent systems solving diverse\nreal-world problems. But a major roadblock in the ubiquitous acceptance of\nthese models is their enormous computational complexity and memory footprint.\nHence efficient architectures and training techniques are required for\ndeployment on extremely low resource inference endpoints. This paper proposes\nan architecture for detection of alphabets in American Sign Language on an ARM\nCortex-M7 microcontroller having just 496 KB of framebuffer RAM. Leveraging\nparameter quantization is a common technique that might cause varying drops in\ntest accuracy. This paper proposes using interpolation as augmentation amongst\nother techniques as an efficient method of reducing this drop, which also helps\nthe model generalize well to previously unseen noisy data. The proposed model\nis about 185 KB post-quantization and inference speed is 20 frames per second.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 14:05:42 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 10:24:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Paul", "Aditya Jyoti", ""], ["Mohan", "Puranjay", ""], ["Sehgal", "Stuti", ""]]}, {"id": "2011.13744", "submitter": "Arash Hooshmand", "authors": "Arash Hooshmand", "title": "Reinforcement Learning-based Joint Path and Energy Optimization of\n  Cellular-Connected Unmanned Aerial Vehicles", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) have attracted considerable research interest\nrecently. Especially when it comes to the realm of Internet of Things, the UAVs\nwith Internet connectivity are one of the main demands. Furthermore, the energy\nconstraint i.e. battery limit is a bottle-neck of the UAVs that can limit their\napplications. We try to address and solve the energy problem. Therefore, a path\nplanning method for a cellular-connected UAV is proposed that will enable the\nUAV to plan its path in an area much larger than its battery range by getting\nrecharged in certain positions equipped with power stations (PSs). In addition\nto the energy constraint, there are also no-fly zones; for example, due to Air\nto Air (A2A) and Air to Ground (A2G) interference or for lack of necessary\nconnectivity that impose extra constraints in the trajectory optimization of\nthe UAV. No-fly zones determine the infeasible areas that should be avoided. We\nhave used a reinforcement learning (RL) hierarchically to extend typical\nshort-range path planners to consider battery recharge and solve the problem of\nUAVs in long missions. The problem is simulated for the UAV that flies over a\nlarge area, and Q-learning algorithm could enable the UAV to find the optimal\npath and recharge policy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 14:16:55 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hooshmand", "Arash", ""]]}, {"id": "2011.13772", "submitter": "Hung-Hsu Chou", "authors": "Hung-Hsu Chou, Carsten Gieshoff, Johannes Maly, Holger Rauhut", "title": "Gradient Descent for Deep Matrix Factorization: Dynamics and Implicit\n  Bias towards Low Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many deep learning scenarios more network parameters than training\nexamples are used. In such situations often several networks can be found that\nexactly interpolate the data. This means that the used learning algorithm\ninduces an implicit bias on the chosen network. This paper aims at shedding\nsome light on the nature of such implicit bias in a certain simpified setting\nof linear networks, i.e., deep matrix factorizations. We provide a rigorous\nanalysis of the dynamics of vanilla gradient descent. We characterize the\ndynamical behaviour of ground-truth eigenvectors and convergence of the\ncorresponding eigenvalues to the true ones. As a consequence, for exactly\ncharacterized time intervals, the effective rank of gradient descent iterates\nis provably close to the effective rank of a low-rank projection of the\nground-truth matrix, such that early stopping of gradient descent produces\nregularized solutions that may be used for denoising, for instance. In\nparticular, apart from few initial steps of the iterations, the effective rank\nof our matrix is monotonically increasing, suggesting that \"matrix\nfactorization implicitly enforces gradient descent to take a route in which the\neffective rank is monotone\". Since empirical observations in more general\nscenarios such as matrix sensing show a similar phenomenon, we believe that our\ntheoretical results help understanding the still mysterious \"implicit bias\" of\ngradient descent in deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 15:08:34 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 13:30:52 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 08:35:00 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Chou", "Hung-Hsu", ""], ["Gieshoff", "Carsten", ""], ["Maly", "Johannes", ""], ["Rauhut", "Holger", ""]]}, {"id": "2011.13775", "submitter": "Denis Korzhenkov", "authors": "Ivan Anokhin, Kirill Demochkin, Taras Khakhulin, Gleb Sterkin, Victor\n  Lempitsky, Denis Korzhenkov", "title": "Image Generators with Conditionally-Independent Pixel Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing image generator networks rely heavily on spatial convolutions and,\noptionally, self-attention blocks in order to gradually synthesize images in a\ncoarse-to-fine manner. Here, we present a new architecture for image\ngenerators, where the color value at each pixel is computed independently given\nthe value of a random latent vector and the coordinate of that pixel. No\nspatial convolutions or similar operations that propagate information across\npixels are involved during the synthesis. We analyze the modeling capabilities\nof such generators when trained in an adversarial fashion, and observe the new\ngenerators to achieve similar generation quality to state-of-the-art\nconvolutional generators. We also investigate several interesting properties\nunique to the new architecture.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 15:16:11 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Anokhin", "Ivan", ""], ["Demochkin", "Kirill", ""], ["Khakhulin", "Taras", ""], ["Sterkin", "Gleb", ""], ["Lempitsky", "Victor", ""], ["Korzhenkov", "Denis", ""]]}, {"id": "2011.13786", "submitter": "Andrey Voynov", "authors": "Anton Cherepkov, Andrey Voynov, Artem Babenko", "title": "Navigating the GAN Parameter Space for Semantic Image Editing", "comments": "Supplementary code: https://github.com/yandex-research/navigan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are currently an indispensable tool\nfor visual editing, being a standard component of image-to-image translation\nand image restoration pipelines. Furthermore, GANs are especially useful for\ncontrollable generation since their latent spaces contain a wide range of\ninterpretable directions, well suited for semantic editing operations. By\ngradually changing latent codes along these directions, one can produce\nimpressive visual effects, unattainable without GANs.\n  In this paper, we significantly expand the range of visual effects achievable\nwith the state-of-the-art models, like StyleGAN2. In contrast to existing\nworks, which mostly operate by latent codes, we discover interpretable\ndirections in the space of the generator parameters. By several simple methods,\nwe explore this space and demonstrate that it also contains a plethora of\ninterpretable directions, which are an excellent source of non-trivial semantic\nmanipulations. The discovered manipulations cannot be achieved by transforming\nthe latent codes and can be used to edit both synthetic and real images. We\nrelease our code and models and hope they will serve as a handy tool for\nfurther efforts on GAN-based image editing.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 15:38:56 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 12:34:59 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 12:45:11 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Cherepkov", "Anton", ""], ["Voynov", "Andrey", ""], ["Babenko", "Artem", ""]]}, {"id": "2011.13788", "submitter": "Guojing Cong", "authors": "Leili Zhang, Giacomo Domeniconi, Chih-Chieh Yang, Seung-gu Kang,\n  Ruhong Zhou, Guojing Cong", "title": "CASTELO: Clustered Atom Subtypes aidEd Lead Optimization -- a combined\n  machine learning and molecular modeling method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drug discovery is a multi-stage process that comprises two costly major\nsteps: pre-clinical research and clinical trials. Among its stages, lead\noptimization easily consumes more than half of the pre-clinical budget. We\npropose a combined machine learning and molecular modeling approach that\nautomates lead optimization workflow \\textit{in silico}. The initial data\ncollection is achieved with physics-based molecular dynamics (MD) simulation.\nContact matrices are calculated as the preliminary features extracted from the\nsimulations. To take advantage of the temporal information from the\nsimulations, we enhanced contact matrices data with temporal dynamism\nrepresentation, which are then modeled with unsupervised convolutional\nvariational autoencoder (CVAE). Finally, conventional clustering method and\nCVAE-based clustering method are compared with metrics to rank the submolecular\nstructures and propose potential candidates for lead optimization. With no need\nfor extensive structure-activity relationship database, our method provides new\nhints for drug modification hotspots which can be used to improve drug\nefficacy. Our workflow can potentially reduce the lead optimization turnaround\ntime from months/years to days compared with the conventional labor-intensive\nprocess and thus can potentially become a valuable tool for medical\nresearchers.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 15:41:00 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhang", "Leili", ""], ["Domeniconi", "Giacomo", ""], ["Yang", "Chih-Chieh", ""], ["Kang", "Seung-gu", ""], ["Zhou", "Ruhong", ""], ["Cong", "Guojing", ""]]}, {"id": "2011.13824", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin,\n  Cho-Jui Hsieh", "title": "Fast and Complete: Enabling Complete Neural Network Verification with\n  Rapid and Massively Parallel Incomplete Verifiers", "comments": "Accepted by ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Formal verification of neural networks (NNs) is a challenging and important\nproblem. Existing efficient complete solvers typically require the\nbranch-and-bound (BaB) process, which splits the problem domain into\nsub-domains and solves each sub-domain using faster but weaker incomplete\nverifiers, such as Linear Programming (LP) on linearly relaxed sub-domains. In\nthis paper, we propose to use the backward mode linear relaxation based\nperturbation analysis (LiRPA) to replace LP during the BaB process, which can\nbe efficiently implemented on the typical machine learning accelerators such as\nGPUs and TPUs. However, unlike LP, LiRPA when applied naively can produce much\nweaker bounds and even cannot check certain conflicts of sub-domains during\nsplitting, making the entire procedure incomplete after BaB. To address these\nchallenges, we apply a fast gradient based bound tightening procedure combined\nwith batch splits and the design of minimal usage of LP bound procedure,\nenabling us to effectively use LiRPA on the accelerator hardware for the\nchallenging complete NN verification problem and significantly outperform\nLP-based approaches. On a single GPU, we demonstrate an order of magnitude\nspeedup compared to existing LP-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 16:42:12 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 16:35:00 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Xu", "Kaidi", ""], ["Zhang", "Huan", ""], ["Wang", "Shiqi", ""], ["Wang", "Yihan", ""], ["Jana", "Suman", ""], ["Lin", "Xue", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2011.13831", "submitter": "Pierre Ablin", "authors": "Pierre Ablin", "title": "Deep orthogonal linear networks are shallow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of training a deep orthogonal linear network, which\nconsists of a product of orthogonal matrices, with no non-linearity in-between.\nWe show that training the weights with Riemannian gradient descent is\nequivalent to training the whole factorization by gradient descent. This means\nthat there is no effect of overparametrization and implicit bias at all in this\nsetting: training such a deep, overparametrized, network is perfectly\nequivalent to training a one-layer shallow network.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 16:57:19 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ablin", "Pierre", ""]]}, {"id": "2011.13832", "submitter": "Nabarun Mondal Mr", "authors": "Nabarun Mondal, Mrunal Lohia", "title": "Supervised Text Classification using Text Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised text classification is a classical and active area of ML research.\nIn large enterprise, solutions to this problem has significant importance. This\nis specifically true in ticketing systems where prediction of the type and\nsubtype of tickets given new incoming ticket text to find out optimal routing\nis a multi billion dollar industry.\n  In this paper authors describe a class of industrial standard algorithms\nwhich can accurately ( 86\\% and above ) predict classification of any text\ngiven prior labelled text data - by novel use of any text search engine.\n  These algorithms were used to automate routing of issue tickets to the\nappropriate team. This class of algorithms has far reaching consequences for a\nwide variety of industrial applications, IT support, RPA script triggering,\neven legal domain where massive set of pre labelled data are already available.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 19:51:51 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 19:53:45 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Mondal", "Nabarun", ""], ["Lohia", "Mrunal", ""]]}, {"id": "2011.13844", "submitter": "James Smith", "authors": "James E. Smith", "title": "A Temporal Neural Network Architecture for Online Learning", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing proposition is that by emulating the operation of the brain's\nneocortex, a spiking neural network (SNN) can achieve similar desirable\nfeatures: flexible learning, speed, and efficiency. Temporal neural networks\n(TNNs) are SNNs that communicate and process information encoded as relative\nspike times (in contrast to spike rates). A TNN architecture is proposed, and,\nas a proof-of-concept, TNN operation is demonstrated within the larger context\nof online supervised classification. First, through unsupervised learning, a\nTNN partitions input patterns into clusters based on similarity. The TNN then\npasses a cluster identifier to a simple online supervised decoder which\nfinishes the classification task. The TNN learning process adjusts synaptic\nweights by using only signals local to each synapse, and clustering behavior\nemerges globally. The system architecture is described at an abstraction level\nanalogous to the gate and register transfer levels in conventional digital\ndesign. Besides features of the overall architecture, several TNN components\nare new to this work. Although not addressed directly, the overall research\nobjective is a direct hardware implementation of TNNs. Consequently, all the\narchitecture elements are simple, and processing is done at very low precision.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 17:15:29 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 22:29:32 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Smith", "James E.", ""]]}, {"id": "2011.13847", "submitter": "Vieri Giuliano Santucci", "authors": "Vieri Giuliano Santucci and Davide Montella and Bruno Castro da Silva\n  and Gianluca Baldassarre", "title": "Autonomous learning of multiple, context-dependent tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When facing the problem of autonomously learning multiple tasks with\nreinforcement learning systems, researchers typically focus on solutions where\njust one parametrised policy per task is sufficient to solve them. However, in\ncomplex environments presenting different contexts, the same task might need a\nset of different skills to be solved. These situations pose two challenges: (a)\nto recognise the different contexts that need different policies; (b) quickly\nlearn the policies to accomplish the same tasks in the new discovered contexts.\nThese two challenges are even harder if faced within an open-ended learning\nframework where an agent has to autonomously discover the goals that it might\naccomplish in a given environment, and also to learn the motor skills to\naccomplish them. We propose a novel open-ended learning robot architecture,\nC-GRAIL, that solves the two challenges in an integrated fashion. In\nparticular, the architecture is able to detect new relevant contests, and\nignore irrelevant ones, on the basis of the decrease of the expected\nperformance for a given goal. Moreover, the architecture can quickly learn the\npolicies for the new contexts by exploiting transfer learning importing\nknowledge from already acquired policies. The architecture is tested in a\nsimulated robotic environment involving a robot that autonomously learns to\nreach relevant target objects in the presence of multiple obstacles generating\nseveral different obstacles. The proposed architecture outperforms other models\nnot using the proposed autonomous context-discovery and transfer-learning\nmechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 17:25:36 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Santucci", "Vieri Giuliano", ""], ["Montella", "Davide", ""], ["da Silva", "Bruno Castro", ""], ["Baldassarre", "Gianluca", ""]]}, {"id": "2011.13849", "submitter": "Reza Maalek", "authors": "Reza Maalek and Derek Lichti", "title": "Robust Detection of Non-overlapping Ellipses from Points with\n  Applications to Circular Target Extraction in Images and Cylinder Detection\n  in Point Clouds", "comments": null, "journal-ref": null, "doi": "10.1016/j.isprsjprs.2021.04.010", "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This manuscript provides a collection of new methods for the automated\ndetection of non-overlapping ellipses from edge points. The methods introduce\nnew developments in: (i) robust Monte Carlo-based ellipse fitting to\n2-dimensional (2D) points in the presence of outliers; (ii) detection of\nnon-overlapping ellipse from 2D edge points; and (iii) extraction of cylinder\nfrom 3D point clouds. The proposed methods were thoroughly compared with\nestablished state-of-the-art methods, using simulated and real-world datasets,\nthrough the design of four sets of original experiments. It was found that the\nproposed robust ellipse detection was superior to four reliable robust methods,\nincluding the popular least median of squares, in both simulated and real-world\ndatasets. The proposed process for detecting non-overlapping ellipses achieved\nF-measure of 99.3% on real images, compared to F-measures of 42.4%, 65.6%, and\n59.2%, obtained using the methods of Fornaciari, Patraucean, and Panagiotakis,\nrespectively. The proposed cylinder extraction method identified all detectable\nmechanical pipes in two real-world point clouds, obtained under laboratory, and\nindustrial construction site conditions. The results of this investigation show\npromise for the application of the proposed methods for automatic extraction of\ncircular targets from images and pipes from point clouds.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 21:56:02 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 15:07:21 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 17:56:30 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Maalek", "Reza", ""], ["Lichti", "Derek", ""]]}, {"id": "2011.13851", "submitter": "Mahdi Rezaei", "authors": "Soheil Khatibi, Meisam Teimouri, Mahdi Rezaei", "title": "Real-time Active Vision for a Humanoid Soccer Robot Using Deep\n  Reinforcement Learning", "comments": "The paper has been accepted in ICAART 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present an active vision method using a deep reinforcement\nlearning approach for a humanoid soccer-playing robot. The proposed method\nadaptively optimises the viewpoint of the robot to acquire the most useful\nlandmarks for self-localisation while keeping the ball into its viewpoint.\nActive vision is critical for humanoid decision-maker robots with a limited\nfield of view. To deal with an active vision problem, several probabilistic\nentropy-based approaches have previously been proposed which are highly\ndependent on the accuracy of the self-localisation model. However, in this\nresearch, we formulate the problem as an episodic reinforcement learning\nproblem and employ a Deep Q-learning method to solve it. The proposed network\nonly requires the raw images of the camera to move the robot's head toward the\nbest viewpoint. The model shows a very competitive rate of 80% success rate in\nachieving the best viewpoint. We implemented the proposed method on a humanoid\nrobot simulated in Webots simulator. Our evaluations and experimental results\nshow that the proposed method outperforms the entropy-based methods in the\nRoboCup context, in cases with high self-localisation errors.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 17:29:48 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Khatibi", "Soheil", ""], ["Teimouri", "Meisam", ""], ["Rezaei", "Mahdi", ""]]}, {"id": "2011.13863", "submitter": "Clemens Hutter", "authors": "Clemens Hutter, Moritz von Stosch, Mariano Nicolas Cruz Bournazou,\n  Alessandro Butt\\'e", "title": "Knowledge transfer across cell lines using Hybrid Gaussian Process\n  models with entity embedding vectors", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To date, a large number of experiments are performed to develop a biochemical\nprocess. The generated data is used only once, to take decisions for\ndevelopment. Could we exploit data of already developed processes to make\npredictions for a novel process, we could significantly reduce the number of\nexperiments needed. Processes for different products exhibit differences in\nbehaviour, typically only a subset behave similar. Therefore, effective\nlearning on multiple product spanning process data requires a sensible\nrepresentation of the product identity. We propose to represent the product\nidentity (a categorical feature) by embedding vectors that serve as input to a\nGaussian Process regression model. We demonstrate how the embedding vectors can\nbe learned from process data and show that they capture an interpretable notion\nof product similarity. The improvement in performance is compared to\ntraditional one-hot encoding on a simulated cross product learning task. All in\nall, the proposed method could render possible significant reductions in\nwet-lab experiments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 17:38:15 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hutter", "Clemens", ""], ["von Stosch", "Moritz", ""], ["Bournazou", "Mariano Nicolas Cruz", ""], ["Butt\u00e9", "Alessandro", ""]]}, {"id": "2011.13885", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Alexander Novikov, Ksenia Konyushkova, Caglar Gulcehre,\n  Ziyu Wang, Yusuf Aytar, Misha Denil, Nando de Freitas, Scott Reed", "title": "Offline Learning from Demonstrations and Unlabeled Experience", "comments": "Accepted to Offline Reinforcement Learning Workshop at Neural\n  Information Processing Systems (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavior cloning (BC) is often practical for robot learning because it allows\na policy to be trained offline without rewards, by supervised learning on\nexpert demonstrations. However, BC does not effectively leverage what we will\nrefer to as unlabeled experience: data of mixed and unknown quality without\nreward annotations. This unlabeled data can be generated by a variety of\nsources such as human teleoperation, scripted policies and other agents on the\nsame robot. Towards data-driven offline robot learning that can use this\nunlabeled experience, we introduce Offline Reinforced Imitation Learning\n(ORIL). ORIL first learns a reward function by contrasting observations from\ndemonstrator and unlabeled trajectories, then annotates all data with the\nlearned reward, and finally trains an agent via offline reinforcement learning.\nAcross a diverse set of continuous control and simulated robotic manipulation\ntasks, we show that ORIL consistently outperforms comparable BC agents by\neffectively leveraging unlabeled experience.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:20:04 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zolna", "Konrad", ""], ["Novikov", "Alexander", ""], ["Konyushkova", "Ksenia", ""], ["Gulcehre", "Caglar", ""], ["Wang", "Ziyu", ""], ["Aytar", "Yusuf", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""], ["Reed", "Scott", ""]]}, {"id": "2011.13897", "submitter": "Homanga Bharadhwaj", "authors": "Kevin Xie, Homanga Bharadhwaj, Danijar Hafner, Animesh Garg, Florian\n  Shkurti", "title": "Latent Skill Planning for Exploration and Transfer", "comments": "First two authors contributed equally. Published as a conference\n  paper in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To quickly solve new tasks in complex environments, intelligent agents need\nto build up reusable knowledge. For example, a learned world model captures\nknowledge about the environment that applies to new tasks. Similarly, skills\ncapture general behaviors that can apply to new tasks. In this paper, we\ninvestigate how these two approaches can be integrated into a single\nreinforcement learning agent. Specifically, we leverage the idea of partial\namortization for fast adaptation at test time. For this, actions are produced\nby a policy that is learned over time while the skills it conditions on are\nchosen using online planning. We demonstrate the benefits of our design\ndecisions across a suite of challenging locomotion tasks and demonstrate\nimproved sample efficiency in single tasks as well as in transfer from one task\nto another, as compared to competitive baselines. Videos are available at:\nhttps://sites.google.com/view/latent-skill-planning/\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:40:03 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 15:53:04 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Xie", "Kevin", ""], ["Bharadhwaj", "Homanga", ""], ["Hafner", "Danijar", ""], ["Garg", "Animesh", ""], ["Shkurti", "Florian", ""]]}, {"id": "2011.13916", "submitter": "Honglin Li", "authors": "Honglin Li, Magdalena Anita Kolanko, Shirin Enshaeifar, Severin\n  Skillman, Andreas Markides, Mark Kenny, Eyal Soreq, Samaneh Kouchaki, Kirsten\n  Jensen, Loren Cameron, Michael Crone, Paul Freemont, Helen Rostill, David J.\n  Sharp, Ramin Nilforooshan, Payam Barnaghi", "title": "Deep Representation for Connected Health: Semi-supervised Learning for\n  Analysing the Risk of Urinary Tract Infections in People with Dementia", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning techniques combined with in-home monitoring technologies\nprovide a unique opportunity to automate diagnosis and early detection of\nadverse health conditions in long-term conditions such as dementia. However,\naccessing sufficient labelled training samples and integrating high-quality,\nroutinely collected data from heterogeneous in-home monitoring technologies are\nmain obstacles hindered utilising these technologies in real-world medicine.\nThis work presents a semi-supervised model that can continuously learn from\nroutinely collected in-home observation and measurement data. We show how our\nmodel can process highly imbalanced and dynamic data to make robust predictions\nin analysing the risk of Urinary Tract Infections (UTIs) in dementia. UTIs are\ncommon in older adults and constitute one of the main causes of avoidable\nhospital admissions in people with dementia (PwD). Health-related conditions,\nsuch as UTI, have a lower prevalence in individuals, which classifies them as\nsporadic cases (i.e. rare or scattered, yet important events). This limits the\naccess to sufficient training data, without which the supervised learning\nmodels risk becoming overfitted or biased. We introduce a probabilistic\nsemi-supervised learning framework to address these issues. The proposed method\nproduces a risk analysis score for UTIs using routinely collected data by\nin-home sensing technologies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:58:05 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 11:15:24 GMT"}, {"version": "v3", "created": "Sat, 3 Apr 2021 09:06:17 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 16:23:50 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Li", "Honglin", ""], ["Kolanko", "Magdalena Anita", ""], ["Enshaeifar", "Shirin", ""], ["Skillman", "Severin", ""], ["Markides", "Andreas", ""], ["Kenny", "Mark", ""], ["Soreq", "Eyal", ""], ["Kouchaki", "Samaneh", ""], ["Jensen", "Kirsten", ""], ["Cameron", "Loren", ""], ["Crone", "Michael", ""], ["Freemont", "Paul", ""], ["Rostill", "Helen", ""], ["Sharp", "David J.", ""], ["Nilforooshan", "Ramin", ""], ["Barnaghi", "Payam", ""]]}, {"id": "2011.13917", "submitter": "Jennifer J. Sun", "authors": "Jennifer J. Sun, Ann Kennedy, Eric Zhan, David J. Anderson, Yisong\n  Yue, Pietro Perona", "title": "Task Programming: Learning Data Efficient Behavior Representations", "comments": "To appear in as an Oral in CVPR 2021. Code:\n  https://github.com/neuroethology/TREBA. Project page:\n  https://sites.google.com/view/task-programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialized domain knowledge is often necessary to accurately annotate\ntraining sets for in-depth analysis, but can be burdensome and time-consuming\nto acquire from domain experts. This issue arises prominently in automated\nbehavior analysis, in which agent movements or actions of interest are detected\nfrom video tracking data. To reduce annotation effort, we present TREBA: a\nmethod to learn annotation-sample efficient trajectory embedding for behavior\nanalysis, based on multi-task self-supervised learning. The tasks in our method\ncan be efficiently engineered by domain experts through a process we call \"task\nprogramming\", which uses programs to explicitly encode structured knowledge\nfrom domain experts. Total domain expert effort can be reduced by exchanging\ndata annotation time for the construction of a small number of programmed\ntasks. We evaluate this trade-off using data from behavioral neuroscience, in\nwhich specialized domain knowledge is used to identify behaviors. We present\nexperimental results in three datasets across two domains: mice and fruit\nflies. Using embeddings from TREBA, we reduce annotation burden by up to a\nfactor of 10 without compromising accuracy compared to state-of-the-art\nfeatures. Our results thus suggest that task programming and self-supervision\ncan be an effective way to reduce annotation effort for domain experts.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:58:32 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 17:59:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Sun", "Jennifer J.", ""], ["Kennedy", "Ann", ""], ["Zhan", "Eric", ""], ["Anderson", "David J.", ""], ["Yue", "Yisong", ""], ["Perona", "Pietro", ""]]}, {"id": "2011.13920", "submitter": "Sara Sabour", "authors": "Sara Sabour, Andrea Tagliasacchi, Soroosh Yazdani, Geoffrey E. Hinton,\n  David J. Fleet", "title": "Unsupervised part representation by Flow Capsules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capsule networks aim to parse images into a hierarchy of objects, parts and\nrelations. While promising, they remain limited by an inability to learn\neffective low level part descriptions. To address this issue we propose a way\nto learn primary capsule encoders that detect atomic parts from a single image.\nDuring training we exploit motion as a powerful perceptual cue for part\ndefinition, with an expressive decoder for part generation within a layered\nimage model with occlusion. Experiments demonstrate robust part discovery in\nthe presence of multiple objects, cluttered backgrounds, and occlusion. The\npart decoder infers the underlying shape masks, effectively filling in occluded\nregions of the detected shapes. We evaluate FlowCapsules on unsupervised part\nsegmentation and unsupervised image classification.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 18:59:42 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 18:07:46 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Sabour", "Sara", ""], ["Tagliasacchi", "Andrea", ""], ["Yazdani", "Soroosh", ""], ["Hinton", "Geoffrey E.", ""], ["Fleet", "David J.", ""]]}, {"id": "2011.13951", "submitter": "Benjamin Miller", "authors": "Benjamin Kurt Miller, Alex Cole, Gilles Louppe, Christoph Weniger", "title": "Simulation-efficient marginal posterior estimation with swyft: stop\n  wasting your precious time", "comments": "Accepted at Machine Learning and the Physical Sciences at NeurIPS\n  2020. Package: https://github.com/undark-lab/swyft/", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.LG hep-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present algorithms (a) for nested neural likelihood-to-evidence ratio\nestimation, and (b) for simulation reuse via an inhomogeneous Poisson point\nprocess cache of parameters and corresponding simulations. Together, these\nalgorithms enable automatic and extremely simulator efficient estimation of\nmarginal and joint posteriors. The algorithms are applicable to a wide range of\nphysics and astronomy problems and typically offer an order of magnitude better\nsimulator efficiency than traditional likelihood-based sampling methods. Our\napproach is an example of likelihood-free inference, thus it is also applicable\nto simulators which do not offer a tractable likelihood function. Simulator\nruns are never rejected and can be automatically reused in future analysis. As\nfunctional prototype implementation we provide the open-source software package\nswyft.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 19:00:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Miller", "Benjamin Kurt", ""], ["Cole", "Alex", ""], ["Louppe", "Gilles", ""], ["Weniger", "Christoph", ""]]}, {"id": "2011.13974", "submitter": "Sidike Paheding", "authors": "Uzair Khan, Paheding Sidike, Colin Elkin and Vijay Devabhaktuni", "title": "Trends in deep learning for medical hyperspectral image analysis", "comments": null, "journal-ref": "in IEEE Access, vol. 9, pp. 79534-79548, 2021", "doi": "10.1109/ACCESS.2021.3068392", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have seen acute growth of interest in their\napplications throughout several fields of interest in the last decade, with\nmedical hyperspectral imaging being a particularly promising domain. So far, to\nthe best of our knowledge, there is no review paper that discusses the\nimplementation of deep learning for medical hyperspectral imaging, which is\nwhat this review paper aims to accomplish by examining publications that\ncurrently utilize deep learning to perform effective analysis of medical\nhyperspectral imagery. This paper discusses deep learning concepts that are\nrelevant and applicable to medical hyperspectral imaging analysis, several of\nwhich have been implemented since the boom in deep learning. This will comprise\nof reviewing the use of deep learning for classification, segmentation, and\ndetection in order to investigate the analysis of medical hyperspectral\nimaging. Lastly, we discuss the current and future challenges pertaining to\nthis discipline and the possible efforts to overcome such trials.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 19:42:06 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Khan", "Uzair", ""], ["Sidike", "Paheding", ""], ["Elkin", "Colin", ""], ["Devabhaktuni", "Vijay", ""]]}, {"id": "2011.13986", "submitter": "Johannes Schneider", "authors": "Johannes Schneider and Michalis Vlachos", "title": "Reflective-Net: Learning from Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans possess a remarkable capability to make fast, intuitive decisions, but\nalso to self-reflect, i.e., to explain to oneself, and to efficiently learn\nfrom explanations by others. This work provides the first steps toward\nmimicking this process by capitalizing on the explanations generated based on\nexisting explanation methods, i.e. Grad-CAM. Learning from explanations\ncombined with conventional labeled data yields significant improvements for\nclassification in terms of accuracy and training time.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 20:40:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Schneider", "Johannes", ""], ["Vlachos", "Michalis", ""]]}, {"id": "2011.13988", "submitter": "Katelyn Morrison", "authors": "Katelyn Morrison", "title": "Reducing Discrimination in Learning Algorithms for Social Good in\n  Sociotechnical Systems", "comments": "3 page position paper accepted to the AI for Social Good workshop at\n  The International Joint Conference on Artificial Intelligence (IJCAI). To be\n  presented on January 8th, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sociotechnical systems within cities are now equipped with machine learning\nalgorithms in hopes to increase efficiency and functionality by modeling and\npredicting trends. Machine learning algorithms have been applied in these\ndomains to address challenges such as balancing the distribution of bikes\nthroughout a city and identifying demand hotspots for ride sharing drivers.\nHowever, these algorithms applied to challenges in sociotechnical systems have\nexacerbated social inequalities due to previous bias in data sets or the lack\nof data from marginalized communities. In this paper, I will address how smart\nmobility initiatives in cities use machine learning algorithms to address\nchallenges. I will also address how these algorithms unintentionally\ndiscriminate against features such as socioeconomic status to motivate the\nimportance of algorithmic fairness. Using the bike sharing program in\nPittsburgh, PA, I will present a position on how discrimination can be\neliminated from the pipeline using Bayesian Optimization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 20:45:10 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 05:10:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Morrison", "Katelyn", ""]]}, {"id": "2011.13996", "submitter": "Vivek Dixit", "authors": "Vivek Dixit, Raja Selvarajan, Tamer Aldwairi, Yaroslav Koshka, Mark A.\n  Novotny, Travis S. Humble, Muhammad A. Alam and Sabre Kais", "title": "Training a quantum annealing based restricted Boltzmann machine on\n  cybersecurity data", "comments": "in IEEE Transactions on Emerging Topics in Computational Intelligence", "journal-ref": "V. Dixit et al., \"Training a Quantum Annealing Based Restricted\n  Boltzmann Machine on Cybersecurity Data,\" in IEEE Transactions on Emerging\n  Topics in Computational Intelligence, doi: 10.1109/TETCI.2021.3074916", "doi": "10.1109/TETCI.2021.3074916", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a real-world application that uses a quantum computer.\nSpecifically, we train a RBM using QA for cybersecurity applications. The\nD-Wave 2000Q has been used to implement QA. RBMs are trained on the ISCX data,\nwhich is a benchmark dataset for cybersecurity. For comparison, RBMs are also\ntrained using CD. CD is a commonly used method for RBM training. Our analysis\nof the ISCX data shows that the dataset is imbalanced. We present two different\nschemes to balance the training dataset before feeding it to a classifier. The\nfirst scheme is based on the undersampling of benign instances. The imbalanced\ntraining dataset is divided into five sub-datasets that are trained separately.\nA majority voting is then performed to get the result. Our results show the\nmajority vote increases the classification accuracy up from 90.24% to 95.68%,\nin the case of CD. For the case of QA, the classification accuracy increases\nfrom 74.14% to 80.04%. In the second scheme, a RBM is used to generate\nsynthetic data to balance the training dataset. We show that both QA and\nCD-trained RBM can be used to generate useful synthetic data. Balanced training\ndata is used to evaluate several classifiers. Among the classifiers\ninvestigated, K-Nearest Neighbor (KNN) and Neural Network (NN) perform better\nthan other classifiers. They both show an accuracy of 93%. Our results show a\nproof-of-concept that a QA-based RBM can be trained on a 64-bit binary dataset.\nThe illustrative example suggests the possibility to migrate many practical\nclassification problems to QA-based techniques. Further, we show that synthetic\ndata generated from a RBM can be used to balance the original dataset.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 21:18:45 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 22:53:36 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 01:31:11 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 10:23:44 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Dixit", "Vivek", ""], ["Selvarajan", "Raja", ""], ["Aldwairi", "Tamer", ""], ["Koshka", "Yaroslav", ""], ["Novotny", "Mark A.", ""], ["Humble", "Travis S.", ""], ["Alam", "Muhammad A.", ""], ["Kais", "Sabre", ""]]}, {"id": "2011.14004", "submitter": "Jihyeon Lee", "authors": "Jihyeon Lee, Joseph Z. Xu, Kihyuk Sohn, Wenhan Lu, David Berthelot,\n  Izzeddin Gur, Pranav Khaitan, Ke-Wei (Fiona) Huang, Kyriacos Koupparis,\n  Bernhard Kowatsch", "title": "Assessing Post-Disaster Damage from Satellite Imagery using\n  Semi-Supervised Learning Techniques", "comments": "NeurIPS 2020 Artificial Intelligence for Humanitarian Assistance and\n  Disaster Response Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To respond to disasters such as earthquakes, wildfires, and armed conflicts,\nhumanitarian organizations require accurate and timely data in the form of\ndamage assessments, which indicate what buildings and population centers have\nbeen most affected. Recent research combines machine learning with remote\nsensing to automatically extract such information from satellite imagery,\nreducing manual labor and turn-around time. A major impediment to using machine\nlearning methods in real disaster response scenarios is the difficulty of\nobtaining a sufficient amount of labeled data to train a model for an unfolding\ndisaster. This paper shows a novel application of semi-supervised learning\n(SSL) to train models for damage assessment with a minimal amount of labeled\ndata and large amount of unlabeled data. We compare the performance of\nstate-of-the-art SSL methods, including MixMatch and FixMatch, to a supervised\nbaseline for the 2010 Haiti earthquake, 2017 Santa Rosa wildfire, and 2016\narmed conflict in Syria. We show how models trained with SSL methods can reach\nfully supervised performance despite using only a fraction of labeled data and\nidentify areas for further improvements.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 22:26:14 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lee", "Jihyeon", "", "Fiona"], ["Xu", "Joseph Z.", "", "Fiona"], ["Sohn", "Kihyuk", "", "Fiona"], ["Lu", "Wenhan", "", "Fiona"], ["Berthelot", "David", "", "Fiona"], ["Gur", "Izzeddin", "", "Fiona"], ["Khaitan", "Pranav", "", "Fiona"], ["Ke-Wei", "", "", "Fiona"], ["Huang", "", ""], ["Koupparis", "Kyriacos", ""], ["Kowatsch", "Bernhard", ""]]}, {"id": "2011.14006", "submitter": "Patricia Pauli", "authors": "Patricia Pauli, Johannes K\\\"ohler, Julian Berberich, Anne Koch and\n  Frank Allg\\\"ower", "title": "Offset-free setpoint tracking using neural network controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method to analyze local and global stability in\noffset-free setpoint tracking using neural network controllers and we provide\nellipsoidal inner approximations of the corresponding region of attraction. We\nconsider a feedback interconnection of a linear plant in connection with a\nneural network controller and an integrator, which allows for offset-free\ntracking of a desired piecewise constant reference that enters the controller\nas an external input. Exploiting the fact that activation functions used in\nneural networks are slope-restricted, we derive linear matrix inequalities to\nverify stability using Lyapunov theory. After stating a global stability\nresult, we present less conservative local stability conditions (i) for a given\nreference and (ii) for any reference from a certain set. The latter result even\nenables guaranteed tracking under setpoint changes using a reference governor\nwhich can lead to a significant increase of the region of attraction. Finally,\nwe demonstrate the applicability of our analysis by verifying stability and\noffset-free tracking of a neural network controller that was trained to\nstabilize a linearized inverted pendulum.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:13:13 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 17:10:14 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Pauli", "Patricia", ""], ["K\u00f6hler", "Johannes", ""], ["Berberich", "Julian", ""], ["Koch", "Anne", ""], ["Allg\u00f6wer", "Frank", ""]]}, {"id": "2011.14015", "submitter": "Udai Nagpal", "authors": "Udai G. Nagpal, David A Knowles", "title": "Active Learning in CNNs via Expected Improvement Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models such as Convolutional Neural Networks (CNNs) have\ndemonstrated high levels of effectiveness in a variety of domains, including\ncomputer vision and more recently, computational biology. However, training\neffective models often requires assembling and/or labeling large datasets,\nwhich may be prohibitively time-consuming or costly. Pool-based active learning\ntechniques have the potential to mitigate these issues, leveraging models\ntrained on limited data to selectively query unlabeled data points from a pool\nin an attempt to expedite the learning process. Here we present \"Dropout-based\nExpected IMprOvementS\" (DEIMOS), a flexible and computationally-efficient\napproach to active learning that queries points that are expected to maximize\nthe model's improvement across a representative sample of points. The proposed\nframework enables us to maintain a prediction covariance matrix capturing model\nuncertainty, and to dynamically update this matrix in order to generate diverse\nbatches of points in the batch-mode setting. Our active learning results\ndemonstrate that DEIMOS outperforms several existing baselines across multiple\nregression and classification tasks taken from computer vision and genomics.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 22:06:52 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Nagpal", "Udai G.", ""], ["Knowles", "David A", ""]]}, {"id": "2011.14027", "submitter": "Jack Lanchantin", "authors": "Jack Lanchantin, Tianlu Wang, Vicente Ordonez, Yanjun Qi", "title": "General Multi-label Image Classification with Transformers", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-label image classification is the task of predicting a set of labels\ncorresponding to objects, attributes or other entities present in an image. In\nthis work we propose the Classification Transformer (C-Tran), a general\nframework for multi-label image classification that leverages Transformers to\nexploit the complex dependencies among visual features and labels. Our approach\nconsists of a Transformer encoder trained to predict a set of target labels\ngiven an input set of masked labels, and visual features from a convolutional\nneural network. A key ingredient of our method is a label mask training\nobjective that uses a ternary encoding scheme to represent the state of the\nlabels as positive, negative, or unknown during training. Our model shows\nstate-of-the-art performance on challenging datasets such as COCO and Visual\nGenome. Moreover, because our model explicitly represents the uncertainty of\nlabels during training, it is more general by allowing us to produce improved\nresults for images with partial or extra label annotations during inference. We\ndemonstrate this additional capability in the COCO, Visual Genome, News500, and\nCUB image datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 23:20:35 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lanchantin", "Jack", ""], ["Wang", "Tianlu", ""], ["Ordonez", "Vicente", ""], ["Qi", "Yanjun", ""]]}, {"id": "2011.14031", "submitter": "Fnu Devvrit", "authors": "Devvrit, Minhao Cheng, Cho-Jui Hsieh, Inderjit Dhillon", "title": "Voting based ensemble improves robustness of defensive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing robust models against adversarial perturbations has been an active\narea of research and many algorithms have been proposed to train individual\nrobust models. Taking these pretrained robust models, we aim to study whether\nit is possible to create an ensemble to further improve robustness. Several\nprevious attempts tackled this problem by ensembling the soft-label prediction\nand have been proved vulnerable based on the latest attack methods. In this\npaper, we show that if the robust training loss is diverse enough, a simple\nhard-label based voting ensemble can boost the robust error over each\nindividual model. Furthermore, given a pool of robust models, we develop a\nprincipled way to select which models to ensemble. Finally, to verify the\nimproved robustness, we conduct extensive experiments to study how to attack a\nvoting-based ensemble and develop several new white-box attacks. On CIFAR-10\ndataset, by ensembling several state-of-the-art pre-trained defense models, our\nmethod can achieve a 59.8% robust accuracy, outperforming all the existing\ndefensive models without using additional data.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:08:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Devvrit", "", ""], ["Cheng", "Minhao", ""], ["Hsieh", "Cho-Jui", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2011.14032", "submitter": "Sebastiano Barbieri", "authors": "Sebastiano Barbieri, Suneela Mehta, Billy Wu, Chrianna Bharat, Katrina\n  Poppe, Louisa Jorm, Rod Jackson", "title": "Predicting cardiovascular risk from national administrative databases\n  using a combined survival analysis and deep learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AIMS. This study compared the performance of deep learning extensions of\nsurvival analysis models with traditional Cox proportional hazards (CPH) models\nfor deriving cardiovascular disease (CVD) risk prediction equations in national\nhealth administrative datasets. METHODS. Using individual person linkage of\nmultiple administrative datasets, we constructed a cohort of all New Zealand\nresidents aged 30-74 years who interacted with publicly funded health services\nduring 2012, and identified hospitalisations and deaths from CVD over five\nyears of follow-up. After excluding people with prior CVD or heart failure,\nsex-specific deep learning and CPH models were developed to estimate the risk\nof fatal or non-fatal CVD events within five years. The proportion of explained\ntime-to-event occurrence, calibration, and discrimination were compared between\nmodels across the whole study population and in specific risk groups. FINDINGS.\nFirst CVD events occurred in 61,927 of 2,164,872 people. Among diagnoses and\nprocedures, the largest 'local' hazard ratios were associated by the deep\nlearning models with tobacco use in women (2.04, 95%CI: 1.99-2.10) and with\nchronic obstructive pulmonary disease with acute lower respiratory infection in\nmen (1.56, 95%CI: 1.50-1.62). Other identified predictors (e.g. hypertension,\nchest pain, diabetes) aligned with current knowledge about CVD risk predictors.\nThe deep learning models significantly outperformed the CPH models on the basis\nof proportion of explained time-to-event occurrence (Royston and Sauerbrei's\nR-squared: 0.468 vs. 0.425 in women and 0.383 vs. 0.348 in men), calibration,\nand discrimination (all p<0.0001). INTERPRETATION. Deep learning extensions of\nsurvival analysis models can be applied to large health administrative\ndatabases to derive interpretable CVD risk prediction equations that are more\naccurate than traditional CPH models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:10:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Barbieri", "Sebastiano", ""], ["Mehta", "Suneela", ""], ["Wu", "Billy", ""], ["Bharat", "Chrianna", ""], ["Poppe", "Katrina", ""], ["Jorm", "Louisa", ""], ["Jackson", "Rod", ""]]}, {"id": "2011.14033", "submitter": "Priyank Agrawal", "authors": "Priyank Agrawal, Vashist Avadhanula and Theja Tulabandhula", "title": "A Tractable Online Learning Algorithm for the Multinomial Logit\n  Contextual Bandit", "comments": "updated version with convex relaxation result", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the contextual variant of the MNL-Bandit problem.\nMore specifically, we consider a dynamic set optimization problem, where in\nevery round a decision maker offers a subset (assortment) of products to a\nconsumer, and observes their response. Consumers purchase products so as to\nmaximize their utility. We assume that the products are described by a set of\nattributes and the mean utility of a product is linear in the values of these\nattributes. We model consumer choice behavior by means of the widely used\nMultinomial Logit (MNL) model, and consider the decision maker's problem of\ndynamically learning the model parameters, while optimizing cumulative revenue\nover the selling horizon $T$. Though this problem has attracted considerable\nattention in recent times, many existing methods often involve solving an\nintractable non-convex optimization problem and their theoretical performance\nguarantees depend on a problem dependent parameter which could be prohibitively\nlarge. In particular, existing algorithms for this problem have regret bounded\nby $O(\\sqrt{\\kappa d T})$, where $\\kappa$ is a problem dependent constant that\ncan have exponential dependency on the number of attributes. In this paper, we\npropose an optimistic algorithm and show that the regret is bounded by\n$O(\\sqrt{dT} + \\kappa)$, significantly improving the performance over existing\nmethods. Further, we propose a convex relaxation of the optimization step which\nallows for tractable decision-making while retaining the favourable regret\nguarantee.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:20:36 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 07:48:58 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 19:53:26 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Agrawal", "Priyank", ""], ["Avadhanula", "Vashist", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2011.14036", "submitter": "Taro Makino", "authors": "Taro Makino, Stanislaw Jastrzebski, Witold Oleszkiewicz, Celin Chacko,\n  Robin Ehrenpreis, Naziya Samreen, Chloe Chhor, Eric Kim, Jiyon Lee, Kristine\n  Pysarenko, Beatriu Reig, Hildegard Toth, Divya Awal, Linda Du, Alice Kim,\n  James Park, Daniel K. Sodickson, Laura Heacock, Linda Moy, Kyunghyun Cho,\n  Krzysztof J. Geras", "title": "Differences between human and machine perception in medical diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) show promise in image-based medical diagnosis,\nbut cannot be fully trusted since their performance can be severely degraded by\ndataset shifts to which human perception remains invariant. If we can better\nunderstand the differences between human and machine perception, we can\npotentially characterize and mitigate this effect. We therefore propose a\nframework for comparing human and machine perception in medical diagnosis. The\ntwo are compared with respect to their sensitivity to the removal of clinically\nmeaningful information, and to the regions of an image deemed most suspicious.\nDrawing inspiration from the natural image domain, we frame both comparisons in\nterms of perturbation robustness. The novelty of our framework is that separate\nanalyses are performed for subgroups with clinically meaningful differences. We\nargue that this is necessary in order to avert Simpson's paradox and draw\ncorrect conclusions. We demonstrate our framework with a case study in breast\ncancer screening, and reveal significant differences between radiologists and\nDNNs. We compare the two with respect to their robustness to Gaussian low-pass\nfiltering, performing a subgroup analysis on microcalcifications and soft\ntissue lesions. For microcalcifications, DNNs use a separate set of high\nfrequency components than radiologists, some of which lie outside the image\nregions considered most suspicious by radiologists. These features run the risk\nof being spurious, but if not, could represent potential new biomarkers. For\nsoft tissue lesions, the divergence between radiologists and DNNs is even\nstarker, with DNNs relying heavily on spurious high frequency components\nignored by radiologists. Importantly, this deviation in soft tissue lesions was\nonly observable through subgroup analysis, which highlights the importance of\nincorporating medical domain knowledge into our comparison framework.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:32:17 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Makino", "Taro", ""], ["Jastrzebski", "Stanislaw", ""], ["Oleszkiewicz", "Witold", ""], ["Chacko", "Celin", ""], ["Ehrenpreis", "Robin", ""], ["Samreen", "Naziya", ""], ["Chhor", "Chloe", ""], ["Kim", "Eric", ""], ["Lee", "Jiyon", ""], ["Pysarenko", "Kristine", ""], ["Reig", "Beatriu", ""], ["Toth", "Hildegard", ""], ["Awal", "Divya", ""], ["Du", "Linda", ""], ["Kim", "Alice", ""], ["Park", "James", ""], ["Sodickson", "Daniel K.", ""], ["Heacock", "Laura", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "2011.14045", "submitter": "Ran Wang", "authors": "Haojing Shen, Sihong Chen, Ran Wang and Xizhao Wang", "title": "Generalized Adversarial Examples: Attacks and Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of the works follow such definition of adversarial example that is\nimperceptible to humans but can fool the deep neural networks (DNNs). Some\nworks find another interesting form of adversarial examples such as one which\nis unrecognizable to humans, but DNNs classify it as one class with high\nconfidence and adversarial patch. Based on this phenomenon, in this paper, from\nthe perspective of cognition of humans and machines, we propose a new\ndefinition of adversarial examples. We show that imperceptible adversarial\nexamples, unrecognizable adversarial examples, and adversarial patches are\nderivates of generalized adversarial examples. Then, we propose three types of\nadversarial attacks based on the generalized definition. Finally, we propose a\ndefence mechanism that achieves state-of-the-art performance. We construct a\nlossy compression function to filter out the redundant features generated by\nthe network. In this process, the perturbation produced by the attacker will be\nfiltered out. Therefore, the defence mechanism can effectively improve the\nrobustness of the model. The experiments show that our attack methods can\neffectively generate adversarial examples, and our defence method can\nsignificantly improve the adversarial robustness of DNNs compared with\nadversarial training. As far as we know, our defending method achieves the best\nperformance even though we do not adopt adversarial training.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 01:41:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shen", "Haojing", ""], ["Chen", "Sihong", ""], ["Wang", "Ran", ""], ["Wang", "Xizhao", ""]]}, {"id": "2011.14047", "submitter": "Cesar F. Caiafa", "authors": "Cesar F. Caiafa, Ziyao Wang, Jordi Sol\\'e-Casals, Qibin Zhao", "title": "Learning from Incomplete Features by Simultaneous Training of Neural\n  Networks and Sparse Coding", "comments": "11 pages, 7 figures, paper accepted for presentation at L2ID Workshop\n  at CVPR 2021 (19-25 June, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the problem of training a classifier on a dataset with\nincomplete features is addressed. We assume that different subsets of features\n(random or structured) are available at each data instance. This situation\ntypically occurs in the applications when not all the features are collected\nfor every data sample. A new supervised learning method is developed to train a\ngeneral classifier, such as a logistic regression or a deep neural network,\nusing only a subset of features per sample, while assuming sparse\nrepresentations of data vectors on an unknown dictionary. Sufficient conditions\nare identified, such that, if it is possible to train a classifier on\nincomplete observations so that their reconstructions are well separated by a\nhyperplane, then the same classifier also correctly separates the original\n(unobserved) data samples. Extensive simulation results on synthetic and\nwell-known datasets are presented that validate our theoretical findings and\ndemonstrate the effectiveness of the proposed method compared to traditional\ndata imputation approaches and one state-of-the-art algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 02:20:39 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 20:09:10 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Caiafa", "Cesar F.", ""], ["Wang", "Ziyao", ""], ["Sol\u00e9-Casals", "Jordi", ""], ["Zhao", "Qibin", ""]]}, {"id": "2011.14048", "submitter": "Amrith Setlur", "authors": "Amrith Setlur, Oscar Li, Virginia Smith", "title": "Is Support Set Diversity Necessary for Meta-Learning?", "comments": null, "journal-ref": "NeurIPS 2020 Workshop on Meta-learning", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning is a popular framework for learning with limited data in which\nan algorithm is produced by training over multiple few-shot learning tasks. For\nclassification problems, these tasks are typically constructed by sampling a\nsmall number of support and query examples from a subset of the classes. While\nconventional wisdom is that task diversity should improve the performance of\nmeta-learning, in this work we find evidence to the contrary: we propose a\nmodification to traditional meta-learning approaches in which we keep the\nsupport sets fixed across tasks, thus reducing task diversity. Surprisingly, we\nfind that not only does this modification not result in adverse effects, it\nalmost always improves the performance for a variety of datasets and\nmeta-learning methods. We also provide several initial analyses to understand\nthis phenomenon. Our work serves to: (i) more closely investigate the effect of\nsupport set construction for the problem of meta-learning, and (ii) suggest a\nsimple, general, and competitive baseline for few-shot learning.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 02:28:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Setlur", "Amrith", ""], ["Li", "Oscar", ""], ["Smith", "Virginia", ""]]}, {"id": "2011.14057", "submitter": "Hans Riess", "authors": "Hans Riess and Jakob Hansen", "title": "Multidimensional Persistence Module Classification via Lattice-Theoretic\n  Convolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiparameter persistent homology has been largely neglected as an input to\nmachine learning algorithms. We consider the use of lattice-based convolutional\nneural network layers as a tool for the analysis of features arising from\nmultiparameter persistence modules. We find that these show promise as an\nalternative to convolutions for the classification of multidimensional\npersistence modules.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 03:28:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Riess", "Hans", ""], ["Hansen", "Jakob", ""]]}, {"id": "2011.14058", "submitter": "Wei He", "authors": "Zhongzhan Huang, Senwei Liang, Mingfu Liang, Wei He, Haizhao Yang", "title": "Efficient Attention Network: Accelerate Attention by Searching Where to\n  Plug", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many plug-and-play self-attention modules are proposed to enhance\nthe model generalization by exploiting the internal information of deep\nconvolutional neural networks (CNNs). Previous works lay an emphasis on the\ndesign of attention module for specific functionality, e.g., light-weighted or\ntask-oriented attention. However, they ignore the importance of where to plug\nin the attention module since they connect the modules individually with each\nblock of the entire CNN backbone for granted, leading to incremental\ncomputational cost and number of parameters with the growth of network depth.\nThus, we propose a framework called Efficient Attention Network (EAN) to\nimprove the efficiency for the existing attention modules. In EAN, we leverage\nthe sharing mechanism (Huang et al. 2020) to share the attention module within\nthe backbone and search where to connect the shared attention module via\nreinforcement learning. Finally, we obtain the attention network with sparse\nconnections between the backbone and modules, while (1) maintaining accuracy\n(2) reducing extra parameter increment and (3) accelerating inference.\nExtensive experiments on widely-used benchmarks and popular attention networks\nshow the effectiveness of EAN. Furthermore, we empirically illustrate that our\nEAN has the capacity of transferring to other tasks and capturing the\ninformative features. The code is available at\nhttps://github.com/gbup-group/EAN-efficient-attention-network.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 03:31:08 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 12:44:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huang", "Zhongzhan", ""], ["Liang", "Senwei", ""], ["Liang", "Mingfu", ""], ["He", "Wei", ""], ["Yang", "Haizhao", ""]]}, {"id": "2011.14066", "submitter": "Vatsal Shah", "authors": "Vatsal Shah, Soumya Basu, Anastasios Kyrillidis, Sujay Sanghavi", "title": "On Generalization of Adaptive Methods for Over-parameterized Linear\n  Regression", "comments": "arXiv admin note: substantial text overlap with arXiv:1811.07055", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterization and adaptive methods have played a crucial role in the\nsuccess of deep learning in the last decade. The widespread use of\nover-parameterization has forced us to rethink generalization by bringing forth\nnew phenomena, such as implicit regularization of optimization algorithms and\ndouble descent with training progression. A series of recent works have started\nto shed light on these areas in the quest to understand -- why do neural\nnetworks generalize well? The setting of over-parameterized linear regression\nhas provided key insights into understanding this mysterious behavior of neural\nnetworks.\n  In this paper, we aim to characterize the performance of adaptive methods in\nthe over-parameterized linear regression setting. First, we focus on two\nsub-classes of adaptive methods depending on their generalization performance.\nFor the first class of adaptive methods, the parameter vector remains in the\nspan of the data and converges to the minimum norm solution like gradient\ndescent (GD). On the other hand, for the second class of adaptive methods, the\ngradient rotation caused by the pre-conditioner matrix results in an in-span\ncomponent of the parameter vector that converges to the minimum norm solution\nand the out-of-span component that saturates. Our experiments on\nover-parameterized linear regression and deep neural networks support this\ntheory.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 04:19:32 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shah", "Vatsal", ""], ["Basu", "Soumya", ""], ["Kyrillidis", "Anastasios", ""], ["Sanghavi", "Sujay", ""]]}, {"id": "2011.14075", "submitter": "Benjamin Laufer", "authors": "Benjamin Laufer", "title": "Feedback Effects in Repeat-Use Criminal Risk Assessments", "comments": "10 pages. arXiv admin note: substantial text overlap with\n  arXiv:2005.13404", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.LG cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the criminal legal context, risk assessment algorithms are touted as\ndata-driven, well-tested tools. Studies known as validation tests are typically\ncited by practitioners to show that a particular risk assessment algorithm has\npredictive accuracy, establishes legitimate differences between risk groups,\nand maintains some measure of group fairness in treatment. To establish these\nimportant goals, most tests use a one-shot, single-point measurement. Using a\nPolya Urn model, we explore the implication of feedback effects in sequential\nscoring-decision processes. We show through simulation that risk can propagate\nover sequential decisions in ways that are not captured by one-shot tests. For\nexample, even a very small or undetectable level of bias in risk allocation can\namplify over sequential risk-based decisions, leading to observable group\ndifferences after a number of decision iterations. Risk assessment tools\noperate in a highly complex and path-dependent process, fraught with historical\ninequity. We conclude from this study that these tools do not properly account\nfor compounding effects, and require new approaches to development and\nauditing.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 06:40:05 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Laufer", "Benjamin", ""]]}, {"id": "2011.14078", "submitter": "Sambaran Bandyopadhyay", "authors": "Sambaran Bandyopadhyay, Vishal Peter", "title": "Self-Expressive Graph Neural Network for Unsupervised Community\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks are able to achieve promising performance on multiple\ngraph downstream tasks such as node classification and link prediction.\nComparatively lesser work has been done to design graph neural networks (GNNs)\nwhich can operate directly for community detection in a graph. Traditionally,\nGNNs are trained on a semi-supervised or self-supervised loss function and then\nclustering algorithms are applied to detect communities. However, such\ndecoupled approaches are inherently sub-optimal. Design of an unsupervised\ncommunity detection loss function to train a GNN is a fundamental challenge to\npropose an integrated solution. To tackle this problem, we combine the\nprinciple of self-expressiveness with the framework of self-supervised graph\nneural network for unsupervised community detection for the first time in the\nliterature. To improve the scalability of the approach, we propose a randomly\nsampled batch-wise training and use the principle of self-expressiveness to\ngenerate a subset of strong node similarity / dissimilarity values. These\nvalues are used to regularize the node communities obtained from a\nself-supervised graph neural network. Our solution is trained in an end-to-end\nfashion. We are able to achieve state-of-the-art community detection results on\nmultiple publicly available datasets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 07:17:30 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bandyopadhyay", "Sambaran", ""], ["Peter", "Vishal", ""]]}, {"id": "2011.14085", "submitter": "Ching-Chia Kao", "authors": "Ching-Chia Kao, Jhe-Bang Ko, Chun-Shien Lu", "title": "Deterministic Certification to Adversarial Attacks via Bernstein\n  Polynomial Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing has established state-of-the-art provable robustness\nagainst $\\ell_2$ norm adversarial attacks with high probability. However, the\nintroduced Gaussian data augmentation causes a severe decrease in natural\naccuracy. We come up with a question, \"Is it possible to construct a smoothed\nclassifier without randomization while maintaining natural accuracy?\". We find\nthe answer is definitely yes. We study how to transform any classifier into a\ncertified robust classifier based on a popular and elegant mathematical tool,\nBernstein polynomial. Our method provides a deterministic algorithm for\ndecision boundary smoothing. We also introduce a distinctive approach of\nnorm-independent certified robustness via numerical solutions of nonlinear\nsystems of equations. Theoretical analyses and experimental results indicate\nthat our method is promising for classifier smoothing and robustness\ncertification.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 08:27:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kao", "Ching-Chia", ""], ["Ko", "Jhe-Bang", ""], ["Lu", "Chun-Shien", ""]]}, {"id": "2011.14087", "submitter": "Paul Wimmer", "authors": "Paul Wimmer, Jens Mehnert and Alexandru Condurache", "title": "FreezeNet: Full Performance by Reduced Storage Costs", "comments": "Conference Paper of the Asian Conference on Computer Vision (ACCV)\n  2020", "journal-ref": "ACCV (6) 2020: 685-701", "doi": "10.1007/978-3-030-69544-6\\_41", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning generates sparse networks by setting parameters to zero. In this work\nwe improve one-shot pruning methods, applied before training, without adding\nany additional storage costs while preserving the sparse gradient computations.\nThe main difference to pruning is that we do not sparsify the network's weights\nbut learn just a few key parameters and keep the other ones fixed at their\nrandom initialized value. This mechanism is called freezing the parameters.\nThose frozen weights can be stored efficiently with a single 32bit random seed\nnumber. The parameters to be frozen are determined one-shot by a single for-\nand backward pass applied before training starts. We call the introduced method\nFreezeNet. In our experiments we show that FreezeNets achieve good results,\nespecially for extreme freezing rates. Freezing weights preserves the gradient\nflow throughout the network and consequently, FreezeNets train better and have\nan increased capacity compared to their pruned counterparts. On the\nclassification tasks MNIST and CIFAR-10/100 we outperform SNIP, in this setting\nthe best reported one-shot pruning method, applied before training. On MNIST,\nFreezeNet achieves 99.2% performance of the baseline LeNet-5-Caffe\narchitecture, while compressing the number of trained and stored parameters by\na factor of x 157.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 08:32:44 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Wimmer", "Paul", ""], ["Mehnert", "Jens", ""], ["Condurache", "Alexandru", ""]]}, {"id": "2011.14097", "submitter": "Shohreh Deldari", "authors": "Shohreh Deldari, Daniel V. Smith, Hao Xue, Flora D. Salim", "title": "Time Series Change Point Detection with Self-Supervised Contrastive\n  Predictive Coding", "comments": "Accepted at The WEB Conference 2021 (WWW'21)", "journal-ref": null, "doi": "10.1145/3442381.3449903", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change Point Detection (CPD) methods identify the times associated with\nchanges in the trends and properties of time series data in order to describe\nthe underlying behaviour of the system. For instance, detecting the changes and\nanomalies associated with web service usage, application usage or human\nbehaviour can provide valuable insights for downstream modelling tasks. We\npropose a novel approach for self-supervised Time Series Change Point detection\nmethod based onContrastivePredictive coding (TS-CP^2). TS-CP^2 is the first\napproach to employ a contrastive learning strategy for CPD by learning an\nembedded representation that separates pairs of embeddings of time adjacent\nintervals from pairs of interval embeddings separated across time. Through\nextensive experiments on three diverse, widely used time series datasets, we\ndemonstrate that our method outperforms five state-of-the-art CPD methods,\nwhich include unsupervised and semi-supervisedapproaches. TS-CP^2 is shown to\nimprove the performance of methods that use either handcrafted statistical or\ntemporal features by 79.4% and deep learning-based methods by 17.0% with\nrespect to the F1-score averaged across the three datasets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 09:36:18 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 23:21:33 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 22:26:19 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 09:20:41 GMT"}, {"version": "v5", "created": "Fri, 5 Mar 2021 00:24:56 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Deldari", "Shohreh", ""], ["Smith", "Daniel V.", ""], ["Xue", "Hao", ""], ["Salim", "Flora D.", ""]]}, {"id": "2011.14115", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Shankari Giri, Johannes T. Margraf, Stephan\n  G\\\"unnemann", "title": "Fast and Uncertainty-Aware Directional Message Passing for\n  Non-Equilibrium Molecules", "comments": "Published at the Machine Learning for Molecules Workshop at NeurIPS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important tasks in chemistry revolve around molecules during reactions.\nThis requires predictions far from the equilibrium, while most recent work in\nmachine learning for molecules has been focused on equilibrium or\nnear-equilibrium states. In this paper we aim to extend this scope in three\nways. First, we propose the DimeNet++ model, which is 8x faster and 10% more\naccurate than the original DimeNet on the QM9 benchmark of equilibrium\nmolecules. Second, we validate DimeNet++ on highly reactive molecules by\ndeveloping the challenging COLL dataset, which contains distorted\nconfigurations of small molecules during collisions. Finally, we investigate\nensembling and mean-variance estimation for uncertainty quantification with the\ngoal of accelerating the exploration of the vast space of non-equilibrium\nstructures. Our DimeNet++ implementation as well as the COLL dataset are\navailable online.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 11:39:42 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 12:29:05 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Klicpera", "Johannes", ""], ["Giri", "Shankari", ""], ["Margraf", "Johannes T.", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2011.14126", "submitter": "Zakaria Mhammedi", "authors": "Zakaria Mhammedi and Hisham Husain", "title": "Risk-Monotonicity in Statistical Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquisition of data is a difficult task in many applications of machine\nlearning, and it is only natural that one hopes and expects the populating risk\nto decrease (better performance) monotonically with increasing data points. It\nturns out, somewhat surprisingly, that this is not the case even for the most\nstandard algorithms such as empirical risk minimization. Non-monotonic\nbehaviour of the risk and instability in training have manifested and appeared\nin the popular deep learning paradigm under the description of double descent.\nThese problems highlight bewilderment in our understanding of learning\nalgorithms and generalization. It is, therefore, crucial to pursue this concern\nand provide a characterization of such behaviour. In this paper, we derive the\nfirst consistent and risk-monotonic algorithms for a general statistical\nlearning setting under weak assumptions, consequently resolving an open problem\n(Viering et al. 2019) on how to avoid non-monotonic behaviour of risk curves.\nOur work makes a significant contribution to the topic of risk-monotonicity,\nwhich may be key in resolving empirical phenomena such as double descent.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 12:52:12 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 07:21:06 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 04:26:33 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Husain", "Hisham", ""]]}, {"id": "2011.14130", "submitter": "Yong-Liang Xiao", "authors": "Yong-Liang Xiao", "title": "Optical Phase Dropout in Diffractive Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unitary learning is a backpropagation that serves to unitary weights update\nin deep complex-valued neural network with full connections, meeting a physical\nunitary prior in diffractive deep neural network ([DN]2). However, the square\nmatrix property of unitary weights induces that the function signal has a\nlimited dimension that could not generalize well. To address the overfitting\nproblem that comes from the small samples loaded to [DN]2, an optical phase\ndropout trick is implemented. Phase dropout in unitary space that is evolved\nfrom a complex dropout and has a statistical inference is formulated for the\nfirst time. A synthetic mask recreated from random point apertures with random\nphase-shifting and its smothered modulation tailors the redundant links through\nincompletely sampling the input optical field at each diffractive layer. The\nphysical features about the synthetic mask using different nonlinear\nactivations are elucidated in detail. The equivalence between digital and\ndiffractive model determines compound modulations that could successfully\ncircumvent the nonlinear activations physically implemented in [DN]2. The\nnumerical experiments verify the superiority of optical phase dropout in [DN]2\nto enhance accuracy in 2D classification and recognition tasks-oriented.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 13:33:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Xiao", "Yong-Liang", ""]]}, {"id": "2011.14134", "submitter": "Soumick Chatterjee", "authors": "Soumick Chatterjee, Alessandro Sciarra, Max D\\\"unnwald, Steffen\n  Oeltze-Jafra, Andreas N\\\"urnberger and Oliver Speck", "title": "Retrospective Motion Correction of MR Images using Prior-Assisted Deep\n  Learning", "comments": null, "journal-ref": "Medical Imaging Meets NeurIPS 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In MRI, motion artefacts are among the most common types of artefacts. They\ncan degrade images and render them unusable for accurate diagnosis. Traditional\nmethods, such as prospective or retrospective motion correction, have been\nproposed to avoid or alleviate motion artefacts. Recently, several other\nmethods based on deep learning approaches have been proposed to solve this\nproblem. This work proposes to enhance the performance of existing deep\nlearning models by the inclusion of additional information present as image\npriors. The proposed approach has shown promising results and will be further\ninvestigated for clinical validity.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 14:03:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chatterjee", "Soumick", ""], ["Sciarra", "Alessandro", ""], ["D\u00fcnnwald", "Max", ""], ["Oeltze-Jafra", "Steffen", ""], ["N\u00fcrnberger", "Andreas", ""], ["Speck", "Oliver", ""]]}, {"id": "2011.14135", "submitter": "Benjamin Moster", "authors": "Abhishek Malik, Benjamin P. Moster and Christian Obermeier", "title": "Exoplanet Detection using Machine Learning", "comments": "10 pages, 8 figures, 4 tables, submitted to MNRAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new machine learning based technique to detect exoplanets\nusing the transit method. Machine learning and deep learning techniques have\nproven to be broadly applicable in various scientific research areas. We aim to\nexploit some of these methods to improve the conventional algorithm based\napproaches presently used in astrophysics to detect exoplanets. Using the\ntime-series analysis library TSFresh to analyse light curves, we extracted 789\nfeatures from each curve, which capture the information about the\ncharacteristics of a light curve. We then used these features to train a\ngradient boosting classifier using the machine learning tool lightgbm. This\napproach was tested on simulated data, which showed that is more effective than\nthe conventional box least squares fitting (BLS) method. We further found that\nour method produced comparable results to existing state-of-the-art deep\nlearning models, while being much more computationally efficient and without\nneeding folded and secondary views of the light curves. For Kepler data, the\nmethod is able to predict a planet with an AUC of 0.948, so that 94.8 per cent\nof the true planet signals are ranked higher than non-planet signals. The\nresulting recall is 0.96, so that 96 per cent of real planets are classified as\nplanets. For the Transiting Exoplanet Survey Satellite (TESS) data, we found\nour method can classify light curves with an accuracy of 0.98, and is able to\nidentify planets with a recall of 0.82 at a precision of 0.63.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 14:06:39 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 00:08:20 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Malik", "Abhishek", ""], ["Moster", "Benjamin P.", ""], ["Obermeier", "Christian", ""]]}, {"id": "2011.14137", "submitter": "Abdul Wahab", "authors": "Abdul Wahab, Muhammad Anas Tahir, Naveed Iqbal, Faisal Shafait, Syed\n  Muhammad Raza Kazmi", "title": "Short-Term Load Forecasting using Bi-directional Sequential Models and\n  Feature Engineering for Small Datasets", "comments": "8 pages, 13 figures, 5 tables. Submitted to IEEE Transactions on\n  Power Systems, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electricity load forecasting enables the grid operators to optimally\nimplement the smart grid's most essential features such as demand response and\nenergy efficiency. Electricity demand profiles can vary drastically from one\nregion to another on diurnal, seasonal and yearly scale. Hence to devise a load\nforecasting technique that can yield the best estimates on diverse datasets,\nspecially when the training data is limited, is a big challenge. This paper\npresents a deep learning architecture for short-term load forecasting based on\nbidirectional sequential models in conjunction with feature engineering that\nextracts the hand-crafted derived features in order to aid the model for better\nlearning and predictions. In the proposed architecture, named as Deep Derived\nFeature Fusion (DeepDeFF), the raw input and hand-crafted features are trained\nat separate levels and then their respective outputs are combined to make the\nfinal prediction. The efficacy of the proposed methodology is evaluated on\ndatasets from five countries with completely different patterns. The results\ndemonstrate that the proposed technique is superior to the existing state of\nthe art.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 14:11:35 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wahab", "Abdul", ""], ["Tahir", "Muhammad Anas", ""], ["Iqbal", "Naveed", ""], ["Shafait", "Faisal", ""], ["Kazmi", "Syed Muhammad Raza", ""]]}, {"id": "2011.14139", "submitter": "Guillermo Ramon", "authors": "Fatih Altay, Guillermo Ramon Sanchez, Yanli James, Stephen V. Faraone,\n  Senem Velipasalar, Asif Salekin", "title": "Preclinical Stage Alzheimer's Disease Detection Using Magnetic Resonance\n  Image Scans", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease is one of the diseases that mostly affects older people\nwithout being a part of aging. The most common symptoms include problems with\ncommunicating and abstract thinking, as well as disorientation. It is important\nto detect Alzheimer's disease in early stages so that cognitive functioning\nwould be improved by medication and training. In this paper, we propose two\nattention model networks for detecting Alzheimer's disease from MRI images to\nhelp early detection efforts at the preclinical stage. We also compare the\nperformance of these two attention network models with a baseline model.\nRecently available OASIS-3 Longitudinal Neuroimaging, Clinical, and Cognitive\nDataset is used to train, evaluate and compare our models. The novelty of this\nresearch resides in the fact that we aim to detect Alzheimer's disease when all\nthe parameters, physical assessments, and clinical data state that the patient\nis healthy and showing no symptoms\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 14:25:30 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Altay", "Fatih", ""], ["Sanchez", "Guillermo Ramon", ""], ["James", "Yanli", ""], ["Faraone", "Stephen V.", ""], ["Velipasalar", "Senem", ""], ["Salekin", "Asif", ""]]}, {"id": "2011.14143", "submitter": "Tarun Yenamandra", "authors": "Tarun Yenamandra, Ayush Tewari, Florian Bernard, Hans-Peter Seidel,\n  Mohamed Elgharib, Daniel Cremers, Christian Theobalt", "title": "i3DMM: Deep Implicit 3D Morphable Model of Human Heads", "comments": "Project page: http://gvv.mpi-inf.mpg.de/projects/i3DMM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first deep implicit 3D morphable model (i3DMM) of full heads.\nUnlike earlier morphable face models it not only captures identity-specific\ngeometry, texture, and expressions of the frontal face, but also models the\nentire head, including hair. We collect a new dataset consisting of 64 people\nwith different expressions and hairstyles to train i3DMM. Our approach has the\nfollowing favorable properties: (i) It is the first full head morphable model\nthat includes hair. (ii) In contrast to mesh-based models it can be trained on\nmerely rigidly aligned scans, without requiring difficult non-rigid\nregistration. (iii) We design a novel architecture to decouple the shape model\ninto an implicit reference shape and a deformation of this reference shape.\nWith that, dense correspondences between shapes can be learned implicitly. (iv)\nThis architecture allows us to semantically disentangle the geometry and color\ncomponents, as color is learned in the reference space. Geometry is further\ndisentangled as identity, expressions, and hairstyle, while color is\ndisentangled as identity and hairstyle components. We show the merits of i3DMM\nusing ablation studies, comparisons to state-of-the-art models, and\napplications such as semantic head editing and texture transfer. We will make\nour model publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 15:01:53 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yenamandra", "Tarun", ""], ["Tewari", "Ayush", ""], ["Bernard", "Florian", ""], ["Seidel", "Hans-Peter", ""], ["Elgharib", "Mohamed", ""], ["Cremers", "Daniel", ""], ["Theobalt", "Christian", ""]]}, {"id": "2011.14145", "submitter": "Feng Bao", "authors": "Richard Archibald, Feng Bao, Yanzhao Cao, and He Zhang", "title": "A Backward SDE Method for Uncertainty Quantification in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a probabilistic machine learning method, which formulates a class\nof stochastic neural networks by a stochastic optimal control problem. An\nefficient stochastic gradient descent algorithm is introduced under the\nstochastic maximum principle framework. Numerical experiments for applications\nof stochastic neural networks are carried out to validate the effectiveness of\nour methodology.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 15:19:36 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 01:42:45 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Archibald", "Richard", ""], ["Bao", "Feng", ""], ["Cao", "Yanzhao", ""], ["Zhang", "He", ""]]}, {"id": "2011.14164", "submitter": "Nanqing Dong", "authors": "Nanqing Dong, Michael Kampffmeyer, Xiaodan Liang, Min Xu, Irina\n  Voiculescu, Eric P. Xing", "title": "Towards Robust Medical Image Segmentation on Small-Scale Data with\n  Incomplete Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-driven nature of deep learning models for semantic segmentation\nrequires a large number of pixel-level annotations. However, large-scale and\nfully labeled medical datasets are often unavailable for practical tasks.\nRecently, partially supervised methods have been proposed to utilize images\nwith incomplete labels to mitigate the data scarcity problem in the medical\ndomain. As an emerging research area, the breakthroughs made by existing\nmethods rely on either large-scale data or complex model design, which makes\nthem 1) less practical for certain real-life tasks and 2) less robust for\nsmall-scale data. It is time to step back and think about the robustness of\npartially supervised methods and how to maximally utilize small-scale and\npartially labeled data for medical image segmentation tasks. To bridge the\nmethodological gaps in label-efficient deep learning with partial supervision,\nwe propose RAMP, a simple yet efficient data augmentation framework for\npartially supervised medical image segmentation by exploiting the assumption\nthat patients share anatomical similarities. We systematically evaluate RAMP\nand the previous methods in various controlled multi-structure segmentation\ntasks. Compared to the mainstream approaches, RAMP consistently improves the\nperformance of traditional segmentation networks on small-scale partially\nlabeled data and utilize additional image-wise weak annotations.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 16:31:00 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dong", "Nanqing", ""], ["Kampffmeyer", "Michael", ""], ["Liang", "Xiaodan", ""], ["Xu", "Min", ""], ["Voiculescu", "Irina", ""], ["Xing", "Eric P.", ""]]}, {"id": "2011.14172", "submitter": "Jiaxin Zhang", "authors": "Jiaxin Zhang, Congjie Wei, Chenglin Wu", "title": "Thermodynamic Consistent Neural Networks for Learning Material\n  Interfacial Mechanics", "comments": "NeurIPS 2020 workshop on Interpretable Inductive Biases and\n  Physically Structured Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For multilayer materials in thin substrate systems, interfacial failure is\none of the most challenges. The traction-separation relations (TSR)\nquantitatively describe the mechanical behavior of a material interface\nundergoing openings, which is critical to understand and predict interfacial\nfailures under complex loadings. However, existing theoretical models have\nlimitations on enough complexity and flexibility to well learn the real-world\nTSR from experimental observations. A neural network can fit well along with\nthe loading paths but often fails to obey the laws of physics, due to a lack of\nexperimental data and understanding of the hidden physical mechanism. In this\npaper, we propose a thermodynamic consistent neural network (TCNN) approach to\nbuild a data-driven model of the TSR with sparse experimental data. The TCNN\nleverages recent advances in physics-informed neural networks (PINN) that\nencode prior physical information into the loss function and efficiently train\nthe neural networks using automatic differentiation. We investigate three\nthermodynamic consistent principles, i.e., positive energy dissipation,\nsteepest energy dissipation gradient, and energy conservative loading path. All\nof them are mathematically formulated and embedded into a neural network model\nwith a novel defined loss function. A real-world experiment demonstrates the\nsuperior performance of TCNN, and we find that TCNN provides an accurate\nprediction of the whole TSR surface and significantly reduces the violated\nprediction against the laws of physics.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 17:25:10 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhang", "Jiaxin", ""], ["Wei", "Congjie", ""], ["Wu", "Chenglin", ""]]}, {"id": "2011.14177", "submitter": "Jiaxin Zhang", "authors": "Sirui Bi, Jiaxin Zhang, Guannan Zhang", "title": "Scalable Deep-Learning-Accelerated Topology Optimization for Additively\n  Manufactured Materials", "comments": "NeurIPS 2020 Workshop on Machine Learning for Engineering Modeling,\n  Simulation and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topology optimization (TO) is a popular and powerful computational approach\nfor designing novel structures, materials, and devices. Two computational\nchallenges have limited the applicability of TO to a variety of industrial\napplications. First, a TO problem often involves a large number of design\nvariables to guarantee sufficient expressive power. Second, many TO problems\nrequire a large number of expensive physical model simulations, and those\nsimulations cannot be parallelized. To address these issues, we propose a\ngeneral scalable deep-learning (DL) based TO framework, referred to as SDL-TO,\nwhich utilizes parallel schemes in high performance computing (HPC) to\naccelerate the TO process for designing additively manufactured (AM) materials.\nUnlike the existing studies of DL for TO, our framework accelerates TO by\nlearning the iterative history data and simultaneously training on the mapping\nbetween the given design and its gradient. The surrogate gradient is learned by\nutilizing parallel computing on multiple CPUs incorporated with a distributed\nDL training on multiple GPUs. The learned TO gradient enables a fast online\nupdate scheme instead of an expensive update based on the physical simulator or\nsolver. Using a local sampling strategy, we achieve to reduce the intrinsic\nhigh dimensionality of the design space and improve the training accuracy and\nthe scalability of the SDL-TO framework. The method is demonstrated by\nbenchmark examples and AM materials design for heat conduction. The proposed\nSDL-TO framework shows competitive performance compared to the baseline methods\nbut significantly reduces the computational cost by a speed up of around 8.6x\nover the standard TO implementation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 17:38:31 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bi", "Sirui", ""], ["Zhang", "Jiaxin", ""], ["Zhang", "Guannan", ""]]}, {"id": "2011.14193", "submitter": "Wen-Hua Chen Prof", "authors": "Wen-Hua Chen", "title": "Model Predictive Control with and without Terminal Weight: Stability and\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.RO cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents stability analysis tools for model predictive control\n(MPC) with and without terminal weight. Stability analysis of MPC with a\nlimited horizon but without terminal weight is a long-standing open problem. By\nusing a modified value function as an Lyapunov function candidate and the\nprinciple of optimality, this paper establishes stability conditions for this\ntype of widely spread MPC algorithms. A new stability guaranteed MPC algorithm\nwithout terminal weight (MPCS) is presented. With the help of designing a new\nsublevel set defined by the value function of one-step ahead stage cost,\nconditions for checking its recursive feasibility and stability of the proposed\nMPC algorithm are presented. The new stability condition and the derived MPCS\novercome the difficulties arising in the existing terminal weight based MPC\nframework, including the need of searching a suitable terminal weight and\npossible poor performance caused by an inappropriate terminal weight. This work\nis further extended to MPC with a terminal weight for the completeness.\nNumerical examples are presented to demonstrate the effectiveness of the\nproposed tool, whereas the existing stability analysis tools are either not\napplicable or lead to quite conservative results. It shows that the proposed\ntools offer a number of mechanisms to achieve stability: adjusting state and/or\ncontrol weights, extending the length of horizon, and adding a simple extra\nconstraint on the first or second state in the optimisation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:48:31 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 15:12:05 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chen", "Wen-Hua", ""]]}, {"id": "2011.14194", "submitter": "Thu Huong Truong", "authors": "Truong Thu Huong, Ta Phuong Bac, Dao M. Long, Bui D. Thang, Nguyen T.\n  Binh, Tran D. Luong, and Tran Kim Phuc", "title": "LocKedge: Low-Complexity Cyberattack Detection in IoT Edge Computing", "comments": "13 pages, 20 figures, submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things and its applications are becoming commonplace with more\ndevices, but always at risk of network security. It is therefore crucial for an\nIoT network design to identify attackers accurately, quickly and promptly. Many\nsolutions have been proposed, mainly concerning secure IoT architectures and\nclassification algorithms, but none of them have paid enough attention to\nreducing the complexity. Our proposal in this paper is an edge cloud\narchitecture that fulfills the detection task right at the edge layer, near the\nsource of the attacks for quick response, versatility, as well as reducing the\nworkload of the cloud. We also propose a multi attack detection mechanism\ncalled LocKedge Low Complexity Cyberattack Detection in IoT Edge Computing,\nwhich has low complexity for deployment at the edge zone while still\nmaintaining high accuracy. LocKedge is implemented in two manners: centralized\nand federated learning manners in order to verify the performance of the\narchitecture from different perspectives. The performance of our proposed\nmechanism is compared with that of other machine learning and deep learning\nmethods using the most updated BoT IoT data set. The results show that LocKedge\noutperforms other algorithms such as NN, CNN, RNN, KNN, SVM, KNN, RF and\nDecision Tree in terms of accuracy and NN in terms of complexity.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:49:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Huong", "Truong Thu", ""], ["Bac", "Ta Phuong", ""], ["Long", "Dao M.", ""], ["Thang", "Bui D.", ""], ["Binh", "Nguyen T.", ""], ["Luong", "Tran D.", ""], ["Phuc", "Tran Kim", ""]]}, {"id": "2011.14196", "submitter": "Seyed Mohsen Hosseini", "authors": "Seyed Mohsen Hosseini", "title": "Lattice Fusion Networks for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for feature fusion in convolutional neural networks is\nproposed in this paper. Different feature fusion techniques are suggested to\nfacilitate the flow of information and improve the training of deep neural\nnetworks. Some of these techniques as well as the proposed network can be\nconsidered a type of Directed Acyclic Graph (DAG) Network, where a layer can\nreceive inputs from other layers and have outputs to other layers. In the\nproposed general framework of Lattice Fusion Network (LFNet), feature maps of\neach convolutional layer are passed to other layers based on a lattice graph\nstructure, where nodes are convolutional layers. To evaluate the performance of\nthe proposed architecture, different designs based on the general framework of\nLFNet are implemented for the task of image denoising. This task is used as an\nexample where training deep convolutional networks is needed. Results are\ncompared with state of the art methods. The proposed network is able to achieve\nbetter results with far fewer learnable parameters, which shows the\neffectiveness of LFNets for training of deep neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:57:54 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 04:29:24 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 17:27:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Hosseini", "Seyed Mohsen", ""]]}, {"id": "2011.14200", "submitter": "Sandesh Ramesh", "authors": "Sandesh Ramesh, Manoj Kumar M V, and Sanjay H A", "title": "E-Pro: Euler Angle and Probabilistic Model for Face Detection and\n  Recognition", "comments": "4th International Conference on Inventive Systems and Control\n  (ICISC), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  It is human nature to give prime importance to facial appearances. Often, to\nlook good is to feel good. Also, facial features are unique to every individual\non this planet, which means it is a source of vital information. This work\nproposes a framework named E-Pro for the detection and recognition of faces by\ntaking facial images as inputs. E-Pro has its potential application in various\ndomains, namely attendance, surveillance, crowd monitoring, biometric-based\nauthentication etc. E-Pro is developed here as a mobile application that aims\nto aid lecturers to mark attendance in a classroom by detecting and recognizing\nthe faces of students from a picture clicked through the app. E-Pro has been\ndeveloped using Google Firebase Face Recognition APIs, which uses Euler Angles,\nand Probabilistic Model. E-Pro has been tested on stock images and the\nexperimental results are promising.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 19:12:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ramesh", "Sandesh", ""], ["M", "Manoj Kumar", "V"], ["A", "Sanjay H", ""]]}, {"id": "2011.14204", "submitter": "Ayush Jaiswal", "authors": "Ayush Jaiswal, Yue Wu, Pradeep Natarajan, Premkumar Natarajan", "title": "Class-agnostic Object Detection", "comments": "To appear in Proceedings of WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection models perform well at localizing and classifying objects\nthat they are shown during training. However, due to the difficulty and cost\nassociated with creating and annotating detection datasets, trained models\ndetect a limited number of object types with unknown objects treated as\nbackground content. This hinders the adoption of conventional detectors in\nreal-world applications like large-scale object matching, visual grounding,\nvisual relation prediction, obstacle detection (where it is more important to\ndetermine the presence and location of objects than to find specific types),\netc. We propose class-agnostic object detection as a new problem that focuses\non detecting objects irrespective of their object-classes. Specifically, the\ngoal is to predict bounding boxes for all objects in an image but not their\nobject-classes. The predicted boxes can then be consumed by another system to\nperform application-specific classification, retrieval, etc. We propose\ntraining and evaluation protocols for benchmarking class-agnostic detectors to\nadvance future research in this domain. Finally, we propose (1) baseline\nmethods and (2) a new adversarial learning framework for class-agnostic\ndetection that forces the model to exclude class-specific information from\nfeatures used for predictions. Experimental results show that adversarial\nlearning improves class-agnostic detection efficacy.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 19:22:38 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jaiswal", "Ayush", ""], ["Wu", "Yue", ""], ["Natarajan", "Pradeep", ""], ["Natarajan", "Premkumar", ""]]}, {"id": "2011.14211", "submitter": "Bingzhe Wei", "authors": "Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Chunxu Zhang, Bo\n  Yang", "title": "Curvature Regularization to Prevent Distortion in Graph Embedding", "comments": "Published as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on graph embedding has achieved success in various\napplications. Most graph embedding methods preserve the proximity in a graph\ninto a manifold in an embedding space. We argue an important but neglected\nproblem about this proximity-preserving strategy: Graph topology patterns,\nwhile preserved well into an embedding manifold by preserving proximity, may\ndistort in the ambient embedding Euclidean space, and hence to detect them\nbecomes difficult for machine learning models. To address the problem, we\npropose curvature regularization, to enforce flatness for embedding manifolds,\nthereby preventing the distortion. We present a novel angle-based sectional\ncurvature, termed ABS curvature, and accordingly three kinds of curvature\nregularization to induce flat embedding manifolds during graph embedding. We\nintegrate curvature regularization into five popular proximity-preserving\nembedding methods, and empirical results in two applications show significant\nimprovements on a wide range of open graph datasets.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 20:16:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Pei", "Hongbin", ""], ["Wei", "Bingzhe", ""], ["Chang", "Kevin Chen-Chuan", ""], ["Zhang", "Chunxu", ""], ["Yang", "Bo", ""]]}, {"id": "2011.14212", "submitter": "Benjamin Gravell", "authors": "Benjamin Gravell, Iman Shames, Tyler Summers", "title": "Approximate Midpoint Policy Iteration for Linear Quadratic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a midpoint policy iteration algorithm to solve linear quadratic\noptimal control problems in both model-based and model-free settings. The\nalgorithm is a variation of Newton's method, and we show that in the\nmodel-based setting it achieves cubic convergence, which is superior to\nstandard policy iteration and policy gradient algorithms that achieve quadratic\nand linear convergence, respectively. We also demonstrate that the algorithm\ncan be approximately implemented without knowledge of the dynamics model by\nusing least-squares estimates of the state-action value function from\ntrajectory data, from which policy improvements can be obtained. With\nsufficient trajectory data, the policy iterates converge cubically to\napproximately optimal policies, and this occurs with the same available sample\nbudget as the approximate standard policy iteration. Numerical experiments\ndemonstrate effectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 20:22:10 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 05:52:22 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Gravell", "Benjamin", ""], ["Shames", "Iman", ""], ["Summers", "Tyler", ""]]}, {"id": "2011.14214", "submitter": "Anadi Chaman", "authors": "Anadi Chaman (1), Ivan Dokmani\\'c (2) ((1) University of Illinois at\n  Urbana-Champaign, (2) University of Basel)", "title": "Truly shift-invariant convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the use of convolution and pooling layers, convolutional neural\nnetworks were for a long time thought to be shift-invariant. However, recent\nworks have shown that the output of a CNN can change significantly with small\nshifts in input: a problem caused by the presence of downsampling (stride)\nlayers. The existing solutions rely either on data augmentation or on\nanti-aliasing, both of which have limitations and neither of which enables\nperfect shift invariance. Additionally, the gains obtained from these methods\ndo not extend to image patterns not seen during training. To address these\nchallenges, we propose adaptive polyphase sampling (APS), a simple sub-sampling\nscheme that allows convolutional neural networks to achieve 100% consistency in\nclassification performance under shifts, without any loss in accuracy. With\nAPS, the networks exhibit perfect consistency to shifts even before training,\nmaking it the first approach that makes convolutional neural networks truly\nshift-invariant.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 20:57:35 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 12:46:12 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 12:18:15 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 19:47:57 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Chaman", "Anadi", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "2011.14220", "submitter": "Harsh Dhiman", "authors": "Harsh S. Dhiman, Dipankar Deb", "title": "Machine Intelligent Techniques for Ramp Event Prediction in Offshore and\n  Onshore Wind Farms", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Globally, wind energy has lessened the burden on conventional fossil fuel\nbased power generation. Wind resource assessment for onshore and offshore wind\nfarms aids in accurate forecasting and analyzing nature of ramp events. From an\nindustrial point of view, a large ramp event in a short time duration is likely\nto cause damage to the wind farm connected to the utility grid. In this\nmanuscript, ramp events are predicted using hybrid machine intelligent\ntechniques such as Support vector regression (SVR) and its variants, random\nforest regression and gradient boosted machines for onshore and offshore wind\nfarm sites. Wavelet transform based signal processing technique is used to\nextract features from wind speed. Results reveal that SVR based prediction\nmodels gives the best forecasting performance out of all models. In addition,\ngradient boosted machines (GBM) predicts ramp events closer to Twin support\nvector regression (TSVR) model. Furthermore, the randomness in ramp power is\nevaluated for onshore and offshore wind farms by calculating log energy entropy\nof features obtained from wavelet decomposition and empirical model\ndecomposition.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 21:21:42 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dhiman", "Harsh S.", ""], ["Deb", "Dipankar", ""]]}, {"id": "2011.14227", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "PCPs: Patient Cardiac Prototypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many clinical deep learning algorithms are population-based and difficult to\ninterpret. Such properties limit their clinical utility as population-based\nfindings may not generalize to individual patients and physicians are reluctant\nto incorporate opaque models into their clinical workflow. To overcome these\nobstacles, we propose to learn patient-specific embeddings, entitled patient\ncardiac prototypes (PCPs), that efficiently summarize the cardiac state of the\npatient. To do so, we attract representations of multiple cardiac signals from\nthe same patient to the corresponding PCP via supervised contrastive learning.\nWe show that the utility of PCPs is multifold. First, they allow for the\ndiscovery of similar patients both within and across datasets. Second, such\nsimilarity can be leveraged in conjunction with a hypernetwork to generate\npatient-specific parameters, and in turn, patient-specific diagnoses. Third, we\nfind that PCPs act as a compact substitute for the original dataset, allowing\nfor dataset distillation.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 22:41:27 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2011.14229", "submitter": "Jian Wang", "authors": "Jian Wang, Miaomiao Zhang", "title": "Deep Learning for Regularization Prediction in Diffeomorphic Image\n  Registration", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a predictive model for estimating regularization\nparameters of diffeomorphic image registration. We introduce a novel framework\nthat automatically determines the parameters controlling the smoothness of\ndiffeomorphic transformations. Our method significantly reduces the effort of\nparameter tuning, which is time and labor-consuming. To achieve the goal, we\ndevelop a predictive model based on deep convolutional neural networks (CNN)\nthat learns the mapping between pairwise images and the regularization\nparameter of image registration. In contrast to previous methods that estimate\nsuch parameters in a high-dimensional image space, our model is built in an\nefficient bandlimited space with much lower dimensions. We demonstrate the\neffectiveness of our model on both 2D synthetic data and 3D real brain images.\nExperimental results show that our model not only predicts appropriate\nregularization parameters for image registration, but also improving the\nnetwork training in terms of time and memory efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 22:56:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Jian", ""], ["Zhang", "Miaomiao", ""]]}, {"id": "2011.14230", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "DROPS: Deep Retrieval of Physiological Signals via Attribute-specific\n  Clinical Prototypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ongoing digitization of health records within the healthcare industry\nresults in large-scale datasets. Manually extracting clinically-useful insight\nfrom such datasets is non-trivial. However, doing so at scale while\nsimultaneously leveraging patient-specific attributes such as sex and age can\nassist with clinical-trial enrollment, medical school educational endeavours,\nand the evaluation of the fairness of neural networks. To facilitate the\nreliable extraction of clinical information, we propose to learn embeddings,\nknown as clinical prototypes (CPs), via supervised contrastive learning. We\nshow that CPs can be efficiently used for large-scale retrieval and clustering\nof physiological signals based on multiple patient attributes. We also show\nthat CPs capture attribute-specific semantic relationships.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 23:02:55 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2011.14238", "submitter": "Amy Zhang", "authors": "Amy X. Zhang, Le Bao, Michael J. Daniels", "title": "Approximate Cross-validated Mean Estimates for Bayesian Hierarchical\n  Regression Models", "comments": "17 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel procedure for obtaining cross-validated predictive\nestimates for Bayesian hierarchical regression models (BHRMs). Bayesian\nhierarchical models are popular for their ability to model complex dependence\nstructures and provide probabilistic uncertainty estimates, but can be\ncomputationally expensive to run. Cross-validation (CV) is therefore not a\ncommon practice to evaluate the predictive performance of BHRMs. Our method\ncircumvents the need to re-run computationally costly estimation methods for\neach cross-validation fold and makes CV more feasible for large BHRMs. By\nconditioning on the variance-covariance parameters, we shift the CV problem\nfrom probability-based sampling to a simple and familiar optimization problem.\nIn many cases, this produces estimates which are equivalent to full CV. We\nprovide theoretical results and demonstrate its efficacy on publicly available\ndata and in simulations.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 00:00:20 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 20:45:30 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhang", "Amy X.", ""], ["Bao", "Le", ""], ["Daniels", "Michael J.", ""]]}, {"id": "2011.14244", "submitter": "Yao Fu", "authors": "Yao Fu, Chuanqi Tan, Bin Bi, Mosha Chen, Yansong Feng, Alexander M.\n  Rush", "title": "Latent Template Induction with Gumbel-CRFs", "comments": "NeurIPS 2020 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to control the structure of sentences is a challenging problem in\ntext generation. Existing work either relies on simple deterministic approaches\nor RL-based hard structures. We explore the use of structured variational\nautoencoders to infer latent templates for sentence generation using a soft,\ncontinuous relaxation in order to utilize reparameterization for training.\nSpecifically, we propose a Gumbel-CRF, a continuous relaxation of the CRF\nsampling algorithm using a relaxed Forward-Filtering Backward-Sampling (FFBS)\napproach. As a reparameterized gradient estimator, the Gumbel-CRF gives more\nstable gradients than score-function based estimators. As a structured\ninference network, we show that it learns interpretable templates during\ntraining, which allows us to control the decoder during testing. We demonstrate\nthe effectiveness of our methods with experiments on data-to-text generation\nand unsupervised paraphrase generation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 01:00:57 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Fu", "Yao", ""], ["Tan", "Chuanqi", ""], ["Bi", "Bin", ""], ["Chen", "Mosha", ""], ["Feng", "Yansong", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2011.14246", "submitter": "Scott Hottovy", "authors": "Elana Kozak and Scott Hottovy", "title": "Monte Carlo Tree Search for a single target search game on a 2-D lattice", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monte Carlo Tree Search (MCTS) is a branch of stochastic modeling that\nutilizes decision trees for optimization, mostly applied to artificial\nintelligence (AI) game players. This project imagines a game in which an AI\nplayer searches for a stationary target within a 2-D lattice. We analyze its\nbehavior with different target distributions and compare its efficiency to the\nLevy Flight Search, a model for animal foraging behavior. In addition to\nsimulated data analysis we prove two theorems about the convergence of MCTS\nwhen computation constraints neglected.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 01:07:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kozak", "Elana", ""], ["Hottovy", "Scott", ""]]}, {"id": "2011.14251", "submitter": "Kamyar Azizzadenesheli Ph.D.", "authors": "Kamyar Azizzadenesheli", "title": "Importance Weight Estimation and Generalization in Domain Adaptation\n  under Label Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generalization under labeled shift for categorical and general\nnormed label spaces. We propose a series of methods to estimate the importance\nweights from labeled source to unlabeled target domain and provide confidence\nbounds for these estimators. We deploy these estimators and provide\ngeneralization bounds in the unlabeled target domain.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 01:37:58 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 20:38:20 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Azizzadenesheli", "Kamyar", ""]]}, {"id": "2011.14266", "submitter": "Samuel Daulton", "authors": "Hongseok Namkoong, Samuel Daulton, Eytan Bakshy", "title": "Distilled Thompson Sampling: Practical and Efficient Thompson Sampling\n  via Imitation Learning", "comments": null, "journal-ref": "Offline Reinforcement Learning Workshop at Neural Information\n  Processing Systems, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling (TS) has emerged as a robust technique for contextual\nbandit problems. However, TS requires posterior inference and optimization for\naction generation, prohibiting its use in many internet applications where\nlatency and ease of deployment are of concern. We propose a novel\nimitation-learning-based algorithm that distills a TS policy into an explicit\npolicy representation by performing posterior inference and optimization\noffline. The explicit policy representation enables fast online decision-making\nand easy deployment in mobile and server-based environments. Our algorithm\niteratively performs offline batch updates to the TS policy and learns a new\nimitation policy. Since we update the TS policy with observations collected\nunder the imitation policy, our algorithm emulates an off-policy version of TS.\nOur imitation algorithm guarantees Bayes regret comparable to TS, up to the sum\nof single-step imitation errors. We show these imitation errors can be made\narbitrarily small when unlabeled contexts are cheaply available, which is the\ncase for most large-scale internet applications. Empirically, we show that our\nimitation policy achieves comparable regret to TS, while reducing decision-time\nlatency by over an order of magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 03:57:42 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:08:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Namkoong", "Hongseok", ""], ["Daulton", "Samuel", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2011.14267", "submitter": "Qiwen Cui", "authors": "Qiwen Cui and Lin F. Yang", "title": "Minimax Sample Complexity for Turn-based Stochastic Game", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The empirical success of Multi-agent reinforcement learning is encouraging,\nwhile few theoretical guarantees have been revealed. In this work, we prove\nthat the plug-in solver approach, probably the most natural reinforcement\nlearning algorithm, achieves minimax sample complexity for turn-based\nstochastic game (TBSG). Specifically, we plan in an empirical TBSG by utilizing\na `simulator' that allows sampling from arbitrary state-action pair. We show\nthat the empirical Nash equilibrium strategy is an approximate Nash equilibrium\nstrategy in the true TBSG and give both problem-dependent and\nproblem-independent bound. We develop absorbing TBSG and reward perturbation\ntechniques to tackle the complex statistical dependence. The key idea is\nartificially introducing a suboptimality gap in TBSG and then the Nash\nequilibrium strategy lies in a finite set.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 03:58:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cui", "Qiwen", ""], ["Yang", "Lin F.", ""]]}, {"id": "2011.14269", "submitter": "Hongkang Yang", "authors": "Hongkang Yang and Weinan E", "title": "Generalization and Memorization: The Bias Potential Model", "comments": "Added new section on regularized model", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models for learning probability distributions such as generative models and\ndensity estimators behave quite differently from models for learning functions.\nOne example is found in the memorization phenomenon, namely the ultimate\nconvergence to the empirical distribution, that occurs in generative\nadversarial networks (GANs). For this reason, the issue of generalization is\nmore subtle than that for supervised learning. For the bias potential model, we\nshow that dimension-independent generalization accuracy is achievable if early\nstopping is adopted, despite that in the long term, the model either memorizes\nthe samples or diverges.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:04:54 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 03:38:28 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 04:29:13 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 03:57:31 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Yang", "Hongkang", ""], ["E", "Weinan", ""]]}, {"id": "2011.14276", "submitter": "Hector Javier Hortua", "authors": "Hector J. Hortua, Riccardo Volpi, Dimitri Marinelli, Luigi Malago", "title": "Accelerating MCMC algorithms through Bayesian Deep Networks", "comments": "Accepted in the Third Workshop on Machine Learning and the Physical\n  Sciences, NeurIPS 2020, Vancouver, Canada. Text overlap with\n  arXiv:1911.08508v3", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) algorithms are commonly used for their\nversatility in sampling from complicated probability distributions. However, as\nthe dimension of the distribution gets larger, the computational costs for a\nsatisfactory exploration of the sampling space become challenging. Adaptive\nMCMC methods employing a choice of proposal distribution can address this issue\nspeeding up the convergence. In this paper we show an alternative way of\nperforming adaptive MCMC, by using the outcome of Bayesian Neural Networks as\nthe initial proposal for the Markov Chain. This combined approach increases the\nacceptance rate in the Metropolis-Hasting algorithm and accelerate the\nconvergence of the MCMC while reaching the same final accuracy. Finally, we\ndemonstrate the main advantages of this approach by constraining the\ncosmological parameters directly from Cosmic Microwave Background maps.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:29:00 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Hortua", "Hector J.", ""], ["Volpi", "Riccardo", ""], ["Marinelli", "Dimitri", ""], ["Malago", "Luigi", ""]]}, {"id": "2011.14280", "submitter": "Hrithwik Shalu", "authors": "Sudhir Kumar Suman, Hrithwik Shalu, Lakshya A Agrawal, Archit Agrawal,\n  Juned Kadiwala", "title": "A Novel Sentiment Analysis Engine for Preliminary Depression Status\n  Estimation on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text sentiment analysis for preliminary depression status estimation of users\non social media is a widely exercised and feasible method, However, the immense\nvariety of users accessing the social media websites and their ample mix of\nvocabularies makes it difficult for commonly applied deep learning-based\nclassifiers to perform. To add to the situation, the lack of adaptability of\ntraditional supervised machine learning could hurt at many levels. We propose a\ncloud-based smartphone application, with a deep learning-based backend to\nprimarily perform depression detection on Twitter social media. The backend\nmodel consists of a RoBERTa based siamese sentence classifier that compares a\ngiven tweet (Query) with a labeled set of tweets with known sentiment (\nStandard Corpus ). The standard corpus is varied over time with expert opinion\nso as to improve the model's reliability. A psychologist ( with the patient's\npermission ) could leverage the application to assess the patient's depression\nstatus prior to counseling, which provides better insight into the mental\nhealth status of a patient. In addition, to the same, the psychologist could be\nreferred to cases of similar characteristics, which could in turn help in more\neffective treatment. We evaluate our backend model after fine-tuning it on a\npublicly available dataset. The find tuned model is made to predict depression\non a large set of tweet samples with random noise factors. The model achieved\npinnacle results, with a testing accuracy of 87.23% and an AUC of 0.8621.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 04:42:53 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Suman", "Sudhir Kumar", ""], ["Shalu", "Hrithwik", ""], ["Agrawal", "Lakshya A", ""], ["Agrawal", "Archit", ""], ["Kadiwala", "Juned", ""]]}, {"id": "2011.14306", "submitter": "Terumasa Tokunaga Dr", "authors": "Ryoya Katafuchi, Terumasa Tokunaga", "title": "Image-based Plant Disease Diagnosis with Unsupervised Anomaly Detection\n  Based on Reconstructability of Colors", "comments": "14 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an unsupervised anomaly detection technique for\nimage-based plant disease diagnosis. The construction of large and publicly\navailable datasets containing labeled images of healthy and diseased crop\nplants led to growing interest in computer vision techniques for automatic\nplant disease diagnosis. Although supervised image classifiers based on deep\nlearning can be a powerful tool for plant disease diagnosis, they require a\nhuge amount of labeled data. The data mining technique of anomaly detection\nincludes unsupervised approaches that do not require rare samples for training\nclassifiers. We propose an unsupervised anomaly detection technique for\nimage-based plant disease diagnosis that is based on the reconstructability of\ncolors; a deep encoder-decoder network trained to reconstruct the colors of\n\\textit{healthy} plant images should fail to reconstruct colors of symptomatic\nregions. Our proposed method includes a new image-based framework for plant\ndisease detection that utilizes a conditional adversarial network called\npix2pix and a new anomaly score based on CIEDE2000 color difference.\nExperiments with PlantVillage dataset demonstrated the superiority of our\nproposed method compared to an existing anomaly detector at identifying\ndiseased crop images in terms of accuracy, interpretability and computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 07:44:05 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 13:47:44 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 17:27:41 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 16:44:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Katafuchi", "Ryoya", ""], ["Tokunaga", "Terumasa", ""]]}, {"id": "2011.14307", "submitter": "Adrian Prochaska", "authors": "Adrian Prochaska and Julien Pillas and Bernard B\\\"aker", "title": "Active Output Selection Strategies for Multiple Learning Regression\n  Models", "comments": "The paper is accepted for publication at ICPRAM 2021", "journal-ref": "ICPRAM 2021", "doi": "10.5220/0010181501500157", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning shows promise to decrease test bench time for model-based\ndrivability calibration. This paper presents a new strategy for active output\nselection, which suits the needs of calibration tasks. The strategy is actively\nlearning multiple outputs in the same input space. It chooses the output model\nwith the highest cross-validation error as leading. The presented method is\napplied to three different toy examples with noise in a real world range and to\na benchmark dataset. The results are analyzed and compared to other existing\nstrategies. In a best case scenario, the presented strategy is able to decrease\nthe number of points by up to 30% compared to a sequential space-filling design\nwhile outperforming other existing active learning strategies. The results are\npromising but also show that the algorithm has to be improved to increase\nrobustness for noisy environments. Further research will focus on improving the\nalgorithm and applying it to a real-world example.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 08:05:53 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Prochaska", "Adrian", ""], ["Pillas", "Julien", ""], ["B\u00e4ker", "Bernard", ""]]}, {"id": "2011.14317", "submitter": "Arindam Bhattacharya", "authors": "Arindam Bhattacharya and Sumanth Varambally and Amitabha Bagchi and\n  Srikanta Bedathur", "title": "FROCC: Fast Random projection-based One-Class Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Fast Random projection-based One-Class Classification (FROCC), an\nextremely efficient method for one-class classification. Our method is based on\na simple idea of transforming the training data by projecting it onto a set of\nrandom unit vectors that are chosen uniformly and independently from the unit\nsphere, and bounding the regions based on separation of the data. FROCC can be\nnaturally extended with kernels. We theoretically prove that FROCC generalizes\nwell in the sense that it is stable and has low bias. FROCC achieves up to 3.1\npercent points better ROC, with 1.2--67.8x speedup in training and test times\nover a range of state-of-the-art benchmarks including the SVM and the deep\nlearning based models for the OCC task.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 08:56:59 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 11:10:57 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 14:11:48 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bhattacharya", "Arindam", ""], ["Varambally", "Sumanth", ""], ["Bagchi", "Amitabha", ""], ["Bedathur", "Srikanta", ""]]}, {"id": "2011.14340", "submitter": "Dawid Rymarczyk", "authors": "Dawid Rymarczyk, {\\L}ukasz Struski, Jacek Tabor, Bartosz Zieli\\'nski", "title": "ProtoPShare: Prototype Sharing for Interpretable Image Classification\n  and Similarity Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce ProtoPShare, a self-explained method that\nincorporates the paradigm of prototypical parts to explain its predictions. The\nmain novelty of the ProtoPShare is its ability to efficiently share\nprototypical parts between the classes thanks to our data-dependent\nmerge-pruning. Moreover, the prototypes are more consistent and the model is\nmore robust to image perturbations than the state of the art method ProtoPNet.\nWe verify our findings on two datasets, the CUB-200-2011 and the Stanford Cars.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 11:23:05 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rymarczyk", "Dawid", ""], ["Struski", "\u0141ukasz", ""], ["Tabor", "Jacek", ""], ["Zieli\u0144ski", "Bartosz", ""]]}, {"id": "2011.14359", "submitter": "Jinlin Lai", "authors": "Jinlin Lai, Lixin Zou, Jiaxing Song", "title": "Optimal Mixture Weights for Off-Policy Evaluation with Multiple Behavior\n  Policies", "comments": "Offline Reinforcement Learning Workshop at Neural Information\n  Processing Systems, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation is a key component of reinforcement learning which\nevaluates a target policy with offline data collected from behavior policies.\nIt is a crucial step towards safe reinforcement learning and has been used in\nadvertisement, recommender systems and many other applications. In these\napplications, sometimes the offline data is collected from multiple behavior\npolicies. Previous works regard data from different behavior policies equally.\nNevertheless, some behavior policies are better at producing good estimators\nwhile others are not. This paper starts with discussing how to correctly mix\nestimators produced by different behavior policies. We propose three ways to\nreduce the variance of the mixture estimator when all sub-estimators are\nunbiased or asymptotically unbiased. Furthermore, experiments on simulated\nrecommender systems show that our methods are effective in reducing the\nMean-Square Error of estimation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 12:57:54 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lai", "Jinlin", ""], ["Zou", "Lixin", ""], ["Song", "Jiaxing", ""]]}, {"id": "2011.14365", "submitter": "Weifeng Zhu", "authors": "Jiazhu Dai, Weifeng Zhu, Xiangfeng Luo", "title": "A Targeted Universal Attack on Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data exist in numerous applications in real life. As a\nstate-of-the-art graph neural network, the graph convolutional network (GCN)\nplays an important role in processing graph-structured data. However, a recent\nstudy reported that GCNs are also vulnerable to adversarial attacks, which\nmeans that GCN models may suffer malicious attacks with unnoticeable\nmodifications of the data. Among all the adversarial attacks on GCNs, there is\na special kind of attack method called the universal adversarial attack, which\ngenerates a perturbation that can be applied to any sample and causes GCN\nmodels to output incorrect results. Although universal adversarial attacks in\ncomputer vision have been extensively researched, there are few research works\non universal adversarial attacks on graph structured data. In this paper, we\npropose a targeted universal adversarial attack against GCNs. Our method\nemploys a few nodes as the attack nodes. The attack capability of the attack\nnodes is enhanced through a small number of fake nodes connected to them.\nDuring an attack, any victim node will be misclassified by the GCN as the\nattack node class as long as it is linked to them. The experiments on three\npopular datasets show that the average attack success rate of the proposed\nattack on any victim node in the graph reaches 83% when using only 3 attack\nnodes and 6 fake nodes. We hope that our work will make the community aware of\nthe threat of this type of attack and raise the attention given to its future\ndefense.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 13:19:53 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dai", "Jiazhu", ""], ["Zhu", "Weifeng", ""], ["Luo", "Xiangfeng", ""]]}, {"id": "2011.14370", "submitter": "Sidhartha Narayan S", "authors": "Sarah, S.Sidhartha Narayan, Irfaan Arif, Hrithwik Shalu, Juned\n  Kadiwala", "title": "A smartphone based multi input workflow for non-invasive estimation of\n  haemoglobin levels using machine learning techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a low cost, non invasive healthcare system that measures\nhaemoglobin levels in patients and can be used as a preliminary diagnostic test\nfor anaemia. A combination of image processing, machine learning and deep\nlearning techniques are employed to develop predictive models to measure\nhaemoglobin levels. This is achieved through the color analysis of the\nfingernail beds, palpebral conjunctiva and tongue of the patients. This\npredictive model is then encapsulated in a healthcare application. This\napplication expedites data collection and facilitates active learning of the\nmodel. It also incorporates personalized calibration of the model for each\npatient, assisting in the continual monitoring of the haemoglobin levels of the\npatient. Upon validating this framework using data, it can serve as a highly\naccurate preliminary diagnostic test for anaemia.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 13:57:09 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sarah", "", ""], ["Narayan", "S. Sidhartha", ""], ["Arif", "Irfaan", ""], ["Shalu", "Hrithwik", ""], ["Kadiwala", "Juned", ""]]}, {"id": "2011.14371", "submitter": "Arnav Kumar Jain", "authors": "Hadia Mohmmed Osman Ahmed Samil, Annabelle Martin, Arnav Kumar Jain,\n  Susan Amin and Samira Ebrahimi Kahou", "title": "Predicting Regional Locust Swarm Distribution with Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locust infestation of some regions in the world, including Africa, Asia and\nMiddle East has become a concerning issue that can affect the health and the\nlives of millions of people. In this respect, there have been attempts to\nresolve or reduce the severity of this problem via detection and monitoring of\nlocust breeding areas using satellites and sensors, or the use of chemicals to\nprevent the formation of swarms. However, such methods have not been able to\nsuppress the emergence and the collective behaviour of locusts. The ability to\npredict the location of the locust swarms prior to their formation, on the\nother hand, can help people get prepared and tackle the infestation issue more\neffectively. Here, we use machine learning to predict the location of locust\nswarms using the available data published by the Food and Agriculture\nOrganization of the United Nations. The data includes the location of the\nobserved swarms as well as environmental information, including soil moisture\nand the density of vegetation. The obtained results show that our proposed\nmodel can successfully, and with reasonable precision, predict the location of\nlocust swarms, as well as their likely level of damage using a notion of\ndensity.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 14:07:05 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Samil", "Hadia Mohmmed Osman Ahmed", ""], ["Martin", "Annabelle", ""], ["Jain", "Arnav Kumar", ""], ["Amin", "Susan", ""], ["Kahou", "Samira Ebrahimi", ""]]}, {"id": "2011.14379", "submitter": "Louis Monier", "authors": "Louis Monier, Jakub Kmec, Alexandre Laterre, Thomas Pierrot, Valentin\n  Courgeau, Olivier Sigaud and Karim Beguir", "title": "Offline Reinforcement Learning Hands-On", "comments": "Accepted at NeurIPS 2020 Offline Reinforcement Learning Workshop.\n  First two authors contributed equally. Authors three and four advised equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline Reinforcement Learning (RL) aims to turn large datasets into powerful\ndecision-making engines without any online interactions with the environment.\nThis great promise has motivated a large amount of research that hopes to\nreplicate the success RL has experienced in simulation settings. This work\nambitions to reflect upon these efforts from a practitioner viewpoint. We start\nby discussing the dataset properties that we hypothesise can characterise the\ntype of offline methods that will be the most successful. We then verify these\nclaims through a set of experiments and designed datasets generated from\nenvironments with both discrete and continuous action spaces. We experimentally\nvalidate that diversity and high-return examples in the data are crucial to the\nsuccess of offline RL and show that behavioural cloning remains a strong\ncontender compared to its contemporaries. Overall, this work stands as a\ntutorial to help people build their intuition on today's offline RL methods and\ntheir applicability.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 14:45:02 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Monier", "Louis", ""], ["Kmec", "Jakub", ""], ["Laterre", "Alexandre", ""], ["Pierrot", "Thomas", ""], ["Courgeau", "Valentin", ""], ["Sigaud", "Olivier", ""], ["Beguir", "Karim", ""]]}, {"id": "2011.14381", "submitter": "Andrii Zadaianchuk", "authors": "Andrii Zadaianchuk, Maximilian Seitzer, Georg Martius", "title": "Self-supervised Visual Reinforcement Learning with Object-centric\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents need large repertoires of skills to act reasonably on new\ntasks that they have not seen before. However, acquiring these skills using\nonly a stream of high-dimensional, unstructured, and unlabeled observations is\na tricky challenge for any autonomous agent. Previous methods have used\nvariational autoencoders to encode a scene into a low-dimensional vector that\ncan be used as a goal for an agent to discover new skills. Nevertheless, in\ncompositional/multi-object environments it is difficult to disentangle all the\nfactors of variation into such a fixed-length representation of the whole\nscene. We propose to use object-centric representations as a modular and\nstructured observation space, which is learned with a compositional generative\nworld model. We show that the structure in the representations in combination\nwith goal-conditioned attention policies helps the autonomous agent to discover\nand learn useful skills. These skills can be further combined to address\ncompositional tasks like the manipulation of several different objects.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 14:55:09 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zadaianchuk", "Andrii", ""], ["Seitzer", "Maximilian", ""], ["Martius", "Georg", ""]]}, {"id": "2011.14389", "submitter": "Robert Weston Mr", "authors": "Rob Weston, Oiwi Parker Jones and Ingmar Posner", "title": "There and Back Again: Learning to Simulate Radar Data for Real-World\n  Applications", "comments": "6 pages + 2 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulating realistic radar data has the potential to significantly accelerate\nthe development of data-driven approaches to radar processing. However, it is\nfraught with difficulty due to the notoriously complex image formation process.\nHere we propose to learn a radar sensor model capable of synthesising faithful\nradar observations based on simulated elevation maps. In particular, we adopt\nan adversarial approach to learning a forward sensor model from unaligned radar\nexamples. In addition, modelling the backward model encourages the output to\nremain aligned to the world state through a cyclical consistency criterion. The\nbackward model is further constrained to predict elevation maps from real radar\ndata that are grounded by partial measurements obtained from corresponding\nlidar scans. Both models are trained in a joint optimisation. We demonstrate\nthe efficacy of our approach by evaluating a down-stream segmentation model\ntrained purely on simulated data in a real-world deployment. This achieves\nperformance within four percentage points of the same model trained entirely on\nreal data.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 15:49:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Weston", "Rob", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "2011.14393", "submitter": "Jalal Arabneydi", "authors": "Vida Fathi, Jalal Arabneydi and Amir G. Aghdam", "title": "Reinforcement Learning in Linear Quadratic Deep Structured Teams: Global\n  Convergence of Policy Gradient Methods", "comments": "Proceedings of IEEE Conference on Decision and Control, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the global convergence of model-based and model-free\npolicy gradient descent and natural policy gradient descent algorithms for\nlinear quadratic deep structured teams. In such systems, agents are partitioned\ninto a few sub-populations wherein the agents in each sub-population are\ncoupled in the dynamics and cost function through a set of linear regressions\nof the states and actions of all agents. Every agent observes its local state\nand the linear regressions of states, called deep states. For a sufficiently\nsmall risk factor and/or sufficiently large population, we prove that\nmodel-based policy gradient methods globally converge to the optimal solution.\nGiven an arbitrary number of agents, we develop model-free policy gradient and\nnatural policy gradient algorithms for the special case of risk-neutral cost\nfunction. The proposed algorithms are scalable with respect to the number of\nagents due to the fact that the dimension of their policy space is independent\nof the number of agents in each sub-population. Simulations are provided to\nverify the theoretical results.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 16:02:39 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 06:55:09 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Fathi", "Vida", ""], ["Arabneydi", "Jalal", ""], ["Aghdam", "Amir G.", ""]]}, {"id": "2011.14420", "submitter": "Weijun Luo", "authors": "Weijun Luo", "title": "Improving Neural Network with Uniform Sparse Connectivity", "comments": "paper accepted by IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3040943", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network forms the foundation of deep learning and numerous AI\napplications. Classical neural networks are fully connected, expensive to train\nand prone to overfitting. Sparse networks tend to have convoluted structure\nsearch, suboptimal performance and limited usage. We proposed the novel uniform\nsparse network (USN) with even and sparse connectivity within each layer. USN\nhas one striking property that its performance is independent of the\nsubstantial topology variation and enormous model space, thus offers a\nsearch-free solution to all above mentioned issues of neural networks. USN\nconsistently and substantially outperforms the state-of-the-art sparse network\nmodels in prediction accuracy, speed and robustness. It even achieves higher\nprediction accuracy than the fully connected network with only 0.55% parameters\nand 1/4 computing time and resources. Importantly, USN is conceptually simple\nas a natural generalization of fully connected network with multiple\nimprovements in accuracy, robustness and scalability. USN can replace the\nlatter in a range of applications, data types and deep learning architectures.\nWe have made USN open source at https://github.com/datapplab/sparsenet.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 19:00:05 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 19:45:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Luo", "Weijun", ""]]}, {"id": "2011.14421", "submitter": "Maxime Labonne", "authors": "Maxime Labonne, Jorge L\\'opez, Claude Poletti, Jean-Baptiste Munier", "title": "Short-Term Flow-Based Bandwidth Forecasting using Machine Learning", "comments": "4 pages, 1 figure 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel framework to predict traffic flows' bandwidth\nahead of time. Modern network management systems share a common issue: the\nnetwork situation evolves between the moment the decision is made and the\nmoment when actions (countermeasures) are applied. This framework converts\npackets from real-life traffic into flows containing relevant features. Machine\nlearning models, including Decision Tree, Random Forest, XGBoost, and Deep\nNeural Network, are trained on these data to predict the bandwidth at the next\ntime instance for every flow. Predictions can be fed to the management system\ninstead of current flows bandwidth in order to take decisions on a more\naccurate network state. Experiments were performed on 981,774 flows and 15\ndifferent time windows (from 0.03s to 4s). They show that the Random Forest is\nthe best performing and most reliable model, with a predictive performance\nconsistently better than relying on the current bandwidth (+19.73% in mean\nabsolute error and +18.00% in root mean square error). Experimental results\nindicate that this framework can help network management systems to take more\ninformed decisions using a predicted network state.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 19:06:15 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 12:51:24 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Labonne", "Maxime", ""], ["L\u00f3pez", "Jorge", ""], ["Poletti", "Claude", ""], ["Munier", "Jean-Baptiste", ""]]}, {"id": "2011.14427", "submitter": "George Cazenavette V", "authors": "George Cazenavette, Calvin Murdock, Simon Lucey", "title": "Architectural Adversarial Robustness: The Case for Deep Pursuit", "comments": "11 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their unmatched performance, deep neural networks remain susceptible\nto targeted attacks by nearly imperceptible levels of adversarial noise. While\nthe underlying cause of this sensitivity is not well understood, theoretical\nanalyses can be simplified by reframing each layer of a feed-forward network as\nan approximate solution to a sparse coding problem. Iterative solutions using\nbasis pursuit are theoretically more stable and have improved adversarial\nrobustness. However, cascading layer-wise pursuit implementations suffer from\nerror accumulation in deeper networks. In contrast, our new method of deep\npursuit approximates the activations of all layers as a single global\noptimization problem, allowing us to consider deeper, real-world architectures\nwith skip connections such as residual networks. Experimentally, our approach\ndemonstrates improved robustness to adversarial noise.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 19:39:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cazenavette", "George", ""], ["Murdock", "Calvin", ""], ["Lucey", "Simon", ""]]}, {"id": "2011.14430", "submitter": "Tanvir Ahamed", "authors": "Tanvir Ahamed, Bo Zou, Nahid Parvez Farazi and Theja Tulabandhula", "title": "Deep Reinforcement Learning for Crowdsourced Urban Delivery: System\n  States Characterization, Heuristics-guided Action Choice, and\n  Rule-Interposing Integration", "comments": "50 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the problem of assigning shipping requests to ad hoc\ncouriers in the context of crowdsourced urban delivery. The shipping requests\nare spatially distributed each with a limited time window between the earliest\ntime for pickup and latest time for delivery. The ad hoc couriers, termed\ncrowdsourcees, also have limited time availability and carrying capacity. We\npropose a new deep reinforcement learning (DRL)-based approach to tackling this\nassignment problem. A deep Q network (DQN) algorithm is trained which entails\ntwo salient features of experience replay and target network that enhance the\nefficiency, convergence, and stability of DRL training. More importantly, this\npaper makes three methodological contributions: 1) presenting a comprehensive\nand novel characterization of crowdshipping system states that encompasses\nspatial-temporal and capacity information of crowdsourcees and requests; 2)\nembedding heuristics that leverage the information offered by the state\nrepresentation and are based on intuitive reasoning to guide specific actions\nto take, to preserve tractability and enhance efficiency of training; and 3)\nintegrating rule-interposing to prevent repeated visiting of the same routes\nand node sequences during routing improvement, thereby further enhancing the\ntraining efficiency by accelerating learning. The effectiveness of the proposed\napproach is demonstrated through extensive numerical analysis. The results show\nthe benefits brought by the heuristics-guided action choice and\nrule-interposing in DRL training, and the superiority of the proposed approach\nover existing heuristics in both solution quality, time, and scalability.\nBesides the potential to improve the efficiency of crowdshipping operation\nplanning, the proposed approach also provides a new avenue and generic\nframework for other problems in the vehicle routing context.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 19:50:34 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ahamed", "Tanvir", ""], ["Zou", "Bo", ""], ["Farazi", "Nahid Parvez", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "2011.14439", "submitter": "Sam Greydanus", "authors": "Sam Greydanus", "title": "Scaling down Deep Learning", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Though deep learning models have taken on commercial and political relevance,\nmany aspects of their training and operation remain poorly understood. This has\nsparked interest in \"science of deep learning\" projects, many of which are run\nat scale and require enormous amounts of time, money, and electricity. But how\nmuch of this research really needs to occur at scale? In this paper, we\nintroduce MNIST-1D: a minimalist, low-memory, and low-compute alternative to\nclassic deep learning benchmarks. The training examples are 20 times smaller\nthan MNIST examples yet they differentiate more clearly between linear,\nnonlinear, and convolutional models which attain 32, 68, and 94% accuracy\nrespectively (these models obtain 94, 99+, and 99+% on MNIST). Then we present\nexample use cases which include measuring the spatial inductive biases of\nlottery tickets, observing deep double descent, and metalearning an activation\nfunction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 20:08:37 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 22:09:02 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 20:09:44 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Greydanus", "Sam", ""]]}, {"id": "2011.14445", "submitter": "Bj\\\"orn Schuller", "authors": "Gauri Deshpande, Bj\\\"orn W. Schuller", "title": "Audio, Speech, Language, & Signal Processing for COVID-19: A\n  Comprehensive Overview", "comments": "arXiv admin note: text overlap with arXiv:2005.08579", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Coronavirus (COVID-19) pandemic has been the research focus world-wide in\nthe year 2020. Several efforts, from collection of COVID-19 patients' data to\nscreening them for the virus's detection are taken with rigour. A major portion\nof COVID-19 symptoms are related to the functioning of the respiratory system,\nwhich in-turn critically influences the human speech production system. This\ndrives the research focus towards identifying the markers of COVID-19 in speech\nand other human generated audio signals. In this paper, we give an overview of\nthe speech and other audio signal, language and general signal processing-based\nwork done using Artificial Intelligence techniques to screen, diagnose,\nmonitor, and spread the awareness aboutCOVID-19. We also briefly describe the\nresearch related to detect accord-ing COVID-19 symptoms carried out so far. We\naspire that this collective information will be useful in developing automated\nsystems, which can help in the context of COVID-19 using non-obtrusive and easy\nto use modalities such as audio, speech, and language.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 21:33:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Deshpande", "Gauri", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2011.14458", "submitter": "Yichen Zhang", "authors": "Yichen Zhang and Feng Qiu and Tianqi Hong and Zhaoyu Wang and Fangxing\n  Li", "title": "Hybrid Imitation Learning for Real-Time Service Restoration in Resilient\n  Distribution Systems", "comments": null, "journal-ref": null, "doi": "10.1109/TII.2021.3078110", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-healing capability is one of the most critical factors for a resilient\ndistribution system, which requires intelligent agents to automatically perform\nrestorative actions online, including network reconfiguration and reactive\npower dispatch. These agents should be equipped with a predesigned decision\npolicy to meet real-time requirements and handle highly complex $N-k$\nscenarios. The disturbance randomness hampers the application of\nexploration-dominant algorithms like traditional reinforcement learning (RL),\nand the agent training problem under $N-k$ scenarios has not been thoroughly\nsolved. In this paper, we propose the imitation learning (IL) framework to\ntrain such policies, where the agent will interact with an expert to learn its\noptimal policy, and therefore significantly improve the training efficiency\ncompared with the RL methods. To handle tie-line operations and reactive power\ndispatch simultaneously, we design a hybrid policy network for such a\ndiscrete-continuous hybrid action space. We employ the 33-node system under\n$N-k$ disturbances to verify the proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 22:51:05 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 17:06:48 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 16:34:23 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhang", "Yichen", ""], ["Qiu", "Feng", ""], ["Hong", "Tianqi", ""], ["Wang", "Zhaoyu", ""], ["Li", "Fangxing", ""]]}, {"id": "2011.14473", "submitter": "Gabriel Gusm\\~ao S.", "authors": "Gabriel S. Gusm\\~ao, Adhika P. Retnanto, Shashwati C. da Cunha, Andrew\n  J. Medford", "title": "Kinetics-Informed Neural Networks", "comments": "Pre-print for first submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chemical kinetics consists of the phenomenological framework for the\ndisentanglement of reaction mechanisms, optimization of reaction performance\nand the rational design of chemical processes. Here, we utilize feed-forward\nartificial neural networks as basis functions for the construction of surrogate\nmodels to solve ordinary differential equations (ODEs) that describe\nmicrokinetic models (MKMs). We present an algebraic framework for the\nmathematical description and classification of reaction networks, types of\nelementary reaction, and chemical species. Under this framework, we demonstrate\nthat the simultaneous training of neural nets and kinetic model parameters in a\nregularized multiobjective optimization setting leads to the solution of the\ninverse problem through the estimation of kinetic parameters from synthetic\nexperimental data. We probe the limits at which kinetic parameters can be\nretrieved as a function of knowledge about the chemical system states over\ntime, and assess the robustness of the methodology with respect to statistical\nnoise. This surrogate approach to inverse kinetic ODEs can assist in the\nelucidation of reaction mechanisms based on transient data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 00:07:09 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Gusm\u00e3o", "Gabriel S.", ""], ["Retnanto", "Adhika P.", ""], ["da Cunha", "Shashwati C.", ""], ["Medford", "Andrew J.", ""]]}, {"id": "2011.14479", "submitter": "Huaxiong Li", "authors": "Haoxing Chen and Huaxiong Li and Yaohui Li and Chunlin Chen", "title": "Multi-scale Adaptive Task Attention Network for Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of few-shot learning is to classify unseen categories with few\nlabeled samples. Recently, the low-level information metric-learning based\nmethods have achieved satisfying performance, since local representations (LRs)\nare more consistent between seen and unseen classes. However, most of these\nmethods deal with each category in the support set independently, which is not\nsufficient to measure the relation between features, especially in a certain\ntask. Moreover, the low-level information-based metric learning method suffers\nwhen dominant objects of different scales exist in a complex background. To\naddress these issues, this paper proposes a novel Multi-scale Adaptive Task\nAttention Network (MATANet) for few-shot learning. Specifically, we first use a\nmulti-scale feature generator to generate multiple features at different\nscales. Then, an adaptive task attention module is proposed to select the most\nimportant LRs among the entire task. Afterwards, a similarity-to-class module\nand a fusion layer are utilized to calculate a joint multi-scale similarity\nbetween the query image and the support set. Extensive experiments on popular\nbenchmarks clearly show the effectiveness of the proposed MATANet compared with\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 00:36:01 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chen", "Haoxing", ""], ["Li", "Huaxiong", ""], ["Li", "Yaohui", ""], ["Chen", "Chunlin", ""]]}, {"id": "2011.14486", "submitter": "Benoit Steiner", "authors": "Benoit Steiner and Chris Cummins and Horace He and Hugh Leather", "title": "Value Function Based Performance Optimization of Deep Learning Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning techniques become ubiquitous, the efficiency of neural\nnetwork implementations is becoming correspondingly paramount. Frameworks, such\nas Halide and TVM, separate out the algorithmic representation of the network\nfrom the schedule that determines its implementation. Finding good schedules,\nhowever, remains extremely challenging. We model this scheduling problem as a\nsequence of optimization choices, and present a new technique to accurately\npredict the expected performance of a partial schedule. By leveraging these\npredictions we can make these optimization decisions greedily and rapidly\nidentify an efficient schedule. This enables us to find schedules that improve\nthe throughput of deep neural networks by 2.6x over Halide and 1.5x over TVM.\nMoreover, our technique is two to three orders of magnitude faster than that of\nthese tools, and completes in seconds instead of hours.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 01:20:14 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Steiner", "Benoit", ""], ["Cummins", "Chris", ""], ["He", "Horace", ""], ["Leather", "Hugh", ""]]}, {"id": "2011.14495", "submitter": "Marek Petrik", "authors": "Elita A. Lobo, Mohammad Ghavamzadeh, Marek Petrik", "title": "Soft-Robust Algorithms for Batch Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, robust policies for high-stakes decision-making\nproblems with limited data are usually computed by optimizing the percentile\ncriterion, which minimizes the probability of a catastrophic failure.\nUnfortunately, such policies are typically overly conservative as the\npercentile criterion is non-convex, difficult to optimize, and ignores the mean\nperformance. To overcome these shortcomings, we study the soft-robust\ncriterion, which uses risk measures to balance the mean and percentile\ncriterion better. In this paper, we establish the soft-robust criterion's\nfundamental properties, show that it is NP-hard to optimize, and propose and\nanalyze two algorithms to approximately optimize it. Our theoretical analyses\nand empirical evaluations demonstrate that our algorithms compute much less\nconservative solutions than the existing approximate methods for optimizing the\npercentile-criterion.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 01:36:16 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 17:46:32 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Lobo", "Elita A.", ""], ["Ghavamzadeh", "Mohammad", ""], ["Petrik", "Marek", ""]]}, {"id": "2011.14522", "submitter": "Greg Yang", "authors": "Greg Yang, Edward J. Hu", "title": "Feature Learning in Infinite-Width Neural Networks", "comments": "4th paper in the Tensor Programs series. Appearing in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As its width tends to infinity, a deep neural network's behavior under\ngradient descent can become simplified and predictable (e.g. given by the\nNeural Tangent Kernel (NTK)), if it is parametrized appropriately (e.g. the NTK\nparametrization). However, we show that the standard and NTK parametrizations\nof a neural network do not admit infinite-width limits that can learn features,\nwhich is crucial for pretraining and transfer learning such as with BERT. We\npropose simple modifications to the standard parametrization to allow for\nfeature learning in the limit. Using the *Tensor Programs* technique, we derive\nexplicit formulas for such limits. On Word2Vec and few-shot learning on\nOmniglot via MAML, two canonical tasks that rely crucially on feature learning,\nwe compute these limits exactly. We find that they outperform both NTK\nbaselines and finite-width networks, with the latter approaching the\ninfinite-width feature learning performance as width increases.\n  More generally, we classify a natural space of neural network\nparametrizations that generalizes standard, NTK, and Mean Field\nparametrizations. We show 1) any parametrization in this space either admits\nfeature learning or has an infinite-width training dynamics given by kernel\ngradient descent, but not both; 2) any such infinite-width limit can be\ncomputed using the Tensor Programs technique. Code for our experiments can be\nfound at github.com/edwardjhu/TP4.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 03:21:05 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 08:04:47 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Yang", "Greg", ""], ["Hu", "Edward J.", ""]]}, {"id": "2011.14540", "submitter": "Shuhao Cui", "authors": "Shuhao Cui, Xuan Jin, Shuhui Wang, Yuan He, Qingming Huang", "title": "Heuristic Domain Adaptation", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In visual domain adaptation (DA), separating the domain-specific\ncharacteristics from the domain-invariant representations is an ill-posed\nproblem. Existing methods apply different kinds of priors or directly minimize\nthe domain discrepancy to address this problem, which lack flexibility in\nhandling real-world situations. Another research pipeline expresses the\ndomain-specific information as a gradual transferring process, which tends to\nbe suboptimal in accurately removing the domain-specific properties. In this\npaper, we address the modeling of domain-invariant and domain-specific\ninformation from the heuristic search perspective. We identify the\ncharacteristics in the existing representations that lead to larger domain\ndiscrepancy as the heuristic representations. With the guidance of heuristic\nrepresentations, we formulate a principled framework of Heuristic Domain\nAdaptation (HDA) with well-founded theoretical guarantees. To perform HDA, the\ncosine similarity scores and independence measurements between domain-invariant\nand domain-specific representations are cast into the constraints at the\ninitial and final states during the learning procedure. Similar to the final\ncondition of heuristic search, we further derive a constraint enforcing the\nfinal range of heuristic network output to be small. Accordingly, we propose\nHeuristic Domain Adaptation Network (HDAN), which explicitly learns the\ndomain-invariant and domain-specific representations with the above mentioned\nconstraints. Extensive experiments show that HDAN has exceeded state-of-the-art\non unsupervised DA, multi-source DA and semi-supervised DA. The code is\navailable at https://github.com/cuishuhao/HDA.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 04:21:35 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Cui", "Shuhao", ""], ["Jin", "Xuan", ""], ["Wang", "Shuhui", ""], ["He", "Yuan", ""], ["Huang", "Qingming", ""]]}, {"id": "2011.14549", "submitter": "Amin Jalali", "authors": "Amin Jalali", "title": "Persistent Reductions in Regularized Loss Minimization for Variable\n  Selection", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of regularized loss minimization with polyhedral gauges, we\nshow that for a broad class of loss functions (possibly non-smooth and\nnon-convex) and under a simple geometric condition on the input data it is\npossible to efficiently identify a subset of features which are guaranteed to\nhave zero coefficients in all optimal solutions in all problems with loss\nfunctions from said class, before any iterative optimization has been performed\nfor the original problem. This procedure is standalone, takes only the data as\ninput, and does not require any calls to the loss function. Therefore, we term\nthis procedure as a persistent reduction for the aforementioned class of\nregularized loss minimization problems. This reduction can be efficiently\nimplemented via an extreme ray identification subroutine applied to a\npolyhedral cone formed from the datapoints. We employ an existing\noutput-sensitive algorithm for extreme ray identification which makes our\nguarantee and algorithm applicable in ultra-high dimensional problems.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 04:59:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jalali", "Amin", ""]]}, {"id": "2011.14554", "submitter": "Jeong-Hoe Ku", "authors": "Jeong-Hoe Ku, JiHun Oh, YoungYoon Lee, Gaurav Pooniwala, SangJeong Lee", "title": "A Selective Survey on Versatile Knowledge Distillation Paradigm for\n  Neural Network Models", "comments": "15 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to provide a selective survey about knowledge\ndistillation(KD) framework for researchers and practitioners to take advantage\nof it for developing new optimized models in the deep neural network field. To\nthis end, we give a brief overview of knowledge distillation and some related\nworks including learning using privileged information(LUPI) and generalized\ndistillation(GD). Even though knowledge distillation based on the\nteacher-student architecture was initially devised as a model compression\ntechnique, it has found versatile applications over various frameworks.\n  In this paper, we review the characteristics of knowledge distillation from\nthe hypothesis that the three important ingredients of knowledge distillation\nare distilled knowledge and loss,teacher-student paradigm, and the distillation\nprocess. In addition, we survey the versatility of the knowledge distillation\nby studying its direct applications and its usage in combination with other\ndeep learning paradigms. Finally we present some future works in knowledge\ndistillation including explainable knowledge distillation where the analytical\nanalysis of the performance gain is studied and the self-supervised learning\nwhich is a hot research topic in deep learning community.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 05:22:02 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ku", "Jeong-Hoe", ""], ["Oh", "JiHun", ""], ["Lee", "YoungYoon", ""], ["Pooniwala", "Gaurav", ""], ["Lee", "SangJeong", ""]]}, {"id": "2011.14572", "submitter": "Farhad Farokhi", "authors": "Farhad Farokhi", "title": "Gradient Sparsification Can Improve Performance of\n  Differentially-Private Convex Machine Learning", "comments": "Fixed typos and a mistake in the proof of Proposition 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use gradient sparsification to reduce the adverse effect of differential\nprivacy noise on performance of private machine learning models. To this aim,\nwe employ compressed sensing and additive Laplace noise to evaluate\ndifferentially-private gradients. Noisy privacy-preserving gradients are used\nto perform stochastic gradient descent for training machine learning models.\nSparsification, achieved by setting the smallest gradient entries to zero, can\nreduce the convergence speed of the training algorithm. However, by\nsparsification and compressed sensing, the dimension of communicated gradient\nand the magnitude of additive noise can be reduced. The interplay between these\neffects determines whether gradient sparsification improves the performance of\ndifferentially-private machine learning models. We investigate this\nanalytically in the paper. We prove that, for small privacy budgets,\ncompression can improve performance of privacy-preserving machine learning\nmodels. However, for large privacy budgets, compression does not necessarily\nimprove the performance. Intuitively, this is because the effect of\nprivacy-preserving noise is minimal in large privacy budget regime and thus\nimprovements from gradient sparsification cannot compensate for its slower\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 06:37:06 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 23:54:09 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Farokhi", "Farhad", ""]]}, {"id": "2011.14578", "submitter": "Stone Yun", "authors": "Stone Yun and Alexander Wong", "title": "Where Should We Begin? A Low-Level Exploration of Weight Initialization\n  Impact on Quantized Behaviour of Deep Neural Networks", "comments": "Accepted for publication at the 6th Annual Conference on Computer\n  Vision and Intelligent Systems (CVIS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the proliferation of deep convolutional neural network (CNN) algorithms\nfor mobile processing, limited precision quantization has become an essential\ntool for CNN efficiency. Consequently, various works have sought to design\nfixed precision quantization algorithms and quantization-focused optimization\ntechniques that minimize quantization induced performance degradation. However,\nthere is little concrete understanding of how various CNN design decisions/best\npractices affect quantized inference behaviour. Weight initialization\nstrategies are often associated with solving issues such as vanishing/exploding\ngradients but an often-overlooked aspect is their impact on the final trained\ndistributions of each layer. We present an in-depth, fine-grained ablation\nstudy of the effect of different weights initializations on the final\ndistributions of weights and activations of different CNN architectures. The\nfine-grained, layerwise analysis enables us to gain deep insights on how\ninitial weights distributions will affect final accuracy and quantized\nbehaviour. To our best knowledge, we are the first to perform such a low-level,\nin-depth quantitative analysis of weights initialization and its effect on\nquantized behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 06:54:28 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yun", "Stone", ""], ["Wong", "Alexander", ""]]}, {"id": "2011.14580", "submitter": "Thao Nguyen", "authors": "Badih Ghazi, Ravi Kumar, Pasin Manurangsi, Thao Nguyen", "title": "Robust and Private Learning of Halfspaces", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the trade-off between differential privacy and\nadversarial robustness under L2-perturbations in the context of learning\nhalfspaces. We prove nearly tight bounds on the sample complexity of robust\nprivate learning of halfspaces for a large regime of parameters. A highlight of\nour results is that robust and private learning is harder than robust or\nprivate learning alone. We complement our theoretical analysis with\nexperimental results on the MNIST and USPS datasets, for a learning algorithm\nthat is both differentially private and adversarially robust.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 06:59:20 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 23:20:21 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Ghazi", "Badih", ""], ["Kumar", "Ravi", ""], ["Manurangsi", "Pasin", ""], ["Nguyen", "Thao", ""]]}, {"id": "2011.14585", "submitter": "Jaehui Hwang", "authors": "Jaehui Hwang, Jun-Hyuk Kim, Jun-Ho Choi, and Jong-Seok Lee", "title": "Just One Moment: Inconspicuous One Frame Attack on Deep Action\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The video-based action recognition task has been extensively studied in\nrecent years. In this paper, we study the vulnerability of deep learning-based\naction recognition methods against the adversarial attack using a new one frame\nattack that adds an inconspicuous perturbation to only a single frame of a\ngiven video clip. We investigate the effectiveness of our one frame attack on\nstate-of-the-art action recognition models, along with thorough analysis of the\nvulnerability in terms of their model structure and perceivability of the\nperturbation. Our method shows high fooling rates and produces hardly\nperceivable perturbation to human observers, which is evaluated by a subjective\ntest. In addition, we present a video-agnostic approach that finds a universal\nperturbation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 07:11:56 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Hwang", "Jaehui", ""], ["Kim", "Jun-Hyuk", ""], ["Choi", "Jun-Ho", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "2011.14586", "submitter": "Stone Yun", "authors": "Stone Yun and Alexander Wong", "title": "FactorizeNet: Progressive Depth Factorization for Efficient Network\n  Architecture Exploration Under Quantization Constraints", "comments": "Accepted for Publication at the 2020 Workshop on Energy Efficient\n  Machine Learning and Cognitive Computing (EMC2 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depth factorization and quantization have emerged as two of the principal\nstrategies for designing efficient deep convolutional neural network (CNN)\narchitectures tailored for low-power inference on the edge. However, there is\nstill little detailed understanding of how different depth factorization\nchoices affect the final, trained distributions of each layer in a CNN,\nparticularly in the situation of quantized weights and activations. In this\nstudy, we introduce a progressive depth factorization strategy for efficient\nCNN architecture exploration under quantization constraints. By algorithmically\nincreasing the granularity of depth factorization in a progressive manner, the\nproposed strategy enables a fine-grained, low-level analysis of layer-wise\ndistributions. Thus enabling the gain of in-depth, layer-level insights on\nefficiency-accuracy tradeoffs under fixed-precision quantization. Such a\nprogressive depth factorization strategy also enables efficient identification\nof the optimal depth-factorized macroarchitecture design (which we will refer\nto here as FactorizeNet) based on the desired efficiency-accuracy requirements.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 07:12:26 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yun", "Stone", ""], ["Wong", "Alexander", ""]]}, {"id": "2011.14593", "submitter": "Christina Baek", "authors": "Ziyang Wu, Christina Baek, Chong You, Yi Ma", "title": "Incremental Learning via Rate Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning architectures suffer from catastrophic forgetting, a\nfailure to retain knowledge of previously learned classes when incrementally\ntrained on new classes. The fundamental roadblock faced by deep learning\nmethods is that deep learning models are optimized as \"black boxes,\" making it\ndifficult to properly adjust the model parameters to preserve knowledge about\npreviously seen data. To overcome the problem of catastrophic forgetting, we\npropose utilizing an alternative \"white box\" architecture derived from the\nprinciple of rate reduction, where each layer of the network is explicitly\ncomputed without back propagation. Under this paradigm, we demonstrate that,\ngiven a pre-trained network and new data classes, our approach can provably\nconstruct a new network that emulates joint training with all past and new\nclasses. Finally, our experiments show that our proposed learning algorithm\nobserves significantly less decay in classification performance, outperforming\nstate of the art methods on MNIST and CIFAR-10 by a large margin and justifying\nthe use of \"white box\" algorithms for incremental learning even for\nsufficiently complex image data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 07:23:55 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wu", "Ziyang", ""], ["Baek", "Christina", ""], ["You", "Chong", ""], ["Ma", "Yi", ""]]}, {"id": "2011.14603", "submitter": "Sandesh Ramesh", "authors": "Sandesh Ramesh, Manoj Kumar M V, and K Aditya Shastry", "title": "REaL: Real-time Face Detection and Recognition Using Euclidean Space and\n  Likelihood Estimation", "comments": "International Journal of System Assurance Engineering and Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Detecting and recognizing faces accurately has always been a challenge.\nDifferentiating facial features, training images, and producing quick results\nrequire a lot of computation. The REaL system we have proposed in this paper\ndiscusses its functioning and ways in which computations can be carried out in\na short period. REaL experiments are carried out on live images and the\nrecognition rates are promising. The system is also successful in removing\nnon-human objects from its calculations. The system uses a local database to\nstore captured images and feeds the neural network frequently. The captured\nimages are cropped automatically to remove unwanted noise. The system\ncalculates the Euler angles and the probability of whether the face is smiling,\nhas its left eye, and right eyes open or not.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 08:03:04 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ramesh", "Sandesh", ""], ["M", "Manoj Kumar", "V"], ["Shastry", "K Aditya", ""]]}, {"id": "2011.14615", "submitter": "Qi Yang", "authors": "Aleksandr Farseev, Qi Yang, Andrey Filchenkov, Kirill Lepikhin, Yu-Yi\n  Chu-Farseeva, Daron-Benjamin Loo", "title": "SoMin.ai: Personality-Driven Content Generation Platform", "comments": "WSDM 2021 - Demonstration", "journal-ref": null, "doi": "10.1145/3437963.3441714", "report-no": null, "categories": "cs.MM cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical demonstration, we showcase the World's first\npersonality-driven marketing content generation platform, called SoMin.ai. The\nplatform combines deep multi-view personality profiling framework and style\ngenerative adversarial networks facilitating the automatic creation of content\nthat appeals to different human personality types. The platform can be used for\nthe enhancement of the social networking user experience as well as for content\nmarketing routines. Guided by the MBTI personality type, automatically derived\nfrom a user social network content, SoMin.ai generates new social media content\nbased on the preferences of other users with a similar personality type aiming\nat enhancing the user experience on social networking venues as well\ndiversifying the efforts of marketers when crafting new content for digital\nmarketing campaigns. The real-time user feedback to the platform via the\nplatform's GUI fine-tunes the content generation model and the evaluation\nresults demonstrate the promising performance of the proposed multi-view\npersonality profiling framework when being applied in the content generation\nscenario. By leveraging content generation at a large scale, marketers will be\nable to execute more effective digital marketing campaigns at a lower cost.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 08:33:39 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 11:39:23 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Farseev", "Aleksandr", ""], ["Yang", "Qi", ""], ["Filchenkov", "Andrey", ""], ["Lepikhin", "Kirill", ""], ["Chu-Farseeva", "Yu-Yi", ""], ["Loo", "Daron-Benjamin", ""]]}, {"id": "2011.14620", "submitter": "Przemys{\\l}aw Spurek", "authors": "Maciej Zi\\k{e}ba, Marcin Przewi\\k{e}\\'zlikowski, Marek \\'Smieja, Jacek\n  Tabor, Tomasz Trzcinski, Przemys{\\l}aw Spurek", "title": "RegFlow: Probabilistic Flow-based Regression for Future Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting future states or actions of a given system remains a fundamental,\nyet unsolved challenge of intelligence, especially in the scope of complex and\nnon-deterministic scenarios, such as modeling behavior of humans. Existing\napproaches provide results under strong assumptions concerning unimodality of\nfuture states, or, at best, assuming specific probability distributions that\noften poorly fit to real-life conditions. In this work we introduce a robust\nand flexible probabilistic framework that allows to model future predictions\nwith virtually no constrains regarding the modality or underlying probability\ndistribution. To achieve this goal, we leverage a hypernetwork architecture and\ntrain a continuous normalizing flow model. The resulting method dubbed RegFlow\nachieves state-of-the-art results on several benchmark datasets, outperforming\ncompeting approaches by a significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 08:45:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zi\u0119ba", "Maciej", ""], ["Przewi\u0119\u017alikowski", "Marcin", ""], ["\u015amieja", "Marek", ""], ["Tabor", "Jacek", ""], ["Trzcinski", "Tomasz", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "2011.14632", "submitter": "Ilya Trofimov", "authors": "N. Mazyavkina, S. Moustafa, I. Trofimov, E. Burnaev", "title": "Optimizing the Neural Architecture of Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) enjoyed significant progress over the last years.\nOne of the most important steps forward was the wide application of neural\nnetworks. However, architectures of these neural networks are typically\nconstructed manually. In this work, we study recently proposed neural\narchitecture search (NAS) methods for optimizing the architecture of RL agents.\nWe carry out experiments on the Atari benchmark and conclude that modern NAS\nmethods find architectures of RL agents outperforming a manually selected one.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:18:05 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 13:25:20 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 10:21:47 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Mazyavkina", "N.", ""], ["Moustafa", "S.", ""], ["Trofimov", "I.", ""], ["Burnaev", "E.", ""]]}, {"id": "2011.14638", "submitter": "Xu Chen", "authors": "Xu Chen, Yuanxing Zhang, Lun Du, Zheng Fang, Yi Ren, Kaigui Bian,\n  Kunqing Xie", "title": "TSSRGCN: Temporal Spectral Spatial Retrieval Graph Convolutional Network\n  for Traffic Flow Forecasting", "comments": "Published as a conference paper at ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow forecasting is of great significance for improving the\nefficiency of transportation systems and preventing emergencies. Due to the\nhighly non-linearity and intricate evolutionary patterns of short-term and\nlong-term traffic flow, existing methods often fail to take full advantage of\nspatial-temporal information, especially the various temporal patterns with\ndifferent period shifting and the characteristics of road segments. Besides,\nthe globality representing the absolute value of traffic status indicators and\nthe locality representing the relative value have not been considered\nsimultaneously. This paper proposes a neural network model that focuses on the\nglobality and locality of traffic networks as well as the temporal patterns of\ntraffic data. The cycle-based dilated deformable convolution block is designed\nto capture different time-varying trends on each node accurately. Our model can\nextract both global and local spatial information since we combine two graph\nconvolutional network methods to learn the representations of nodes and edges.\nExperiments on two real-world datasets show that the model can scrutinize the\nspatial-temporal correlation of traffic data, and its performance is better\nthan the compared state-of-the-art methods. Further analysis indicates that the\nlocality and globality of the traffic networks are critical to traffic flow\nprediction and the proposed TSSRGCN model can adapt to the various temporal\ntraffic patterns.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:21:43 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chen", "Xu", ""], ["Zhang", "Yuanxing", ""], ["Du", "Lun", ""], ["Fang", "Zheng", ""], ["Ren", "Yi", ""], ["Bian", "Kaigui", ""], ["Xie", "Kunqing", ""]]}, {"id": "2011.14645", "submitter": "Deepak Maurya Mr", "authors": "Deepak Maurya, Arun K. Tangirala and Shankar Narasimhan", "title": "Identification of Errors-in-Variables ARX Models Using Modified Dynamic\n  Iterative PCA", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identification of autoregressive models with exogenous input (ARX) is a\nclassical problem in system identification. This article considers the\nerrors-in-variables (EIV) ARX model identification problem, where input\nmeasurements are also corrupted with noise. The recently proposed DIPCA\ntechnique solves the EIV identification problem but is only applicable to white\nmeasurement errors. We propose a novel identification algorithm based on a\nmodified Dynamic Iterative Principal Components Analysis (DIPCA) approach for\nidentifying the EIV-ARX model for single-input, single-output (SISO) systems\nwhere the output measurements are corrupted with coloured noise consistent with\nthe ARX model. Most of the existing methods assume important parameters like\ninput-output orders, delay, or noise-variances to be known. This work's novelty\nlies in the joint estimation of error variances, process order, delay, and\nmodel parameters. The central idea used to obtain all these parameters in a\ntheoretically rigorous manner is based on transforming the lagged measurements\nusing the appropriate error covariance matrix, which is obtained using\nestimated error variances and model parameters. Simulation studies on two\nsystems are presented to demonstrate the efficacy of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:35:02 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Maurya", "Deepak", ""], ["Tangirala", "Arun K.", ""], ["Narasimhan", "Shankar", ""]]}, {"id": "2011.14646", "submitter": "Ivan Stelmakh", "authors": "Ivan Stelmakh, Nihar B. Shah, Aarti Singh, and Hal Daum\\'e III", "title": "Prior and Prejudice: The Novice Reviewers' Bias against Resubmissions in\n  Conference Peer Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning and computer science conferences are experiencing a\nsurge in the number of submissions that challenges the quality of peer review\nas the number of competent reviewers is growing at a much slower rate. To curb\nthis trend and reduce the burden on reviewers, several conferences have started\nencouraging or even requiring authors to declare the previous submission\nhistory of their papers. Such initiatives have been met with skepticism among\nauthors, who raise the concern about a potential bias in reviewers'\nrecommendations induced by this information. In this work, we investigate\nwhether reviewers exhibit a bias caused by the knowledge that the submission\nunder review was previously rejected at a similar venue, focusing on a\npopulation of novice reviewers who constitute a large fraction of the reviewer\npool in leading machine learning and computer science conferences. We design\nand conduct a randomized controlled trial closely replicating the relevant\ncomponents of the peer-review pipeline with $133$ reviewers (master's, junior\nPhD students, and recent graduates of top US universities) writing reviews for\n$19$ papers. The analysis reveals that reviewers indeed become negatively\nbiased when they receive a signal about paper being a resubmission, giving\nalmost 1 point lower overall score on a 10-point Likert item ($\\Delta = -0.78,\n\\ 95\\% \\ \\text{CI} = [-1.30, -0.24]$) than reviewers who do not receive such a\nsignal. Looking at specific criteria scores (originality, quality, clarity and\nsignificance), we observe that novice reviewers tend to underrate quality the\nmost.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:35:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Stelmakh", "Ivan", ""], ["Shah", "Nihar B.", ""], ["Singh", "Aarti", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "2011.14651", "submitter": "Ying-Jer Kao", "authors": "Samuel Yen-Chi Chen, Chih-Min Huang, Chia-Wei Hsing and Ying-Jer Kao", "title": "Hybrid quantum-classical classifier based on tensor network and\n  variational quantum circuit", "comments": "8 pages, 7 figures, and 1 table. Proceeding for the First Workshop on\n  Quantum Tensor Networks in Machine Learning, 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One key step in performing quantum machine learning (QML) on noisy\nintermediate-scale quantum (NISQ) devices is the dimension reduction of the\ninput data prior to their encoding. Traditional principle component analysis\n(PCA) and neural networks have been used to perform this task; however, the\nclassical and quantum layers are usually trained separately. A framework that\nallows for a better integration of the two key components is thus highly\ndesirable. Here we introduce a hybrid model combining the quantum-inspired\ntensor networks (TN) and the variational quantum circuits (VQC) to perform\nsupervised learning tasks, which allows for an end-to-end training. We show\nthat a matrix product state based TN with low bond dimensions performs better\nthan PCA as a feature extractor to compress data for the input of VQCs in the\nbinary classification of MNIST dataset. The architecture is highly adaptable\nand can easily incorporate extra quantum resource when available.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:43:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Chen", "Samuel Yen-Chi", ""], ["Huang", "Chih-Min", ""], ["Hsing", "Chia-Wei", ""], ["Kao", "Ying-Jer", ""]]}, {"id": "2011.14654", "submitter": "Haiwen Huang", "authors": "Haiwen Huang, Zhihan Li, Lulu Wang, Sishuo Chen, Bin Dong, Xinyu Zhou", "title": "Feature Space Singularity for Out-of-Distribution Detection", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-Distribution (OoD) detection is important for building safe artificial\nintelligence systems. However, current OoD detection methods still cannot meet\nthe performance requirements for practical deployment. In this paper, we\npropose a simple yet effective algorithm based on a novel observation: in a\ntrained neural network, OoD samples with bounded norms well concentrate in the\nfeature space. We call the center of OoD features the Feature Space Singularity\n(FSS), and denote the distance of a sample feature to FSS as FSSD. Then, OoD\nsamples can be identified by taking a threshold on the FSSD. Our analysis of\nthe phenomenon reveals why our algorithm works. We demonstrate that our\nalgorithm achieves state-of-the-art performance on various OoD detection\nbenchmarks. Besides, FSSD also enjoys robustness to slight corruption in test\ndata and can be further enhanced by ensembling. These make FSSD a promising\nalgorithm to be employed in real world. We release our code at\n\\url{https://github.com/megvii-research/FSSD_OoD_Detection}.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 09:47:20 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 19:56:16 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Huang", "Haiwen", ""], ["Li", "Zhihan", ""], ["Wang", "Lulu", ""], ["Chen", "Sishuo", ""], ["Dong", "Bin", ""], ["Zhou", "Xinyu", ""]]}, {"id": "2011.14661", "submitter": "Yusuke Kawamoto", "authors": "Seira Hidano, Takao Murakami, Yusuke Kawamoto", "title": "TransMIA: Membership Inference Attacks Using Transfer Shadow Training", "comments": "IJCNN 2021 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Transfer learning has been widely studied and gained increasing popularity to\nimprove the accuracy of machine learning models by transferring some knowledge\nacquired in different training. However, no prior work has pointed out that\ntransfer learning can strengthen privacy attacks on machine learning models. In\nthis paper, we propose TransMIA (Transfer learning-based Membership Inference\nAttacks), which use transfer learning to perform membership inference attacks\non the source model when the adversary is able to access the parameters of the\ntransferred model. In particular, we propose a transfer shadow training\ntechnique, where an adversary employs the parameters of the transferred model\nto construct shadow models, to significantly improve the performance of\nmembership inference when a limited amount of shadow training data is available\nto the adversary. We evaluate our attacks using two real datasets, and show\nthat our attacks outperform the state-of-the-art that does not use our transfer\nshadow training technique. We also compare four combinations of the\nlearning-based/entropy-based approach and the fine-tuning/freezing approach,\nall of which employ our transfer shadow training technique. Then we examine the\nperformance of these four approaches based on the distributions of confidence\nvalues, and discuss possible countermeasures against our attacks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 10:03:43 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 13:20:40 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 14:50:44 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Hidano", "Seira", ""], ["Murakami", "Takao", ""], ["Kawamoto", "Yusuke", ""]]}, {"id": "2011.14684", "submitter": "Francesco Salvetti", "authors": "Simone Angarano, Vittorio Mazzia, Francesco Salvetti, Giovanni Fantin\n  and Marcello Chiaberge", "title": "Robust Ultra-wideband Range Error Mitigation with Deep Learning at the\n  Edge", "comments": "Submitted to Engineering Applications of Artificial Intelligence", "journal-ref": "Engineering Applications of Artificial Intelligence, Volume 102,\n  June 2021, 104278", "doi": "10.1016/j.engappai.2021.104278", "report-no": null, "categories": "cs.LG cs.AI cs.RO eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ultra-wideband (UWB) is the state-of-the-art and most popular technology for\nwireless localization. Nevertheless, precise ranging and localization in\nnon-line-of-sight (NLoS) conditions is still an open research topic. Indeed,\nmultipath effects, reflections, refractions, and complexity of the indoor radio\nenvironment can easily introduce a positive bias in the ranging measurement,\nresulting in highly inaccurate and unsatisfactory position estimation. This\narticle proposes an efficient representation learning methodology that exploits\nthe latest advancement in deep learning and graph optimization techniques to\nachieve effective ranging error mitigation at the edge. Channel Impulse\nResponse (CIR) signals are directly exploited to extract high semantic features\nto estimate corrections in either NLoS or LoS conditions. Extensive\nexperimentation with different settings and configurations has proved the\neffectiveness of our methodology and demonstrated the feasibility of a robust\nand low computational power UWB range error mitigation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 10:52:21 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 09:16:00 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Angarano", "Simone", ""], ["Mazzia", "Vittorio", ""], ["Salvetti", "Francesco", ""], ["Fantin", "Giovanni", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2011.14688", "submitter": "Nina Otter", "authors": "Guido Mont\\'ufar, Nina Otter, Yuguang Wang", "title": "Can neural networks learn persistent homology features?", "comments": "Topological Data Analysis and Beyond Workshop at the 34th Conference\n  on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topological data analysis uses tools from topology -- the mathematical area\nthat studies shapes -- to create representations of data. In particular, in\npersistent homology, one studies one-parameter families of spaces associated\nwith data, and persistence diagrams describe the lifetime of topological\ninvariants, such as connected components or holes, across the one-parameter\nfamily. In many applications, one is interested in working with features\nassociated with persistence diagrams rather than the diagrams themselves. In\nour work, we explore the possibility of learning several types of features\nextracted from persistence diagrams using neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 10:58:53 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Mont\u00fafar", "Guido", ""], ["Otter", "Nina", ""], ["Wang", "Yuguang", ""]]}, {"id": "2011.14691", "submitter": "Avishree Khare", "authors": "Het Shah, Avishree Khare, Neelay Shah, Khizir Siddiqui", "title": "KD-Lib: A PyTorch library for Knowledge Distillation, Pruning and\n  Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the growing size of neural networks has led to a vast amount\nof research concerning compression techniques to mitigate the drawbacks of such\nlarge sizes. Most of these research works can be categorized into three broad\nfamilies : Knowledge Distillation, Pruning, and Quantization. While there has\nbeen steady research in this domain, adoption and commercial usage of the\nproposed techniques has not quite progressed at the rate. We present KD-Lib, an\nopen-source PyTorch based library, which contains state-of-the-art modular\nimplementations of algorithms from the three families on top of multiple\nabstraction layers. KD-Lib is model and algorithm-agnostic, with extended\nsupport for hyperparameter tuning using Optuna and Tensorboard for logging and\nmonitoring. The library can be found at - https://github.com/SforAiDl/KD_Lib.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 11:11:22 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shah", "Het", ""], ["Khare", "Avishree", ""], ["Shah", "Neelay", ""], ["Siddiqui", "Khizir", ""]]}, {"id": "2011.14694", "submitter": "Muhammad Saif-ur-Rehman", "authors": "Omair Ali, Muhammad Saif-ur-Rehman, Susanne Dyck, Tobias Glasmachers,\n  Ioannis Iossifidis and Christian Klaes", "title": "Improving the performance of EEG decoding using anchored-STFT in\n  conjunction with gradient norm adversarial augmentation", "comments": "42 pages, 19 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brain-computer interfaces (BCIs) enable direct communication between humans\nand machines by translating brain activity into control commands. EEG is one of\nthe most common sources of neural signals because of its inexpensive and\nnon-invasive nature. However, interpretation of EEG signals is non-trivial\nbecause EEG signals have a low spatial resolution and are often distorted with\nnoise and artifacts. Therefore, it is possible that meaningful patterns for\nclassifying EEG signals are deeply hidden. Nowadays, state-of-the-art\ndeep-learning algorithms have proven to be quite efficient in learning hidden,\nmeaningful patterns. However, the performance of the deep learning algorithms\ndepends upon the quality and the amount of the provided training data. Hence, a\nbetter input formation (feature extraction) technique and a generative model to\nproduce high-quality data can enable the deep learning algorithms to adapt high\ngeneralization quality. In this study, we proposed a novel input formation\n(feature extraction) method in conjunction with a novel deep learning based\ngenerative model to harness new training examples. The feature vectors are\nextracted using a modified Short Time Fourier Transform (STFT) called\nanchored-STFT. Anchored-STFT, inspired by wavelet transform, tries to minimize\nthe tradeoff between time and frequency resolution. As a result, it extracts\nthe inputs (feature vectors) with better time and frequency resolution compared\nto the standard STFT. Secondly, we introduced a novel generative adversarial\ndata augmentation technique called gradient norm adversarial augmentation\n(GNAA) for generating more training data. Thirdly, we investigated the\nexistence and significance of adversarial inputs in EEG data. Our approach\nobtained the kappa value of 0.814 for BCI competition II dataset III and 0.755\nfor BCI competition IV dataset 2b for session-to-session transfer on test data.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 11:18:06 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 15:30:24 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 09:57:18 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Ali", "Omair", ""], ["Saif-ur-Rehman", "Muhammad", ""], ["Dyck", "Susanne", ""], ["Glasmachers", "Tobias", ""], ["Iossifidis", "Ioannis", ""], ["Klaes", "Christian", ""]]}, {"id": "2011.14696", "submitter": "Akshay L Chandra", "authors": "Akshay L Chandra, Sai Vikas Desai, Chaitanya Devaguptapu, Vineeth N\n  Balasubramanian", "title": "On Initial Pools for Deep Active Learning", "comments": "Accepted at NeurIPS 2020 Preregistration Workshop and included in\n  PMLR v148. 19 pages, 9 figures", "journal-ref": "Proceedings of Machine Learning Research. 148 (2021) 14-32", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active Learning (AL) techniques aim to minimize the training data required to\ntrain a model for a given task. Pool-based AL techniques start with a small\ninitial labeled pool and then iteratively pick batches of the most informative\nsamples for labeling. Generally, the initial pool is sampled randomly and\nlabeled to seed the AL iterations. While recent studies have focused on\nevaluating the robustness of various query functions in AL, little to no\nattention has been given to the design of the initial labeled pool for deep\nactive learning. Given the recent successes of learning representations in\nself-supervised/unsupervised ways, we study if an intelligently sampled initial\nlabeled pool can improve deep AL performance. We investigate the effect of\nintelligently sampled initial labeled pools, including the use of\nself-supervised and unsupervised strategies, on deep AL methods. The setup,\nhypotheses, methodology, and implementation details were evaluated by peer\nreview before experiments were conducted. Experimental results could not\nconclusively prove that intelligently sampled initial pools are better for AL\nthan random initial pools in the long run, although a Variational\nAutoencoder-based initial pool sampling strategy showed interesting trends that\nmerit deeper investigation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 11:22:31 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 11:14:09 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Chandra", "Akshay L", ""], ["Desai", "Sai Vikas", ""], ["Devaguptapu", "Chaitanya", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2011.14700", "submitter": "Dat Nguyen Thanh", "authors": "Dat Thanh Nguyen, Maurice Quach, Giuseppe Valenzise, Pierre Duhamel", "title": "Learning-based lossless compression of 3D point cloud geometry", "comments": "5 pages, accepted paper at ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a learning-based, lossless compression method for static\npoint cloud geometry, based on context-adaptive arithmetic coding. Unlike most\nexisting methods working in the octree domain, our encoder operates in a hybrid\nmode, mixing octree and voxel-based coding. We adaptively partition the point\ncloud into multi-resolution voxel blocks according to the point cloud\nstructure, and use octree to signal the partitioning. On the one hand, octree\nrepresentation can eliminate the sparsity in the point cloud. On the other\nhand, in the voxel domain, convolutions can be naturally expressed, and\ngeometric information (i.e., planes, surfaces, etc.) is explicitly processed by\na neural network. Our context model benefits from these properties and learns a\nprobability distribution of the voxels using a deep convolutional neural\nnetwork with masked filters, called VoxelDNN. Experiments show that our method\noutperforms the state-of-the-art MPEG G-PCC standard with average rate savings\nof 28% on a diverse set of point clouds from the Microsoft Voxelized Upper\nBodies (MVUB) and MPEG. The implementation is available at\nhttps://github.com/Weafre/VoxelDNN.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 11:27:16 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 09:29:28 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Nguyen", "Dat Thanh", ""], ["Quach", "Maurice", ""], ["Valenzise", "Giuseppe", ""], ["Duhamel", "Pierre", ""]]}, {"id": "2011.14711", "submitter": "Bhaskar Chaudhury", "authors": "Vishrut Jetly and Bhaskar Chaudhury", "title": "Extracting Electron Scattering Cross Sections from Swarm Data using Deep\n  Neural Networks", "comments": null, "journal-ref": "Machine Learning: Science and Technology, 2021", "doi": "10.1088/2632-2153/abf15a", "report-no": null, "categories": "physics.plasm-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electron-neutral scattering cross sections are fundamental quantities in\nsimulations of low temperature plasmas used for many technological applications\ntoday. From these microscopic cross sections, several macro-scale quantities\n(called \"swarm\" parameters) can be calculated. However, measurements as well as\ntheoretical calculations of cross sections are challenging. Since the 1960s\nresearchers have attempted to solve the inverse swarm problem of obtaining\ncross sections from swarm data; but the solutions are not necessarily unique.\nTo address this issues, we examine the use of deep learning models which are\ntrained using the previous determinations of elastic momentum transfer,\nionization and excitation cross sections for different gases available on the\nLXCat website and their corresponding swarm parameters calculated using the\nBOLSIG+ solver for the numerical solution of the Boltzmann equation for\nelectrons in weakly ionized gases. We implement artificial neural network\n(ANN), convolutional neural network (CNN) and densely connected convolutional\nnetwork (DenseNet) for this investigation. To the best of our knowledge, there\nis no study exploring the use of CNN and DenseNet for the inverse swarm\nproblem. We test the validity of predictions by all these trained networks for\na broad range of gas species and we deduce that DenseNet effectively extracts\nboth long and short term features from the swarm data and hence, it predicts\ncross sections with significantly higher accuracy compared to ANN. Further, we\napply Monte Carlo dropout as Bayesian approximation to estimate the probability\ndistribution of the cross sections to determine all plausible solutions of this\ninverse problem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 11:48:15 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Jetly", "Vishrut", ""], ["Chaudhury", "Bhaskar", ""]]}, {"id": "2011.14721", "submitter": "Veronica Alvarez", "authors": "Ver\\'onica \\'Alvarez, Santiago Mazuelas, and Jos\\'e A. Lozano", "title": "Probabilistic Load Forecasting Based on Adaptive Online Learning", "comments": "\\c{opyright} 2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": "10.1109/TPWRS.2021.3050837", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Load forecasting is crucial for multiple energy management tasks such as\nscheduling generation capacity, planning supply and demand, and minimizing\nenergy trade costs. Such relevance has increased even more in recent years due\nto the integration of renewable energies, electric cars, and microgrids.\nConventional load forecasting techniques obtain single-value load forecasts by\nexploiting consumption patterns of past load demand. However, such techniques\ncannot assess intrinsic uncertainties in load demand, and cannot capture\ndynamic changes in consumption patterns. To address these problems, this paper\npresents a method for probabilistic load forecasting based on the adaptive\nonline learning of hidden Markov models. We propose learning and forecasting\ntechniques with theoretical guarantees, and experimentally assess their\nperformance in multiple scenarios. In particular, we develop adaptive online\nlearning techniques that update model parameters recursively, and sequential\nprediction techniques that obtain probabilistic forecasts using the most recent\nparameters. The performance of the method is evaluated using multiple datasets\ncorresponding with regions that have different sizes and display assorted\ntime-varying consumption patterns. The results show that the proposed method\ncan significantly improve the performance of existing techniques for a wide\nrange of scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 12:02:26 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 15:40:39 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 09:57:28 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["\u00c1lvarez", "Ver\u00f3nica", ""], ["Mazuelas", "Santiago", ""], ["Lozano", "Jos\u00e9 A.", ""]]}, {"id": "2011.14723", "submitter": "Dvir Ginzburg", "authors": "Dvir Ginzburg and Dan Raviv", "title": "Dual Geometric Graph Network (DG2N) -- Iterative network for deformable\n  shape alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel new approach for aligning geometric models using a dual\ngraph structure where local features are mapping probabilities. Alignment of\nnon-rigid structures is one of the most challenging computer vision tasks due\nto the high number of unknowns needed to model the correspondence. We have seen\na leap forward using DNN models in template alignment and functional maps, but\nthose methods fail for inter-class alignment where nonisometric deformations\nexist. Here we propose to rethink this task and use unrolling concepts on a\ndual graph structure - one for a forward map and one for a backward map, where\nthe features are pulled back matching probabilities from the target into the\nsource. We report state of the art results on stretchable domains alignment in\na rapid and stable solution for meshes and cloud of points.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 12:03:28 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 06:23:32 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ginzburg", "Dvir", ""], ["Raviv", "Dan", ""]]}, {"id": "2011.14733", "submitter": "Farzan Shenavarmasouleh", "authors": "Farzan Shenavarmasouleh, Farid Ghareh Mohammadi, M. Hadi Amini, Hamid\n  R. Arabnia", "title": "DRDr II: Detecting the Severity Level of Diabetic Retinopathy Using Mask\n  RCNN and Transfer Learning", "comments": "The 2020 International Conference on Computational Science and\n  Computational Intelligence (CSCI'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DRDr II is a hybrid of machine learning and deep learning worlds. It builds\non the successes of its antecedent, namely, DRDr, that was trained to detect,\nlocate, and create segmentation masks for two types of lesions (exudates and\nmicroaneurysms) that can be found in the eyes of the Diabetic Retinopathy (DR)\npatients; and uses the entire model as a solid feature extractor in the core of\nits pipeline to detect the severity level of the DR cases. We employ a big\ndataset with over 35 thousand fundus images collected from around the globe and\nafter 2 phases of preprocessing alongside feature extraction, we succeed in\npredicting the correct severity levels with over 92% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 12:23:22 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shenavarmasouleh", "Farzan", ""], ["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "2011.14754", "submitter": "Mostafa Haghi Kashani", "authors": "Sepideh Bazzaz Abkenar, Mostafa Haghi Kashani, Mohammad Akbari,\n  Ebrahim Mahdipour", "title": "Twitter Spam Detection: A Systematic Review", "comments": "18 pages, 12 figures, 14 tables, 91 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the rise of Internet access and mobile devices around the\nglobe, more people are using social networks for collaboration and receiving\nreal-time information. Twitter, the microblogging that is becoming a critical\nsource of communication and news propagation, has grabbed the attention of\nspammers to distract users. So far, researchers have introduced various defense\ntechniques to detect spams and combat spammer activities on Twitter. To\novercome this problem, in recent years, many novel techniques have been offered\nby researchers, which have greatly enhanced the spam detection performance.\nTherefore, it raises a motivation to conduct a systematic review about\ndifferent approaches of spam detection on Twitter. This review focuses on\ncomparing the existing research techniques on Twitter spam detection\nsystematically. Literature review analysis reveals that most of the existing\nmethods rely on Machine Learning-based algorithms. Among these Machine Learning\nalgorithms, the major differences are related to various feature selection\nmethods. Hence, we propose a taxonomy based on different feature selection\nmethods and analyses, namely content analysis, user analysis, tweet analysis,\nnetwork analysis, and hybrid analysis. Then, we present numerical analyses and\ncomparative studies on current approaches, coming up with open challenges that\nhelp researchers develop solutions in this topic.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:10:24 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:31:06 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Abkenar", "Sepideh Bazzaz", ""], ["Kashani", "Mostafa Haghi", ""], ["Akbari", "Mohammad", ""], ["Mahdipour", "Ebrahim", ""]]}, {"id": "2011.14764", "submitter": "Heinke Hihn", "authors": "Peter Bellmann, Heinke Hihn, Daniel A. Braun, Friedhelm Schwenker", "title": "Binary Classification: Counterbalancing Class Imbalance by Applying\n  Regression Models in Combination with One-Sided Label Shifts", "comments": "Accepted at ICAART 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many real-world pattern recognition scenarios, such as in medical\napplications, the corresponding classification tasks can be of an imbalanced\nnature. In the current study, we focus on binary, imbalanced classification\ntasks, i.e.~binary classification tasks in which one of the two classes is\nunder-represented (minority class) in comparison to the other class (majority\nclass). In the literature, many different approaches have been proposed, such\nas under- or oversampling, to counter class imbalance. In the current work, we\nintroduce a novel method, which addresses the issues of class imbalance. To\nthis end, we first transfer the binary classification task to an equivalent\nregression task. Subsequently, we generate a set of negative and positive\ntarget labels, such that the corresponding regression task becomes balanced,\nwith respect to the redefined target label set. We evaluate our approach on a\nnumber of publicly available data sets in combination with Support Vector\nMachines. Moreover, we compare our proposed method to one of the most popular\noversampling techniques (SMOTE). Based on the detailed discussion of the\npresented outcomes of our experimental evaluation, we provide promising ideas\nfor future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:24:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Bellmann", "Peter", ""], ["Hihn", "Heinke", ""], ["Braun", "Daniel A.", ""], ["Schwenker", "Friedhelm", ""]]}, {"id": "2011.14773", "submitter": "Gregorio Bernabe G.", "authors": "Jes\\'us M. Rodr\\'iguez-de-Vera and Josefa Gonz\\'alez-Carrillo and\n  Jos\\'e M. Garc\\'ia and Gregorio Bernab\\'e", "title": "Deep learning approach to left ventricular non-compaction measurement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Left ventricular non-compaction (LVNC) is a rare cardiomyopathy characterized\nby abnormal trabeculations in the left ventricle cavity. Although traditional\ncomputer vision approaches exist for LVNC diagnosis, deep learning-based tools\ncould not be found in the literature. In this paper, a first approach using\nconvolutional neural networks (CNNs) is presented. Four CNNs are trained to\nautomatically segment the compacted and trabecular areas of the left ventricle\nfor a population of patients diagnosed with Hypertrophic cardiomyopathy.\nInference results confirm that deep learning-based approaches can achieve\nexcellent results in the diagnosis and measurement of LVNC. The two best CNNs\n(U-Net and Efficient U-Net B1) perform image segmentation in less than 0.2 s on\na CPU and in less than 0.01 s on a GPU. Additionally, a subjective evaluation\nof the output images with the identified zones is performed by expert\ncardiologists, with a perfect visual agreement for all the slices,\noutperforming already existing automatic tools.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:32:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rodr\u00edguez-de-Vera", "Jes\u00fas M.", ""], ["Gonz\u00e1lez-Carrillo", "Josefa", ""], ["Garc\u00eda", "Jos\u00e9 M.", ""], ["Bernab\u00e9", "Gregorio", ""]]}, {"id": "2011.14776", "submitter": "Ruikang Zhong", "authors": "Ruikang Zhong, Xiao Liu, Yuanwei Liu and Yue Chen", "title": "NOMA in UAV-aided cellular offloading: A machine learning approach", "comments": "arXiv admin note: substantial text overlap with arXiv:2010.09094", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel framework is proposed for cellular offloading with the aid of\nmultiple unmanned aerial vehicles (UAVs), while non-orthogonal multiple access\n(NOMA) technique is employed at each UAV to further improve the spectrum\nefficiency of the wireless network. The optimization problem of joint\nthree-dimensional (3D) trajectory design and power allocation is formulated for\nmaximizing the throughput. In an effort to solve this pertinent dynamic\nproblem, a K-means based clustering algorithm is first adopted for periodically\npartitioning users. Afterward, a mutual deep Q-network (MDQN) algorithm is\nproposed to jointly determine the optimal 3D trajectory and power allocation of\nUAVs. In contrast to the conventional deep Q-network (DQN) algorithm, the MDQN\nalgorithm enables the experience of multi-agent to be input into a shared\nneural network to shorten the training time with the assistance of state\nabstraction. Numerical results demonstrate that: 1) the proposed MDQN algorithm\nhas a faster convergence rate than the conventional DQN algorithm in the\nmulti-agent case; 2) The achievable sum rate of the NOMA enhanced UAV network\nis $23\\%$ superior to the case of orthogonal multiple access (OMA); 3) By\ndesigning the optimal 3D trajectory of UAVs with the aid of the MDON algorithm,\nthe sum rate of the network enjoys ${142\\%}$ and ${56\\%}$ gains than that of\ninvoking the circular trajectory and the 2D trajectory, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 18 Oct 2020 17:38:48 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhong", "Ruikang", ""], ["Liu", "Xiao", ""], ["Liu", "Yuanwei", ""], ["Chen", "Yue", ""]]}, {"id": "2011.14779", "submitter": "Pratyush Maini", "authors": "Jean-Baptiste Truong, Pratyush Maini, Robert J. Walls, Nicolas\n  Papernot", "title": "Data-Free Model Extraction", "comments": "Published in the 2021 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current model extraction attacks assume that the adversary has access to a\nsurrogate dataset with characteristics similar to the proprietary data used to\ntrain the victim model. This requirement precludes the use of existing model\nextraction techniques on valuable models, such as those trained on rare or hard\nto acquire datasets. In contrast, we propose data-free model extraction methods\nthat do not require a surrogate dataset. Our approach adapts techniques from\nthe area of data-free knowledge transfer for model extraction. As part of our\nstudy, we identify that the choice of loss is critical to ensuring that the\nextracted model is an accurate replica of the victim model. Furthermore, we\naddress difficulties arising from the adversary's limited access to the victim\nmodel in a black-box setting. For example, we recover the model's logits from\nits probability predictions to approximate gradients. We find that the proposed\ndata-free model extraction approach achieves high-accuracy with reasonable\nquery complexity -- 0.99x and 0.92x the victim model accuracy on SVHN and\nCIFAR-10 datasets given 2M and 20M queries respectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:37:47 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 16:12:34 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Truong", "Jean-Baptiste", ""], ["Maini", "Pratyush", ""], ["Walls", "Robert J.", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2011.14787", "submitter": "Michal P\\'andy", "authors": "Michal P\\'andy, Daniel Lenton, Ronald Clark", "title": "Unsupervised Path Regression Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that challenging shortest path problems can be solved via\ndirect spline regression from a neural network, trained in an unsupervised\nmanner (i.e. without requiring ground truth optimal paths for training). To\nachieve this, we derive a geometry-dependent optimal cost function whose minima\nguarantees collision-free solutions. Our method beats state-of-the-art\nsupervised learning baselines for shortest path planning, with a much more\nscalable training pipeline, and a significant speedup in inference time.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:45:55 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 11:38:55 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["P\u00e1ndy", "Michal", ""], ["Lenton", "Daniel", ""], ["Clark", "Ronald", ""]]}, {"id": "2011.14799", "submitter": "Ramkumar Raghu", "authors": "Ramkumar Raghu, Mahadesh Panju, Vaneet Aggarwal and Vinod Sharma", "title": "Scheduling and Power Control for Wireless Multicast Systems via Deep\n  Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.05308", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicasting in wireless systems is a natural way to exploit the redundancy\nin user requests in a Content Centric Network. Power control and optimal\nscheduling can significantly improve the wireless multicast network's\nperformance under fading. However, the model based approaches for power control\nand scheduling studied earlier are not scalable to large state space or\nchanging system dynamics. In this paper, we use deep reinforcement learning\nwhere we use function approximation of the Q-function via a deep neural network\nto obtain a power control policy that matches the optimal policy for a small\nnetwork. We show that power control policy can be learnt for reasonably large\nsystems via this approach. Further we use multi-timescale stochastic\noptimization to maintain the average power constraint. We demonstrate that a\nslight modification of the learning algorithm allows tracking of time varying\nsystem statistics. Finally, we extend the multi-timescale approach to\nsimultaneously learn the optimal queueing strategy along with power control. We\ndemonstrate scalability, tracking and cross layer optimization capabilities of\nour algorithms via simulations. The proposed multi-timescale approach can be\nused in general large state space dynamical systems with multiple objectives\nand constraints, and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2020 15:59:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Raghu", "Ramkumar", ""], ["Panju", "Mahadesh", ""], ["Aggarwal", "Vaneet", ""], ["Sharma", "Vinod", ""]]}, {"id": "2011.14808", "submitter": "Xiangzhong Luo Mr.", "authors": "Di Liu, Hao Kong, Xiangzhong Luo, Weichen Liu, Ravi Subramaniam", "title": "Bringing AI To Edge: From Deep Learning's Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Edge computing and artificial intelligence (AI), especially deep learning for\nnowadays, are gradually intersecting to build a novel system, called edge\nintelligence. However, the development of edge intelligence systems encounters\nsome challenges, and one of these challenges is the \\textit{computational gap}\nbetween computation-intensive deep learning algorithms and less-capable edge\nsystems. Due to the computational gap, many edge intelligence systems cannot\nmeet the expected performance requirements. To bridge the gap, a plethora of\ndeep learning techniques and optimization methods are proposed in the past\nyears: light-weight deep learning models, network compression, and efficient\nneural architecture search. Although some reviews or surveys have partially\ncovered this large body of literature, we lack a systematic and comprehensive\nreview to discuss all aspects of these deep learning techniques which are\ncritical for edge intelligence implementation. As various and diverse methods\nwhich are applicable to edge systems are proposed intensively, a holistic\nreview would enable edge computing engineers and community to know the\nstate-of-the-art deep learning techniques which are instrumental for edge\nintelligence and to facilitate the development of edge intelligence systems.\nThis paper surveys the representative and latest deep learning techniques that\nare useful for edge intelligence systems, including hand-crafted models, model\ncompression, hardware-aware neural architecture search and adaptive deep\nlearning models. Finally, based on observations and simple experiments we\nconducted, we discuss some future directions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 12:07:21 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Liu", "Di", ""], ["Kong", "Hao", ""], ["Luo", "Xiangzhong", ""], ["Liu", "Weichen", ""], ["Subramaniam", "Ravi", ""]]}, {"id": "2011.14814", "submitter": "Gal Lifshitz", "authors": "Gal Lifshitz and Dan Raviv", "title": "Unsupervised Optical Flow Using Cost Function Unrolling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing motion between two consecutive images is one of the fundamental\ntasks in computer vision. In the lack of labeled data, the loss functions are\nsplit into consistency and smoothness, allowing for self-supervised training.\nThis paper focuses on the cost function derivation and presents an unrolling\niterative approach, transferring the hard L1 smoothness constraint into a\nsofter multi-layer iterative scheme. More accurate gradients, especially near\nnon-differential positions, improve the network's convergence, providing\nsuperior results on tested scenarios. We report state-of-the-art results on\nboth MPI Sintel and KITTI 2015 unsupervised optical flow benchmarks. The\nprovided approach can be used to enhance various architectures and not limited\njust to the presented pipeline.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 14:10:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lifshitz", "Gal", ""], ["Raviv", "Dan", ""]]}, {"id": "2011.14818", "submitter": "Chandra Thapa", "authors": "Chandra Thapa and M.A.P. Chamikara and Seyit A. Camtepe", "title": "Advancements of federated learning towards privacy preservation: from\n  federated learning to split learning", "comments": "Authors' preprint version (before any peer-review) of a book chapter\n  to appear in the Book series \"Studies in Computational Intelligence\", Book\n  title \"Federated Learning Systems: Towards Next-generation AI\", Book eds.\n  Muhammad Habib ur Rehman and Mohamed Medhat Gaber, Publisher \"Springer Nature\n  Switzerland AG Gewerbestrasse 11, 6330 Cham, Switzerland.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the distributed collaborative machine learning (DCML) paradigm, federated\nlearning (FL) recently attracted much attention due to its applications in\nhealth, finance, and the latest innovations such as industry 4.0 and smart\nvehicles. FL provides privacy-by-design. It trains a machine learning model\ncollaboratively over several distributed clients (ranging from two to millions)\nsuch as mobile phones, without sharing their raw data with any other\nparticipant. In practical scenarios, all clients do not have sufficient\ncomputing resources (e.g., Internet of Things), the machine learning model has\nmillions of parameters, and its privacy between the server and the clients\nwhile training/testing is a prime concern (e.g., rival parties). In this\nregard, FL is not sufficient, so split learning (SL) is introduced. SL is\nreliable in these scenarios as it splits a model into multiple portions,\ndistributes them among clients and server, and trains/tests their respective\nmodel portions to accomplish the full model training/testing. In SL, the\nparticipants do not share both data and their model portions to any other\nparties, and usually, a smaller network portion is assigned to the clients\nwhere data resides. Recently, a hybrid of FL and SL, called splitfed learning,\nis introduced to elevate the benefits of both FL (faster training/testing time)\nand SL (model split and training). Following the developments from FL to SL,\nand considering the importance of SL, this chapter is designed to provide\nextensive coverage in SL and its variants. The coverage includes fundamentals,\nexisting findings, integration with privacy measures such as differential\nprivacy, open problems, and code implementation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 05:01:33 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Thapa", "Chandra", ""], ["Chamikara", "M. A. P.", ""], ["Camtepe", "Seyit A.", ""]]}, {"id": "2011.14820", "submitter": "Claire Heaney", "authors": "Claire E. Heaney, Yuling Li, Omar K. Matar and Christopher C. Pain", "title": "Applying Convolutional Neural Networks to Data on Unstructured Meshes\n  with Space-Filling Curves", "comments": "17 figures, 52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first classical Convolutional Neural Network (CNN)\nthat can be applied directly to data from unstructured finite element meshes or\ncontrol volume grids. CNNs have been hugely influential in the areas of image\nclassification and image compression, both of which typically deal with data on\nstructured grids. Unstructured meshes are frequently used to solve partial\ndifferential equations and are particularly suitable for problems that require\nthe mesh to conform to complex geometries or for problems that require variable\nmesh resolution. Central to the approach are space-filling curves, which\ntraverse the nodes or cells of a mesh tracing out a path that is as short as\npossible (in terms of numbers of edges) and that visits each node or cell\nexactly once. The space-filling curves (SFCs) are used to find an ordering of\nthe nodes or cells that can transform multi-dimensional solutions on\nunstructured meshes into a one-dimensional (1D) representation, to which 1D\nconvolutional layers can then be applied. Although developed in two dimensions,\nthe approach is applicable to higher dimensional problems.\n  To demonstrate the approach, the network we choose is a convolutional\nautoencoder (CAE) although other types of CNN could be used. The approach is\ntested by applying CAEs to data sets that have been reordered with an SFC.\nSparse layers are used at the input and output of the autoencoder, and the use\nof multiple SFCs is explored. We compare the accuracy of the SFC-based CAE with\nthat of a classical CAE applied to two idealised problems on structured meshes,\nand then apply the approach to solutions of flow past a cylinder obtained using\nthe finite-element method and an unstructured mesh.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 01:03:50 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:14:49 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Heaney", "Claire E.", ""], ["Li", "Yuling", ""], ["Matar", "Omar K.", ""], ["Pain", "Christopher C.", ""]]}, {"id": "2011.14821", "submitter": "James P. Crutchfield", "authors": "Nicolas Brodu and James P. Crutchfield", "title": "Discovering Causal Structure with Reproducing-Kernel Hilbert Space\n  $\\epsilon$-Machines", "comments": "20 pages, 9 figures, 57 citations;\n  csc.ucdavis.edu/~cmg/compmech/pubs/kem.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We merge computational mechanics' definition of causal states\n(predictively-equivalent histories) with reproducing-kernel Hilbert space\n(RKHS) representation inference. The result is a widely-applicable method that\ninfers causal structure directly from observations of a system's behaviors\nwhether they are over discrete or continuous events or time. A structural\nrepresentation -- a finite- or infinite-state kernel $\\epsilon$-machine -- is\nextracted by a reduced-dimension transform that gives an efficient\nrepresentation of causal states and their topology. In this way, the system\ndynamics are represented by a stochastic (ordinary or partial) differential\nequation that acts on causal states. We introduce an algorithm to estimate the\nassociated evolution operator. Paralleling the Fokker-Plank equation, it\nefficiently evolves causal-state distributions and makes predictions in the\noriginal data space via an RKHS functional mapping. We demonstrate these\ntechniques, together with their predictive abilities, on discrete-time,\ndiscrete-value infinite Markov-order processes generated by finite-state hidden\nMarkov models with (i) finite or (ii) uncountably-infinite causal states and\n(iii) a continuous-time, continuous-value process generated by a\nthermally-driven chaotic flow. The method robustly estimates causal structure\nin the presence of varying external and measurement noise levels.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 23:41:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Brodu", "Nicolas", ""], ["Crutchfield", "James P.", ""]]}, {"id": "2011.14824", "submitter": "Wenyu Zhao", "authors": "Wenyu Zhao, Teli Ma, Xuan Gong, Baochang Zhang, and David Doermann", "title": "A Review of Recent Advances of Binary Neural Networks for Edge Computing", "comments": null, "journal-ref": null, "doi": "10.1109/JMASS.2020.3034205", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing is promising to become one of the next hottest topics in\nartificial intelligence because it benefits various evolving domains such as\nreal-time unmanned aerial systems, industrial applications, and the demand for\nprivacy protection. This paper reviews recent advances on binary neural network\n(BNN) and 1-bit CNN technologies that are well suitable for front-end,\nedge-based computing. We introduce and summarize existing work and classify\nthem based on gradient approximation, quantization, architecture, loss\nfunctions, optimization method, and binary neural architecture search. We also\nintroduce applications in the areas of computer vision and speech recognition\nand discuss future applications for edge computing.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 01:10:21 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhao", "Wenyu", ""], ["Ma", "Teli", ""], ["Gong", "Xuan", ""], ["Zhang", "Baochang", ""], ["Doermann", "David", ""]]}, {"id": "2011.14826", "submitter": "Pablo Samuel Castro", "authors": "Johan S. Obando-Ceron and Pablo Samuel Castro", "title": "Revisiting Rainbow: Promoting more Insightful and Inclusive Deep\n  Reinforcement Learning Research", "comments": "Proceedings of the 38th International Conference on Machine Learning\n  (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the introduction of DQN, a vast majority of reinforcement learning\nresearch has focused on reinforcement learning with deep neural networks as\nfunction approximators. New methods are typically evaluated on a set of\nenvironments that have now become standard, such as Atari 2600 games. While\nthese benchmarks help standardize evaluation, their computational cost has the\nunfortunate side effect of widening the gap between those with ample access to\ncomputational resources, and those without. In this work we argue that, despite\nthe community's emphasis on large-scale environments, the traditional\nsmall-scale environments can still yield valuable scientific insights and can\nhelp reduce the barriers to entry for underprivileged communities. To\nsubstantiate our claims, we empirically revisit the paper which introduced the\nRainbow algorithm [Hessel et al., 2018] and present some new insights into the\nalgorithms used by Rainbow.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:23:40 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 19:53:36 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Obando-Ceron", "Johan S.", ""], ["Castro", "Pablo Samuel", ""]]}, {"id": "2011.14830", "submitter": "Elaheh Alipourchavary", "authors": "Elaheh AlipourChavary, Sarah M. Erfani, Christopher Leckie", "title": "Improving Scalability of Contrast Pattern Mining for Network Traffic\n  Using Closed Patterns", "comments": "4 pages; 3figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrast pattern mining (CPM) aims to discover patterns whose support\nincreases significantly from a background dataset compared to a target dataset.\nCPM is particularly useful for characterising changes in evolving systems,\ne.g., in network traffic analysis to detect unusual activity. While most\nexisting techniques focus on extracting either the whole set of contrast\npatterns (CPs) or minimal sets, the problem of efficiently finding a relevant\nsubset of CPs, especially in high dimensional datasets, is an open challenge.\nIn this paper, we focus on extracting the most specific set of CPs to discover\nsignificant changes between two datasets. Our approach to this problem uses\nclosed patterns to substantially reduce redundant patterns. Our experimental\nresults on several real and emulated network traffic datasets demonstrate that\nour proposed unsupervised algorithm is up to 100 times faster than an existing\napproach for CPM on network traffic data [2]. In addition, as an application of\nCPs, we demonstrate that CPM is a highly effective method for detection of\nmeaningful changes in network traffic.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 08:52:47 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["AlipourChavary", "Elaheh", ""], ["Erfani", "Sarah M.", ""], ["Leckie", "Christopher", ""]]}, {"id": "2011.14844", "submitter": "Emilio Calvanese Strinati", "authors": "Emilio Calvanese Strinati and Sergio Barbarossa", "title": "6G Networks: Beyond Shannon Towards Semantic and Goal-Oriented\n  Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to promote the idea that including semantic and\ngoal-oriented aspects in future 6G networks can produce a significant leap\nforward in terms of system effectiveness and sustainability. Semantic\ncommunication goes beyond the common Shannon paradigm of guaranteeing the\ncorrect reception of each single transmitted packet, irrespective of the\nmeaning conveyed by the packet. The idea is that, whenever communication occurs\nto convey meaning or to accomplish a goal, what really matters is the impact\nthat the correct reception/interpretation of a packet is going to have on the\ngoal accomplishment. Focusing on semantic and goal-oriented aspects, and\npossibly combining them, helps to identify the relevant information, i.e. the\ninformation strictly necessary to recover the meaning intended by the\ntransmitter or to accomplish a goal. Combining knowledge representation and\nreasoning tools with machine learning algorithms paves the way to build\nsemantic learning strategies enabling current machine learning algorithms to\nachieve better interpretation capabilities and contrast adversarial attacks. 6G\nsemantic networks can bring semantic learning mechanisms at the edge of the\nnetwork and, at the same time, semantic learning can help 6G networks to\nimprove their efficiency and sustainability.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 13:33:04 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:00:59 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 08:38:38 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Strinati", "Emilio Calvanese", ""], ["Barbarossa", "Sergio", ""]]}, {"id": "2011.14858", "submitter": "Aditya Jyoti Paul", "authors": "Puranjay Mohan, Aditya Jyoti Paul, Abhay Chirania", "title": "A Tiny CNN Architecture for Medical Face Mask Detection for\n  Resource-Constrained Endpoints", "comments": "11 pages, Published in Springer LNEE at\n  http://link.springer.com/chapter/10.1007%2F978-981-16-0749-3_52", "journal-ref": "Innovations in Electrical and Electronic Engineering. Lecture\n  Notes in Electrical Engineering, vol 756, pp 657-670, Springer, Singapore,\n  2021", "doi": "10.1007/978-981-16-0749-3_52", "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is going through one of the most dangerous pandemics of all time\nwith the rapid spread of the novel coronavirus (COVID-19). According to the\nWorld Health Organisation, the most effective way to thwart the transmission of\ncoronavirus is to wear medical face masks. Monitoring the use of face masks in\npublic places has been a challenge because manual monitoring could be unsafe.\nThis paper proposes an architecture for detecting medical face masks for\ndeployment on resource-constrained endpoints having extremely low memory\nfootprints. A small development board with an ARM Cortex-M7 microcontroller\nclocked at 480 Mhz and having just 496 KB of framebuffer RAM, has been used for\nthe deployment of the model. Using the TensorFlow Lite framework, the model is\nquantized to further reduce its size. The proposed model is 138 KB post\nquantization and runs at the inference speed of 30 FPS.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 14:56:23 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 18:52:33 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 12:55:21 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Mohan", "Puranjay", ""], ["Paul", "Aditya Jyoti", ""], ["Chirania", "Abhay", ""]]}, {"id": "2011.14859", "submitter": "Derek Lim", "authors": "Derek Lim, Ren\\'e Vidal, Benjamin D. Haeffele", "title": "Doubly Stochastic Subspace Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many state-of-the-art subspace clustering methods follow a two-step process\nby first constructing an affinity matrix between data points and then applying\nspectral clustering to this affinity. Most of the research into these methods\nfocuses on the first step of generating the affinity, which often exploits the\nself-expressive property of linear subspaces, with little consideration\ntypically given to the spectral clustering step that produces the final\nclustering. Moreover, existing methods often obtain the final affinity that is\nused in the spectral clustering step by applying ad-hoc or arbitrarily chosen\npostprocessing steps to the affinity generated by a self-expressive clustering\nformulation, which can have a significant impact on the overall clustering\nperformance. In this work, we unify these two steps by learning both a\nself-expressive representation of the data and an affinity matrix that is\nwell-normalized for spectral clustering. In our proposed models, we constrain\nthe affinity matrix to be doubly stochastic, which results in a principled\nmethod for affinity matrix normalization while also exploiting known benefits\nof doubly stochastic normalization in spectral clustering. We develop a general\nframework and derive two models: one that jointly learns the self-expressive\nrepresentation along with the doubly stochastic affinity, and one that\nsequentially solves for one then the other. Furthermore, we leverage sparsity\nin the problem to develop a fast active-set method for the sequential solver\nthat enables efficient computation on large datasets. Experiments show that our\nmethod achieves state-of-the-art subspace clustering performance on many common\ndatasets in computer vision.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 14:56:54 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 23:50:41 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lim", "Derek", ""], ["Vidal", "Ren\u00e9", ""], ["Haeffele", "Benjamin D.", ""]]}, {"id": "2011.14867", "submitter": "Deyu Bo", "authors": "Xiao Wang and Deyu Bo and Chuan Shi and Shaohua Fan and Yanfang Ye and\n  Philip S. Yu", "title": "A Survey on Heterogeneous Graph Embedding: Methods, Techniques,\n  Applications and Sources", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous graphs (HGs) also known as heterogeneous information networks\nhave become ubiquitous in real-world scenarios; therefore, HG embedding, which\naims to learn representations in a lower-dimension space while preserving the\nheterogeneous structures and semantics for downstream tasks (e.g., node/graph\nclassification, node clustering, link prediction), has drawn considerable\nattentions in recent years. In this survey, we perform a comprehensive review\nof the recent development on HG embedding methods and techniques. We first\nintroduce the basic concepts of HG and discuss the unique challenges brought by\nthe heterogeneity for HG embedding in comparison with homogeneous graph\nrepresentation learning; and then we systemically survey and categorize the\nstate-of-the-art HG embedding methods based on the information they used in the\nlearning process to address the challenges posed by the HG heterogeneity. In\nparticular, for each representative HG embedding method, we provide detailed\nintroduction and further analyze its pros and cons; meanwhile, we also explore\nthe transformativeness and applicability of different types of HG embedding\nmethods in the real-world industrial environments for the first time. In\naddition, we further present several widely deployed systems that have\ndemonstrated the success of HG embedding techniques in resolving real-world\napplication problems with broader impacts. To facilitate future research and\napplications in this area, we also summarize the open-source code, existing\ngraph learning platforms and benchmark datasets. Finally, we explore the\nadditional issues and challenges of HG embedding and forecast the future\nresearch directions in this field.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:03:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wang", "Xiao", ""], ["Bo", "Deyu", ""], ["Shi", "Chuan", ""], ["Fan", "Shaohua", ""], ["Ye", "Yanfang", ""], ["Yu", "Philip S.", ""]]}, {"id": "2011.14870", "submitter": "Luis Felipe M\\\"uller de Oliveira Henriques", "authors": "Luis Felipe M.O. Henriques, Eduardo Morgan, Sergio Colcher, Ruy Luiz\n  Milidi\\'u", "title": "Prior Flow Variational Autoencoder: A density estimation model for\n  Non-Intrusive Load Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Intrusive Load Monitoring (NILM) is a computational technique to estimate\nthe power loads' appliance-by-appliance from the whole consumption measured by\na single meter. In this paper, we propose a conditional density estimation\nmodel, based on deep neural networks, that joins a Conditional Variational\nAutoencoder with a Conditional Invertible Normalizing Flow model to estimate\nthe individual appliance's power demand. The resulting model is called Prior\nFlow Variational Autoencoder or, for simplicity PFVAE. Thus, instead of having\none model per appliance, the resulting model is responsible for estimating the\npower demand, appliance-by-appliance, at once. We train and evaluate our\nproposed model in a publicly available dataset composed of power demand\nmeasures from a poultry feed factory located in Brazil. The proposed model's\nquality is evaluated by comparing the obtained normalized disaggregation error\n(NDE) and signal aggregated error (SAE) with the previous work values on the\nsame dataset. Our proposal achieves highly competitive results, and for six of\nthe eight machines belonging to the dataset, we observe consistent improvements\nthat go from 28% up to 81% in NDE and from 27% up to 86% in SAE.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:05:59 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 22:51:43 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Henriques", "Luis Felipe M. O.", ""], ["Morgan", "Eduardo", ""], ["Colcher", "Sergio", ""], ["Milidi\u00fa", "Ruy Luiz", ""]]}, {"id": "2011.14871", "submitter": "Sahithya Ravi", "authors": "Sahithya Ravi, Samaneh Khoshrou, Mykola Pechenizkiy", "title": "ViDi: Descriptive Visual Data Clustering as Radiologist Assistant in\n  COVID-19 Streamline Diagnostic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the light of the COVID-19 pandemic, deep learning methods have been widely\ninvestigated in detecting COVID-19 from chest X-rays. However, a more pragmatic\napproach to applying AI methods to a medical diagnosis is designing a framework\nthat facilitates human-machine interaction and expert decision making. Studies\nhave shown that categorization can play an essential rule in accelerating\nreal-world decision making. Inspired by descriptive document clustering, we\npropose a domain-independent explanatory clustering framework to group\ncontextually related instances and support radiologists' decision making. While\nmost descriptive clustering approaches employ domain-specific characteristics\nto form meaningful clusters, we focus on model-level explanation as a more\ngeneral-purpose element of every learning process to achieve cluster\nhomogeneity. We employ DeepSHAP to generate homogeneous clusters in terms of\ndisease severity and describe the clusters using favorable and unfavorable\nsaliency maps, which visualize the class discriminating regions of an image.\nThese human-interpretable maps complement radiologist knowledge to investigate\nthe whole cluster at once. Besides, as part of this study, we evaluate a model\nbased on VGG-19, which can identify COVID and pneumonia cases with a positive\npredictive value of 95% and 97%, respectively, comparable to the recent\nexplainable approaches for COVID diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:06:08 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ravi", "Sahithya", ""], ["Khoshrou", "Samaneh", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2011.14878", "submitter": "Ian Covert", "authors": "Ian Covert, Scott Lundberg, Su-In Lee", "title": "Explaining by Removing: A Unified Framework for Model Explanation", "comments": "arXiv admin note: text overlap with arXiv:2011.03623", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have proposed a wide variety of model explanation approaches, but\nit remains unclear how most methods are related or when one method is\npreferable to another. We establish a new class of methods, removal-based\nexplanations, that are based on the principle of simulating feature removal to\nquantify each feature's influence. These methods vary in several respects, so\nwe develop a framework that characterizes each method along three dimensions:\n1) how the method removes features, 2) what model behavior the method explains,\nand 3) how the method summarizes each feature's influence. Our framework\nunifies 25 existing methods, including several of the most widely used\napproaches (SHAP, LIME, Meaningful Perturbations, permutation tests). This new\nclass of explanation methods has rich connections that we examine using tools\nthat have been largely overlooked by the explainability literature. To anchor\nremoval-based explanations in cognitive psychology, we show that feature\nremoval is a simple application of subtractive counterfactual reasoning. Ideas\nfrom cooperative game theory shed light on the relationships and trade-offs\namong different methods, and we derive conditions under which all removal-based\nexplanations have information-theoretic interpretations. Through this analysis,\nwe develop a unified framework that helps practitioners better understand model\nexplanation tools, and that offers a strong theoretical foundation upon which\nfuture explainability research can build.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:47:48 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Covert", "Ian", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "2011.14880", "submitter": "Bojun Ouyang", "authors": "Bojun Ouyang, Dan Raviv", "title": "Occlusion Guided Scene Flow Estimation on 3D Point Clouds", "comments": "Aaccepted at CVPR 2021 Workshop on Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D scene flow estimation is a vital tool in perceiving our environment given\ndepth or range sensors. Unlike optical flow, the data is usually sparse and in\nmost cases partially occluded in between two temporal samplings. Here we\npropose a new scene flow architecture called OGSF-Net which tightly couples the\nlearning for both flow and occlusions between frames. Their coupled symbiosis\nresults in a more accurate prediction of flow in space. Unlike a traditional\nmulti-action network, our unified approach is fused throughout the network,\nboosting performances for both occlusion detection and flow estimation. Our\narchitecture is the first to gauge the occlusion in 3D scene flow estimation on\npoint clouds. In key datasets such as Flyingthings3D and KITTI, we achieve the\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:22:03 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 16:49:36 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ouyang", "Bojun", ""], ["Raviv", "Dan", ""]]}, {"id": "2011.14890", "submitter": "Niko Grupen", "authors": "Niko A. Grupen, Daniel D. Lee, Bart Selman", "title": "Low-Bandwidth Communication Emerges Naturally in Multi-Agent Learning\n  Systems", "comments": "10 pages, 6 figures, Appearing in Talking to Strangers: Zero-Shot\n  Emergent Communication Workshop NeurIPS 2020. Fixed part (a) of Figure 2 to\n  include correct baseline reported in quantitative results section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we study emergent communication through the lens of cooperative\nmulti-agent behavior in nature. Using insights from animal communication, we\npropose a spectrum from low-bandwidth (e.g. pheromone trails) to high-bandwidth\n(e.g. compositional language) communication that is based on the cognitive,\nperceptual, and behavioral capabilities of social agents. Through a series of\nexperiments with pursuit-evasion games, we identify multi-agent reinforcement\nlearning algorithms as a computational model for the low-bandwidth end of the\ncommunication spectrum.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:29:57 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 20:21:14 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Grupen", "Niko A.", ""], ["Lee", "Daniel D.", ""], ["Selman", "Bart", ""]]}, {"id": "2011.14901", "submitter": "Annika Lindh", "authors": "Annika Lindh, Robert J. Ross, John D. Kelleher", "title": "Language-Driven Region Pointer Advancement for Controllable Image\n  Captioning", "comments": "Accepted to COLING 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Controllable Image Captioning is a recent sub-field in the multi-modal task\nof Image Captioning wherein constraints are placed on which regions in an image\nshould be described in the generated natural language caption. This puts a\nstronger focus on producing more detailed descriptions, and opens the door for\nmore end-user control over results. A vital component of the Controllable Image\nCaptioning architecture is the mechanism that decides the timing of attending\nto each region through the advancement of a region pointer. In this paper, we\npropose a novel method for predicting the timing of region pointer advancement\nby treating the advancement step as a natural part of the language structure\nvia a NEXT-token, motivated by a strong correlation to the sentence structure\nin the training data. We find that our timing agrees with the ground-truth\ntiming in the Flickr30k Entities test data with a precision of 86.55% and a\nrecall of 97.92%. Our model implementing this technique improves the\nstate-of-the-art on standard captioning metrics while additionally\ndemonstrating a considerably larger effective vocabulary size.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 15:34:59 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lindh", "Annika", ""], ["Ross", "Robert J.", ""], ["Kelleher", "John D.", ""]]}, {"id": "2011.14908", "submitter": "Seyed Mohsen Hosseini", "authors": "Seyed Mohsen Hosseini", "title": "Image Denoising for Strong Gaussian Noises With Specialized CNNs for\n  Different Frequency Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning approach to image denoising a network is trained to\nrecover a clean image from a noisy one. In this paper a novel structure is\nproposed based on training multiple specialized networks as opposed to existing\nstructures that are base on a single network. The proposed model is an\nalternative for training a very deep network to avoid issues like vanishing or\nexploding gradient. By dividing a very deep network into two smaller networks\nthe same number of learnable parameters will be available, but two smaller\nnetworks should be trained which are easier to train. Over smoothing and waxy\nartifacts are major problems with existing methods; because the network tries\nto keep the Mean Square Error (MSE) low for general structures and details,\nwhich leads to overlooking of details. This problem is more severe in the\npresence of strong noise. To reduce this problem, in the proposed structure,\nthe image is decomposed into its low and high frequency components and each\ncomponent is used to train a separate denoising convolutional neural network.\nOne network is specialized to reconstruct the general structure of the image\nand the other one is specialized to reconstruct the details. Results of the\nproposed method show higher peak signal to noise ratio (PSNR), and structural\nsimilarity index (SSIM) compared to a popular state of the art denoising method\nin the presence of strong noises.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 23:20:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Hosseini", "Seyed Mohsen", ""]]}, {"id": "2011.14917", "submitter": "Muhammad Umer", "authors": "Muhammad Umer, Robi Polikar", "title": "Comparative Analysis of Extreme Verification Latency Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the more challenging real-world problems in computational intelligence\nis to learn from non-stationary streaming data, also known as concept drift.\nPerhaps even a more challenging version of this scenario is when -- following a\nsmall set of initial labeled data -- the data stream consists of unlabeled data\nonly. Such a scenario is typically referred to as learning in initially labeled\nnonstationary environment, or simply as extreme verification latency (EVL).\nBecause of the very challenging nature of the problem, very few algorithms have\nbeen proposed in the literature up to date. This work is a very first effort to\nprovide a review of some of the existing algorithms (important/prominent) in\nthis field to the research community. More specifically, this paper is a\ncomprehensive survey and comparative analysis of some of the EVL algorithms to\npoint out the weaknesses and strengths of different approaches from three\ndifferent perspectives: classification accuracy, computational complexity and\nparameter sensitivity using several synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:34:56 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Umer", "Muhammad", ""], ["Polikar", "Robi", ""]]}, {"id": "2011.14924", "submitter": "Paul Waddell", "authors": "Paul Waddell and Arezoo Besharati-Zadeh", "title": "A Comparison of Statistical and Machine Learning Algorithms for\n  Predicting Rents in the San Francisco Bay Area", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Urban transportation and land use models have used theory and statistical\nmodeling methods to develop model systems that are useful in planning\napplications. Machine learning methods have been considered too 'black box',\nlacking interpretability, and their use has been limited within the land use\nand transportation modeling literature. We present a use case in which\npredictive accuracy is of primary importance, and compare the use of random\nforest regression to multiple regression using ordinary least squares, to\npredict rents per square foot in the San Francisco Bay Area using a large\nvolume of rental listings scraped from the Craigslist website. We find that we\nare able to obtain useful predictions from both models using almost exclusively\nlocal accessibility variables, though the predictive accuracy of the random\nforest model is substantially higher.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 08:50:45 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Waddell", "Paul", ""], ["Besharati-Zadeh", "Arezoo", ""]]}, {"id": "2011.14925", "submitter": "Minji Yoon", "authors": "Minji Yoon, Th\\'eophile Gervet, Bryan Hooi, and Christos Faloutsos", "title": "Autonomous Graph Mining Algorithm Search with Best Speed/Accuracy\n  Trade-off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph data is ubiquitous in academia and industry, from social networks to\nbioinformatics. The pervasiveness of graphs today has raised the demand for\nalgorithms that can answer various questions: Which products would a user like\nto purchase given her order list? Which users are buying fake followers to\nincrease their public reputation? Myriads of new graph mining algorithms are\nproposed every year to answer such questions - each with a distinct problem\nformulation, computational time, and memory footprint. This lack of unity makes\nit difficult for a practitioner to compare different algorithms and pick the\nmost suitable one for a specific application. These challenges - even more\nsevere for non-experts - create a gap in which state-of-the-art techniques\ndeveloped in academic settings fail to be optimally deployed in real-world\napplications. To bridge this gap, we propose AUTOGM, an automated system for\ngraph mining algorithm development. We first define a unified framework\nUNIFIEDGM that integrates various message-passing based graph algorithms,\nranging from conventional algorithms like PageRank to graph neural networks.\nThen UNIFIEDGM defines a search space in which five parameters are required to\ndetermine a graph algorithm. Under this search space, AUTOGM explicitly\noptimizes for the optimal parameter set of UNIFIEDGM using Bayesian\nOptimization. AUTOGM defines a novel budget-aware objective function for the\noptimization to incorporate a practical issue - finding the best speed-accuracy\ntrade-off under a computation budget - into the graph algorithm generation\nproblem. Experiments on real-world benchmark datasets demonstrate that AUTOGM\ngenerates novel graph mining algorithms with the best speed/accuracy trade-off\ncompared to existing models with heuristic parameters.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 02:37:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yoon", "Minji", ""], ["Gervet", "Th\u00e9ophile", ""], ["Hooi", "Bryan", ""], ["Faloutsos", "Christos", ""]]}, {"id": "2011.14934", "submitter": "Sahil Suneja", "authors": "Sahil Suneja, Yunhui Zheng, Yufan Zhuang, Jim Laredo, Alessandro\n  Morari", "title": "Probing Model Signal-Awareness via Prediction-Preserving Input\n  Minimization", "comments": "Authors Sahil Suneja, Yunhui Zheng, and Yufan Zhuang contributed\n  equally to this research. FSE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the signal awareness of AI models for source code\nunderstanding. Using a software vulnerability detection use case, we evaluate\nthe models' ability to capture the correct vulnerability signals to produce\ntheir predictions. Our prediction-preserving input minimization (P2IM) approach\nsystematically reduces the original source code to a minimal snippet which a\nmodel needs to maintain its prediction. The model's reliance on incorrect\nsignals is then uncovered when the vulnerability in the original code is\nmissing in the minimal snippet, both of which the model however predicts as\nbeing vulnerable. We measure the signal awareness of models using a new metric\nwe propose- Signal-aware Recall (SAR). We apply P2IM on three different neural\nnetwork architectures across multiple datasets. The results show a sharp drop\nin the model's Recall from the high 90s to sub-60s with the new metric,\nhighlighting that the models are presumably picking up a lot of noise or\ndataset nuances while learning their vulnerability detection logic. Although\nthe drop in model performance may be perceived as an adversarial attack, but\nthis isn't P2IM's objective. The idea is rather to uncover the signal-awareness\nof a black-box model in a data-driven manner via controlled queries. SAR's\npurpose is to measure the impact of task-agnostic model training, and not to\nsuggest a shortcoming in the Recall metric. The expectation, in fact, is for\nSAR to match Recall in the ideal scenario where the model truly captures\ntask-specific signals.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 20:05:23 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 21:44:44 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Suneja", "Sahil", ""], ["Zheng", "Yunhui", ""], ["Zhuang", "Yufan", ""], ["Laredo", "Jim", ""], ["Morari", "Alessandro", ""]]}, {"id": "2011.14954", "submitter": "Zichang Liu", "authors": "Zichang Liu, Li Chou, Anshumali Shrivastava", "title": "Neighbor Oblivious Learning (NObLe) for Device Localization and Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  On-device localization and tracking are increasingly crucial for various\napplications. Along with a rapidly growing amount of location data, machine\nlearning (ML) techniques are becoming widely adopted. A key reason is that ML\ninference is significantly more energy-efficient than GPS query at comparable\naccuracy, and GPS signals can become extremely unreliable for specific\nscenarios. To this end, several techniques such as deep neural networks have\nbeen proposed. However, during training, almost none of them incorporate the\nknown structural information such as floor plan, which can be especially useful\nin indoor or other structured environments. In this paper, we argue that the\nstate-of-the-art-systems are significantly worse in terms of accuracy because\nthey are incapable of utilizing these essential structural information. The\nproblem is incredibly hard because the structural properties are not explicitly\navailable, making most structural learning approaches inapplicable. Given that\nboth input and output space potentially contain rich structures, we study our\nmethod through the intuitions from manifold-projection. Whereas existing\nmanifold based learning methods actively utilized neighborhood information,\nsuch as Euclidean distances, our approach performs Neighbor Oblivious Learning\n(NObLe). We demonstrate our approach's effectiveness on two orthogonal\napplications, including WiFi-based fingerprint localization and inertial\nmeasurement unit(IMU) based device tracking, and show that it gives significant\nimprovement over state-of-art prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 17:25:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Liu", "Zichang", ""], ["Chou", "Li", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "2011.14956", "submitter": "Yongquan Yang", "authors": "Yongquan Yang, Yiming Yang, Jie Chen, Jiayi Zheng, Zhongxi Zheng", "title": "Handling Noisy Labels via One-Step Abductive Multi-Target Learning", "comments": "35 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from noisy labels is an important concern because of the lack of\naccurate ground-truth labels in plenty of real-world scenarios. In practice,\nvarious approaches for this concern first make corrections corresponding to\npotentially noisy-labeled instances, and then update predictive model with\ninformation of the made corrections. However, in specific areas, such as\nmedical histopathology whole slide image analysis (MHWSIA), it is often\ndifficult or even impossible for experts to manually achieve the noisy-free\nground-truth labels which leads to labels with heavy noise. This situation\nraises two more difficult problems: 1) the methodology of approaches making\ncorrections corresponding to potentially noisy-labeled instances has\nlimitations due to the heavy noise existing in labels; and 2) the appropriate\nevaluation strategy for validation/testing is unclear because of the great\ndifficulty in collecting the noisy-free ground-truth labels. In this paper, we\nfocus on alleviating these two problems. For the problem 1), we present a\none-step abductive multi-target learning framework (OSAMTLF) that imposes a\none-step logical reasoning upon machine learning via a multi-target learning\nprocedure to abduct the predictions of the learning model to be subject to our\nprior knowledge. For the problem 2), we propose a logical assessment formula\n(LAF) that evaluates the logical rationality of the outputs of an approach by\nestimating the consistencies between the predictions of the learning model and\nthe logical facts narrated from the results of the one-step logical reasoning\nof OSAMTLF. Applying OSAMTLF and LAF to the Helicobacter pylori (H. pylori)\nsegmentation task in MHWSIA, we show that OSAMTLF is able to abduct the machine\nlearning model achieving logically more rational predictions, which is beyond\nthe capability of various state-of-the-art approaches for learning from noisy\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 09:40:34 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yang", "Yongquan", ""], ["Yang", "Yiming", ""], ["Chen", "Jie", ""], ["Zheng", "Jiayi", ""], ["Zheng", "Zhongxi", ""]]}, {"id": "2011.14960", "submitter": "Kamil Deja", "authors": "Kamil Deja, Pawe{\\l} Wawrzy\\'nski, Daniel Marczak, Wojciech Masarczyk,\n  Tomasz Trzci\\'nski", "title": "BinPlay: A Binary Latent Autoencoder for Generative Replay Continual\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a binary latent space autoencoder architecture to rehearse\ntraining samples for the continual learning of neural networks. The ability to\nextend the knowledge of a model with new data without forgetting previously\nlearned samples is a fundamental requirement in continual learning. Existing\nsolutions address it by either replaying past data from memory, which is\nunsustainable with growing training data, or by reconstructing past samples\nwith generative models that are trained to generalize beyond training data and,\nhence, miss important details of individual samples. In this paper, we take the\nbest of both worlds and introduce a novel generative rehearsal approach called\nBinPlay. Its main objective is to find a quality-preserving encoding of past\nsamples into precomputed binary codes living in the autoencoder's binary latent\nspace. Since we parametrize the formula for precomputing the codes only on the\nchronological indices of the training samples, the autoencoder is able to\ncompute the binary embeddings of rehearsed samples on the fly without the need\nto keep them in memory. Evaluation on three benchmark datasets shows up to a\ntwofold accuracy improvement of BinPlay versus competing generative replay\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:50:58 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Deja", "Kamil", ""], ["Wawrzy\u0144ski", "Pawe\u0142", ""], ["Marczak", "Daniel", ""], ["Masarczyk", "Wojciech", ""], ["Trzci\u0144ski", "Tomasz", ""]]}, {"id": "2011.14962", "submitter": "Thomas Moreau", "authors": "Cl\\'ement Lalanne (CGB, CMLA), Maxence Rateaux (CGB), Laurent Oudre\n  (L2TI), Matthieu Robert (CGB), Thomas Moreau (PARIETAL)", "title": "Extraction of Nystagmus Patterns from Eye-Tracker Data with\n  Convolutional Sparse Coding", "comments": null, "journal-ref": "Annual International Conference of the IEEE Engineering in\n  Medicine & Biology Society (EMBC), Jul 2020, Montreal, QC, Canada. pp.928-931", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the Nystagmus waveforms from eye-tracking records is crucial\nfor the clinicial interpretation of this pathological movement. A major issue\nto automatize this analysis is the presence of natural eye movements and eye\nblink artefacts that are mixed with the signal of interest. We propose a method\nbased on Convolutional Dictionary Learning that is able to automaticcaly\nhighlight the Nystagmus waveforms, separating the natural motion from the\npathological movements. We show on simulated signals that our method can indeed\nimprove the pattern recovery rate and provide clinical examples to illustrate\nhow this algorithm performs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:41:23 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Lalanne", "Cl\u00e9ment", "", "CGB, CMLA"], ["Rateaux", "Maxence", "", "CGB"], ["Oudre", "Laurent", "", "L2TI"], ["Robert", "Matthieu", "", "CGB"], ["Moreau", "Thomas", "", "PARIETAL"]]}, {"id": "2011.14963", "submitter": "Sharu Theresa Jose", "authors": "Sharu Theresa Jose, Osvaldo Simeone", "title": "Free Energy Minimization: A Unified Framework for Modelling, Inference,\n  Learning,and Optimization", "comments": "To Appear in IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of these lecture notes is to review the problem of free energy\nminimization as a unified framework underlying the definition of maximum\nentropy modelling, generalized Bayesian inference, learning with latent\nvariables, statistical learning analysis of generalization,and local\noptimization. Free energy minimization is first introduced, here and\nhistorically, as a thermodynamic principle. Then, it is described\nmathematically in the context of Fenchel duality. Finally, the mentioned\napplications to modelling, inference, learning, and optimization are covered\nstarting from basic principles.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:29:03 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jose", "Sharu Theresa", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2011.14965", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha and Saibal Mukhopadhyay", "title": "A Deep Learning Approach for Predicting Spatiotemporal Dynamics From\n  Sparsely Observed Data", "comments": "11 pages, 10 figures; Accepted manuscript IEEE Access", "journal-ref": "IEEE Access, vol. 9, pp. 64200-64210, 2021", "doi": "10.1109/ACCESS.2021.3075899", "report-no": null, "categories": "stat.ML cs.LG cs.NA math.AP math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the problem of learning prediction models for\nspatiotemporal physical processes driven by unknown partial differential\nequations (PDEs). We propose a deep learning framework that learns the\nunderlying dynamics and predicts its evolution using sparsely distributed data\nsites. Deep learning has shown promising results in modeling physical dynamics\nin recent years. However, most of the existing deep learning methods for\nmodeling physical dynamics either focus on solving known PDEs or require data\nin a dense grid when the governing PDEs are unknown. In contrast, our method\nfocuses on learning prediction models for unknown PDE-driven dynamics only from\nsparsely observed data. The proposed method is spatial dimension-independent\nand geometrically flexible. We demonstrate our method in the forecasting task\nfor the two-dimensional wave equation and the Burgers-Fisher equation in\nmultiple geometries with different boundary conditions, and the ten-dimensional\nheat equation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:38:00 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 17:27:58 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Saha", "Priyabrata", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2011.14966", "submitter": "Harikrishnan P", "authors": "Hrithwik Shalu, Harikrishnan P, Hari Sankar CN, Akash Das, Saptarshi\n  Majumder, Arnhav Datar, Subin Mathew MS, Anugyan Das and Juned Kadiwala", "title": "Depression Status Estimation by Deep Learning based Hybrid Multi-Modal\n  Fusion Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preliminary detection of mild depression could immensely help in effective\ntreatment of the common mental health disorder. Due to the lack of proper\nawareness and the ample mix of stigmas and misconceptions present within the\nsociety, mental health status estimation has become a truly difficult task. Due\nto the immense variations in character level traits from person to person,\ntraditional deep learning methods fail to generalize in a real world setting.\nIn our study we aim to create a human allied AI workflow which could\nefficiently adapt to specific users and effectively perform in real world\nscenarios. We propose a Hybrid deep learning approach that combines the essence\nof one shot learning, classical supervised deep learning methods and human\nallied interactions for adaptation. In order to capture maximum information and\nmake efficient diagnosis video, audio, and text modalities are utilized. Our\nHybrid Fusion model achieved a high accuracy of 96.3% on the Dataset; and\nattained an AUC of 0.9682 which proves its robustness in discriminating classes\nin complex real-world scenarios making sure that no cases of mild depression\nare missed during diagnosis. The proposed method is deployed in a cloud-based\nsmartphone application for robust testing. With user-specific adaptations and\nstate of the art methodologies, we present a state-of-the-art model with user\nfriendly experience.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:38:18 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Shalu", "Hrithwik", ""], ["P", "Harikrishnan", ""], ["CN", "Hari Sankar", ""], ["Das", "Akash", ""], ["Majumder", "Saptarshi", ""], ["Datar", "Arnhav", ""], ["MS", "Subin Mathew", ""], ["Das", "Anugyan", ""], ["Kadiwala", "Juned", ""]]}, {"id": "2011.14969", "submitter": "Gaurang Sriramanan", "authors": "Gaurang Sriramanan, Sravanti Addepalli, Arya Baburaj, R. Venkatesh\n  Babu", "title": "Guided Adversarial Attack for Evaluating and Enhancing Adversarial\n  Defenses", "comments": "NeurIPS 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the development of adversarial attacks have been fundamental to\nthe progress of adversarial defense research. Efficient and effective attacks\nare crucial for reliable evaluation of defenses, and also for developing robust\nmodels. Adversarial attacks are often generated by maximizing standard losses\nsuch as the cross-entropy loss or maximum-margin loss within a constraint set\nusing Projected Gradient Descent (PGD). In this work, we introduce a relaxation\nterm to the standard loss, that finds more suitable gradient-directions,\nincreases attack efficacy and leads to more efficient adversarial training. We\npropose Guided Adversarial Margin Attack (GAMA), which utilizes function\nmapping of the clean image to guide the generation of adversaries, thereby\nresulting in stronger attacks. We evaluate our attack against multiple defenses\nand show improved performance when compared to existing attacks. Further, we\npropose Guided Adversarial Training (GAT), which achieves state-of-the-art\nperformance amongst single-step defenses by utilizing the proposed relaxation\nterm for both attack generation and training.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:39:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sriramanan", "Gaurang", ""], ["Addepalli", "Sravanti", ""], ["Baburaj", "Arya", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "2011.14985", "submitter": "G\\\"unther Waxenegger-Wilfing", "authors": "G\\\"unther Waxenegger-Wilfing, Ushnish Sengupta, Jan Martin, Wolfgang\n  Armbruster, Justin Hardi, Matthew Juniper, Michael Oschwald", "title": "Early Detection of Thermoacoustic Instabilities in a Cryogenic Rocket\n  Thrust Chamber using Combustion Noise Features and Machine Learning", "comments": null, "journal-ref": null, "doi": "10.1063/5.0038817", "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combustion instabilities are particularly problematic for rocket thrust\nchambers because of their high energy release rates and their operation close\nto the structural limits. In the last decades, progress has been made in\npredicting high amplitude combustion instabilities but still, no reliable\nprediction ability is given. Reliable early warning signals are the main\nrequirement for active combustion control systems. In this paper, we present a\ndata-driven method for the early detection of thermoacoustic instabilities.\nRecurrence quantification analysis is used to calculate characteristic\ncombustion features from short-length time series of dynamic pressure sensor\ndata. Features like the recurrence rate are used to train support vector\nmachines to detect the onset of an instability a few hundred milliseconds in\nadvance. The performance of the proposed method is investigated on experimental\ndata from a representative LOX/H$_2$ research thrust chamber. In most cases,\nthe method is able to timely predict two types of thermoacoustic instabilities\non test data not used for training. The results are compared with\nstate-of-the-art early warning indicators.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 17:30:00 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Waxenegger-Wilfing", "G\u00fcnther", ""], ["Sengupta", "Ushnish", ""], ["Martin", "Jan", ""], ["Armbruster", "Wolfgang", ""], ["Hardi", "Justin", ""], ["Juniper", "Matthew", ""], ["Oschwald", "Michael", ""]]}, {"id": "2011.14992", "submitter": "Haifeng Li", "authors": "Jiawei Zhu, Xin Han, Hanhan Deng, Chao Tao, Ling Zhao, Lin Tao,\n  Haifeng Li", "title": "KST-GCN: A Knowledge-Driven Spatial-Temporal Graph Convolutional Network\n  for Traffic Forecasting", "comments": "11 pages, 17 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When considering the spatial and temporal features of traffic, capturing the\nimpacts of various external factors on travel is an important step towards\nachieving accurate traffic forecasting. The impacts of external factors on the\ntraffic flow have complex correlations. However, existing studies seldom\nconsider external factors or neglecting the effect of the complex correlations\namong external factors on traffic. Intuitively, knowledge graphs can naturally\ndescribe these correlations, but knowledge graphs and traffic networks are\nessentially heterogeneous networks; thus, it is a challenging problem to\nintegrate the information in both networks. We propose a knowledge\nrepresentation-driven traffic forecasting method based on spatiotemporal graph\nconvolutional networks. We first construct a city knowledge graph for traffic\nforecasting, then use KS-Cells to combine the information from the knowledge\ngraph and the traffic network, and finally, capture the temporal changes of the\ntraffic state with GRU. Testing on real-world datasets shows that the KST-GCN\nhas higher accuracy than the baseline traffic forecasting methods at various\nprediction horizons. We provide a new way to integrate knowledge and the\nspatiotemporal features of data for traffic forecasting tasks. Without any loss\nof generality, the proposed method can also be extended to other spatiotemporal\nforecasting tasks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 14:15:52 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Zhu", "Jiawei", ""], ["Han", "Xin", ""], ["Deng", "Hanhan", ""], ["Tao", "Chao", ""], ["Zhao", "Ling", ""], ["Tao", "Lin", ""], ["Li", "Haifeng", ""]]}, {"id": "2011.15000", "submitter": "Abhijeet Patil", "authors": "Abhijeet Patil, Mohd. Talha, Aniket Bhatia, Nikhil Cherian Kurian,\n  Sammed Mangale, Sunil Patel, Amit Sethi", "title": "Fast, Self Supervised, Fully Convolutional Color Normalization of H&E\n  Stained Images", "comments": "--", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Performance of deep learning algorithms decreases drastically if the data\ndistributions of the training and testing sets are different. Due to variations\nin staining protocols, reagent brands, and habits of technicians, color\nvariation in digital histopathology images is quite common. Color variation\ncauses problems for the deployment of deep learning-based solutions for\nautomatic diagnosis system in histopathology. Previously proposed color\nnormalization methods consider a small patch as a reference for normalization,\nwhich creates artifacts on out-of-distribution source images. These methods are\nalso slow as most of the computation is performed on CPUs instead of the GPUs.\nWe propose a color normalization technique, which is fast during its\nself-supervised training as well as inference. Our method is based on a\nlightweight fully-convolutional neural network and can be easily attached to a\ndeep learning-based pipeline as a pre-processing block. For classification and\nsegmentation tasks on CAMELYON17 and MoNuSeg datasets respectively, the\nproposed method is faster and gives a greater increase in accuracy than the\nstate of the art methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:05:58 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Patil", "Abhijeet", ""], ["Talha", "Mohd.", ""], ["Bhatia", "Aniket", ""], ["Kurian", "Nikhil Cherian", ""], ["Mangale", "Sammed", ""], ["Patel", "Sunil", ""], ["Sethi", "Amit", ""]]}, {"id": "2011.15001", "submitter": "Morgane Menz", "authors": "Morgane Menz, Sylvain Dubreuil, J\\'er\\^ome Morio, Christian Gogu,\n  Nathalie Bartoli and Marie Chiron", "title": "Variance based sensitivity analysis for Monte Carlo and importance\n  sampling reliability assessment with Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running a reliability analysis on engineering problems involving complex\nnumerical models can be computationally very expensive, requiring advanced\nsimulation methods to reduce the overall numerical cost. Gaussian process based\nactive learning methods for reliability analysis have emerged as a promising\nway for reducing this computational cost. The learning phase of these methods\nconsists in building a Gaussian process surrogate model of the performance\nfunction and using the uncertainty structure of the Gaussian process to enrich\niteratively this surrogate model. For that purpose a learning criterion has to\nbe defined. Then, the estimation of the probability of failure is typically\nobtained by a classification of a population evaluated on the final surrogate\nmodel. Hence, the estimator of the probability of failure holds two different\nuncertainty sources related to the surrogate model approximation and to the\nsampling based integration technique. In this paper, we propose a methodology\nto quantify the sensitivity of the probability of failure estimator to both\nuncertainty sources. This analysis also enables to control the whole error\nassociated to the failure probability estimate and thus provides an accuracy\ncriterion on the estimation. Thus, an active learning approach integrating this\nanalysis to reduce the main source of error and stopping when the global\nvariability is sufficiently low is introduced. The approach is proposed for\nboth a Monte Carlo based method as well as an importance sampling based method,\nseeking to improve the estimation of rare event probabilities. Performance of\nthe proposed strategy is then assessed on several examples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:06:28 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Menz", "Morgane", ""], ["Dubreuil", "Sylvain", ""], ["Morio", "J\u00e9r\u00f4me", ""], ["Gogu", "Christian", ""], ["Bartoli", "Nathalie", ""], ["Chiron", "Marie", ""]]}, {"id": "2011.15007", "submitter": "Brady Neal", "authors": "Brady Neal, Chin-Wei Huang, Sunand Raghupathi", "title": "RealCause: Realistic Causal Inference Benchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many different causal effect estimators in causal inference.\nHowever, it is unclear how to choose between these estimators because there is\nno ground-truth for causal effects. A commonly used option is to simulate\nsynthetic data, where the ground-truth is known. However, the best causal\nestimators on synthetic data are unlikely to be the best causal estimators on\nreal data. An ideal benchmark for causal estimators would both (a) yield\nground-truth values of the causal effects and (b) be representative of real\ndata. Using flexible generative models, we provide a benchmark that both yields\nground-truth and is realistic. Using this benchmark, we evaluate over 1500\ndifferent causal estimators and provide evidence that it is rational to choose\nhyperparameters for causal estimators using predictive metrics.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:12:18 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 14:14:37 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Neal", "Brady", ""], ["Huang", "Chin-Wei", ""], ["Raghupathi", "Sunand", ""]]}, {"id": "2011.15014", "submitter": "Wanxin Jin", "authors": "Wanxin Jin, Todd D. Murphey, Shaoshuai Mou", "title": "Learning from Incremental Directional Corrections", "comments": "Please find the codes and games at\n  https://github.com/wanxinjin/Learning-from-Directional-Corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a technique which enables a robot to learn a control\nobjective function incrementally from human user's corrections. The human's\ncorrections can be as simple as directional corrections -- corrections that\nindicate the direction of a control change without indicating its magnitude --\napplied at some time instances during the robot's motion. We only assume that\neach of the human's corrections, regardless of its magnitude, points in a\ndirection that improves the robot's current motion relative to an implicit\nobjective function. The proposed method uses the direction of a correction to\nupdate the estimate of the objective function based on a cutting plane\ntechnique. We establish the theoretical results to show that this process of\nincremental correction and update guarantees convergence of the learned\nobjective function to the implicit one. The method is validated by both\nsimulations and two human-robot games, where human players teach a 2-link robot\narm and a 6-DoF quadrotor system for motion planning in environments with\nobstacles.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:16:39 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Jin", "Wanxin", ""], ["Murphey", "Todd D.", ""], ["Mou", "Shaoshuai", ""]]}, {"id": "2011.15031", "submitter": "Siavash Golkar", "authors": "Siavash Golkar, David Lipshutz, Yanis Bahroun, Anirvan M. Sengupta,\n  Dmitri B. Chklovskii", "title": "A biologically plausible neural network for local supervision in\n  cortical microcircuits", "comments": "Abstract presented at the NeurIPS 2020 workshop \"Beyond\n  Backpropagation\". arXiv admin note: text overlap with arXiv:2010.12660", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The backpropagation algorithm is an invaluable tool for training artificial\nneural networks; however, because of a weight sharing requirement, it does not\nprovide a plausible model of brain function. Here, in the context of a\ntwo-layer network, we derive an algorithm for training a neural network which\navoids this problem by not requiring explicit error computation and\nbackpropagation. Furthermore, our algorithm maps onto a neural network that\nbears a remarkable resemblance to the connectivity structure and learning rules\nof the cortex. We find that our algorithm empirically performs comparably to\nbackprop on a number of datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:35:22 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Golkar", "Siavash", ""], ["Lipshutz", "David", ""], ["Bahroun", "Yanis", ""], ["Sengupta", "Anirvan M.", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "2011.15038", "submitter": "Rafi Trad", "authors": "Rafi Trad, Myra Spiliopoulou", "title": "A Framework for Authorial Clustering of Shorter Texts in Latent Semantic\n  Spaces", "comments": "8 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Authorial clustering involves the grouping of documents written by the same\nauthor or team of authors without any prior positive examples of an author's\nwriting style or thematic preferences. For authorial clustering on shorter\ntexts (paragraph-length texts that are typically shorter than conventional\ndocuments), the document representation is particularly important: very\nhigh-dimensional feature spaces lead to data sparsity and suffer from serious\nconsequences like the curse of dimensionality, while feature selection may lead\nto information loss. We propose a high-level framework which utilizes a compact\ndata representation in a latent feature space derived with non-parametric topic\nmodeling. Authorial clusters are identified thereafter in two scenarios: (a)\nfully unsupervised and (b) semi-supervised where a small number of shorter\ntexts are known to belong to the same author (must-link constraints) or not\n(cannot-link constraints). We report on experiments with 120 collections in\nthree languages and two genres and show that the topic-based latent feature\nspace provides a promising level of performance while reducing the\ndimensionality by a factor of 1500 compared to state-of-the-arts. We also\ndemonstrate that, while prior knowledge on the precise number of authors (i.e.\nauthorial clusters) does not contribute much to additional quality, little\nknowledge on constraints in authorial clusters memberships leads to clear\nperformance improvements in front of this difficult task. Thorough\nexperimentation with standard metrics indicates that there still remains an\nample room for improvement for authorial clustering, especially with shorter\ntexts\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:39:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Trad", "Rafi", ""], ["Spiliopoulou", "Myra", ""]]}, {"id": "2011.15039", "submitter": "Runzhong Wang", "authors": "Runzhong Wang, Tianqi Zhang, Tianshu Yu, Junchi Yan, Xiaokang Yang", "title": "Combinatorial Learning of Graph Edit Distance via Dynamic Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Edit Distance (GED) is a popular similarity measurement for pairwise\ngraphs and it also refers to the recovery of the edit path from the source\ngraph to the target graph. Traditional A* algorithm suffers scalability issues\ndue to its exhaustive nature, whose search heuristics heavily rely on human\nprior knowledge. This paper presents a hybrid approach by combing the\ninterpretability of traditional search-based techniques for producing the edit\npath, as well as the efficiency and adaptivity of deep embedding models to\nachieve a cost-effective GED solver. Inspired by dynamic programming,\nnode-level embedding is designated in a dynamic reuse fashion and suboptimal\nbranches are encouraged to be pruned. To this end, our method can be readily\nintegrated into A* procedure in a dynamic fashion, as well as significantly\nreduce the computational burden with a learned heuristic. Experimental results\non different graph datasets show that our approach can remarkably ease the\nsearch process of A* without sacrificing much accuracy. To our best knowledge,\nthis work is also the first deep learning-based GED method for recovering the\nedit path.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:41:02 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 02:05:29 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Wang", "Runzhong", ""], ["Zhang", "Tianqi", ""], ["Yu", "Tianshu", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""]]}, {"id": "2011.15045", "submitter": "Sreyas Mohan", "authors": "Dev Yashpal Sheth, Sreyas Mohan, Joshua L. Vincent, Ramon Manzorro,\n  Peter A. Crozier, Mitesh M. Khapra, Eero P. Simoncelli, Carlos\n  Fernandez-Granda", "title": "Unsupervised Deep Video Denoising", "comments": "Dev and Sreyas contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) currently achieve state-of-the-art\nperformance in denoising videos. They are typically trained with supervision,\nminimizing the error between the network output and ground-truth clean videos.\nHowever, in many applications, such as microscopy, noiseless videos are not\navailable. To address these cases, we build on recent advances in unsupervised\nstill image denoising to develop an Unsupervised Deep Video Denoiser (UDVD).\nUDVD is shown to perform competitively with current state-of-the-art supervised\nmethods on benchmark datasets, even when trained only on a single short noisy\nvideo sequence. Experiments on fluorescence-microscopy and electron-microscopy\ndata illustrate the promise of our approach for imaging modalities where\nground-truth clean data is generally not available. In addition, we study the\nmechanisms used by trained CNNs to perform video denoising. An analysis of the\ngradient of the network output with respect to its input reveals that these\nnetworks perform spatio-temporal filtering that is adapted to the particular\nspatial structures and motion of the underlying content. We interpret this as\nan implicit and highly effective form of motion compensation, a widely used\nparadigm in traditional video denoising, compression, and analysis. Code and\niPython notebooks for our analysis are available in\nhttps://sreyas-mohan.github.io/udvd/ .\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:45:08 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 04:25:50 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sheth", "Dev Yashpal", ""], ["Mohan", "Sreyas", ""], ["Vincent", "Joshua L.", ""], ["Manzorro", "Ramon", ""], ["Crozier", "Peter A.", ""], ["Khapra", "Mitesh M.", ""], ["Simoncelli", "Eero P.", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "2011.15050", "submitter": "Ivan Stelmakh", "authors": "Ivan Stelmakh, Nihar B. Shah, Aarti Singh, and Hal Daum\\'e III", "title": "A Novice-Reviewer Experiment to Address Scarcity of Qualified Reviewers\n  in Large Conferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conference peer review constitutes a human-computation process whose\nimportance cannot be overstated: not only it identifies the best submissions\nfor acceptance, but, ultimately, it impacts the future of the whole research\narea by promoting some ideas and restraining others. A surge in the number of\nsubmissions received by leading AI conferences has challenged the\nsustainability of the review process by increasing the burden on the pool of\nqualified reviewers which is growing at a much slower rate. In this work, we\nconsider the problem of reviewer recruiting with a focus on the scarcity of\nqualified reviewers in large conferences. Specifically, we design a procedure\nfor (i) recruiting reviewers from the population not typically covered by major\nconferences and (ii) guiding them through the reviewing pipeline. In\nconjunction with ICML 2020 -- a large, top-tier machine learning conference --\nwe recruit a small set of reviewers through our procedure and compare their\nperformance with the general population of ICML reviewers. Our experiment\nreveals that a combination of the recruiting and guiding mechanisms allows for\na principled enhancement of the reviewer pool and results in reviews of\nsuperior quality compared to the conventional pool of reviews as evaluated by\nsenior members of the program committee (meta-reviewers).\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:48:55 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Stelmakh", "Ivan", ""], ["Shah", "Nihar B.", ""], ["Singh", "Aarti", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "2011.15056", "submitter": "Jakub Tomczak", "authors": "Jakub M. Tomczak", "title": "General Invertible Transformations for Flow-based Generative Modeling", "comments": "Code: https://github.com/jmtomczak/git_flow, accepted to INNF+ 2021\n  at ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new class of invertible transformations with an\napplication to flow-based generative models. We indicate that many well-known\ninvertible transformations in reversible logic and reversible neural networks\ncould be derived from our proposition. Next, we propose two new coupling layers\nthat are important building blocks of flow-based generative models. In the\nexperiments on digit data, we present how these new coupling layers could be\nused in Integer Discrete Flows (IDF), and that they achieve better results than\nstandard coupling layers used in IDF and RealNVP.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:54:43 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 13:04:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tomczak", "Jakub M.", ""]]}, {"id": "2011.15069", "submitter": "R\\'emy Brossard", "authors": "R\\'emy Brossard, Oriel Frigo, David Dehaene", "title": "Graph convolutions that can finally model local structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite quick progress in the last few years, recent studies have shown that\nmodern graph neural networks can still fail at very simple tasks, like\ndetecting small cycles. This hints at the fact that current networks fail to\ncatch information about the local structure, which is problematic if the\ndownstream task heavily relies on graph substructure analysis, as in the\ncontext of chemistry. We propose a very simple correction to the now standard\nGIN convolution that enables the network to detect small cycles with nearly no\ncost in terms of computation time and number of parameters. Tested on real life\nmolecule property datasets, our model consistently improves performance on\nlarge multi-tasked datasets over all baselines, both globally and on a per-task\nsetting.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:05:22 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 07:58:32 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Brossard", "R\u00e9my", ""], ["Frigo", "Oriel", ""], ["Dehaene", "David", ""]]}, {"id": "2011.15079", "submitter": "Christian Diller", "authors": "Christian Diller, Thomas Funkhouser, Angela Dai", "title": "Forecasting Characteristic 3D Poses of Human Actions", "comments": "Paper Video: https://youtu.be/vSxJg9z7cAM Project Page:\n  https://charposes.christian-diller.de/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the task of forecasting characteristic 3D poses: from a monocular\nvideo observation of a person, to predict a future 3D pose of that person in a\nlikely action-defining, characteristic pose - for instance, from observing a\nperson reaching for a banana, predict the pose of the person eating the banana.\nPrior work on human motion prediction estimates future poses at fixed time\nintervals. Although easy to define, this frame-by-frame formulation confounds\ntemporal and intentional aspects of human action. Instead, we define a\nsemantically meaningful pose prediction task that decouples the predicted pose\nfrom time, taking inspiration from goal-directed behavior. To predict\ncharacteristic poses, we propose a probabilistic approach that first models the\npossible multi-modality in the distribution of likely characteristic poses. It\nthen samples future pose hypotheses from the predicted distribution in an\nautoregressive fashion to model dependencies between joints and finally\noptimizes the resulting pose with bone length and angle constraints. To\nevaluate our method, we construct a dataset of manually annotated\ncharacteristic 3D poses. Our experiments with this dataset suggest that our\nproposed probabilistic approach outperforms state-of-the-art methods by 22% on\naverage.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:20:17 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 17:58:08 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Diller", "Christian", ""], ["Funkhouser", "Thomas", ""], ["Dai", "Angela", ""]]}, {"id": "2011.15083", "submitter": "Ivan Stelmakh", "authors": "Ivan Stelmakh, Charvi Rastogi, Nihar B. Shah, Aarti Singh, and Hal\n  Daum\\'e III", "title": "A Large Scale Randomized Controlled Trial on Herding in Peer-Review\n  Discussions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is the backbone of academia and humans constitute a cornerstone\nof this process, being responsible for reviewing papers and making the final\nacceptance/rejection decisions. Given that human decision making is known to be\nsusceptible to various cognitive biases, it is important to understand which\n(if any) biases are present in the peer-review process and design the pipeline\nsuch that the impact of these biases is minimized. In this work, we focus on\nthe dynamics of between-reviewers discussions and investigate the presence of\nherding behaviour therein. In that, we aim to understand whether reviewers and\nmore senior decision makers get disproportionately influenced by the first\nargument presented in the discussion when (in case of reviewers) they form an\nindependent opinion about the paper before discussing it with others.\nSpecifically, in conjunction with the review process of ICML 2020 -- a large,\ntop tier machine learning conference -- we design and execute a randomized\ncontrolled trial with the goal of testing for the conditional causal effect of\nthe discussion initiator's opinion on the outcome of a paper.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:23:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Stelmakh", "Ivan", ""], ["Rastogi", "Charvi", ""], ["Shah", "Nihar B.", ""], ["Singh", "Aarti", ""], ["Daum\u00e9", "Hal", "III"]]}, {"id": "2011.15084", "submitter": "Yecheng Ma", "authors": "Yecheng Jason Ma, Jeevana Priya Inala, Dinesh Jayaraman, Osbert\n  Bastani", "title": "Diverse Sampling for Normalizing Flow Based Trajectory Forecasting", "comments": "Technical report, 18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For autonomous cars to drive safely and effectively, they must anticipate the\nstochastic future trajectories of other agents in the scene, such as\npedestrians and other cars. Forecasting such complex multi-modal distributions\nrequires powerful probabilistic approaches. Normalizing flows have recently\nemerged as an attractive tool to model such distributions. However, when\ngenerating trajectory predictions from a flow model, a key drawback is that\nindependent samples often do not adequately capture all the modes in the\nunderlying distribution. We propose Diversity Sampling for Flow (DSF), a method\nfor improving the quality and the diversity of trajectory samples from a\npre-trained flow model. Rather than producing individual samples, DSF produces\na set of trajectories in one shot. Given a pre-trained forecasting flow model,\nwe train DSF using gradients from the model, to optimize an objective function\nthat rewards high likelihood for individual trajectories in the predicted set,\ntogether with high spatial separation between trajectories. DSF is easy to\nimplement, and we show that it offers a simple plug-in improvement for several\nexisting flow-based forecasting models, achieving state-of-art results on two\nchallenging vehicle and pedestrian forecasting benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:23:29 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ma", "Yecheng Jason", ""], ["Inala", "Jeevana Priya", ""], ["Jayaraman", "Dinesh", ""], ["Bastani", "Osbert", ""]]}, {"id": "2011.15091", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Yoshua Bengio", "title": "Inductive Biases for Deep Learning of Higher-Level Cognition", "comments": "This document contains a review of authors research as part of the\n  requirement of AG's predoctoral exam, an overview of the main contributions\n  of the authors few recent papers (co-authored with several other co-authors)\n  as well as a vision of proposed future research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fascinating hypothesis is that human and animal intelligence could be\nexplained by a few principles (rather than an encyclopedic list of heuristics).\nIf that hypothesis was correct, we could more easily both understand our own\nintelligence and build intelligent machines. Just like in physics, the\nprinciples themselves would not be sufficient to predict the behavior of\ncomplex systems like brains, and substantial computation might be needed to\nsimulate human-like intelligence. This hypothesis would suggest that studying\nthe kind of inductive biases that humans and animals exploit could help both\nclarify these principles and provide inspiration for AI research and\nneuroscience theories. Deep learning already exploits several key inductive\nbiases, and this work considers a larger list, focusing on those which concern\nmostly higher-level and sequential conscious processing. The objective of\nclarifying these particular principles is that they could potentially help us\nbuild AI systems benefiting from humans' abilities in terms of flexible\nout-of-distribution and systematic generalization, which is currently an area\nwhere a large gap exists between state-of-the-art machine learning and human\nintelligence.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:29:25 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 17:51:00 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 21:54:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2011.15095", "submitter": "Sneh Pandya", "authors": "Joshua Yao-Yu Lin, Sneh Pandya, Devanshi Pratap, Xin Liu, Matias\n  Carrasco Kind", "title": "AGNet: Weighing Black Holes with Machine Learning", "comments": "5 pages, 3 figures, 1 table. Accepted to the Machine Learning and the\n  Physical Sciences Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.GA astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supermassive black holes (SMBHs) are ubiquitously found at the centers of\nmost galaxies. Measuring SMBH mass is important for understanding the origin\nand evolution of SMBHs. However, traditional methods require spectral data\nwhich is expensive to gather. To solve this problem, we present an algorithm\nthat weighs SMBHs using quasar light time series, circumventing the need for\nexpensive spectra. We train, validate, and test neural networks that directly\nlearn from the Sloan Digital Sky Survey (SDSS) Stripe 82 data for a sample of\n$9,038$ spectroscopically confirmed quasars to map out the nonlinear encoding\nbetween black hole mass and multi-color optical light curves. We find a\n1$\\sigma$ scatter of 0.35 dex between the predicted mass and the fiducial\nvirial mass based on SDSS single-epoch spectra. Our results have direct\nimplications for efficient applications with future observations from the Vera\nRubin Observatory.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:30:24 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 06:15:26 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Lin", "Joshua Yao-Yu", ""], ["Pandya", "Sneh", ""], ["Pratap", "Devanshi", ""], ["Liu", "Xin", ""], ["Kind", "Matias Carrasco", ""]]}, {"id": "2011.15102", "submitter": "Pengtao Xie", "authors": "Xuefeng Du, Haochen Zhang, Pengtao Xie", "title": "Learning by Passing Tests, with Application to Neural Architecture\n  Search", "comments": "arXiv admin note: substantial text overlap with arXiv:2012.04863,\n  arXiv:2012.12502, arXiv:2012.12899", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning through tests is a broadly used methodology in human learning and\nshows great effectiveness in improving learning outcome: a sequence of tests\nare made with increasing levels of difficulty; the learner takes these tests to\nidentify his/her weak points in learning and continuously addresses these weak\npoints to successfully pass these tests. We are interested in investigating\nwhether this powerful learning technique can be borrowed from humans to improve\nthe learning abilities of machines. We propose a novel learning approach called\nlearning by passing tests (LPT). In our approach, a tester model creates\nincreasingly more-difficult tests to evaluate a learner model. The learner\ntries to continuously improve its learning ability so that it can successfully\npass however difficult tests created by the tester. We propose a multi-level\noptimization framework to formulate LPT, where the tester learns to create\ndifficult and meaningful tests and the learner learns to pass these tests. We\ndevelop an efficient algorithm to solve the LPT problem. Our method is applied\nfor neural architecture search and achieves significant improvement over\nstate-of-the-art baselines on CIFAR-100, CIFAR-10, and ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:33:34 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 03:43:01 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Du", "Xuefeng", ""], ["Zhang", "Haochen", ""], ["Xie", "Pengtao", ""]]}, {"id": "2011.15110", "submitter": "Thomas O'Leary-Roseberry", "authors": "Thomas O'Leary-Roseberry, Umberto Villa, Peng Chen, and Omar Ghattas", "title": "Derivative-Informed Projected Neural Networks for High-Dimensional\n  Parametric Maps Governed by PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many-query problems, arising from uncertainty quantification, Bayesian\ninversion, Bayesian optimal experimental design, and optimization under\nuncertainty-require numerous evaluations of a parameter-to-output map. These\nevaluations become prohibitive if this parametric map is high-dimensional and\ninvolves expensive solution of partial differential equations (PDEs). To tackle\nthis challenge, we propose to construct surrogates for high-dimensional\nPDE-governed parametric maps in the form of projected neural networks that\nparsimoniously capture the geometry and intrinsic low-dimensionality of these\nmaps. Specifically, we compute Jacobians of these PDE-based maps, and project\nthe high-dimensional parameters onto a low-dimensional derivative-informed\nactive subspace; we also project the possibly high-dimensional outputs onto\ntheir principal subspace. This exploits the fact that many high-dimensional\nPDE-governed parametric maps can be well-approximated in low-dimensional\nparameter and output subspace. We use the projection basis vectors in the\nactive subspace as well as the principal output subspace to construct the\nweights for the first and last layers of the neural network, respectively. This\nfrees us to train the weights in only the low-dimensional layers of the neural\nnetwork. The architecture of the resulting neural network captures to first\norder, the low-dimensional structure and geometry of the parametric map. We\ndemonstrate that the proposed projected neural network achieves greater\ngeneralization accuracy than a full neural network, especially in the limited\ntraining data regime afforded by expensive PDE-based parametric maps. Moreover,\nwe show that the number of degrees of freedom of the inner layers of the\nprojected network is independent of the parameter and output dimensions, and\nhigh accuracy can be achieved with weight dimension independent of the\ndiscretization dimension.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:46:40 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 22:08:58 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["O'Leary-Roseberry", "Thomas", ""], ["Villa", "Umberto", ""], ["Chen", "Peng", ""], ["Ghattas", "Omar", ""]]}, {"id": "2011.15119", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Yunrong Guo, Maria Shugrina, Sanja Fidler", "title": "UniCon: Universal Neural Controller For Physics-based Character Motion", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The field of physics-based animation is gaining importance due to the\nincreasing demand for realism in video games and films, and has recently seen\nwide adoption of data-driven techniques, such as deep reinforcement learning\n(RL), which learn control from (human) demonstrations. While RL has shown\nimpressive results at reproducing individual motions and interactive\nlocomotion, existing methods are limited in their ability to generalize to new\nmotions and their ability to compose a complex motion sequence interactively.\nIn this paper, we propose a physics-based universal neural controller (UniCon)\nthat learns to master thousands of motions with different styles by learning on\nlarge-scale motion datasets. UniCon is a two-level framework that consists of a\nhigh-level motion scheduler and an RL-powered low-level motion executor, which\nis our key innovation. By systematically analyzing existing multi-motion RL\nframeworks, we introduce a novel objective function and training techniques\nwhich make a significant leap in performance. Once trained, our motion executor\ncan be combined with different high-level schedulers without the need for\nretraining, enabling a variety of real-time interactive applications. We show\nthat UniCon can support keyboard-driven control, compose motion sequences drawn\nfrom a large pool of locomotion and acrobatics skills and teleport a person\ncaptured on video to a physics-based virtual avatar. Numerical and qualitative\nresults demonstrate a significant improvement in efficiency, robustness and\ngeneralizability of UniCon over prior state-of-the-art, showcasing\ntransferability to unseen motions, unseen humanoid models and unseen\nperturbation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:51:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Tingwu", ""], ["Guo", "Yunrong", ""], ["Shugrina", "Maria", ""], ["Fidler", "Sanja", ""]]}, {"id": "2011.15122", "submitter": "Willem Van Jaarsveld", "authors": "Willem van Jaarsveld", "title": "Model-based controlled learning of MDP policies with an application to\n  lost-sales inventory control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent literature established that neural networks can represent good MDP\npolicies across a range of stochastic dynamic models in supply chain and\nlogistics. To overcome limitations of the model-free algorithms typically\nemployed to learn/find such neural network policies, a model-based algorithm is\nproposed that incorporates variance reduction techniques. For the classical\nlost sales inventory model, the algorithm learns neural network policies that\nare superior to those learned using model-free algorithms, while also\noutperforming heuristic benchmarks. The algorithm may be an interesting\ncandidate to apply to other stochastic dynamic problems in supply chain and\nlogistics.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 18:53:08 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["van Jaarsveld", "Willem", ""]]}]