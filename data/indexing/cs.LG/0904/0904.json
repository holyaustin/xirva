[{"id": "0904.0545", "submitter": "Petar Kormushev", "authors": "Petar Kormushev, Kohei Nomoto, Fangyan Dong, Kaoru Hirota", "title": "Time Hopping technique for faster reinforcement learning in simulations", "comments": "This preprint has been withdrawn by the author for revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This preprint has been withdrawn by the author for revision\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 10:38:06 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2011 15:24:24 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Kormushev", "Petar", ""], ["Nomoto", "Kohei", ""], ["Dong", "Fangyan", ""], ["Hirota", "Kaoru", ""]]}, {"id": "0904.0546", "submitter": "Petar Kormushev", "authors": "Petar Kormushev, Kohei Nomoto, Fangyan Dong, Kaoru Hirota", "title": "Eligibility Propagation to Speed up Time Hopping for Reinforcement\n  Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mechanism called Eligibility Propagation is proposed to speed up the Time\nHopping technique used for faster Reinforcement Learning in simulations.\nEligibility Propagation provides for Time Hopping similar abilities to what\neligibility traces provide for conventional Reinforcement Learning. It\npropagates values from one state to all of its temporal predecessors using a\nstate transitions graph. Experiments on a simulated biped crawling robot\nconfirm that Eligibility Propagation accelerates the learning process more than\n3 times.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 10:42:28 GMT"}], "update_date": "2009-04-06", "authors_parsed": [["Kormushev", "Petar", ""], ["Nomoto", "Kohei", ""], ["Dong", "Fangyan", ""], ["Hirota", "Kaoru", ""]]}, {"id": "0904.0643", "submitter": "David N. Levin", "authors": "David N. Levin (University of Chicago)", "title": "Performing Nonlinear Blind Source Separation with Signal Invariants", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": "10.1109/TSP.2009.2034916", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a time series of multicomponent measurements x(t), the usual objective\nof nonlinear blind source separation (BSS) is to find a \"source\" time series\ns(t), comprised of statistically independent combinations of the measured\ncomponents. In this paper, the source time series is required to have a density\nfunction in (s,ds/dt)-space that is equal to the product of density functions\nof individual components. This formulation of the BSS problem has a solution\nthat is unique, up to permutations and component-wise transformations.\nSeparability is shown to impose constraints on certain locally invariant\n(scalar) functions of x, which are derived from local higher-order correlations\nof the data's velocity dx/dt. The data are separable if and only if they\nsatisfy these constraints, and, if the constraints are satisfied, the sources\ncan be explicitly constructed from the data. The method is illustrated by using\nit to separate two speech-like sounds recorded with a single microphone.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 19:29:47 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Levin", "David N.", "", "University of Chicago"]]}, {"id": "0904.0648", "submitter": "Nisheeth Srivastava", "authors": "Nisheeth Srivastava", "title": "Evolvability need not imply learnability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We show that Boolean functions expressible as monotone disjunctive normal\nforms are PAC-evolvable under a uniform distribution on the Boolean cube if the\nhypothesis size is allowed to remain fixed. We further show that this result is\ninsufficient to prove the PAC-learnability of monotone Boolean functions,\nthereby demonstrating a counter-example to a recent claim to the contrary. We\nfurther discuss scenarios wherein evolvability and learnability will coincide\nas well as scenarios under which they differ. The implications of the latter\ncase on the prospects of learning in complex hypothesis spaces is briefly\nexamined.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 20:30:24 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Srivastava", "Nisheeth", ""]]}, {"id": "0904.0776", "submitter": "Vivien Robinet", "authors": "Vivien Robinet (Leibniz - IMAG, TIMC), Gilles Bisson (Leibniz - IMAG,\n  TIMC), Mirta B. Gordon (Leibniz - IMAG, TIMC), Beno\\^it Lemaire (Leibniz -\n  IMAG, TIMC)", "title": "Induction of High-level Behaviors from Problem-solving Traces using\n  Machine Learning Tools", "comments": null, "journal-ref": "IEEE Intelligent Systems 22, 4 (2007) 22", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies machine learning techniques to student modeling. It\npresents a method for discovering high-level student behaviors from a very\nlarge set of low-level traces corresponding to problem-solving actions in a\nlearning environment. Basic actions are encoded into sets of domain-dependent\nattribute-value patterns called cases. Then a domain-independent hierarchical\nclustering identifies what we call general attitudes, yielding automatic\ndiagnosis expressed in natural language, addressed in principle to teachers.\nThe method can be applied to individual students or to entire groups, like a\nclass. We exhibit examples of this system applied to thousands of students'\nactions in the domain of algebraic transformations.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2009 14:21:49 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Robinet", "Vivien", "", "Leibniz - IMAG, TIMC"], ["Bisson", "Gilles", "", "Leibniz - IMAG,\n  TIMC"], ["Gordon", "Mirta B.", "", "Leibniz - IMAG, TIMC"], ["Lemaire", "Beno\u00eet", "", "Leibniz -\n  IMAG, TIMC"]]}, {"id": "0904.0814", "submitter": "Ashish Rastogi", "authors": "Corinna Cortes, Mehryar Mohri, Dmitry Pechyony, Ashish Rastogi", "title": "Stability Analysis and Learning Bounds for Transductive Regression\n  Algorithms", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses the notion of algorithmic stability to derive novel\ngeneralization bounds for several families of transductive regression\nalgorithms, both by using convexity and closed-form solutions. Our analysis\nhelps compare the stability of these algorithms. It also shows that a number of\nwidely used transductive regression algorithms are in fact unstable. Finally,\nit reports the results of experiments with local transductive regression\ndemonstrating the benefit of our stability bounds for model selection, for one\nof the algorithms, in particular for determining the radius of the local\nneighborhood used by the algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2009 20:08:44 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Cortes", "Corinna", ""], ["Mohri", "Mehryar", ""], ["Pechyony", "Dmitry", ""], ["Rastogi", "Ashish", ""]]}, {"id": "0904.1227", "submitter": "Luis Rademacher", "authors": "Navin Goyal, Luis Rademacher", "title": "Learning convex bodies is hard", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that learning a convex body in $\\RR^d$, given random samples from the\nbody, requires $2^{\\Omega(\\sqrt{d/\\eps})}$ samples. By learning a convex body\nwe mean finding a set having at most $\\eps$ relative symmetric difference with\nthe input body. To prove the lower bound we construct a hard to learn family of\nconvex bodies. Our construction of this family is very simple and based on\nerror correcting codes.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2009 21:15:42 GMT"}], "update_date": "2009-04-09", "authors_parsed": [["Goyal", "Navin", ""], ["Rademacher", "Luis", ""]]}, {"id": "0904.1579", "submitter": "Fedor Zhdanov", "authors": "Fedor Zhdanov, Vladimir Vovk, Brian Burford, Dmitry Devetyarov, Ilia\n  Nouretdinov and Alex Gammerman", "title": "Online prediction of ovarian cancer", "comments": "11 pages, 4 figures, uses llncs.cls", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply computer learning methods to diagnosing ovarian cancer\nusing the level of the standard biomarker CA125 in conjunction with information\nprovided by mass-spectrometry. We are working with a new data set collected\nover a period of 7 years. Using the level of CA125 and mass-spectrometry peaks,\nour algorithm gives probability predictions for the disease. To estimate\nclassification accuracy we convert probability predictions into strict\npredictions. Our algorithm makes fewer errors than almost any linear\ncombination of the CA125 level and one peak's intensity (taken on the log\nscale). To check the power of our algorithm we use it to test the hypothesis\nthat CA125 and the peaks do not contain useful information for the prediction\nof the disease at a particular time before the diagnosis. Our algorithm\nproduces $p$-values that are better than those produced by the algorithm that\nhas been previously applied to this data set. Our conclusion is that the\nproposed algorithm is more reliable for prediction on new data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2009 18:26:36 GMT"}], "update_date": "2009-04-10", "authors_parsed": [["Zhdanov", "Fedor", ""], ["Vovk", "Vladimir", ""], ["Burford", "Brian", ""], ["Devetyarov", "Dmitry", ""], ["Nouretdinov", "Ilia", ""], ["Gammerman", "Alex", ""]]}, {"id": "0904.1700", "submitter": "Antoine Sinton", "authors": "Antoine Sinton", "title": "Recovering the state sequence of hidden Markov models using mean-field\n  approximations", "comments": "43 pages, 41 figures", "journal-ref": null, "doi": "10.1088/1742-5468/2009/07/P07026", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring the sequence of states from observations is one of the most\nfundamental problems in Hidden Markov Models. In statistical physics language,\nthis problem is equivalent to computing the marginals of a one-dimensional\nmodel with a random external field. While this task can be accomplished through\ntransfer matrix methods, it becomes quickly intractable when the underlying\nstate space is large.\n  This paper develops several low-complexity approximate algorithms to address\nthis inference problem when the state space becomes large. The new algorithms\nare based on various mean-field approximations of the transfer matrix. Their\nperformances are studied in detail on a simple realistic model for DNA\npyrosequencing.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2009 15:19:14 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2009 13:08:39 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Sinton", "Antoine", ""]]}, {"id": "0904.1888", "submitter": "Stevan Harnad", "authors": "Stevan Harnad", "title": "On Fodor on Darwin on Evolution", "comments": "21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jerry Fodor argues that Darwin was wrong about \"natural selection\" because\n(1) it is only a tautology rather than a scientific law that can support\ncounterfactuals (\"If X had happened, Y would have happened\") and because (2)\nonly minds can select. Hence Darwin's analogy with \"artificial selection\" by\nanimal breeders was misleading and evolutionary explanation is nothing but\npost-hoc historical narrative. I argue that Darwin was right on all counts.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2009 00:59:10 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Harnad", "Stevan", ""]]}, {"id": "0904.2037", "submitter": "Chunhua Shen", "authors": "Chunhua Shen and Hanxi Li", "title": "Boosting through Optimization of Margin Distributions", "comments": "9 pages. To publish/Published in IEEE Transactions on Neural\n  Networks, 21(7), July 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting has attracted much research attention in the past decade. The\nsuccess of boosting algorithms may be interpreted in terms of the margin\ntheory. Recently it has been shown that generalization error of classifiers can\nbe obtained by explicitly taking the margin distribution of the training data\ninto account. Most of the current boosting algorithms in practice usually\noptimizes a convex loss function and do not make use of the margin\ndistribution. In this work we design a new boosting algorithm, termed\nmargin-distribution boosting (MDBoost), which directly maximizes the average\nmargin and minimizes the margin variance simultaneously. This way the margin\ndistribution is optimized. A totally-corrective optimization algorithm based on\ncolumn generation is proposed to implement MDBoost. Experiments on UCI datasets\nshow that MDBoost outperforms AdaBoost and LPBoost in most cases.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2009 01:57:12 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2009 02:24:51 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2010 09:00:26 GMT"}], "update_date": "2010-01-06", "authors_parsed": [["Shen", "Chunhua", ""], ["Li", "Hanxi", ""]]}, {"id": "0904.2160", "submitter": "Debprakash Patnaik", "authors": "Debprakash Patnaik and Srivatsan Laxman and Naren Ramakrishnan", "title": "Inferring Dynamic Bayesian Networks using Frequent Episode Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Several different threads of research have been proposed for\nmodeling and mining temporal data. On the one hand, approaches such as dynamic\nBayesian networks (DBNs) provide a formal probabilistic basis to model\nrelationships between time-indexed random variables but these models are\nintractable to learn in the general case. On the other, algorithms such as\nfrequent episode mining are scalable to large datasets but do not exhibit the\nrigorous probabilistic interpretations that are the mainstay of the graphical\nmodels literature.\n  Results: We present a unification of these two seemingly diverse threads of\nresearch, by demonstrating how dynamic (discrete) Bayesian networks can be\ninferred from the results of frequent episode mining. This helps bridge the\nmodeling emphasis of the former with the counting emphasis of the latter.\nFirst, we show how, under reasonable assumptions on data characteristics and on\ninfluences of random variables, the optimal DBN structure can be computed using\na greedy, local, algorithm. Next, we connect the optimality of the DBN\nstructure with the notion of fixed-delay episodes and their counts of distinct\noccurrences. Finally, to demonstrate the practical feasibility of our approach,\nwe focus on a specific (but broadly applicable) class of networks, called\nexcitatory networks, and show how the search for the optimal DBN structure can\nbe conducted using just information from frequent episodes. Application on\ndatasets gathered from mathematical models of spiking neurons as well as real\nneuroscience datasets are presented.\n  Availability: Algorithmic implementations, simulator codebases, and datasets\nare available from our website at http://neural-code.cs.vt.edu/dbn\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2009 17:32:00 GMT"}], "update_date": "2009-04-15", "authors_parsed": [["Patnaik", "Debprakash", ""], ["Laxman", "Srivatsan", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "0904.2320", "submitter": "Sherief Abdallah", "authors": "Sherief Abdallah", "title": "Why Global Performance is a Poor Metric for Verifying Convergence of\n  Multi-agent Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental verification has been the method of choice for verifying the\nstability of a multi-agent reinforcement learning (MARL) algorithm as the\nnumber of agents grows and theoretical analysis becomes prohibitively complex.\nFor cooperative agents, where the ultimate goal is to optimize some global\nmetric, the stability is usually verified by observing the evolution of the\nglobal performance metric over time. If the global metric improves and\neventually stabilizes, it is considered a reasonable verification of the\nsystem's stability.\n  The main contribution of this note is establishing the need for better\nexperimental frameworks and measures to assess the stability of large-scale\nadaptive cooperative systems. We show an experimental case study where the\nstability of the global performance metric can be rather deceiving, hiding an\nunderlying instability in the system that later leads to a significant drop in\nperformance. We then propose an alternative metric that relies on agents' local\npolicies and show, experimentally, that our proposed metric is more effective\n(than the traditional global performance metric) in exposing the instability of\nMARL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2009 13:49:42 GMT"}], "update_date": "2009-04-16", "authors_parsed": [["Abdallah", "Sherief", ""]]}, {"id": "0904.2595", "submitter": "Mark Levene", "authors": "Mark Levene and Trevor Fenner", "title": "A Methodology for Learning Players' Styles from Game Records", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a preliminary investigation into learning a Chess player's style\nfrom game records. The method is based on attempting to learn features of a\nplayer's individual evaluation function using the method of temporal\ndifferences, with the aid of a conventional Chess engine architecture. Some\nencouraging results were obtained in learning the styles of two recent Chess\nworld champions, and we report on our attempt to use the learnt styles to\ndiscriminate between the players from game records by trying to detect who was\nplaying white and who was playing black. We also discuss some limitations of\nour approach and propose possible directions for future research. The method we\nhave presented may also be applicable to other strategic games, and may even be\ngeneralisable to other domains where sequences of agents' actions are recorded.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2009 21:30:30 GMT"}], "update_date": "2009-04-20", "authors_parsed": [["Levene", "Mark", ""], ["Fenner", "Trevor", ""]]}, {"id": "0904.2623", "submitter": "James Petterson", "authors": "James Petterson, Tiberio Caetano, Julian McAuley, Jin Yu", "title": "Exponential Family Graph Matching and Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning max-weight matching predictors in bipartite\ngraphs. The method consists of performing maximum a posteriori estimation in\nexponential families with sufficient statistics that encode permutations and\ndata features. Although inference is in general hard, we show that for one very\nrelevant application - web page ranking - exact inference is efficient. For\ngeneral model instances, an appropriate sampler is readily available. Contrary\nto existing max-margin matching models, our approach is statistically\nconsistent and, in addition, experiments with increasing sample sizes indicate\nsuperior improvement over such models. We apply the method to graph matching in\ncomputer vision as well as to a standard benchmark dataset for learning web\npage ranking, in which we obtain state-of-the-art results, in particular\nimproving on max-margin variants. The drawback of this method with respect to\nmax-margin alternatives is its runtime for large graphs, which is comparatively\nhigh.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2009 03:48:02 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2009 03:54:58 GMT"}], "update_date": "2009-06-05", "authors_parsed": [["Petterson", "James", ""], ["Caetano", "Tiberio", ""], ["McAuley", "Julian", ""], ["Yu", "Jin", ""]]}, {"id": "0904.3151", "submitter": "Takeaki Uno", "authors": "Takeaki Uno, Masashi Sugiyama, Koji Tsuda", "title": "Efficient Construction of Neighborhood Graphs by the Multiple Sorting\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neighborhood graphs are gaining popularity as a concise data representation\nin machine learning. However, naive graph construction by pairwise distance\ncalculation takes $O(n^2)$ runtime for $n$ data points and this is\nprohibitively slow for millions of data points. For strings of equal length,\nthe multiple sorting method (Uno, 2008) can construct an $\\epsilon$-neighbor\ngraph in $O(n+m)$ time, where $m$ is the number of $\\epsilon$-neighbor pairs in\nthe data. To introduce this remarkably efficient algorithm to continuous\ndomains such as images, signals and texts, we employ a random projection method\nto convert vectors to strings. Theoretical results are presented to elucidate\nthe trade-off between approximation quality and computation time. Empirical\nresults show the efficiency of our method in comparison to fast nearest\nneighbor alternatives.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 01:03:06 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Uno", "Takeaki", ""], ["Sugiyama", "Masashi", ""], ["Tsuda", "Koji", ""]]}, {"id": "0904.3352", "submitter": "Istvan Szita", "authors": "Istvan Szita, Andras Lorincz", "title": "Optimistic Initialization and Greediness Lead to Polynomial Time\n  Learning in Factored MDPs - Extended Version", "comments": "This paper is the extended version of a similarly named paper\n  appearing in ICML'09, containing the rigorous proofs of the main theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose an algorithm for polynomial-time reinforcement\nlearning in factored Markov decision processes (FMDPs). The factored optimistic\ninitial model (FOIM) algorithm, maintains an empirical model of the FMDP in a\nconventional way, and always follows a greedy policy with respect to its model.\nThe only trick of the algorithm is that the model is initialized\noptimistically. We prove that with suitable initialization (i) FOIM converges\nto the fixed point of approximate value iteration (AVI); (ii) the number of\nsteps when the agent makes non-near-optimal decisions (with respect to the\nsolution of AVI) is polynomial in all relevant quantities; (iii) the per-step\ncosts of the algorithm are also polynomial. To our best knowledge, FOIM is the\nfirst algorithm with these properties. This extended version contains the\nrigorous proofs of the main theorem. A version of this paper appeared in\nICML'09.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2009 22:07:24 GMT"}], "update_date": "2009-04-23", "authors_parsed": [["Szita", "Istvan", ""], ["Lorincz", "Andras", ""]]}, {"id": "0904.3664", "submitter": "Amnon Shashua", "authors": "Amnon Shashua", "title": "Introduction to Machine Learning: Class Notes 67577", "comments": "109 pages, class notes of Machine Learning course given at the Hebrew\n  University of Jerusalem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction to Machine learning covering Statistical Inference (Bayes, EM,\nML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),\nand PAC learning (the Formal model, VC dimension, Double Sampling theorem).\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2009 11:40:57 GMT"}], "update_date": "2009-04-24", "authors_parsed": [["Shashua", "Amnon", ""]]}, {"id": "0904.3667", "submitter": "Florentina Pintea", "authors": "Alin Munteanu, Cristina Ofelia Sofran", "title": "Considerations upon the Machine Learning Technologies", "comments": "6 pages,exposed on 1st \"European Conference on Computer Sciences &\n  Applications\" - XA2006, Timisoara, Romania", "journal-ref": "Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 133-138", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence offers superior techniques and methods by which\nproblems from diverse domains may find an optimal solution. The Machine\nLearning technologies refer to the domain of artificial intelligence aiming to\ndevelop the techniques allowing the computers to \"learn\". Some systems based on\nMachine Learning technologies tend to eliminate the necessity of the human\nintelligence while the others adopt a man-machine collaborative approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2009 11:48:38 GMT"}], "update_date": "2009-04-24", "authors_parsed": [["Munteanu", "Alin", ""], ["Sofran", "Cristina Ofelia", ""]]}, {"id": "0904.4527", "submitter": "Marcus Hutter", "authors": "Alberto Piatti and Marco Zaffalon and Fabio Trojani and Marcus Hutter", "title": "Limits of Learning about a Categorical Latent Variable under Prior\n  Near-Ignorance", "comments": "27 LaTeX pages", "journal-ref": "International Journal of Approximate Reasoning, 50:4 (2009) pages\n  597-611", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the coherent theory of (epistemic) uncertainty of\nWalley, in which beliefs are represented through sets of probability\ndistributions, and we focus on the problem of modeling prior ignorance about a\ncategorical random variable. In this setting, it is a known result that a state\nof prior ignorance is not compatible with learning. To overcome this problem,\nanother state of beliefs, called \\emph{near-ignorance}, has been proposed.\nNear-ignorance resembles ignorance very closely, by satisfying some principles\nthat can arguably be regarded as necessary in a state of ignorance, and allows\nlearning to take place. What this paper does, is to provide new and substantial\nevidence that also near-ignorance cannot be really regarded as a way out of the\nproblem of starting statistical inference in conditions of very weak beliefs.\nThe key to this result is focusing on a setting characterized by a variable of\ninterest that is \\emph{latent}. We argue that such a setting is by far the most\ncommon case in practice, and we provide, for the case of categorical latent\nvariables (and general \\emph{manifest} variables) a condition that, if\nsatisfied, prevents learning to take place under prior near-ignorance. This\ncondition is shown to be easily satisfied even in the most common statistical\nproblems. We regard these results as a strong form of evidence against the\npossibility to adopt a condition of prior near-ignorance in real statistical\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2009 03:16:20 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Piatti", "Alberto", ""], ["Zaffalon", "Marco", ""], ["Trojani", "Fabio", ""], ["Hutter", "Marcus", ""]]}, {"id": "0904.4608", "submitter": "Srivatsan Laxman", "authors": "Srivatsan Laxman, Basel Shadid, P. S. Sastry and K. P. Unnikrishnan", "title": "Temporal data mining for root-cause analysis of machine faults in\n  automotive assembly lines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engine assembly is a complex and heavily automated distributed-control\nprocess, with large amounts of faults data logged everyday. We describe an\napplication of temporal data mining for analyzing fault logs in an engine\nassembly plant. Frequent episode discovery framework is a model-free method\nthat can be used to deduce (temporal) correlations among events from the logs\nin an efficient manner. In addition to being theoretically elegant and\ncomputationally efficient, frequent episodes are also easy to interpret in the\nform actionable recommendations. Incorporation of domain-specific information\nis critical to successful application of the method for analyzing fault logs in\nthe manufacturing domain. We show how domain-specific knowledge can be\nincorporated using heuristic rules that act as pre-filters and post-filters to\nfrequent episode discovery. The system described here is currently being used\nin one of the engine assembly plants of General Motors and is planned for\nadaptation in other plants. To the best of our knowledge, this paper presents\nthe first real, large-scale application of temporal data mining in the\nmanufacturing domain. We believe that the ideas presented in this paper can\nhelp practitioners engineer tools for analysis in other similar or related\napplication domains as well.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2009 13:17:31 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2009 17:02:30 GMT"}], "update_date": "2009-04-30", "authors_parsed": [["Laxman", "Srivatsan", ""], ["Shadid", "Basel", ""], ["Sastry", "P. S.", ""], ["Unnikrishnan", "K. P.", ""]]}, {"id": "0904.4717", "submitter": "Aram Galstyan", "authors": "Aram Galstyan", "title": "Continuous Strategy Replicator Dynamics for Multi--Agent Learning", "comments": "12 pages, 15 figures, accepted for publication in JAAMAS", "journal-ref": null, "doi": "10.1007/s10458-011-9181-6", "report-no": null, "categories": "cs.LG cs.AI cs.GT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of multi-agent learning and adaptation has attracted a great deal\nof attention in recent years. It has been suggested that the dynamics of multi\nagent learning can be studied using replicator equations from population\nbiology. Most existing studies so far have been limited to discrete strategy\nspaces with a small number of available actions. In many cases, however, the\nchoices available to agents are better characterized by continuous spectra.\nThis paper suggests a generalization of the replicator framework that allows to\nstudy the adaptive dynamics of Q-learning agents with continuous strategy\nspaces. Instead of probability vectors, agents strategies are now characterized\nby probability measures over continuous variables. As a result, the ordinary\ndifferential equations for the discrete case are replaced by a system of\ncoupled integral--differential replicator equations that describe the mutual\nevolution of individual agent strategies. We derive a set of functional\nequations describing the steady state of the replicator dynamics, examine their\nsolutions for several two-player games, and confirm our analytical results\nusing simulations.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2009 23:00:03 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2011 20:32:36 GMT"}], "update_date": "2011-09-26", "authors_parsed": [["Galstyan", "Aram", ""]]}, {"id": "0904.4774", "submitter": "Karin Schnass", "authors": "Remi Gribonval, Karin Schnass", "title": "Dictionary Identification - Sparse Matrix-Factorisation via\n  $\\ell_1$-Minimisation", "comments": "32 pages (IEEE draft format), 8 figures, submitted to IEEE Trans.\n  Inf. Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article treats the problem of learning a dictionary providing sparse\nrepresentations for a given signal class, via $\\ell_1$-minimisation. The\nproblem can also be seen as factorising a $\\ddim \\times \\nsig$ matrix $Y=(y_1\n>... y_\\nsig), y_n\\in \\R^\\ddim$ of training signals into a $\\ddim \\times\n\\natoms$ dictionary matrix $\\dico$ and a $\\natoms \\times \\nsig$ coefficient\nmatrix $\\X=(x_1... x_\\nsig), x_n \\in \\R^\\natoms$, which is sparse. The exact\nquestion studied here is when a dictionary coefficient pair $(\\dico,\\X)$ can be\nrecovered as local minimum of a (nonconvex) $\\ell_1$-criterion with input\n$Y=\\dico \\X$. First, for general dictionaries and coefficient matrices,\nalgebraic conditions ensuring local identifiability are derived, which are then\nspecialised to the case when the dictionary is a basis. Finally, assuming a\nrandom Bernoulli-Gaussian sparse model on the coefficient matrix, it is shown\nthat sufficiently incoherent bases are locally identifiable with high\nprobability. The perhaps surprising result is that the typically sufficient\nnumber of training samples $\\nsig$ grows up to a logarithmic factor only\nlinearly with the signal dimension, i.e. $\\nsig \\approx C \\natoms \\log\n\\natoms$, in contrast to previous approaches requiring combinatorially many\nsamples.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2009 10:04:09 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2010 11:28:31 GMT"}], "update_date": "2010-03-01", "authors_parsed": [["Gribonval", "Remi", ""], ["Schnass", "Karin", ""]]}]