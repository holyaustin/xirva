[{"id": "2107.00001", "submitter": "Jan Philipp Portisch", "authors": "Jan Portisch, Michael Hladik, Heiko Paulheim", "title": "Background Knowledge in Schema Matching: Strategy vs. Data", "comments": "accepted at the International Semantic Web Conference '21 (ISWC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of external background knowledge can be beneficial for the task of\nmatching schemas or ontologies automatically. In this paper, we exploit six\ngeneral-purpose knowledge graphs as sources of background knowledge for the\nmatching task. The background sources are evaluated by applying three different\nexploitation strategies. We find that explicit strategies still outperform\nlatent ones and that the choice of the strategy has a greater impact on the\nfinal alignment than the actual background dataset on which the strategy is\napplied. While we could not identify a universally superior resource, BabelNet\nachieved consistently good results. Our best matcher configuration with\nBabelNet performs very competitively when compared to other matching systems\neven though no dataset-specific optimizations were made.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:16:33 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Portisch", "Jan", ""], ["Hladik", "Michael", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2107.00002", "submitter": "Honggui Li", "authors": "Honggui Li, Dimitri Galayko, Maria Trocan, Mohamad Sawan", "title": "Cascade Decoders-Based Autoencoders for Image Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoencoders are composed of coding and decoding units, hence they hold the\ninherent potential of high-performance data compression and signal compressed\nsensing. The main disadvantages of current autoencoders comprise the following\nseveral aspects: the research objective is not data reconstruction but feature\nrepresentation; the performance evaluation of data recovery is neglected; it is\nhard to achieve lossless data reconstruction by pure autoencoders, even by pure\ndeep learning. This paper aims for image reconstruction of autoencoders,\nemploys cascade decoders-based autoencoders, perfects the performance of image\nreconstruction, approaches gradually lossless image recovery, and provides\nsolid theory and application basis for autoencoders-based image compression and\ncompressed sensing. The proposed serial decoders-based autoencoders include the\narchitectures of multi-level decoders and the related optimization algorithms.\nThe cascade decoders consist of general decoders, residual decoders,\nadversarial decoders and their combinations. It is evaluated by the\nexperimental results that the proposed autoencoders outperform the classical\nautoencoders in the performance of image reconstruction.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 23:40:54 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Honggui", ""], ["Galayko", "Dimitri", ""], ["Trocan", "Maria", ""], ["Sawan", "Mohamad", ""]]}, {"id": "2107.00003", "submitter": "Bowei Xi", "authors": "Juan Shu and Bowei Xi and Charles Kamhoua", "title": "Understanding Adversarial Examples Through Deep Neural Network's\n  Response Surface and Uncertainty Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep neural network (DNN) is a popular model implemented in many systems to\nhandle complex tasks such as image classification, object recognition, natural\nlanguage processing etc. Consequently DNN structural vulnerabilities become\npart of the security vulnerabilities in those systems. In this paper we study\nthe root cause of DNN adversarial examples. We examine the DNN response surface\nto understand its classification boundary. Our study reveals the structural\nproblem of DNN classification boundary that leads to the adversarial examples.\nExisting attack algorithms can generate from a handful to a few hundred\nadversarial examples given one clean image. We show there are infinitely many\nadversarial images given one clean sample, all within a small neighborhood of\nthe clean sample. We then define DNN uncertainty regions and show\ntransferability of adversarial examples is not universal. We also argue that\ngeneralization error, the large sample theoretical guarantee established for\nDNN, cannot adequately capture the phenomenon of adversarial examples. We need\nnew theory to measure DNN robustness.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 02:38:17 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Shu", "Juan", ""], ["Xi", "Bowei", ""], ["Kamhoua", "Charles", ""]]}, {"id": "2107.00051", "submitter": "Lichao Sun", "authors": "Wanning Pan, Lichao Sun", "title": "Global Knowledge Distillation in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation has caught a lot of attention in Federated Learning\n(FL) recently. It has the advantage for FL to train on heterogeneous clients\nwhich have different data size and data structure. However, data samples across\nall devices are usually not independent and identically distributed\n(non-i.i.d), posing additional challenges to the convergence and speed of\nfederated learning. As FL randomly asks the clients to join the training\nprocess and each client only learns from local non-i.i.d data, which makes\nlearning processing even slower. In order to solve this problem, an intuitive\nidea is using the global model to guide local training. In this paper, we\npropose a novel global knowledge distillation method, named FedGKD, which\nlearns the knowledge from past global models to tackle down the local bias\ntraining problem. By learning from global knowledge and consistent with current\nlocal models, FedGKD learns a global knowledge model in FL. To demonstrate the\neffectiveness of the proposed method, we conduct extensive experiments on\nvarious CV datasets (CIFAR-10/100) and settings (non-i.i.d data). The\nevaluation results show that FedGKD outperforms previous state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:14:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Pan", "Wanning", ""], ["Sun", "Lichao", ""]]}, {"id": "2107.00052", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Hugo Berard, Gauthier Gidel, Ioannis Mitliagkas, Simon\n  Lacoste-Julien", "title": "Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth\n  Games: Convergence Analysis under Expected Co-coercivity", "comments": "35 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two of the most prominent algorithms for solving unconstrained smooth games\nare the classical stochastic gradient descent-ascent (SGDA) and the recently\nintroduced stochastic consensus optimization (SCO) (Mescheder et al., 2017).\nSGDA is known to converge to a stationary point for specific classes of games,\nbut current convergence analyses require a bounded variance assumption. SCO is\nused successfully for solving large-scale adversarial problems, but its\nconvergence guarantees are limited to its deterministic variant. In this work,\nwe introduce the expected co-coercivity condition, explain its benefits, and\nprovide the first last-iterate convergence guarantees of SGDA and SCO under\nthis condition for solving a class of stochastic variational inequality\nproblems that are potentially non-monotone. We prove linear convergence of both\nmethods to a neighborhood of the solution when they use constant step-size, and\nwe propose insightful stepsize-switching rules to guarantee convergence to the\nexact solution. In addition, our convergence guarantees hold under the\narbitrary sampling paradigm, and as such, we give insights into the complexity\nof minibatching.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:32:46 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Loizou", "Nicolas", ""], ["Berard", "Hugo", ""], ["Gidel", "Gauthier", ""], ["Mitliagkas", "Ioannis", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2107.00055", "submitter": "Roy Dong", "authors": "Roy Dong and Lillian J. Ratliff", "title": "Which Echo Chamber? Regions of Attraction in Learning with\n  Decision-Dependent Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data-driven methods are deployed in real-world settings, the processes\nthat generate the observed data will often react to the decisions of the\nlearner. For example, a data source may have some incentive for the algorithm\nto provide a particular label (e.g. approve a bank loan), and manipulate their\nfeatures accordingly. Work in strategic classification and decision-dependent\ndistributions seeks to characterize the closed-loop behavior of deploying\nlearning algorithms by explicitly considering the effect of the classifier on\nthe underlying data distribution. More recently, works in performative\nprediction seek to classify the closed-loop behavior by considering general\nproperties of the mapping from classifier to data distribution, rather than an\nexplicit form. Building on this notion, we analyze repeated risk minimization\nas the perturbed trajectories of the gradient flows of performative risk\nminimization. We consider the case where there may be multiple local minimizers\nof performative risk, motivated by real world situations where the initial\nconditions may have significant impact on the long-term behavior of the system.\nAs a motivating example, we consider a company whose current employee\ndemographics affect the applicant pool they interview: the initial demographics\nof the company can affect the long-term hiring policies of the company. We\nprovide sufficient conditions to characterize the region of attraction for the\nvarious equilibria in this settings. Additionally, we introduce the notion of\nperformative alignment, which provides a geometric condition on the convergence\nof repeated risk minimization to performative risk minimizers.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 18:38:08 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dong", "Roy", ""], ["Ratliff", "Lillian J.", ""]]}, {"id": "2107.00068", "submitter": "Zixiu Wang", "authors": "Zixiu Wang, Yiwen Guo and Hu Ding", "title": "Robust Coreset for Continuous-and-Bounded Learning (with Outliers)", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this big data era, we often confront large-scale data in many machine\nlearning tasks. A common approach for dealing with large-scale data is to build\na small summary, {\\em e.g.,} coreset, that can efficiently represent the\noriginal input. However, real-world datasets usually contain outliers and most\nexisting coreset construction methods are not resilient against outliers (in\nparticular, the outliers can be located arbitrarily in the space by an\nadversarial attacker). In this paper, we propose a novel robust coreset method\nfor the {\\em continuous-and-bounded learning} problem (with outliers) which\nincludes a broad range of popular optimization objectives in machine learning,\nlike logistic regression and $ k $-means clustering. Moreover, our robust\ncoreset can be efficiently maintained in fully-dynamic environment. To the best\nof our knowledge, this is the first robust and fully-dynamic coreset\nconstruction method for these optimization problems. We also conduct the\nexperiments to evaluate the effectiveness of our robust coreset in practice.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 19:24:20 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Zixiu", ""], ["Guo", "Yiwen", ""], ["Ding", "Hu", ""]]}, {"id": "2107.00070", "submitter": "Yang Li", "authors": "Yang Li and Shihao Ji", "title": "Dep-$L_0$: Improving $L_0$-based Network Sparsification via Dependency\n  Modeling", "comments": "Published as a conference paper at ECML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks with an $L_0$ regularization is one of the\nprominent approaches for network pruning or sparsification. The method prunes\nthe network during training by encouraging weights to become exactly zero.\nHowever, recent work of Gale et al. reveals that although this method yields\nhigh compression rates on smaller datasets, it performs inconsistently on\nlarge-scale learning tasks, such as ResNet50 on ImageNet. We analyze this\nphenomenon through the lens of variational inference and find that it is likely\ndue to the independent modeling of binary gates, the mean-field approximation,\nwhich is known in Bayesian statistics for its poor performance due to the crude\napproximation. To mitigate this deficiency, we propose a dependency modeling of\nbinary gates, which can be modeled effectively as a multi-layer perceptron\n(MLP). We term our algorithm Dep-$L_0$ as it prunes networks via a\ndependency-enabled $L_0$ regularization. Extensive experiments on CIFAR10,\nCIFAR100 and ImageNet with VGG16, ResNet50, ResNet56 show that our Dep-$L_0$\noutperforms the original $L_0$-HC algorithm of Louizos et al. by a significant\nmargin, especially on ImageNet. Compared with the state-of-the-arts network\nsparsification algorithms, our dependency modeling makes the $L_0$-based\nsparsification once again very competitive on large-scale learning tasks. Our\nsource code is available at https://github.com/leo-yangli/dep-l0.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 19:33:35 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Yang", ""], ["Ji", "Shihao", ""]]}, {"id": "2107.00079", "submitter": "Nikhil Muralidhar", "authors": "Nikhil Muralidhar, Sathappah Muthiah, Patrick Butler, Manish Jain, Yu\n  Yu, Katy Burne, Weipeng Li, David Jones, Prakash Arunachalam, Hays 'Skip'\n  McCormick, Naren Ramakrishnan", "title": "Using AntiPatterns to avoid MLOps Mistakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe lessons learned from developing and deploying machine learning\nmodels at scale across the enterprise in a range of financial analytics\napplications. These lessons are presented in the form of antipatterns. Just as\ndesign patterns codify best software engineering practices, antipatterns\nprovide a vocabulary to describe defective practices and methodologies. Here we\ncatalog and document numerous antipatterns in financial ML operations (MLOps).\nSome antipatterns are due to technical errors, while others are due to not\nhaving sufficient knowledge of the surrounding context in which ML results are\nused. By providing a common vocabulary to discuss these situations, our intent\nis that antipatterns will support better documentation of issues, rapid\ncommunication between stakeholders, and faster resolution of problems. In\naddition to cataloging antipatterns, we describe solutions, best practices, and\nfuture directions toward MLOps maturity.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 20:00:52 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Muralidhar", "Nikhil", ""], ["Muthiah", "Sathappah", ""], ["Butler", "Patrick", ""], ["Jain", "Manish", ""], ["Yu", "Yu", ""], ["Burne", "Katy", ""], ["Li", "Weipeng", ""], ["Jones", "David", ""], ["Arunachalam", "Prakash", ""], ["McCormick", "Hays 'Skip'", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "2107.00080", "submitter": "Benajmin Radford J", "authors": "Benjamin J. Radford", "title": "Regressing Location on Text for Probabilistic Geocoding", "comments": "5 pages, 4 figures. Proceedings of the CASE Workshop at ACL-IJCNLP\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Text data are an important source of detailed information about social and\npolitical events. Automated systems parse large volumes of text data to infer\nor extract structured information that describes actors, actions, dates, times,\nand locations. One of these sub-tasks is geocoding: predicting the geographic\ncoordinates associated with events or locations described by a given text. We\npresent an end-to-end probabilistic model for geocoding text data.\nAdditionally, we collect a novel data set for evaluating the performance of\ngeocoding systems. We compare the model-based solution, called ELECTRo-map, to\nthe current state-of-the-art open source system for geocoding texts for event\ndata. Finally, we discuss the benefits of end-to-end model-based geocoding,\nincluding principled uncertainty estimation and the ability of these models to\nleverage contextual information.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 20:04:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Radford", "Benjamin J.", ""]]}, {"id": "2107.00088", "submitter": "Sean Hooten", "authors": "Sean Hooten, Raymond G. Beausoleil, Thomas Van Vaerenbergh", "title": "Inverse Design of Grating Couplers Using the Policy Gradient Method from\n  Reinforcement Learning", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a proof-of-concept technique for the inverse design of\nelectromagnetic devices motivated by the policy gradient method in\nreinforcement learning, named PHORCED (PHotonic Optimization using REINFORCE\nCriteria for Enhanced Design). This technique uses a probabilistic generative\nneural network interfaced with an electromagnetic solver to assist in the\ndesign of photonic devices, such as grating couplers. We show that PHORCED\nobtains better performing grating coupler designs than local gradient-based\ninverse design via the adjoint method, while potentially providing faster\nconvergence over competing state-of-the-art generative methods. Furthermore, we\nimplement transfer learning with PHORCED, demonstrating that a neural network\ntrained to optimize 8$^\\circ$ grating couplers can then be re-trained on\ngrating couplers with alternate scattering angles while requiring >$10\\times$\nfewer simulations than control cases.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 20:40:46 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 04:49:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Hooten", "Sean", ""], ["Beausoleil", "Raymond G.", ""], ["Van Vaerenbergh", "Thomas", ""]]}, {"id": "2107.00090", "submitter": "Reese Jones", "authors": "Ari Frankel and Cosmin Safta and Coleman Alleman and Reese Jones", "title": "Mesh-based graph convolutional neural network models of processes with\n  complex initial states", "comments": "38 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Predicting the evolution of a representative sample of a material with\nmicrostructure is a fundamental problem in homogenization. In this work we\npropose a graph convolutional neural network that utilizes the discretized\nrepresentation of the initial microstructure directly, without segmentation or\nclustering. Compared to feature-based and pixel-based convolutional neural\nnetwork models, the proposed method has a number of advantages: (a) it is deep\nin that it does not require featurization but can benefit from it, (b) it has a\nsimple implementation with standard convolutional filters and layers, (c) it\nworks natively on unstructured and structured grid data without interpolation\n(unlike pixel-based convolutional neural networks), and (d) it preserves\nrotational invariance like other graph-based convolutional neural networks. We\ndemonstrate the performance of the proposed network and compare it to\ntraditional pixel-based convolution neural network models and feature-based\ngraph convolutional neural networks on three large datasets.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 03:40:40 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Frankel", "Ari", ""], ["Safta", "Cosmin", ""], ["Alleman", "Coleman", ""], ["Jones", "Reese", ""]]}, {"id": "2107.00092", "submitter": "Gaurab Bhattacharya", "authors": "Gaurab Bhattacharya", "title": "From DNNs to GANs: Review of efficient hardware architectures for deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent times, the trend in very large scale integration (VLSI) industry is\nmulti-dimensional, for example, reduction of energy consumption, occupancy of\nless space, precise result, less power dissipation, faster response. To meet\nthese needs, the hardware architecture should be reliable and robust to these\nproblems. Recently, neural network and deep learning has been started to impact\nthe present research paradigm significantly which consists of parameters in the\norder of millions, nonlinear function for activation, convolutional operation\nfor feature extraction, regression for classification, generative adversarial\nnetworks. These operations involve huge calculation and memory overhead.\nPresently available DSP processors are incapable of performing these operations\nand they mostly face the problems, for example, memory overhead, performance\ndrop and compromised accuracy. Moreover, if a huge silicon area is powered to\naccelerate the operation using parallel computation, the ICs will be having\nsignificant chance of burning out due to the considerable generation of heat.\nHence, novel dark silicon constraint is developed to reduce the heat\ndissipation without sacrificing the accuracy. Similarly, different algorithms\nhave been adapted to design a DSP processor compatible for fast performance in\nneural network, activation function, convolutional neural network and\ngenerative adversarial network. In this review, we illustrate the recent\ndevelopments in hardware for accelerating the efficient implementation of deep\nlearning networks with enhanced performance. The techniques investigated in\nthis review are expected to direct future research challenges of hardware\noptimization for high-performance computations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 13:23:06 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Bhattacharya", "Gaurab", ""]]}, {"id": "2107.00096", "submitter": "Pascal Notin", "authors": "Pascal Notin, Jos\\'e Miguel Hern\\'andez-Lobato, Yarin Gal", "title": "Improving black-box optimization in VAE latent space using decoder\n  uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimization in the latent space of variational autoencoders is a promising\napproach to generate high-dimensional discrete objects that maximize an\nexpensive black-box property (e.g., drug-likeness in molecular generation,\nfunction approximation with arithmetic expressions). However, existing methods\nlack robustness as they may decide to explore areas of the latent space for\nwhich no data was available during training and where the decoder can be\nunreliable, leading to the generation of unrealistic or invalid objects. We\npropose to leverage the epistemic uncertainty of the decoder to guide the\noptimization process. This is not trivial though, as a naive estimation of\nuncertainty in the high-dimensional and structured settings we consider would\nresult in high estimator variance. To solve this problem, we introduce an\nimportance sampling-based estimator that provides more robust estimates of\nepistemic uncertainty. Our uncertainty-guided optimization approach does not\nrequire modifications of the model architecture nor the training process. It\nproduces samples with a better trade-off between black-box objective and\nvalidity of the generated samples, sometimes improving both simultaneously. We\nillustrate these advantages across several experimental settings in digit\ngeneration, arithmetic expression approximation and molecule generation for\ndrug design.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 20:46:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Notin", "Pascal", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Gal", "Yarin", ""]]}, {"id": "2107.00100", "submitter": "Prateek Mishra", "authors": "Prateek Mishra, Kumar Divya Mani, Prashant Johri, Dikhsa Arya", "title": "FCMI: Feature Correlation based Missing Data Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Processed data are insightful, and crude data are obtuse. A serious threat to\ndata reliability is missing values. Such data leads to inaccurate analysis and\nwrong predictions. We propose an efficient technique to impute the missing\nvalue in the dataset based on correlation called FCMI (Feature Correlation\nbased Missing Data Imputation). We have considered the correlation of the\nattributes of the dataset, and that is our central idea. Our proposed algorithm\npicks the highly correlated attributes of the dataset and uses these attributes\nto build a regression model whose parameters are optimized such that the\ncorrelation of the dataset is maintained. Experiments conducted on both\nclassification and regression datasets show that the proposed imputation\ntechnique outperforms existing imputation algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 13:35:33 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Mishra", "Prateek", ""], ["Mani", "Kumar Divya", ""], ["Johri", "Prashant", ""], ["Arya", "Dikhsa", ""]]}, {"id": "2107.00101", "submitter": "Xinyun Chen", "authors": "Xinyun Chen, Dawn Song, Yuandong Tian", "title": "Latent Execution for Neural Program Synthesis Beyond Domain-Specific\n  Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Program synthesis from input-output examples has been a long-standing\nchallenge, and recent works have demonstrated some success in designing deep\nneural networks for program synthesis. However, existing efforts in\ninput-output neural program synthesis have been focusing on domain-specific\nlanguages, thus the applicability of previous approaches to synthesize code in\nfull-fledged popular programming languages, such as C, remains a question. The\nmain challenges lie in two folds. On the one hand, the program search space\ngrows exponentially when the syntax and semantics of the programming language\nbecome more complex, which poses higher requirements on the synthesis\nalgorithm. On the other hand, increasing the complexity of the programming\nlanguage also imposes more difficulties on data collection, since building a\nlarge-scale training set for input-output program synthesis require random\nprogram generators to sample programs and input-output examples. In this work,\nwe take the first step to synthesize C programs from input-output examples. In\nparticular, we propose LaSynth, which learns the latent representation to\napproximate the execution of partially generated programs, even if their\nsemantics are not well-defined. We demonstrate the possibility of synthesizing\nelementary C code from input-output examples, and leveraging learned execution\nsignificantly improves the prediction performance over existing approaches.\nMeanwhile, compared to the randomly generated ground-truth programs, LaSynth\nsynthesizes more concise programs that resemble human-written code. We show\nthat training on these synthesized programs further improves the prediction\nperformance for both Karel and C program synthesis, indicating the promise of\nleveraging the learned program synthesizer to improve the dataset quality for\ninput-output program synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 02:21:32 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chen", "Xinyun", ""], ["Song", "Dawn", ""], ["Tian", "Yuandong", ""]]}, {"id": "2107.00110", "submitter": "Masataro Asai", "authors": "Masataro Asai, Hiroshi Kajino, Alex Fukunaga, Christian Muise", "title": "Classical Planning in Deep Latent Space", "comments": "Under review at Journal of Artificial Intelligence Research (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current domain-independent, classical planners require symbolic models of the\nproblem domain and instance as input, resulting in a knowledge acquisition\nbottleneck. Meanwhile, although deep learning has achieved significant success\nin many fields, the knowledge is encoded in a subsymbolic representation which\nis incompatible with symbolic systems such as planners. We propose Latplan, an\nunsupervised architecture combining deep learning and classical planning. Given\nonly an unlabeled set of image pairs showing a subset of transitions allowed in\nthe environment (training inputs), Latplan learns a complete propositional PDDL\naction model of the environment. Later, when a pair of images representing the\ninitial and the goal states (planning inputs) is given, Latplan finds a plan to\nthe goal state in a symbolic latent space and returns a visualized plan\nexecution. We evaluate Latplan using image-based versions of 6 planning\ndomains: 8-puzzle, 15-Puzzle, Blocksworld, Sokoban and Two variations of\nLightsOut.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 21:31:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Asai", "Masataro", ""], ["Kajino", "Hiroshi", ""], ["Fukunaga", "Alex", ""], ["Muise", "Christian", ""]]}, {"id": "2107.00116", "submitter": "Farzan Memarian", "authors": "Farzan Memarian, Abolfazl Hashemi, Scott Niekum, Ufuk Topcu", "title": "Robust Generative Adversarial Imitation Learning via Local Lipschitzness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore methodologies to improve the robustness of generative adversarial\nimitation learning (GAIL) algorithms to observation noise. Towards this\nobjective, we study the effect of local Lipschitzness of the discriminator and\nthe generator on the robustness of policies learned by GAIL. In many robotics\napplications, the learned policies by GAIL typically suffer from a degraded\nperformance at test time since the observations from the environment might be\ncorrupted by noise. Hence, robustifying the learned policies against the\nobservation noise is of critical importance. To this end, we propose a\nregularization method to induce local Lipschitzness in the generator and the\ndiscriminator of adversarial imitation learning methods. We show that the\nmodified objective leads to learning significantly more robust policies.\nMoreover, we demonstrate -- both theoretically and experimentally -- that\ntraining a locally Lipschitz discriminator leads to a locally Lipschitz\ngenerator, thereby improving the robustness of the resultant policy. We perform\nextensive experiments on simulated robot locomotion environments from the\nMuJoCo suite that demonstrate the proposed method learns policies that\nsignificantly outperform the state-of-the-art generative adversarial imitation\nlearning algorithm when applied to test scenarios with noise-corrupted\nobservations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 21:48:27 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Memarian", "Farzan", ""], ["Hashemi", "Abolfazl", ""], ["Niekum", "Scott", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2107.00124", "submitter": "Ashwinkumar Ganesan", "authors": "Ashwinkumar Ganesan, Francis Ferraro, Tim Oates", "title": "Learning a Reversible Embedding Mapping using Bi-Directional Manifold\n  Alignment", "comments": null, "journal-ref": "Findings of the Association for Computational Linguistics: ACL\n  2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bi-Directional Manifold Alignment (BDMA) that learns a\nnon-linear mapping between two manifolds by explicitly training it to be\nbijective. We demonstrate BDMA by training a model for a pair of languages\nrather than individual, directed source and target combinations, reducing the\nnumber of models by 50%. We show that models trained with BDMA in the \"forward\"\n(source to target) direction can successfully map words in the \"reverse\"\n(target to source) direction, yielding equivalent (or better) performance to\nstandard unidirectional translation models where the source and target language\nis flipped. We also show how BDMA reduces the overall size of the model.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 22:13:42 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ganesan", "Ashwinkumar", ""], ["Ferraro", "Francis", ""], ["Oates", "Tim", ""]]}, {"id": "2107.00157", "submitter": "Bob Li", "authors": "Zhiming Li, Xiaofei Xie, Haoliang Li, Zhengzi Xu, Yi Li, Yang Liu", "title": "Cross-Lingual Adaptation for Type Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based techniques have been widely applied to the program\nanalysis tasks, in fields such as type inference, fault localization, and code\nsummarization. Hitherto deep learning-based software engineering systems rely\nthoroughly on supervised learning approaches, which require laborious manual\neffort to collect and label a prohibitively large amount of data. However, most\nTuring-complete imperative languages share similar control- and data-flow\nstructures, which make it possible to transfer knowledge learned from one\nlanguage to another. In this paper, we propose cross-lingual adaptation of\nprogram analysis, which allows us to leverage prior knowledge learned from the\nlabeled dataset of one language and transfer it to the others. Specifically, we\nimplemented a cross-lingual adaptation framework, PLATO, to transfer a deep\nlearning-based type inference procedure across weakly typed languages, e.g.,\nPython to JavaScript and vice versa. PLATO incorporates a novel joint graph\nkernelized attention based on abstract syntax tree and control flow graph, and\napplies anchor word augmentation across different languages. Besides, by\nleveraging data from strongly typed languages, PLATO improves the perplexity of\nthe backbone cross-programming-language model and the performance of downstream\ncross-lingual transfer for type inference. Experimental results illustrate that\nour framework significantly improves the transferability over the baseline\nmethod by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:20:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Zhiming", ""], ["Xie", "Xiaofei", ""], ["Li", "Haoliang", ""], ["Xu", "Zhengzi", ""], ["Li", "Yi", ""], ["Liu", "Yang", ""]]}, {"id": "2107.00166", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Geng Yuan, Xuan Shen, Tianlong Chen, Xuxi Chen, Xiaohan\n  Chen, Ning Liu, Minghai Qin, Sijia Liu, Zhangyang Wang, Yanzhi Wang", "title": "Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win\n  the Jackpot?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There have been long-standing controversies and inconsistencies over the\nexperiment setup and criteria for identifying the \"winning ticket\" in\nliterature. To reconcile such, we revisit the definition of lottery ticket\nhypothesis, with comprehensive and more rigorous conditions. Under our new\ndefinition, we show concrete evidence to clarify whether the winning ticket\nexists across the major DNN architectures and/or applications. Through\nextensive experiments, we perform quantitative analysis on the correlations\nbetween winning tickets and various experimental factors, and empirically study\nthe patterns of our observations. We find that the key training\nhyperparameters, such as learning rate and training epochs, as well as the\narchitecture characteristics such as capacities and residual connections, are\nall highly correlated with whether and when the winning tickets can be\nidentified. Based on our analysis, we summarize a guideline for parameter\nsettings in regards of specific architecture characteristics, which we hope to\ncatalyze the research progress on the topic of lottery ticket hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 01:27:07 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ma", "Xiaolong", ""], ["Yuan", "Geng", ""], ["Shen", "Xuan", ""], ["Chen", "Tianlong", ""], ["Chen", "Xuxi", ""], ["Chen", "Xiaohan", ""], ["Liu", "Ning", ""], ["Qin", "Minghai", ""], ["Liu", "Sijia", ""], ["Wang", "Zhangyang", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2107.00179", "submitter": "Hongji Wei", "authors": "T. Tony Cai and Hongji Wei", "title": "Distributed Nonparametric Function Estimation: Optimal Rate of\n  Convergence and Cost of Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DC cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed minimax estimation and distributed adaptive estimation under\ncommunication constraints for Gaussian sequence model and white noise model are\nstudied. The minimax rate of convergence for distributed estimation over a\ngiven Besov class, which serves as a benchmark for the cost of adaptation, is\nestablished. We then quantify the exact communication cost for adaptation and\nconstruct an optimally adaptive procedure for distributed estimation over a\nrange of Besov classes. The results demonstrate significant differences between\nnonparametric function estimation in the distributed setting and the\nconventional centralized setting. For global estimation, adaptation in general\ncannot be achieved for free in the distributed setting. The new technical tools\nto obtain the exact characterization for the cost of adaptation can be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 02:16:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Cai", "T. Tony", ""], ["Wei", "Hongji", ""]]}, {"id": "2107.00181", "submitter": "Zhen Huang", "authors": "Zhen Huang, Xu Shen, Jun Xing, Tongliang Liu, Xinmei Tian, Houqiang\n  Li, Bing Deng, Jianqiang Huang and Xian-Sheng Hua", "title": "Revisiting Knowledge Distillation: An Inheritance and Exploration\n  Framework", "comments": "Accepted by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge Distillation (KD) is a popular technique to transfer knowledge from\na teacher model or ensemble to a student model. Its success is generally\nattributed to the privileged information on similarities/consistency between\nthe class distributions or intermediate feature representations of the teacher\nmodel and the student model. However, directly pushing the student model to\nmimic the probabilities/features of the teacher model to a large extent limits\nthe student model in learning undiscovered knowledge/features. In this paper,\nwe propose a novel inheritance and exploration knowledge distillation framework\n(IE-KD), in which a student model is split into two parts - inheritance and\nexploration. The inheritance part is learned with a similarity loss to transfer\nthe existing learned knowledge from the teacher model to the student model,\nwhile the exploration part is encouraged to learn representations different\nfrom the inherited ones with a dis-similarity loss. Our IE-KD framework is\ngeneric and can be easily combined with existing distillation or mutual\nlearning methods for training deep neural networks. Extensive experiments\ndemonstrate that these two parts can jointly push the student model to learn\nmore diversified and effective representations, and our IE-KD can be a general\ntechnique to improve the student network to achieve SOTA performance.\nFurthermore, by applying our IE-KD to the training of two networks, the\nperformance of both can be improved w.r.t. deep mutual learning. The code and\nmodels of IE-KD will be make publicly available at\nhttps://github.com/yellowtownhz/IE-KD.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 02:20:56 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Huang", "Zhen", ""], ["Shen", "Xu", ""], ["Xing", "Jun", ""], ["Liu", "Tongliang", ""], ["Tian", "Xinmei", ""], ["Li", "Houqiang", ""], ["Deng", "Bing", ""], ["Huang", "Jianqiang", ""], ["Hua", "Xian-Sheng", ""]]}, {"id": "2107.00191", "submitter": "Wonju Lee", "authors": "Wonju Lee, Seok-Yong Byun, Jooeun Kim, Minje Park, Kirill Chechil", "title": "Unsupervised Model Drift Estimation with Batch Normalization Statistics\n  for Dataset Shift Detection and Model Selection", "comments": "11 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While many real-world data streams imply that they change frequently in a\nnonstationary way, most of deep learning methods optimize neural networks on\ntraining data, and this leads to severe performance degradation when dataset\nshift happens. However, it is less possible to annotate or inspect newly\nstreamed data by humans, and thus it is desired to measure model drift at\ninference time in an unsupervised manner. In this paper, we propose a novel\nmethod of model drift estimation by exploiting statistics of batch\nnormalization layer on unlabeled test data. To remedy possible sampling error\nof streamed input data, we adopt low-rank approximation to each\nrepresentational layer. We show the effectiveness of our method not only on\ndataset shift detection but also on model selection when there are multiple\ncandidate models among model zoo or training trajectories in an unsupervised\nway. We further demonstrate the consistency of our method by comparing model\ndrift scores between different network architectures.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 03:04:47 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lee", "Wonju", ""], ["Byun", "Seok-Yong", ""], ["Kim", "Jooeun", ""], ["Park", "Minje", ""], ["Chechil", "Kirill", ""]]}, {"id": "2107.00195", "submitter": "Wei-Ming Li", "authors": "Wei-Ming Li and Shi-Ju Ran", "title": "Non-parametric Active Learning and Rate Reduction in Many-body Hilbert\n  Space with Rescaled Logarithmic Fidelity", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantum and quantum-inspired machine learning, the very first step is to\nembed the data in quantum space known as Hilbert space. Developing quantum\nkernel function (QKF), which defines the distances among the samples in the\nHilbert space, belongs to the fundamental topics for machine learning. In this\nwork, we propose the rescaled logarithmic fidelity (RLF) and a non-parametric\nactive learning in the quantum space, which we name as RLF-NAL. The rescaling\ntakes advantage of the non-linearity of the kernel to tune the mutual distances\nof samples in the Hilbert space, and meanwhile avoids the exponentially-small\nfidelities between quantum many-qubit states. We compare RLF-NAL with several\nwell-known non-parametric algorithms including naive Bayes classifiers,\n$k$-nearest neighbors, and spectral clustering. Our method exhibits excellent\naccuracy particularly for the unsupervised case with no labeled samples and the\nfew-shot cases with small numbers of labeled samples. With the visualizations\nby t-SNE, our results imply that the machine learning in the Hilbert space\ncomplies with the principles of maximal coding rate reduction, where the\nlow-dimensional data exhibit within-class compressibility, between-class\ndiscrimination, and overall diversity. Our proposals can be applied to other\nquantum and quantum-inspired machine learning, including the methods using the\nparametric models such as tensor networks, quantum circuits, and quantum neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 03:13:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Wei-Ming", ""], ["Ran", "Shi-Ju", ""]]}, {"id": "2107.00197", "submitter": "Wei-Lun Chao", "authors": "Han-Jia Ye, Lu Ming, De-Chuan Zhan, Wei-Lun Chao", "title": "Few-Shot Learning with a Strong Teacher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Few-shot learning (FSL) aims to train a strong classifier using limited\nlabeled examples. Many existing works take the meta-learning approach, sampling\nfew-shot tasks in turn and optimizing the few-shot learner's performance on\nclassifying the query examples. In this paper, we point out two potential\nweaknesses of this approach. First, the sampled query examples may not provide\nsufficient supervision for the few-shot learner. Second, the effectiveness of\nmeta-learning diminishes sharply with increasing shots (i.e., the number of\ntraining examples per class). To resolve these issues, we propose a novel\nobjective to directly train the few-shot learner to perform like a strong\nclassifier. Concretely, we associate each sampled few-shot task with a strong\nclassifier, which is learned with ample labeled examples. The strong classifier\nhas a better generalization ability and we use it to supervise the few-shot\nlearner. We present an efficient way to construct the strong classifier, making\nour proposed objective an easily plug-and-play term to existing meta-learning\nbased FSL methods. We validate our approach in combinations with many\nrepresentative meta-learning methods. On several benchmark datasets including\nminiImageNet and tiredImageNet, our approach leads to a notable improvement\nacross a variety of tasks. More importantly, with our approach, meta-learning\nbased FSL methods can consistently outperform non-meta-learning based ones,\neven in a many-shot setting, greatly strengthening their applicability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 03:20:46 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ye", "Han-Jia", ""], ["Ming", "Lu", ""], ["Zhan", "De-Chuan", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2107.00204", "submitter": "Yi Liu", "authors": "Wenjun Zeng and Yi Liu", "title": "Markov Decision Process modeled with Bandits for Sequential Decision\n  Making in Linear-flow", "comments": "Accepted by 2021 KDD Multi-Armed Bandits and Reinforcement Learning\n  Workshop: https://sites.google.com/view/marble-kdd", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In membership/subscriber acquisition and retention, we sometimes need to\nrecommend marketing content for multiple pages in sequence. Different from\ngeneral sequential decision making process, the use cases have a simpler flow\nwhere customers per seeing recommended content on each page can only return\nfeedback as moving forward in the process or dropping from it until a\ntermination state. We refer to this type of problems as sequential decision\nmaking in linear--flow. We propose to formulate the problem as an MDP with\nBandits where Bandits are employed to model the transition probability matrix.\nAt recommendation time, we use Thompson sampling (TS) to sample the transition\nprobabilities and allocate the best series of actions with analytical solution\nthrough exact dynamic programming. The way that we formulate the problem allows\nus to leverage TS's efficiency in balancing exploration and exploitation and\nBandit's convenience in modeling actions' incompatibility. In the simulation\nstudy, we observe the proposed MDP with Bandits algorithm outperforms\nQ-learning with $\\epsilon$-greedy and decreasing $\\epsilon$, independent\nBandits, and interaction Bandits. We also find the proposed algorithm's\nperformance is the most robust to changes in the across-page interdependence\nstrength.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 03:54:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zeng", "Wenjun", ""], ["Liu", "Yi", ""]]}, {"id": "2107.00206", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Zhenfeng Zhu, Zhizhe Liu, Zhenyu Guo, Yang Liu, Yao Zhao", "title": "Multi-modal Graph Learning for Disease Prediction", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Benefiting from the powerful expressive capability of graphs, graph-based\napproaches have achieved impressive performance in various biomedical\napplications. Most existing methods tend to define the adjacency matrix among\nsamples manually based on meta-features, and then obtain the node embeddings\nfor downstream tasks by Graph Representation Learning (GRL). However, it is not\neasy for these approaches to generalize to unseen samples. Meanwhile, the\ncomplex correlation between modalities is also ignored. As a result, these\nfactors inevitably yield the inadequacy of providing valid information about\nthe patient's condition for a reliable diagnosis. In this paper, we propose an\nend-to-end Multimodal Graph Learning framework (MMGL) for disease prediction.\nTo effectively exploit the rich information across multi-modality associated\nwith diseases, amodal-attentional multi-modal fusion is proposed to integrate\nthe features of each modality by leveraging the correlation and complementarity\nbetween the modalities. Furthermore, instead of defining the adjacency matrix\nmanually as existing methods, the latent graph structure can be captured\nthrough a novel way of adaptive graph learning. It could be jointly optimized\nwith the prediction model, thus revealing the intrinsic connections among\nsamples. Unlike the previous transductive methods, our model is also applicable\nto the scenario of inductive learning for those unseen data. An extensive group\nof experiments on two disease prediction problems is then carefully designed\nand presented, demonstrating that MMGL obtains more favorable performances. In\naddition, we also visualize and analyze the learned graph structure to provide\nmore reliable decision support for doctors in real medical applications and\ninspiration for disease research.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 03:59:22 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zheng", "Shuai", ""], ["Zhu", "Zhenfeng", ""], ["Liu", "Zhizhe", ""], ["Guo", "Zhenyu", ""], ["Liu", "Yang", ""], ["Zhao", "Yao", ""]]}, {"id": "2107.00219", "submitter": "Brian Liu", "authors": "Brian Liu and Miaolan Xie and Madeleine Udell", "title": "ControlBurn: Feature Selection by Sparse Forests", "comments": "15 pages", "journal-ref": null, "doi": "10.1145/3447548.3467387", "report-no": null, "categories": "cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tree ensembles distribute feature importance evenly amongst groups of\ncorrelated features. The average feature ranking of the correlated group is\nsuppressed, which reduces interpretability and complicates feature selection.\nIn this paper we present ControlBurn, a feature selection algorithm that uses a\nweighted LASSO-based feature selection method to prune unnecessary features\nfrom tree ensembles, just as low-intensity fire reduces overgrown vegetation.\nLike the linear LASSO, ControlBurn assigns all the feature importance of a\ncorrelated group of features to a single feature. Moreover, the algorithm is\nefficient and only requires a single training iteration to run, unlike\niterative wrapper-based feature selection methods. We show that ControlBurn\nperforms substantially better than feature selection methods with comparable\ncomputational costs on datasets with correlated features.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 05:14:51 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Liu", "Brian", ""], ["Xie", "Miaolan", ""], ["Udell", "Madeleine", ""]]}, {"id": "2107.00223", "submitter": "Kei Uchizawa Dr.", "authors": "Kei Uchizawa and Haruki Abe", "title": "Circuit Complexity of Visual Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study computational hardness of feature and conjunction search through the\nlens of circuit complexity. Let $x = (x_1, ... , x_n)$ (resp., $y = (y_1, ... ,\ny_n)$) be Boolean variables each of which takes the value one if and only if a\nneuron at place $i$ detects a feature (resp., another feature). We then simply\nformulate the feature and conjunction search as Boolean functions ${\\rm\nFTR}_n(x) = \\bigvee_{i=1}^n x_i$ and ${\\rm CONJ}_n(x, y) = \\bigvee_{i=1}^n x_i\n\\wedge y_i$, respectively. We employ a threshold circuit or a discretized\ncircuit (such as a sigmoid circuit or a ReLU circuit with discretization) as\nour models of neural networks, and consider the following four computational\nresources: [i] the number of neurons (size), [ii] the number of levels (depth),\n[iii] the number of active neurons outputting non-zero values (energy), and\n[iv] synaptic weight resolution (weight).\n  We first prove that any threshold circuit $C$ of size $s$, depth $d$, energy\n$e$ and weight $w$ satisfies $\\log rk(M_C) \\le ed (\\log s + \\log w + \\log n)$,\nwhere $rk(M_C)$ is the rank of the communication matrix $M_C$ of a\n$2n$-variable Boolean function that $C$ computes. Since ${\\rm CONJ}_n$ has rank\n$2^n$, we have $n \\le ed (\\log s + \\log w + \\log n)$. Thus, an exponential\nlower bound on the size of even sublinear-depth threshold circuits exists if\nthe energy and weight are sufficiently small. Since ${\\rm FTR}_n$ is computable\nindependently of $n$, our result suggests that computational capacity for the\nfeature and conjunction search are different. We also show that the inequality\nis tight up to a constant factor if $ed = o(n/ \\log n)$. We next show that a\nsimilar inequality holds for any discretized circuit. Thus, if we regard the\nnumber of gates outputting non-zero values as a measure for sparse activity,\nour results suggest that larger depth helps neural networks to acquire sparse\nactivity.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 05:37:53 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Uchizawa", "Kei", ""], ["Abe", "Haruki", ""]]}, {"id": "2107.00228", "submitter": "Marc Fischer", "authors": "Marc Fischer, Maximilian Baader, Martin Vechev", "title": "Scalable Certified Segmentation via Randomized Smoothing", "comments": "ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new certification method for image and point cloud segmentation\nbased on randomized smoothing. The method leverages a novel scalable algorithm\nfor prediction and certification that correctly accounts for multiple testing,\nnecessary for ensuring statistical guarantees. The key to our approach is\nreliance on established multiple-testing correction mechanisms as well as the\nability to abstain from classifying single pixels or points while still\nrobustly segmenting the overall input. Our experimental evaluation on synthetic\ndata and challenging datasets, such as Pascal Context, Cityscapes, and\nShapeNet, shows that our algorithm can achieve, for the first time, competitive\naccuracy and certification guarantees on real-world segmentation tasks. We\nprovide an implementation at https://github.com/eth-sri/segmentation-smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 05:52:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Fischer", "Marc", ""], ["Baader", "Maximilian", ""], ["Vechev", "Martin", ""]]}, {"id": "2107.00230", "submitter": "Binghui Li", "authors": "Binghui Li, Shiji Xin, Qizhe Zhang", "title": "Boosting Certified $\\ell_\\infty$ Robustness with EMA Method and Ensemble\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural network with $1$-Lipschitz property based on $\\ell_\\infty$-dist\nneuron has a theoretical guarantee in certified $\\ell_\\infty$ robustness.\nHowever, due to the inherent difficulties in the training of the network, the\ncertified accuracy of previous work is limited. In this paper, we propose two\napproaches to deal with these difficuties. Aiming at the characteristics of the\ntraining process based on $\\ell_\\infty$-norm neural network, we introduce the\nEMA method to improve the training process. Considering the randomness of the\ntraining algorithm, we propose an ensemble method based on trained base models\nthat have the $1$-Lipschitz property and gain significant improvement in the\nsmall parameter network. Moreover, we give the theoretical analysis of the\nensemble method based on the $1$-Lipschitz property on the certified\nrobustness, which ensures the effectiveness and stability of the algorithm. Our\ncode is available at\nhttps://github.com/Theia-4869/EMA-and-Ensemble-Lip-Networks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:01:12 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Binghui", ""], ["Xin", "Shiji", ""], ["Zhang", "Qizhe", ""]]}, {"id": "2107.00231", "submitter": "Bochen Li", "authors": "Bochen Li, Yuxuan Wang, and Zhiyao Duan", "title": "Audiovisual Singing Voice Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Separating a song into vocal and accompaniment components is an active\nresearch topic, and recent years witnessed an increased performance from\nsupervised training using deep learning techniques. We propose to apply the\nvisual information corresponding to the singers' vocal activities to further\nimprove the quality of the separated vocal signals. The video frontend model\ntakes the input of mouth movement and fuses it into the feature embeddings of\nan audio-based separation framework. To facilitate the network to learn\naudiovisual correlation of singing activities, we add extra vocal signals\nirrelevant to the mouth movement to the audio mixture during training. We\ncreate two audiovisual singing performance datasets for training and\nevaluation, respectively, one curated from audition recordings on the Internet,\nand the other recorded in house. The proposed method outperforms audio-based\nmethods in terms of separation quality on most test recordings. This advantage\nis especially pronounced when there are backing vocals in the accompaniment,\nwhich poses a great challenge for audio-only methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:04:53 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Bochen", ""], ["Wang", "Yuxuan", ""], ["Duan", "Zhiyao", ""]]}, {"id": "2107.00233", "submitter": "Tehrim Yoon", "authors": "Tehrim Yoon, Sumin Shin, Sung Ju Hwang, Eunho Yang", "title": "FedMix: Approximation of Mixup under Mean Augmented Federated Learning", "comments": null, "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) allows edge devices to collectively learn a model\nwithout directly sharing data within each device, thus preserving privacy and\neliminating the need to store data globally. While there are promising results\nunder the assumption of independent and identically distributed (iid) local\ndata, current state-of-the-art algorithms suffer from performance degradation\nas the heterogeneity of local data across clients increases. To resolve this\nissue, we propose a simple framework, Mean Augmented Federated Learning (MAFL),\nwhere clients send and receive averaged local data, subject to the privacy\nrequirements of target applications. Under our framework, we propose a new\naugmentation algorithm, named FedMix, which is inspired by a phenomenal yet\nsimple data augmentation method, Mixup, but does not require local raw data to\nbe directly shared among devices. Our method shows greatly improved performance\nin the standard benchmark datasets of FL, under highly non-iid federated\nsettings, compared to conventional algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:14:51 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yoon", "Tehrim", ""], ["Shin", "Sumin", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Eunho", ""]]}, {"id": "2107.00243", "submitter": "Jonathan Wenger", "authors": "Jonathan Wenger and Geoff Pleiss and Philipp Hennig and John P.\n  Cunningham and Jacob R. Gardner", "title": "Reducing the Variance of Gaussian Process Hyperparameter Optimization\n  with Preconditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes remain popular as a flexible and expressive model class,\nbut the computational cost of kernel hyperparameter optimization stands as a\nmajor limiting factor to their scaling and broader adoption. Recent work has\nmade great strides combining stochastic estimation with iterative numerical\ntechniques, essentially boiling down GP inference to the cost of (many)\nmatrix-vector multiplies. Preconditioning -- a highly effective step for any\niterative method involving matrix-vector multiplication -- can be used to\naccelerate convergence and thus reduce bias in hyperparameter optimization.\nHere, we prove that preconditioning has an additional benefit that has been\npreviously unexplored. It not only reduces the bias of the $\\log$-marginal\nlikelihood estimator and its derivatives, but it also simultaneously can reduce\nvariance at essentially negligible cost. We leverage this result to derive\nsample-efficient algorithms for GP hyperparameter optimization requiring as few\nas $\\mathcal{O}(\\log(\\varepsilon^{-1}))$ instead of\n$\\mathcal{O}(\\varepsilon^{-2})$ samples to achieve error $\\varepsilon$. Our\ntheoretical results enable provably efficient and scalable optimization of\nkernel hyperparameters, which we validate empirically on a set of large-scale\nbenchmark problems. There, variance reduction via preconditioning results in an\norder of magnitude speedup in hyperparameter optimization of exact GPs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:43:11 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wenger", "Jonathan", ""], ["Pleiss", "Geoff", ""], ["Hennig", "Philipp", ""], ["Cunningham", "John P.", ""], ["Gardner", "Jacob R.", ""]]}, {"id": "2107.00247", "submitter": "Mohammad Hossein Rohban", "authors": "Alireza Mousavi Hosseini, Amir Mohammad Abouei, Mohammad Hossein\n  Rohban", "title": "The Interplay between Distribution Parameters and the\n  Accuracy-Robustness Tradeoff in Classification", "comments": "Accepted for presentation in AML ICML workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial training tends to result in models that are less accurate on\nnatural (unperturbed) examples compared to standard models. This can be\nattributed to either an algorithmic shortcoming or a fundamental property of\nthe training data distribution, which admits different solutions for optimal\nstandard and adversarial classifiers. In this work, we focus on the latter case\nunder a binary Gaussian mixture classification problem. Unlike earlier work, we\naim to derive the natural accuracy gap between the optimal Bayes and\nadversarial classifiers, and study the effect of different distributional\nparameters, namely separation between class centroids, class proportions, and\nthe covariance matrix, on the derived gap. We show that under certain\nconditions, the natural error of the optimal adversarial classifier, as well as\nthe gap, are locally minimized when classes are balanced, contradicting the\nperformance of the Bayes classifier where perfect balance induces the worst\naccuracy. Moreover, we show that with an $\\ell_\\infty$ bounded perturbation and\nan adversarial budget of $\\epsilon$, this gap is $\\Theta(\\epsilon^2)$ for the\nworst-case parameters, which for suitably small $\\epsilon$ indicates the\ntheoretical possibility of achieving robust classifiers with near-perfect\naccuracy, which is rarely reflected in practical algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 06:57:50 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Hosseini", "Alireza Mousavi", ""], ["Abouei", "Amir Mohammad", ""], ["Rohban", "Mohammad Hossein", ""]]}, {"id": "2107.00254", "submitter": "Mingkui Tan", "authors": "Shuaicheng Niu, Jiaxiang Wu, Guanghui Xu, Yifan Zhang, Yong Guo,\n  Peilin Zhao, Peng Wang, Mingkui Tan", "title": "AdaXpert: Adapting Neural Architecture for Growing Data", "comments": "accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications, data often come in a growing manner, where the\ndata volume and the number of classes may increase dynamically. This will bring\na critical challenge for learning: given the increasing data volume or the\nnumber of classes, one has to instantaneously adjust the neural model capacity\nto obtain promising performance. Existing methods either ignore the growing\nnature of data or seek to independently search an optimal architecture for a\ngiven dataset, and thus are incapable of promptly adjusting the architectures\nfor the changed data. To address this, we present a neural architecture\nadaptation method, namely Adaptation eXpert (AdaXpert), to efficiently adjust\nprevious architectures on the growing data. Specifically, we introduce an\narchitecture adjuster to generate a suitable architecture for each data\nsnapshot, based on the previous architecture and the different extent between\ncurrent and previous data distributions. Furthermore, we propose an adaptation\ncondition to determine the necessity of adjustment, thereby avoiding\nunnecessary and time-consuming adjustments. Extensive experiments on two growth\nscenarios (increasing data volume and number of classes) demonstrate the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 07:22:05 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Niu", "Shuaicheng", ""], ["Wu", "Jiaxiang", ""], ["Xu", "Guanghui", ""], ["Zhang", "Yifan", ""], ["Guo", "Yong", ""], ["Zhao", "Peilin", ""], ["Wang", "Peng", ""], ["Tan", "Mingkui", ""]]}, {"id": "2107.00272", "submitter": "David Ahmedt-Aristizabal", "authors": "David Ahmedt-Aristizabal, Mohammad Ali Armin, Simon Denman, Clinton\n  Fookes, Lars Petersson", "title": "A Survey on Graph-Based Deep Learning for Computational Histopathology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the remarkable success of representation learning for prediction\nproblems, we have witnessed a rapid expansion of the use of machine learning\nand deep learning for the analysis of digital pathology and biopsy image\npatches. However, traditional learning over patch-wise features using\nconvolutional neural networks limits the model when attempting to capture\nglobal contextual information. The phenotypical and topological distribution of\nconstituent histological entities play a critical role in tissue diagnosis. As\nsuch, graph data representations and deep learning have attracted significant\nattention for encoding tissue representations, and capturing intra- and inter-\nentity level interactions. In this review, we provide a conceptual grounding of\ngraph-based deep learning and discuss its current success for tumor\nlocalization and classification, tumor invasion and staging, image retrieval,\nand survival prediction. We provide an overview of these methods in a\nsystematic manner organized by the graph representation of the input image\nincluding whole slide images and tissue microarrays. We also outline the\nlimitations of existing techniques, and suggest potential future advances in\nthis domain.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 07:50:35 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ahmedt-Aristizabal", "David", ""], ["Armin", "Mohammad Ali", ""], ["Denman", "Simon", ""], ["Fookes", "Clinton", ""], ["Petersson", "Lars", ""]]}, {"id": "2107.00283", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Steven A. Hicks, P{\\aa}l Halvorsen, Michael A.\n  Riegler", "title": "DivergentNets: Medical Image Segmentation by Network Ensemble", "comments": "the winning model of the segmentation generalization challenge at\n  EndoCV 2021", "journal-ref": "Proceedings of the 3rd International Workshop and Challenge on\n  Computer Vision in Endoscopy (EndoCV 2021) colocated with with the 17th IEEE\n  International Symposium on Biomedical Imaging (ISBI 2021)", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detection of colon polyps has become a trending topic in the intersecting\nfields of machine learning and gastrointestinal endoscopy. The focus has mainly\nbeen on per-frame classification. More recently, polyp segmentation has gained\nattention in the medical community. Segmentation has the advantage of being\nmore accurate than per-frame classification or object detection as it can show\nthe affected area in greater detail. For our contribution to the EndoCV 2021\nsegmentation challenge, we propose two separate approaches. First, a\nsegmentation model named TriUNet composed of three separate UNet models.\nSecond, we combine TriUNet with an ensemble of well-known segmentation models,\nnamely UNet++, FPN, DeepLabv3, and DeepLabv3+, into a model called\nDivergentNets to produce more generalizable medical image segmentation masks.\nIn addition, we propose a modified Dice loss that calculates loss only for a\nsingle class when performing multiclass segmentation, forcing the model to\nfocus on what is most important. Overall, the proposed methods achieved the\nbest average scores for each respective round in the challenge, with TriUNet\nbeing the winning model in Round I and DivergentNets being the winning model in\nRound II of the segmentation generalization challenge at EndoCV 2021. The\nimplementation of our approach is made publicly available on GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 08:15:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Thambawita", "Vajira", ""], ["Hicks", "Steven A.", ""], ["Halvorsen", "P\u00e5l", ""], ["Riegler", "Michael A.", ""]]}, {"id": "2107.00284", "submitter": "Kai Liu", "authors": "Kai Liu and Yuyang Zhao and Gang Wang and Bei Peng", "title": "SA-MATD3:Self-attention-based multi-agent continuous control method in\n  cooperative environments", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cooperative problems under continuous control have always been the focus of\nmulti-agent reinforcement learning. Existing algorithms suffer from the problem\nof uneven learning degree with the increase of the number of agents. In this\npaper, a new structure for a multi-agent actor critic is proposed, and the\nself-attention mechanism is applied in the critic network and the value\ndecomposition method used to solve the uneven problem. The proposed algorithm\nmakes full use of the samples in the replay memory buffer to learn the behavior\nof a class of agents. First, a new update method is proposed for policy\nnetworks that promotes learning efficiency. Second, the utilization of samples\nis improved, at the same time reflecting the ability of perspective-taking\namong groups. Finally, the \"deceptive signal\" in training is eliminated and the\nlearning degree among agents is more uniform than in the existing methods.\nMultiple experiments were conducted in two typical scenarios of a multi-agent\nparticle environment. Experimental results show that the proposed algorithm can\nperform better than the state-of-the-art ones, and that it exhibits higher\nlearning efficiency with an increasing number of agents.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 08:15:05 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Kai", ""], ["Zhao", "Yuyang", ""], ["Wang", "Gang", ""], ["Peng", "Bei", ""]]}, {"id": "2107.00296", "submitter": "Yuhao Niu", "authors": "Yuhao Niu, Lin Gu, Yitian Zhao, Feng Lu", "title": "Explainable Diabetic Retinopathy Detection and Retinal Image Generation", "comments": "Code is available at https://github.com/zzdyyy/Patho-GAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though deep learning has shown successful performance in classifying the\nlabel and severity stage of certain diseases, most of them give few\nexplanations on how to make predictions. Inspired by Koch's Postulates, the\nfoundation in evidence-based medicine (EBM) to identify the pathogen, we\npropose to exploit the interpretability of deep learning application in medical\ndiagnosis. By determining and isolating the neuron activation patterns on which\ndiabetic retinopathy (DR) detector relies to make decisions, we demonstrate the\ndirect relation between the isolated neuron activation and lesions for a\npathological explanation. To be specific, we first define novel pathological\ndescriptors using activated neurons of the DR detector to encode both spatial\nand appearance information of lesions. Then, to visualize the symptom encoded\nin the descriptor, we propose Patho-GAN, a new network to synthesize medically\nplausible retinal images. By manipulating these descriptors, we could even\narbitrarily control the position, quantity, and categories of generated\nlesions. We also show that our synthesized images carry the symptoms directly\nrelated to diabetic retinopathy diagnosis. Our generated images are both\nqualitatively and quantitatively superior to the ones by previous methods.\nBesides, compared to existing methods that take hours to generate an image, our\nsecond level speed endows the potential to be an effective solution for data\naugmentation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 08:30:04 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Niu", "Yuhao", ""], ["Gu", "Lin", ""], ["Zhao", "Yitian", ""], ["Lu", "Feng", ""]]}, {"id": "2107.00306", "submitter": "Rui Yang", "authors": "Rui Yang, Meng Fang, Lei Han, Yali Du, Feng Luo, Xiu Li", "title": "MHER: Model-based Hindsight Experience Replay", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving multi-goal reinforcement learning (RL) problems with sparse rewards\nis generally challenging. Existing approaches have utilized goal relabeling on\ncollected experiences to alleviate issues raised from sparse rewards. However,\nthese methods are still limited in efficiency and cannot make full use of\nexperiences. In this paper, we propose Model-based Hindsight Experience Replay\n(MHER), which exploits experiences more efficiently by leveraging environmental\ndynamics to generate virtual achieved goals. Replacing original goals with\nvirtual goals generated from interaction with a trained dynamics model leads to\na novel relabeling method, \\emph{model-based relabeling} (MBR). Based on MBR,\nMHER performs both reinforcement learning and supervised learning for efficient\npolicy improvement. Theoretically, we also prove the supervised part in MHER,\ni.e., goal-conditioned supervised learning with MBR data, optimizes a lower\nbound on the multi-goal RL objective. Experimental results in several\npoint-based tasks and simulated robotics environments show that MHER achieves\nsignificantly higher sample efficiency than previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 08:52:45 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yang", "Rui", ""], ["Fang", "Meng", ""], ["Han", "Lei", ""], ["Du", "Yali", ""], ["Luo", "Feng", ""], ["Li", "Xiu", ""]]}, {"id": "2107.00309", "submitter": "Haibin Wu", "authors": "Haibin Wu, Po-chun Hsu, Ji Gao, Shanshan Zhang, Shen Huang, Jian Kang,\n  Zhiyong Wu, Helen Meng, Hung-yi Lee", "title": "Spotting adversarial samples for speaker verification by neural vocoders", "comments": "Submitted to ASRU 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Automatic speaker verification (ASV), one of the most important technology\nfor biometric identification, has been widely adopted in security-critical\napplications, including transaction authentication and access control. However,\nprevious work has shown that ASV is seriously vulnerable to recently emerged\nadversarial attacks, yet effective countermeasures against them are limited. In\nthis paper, we adopt neural vocoders to spot adversarial samples for ASV. We\nuse the neural vocoder to re-synthesize audio and find that the difference\nbetween the ASV scores for the original and re-synthesized audio is a good\nindicator for discrimination between genuine and adversarial samples. This\neffort is, to the best of our knowledge, among the first to pursue such a\ntechnical direction for detecting adversarial samples for ASV, and hence there\nis a lack of established baselines for comparison. Consequently, we implement\nthe Griffin-Lim algorithm as the detection baseline. The proposed approach\nachieves effective detection performance that outperforms all the baselines in\nall the settings. We also show that the neural vocoder adopted in the detection\nframework is dataset-independent. Our codes will be made open-source for future\nworks to do comparison.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 08:58:16 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 07:47:17 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wu", "Haibin", ""], ["Hsu", "Po-chun", ""], ["Gao", "Ji", ""], ["Zhang", "Shanshan", ""], ["Huang", "Shen", ""], ["Kang", "Jian", ""], ["Wu", "Zhiyong", ""], ["Meng", "Helen", ""], ["Lee", "Hung-yi", ""]]}, {"id": "2107.00315", "submitter": "Neeraj Varshney", "authors": "Neeraj Varshney, Swaroop Mishra, Chitta Baral", "title": "Interviewer-Candidate Role Play: Towards Developing Real-World NLP\n  Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard NLP tasks do not incorporate several common real-world scenarios\nsuch as seeking clarifications about the question, taking advantage of clues,\nabstaining in order to avoid incorrect answers, etc. This difference in task\nformulation hinders the adoption of NLP systems in real-world settings. In this\nwork, we take a step towards bridging this gap and present a multi-stage task\nthat simulates a typical human-human questioner-responder interaction such as\nan interview. Specifically, the system is provided with question\nsimplifications, knowledge statements, examples, etc. at various stages to\nimprove its prediction when it is not sufficiently confident. We instantiate\nthe proposed task in Natural Language Inference setting where a system is\nevaluated on both in-domain and out-of-domain (OOD) inputs. We conduct\ncomprehensive experiments and find that the multi-stage formulation of our task\nleads to OOD generalization performance improvement up to 2.29% in Stage 1,\n1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard\nunguided prediction. However, our task leaves a significant challenge for NLP\nresearchers to further improve OOD performance at each stage.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:08:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Varshney", "Neeraj", ""], ["Mishra", "Swaroop", ""], ["Baral", "Chitta", ""]]}, {"id": "2107.00323", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Sarthak Jain, Sameer Singh and Byron C. Wallace", "title": "Combining Feature and Instance Attribution to Detect Artifacts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training the large deep neural networks that dominate NLP requires large\ndatasets. Many of these are collected automatically or via crowdsourcing, and\nmay exhibit systematic biases or annotation artifacts. By the latter, we mean\ncorrelations between inputs and outputs that are spurious, insofar as they do\nnot represent a generally held causal relationship between features and\nclasses; models that exploit such correlations may appear to perform a given\ntask well, but fail on out of sample data. In this paper we propose methods to\nfacilitate identification of training data artifacts, using new hybrid\napproaches that combine saliency maps (which highlight important input\nfeatures) with instance attribution methods (which retrieve training samples\ninfluential to a given prediction). We show that this proposed training-feature\nattribution approach can be used to uncover artifacts in training data, and use\nit to identify previously unreported artifacts in a few standard NLP datasets.\nWe execute a small user study to evaluate whether these methods are useful to\nNLP researchers in practice, with promising results. We make code for all\nmethods and experiments in this paper available.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:26:13 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Jain", "Sarthak", ""], ["Singh", "Sameer", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2107.00339", "submitter": "Grace Zhang", "authors": "Grace Zhang, Linghan Zhong, Youngwoon Lee, Joseph J. Lim", "title": "Policy Transfer across Visual and Dynamics Domain Gaps via Iterative\n  Grounding", "comments": "Robotics: Science and Systems (RSS), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to transfer a policy from one environment to another is a\npromising avenue for efficient robot learning in realistic settings where task\nsupervision is not available. This can allow us to take advantage of\nenvironments well suited for training, such as simulators or laboratories, to\nlearn a policy for a real robot in a home or office. To succeed, such policy\ntransfer must overcome both the visual domain gap (e.g. different illumination\nor background) and the dynamics domain gap (e.g. different robot calibration or\nmodelling error) between source and target environments. However, prior policy\ntransfer approaches either cannot handle a large domain gap or can only address\none type of domain gap at a time. In this paper, we propose a novel policy\ntransfer method with iterative \"environment grounding\", IDAPT, that alternates\nbetween (1) directly minimizing both visual and dynamics domain gaps by\ngrounding the source environment in the target environment domains, and (2)\ntraining a policy on the grounded source environment. This iterative training\nprogressively aligns the domains between the two environments and adapts the\npolicy to the target environment. Once trained, the policy can be directly\nexecuted on the target environment. The empirical results on locomotion and\nrobotic manipulation tasks demonstrate that our approach can effectively\ntransfer a policy across visual and dynamics domain gaps with minimal\nsupervision and interaction with the target environment. Videos and code are\navailable at https://clvrai.com/idapt .\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:09:59 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zhang", "Grace", ""], ["Zhong", "Linghan", ""], ["Lee", "Youngwoon", ""], ["Lim", "Joseph J.", ""]]}, {"id": "2107.00352", "submitter": "Yifei Wang", "authors": "Yifei Wang, Yisen Wang, Jiansheng Yang, Zhouchen Lin", "title": "Reparameterized Sampling for Generative Adversarial Networks", "comments": "ECML PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, sampling methods have been successfully applied to enhance the\nsample quality of Generative Adversarial Networks (GANs). However, in practice,\nthey typically have poor sample efficiency because of the independent proposal\nsampling from the generator. In this work, we propose REP-GAN, a novel sampling\nmethod that allows general dependent proposals by REParameterizing the Markov\nchains into the latent space of the generator. Theoretically, we show that our\nreparameterized proposal admits a closed-form Metropolis-Hastings acceptance\nratio. Empirically, extensive experiments on synthetic and real datasets\ndemonstrate that our REP-GAN largely improves the sample efficiency and obtains\nbetter sample quality simultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:34:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Yifei", ""], ["Wang", "Yisen", ""], ["Yang", "Jiansheng", ""], ["Lin", "Zhouchen", ""]]}, {"id": "2107.00359", "submitter": "Hadi Beik-Mohammadi", "authors": "Hadi Beik-Mohammadi, Matthias Kerzel, Benedikt Pleintinger, Thomas\n  Hulin, Philipp Reisich, Annika Schmidt, Aaron Pereira, Stefan Wermter, Neal\n  Y. Lii", "title": "Model Mediated Teleoperation with a Hand-Arm Exoskeleton in Long Time\n  Delays Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Telerobotic systems must adapt to new environmental conditions and deal with\nhigh uncertainty caused by long-time delays. As one of the best alternatives to\nhuman-level intelligence, Reinforcement Learning (RL) may offer a solution to\ncope with these issues. This paper proposes to integrate RL with the Model\nMediated Teleoperation (MMT) concept. The teleoperator interacts with a\nsimulated virtual environment, which provides instant feedback. Whereas\nfeedback from the real environment is delayed, feedback from the model is\ninstantaneous, leading to high transparency. The MMT is realized in combination\nwith an intelligent system with two layers. The first layer utilizes Dynamic\nMovement Primitives (DMP) which accounts for certain changes in the avatar\nenvironment. And, the second layer addresses the problems caused by uncertainty\nin the model using RL methods. Augmented reality was also provided to fuse the\navatar device and virtual environment models for the teleoperator. Implemented\non DLR's Exodex Adam hand-arm haptic exoskeleton, the results show RL methods\nare able to find different solutions when changes are applied to the object\nposition after the demonstration. The results also show DMPs to be effective at\nadapting to new conditions where there is no uncertainty involved.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:49:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Beik-Mohammadi", "Hadi", ""], ["Kerzel", "Matthias", ""], ["Pleintinger", "Benedikt", ""], ["Hulin", "Thomas", ""], ["Reisich", "Philipp", ""], ["Schmidt", "Annika", ""], ["Pereira", "Aaron", ""], ["Wermter", "Stefan", ""], ["Lii", "Neal Y.", ""]]}, {"id": "2107.00360", "submitter": "Marco Huber", "authors": "Nina Schaaf, Omar de Mitri, Hang Beom Kim, Alexander Windberger, Marco\n  F. Huber", "title": "Towards Measuring Bias in Image Classification", "comments": "Accepted for publication at the 30th International Conference on\n  Artificial Neural Networks (ICANN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have become de fact state-of-the-art for\nthe main computer vision tasks. However, due to the complex underlying\nstructure their decisions are hard to understand which limits their use in some\ncontext of the industrial world. A common and hard to detect challenge in\nmachine learning (ML) tasks is data bias. In this work, we present a systematic\napproach to uncover data bias by means of attribution maps. For this purpose,\nfirst an artificial dataset with a known bias is created and used to train\nintentionally biased CNNs. The networks' decisions are then inspected using\nattribution maps. Finally, meaningful metrics are used to measure the\nattribution maps' representativeness with respect to the known bias. The\nproposed study shows that some attribution map techniques highlight the\npresence of bias in the data better than others and metrics can support the\nidentification of bias.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:50:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Schaaf", "Nina", ""], ["de Mitri", "Omar", ""], ["Kim", "Hang Beom", ""], ["Windberger", "Alexander", ""], ["Huber", "Marco F.", ""]]}, {"id": "2107.00363", "submitter": "Nicolas Dewolf", "authors": "Nicolas Dewolf, Bernard De Baets, Willem Waegeman", "title": "Well-calibrated prediction intervals for regression problems", "comments": "submitted to AI Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last few decades, various methods have been proposed for estimating\nprediction intervals in regression settings, including Bayesian methods,\nensemble methods, direct interval estimation methods and conformal prediction\nmethods. An important issue is the calibration of these methods: the generated\nprediction intervals should have a predefined coverage level, without being\noverly conservative. In this work, we review the above four classes of methods\nfrom a conceptual and experimental point of view. Results on benchmark data\nsets from various domains highlight large fluctuations in performance from one\ndata set to another. These observations can be attributed to the violation of\ncertain assumptions that are inherent to some classes of methods. We illustrate\nhow conformal prediction can be used as a general calibration procedure for\nmethods that deliver poor results without a calibration step.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:59:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dewolf", "Nicolas", ""], ["De Baets", "Bernard", ""], ["Waegeman", "Willem", ""]]}, {"id": "2107.00364", "submitter": "Etai Littwin", "authors": "Etai Littwin, Omid Saremi, Shuangfei Zhai, Vimal Thilak, Hanlin Goh,\n  Joshua M. Susskind, Greg Yang", "title": "Implicit Acceleration and Feature Learning in Infinitely Wide Neural\n  Networks with Bottlenecks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We analyze the learning dynamics of infinitely wide neural networks with a\nfinite sized bottle-neck. Unlike the neural tangent kernel limit, a bottleneck\nin an otherwise infinite width network al-lows data dependent feature learning\nin its bottle-neck representation. We empirically show that a single bottleneck\nin infinite networks dramatically accelerates training when compared to purely\nin-finite networks, with an improved overall performance. We discuss the\nacceleration phenomena by drawing similarities to infinitely wide deep linear\nmodels, where the acceleration effect of a bottleneck can be understood\ntheoretically.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:00:43 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 08:32:58 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Littwin", "Etai", ""], ["Saremi", "Omid", ""], ["Zhai", "Shuangfei", ""], ["Thilak", "Vimal", ""], ["Goh", "Hanlin", ""], ["Susskind", "Joshua M.", ""], ["Yang", "Greg", ""]]}, {"id": "2107.00366", "submitter": "Hamed Damirchi", "authors": "Hamed Damirchi, Rooholla Khorrambakht, Hamid D. Taghirad, and Behzad\n  Moshiri", "title": "A Consistency-Based Loss for Deep Odometry Through Uncertainty\n  Propagation", "comments": "8 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The incremental poses computed through odometry can be integrated over time\nto calculate the pose of a device with respect to an initial location. The\nresulting global pose may be used to formulate a second, consistency based,\nloss term in a deep odometry setting. In such cases where multiple losses are\nimposed on a network, the uncertainty over each output can be derived to weigh\nthe different loss terms in a maximum likelihood setting. However, when\nimposing a constraint on the integrated transformation, due to how only\nodometry is estimated at each iteration of the algorithm, there is no\ninformation about the uncertainty associated with the global pose to weigh the\nglobal loss term. In this paper, we associate uncertainties with the output\nposes of a deep odometry network and propagate the uncertainties through each\niteration. Our goal is to use the estimated covariance matrix at each\nincremental step to weigh the loss at the corresponding step while weighting\nthe global loss term using the compounded uncertainty. This formulation\nprovides an adaptive method to weigh the incremental and integrated loss terms\nagainst each other, noting the increase in uncertainty as new estimates arrive.\nWe provide quantitative and qualitative analysis of pose estimates and show\nthat our method surpasses the accuracy of the state-of-the-art Visual Odometry\napproaches. Then, uncertainty estimates are evaluated and comparisons against\nfixed baselines are provided. Finally, the uncertainty values are used in a\nrealistic example to show the effectiveness of uncertainty quantification for\nlocalization.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:09:20 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Damirchi", "Hamed", ""], ["Khorrambakht", "Rooholla", ""], ["Taghirad", "Hamid D.", ""], ["Moshiri", "Behzad", ""]]}, {"id": "2107.00371", "submitter": "Sheng Gao", "authors": "Sheng Gao, Zongming Ma", "title": "Sparse GCA and Thresholded Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalized correlation analysis (GCA) is concerned with uncovering linear\nrelationships across multiple datasets. It generalizes canonical correlation\nanalysis that is designed for two datasets. We study sparse GCA when there are\npotentially multiple generalized correlation tuples in data and the loading\nmatrix has a small number of nonzero rows. It includes sparse CCA and sparse\nPCA of correlation matrices as special cases. We first formulate sparse GCA as\ngeneralized eigenvalue problems at both population and sample levels via a\ncareful choice of normalization constraints. Based on a Lagrangian form of the\nsample optimization problem, we propose a thresholded gradient descent\nalgorithm for estimating GCA loading vectors and matrices in high dimensions.\nWe derive tight estimation error bounds for estimators generated by the\nalgorithm with proper initialization. We also demonstrate the prowess of the\nalgorithm on a number of synthetic datasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:15:20 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Gao", "Sheng", ""], ["Ma", "Zongming", ""]]}, {"id": "2107.00379", "submitter": "Hanna Tseran", "authors": "Hanna Tseran, Guido Mont\\'ufar", "title": "On the Expected Complexity of Maxout Networks", "comments": "41 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with neural networks relies on the complexity of the representable\nfunctions, but more importantly, the particular assignment of typical\nparameters to functions of different complexity. Taking the number of\nactivation regions as a complexity measure, recent works have shown that the\npractical complexity of deep ReLU networks is often far from the theoretical\nmaximum. In this work we show that this phenomenon also occurs in networks with\nmaxout (multi-argument) activation functions and when considering the decision\nboundaries in classification tasks. We also show that the parameter space has a\nmultitude of full-dimensional regions with widely different complexity, and\nobtain nontrivial lower bounds on the expected complexity. Finally, we\ninvestigate different parameter initialization procedures and show that they\ncan increase the speed of convergence in training.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:36:32 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Tseran", "Hanna", ""], ["Mont\u00fafar", "Guido", ""]]}, {"id": "2107.00385", "submitter": "Viera Maslej-Kre\\v{s}\\v{n}\\'akov\\'a", "authors": "Viera Maslej-Kre\\v{s}\\v{n}\\'akov\\'a, Khadija El Bouchefry, Peter Butka", "title": "Morphological classification of compact and extended radio galaxies\n  using convolutional neural networks and data augmentation techniques", "comments": "12 pages, 7 figures, 9 tables, published in Monthly Notices of the\n  Royal Astronomical Society", "journal-ref": "Mon Not Roy Astron Soc 505 (2021) 1464-1475", "doi": "10.1093/mnras/stab1400", "report-no": null, "categories": "astro-ph.GA astro-ph.IM cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning techniques have been increasingly used in astronomical\napplications and have proven to successfully classify objects in image data\nwith high accuracy. The current work uses archival data from the Faint Images\nof the Radio Sky at Twenty Centimeters (FIRST) to classify radio galaxies into\nfour classes: Fanaroff-Riley Class I (FRI), Fanaroff-Riley Class II (FRII),\nBent-Tailed (BENT), and Compact (COMPT). The model presented in this work is\nbased on Convolutional Neural Networks (CNNs). The proposed architecture\ncomprises three parallel blocks of convolutional layers combined and processed\nfor final classification by two feed-forward layers. Our model classified\nselected classes of radio galaxy sources on an independent testing subset with\nan average of 96\\% for precision, recall, and F1 score. The best selected\naugmentation techniques were rotations, horizontal or vertical flips, and\nincrease of brightness. Shifts, zoom and decrease of brightness worsened the\nperformance of the model. The current results show that model developed in this\nwork is able to identify different morphological classes of radio galaxies with\na high efficiency and performance\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:53:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Maslej-Kre\u0161\u0148\u00e1kov\u00e1", "Viera", ""], ["Bouchefry", "Khadija El", ""], ["Butka", "Peter", ""]]}, {"id": "2107.00391", "submitter": "Luis Miguel L\\'opez-Ramos", "authors": "Luis Miguel Lopez-Ramos, Kevin Roy, Baltasar Beferull-Lozano", "title": "Explainable nonlinear modelling of multiple time series with invertible\n  neural networks", "comments": "4 figures, 13 pages (original submission 12 pages) Dubmitted to: 4th\n  International Conference on Intelligent Technologies and Applications (INTAP\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A method for nonlinear topology identification is proposed, based on the\nassumption that a collection of time series are generated in two steps: i) a\nvector autoregressive process in a latent space, and ii) a nonlinear,\ncomponent-wise, monotonically increasing observation mapping. The latter\nmappings are assumed invertible, and are modelled as shallow neural networks,\nso that their inverse can be numerically evaluated, and their parameters can be\nlearned using a technique inspired in deep learning. Due to the function\ninversion, the back-propagation step is not straightforward, and this paper\nexplains the steps needed to calculate the gradients applying implicit\ndifferentiation. Whereas the model explainability is the same as that for\nlinear VAR processes, preliminary numerical tests show that the prediction\nerror becomes smaller.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:07:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lopez-Ramos", "Luis Miguel", ""], ["Roy", "Kevin", ""], ["Beferull-Lozano", "Baltasar", ""]]}, {"id": "2107.00400", "submitter": "Dat Nguyen Thanh", "authors": "Dat Thanh Nguyen, Maurice Quach, Giuseppe Valenzise, Pierre Duhamel", "title": "Lossless Coding of Point Cloud Geometry using a Deep Generative Model", "comments": "This paper has been submitted to the IEEE Transactions on Circuits\n  and Systems for Video Technology (TCSVT). arXiv admin note: text overlap with\n  arXiv:2011.14700", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a lossless point cloud (PC) geometry compression method\nthat uses neural networks to estimate the probability distribution of voxel\noccupancy. First, to take into account the PC sparsity, our method adaptively\npartitions a point cloud into multiple voxel block sizes. This partitioning is\nsignalled via an octree. Second, we employ a deep auto-regressive generative\nmodel to estimate the occupancy probability of each voxel given the previously\nencoded ones. We then employ the estimated probabilities to code efficiently a\nblock using a context-based arithmetic coder. Our context has variable size and\ncan expand beyond the current block to learn more accurate probabilities. We\nalso consider using data augmentation techniques to increase the generalization\ncapability of the learned probability models, in particular in the presence of\nnoise and lower-density point clouds. Experimental evaluation, performed on a\nvariety of point clouds from four different datasets and with diverse\ncharacteristics, demonstrates that our method reduces significantly (by up to\n30%) the rate for lossless coding compared to the state-of-the-art MPEG codec.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:20:22 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Nguyen", "Dat Thanh", ""], ["Quach", "Maurice", ""], ["Valenzise", "Giuseppe", ""], ["Duhamel", "Pierre", ""]]}, {"id": "2107.00401", "submitter": "Alberto Marchisio", "authors": "Alberto Viale and Alberto Marchisio and Maurizio Martina and Guido\n  Masera and Muhammad Shafique", "title": "CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous\n  Cars on the Loihi Neuromorphic Research Processor", "comments": "Accepted for publication at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Driving (AD) related features provide new forms of mobility that\nare also beneficial for other kind of intelligent and autonomous systems like\nrobots, smart transportation, and smart industries. For these applications, the\ndecisions need to be made fast and in real-time. Moreover, in the quest for\nelectric mobility, this task must follow low power policy, without affecting\nmuch the autonomy of the mean of transport or the robot. These two challenges\ncan be tackled using the emerging Spiking Neural Networks (SNNs). When deployed\non a specialized neuromorphic hardware, SNNs can achieve high performance with\nlow latency and low power consumption. In this paper, we use an SNN connected\nto an event-based camera for facing one of the key problems for AD, i.e., the\nclassification between cars and other objects. To consume less power than\ntraditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The\nexperiments are made following an offline supervised learning rule, followed by\nmapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our\nbest experiment achieves an accuracy on offline implementation of 86%, that\ndrops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware\nimplementation has maximum 0.72 ms of latency for every sample, and consumes\nonly 310 mW. To the best of our knowledge, this work is the first\nimplementation of an event-based car classifier on a Neuromorphic Chip.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:20:48 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Viale", "Alberto", ""], ["Marchisio", "Alberto", ""], ["Martina", "Maurizio", ""], ["Masera", "Guido", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2107.00415", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio and Giacomo Pira and Maurizio Martina and Guido\n  Masera and Muhammad Shafique", "title": "DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking\n  Neural Networks", "comments": "Accepted for publication at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs), despite being energy-efficient when\nimplemented on neuromorphic hardware and coupled with event-based Dynamic\nVision Sensors (DVS), are vulnerable to security threats, such as adversarial\nattacks, i.e., small perturbations added to the input for inducing a\nmisclassification. Toward this, we propose DVS-Attacks, a set of stealthy yet\nefficient adversarial attack methodologies targeted to perturb the event\nsequences that compose the input of the SNNs. First, we show that noise filters\nfor DVS can be used as defense mechanisms against adversarial attacks.\nAfterwards, we implement several attacks and test them in the presence of two\ntypes of noise filters for DVS cameras. The experimental results show that the\nfilters can only partially defend the SNNs against our proposed DVS-Attacks.\nUsing the best settings for the noise filters, our proposed Mask Filter-Aware\nDash Attack reduces the accuracy by more than 20% on the DVS-Gesture dataset\nand by more than 65% on the MNIST dataset, compared to the original clean\nframes. The source code of all the proposed DVS-Attacks and noise filters is\nreleased at https://github.com/albertomarchisio/DVS-Attacks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:56:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Marchisio", "Alberto", ""], ["Pira", "Giacomo", ""], ["Martina", "Maurizio", ""], ["Masera", "Guido", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2107.00421", "submitter": "Wei Jiang", "authors": "Yiyang Chen, Wei Jiang and Themistoklis Charalambous", "title": "Machine learning based iterative learning control for non-repetitive\n  time-varying systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repetitive tracking task for time-varying systems (TVSs) with\nnon-repetitive time-varying parameters, which is also called non-repetitive\nTVSs, is realized in this paper using iterative learning control (ILC). A\nmachine learning (ML) based nominal model update mechanism, which utilizes the\nlinear regression technique to update the nominal model at each ILC trial only\nusing the current trial information, is proposed for non-repetitive TVSs in\norder to enhance the ILC performance. Given that the ML mechanism forces the\nmodel uncertainties to remain within the ILC robust tolerance, an ILC update\nlaw is proposed to deal with non-repetitive TVSs. How to tune parameters inside\nML and ILC algorithms to achieve the desired aggregate performance is also\nprovided. The robustness and reliability of the proposed method are verified by\nsimulations. Comparison with current state-of-the-art demonstrates its superior\ncontrol performance in terms of controlling precision. This paper broadens ILC\napplications from time-invariant systems to non-repetitive TVSs, adopts ML\nregression technique to estimate non-repetitive time-varying parameters between\ntwo ILC trials and proposes a detailed parameter tuning mechanism to achieve\ndesired performance, which are the main contributions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:06:33 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chen", "Yiyang", ""], ["Jiang", "Wei", ""], ["Charalambous", "Themistoklis", ""]]}, {"id": "2107.00425", "submitter": "Alejandro Morales-Hern\\'andez", "authors": "Alejandro Morales-Hern\\'andez, Gonzalo N\\'apoles, Agnieszka\n  Jastrzebska, Yamisleydi Salgueiro, Koen Vanhoof", "title": "Online learning of windmill time series using Long Short-term Cognitive\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Forecasting windmill time series is often the basis of other processes such\nas anomaly detection, health monitoring, or maintenance scheduling. The amount\nof data generated on windmill farms makes online learning the most viable\nstrategy to follow. Such settings require retraining the model each time a new\nbatch of data is available. However, update the model with the new information\nis often very expensive to perform using traditional Recurrent Neural Networks\n(RNNs). In this paper, we use Long Short-term Cognitive Networks (LSTCNs) to\nforecast windmill time series in online settings. These recently introduced\nneural systems consist of chained Short-term Cognitive Network blocks, each\nprocessing a temporal data chunk. The learning algorithm of these blocks is\nbased on a very fast, deterministic learning rule that makes LSTCNs suitable\nfor online learning tasks. The numerical simulations using a case study with\nfour windmills showed that our approach reported the lowest forecasting errors\nwith respect to a simple RNN, a Long Short-term Memory, a Gated Recurrent Unit,\nand a Hidden Markov Model. What is perhaps more important is that the LSTCN\napproach is significantly faster than these state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:13:24 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Morales-Hern\u00e1ndez", "Alejandro", ""], ["N\u00e1poles", "Gonzalo", ""], ["Jastrzebska", "Agnieszka", ""], ["Salgueiro", "Yamisleydi", ""], ["Vanhoof", "Koen", ""]]}, {"id": "2107.00429", "submitter": "Giovanni Volpe", "authors": "Yu-Wei Chang and Laura Natali and Oveis Jamialahmadi and Stefano Romeo\n  and Joana B. Pereira and Giovanni Volpe", "title": "Neural Network Training with Highly Incomplete Datasets", "comments": "11 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training and validation rely on the availability of large\nhigh-quality datasets. However, in many cases only incomplete datasets are\navailable, particularly in health care applications, where each patient\ntypically undergoes different clinical procedures or can drop out of a study.\nSince the data to train the neural networks need to be complete, most studies\ndiscard the incomplete datapoints, which reduces the size of the training data,\nor impute the missing features, which can lead to artefacts. Alas, both\napproaches are inadequate when a large portion of the data is missing. Here, we\nintroduce GapNet, an alternative deep-learning training approach that can use\nhighly incomplete datasets. First, the dataset is split into subsets of samples\ncontaining all values for a certain cluster of features. Then, these subsets\nare used to train individual neural networks. Finally, this ensemble of neural\nnetworks is combined into a single neural network whose training is fine-tuned\nusing all complete datapoints. Using two highly incomplete real-world medical\ndatasets, we show that GapNet improves the identification of patients with\nunderlying Alzheimer's disease pathology and of patients at risk of\nhospitalization due to Covid-19. By distilling the information available in\nincomplete datasets without having to reduce their size or to impute missing\nvalues, GapNet will permit to extract valuable information from a wide range of\ndatasets, benefiting diverse fields from medicine to engineering.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:21:45 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chang", "Yu-Wei", ""], ["Natali", "Laura", ""], ["Jamialahmadi", "Oveis", ""], ["Romeo", "Stefano", ""], ["Pereira", "Joana B.", ""], ["Volpe", "Giovanni", ""]]}, {"id": "2107.00436", "submitter": "Erik Larsen", "authors": "Erik Larsen, David Noever, Korey MacVittie and John Lilly", "title": "Overhead-MNIST: Machine Learning Baselines for Image Classification", "comments": "6 pages; 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Twenty-three machine learning algorithms were trained then scored to\nestablish baseline comparison metrics and to select an image classification\nalgorithm worthy of embedding into mission-critical satellite imaging systems.\nThe Overhead-MNIST dataset is a collection of satellite images similar in style\nto the ubiquitous MNIST hand-written digits found in the machine learning\nliterature. The CatBoost classifier, Light Gradient Boosting Machine, and\nExtreme Gradient Boosting models produced the highest accuracies, Areas Under\nthe Curve (AUC), and F1 scores in a PyCaret general comparison. Separate\nevaluations showed that a deep convolutional architecture was the most\npromising. We present results for the overall best performing algorithm as a\nbaseline for edge deployability and future performance improvement: a\nconvolutional neural network (CNN) scoring 0.965 categorical accuracy on unseen\ntest data.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:30:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Larsen", "Erik", ""], ["Noever", "David", ""], ["MacVittie", "Korey", ""], ["Lilly", "John", ""]]}, {"id": "2107.00451", "submitter": "Raivo Koot", "authors": "Raivo Koot, Haiping Lu", "title": "VideoLightFormer: Lightweight Action Recognition using Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient video action recognition remains a challenging problem. One large\nmodel after another takes the place of the state-of-the-art on the Kinetics\ndataset, but real-world efficiency evaluations are often lacking. In this work,\nwe fill this gap and investigate the use of transformers for efficient action\nrecognition. We propose a novel, lightweight action recognition architecture,\nVideoLightFormer. In a factorized fashion, we carefully extend the 2D\nconvolutional Temporal Segment Network with transformers, while maintaining\nspatial and temporal video structure throughout the entire model. Existing\nmethods often resort to one of the two extremes, where they either apply huge\ntransformers to video features, or minimal transformers on highly pooled video\nfeatures. Our method differs from them by keeping the transformer models small,\nbut leveraging full spatiotemporal feature structure. We evaluate\nVideoLightFormer in a high-efficiency setting on the temporally-demanding\nEPIC-KITCHENS-100 and Something-Something-V2 (SSV2) datasets and find that it\nachieves a better mix of efficiency and accuracy than existing state-of-the-art\nmodels, apart from the Temporal Shift Module on SSV2.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:55:52 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Koot", "Raivo", ""], ["Lu", "Haiping", ""]]}, {"id": "2107.00462", "submitter": "Skylar Wurster", "authors": "Skylar W. Wurster, Han-Wei Shen, Hanqi Guo, Thomas Peterka, Mukund\n  Raj, and Jiayi Xu", "title": "Deep Hierarchical Super-Resolution for Scientific Data Reduction and\n  Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for hierarchical super resolution (SR) using neural\nnetworks on an octree data representation. We train a hierarchy of neural\nnetworks, each capable of 2x upscaling in each spatial dimension between two\nlevels of detail, and use these networks in tandem to facilitate large scale\nfactor super resolution, scaling with the number of trained networks. We\nutilize these networks in a hierarchical super resolution algorithm that\nupscales multiresolution data to a uniform high resolution without introducing\nseam artifacts on octree node boundaries. We evaluate application of this\nalgorithm in a data reduction framework by dynamically downscaling input data\nto an octree-based data structure to represent the multiresolution data before\ncompressing for additional storage reduction. We demonstrate that our approach\navoids seam artifacts common to multiresolution data formats, and show how\nneural network super resolution assisted data reduction can preserve global\nfeatures better than compressors alone at the same compression ratios.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 18:32:11 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wurster", "Skylar W.", ""], ["Shen", "Han-Wei", ""], ["Guo", "Hanqi", ""], ["Peterka", "Thomas", ""], ["Raj", "Mukund", ""], ["Xu", "Jiayi", ""]]}, {"id": "2107.00464", "submitter": "Junchi Li", "authors": "Chris Junchi Li, Yaodong Yu, Nicolas Loizou, Gauthier Gidel, Yi Ma,\n  Nicolas Le Roux, Michael I. Jordan", "title": "On the Convergence of Stochastic Extragradient for Bilinear Games with\n  Restarted Iteration Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stochastic bilinear minimax optimization problem, presenting an\nanalysis of the Stochastic ExtraGradient (SEG) method with constant step size,\nand presenting variations of the method that yield favorable convergence. We\nfirst note that the last iterate of the basic SEG method only contracts to a\nfixed neighborhood of the Nash equilibrium, independent of the step size. This\ncontrasts sharply with the standard setting of minimization where standard\nstochastic algorithms converge to a neighborhood that vanishes in proportion to\nthe square-root (constant) step size. Under the same setting, however, we prove\nthat when augmented with iteration averaging, SEG provably converges to the\nNash equilibrium, and such a rate is provably accelerated by incorporating a\nscheduled restarting procedure. In the interpolation setting, we achieve an\noptimal convergence rate up to tight constants. We present numerical\nexperiments that validate our theoretical findings and demonstrate the\neffectiveness of the SEG method when equipped with iteration averaging and\nrestarting.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:51:36 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Chris Junchi", ""], ["Yu", "Yaodong", ""], ["Loizou", "Nicolas", ""], ["Gidel", "Gauthier", ""], ["Ma", "Yi", ""], ["Roux", "Nicolas Le", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2107.00465", "submitter": "Rahul Nellikkath", "authors": "Rahul Nellikkath, Spyros Chatzivasileiadis", "title": "Physics-Informed Neural Networks for Minimising Worst-Case Violations in\n  DC Optimal Power Flow", "comments": "The code to reproduce all simulation results is available online in\n  https://github.com/RahulNellikkath/Physics-Informed-Neural-Network-for-DC-OPF", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Physics-informed neural networks exploit the existing models of the\nunderlying physical systems to generate higher accuracy results with fewer\ndata. Such approaches can help drastically reduce the computation time and\ngenerate a good estimate of computationally intensive processes in power\nsystems, such as dynamic security assessment or optimal power flow. Combined\nwith the extraction of worst-case guarantees for the neural network\nperformance, such neural networks can be applied in safety-critical\napplications in power systems and build a high level of trust among power\nsystem operators. This paper takes the first step and applies, for the first\ntime to our knowledge, Physics-Informed Neural Networks with Worst-Case\nGuarantees for the DC Optimal Power Flow problem. We look for guarantees\nrelated to (i) maximum constraint violations, (ii) maximum distance between\npredicted and optimal decision variables, and (iii) maximum sub-optimality in\nthe entire input domain. In a range of PGLib-OPF networks, we demonstrate how\nphysics-informed neural networks can be supplied with worst-case guarantees and\nhow they can lead to reduced worst-case violations compared with conventional\nneural networks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 10:45:22 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Nellikkath", "Rahul", ""], ["Chatzivasileiadis", "Spyros", ""]]}, {"id": "2107.00469", "submitter": "Idan Amir", "authors": "Idan Amir, Yair Carmon, Tomer Koren, Roi Livni", "title": "Never Go Full Batch (in Stochastic Convex Optimization)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the generalization performance of $\\text{full-batch}$ optimization\nalgorithms for stochastic convex optimization: these are first-order methods\nthat only access the exact gradient of the empirical risk (rather than\ngradients with respect to individual data points), that include a wide range of\nalgorithms such as gradient descent, mirror descent, and their regularized\nand/or accelerated variants. We provide a new separation result showing that,\nwhile algorithms such as stochastic gradient descent can generalize and\noptimize the population risk to within $\\epsilon$ after $O(1/\\epsilon^2)$\niterations, full-batch methods either need at least $\\Omega(1/\\epsilon^4)$\niterations or exhibit a dimension-dependent sample complexity.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:07:50 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Amir", "Idan", ""], ["Carmon", "Yair", ""], ["Koren", "Tomer", ""], ["Livni", "Roi", ""]]}, {"id": "2107.00471", "submitter": "Vajira Thambawita", "authors": "Vajira Thambawita, Pegah Salehi, Sajad Amouei Sheshkal, Steven A.\n  Hicks, Hugo L.Hammer, Sravanthi Parasa, Thomas de Lange, P{\\aa}l Halvorsen,\n  Michael A. Riegler", "title": "SinGAN-Seg: Synthetic Training Data Generation for Medical Image\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Processing medical data to find abnormalities is a time-consuming and costly\ntask, requiring tremendous efforts from medical experts. Therefore, Ai has\nbecome a popular tool for the automatic processing of medical data, acting as a\nsupportive tool for doctors. AI tools highly depend on data for training the\nmodels. However, there are several constraints to access to large amounts of\nmedical data to train machine learning algorithms in the medical domain, e.g.,\ndue to privacy concerns and the costly, time-consuming medical data annotation\nprocess. To address this, in this paper we present a novel synthetic data\ngeneration pipeline called SinGAN-Seg to produce synthetic medical data with\nthe corresponding annotated ground truth masks. We show that these synthetic\ndata generation pipelines can be used as an alternative to bypass privacy\nconcerns and as an alternative way to produce artificial segmentation datasets\nwith corresponding ground truth masks to avoid the tedious medical data\nannotation process. As a proof of concept, we used an open polyp segmentation\ndataset. By training UNet++ using both the real polyp segmentation dataset and\nthe corresponding synthetic dataset generated from the SinGAN-Seg pipeline, we\nshow that the synthetic data can achieve a very close performance to the real\ndata when the real segmentation datasets are large enough. In addition, we show\nthat synthetic data generated from the SinGAN-Seg pipeline improving the\nperformance of segmentation algorithms when the training dataset is very small.\nSince our SinGAN-Seg pipeline is applicable for any medical dataset, this\npipeline can be used with any other segmentation datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:34:34 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Thambawita", "Vajira", ""], ["Salehi", "Pegah", ""], ["Sheshkal", "Sajad Amouei", ""], ["Hicks", "Steven A.", ""], ["Hammer", "Hugo L.", ""], ["Parasa", "Sravanthi", ""], ["de Lange", "Thomas", ""], ["Halvorsen", "P\u00e5l", ""], ["Riegler", "Michael A.", ""]]}, {"id": "2107.00472", "submitter": "Baojian Zhou", "authors": "Baojian Zhou, Yifan Sun", "title": "Approximate Frank-Wolfe Algorithms over Graph-structured Support Sets", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose approximate Frank-Wolfe (FW) algorithms to solve\nconvex optimization problems over graph-structured support sets where the\n\\textit{linear minimization oracle} (LMO) cannot be efficiently obtained in\ngeneral. We first demonstrate that two popular approximation assumptions\n(\\textit{additive} and \\textit{multiplicative gap errors)}, are not valid for\nour problem, in that no cheap gap-approximate LMO oracle exists in general.\nInstead, a new \\textit{approximate dual maximization oracle} (DMO) is proposed,\nwhich approximates the inner product rather than the gap. When the objective is\n$L$-smooth, we prove that the standard FW method using a $\\delta$-approximate\nDMO converges as $\\mathcal{O}(L / \\delta t + (1-\\delta)(\\delta^{-1} +\n\\delta^{-2}))$ in general, and as $\\mathcal{O}(L/(\\delta^2(t+2)))$ over a\n$\\delta$-relaxation of the constraint set. Additionally, when the objective is\n$\\mu$-strongly convex and the solution is unique, a variant of FW converges to\n$\\mathcal{O}(L^2\\log(t)/(\\mu \\delta^6 t^2))$ with the same per-iteration\ncomplexity. Our empirical results suggest that even these improved bounds are\npessimistic, with significant improvement in recovering real-world images with\ngraph-structured sparsity.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:39:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zhou", "Baojian", ""], ["Sun", "Yifan", ""]]}, {"id": "2107.00481", "submitter": "Wanlu Lei", "authors": "Wanlu Lei, Yu Ye, Ming Xiao, Mikael Skoglund, Zhu Han", "title": "Adaptive Stochastic ADMM for Decentralized Reinforcement Learning in\n  Edge Industrial IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing provides a promising paradigm to support the implementation of\nIndustrial Internet of Things (IIoT) by offloading tasks to nearby edge nodes.\nMeanwhile, the increasing network size makes it impractical for centralized\ndata processing due to limited bandwidth, and consequently a decentralized\nlearning scheme is preferable. Reinforcement learning (RL) has been widely\ninvestigated and shown to be a promising solution for decision-making and\noptimal control processes. For RL in a decentralized setup, edge nodes (agents)\nconnected through a communication network aim to work collaboratively to find a\npolicy to optimize the global reward as the sum of local rewards. However,\ncommunication costs, scalability and adaptation in complex environments with\nheterogeneous agents may significantly limit the performance of decentralized\nRL. Alternating direction method of multipliers (ADMM) has a structure that\nallows for decentralized implementation, and has shown faster convergence than\ngradient descent based methods. Therefore, we propose an adaptive stochastic\nincremental ADMM (asI-ADMM) algorithm and apply the asI-ADMM to decentralized\nRL with edge-computing-empowered IIoT networks. We provide convergence\nproperties for proposed algorithms by designing a Lyapunov function and prove\nthat the asI-ADMM has $O(\\frac{1}{k}) +O(\\frac{1}{M})$ convergence rate where\n$k$ and $ M$ are the number of iterations and batch samples, respectively.\nThen, we test our algorithm with two supervised learning problems. For\nperformance evaluation, we simulate two applications in decentralized RL\nsettings with homogeneous and heterogeneous agents. The experiment results show\nthat our proposed algorithms outperform the state of the art in terms of\ncommunication costs and scalability, and can well adapt to complex IoT\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:49:07 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lei", "Wanlu", ""], ["Ye", "Yu", ""], ["Xiao", "Ming", ""], ["Skoglund", "Mikael", ""], ["Han", "Zhu", ""]]}, {"id": "2107.00488", "submitter": "Xiongjie Chen", "authors": "Xiongjie Chen, Hao Wen, and Yunpeng Li", "title": "Differentiable Particle Filters through Conditional Normalizing Flow", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable particle filters provide a flexible mechanism to adaptively\ntrain dynamic and measurement models by learning from observed data. However,\nmost existing differentiable particle filters are within the bootstrap particle\nfiltering framework and fail to incorporate the information from latest\nobservations to construct better proposals. In this paper, we utilize\nconditional normalizing flows to construct proposal distributions for\ndifferentiable particle filters, enriching the distribution families that the\nproposal distributions can represent. In addition, normalizing flows are\nincorporated in the construction of the dynamic model, resulting in a more\nexpressive dynamic model. We demonstrate the performance of the proposed\nconditional normalizing flow-based differentiable particle filters in a visual\ntracking task.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:31:27 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chen", "Xiongjie", ""], ["Wen", "Hao", ""], ["Li", "Yunpeng", ""]]}, {"id": "2107.00501", "submitter": "Marcel Keller", "authors": "Marcel Keller and Ke Sun", "title": "Secure Quantized Training for Deep Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We have implemented training of neural networks in secure multi-party\ncomputation (MPC) using quantization commonly used in the said setting. To the\nbest of our knowledge, we are the first to present an MNIST classifier purely\ntrained in MPC that comes within 0.2 percent of the accuracy of the same\nconvolutional neural network trained via plaintext computation. More\nconcretely, we have trained a network with two convolution and two dense layers\nto 99.2% accuracy in 25 epochs. This took 3.5 hours in our MPC implementation\n(under one hour for 99% accuracy).\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:45:01 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Keller", "Marcel", ""], ["Sun", "Ke", ""]]}, {"id": "2107.00507", "submitter": "Mark Stamp", "authors": "Han-Chih Chang, Jianwei Li, Ching-Seh Wu, Mark Stamp", "title": "Machine Learning and Deep Learning for Fixed-Text Keystroke Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Keystroke dynamics can be used to analyze the way that users type by\nmeasuring various aspects of keyboard input. Previous work has demonstrated the\nfeasibility of user authentication and identification utilizing keystroke\ndynamics. In this research, we consider a wide variety of machine learning and\ndeep learning techniques based on fixed-text keystroke-derived features, we\noptimize the resulting models, and we compare our results to those obtained in\nrelated research. We find that models based on extreme gradient boosting\n(XGBoost) and multi-layer perceptrons (MLP)perform well in our experiments. Our\nbest models outperform previous comparable research.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:54:29 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chang", "Han-Chih", ""], ["Li", "Jianwei", ""], ["Wu", "Ching-Seh", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.00516", "submitter": "Jian Wu", "authors": "Muntabir Hasan Choudhury, Himarsha R. Jayanetti, Jian Wu, William A.\n  Ingram, Edward A. Fox", "title": "Automatic Metadata Extraction Incorporating Visual Features from Scanned\n  Electronic Theses and Dissertations", "comments": "7 pages, 4 figures, 1 table. Accepted by JCDL '21 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Electronic Theses and Dissertations (ETDs) contain domain knowledge that can\nbe used for many digital library tasks, such as analyzing citation networks and\npredicting research trends. Automatic metadata extraction is important to build\nscalable digital library search engines. Most existing methods are designed for\nborn-digital documents, so they often fail to extract metadata from scanned\ndocuments such as for ETDs. Traditional sequence tagging methods mainly rely on\ntext-based features. In this paper, we propose a conditional random field (CRF)\nmodel that combines text-based and visual features. To verify the robustness of\nour model, we extended an existing corpus and created a new ground truth corpus\nconsisting of 500 ETD cover pages with human validated metadata. Our\nexperiments show that CRF with visual features outperformed both a heuristic\nand a CRF model with only text-based features. The proposed model achieved\n81.3%-96% F1 measure on seven metadata fields. The data and source code are\npublicly available on Google Drive (https://tinyurl.com/y8kxzwrp) and a GitHub\nrepository (https://github.com/lamps-lab/ETDMiner/tree/master/etd_crf),\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:59:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Choudhury", "Muntabir Hasan", ""], ["Jayanetti", "Himarsha R.", ""], ["Wu", "Jian", ""], ["Ingram", "William A.", ""], ["Fox", "Edward A.", ""]]}, {"id": "2107.00520", "submitter": "Aahlad Manas Puli", "authors": "Aahlad Puli, Lily H. Zhang, Eric K. Oermann, Rajesh Ranganath", "title": "Predictive Modeling in the Presence of Nuisance-Induced Spurious\n  Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep predictive models often make use of spurious correlations between the\nlabel and the covariates that differ between training and test distributions.\nIn many classification tasks, spurious correlations are induced by a changing\nrelationship between the label and some nuisance variables correlated with the\ncovariates. For example, in classifying animals in natural images, the\nbackground, which is the nuisance, can predict the type of animal. This\nnuisance-label relationship does not always hold. We formalize a family of\ndistributions that only differ in the nuisance-label relationship and introduce\na distribution where this relationship is broken called the nuisance-randomized\ndistribution. We introduce a set of predictive models built from the\nnuisance-randomized distribution with representations, that when conditioned\non, do not correlate the label and the nuisance. For models in this set, we\nlower bound the performance for any member of the family with the mutual\ninformation between the representation and the label under the\nnuisance-randomized distribution. To build predictive models that maximize the\nperformance lower bound, we develop Nuisance-Randomized Distillation (NURD). We\nevaluate NURD on a synthetic example, colored-MNIST, and classifying chest\nX-rays. When using non-lung patches as the nuisance in classifying chest\nX-rays, NURD produces models that predict pneumonia under strong spurious\ncorrelations.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:12:59 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 08:41:13 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Puli", "Aahlad", ""], ["Zhang", "Lily H.", ""], ["Oermann", "Eric K.", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2107.00534", "submitter": "John Cartlidge", "authors": "Zijian Shi and John Cartlidge", "title": "The Limit Order Book Recreation Model (LOBRM): An Extended Analysis", "comments": "16 pages, preprint accepted for publication in the European\n  Conference on Machine Learning and Principles and Practice of Knowledge\n  Discovery in Databases (ECML-PKDD 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The limit order book (LOB) depicts the fine-grained demand and supply\nrelationship for financial assets and is widely used in market microstructure\nstudies. Nevertheless, the availability and high cost of LOB data restrict its\nwider application. The LOB recreation model (LOBRM) was recently proposed to\nbridge this gap by synthesizing the LOB from trades and quotes (TAQ) data.\nHowever, in the original LOBRM study, there were two limitations: (1)\nexperiments were conducted on a relatively small dataset containing only one\nday of LOB data; and (2) the training and testing were performed in a\nnon-chronological fashion, which essentially re-frames the task as\ninterpolation and potentially introduces lookahead bias. In this study, we\nextend the research on LOBRM and further validate its use in real-world\napplication scenarios. We first advance the workflow of LOBRM by (1) adding a\ntime-weighted z-score standardization for the LOB and (2) substituting the\nordinary differential equation kernel with an exponential decay kernel to lower\ncomputation complexity. Experiments are conducted on the extended LOBSTER\ndataset in a chronological fashion, as it would be used in a real-world\napplication. We find that (1) LOBRM with decay kernel is superior to\ntraditional non-linear models, and module ensembling is effective; (2)\nprediction accuracy is negatively related to the volatility of order volumes\nresting in the LOB; (3) the proposed sparse encoding method for TAQ exhibits\ngood generalization ability and can facilitate manifold tasks; and (4) the\ninfluence of stochastic drift on prediction accuracy can be alleviated by\nincreasing historical samples.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 15:25:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Shi", "Zijian", ""], ["Cartlidge", "John", ""]]}, {"id": "2107.00541", "submitter": "Elliot Chane-Sane", "authors": "Elliot Chane-Sane, Cordelia Schmid, Ivan Laptev", "title": "Goal-Conditioned Reinforcement Learning with Imagined Subgoals", "comments": "ICML 2021. See the project webpage at\n  https://www.di.ens.fr/willow/research/ris/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Goal-conditioned reinforcement learning endows an agent with a large variety\nof skills, but it often struggles to solve tasks that require more temporally\nextended reasoning. In this work, we propose to incorporate imagined subgoals\ninto policy learning to facilitate learning of complex tasks. Imagined subgoals\nare predicted by a separate high-level policy, which is trained simultaneously\nwith the policy and its critic. This high-level policy predicts intermediate\nstates halfway to the goal using the value function as a reachability metric.\nWe don't require the policy to reach these subgoals explicitly. Instead, we use\nthem to define a prior policy, and incorporate this prior into a KL-constrained\npolicy iteration scheme to speed up and regularize learning. Imagined subgoals\nare used during policy learning, but not during test time, where we only apply\nthe learned policy. We evaluate our approach on complex robotic navigation and\nmanipulation tasks and show that it outperforms existing methods by a large\nmargin.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 15:30:59 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chane-Sane", "Elliot", ""], ["Schmid", "Cordelia", ""], ["Laptev", "Ivan", ""]]}, {"id": "2107.00561", "submitter": "Ryan Feng", "authors": "Nelson Manohar-Alers, Ryan Feng, Sahib Singh, Jiguo Song, Atul Prakash", "title": "Using Anomaly Feature Vectors for Detecting, Classifying and Warning of\n  Outlier Adversarial Examples", "comments": "ICML 2021 workshop on A Blessing in Disguise: The Prospects and\n  Perils of Adversarial Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DeClaW, a system for detecting, classifying, and warning of\nadversarial inputs presented to a classification neural network. In contrast to\ncurrent state-of-the-art methods that, given an input, detect whether an input\nis clean or adversarial, we aim to also identify the types of adversarial\nattack (e.g., PGD, Carlini-Wagner or clean). To achieve this, we extract\nstatistical profiles, which we term as anomaly feature vectors, from a set of\nlatent features. Preliminary findings suggest that AFVs can help distinguish\namong several types of adversarial attacks (e.g., PGD versus Carlini-Wagner)\nwith close to 93% accuracy on the CIFAR-10 dataset. The results open the door\nto using AFV-based methods for exploring not only adversarial attack detection\nbut also classification of the attack type and then design of attack-specific\nmitigation strategies.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:00:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Manohar-Alers", "Nelson", ""], ["Feng", "Ryan", ""], ["Singh", "Sahib", ""], ["Song", "Jiguo", ""], ["Prakash", "Atul", ""]]}, {"id": "2107.00571", "submitter": "Pierre Gillot", "authors": "Pierre Gillot and Pekka Parviainen", "title": "Learning Large DAGs by Combining Continuous Optimization and Feedback\n  Arc Set Heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks represent relations between variables using a directed\nacyclic graph (DAG). Learning the DAG is an NP-hard problem and exact learning\nalgorithms are feasible only for small sets of variables. We propose two\nscalable heuristics for learning DAGs in the linear structural equation case.\nOur methods learn the DAG by alternating between unconstrained gradient\ndescent-based step to optimize an objective function and solving a maximum\nacyclic subgraph problem to enforce acyclicity. Thanks to this decoupling, our\nmethods scale up beyond thousands of variables.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:10:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Gillot", "Pierre", ""], ["Parviainen", "Pekka", ""]]}, {"id": "2107.00591", "submitter": "Seunghyun Lee", "authors": "Seunghyun Lee, Younggyo Seo, Kimin Lee, Pieter Abbeel, Jinwoo Shin", "title": "Offline-to-Online Reinforcement Learning via Balanced Replay and\n  Pessimistic Q-Ensemble", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advance in deep offline reinforcement learning (RL) has made it\npossible to train strong robotic agents from offline datasets. However,\ndepending on the quality of the trained agents and the application being\nconsidered, it is often desirable to fine-tune such agents via further online\ninteractions. In this paper, we observe that state-action distribution shift\nmay lead to severe bootstrap error during fine-tuning, which destroys the good\ninitial policy obtained via offline RL. To address this issue, we first propose\na balanced replay scheme that prioritizes samples encountered online while also\nencouraging the use of near-on-policy samples from the offline dataset.\nFurthermore, we leverage multiple Q-functions trained pessimistically offline,\nthereby preventing overoptimism concerning unfamiliar actions at novel states\nduring the initial training phase. We show that the proposed method improves\nsample-efficiency and final performance of the fine-tuned robotic agents on\nvarious locomotion and manipulation tasks. Our code is available at:\nhttps://github.com/shlee94/Off2OnRL.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:26:54 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lee", "Seunghyun", ""], ["Seo", "Younggyo", ""], ["Lee", "Kimin", ""], ["Abbeel", "Pieter", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2107.00593", "submitter": "Lucius Bynum", "authors": "Lucius E.J. Bynum, Joshua R. Loftus, Julia Stoyanovich", "title": "Impact Remediation: Optimal Interventions to Reduce Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A significant body of research in the data sciences considers unfair\ndiscrimination against social categories such as race or gender that could\noccur or be amplified as a result of algorithmic decisions. Simultaneously,\nreal-world disparities continue to exist, even before algorithmic decisions are\nmade. In this work, we draw on insights from the social sciences and humanistic\nstudies brought into the realm of causal modeling and constrained optimization,\nand develop a novel algorithmic framework for tackling pre-existing real-world\ndisparities. The purpose of our framework, which we call the \"impact\nremediation framework,\" is to measure real-world disparities and discover the\noptimal intervention policies that could help improve equity or access to\nopportunity for those who are underserved with respect to an outcome of\ninterest. We develop a disaggregated approach to tackling pre-existing\ndisparities that relaxes the typical set of assumptions required for the use of\nsocial categories in structural causal models. Our approach flexibly\nincorporates counterfactuals and is compatible with various ontological\nassumptions about the nature of social categories. We demonstrate impact\nremediation with a real-world case study and compare our disaggregated approach\nto an existing state-of-the-art approach, comparing its structure and resulting\npolicy recommendations. In contrast to most work on optimal policy learning, we\nexplore disparity reduction itself as an objective, explicitly focusing the\npower of algorithms on reducing inequality.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:35:12 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Bynum", "Lucius E. J.", ""], ["Loftus", "Joshua R.", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "2107.00594", "submitter": "Salah Zaiem", "authors": "Salah Zaiem, Titouan Parcollet and Slim Essid", "title": "Pretext Tasks selection for multitask self-supervised speech\n  representation learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through solving pretext tasks, self-supervised learning leverages unlabeled\ndata to extract useful latent representations replacing traditional input\nfeatures in the downstream task. In various application domains, including\ncomputer vision, natural language processing and audio/speech signal\nprocessing, a wide range of features where engineered through decades of\nresearch efforts. As it turns out, learning to predict such features has proven\nto be a particularly relevant pretext task leading to building useful\nself-supervised representations that prove to be effective for downstream\ntasks. However, methods and common practices for combining such pretext tasks,\nwhere each task targets a different group of features for better performance on\nthe downstream task have not been explored and understood properly. In fact,\nthe process relies almost exclusively on a computationally heavy experimental\nprocedure, which becomes intractable with the increase of the number of pretext\ntasks. This paper introduces a method to select a group of pretext tasks among\na set of candidates. The method we propose estimates properly calibrated\nweights for the partial losses corresponding to the considered pretext tasks\nduring the self-supervised training process. The experiments conducted on\nspeaker recognition and automatic speech recognition validate our approach, as\nthe groups selected and weighted with our method perform better than classic\nbaselines, thus facilitating the selection and combination of relevant\npseudo-labels for self-supervised representation learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:36:29 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zaiem", "Salah", ""], ["Parcollet", "Titouan", ""], ["Essid", "Slim", ""]]}, {"id": "2107.00595", "submitter": "Ziwei Ji", "authors": "Ziwei Ji, Nathan Srebro, Matus Telgarsky", "title": "Fast Margin Maximization via Dual Acceleration", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and analyze a momentum-based gradient method for training linear\nclassifiers with an exponentially-tailed loss (e.g., the exponential or\nlogistic loss), which maximizes the classification margin on separable data at\na rate of $\\widetilde{\\mathcal{O}}(1/t^2)$. This contrasts with a rate of\n$\\mathcal{O}(1/\\log(t))$ for standard gradient descent, and $\\mathcal{O}(1/t)$\nfor normalized gradient descent. This momentum-based method is derived via the\nconvex dual of the maximum-margin problem, and specifically by applying\nNesterov acceleration to this dual, which manages to result in a simple and\nintuitive method in the primal. This dual view can also be used to derive a\nstochastic variant, which performs adaptive non-uniform sampling via the dual\nvariables.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:36:39 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ji", "Ziwei", ""], ["Srebro", "Nathan", ""], ["Telgarsky", "Matus", ""]]}, {"id": "2107.00606", "submitter": "Francesco Salvetti", "authors": "Vittorio Mazzia, Simone Angarano, Francesco Salvetti, Federico\n  Angelini and Marcello Chiaberge", "title": "Action Transformer: A Self-Attention Model for Short-Time Human Action\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks based purely on attention have been successful across\nseveral domains, relying on minimal architectural priors from the designer. In\nHuman Action Recognition (HAR), attention mechanisms have been primarily\nadopted on top of standard convolutional or recurrent layers, improving the\noverall generalization capability. In this work, we introduce Action\nTransformer (AcT), a simple, fully self-attentional architecture that\nconsistently outperforms more elaborated networks that mix convolutional,\nrecurrent, and attentive layers. In order to limit computational and energy\nrequests, building on previous human action recognition research, the proposed\napproach exploits 2D pose representations over small temporal windows,\nproviding a low latency solution for accurate and effective real-time\nperformance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as\nan attempt to build a formal training and evaluation benchmark for real-time\nshort-time human action recognition. Extensive experimentation on MPOSE2021\nwith our proposed methodology and several previous architectural solutions\nproves the effectiveness of the AcT model and poses the base for future work on\nHAR.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:53:16 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 09:33:48 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 09:11:17 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mazzia", "Vittorio", ""], ["Angarano", "Simone", ""], ["Salvetti", "Francesco", ""], ["Angelini", "Federico", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2107.00623", "submitter": "Eduardo Fonseca", "authors": "Eduardo Fonseca, Andres Ferraro, Xavier Serra", "title": "Improving Sound Event Classification by Increasing Shift Invariance in\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies have put into question the commonly assumed shift invariance\nproperty of convolutional networks, showing that small shifts in the input can\naffect the output predictions substantially. In this paper, we analyze the\nbenefits of addressing lack of shift invariance in CNN-based sound event\nclassification. Specifically, we evaluate two pooling methods to improve shift\ninvariance in CNNs, based on low-pass filtering and adaptive sampling of\nincoming feature maps. These methods are implemented via small architectural\nmodifications inserted into the pooling layers of CNNs. We evaluate the effect\nof these architectural changes on the FSD50K dataset using models of different\ncapacity and in presence of strong regularization. We show that these\nmodifications consistently improve sound event classification in all cases\nconsidered. We also demonstrate empirically that the proposed pooling methods\nincrease shift invariance in the network, making it more robust against\ntime/frequency shifts in input spectrograms. This is achieved by adding a\nnegligible amount of trainable parameters, which makes these methods an\nappealing alternative to conventional pooling layers. The outcome is a new\nstate-of-the-art mAP of 0.541 on the FSD50K classification benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:21:02 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 15:59:21 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fonseca", "Eduardo", ""], ["Ferraro", "Andres", ""], ["Serra", "Xavier", ""]]}, {"id": "2107.00630", "submitter": "Diederik P. Kingma Dr.", "authors": "Diederik P. Kingma, Tim Salimans, Ben Poole, Jonathan Ho", "title": "Variational Diffusion Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diffusion-based generative models have demonstrated a capacity for\nperceptually impressive synthesis, but can they also be great likelihood-based\nmodels? We answer this in the affirmative, and introduce a family of\ndiffusion-based generative models that obtain state-of-the-art likelihoods on\nstandard image density estimation benchmarks. Unlike other diffusion-based\nmodels, our method allows for efficient optimization of the noise schedule\njointly with the rest of the model. We show that the variational lower bound\n(VLB) simplifies to a remarkably short expression in terms of the\nsignal-to-noise ratio of the diffused data, thereby improving our theoretical\nunderstanding of this model class. Using this insight, we prove an equivalence\nbetween several models proposed in the literature. In addition, we show that\nthe continuous-time VLB is invariant to the noise schedule, except for the\nsignal-to-noise ratio at its endpoints. This enables us to learn a noise\nschedule that minimizes the variance of the resulting VLB estimator, leading to\nfaster optimization. Combining these advances with architectural improvements,\nwe obtain state-of-the-art likelihoods on image density estimation benchmarks,\noutperforming autoregressive models that have dominated these benchmarks for\nmany years, with often significantly faster optimization. In addition, we show\nhow to turn the model into a bits-back compression scheme, and demonstrate\nlossless compression rates close to the theoretical optimum.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:43:20 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 22:40:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kingma", "Diederik P.", ""], ["Salimans", "Tim", ""], ["Poole", "Ben", ""], ["Ho", "Jonathan", ""]]}, {"id": "2107.00637", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Samuele Papa, Michele De Vita, Bernhard Sch\\\"olkopf,\n  Ole Winther, Francesco Locatello", "title": "Generalization and Robustness Implications in Object-Centric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea behind object-centric representation learning is that natural scenes\ncan better be modeled as compositions of objects and their relations as opposed\nto distributed representations. This inductive bias can be injected into neural\nnetworks to potentially improve systematic generalization and learning\nefficiency of downstream tasks in scenes with multiple objects. In this paper,\nwe train state-of-the-art unsupervised models on five common multi-object\ndatasets and evaluate segmentation accuracy and downstream object property\nprediction. In addition, we study systematic generalization and robustness by\ninvestigating the settings where either single objects are out-of-distribution\n-- e.g., having unseen colors, textures, and shapes -- or global properties of\nthe scene are altered -- e.g., by occlusions, cropping, or increasing the\nnumber of objects. From our experimental study, we find object-centric\nrepresentations to be generally useful for downstream tasks and robust to\nshifts in the data distribution, especially if shifts affect single objects.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:51:11 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Dittadi", "Andrea", ""], ["Papa", "Samuele", ""], ["De Vita", "Michele", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Winther", "Ole", ""], ["Locatello", "Francesco", ""]]}, {"id": "2107.00641", "submitter": "Jianwei Yang", "authors": "Jianwei Yang, Chunyuan Li, Pengchuan Zhang, Xiyang Dai, Bin Xiao, Lu\n  Yuan, Jianfeng Gao", "title": "Focal Self-attention for Local-Global Interactions in Vision\n  Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Vision Transformer and its variants have shown great promise on\nvarious computer vision tasks. The ability of capturing short- and long-range\nvisual dependencies through self-attention is arguably the main source for the\nsuccess. But it also brings challenges due to quadratic computational overhead,\nespecially for the high-resolution vision tasks (e.g., object detection). In\nthis paper, we present focal self-attention, a new mechanism that incorporates\nboth fine-grained local and coarse-grained global interactions. Using this new\nmechanism, each token attends the closest surrounding tokens at fine\ngranularity but the tokens far away at coarse granularity, and thus can capture\nboth short- and long-range visual dependencies efficiently and effectively.\nWith focal self-attention, we propose a new variant of Vision Transformer\nmodels, called Focal Transformer, which achieves superior performance over the\nstate-of-the-art vision Transformers on a range of public image classification\nand object detection benchmarks. In particular, our Focal Transformer models\nwith a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8\nTop-1 accuracy, respectively, on ImageNet classification at 224x224 resolution.\nUsing Focal Transformers as the backbones, we obtain consistent and substantial\nimprovements over the current state-of-the-art Swin Transformers for 6\ndifferent object detection methods trained with standard 1x and 3x schedules.\nOur largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs\non COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation,\ncreating new SoTA on three of the most challenging computer vision tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:56:09 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Yang", "Jianwei", ""], ["Li", "Chunyuan", ""], ["Zhang", "Pengchuan", ""], ["Dai", "Xiyang", ""], ["Xiao", "Bin", ""], ["Yuan", "Lu", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2107.00643", "submitter": "Nimit Sohoni", "authors": "Mayee Chen, Karan Goel, Nimit Sohoni, Fait Poms, Kayvon Fatahalian,\n  Christopher R\\'e", "title": "Mandoline: Model Evaluation under Distribution Shift", "comments": "32 pages. Published as a conference paper at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are often deployed in different settings than they\nwere trained and validated on, posing a challenge to practitioners who wish to\npredict how well the deployed model will perform on a target distribution. If\nan unlabeled sample from the target distribution is available, along with a\nlabeled sample from a possibly different source distribution, standard\napproaches such as importance weighting can be applied to estimate performance\non the target. However, importance weighting struggles when the source and\ntarget distributions have non-overlapping support or are high-dimensional.\nTaking inspiration from fields such as epidemiology and polling, we develop\nMandoline, a new evaluation framework that mitigates these issues. Our key\ninsight is that practitioners may have prior knowledge about the ways in which\nthe distribution shifts, which we can use to better guide the importance\nweighting procedure. Specifically, users write simple \"slicing functions\" -\nnoisy, potentially correlated binary functions intended to capture possible\naxes of distribution shift - to compute reweighted performance estimates. We\nfurther describe a density ratio estimation framework for the slices and show\nhow its estimation error scales with slice quality and dataset size. Empirical\nvalidation on NLP and vision tasks shows that \\name can estimate performance on\nthe target distribution up to $3\\times$ more accurately compared to standard\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:57:57 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Chen", "Mayee", ""], ["Goel", "Karan", ""], ["Sohoni", "Nimit", ""], ["Poms", "Fait", ""], ["Fatahalian", "Kayvon", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2107.00644", "submitter": "Nicklas Hansen", "authors": "Nicklas Hansen, Hao Su, Xiaolong Wang", "title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under\n  Data Augmentation", "comments": "Code and videos are available at https://nicklashansen.github.io/SVEA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While agents trained by Reinforcement Learning (RL) can solve increasingly\nchallenging tasks directly from visual observations, generalizing learned\nskills to novel environments remains very challenging. Extensive use of data\naugmentation is a promising technique for improving generalization in RL, but\nit is often found to decrease sample efficiency and can even lead to\ndivergence. In this paper, we investigate causes of instability when using data\naugmentation in common off-policy RL algorithms. We identify two problems, both\nrooted in high-variance Q-targets. Based on our findings, we propose a simple\nyet effective technique for stabilizing this class of algorithms under\naugmentation. We perform extensive empirical evaluation of image-based RL using\nboth ConvNets and Vision Transformers (ViT) on a family of benchmarks based on\nDeepMind Control Suite, as well as in robotic manipulation tasks. Our method\ngreatly improves stability and sample efficiency of ConvNets under\naugmentation, and achieves generalization results competitive with\nstate-of-the-art methods for image-based RL. We further show that our method\nscales to RL with ViT-based architectures, and that data augmentation may be\nespecially important in this setting.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:58:05 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Hansen", "Nicklas", ""], ["Su", "Hao", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2107.00645", "submitter": "Yongming Rao", "authors": "Yongming Rao, Wenliang Zhao, Zheng Zhu, Jiwen Lu, Jie Zhou", "title": "Global Filter Networks for Image Classification", "comments": "Project page: https://gfnet.ivg-research.xyz/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in self-attention and pure multi-layer perceptrons (MLP)\nmodels for vision have shown great potential in achieving promising performance\nwith fewer inductive biases. These models are generally based on learning\ninteraction among spatial locations from raw data. The complexity of\nself-attention and MLP grows quadratically as the image size increases, which\nmakes these models hard to scale up when high-resolution features are required.\nIn this paper, we present the Global Filter Network (GFNet), a conceptually\nsimple yet computationally efficient architecture, that learns long-term\nspatial dependencies in the frequency domain with log-linear complexity. Our\narchitecture replaces the self-attention layer in vision transformers with\nthree key operations: a 2D discrete Fourier transform, an element-wise\nmultiplication between frequency-domain features and learnable global filters,\nand a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity\ntrade-offs of our models on both ImageNet and downstream tasks. Our results\ndemonstrate that GFNet can be a very competitive alternative to\ntransformer-style models and CNNs in efficiency, generalization ability and\nrobustness. Code is available at https://github.com/raoyongming/GFNet\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:58:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Rao", "Yongming", ""], ["Zhao", "Wenliang", ""], ["Zhu", "Zheng", ""], ["Lu", "Jiwen", ""], ["Zhou", "Jie", ""]]}, {"id": "2107.00648", "submitter": "Nathaniel Braman", "authors": "Nathaniel Braman, Jacob W. H. Gordon, Emery T. Goossens, Caleb Willis,\n  Martin C. Stumpe, Jagadish Venkataraman", "title": "Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery\n  Integrating Radiology, Pathology, Genomic, and Clinical Data", "comments": "Accepted for presentation at MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM q-bio.GN q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clinical decision-making in oncology involves multimodal data such as\nradiology scans, molecular profiling, histopathology slides, and clinical\nfactors. Despite the importance of these modalities individually, no deep\nlearning framework to date has combined them all to predict patient prognosis.\nHere, we predict the overall survival (OS) of glioma patients from diverse\nmultimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to\ncombine information from multiparametric MRI exams, biopsy-based modalities\n(such as H&E slide images and/or DNA sequencing), and clinical variables into a\ncomprehensive multimodal risk score. Prognostic embeddings from each modality\nare learned and combined via attention-gated tensor fusion. To maximize the\ninformation gleaned from each modality, we introduce a multimodal\northogonalization (MMO) loss term that increases model performance by\nincentivizing constituent embeddings to be more complementary. DOF predicts OS\nin glioma patients with a median C-index of 0.788 +/- 0.067, significantly\noutperforming (p=0.023) the best performing unimodal model with a median\nC-index of 0.718 +/- 0.064. The prognostic model significantly stratifies\nglioma patients by OS within clinical subsets, adding further granularity to\nprognostic clinical grading and molecular subtyping.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:59:01 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Braman", "Nathaniel", ""], ["Gordon", "Jacob W. H.", ""], ["Goossens", "Emery T.", ""], ["Willis", "Caleb", ""], ["Stumpe", "Martin C.", ""], ["Venkataraman", "Jagadish", ""]]}, {"id": "2107.00652", "submitter": "Dongdong Chen", "authors": "Xiaoyi Dong and Jianmin Bao and Dongdong Chen and Weiming Zhang and\n  Nenghai Yu and Lu Yuan and Dong Chen and Baining Guo", "title": "CSWin Transformer: A General Vision Transformer Backbone with\n  Cross-Shaped Windows", "comments": "The code repo is available at\n  https://github.com/microsoft/CSWin-Transformer, SOTA performance on ADE20k\n  Segmentation benchmark is updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CSWin Transformer, an efficient and effective Transformer-based\nbackbone for general-purpose vision tasks. A challenging issue in Transformer\ndesign is that global self-attention is very expensive to compute whereas local\nself-attention often limits the field of interactions of each token. To address\nthis issue, we develop the Cross-Shaped Window self-attention mechanism for\ncomputing self-attention in the horizontal and vertical stripes in parallel\nthat form a cross-shaped window, with each stripe obtained by splitting the\ninput feature into stripes of equal width. We provide a detailed mathematical\nanalysis of the effect of the stripe width and vary the stripe width for\ndifferent layers of the Transformer network which achieves strong modeling\ncapability while limiting the computation cost. We also introduce\nLocally-enhanced Positional Encoding (LePE), which handles the local positional\ninformation better than existing encoding schemes. LePE naturally supports\narbitrary input resolutions, and is thus especially effective and friendly for\ndownstream tasks. Incorporated with these designs and a hierarchical structure,\nCSWin Transformer demonstrates competitive performance on common vision tasks.\nSpecifically, it achieves 85.4% Top-1 accuracy on ImageNet-1K without any extra\ntraining data or label, 53.9 box AP and 46.4 mask AP on the COCO detection\ntask, and 51.7 mIOU on the ADE20K semantic segmentation task, surpassing\nprevious state-of-the-art Swin Transformer backbone by +1.2, +2.0, +1.4, and\n+2.0 respectively under the similar FLOPs setting. By further pretraining on\nthe larger dataset ImageNet-21K, we achieve 87.5% Top-1 accuracy on ImageNet-1K\nand state-of-the-art segmentation performance on ADE20K with 55.7 mIoU. The\ncode and models will be available at\nhttps://github.com/microsoft/CSWin-Transformer.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 17:59:56 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 17:59:49 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Dong", "Xiaoyi", ""], ["Bao", "Jianmin", ""], ["Chen", "Dongdong", ""], ["Zhang", "Weiming", ""], ["Yu", "Nenghai", ""], ["Yuan", "Lu", ""], ["Chen", "Dong", ""], ["Guo", "Baining", ""]]}, {"id": "2107.00653", "submitter": "Yu Shi", "authors": "Yu Shi", "title": "Transformer-F: A Transformer network with effective methods for learning\n  universal sentence representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer model is widely used in natural language processing for\nsentence representation. However, the previous Transformer-based models focus\non function words that have limited meaning in most cases and could merely\nextract high-level semantic abstraction features. In this paper, two approaches\nare introduced to improve the performance of Transformers. We calculated the\nattention score by multiplying the part-of-speech weight vector with the\ncorrelation coefficient, which helps extract the words with more practical\nmeaning. The weight vector is obtained by the input text sequence based on the\nimportance of the part-of-speech. Furthermore, we fuse the features of each\nlayer to make the sentence representation results more comprehensive and\naccurate. In experiments, we demonstrate the effectiveness of our model\nTransformer-F on three standard text classification datasets. Experimental\nresults show that our proposed model significantly boosts the performance of\ntext classification as compared to the baseline model. Specifically, we obtain\na 5.28% relative improvement over the vanilla Transformer on the simple tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 03:20:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Shi", "Yu", ""]]}, {"id": "2107.00656", "submitter": "William Korcari Mr.", "authors": "Lisa Benato, Erik Buhmann, Martin Erdmann, Peter Fackeldey, Jonas\n  Glombitza, Nikolai Hartmann, Gregor Kasieczka, William Korcari, Thomas Kuhr,\n  Jan Steinheimer, Horst St\\\"ocker, Tilman Plehn and Kai Zhou", "title": "Shared Data and Algorithms for Deep Learning in Fundamental Physics", "comments": "13 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM hep-ph nucl-th physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a collection of datasets from fundamental physics research --\nincluding particle physics, astroparticle physics, and hadron- and nuclear\nphysics -- for supervised machine learning studies. These datasets, containing\nhadronic top quarks, cosmic-ray induced air showers, phase transitions in\nhadronic matter, and generator-level histories, are made public to simplify\nfuture work on cross-disciplinary machine learning and transfer learning in\nfundamental physics. Based on these data, we present a simple yet flexible\ngraph-based neural network architecture that can easily be applied to a wide\nrange of supervised learning tasks in these domains. We show that our approach\nreaches performance close to state-of-the-art dedicated methods on all\ndatasets. To simplify adaptation for various problems, we provide\neasy-to-follow instructions on how graph-based representations of data\nstructures, relevant for fundamental physics, can be constructed and provide\ncode implementations for several of them. Implementations are also provided for\nour proposed method and all reference algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:00:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Benato", "Lisa", ""], ["Buhmann", "Erik", ""], ["Erdmann", "Martin", ""], ["Fackeldey", "Peter", ""], ["Glombitza", "Jonas", ""], ["Hartmann", "Nikolai", ""], ["Kasieczka", "Gregor", ""], ["Korcari", "William", ""], ["Kuhr", "Thomas", ""], ["Steinheimer", "Jan", ""], ["St\u00f6cker", "Horst", ""], ["Plehn", "Tilman", ""], ["Zhou", "Kai", ""]]}, {"id": "2107.00680", "submitter": "Yi Liu", "authors": "Yi Liu and Lihong Li", "title": "A Map of Bandits for E-commerce", "comments": "Accepted by KDD Bandit and RL workshop:\n  https://sites.google.com/view/marble-kdd/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rich body of Bandit literature not only offers a diverse toolbox of\nalgorithms, but also makes it hard for a practitioner to find the right\nsolution to solve the problem at hand. Typical textbooks on Bandits focus on\ndesigning and analyzing algorithms, and surveys on applications often present a\nlist of individual applications. While these are valuable resources, there\nexists a gap in mapping applications to appropriate Bandit algorithms. In this\npaper, we aim to reduce this gap with a structured map of Bandits to help\npractitioners navigate to find relevant and practical Bandit algorithms.\nInstead of providing a comprehensive overview, we focus on a small number of\nkey decision points related to reward, action, and features, which often affect\nhow Bandit algorithms are chosen in practice.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:08:16 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Yi", ""], ["Li", "Lihong", ""]]}, {"id": "2107.00685", "submitter": "Zehao Dou", "authors": "Zehao Dou, Zhuoran Yang, Zhaoran Wang, Simon S.Du", "title": "Gap-Dependent Bounds for Two-Player Markov Games", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most popular methods in the field of reinforcement learning,\nQ-learning has received increasing attention. Recently, there have been more\ntheoretical works on the regret bound of algorithms that belong to the\nQ-learning class in different settings. In this paper, we analyze the\ncumulative regret when conducting Nash Q-learning algorithm on 2-player\nturn-based stochastic Markov games (2-TBSG), and propose the very first gap\ndependent logarithmic upper bounds in the episodic tabular setting. This bound\nmatches the theoretical lower bound only up to a logarithmic term. Furthermore,\nwe extend the conclusion to the discounted game setting with infinite horizon\nand propose a similar gap dependent logarithmic regret bound. Also, under the\nlinear MDP assumption, we obtain another logarithmic regret for 2-TBSG, in both\ncentralized and independent settings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:25:07 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Dou", "Zehao", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Du", "Simon S.", ""]]}, {"id": "2107.00693", "submitter": "Asiful Arefeen", "authors": "Asiful Arefeen, Ali Akbari, Seyed Iman Mirzadeh, Roozbeh Jafari,\n  Behrooz A. Shirazi and Hassan Ghasemzadeh", "title": "Inter-Beat Interval Estimation with Tiramisu Model: A Novel Approach\n  with Reduced Error", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inter-beat interval (IBI) measurement enables estimation of heart-rate\nvariability (HRV) which, in turns, can provide early indication of potential\ncardiovascular diseases. However, extracting IBIs from noisy signals is\nchallenging since the morphology of the signal is distorted in the presence of\nthe noise. Electrocardiogram (ECG) of a person in heavy motion is highly\ncorrupted with noise, known as motion-artifact, and IBI extracted from it is\ninaccurate. As a part of remote health monitoring and wearable system\ndevelopment, denoising ECG signals and estimating IBIs correctly from them have\nbecome an emerging topic among signal-processing researchers. Apart from\nconventional methods, deep-learning techniques have been successfully used in\nsignal denoising recently, and diagnosis process has become easier, leading to\naccuracy levels that were previously unachievable. We propose a deep-learning\napproach leveraging tiramisu autoencoder model to suppress motion-artifact\nnoise and make the R-peaks of the ECG signal prominent even in the presence of\nhigh-intensity motion. After denoising, IBIs are estimated more accurately\nexpediting diagnosis tasks. Results illustrate that our method enables IBI\nestimation from noisy ECG signals with SNR up to -30dB with average root mean\nsquare error (RMSE) of 13 milliseconds for estimated IBIs. At this noise level,\nour error percentage remains below 8% and outperforms other state of the art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:39:43 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Arefeen", "Asiful", ""], ["Akbari", "Ali", ""], ["Mirzadeh", "Seyed Iman", ""], ["Jafari", "Roozbeh", ""], ["Shirazi", "Behrooz A.", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2107.00703", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Christian Scheller, Yanick Schraner, Ville\n  Hautam\\\"aki", "title": "Distilling Reinforcement Learning Tricks for Video Games", "comments": "To appear in IEEE Conference on Games 2021. Experiment code is\n  available at https://github.com/Miffyli/rl-human-prior-tricks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) research focuses on general solutions that can be\napplied across different domains. This results in methods that RL practitioners\ncan use in almost any domain. However, recent studies often lack the\nengineering steps (\"tricks\") which may be needed to effectively use RL, such as\nreward shaping, curriculum learning, and splitting a large task into smaller\nchunks. Such tricks are common, if not necessary, to achieve state-of-the-art\nresults and win RL competitions. To ease the engineering efforts, we distill\ndescriptions of tricks from state-of-the-art results and study how well these\ntricks can improve a standard deep Q-learning agent. The long-term goal of this\nwork is to enable combining proven RL methods with domain-specific tricks by\nproviding a unified software framework and accompanying insights in multiple\ndomains.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:02:38 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Scheller", "Christian", ""], ["Schraner", "Yanick", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2107.00710", "submitter": "Ulysse C\\^ot\\'e-Allard", "authors": "Ulysse C\\^ot\\'e-Allard, Petter Jakobsen, Andrea Stautland, Tine\n  Nordgreen, Ole Bernt Fasmer, Ketil Joachim Oedegaard, Jim Torresen", "title": "Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition\n  Based on Wrist-worn Sensors", "comments": "Submitted for peer-review. 11 pages + 3. 2 Figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Manic episodes of bipolar disorder can lead to uncritical behaviour and\ndelusional psychosis, often with destructive consequences for those affected\nand their surroundings. Early detection and intervention of a manic episode are\ncrucial to prevent escalation, hospital admission and premature death. However,\npeople with bipolar disorder may not recognize that they are experiencing a\nmanic episode and symptoms such as euphoria and increased productivity can also\ndeter affected individuals from seeking help. This work proposes to perform\nuser-independent, automatic mood-state detection based on actigraphy and\nelectrodermal activity acquired from a wrist-worn device during mania and after\nrecovery (euthymia). This paper proposes a new deep learning-based ensemble\nmethod leveraging long (20h) and short (5 minutes) time-intervals to\ndiscriminate between the mood-states. When tested on 47 bipolar patients, the\nproposed classification scheme achieves an average accuracy of 91.59% in\neuthymic/manic mood-state recognition.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:35:54 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["C\u00f4t\u00e9-Allard", "Ulysse", ""], ["Jakobsen", "Petter", ""], ["Stautland", "Andrea", ""], ["Nordgreen", "Tine", ""], ["Fasmer", "Ole Bernt", ""], ["Oedegaard", "Ketil Joachim", ""], ["Torresen", "Jim", ""]]}, {"id": "2107.00717", "submitter": "Suraj Kothawade", "authors": "Suraj Kothawade, Nathan Beck, Krishnateja Killamsetty, Rishabh Iyer", "title": "SIMILAR: Submodular Information Measures Based Active Learning In\n  Realistic Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning has proven to be useful for minimizing labeling costs by\nselecting the most informative samples. However, existing active learning\nmethods do not work well in realistic scenarios such as imbalance or rare\nclasses, out-of-distribution data in the unlabeled set, and redundancy. In this\nwork, we propose SIMILAR (Submodular Information Measures based actIve\nLeARning), a unified active learning framework using recently proposed\nsubmodular information measures (SIM) as acquisition functions. We argue that\nSIMILAR not only works in standard active learning, but also easily extends to\nthe realistic settings considered above and acts as a one-stop solution for\nactive learning that is scalable to large real-world datasets. Empirically, we\nshow that SIMILAR significantly outperforms existing active learning algorithms\nby as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case\nof out-of-distribution data on several image classification tasks like\nCIFAR-10, MNIST, and ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:49:44 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kothawade", "Suraj", ""], ["Beck", "Nathan", ""], ["Killamsetty", "Krishnateja", ""], ["Iyer", "Rishabh", ""]]}, {"id": "2107.00719", "submitter": "Po-Yu Kao", "authors": "Po-Yu Kao, Shu-Min Kao, Nan-Lan Huang, Yen-Chu Lin", "title": "Toward Drug-Target Interaction Prediction via Ensemble Modeling and\n  Transfer Learning", "comments": "8 pages, 1 figure, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Drug-target interaction (DTI) prediction plays a crucial role in drug\ndiscovery, and deep learning approaches have achieved state-of-the-art\nperformance in this field. We introduce an ensemble of deep learning models\n(EnsembleDLM) for DTI prediction. EnsembleDLM only uses the sequence\ninformation of chemical compounds and proteins, and it aggregates the\npredictions from multiple deep neural networks. This approach not only achieves\nstate-of-the-art performance in Davis and KIBA datasets but also reaches\ncutting-edge performance in the cross-domain applications across different\nbio-activity types and different protein classes. We also demonstrate that\nEnsembleDLM achieves a good performance (Pearson correlation coefficient and\nconcordance index > 0.8) in the new domain with approximately 50% transfer\nlearning data, i.e., the training set has twice as much data as the test set.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 04:00:03 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 02:14:55 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kao", "Po-Yu", ""], ["Kao", "Shu-Min", ""], ["Huang", "Nan-Lan", ""], ["Lin", "Yen-Chu", ""]]}, {"id": "2107.00722", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Abdalkarim Mohtasib, Amir Ghalamzan E., Nicola Bellotto, Heriberto\n  Cuay\\'ahuitl", "title": "Neural Task Success Classifiers for Robotic Manipulation from Few Real\n  Demonstrations", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots learning a new manipulation task from a small amount of demonstrations\nare increasingly demanded in different workspaces. A classifier model assessing\nthe quality of actions can predict the successful completion of a task, which\ncan be used by intelligent agents for action-selection. This paper presents a\nnovel classifier that learns to classify task completion only from a few\ndemonstrations. We carry out a comprehensive comparison of different neural\nclassifiers, e.g. fully connected-based, fully convolutional-based,\nsequence2sequence-based, and domain adaptation-based classification. We also\npresent a new dataset including five robot manipulation tasks, which is\npublicly available. We compared the performances of our novel classifier and\nthe existing models using our dataset and the MIME dataset. The results suggest\ndomain adaptation and timing-based features improve success prediction. Our\nnovel model, i.e. fully convolutional neural network with domain adaptation and\ntiming features, achieves an average classification accuracy of 97.3\\% and\n95.5\\% across tasks in both datasets whereas state-of-the-art classifiers\nwithout domain adaptation and timing-features only achieve 82.4\\% and 90.3\\%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 19:58:16 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Mohtasib", "Abdalkarim", ""], ["E.", "Amir Ghalamzan", ""], ["Bellotto", "Nicola", ""], ["Cuay\u00e1huitl", "Heriberto", ""]]}, {"id": "2107.00727", "submitter": "Shanu Kumar", "authors": "Shanu Kumar, Vinod Kumar Kurmi, Praphul Singh, Vinay P Namboodiri", "title": "Mitigating Uncertainty of Classifier for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding unsupervised domain adaptation has been an important task that\nhas been well explored. However, the wide variety of methods have not analyzed\nthe role of a classifier's performance in detail. In this paper, we thoroughly\nexamine the role of a classifier in terms of matching source and target\ndistributions. We specifically investigate the classifier ability by matching\na) the distribution of features, b) probabilistic uncertainty for samples and\nc) certainty activation mappings. Our analysis suggests that using these three\ndistributions does result in a consistently improved performance on all the\ndatasets. Our work thus extends present knowledge on the role of the various\ndistributions obtained from the classifier towards solving unsupervised domain\nadaptation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 20:08:15 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kumar", "Shanu", ""], ["Kurmi", "Vinod Kumar", ""], ["Singh", "Praphul", ""], ["Namboodiri", "Vinay P", ""]]}, {"id": "2107.00730", "submitter": "Anubhab Ghosh", "authors": "Anubhab Ghosh, Antoine Honor\\'e, Dong Liu, Gustav Eje Henter, Saikat\n  Chatterjee", "title": "Normalizing Flow based Hidden Markov Models for Classification of Speech\n  Phones with Explainability", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pursuit of explainability, we develop generative models for sequential\ndata. The proposed models provide state-of-the-art classification results and\nrobust performance for speech phone classification. We combine modern neural\nnetworks (normalizing flows) and traditional generative models (hidden Markov\nmodels - HMMs). Normalizing flow-based mixture models (NMMs) are used to model\nthe conditional probability distribution given the hidden state in the HMMs.\nModel parameters are learned through judicious combinations of time-tested\nBayesian learning methods and contemporary neural network learning methods. We\nmainly combine expectation-maximization (EM) and mini-batch gradient descent.\nThe proposed generative models can compute likelihood of a data and hence\ndirectly suitable for maximum-likelihood (ML) classification approach. Due to\nstructural flexibility of HMMs, we can use different normalizing flow models.\nThis leads to different types of HMMs providing diversity in data modeling\ncapacity. The diversity provides an opportunity for easy decision fusion from\ndifferent models. For a standard speech phone classification setup involving 39\nphones (classes) and the TIMIT dataset, we show that the use of standard\nfeatures called mel-frequency-cepstral-coeffcients (MFCCs), the proposed\ngenerative models, and the decision fusion together can achieve $86.6\\%$\naccuracy by generative training only. This result is close to state-of-the-art\nresults, for examples, $86.2\\%$ accuracy of PyTorch-Kaldi toolkit [1], and\n$85.1\\%$ accuracy using light gated recurrent units [2]. We do not use any\ndiscriminative learning approach and related sophisticated features in this\narticle.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 20:10:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Ghosh", "Anubhab", ""], ["Honor\u00e9", "Antoine", ""], ["Liu", "Dong", ""], ["Henter", "Gustav Eje", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "2107.00734", "submitter": "Daniel Hackett", "authors": "Daniel C. Hackett, Chung-Chun Hsieh, Michael S. Albergo, Denis Boyda,\n  Jiunn-Wei Chen, Kai-Feng Chen, Kyle Cranmer, Gurtej Kanwar, and Phiala E.\n  Shanahan", "title": "Flow-based sampling for multimodal distributions in lattice field theory", "comments": "33 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": "MIT-CTP/5312", "categories": "hep-lat cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results have demonstrated that samplers constructed with flow-based\ngenerative models are a promising new approach for configuration generation in\nlattice field theory. In this paper, we present a set of methods to construct\nflow models for targets with multiple separated modes (i.e. theories with\nmultiple vacua). We demonstrate the application of these methods to modeling\ntwo-dimensional real scalar field theory in its symmetry-broken phase. In this\ncontext we investigate the performance of different flow-based sampling\nalgorithms, including a composite sampling algorithm where flow-based proposals\nare occasionally augmented by applying updates using traditional algorithms\nlike HMC.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 20:22:10 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Hackett", "Daniel C.", ""], ["Hsieh", "Chung-Chun", ""], ["Albergo", "Michael S.", ""], ["Boyda", "Denis", ""], ["Chen", "Jiunn-Wei", ""], ["Chen", "Kai-Feng", ""], ["Cranmer", "Kyle", ""], ["Kanwar", "Gurtej", ""], ["Shanahan", "Phiala E.", ""]]}, {"id": "2107.00745", "submitter": "Vaden Masrani", "authors": "Vaden Masrani, Rob Brekelmans, Thang Bui, Frank Nielsen, Aram\n  Galstyan, Greg Ver Steeg, Frank Wood", "title": "q-Paths: Generalizing the Geometric Annealing Path using Power Means", "comments": "arXiv admin note: text overlap with arXiv:2012.07823", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many common machine learning methods involve the geometric annealing path, a\nsequence of intermediate densities between two distributions of interest\nconstructed using the geometric average. While alternatives such as the\nmoment-averaging path have demonstrated performance gains in some settings,\ntheir practical applicability remains limited by exponential family endpoint\nassumptions and a lack of closed form energy function. In this work, we\nintroduce $q$-paths, a family of paths which is derived from a generalized\nnotion of the mean, includes the geometric and arithmetic mixtures as special\ncases, and admits a simple closed form involving the deformed logarithm\nfunction from nonextensive thermodynamics. Following previous analysis of the\ngeometric path, we interpret our $q$-paths as corresponding to a\n$q$-exponential family of distributions, and provide a variational\nrepresentation of intermediate densities as minimizing a mixture of\n$\\alpha$-divergences to the endpoints. We show that small deviations away from\nthe geometric path yield empirical gains for Bayesian inference using\nSequential Monte Carlo and generative model evaluation using Annealed\nImportance Sampling.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:09:06 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Masrani", "Vaden", ""], ["Brekelmans", "Rob", ""], ["Bui", "Thang", ""], ["Nielsen", "Frank", ""], ["Galstyan", "Aram", ""], ["Steeg", "Greg Ver", ""], ["Wood", "Frank", ""]]}, {"id": "2107.00753", "submitter": "Nitish Joshi", "authors": "Nitish Joshi, He He", "title": "An Investigation of the (In)effectiveness of Counterfactually Augmented\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While pretrained language models achieve excellent performance on natural\nlanguage understanding benchmarks, they tend to rely on spurious correlations\nand generalize poorly to out-of-distribution (OOD) data. Recent work has\nexplored using counterfactually-augmented data (CAD) -- data generated by\nminimally perturbing examples to flip the ground-truth label -- to identify\nrobust features that are invariant under distribution shift. However, empirical\nresults using CAD for OOD generalization have been mixed. To explain this\ndiscrepancy, we draw insights from a linear Gaussian model and demonstrate the\npitfalls of CAD. Specifically, we show that (a) while CAD is effective at\nidentifying robust features, it may prevent the model from learning unperturbed\nrobust features, and (b) CAD may exacerbate existing spurious correlations in\nthe data. Our results show that the lack of perturbation diversity in current\nCAD datasets limits its effectiveness on OOD generalization, calling for\ninnovative crowdsourcing procedures to elicit diverse perturbation of examples.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:46:43 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Joshi", "Nitish", ""], ["He", "He", ""]]}, {"id": "2107.00758", "submitter": "Greg D'Eon", "authors": "Greg d'Eon, Jason d'Eon, James R. Wright, Kevin Leyton-Brown", "title": "The Spotlight: A General Method for Discovering Systematic Errors in\n  Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning models often make systematic errors on rare subsets of\nthe data. However, such systematic errors can be difficult to identify, as\nmodel performance can only be broken down across sensitive groups when these\ngroups are known and explicitly labelled. This paper introduces a method for\ndiscovering systematic errors, which we call the spotlight. The key idea is\nthat similar inputs tend to have similar representations in the final hidden\nlayer of a neural network. We leverage this structure by \"shining a spotlight\"\non this representation space to find contiguous regions where the model\nperforms poorly. We show that the spotlight surfaces semantically meaningful\nareas of weakness in a wide variety of model architectures, including image\nclassifiers, language models, and recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:58:00 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["d'Eon", "Greg", ""], ["d'Eon", "Jason", ""], ["Wright", "James R.", ""], ["Leyton-Brown", "Kevin", ""]]}, {"id": "2107.00761", "submitter": "Francesco Silvestri", "authors": "Elia Costa and Francesco Silvestri", "title": "On the Bike Spreading Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CE cs.LG cs.SI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A free-floating bike-sharing system (FFBSS) is a dockless rental system where\nan individual can borrow a bike and returns it everywhere, within the service\narea. To improve the rental service, available bikes should be distributed over\nthe entire service area: a customer leaving from any position is then more\nlikely to find a near bike and then to use the service. Moreover, spreading\nbikes among the entire service area increases urban spatial equity since the\nbenefits of FFBSS are not a prerogative of just a few zones. For guaranteeing\nsuch distribution, the FFBSS operator can use vans to manually relocate bikes,\nbut it incurs high economic and environmental costs. We propose a novel\napproach that exploits the existing bike flows generated by customers to\ndistribute bikes. More specifically, by envisioning the problem as an Influence\nMaximization problem, we show that it is possible to position batches of bikes\non a small number of zones, and then the daily use of FFBSS will efficiently\nspread these bikes on a large area. We show that detecting these areas is\nNP-complete, but there exists a simple and efficient $1-1/e$ approximation\nalgorithm; our approach is then evaluated on a dataset of rides from the\nfree-floating bike-sharing system of the city of Padova.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 22:14:31 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Costa", "Elia", ""], ["Silvestri", "Francesco", ""]]}, {"id": "2107.00774", "submitter": "Shyam Narayanan", "authors": "Hossein Esfandiari, Vahab Mirrokni, Shyam Narayanan", "title": "Almost Tight Approximation Algorithms for Explainable Clustering", "comments": "27 pages. Added references to independent work, as well as a table of\n  results, pseudocode, and improved introduction. Note: first version was\n  uploaded on July 1, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to an increasing interest for transparency in artificial\nintelligence, several methods of explainable machine learning have been\ndeveloped with the simultaneous goal of accuracy and interpretability by\nhumans. In this paper, we study a recent framework of explainable clustering\nfirst suggested by Dasgupta et al.~\\cite{dasgupta2020explainable}.\nSpecifically, we focus on the $k$-means and $k$-medians problems and provide\nnearly tight upper and lower bounds.\n  First, we provide an $O(\\log k \\log \\log k)$-approximation algorithm for\nexplainable $k$-medians, improving on the best known algorithm of\n$O(k)$~\\cite{dasgupta2020explainable} and nearly matching the known\n$\\Omega(\\log k)$ lower bound~\\cite{dasgupta2020explainable}. In addition, in\nlow-dimensional spaces $d \\ll \\log k$, we show that our algorithm also provides\nan $O(d \\log^2 d)$-approximate solution for explainable $k$-medians. This\nimproves over the best known bound of $O(d \\log k)$ for low\ndimensions~\\cite{laber2021explainable}, and is a constant for constant\ndimensional spaces. To complement this, we show a nearly matching $\\Omega(d)$\nlower bound. Next, we study the $k$-means problem in this context and provide\nan $O(k \\log k)$-approximation algorithm for explainable $k$-means, improving\nover the $O(k^2)$ bound of Dasgupta et al. and the $O(d k \\log k)$ bound of\n\\cite{laber2021explainable}. To complement this we provide an almost tight\n$\\Omega(k)$ lower bound, improving over the $\\Omega(\\log k)$ lower bound of\nDasgupta et al. Given an approximate solution to the classic $k$-means and\n$k$-medians, our algorithm for $k$-medians runs in time $O(kd \\log^2 k )$ and\nour algorithm for $k$-means runs in time $ O(k^2 d)$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 23:49:23 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 16:39:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Esfandiari", "Hossein", ""], ["Mirrokni", "Vahab", ""], ["Narayanan", "Shyam", ""]]}, {"id": "2107.00778", "submitter": "Wei-Lun Chao", "authors": "Hong-You Chen, Wei-Lun Chao", "title": "On Bridging Generic and Personalized Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning is promising for its ability to collaboratively train\nmodels with multiple clients without accessing their data, but vulnerable when\nclients' data distributions diverge from each other. This divergence further\nleads to a dilemma: \"Should we prioritize the learned model's generic\nperformance (for future use at the server) or its personalized performance (for\neach client)?\" These two, seemingly competing goals have divided the community\nto focus on one or the other, yet in this paper we show that it is possible to\napproach both at the same time. Concretely, we propose a novel federated\nlearning framework that explicitly decouples a model's dual duties with two\nprediction tasks. On the one hand, we introduce a family of losses that are\nrobust to non-identical class distributions, enabling clients to train a\ngeneric predictor with a consistent objective across them. On the other hand,\nwe formulate the personalized predictor as a lightweight adaptive module that\nis learned to minimize each client's empirical risk on top of the generic\npredictor. With this two-loss, two-predictor framework which we name Federated\nRobust Decoupling Fed-RoD, the learned model can simultaneously achieve\nstate-of-the-art generic and personalized performance, essentially bridging the\ntwo tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 00:25:48 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Hong-You", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2107.00783", "submitter": "Yunhan Huang", "authors": "Yunhan Huang, Linan Huang, Quanyan Zhu", "title": "Reinforcement Learning for Feedback-Enabled Cyber Resilience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth in the number of devices and their connectivity has enlarged\nthe attack surface and weakened cyber systems. As attackers become increasingly\nsophisticated and resourceful, mere reliance on traditional cyber protection,\nsuch as intrusion detection, firewalls, and encryption, is insufficient to\nsecure cyber systems. Cyber resilience provides a new security paradigm that\ncomplements inadequate protection with resilience mechanisms. A Cyber-Resilient\nMechanism (CRM) adapts to the known or zero-day threats and uncertainties in\nreal-time and strategically responds to them to maintain the critical functions\nof the cyber systems. Feedback architectures play a pivotal role in enabling\nthe online sensing, reasoning, and actuation of the CRM. Reinforcement Learning\n(RL) is an important class of algorithms that epitomize the feedback\narchitectures for cyber resiliency, allowing the CRM to provide dynamic and\nsequential responses to attacks with limited prior knowledge of the attacker.\nIn this work, we review the literature on RL for cyber resiliency and discuss\nthe cyber-resilient defenses against three major types of vulnerabilities,\ni.e., posture-related, information-related, and human-related vulnerabilities.\nWe introduce moving target defense, defensive cyber deception, and assistive\nhuman security technologies as three application domains of CRMs to elaborate\non their designs. The RL technique also has vulnerabilities itself. We explain\nthe major vulnerabilities of RL and present several attack models in which the\nattacks target the rewards, the measurements, and the actuators. We show that\nthe attacker can trick the RL agent into learning a nefarious policy with\nminimum attacking effort, which shows serious security concerns for RL-enabled\nsystems. Finally, we discuss the future challenges of RL for cyber security and\nresiliency and emerging applications of RL-based CRMs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 01:08:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Huang", "Yunhan", ""], ["Huang", "Linan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2107.00793", "submitter": "Kevin Xia", "authors": "Kevin Xia, Kai-Zhan Lee, Yoshua Bengio, Elias Bareinboim", "title": "The Causal-Neural Connection: Expressiveness, Learnability, and\n  Inference", "comments": "10 pages main body (53 total pages with references and appendix), 5\n  figures in main body (20 total figures including appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the central elements of any causal inference is an object called\nstructural causal model (SCM), which represents a collection of mechanisms and\nexogenous sources of random variation of the system under investigation (Pearl,\n2000). An important property of many kinds of neural networks is universal\napproximability: the ability to approximate any function to arbitrary\nprecision. Given this property, one may be tempted to surmise that a collection\nof neural nets is capable of learning any SCM by training on data generated by\nthat SCM. In this paper, we show this is not the case by disentangling the\nnotions of expressivity and learnability. Specifically, we show that the causal\nhierarchy theorem (Thm. 1, Bareinboim et al., 2020), which describes the limits\nof what can be learned from data, still holds for neural models. For instance,\nan arbitrarily complex and expressive neural net is unable to predict the\neffects of interventions given observational data alone. Given this result, we\nintroduce a special type of SCM called a neural causal model (NCM), and\nformalize a new type of inductive bias to encode structural constraints\nnecessary for performing causal inferences. Building on this new class of\nmodels, we focus on solving two canonical tasks found in the literature known\nas causal identification and estimation. Leveraging the neural toolbox, we\ndevelop an algorithm that is both sufficient and necessary to determine whether\na causal effect can be learned from data (i.e., causal identifiability); it\nthen estimates the effect whenever identifiability holds (causal estimation).\nSimulations corroborate the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 01:55:18 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 18:31:52 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xia", "Kevin", ""], ["Lee", "Kai-Zhan", ""], ["Bengio", "Yoshua", ""], ["Bareinboim", "Elias", ""]]}, {"id": "2107.00797", "submitter": "John Chen", "authors": "John Chen, Qihan Wang, Anastasios Kyrillidis", "title": "Mitigating deep double descent by concatenating inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The double descent curve is one of the most intriguing properties of deep\nneural networks. It contrasts the classical bias-variance curve with the\nbehavior of modern neural networks, occurring where the number of samples nears\nthe number of parameters. In this work, we explore the connection between the\ndouble descent phenomena and the number of samples in the deep neural network\nsetting. In particular, we propose a construction which augments the existing\ndataset by artificially increasing the number of samples. This construction\nempirically mitigates the double descent curve in this setting. We reproduce\nexisting work on deep double descent, and observe a smooth descent into the\noverparameterized region for our construction. This occurs both with respect to\nthe model size, and with respect to the number epochs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 02:06:44 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "John", ""], ["Wang", "Qihan", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2107.00798", "submitter": "Liren Shan", "authors": "Konstantin Makarychev, Liren Shan", "title": "Near-optimal Algorithms for Explainable k-Medians and k-Means", "comments": "28 pages, 4 figures, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of explainable $k$-medians and $k$-means introduced\nby Dasgupta, Frost, Moshkovitz, and Rashtchian~(ICML 2020). In this problem,\nour goal is to find a \\emph{threshold decision tree} that partitions data into\n$k$ clusters and minimizes the $k$-medians or $k$-means objective. The obtained\nclustering is easy to interpret because every decision node of a threshold tree\nsplits data based on a single feature into two groups. We propose a new\nalgorithm for this problem which is $\\tilde O(\\log k)$ competitive with\n$k$-medians with $\\ell_1$ norm and $\\tilde O(k)$ competitive with $k$-means.\nThis is an improvement over the previous guarantees of $O(k)$ and $O(k^2)$ by\nDasgupta et al (2020). We also provide a new algorithm which is $O(\\log^{3/2}\nk)$ competitive for $k$-medians with $\\ell_2$ norm. Our first algorithm is\nnear-optimal: Dasgupta et al (2020) showed a lower bound of $\\Omega(\\log k)$\nfor $k$-medians; in this work, we prove a lower bound of $\\tilde\\Omega(k)$ for\n$k$-means. We also provide a lower bound of $\\Omega(\\log k)$ for $k$-medians\nwith $\\ell_2$ norm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 02:07:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Makarychev", "Konstantin", ""], ["Shan", "Liren", ""]]}, {"id": "2107.00801", "submitter": "Atsutoshi Kumagai", "authors": "Atsutoshi Kumagai and Tomoharu Iwata and Yasuhiro Fujiwara", "title": "Meta-Learning for Relative Density-Ratio Estimation", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ratio of two probability densities, called a density-ratio, is a vital\nquantity in machine learning. In particular, a relative density-ratio, which is\na bounded extension of the density-ratio, has received much attention due to\nits stability and has been used in various applications such as outlier\ndetection and dataset comparison. Existing methods for (relative) density-ratio\nestimation (DRE) require many instances from both densities. However,\nsufficient instances are often unavailable in practice. In this paper, we\npropose a meta-learning method for relative DRE, which estimates the relative\ndensity-ratio from a few instances by using knowledge in related datasets.\nSpecifically, given two datasets that consist of a few instances, our model\nextracts the datasets' information by using neural networks and uses it to\nobtain instance embeddings appropriate for the relative DRE. We model the\nrelative density-ratio by a linear model on the embedded space, whose global\noptimum solution can be obtained as a closed-form solution. The closed-form\nsolution enables fast and effective adaptation to a few instances, and its\ndifferentiability enables us to train our model such that the expected test\nerror for relative DRE can be explicitly minimized after adapting to a few\ninstances. We empirically demonstrate the effectiveness of the proposed method\nby using three problems: relative DRE, dataset comparison, and outlier\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 02:13:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kumagai", "Atsutoshi", ""], ["Iwata", "Tomoharu", ""], ["Fujiwara", "Yasuhiro", ""]]}, {"id": "2107.00813", "submitter": "Changxin Qiu", "authors": "Changxin Qiu, Jue Yan", "title": "Cell-average based neural network method for hyperbolic and parabolic\n  partial differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by finite volume scheme, a cell-average based neural network method\nis proposed. The method is based on the integral or weak formulation of partial\ndifferential equations. A simple feed forward network is forced to learn the\nsolution average evolution between two neighboring time steps. Offline\nsupervised training is carried out to obtain the optimal network parameter set,\nwhich uniquely identifies one finite volume like neural network method. Once\nwell trained, the network method is implemented as a finite volume scheme, thus\nis mesh dependent. Different to traditional numerical methods, our method can\nbe relieved from the explicit scheme CFL restriction and can adapt to any time\nstep size for solution evolution. For Heat equation, first order of convergence\nis observed and the errors are related to the spatial mesh size but are\nobserved independent of the mesh size in time. The cell-average based neural\nnetwork method can sharply evolve contact discontinuity with almost zero\nnumerical diffusion introduced. Shock and rarefaction waves are well captured\nfor nonlinear hyperbolic conservation laws.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 03:29:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Qiu", "Changxin", ""], ["Yan", "Jue", ""]]}, {"id": "2107.00816", "submitter": "Atsutoshi Kumagai", "authors": "Atsutoshi Kumagai and Tomoharu Iwata and Yasuhiro Fujiwara", "title": "Few-shot Learning for Unsupervised Feature Selection", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a few-shot learning method for unsupervised feature selection,\nwhich is a task to select a subset of relevant features in unlabeled data.\nExisting methods usually require many instances for feature selection. However,\nsufficient instances are often unavailable in practice. The proposed method can\nselect a subset of relevant features in a target task given a few unlabeled\ntarget instances by training with unlabeled instances in multiple source tasks.\nOur model consists of a feature selector and decoder. The feature selector\noutputs a subset of relevant features taking a few unlabeled instances as input\nsuch that the decoder can reconstruct the original features of unseen instances\nfrom the selected ones. The feature selector uses the Concrete random variables\nto select features via gradient descent. To encode task-specific properties\nfrom a few unlabeled instances to the model, the Concrete random variables and\ndecoder are modeled using permutation-invariant neural networks that take a few\nunlabeled instances as input. Our model is trained by minimizing the expected\ntest reconstruction error given a few unlabeled instances that is calculated\nwith datasets in source tasks. We experimentally demonstrate that the proposed\nmethod outperforms existing feature selection methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 03:52:51 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kumagai", "Atsutoshi", ""], ["Iwata", "Tomoharu", ""], ["Fujiwara", "Yasuhiro", ""]]}, {"id": "2107.00819", "submitter": "Mingda Qiao", "authors": "Guy Blanc, Jane Lange, Mingda Qiao, Li-Yang Tan", "title": "Decision tree heuristics can fail, even in the smoothed setting", "comments": "To appear in RANDOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy decision tree learning heuristics are mainstays of machine learning\npractice, but theoretical justification for their empirical success remains\nelusive. In fact, it has long been known that there are simple target functions\nfor which they fail badly (Kearns and Mansour, STOC 1996).\n  Recent work of Brutzkus, Daniely, and Malach (COLT 2020) considered the\nsmoothed analysis model as a possible avenue towards resolving this disconnect.\nWithin the smoothed setting and for targets $f$ that are $k$-juntas, they\nshowed that these heuristics successfully learn $f$ with depth-$k$ decision\ntree hypotheses. They conjectured that the same guarantee holds more generally\nfor targets that are depth-$k$ decision trees.\n  We provide a counterexample to this conjecture: we construct targets that are\ndepth-$k$ decision trees and show that even in the smoothed setting, these\nheuristics build trees of depth $2^{\\Omega(k)}$ before achieving high accuracy.\nWe also show that the guarantees of Brutzkus et al. cannot extend to the\nagnostic setting: there are targets that are very close to $k$-juntas, for\nwhich these heuristics build trees of depth $2^{\\Omega(k)}$ before achieving\nhigh accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 04:24:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Qiao", "Mingda", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2107.00821", "submitter": "George K. Thiruvathukal", "authors": "Vishnu Banna and Akhil Chinnakotla and Zhengxin Yan and Anirudh\n  Vegesana and Naveen Vivek and Kruthi Krishnappa and Wenxin Jiang and\n  Yung-Hsiang Lu and George K. Thiruvathukal and James C. Davis", "title": "An Experience Report on Machine Learning Reproducibility: Guidance for\n  Practitioners and TensorFlow Model Garden Contributors", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning techniques are becoming a fundamental tool for scientific\nand engineering progress. These techniques are applied in contexts as diverse\nas astronomy and spam filtering. However, correctly applying these techniques\nrequires careful engineering. Much attention has been paid to the technical\npotential; relatively little attention has been paid to the software\nengineering process required to bring research-based machine learning\ntechniques into practical utility. Technology companies have supported the\nengineering community through machine learning frameworks such as TensorFLow\nand PyTorch, but the details of how to engineer complex machine learning models\nin these frameworks have remained hidden.\n  To promote best practices within the engineering community, academic\ninstitutions and Google have partnered to launch a Special Interest Group on\nMachine Learning Models (SIGMODELS) whose goal is to develop exemplary\nimplementations of prominent machine learning models in community locations\nsuch as the TensorFlow Model Garden (TFMG). The purpose of this report is to\ndefine a process for reproducing a state-of-the-art machine learning model at a\nlevel of quality suitable for inclusion in the TFMG. We define the engineering\nprocess and elaborate on each step, from paper analysis to model release. We\nreport on our experiences implementing the YOLO model family with a team of 26\nstudent researchers, share the tools we developed, and describe the lessons we\nlearned along the way.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 04:32:18 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 16:44:14 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Banna", "Vishnu", ""], ["Chinnakotla", "Akhil", ""], ["Yan", "Zhengxin", ""], ["Vegesana", "Anirudh", ""], ["Vivek", "Naveen", ""], ["Krishnappa", "Kruthi", ""], ["Jiang", "Wenxin", ""], ["Lu", "Yung-Hsiang", ""], ["Thiruvathukal", "George K.", ""], ["Davis", "James C.", ""]]}, {"id": "2107.00833", "submitter": "Sarah Dean", "authors": "Mihaela Curmei, Sarah Dean, Benjamin Recht", "title": "Quantifying Availability and Discovery in Recommender Systems via\n  Stochastic Reachability", "comments": "to appear ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider how preference models in interactive recommendation\nsystems determine the availability of content and users' opportunities for\ndiscovery. We propose an evaluation procedure based on stochastic reachability\nto quantify the maximum probability of recommending a target piece of content\nto an user for a set of allowable strategic modifications. This framework\nallows us to compute an upper bound on the likelihood of recommendation with\nminimal assumptions about user behavior. Stochastic reachability can be used to\ndetect biases in the availability of content and diagnose limitations in the\nopportunities for discovery granted to users. We show that this metric can be\ncomputed efficiently as a convex program for a variety of practical settings,\nand further argue that reachability is not inherently at odds with accuracy. We\ndemonstrate evaluations of recommendation algorithms trained on large datasets\nof explicit and implicit ratings. Our results illustrate how preference models,\nselection rules, and user interventions impact reachability and how these\neffects can be distributed unevenly.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:18:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Curmei", "Mihaela", ""], ["Dean", "Sarah", ""], ["Recht", "Benjamin", ""]]}, {"id": "2107.00838", "submitter": "Md Nazmul Karim", "authors": "Nazmul Karim, Alireza Zaeemzadeh, and Nazanin Rahnavard", "title": "RL-NCS: Reinforcement learning based data-driven approach for nonuniform\n  compressed sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A reinforcement-learning-based non-uniform compressed sensing (NCS) framework\nfor time-varying signals is introduced. The proposed scheme, referred to as\nRL-NCS, aims to boost the performance of signal recovery through an optimal and\nadaptive distribution of sensing energy among two groups of coefficients of the\nsignal, referred to as the region of interest (ROI) coefficients and non-ROI\ncoefficients. The coefficients in ROI usually have greater importance and need\nto be reconstructed with higher accuracy compared to non-ROI coefficients. In\norder to accomplish this task, the ROI is predicted at each time step using two\nspecific approaches. One of these approaches incorporates a long short-term\nmemory (LSTM) network for the prediction. The other approach employs the\nprevious ROI information for predicting the next step ROI. Using the\nexploration-exploitation technique, a Q-network learns to choose the best\napproach for designing the measurement matrix. Furthermore, a joint loss\nfunction is introduced for the efficient training of the Q-network as well as\nthe LSTM network. The result indicates a significant performance gain for our\nproposed method, even for rapidly varying signals and a reduced number of\nmeasurements.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 05:07:09 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Karim", "Nazmul", ""], ["Zaeemzadeh", "Alireza", ""], ["Rahnavard", "Nazanin", ""]]}, {"id": "2107.00839", "submitter": "Fran\\c{c}ois Delarue", "authors": "Fran\\c{c}ois Delarue and Athanasios Vasileiadis", "title": "Exploration noise for learning linear-quadratic mean field games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of this paper is to demonstrate that common noise may serve as an\nexploration noise for learning the solution of a mean field game. This concept\nis here exemplified through a toy linear-quadratic model, for which a suitable\nform of common noise has already been proven to restore existence and\nuniqueness. We here go one step further and prove that the same form of common\nnoise may force the convergence of the learning algorithm called `fictitious\nplay', and this without any further potential or monotone structure. Several\nnumerical examples are provided in order to support our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 05:18:50 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Delarue", "Fran\u00e7ois", ""], ["Vasileiadis", "Athanasios", ""]]}, {"id": "2107.00844", "submitter": "Younsik Kim", "authors": "Younsik Kim, Dongjin Oh, Soonsang Huh, Dongjoon Song, Sunbeom Jeong,\n  Junyoung Kwon, Minsoo Kim, Donghan Kim, Hanyoung Ryu, Jongkeun Jung, Wonshik\n  Kyung, Byungmin Sohn, Suyoung Lee, Jounghoon Hyun, Yeonghoon Lee, Yeongkwan\n  Kimand Changyoung Kim", "title": "Deep learning-based statistical noise reduction for multidimensional\n  spectral data", "comments": "8 pages, 8 figures", "journal-ref": "Review of Scientific Instruments 92, 073901 (2021)", "doi": "10.1063/5.0054920", "report-no": null, "categories": "cs.LG physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In spectroscopic experiments, data acquisition in multi-dimensional phase\nspace may require long acquisition time, owing to the large phase space volume\nto be covered. In such case, the limited time available for data acquisition\ncan be a serious constraint for experiments in which multidimensional spectral\ndata are acquired. Here, taking angle-resolved photoemission spectroscopy\n(ARPES) as an example, we demonstrate a denoising method that utilizes deep\nlearning as an intelligent way to overcome the constraint. With readily\navailable ARPES data and random generation of training data set, we\nsuccessfully trained the denoising neural network without overfitting. The\ndenoising neural network can remove the noise in the data while preserving its\nintrinsic information. We show that the denoising neural network allows us to\nperform similar level of second-derivative and line shape analysis on data\ntaken with two orders of magnitude less acquisition time. The importance of our\nmethod lies in its applicability to any multidimensional spectral data that are\nsusceptible to statistical noise.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 05:37:16 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Kim", "Younsik", ""], ["Oh", "Dongjin", ""], ["Huh", "Soonsang", ""], ["Song", "Dongjoon", ""], ["Jeong", "Sunbeom", ""], ["Kwon", "Junyoung", ""], ["Kim", "Minsoo", ""], ["Kim", "Donghan", ""], ["Ryu", "Hanyoung", ""], ["Jung", "Jongkeun", ""], ["Kyung", "Wonshik", ""], ["Sohn", "Byungmin", ""], ["Lee", "Suyoung", ""], ["Hyun", "Jounghoon", ""], ["Lee", "Yeonghoon", ""], ["Kim", "Yeongkwan Kimand Changyoung", ""]]}, {"id": "2107.00848", "submitter": "Nan Rosemary Ke", "authors": "Nan Rosemary Ke, Aniket Didolkar, Sarthak Mittal, Anirudh Goyal,\n  Guillaume Lajoie, Stefan Bauer, Danilo Rezende, Yoshua Bengio, Michael Mozer,\n  Christopher Pal", "title": "Systematic Evaluation of Causal Discovery in Visual Model Based\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inducing causal relationships from observations is a classic problem in\nmachine learning. Most work in causality starts from the premise that the\ncausal variables themselves are observed. However, for AI agents such as robots\ntrying to make sense of their environment, the only observables are low-level\nvariables like pixels in images. To generalize well, an agent must induce\nhigh-level variables, particularly those which are causal or are affected by\ncausal variables. A central goal for AI and causality is thus the joint\ndiscovery of abstract representations and causal structure. However, we note\nthat existing environments for studying causal induction are poorly suited for\nthis objective because they have complicated task-specific causal graphs which\nare impossible to manipulate parametrically (e.g., number of nodes, sparsity,\ncausal chain length, etc.). In this work, our goal is to facilitate research in\nlearning representations of high-level variables as well as causal structures\namong them. In order to systematically probe the ability of methods to identify\nthese variables and structures, we design a suite of benchmarking RL\nenvironments. We evaluate various representation learning algorithms from the\nliterature and find that explicitly incorporating structure and modularity in\nmodels can help causal induction in model-based reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 05:44:56 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Ke", "Nan Rosemary", ""], ["Didolkar", "Aniket", ""], ["Mittal", "Sarthak", ""], ["Goyal", "Anirudh", ""], ["Lajoie", "Guillaume", ""], ["Bauer", "Stefan", ""], ["Rezende", "Danilo", ""], ["Bengio", "Yoshua", ""], ["Mozer", "Michael", ""], ["Pal", "Christopher", ""]]}, {"id": "2107.00860", "submitter": "Hayeon Lee", "authors": "Hayeon Lee, Eunyoung Hyung, Sung Ju Hwang", "title": "Rapid Neural Architecture Search by Learning to Generate Graphs from\n  Datasets", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the success of recent Neural Architecture Search (NAS) methods on\nvarious tasks which have shown to output networks that largely outperform\nhuman-designed networks, conventional NAS methods have mostly tackled the\noptimization of searching for the network architecture for a single task\n(dataset), which does not generalize well across multiple tasks (datasets).\nMoreover, since such task-specific methods search for a neural architecture\nfrom scratch for every given task, they incur a large computational cost, which\nis problematic when the time and monetary budget are limited. In this paper, we\npropose an efficient NAS framework that is trained once on a database\nconsisting of datasets and pretrained networks and can rapidly search for a\nneural architecture for a novel dataset. The proposed MetaD2A (Meta\nDataset-to-Architecture) model can stochastically generate graphs\n(architectures) from a given set (dataset) via a cross-modal latent space\nlearned with amortized meta-learning. Moreover, we also propose a\nmeta-performance predictor to estimate and select the best architecture without\ndirect training on target datasets. The experimental results demonstrate that\nour model meta-learned on subsets of ImageNet-1K and architectures from\nNAS-Bench 201 search space successfully generalizes to multiple unseen datasets\nincluding CIFAR-10 and CIFAR-100, with an average search time of 33 GPU\nseconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than\nNSGANetV2, a transferable NAS method, with comparable performance. We believe\nthat the MetaD2A proposes a new research direction for rapid NAS as well as\nways to utilize the knowledge from rich databases of datasets and architectures\naccumulated over the past years. Code is available at\nhttps://github.com/HayeonLee/MetaD2A.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 06:33:59 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Lee", "Hayeon", ""], ["Hyung", "Eunyoung", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2107.00866", "submitter": "Yunzhuang Shen", "authors": "Yunzhuang Shen, Yuan Sun, Andrew Eberhard, Xiaodong Li", "title": "Learning Primal Heuristics for Mixed Integer Programs", "comments": "Accepted by IJCNN'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel primal heuristic for Mixed Integer Programs, by\nemploying machine learning techniques. Mixed Integer Programming is a general\ntechnique for formulating combinatorial optimization problems. Inside a solver,\nprimal heuristics play a critical role in finding good feasible solutions that\nenable one to tighten the duality gap from the outset of the Branch-and-Bound\nalgorithm (B&B), greatly improving its performance by pruning the B&B tree\naggressively. In this paper, we investigate whether effective primal heuristics\ncan be automatically learned via machine learning. We propose a new method to\nrepresent an optimization problem as a graph, and train a Graph Convolutional\nNetwork on solved problem instances with known optimal solutions. This in turn\ncan predict the values of decision variables in the optimal solution for an\nunseen problem instance of a similar type. The prediction of variable solutions\nis then leveraged by a novel configuration of the B&B method, Probabilistic\nBranching with guided Depth-first Search (PB-DFS) approach, aiming to find\n(near-)optimal solutions quickly. The experimental results show that this new\nheuristic can find better primal solutions at a much earlier stage of the\nsolving process, compared to other state-of-the-art primal heuristics.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 06:46:23 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Shen", "Yunzhuang", ""], ["Sun", "Yuan", ""], ["Eberhard", "Andrew", ""], ["Li", "Xiaodong", ""]]}, {"id": "2107.00871", "submitter": "Kazuya Takabatake", "authors": "Kazuya Takabatake, Shotaro Akaho", "title": "Reconsidering Dependency Networks from an Information Geometry\n  Perspective", "comments": "28pages, 7figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Dependency networks (Heckerman et al., 2000) are potential probabilistic\ngraphical models for systems comprising a large number of variables. Like\nBayesian networks, the structure of a dependency network is represented by a\ndirected graph, and each node has a conditional probability table. Learning and\ninference are realized locally on individual nodes; therefore, computation\nremains tractable even with a large number of variables. However, the\ndependency network's learned distribution is the stationary distribution of a\nMarkov chain called pseudo-Gibbs sampling and has no closed-form expressions.\nThis technical disadvantage has impeded the development of dependency networks.\nIn this paper, we consider a certain manifold for each node. Then, we can\ninterpret pseudo-Gibbs sampling as iterative m-projections onto these\nmanifolds. This interpretation provides a theoretical bound for the location\nwhere the stationary distribution of pseudo-Gibbs sampling exists in\ndistribution space. Furthermore, this interpretation involves structure and\nparameter learning algorithms as optimization problems. In addition, we compare\ndependency and Bayesian networks experimentally. The results demonstrate that\nthe dependency network and the Bayesian network have roughly the same\nperformance in terms of the accuracy of their learned distributions. The\nresults also show that the dependency network can learn much faster than the\nBayesian network.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 07:05:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Takabatake", "Kazuya", ""], ["Akaho", "Shotaro", ""]]}, {"id": "2107.00877", "submitter": "Takashi Amakasu", "authors": "Takashi Amakasu, Nicolas Chauvet, Guillaume Bachelier, Serge Huant,\n  Ryoichi Horisaki, Makoto Naruse", "title": "Conflict-free collective stochastic decision making by orbital angular\n  momentum entangled photons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LG physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent cross-disciplinary studies involving both optics and computing,\nsingle-photon-based decision-making has been demonstrated by utilizing the\nwave-particle duality of light to solve multi-armed bandit problems.\nFurthermore, entangled-photon-based decision-making has managed to solve a\ncompetitive multi-armed bandit problem in such a way that conflicts of\ndecisions among players are avoided while ensuring equality. However, as these\nstudies are based on the polarization of light, the number of available choices\nis limited to two, corresponding to two orthogonal polarization states. Here we\npropose a scalable principle to solve competitive decision-making situations by\nusing the orbital angular momentum as the tunable degree of freedom of photons,\nwhich theoretically allows an unlimited number of arms. Moreover, by extending\nthe Hong-Ou-Mandel effect to more than two states, we theoretically establish\nan experimental configuration able to generate entangled photon states with\norbital angular momentum and conditions that provide conflict-free selections\nat every turn. We numerically examine total rewards regarding three-armed\nbandit problems, for which the proposed strategy accomplishes almost the\ntheoretical maximum, which is greater than a conventional mixed strategy\nintending to realize Nash equilibrium. This is thanks to the entanglement\nproperty that achieves no-conflict selections, even in the exploring phase to\nfind the best arms.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 07:32:01 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Amakasu", "Takashi", ""], ["Chauvet", "Nicolas", ""], ["Bachelier", "Guillaume", ""], ["Huant", "Serge", ""], ["Horisaki", "Ryoichi", ""], ["Naruse", "Makoto", ""]]}, {"id": "2107.00881", "submitter": "Geet Shingi", "authors": "Geet Shingi, Harsh Saglani, Preeti Jain", "title": "Segmented Federated Learning for Adaptive Intrusion Detection System", "comments": "Accepted at the Workshop on Artificial Intelligence for Social Good\n  (AI4SG) at the 30th International Joint Conference on Artificial Intelligence\n  (IJCAI), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cyberattacks are a major issues and it causes organizations great financial,\nand reputation harm. However, due to various factors, the current network\nintrusion detection systems (NIDS) seem to be insufficent. Predominant NIDS\nidentifies Cyberattacks through a handcrafted dataset of rules. Although the\nrecent applications of machine learning and deep learning have alleviated the\nenormous effort in NIDS, the security of network data has always been a prime\nconcern. However, to encounter the security problem and enable sharing among\norganizations, Federated Learning (FL) scheme is employed. Although the current\nFL systems have been successful, a network's data distribution does not always\nfit into a single global model as in FL. Thus, in such cases, having a single\nglobal model in FL is no feasible. In this paper, we propose a\nSegmented-Federated Learning (Segmented-FL) learning scheme for a more\nefficient NIDS. The Segmented-FL approach employs periodic local model\nevaluation based on which the segmentation occurs. We aim to bring similar\nnetwork environments to the same group. Further, the Segmented-FL system is\ncoupled with a weighted aggregation of local model parameters based on the\nnumber of data samples a worker possesses to further augment the performance.\nThe improved performance by our system as compared to the FL and centralized\nsystems on standard dataset further validates our system and makes a strong\ncase for extending our technique across various tasks. The solution finds its\napplication in organizations that want to collaboratively learn on diverse\nnetwork environments and protect the privacy of individual datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 07:47:05 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Shingi", "Geet", ""], ["Saglani", "Harsh", ""], ["Jain", "Preeti", ""]]}, {"id": "2107.00896", "submitter": "Zhongjie Shi", "authors": "Tong Mao, Zhongjie Shi, and Ding-Xuan Zhou", "title": "Theory of Deep Convolutional Neural Networks III: Approximating Radial\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a family of deep neural networks consisting of two groups of\nconvolutional layers, a downsampling operator, and a fully connected layer. The\nnetwork structure depends on two structural parameters which determine the\nnumbers of convolutional layers and the width of the fully connected layer. We\nestablish an approximation theory with explicit approximation rates when the\napproximated function takes a composite form $f\\circ Q$ with a feature\npolynomial $Q$ and a univariate function $f$. In particular, we prove that such\na network can outperform fully connected shallow networks in approximating\nradial functions with $Q(x) =|x|^2$, when the dimension $d$ of data from\n$\\mathbb{R}^d$ is large. This gives the first rigorous proof for the\nsuperiority of deep convolutional neural networks in approximating functions\nwith special structures. Then we carry out generalization analysis for\nempirical risk minimization with such a deep network in a regression framework\nwith the regression function of the form $f\\circ Q$. Our network structure\nwhich does not use any composite information or the functions $Q$ and $f$ can\nautomatically extract features and make use of the composite nature of the\nregression function via tuning the structural parameters. Our analysis provides\nan error bound which decreases with the network depth to a minimum and then\nincreases, verifying theoretically a trade-off phenomenon observed for network\ndepths in many practical applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 08:22:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Mao", "Tong", ""], ["Shi", "Zhongjie", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "2107.00921", "submitter": "Tao Han", "authors": "Tao Han, Hantao Huang, Ziang Yang, Wei Han", "title": "Supervised Contrastive Learning for Accented Speech Recognition", "comments": "Accented speech recognition, deep neural networks, model adaptation,\n  supervised contrastive learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based speech recognition systems suffer from performance\ndegradation due to accented speech, especially unfamiliar accents. In this\npaper, we study the supervised contrastive learning framework for accented\nspeech recognition. To build different views (similar \"positive\" data samples)\nfor contrastive learning, three data augmentation techniques including noise\ninjection, spectrogram augmentation and TTS-same-sentence generation are\nfurther investigated. From the experiments on the Common Voice dataset, we have\nshown that contrastive learning helps to build data-augmentation invariant and\npronunciation invariant representations, which significantly outperforms\ntraditional joint training methods in both zero-shot and full-shot settings.\nExperiments show that contrastive learning can improve accuracy by 3.66%\n(zero-shot) and 3.78% (full-shot) on average, comparing to the joint training\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:23:33 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Han", "Tao", ""], ["Huang", "Hantao", ""], ["Yang", "Ziang", ""], ["Han", "Wei", ""]]}, {"id": "2107.00927", "submitter": "Luisa M\\\"arz", "authors": "Luisa M\\\"arz, Stefan Schweter, Nina Poerner, Benjamin Roth and Hinrich\n  Sch\\\"utze", "title": "Data Centric Domain Adaptation for Historical Text with OCR Errors", "comments": "14 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose new methods for in-domain and cross-domain Named Entity\nRecognition (NER) on historical data for Dutch and French. For the cross-domain\ncase, we address domain shift by integrating unsupervised in-domain data via\ncontextualized string embeddings; and OCR errors by injecting synthetic OCR\nerrors into the source domain and address data centric domain adaptation. We\npropose a general approach to imitate OCR errors in arbitrary input data. Our\ncross-domain as well as our in-domain results outperform several strong\nbaselines and establish state-of-the-art results. We publish preprocessed\nversions of the French and Dutch Europeana NER corpora.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:37:15 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["M\u00e4rz", "Luisa", ""], ["Schweter", "Stefan", ""], ["Poerner", "Nina", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2107.00931", "submitter": "Zeynep Hilal Kilimci", "authors": "Anil Berk Altuner, Zeynep Hilal Kilimci", "title": "A Novel Deep Reinforcement Learning Based Stock Direction Prediction\n  using Knowledge Graph and Community Aware Sentiments", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CE cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Stock market prediction has been an important topic for investors,\nresearchers, and analysts. Because it is affected by too many factors, stock\nmarket prediction is a difficult task to handle. In this study, we propose a\nnovel method that is based on deep reinforcement learning methodologies for the\ndirection prediction of stocks using sentiments of community and knowledge\ngraph. For this purpose, we firstly construct a social knowledge graph of users\nby analyzing relations between connections. After that, time series analysis of\nrelated stock and sentiment analysis is blended with deep reinforcement\nmethodology. Turkish version of Bidirectional Encoder Representations from\nTransformers (BerTurk) is employed to analyze the sentiments of the users while\ndeep Q-learning methodology is used for the deep reinforcement learning side of\nthe proposed model to construct the deep Q network. In order to demonstrate the\neffectiveness of the proposed model, Garanti Bank (GARAN), Akbank (AKBNK),\nT\\\"urkiye \\.I\\c{s} Bankas{\\i} (ISCTR) stocks in Istanbul Stock Exchange are\nused as a case study. Experiment results show that the proposed novel model\nachieves remarkable results for stock market prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:39:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Altuner", "Anil Berk", ""], ["Kilimci", "Zeynep Hilal", ""]]}, {"id": "2107.00940", "submitter": "Suryanarayana Maddu", "authors": "Suryanarayana Maddu, Dominik Sturm, Christian L. M\u007f\\\"uller, Ivo F.\n  Sbalzarini", "title": "Inverse-Dirichlet Weighting Enables Reliable Training of Physics\n  Informed Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph q-bio.QM", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We characterize and remedy a failure mode that may arise from multi-scale\ndynamics with scale imbalances during training of deep neural networks, such as\nPhysics Informed Neural Networks (PINNs). PINNs are popular machine-learning\ntemplates that allow for seamless integration of physical equation models with\ndata. Their training amounts to solving an optimization problem over a weighted\nsum of data-fidelity and equation-fidelity objectives. Conflicts between\nobjectives can arise from scale imbalances, heteroscedasticity in the data,\nstiffness of the physical equation, or from catastrophic interference during\nsequential training. We explain the training pathology arising from this and\npropose a simple yet effective inverse-Dirichlet weighting strategy to\nalleviate the issue. We compare with Sobolev training of neural networks,\nproviding the baseline of analytically $\\boldsymbol{\\epsilon}$-optimal\ntraining. We demonstrate the effectiveness of inverse-Dirichlet weighting in\nvarious applications, including a multi-scale model of active turbulence, where\nwe show orders of magnitude improvement in accuracy and convergence over\nconventional PINN training. For inverse modeling using sequential training, we\nfind that inverse-Dirichlet weighting protects a PINN against catastrophic\nforgetting.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:01:37 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Maddu", "Suryanarayana", ""], ["Sturm", "Dominik", ""], ["M\u007f\u00fcller", "Christian L.", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "2107.00941", "submitter": "Rahul Goel", "authors": "Raj Jagtap, Abhinav Kumar, Rahul Goel, Shakshi Sharma, Rajesh Sharma,\n  Clint P. George", "title": "Misinformation Detection on YouTube Using Video Captions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of people use platforms such as YouTube, Facebook, Twitter, and\nother mass media. Due to the accessibility of these platforms, they are often\nused to establish a narrative, conduct propaganda, and disseminate\nmisinformation. This work proposes an approach that uses state-of-the-art NLP\ntechniques to extract features from video captions (subtitles). To evaluate our\napproach, we utilize a publicly accessible and labeled dataset for classifying\nvideos as misinformation or not. The motivation behind exploring video captions\nstems from our analysis of videos metadata. Attributes such as the number of\nviews, likes, dislikes, and comments are ineffective as videos are hard to\ndifferentiate using this information. Using caption dataset, the proposed\nmodels can classify videos among three classes (Misinformation, Debunking\nMisinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the\nrelevance of the misinformation class, we re-formulate our classification\nproblem as a two-class classification - Misinformation vs. others (Debunking\nMisinformation and Neutral). In our experiments, the proposed models can\nclassify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:02:36 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Jagtap", "Raj", ""], ["Kumar", "Abhinav", ""], ["Goel", "Rahul", ""], ["Sharma", "Shakshi", ""], ["Sharma", "Rajesh", ""], ["George", "Clint P.", ""]]}, {"id": "2107.00946", "submitter": "Lingbo Liu", "authors": "Lingbo Liu, Yuying Zhu, Guanbin Li, Ziyi Wu, Lei Bai, Mingzhi Mao,\n  Liang Lin", "title": "Online Metro Origin-Destination Prediction via Heterogeneous Information\n  Aggregation", "comments": "UnderReview", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metro origin-destination prediction is a crucial yet challenging task for\nintelligent transportation management, which aims to accurately forecast two\nspecific types of cross-station ridership, i.e., Origin-Destination (OD) one\nand Destination-Origin (DO) one. However, complete OD matrices of previous time\nintervals can not be obtained immediately in online metro systems, and\nconventional methods only used limited information to forecast the future OD\nand DO ridership separately. In this work, we proposed a novel neural network\nmodule termed Heterogeneous Information Aggregation Machine (HIAM), which fully\nexploits heterogeneous information of historical data (e.g., incomplete OD\nmatrices, unfinished order vectors, and DO matrices) to jointly learn the\nevolutionary patterns of OD and DO ridership. Specifically, an OD modeling\nbranch estimates the potential destinations of unfinished orders explicitly to\ncomplement the information of incomplete OD matrices, while a DO modeling\nbranch takes DO matrices as input to capture the spatial-temporal distribution\nof DO ridership. Moreover, a Dual Information Transformer is introduced to\npropagate the mutual information among OD features and DO features for modeling\nthe OD-DO causality and correlation. Based on the proposed HIAM, we develop a\nunified Seq2Seq network to forecast the future OD and DO ridership\nsimultaneously. Extensive experiments conducted on two large-scale benchmarks\ndemonstrate the effectiveness of our method for online metro origin-destination\nprediction.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:11:51 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 01:28:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liu", "Lingbo", ""], ["Zhu", "Yuying", ""], ["Li", "Guanbin", ""], ["Wu", "Ziyi", ""], ["Bai", "Lei", ""], ["Mao", "Mingzhi", ""], ["Lin", "Liang", ""]]}, {"id": "2107.00948", "submitter": "Haoyi Xiong", "authors": "Zhiyuan Wang, Haoyi Xiong, Jie Zhang, Sijia Yang, Mehdi Boukhechba,\n  Laura E. Barnes, Daqing Zhang", "title": "From Personalized Medicine to Population Health: A Survey of mHealth\n  Sensing Techniques", "comments": "Submitted to a journal for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile Sensing Apps have been widely used as a practical approach to collect\nbehavioral and health-related information from individuals and provide timely\nintervention to promote health and well-beings, such as mental health and\nchronic cares. As the objectives of mobile sensing could be either \\emph{(a)\npersonalized medicine for individuals} or \\emph{(b) public health for\npopulations}, in this work we review the design of these mobile sensing apps,\nand propose to categorize the design of these apps/systems in two paradigms --\n\\emph{(i) Personal Sensing} and \\emph{(ii) Crowd Sensing} paradigms. While both\nsensing paradigms might incorporate with common ubiquitous sensing\ntechnologies, such as wearable sensors, mobility monitoring, mobile data\noffloading, and/or cloud-based data analytics to collect and process sensing\ndata from individuals, we present a novel taxonomy system with two major\ncomponents that can specify and classify apps/systems from aspects of the\nlife-cycle of mHealth Sensing: \\emph{(1) Sensing Task Creation \\&\nParticipation}, \\emph{(2) Health Surveillance \\& Data Collection}, and\n\\emph{(3) Data Analysis \\& Knowledge Discovery}. With respect to different\ngoals of the two paradigms, this work systematically reviews this field, and\nsummarizes the design of typical apps/systems in the view of the configurations\nand interactions between these two components. In addition to summarization,\nthe proposed taxonomy system also helps figure out the potential directions of\nmobile sensing for health from both personalized medicines and population\nhealth perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:16:21 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wang", "Zhiyuan", ""], ["Xiong", "Haoyi", ""], ["Zhang", "Jie", ""], ["Yang", "Sijia", ""], ["Boukhechba", "Mehdi", ""], ["Barnes", "Laura E.", ""], ["Zhang", "Daqing", ""]]}, {"id": "2107.00956", "submitter": "R\\'emy Portelas", "authors": "Grgur Kova\\v{c}, R\\'emy Portelas, Katja Hofmann, Pierre-Yves Oudeyer", "title": "SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement\n  Learning Agents", "comments": "under review. This paper extends and generalizes work in\n  arXiv:2104.13207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building embodied autonomous agents capable of participating in social\ninteractions with humans is one of the main challenges in AI. Within the Deep\nReinforcement Learning (DRL) field, this objective motivated multiple works on\nembodied language use. However, current approaches focus on language as a\ncommunication tool in very simplified and non-diverse social situations: the\n\"naturalness\" of language is reduced to the concept of high vocabulary size and\nvariability. In this paper, we argue that aiming towards human-level AI\nrequires a broader set of key social skills: 1) language use in complex and\nvariable social contexts; 2) beyond language, complex embodied communication in\nmultimodal settings within constantly evolving social worlds. We explain how\nconcepts from cognitive sciences could help AI to draw a roadmap towards\nhuman-like intelligence, with a focus on its social dimensions. As a first\nstep, we propose to expand current research to a broader set of core social\nskills. To do this, we present SocialAI, a benchmark to assess the acquisition\nof social skills of DRL agents using multiple grid-world environments featuring\nother (scripted) social agents. We then study the limits of a recent SOTA DRL\napproach when tested on SocialAI and discuss important next steps towards\nproficient social agents. Videos and code are available at\nhttps://sites.google.com/view/socialai.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:39:18 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 06:42:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kova\u010d", "Grgur", ""], ["Portelas", "R\u00e9my", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2107.00957", "submitter": "Tareq Si Salem", "authors": "Tareq Si Salem, Giovanni Neglia, Damiano Carra", "title": "A\\c{C}AI: Ascent Similarity Caching with Approximate Indexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Similarity search is a key operation in multimedia retrieval systems and\nrecommender systems, and it will play an important role also for future machine\nlearning and augmented reality applications. When these systems need to serve\nlarge objects with tight delay constraints, edge servers close to the end-user\ncan operate as similarity caches to speed up the retrieval. In this paper we\npresent A\\c{C}AI, a new similarity caching policy which improves on the state\nof the art by using (i) an (approximate) index for the whole catalog to decide\nwhich objects to serve locally and which to retrieve from the remote server,\nand (ii) a mirror ascent algorithm to update the set of local objects with\nstrong guarantees even when the request process does not exhibit any\nstatistical regularity.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:40:47 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Salem", "Tareq Si", ""], ["Neglia", "Giovanni", ""], ["Carra", "Damiano", ""]]}, {"id": "2107.00961", "submitter": "Anastasios Kyrillidis", "authors": "Chen Dun, Cameron R. Wolfe, Christopher M. Jermaine, Anastasios\n  Kyrillidis", "title": "ResIST: Layer-Wise Decomposition of ResNets for Distributed Training", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose {\\rm \\texttt{ResIST}}, a novel distributed training protocol for\nResidual Networks (ResNets). {\\rm \\texttt{ResIST}} randomly decomposes a global\nResNet into several shallow sub-ResNets that are trained independently in a\ndistributed manner for several local iterations, before having their updates\nsynchronized and aggregated into the global model. In the next round, new\nsub-ResNets are randomly generated and the process repeats. By construction,\nper iteration, {\\rm \\texttt{ResIST}} communicates only a small portion of\nnetwork parameters to each machine and never uses the full model during\ntraining. Thus, {\\rm \\texttt{ResIST}} reduces the communication, memory, and\ntime requirements of ResNet training to only a fraction of the requirements of\nprevious methods. In comparison to common protocols like data-parallel training\nand data-parallel training with local SGD, {\\rm \\texttt{ResIST}} yields a\ndecrease in wall-clock training time, while being competitive with respect to\nmodel performance.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:48:50 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Dun", "Chen", ""], ["Wolfe", "Cameron R.", ""], ["Jermaine", "Christopher M.", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2107.00964", "submitter": "Ioannis Tzortzis", "authors": "Charalampos Zafeiropoulos, Ioannis N. Tzortzis, Ioannis Rallis,\n  Eftychios Protopapadakis, Nikolaos Doulamis and Anastasios Doulamis", "title": "Evaluating the Usefulness of Unsupervised monitoring in Cultural\n  Heritage Monuments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we scrutinize the effectiveness of various clustering\ntechniques, investigating their applicability in Cultural Heritage monitoring\napplications. In the context of this paper, we detect the level of\ndecomposition and corrosion on the walls of Saint Nicholas fort in Rhodes\nutilizing hyperspectral images. A total of 6 different clustering approaches\nhave been evaluated over a set of 14 different orthorectified hyperspectral\nimages. Experimental setup in this study involves K-means, Spectral, Meanshift,\nDBSCAN, Birch and Optics algorithms. For each of these techniques we evaluate\nits performance by the use of performance metrics such as Calinski-Harabasz,\nDavies-Bouldin indexes and Silhouette value. In this approach, we evaluate the\noutcomes of the clustering methods by comparing them with a set of annotated\nimages which denotes the ground truth regarding the decomposition and/or\ncorrosion area of the original images. The results depict that a few clustering\ntechniques applied on the given dataset succeeded decent accuracy, precision,\nrecall and f1 scores. Eventually, it was observed that the deterioration was\ndetected quite accurately.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:51:28 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zafeiropoulos", "Charalampos", ""], ["Tzortzis", "Ioannis N.", ""], ["Rallis", "Ioannis", ""], ["Protopapadakis", "Eftychios", ""], ["Doulamis", "Nikolaos", ""], ["Doulamis", "Anastasios", ""]]}, {"id": "2107.00967", "submitter": "Xiang Hu", "authors": "Xiang Hu, Haitao Mi, Zujie Wen, Yafang Wang, Yi Su, Jing Zheng, Gerard\n  de Melo", "title": "R2D2: Recursive Transformer based on Differentiable Tree for\n  Interpretable Hierarchical Language Modeling", "comments": "To be published in the proceedings of ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language understanding operates at multiple levels of granularity\n(e.g., words, phrases, and sentences) with increasing levels of abstraction\nthat can be hierarchically combined. However, existing deep models with stacked\nlayers do not explicitly model any sort of hierarchical process. This paper\nproposes a recursive Transformer model based on differentiable CKY style binary\ntrees to emulate the composition process. We extend the bidirectional language\nmodel pre-training objective to this architecture, attempting to predict each\nword given its left and right abstraction nodes. To scale up our approach, we\nalso introduce an efficient pruned tree induction algorithm to enable encoding\nin just a linear number of composition steps. Experimental results on language\nmodeling and unsupervised parsing show the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 11:00:46 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Hu", "Xiang", ""], ["Mi", "Haitao", ""], ["Wen", "Zujie", ""], ["Wang", "Yafang", ""], ["Su", "Yi", ""], ["Zheng", "Jing", ""], ["de Melo", "Gerard", ""]]}, {"id": "2107.00968", "submitter": "Thanaphon Suwannaphong", "authors": "Thanaphon Suwannaphong, Sawaphob Chavana, Sahapol Tongsom, Duangdao\n  Palasuwan, Thanarat H. Chalidabhongse and Nantheera Anantrasirichai", "title": "Parasitic Egg Detection and Classification in Low-cost Microscopic\n  Images using Transfer Learning", "comments": "7 pages, 9 figures, Preprint submitted to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intestinal parasitic infection leads to several morbidities to humans\nworldwide, especially in tropical countries. The traditional diagnosis usually\nrelies on manual analysis from microscopic images which is prone to human error\ndue to morphological similarity of different parasitic eggs and abundance of\nimpurities in a sample. Many studies have developed automatic systems for\nparasite egg detection to reduce human workload. However, they work with high\nquality microscopes, which unfortunately remain unaffordable in some rural\nareas. Our work thus exploits a benefit of a low-cost USB microscope. This\ninstrument however provides poor quality of images due to limitation of\nmagnification (10x), causing difficulty in parasite detection and species\nclassification. In this paper, we propose a CNN-based technique using transfer\nlearning strategy to enhance the efficiency of automatic parasite\nclassification in poor-quality microscopic images. The patch-based technique\nwith sliding window is employed to search for location of the eggs. Two\nnetworks, AlexNet and ResNet50, are examined with a trade-off between\narchitecture size and classification performance. The results show that our\nproposed framework outperforms the state-of-the-art object recognition methods.\nOur system combined with final decision from an expert may improve the real\nfaecal examination with low-cost microscopes.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 11:05:45 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Suwannaphong", "Thanaphon", ""], ["Chavana", "Sawaphob", ""], ["Tongsom", "Sahapol", ""], ["Palasuwan", "Duangdao", ""], ["Chalidabhongse", "Thanarat H.", ""], ["Anantrasirichai", "Nantheera", ""]]}, {"id": "2107.00992", "submitter": "Jian Gu", "authors": "Jian Gu, Zimin Chen, Martin Monperrus", "title": "Multimodal Representation for Neural Code Search", "comments": "12 pages, 9 figures, accepted by ICSME 2021, the camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic code search is about finding semantically relevant code snippets for\na given natural language query. In the state-of-the-art approaches, the\nsemantic similarity between code and query is quantified as the distance of\ntheir representation in the shared vector space. In this paper, to improve the\nvector space, we introduce tree-serialization methods on a simplified form of\nAST and build the multimodal representation for the code data. We conduct\nextensive experiments using a single corpus that is large-scale and\nmulti-language: CodeSearchNet. Our results show that both our tree-serialized\nrepresentations and multimodal learning model improve the performance of code\nsearch. Last, we define intuitive quantification metrics oriented to the\ncompleteness of semantic and syntactic information of the code data, to help\nunderstand the experimental findings.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 12:08:19 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 12:01:25 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Gu", "Jian", ""], ["Chen", "Zimin", ""], ["Monperrus", "Martin", ""]]}, {"id": "2107.00996", "submitter": "Adel Bibi", "authors": "Motasem Alfarra, Adel Bibi, Naeemullah Khan, Philip H. S. Torr, and\n  Bernard Ghanem", "title": "DeformRS: Certifying Input Deformations with Randomized Smoothing", "comments": "First two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to input deformations in the form of\nvector fields of pixel displacements and to other parameterized geometric\ndeformations e.g. translations, rotations, etc. Current input deformation\ncertification methods either (i) do not scale to deep networks on large input\ndatasets, or (ii) can only certify a specific class of deformations, e.g. only\nrotations. We reformulate certification in randomized smoothing setting for\nboth general vector field and parameterized deformations and propose\nDeformRS-VF and DeformRS-Par, respectively. Our new formulation scales to large\nnetworks on large input datasets. For instance, DeformRS-Par certifies rich\ndeformations, covering translations, rotations, scaling, affine deformations,\nand other visually aligned deformations such as ones parameterized by\nDiscrete-Cosine-Transform basis. Extensive experiments on MNIST, CIFAR10 and\nImageNet show that DeformRS-Par outperforms existing state-of-the-art in\ncertified accuracy, e.g. improved certified accuracy of 6% against perturbed\nrotations in the set [-10,10] degrees on ImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 12:20:15 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Alfarra", "Motasem", ""], ["Bibi", "Adel", ""], ["Khan", "Naeemullah", ""], ["Torr", "Philip H. S.", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2107.00998", "submitter": "Youry Khmelevsky", "authors": "Albert Wong, Chun Yin Chiu, Ga\\'etan Hains, Jack Humphrey, Hans\n  Fuhrmann, Youry Khmelevsky, Chris Mazur", "title": "Gamers Private Network Performance Forecasting. From Raw Data to the\n  Data Warehouse with Machine Learning and Neural Nets", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Gamers Private Network (GPN) is a client/server technology that guarantees a\nconnection for online video games that is more reliable and lower latency than\na standard internet connection. Users of the GPN technology benefit from a\nstable and high-quality gaming experience for online games, which are hosted\nand played across the world. After transforming a massive volume of raw\nnetworking data collected by WTFast, we have structured the cleaned data into a\nspecial-purpose data warehouse and completed the extensive analysis using\nmachine learning and neural nets technologies, and business intelligence tools.\nThese analyses demonstrate the ability to predict and quantify changes in the\nnetwork and demonstrate the benefits gained from the use of a GPN for users\nwhen connected to an online game session.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 00:45:01 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wong", "Albert", ""], ["Chiu", "Chun Yin", ""], ["Hains", "Ga\u00e9tan", ""], ["Humphrey", "Jack", ""], ["Fuhrmann", "Hans", ""], ["Khmelevsky", "Youry", ""], ["Mazur", "Chris", ""]]}, {"id": "2107.01001", "submitter": "Peng Yang", "authors": "Peng Yang, Tony Q. S. Quek, Jingxuan Chen, Chaoqun You, and Xianbin\n  Cao", "title": "Feeling of Presence Maximization: mmWave-Enabled Virtual Reality Meets\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the problem of providing ultra-reliable and\nenergy-efficient virtual reality (VR) experiences for wireless mobile users. To\nensure reliable ultra-high-definition (UHD) video frame delivery to mobile\nusers and enhance their immersive visual experiences, a coordinated multipoint\n(CoMP) transmission technique and millimeter wave (mmWave) communications are\nexploited. Owing to user movement and time-varying wireless channels, the\nwireless VR experience enhancement problem is formulated as a\nsequence-dependent and mixed-integer problem with a goal of maximizing users'\nfeeling of presence (FoP) in the virtual world, subject to power consumption\nconstraints on access points (APs) and users' head-mounted displays (HMDs). The\nproblem, however, is hard to be directly solved due to the lack of users'\naccurate tracking information and the sequence-dependent and mixed-integer\ncharacteristics. To overcome this challenge, we develop a parallel echo state\nnetwork (ESN) learning method to predict users' tracking information by\ntraining fresh and historical tracking samples separately collected by APs.\nWith the learnt results, we propose a deep reinforcement learning (DRL) based\noptimization algorithm to solve the formulated problem. In this algorithm, we\nimplement deep neural networks (DNNs) as a scalable solution to produce integer\ndecision variables and solving a continuous power control problem to criticize\nthe integer decision variables. Finally, the performance of the proposed\nalgorithm is compared with various benchmark algorithms, and the impact of\ndifferent design parameters is also discussed. Simulation results demonstrate\nthat the proposed algorithm is more 4.14% energy-efficient than the benchmark\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:35:10 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 13:19:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yang", "Peng", ""], ["Quek", "Tony Q. S.", ""], ["Chen", "Jingxuan", ""], ["You", "Chaoqun", ""], ["Cao", "Xianbin", ""]]}, {"id": "2107.01002", "submitter": "Ilia Karmanov", "authors": "Ilia Karmanov, Farhad G. Zanjani, Simone Merlin, Ishaque Kadampot,\n  Daniel Dijkman", "title": "WiCluster: Passive Indoor 2D/3D Positioning using WiFi without Precise\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CV cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce WiCluster, a new machine learning (ML) approach for passive\nindoor positioning using radio frequency (RF) channel state information (CSI).\nWiCluster can predict both a zone-level position and a precise 2D or 3D\nposition, without using any precise position labels during training. Prior\nCSI-based indoor positioning work has relied on non-parametric approaches using\ndigital signal-processing (DSP) and, more recently, parametric approaches\n(e.g., fully supervised ML methods). However these do not handle the complexity\nof real-world environments well and do not meet requirements for large-scale\ncommercial deployments: the accuracy of DSP-based method deteriorates\nsignificantly in non-line-of-sight conditions, while supervised ML methods need\nlarge amounts of hard-to-acquire centimeter accuracy position labels. In\ncontrast, WiCluster is both precise and requires weaker label-information that\ncan be easily collected. Our first contribution is a novel dimensionality\nreduction method for charting. It combines a triplet-loss with a multi-scale\nclustering-loss to map the high-dimensional CSI representation to a 2D/3D\nlatent space. Our second contribution is two weakly supervised losses that map\nthis latent space into a Cartesian map, resulting in meter-accuracy position\nresults. These losses only require simple to acquire priors: a sketch of the\nfloorplan, approximate location of access-point locations and a few CSI packets\nthat are labeled with the corresponding zone in the floorplan. Thirdly, we\nreport results and a robustness study for 2D positioning in a single-floor\noffice building and 3D positioning in a two-floor home to show the robustness\nof our method.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 12:09:46 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Karmanov", "Ilia", ""], ["Zanjani", "Farhad G.", ""], ["Merlin", "Simone", ""], ["Kadampot", "Ishaque", ""], ["Dijkman", "Daniel", ""]]}, {"id": "2107.01017", "submitter": "Angelo Menezes", "authors": "Angelo Garangau Menezes and Saulo Martiello Mastelini", "title": "MegazordNet: combining statistical and machine learning standpoints for\n  time series forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forecasting financial time series is considered to be a difficult task due to\nthe chaotic feature of the series. Statistical approaches have shown solid\nresults in some specific problems such as predicting market direction and\nsingle-price of stocks; however, with the recent advances in deep learning and\nbig data techniques, new promising options have arises to tackle financial time\nseries forecasting. Moreover, recent literature has shown that employing a\ncombination of statistics and machine learning may improve accuracy in the\nforecasts in comparison to single solutions. Taking into consideration the\nmentioned aspects, in this work, we proposed the MegazordNet, a framework that\nexplores statistical features within a financial series combined with a\nstructured deep learning model for time series forecasting. We evaluated our\napproach predicting the closing price of stocks in the S&P 500 using different\nmetrics, and we were able to beat single statistical and machine learning\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 15:06:54 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Menezes", "Angelo Garangau", ""], ["Mastelini", "Saulo Martiello", ""]]}, {"id": "2107.01025", "submitter": "Anirudha Jitani", "authors": "Anirudha Jitani, Aditya Mahajan, Zhongwen Zhu, Hatem Abou-zeid,\n  Emmanuel T. Fapi, and Hakimeh Purmehdi", "title": "Structure-aware reinforcement learning for node-overload protection in\n  mobile edge computing", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile Edge Computing (MEC) refers to the concept of placing computational\ncapability and applications at the edge of the network, providing benefits such\nas reduced latency in handling client requests, reduced network congestion, and\nimproved performance of applications. The performance and reliability of MEC\nare degraded significantly when one or several edge servers in the cluster are\noverloaded. Especially when a server crashes due to the overload, it causes\nservice failures in MEC. In this work, an adaptive admission control policy to\nprevent edge node from getting overloaded is presented. This approach is based\non a recently-proposed low complexity RL (Reinforcement Learning) algorithm\ncalled SALMUT (Structure-Aware Learning for Multiple Thresholds), which\nexploits the structure of the optimal admission control policy in multi-class\nqueues for an average-cost setting. We extend the framework to work for node\noverload-protection problem in a discounted-cost setting. The proposed solution\nis validated using several scenarios mimicking real-world deployments in two\ndifferent settings - computer simulations and a docker testbed. Our empirical\nevaluations show that the total discounted cost incurred by SALMUT is similar\nto state-of-the-art deep RL algorithms such as PPO (Proximal Policy\nOptimization) and A2C (Advantage Actor Critic) but requires an order of\nmagnitude less time to train, outputs easily interpretable policy, and can be\ndeployed in an online manner.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:11:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Jitani", "Anirudha", ""], ["Mahajan", "Aditya", ""], ["Zhu", "Zhongwen", ""], ["Abou-zeid", "Hatem", ""], ["Fapi", "Emmanuel T.", ""], ["Purmehdi", "Hakimeh", ""]]}, {"id": "2107.01032", "submitter": "Ziaur Rahman", "authors": "SK. A. Shezan, S. Rawdah, Shafin Ali, Ziaur Rahman", "title": "Design and implementation of an islanded hybrid microgrid system for a\n  large resort center for Penang Island with the proper application of excess\n  energy", "comments": "15 Pages, 14 Figures, 6 Tables", "journal-ref": "Environ Prog Sustainable Energy. 2021;e13584", "doi": "10.1002/ep.13584", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The energy demand is growing daily at an accelerated pace due to the\ninternationalization and development of civilization. Yet proper economic\nutilization of additional energy generated by the Islanded Hybrid Microgrid\nSystem (IHMS) that was not consumed by the load is a major global challenge. To\nresolve the above-stated summons, this research focuses on a multi-optimal\ncombination of IHMS for the Penang Hill Resort located on Penang Island,\nMalaysia, with effective use of redundant energy. To avail this excess energy\nefficiently, an electrical heater along with a storage tank has been designed\nconcerning diversion load having proper energy management. Furthermore, the\nsystem design has adopted the HOMER Pro software for profitable and practical\nanalysis. Alongside, MATLAB Simulink had stabilized the whole system by\nrepresenting the values of 2068 and 19,072 kW that have been determined as the\napproximated peak and average load per day for the resort. Moreover, the\noptimized IHMS is comprehended of Photovoltaic (PV) cells, Diesel Generator,\nWind Turbine, Battery, and Converter. Adjacent to this, the optimized system\nensued in having a Net Present Cost (NPC) of $21.66 million, Renewable Fraction\n(RF) of 27.8%, Cost of Energy (COE) of $0.165/kWh, CO2 of 1,735,836 kg/year,\nand excess energy of 517.29MWh per annum. Since the diesel generator lead\nsystem was included in the scheme, a COE of $0.217/kWh, CO2 of 5,124,879\nkg/year, and NPC of $23.25 million were attained. The amount of excess energy\nis effectively utilized with an electrical heater as a diversion load.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:18:53 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Shezan", "SK. A.", ""], ["Rawdah", "S.", ""], ["Ali", "Shafin", ""], ["Rahman", "Ziaur", ""]]}, {"id": "2107.01034", "submitter": "Jonathan Dumas", "authors": "Jonathan Dumas", "title": "Weather-based forecasting of energy generation, consumption and price\n  for electrical microgrids management", "comments": "PhD thesis. It is a first draft version. This manuscript must be\n  evaluated by the supervisor to be decided if it is suitable to be defended\n  before a jury", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Intergovernmental Panel on Climate Change proposes different mitigation\nstrategies to achieve the net emissions reductions that would be required to\nfollow a pathway that limits global warming to 1.5{\\deg}C with no or limited\novershoot. The transition towards a carbon-free society goes through an\ninevitable increase of the share of renewable generation in the energy mix and\na drastic decrease in terms of the total consumption of fossil fuels.\nTherefore, this thesis studies the integration of renewables in power systems\nby investigating forecasting and decision-making tools. Indeed, in contrast to\nconventional power plants, renewable energy is subject to uncertainty. Most of\nthe generation technologies based on renewable sources are non-dispatchable,\nand their production is stochastic and hard to predict in advance. A high share\nof renewables is a great challenge for power systems that have been designed\nand sized for dispatchable units. In this context, probabilistic forecasts,\nwhich aim at modeling the distribution of all possible future realizations,\nhave become an important tool to equip decision-makers, hopefully leading to\nbetter decisions in energy applications. This thesis focus on two main research\nquestions: (1) How to produce reliable probabilistic forecasts of renewable\ngeneration, consumption, and electricity prices? (2) How to make decisions with\nuncertainty using probabilistic forecasts? The thesis perimeter is the energy\nmanagement of \"small\" systems such as microgrids at a residential scale on a\nday-ahead basis. It is divided into two main parts to propose directions to\naddress both research questions (1) a forecasting part; (2) a planning and\ncontrol part.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:02:36 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Dumas", "Jonathan", ""]]}, {"id": "2107.01057", "submitter": "Frederik Tr\\\"auble", "authors": "Frederik Tr\\\"auble, Julius von K\\\"ugelgen, Matth\\\"aus Kleindessner,\n  Francesco Locatello, Bernhard Sch\\\"olkopf, Peter Gehler", "title": "Backward-Compatible Prediction Updates: A Probabilistic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When machine learning systems meet real world applications, accuracy is only\none of several requirements. In this paper, we assay a complementary\nperspective originating from the increasing availability of pre-trained and\nregularly improving state-of-the-art models. While new improved models develop\nat a fast pace, downstream tasks vary more slowly or stay constant. Assume that\nwe have a large unlabelled data set for which we want to maintain accurate\npredictions. Whenever a new and presumably better ML models becomes available,\nwe encounter two problems: (i) given a limited budget, which data points should\nbe re-evaluated using the new model?; and (ii) if the new predictions differ\nfrom the current ones, should we update? Problem (i) is about compute cost,\nwhich matters for very large data sets and models. Problem (ii) is about\nmaintaining consistency of the predictions, which can be highly relevant for\ndownstream applications; our demand is to avoid negative flips, i.e., changing\ncorrect to incorrect predictions. In this paper, we formalize the Prediction\nUpdate Problem and present an efficient probabilistic approach as answer to the\nabove questions. In extensive experiments on standard classification benchmark\ndata sets, we show that our method outperforms alternative strategies along key\nmetrics for backward-compatible prediction updates.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:05:31 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Tr\u00e4uble", "Frederik", ""], ["von K\u00fcgelgen", "Julius", ""], ["Kleindessner", "Matth\u00e4us", ""], ["Locatello", "Francesco", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gehler", "Peter", ""]]}, {"id": "2107.01076", "submitter": "Marya Bazzi", "authors": "Adam Tsakalidis, Pierpaolo Basile, Marya Bazzi, Mihai Cucuringu and\n  Barbara McGillivray", "title": "DUKweb: Diachronic word representations from the UK Web Archive corpus", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical semantic change (detecting shifts in the meaning and usage of words)\nis an important task for social and cultural studies as well as for Natural\nLanguage Processing applications. Diachronic word embeddings (time-sensitive\nvector representations of words that preserve their meaning) have become the\nstandard resource for this task. However, given the significant computational\nresources needed for their generation, very few resources exist that make\ndiachronic word embeddings available to the scientific community.\n  In this paper we present DUKweb, a set of large-scale resources designed for\nthe diachronic analysis of contemporary English. DUKweb was created from the\nJISC UK Web Domain Dataset (1996-2013), a very large archive which collects\nresources from the Internet Archive that were hosted on domains ending in\n`.uk'. DUKweb consists of a series word co-occurrence matrices and two types of\nword embeddings for each year in the JISC UK Web Domain dataset. We show the\nreuse potential of DUKweb and its quality standards via a case study on word\nmeaning change detection.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:32:33 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Tsakalidis", "Adam", ""], ["Basile", "Pierpaolo", ""], ["Bazzi", "Marya", ""], ["Cucuringu", "Mihai", ""], ["McGillivray", "Barbara", ""]]}, {"id": "2107.01079", "submitter": "Chen Chen", "authors": "Chen Chen, Kerstin Hammernik, Cheng Ouyang, Chen Qin, Wenjia Bai,\n  Daniel Rueckert", "title": "Cooperative Training and Latent Space Data Augmentation for Robust\n  Medical Image Segmentation", "comments": "MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning-based segmentation methods are vulnerable to unforeseen data\ndistribution shifts during deployment, e.g. change of image appearances or\ncontrasts caused by different scanners, unexpected imaging artifacts etc. In\nthis paper, we present a cooperative framework for training image segmentation\nmodels and a latent space augmentation method for generating hard examples.\nBoth contributions improve model generalization and robustness with limited\ndata. The cooperative training framework consists of a fast-thinking network\n(FTN) and a slow-thinking network (STN). The FTN learns decoupled image\nfeatures and shape features for image reconstruction and segmentation tasks.\nThe STN learns shape priors for segmentation correction and refinement. The two\nnetworks are trained in a cooperative manner. The latent space augmentation\ngenerates challenging examples for training by masking the decoupled latent\nspace in both channel-wise and spatial-wise manners. We performed extensive\nexperiments on public cardiac imaging datasets. Using only 10 subjects from a\nsingle site for training, we demonstrated improved cross-site segmentation\nperformance and increased robustness against various unforeseen imaging\nartifacts compared to strong baseline methods. Particularly, cooperative\ntraining with latent space data augmentation yields 15% improvement in terms of\naverage Dice score when compared to a standard training method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:39:13 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Chen", ""], ["Hammernik", "Kerstin", ""], ["Ouyang", "Cheng", ""], ["Qin", "Chen", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""]]}, {"id": "2107.01081", "submitter": "Alberto Badias", "authors": "Alberto Badias and Ashis Banerjee", "title": "Neural Network Layer Algebra: A Framework to Measure Capacity and\n  Compression in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a new framework to measure the intrinsic properties of (deep)\nneural networks. While we focus on convolutional networks, our framework can be\nextrapolated to any network architecture. In particular, we evaluate two\nnetwork properties, namely, capacity (related to expressivity) and compression,\nboth of which depend only on the network structure and are independent of the\ntraining and test data. To this end, we propose two metrics: the first one,\ncalled layer complexity, captures the architectural complexity of any network\nlayer; and, the second one, called layer intrinsic power, encodes how data is\ncompressed along the network. The metrics are based on the concept of layer\nalgebra, which is also introduced in this paper. This concept is based on the\nidea that the global properties depend on the network topology, and the leaf\nnodes of any neural network can be approximated using local transfer functions,\nthereby, allowing a simple computation of the global metrics. We also compare\nthe properties of the state-of-the art architectures using our metrics and use\nthe properties to analyze the classification accuracy on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:43:53 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Badias", "Alberto", ""], ["Banerjee", "Ashis", ""]]}, {"id": "2107.01091", "submitter": "Nikiita Pavlichenko", "authors": "Nikita Pavlichenko, Ivan Stelmakh, Dmitry Ustalov", "title": "Vox Populi, Vox DIY: Benchmark Dataset for Crowdsourced Audio\n  Transcription", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.HC cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain-specific data is the crux of the successful transfer of machine\nlearning systems from benchmarks to real life. Crowdsourcing has become one of\nthe standard tools for cheap and time-efficient data collection for simple\nproblems such as image classification: thanks in large part to advances in\nresearch on aggregation methods. However, the applicability of crowdsourcing to\nmore complex tasks (e.g., speech recognition) remains limited due to the lack\nof principled aggregation methods for these modalities. The main obstacle\ntowards designing advanced aggregation methods is the absence of training data,\nand in this work, we focus on bridging this gap in speech recognition. For\nthis, we collect and release CrowdSpeech -- the first publicly available\nlarge-scale dataset of crowdsourced audio transcriptions. Evaluation of\nexisting aggregation methods on our data shows room for improvement, suggesting\nthat our work may entail the design of better algorithms. At a higher level, we\nalso contribute to the more general challenge of collecting high-quality\ndatasets using crowdsourcing: we develop a principled pipeline for constructing\ndatasets of crowdsourced audio transcriptions in any novel domain. We show its\napplicability on an under-resourced language by constructing VoxDIY -- a\ncounterpart of CrowdSpeech for the Russian language. We also release the code\nthat allows a full replication of our data collection pipeline and share\nvarious insights on best practices of data collection via crowdsourcing.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 14:05:28 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Pavlichenko", "Nikita", ""], ["Stelmakh", "Ivan", ""], ["Ustalov", "Dmitry", ""]]}, {"id": "2107.01103", "submitter": "Subhabrata Majumdar", "authors": "Subhabrata Majumdar, Snigdhansu Chatterjee", "title": "Generalized Multivariate Signs for Nonparametric Hypothesis Testing in\n  High Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data, where the dimension of the feature space is much\nlarger than sample size, arise in a number of statistical applications. In this\ncontext, we construct the generalized multivariate sign transformation, defined\nas a vector divided by its norm. For different choices of the norm function,\nthe resulting transformed vector adapts to certain geometrical features of the\ndata distribution. Building up on this idea, we obtain one-sample and\ntwo-sample testing procedures for mean vectors of high-dimensional data using\nthese generalized sign vectors. These tests are based on U-statistics using\nkernel inner products, do not require prohibitive assumptions, and are amenable\nto a fast randomization-based implementation. Through experiments in a number\nof data settings, we show that tests using generalized signs display higher\npower than existing tests, while maintaining nominal type-I error rates.\nFinally, we provide example applications on the MNIST and Minnesota Twin\nStudies genomic data.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 14:31:44 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Majumdar", "Subhabrata", ""], ["Chatterjee", "Snigdhansu", ""]]}, {"id": "2107.01105", "submitter": "John Bronskill", "authors": "John Bronskill, Daniela Massiceti, Massimiliano Patacchiola, Katja\n  Hofmann, Sebastian Nowozin, Richard E. Turner", "title": "Memory Efficient Meta-Learning with Large Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning approaches to few-shot classification are computationally\nefficient at test time requiring just a few optimization steps or single\nforward pass to learn a new task, but they remain highly memory-intensive to\ntrain. This limitation arises because a task's entire support set, which can\ncontain up to 1000 images, must be processed before an optimization step can be\ntaken. Harnessing the performance gains offered by large images thus requires\neither parallelizing the meta-learner across multiple GPUs, which may not be\navailable, or trade-offs between task and image size when memory constraints\napply. We improve on both options by proposing LITE, a general and memory\nefficient episodic training scheme that enables meta-training on large tasks\ncomposed of large images on a single GPU. We achieve this by observing that the\ngradients for a task can be decomposed into a sum of gradients over the task's\ntraining images. This enables us to perform a forward pass on a task's entire\ntraining set but realize significant memory savings by back-propagating only a\nrandom subset of these images which we show is an unbiased approximation of the\nfull gradient. We use LITE to train meta-learners and demonstrate new\nstate-of-the-art accuracy on the real-world ORBIT benchmark and 3 of the 4\nparts of the challenging VTAB+MD benchmark relative to leading meta-learners.\nLITE also enables meta-learners to be competitive with transfer learning\napproaches but at a fraction of the test-time computational cost, thus serving\nas a counterpoint to the recent narrative that transfer learning is all you\nneed for few-shot classification.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 14:37:13 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Bronskill", "John", ""], ["Massiceti", "Daniela", ""], ["Patacchiola", "Massimiliano", ""], ["Hofmann", "Katja", ""], ["Nowozin", "Sebastian", ""], ["Turner", "Richard E.", ""]]}, {"id": "2107.01106", "submitter": "Yifan Sun", "authors": "Yifan Sun and Francis Bach", "title": "Screening for a Reweighted Penalized Conditional Gradient Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional gradient method (CGM) is widely used in large-scale sparse\nconvex optimization, having a low per iteration computational cost for\nstructured sparse regularizers and a greedy approach to collecting nonzeros. We\nexplore the sparsity acquiring properties of a general penalized CGM (P-CGM)\nfor convex regularizers and a reweighted penalized CGM (RP-CGM) for nonconvex\nregularizers, replacing the usual convex constraints with gauge-inspired\npenalties. This generalization does not increase the per-iteration complexity\nnoticeably. Without assuming bounded iterates or using line search, we show\n$O(1/t)$ convergence of the gap of each subproblem, which measures distance to\na stationary point. We couple this with a screening rule which is safe in the\nconvex case, converging to the true support at a rate $O(1/(\\delta^2))$ where\n$\\delta \\geq 0$ measures how close the problem is to degeneracy. In the\nnonconvex case the screening rule converges to the true support in a finite\nnumber of iterations, but is not necessarily safe in the intermediate iterates.\nIn our experiments, we verify the consistency of the method and adjust the\naggressiveness of the screening rule by tuning the concavity of the\nregularizer.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 14:37:37 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Sun", "Yifan", ""], ["Bach", "Francis", ""]]}, {"id": "2107.01126", "submitter": "Laila Melkas", "authors": "Laila Melkas, Rafael Savvides, Suyog Chandramouli, Jarmo M\\\"akel\\\"a,\n  Tuomo Nieminen, Ivan Mammarella and Kai Puolam\\\"aki", "title": "Interactive Causal Structure Discovery in Earth System Sciences", "comments": "23 pages, 8 figures, to be published in Proceedings of the 2021 KDD\n  Workshop on Causal Discovery", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal structure discovery (CSD) models are making inroads into several\ndomains, including Earth system sciences. Their widespread adaptation is\nhowever hampered by the fact that the resulting models often do not take into\naccount the domain knowledge of the experts and that it is often necessary to\nmodify the resulting models iteratively. We present a workflow that is required\nto take this knowledge into account and to apply CSD algorithms in Earth system\nsciences. At the same time, we describe open research questions that still need\nto be addressed. We present a way to interactively modify the outputs of the\nCSD algorithms and argue that the user interaction can be modelled as a greedy\nfinding of the local maximum-a-posteriori solution of the likelihood function,\nwhich is composed of the likelihood of the causal model and the prior\ndistribution representing the knowledge of the expert user. We use a real-world\ndata set for examples constructed in collaboration with our co-authors, who are\nthe domain area experts. We show that finding maximally usable causal models in\nthe Earth system sciences or other similar domains is a difficult task which\ncontains many interesting open research questions. We argue that taking the\ndomain knowledge into account has a substantial effect on the final causal\nmodels discovered.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 09:23:08 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Melkas", "Laila", ""], ["Savvides", "Rafael", ""], ["Chandramouli", "Suyog", ""], ["M\u00e4kel\u00e4", "Jarmo", ""], ["Nieminen", "Tuomo", ""], ["Mammarella", "Ivan", ""], ["Puolam\u00e4ki", "Kai", ""]]}, {"id": "2107.01130", "submitter": "Davood Zabihzadeh", "authors": "Davood Zabihzadeh", "title": "Ensemble of Loss Functions to Improve Generalizability of Deep Metric\n  Learning methods", "comments": "27 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Metric Learning (DML) learns a non-linear semantic embedding from input\ndata that brings similar pairs together while keeps dissimilar data away from\neach other. To this end, many different methods are proposed in the last decade\nwith promising results in various applications. The success of a DML algorithm\ngreatly depends on its loss function. However, no loss function is perfect, and\nit deals only with some aspects of an optimal similarity embedding. Besides,\nthe generalizability of the DML on unseen categories during the test stage is\nan important matter that is not considered by existing loss functions. To\naddress these challenges, we propose novel approaches to combine different\nlosses built on top of a shared deep feature extractor. The proposed ensemble\nof losses enforces the deep model to extract features that are consistent with\nall losses. Since the selected losses are diverse and each emphasizes different\naspects of an optimal semantic embedding, our effective combining methods yield\na considerable improvement over any individual loss and generalize well on\nunseen categories. Here, there is no limitation in choosing loss functions, and\nour methods can work with any set of existing ones. Besides, they can optimize\neach loss function as well as its weight in an end-to-end paradigm with no need\nto adjust any hyper-parameter. We evaluate our methods on some popular datasets\nfrom the machine vision domain in conventional Zero-Shot-Learning (ZSL)\nsettings. The results are very encouraging and show that our methods outperform\nall baseline losses by a large margin in all datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:19:46 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zabihzadeh", "Davood", ""]]}, {"id": "2107.01131", "submitter": "Junya Chen", "authors": "Qing Guo, Junya Chen, Dong Wang, Yuewei Yang, Xinwei Deng, Lawrence\n  Carin, Fan Li, Chenyang Tao", "title": "Tight Mutual Information Estimation With Contrastive Fenchel-Legendre\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Successful applications of InfoNCE and its variants have popularized the use\nof contrastive variational mutual information (MI) estimators in machine\nlearning. While featuring superior stability, these estimators crucially depend\non costly large-batch training, and they sacrifice bound tightness for variance\nreduction. To overcome these limitations, we revisit the mathematics of popular\nvariational MI bounds from the lens of unnormalized statistical modeling and\nconvex optimization. Our investigation not only yields a new unified\ntheoretical framework encompassing popular variational MI bounds but also leads\nto a novel, simple, and powerful contrastive MI estimator named as FLO.\nTheoretically, we show that the FLO estimator is tight, and it provably\nconverges under stochastic gradient descent. Empirically, our FLO estimator\novercomes the limitations of its predecessors and learns more efficiently. The\nutility of FLO is verified using an extensive set of benchmarks, which also\nreveals the trade-offs in practical MI estimation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:20:41 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Guo", "Qing", ""], ["Chen", "Junya", ""], ["Wang", "Dong", ""], ["Yang", "Yuewei", ""], ["Deng", "Xinwei", ""], ["Carin", "Lawrence", ""], ["Li", "Fan", ""], ["Tao", "Chenyang", ""]]}, {"id": "2107.01152", "submitter": "Junya Chen", "authors": "Junya Chen, Zhe Gan, Xuan Li, Qing Guo, Liqun Chen, Shuyang Gao,\n  Tagyoung Chung, Yi Xu, Belinda Zeng, Wenlian Lu, Fan Li, Lawrence Carin,\n  Chenyang Tao", "title": "Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive\n  Learners With FlatNCE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  InfoNCE-based contrastive representation learners, such as SimCLR, have been\ntremendously successful in recent years. However, these contrastive schemes are\nnotoriously resource demanding, as their effectiveness breaks down with\nsmall-batch training (i.e., the log-K curse, whereas K is the batch-size). In\nthis work, we reveal mathematically why contrastive learners fail in the\nsmall-batch-size regime, and present a novel simple, non-trivial contrastive\nobjective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no\nlonger explicitly appeals to a discriminative classification goal for\ncontrastive learning. Theoretically, we show FlatNCE is the mathematical dual\nformulation of InfoNCE, thus bridging the classical literature on energy\nmodeling; and empirically, we demonstrate that, with minimal modification of\ncode, FlatNCE enables immediate performance boost independent of the\nsubject-matter engineering efforts. The significance of this work is furthered\nby the powerful generalization of contrastive learning techniques, and the\nintroduction of new tools to monitor and diagnose contrastive training. We\nsubstantiate our claims with empirical evidence on CIFAR10, ImageNet, and other\ndatasets, where FlatNCE consistently outperforms InfoNCE.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:50:43 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Chen", "Junya", ""], ["Gan", "Zhe", ""], ["Li", "Xuan", ""], ["Guo", "Qing", ""], ["Chen", "Liqun", ""], ["Gao", "Shuyang", ""], ["Chung", "Tagyoung", ""], ["Xu", "Yi", ""], ["Zeng", "Belinda", ""], ["Lu", "Wenlian", ""], ["Li", "Fan", ""], ["Carin", "Lawrence", ""], ["Tao", "Chenyang", ""]]}, {"id": "2107.01154", "submitter": "Wenqi Wei", "authors": "Wenqi Wei, Ling Liu, Yanzhao Wu, Gong Su, Arun Iyengar", "title": "Gradient-Leakage Resilient Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning(FL) is an emerging distributed learning paradigm with\ndefault client privacy because clients can keep sensitive data on their devices\nand only share local training parameter updates with the federated server.\nHowever, recent studies reveal that gradient leakages in FL may compromise the\nprivacy of client training data. This paper presents a gradient leakage\nresilient approach to privacy-preserving federated learning with per training\nexample-based client differential privacy, coined as Fed-CDP. It makes three\noriginal contributions. First, we identify three types of client gradient\nleakage threats in federated learning even with encrypted client-server\ncommunications. We articulate when and why the conventional server coordinated\ndifferential privacy approach, coined as Fed-SDP, is insufficient to protect\nthe privacy of the training data. Second, we introduce Fed-CDP, the per\nexample-based client differential privacy algorithm, and provide a formal\nanalysis of Fed-CDP with the $(\\epsilon, \\delta)$ differential privacy\nguarantee, and a formal comparison between Fed-CDP and Fed-SDP in terms of\nprivacy accounting. Third, we formally analyze the privacy-utility trade-off\nfor providing differential privacy guarantee by Fed-CDP and present a dynamic\ndecay noise-injection policy to further improve the accuracy and resiliency of\nFed-CDP. We evaluate and compare Fed-CDP and Fed-CDP(decay) with Fed-SDP in\nterms of differential privacy guarantee and gradient leakage resilience over\nfive benchmark datasets. The results show that the Fed-CDP approach outperforms\nconventional Fed-SDP in terms of resilience to client gradient leakages while\noffering competitive accuracy performance in federated learning.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:51:07 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""], ["Wu", "Yanzhao", ""], ["Su", "Gong", ""], ["Iyengar", "Arun", ""]]}, {"id": "2107.01163", "submitter": "Enrico Maria Malatesta", "authors": "Carlo Baldassi, Clarissa Lauditi, Enrico M. Malatesta, Gabriele\n  Perugini, Riccardo Zecchina", "title": "Unveiling the structure of wide flat minima in neural networks", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG math-ph math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning has revealed the application potential of neural\nnetworks across the sciences and opened up fundamental theoretical problems. In\nparticular, the fact that learning algorithms based on simple variants of\ngradient methods are able to find near-optimal minima of highly nonconvex loss\nfunctions is an unexpected feature of neural networks which needs to be\nunderstood in depth. Such algorithms are able to fit the data almost perfectly,\neven in the presence of noise, and yet they have excellent predictive\ncapabilities. Several empirical results have shown a reproducible correlation\nbetween the so-called flatness of the minima achieved by the algorithms and the\ngeneralization performance. At the same time, statistical physics results have\nshown that in nonconvex networks a multitude of narrow minima may coexist with\na much smaller number of wide flat minima, which generalize well. Here we show\nthat wide flat minima arise from the coalescence of minima that correspond to\nhigh-margin classifications. Despite being exponentially rare compared to\nzero-margin solutions, high-margin minima tend to concentrate in particular\nregions. These minima are in turn surrounded by other solutions of smaller and\nsmaller margin, leading to dense regions of solutions over long distances. Our\nanalysis also provides an alternative analytical method for estimating when\nflat minima appear and when algorithms begin to find solutions, as the number\nof model parameters varies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:04:57 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Baldassi", "Carlo", ""], ["Lauditi", "Clarissa", ""], ["Malatesta", "Enrico M.", ""], ["Perugini", "Gabriele", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "2107.01173", "submitter": "Guanghui Wang", "authors": "Guanghui Wang, Ming Yang, Lijun Zhang, Tianbao Yang", "title": "Momentum Accelerates the Convergence of Stochastic AUPRC Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study stochastic optimization of areas under\nprecision-recall curves (AUPRC), which is widely used for combating imbalanced\nclassification tasks. Although a few methods have been proposed for maximizing\nAUPRC, stochastic optimization of AUPRC with convergence guarantee remains an\nundeveloped territory. A recent work [42] has proposed a promising approach\ntowards AUPRC based on maximizing a surrogate loss for the average precision,\nand proved an $O(1/\\epsilon^5)$ complexity for finding an $\\epsilon$-stationary\nsolution of the non-convex objective. In this paper, we further improve the\nstochastic optimization of AURPC by (i) developing novel stochastic momentum\nmethods with a better iteration complexity of $O(1/\\epsilon^4)$ for finding an\n$\\epsilon$-stationary solution; and (ii) designing a novel family of stochastic\nadaptive methods with the same iteration complexity of $O(1/\\epsilon^4)$, which\nenjoy faster convergence in practice. To this end, we propose two innovative\ntechniques that are critical for improving the convergence: (i) the biased\nestimators for tracking individual ranking scores are updated in a randomized\ncoordinate-wise manner; and (ii) a momentum update is used on top of the\nstochastic gradient estimator for tracking the gradient of the objective.\nExtensive experiments on various data sets demonstrate the effectiveness of the\nproposed algorithms. Of independent interest, the proposed stochastic momentum\nand adaptive algorithms are also applicable to a class of two-level stochastic\ndependent compositional optimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:21:52 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wang", "Guanghui", ""], ["Yang", "Ming", ""], ["Zhang", "Lijun", ""], ["Yang", "Tianbao", ""]]}, {"id": "2107.01184", "submitter": "Tyler Cody", "authors": "Tyler Cody, Stephen Adams, Peter A. Beling", "title": "Empirically Measuring Transfer Distance for System Design and Operation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical machine learning approaches are sensitive to non-stationarity.\nTransfer learning can address non-stationarity by sharing knowledge from one\nsystem to another, however, in areas like machine prognostics and defense, data\nis fundamentally limited. Therefore, transfer learning algorithms have little,\nif any, examples from which to learn. Herein, we suggest that these constraints\non algorithmic learning can be addressed by systems engineering. We formally\ndefine transfer distance in general terms and demonstrate its use in\nempirically quantifying the transferability of models. We consider the use of\ntransfer distance in the design of machine rebuild procedures to allow for\ntransferable prognostic models. We also consider the use of transfer distance\nin predicting operational performance in computer vision. Practitioners can use\nthe presented methodology to design and operate systems with consideration for\nthe learning theoretic challenges faced by component learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:45:58 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Cody", "Tyler", ""], ["Adams", "Stephen", ""], ["Beling", "Peter A.", ""]]}, {"id": "2107.01185", "submitter": "Prajoy Podder", "authors": "Prajoy Podder, Subrato Bharati, M. Rubaiyat Hossain Mondal, Pinto\n  Kumar Paul, Utku Kose", "title": "Artificial Neural Network for Cybersecurity: A Comprehensive Review", "comments": "14 Pages, 8 Figures", "journal-ref": "Journal of Information Assurance and Security, Volume: 16, Issue:\n  1, 2021, pp.010-023", "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybersecurity is a very emerging field that protects systems, networks, and\ndata from digital attacks. With the increase in the scale of the Internet and\nthe evolution of cyber attacks, developing novel cybersecurity tools has become\nimportant, particularly for Internet of things (IoT) networks. This paper\nprovides a systematic review of the application of deep learning (DL)\napproaches for cybersecurity. This paper provides a short description of DL\nmethods which is used in cybersecurity, including deep belief networks,\ngenerative adversarial networks, recurrent neural networks, and others. Next,\nwe illustrate the differences between shallow learning and DL. Moreover, a\ndiscussion is provided on the currently prevailing cyber-attacks in IoT and\nother networks, and the effectiveness of DL methods to manage these attacks.\nBesides, this paper describes studies that highlight the DL technique,\ncybersecurity applications, and the source of datasets. Next, a discussion is\nprovided on the feasibility of DL systems for malware detection and\nclassification, intrusion detection, and other frequent cyber-attacks,\nincluding identifying file type, spam, and network traffic. Our review\nindicates that high classification accuracy of 99.72% is obtained by restricted\nBoltzmann machine (RBM) when applied to a custom dataset, while long short-term\nmemory (LSTM) achieves an accuracy of 99.80% for KDD Cup 99 dataset. Finally,\nthis article discusses the importance of cybersecurity for reliable and\npracticable IoT-driven healthcare systems.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 09:32:48 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Podder", "Prajoy", ""], ["Bharati", "Subrato", ""], ["Mondal", "M. Rubaiyat Hossain", ""], ["Paul", "Pinto Kumar", ""], ["Kose", "Utku", ""]]}, {"id": "2107.01188", "submitter": "Martin Schuetz", "authors": "Martin J. A. Schuetz, J. Kyle Brubaker, Helmut G. Katzgraber", "title": "Combinatorial Optimization with Physics-Inspired Graph Neural Networks", "comments": "Manuscript: 13 pages, 5 figures, 1 table. Supplemental Material: 1\n  page, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.AI math.OC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how graph neural networks can be used to solve combinatorial\noptimization problems. Our approach is broadly applicable to canonical NP-hard\nproblems in the form of quadratic unconstrained binary optimization problems,\nsuch as maximum cut, minimum vertex cover, maximum independent set, as well as\nIsing spin glasses and higher-order generalizations thereof in the form of\npolynomial unconstrained binary optimization problems. We apply a relaxation\nstrategy to the problem Hamiltonian to generate a differentiable loss function\nwith which we train the graph neural network and apply a simple projection to\ninteger variables once the unsupervised training process has completed. We\nshowcase our approach with numerical results for the canonical maximum cut and\nmaximum independent set problems. We find that the graph neural network\noptimizer performs on par or outperforms existing solvers, with the ability to\nscale beyond the state of the art to problems with millions of variables.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:54:35 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Schuetz", "Martin J. A.", ""], ["Brubaker", "J. Kyle", ""], ["Katzgraber", "Helmut G.", ""]]}, {"id": "2107.01189", "submitter": "Jerrick Liu", "authors": "Jerrick Liu, Nathan Inkawhich, Oliver Nina, Radu Timofte, Sahil Jain,\n  Bob Lee, Yuru Duan, Wei Wei, Lei Zhang, Songzheng Xu, Yuxuan Sun, Jiaqi Tang,\n  Xueli Geng, Mengru Ma, Gongzhe Li, Xueli Geng, Huanqia Cai, Chengxue Cai, Sol\n  Cummings, Casian Miron, Alexandru Pasarica, Cheng-Yen Yang, Hung-Min Hsu,\n  Jiarui Cai, Jie Mei, Chia-Ying Yeh, Jenq-Neng Hwang, Michael Xin, Zhongkai\n  Shangguan, Zihe Zheng, Xu Yifei, Lehan Yang, Kele Xu, Min Feng", "title": "NTIRE 2021 Multi-modal Aerial View Object Classification Challenge", "comments": "10 pages, 1 figure. Conference on Computer Vision and Pattern\n  Recognition", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR) Workshops, 2021, 588-595", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce the first Challenge on Multi-modal Aerial View\nObject Classification (MAVOC) in conjunction with the NTIRE 2021 workshop at\nCVPR. This challenge is composed of two different tracks using EO andSAR\nimagery. Both EO and SAR sensors possess different advantages and drawbacks.\nThe purpose of this competition is to analyze how to use both sets of sensory\ninformation in complementary ways. We discuss the top methods submitted for\nthis competition and evaluate their results on our blind test set. Our\nchallenge results show significant improvement of more than 15% accuracy from\nour current baselines for each track of the competition\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:55:08 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Liu", "Jerrick", ""], ["Inkawhich", "Nathan", ""], ["Nina", "Oliver", ""], ["Timofte", "Radu", ""], ["Jain", "Sahil", ""], ["Lee", "Bob", ""], ["Duan", "Yuru", ""], ["Wei", "Wei", ""], ["Zhang", "Lei", ""], ["Xu", "Songzheng", ""], ["Sun", "Yuxuan", ""], ["Tang", "Jiaqi", ""], ["Geng", "Xueli", ""], ["Ma", "Mengru", ""], ["Li", "Gongzhe", ""], ["Geng", "Xueli", ""], ["Cai", "Huanqia", ""], ["Cai", "Chengxue", ""], ["Cummings", "Sol", ""], ["Miron", "Casian", ""], ["Pasarica", "Alexandru", ""], ["Yang", "Cheng-Yen", ""], ["Hsu", "Hung-Min", ""], ["Cai", "Jiarui", ""], ["Mei", "Jie", ""], ["Yeh", "Chia-Ying", ""], ["Hwang", "Jenq-Neng", ""], ["Xin", "Michael", ""], ["Shangguan", "Zhongkai", ""], ["Zheng", "Zihe", ""], ["Yifei", "Xu", ""], ["Yang", "Lehan", ""], ["Xu", "Kele", ""], ["Feng", "Min", ""]]}, {"id": "2107.01192", "submitter": "Sudeep Pasricha", "authors": "Liping Wang, Saideep Tiku, Sudeep Pasricha", "title": "CHISEL: Compression-Aware High-Accuracy Embedded Indoor Localization\n  with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  GPS technology has revolutionized the way we localize and navigate outdoors.\nHowever, the poor reception of GPS signals in buildings makes it unsuitable for\nindoor localization. WiFi fingerprinting-based indoor localization is one of\nthe most promising ways to meet this demand. Unfortunately, most work in the\ndomain fails to resolve challenges associated with deployability on\nresource-limited embedded devices. In this work, we propose a compression-aware\nand high-accuracy deep learning framework called CHISEL that outperforms the\nbest-known works in the area while maintaining localization robustness on\nembedded devices.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 17:00:01 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wang", "Liping", ""], ["Tiku", "Saideep", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2107.01196", "submitter": "Tyler Cody", "authors": "Tyler Cody, Peter A. Beling", "title": "A Systems Theory of Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing frameworks for transfer learning are incomplete from a systems\ntheoretic perspective. They place emphasis on notions of domain and task, and\nneglect notions of structure and behavior. In doing so, they limit the extent\nto which formalism can be carried through into the elaboration of their\nframeworks. Herein, we use Mesarovician systems theory to define transfer\nlearning as a relation on sets and subsequently characterize the general nature\nof transfer learning as a mathematical construct. We interpret existing\nframeworks in terms of ours and go beyond existing frameworks to define notions\nof transferability, transfer roughness, and transfer distance. Importantly,\ndespite its formalism, our framework avoids the detailed mathematics of\nlearning theory or machine learning solution methods without excluding their\nconsideration. As such, we provide a formal, general systems framework for\nmodeling transfer learning that offers a rigorous foundation for system design\nand analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 17:25:42 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Cody", "Tyler", ""], ["Beling", "Peter A.", ""]]}, {"id": "2107.01199", "submitter": "Milena Bajic", "authors": "Milena Bajic, Shahrzad M. Pour, Asmus Skar, Matteo Pettinari, Eyal\n  Levenberg, Tommy Sonne Alstr{\\o}m", "title": "Road Roughness Estimation Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road roughness is a very important road condition for the infrastructure, as\nthe roughness affects both the safety and ride comfort of passengers. The roads\ndeteriorate over time which means the road roughness must be continuously\nmonitored in order to have an accurate understand of the condition of the road\ninfrastructure. In this paper, we propose a machine learning pipeline for road\nroughness prediction using the vertical acceleration of the car and the car\nspeed. We compared well-known supervised machine learning models such as linear\nregression, naive Bayes, k-nearest neighbor, random forest, support vector\nmachine, and the multi-layer perceptron neural network. The models are trained\non an optimally selected set of features computed in the temporal and\nstatistical domain. The results demonstrate that machine learning methods can\naccurately predict road roughness, using the recordings of the cost\napproachable in-vehicle sensors installed in conventional passenger cars. Our\nfindings demonstrate that the technology is well suited to meet future pavement\ncondition monitoring, by enabling continuous monitoring of a wide road network.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 17:37:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Bajic", "Milena", ""], ["Pour", "Shahrzad M.", ""], ["Skar", "Asmus", ""], ["Pettinari", "Matteo", ""], ["Levenberg", "Eyal", ""], ["Alstr\u00f8m", "Tommy Sonne", ""]]}, {"id": "2107.01201", "submitter": "Quan Wang", "authors": "Rajeev Rikhye, Quan Wang, Qiao Liang, Yanzhang He, Ian McGraw", "title": "Multi-user VoiceFilter-Lite via Attentive Speaker Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a solution to allow speaker conditioned speech\nmodels, such as VoiceFilter-Lite, to support an arbitrary number of enrolled\nusers in a single pass. This is achieved by using an attention mechanism on\nmultiple speaker embeddings to compute a single attentive embedding, which is\nthen used as a side input to the model. We implemented multi-user\nVoiceFilter-Lite and evaluated it for three tasks: (1) a streaming automatic\nspeech recognition (ASR) task; (2) a text-independent speaker verification\ntask; and (3) a personalized keyphrase detection task, where ASR has to detect\nkeyphrases from multiple enrolled users in a noisy environment. Our experiments\nshow that, with up to four enrolled users, multi-user VoiceFilter-Lite is able\nto significantly reduce speech recognition and speaker verification errors when\nthere is overlapping speech, without affecting performance under other acoustic\nconditions. This attentive speaker embedding approach can also be easily\napplied to other speaker-conditioned models such as personal VAD and\npersonalized ASR.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 17:45:37 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Rikhye", "Rajeev", ""], ["Wang", "Quan", ""], ["Liang", "Qiao", ""], ["He", "Yanzhang", ""], ["McGraw", "Ian", ""]]}, {"id": "2107.01202", "submitter": "Mohd Zeeshan Ansari", "authors": "Mohd Zeeshan Ansari, M M Sufyan Beg, Tanvir Ahmad, Mohd Jazib Khan,\n  Ghazali Wasim", "title": "Language Identification of Hindi-English tweets using code-mixed BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Language identification of social media text has been an interesting problem\nof study in recent years. Social media messages are predominantly in code mixed\nin non-English speaking states. Prior knowledge by pre-training contextual\nembeddings have shown state of the art results for a range of downstream tasks.\nRecently, models such as BERT have shown that using a large amount of unlabeled\ndata, the pretrained language models are even more beneficial for learning\ncommon language representations. Extensive experiments exploiting transfer\nlearning and fine-tuning BERT models to identify language on Twitter are\npresented in this paper. The work utilizes a data collection of\nHindi-English-Urdu codemixed text for language pre-training and Hindi-English\ncodemixed for subsequent word-level language classification. The results show\nthat the representations pre-trained over codemixed data produce better results\nby their monolingual counterpart.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 17:51:36 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Ansari", "Mohd Zeeshan", ""], ["Beg", "M M Sufyan", ""], ["Ahmad", "Tanvir", ""], ["Khan", "Mohd Jazib", ""], ["Wasim", "Ghazali", ""]]}, {"id": "2107.01214", "submitter": "Benjamin Miller", "authors": "Benjamin Kurt Miller, Alex Cole, Patrick Forr\\'e, Gilles Louppe,\n  Christoph Weniger", "title": "Truncated Marginal Neural Ratio Estimation", "comments": "9 pages. 23 pages with references and supplemental material. Code\n  available at http://github.com/bkmi/tmnre/ Underlying library\n  http://github.com/undark-lab/swyft/", "journal-ref": null, "doi": "10.5281/zenodo.5043707", "report-no": null, "categories": "stat.ML astro-ph.IM cs.LG hep-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Parametric stochastic simulators are ubiquitous in science, often featuring\nhigh-dimensional input parameters and/or an intractable likelihood. Performing\nBayesian parameter inference in this context can be challenging. We present a\nneural simulator-based inference algorithm which simultaneously offers\nsimulation efficiency and fast empirical posterior testability, which is unique\namong modern algorithms. Our approach is simulation efficient by simultaneously\nestimating low-dimensional marginal posteriors instead of the joint posterior\nand by proposing simulations targeted to an observation of interest via a prior\nsuitably truncated by an indicator function. Furthermore, by estimating a\nlocally amortized posterior our algorithm enables efficient empirical tests of\nthe robustness of the inference results. Such tests are important for\nsanity-checking inference in real-world applications, which do not feature a\nknown ground truth. We perform experiments on a marginalized version of the\nsimulation-based inference benchmark and two complex and narrow posteriors,\nhighlighting the simulator efficiency of our algorithm as well as the quality\nof the estimated marginal posteriors. Implementation on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 18:00:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Miller", "Benjamin Kurt", ""], ["Cole", "Alex", ""], ["Forr\u00e9", "Patrick", ""], ["Louppe", "Gilles", ""], ["Weniger", "Christoph", ""]]}, {"id": "2107.01238", "submitter": "Sunny Tran", "authors": "Sunny Tran, Pranav Krishna, Ishan Pakuwal, Prabhakar Kafle, Nikhil\n  Singh, Jayson Lynch, Iddo Drori", "title": "Solving Machine Learning Problems", "comments": "38 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can a machine learn Machine Learning? This work trains a machine learning\nmodel to solve machine learning problems from a University undergraduate level\ncourse. We generate a new training set of questions and answers consisting of\ncourse exercises, homework, and quiz questions from MIT's 6.036 Introduction to\nMachine Learning course and train a machine learning model to answer these\nquestions. Our system demonstrates an overall accuracy of 96% for open-response\nquestions and 97% for multiple-choice questions, compared with MIT students'\naverage of 93%, achieving grade A performance in the course, all in real-time.\nQuestions cover all 12 topics taught in the course, excluding coding questions\nor questions with images. Topics include: (i) basic machine learning\nprinciples; (ii) perceptrons; (iii) feature extraction and selection; (iv)\nlogistic regression; (v) regression; (vi) neural networks; (vii) advanced\nneural networks; (viii) convolutional neural networks; (ix) recurrent neural\nnetworks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)\ndecision trees. Our system uses Transformer models within an encoder-decoder\narchitecture with graph and tree representations. An important aspect of our\napproach is a data-augmentation scheme for generating new example problems. We\nalso train a machine learning model to generate problem hints. Thus, our system\nautomatically generates new questions across topics, answers both open-response\nquestions and multiple-choice questions, classifies problems, and generates\nproblem hints, pushing the envelope of AI for STEM education.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 18:52:50 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Tran", "Sunny", ""], ["Krishna", "Pranav", ""], ["Pakuwal", "Ishan", ""], ["Kafle", "Prabhakar", ""], ["Singh", "Nikhil", ""], ["Lynch", "Jayson", ""], ["Drori", "Iddo", ""]]}, {"id": "2107.01253", "submitter": "Paulito Palmes", "authors": "Paulito P. Palmes, Akihiro Kishimoto, Radu Marinescu, Parikshit Ram,\n  Elizabeth Daly", "title": "Designing Machine Learning Pipeline Toolkit for AutoML Surrogate\n  Modeling Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The pipeline optimization problem in machine learning requires simultaneous\noptimization of pipeline structures and parameter adaptation of their elements.\nHaving an elegant way to express these structures can help lessen the\ncomplexity in the management and analysis of their performances together with\nthe different choices of optimization strategies. With these issues in mind, we\ncreated the AutoMLPipeline (AMLP) toolkit which facilitates the creation and\nevaluation of complex machine learning pipeline structures using simple\nexpressions. We use AMLP to find optimal pipeline signatures, datamine them,\nand use these datamined features to speed-up learning and prediction. We\nformulated a two-stage pipeline optimization with surrogate modeling in AMLP\nwhich outperforms other AutoML approaches with a 4-hour time budget in less\nthan 5 minutes of AMLP computation time.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 20:06:40 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 00:06:56 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Palmes", "Paulito P.", ""], ["Kishimoto", "Akihiro", ""], ["Marinescu", "Radu", ""], ["Ram", "Parikshit", ""], ["Daly", "Elizabeth", ""]]}, {"id": "2107.01264", "submitter": "Teodor Vanislavov Marinov", "authors": "Christoph Dann, Teodor V. Marinov, Mehryar Mohri, Julian Zimmert", "title": "Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds\n  for Episodic Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide improved gap-dependent regret bounds for reinforcement learning in\nfinite episodic Markov decision processes. Compared to prior work, our bounds\ndepend on alternative definitions of gaps. These definitions are based on the\ninsight that, in order to achieve a favorable regret, an algorithm does not\nneed to learn how to behave optimally in states that are not reached by an\noptimal policy. We prove tighter upper regret bounds for optimistic algorithms\nand accompany them with new information-theoretic lower bounds for a large\nclass of MDPs. Our results show that optimistic algorithms can not achieve the\ninformation-theoretic lower bounds even in deterministic MDPs unless there is a\nunique optimal policy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 20:36:05 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dann", "Christoph", ""], ["Marinov", "Teodor V.", ""], ["Mohri", "Mehryar", ""], ["Zimmert", "Julian", ""]]}, {"id": "2107.01269", "submitter": "Niko Moritz", "authors": "Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech\n  Recognition", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based end-to-end automatic speech recognition (ASR) systems have\nrecently demonstrated state-of-the-art results for numerous tasks. However, the\napplication of self-attention and attention-based encoder-decoder models\nremains challenging for streaming ASR, where each word must be recognized\nshortly after it was spoken. In this work, we present the dual\ncausal/non-causal self-attention (DCN) architecture, which in contrast to\nrestricted self-attention prevents the overall context to grow beyond the\nlook-ahead of a single layer when used in a deep architecture. DCN is compared\nto chunk-based and restricted self-attention using streaming transformer and\nconformer architectures, showing improved ASR performance over restricted\nself-attention and competitive ASR results compared to chunk-based\nself-attention, while providing the advantage of frame-synchronous processing.\nCombined with triggered attention, the proposed streaming end-to-end ASR\nsystems obtained state-of-the-art results on the LibriSpeech, HKUST, and\nSwitchboard ASR tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 20:56:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2107.01272", "submitter": "Rui Wang", "authors": "Rui Wang", "title": "Physics-Guided Deep Learning for Dynamical Systems: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling complex physical dynamics is a fundamental task in science and\nengineering. Traditional physics-based models are interpretable but rely on\nrigid assumptions. And the direct numerical approximation is usually\ncomputationally intensive, requiring significant computational resources and\nexpertise. While deep learning (DL) provides novel alternatives for efficiently\nrecognizing complex patterns and emulating nonlinear dynamics, it does not\nnecessarily obey the governing laws of physical systems, nor do they generalize\nwell across different systems. Thus, the study of physics-guided DL emerged and\nhas gained great progress. It aims to take the best from both physics-based\nmodeling and state-of-the-art DL models to better solve scientific problems. In\nthis paper, we provide a structured overview of existing methodologies of\nintegrating prior physical knowledge or physics-based modeling into DL and\ndiscuss the emerging opportunities.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 20:59:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Rui", ""]]}, {"id": "2107.01273", "submitter": "Naftali Cohen", "authors": "Naftali Cohen, Srijan Sood, Zhen Zeng, Tucker Balch, Manuela Veloso", "title": "Visual Time Series Forecasting: An Image-driven Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address time-series forecasting as a computer vision task.\nWe capture input data as an image and train a model to produce the subsequent\nimage. This approach results in predicting distributions as opposed to\npointwise values. To assess the robustness and quality of our approach, we\nexamine various datasets and multiple evaluation metrics. Our experiments show\nthat our forecasting tool is effective for cyclic data but somewhat less for\nirregular data such as stock prices. Importantly, when using image-based\nevaluation metrics, we find our method to outperform various baselines,\nincluding ARIMA, and a numerical variation of our deep learning approach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 20:59:48 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cohen", "Naftali", ""], ["Sood", "Srijan", ""], ["Zeng", "Zhen", ""], ["Balch", "Tucker", ""], ["Veloso", "Manuela", ""]]}, {"id": "2107.01275", "submitter": "Timo Lohrenz", "authors": "Timo Lohrenz, Patrick Schwarz, Zhengyang Li, Tim Fingscheidt", "title": "Relaxed Attention: A Simple Method to Boost Performance of End-to-End\n  Automatic Speech Recognition", "comments": "submitted to ASRU 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, attention-based encoder-decoder (AED) models have shown high\nperformance for end-to-end automatic speech recognition (ASR) across several\ntasks. Addressing overconfidence in such models, in this paper we introduce the\nconcept of relaxed attention, which is a simple gradual injection of a uniform\ndistribution to the encoder-decoder attention weights during training that is\neasily implemented with two lines of code. We investigate the effect of relaxed\nattention across different AED model architectures and two prominent ASR tasks,\nWall Street Journal (WSJ) and Librispeech. We found that transformers trained\nwith relaxed attention outperform the standard baseline models consistently\nduring decoding with external language models. On WSJ, we set a new benchmark\nfor transformer-based end-to-end speech recognition with a word error rate of\n3.65%, outperforming state of the art (4.20%) by 13.1% relative, while\nintroducing only a single hyperparameter. Upon acceptance, models will be\npublished on github.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 21:01:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lohrenz", "Timo", ""], ["Schwarz", "Patrick", ""], ["Li", "Zhengyang", ""], ["Fingscheidt", "Tim", ""]]}, {"id": "2107.01277", "submitter": "Mukund Telukunta", "authors": "Mukund Telukunta, Venkata Sriram Siddhardh Nadendla", "title": "Non-Comparative Fairness for Human-Auditing and Its Relation to\n  Traditional Fairness Notions", "comments": "arXiv admin note: substantial text overlap with arXiv:2009.04383", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias evaluation in machine-learning based services (MLS) based on traditional\nalgorithmic fairness notions that rely on comparative principles is practically\ndifficult, making it necessary to rely on human auditor feedback. However, in\nspite of taking rigorous training on various comparative fairness notions,\nhuman auditors are known to disagree on various aspects of fairness notions in\npractice, making it difficult to collect reliable feedback. This paper offers a\nparadigm shift to the domain of algorithmic fairness via proposing a new\nfairness notion based on the principle of non-comparative justice. In contrary\nto traditional fairness notions where the outcomes of two individuals/groups\nare compared, our proposed notion compares the MLS' outcome with a desired\noutcome for each input. This desired outcome naturally describes a human\nauditor's expectation, and can be easily used to evaluate MLS on crowd-auditing\nplatforms. We show that any MLS can be deemed fair from the perspective of\ncomparative fairness (be it in terms of individual fairness, statistical\nparity, equal opportunity or calibration) if it is non-comparatively fair with\nrespect to a fair auditor. We also show that the converse holds true in the\ncontext of individual fairness. Given that such an evaluation relies on the\ntrustworthiness of the auditor, we also present an approach to identify fair\nand reliable auditors by estimating their biases with respect to a given set of\nsensitive attributes, as well as quantify the uncertainty in the estimation of\nbiases within a given MLS. Furthermore, all of the above results are also\nvalidated on COMPAS, German credit and Adult Census Income datasets.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 20:05:22 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Telukunta", "Mukund", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""]]}, {"id": "2107.01281", "submitter": "Jean-Baptiste Mouret", "authors": "Luigi Penco, Jean-Baptiste Mouret, Serena Ivaldi", "title": "Prescient teleoperation of humanoid robots", "comments": "Video: https://www.youtube.com/watch?v=N3u4ot3aIyQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humanoid robots could be versatile and intuitive human avatars that operate\nremotely in inaccessible places: the robot could reproduce in the remote\nlocation the movements of an operator equipped with a wearable motion capture\ndevice while sending visual feedback to the operator. While substantial\nprogress has been made on transferring (\"retargeting\") human motions to\nhumanoid robots, a major problem preventing the deployment of such systems in\nreal applications is the presence of communication delays between the human\ninput and the feedback from the robot: even a few hundred milliseconds of delay\ncan irreversibly disturb the operator, let alone a few seconds. To overcome\nthese delays, we introduce a system in which a humanoid robot executes commands\nbefore it actually receives them, so that the visual feedback appears to be\nsynchronized to the operator, whereas the robot executed the commands in the\npast. To do so, the robot continuously predicts future commands by querying a\nmachine learning model that is trained on past trajectories and conditioned on\nthe last received commands. In our experiments, an operator was able to\nsuccessfully control a humanoid robot (32 degrees of freedom) with stochastic\ndelays up to 2 seconds in several whole-body manipulation tasks, including\nreaching different targets, picking up, and placing a box at distinct\nlocations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 21:10:35 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 15:26:57 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Penco", "Luigi", ""], ["Mouret", "Jean-Baptiste", ""], ["Ivaldi", "Serena", ""]]}, {"id": "2107.01285", "submitter": "Toby Hocking", "authors": "Jonathan Hillman and Toby Dylan Hocking", "title": "Optimizing ROC Curves with a Sort-Based Surrogate Loss Function for\n  Binary Classification and Changepoint Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Receiver Operating Characteristic (ROC) curves are plots of true positive\nrate versus false positive rate which are useful for evaluating binary\nclassification models, but difficult to use for learning since the Area Under\nthe Curve (AUC) is non-convex. ROC curves can also be used in other problems\nthat have false positive and true positive rates such as changepoint detection.\nWe show that in this more general context, the ROC curve can have loops, points\nwith highly sub-optimal error rates, and AUC greater than one. This observation\nmotivates a new optimization objective: rather than maximizing the AUC, we\nwould like a monotonic ROC curve with AUC=1 that avoids points with large\nvalues for Min(FP,FN). We propose a convex relaxation of this objective that\nresults in a new surrogate loss function called the AUM, short for Area Under\nMin(FP, FN). Whereas previous loss functions are based on summing over all\nlabeled examples or pairs, the AUM requires a sort and a sum over the sequence\nof points on the ROC curve. We show that AUM directional derivatives can be\nefficiently computed and used in a gradient descent learning algorithm. In our\nempirical study of supervised binary classification and changepoint detection\nproblems, we show that our new AUM minimization learning algorithm results in\nimproved AUC and comparable speed relative to previous baselines.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 21:21:19 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hillman", "Jonathan", ""], ["Hocking", "Toby Dylan", ""]]}, {"id": "2107.01296", "submitter": "Uday Singh Saini", "authors": "Uday Singh Saini, Pravallika Devineni, Evangelos E. Papalexakis", "title": "Subspace Clustering Based Analysis of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tools to analyze the latent space of deep neural networks provide a step\ntowards better understanding them. In this work, we motivate sparse subspace\nclustering (SSC) with an aim to learn affinity graphs from the latent structure\nof a given neural network layer trained over a set of inputs. We then use tools\nfrom Community Detection to quantify structures present in the input. These\nexperiments reveal that as we go deeper in a network, inputs tend to have an\nincreasing affinity to other inputs of the same class. Subsequently, we utilise\nmatrix similarity measures to perform layer-wise comparisons between affinity\ngraphs. In doing so we first demonstrate that when comparing a given layer\ncurrently under training to its final state, the shallower the layer of the\nnetwork, the quicker it is to converge than the deeper layers. When performing\na pairwise analysis of the entire network architecture, we observe that, as the\nnetwork increases in size, it reorganises from a state where each layer is\nmoderately similar to its neighbours, to a state where layers within a block\nhave high similarity than to layers in other blocks. Finally, we analyze the\nlearned affinity graphs of the final convolutional layer of the network and\ndemonstrate how an input's local neighbourhood affects its classification by\nthe network.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 22:46:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Saini", "Uday Singh", ""], ["Devineni", "Pravallika", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2107.01301", "submitter": "Shih-Yu Sun", "authors": "Shih-Yu Sun, Vimal Thilak, Etai Littwin, Omid Saremi, Joshua M.\n  Susskind", "title": "Implicit Greedy Rank Learning in Autoencoders via Overparameterized\n  Linear Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep linear networks trained with gradient descent yield low rank solutions,\nas is typically studied in matrix factorization. In this paper, we take a step\nfurther and analyze implicit rank regularization in autoencoders. We show\ngreedy learning of low-rank latent codes induced by a linear sub-network at the\nautoencoder bottleneck. We further propose orthogonal initialization and\nprincipled learning rate adjustment to mitigate sensitivity of training\ndynamics to spectral prior and linear depth. With linear autoencoders on\nsynthetic data, our method converges stably to ground-truth latent code rank.\nWith nonlinear autoencoders, our method converges to latent ranks optimal for\ndownstream classification and image sampling.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 23:17:50 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sun", "Shih-Yu", ""], ["Thilak", "Vimal", ""], ["Littwin", "Etai", ""], ["Saremi", "Omid", ""], ["Susskind", "Joshua M.", ""]]}, {"id": "2107.01303", "submitter": "Javid Dadashkarimi", "authors": "Javid Dadashkarimi and Amin Karbasi and Dustin Scheinost", "title": "Data-driven mapping between functional connectomes using optimal\n  transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connectomes derived from functional magnetic resonance imaging\nhave long been used to understand the functional organization of the brain.\nNevertheless, a connectome is intrinsically linked to the atlas used to create\nit. In other words, a connectome generated from one atlas is different in scale\nand resolution compared to a connectome generated from another atlas. Being\nable to map connectomes and derived results between different atlases without\nadditional pre-processing is a crucial step in improving interpretation and\ngeneralization between studies that use different atlases. Here, we use optimal\ntransport, a powerful mathematical technique, to find an optimum mapping\nbetween two atlases. This mapping is then used to transform time series from\none atlas to another in order to reconstruct a connectome. We validate our\napproach by comparing transformed connectomes against their \"gold-standard\"\ncounterparts (i.e., connectomes generated directly from an atlas) and\ndemonstrate the utility of transformed connectomes by applying these\nconnectomes to predictive models based on a different atlas. We show that these\ntransformed connectomes are significantly similar to their \"gold-standard\"\ncounterparts and maintain individual differences in brain-behavior\nassociations, demonstrating both the validity of our approach and its utility\nin downstream analyses. Overall, our approach is a promising avenue to increase\nthe generalization of connectome-based results across different atlases.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 23:43:34 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dadashkarimi", "Javid", ""], ["Karbasi", "Amin", ""], ["Scheinost", "Dustin", ""]]}, {"id": "2107.01310", "submitter": "Reza Asadi Mr", "authors": "Reza Asadi and Amelia Regan", "title": "Clustering of Time Series Data with Prior Geographical Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Time Series data are broadly studied in various domains of transportation\nsystems. Traffic data area challenging example of spatio-temporal data, as it\nis multi-variate time series with high correlations in spatial and temporal\nneighborhoods. Spatio-temporal clustering of traffic flow data find similar\npatterns in both spatial and temporal domain, where it provides better\ncapability for analyzing a transportation network, and improving related\nmachine learning models, such as traffic flow prediction and anomaly detection.\nIn this paper, we propose a spatio-temporal clustering model, where it clusters\ntime series data based on spatial and temporal contexts. We propose a variation\nof a Deep Embedded Clustering(DEC) model for finding spatio-temporal clusters.\nThe proposed model Spatial-DEC (S-DEC) use prior geographical information in\nbuilding latent feature representations. We also define evaluation metrics for\nspatio-temporal clusters. Not only do the obtained clusters have better\ntemporal similarity when evaluated using DTW distance, but also the clusters\nbetter represents spatial connectivity and dis-connectivity. We use traffic\nflow data obtained by PeMS in our analysis. The results show that the proposed\nSpatial-DEC can find more desired spatio-temporal clusters.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 00:19:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Asadi", "Reza", ""], ["Regan", "Amelia", ""]]}, {"id": "2107.01319", "submitter": "Yifan Xing", "authors": "Yifan Xing, Tong He, Tianjun Xiao, Yongxin Wang, Yuanjun Xiong, Wei\n  Xia, David Wipf, Zheng Zhang, Stefano Soatto", "title": "Learning Hierarchical Graph Neural Networks for Image Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a hierarchical graph neural network (GNN) model that learns how to\ncluster a set of images into an unknown number of identities using a training\nset of images annotated with labels belonging to a disjoint set of identities.\nOur hierarchical GNN uses a novel approach to merge connected components\npredicted at each level of the hierarchy to form a new graph at the next level.\nUnlike fully unsupervised hierarchical clustering, the choice of grouping and\ncomplexity criteria stems naturally from supervision in the training set. The\nresulting method, Hi-LANDER, achieves an average of 54% improvement in F-score\nand 8% increase in Normalized Mutual Information (NMI) relative to current\nGNN-based clustering algorithms. Additionally, state-of-the-art GNN-based\nmethods rely on separate models to predict linkage probabilities and node\ndensities as intermediate steps of the clustering process. In contrast, our\nunified framework achieves a seven-fold decrease in computational cost. We\nrelease our training and inference code at\nhttps://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 01:28:42 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 14:50:19 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Xing", "Yifan", ""], ["He", "Tong", ""], ["Xiao", "Tianjun", ""], ["Wang", "Yongxin", ""], ["Xiong", "Yuanjun", ""], ["Xia", "Wei", ""], ["Wipf", "David", ""], ["Zhang", "Zheng", ""], ["Soatto", "Stefano", ""]]}, {"id": "2107.01323", "submitter": "Qiong Zhang", "authors": "Qiong Zhang, Jiahua Chen", "title": "Minimum Wasserstein Distance Estimator under Finite Location-scale\n  Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When a population exhibits heterogeneity, we often model it via a finite\nmixture: decompose it into several different but homogeneous subpopulations.\nContemporary practice favors learning the mixtures by maximizing the likelihood\nfor statistical efficiency and the convenient EM-algorithm for numerical\ncomputation. Yet the maximum likelihood estimate (MLE) is not well defined for\nthe most widely used finite normal mixture in particular and for finite\nlocation-scale mixture in general. We hence investigate feasible alternatives\nto MLE such as minimum distance estimators. Recently, the Wasserstein distance\nhas drawn increased attention in the machine learning community. It has\nintuitive geometric interpretation and is successfully employed in many new\napplications. Do we gain anything by learning finite location-scale mixtures\nvia a minimum Wasserstein distance estimator (MWDE)? This paper investigates\nthis possibility in several respects. We find that the MWDE is consistent and\nderive a numerical solution under finite location-scale mixtures. We study its\nrobustness against outliers and mild model mis-specifications. Our moderate\nscaled simulation study shows the MWDE suffers some efficiency loss against a\npenalized version of MLE in general without noticeable gain in robustness. We\nreaffirm the general superiority of the likelihood based learning strategies\neven for the non-regular finite location-scale mixtures.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:06:49 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Qiong", ""], ["Chen", "Jiahua", ""]]}, {"id": "2107.01325", "submitter": "Connor Lawless", "authors": "Connor Lawless, Oktay Gunluk", "title": "Fair Decision Rules for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has begun automating decision making in\nfields as varied as college admissions, credit lending, and criminal\nsentencing. The socially sensitive nature of some of these applications\ntogether with increasing regulatory constraints has necessitated the need for\nalgorithms that are both fair and interpretable. In this paper we consider the\nproblem of building Boolean rule sets in disjunctive normal form (DNF), an\ninterpretable model for binary classification, subject to fairness constraints.\nWe formulate the problem as an integer program that maximizes classification\naccuracy with explicit constraints on two different measures of classification\nparity: equality of opportunity and equalized odds. Column generation\nframework, with a novel formulation, is used to efficiently search over\nexponentially many possible rules. When combined with faster heuristics, our\nmethod can deal with large data-sets. Compared to other fair and interpretable\nclassifiers, our method is able to find rule sets that meet stricter notions of\nfairness with a modest trade-off in accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:32:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lawless", "Connor", ""], ["Gunluk", "Oktay", ""]]}, {"id": "2107.01326", "submitter": "Ken Li", "authors": "Hui Li, Xing Fu, Ruofan Wu, Jinyu Xu, Kai Xiao, Xiaofu Chang, Weiqiang\n  Wang, Shuai Chen, Leilei Shi, Tao Xiong, Yuan Qi", "title": "SHORING: Design Provable Conditional High-Order Interaction Network via\n  Symbolic Testing", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning provides a promising way to extract effective representations\nfrom raw data in an end-to-end fashion and has proven its effectiveness in\nvarious domains such as computer vision, natural language processing, etc.\nHowever, in domains such as content/product recommendation and risk management,\nwhere sequence of event data is the most used raw data form and experts derived\nfeatures are more commonly used, deep learning models struggle to dominate the\ngame. In this paper, we propose a symbolic testing framework that helps to\nanswer the question of what kinds of expert-derived features could be learned\nby a neural network. Inspired by this testing framework, we introduce an\nefficient architecture named SHORING, which contains two components:\n\\textit{event network} and \\textit{sequence network}. The \\textit{event}\nnetwork learns arbitrarily yet efficiently high-order \\textit{event-level}\nembeddings via a provable reparameterization trick, the \\textit{sequence}\nnetwork aggregates from sequence of \\textit{event-level} embeddings. We argue\nthat SHORING is capable of learning certain standard symbolic expressions which\nthe standard multi-head self-attention network fails to learn, and conduct\ncomprehensive experiments and ablation studies on four synthetic datasets and\nthree real-world datasets. The results show that SHORING empirically\noutperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:33:32 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Hui", ""], ["Fu", "Xing", ""], ["Wu", "Ruofan", ""], ["Xu", "Jinyu", ""], ["Xiao", "Kai", ""], ["Chang", "Xiaofu", ""], ["Wang", "Weiqiang", ""], ["Chen", "Shuai", ""], ["Shi", "Leilei", ""], ["Xiong", "Tao", ""], ["Qi", "Yuan", ""]]}, {"id": "2107.01330", "submitter": "Md Nazmul Karim", "authors": "Nazmul Karim and Nazanin Rahnavard", "title": "SPI-GAN: Towards Single-Pixel Imaging through Generative Adversarial\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Single-pixel imaging is a novel imaging scheme that has gained popularity due\nto its huge computational gain and potential for a low-cost alternative to\nimaging beyond the visible spectrum. The traditional reconstruction methods\nstruggle to produce a clear recovery when one limits the number of illumination\npatterns from a spatial light modulator. As a remedy, several\ndeep-learning-based solutions have been proposed which lack good generalization\nability due to the architectural setup and loss functions. In this paper, we\npropose a generative adversarial network-based reconstruction framework for\nsingle-pixel imaging, referred to as SPI-GAN. Our method can reconstruct images\nwith 17.92 dB PSNR and 0.487 SSIM, even if the sampling ratio drops to 5%. This\nfacilitates much faster reconstruction making our method suitable for\nsingle-pixel video. Furthermore, our ResNet-like architecture for the generator\nleads to useful representation learning that allows us to reconstruct\ncompletely unseen objects. The experimental results demonstrate that SPI-GAN\nachieves significant performance gain, e.g. near 3dB PSNR gain, over the\ncurrent state-of-the-art method.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 03:06:09 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Karim", "Nazmul", ""], ["Rahnavard", "Nazanin", ""]]}, {"id": "2107.01333", "submitter": "Shuyan Wang", "authors": "Shuyan Wang, Peter Spirtes", "title": "A Uniformly Consistent Estimator of non-Gaussian Causal Effects Under\n  the k-Triangle-Faithfulness Assumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kalisch and B\\\"{u}hlmann (2007) showed that for linear Gaussian models, under\nthe Causal Markov Assumption, the Strong Causal Faithfulness Assumption, and\nthe assumption of causal sufficiency, the PC algorithm is a uniformly\nconsistent estimator of the Markov Equivalence Class of the true causal DAG for\nlinear Gaussian models; it follows from this that for the identifiable causal\neffects in the Markov Equivalence Class, there are uniformly consistent\nestimators of causal effects as well. The $k$-Triangle-Faithfulness Assumption\nis a strictly weaker assumption that avoids some implausible implications of\nthe Strong Causal Faithfulness Assumption and also allows for uniformly\nconsistent estimates of Markov Equivalence Classes (in a weakened sense), and\nof identifiable causal effects. However, both of these assumptions are\nrestricted to linear Gaussian models. We propose the Generalized $k$-Triangle\nFaithfulness, which can be applied to any smooth distribution. In addition,\nunder the Generalized $k$-Triangle Faithfulness Assumption, we describe the\nEdge Estimation Algorithm that provides uniformly consistent estimates of\ncausal effects in some cases (and otherwise outputs \"can't tell\"), and the\n\\textit{Very Conservative }$SGS$ Algorithm that (in a slightly weaker sense) is\na uniformly consistent estimator of the Markov equivalence class of the true\nDAG.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 03:26:48 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Shuyan", ""], ["Spirtes", "Peter", ""]]}, {"id": "2107.01335", "submitter": "Cyrus Rashtchian", "authors": "Cyrus Rashtchian, David P. Woodruff, Peng Ye, Hanlin Zhu", "title": "Average-Case Communication Complexity of Statistical Problems", "comments": "28 pages. Conference on Learning Theory (COLT), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study statistical problems, such as planted clique, its variants, and\nsparse principal component analysis in the context of average-case\ncommunication complexity. Our motivation is to understand the\nstatistical-computational trade-offs in streaming, sketching, and query-based\nmodels. Communication complexity is the main tool for proving lower bounds in\nthese models, yet many prior results do not hold in an average-case setting. We\nprovide a general reduction method that preserves the input distribution for\nproblems involving a random graph or matrix with planted structure. Then, we\nderive two-party and multi-party communication lower bounds for detecting or\nfinding planted cliques, bipartite cliques, and related problems. As a\nconsequence, we obtain new bounds on the query complexity in the edge-probe,\nvector-matrix-vector, matrix-vector, linear sketching, and\n$\\mathbb{F}_2$-sketching models. Many of these results are nearly tight, and we\nuse our techniques to provide simple proofs of some known lower bounds for the\nedge-probe model.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 03:31:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Rashtchian", "Cyrus", ""], ["Woodruff", "David P.", ""], ["Ye", "Peng", ""], ["Zhu", "Hanlin", ""]]}, {"id": "2107.01337", "submitter": "Md Selim", "authors": "Md Selim, Jie Zhang, Baowei Fei, Guo-Qiang Zhang, Jin Chen", "title": "CT Image Harmonization for Enhancing Radiomics Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While remarkable advances have been made in Computed Tomography (CT),\ncapturing CT images with non-standardized protocols causes low reproducibility\nregarding radiomic features, forming a barrier on CT image analysis in a large\nscale. RadiomicGAN is developed to effectively mitigate the discrepancy caused\nby using non-standard reconstruction kernels. RadiomicGAN consists of hybrid\nneural blocks including both pre-trained and trainable layers adopted to learn\nradiomic feature distributions efficiently. A novel training approach, called\nDynamic Window-based Training, has been developed to smoothly transform the\npre-trained model to the medical imaging domain. Model performance evaluated\nusing 1401 radiomic features show that RadiomicGAN clearly outperforms the\nstate-of-art image standardization models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 04:03:42 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Selim", "Md", ""], ["Zhang", "Jie", ""], ["Fei", "Baowei", ""], ["Zhang", "Guo-Qiang", ""], ["Chen", "Jin", ""]]}, {"id": "2107.01338", "submitter": "Shiv Shankar", "authors": "Shiv Shankar, Daniel Sheldon", "title": "Sibling Regression for Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Field observations form the basis of many scientific studies, especially in\necological and social sciences. Despite efforts to conduct such surveys in a\nstandardized way, observations can be prone to systematic measurement errors.\nThe removal of systematic variability introduced by the observation process, if\npossible, can greatly increase the value of this data. Existing non-parametric\ntechniques for correcting such errors assume linear additive noise models. This\nleads to biased estimates when applied to generalized linear models (GLM). We\npresent an approach based on residual functions to address this limitation. We\nthen demonstrate its effectiveness on synthetic data and show it reduces\nsystematic detection variability in moth surveys.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 04:07:11 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 15:37:01 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Shankar", "Shiv", ""], ["Sheldon", "Daniel", ""]]}, {"id": "2107.01343", "submitter": "Mingliang Bai", "authors": "Mingliang Bai, Xinyu Zhao, Zhenhua Long, Jinfu Liu, Daren Yu", "title": "Short-term probabilistic photovoltaic power forecast based on deep\n  convolutional long short-term memory network and kernel density estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar energy is a clean and renewable energy. Photovoltaic (PV) power is an\nimportant way to utilize solar energy. Accurate PV power forecast is crucial to\nthe large-scale application of PV power and the stability of electricity grid.\nThis paper proposes a novel method for short-term photovoltaic power forecast\nusing deep convolutional long short-term memory (ConvLSTM) network and kernel\ndensity estimation (KDE). In the proposed method, ConvLSTM is used to forecast\nthe future photovoltaic power and KDE is used for estimating the joint\nprobabilistic density function and giving the probabilistic confidence\ninterval. Experiments in an actual photovoltaic power station verify the\neffectiveness of the proposed method. Comparison experiments with convolutional\nneural network (CNN) and long short-term memory network (LSTM)shows that\nConvLSTM can combine the advantages of both CNN and LSTM and significantly\noutperform CNN and LSTM in terms of forecast accuracy. Through further\ncomparison with other five conventional methods including multilayer perceptron\n(MLP), support vector regression (SVR), extreme learning machine (ELM),\nclassification and regression tree (CART) and gradient boosting decision tree\n(GBDT), ConvLSTM can significantly improve the forecast accuracy by more than\n20% for most of the five methods and the superiorities of ConvLSTM are further\nverified.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 04:49:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bai", "Mingliang", ""], ["Zhao", "Xinyu", ""], ["Long", "Zhenhua", ""], ["Liu", "Jinfu", ""], ["Yu", "Daren", ""]]}, {"id": "2107.01345", "submitter": "Martin Kopp", "authors": "Jaroslav Hlav\\'a\\v{c}, Martin Kopp, Jan Kohout", "title": "Cluster Representatives Selection in Non-Metric Spaces for Nearest\n  Prototype Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The nearest prototype classification is a less computationally intensive\nreplacement for the $k$-NN method, especially when large datasets are\nconsidered. In metric spaces, centroids are often used as prototypes to\nrepresent whole clusters. The selection of cluster prototypes in non-metric\nspaces is more challenging as the idea of computing centroids is not directly\napplicable.\n  In this paper, we present CRS, a novel method for selecting a small yet\nrepresentative subset of objects as a cluster prototype. Memory and\ncomputationally efficient selection of representatives is enabled by leveraging\nthe similarity graph representation of each cluster created by the NN-Descent\nalgorithm. CRS can be used in an arbitrary metric or non-metric space because\nof the graph-based approach, which requires only a pairwise similarity measure.\nAs we demonstrate in the experimental evaluation, our method outperforms the\nstate of the art techniques on multiple datasets from different domains.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 04:51:07 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hlav\u00e1\u010d", "Jaroslav", ""], ["Kopp", "Martin", ""], ["Kohout", "Jan", ""]]}, {"id": "2107.01347", "submitter": "Paolo Fazzini", "authors": "Paolo Fazzini, Isaac Wheeler, Francesco Petracchini", "title": "Traffic Signal Control with Communicative Deep Reinforcement Learning\n  Agents: a Case Study", "comments": "41 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this work we theoretically and experimentally analyze Multi-Agent\nAdvantage Actor-Critic (MA2C) and Independent Advantage Actor-Critic (IA2C),\ntwo recently proposed multi-agent reinforcement learning methods that can be\napplied to control traffic signals in urban areas. The two methods differ in\ntheir use of a reward calculated locally or globally and in the management of\nagents' communication. We analyze the methods theoretically with the framework\nprovided by non-Markov decision processes, which provides useful insights in\nthe analysis of the algorithms. Moreover, we analyze the efficacy and the\nrobustness of the methods experimentally by testing them in two traffic areas\nin the Bologna (Italy) area, simulated by SUMO, a software tool. The\nexperimental results indicate that MA2C achieves the best performance in the\nmajority of cases, outperforms the alternative method considered, and displays\nsufficient stability during the learning process.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 05:12:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fazzini", "Paolo", ""], ["Wheeler", "Isaac", ""], ["Petracchini", "Francesco", ""]]}, {"id": "2107.01348", "submitter": "Vektor Dewanto", "authors": "Vektor Dewanto, Marcus Gallagher", "title": "Examining average and discounted reward optimality criteria in\n  reinforcement learning", "comments": "14 pages, 3 figures, 10-page main content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In reinforcement learning (RL), the goal is to obtain an optimal policy, for\nwhich the optimality criterion is fundamentally important. Two major optimality\ncriteria are average and discounted rewards, where the later is typically\nconsidered as an approximation to the former. While the discounted reward is\nmore popular, it is problematic to apply in environments that have no natural\nnotion of discounting. This motivates us to revisit a) the progression of\noptimality criteria in dynamic programming, b) justification for and\ncomplication of an artificial discount factor, and c) benefits of directly\nmaximizing the average reward. Our contributions include a thorough examination\nof the relationship between average and discounted rewards, as well as a\ndiscussion of their pros and cons in RL. We emphasize that average-reward RL\nmethods possess the ingredient and mechanism for developing the general\ndiscounting-free optimality criterion (Veinott, 1969) in RL.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 05:28:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dewanto", "Vektor", ""], ["Gallagher", "Marcus", ""]]}, {"id": "2107.01349", "submitter": "Dong-Wan Choi", "authors": "Jong-Yeong Kim and Dong-Wan Choi", "title": "Split-and-Bridge: Adaptable Class Incremental Learning within a Single\n  Neural Network", "comments": "In AAAI-2021", "journal-ref": "In Proceedings of the AAAI Conference on Artificial Intelligence\n  (Vol. 35, No. 9, pp. 8137-8145) 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning has been a major problem in the deep learning community,\nwhere the main challenge is how to effectively learn a series of newly arriving\ntasks without forgetting the knowledge of previous tasks. Initiated by Learning\nwithout Forgetting (LwF), many of the existing works report that knowledge\ndistillation is effective to preserve the previous knowledge, and hence they\ncommonly use a soft label for the old task, namely a knowledge distillation\n(KD) loss, together with a class label for the new task, namely a cross entropy\n(CE) loss, to form a composite loss for a single neural network. However, this\napproach suffers from learning the knowledge by a CE loss as a KD loss often\nmore strongly influences the objective function when they are in a competitive\nsituation within a single network. This could be a critical problem\nparticularly in a class incremental scenario, where the knowledge across tasks\nas well as within the new task, both of which can only be acquired by a CE\nloss, is essentially learned due to the existence of a unified classifier. In\nthis paper, we propose a novel continual learning method, called\nSplit-and-Bridge, which can successfully address the above problem by partially\nsplitting a neural network into two partitions for training the new task\nseparated from the old task and re-connecting them for learning the knowledge\nacross tasks. In our thorough experimental analysis, our Split-and-Bridge\nmethod outperforms the state-of-the-art competitors in KD-based continual\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 05:51:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kim", "Jong-Yeong", ""], ["Choi", "Dong-Wan", ""]]}, {"id": "2107.01353", "submitter": "Hao Peng", "authors": "Hao Peng, Pei Chen, Rui Liu, Luonan Chen", "title": "Spatiotemporal convolutional network for time-series prediction and\n  causal inference", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making predictions in a robust way is not easy for nonlinear systems. In this\nwork, a neural network computing framework, i.e., a spatiotemporal\nconvolutional network (STCN), was developed to efficiently and accurately\nrender a multistep-ahead prediction of a time series by employing a\nspatial-temporal information (STI) transformation. The STCN combines the\nadvantages of both the temporal convolutional network (TCN) and the STI\nequation, which maps the high-dimensional/spatial data to the future temporal\nvalues of a target variable, thus naturally providing the prediction of the\ntarget variable. From the observed variables, the STCN also infers the causal\nfactors of the target variable in the sense of Granger causality, which are in\nturn selected as effective spatial information to improve the prediction\nrobustness. The STCN was successfully applied to both benchmark systems and\nreal-world datasets, all of which show superior and robust performance in\nmultistep-ahead prediction, even when the data were perturbed by noise. From\nboth theoretical and computational viewpoints, the STCN has great potential in\npractical applications in artificial intelligence (AI) or machine learning\nfields as a model-free method based only on the observed data, and also opens a\nnew way to explore the observed high-dimensional data in a dynamical manner for\nmachine learning.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 06:20:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Peng", "Hao", ""], ["Chen", "Pei", ""], ["Liu", "Rui", ""], ["Chen", "Luonan", ""]]}, {"id": "2107.01354", "submitter": "Dong-Wan Choi", "authors": "Hakbin Kim and Dong-Wan Choi", "title": "Pool of Experts: Realtime Querying Specialized Knowledge in Massive\n  Neural Networks", "comments": "In SIGMOD/PODS 2021", "journal-ref": "SIGMOD Conference 2021: 2244-2252", "doi": "10.1145/3448016.3457326", "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the great success of deep learning technologies, training and\ndelivery of a practically serviceable model is still a highly time-consuming\nprocess. Furthermore, a resulting model is usually too generic and heavyweight,\nand hence essentially goes through another expensive model compression phase to\nfit in a resource-limited device like embedded systems. Inspired by the fact\nthat a machine learning task specifically requested by mobile users is often\nmuch simpler than it is supported by a massive generic model, this paper\nproposes a framework, called Pool of Experts (PoE), that instantly builds a\nlightweight and task-specific model without any training process. For a\nrealtime model querying service, PoE first extracts a pool of primitive\ncomponents, called experts, from a well-trained and sufficiently generic\nnetwork by exploiting a novel conditional knowledge distillation method, and\nthen performs our train-free knowledge consolidation to quickly combine\nnecessary experts into a lightweight network for a target task. Thanks to this\ntrain-free property, in our thorough empirical study, PoE can build a fairly\naccurate yet compact model in a realtime manner, whereas it takes a few minutes\nper query for the other training methods to achieve a similar level of the\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 06:31:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kim", "Hakbin", ""], ["Choi", "Dong-Wan", ""]]}, {"id": "2107.01358", "submitter": "Girish Varma", "authors": "Sandeep Nagar, Marius Dufraisse, Girish Varma", "title": "CInC Flow: Characterizable Invertible 3x3 Convolution", "comments": "Accepted for the 4th Workshop on Tractable Probabilistic\n  Modeling,(UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are an essential alternative to GANs for generative\nmodelling, which can be optimized directly on the maximum likelihood of the\ndataset. They also allow computation of the exact latent vector corresponding\nto an image since they are composed of invertible transformations. However, the\nrequirement of invertibility of the transformation prevents standard and\nexpressive neural network models such as CNNs from being directly used.\nEmergent convolutions were proposed to construct an invertible 3$\\times$3 CNN\nlayer using a pair of masked CNN layers, making them inefficient. We study\nconditions such that 3$\\times$3 CNNs are invertible, allowing them to construct\nexpressive normalizing flows. We derive necessary and sufficient conditions on\na padded CNN for it to be invertible. Our conditions for invertibility are\nsimple, can easily be maintained during the training process. Since we require\nonly a single CNN layer for every effective invertible CNN layer, our approach\nis more efficient than emerging convolutions. We also proposed a coupling\nmethod, Quad-coupling. We benchmark our approach and show similar performance\nresults to emergent convolutions while improving the model's efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 06:55:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nagar", "Sandeep", ""], ["Dufraisse", "Marius", ""], ["Varma", "Girish", ""]]}, {"id": "2107.01360", "submitter": "Yue Jin", "authors": "Yue Jin, Yue Zhang, Tao Qin, Xudong Zhang, Jian Yuan, Houqiang Li,\n  Tie-Yan Liu", "title": "Supervised Off-Policy Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) leverages data generated by other policies to\nevaluate a target policy. Previous OPE methods mainly focus on precisely\nestimating the true performance of a policy. We observe that in many\napplications, (1) the end goal of OPE is to compare two or multiple candidate\npolicies and choose a good one, which is actually a much simpler task than\nevaluating their true performance; and (2) there are usually multiple policies\nthat have been deployed in real-world systems and thus whose true performance\nis known through serving real users. Inspired by the two observations, in this\nwork, we define a new problem, supervised off-policy ranking (SOPR), which aims\nto rank a set of new/target policies based on supervised learning by leveraging\noff-policy data and policies with known performance. We further propose a\nmethod for supervised off-policy ranking that learns a policy scoring model by\ncorrectly ranking training policies with known performance rather than\nestimating their precise performance. Our method leverages logged states and\npolicies to learn a Transformer based model that maps offline interaction data\nincluding logged states and the actions taken by a target policy on these\nstates to a score. Experiments on different games, datasets, training policy\nsets, and test policy sets show that our method outperforms strong baseline OPE\nmethods in terms of both rank correlation and performance gap between the truly\nbest and the best of the ranked top three policies. Furthermore, our method is\nmore stable than baseline methods.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 07:01:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Jin", "Yue", ""], ["Zhang", "Yue", ""], ["Qin", "Tao", ""], ["Zhang", "Xudong", ""], ["Yuan", "Jian", ""], ["Li", "Houqiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2107.01366", "submitter": "Eugene Kharitonov", "authors": "Rahma Chaabouni, Roberto Dess\\`i, Eugene Kharitonov", "title": "Can Transformers Jump Around Right in Natural Language? Assessing\n  Performance Transfer from SCAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite their practical success, modern seq2seq architectures are unable to\ngeneralize systematically on several SCAN tasks. Hence, it is not clear if\nSCAN-style compositional generalization is useful in realistic NLP tasks. In\nthis work, we study the benefit that such compositionality brings about to\nseveral machine translation tasks. We present several focused modifications of\nTransformer that greatly improve generalization capabilities on SCAN and select\none that remains on par with a vanilla Transformer on a standard machine\ntranslation (MT) task. Next, we study its performance in low-resource settings\nand on a newly introduced distribution-shifted English-French translation task.\nOverall, we find that improvements of a SCAN-capable model do not directly\ntransfer to the resource-rich MT setup. In contrast, in the low-resource setup,\ngeneral modifications lead to an improvement of up to 13.1% BLEU score w.r.t. a\nvanilla Transformer. Similarly, an improvement of 14% in an accuracy-based\nmetric is achieved in the introduced compositional English-French translation\ntask. This provides experimental evidence that the compositional generalization\nassessed in SCAN is particularly useful in resource-starved and domain-shifted\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 07:45:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Dess\u00ec", "Roberto", ""], ["Kharitonov", "Eugene", ""]]}, {"id": "2107.01372", "submitter": "Eungyeup Kim", "authors": "Eungyeup Kim, Jungsoo Lee, Juyoung Lee, Jihyeon Lee, Jaegul Choo", "title": "Learning Debiased Representation via Disentangled Feature Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image classification models tend to make decisions based on peripheral\nattributes of data items that have strong correlation with a target variable\n(i.e., dataset bias). These biased models suffer from the poor generalization\ncapability when evaluated on unbiased datasets. Existing approaches for\ndebiasing often identify and emphasize those samples with no such correlation\n(i.e., bias-conflicting) without defining the bias type in advance. However,\nsuch bias-conflicting samples are significantly scarce in biased datasets,\nlimiting the debiasing capability of these approaches. This paper first\npresents an empirical analysis revealing that training with \"diverse\"\nbias-conflicting samples beyond a given training set is crucial for debiasing\nas well as the generalization capability. Based on this observation, we propose\na novel feature-level data augmentation technique in order to synthesize\ndiverse bias-conflicting samples. To this end, our method learns the\ndisentangled representation of (1) the intrinsic attributes (i.e., those\ninherently defining a certain class) and (2) bias attributes (i.e., peripheral\nattributes causing the bias), from a large number of bias-aligned samples, the\nbias attributes of which have strong correlation with the target variable.\nUsing the disentangled representation, we synthesize bias-conflicting samples\nthat contain the diverse intrinsic attributes of bias-aligned samples by\nswapping their latent features. By utilizing these diversified bias-conflicting\nfeatures during the training, our approach achieves superior classification\naccuracy and debiasing results against the existing baselines on both synthetic\nas well as real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 08:03:25 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kim", "Eungyeup", ""], ["Lee", "Jungsoo", ""], ["Lee", "Juyoung", ""], ["Lee", "Jihyeon", ""], ["Choo", "Jaegul", ""]]}, {"id": "2107.01390", "submitter": "Thai Hung Le", "authors": "Hung Le", "title": "Memory and attention in deep learning", "comments": "PHD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligence necessitates memory. Without memory, humans fail to perform\nvarious nontrivial tasks such as reading novels, playing games or solving\nmaths. As the ultimate goal of machine learning is to derive intelligent\nsystems that learn and act automatically just like human, memory construction\nfor machine is inevitable. Artificial neural networks model neurons and\nsynapses in the brain by interconnecting computational units via weights, which\nis a typical class of machine learning algorithms that resembles memory\nstructure. Their descendants with more complicated modeling techniques (a.k.a\ndeep learning) have been successfully applied to many practical problems and\ndemonstrated the importance of memory in the learning process of machinery\nsystems. Recent progresses on modeling memory in deep learning have revolved\naround external memory constructions, which are highly inspired by\ncomputational Turing models and biological neuronal systems. Attention\nmechanisms are derived to support acquisition and retention operations on the\nexternal memory. Despite the lack of theoretical foundations, these approaches\nhave shown promises to help machinery systems reach a higher level of\nintelligence. The aim of this thesis is to advance the understanding on memory\nand attention in deep learning. Its contributions include: (i) presenting a\ncollection of taxonomies for memory, (ii) constructing new memory-augmented\nneural networks (MANNs) that support multiple control and memory units, (iii)\nintroducing variability via memory in sequential generative models, (iv)\nsearching for optimal writing operations to maximise the memorisation capacity\nin slot-based memory networks, and (v) simulating the Universal Turing Machine\nvia Neural Stored-program Memory-a new kind of external memory for neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:21:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Le", "Hung", ""]]}, {"id": "2107.01392", "submitter": "Ayushe Gangal", "authors": "Peeyush Kumar, Ayushe Gangal and Sunita Kumari", "title": "WisdomNet: Prognosis of COVID-19 with Slender Prospect of False Negative\n  Cases and Vaticinating the Probability of Maturation to ARDS using\n  Posteroanterior Chest X-Rays", "comments": "10 pages, 4 figures, 1 table", "journal-ref": "J Pure Appl Microbiol. 2020;14(suppl 1):869-878, Article Number:\n  6236", "doi": "10.22207/JPAM.14.SPL1.24", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Coronavirus is a large virus family consisting of diverse viruses, some of\nwhich disseminate among mammals and others cause sickness among humans.\nCOVID-19 is highly contagious and is rapidly spreading, rendering its early\ndiagnosis of preeminent status. Researchers, medical specialists and\norganizations all over the globe have been working tirelessly to combat this\nvirus and help in its containment. In this paper, a novel neural network called\nWisdomNet has been proposed, for the diagnosis of COVID-19 using chest X-rays.\nThe WisdomNet uses the concept of Wisdom of Crowds as its founding idea. It is\na two-layered convolutional Neural Network (CNN), which takes chest x-ray\nimages as input. Both layers of the proposed neural network consist of a number\nof neural networks each. The dataset used for this study consists of chest\nx-ray images of COVID-19 positive patients, compiled and shared by Dr. Cohen on\nGitHub, and the chest x-ray images of healthy lungs and lungs affected by viral\nand bacterial pneumonia were obtained from Kaggle. The network not only\npinpoints the presence of COVID-19, but also gives the probability of the\ndisease maturing into Acute Respiratory Distress Syndrome (ARDS). Thus,\npredicting the progression of the disease in the COVID-19 positive patients.\nThe network also slender the occurrences of false negative cases by employing a\nhigh threshold value, thus aids in curbing the spread of the disease and gives\nan accuracy of 100% for successfully predicting COVID-19 among the chest x-rays\nof patients affected with COVID-19, bacterial and viral pneumonia.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:55:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kumar", "Peeyush", ""], ["Gangal", "Ayushe", ""], ["Kumari", "Sunita", ""]]}, {"id": "2107.01400", "submitter": "Yaniv Shulman", "authors": "Yaniv Shulman", "title": "Exact Backpropagation in Binary Weighted Networks with Group Weight\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantization based model compression serves as high performing and fast\napproach for inference that yields models which are highly compressed when\ncompared to their full-precision floating point counterparts. The most extreme\nquantization is a 1-bit representation of parameters such that they have only\ntwo possible values, typically -1(0) or +1, enabling efficient implementation\nof the ubiquitous dot product using only additions. The main contribution of\nthis work is the introduction of a method to smooth the combinatorial problem\nof determining a binary vector of weights to minimize the expected loss for a\ngiven objective by means of empirical risk minimization with backpropagation.\nThis is achieved by approximating a multivariate binary state over the weights\nutilizing a deterministic and differentiable transformation of real-valued,\ncontinuous parameters. The proposed method adds little overhead in training,\ncan be readily applied without any substantial modifications to the original\narchitecture, does not introduce additional saturating nonlinearities or\nauxiliary losses, and does not prohibit applying other methods for binarizing\nthe activations. Contrary to common assertions made in the literature, it is\ndemonstrated that binary weighted networks can train well with the same\nstandard optimization techniques and similar hyperparameter settings as their\nfull-precision counterparts, specifically momentum SGD with large learning\nrates and $L_2$ regularization. To conclude experiments demonstrate the method\nperforms remarkably well across a number of inductive image classification\ntasks with various architectures compared to their full-precision counterparts.\nThe source code is publicly available at\nhttps://bitbucket.org/YanivShu/binary_weighted_networks_public.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 10:29:34 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 03:22:29 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Shulman", "Yaniv", ""]]}, {"id": "2107.01407", "submitter": "Lionel Blond\\'e", "authors": "Lionel Blond\\'e, Alexandros Kalousis", "title": "Where is the Grass Greener? Revisiting Generalized Policy Iteration for\n  Offline Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of state-of-the-art baselines in the offline RL regime varies\nwidely over the spectrum of dataset qualities, ranging from \"far-from-optimal\"\nrandom data to \"close-to-optimal\" expert demonstrations. We re-implement these\nunder a fair, unified, and highly factorized framework, and show that when a\ngiven baseline outperforms its competing counterparts on one end of the\nspectrum, it never does on the other end. This consistent trend prevents us\nfrom naming a victor that outperforms the rest across the board. We attribute\nthe asymmetry in performance between the two ends of the quality spectrum to\nthe amount of inductive bias injected into the agent to entice it to posit that\nthe behavior underlying the offline dataset is optimal for the task. The more\nbias is injected, the higher the agent performs, provided the dataset is\nclose-to-optimal. Otherwise, its effect is brutally detrimental. Adopting an\nadvantage-weighted regression template as base, we conduct an investigation\nwhich corroborates that injections of such optimality inductive bias, when not\ndone parsimoniously, makes the agent subpar in the datasets it was dominant as\nsoon as the offline policy is sub-optimal. In an effort to design methods that\nperform well across the whole spectrum, we revisit the generalized policy\niteration scheme for the offline regime, and study the impact of nine distinct\nnewly-introduced proposal distributions over actions, involved in proposed\ngeneralization of the policy evaluation and policy improvement update rules. We\nshow that certain orchestrations strike the right balance and can improve the\nperformance on one end of the spectrum without harming it on the other end.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:00:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Blond\u00e9", "Lionel", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "2107.01408", "submitter": "Hyungi Lee", "authors": "Hyungi Lee, Eunggu Yun, Hongseok Yang, Juho Lee", "title": "Scale Mixtures of Neural Network Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works have revealed that infinitely-wide feed-forward or recurrent\nneural networks of any architecture correspond to Gaussian processes referred\nto as $\\mathrm{NNGP}$. While these works have extended the class of neural\nnetworks converging to Gaussian processes significantly, however, there has\nbeen little focus on broadening the class of stochastic processes that such\nneural networks converge to. In this work, inspired by the scale mixture of\nGaussian random variables, we propose the scale mixture of $\\mathrm{NNGP}$ for\nwhich we introduce a prior distribution on the scale of the last-layer\nparameters. We show that simply introducing a scale prior on the last-layer\nparameters can turn infinitely-wide neural networks of any architecture into a\nricher class of stochastic processes. Especially, with certain scale priors, we\nobtain heavy-tailed stochastic processes, and we recover Student's $t$\nprocesses in the case of inverse gamma priors. We further analyze the\ndistributions of the neural networks initialized with our prior setting and\ntrained with gradient descents and obtain similar results as for\n$\\mathrm{NNGP}$. We present a practical posterior-inference algorithm for the\nscale mixture of $\\mathrm{NNGP}$ and empirically demonstrate its usefulness on\nregression and classification tasks.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:02:18 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lee", "Hyungi", ""], ["Yun", "Eunggu", ""], ["Yang", "Hongseok", ""], ["Lee", "Juho", ""]]}, {"id": "2107.01410", "submitter": "Amirhossein Nouranizadeh", "authors": "Amirhossein Nouranizadeh, Mohammadjavad Matinkia, Mohammad Rahmati,\n  Reza Safabakhsh", "title": "Maximum Entropy Weighted Independent Set Pooling for Graph Neural\n  Networks", "comments": "21 pages, 12 figures, under review in 35th Conference on Neural\n  Information Processing Systems (NeurIPS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel pooling layer for graph neural networks\nbased on maximizing the mutual information between the pooled graph and the\ninput graph. Since the maximum mutual information is difficult to compute, we\nemploy the Shannon capacity of a graph as an inductive bias to our pooling\nmethod. More precisely, we show that the input graph to the pooling layer can\nbe viewed as a representation of a noisy communication channel. For such a\nchannel, sending the symbols belonging to an independent set of the graph\nyields a reliable and error-free transmission of information. We show that\nreaching the maximum mutual information is equivalent to finding a maximum\nweight independent set of the graph where the weights convey entropy contents.\nThrough this communication theoretic standpoint, we provide a distinct\nperspective for posing the problem of graph pooling as maximizing the\ninformation transmission rate across a noisy communication channel, implemented\nby a graph neural network. We evaluate our method, referred to as Maximum\nEntropy Weighted Independent Set Pooling (MEWISPool), on graph classification\ntasks and the combinatorial optimization problem of the maximum independent\nset. Empirical results demonstrate that our method achieves the\nstate-of-the-art and competitive results on graph classification tasks and the\nmaximum independent set problem in several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:19:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nouranizadeh", "Amirhossein", ""], ["Matinkia", "Mohammadjavad", ""], ["Rahmati", "Mohammad", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "2107.01412", "submitter": "Sen Yan", "authors": "Wanyun Cui, Sen Yan", "title": "Isotonic Data Augmentation for Knowledge Distillation", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation uses both real hard labels and soft labels predicted\nby teacher models as supervision. Intuitively, we expect the soft labels and\nhard labels to be concordant w.r.t. their orders of probabilities. However, we\nfound critical order violations between hard labels and soft labels in\naugmented samples. For example, for an augmented sample $x=0.7*panda+0.3*cat$,\nwe expect the order of meaningful soft labels to be\n$P_\\text{soft}(panda|x)>P_\\text{soft}(cat|x)>P_\\text{soft}(other|x)$. But real\nsoft labels usually violate the order, e.g.\n$P_\\text{soft}(tiger|x)>P_\\text{soft}(panda|x)>P_\\text{soft}(cat|x)$. We\nattribute this to the unsatisfactory generalization ability of the teacher,\nwhich leads to the prediction error of augmented samples. Empirically, we found\nthe violations are common and injure the knowledge transfer. In this paper, we\nintroduce order restrictions to data augmentation for knowledge distillation,\nwhich is denoted as isotonic data augmentation (IDA). We use isotonic\nregression (IR) -- a classic technique from statistics -- to eliminate the\norder violations. We show that IDA can be modeled as a tree-structured IR\nproblem. We thereby adapt the classical IRT-BIN algorithm for optimal solutions\nwith $O(c \\log c)$ time complexity, where $c$ is the number of labels. In order\nto further reduce the time complexity, we also propose a GPU-friendly\napproximation with linear time complexity. We have verified on variant datasets\nand data augmentation techniques that our proposed IDA algorithms effectively\nincreases the accuracy of knowledge distillation by eliminating the rank\nviolations.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:34:44 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 05:39:45 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cui", "Wanyun", ""], ["Yan", "Sen", ""]]}, {"id": "2107.01460", "submitter": "Arnu Pretorius", "authors": "Arnu Pretorius, Kale-ab Tessera, Andries P. Smit, Claude Formanek, St\n  John Grimbly, Kevin Eloff, Siphelele Danisa, Lawrence Francis, Jonathan\n  Shock, Herman Kamper, Willie Brink, Herman Engelbrecht, Alexandre Laterre,\n  Karim Beguir", "title": "Mava: a research framework for distributed multi-agent reinforcement\n  learning", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breakthrough advances in reinforcement learning (RL) research have led to a\nsurge in the development and application of RL. To support the field and its\nrapid growth, several frameworks have emerged that aim to help the community\nmore easily build effective and scalable agents. However, very few of these\nframeworks exclusively support multi-agent RL (MARL), an increasingly active\nfield in itself, concerned with decentralised decision-making problems. In this\nwork, we attempt to fill this gap by presenting Mava: a research framework\nspecifically designed for building scalable MARL systems. Mava provides useful\ncomponents, abstractions, utilities and tools for MARL and allows for simple\nscaling for multi-process system training and execution, while providing a high\nlevel of flexibility and composability. Mava is built on top of DeepMind's Acme\n\\citep{hoffman2020acme}, and therefore integrates with, and greatly benefits\nfrom, a wide range of already existing single-agent RL components made\navailable in Acme. Several MARL baseline systems have already been implemented\nin Mava. These implementations serve as examples showcasing Mava's reusable\nfeatures, such as interchangeable system architectures, communication and\nmixing modules. Furthermore, these implementations allow existing MARL\nalgorithms to be easily reproduced and extended. We provide experimental\nresults for these implementations on a wide range of multi-agent environments\nand highlight the benefits of distributed system training.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 16:23:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Pretorius", "Arnu", ""], ["Tessera", "Kale-ab", ""], ["Smit", "Andries P.", ""], ["Formanek", "Claude", ""], ["Grimbly", "St John", ""], ["Eloff", "Kevin", ""], ["Danisa", "Siphelele", ""], ["Francis", "Lawrence", ""], ["Shock", "Jonathan", ""], ["Kamper", "Herman", ""], ["Brink", "Willie", ""], ["Engelbrecht", "Herman", ""], ["Laterre", "Alexandre", ""], ["Beguir", "Karim", ""]]}, {"id": "2107.01461", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Hu Hu, Sabato Marco Siniscalchi, Qing Wang, Yuyang\n  Wang, Xianjun Xia, Yuanjun Zhao, Yuzhong Wu, Yannan Wang, Jun Du, Chin-Hui\n  Lee", "title": "A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust\n  Neural Acoustic Scene Classification", "comments": "5 figures. DCASE 2021. The project started in November 2020", "journal-ref": "Detection and Classification of Acoustic Scenes and Events\n  (DCASE), 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose a novel neural model compression strategy combining data\naugmentation, knowledge transfer, pruning, and quantization for device-robust\nacoustic scene classification (ASC). Specifically, we tackle the ASC task in a\nlow-resource environment leveraging a recently proposed advanced neural network\npruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a\nsub-network neural model associated with a small amount non-zero model\nparameters. The effectiveness of LTH for low-complexity acoustic modeling is\nassessed by investigating various data augmentation and compression schemes,\nand we report an efficient joint framework for low-complexity multi-device ASC,\ncalled Acoustic Lottery. Acoustic Lottery could compress an ASC model over\n$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and\nLog loss of 0.76) compared to its not compressed seed model. All results\nreported in this work are based on a joint effort of four groups, namely\nGT-USTC-UKE-Tencent, aiming to address the \"Low-Complexity Acoustic Scene\nClassification (ASC) with Multiple Devices\" in the DCASE 2021 Challenge Task\n1a.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 16:25:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Hu", "Hu", ""], ["Siniscalchi", "Sabato Marco", ""], ["Wang", "Qing", ""], ["Wang", "Yuyang", ""], ["Xia", "Xianjun", ""], ["Zhao", "Yuanjun", ""], ["Wu", "Yuzhong", ""], ["Wang", "Yannan", ""], ["Du", "Jun", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2107.01466", "submitter": "Zhenyu Yuan", "authors": "Zhenyu Yuan, Yuxin Jiang, Jingjing Li, Handong Huang", "title": "A convolutional neural network for prestack fracture detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractures are widely developed in hydrocarbon reservoirs and constitute the\naccumulation spaces and transport channels of oil and gas. Fracture detection\nis a fundamental task for reservoir characterization. From prestack seismic\ngathers, anisotropic analysis and inversion were commonly applied to\ncharacterize the dominant orientations and relative intensities of fractures.\nHowever, the existing methods were mostly based on the vertical aligned facture\nhypothesis, it is impossible for them to recognize fracture dip. Furthermore,\nit is difficult or impractical for existing methods to attain the real fracture\ndensities. Based on data-driven deep learning, this paper designed a\nconvolutional neural network to perform prestack fracture detection.\nCapitalizing on the connections between seismic responses and fracture\nparameters, a suitable azimuth dataset was firstly generated through fracture\neffective medium modeling and anisotropic plane wave analyzing. Then a\nmulti-input and multi-output convolutional neural network was constructed to\nsimultaneously detect fracture density, dip and strike azimuth. The application\non a practical survey validated the effectiveness of the proposed CNN model.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 17:05:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yuan", "Zhenyu", ""], ["Jiang", "Yuxin", ""], ["Li", "Jingjing", ""], ["Huang", "Handong", ""]]}, {"id": "2107.01473", "submitter": "Anton Johansson", "authors": "Anton Johansson, Niklas Engsner, Claes Stranneg{\\aa}rd, Petter Mostad", "title": "Slope and generalization properties of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are very successful tools in for example advanced\nclassification. From a statistical point of view, fitting a neural network may\nbe seen as a kind of regression, where we seek a function from the input space\nto a space of classification probabilities that follows the \"general\" shape of\nthe data, but avoids overfitting by avoiding memorization of individual data\npoints. In statistics, this can be done by controlling the geometric complexity\nof the regression function. We propose to do something similar when fitting\nneural networks by controlling the slope of the network.\n  After defining the slope and discussing some of its theoretical properties,\nwe go on to show empirically in examples, using ReLU networks, that the\ndistribution of the slope of a well-trained neural network classifier is\ngenerally independent of the width of the layers in a fully connected network,\nand that the mean of the distribution only has a weak dependence on the model\narchitecture in general. The slope is of similar size throughout the relevant\nvolume, and varies smoothly. It also behaves as predicted in rescaling\nexamples. We discuss possible applications of the slope concept, such as using\nit as a part of the loss function or stopping criterion during network\ntraining, or ranking data sets in terms of their complexity.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 17:54:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Johansson", "Anton", ""], ["Engsner", "Niklas", ""], ["Stranneg\u00e5rd", "Claes", ""], ["Mostad", "Petter", ""]]}, {"id": "2107.01475", "submitter": "Binghui Wang", "authors": "Binghui Wang, Jiayi Guo, Ang Li, Yiran Chen, Hai Li", "title": "Privacy-Preserving Representation Learning on Graphs: A Mutual\n  Information Perspective", "comments": "Accepted by SIGKDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with graphs has attracted significant attention recently. Existing\nrepresentation learning methods on graphs have achieved state-of-the-art\nperformance on various graph-related tasks such as node classification, link\nprediction, etc. However, we observe that these methods could leak serious\nprivate information. For instance, one can accurately infer the links (or node\nidentity) in a graph from a node classifier (or link predictor) trained on the\nlearnt node representations by existing methods. To address the issue, we\npropose a privacy-preserving representation learning framework on graphs from\nthe \\emph{mutual information} perspective. Specifically, our framework includes\na primary learning task and a privacy protection task, and we consider node\nclassification and link prediction as the two tasks of interest. Our goal is to\nlearn node representations such that they can be used to achieve high\nperformance for the primary learning task, while obtaining performance for the\nprivacy protection task close to random guessing. We formally formulate our\ngoal via mutual information objectives. However, it is intractable to compute\nmutual information in practice. Then, we derive tractable variational bounds\nfor the mutual information terms, where each bound can be parameterized via a\nneural network. Next, we train these parameterized neural networks to\napproximate the true mutual information and learn privacy-preserving node\nrepresentations. We finally evaluate our framework on various graph datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 18:09:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Binghui", ""], ["Guo", "Jiayi", ""], ["Li", "Ang", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "2107.01477", "submitter": "Zhuohang Li", "authors": "Zhuohang Li, Luyang Liu, Jiaxin Zhang, Jian Liu", "title": "Byzantine-robust Federated Learning through Spatial-temporal Analysis of\n  Local Model Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) enables multiple distributed clients (e.g., mobile\ndevices) to collaboratively train a centralized model while keeping the\ntraining data locally on the client. Compared to traditional centralized\nmachine learning, FL offers many favorable features such as offloading\noperations which would usually be performed by a central server and reducing\nrisks of serious privacy leakage. However, Byzantine clients that send\nincorrect or disruptive updates due to system failures or adversarial attacks\nmay disturb the joint learning process, consequently degrading the performance\nof the resulting model. In this paper, we propose to mitigate these failures\nand attacks from a spatial-temporal perspective. Specifically, we use a\nclustering-based method to detect and exclude incorrect updates by leveraging\ntheir geometric properties in the parameter space. Moreover, to further handle\nmalicious clients with time-varying behaviors, we propose to adaptively adjust\nthe learning rate according to momentum-based update speculation. Extensive\nexperiments on 4 public datasets demonstrate that our algorithm achieves\nenhanced robustness comparing to existing methods under both cross-silo and\ncross-device FL settings with faulty/malicious clients.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 18:48:11 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Zhuohang", ""], ["Liu", "Luyang", ""], ["Zhang", "Jiaxin", ""], ["Liu", "Jian", ""]]}, {"id": "2107.01495", "submitter": "Hejie Cui", "authors": "Hejie Cui, Zijie Lu, Pan Li, and Carl Yang", "title": "On Positional and Structural Node Features for Graph Neural Networks on\n  Non-attributed Graphs", "comments": "This paper has been accepted to the Sixth International Workshop on\n  Deep Learning on Graphs (DLG-KDD'21) (co-located with KDD'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in various graph-related\nproblems such as node classification and graph classification, where the\nsuperior performance is mainly established when natural node features are\navailable. However, it is not well understood how GNNs work without natural\nnode features, especially regarding the various ways to construct artificial\nones. In this paper, we point out the two types of artificial node\nfeatures,i.e., positional and structural node features, and provide insights on\nwhy each of them is more appropriate for certain tasks,i.e., positional node\nclassification, structural node classification, and graph classification.\nExtensive experimental results on 10 benchmark datasets validate our insights,\nthus leading to a practical guideline on the choices between different\nartificial node features for GNNs on non-attributed graphs. The code is\navailable at https://github.com/zjzijielu/gnn-exp/.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 20:37:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cui", "Hejie", ""], ["Lu", "Zijie", ""], ["Li", "Pan", ""], ["Yang", "Carl", ""]]}, {"id": "2107.01499", "submitter": "Shaoduo Gan", "authors": "Shaoduo Gan, Xiangru Lian, Rui Wang, Jianbin Chang, Chengjun Liu,\n  Hongmei Shi, Shengzhuo Zhang, Xianghong Li, Tengxu Sun, Jiawei Jiang, Binhang\n  Yuan, Sen Yang, Ji Liu, Ce Zhang", "title": "BAGUA: Scaling up Distributed Learning with System Relaxations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent years have witnessed a growing list of systems for distributed\ndata-parallel training. Existing systems largely fit into two paradigms, i.e.,\nparameter server and MPI-style collective operations. On the algorithmic side,\nresearchers have proposed a wide range of techniques to lower the communication\nvia system relaxations: quantization, decentralization, and communication\ndelay. However, most, if not all, existing systems only rely on standard\nsynchronous and asynchronous stochastic gradient (SG) based optimization,\ntherefore, cannot take advantage of all possible optimizations that the machine\nlearning community has been developing recently. Given this emerging gap\nbetween the current landscapes of systems and theory, we build BAGUA, a\ncommunication framework whose design goal is to provide a system abstraction\nthat is both flexible and modular to support state-of-the-art system relaxation\ntechniques of distributed training. Powered by the new system design, BAGUA has\na great ability to implement and extend various state-of-the-art distributed\nlearning algorithms. In a production cluster with up to 16 machines (128 GPUs),\nBAGUA can outperform PyTorch-DDP, Horovod and BytePS in the end-to-end training\ntime by a significant margin (up to 1.95 times) across a diverse range of\ntasks. Moreover, we conduct a rigorous tradeoff exploration showing that\ndifferent algorithms and system relaxations achieve the best performance over\ndifferent network conditions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 21:27:45 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 08:18:02 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 14:20:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Gan", "Shaoduo", ""], ["Lian", "Xiangru", ""], ["Wang", "Rui", ""], ["Chang", "Jianbin", ""], ["Liu", "Chengjun", ""], ["Shi", "Hongmei", ""], ["Zhang", "Shengzhuo", ""], ["Li", "Xianghong", ""], ["Sun", "Tengxu", ""], ["Jiang", "Jiawei", ""], ["Yuan", "Binhang", ""], ["Yang", "Sen", ""], ["Liu", "Ji", ""], ["Zhang", "Ce", ""]]}, {"id": "2107.01502", "submitter": "Hejie Cui", "authors": "Hejie Cui, Xinglong Liu, Ning Huang", "title": "Pulmonary Vessel Segmentation based on Orthogonal Fused U-Net++ of Chest\n  CT Images", "comments": "Published in Medical Image Computing and Computer Assisted\n  Intervention (MICCAI 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-32226-7_33", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pulmonary vessel segmentation is important for clinical diagnosis of\npulmonary diseases, while is also challenging due to the complicated structure.\nIn this work, we present an effective framework and refinement process of\npulmonary vessel segmentation from chest computed tomographic (CT) images. The\nkey to our approach is a 2.5D segmentation network applied from three\northogonal axes, which presents a robust and fully automated pulmonary vessel\nsegmentation result with lower network complexity and memory usage compared to\n3D networks. The slice radius is introduced to convolve the adjacent\ninformation of the center slice and the multi-planar fusion optimizes the\npresentation of intra- and inter- slice features. Besides, the tree-like\nstructure of the pulmonary vessel is extracted in the post-processing process,\nwhich is used for segmentation refining and pruning. In the evaluation\nexperiments, three fusion methods are tested and the most promising one is\ncompared with the state-of-the-art 2D and 3D structures on 300 cases of lung\nimages randomly selected from LIDC dataset. Our method outperforms other\nnetwork structures by a large margin and achieves by far the highest average\nDICE score of 0.9272 and precision of 0.9310, as per our knowledge from the\npulmonary vessel segmentation models available in the literature.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 21:46:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cui", "Hejie", ""], ["Liu", "Xinglong", ""], ["Huang", "Ning", ""]]}, {"id": "2107.01509", "submitter": "Max Simchowitz", "authors": "Max Simchowitz, Christopher Tosh, Akshay Krishnamurthy, Daniel Hsu,\n  Thodoris Lykouris, Miroslav Dud\\'ik, Robert E. Schapire", "title": "Bayesian decision-making under misspecified priors with applications to\n  meta-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling and other Bayesian sequential decision-making algorithms\nare among the most popular approaches to tackle explore/exploit trade-offs in\n(contextual) bandits. The choice of prior in these algorithms offers\nflexibility to encode domain knowledge but can also lead to poor performance\nwhen misspecified. In this paper, we demonstrate that performance degrades\ngracefully with misspecification. We prove that the expected reward accrued by\nThompson sampling (TS) with a misspecified prior differs by at most\n$\\tilde{\\mathcal{O}}(H^2 \\epsilon)$ from TS with a well specified prior, where\n$\\epsilon$ is the total-variation distance between priors and $H$ is the\nlearning horizon. Our bound does not require the prior to have any parametric\nform. For priors with bounded support, our bound is independent of the\ncardinality or structure of the action space, and we show that it is tight up\nto universal constants in the worst case.\n  Building on our sensitivity analysis, we establish generic PAC guarantees for\nalgorithms in the recently studied Bayesian meta-learning setting and derive\ncorollaries for various families of priors. Our results generalize along two\naxes: (1) they apply to a broader family of Bayesian decision-making\nalgorithms, including a Monte-Carlo implementation of the knowledge gradient\nalgorithm (KG), and (2) they apply to Bayesian POMDPs, the most general\nBayesian decision-making setting, encompassing contextual bandits as a special\ncase. Through numerical simulations, we illustrate how prior misspecification\nand the deployment of one-step look-ahead (as in KG) can impact the convergence\nof meta-learning in multi-armed and contextual bandits with structured and\ncorrelated priors.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 23:17:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Simchowitz", "Max", ""], ["Tosh", "Christopher", ""], ["Krishnamurthy", "Akshay", ""], ["Hsu", "Daniel", ""], ["Lykouris", "Thodoris", ""], ["Dud\u00edk", "Miroslav", ""], ["Schapire", "Robert E.", ""]]}, {"id": "2107.01516", "submitter": "Surya Kant Sahu", "authors": "Sai Mitheran, Abhinav Java, Surya Kant Sahu and Arshad Shaikh", "title": "Improved Representation Learning for Session-based Recommendation", "comments": "Submitted to AJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Session-based recommendation systems suggest relevant items to users by\nmodeling user behavior and preferences using short-term anonymous sessions.\nExisting methods leverage Graph Neural Networks (GNNs) that propagate and\naggregate information from neighboring nodes i.e., local message passing. Such\ngraph-based architectures have representational limits, as a single sub-graph\nis susceptible to overfit the sequential dependencies instead of accounting for\ncomplex transitions between items in different sessions. We propose using a\nTransformer in combination with a target attentive GNN, which allows richer\nRepresentation Learning. Our experimental results and ablation show that our\nproposed method outperforms the existing methods on real-world benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 00:57:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mitheran", "Sai", ""], ["Java", "Abhinav", ""], ["Sahu", "Surya Kant", ""], ["Shaikh", "Arshad", ""]]}, {"id": "2107.01525", "submitter": "Hongwei Zhang", "authors": "Hongwei Zhang and Weidong Zou and Hongbo Zhao and Qi Ming and Tijin\n  Yan and Yuanqing Xia and Weipeng Cao", "title": "AdaL: Adaptive Gradient Transformation Contributes to Convergences and\n  Generalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive optimization methods have been widely used in deep learning. They\nscale the learning rates adaptively according to the past gradient, which has\nbeen shown to be effective to accelerate the convergence. However, they suffer\nfrom poor generalization performance compared with SGD. Recent studies point\nthat smoothing exponential gradient noise leads to generalization degeneration\nphenomenon. Inspired by this, we propose AdaL, with a transformation on the\noriginal gradient. AdaL accelerates the convergence by amplifying the gradient\nin the early stage, as well as dampens the oscillation and stabilizes the\noptimization by shrinking the gradient later. Such modification alleviates the\nsmoothness of gradient noise, which produces better generalization performance.\nWe have theoretically proved the convergence of AdaL and demonstrated its\neffectiveness on several benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 02:55:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Hongwei", ""], ["Zou", "Weidong", ""], ["Zhao", "Hongbo", ""], ["Ming", "Qi", ""], ["Yan", "Tijin", ""], ["Xia", "Yuanqing", ""], ["Cao", "Weipeng", ""]]}, {"id": "2107.01528", "submitter": "Jiexia Ye", "authors": "Jiexia Ye, Furong Zheng, Juanjuan Zhao, Kejiang Ye, Chengzhong Xu", "title": "Incorporating Reachability Knowledge into a Multi-Spatial Graph\n  Convolution Based Seq2Seq Model for Traffic Forecasting", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate traffic state prediction is the foundation of transportation control\nand guidance. It is very challenging due to the complex spatiotemporal\ndependencies in traffic data. Existing works cannot perform well for multi-step\ntraffic prediction that involves long future time period. The spatiotemporal\ninformation dilution becomes serve when the time gap between input step and\npredicted step is large, especially when traffic data is not sufficient or\nnoisy. To address this issue, we propose a multi-spatial graph convolution\nbased Seq2Seq model. Our main novelties are three aspects: (1) We enrich the\nspatiotemporal information of model inputs by fusing multi-view features (time,\nlocation and traffic states) (2) We build multiple kinds of spatial\ncorrelations based on both prior knowledge and data-driven knowledge to improve\nmodel performance especially in insufficient or noisy data cases. (3) A\nspatiotemporal attention mechanism based on reachability knowledge is novelly\ndesigned to produce high-level features fed into decoder of Seq2Seq directly to\nease information dilution. Our model is evaluated on two real world traffic\ndatasets and achieves better performance than other competitors.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 03:23:30 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ye", "Jiexia", ""], ["Zheng", "Furong", ""], ["Zhao", "Juanjuan", ""], ["Ye", "Kejiang", ""], ["Xu", "Chengzhong", ""]]}, {"id": "2107.01529", "submitter": "Shahpar Yakhchi", "authors": "Shahpar Yakhchi", "title": "Learning Complex Users' Preferences for Recommender Systems", "comments": "269 pages, 43 figures, 26 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems (RSs) have emerged as very useful tools to help customers\nwith their decision-making process, find items of their interest, and alleviate\nthe information overload problem. There are two different lines of approaches\nin RSs: (1) general recommenders with the main goal of discovering long-term\nusers' preferences, and (2) sequential recommenders with the main focus of\ncapturing short-term users' preferences in a session of user-item interaction\n(here, a session refers to a record of purchasing multiple items in one\nshopping event). While considering short-term users' preferences may satisfy\ntheir current needs and interests, long-term users' preferences provide users\nwith the items that they may interact with, eventually. In this thesis, we\nfirst focus on improving the performance of general RSs. Most of the existing\ngeneral RSs tend to exploit the users' rating patterns on common items to\ndetect similar users. The data sparsity problem (i.e. the lack of available\ninformation) is one of the major challenges for the current general RSs, and\nthey may fail to have any recommendations when there are no common items of\ninterest among users. We call this problem data sparsity with no feedback on\ncommon items (DSW-n-FCI). To overcome this problem, we propose a\npersonality-based RS in which similar users are identified based on the\nsimilarity of their personality traits.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 03:25:15 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yakhchi", "Shahpar", ""]]}, {"id": "2107.01557", "submitter": "Sandeep Kumar Singh", "authors": "Sandeep Kumar Singh, Jaya Shradha Fowdur, Jakob Gawlikowski and Daniel\n  Medina", "title": "Leveraging Evidential Deep Learning Uncertainties with Graph-based\n  Clustering to Detect Anomalies", "comments": "Under submission in a Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding and representing traffic patterns are key to detecting\nanomalies in the maritime domain. To this end, we propose a novel graph-based\ntraffic representation and association scheme to cluster trajectories of\nvessels using automatic identification system (AIS) data. We utilize the\n(un)clustered data to train a recurrent neural network (RNN)-based evidential\nregression model, which can predict a vessel's trajectory at future timesteps\nwith its corresponding prediction uncertainty. This paper proposes the usage of\na deep learning (DL)-based uncertainty estimation in detecting maritime\nanomalies, such as unusual vessel maneuvering. Furthermore, we utilize the\nevidential deep learning classifiers to detect unusual turns of vessels and the\nloss of AIS signal using predicted class probabilities with associated\nuncertainties. Our experimental results suggest that using graph-based\nclustered data improves the ability of the DL models to learn the\ntemporal-spatial correlation of data and associated uncertainties. Using\ndifferent AIS datasets and experiments, we demonstrate that the estimated\nprediction uncertainty yields fundamental information for the detection of\ntraffic anomalies in the maritime and, possibly in other domains.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 06:31:59 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Singh", "Sandeep Kumar", ""], ["Fowdur", "Jaya Shradha", ""], ["Gawlikowski", "Jakob", ""], ["Medina", "Daniel", ""]]}, {"id": "2107.01559", "submitter": "Ao Liu", "authors": "Ao Liu, Lirong Xia", "title": "Smoothed Differential Privacy", "comments": "9 Page main text + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) is a widely-accepted and widely-applied notion of\nprivacy based on worst-case analysis. Often, DP classifies most mechanisms\nwithout external noise as non-private [Dwork et al., 2014], and external\nnoises, such as Gaussian noise or Laplacian noise [Dwork et al., 2006], are\nintroduced to improve privacy. In many real-world applications, however, adding\nexternal noise is undesirable and sometimes prohibited. For example,\npresidential elections often require a deterministic rule to be used [Liu et\nal., 2020], and small noises can lead to dramatic decreases in the prediction\naccuracy of deep neural networks, especially the underrepresented classes\n[Bagdasaryan et al., 2019].\n  In this paper, we propose a natural extension and relaxation of DP following\nthe worst average-case idea behind the celebrated smoothed analysis [Spielman\nand Teng, 2004]. Our notion, the smoothed DP, can effectively measure the\nprivacy leakage of mechanisms without external noises under realistic settings.\n  We prove several strong properties of the smoothed DP, including\ncomposability, robustness to post-processing and etc. We proved that any\ndiscrete mechanism with sampling procedures is more private than what DP\npredicts. In comparison, many continuous mechanisms with sampling procedures\nare still non-private under smoothed DP. Experimentally, we first verified that\nthe discrete sampling mechanisms are private in real-world elections. Then, we\napply the smoothed DP notion on quantized gradient descent, which indicates\nsome neural networks can be private without adding any extra noises. We believe\nthat these results contribute to the theoretical foundation of realistic\nprivacy measures beyond worst-case analysis.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 06:55:45 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 18:30:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liu", "Ao", ""], ["Xia", "Lirong", ""]]}, {"id": "2107.01561", "submitter": "Ao Liu", "authors": "Ao Liu, Xiaoyu Chen, Sijia Liu, Lirong Xia, Chuang Gan", "title": "Certifiably Robust Interpretation via Renyi Differential Privacy", "comments": "19 page main text + appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent discovery that the interpretation maps of CNNs could\neasily be manipulated by adversarial attacks against network interpretability,\nwe study the problem of interpretation robustness from a new perspective of\n\\Renyi differential privacy (RDP). The advantages of our Renyi-Robust-Smooth\n(RDP-based interpretation method) are three-folds. First, it can offer provable\nand certifiable top-$k$ robustness. That is, the top-$k$ important attributions\nof the interpretation map are provably robust under any input perturbation with\nbounded $\\ell_d$-norm (for any $d\\geq 1$, including $d = \\infty$). Second, our\nproposed method offers $\\sim10\\%$ better experimental robustness than existing\napproaches in terms of the top-$k$ attributions. Remarkably, the accuracy of\nRenyi-Robust-Smooth also outperforms existing approaches. Third, our method can\nprovide a smooth tradeoff between robustness and computational efficiency.\nExperimentally, its top-$k$ attributions are {\\em twice} more robust than\nexisting approaches when the computational resources are highly constrained.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 06:58:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liu", "Ao", ""], ["Chen", "Xiaoyu", ""], ["Liu", "Sijia", ""], ["Xia", "Lirong", ""], ["Gan", "Chuang", ""]]}, {"id": "2107.01562", "submitter": "Boris Hanin", "authors": "Boris Hanin", "title": "Random Neural Networks in the Infinite Width Limit as Gaussian Processes", "comments": "26p", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article gives a new proof that fully connected neural networks with\nrandom weights and biases converge to Gaussian processes in the regime where\nthe input dimension, output dimension, and depth are kept fixed, while the\nhidden layer widths tend to infinity. Unlike prior work, convergence is shown\nassuming only moment conditions for the distribution of weights and for quite\ngeneral non-linearities.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 07:00:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hanin", "Boris", ""]]}, {"id": "2107.01569", "submitter": "Tomohiro Tanaka", "authors": "Tomohiro Tanaka, Ryo Masumura, Mana Ihori, Akihiko Takashima, Takafumi\n  Moriya, Takanori Ashihara, Shota Orihashi, Naoki Makishima", "title": "Cross-Modal Transformer-Based Neural Correction Models for Automatic\n  Speech Recognition", "comments": "Accepted to Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cross-modal transformer-based neural correction models that\nrefines the output of an automatic speech recognition (ASR) system so as to\nexclude ASR errors. Generally, neural correction models are composed of\nencoder-decoder networks, which can directly model sequence-to-sequence mapping\nproblems. The most successful method is to use both input speech and its ASR\noutput text as the input contexts for the encoder-decoder networks. However,\nthe conventional method cannot take into account the relationships between\nthese two different modal inputs because the input contexts are separately\nencoded for each modal. To effectively leverage the correlated information\nbetween the two different modal inputs, our proposed models encode two\ndifferent contexts jointly on the basis of cross-modal self-attention using a\ntransformer. We expect that cross-modal self-attention can effectively capture\nthe relationships between two different modals for refining ASR hypotheses. We\nalso introduce a shallow fusion technique to efficiently integrate the\nfirst-pass ASR model and our proposed neural correction model. Experiments on\nJapanese natural language ASR tasks demonstrated that our proposed models\nachieve better ASR performance than conventional neural correction models.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 07:58:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Tanaka", "Tomohiro", ""], ["Masumura", "Ryo", ""], ["Ihori", "Mana", ""], ["Takashima", "Akihiko", ""], ["Moriya", "Takafumi", ""], ["Ashihara", "Takanori", ""], ["Orihashi", "Shota", ""], ["Makishima", "Naoki", ""]]}, {"id": "2107.01590", "submitter": "Deyu Ming", "authors": "Deyu Ming and Daniel Williamson and Serge Guillas", "title": "Deep Gaussian Process Emulation using Stochastic Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep Gaussian process (DGP) inference method for computer\nmodel emulation using stochastic imputation. By stochastically imputing the\nlatent layers, the approach transforms the DGP into the linked GP, a\nstate-of-the-art surrogate model formed by linking a system of feed-forward\ncoupled GPs. This transformation renders a simple while efficient DGP training\nprocedure that only involves optimizations of conventional stationary GPs. In\naddition, the analytically tractable mean and variance of the linked GP allows\none to implement predictions from DGP emulators in a fast and accurate manner.\nWe demonstrate the method in a series of synthetic examples and real-world\napplications, and show that it is a competitive candidate for efficient DGP\nsurrogate modeling in comparison to the variational inference and the\nfully-Bayesian approach. A $\\texttt{Python}$ package $\\texttt{dgpsi}$\nimplementing the method is also produced and available at\nhttps://github.com/mingdeyu/DGP.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 10:46:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ming", "Deyu", ""], ["Williamson", "Daniel", ""], ["Guillas", "Serge", ""]]}, {"id": "2107.01595", "submitter": "Panayotis Mertikopoulos", "authors": "Saeed Hadikhanloo and Rida Laraki and Panayotis Mertikopoulos and\n  Sylvain Sorin", "title": "Learning in nonatomic games, Part I: Finite action spaces and population\n  games", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the long-run behavior of a wide range of dynamics for learning in\nnonatomic games, in both discrete and continuous time. The class of dynamics\nunder consideration includes fictitious play and its regularized variants, the\nbest-reply dynamics (again, possibly regularized), as well as the dynamics of\ndual averaging / \"follow the regularized leader\" (which themselves include as\nspecial cases the replicator dynamics and Friedman's projection dynamics). Our\nanalysis concerns both the actual trajectory of play and its time-average, and\nwe cover potential and monotone games, as well as games with an evolutionarily\nstable state (global or otherwise). We focus exclusively on games with finite\naction spaces; nonatomic games with continuous action spaces are treated in\ndetail in Part II of this paper.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 11:20:45 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hadikhanloo", "Saeed", ""], ["Laraki", "Rida", ""], ["Mertikopoulos", "Panayotis", ""], ["Sorin", "Sylvain", ""]]}, {"id": "2107.01598", "submitter": "Mohammad Rostami", "authors": "Mohammad Rostami, Aram Galstyan", "title": "Domain Adaptation for Sentiment Analysis Using Increased Intraclass\n  Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is a costly yet necessary task for enterprises to study\nthe opinions of their customers to improve their products and to determine\noptimal marketing strategies. Due to the existence of a wide range of domains\nacross different products and services, cross-domain sentiment analysis methods\nhave received significant attention. These methods mitigate the domain gap\nbetween different applications by training cross-domain generalizable\nclassifiers which help to relax the need for data annotation for each domain.\nMost existing methods focus on learning domain-agnostic representations that\nare invariant with respect to both the source and the target domains. As a\nresult, a classifier that is trained using the source domain annotated data\nwould generalize well in a related target domain. We introduce a new domain\nadaptation method which induces large margins between different classes in an\nembedding space. This embedding space is trained to be domain-agnostic by\nmatching the data distributions across the domains. Large intraclass margins in\nthe source domain help to reduce the effect of \"domain shift\" on the classifier\nperformance in the target domain. Theoretical and empirical analysis are\nprovided to demonstrate that the proposed method is effective.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 11:39:12 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Rostami", "Mohammad", ""], ["Galstyan", "Aram", ""]]}, {"id": "2107.01606", "submitter": "Geir Kjetil Nilsen Mr", "authors": "Geir K. Nilsen and Antonella Z. Munthe-Kaas and Hans J. Skaug and\n  Morten Brun", "title": "A Comparison of the Delta Method and the Bootstrap in Deep Learning\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We validate the recently introduced deep learning classification adapted\nDelta method by a comparison with the classical Bootstrap. We show that there\nis a strong linear relationship between the quantified predictive epistemic\nuncertainty levels obtained from the two methods when applied on two\nLeNet-based neural network classifiers using the MNIST and CIFAR-10 datasets.\nFurthermore, we demonstrate that the Delta method offers a five times\ncomputation time reduction compared to the Bootstrap.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 12:40:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nilsen", "Geir K.", ""], ["Munthe-Kaas", "Antonella Z.", ""], ["Skaug", "Hans J.", ""], ["Brun", "Morten", ""]]}, {"id": "2107.01614", "submitter": "Marija Jegorova", "authors": "Marija Jegorova, Chaitanya Kaul, Charlie Mayor, Alison Q. O'Neil,\n  Alexander Weir, Roderick Murray-Smith, and Sotirios A. Tsaftaris", "title": "Survey: Leakage and Privacy at Inference Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leakage of data from publicly available Machine Learning (ML) models is an\narea of growing significance as commercial and government applications of ML\ncan draw on multiple sources of data, potentially including users' and clients'\nsensitive data. We provide a comprehensive survey of contemporary advances on\nseveral fronts, covering involuntary data leakage which is natural to ML\nmodels, potential malevolent leakage which is caused by privacy attacks, and\ncurrently available defence mechanisms. We focus on inference-time leakage, as\nthe most likely scenario for publicly available models. We first discuss what\nleakage is in the context of different data, tasks, and model architectures. We\nthen propose a taxonomy across involuntary and malevolent leakage, available\ndefences, followed by the currently available assessment metrics and\napplications. We conclude with outstanding challenges and open questions,\noutlining some promising directions for future research.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 12:59:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Jegorova", "Marija", ""], ["Kaul", "Chaitanya", ""], ["Mayor", "Charlie", ""], ["O'Neil", "Alison Q.", ""], ["Weir", "Alexander", ""], ["Murray-Smith", "Roderick", ""], ["Tsaftaris", "Sotirios A.", ""]]}, {"id": "2107.01615", "submitter": "Ralph Foorthuis", "authors": "Ralph Foorthuis", "title": "A Typology of Data Anomalies", "comments": "13 pages, 5 figures. Presented at the 17th International Conference\n  on Information Processing and Management of Uncertainty in Knowledge-Based\n  Systems (IPMU 2018). Note: for a fully developed and more detailed typology\n  of anomalies, see the follow-up publication 'On the Nature and Types of\n  Anomalies: A Review of Deviations in Data'. arXiv admin note: text overlap\n  with arXiv:2007.15634", "journal-ref": null, "doi": "10.1007/978-3-319-91476-3_3", "report-no": null, "categories": "cs.LG cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomalies are cases that are in some way unusual and do not appear to fit the\ngeneral patterns present in the dataset. Several conceptualizations exist to\ndistinguish between different types of anomalies. However, these are either too\nspecific to be generally applicable or so abstract that they neither provide\nconcrete insight into the nature of anomaly types nor facilitate the functional\nevaluation of anomaly detection algorithms. With the recent criticism on 'black\nbox' algorithms and analytics it has become clear that this is an undesirable\nsituation. This paper therefore introduces a general typology of anomalies that\noffers a clear and tangible definition of the different types of anomalies in\ndatasets. The typology also facilitates the evaluation of the functional\ncapabilities of anomaly detection algorithms and as a framework assists in\nanalyzing the conceptual levels of data, patterns and anomalies. Finally, it\nserves as an analytical tool for studying anomaly types from other typologies.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:12:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Foorthuis", "Ralph", ""]]}, {"id": "2107.01620", "submitter": "Mark Stamp", "authors": "Rakesh Nagaraju and Mark Stamp", "title": "Auxiliary-Classifier GAN for Malware Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks (GAN) are a class of powerful machine\nlearning techniques, where both a generative and discriminative model are\ntrained simultaneously. GANs have been used, for example, to successfully\ngenerate \"deep fake\" images. A recent trend in malware research consists of\ntreating executables as images and employing image-based analysis techniques.\nIn this research, we generate fake malware images using auxiliary classifier\nGANs (AC-GAN), and we consider the effectiveness of various techniques for\nclassifying the resulting images. Our results indicate that the resulting\nmulticlass classification problem is challenging, yet we can obtain strong\nresults when restricting the problem to distinguishing between real and fake\nsamples. While the AC-GAN generated images often appear to be very similar to\nreal malware images, we conclude that from a deep learning perspective, the\nAC-GAN generated samples do not rise to the level of deep fake malware images.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:15:03 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nagaraju", "Rakesh", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.01622", "submitter": "Xueying Zhan", "authors": "Xueying Zhan and Qing Li and Antoni B. Chan", "title": "Multiple-criteria Based Active Learning with Fixed-size Determinantal\n  Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning aims to achieve greater accuracy with less training data by\nselecting the most useful data samples from which it learns. Single-criterion\nbased methods (i.e., informativeness and representativeness based methods) are\nsimple and efficient; however, they lack adaptability to different real-world\nscenarios. In this paper, we introduce a multiple-criteria based active\nlearning algorithm, which incorporates three complementary criteria, i.e.,\ninformativeness, representativeness and diversity, to make appropriate\nselections in the active learning rounds under different data types. We\nconsider the selection process as a Determinantal Point Process, which good\nbalance among these criteria. We refine the query selection strategy by both\nselecting the hardest unlabeled data sample and biasing towards the classifiers\nthat are more suitable for the current data distribution. In addition, we also\nconsider the dependencies and relationships between these data points in data\nselection by means of centroidbased clustering approaches. Through evaluations\non synthetic and real-world datasets, we show that our method performs\nsignificantly better and is more stable than other multiple-criteria based AL\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:22:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhan", "Xueying", ""], ["Li", "Qing", ""], ["Chan", "Antoni B.", ""]]}, {"id": "2107.01627", "submitter": "Mark Stamp", "authors": "Lolitha Sresta Tupadha and Mark Stamp", "title": "Machine Learning for Malware Evolution Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malware evolves over time and antivirus must adapt to such evolution. Hence,\nit is critical to detect those points in time where malware has evolved so that\nappropriate countermeasures can be undertaken. In this research, we perform a\nvariety of experiments on a significant number of malware families to determine\nwhen malware evolution is likely to have occurred. All of the evolution\ndetection techniques that we consider are based on machine learning and can be\nfully automated -- in particular, no reverse engineering or other\nlabor-intensive manual analysis is required. Specifically, we consider analysis\nbased on hidden Markov models (HMM) and the word embedding techniques HMM2Vec\nand Word2Vec.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:47:06 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Tupadha", "Lolitha Sresta", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.01629", "submitter": "Ziwei Cong", "authors": "Ziwei Cong, Jia Liu, Puneet Manchanda", "title": "The Role of \"Live\" in Livestreaming Markets: Evidence Using Orthogonal\n  Random Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.GN q-fin.EC stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The common belief about the growing medium of livestreaming is that its value\nlies in its \"live\" component. In this paper, we leverage data from a large\nlivestreaming platform to examine this belief. We are able to do this as this\nplatform also allows viewers to purchase the recorded version of the\nlivestream. We summarize the value of livestreaming content by estimating how\ndemand responds to price before, on the day of, and after the livestream. We do\nthis by proposing a generalized Orthogonal Random Forest framework. This\nframework allows us to estimate heterogeneous treatment effects in the presence\nof high-dimensional confounders whose relationships with the treatment policy\n(i.e., price) are complex but partially known. We find significant dynamics in\nthe price elasticity of demand over the temporal distance to the scheduled\nlivestreaming day and after. Specifically, demand gradually becomes less price\nsensitive over time to the livestreaming day and is inelastic on the\nlivestreaming day. Over the post-livestream period, demand is still sensitive\nto price, but much less than the pre-livestream period. This indicates that the\nvlaue of livestreaming persists beyond the live component. Finally, we provide\nsuggestive evidence for the likely mechanisms driving our results. These are\nquality uncertainty reduction for the patterns pre- and post-livestream and the\npotential of real-time interaction with the creator on the day of the\nlivestream.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:50:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cong", "Ziwei", ""], ["Liu", "Jia", ""], ["Manchanda", "Puneet", ""]]}, {"id": "2107.01641", "submitter": "Gal Shachaf", "authors": "Gal Shachaf, Alon Brutzkus, Amir Globerson", "title": "A Theoretical Analysis of Fine-tuning with Linear Teachers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning is a common practice in deep learning, achieving excellent\ngeneralization results on downstream tasks using relatively little training\ndata. Although widely used in practice, it is lacking strong theoretical\nunderstanding. We analyze the sample complexity of this scheme for regression\nwith linear teachers in several architectures. Intuitively, the success of\nfine-tuning depends on the similarity between the source tasks and the target\ntask, however measuring it is non trivial. We show that a relevant measure\nconsiders the relation between the source task, the target task and the\ncovariance structure of the target data. In the setting of linear regression,\nwe show that under realistic settings a substantial sample complexity reduction\nis plausible when the above measure is low. For deep linear regression, we\npresent a novel result regarding the inductive bias of gradient-based training\nwhen the network is initialized with pretrained weights. Using this result we\nshow that the similarity measure for this setting is also affected by the depth\nof the network. We further present results on shallow ReLU models, and analyze\nthe dependence of sample complexity there on source and target tasks. We\nempirically demonstrate our results for both synthetic and realistic data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:15:50 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Shachaf", "Gal", ""], ["Brutzkus", "Alon", ""], ["Globerson", "Amir", ""]]}, {"id": "2107.01650", "submitter": "Weiming Zhi", "authors": "Weiming Zhi, Tin Lai, Lionel Ott, Edwin V. Bonilla, Fabio Ramos", "title": "Learning ODEs via Diffeomorphisms for Fast and Robust Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in differentiable numerical integrators have enabled the use of\ngradient descent techniques to learn ordinary differential equations (ODEs). In\nthe context of machine learning, differentiable solvers are central for Neural\nODEs (NODEs), a class of deep learning models with continuous depth, rather\nthan discrete layers. However, these integrators can be unsatisfactorily slow\nand inaccurate when learning systems of ODEs from long sequences, or when\nsolutions of the system vary at widely different timescales in each dimension.\nIn this paper we propose an alternative approach to learning ODEs from data: we\nrepresent the underlying ODE as a vector field that is related to another base\nvector field by a differentiable bijection, modelled by an invertible neural\nnetwork. By restricting the base ODE to be amenable to integration, we can\ndrastically speed up and improve the robustness of integration. We demonstrate\nthe efficacy of our method in training and evaluating continuous neural\nnetworks models, as well as in learning benchmark ODE systems. We observe\nimprovements of up to two orders of magnitude when integrating learned ODEs\nwith GPUs computation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:32:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhi", "Weiming", ""], ["Lai", "Tin", ""], ["Ott", "Lionel", ""], ["Bonilla", "Edwin V.", ""], ["Ramos", "Fabio", ""]]}, {"id": "2107.01655", "submitter": "Yang Li", "authors": "Yang Li, Tong Chen, Zi Huang", "title": "Attribute-aware Explainable Complementary Clothing Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling mix-and-match relationships among fashion items has become\nincreasingly demanding yet challenging for modern E-commerce recommender\nsystems. When performing clothes matching, most existing approaches leverage\nthe latent visual features extracted from fashion item images for compatibility\nmodelling, which lacks explainability of generated matching results and can\nhardly convince users of the recommendations. Though recent methods start to\nincorporate pre-defined attribute information (e.g., colour, style, length,\netc.) for learning item representations and improving the model\ninterpretability, their utilisation of attribute information is still mainly\nreserved for enhancing the learned item representations and generating\nexplanations via post-processing. As a result, this creates a severe bottleneck\nwhen we are trying to advance the recommendation accuracy and generating\nfine-grained explanations since the explicit attributes have only loose\nconnections to the actual recommendation process. This work aims to tackle the\nexplainability challenge in fashion recommendation tasks by proposing a novel\nAttribute-aware Fashion Recommender (AFRec). Specifically, AFRec recommender\nassesses the outfit compatibility by explicitly leveraging the extracted\nattribute-level representations from each item's visual feature. The attributes\nserve as the bridge between two fashion items, where we quantify the affinity\nof a pair of items through the learned compatibility between their attributes.\nExtensive experiments have demonstrated that, by making full use of the\nexplicit attributes in the recommendation process, AFRec is able to achieve\nstate-of-the-art recommendation accuracy and generate intuitive explanations at\nthe same time.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:56:07 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Yang", ""], ["Chen", "Tong", ""], ["Huang", "Zi", ""]]}, {"id": "2107.01657", "submitter": "Patrick Kage", "authors": "Patrick Kage, Pavlos Andreadis", "title": "Class Introspection: A Novel Technique for Detecting Unlabeled\n  Subclasses by Leveraging Classifier Explainability Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Detecting latent structure within a dataset is a crucial step in performing\nanalysis of a dataset. However, existing state-of-the-art techniques for\nsubclass discovery are limited: either they are limited to detecting very small\nnumbers of outliers or they lack the statistical power to deal with complex\ndata such as image or audio. This paper proposes a solution to this subclass\ndiscovery problem: by leveraging instance explanation methods, an existing\nclassifier can be extended to detect latent classes via differences in the\nclassifier's internal decisions about each instance. This works not only with\nsimple classification techniques but also with deep neural networks, allowing\nfor a powerful and flexible approach to detecting latent structure within\ndatasets. Effectively, this represents a projection of the dataset into the\nclassifier's \"explanation space,\" and preliminary results show that this\ntechnique outperforms the baseline for the detection of latent classes even\nwith limited processing. This paper also contains a pipeline for analyzing\nclassifiers automatically, and a web application for interactively exploring\nthe results from this technique.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:58:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kage", "Patrick", ""], ["Andreadis", "Pavlos", ""]]}, {"id": "2107.01658", "submitter": "Aramayis Dallakyan", "authors": "Aramayis Dallakyan and Mohsen Pourahmadi", "title": "Learning Bayesian Networks through Birkhoff Polytope: A Relaxation\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish a novel framework for learning a directed acyclic graph (DAG)\nwhen data are generated from a Gaussian, linear structural equation model. It\nconsists of two parts: (1) introduce a permutation matrix as a new parameter\nwithin a regularized Gaussian log-likelihood to represent variable ordering;\nand (2) given the ordering, estimate the DAG structure through sparse Cholesky\nfactor of the inverse covariance matrix. For permutation matrix estimation, we\npropose a relaxation technique that avoids the NP-hard combinatorial problem of\norder estimation. Given an ordering, a sparse Cholesky factor is estimated\nusing a cyclic coordinatewise descent algorithm which decouples row-wise. Our\nframework recovers DAGs without the need for an expensive verification of the\nacyclicity constraint or enumeration of possible parent sets. We establish\nnumerical convergence of the algorithm, and consistency of the Cholesky factor\nestimator when the order of variables is known. Through several simulated and\nmacro-economic datasets, we study the scope and performance of the proposed\nmethodology.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 15:04:02 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dallakyan", "Aramayis", ""], ["Pourahmadi", "Mohsen", ""]]}, {"id": "2107.01677", "submitter": "Nicol\\`o Botteghi", "authors": "Nicol\\`o Botteghi, Mannes Poel, Beril Sirmacek, Christoph Brune", "title": "Low-Dimensional State and Action Representation Learning with MDP\n  Homomorphism Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has shown its ability in solving complicated\nproblems directly from high-dimensional observations. However, in end-to-end\nsettings, Reinforcement Learning algorithms are not sample-efficient and\nrequires long training times and quantities of data. In this work, we proposed\na framework for sample-efficient Reinforcement Learning that take advantage of\nstate and action representations to transform a high-dimensional problem into a\nlow-dimensional one. Moreover, we seek to find the optimal policy mapping\nlatent states to latent actions. Because now the policy is learned on abstract\nrepresentations, we enforce, using auxiliary loss functions, the lifting of\nsuch policy to the original problem domain. Results show that the novel\nframework can efficiently learn low-dimensional and interpretable state and\naction representations and the optimal latent policy.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 16:26:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Botteghi", "Nicol\u00f2", ""], ["Poel", "Mannes", ""], ["Sirmacek", "Beril", ""], ["Brune", "Christoph", ""]]}, {"id": "2107.01689", "submitter": "Jackson Killian", "authors": "Jackson A. Killian, Lily Xu, Arpita Biswas, Milind Tambe", "title": "Robust Restless Bandits: Tackling Interval Uncertainty with Deep\n  Reinforcement Learning", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Robust Restless Bandits, a challenging generalization of\nrestless multi-arm bandits (RMAB). RMABs have been widely studied for\nintervention planning with limited resources. However, most works make the\nunrealistic assumption that the transition dynamics are known perfectly,\nrestricting the applicability of existing methods to real-world scenarios. To\nmake RMABs more useful in settings with uncertain dynamics: (i) We introduce\nthe Robust RMAB problem and develop solutions for a minimax regret objective\nwhen transitions are given by interval uncertainties; (ii) We develop a double\noracle algorithm for solving Robust RMABs and demonstrate its effectiveness on\nthree experimental domains; (iii) To enable our double oracle approach, we\nintroduce RMABPPO, a novel deep reinforcement learning algorithm for solving\nRMABs. RMABPPO hinges on learning an auxiliary \"$\\lambda$-network\" that allows\neach arm's learning to decouple, greatly reducing sample complexity required\nfor training; (iv) Under minimax regret, the adversary in the double oracle\napproach is notoriously difficult to implement due to non-stationarity. To\naddress this, we formulate the adversary oracle as a multi-agent reinforcement\nlearning problem and solve it with a multi-agent extension of RMABPPO, which\nmay be of independent interest as the first known algorithm for this setting.\nCode is available at https://github.com/killian-34/RobustRMAB.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 17:21:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Killian", "Jackson A.", ""], ["Xu", "Lily", ""], ["Biswas", "Arpita", ""], ["Tambe", "Milind", ""]]}, {"id": "2107.01702", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Data-Driven Learning of Feedforward Neural Networks with Different\n  Activation Functions", "comments": "20th International Conference on Artificial Intelligence and Soft\n  Computing ICAISC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work contributes to the development of a new data-driven method (D-DM)\nof feedforward neural networks (FNNs) learning. This method was proposed\nrecently as a way of improving randomized learning of FNNs by adjusting the\nnetwork parameters to the target function fluctuations. The method employs\nlogistic sigmoid activation functions for hidden nodes. In this study, we\nintroduce other activation functions, such as bipolar sigmoid, sine function,\nsaturating linear functions, reLU, and softplus. We derive formulas for their\nparameters, i.e. weights and biases. In the simulation study, we evaluate the\nperformance of FNN data-driven learning with different activation functions.\nThe results indicate that the sigmoid activation functions perform much better\nthan others in the approximation of complex, fluctuated target functions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:20:27 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 07:33:13 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "2107.01705", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Randomized Neural Networks for Forecasting Time Series with Multiple\n  Seasonality", "comments": "International Work Conference on Artificial Neural Networks IWANN\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work contributes to the development of neural forecasting models with\nnovel randomization-based learning methods. These methods improve the fitting\nabilities of the neural model, in comparison to the standard method, by\ngenerating network parameters in accordance with the data and target function\nfeatures. A pattern-based representation of time series makes the proposed\napproach useful for forecasting time series with multiple seasonality. In the\nsimulation study, we evaluate the performance of the proposed models and find\nthat they can compete in terms of forecasting accuracy with fully-trained\nnetworks. Extremely fast and easy training, simple architecture, ease of\nimplementation, high accuracy as well as dealing with nonstationarity and\nmultiple seasonality in time series make the proposed model very attractive for\na wide range of complex time series forecasting problems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:39:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "2107.01707", "submitter": "Rasheed el-Bouri", "authors": "Rasheed el-Bouri, Tingting Zhu, David A. Clifton", "title": "Towards Scheduling Federated Deep Learning using Meta-Gradients for\n  Inter-Hospital Learning", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the abundance and ease of access of personal data today, individual\nprivacy has become of paramount importance, particularly in the healthcare\ndomain. In this work, we aim to utilise patient data extracted from multiple\nhospital data centres to train a machine learning model without sacrificing\npatient privacy. We develop a scheduling algorithm in conjunction with a\nstudent-teacher algorithm that is deployed in a federated manner. This allows a\ncentral model to learn from batches of data at each federal node. The teacher\nacts between data centres to update the main task (student) algorithm using the\ndata that is stored in the various data centres. We show that the scheduler,\ntrained using meta-gradients, can effectively organise training and as a result\ntrain a machine learning model on a diverse dataset without needing explicit\naccess to the patient data. We achieve state-of-the-art performance and show\nhow our method overcomes some of the problems faced in the federated learning\nsuch as node poisoning. We further show how the scheduler can be used as a\nmechanism for transfer learning, allowing different teachers to work together\nin training a student for state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:45:58 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["el-Bouri", "Rasheed", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2107.01711", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Autoencoder based Randomized Learning of Feedforward Neural Networks for\n  Regression", "comments": "International Joint Conference on Neural Networks IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feedforward neural networks are widely used as universal predictive models to\nfit data distribution. Common gradient-based learning, however, suffers from\nmany drawbacks making the training process ineffective and time-consuming.\nAlternative randomized learning does not use gradients but selects hidden node\nparameters randomly. This makes the training process extremely fast. However,\nthe problem in randomized learning is how to determine the random parameters. A\nrecently proposed method uses autoencoders for unsupervised parameter learning.\nThis method showed superior performance on classification tasks. In this work,\nwe apply this method to regression problems, and, finding that it has some\ndrawbacks, we show how to improve it. We propose a learning method of\nautoencoders that controls the produced random weights. We also propose how to\ndetermine the biases of hidden nodes. We empirically compare autoencoder based\nlearning with other randomized learning methods proposed recently for\nregression and find that despite the proposed improvement of the autoencoder\nbased learning, it does not outperform its competitors in fitting accuracy.\nMoreover, the method is much more complex than its competitors.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 19:07:39 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "2107.01726", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ivan Petej, and Alex Gammerman", "title": "Adaptive calibration for binary classification", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note proposes a way of making probability forecasting rules less\nsensitive to changes in data distribution, concentrating on the simple case of\nbinary classification. This is important in applications of machine learning,\nwhere the quality of a trained predictor may drop significantly in the process\nof its exploitation. Our techniques are based on recent work on conformal test\nmartingales and older work on prediction with expert advice, namely tracking\nthe best expert.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 20:32:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Vovk", "Vladimir", ""], ["Petej", "Ivan", ""], ["Gammerman", "Alex", ""]]}, {"id": "2107.01734", "submitter": "Francesco Sanna Passino", "authors": "Francesco Sanna Passino and Nicholas A. Heard", "title": "Latent structure blockmodels for Bayesian spectral graph clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral embedding of network adjacency matrices often produces node\nrepresentations living approximately around low-dimensional submanifold\nstructures. In particular, hidden substructure is expected to arise when the\ngraph is generated from a latent position model. Furthermore, the presence of\ncommunities within the network might generate community-specific submanifold\nstructures in the embedding, but this is not explicitly accounted for in most\nstatistical models for networks. In this article, a class of models called\nlatent structure block models (LSBM) is proposed to address such scenarios,\nallowing for graph clustering when community-specific one dimensional manifold\nstructure is present. LSBMs focus on a specific class of latent space model,\nthe random dot product graph (RDPG), and assign a latent submanifold to the\nlatent positions of each community. A Bayesian model for the embeddings arising\nfrom LSBMs is discussed, and shown to have a good performance on simulated and\nreal world network data. The model is able to correctly recover the underlying\ncommunities living in a one-dimensional manifold, even when the parametric form\nof the underlying curves is unknown, achieving remarkable results on a variety\nof real data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 21:09:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Passino", "Francesco Sanna", ""], ["Heard", "Nicholas A.", ""]]}, {"id": "2107.01739", "submitter": "J. Gregory Pauloski", "authors": "J. Gregory Pauloski, Qi Huang, Lei Huang, Shivaram Venkataraman, Kyle\n  Chard, Ian Foster, Zhao Zhang", "title": "KAISA: An Adaptive Second-order Optimizer Framework for Deep Neural\n  Networks", "comments": "To be published in the proceedings of the International Conference\n  for High Performance Computing, Networking, Storage and Analysis (SC21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kronecker-factored Approximate Curvature (K-FAC) has recently been shown to\nconverge faster in deep neural network (DNN) training than stochastic gradient\ndescent (SGD); however, K-FAC's larger memory footprint hinders its\napplicability to large models. We present KAISA, a K-FAC-enabled, Adaptable,\nImproved, and ScAlable second-order optimizer framework that adapts the memory\nfootprint, communication, and computation given specific models and hardware to\nachieve maximized performance and enhanced scalability. We quantify the\ntradeoffs between memory and communication cost and evaluate KAISA on large\nmodels, including ResNet-50, Mask R-CNN, U-Net, and BERT, on up to 128 NVIDIA\nA100 GPUs. Compared to the original optimizers, KAISA converges 18.1-36.3%\nfaster across applications with the same global batch size. Under a fixed\nmemory budget, KAISA converges 32.5% and 41.6% faster in ResNet-50 and\nBERT-Large, respectively. KAISA can balance memory and communication to achieve\nscaling efficiency equal to or better than the baseline optimizers.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 21:34:22 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Pauloski", "J. Gregory", ""], ["Huang", "Qi", ""], ["Huang", "Lei", ""], ["Venkataraman", "Shivaram", ""], ["Chard", "Kyle", ""], ["Foster", "Ian", ""], ["Zhang", "Zhao", ""]]}, {"id": "2107.01752", "submitter": "Max Little", "authors": "Max A. Little and Ugur Kayas", "title": "Polymorphic dynamic programming by algebraic shortcut fusion", "comments": "Updated v9 with 2 additional figures and descriptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.RA", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Dynamic programming (DP) is a broadly applicable algorithmic design paradigm\nfor the efficient, exact solution of otherwise intractable, combinatorial\nproblems. However, the design of such algorithms is often presented informally\nin an ad-hoc manner, and as a result is often difficult to apply correctly. In\nthis paper, we present a rigorous algebraic formalism for systematically\nderiving novel DP algorithms, either from existing DP algorithms or from simple\nfunctional recurrences. These derivations lead to algorithms which are provably\ncorrect and polymorphic over any semiring, which means that they can be applied\nto the full scope of combinatorial problems expressible in terms of semirings.\nThis includes, for example: optimization, optimal probability and Viterbi\ndecoding, probabilistic marginalization, logical inference, fuzzy sets,\ndifferentiable softmax, and relational and provenance queries. The approach,\nbuilding on many ideas from the existing literature on constructive\nalgorithmics, exploits generic properties of (semiring) polymorphic functions,\ntupling and formal sums (lifting), and algebraic simplifications arising from\nconstraint algebras. We demonstrate the effectiveness of this formalism for\nsome example applications arising in signal processing, bioinformatics and\nreliability engineering.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 00:51:02 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 22:37:35 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Little", "Max A.", ""], ["Kayas", "Ugur", ""]]}, {"id": "2107.01757", "submitter": "Zizhou Su", "authors": "Zizhou Su", "title": "The Least Restriction for Offline Reinforcement Learning", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical applications of reinforcement learning (RL) constrain the\nagent to learn from a fixed offline dataset of logged interactions, which has\nalready been gathered, without offering further possibility for data\ncollection. However, commonly used off-policy RL algorithms, such as the Deep Q\nNetwork and the Deep Deterministic Policy Gradient, are incapable of learning\nwithout data correlated to the distribution under the current policy, making\nthem ineffective for this offline setting. As the first step towards useful\noffline RL algorithms, we analysis the reason of instability in standard\noff-policy RL algorithms. It is due to the bootstrapping error. The key to\navoiding this error, is ensuring that the agent's action space does not go out\nof the fixed offline dataset. Based on our consideration, a creative offline RL\nframework, the Least Restriction (LR), is proposed in this paper. The LR\nregards selecting an action as taking a sample from the probability\ndistribution. It merely set a little limit for action selection, which not only\navoid the action being out of the offline dataset but also remove all the\nunreasonable restrictions in earlier approaches (e.g. Batch-Constrained Deep\nQ-Learning). In the further, we will demonstrate that the LR, is able to learn\nrobustly from different offline datasets, including random and suboptimal\ndemonstrations, on a range of practical control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 01:50:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Su", "Zizhou", ""]]}, {"id": "2107.01760", "submitter": "Taichi Murayama", "authors": "Taichi Murayama, Shoko Wakamiya, Eiji Aramaki", "title": "Single Model for Influenza Forecasting of Multiple Countries by\n  Multi-task Learning", "comments": "European Conference on Machine Learning and Principles and Practice\n  of Knowledge Discovery in Databases (ECML-PKDD), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate forecasting of infectious epidemic diseases such as influenza is\na crucial task undertaken by medical institutions. Although numerous flu\nforecasting methods and models based mainly on historical flu activity data and\nonline user-generated contents have been proposed in previous studies, no flu\nforecasting model targeting multiple countries using two types of data exists\nat present. Our paper leverages multi-task learning to tackle the challenge of\nbuilding one flu forecasting model targeting multiple countries; each country\nas each task. Also, to develop the flu prediction model with higher\nperformance, we solved two issues; finding suitable search queries, which are\npart of the user-generated contents, and how to leverage search queries\nefficiently in the model creation. For the first issue, we propose the transfer\napproaches from English to other languages. For the second issue, we propose a\nnovel flu forecasting model that takes advantage of search queries using an\nattention mechanism and extend the model to a multi-task model for multiple\ncountries' flu forecasts. Experiments on forecasting flu epidemics in five\ncountries demonstrate that our model significantly improved the performance by\nleveraging the search queries and multi-task learning compared to the\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 02:09:26 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 04:20:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Murayama", "Taichi", ""], ["Wakamiya", "Shoko", ""], ["Aramaki", "Eiji", ""]]}, {"id": "2107.01777", "submitter": "Shashank Singh", "authors": "Shashank Singh, Justin Khim", "title": "Statistical Theory for Imbalanced Binary Classification", "comments": "Parts of this paper have been revised from arXiv:2004.04715v2\n  [math.ST]", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within the vast body of statistical theory developed for binary\nclassification, few meaningful results exist for imbalanced classification, in\nwhich data are dominated by samples from one of the two classes. Existing\ntheory faces at least two main challenges. First, meaningful results must\nconsider more complex performance measures than classification accuracy. To\naddress this, we characterize a novel generalization of the Bayes-optimal\nclassifier to any performance metric computed from the confusion matrix, and we\nuse this to show how relative performance guarantees can be obtained in terms\nof the error of estimating the class probability function under uniform\n($\\mathcal{L}_\\infty$) loss. Second, as we show, optimal classification\nperformance depends on certain properties of class imbalance that have not\npreviously been formalized. Specifically, we propose a novel sub-type of class\nimbalance, which we call Uniform Class Imbalance. We analyze how Uniform Class\nImbalance influences optimal classifier performance and show that it\nnecessitates different classifier behavior than other types of class imbalance.\nWe further illustrate these two contributions in the case of $k$-nearest\nneighbor classification, for which we develop novel guarantees. Together, these\nresults provide some of the first meaningful finite-sample statistical theory\nfor imbalanced binary classification.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 03:55:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Singh", "Shashank", ""], ["Khim", "Justin", ""]]}, {"id": "2107.01782", "submitter": "Tidor-Vlad Pricope", "authors": "Tidor-Vlad Pricope", "title": "A contextual analysis of multi-layer perceptron models in classifying\n  hand-written digits and letters: limited resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classifying hand-written digits and letters has taken a big leap with the\nintroduction of ConvNets. However, on very constrained hardware the time\nnecessary to train such models would be high. Our main contribution is twofold.\nFirst, we extensively test an end-to-end vanilla neural network (MLP) approach\nin pure numpy without any pre-processing or feature extraction done beforehand.\nSecond, we show that basic data mining operations can significantly improve the\nperformance of the models in terms of computational time, without sacrificing\nmuch accuracy. We illustrate our claims on a simpler variant of the Extended\nMNIST dataset, called Balanced EMNIST dataset. Our experiments show that,\nwithout any data mining, we get increased generalization performance when using\nmore hidden layers and regularization techniques, the best model achieving\n84.83% accuracy on a test dataset. Using dimensionality reduction done by PCA\nwe were able to increase that figure to 85.08% with only 10% of the original\nfeature space, reducing the memory size needed by 64%. Finally, adding methods\nto remove possibly harmful training samples like deviation from the mean helped\nus to still achieve over 84% test accuracy but with only 32.8% of the original\nmemory size for the training set. This compares favorably to the majority of\nliterature results obtained through similar architectures. Although this\napproach gets outshined by state-of-the-art models, it does scale to some\n(AlexNet, VGGNet) trained on 50% of the same dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 04:30:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Pricope", "Tidor-Vlad", ""]]}, {"id": "2107.01784", "submitter": "Robin Karlsson", "authors": "Robin Karlsson, David Robert Wong, Simon Thompson, Kazuya Takeda", "title": "Learning a Model for Inferring a Spatial Road Lane Network Graph using\n  Self-Supervision", "comments": "Accepted for IEEE ITSC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interconnected road lanes are a central concept for navigating urban roads.\nCurrently, most autonomous vehicles rely on preconstructed lane maps as\ndesigning an algorithmic model is difficult. However, the generation and\nmaintenance of such maps is costly and hinders large-scale adoption of\nautonomous vehicle technology. This paper presents the first self-supervised\nlearning method to train a model to infer a spatially grounded lane-level road\nnetwork graph based on a dense segmented representation of the road scene\ngenerated from onboard sensors. A formal road lane network model is presented\nand proves that any structured road scene can be represented by a directed\nacyclic graph of at most depth three while retaining the notion of intersection\nregions, and that this is the most compressed representation. The formal model\nis implemented by a hybrid neural and search-based model, utilizing a novel\nbarrier function loss formulation for robust learning from partial labels.\nExperiments are conducted for all common road intersection layouts. Results\nshow that the model can generalize to new road layouts, unlike previous\napproaches, demonstrating its potential for real-world application as a\npractical learning-based lane-level map generator.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 04:34:51 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Karlsson", "Robin", ""], ["Wong", "David Robert", ""], ["Thompson", "Simon", ""], ["Takeda", "Kazuya", ""]]}, {"id": "2107.01799", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge and Jose C. Principe", "title": "An Information-Theoretic Approach for Automatically Determining the\n  Number of States when Aggregating Markov Chains", "comments": "Submitted to IEEE ICASSP. arXiv admin note: substantial text overlap\n  with arXiv:1903.09266", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8682473", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fundamental problem when aggregating Markov chains is the specification of\nthe number of state groups. Too few state groups may fail to sufficiently\ncapture the pertinent dynamics of the original, high-order Markov chain. Too\nmany state groups may lead to a non-parsimonious, reduced-order Markov chain\nwhose complexity rivals that of the original. In this paper, we show that an\naugmented value-of-information-based approach to aggregating Markov chains\nfacilitates the determination of the number of state groups. The optimal\nstate-group count coincides with the case where the complexity of the\nreduced-order chain is balanced against the mutual dependence between the\noriginal- and reduced-order chain dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 05:36:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Principe", "Jose C.", ""]]}, {"id": "2107.01804", "submitter": "Shyam Narayanan", "authors": "Shyam Narayanan, Sandeep Silwal, Piotr Indyk, Or Zamir", "title": "Randomized Dimensionality Reduction for Facility Location and\n  Single-Linkage Clustering", "comments": "25 pages. Published as a conference paper in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random dimensionality reduction is a versatile tool for speeding up\nalgorithms for high-dimensional problems. We study its application to two\nclustering problems: the facility location problem, and the single-linkage\nhierarchical clustering problem, which is equivalent to computing the minimum\nspanning tree. We show that if we project the input pointset $X$ onto a random\n$d = O(d_X)$-dimensional subspace (where $d_X$ is the doubling dimension of\n$X$), then the optimum facility location cost in the projected space\napproximates the original cost up to a constant factor. We show an analogous\nstatement for minimum spanning tree, but with the dimension $d$ having an extra\n$\\log \\log n$ term and the approximation factor being arbitrarily close to $1$.\nFurthermore, we extend these results to approximating solutions instead of just\ntheir costs. Lastly, we provide experimental results to validate the quality of\nsolutions and the speedup due to the dimensionality reduction. Unlike several\nprevious papers studying this approach in the context of $k$-means and\n$k$-medians, our dimension bound does not depend on the number of clusters but\nonly on the intrinsic dimensionality of $X$.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 05:55:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Narayanan", "Shyam", ""], ["Silwal", "Sandeep", ""], ["Indyk", "Piotr", ""], ["Zamir", "Or", ""]]}, {"id": "2107.01806", "submitter": "Asaf Shabtai", "authors": "Ron Bitton, Nadav Maman, Inderjeet Singh, Satoru Momiyama, Yuval\n  Elovici, Asaf Shabtai", "title": "A Framework for Evaluating the Cybersecurity Risk of Real World, Machine\n  Learning Production Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although cyberattacks on machine learning (ML) production systems can be\ndestructive, many industry practitioners are ill equipped, lacking tactical and\nstrategic tools that would allow them to analyze, detect, protect against, and\nrespond to cyberattacks targeting their ML-based systems. In this paper, we\ntake a significant step toward securing ML production systems by integrating\nthese systems and their vulnerabilities into cybersecurity risk assessment\nframeworks. Specifically, we performed a comprehensive threat analysis of ML\nproduction systems and developed an extension to the MulVAL attack graph\ngeneration and analysis framework to incorporate cyberattacks on ML production\nsystems. Using the proposed extension, security practitioners can apply attack\ngraph analysis methods in environments that include ML components, thus\nproviding security experts with a practical tool for evaluating the impact and\nquantifying the risk of a cyberattack targeting an ML production system.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 05:58:11 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bitton", "Ron", ""], ["Maman", "Nadav", ""], ["Singh", "Inderjeet", ""], ["Momiyama", "Satoru", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2107.01807", "submitter": "Rachmad Vidya Wicaksana Putra", "authors": "Rachmad Vidya Wicaksana Putra, Muhammad Shafique", "title": "Q-SpiNN: A Framework for Quantizing Spiking Neural Networks", "comments": "Accepted for publication at the 2021 International Joint Conference\n  on Neural Networks (IJCNN), July 2021, Virtual Event", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prominent technique for reducing the memory footprint of Spiking Neural\nNetworks (SNNs) without decreasing the accuracy significantly is quantization.\nHowever, the state-of-the-art only focus on employing the weight quantization\ndirectly from a specific quantization scheme, i.e., either the post-training\nquantization (PTQ) or the in-training quantization (ITQ), and do not consider\n(1) quantizing other SNN parameters (e.g., neuron membrane potential), (2)\nexploring different combinations of quantization approaches (i.e., quantization\nschemes, precision levels, and rounding schemes), and (3) selecting the SNN\nmodel with a good memory-accuracy trade-off at the end. Therefore, the memory\nsaving offered by these state-of-the-art to meet the targeted accuracy is\nlimited, thereby hindering processing SNNs on the resource-constrained systems\n(e.g., the IoT-Edge devices). Towards this, we propose Q-SpiNN, a novel\nquantization framework for memory-efficient SNNs. The key mechanisms of the\nQ-SpiNN are: (1) employing quantization for different SNN parameters based on\ntheir significance to the accuracy, (2) exploring different combinations of\nquantization schemes, precision levels, and rounding schemes to find efficient\nSNN model candidates, and (3) developing an algorithm that quantifies the\nbenefit of the memory-accuracy trade-off obtained by the candidates, and\nselects the Pareto-optimal one. The experimental results show that, for the\nunsupervised network, the Q-SpiNN reduces the memory footprint by ca. 4x, while\nmaintaining the accuracy within 1% from the baseline on the MNIST dataset. For\nthe supervised network, the Q-SpiNN reduces the memory by ca. 2x, while keeping\nthe accuracy within 2% from the baseline on the DVS-Gesture dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:01:15 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Putra", "Rachmad Vidya Wicaksana", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2107.01808", "submitter": "Sahib Singh", "authors": "Sahib Singh, Rosanne Liu", "title": "Why is Pruning at Initialization Immune to Reinitializing and Shuffling?", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies assessing the efficacy of pruning neural networks methods\nuncovered a surprising finding: when conducting ablation studies on existing\npruning-at-initialization methods, namely SNIP, GraSP, SynFlow, and magnitude\npruning, performances of these methods remain unchanged and sometimes even\nimprove when randomly shuffling the mask positions within each layer (Layerwise\nShuffling) or sampling new initial weight values (Reinit), while keeping\npruning masks the same. We attempt to understand the reason behind such network\nimmunity towards weight/mask modifications, by studying layer-wise statistics\nbefore and after randomization operations. We found that under each of the\npruning-at-initialization methods, the distribution of unpruned weights changed\nminimally with randomization operations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:04:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Singh", "Sahib", ""], ["Liu", "Rosanne", ""]]}, {"id": "2107.01809", "submitter": "Xiao Yang", "authors": "Xiao Yang, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu", "title": "Boosting Transferability of Targeted Adversarial Examples via\n  Hierarchical Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer-based adversarial attacks can effectively evaluate model robustness\nin the black-box setting. Though several methods have demonstrated impressive\ntransferability of untargeted adversarial examples, targeted adversarial\ntransferability is still challenging. The existing methods either have low\ntargeted transferability or sacrifice computational efficiency. In this paper,\nwe develop a simple yet practical framework to efficiently craft targeted\ntransfer-based adversarial examples. Specifically, we propose a conditional\ngenerative attacking model, which can generate the adversarial examples\ntargeted at different classes by simply altering the class embedding and share\na single backbone. Extensive experiments demonstrate that our method improves\nthe success rates of targeted black-box attacks by a significant margin over\nthe existing methods -- it reaches an average success rate of 29.6\\% against\nsix diverse models based only on one substitute white-box model in the standard\ntesting of NeurIPS 2017 competition, which outperforms the state-of-the-art\ngradient-based attack methods (with an average success rate of $<$2\\%) by a\nlarge margin. Moreover, the proposed method is also more efficient beyond an\norder of magnitude than gradient-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:17:47 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2107.01820", "submitter": "Michael Thrun PhD", "authors": "Alfred Ultsch, J\\\"org Hoffmann, Maximilian R\\\"ohnert, Malte Von Bonin,\n  Uta Oelschl\\\"agel, Cornelia Brendel, Michael C. Thrun", "title": "An Explainable AI System for the Diagnosis of High Dimensional\n  Biomedical Data", "comments": "22 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical state of the art flow cytometry data samples consists of measures of\nmore than 100.000 cells in 10 or more features. AI systems are able to diagnose\nsuch data with almost the same accuracy as human experts. However, there is one\ncentral challenge in such systems: their decisions have far-reaching\nconsequences for the health and life of people, and therefore, the decisions of\nAI systems need to be understandable and justifiable by humans. In this work,\nwe present a novel explainable AI method, called ALPODS, which is able to\nclassify (diagnose) cases based on clusters, i.e., subpopulations, in the\nhigh-dimensional data. ALPODS is able to explain its decisions in a form that\nis understandable for human experts. For the identified subpopulations, fuzzy\nreasoning rules expressed in the typical language of domain experts are\ngenerated. A visualization method based on these rules allows human experts to\nunderstand the reasoning used by the AI system. A comparison to a selection of\nstate of the art explainable AI systems shows that ALPODS operates efficiently\non known benchmark data and also on everyday routine case data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:00:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ultsch", "Alfred", ""], ["Hoffmann", "J\u00f6rg", ""], ["R\u00f6hnert", "Maximilian", ""], ["Von Bonin", "Malte", ""], ["Oelschl\u00e4gel", "Uta", ""], ["Brendel", "Cornelia", ""], ["Thrun", "Michael C.", ""]]}, {"id": "2107.01825", "submitter": "Yao Yao", "authors": "Yao Yao, Li Xiao, Zhicheng An, Wanpeng Zhang, and Dijun Luo", "title": "Sample Efficient Reinforcement Learning via Model-Ensemble Exploration\n  and Exploitation", "comments": "7 pages, 5 figures, accepted by IEEE International Conference on\n  Robotics and Automation 2021 (IEEE ICRA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based deep reinforcement learning has achieved success in various\ndomains that require high sample efficiencies, such as Go and robotics.\nHowever, there are some remaining issues, such as planning efficient\nexplorations to learn more accurate dynamic models, evaluating the uncertainty\nof the learned models, and more rational utilization of models. To mitigate\nthese issues, we present MEEE, a model-ensemble method that consists of\noptimistic exploration and weighted exploitation. During exploration, unlike\nprior methods directly selecting the optimal action that maximizes the expected\naccumulative return, our agent first generates a set of action candidates and\nthen seeks out the optimal action that takes both expected return and future\nobservation novelty into account. During exploitation, different discounted\nweights are assigned to imagined transition tuples according to their model\nuncertainty respectively, which will prevent model predictive error propagation\nin agent training. Experiments on several challenging continuous control\nbenchmark tasks demonstrated that our approach outperforms other model-free and\nmodel-based state-of-the-art methods, especially in sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:18:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yao", "Yao", ""], ["Xiao", "Li", ""], ["An", "Zhicheng", ""], ["Zhang", "Wanpeng", ""], ["Luo", "Dijun", ""]]}, {"id": "2107.01830", "submitter": "Cai Shaofeng", "authors": "Shaofeng Cai, Kaiping Zheng, Gang Chen, H. V. Jagadish, Beng Chin Ooi,\n  Meihui Zhang", "title": "ARM-Net: Adaptive Relation Modeling Network for Structured Data", "comments": "14 pages, 11 figures, 5 tables, published as a conference paper in\n  ACM SIGMOD 2020", "journal-ref": null, "doi": "10.1145/3448016.3457321", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational databases are the de facto standard for storing and querying\nstructured data, and extracting insights from structured data requires advanced\nanalytics. Deep neural networks (DNNs) have achieved super-human prediction\nperformance in particular data types, e.g., images. However, existing DNNs may\nnot produce meaningful results when applied to structured data. The reason is\nthat there are correlations and dependencies across combinations of attribute\nvalues in a table, and these do not follow simple additive patterns that can be\neasily mimicked by a DNN. The number of possible such cross features is\ncombinatorial, making them computationally prohibitive to model. Furthermore,\nthe deployment of learning models in real-world applications has also\nhighlighted the need for interpretability, especially for high-stakes\napplications, which remains another issue of concern to DNNs.\n  In this paper, we present ARM-Net, an adaptive relation modeling network\ntailored for structured data, and a lightweight framework ARMOR based on\nARM-Net for relational data analytics. The key idea is to model feature\ninteractions with cross features selectively and dynamically, by first\ntransforming the input features into exponential space, and then determining\nthe interaction order and interaction weights adaptively for each cross\nfeature. We propose a novel sparse attention mechanism to dynamically generate\nthe interaction weights given the input tuple, so that we can explicitly model\ncross features of arbitrary orders with noisy features filtered selectively.\nThen during model inference, ARM-Net can specify the cross features being used\nfor each prediction for higher accuracy and better interpretability. Our\nextensive experiments on real-world datasets demonstrate that ARM-Net\nconsistently outperforms existing models and provides more interpretable\npredictions for data-driven decision making.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:37:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Cai", "Shaofeng", ""], ["Zheng", "Kaiping", ""], ["Chen", "Gang", ""], ["Jagadish", "H. V.", ""], ["Ooi", "Beng Chin", ""], ["Zhang", "Meihui", ""]]}, {"id": "2107.01832", "submitter": "Wei Li", "authors": "Xin Liu and Zhisong Pan", "title": "Provable Convergence of Nesterov Accelerated Method for\n  Over-Parameterized Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the empirical success of deep learning, it still lacks theoretical\nunderstandings to explain why randomly initialized neural network trained by\nfirst-order optimization methods is able to achieve zero training loss, even\nthough its landscape is non-convex and non-smooth. Recently, there are some\nworks to demystifies this phenomenon under over-parameterized regime. In this\nwork, we make further progress on this area by considering a commonly used\nmomentum optimization algorithm: Nesterov accelerated method (NAG). We analyze\nthe convergence of NAG for two-layer fully connected neural network with ReLU\nactivation. Specifically, we prove that the error of NAG converges to zero at a\nlinear convergence rate $1-\\Theta(1/\\sqrt{\\kappa})$, where $\\kappa > 1$ is\ndetermined by the initialization and the architecture of neural network.\nComparing to the rate $1-\\Theta(1/\\kappa)$ of gradient descent, NAG achieves an\nacceleration. Besides, it also validates NAG and Heavy-ball method can achieve\na similar convergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:40:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Liu", "Xin", ""], ["Pan", "Zhisong", ""]]}, {"id": "2107.01835", "submitter": "Juliette Achddou", "authors": "Juliette Achddou (PSL, DI-ENS, VALDA ), Olivier Capp\\'e (LTCI, VALDA\n  ), Aur\\'elien Garivier (UMPA-ENSL)", "title": "Fast Rate Learning in Stochastic First Price Bidding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-price auctions have largely replaced traditional bidding approaches\nbased on Vickrey auctions in programmatic advertising. As far as learning is\nconcerned, first-price auctions are more challenging because the optimal\nbidding strategy does not only depend on the value of the item but also\nrequires some knowledge of the other bids. They have already given rise to\nseveral works in sequential learning, many of which consider models for which\nthe value of the buyer or the opponents' maximal bid is chosen in an\nadversarial manner. Even in the simplest settings, this gives rise to\nalgorithms whose regret grows as $\\sqrt{T}$ with respect to the time horizon\n$T$. Focusing on the case where the buyer plays against a stationary stochastic\nenvironment, we show how to achieve significantly lower regret: when the\nopponents' maximal bid distribution is known we provide an algorithm whose\nregret can be as low as $\\log^2(T)$; in the case where the distribution must be\nlearnt sequentially, a generalization of this algorithm can achieve $T^{1/3+\n\\epsilon}$ regret, for any $\\epsilon>0$. To obtain these results, we introduce\ntwo novel ideas that can be of interest in their own right. First, by\ntransposing results obtained in the posted price setting, we provide conditions\nunder which the first-price biding utility is locally quadratic around its\noptimum. Second, we leverage the observation that, on small sub-intervals, the\nconcentration of the variations of the empirical distribution function may be\ncontrolled more accurately than by using the classical\nDvoretzky-Kiefer-Wolfowitz inequality. Numerical simulations confirm that our\nalgorithms converge much faster than alternatives proposed in the literature\nfor various bid distributions, including for bids collected on an actual\nprogrammatic advertising platform.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:48:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Achddou", "Juliette", "", "PSL, DI-ENS, VALDA"], ["Capp\u00e9", "Olivier", "", "LTCI, VALDA"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"]]}, {"id": "2107.01848", "submitter": "Alain Rakotomamonjy", "authors": "Alain Rakotomamonjy (DocApp - LITIS), Liva Ralaivola", "title": "Differentially Private Sliced Wasserstein Distance", "comments": null, "journal-ref": "International Conference of Machine Learning, Jul 2021, Virtual,\n  France", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing machine learning methods that are privacy preserving is today a\ncentral topic of research, with huge practical impacts. Among the numerous ways\nto address privacy-preserving learning, we here take the perspective of\ncomputing the divergences between distributions under the Differential Privacy\n(DP) framework -- being able to compute divergences between distributions is\npivotal for many machine learning problems, such as learning generative models\nor domain adaptation problems. Instead of resorting to the popular\ngradient-based sanitization method for DP, we tackle the problem at its roots\nby focusing on the Sliced Wasserstein Distance and seamlessly making it\ndifferentially private. Our main contribution is as follows: we analyze the\nproperty of adding a Gaussian perturbation to the intrinsic randomized\nmechanism of the Sliced Wasserstein Distance, and we establish the\nsensitivityof the resulting differentially private mechanism. One of our\nimportant findings is that this DP mechanism transforms the Sliced Wasserstein\ndistance into another distance, that we call the Smoothed Sliced Wasserstein\nDistance. This new differentially private distribution distance can be plugged\ninto generative models and domain adaptation algorithms in a transparent way,\nand we empirically show that it yields highly competitive performance compared\nwith gradient-based DP approaches from the literature, with almost no loss in\naccuracy for the domain adaptation problems that we consider.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:06:02 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Rakotomamonjy", "Alain", "", "DocApp - LITIS"], ["Ralaivola", "Liva", ""]]}, {"id": "2107.01850", "submitter": "Jiaqi Zhang", "authors": "Jiaqi Zhang, Chandler Squires, Caroline Uhler", "title": "Matching a Desired Causal State via Shift Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transforming a causal system from a given initial state to a desired target\nstate is an important task permeating multiple fields including control theory,\nbiology, and materials science. In causal models, such transformations can be\nachieved by performing a set of interventions. In this paper, we consider the\nproblem of identifying a shift intervention that matches the desired mean of a\nsystem through active learning. We define the Markov equivalence class that is\nidentifiable from shift interventions and propose two active learning\nstrategies that are guaranteed to exactly match a desired mean. We then derive\na worst-case lower bound for the number of interventions required and show that\nthese strategies are optimal for certain classes of graphs. In particular, we\nshow that our strategies may require exponentially fewer interventions than the\npreviously considered approaches, which optimize for structure learning in the\nunderlying causal graph. In line with our theoretical results, we also\ndemonstrate experimentally that our proposed active learning strategies require\nfewer interventions compared to several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:11:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Jiaqi", ""], ["Squires", "Chandler", ""], ["Uhler", "Caroline", ""]]}, {"id": "2107.01854", "submitter": "Ke Ma", "authors": "Ke Ma and Qianqian Xu and Jinshan Zeng and Xiaochun Cao and Qingming\n  Huang", "title": "Poisoning Attack against Estimating from Pairwise Comparisons", "comments": "31 pages", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3087514", "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.GT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As pairwise ranking becomes broadly employed for elections, sports\ncompetitions, recommendations, and so on, attackers have strong motivation and\nincentives to manipulate the ranking list. They could inject malicious\ncomparisons into the training data to fool the victim. Such a technique is\ncalled poisoning attack in regression and classification tasks. In this paper,\nto the best of our knowledge, we initiate the first systematic investigation of\ndata poisoning attacks on pairwise ranking algorithms, which can be formalized\nas the dynamic and static games between the ranker and the attacker and can be\nmodeled as certain kinds of integer programming problems. To break the\ncomputational hurdle of the underlying integer programming problems, we\nreformulate them into the distributionally robust optimization (DRO) problems,\nwhich are computationally tractable. Based on such DRO formulations, we propose\ntwo efficient poisoning attack algorithms and establish the associated\ntheoretical guarantees. The effectiveness of the suggested poisoning attack\nstrategies is demonstrated by a series of toy simulations and several real data\nexperiments. These experimental results show that the proposed methods can\nsignificantly reduce the performance of the ranker in the sense that the\ncorrelation between the true ranking list and the aggregated results can be\ndecreased dramatically.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:16:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ma", "Ke", ""], ["Xu", "Qianqian", ""], ["Zeng", "Jinshan", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "2107.01856", "submitter": "Michael Schlechtinger", "authors": "Michael Schlechtinger, Damaris Kosack, Heiko Paulheim, Thomas Fetzer", "title": "Winning at Any Cost -- Infringing the Cartel Prohibition With\n  Reinforcement Learning", "comments": "accepted at the 19th International Conference on Practical\n  Applications of Agents and Multi-Agent Systems (PAAMS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pricing decisions are increasingly made by AI. Thanks to their ability to\ntrain with live market data while making decisions on the fly, deep\nreinforcement learning algorithms are especially effective in taking such\npricing decisions. In e-commerce scenarios, multiple reinforcement learning\nagents can set prices based on their competitor's prices. Therefore, research\nstates that agents might end up in a state of collusion in the long run. To\nfurther analyze this issue, we build a scenario that is based on a modified\nversion of a prisoner's dilemma where three agents play the game of rock paper\nscissors. Our results indicate that the action selection can be dissected into\nspecific stages, establishing the possibility to develop collusion prevention\nsystems that are able to recognize situations which might lead to a collusion\nbetween competitors. We furthermore provide evidence for a situation where\nagents are capable of performing a tacit cooperation strategy without being\nexplicitly trained to do so.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:21:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Schlechtinger", "Michael", ""], ["Kosack", "Damaris", ""], ["Paulheim", "Heiko", ""], ["Fetzer", "Thomas", ""]]}, {"id": "2107.01858", "submitter": "Sebastian Berns", "authors": "Sebastian Berns, Terence Broad, Christian Guckelsberger and Simon\n  Colton", "title": "Automating Generative Deep Learning for Artistic Purposes: Challenges\n  and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a framework for automating generative deep learning with a\nspecific focus on artistic applications. The framework provides opportunities\nto hand over creative responsibilities to a generative system as targets for\nautomation. For the definition of targets, we adopt core concepts from\nautomated machine learning and an analysis of generative deep learning\npipelines, both in standard and artistic settings. To motivate the framework,\nwe argue that automation aligns well with the goal of increasing the creative\nresponsibility of a generative system, a central theme in computational\ncreativity research. We understand automation as the challenge of granting a\ngenerative system more creative autonomy, by framing the interaction between\nthe user and the system as a co-creative process. The development of the\nframework is informed by our analysis of the relationship between automation\nand creative autonomy. An illustrative example shows how the framework can give\ninspiration and guidance in the process of handing over creative\nresponsibility.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:26:50 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Berns", "Sebastian", ""], ["Broad", "Terence", ""], ["Guckelsberger", "Christian", ""], ["Colton", "Simon", ""]]}, {"id": "2107.01863", "submitter": "Reymond Mesuga", "authors": "Reymond Mesuga and Brian James Bayanay", "title": "On the Efficiency of Various Deep Transfer Learning Models in Glitch\n  Waveform Detection in Gravitational-Wave Data", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.16403.20000", "report-no": null, "categories": "gr-qc astro-ph.IM cs.LG physics.space-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  LIGO is considered the most sensitive and complicated gravitational\nexperiment ever built. Its main objective is to detect the gravitational wave\nfrom the strongest events in the universe by observing if the length of its\n4-kilometer arms change by a distance 10,000 times smaller than the diameter of\na proton. Due to its sensitivity, LIGO is prone to the disturbance of external\nnoises which affects the data being collected to detect the gravitational wave.\nThese noises are commonly called by the LIGO community as glitches. The\nobjective of this study is to evaluate the effeciency of various deep trasnfer\nlearning models namely VGG19, ResNet50V2, VGG16 and ResNet101 to detect glitch\nwaveform in gravitational wave data. The accuracy achieved by the said models\nare 98.98%, 98.35%, 97.56% and 94.73% respectively. Even though the models\nachieved fairly high accuracy, it is observed that all of the model suffered\nfrom the lack of data for certain classes which is the main concern found in\nthe experiment.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:32:58 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 22:59:16 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 23:57:44 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mesuga", "Reymond", ""], ["Bayanay", "Brian James", ""]]}, {"id": "2107.01873", "submitter": "Lucas Baier", "authors": "Lucas Baier, Tim Schl\\\"or, Jakob Sch\\\"offer, Niklas K\\\"uhl", "title": "Detecting Concept Drift With Neural Network Model Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deployed machine learning models are confronted with the problem of changing\ndata over time, a phenomenon also called concept drift. While existing\napproaches of concept drift detection already show convincing results, they\nrequire true labels as a prerequisite for successful drift detection.\nEspecially in many real-world application scenarios-like the ones covered in\nthis work-true labels are scarce, and their acquisition is expensive.\nTherefore, we introduce a new algorithm for drift detection, Uncertainty Drift\nDetection (UDD), which is able to detect drifts without access to true labels.\nOur approach is based on the uncertainty estimates provided by a deep neural\nnetwork in combination with Monte Carlo Dropout. Structural changes over time\nare detected by applying the ADWIN technique on the uncertainty estimates, and\ndetected drifts trigger a retraining of the prediction model. In contrast to\ninput data-based drift detection, our approach considers the effects of the\ncurrent input data on the properties of the prediction model rather than\ndetecting change on the input data only (which can lead to unnecessary\nretrainings). We show that UDD outperforms other state-of-the-art strategies on\ntwo synthetic as well as ten real-world data sets for both regression and\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 08:56:36 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Baier", "Lucas", ""], ["Schl\u00f6r", "Tim", ""], ["Sch\u00f6ffer", "Jakob", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2107.01875", "submitter": "Lanqing Xue", "authors": "Lanqing Xue, Kaitao Song, Duocai Wu, Xu Tan, Nevin L. Zhang, Tao Qin,\n  Wei-Qiang Zhang, Tie-Yan Liu", "title": "DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling", "comments": "Accepted by ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rap generation, which aims to produce lyrics and corresponding singing beats,\nneeds to model both rhymes and rhythms. Previous works for rap generation\nfocused on rhyming lyrics but ignored rhythmic beats, which are important for\nrap performance. In this paper, we develop DeepRapper, a Transformer-based rap\ngeneration system that can model both rhymes and rhythms. Since there is no\navailable rap dataset with rhythmic beats, we develop a data mining pipeline to\ncollect a large-scale rap dataset, which includes a large number of rap songs\nwith aligned lyrics and rhythmic beats. Second, we design a Transformer-based\nautoregressive language model which carefully models rhymes and rhythms.\nSpecifically, we generate lyrics in the reverse order with rhyme representation\nand constraint for rhyme enhancement and insert a beat symbol into lyrics for\nrhythm/beat modeling. To our knowledge, DeepRapper is the first system to\ngenerate rap with both rhymes and rhythms. Both objective and subjective\nevaluations demonstrate that DeepRapper generates creative and high-quality\nraps with rhymes and rhythms. Code will be released on GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:01:46 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Xue", "Lanqing", ""], ["Song", "Kaitao", ""], ["Wu", "Duocai", ""], ["Tan", "Xu", ""], ["Zhang", "Nevin L.", ""], ["Qin", "Tao", ""], ["Zhang", "Wei-Qiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2107.01876", "submitter": "Xiangyu Zheng", "authors": "Xiangyu Zheng, Xinwei Sun, Wei Chen, Tie-Yan Liu", "title": "Causally Invariant Predictor with Shift-Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an invariant causal predictor that is robust to\ndistribution shift across domains and maximally reserves the transferable\ninvariant information. Based on a disentangled causal factorization, we\nformulate the distribution shift as soft interventions in the system, which\ncovers a wide range of cases for distribution shift as we do not make prior\nspecifications on the causal structure or the intervened variables. Instead of\nimposing regularizations to constrain the invariance of the predictor, we\npropose to predict by the intervened conditional expectation based on the\ndo-operator and then prove that it is invariant across domains. More\nimportantly, we prove that the proposed predictor is the robust predictor that\nminimizes the worst-case quadratic loss among the distributions of all domains.\nFor empirical learning, we propose an intuitive and flexible estimating method\nbased on data regeneration and present a local causal discovery procedure to\nguide the regeneration step. The key idea is to regenerate data such that the\nregenerated distribution is compatible with the intervened graph, which allows\nus to incorporate standard supervised learning methods with the regenerated\ndata. Experimental results on both synthetic and real data demonstrate the\nefficacy of our predictor in improving the predictive accuracy and robustness\nacross domains.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:07:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zheng", "Xiangyu", ""], ["Sun", "Xinwei", ""], ["Chen", "Wei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2107.01881", "submitter": "Tim van Erven", "authors": "Tim van Erven, Sarah Sachs, Wouter M. Koolen and Wojciech Kot{\\l}owski", "title": "Robust Online Convex Optimization in the Presence of Outliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online convex optimization when a number k of data points are\noutliers that may be corrupted. We model this by introducing the notion of\nrobust regret, which measures the regret only on rounds that are not outliers.\nThe aim for the learner is to achieve small robust regret, without knowing\nwhere the outliers are. If the outliers are chosen adversarially, we show that\na simple filtering strategy on extreme gradients incurs O(k) additive overhead\ncompared to the usual regret bounds, and that this is unimprovable, which means\nthat k needs to be sublinear in the number of rounds. We further ask which\nadditional assumptions would allow for a linear number of outliers. It turns\nout that the usual benign cases of independently, identically distributed\n(i.i.d.) observations or strongly convex losses are not sufficient. However,\ncombining i.i.d. observations with the assumption that outliers are those\nobservations that are in an extreme quantile of the distribution, does lead to\nsublinear robust regret, even though the expected number of outliers is linear.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:14:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["van Erven", "Tim", ""], ["Sachs", "Sarah", ""], ["Koolen", "Wouter M.", ""], ["Kot\u0142owski", "Wojciech", ""]]}, {"id": "2107.01892", "submitter": "Weiyue Su", "authors": "Weiyue Su, Zeyang Fang, Hui Zhong, Huijuan Wang, Siming Dai, Zhengjie\n  Huang, Yunsheng Shi, Shikun Feng, Zeyu Chen", "title": "NOTE: Solution for KDD-CUP 2021 WikiKG90M-LSC", "comments": "The 1st solution for KDD-CUP 2021 WIKIKG90M-LSC. 7 pages, 2 figures,\n  1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WikiKG90M in KDD Cup 2021 is a large encyclopedic knowledge graph, which\ncould benefit various downstream applications such as question answering and\nrecommender systems. Participants are invited to complete the knowledge graph\nby predicting missing triplets. Recent representation learning methods have\nachieved great success on standard datasets like FB15k-237. Thus, we train the\nadvanced algorithms in different domains to learn the triplets, including OTE,\nQuatE, RotatE and TransE. Significantly, we modified OTE into NOTE (short for\nNorm-OTE) for better performance. Besides, we use both the DeepWalk and the\npost-smoothing technique to capture the graph structure for supplementation. In\naddition to the representations, we also use various statistical probabilities\namong the head entities, the relations and the tail entities for the final\nprediction. Experimental results show that the ensemble of state-of-the-art\nrepresentation learning methods could draw on each others strengths. And we\ndevelop feature engineering from validation candidates for further\nimprovements. Please note that we apply the same strategy on the test set for\nfinal inference. And these features may not be practical in the real world when\nconsidering ranking against all the entities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:30:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Su", "Weiyue", ""], ["Fang", "Zeyang", ""], ["Zhong", "Hui", ""], ["Wang", "Huijuan", ""], ["Dai", "Siming", ""], ["Huang", "Zhengjie", ""], ["Shi", "Yunsheng", ""], ["Feng", "Shikun", ""], ["Chen", "Zeyu", ""]]}, {"id": "2107.01894", "submitter": "Maliheh Izadi", "authors": "Pooya Rostami Mazrae, Maliheh Izadi, Abbas Heydarnoori", "title": "Automated Recovery of Issue-Commit Links Leveraging Both Textual and\n  Non-textual Data", "comments": "To appear in the Proceedings of the 37th IEEE Conference on Software\n  Maintenance and Evolution (ICSME)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An issue documents discussions around required changes in issue-tracking\nsystems, while a commit contains the change itself in the version control\nsystems. Recovering links between issues and commits can facilitate many\nsoftware evolution tasks such as bug localization, and software documentation.\nA previous study on over half a million issues from GitHub reports only about\n42.2% of issues are manually linked by developers to their pertinent commits.\nAutomating the linking of commit-issue pairs can contribute to the improvement\nof the said tasks. By far, current state-of-the-art approaches for automated\ncommit-issue linking suffer from low precision, leading to unreliable results,\nsometimes to the point that imposes human supervision on the predicted links.\nThe low performance gets even more severe when there is a lack of textual\ninformation in either commits or issues. Current approaches are also proven\ncomputationally expensive.\n  We propose Hybrid-Linker to overcome such limitations by exploiting two\ninformation channels; (1) a non-textual-based component that operates on\nnon-textual, automatically recorded information of the commit-issue pairs to\npredict a link, and (2) a textual-based one which does the same using textual\ninformation of the commit-issue pairs. Then, combining the results from the two\nclassifiers, Hybrid-Linker makes the final prediction. Thus, every time one\ncomponent falls short in predicting a link, the other component fills the gap\nand improves the results. We evaluate Hybrid-Linker against competing\napproaches, namely FRLink and DeepLink on a dataset of 12 projects.\nHybrid-Linker achieves 90.1%, 87.8%, and 88.9% based on recall, precision, and\nF-measure, respectively. It also outperforms FRLink and DeepLink by 31.3%, and\n41.3%, regarding the F-measure. Moreover, Hybrid-Linker exhibits extensive\nimprovements in terms of performance as well.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:38:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mazrae", "Pooya Rostami", ""], ["Izadi", "Maliheh", ""], ["Heydarnoori", "Abbas", ""]]}, {"id": "2107.01895", "submitter": "Yipeng Zhou", "authors": "Yipeng Zhou and Xuezheng Liu and Yao Fu and Di Wu and Chao Li and Shui\n  Yu", "title": "Optimizing the Numbers of Queries and Replies in Federated Learning with\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) empowers distributed clients to collaboratively train\na shared machine learning model through exchanging parameter information.\nDespite the fact that FL can protect clients' raw data, malicious users can\nstill crack original data with disclosed parameters. To amend this flaw,\ndifferential privacy (DP) is incorporated into FL clients to disturb original\nparameters, which however can significantly impair the accuracy of the trained\nmodel. In this work, we study a crucial question which has been vastly\noverlooked by existing works: what are the optimal numbers of queries and\nreplies in FL with DP so that the final model accuracy is maximized. In FL, the\nparameter server (PS) needs to query participating clients for multiple global\niterations to complete training. Each client responds a query from the PS by\nconducting a local iteration. Our work investigates how many times the PS\nshould query clients and how many times each client should reply the PS. We\ninvestigate two most extensively used DP mechanisms (i.e., the Laplace\nmechanism and Gaussian mechanisms). Through conducting convergence rate\nanalysis, we can determine the optimal numbers of queries and replies in FL\nwith DP so that the final model accuracy can be maximized. Finally, extensive\nexperiments are conducted with publicly available datasets: MNIST and FEMNIST,\nto verify our analysis and the results demonstrate that properly setting the\nnumbers of queries and replies can significantly improve the final model\naccuracy in FL with DP.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:42:56 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhou", "Yipeng", ""], ["Liu", "Xuezheng", ""], ["Fu", "Yao", ""], ["Wu", "Di", ""], ["Li", "Chao", ""], ["Yu", "Shui", ""]]}, {"id": "2107.01900", "submitter": "Minkyo Seo", "authors": "Minkyo Seo, Yoonho Lee, Suha Kwak", "title": "On The Distribution of Penultimate Activations of Classification\n  Networks", "comments": "8 pages, UAI 2021, The first two authors equally contributed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies probability distributions of penultimate activations of\nclassification networks. We show that, when a classification network is trained\nwith the cross-entropy loss, its final classification layer forms a\nGenerative-Discriminative pair with a generative classifier based on a specific\ndistribution of penultimate activations. More importantly, the distribution is\nparameterized by the weights of the final fully-connected layer, and can be\nconsidered as a generative model that synthesizes the penultimate activations\nwithout feeding input data. We empirically demonstrate that this generative\nmodel enables stable knowledge distillation in the presence of domain shift,\nand can transfer knowledge from a classifier to variational autoencoders and\ngenerative adversarial networks for class-conditional image generation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:47:10 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 01:10:24 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Seo", "Minkyo", ""], ["Lee", "Yoonho", ""], ["Kwak", "Suha", ""]]}, {"id": "2107.01904", "submitter": "Muhammad Rizki Maulana", "authors": "Muhammad Rizki Maulana and Wee Sun Lee", "title": "Ensemble and Auxiliary Tasks for Data-Efficient Deep Reinforcement\n  Learning", "comments": "ECML-PKDD 2021. Code: https://github.com/NUS-LID/RENAULT; appendix\n  theorem numbering fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble and auxiliary tasks are both well known to improve the performance\nof machine learning models when data is limited. However, the interaction\nbetween these two methods is not well studied, particularly in the context of\ndeep reinforcement learning. In this paper, we study the effects of ensemble\nand auxiliary tasks when combined with the deep Q-learning algorithm. We\nperform a case study on ATARI games under limited data constraint. Moreover, we\nderive a refined bias-variance-covariance decomposition to analyze the\ndifferent ways of learning ensembles and using auxiliary tasks, and use the\nanalysis to help provide some understanding of the case study. Our code is open\nsource and available at https://github.com/NUS-LID/RENAULT.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:54:07 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 03:50:32 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Maulana", "Muhammad Rizki", ""], ["Lee", "Wee Sun", ""]]}, {"id": "2107.01906", "submitter": "Wa\\\"iss Azizian", "authors": "Wa\\\"iss Azizian, Franck Iutzeler, J\\'er\\^ome Malick, Panayotis\n  Mertikopoulos", "title": "The Last-Iterate Convergence Rate of Optimistic Mirror Descent in\n  Stochastic Variational Inequalities", "comments": "31 pages, 3 figures, 1 table; to be presented at the 34th Annual\n  Conference on Learning Theory (COLT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyze the local convergence rate of optimistic mirror\ndescent methods in stochastic variational inequalities, a class of optimization\nproblems with important applications to learning theory and machine learning.\nOur analysis reveals an intricate relation between the algorithm's rate of\nconvergence and the local geometry induced by the method's underlying Bregman\nfunction. We quantify this relation by means of the Legendre exponent, a notion\nthat we introduce to measure the growth rate of the Bregman divergence relative\nto the ambient norm near a solution. We show that this exponent determines both\nthe optimal step-size policy of the algorithm and the optimal rates attained,\nexplaining in this way the differences observed for some popular Bregman\nfunctions (Euclidean projection, negative entropy, fractional power, etc.).\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:54:47 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Azizian", "Wa\u00efss", ""], ["Iutzeler", "Franck", ""], ["Malick", "J\u00e9r\u00f4me", ""], ["Mertikopoulos", "Panayotis", ""]]}, {"id": "2107.01927", "submitter": "Ahmed Hashem El Fiky", "authors": "Ahmed Hashem El Fiky, Ayman El Shenawy, Mohamed Ashraf Madkour", "title": "Android Malware Category and Family Detection and Identification using\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Android malware is one of the most dangerous threats on the internet, and\nit's been on the rise for several years. Despite significant efforts in\ndetecting and classifying android malware from innocuous android applications,\nthere is still a long way to go. As a result, there is a need to provide a\nbasic understanding of the behavior displayed by the most common Android\nmalware categories and families. Each Android malware family and category has a\ndistinct objective. As a result, it has impacted every corporate area,\nincluding healthcare, banking, transportation, government, and e-commerce. In\nthis paper, we presented two machine-learning approaches for Dynamic Analysis\nof Android Malware: one for detecting and identifying Android Malware\nCategories and the other for detecting and identifying Android Malware\nFamilies, which was accomplished by analyzing a massive malware dataset with 14\nprominent malware categories and 180 prominent malware families of\nCCCS-CIC-AndMal2020 dataset on Dynamic Layers. Our approach achieves in Android\nMalware Category detection more than 96 % accurate and achieves in Android\nMalware Family detection more than 99% accurate. Our approach provides a method\nfor high-accuracy Dynamic Analysis of Android Malware while also shortening the\ntime required to analyze smartphone malware.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:48:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fiky", "Ahmed Hashem El", ""], ["Shenawy", "Ayman El", ""], ["Madkour", "Mohamed Ashraf", ""]]}, {"id": "2107.01936", "submitter": "Xi Chen", "authors": "Xi Chen, Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "Adversarial Robustness of Probabilistic Network Embedding for Link\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's networked society, many real-world problems can be formalized as\npredicting links in networks, such as Facebook friendship suggestions,\ne-commerce recommendations, and the prediction of scientific collaborations in\ncitation networks. Increasingly often, link prediction problem is tackled by\nmeans of network embedding methods, owing to their state-of-the-art\nperformance. However, these methods lack transparency when compared to simpler\nbaselines, and as a result their robustness against adversarial attacks is a\npossible point of concern: could one or a few small adversarial modifications\nto the network have a large impact on the link prediction performance when\nusing a network embedding model? Prior research has already investigated\nadversarial robustness for network embedding models, focused on classification\nat the node and graph level. Robustness with respect to the link prediction\ndownstream task, on the other hand, has been explored much less.\n  This paper contributes to filling this gap, by studying adversarial\nrobustness of Conditional Network Embedding (CNE), a state-of-the-art\nprobabilistic network embedding model, for link prediction. More specifically,\ngiven CNE and a network, we measure the sensitivity of the link predictions of\nthe model to small adversarial perturbations of the network, namely changes of\nthe link status of a node pair. Thus, our approach allows one to identify the\nlinks and non-links in the network that are most vulnerable to such\nperturbations, for further investigation by an analyst. We analyze the\ncharacteristics of the most and least sensitive perturbations, and empirically\nconfirm that our approach not only succeeds in identifying the most vulnerable\nlinks and non-links, but also that it does so in a time-efficient manner thanks\nto an effective approximation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:07:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Xi", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2107.01943", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo, Roberto Santana and Jose A. Lozano", "title": "When and How to Fool Explainable Models (and Humans) with Adversarial\n  Examples", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reliable deployment of machine learning models such as neural networks\ncontinues to be challenging due to several limitations. Some of the main\nshortcomings are the lack of interpretability and the lack of robustness\nagainst adversarial examples or out-of-distribution inputs. In this paper, we\nexplore the possibilities and limits of adversarial attacks for explainable\nmachine learning models. First, we extend the notion of adversarial examples to\nfit in explainable machine learning scenarios, in which the inputs, the output\nclassifications and the explanations of the model's decisions are assessed by\nhumans. Next, we propose a comprehensive framework to study whether (and how)\nadversarial examples can be generated for explainable models under human\nassessment, introducing novel attack paradigms. In particular, our framework\nconsiders a wide range of relevant (yet often ignored) factors such as the type\nof problem, the user expertise or the objective of the explanations in order to\nidentify the attack strategies that should be adopted in each scenario to\nsuccessfully deceive the model (and the human). These contributions intend to\nserve as a basis for a more rigorous and realistic study of adversarial\nexamples in the field of explainable machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:20:55 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""], ["Lozano", "Jose A.", ""]]}, {"id": "2107.01952", "submitter": "Giorgos Bouritsas", "authors": "Giorgos Bouritsas, Andreas Loukas, Nikolaos Karalias, Michael M.\n  Bronstein", "title": "Partition and Code: learning how to compress graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.SI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we use machine learning to compress graph data? The absence of ordering\nin graphs poses a significant challenge to conventional compression algorithms,\nlimiting their attainable gains as well as their ability to discover relevant\npatterns. On the other hand, most graph compression approaches rely on\ndomain-dependent handcrafted representations and cannot adapt to different\nunderlying graph distributions. This work aims to establish the necessary\nprinciples a lossless graph compression method should follow to approach the\nentropy storage lower bound. Instead of making rigid assumptions about the\ngraph distribution, we formulate the compressor as a probabilistic model that\ncan be learned from data and generalise to unseen instances. Our \"Partition and\nCode\" framework entails three steps: first, a partitioning algorithm decomposes\nthe graph into elementary structures, then these are mapped to the elements of\na small dictionary on which we learn a probability distribution, and finally,\nan entropy encoder translates the representation into bits. All three steps are\nparametric and can be trained with gradient descent. We theoretically compare\nthe compression quality of several graph encodings and prove, under mild\nconditions, a total ordering of their expected description lengths. Moreover,\nwe show that, under the same conditions, PnC achieves compression gains w.r.t.\nthe baselines that grow either linearly or quadratically with the number of\nvertices. Our algorithms are quantitatively evaluated on diverse real-world\nnetworks obtaining significant performance improvements with respect to\ndifferent families of non-parametric and parametric graph compressors.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:41:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Bouritsas", "Giorgos", ""], ["Loukas", "Andreas", ""], ["Karalias", "Nikolaos", ""], ["Bronstein", "Michael M.", ""]]}, {"id": "2107.01955", "submitter": "B{\\l}a\\.zej Leporowski Mr", "authors": "B{\\l}a\\.zej Leporowski, Daniella Tola, Casper Hansen and Alexandros\n  Iosifidis", "title": "Detecting Faults during Automatic Screwdriving: A Dataset and Use Case\n  of Anomaly Detection for Automatic Screwdriving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting faults in manufacturing applications can be difficult, especially\nif each fault model is to be engineered by hand. Data-driven approaches, using\nMachine Learning (ML) for detecting faults have recently gained increasing\ninterest, where a ML model can be trained on a set of data from a manufacturing\nprocess. In this paper, we present a use case of using ML models for detecting\nfaults during automated screwdriving operations, and introduce a new dataset\ncontaining fully monitored and registered data from a Universal Robot and\nOnRobot screwdriver during both normal and anomalous operations. We illustrate,\nwith the use of two time-series ML models, how to detect faults in an automated\nscrewdriving application.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:46:00 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Leporowski", "B\u0142a\u017cej", ""], ["Tola", "Daniella", ""], ["Hansen", "Casper", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2107.01959", "submitter": "Edward Wagstaff", "authors": "Edward Wagstaff, Fabian B. Fuchs, Martin Engelcke, Michael A. Osborne,\n  Ingmar Posner", "title": "Universal Approximation of Functions on Sets", "comments": "54 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling functions of sets, or equivalently, permutation-invariant\nfunctions, is a long-standing challenge in machine learning. Deep Sets is a\npopular method which is known to be a universal approximator for continuous set\nfunctions. We provide a theoretical analysis of Deep Sets which shows that this\nuniversal approximation property is only guaranteed if the model's latent space\nis sufficiently high-dimensional. If the latent space is even one dimension\nlower than necessary, there exist piecewise-affine functions for which Deep\nSets performs no better than a na\\\"ive constant baseline, as judged by\nworst-case error. Deep Sets may be viewed as the most efficient incarnation of\nthe Janossy pooling paradigm. We identify this paradigm as encompassing most\ncurrently popular set-learning methods. Based on this connection, we discuss\nthe implications of our results for set learning more broadly, and identify\nsome open questions on the universality of Janossy pooling in general.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 11:56:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wagstaff", "Edward", ""], ["Fuchs", "Fabian B.", ""], ["Engelcke", "Martin", ""], ["Osborne", "Michael A.", ""], ["Posner", "Ingmar", ""]]}, {"id": "2107.01969", "submitter": "Rohin Shah", "authors": "Rohin Shah, Cody Wild, Steven H. Wang, Neel Alex, Brandon Houghton,\n  William Guss, Sharada Mohanty, Anssi Kanervisto, Stephanie Milani, Nicholay\n  Topin, Pieter Abbeel, Stuart Russell, Anca Dragan", "title": "The MineRL BASALT Competition on Learning from Human Feedback", "comments": "NeurIPS 2021 Competition Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen a significant increase of interest in deep learning\nresearch, with many public successes that have demonstrated its potential. As\nsuch, these systems are now being incorporated into commercial products. With\nthis comes an additional challenge: how can we build AI systems that solve\ntasks where there is not a crisp, well-defined specification? While multiple\nsolutions have been proposed, in this competition we focus on one in\nparticular: learning from human feedback. Rather than training AI systems using\na predefined reward function or using a labeled dataset with a predefined set\nof categories, we instead train the AI system using a learning signal derived\nfrom some form of human feedback, which can evolve over time as the\nunderstanding of the task changes, or as the capabilities of the AI system\nimprove.\n  The MineRL BASALT competition aims to spur forward research on this important\nclass of techniques. We design a suite of four tasks in Minecraft for which we\nexpect it will be hard to write down hardcoded reward functions. These tasks\nare defined by a paragraph of natural language: for example, \"create a\nwaterfall and take a scenic picture of it\", with additional clarifying details.\nParticipants must train a separate agent for each task, using any method they\nwant. Agents are then evaluated by humans who have read the task description.\nTo help participants get started, we provide a dataset of human demonstrations\non each of the four tasks, as well as an imitation learning baseline that\nleverages these demonstrations.\n  Our hope is that this competition will improve our ability to build AI\nsystems that do what their designers intend them to do, even when the intent\ncannot be easily formalized. Besides allowing AI to solve more tasks, this can\nalso enable more effective regulation of AI systems, as well as making progress\non the value alignment problem.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:18:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Shah", "Rohin", ""], ["Wild", "Cody", ""], ["Wang", "Steven H.", ""], ["Alex", "Neel", ""], ["Houghton", "Brandon", ""], ["Guss", "William", ""], ["Mohanty", "Sharada", ""], ["Kanervisto", "Anssi", ""], ["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Abbeel", "Pieter", ""], ["Russell", "Stuart", ""], ["Dragan", "Anca", ""]]}, {"id": "2107.01979", "submitter": "Niek Tax", "authors": "Niek Tax, Kees Jan de Vries, Mathijs de Jong, Nikoleta Dosoula, Bram\n  van den Akker, Jon Smith, Olivier Thuong, Lucas Bernardi", "title": "Machine Learning for Fraud Detection in E-Commerce: A Research Agenda", "comments": "Accepted and to appear in the proceedings of the KDD 2021 co-located\n  workshop: the 2nd International Workshop on Deployable Machine Learning for\n  Security Defense (MLHat)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud detection and prevention play an important part in ensuring the\nsustained operation of any e-commerce business. Machine learning (ML) often\nplays an important role in these anti-fraud operations, but the organizational\ncontext in which these ML models operate cannot be ignored. In this paper, we\ntake an organization-centric view on the topic of fraud detection by\nformulating an operational model of the anti-fraud departments in e-commerce\norganizations. We derive 6 research topics and 12 practical challenges for\nfraud detection from this operational model. We summarize the state of the\nliterature for each research topic, discuss potential solutions to the\npractical challenges, and identify 22 open research challenges.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:37:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Tax", "Niek", ""], ["de Vries", "Kees Jan", ""], ["de Jong", "Mathijs", ""], ["Dosoula", "Nikoleta", ""], ["Akker", "Bram van den", ""], ["Smith", "Jon", ""], ["Thuong", "Olivier", ""], ["Bernardi", "Lucas", ""]]}, {"id": "2107.01983", "submitter": "Qitong Gao", "authors": "Qitong Gao, Dong Wang, Joshua D. Amason, Siyang Yuan, Chenyang Tao,\n  Ricardo Henao, Majda Hadziahmetovic, Lawrence Carin, Miroslav Pajic", "title": "Imputation-Free Learning from Incomplete Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although recent works have developed methods that can generate estimations\n(or imputations) of the missing entries in a dataset to facilitate downstream\nanalysis, most depend on assumptions that may not align with real-world\napplications and could suffer from poor performance in subsequent tasks. This\nis particularly true if the data have large missingness rates or a small\npopulation. More importantly, the imputation error could be propagated into the\nprediction step that follows, causing the gradients used to train the\nprediction models to be biased. Consequently, in this work, we introduce the\nimportance guided stochastic gradient descent (IGSGD) method to train\nmultilayer perceptrons (MLPs) and long short-term memories (LSTMs) to directly\nperform inference from inputs containing missing values without imputation.\nSpecifically, we employ reinforcement learning (RL) to adjust the gradients\nused to train the models via back-propagation. This not only reduces bias but\nallows the model to exploit the underlying information behind missingness\npatterns. We test the proposed approach on real-world time-series (i.e.,\nMIMIC-III), tabular data obtained from an eye clinic, and a standard dataset\n(i.e., MNIST), where our imputation-free predictions outperform the traditional\ntwo-step imputation-based predictions using state-of-the-art imputation\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:44:39 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gao", "Qitong", ""], ["Wang", "Dong", ""], ["Amason", "Joshua D.", ""], ["Yuan", "Siyang", ""], ["Tao", "Chenyang", ""], ["Henao", "Ricardo", ""], ["Hadziahmetovic", "Majda", ""], ["Carin", "Lawrence", ""], ["Pajic", "Miroslav", ""]]}, {"id": "2107.01988", "submitter": "Pietro Gori", "authors": "Robin Louiset and Pietro Gori and Benoit Dufumier and Josselin Houenou\n  and Antoine Grigis and Edouard Duchesnay", "title": "UCSL : A Machine Learning Expectation-Maximization framework for\n  Unsupervised Clustering driven by Supervised Learning", "comments": "ECML/PKDD 2021", "journal-ref": "ECML/PKDD 2021", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subtype Discovery consists in finding interpretable and consistent sub-parts\nof a dataset, which are also relevant to a certain supervised task. From a\nmathematical point of view, this can be defined as a clustering task driven by\nsupervised learning in order to uncover subgroups in line with the supervised\nprediction. In this paper, we propose a general Expectation-Maximization\nensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised\nLearning). Our method is generic, it can integrate any clustering method and\ncan be driven by both binary classification and regression. We propose to\nconstruct a non-linear model by merging multiple linear estimators, one per\ncluster. Each hyperplane is estimated so that it correctly discriminates - or\npredict - only one cluster. We use SVC or Logistic Regression for\nclassification and SVR for regression. Furthermore, to perform cluster analysis\nwithin a more suitable space, we also propose a dimension-reduction algorithm\nthat projects the data onto an orthonormal space relevant to the supervised\ntask. We analyze the robustness and generalization capability of our algorithm\nusing synthetic and experimental datasets. In particular, we validate its\nability to identify suitable consistent sub-types by conducting a\npsychiatric-diseases cluster analysis with known ground-truth labels. The gain\nof the proposed method over previous state-of-the-art techniques is about +1.9\npoints in terms of balanced accuracy. Finally, we make codes and examples\navailable in a scikit-learn-compatible Python package at\nhttps://github.com/neurospin-projects/2021_rlouiset_ucsl\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 12:55:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Louiset", "Robin", ""], ["Gori", "Pietro", ""], ["Dufumier", "Benoit", ""], ["Houenou", "Josselin", ""], ["Grigis", "Antoine", ""], ["Duchesnay", "Edouard", ""]]}, {"id": "2107.01994", "submitter": "Pietro Gori", "authors": "Mateus Riva and Florian Yger and Pietro Gori and Roberto M. Cesar Jr.\n  and Isabelle Bloch", "title": "Template-Based Graph Clustering", "comments": "ECML-PKDD, Workshop on Graph Embedding and Minin (GEM) 2020", "journal-ref": "ECML-PKDD, Workshop on Graph Embedding and Minin (GEM) 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel graph clustering method guided by additional information\non the underlying structure of the clusters (or communities). The problem is\nformulated as the matching of a graph to a template with smaller dimension,\nhence matching $n$ vertices of the observed graph (to be clustered) to the $k$\nvertices of a template graph, using its edges as support information, and\nrelaxed on the set of orthonormal matrices in order to find a $k$ dimensional\nembedding. With relevant priors that encode the density of the clusters and\ntheir relationships, our method outperforms classical methods, especially for\nchallenging cases.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:13:34 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Riva", "Mateus", ""], ["Yger", "Florian", ""], ["Gori", "Pietro", ""], ["Cesar", "Roberto M.", "Jr."], ["Bloch", "Isabelle", ""]]}, {"id": "2107.01996", "submitter": "Chao Wang Senior Scientist", "authors": "Chao Wang, Pengcheng An", "title": "Explainability via Interactivity? Supporting Nonexperts' Sensemaking of\n  Pretrained CNN by Interacting with Their Daily Surroundings", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research on Explainable AI (XAI) heavily targets on expert users\n(data scientists or AI developers). However, increasing importance has been\nargued for making AI more understandable to nonexperts, who are expected to\nleverage AI techniques, but have limited knowledge about AI. We present a\nmobile application to support nonexperts to interactively make sense of\nConvolutional Neural Networks (CNN); it allows users to play with a pretrained\nCNN by taking pictures of their surrounding objects. We use an up-to-date XAI\ntechnique (Class Activation Map) to intuitively visualize the model's decision\n(the most important image regions that lead to a certain result). Deployed in a\nuniversity course, this playful learning tool was found to support design\nstudents to gain vivid understandings about the capabilities and limitations of\npretrained CNNs in real-world environments. Concrete examples of students'\nplayful explorations are reported to characterize their sensemaking processes\nreflecting different depths of thought.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 19:22:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wang", "Chao", ""], ["An", "Pengcheng", ""]]}, {"id": "2107.02012", "submitter": "Prathmesh Pathwar", "authors": "Prathmesh Pathwar, Simran Gill", "title": "Tackling COVID-19 Infodemic using Deep Learning", "comments": "15 pages, 4 figures, Accepted in 4th International Conference on\n  Computational Intelligence and Data Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:07:47 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Pathwar", "Prathmesh", ""], ["Gill", "Simran", ""]]}, {"id": "2107.02025", "submitter": "Jim Samuel", "authors": "Jim Samuel, Ratnakar Palle and Eduardo Correa Soares", "title": "Textual Data Distributions: Kullback Leibler Textual Distributions\n  Contrasts on GPT-2 Generated Texts, with Supervised, Unsupervised Learning on\n  Vaccine & Market Topics & Sentiment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Efficient textual data distributions (TDD) alignment and generation are open\nresearch problems in textual analytics and NLP. It is presently difficult to\nparsimoniously and methodologically confirm that two or more natural language\ndatasets belong to similar distributions, and to identify the extent to which\ntextual data possess alignment. This study focuses on addressing a segment of\nthe broader problem described above by applying multiple supervised and\nunsupervised machine learning (ML) methods to explore the behavior of TDD by\n(i) topical alignment, and (ii) by sentiment alignment. Furthermore we use\nmultiple text generation methods including fine-tuned GPT-2, to generate text\nby topic and by sentiment. Finally we develop a unique process driven variation\nof Kullback-Leibler divergence (KLD) application to TDD, named KL Textual\nDistributions Contrasts(KL-TDC) to identify the alignment of machine generated\ntextual corpora with naturally occurring textual corpora. This study thus\nidentifies a unique approach for generating and validating TDD by topic and\nsentiment, which can be used to help address sparse data problems and other\nresearch, practice and classroom situations in need of artificially generated\ntopic or sentiment aligned textual data.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:30:46 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Samuel", "Jim", ""], ["Palle", "Ratnakar", ""], ["Soares", "Eduardo Correa", ""]]}, {"id": "2107.02027", "submitter": "Mario Michael Krell", "authors": "Matej Kosec and Sheng Fu and Mario Michael Krell", "title": "Packing: Towards 2x NLP BERT Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We find that at sequence length 512 padding tokens represent in excess of 50%\nof the Wikipedia dataset used for pretraining BERT (Bidirectional Encoder\nRepresentations from Transformers). Therefore by removing all padding we\nachieve a 2x speed-up in terms of sequences/sec. To exploit this characteristic\nof the dataset, we develop and contrast two deterministic packing algorithms.\nBoth algorithms rely on the assumption that sequences are interchangeable and\ntherefore packing can be performed on the histogram of sequence lengths, rather\nthan per sample. This transformation of the problem leads to algorithms which\nare fast and have linear complexity in dataset size. The shortest-pack-first\nhistogram-packing (SPFHP) algorithm determines the packing order for the\nWikipedia dataset of over 16M sequences in 0.02 seconds. The non-negative\nleast-squares histogram-packing (NNLSHP) algorithm converges in 28.4 seconds\nbut produces solutions which are more depth efficient, managing to get near\noptimal packing by combining a maximum of 3 sequences in one sample. Using the\ndataset with multiple sequences per sample requires additional masking in the\nattention layer and a modification of the MLM loss function. We demonstrate\nthat both of these changes are straightforward to implement and have relatively\nlittle impact on the achievable performance gain on modern hardware. Finally,\nwe pretrain BERT-Large using the packed dataset, demonstrating no loss of\nconvergence and the desired 2x speed-up.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 04:37:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Kosec", "Matej", ""], ["Fu", "Sheng", ""], ["Krell", "Mario Michael", ""]]}, {"id": "2107.02036", "submitter": "Doris Tsao", "authors": "Thomas Tsao and Doris Y. Tsao", "title": "A topological solution to object segmentation and tracking", "comments": "21 pages, 6 main figures, 3 supplemental figures, and supplementary\n  material containing mathematical proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The world is composed of objects, the ground, and the sky. Visual perception\nof objects requires solving two fundamental challenges: segmenting visual input\ninto discrete units, and tracking identities of these units despite appearance\nchanges due to object deformation, changing perspective, and dynamic occlusion.\nCurrent computer vision approaches to segmentation and tracking that approach\nhuman performance all require learning, raising the question: can objects be\nsegmented and tracked without learning? Here, we show that the mathematical\nstructure of light rays reflected from environment surfaces yields a natural\nrepresentation of persistent surfaces, and this surface representation provides\na solution to both the segmentation and tracking problems. We describe how to\ngenerate this surface representation from continuous visual input, and\ndemonstrate that our approach can segment and invariantly track objects in\ncluttered synthetic video despite severe appearance changes, without requiring\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:52:57 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Tsao", "Thomas", ""], ["Tsao", "Doris Y.", ""]]}, {"id": "2107.02039", "submitter": "Burc Gokden", "authors": "Burc Gokden", "title": "Power Law Graph Transformer for Machine Translation and Representation\n  Learning", "comments": "55 pages, 39 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the Power Law Graph Transformer, a transformer model with well\ndefined deductive and inductive tasks for prediction and representation\nlearning. The deductive task learns the dataset level (global) and instance\nlevel (local) graph structures in terms of learnable power law distribution\nparameters. The inductive task outputs the prediction probabilities using the\ndeductive task output, similar to a transductive model. We trained our model\nwith Turkish-English and Portuguese-English datasets from TED talk transcripts\nfor machine translation and compared the model performance and characteristics\nto a transformer model with scaled dot product attention trained on the same\nexperimental setup. We report BLEU scores of $17.79$ and $28.33$ on the\nTurkish-English and Portuguese-English translation tasks with our model,\nrespectively. We also show how a duality between a quantization set and\nN-dimensional manifold representation can be leveraged to transform between\nlocal and global deductive-inductive outputs using successive application of\nlinear and non-linear transformations end-to-end.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 15:59:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gokden", "Burc", ""]]}, {"id": "2107.02045", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao and Neil Zhenqiang Gong", "title": "Understanding the Security of Deepfake Detection", "comments": "To appear in SecureComm 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deepfakes pose growing challenges to the trust of information on the\nInternet. Thus, detecting deepfakes has attracted increasing attentions from\nboth academia and industry. State-of-the-art deepfake detection methods consist\nof two key components, i.e., face extractor and face classifier, which extract\nthe face region in an image and classify it to be real/fake, respectively.\nExisting studies mainly focused on improving the detection performance in\nnon-adversarial settings, leaving security of deepfake detection in adversarial\nsettings largely unexplored. In this work, we aim to bridge the gap. In\nparticular, we perform a systematic measurement study to understand the\nsecurity of the state-of-the-art deepfake detection methods in adversarial\nsettings. We use two large-scale public deepfakes data sources including\nFaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes\nare fake face images; and we train state-of-the-art deepfake detection methods.\nThese detection methods can achieve 0.94--0.99 accuracies in non-adversarial\nsettings on these datasets. However, our measurement results uncover multiple\nsecurity limitations of the deepfake detection methods in adversarial settings.\nFirst, we find that an attacker can evade a face extractor, i.e., the face\nextractor fails to extract the correct face regions, via adding small Gaussian\nnoise to its deepfake images. Second, we find that a face classifier trained\nusing deepfakes generated by one method cannot detect deepfakes generated by\nanother method, i.e., an attacker can evade detection via generating deepfakes\nusing a new method. Third, we find that an attacker can leverage backdoor\nattacks developed by the adversarial machine learning community to evade a face\nclassifier. Our results highlight that deepfake detection should consider the\nadversarial nature of the problem.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:18:21 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:04:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2107.02052", "submitter": "Mathias L\\\"owe", "authors": "Mathias L\\\"owe, Jennifer Villareale, Evan Freed, Aleksanteri Sladek,\n  Jichen Zhu, Sebastian Risi", "title": "Dealing with Adversarial Player Strategies in the Neural Network Game\n  iNNk through Ensemble Learning", "comments": "10 pages, 4 Figures. Accepted for publishing at the 16th\n  International Conference on the Foundations of Digital Games (FDG) 2021", "journal-ref": null, "doi": "10.1145/3472538.3472540", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying neural network (NN) methods in games can lead to various new and\nexciting game dynamics not previously possible. However, they also lead to new\nchallenges such as the lack of large, clean datasets, varying player skill\nlevels, and changing gameplay strategies. In this paper, we focus on the\nadversarial player strategy aspect in the game iNNk, in which players try to\ncommunicate secret code words through drawings with the goal of not being\ndeciphered by a NN. Some strategies exploit weaknesses in the NN that\nconsistently trick it into making incorrect classifications, leading to\nunbalanced gameplay. We present a method that combines transfer learning and\nensemble methods to obtain a data-efficient adaptation to these strategies.\nThis combination significantly outperforms the baseline NN across all\nadversarial player strategies despite only being trained on a limited set of\nadversarial examples. We expect the methods developed in this paper to be\nuseful for the rapidly growing field of NN-based games, which will require new\napproaches to deal with unforeseen player creativity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:25:44 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["L\u00f6we", "Mathias", ""], ["Villareale", "Jennifer", ""], ["Freed", "Evan", ""], ["Sladek", "Aleksanteri", ""], ["Zhu", "Jichen", ""], ["Risi", "Sebastian", ""]]}, {"id": "2107.02053", "submitter": "Kaiyang Zhou", "authors": "Kaiyang Zhou, Yongxin Yang, Yu Qiao, Tao Xiang", "title": "MixStyle Neural Networks for Domain Generalization and Adaptation", "comments": "Extension of https://openreview.net/forum?id=6xHJ37MVxxp. Code\n  available at https://github.com/KaiyangZhou/mixstyle-release", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) often have poor generalization\nperformance under domain shift. One way to improve domain generalization is to\ncollect diverse source data from multiple relevant domains so that a CNN model\nis allowed to learn more domain-invariant, and hence generalizable\nrepresentations. In this work, we address domain generalization with MixStyle,\na plug-and-play, parameter-free module that is simply inserted to shallow CNN\nlayers and requires no modification to training objectives. Specifically,\nMixStyle probabilistically mixes feature statistics between instances. This\nidea is inspired by the observation that visual domains can often be\ncharacterized by image styles which are in turn encapsulated within\ninstance-level feature statistics in shallow CNN layers. Therefore, inserting\nMixStyle modules in effect synthesizes novel domains albeit in an implicit way.\nMixStyle is not only simple and flexible, but also versatile -- it can be used\nfor problems whereby unlabeled images are available, such as semi-supervised\ndomain generalization and unsupervised domain adaptation, with a simple\nextension to mix feature statistics between labeled and pseudo-labeled\ninstances. We demonstrate through extensive experiments that MixStyle can\nsignificantly boost the out-of-distribution generalization performance across a\nwide range of tasks including object recognition, instance retrieval, and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:29:19 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhou", "Kaiyang", ""], ["Yang", "Yongxin", ""], ["Qiao", "Yu", ""], ["Xiang", "Tao", ""]]}, {"id": "2107.02063", "submitter": "Honghu Xue", "authors": "Honghu Xue, Rebecca Herzog, Till M Berger, Tobias B\\\"aumer, Anne\n  Weissbach, Elmar Rueckert", "title": "Using Probabilistic Movement Primitives in Analyzing Human Motion\n  Difference under Transcranial Current Stimulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical tasks such as human motion analysis, computer-aided auxiliary\nsystems have become preferred choice for human experts for its high efficiency.\nHowever, conventional approaches are typically based on user-defined features\nsuch as movement onset times, peak velocities, motion vectors or frequency\ndomain analyses. Such approaches entail careful data post-processing or\nspecific domain knowledge to achieve a meaningful feature extraction. Besides,\nthey are prone to noise and the manual-defined features could hardly be re-used\nfor other analyses. In this paper, we proposed probabilistic movement\nprimitives (ProMPs), a widely-used approach in robot skill learning, to model\nhuman motions. The benefit of ProMPs is that the features are directly learned\nfrom the data and ProMPs can capture important features describing the\ntrajectory shape, which can easily be extended to other tasks. Distinct from\nprevious research, where classification tasks are mostly investigated, we\napplied ProMPs together with a variant of Kullback-Leibler (KL) divergence to\nquantify the effect of different transcranial current stimulation methods on\nhuman motions. We presented an initial result with 10 participants. The results\nvalidate ProMPs as a robust and effective feature extractor for human motions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:46:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Xue", "Honghu", ""], ["Herzog", "Rebecca", ""], ["Berger", "Till M", ""], ["B\u00e4umer", "Tobias", ""], ["Weissbach", "Anne", ""], ["Rueckert", "Elmar", ""]]}, {"id": "2107.02069", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "SCOD: Active Object Detection for Embodied Agents using Sensory\n  Commutativity of Action Sequences", "comments": "Accepted to AAMAS 2021 (Extended Abstract)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SCOD (Sensory Commutativity Object Detection), an active method\nfor movable and immovable object detection. SCOD exploits the commutative\nproperties of action sequences, in the scenario of an embodied agent equipped\nwith first-person sensors and a continuous motor space with multiple degrees of\nfreedom. SCOD is based on playing an action sequence in two different orders\nfrom the same starting point and comparing the two final observations obtained\nafter each sequence. Our experiments on 3D realistic robotic setups (iGibson)\ndemonstrate the accuracy of SCOD and its generalization to unseen environments\nand objects. We also successfully apply SCOD on a real robot to further\nillustrate its generalization properties. With SCOD, we aim at providing a\nnovel way of approaching the problem of object discovery in the context of a\nnaive embodied agent. We provide code and a supplementary video.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:58:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "2107.02070", "submitter": "Wilson Mongwe", "authors": "Wilson Tsakane Mongwe, Rendani Mbuvha, Tshilidzi Marwala", "title": "Antithetic Riemannian Manifold And Quantum-Inspired Hamiltonian Monte\n  Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Markov Chain Monte Carlo inference of target posterior distributions in\nmachine learning is predominately conducted via Hamiltonian Monte Carlo and its\nvariants. This is due to Hamiltonian Monte Carlo based samplers ability to\nsuppress random-walk behaviour. As with other Markov Chain Monte Carlo methods,\nHamiltonian Monte Carlo produces auto-correlated samples which results in high\nvariance in the estimators, and low effective sample size rates in the\ngenerated samples. Adding antithetic sampling to Hamiltonian Monte Carlo has\nbeen previously shown to produce higher effective sample rates compared to\nvanilla Hamiltonian Monte Carlo. In this paper, we present new algorithms which\nare antithetic versions of Riemannian Manifold Hamiltonian Monte Carlo and\nQuantum-Inspired Hamiltonian Monte Carlo. The Riemannian Manifold Hamiltonian\nMonte Carlo algorithm improves on Hamiltonian Monte Carlo by taking into\naccount the local geometry of the target, which is beneficial for target\ndensities that may exhibit strong correlations in the parameters.\nQuantum-Inspired Hamiltonian Monte Carlo is based on quantum particles that can\nhave random mass. Quantum-Inspired Hamiltonian Monte Carlo uses a random mass\nmatrix which results in better sampling than Hamiltonian Monte Carlo on spiky\nand multi-modal distributions such as jump diffusion processes. The analysis is\nperformed on jump diffusion process using real world financial market data, as\nwell as on real world benchmark classification tasks using Bayesian logistic\nregression.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:03:07 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mongwe", "Wilson Tsakane", ""], ["Mbuvha", "Rendani", ""], ["Marwala", "Tshilidzi", ""]]}, {"id": "2107.02071", "submitter": "Xiao-Lei Zhang", "authors": "Xiao-Lei Zhang", "title": "Unsupervised Ensemble Selection for Multilayer Bootstrap Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer bootstrap network (MBN), which is a recent simple unsupervised\ndeep model, is sensitive to its network structure. How to select a proper\nnetwork structure that may be dramatically different in different applications\nis a hard issue, given little prior knowledge of data. In this paper, we\nexplore ensemble learning and selection techniques for determining the optimal\nnetwork structure of MBN automatically. Specifically, we first propose an MBN\nensemble (MBN-E) algorithm which concatenates the sparse outputs of a set of\nMBN base models with different network structures into a new representation.\nThen, we take the new representation as a reference for selecting the optimal\nMBN base models. The ensemble selection criteria can be categorized into two\nclasses. The first kind employs optimization-like selection criteria, under the\nassumption that the number of classes of data is known as a prior. The second\nkind proposes distribution divergence criteria, when such a prior is\nunavailable. Experimental results on several benchmark datasets show that MBN-E\nyields good performance that is close to the optimal performance of MBN, while\nthe ensemble selection techniques for MBN-E can further improve the\nperformance. More importantly, MBN-E and its ensemble selection techniques\nmaintain the simple formulation of MBN, and act like off-the-shelf methods that\nreach the state-of-the-art performance without manual hyperparameter tuning.\nThe source code is available at http://www.xiaolei-zhang.net/mbn-e.htm.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:03:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Xiao-Lei", ""]]}, {"id": "2107.02085", "submitter": "Anand Dixit", "authors": "Anand Dixit and Vivekananda Roy", "title": "Analyzing Relevance Vector Machines using a single penalty approach", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance vector machine (RVM) is a popular sparse Bayesian learning model\ntypically used for prediction. Recently it has been shown that improper priors\nassumed on multiple penalty parameters in RVM may lead to an improper\nposterior. Currently in the literature, the sufficient conditions for posterior\npropriety of RVM do not allow improper priors over the multiple penalty\nparameters. In this article, we propose a single penalty relevance vector\nmachine (SPRVM) model in which multiple penalty parameters are replaced by a\nsingle penalty and we consider a semi Bayesian approach for fitting the SPRVM.\nThe necessary and sufficient conditions for posterior propriety of SPRVM are\nmore liberal than those of RVM and allow for several improper priors over the\npenalty parameter. Additionally, we also prove the geometric ergodicity of the\nGibbs sampler used to analyze the SPRVM model and hence can estimate the\nasymptotic standard errors associated with the Monte Carlo estimate of the\nmeans of the posterior predictive distribution. Such a Monte Carlo standard\nerror cannot be computed in the case of RVM, since the rate of convergence of\nthe Gibbs sampler used to analyze RVM is not known. The predictive performance\nof RVM and SPRVM is compared by analyzing three real life datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:26:09 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dixit", "Anand", ""], ["Roy", "Vivekananda", ""]]}, {"id": "2107.02095", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "Are standard Object Segmentation models sufficient for Learning\n  Affordance Segmentation?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affordances are the possibilities of actions the environment offers to the\nindividual. Ordinary objects (hammer, knife) usually have many affordances\n(grasping, pounding, cutting), and detecting these allow artificial agents to\nunderstand what are their possibilities in the environment, with obvious\napplication in Robotics. Proposed benchmarks and state-of-the-art prediction\nmodels for supervised affordance segmentation are usually modifications of\npopular object segmentation models such as Mask R-CNN. We observe that\ntheoretically, these popular object segmentation methods should be sufficient\nfor detecting affordances masks. So we ask the question: is it necessary to\ntailor new architectures to the problem of learning affordances? We show that\napplying the out-of-the-box Mask R-CNN to the problem of affordances\nsegmentation outperforms the current state-of-the-art. We conclude that the\nproblem of supervised affordance segmentation is included in the problem of\nobject segmentation and argue that better benchmarks for affordance learning\nshould include action capacities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:34:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "2107.02128", "submitter": "Thomas Konstantinovsky", "authors": "Thomas Konstantinovsky, Matan Mizrachi", "title": "On Bi-gram Graph Attributes", "comments": "7 pages,8 figures", "journal-ref": null, "doi": "10.5539/cis.v14n3p78", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new approach to text semantic analysis and general corpus\nanalysis using, as termed in this article, a \"bi-gram graph\" representation of\na corpus. The different attributes derived from graph theory are measured and\nanalyzed as unique insights or against other corpus graphs. We observe a vast\ndomain of tools and algorithms that can be developed on top of the graph\nrepresentation; creating such a graph proves to be computationally cheap, and\nmuch of the heavy lifting is achieved via basic graph calculations.\nFurthermore, we showcase the different use-cases for the bi-gram graphs and how\nscalable it proves to be when dealing with large datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 16:36:19 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Konstantinovsky", "Thomas", ""], ["Mizrachi", "Matan", ""]]}, {"id": "2107.02139", "submitter": "Lin Chen", "authors": "Lin Chen, Hossein Esfandiari, Gang Fu, Vahab S. Mirrokni, Qian Yu", "title": "Feature Cross Search via Submodular Optimization", "comments": "Accepted to ESA 2021. Authors are ordered alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study feature cross search as a fundamental primitive in\nfeature engineering. The importance of feature cross search especially for the\nlinear model has been known for a while, with well-known textbook examples. In\nthis problem, the goal is to select a small subset of features, combine them to\nform a new feature (called the crossed feature) by considering their Cartesian\nproduct, and find feature crosses to learn an \\emph{accurate} model. In\nparticular, we study the problem of maximizing a normalized Area Under the\nCurve (AUC) of the linear model trained on the crossed feature column.\n  First, we show that it is not possible to provide an $n^{1/\\log\\log\nn}$-approximation algorithm for this problem unless the exponential time\nhypothesis fails. This result also rules out the possibility of solving this\nproblem in polynomial time unless $\\mathsf{P}=\\mathsf{NP}$. On the positive\nside, by assuming the \\naive\\ assumption, we show that there exists a simple\ngreedy $(1-1/e)$-approximation algorithm for this problem. This result is\nestablished by relating the AUC to the total variation of the commutator of two\nprobability measures and showing that the total variation of the commutator is\nmonotone and submodular. To show this, we relate the submodularity of this\nfunction to the positive semi-definiteness of a corresponding kernel matrix.\nThen, we use Bochner's theorem to prove the positive semi-definiteness by\nshowing that its inverse Fourier transform is non-negative everywhere. Our\ntechniques and structural results might be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 16:58:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Lin", ""], ["Esfandiari", "Hossein", ""], ["Fu", "Gang", ""], ["Mirrokni", "Vahab S.", ""], ["Yu", "Qian", ""]]}, {"id": "2107.02145", "submitter": "Mark Grobman", "authors": "Niv Vosco and Alon Shenkler and Mark Grobman", "title": "Tiled Squeeze-and-Excite: Channel Attention With Local Spatial Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the amount of spatial context required for\nchannel attention. To this end we study the popular squeeze-and-excite (SE)\nblock which is a simple and lightweight channel attention mechanism. SE blocks\nand its numerous variants commonly use global average pooling (GAP) to create a\nsingle descriptor for each channel. Here, we empirically analyze the amount of\nspatial context needed for effective channel attention and find that limited\nlocalcontext on the order of seven rows or columns of the original image is\nsufficient to match the performance of global context. We propose tiled\nsqueeze-and-excite (TSE), which is a framework for building SE-like blocks that\nemploy several descriptors per channel, with each descriptor based on local\ncontext only. We further show that TSE is a drop-in replacement for the SE\nblock and can be used in existing SE networks without re-training. This implies\nthat local context descriptors are similar both to each other and to the global\ncontext descriptor. Finally, we show that TSE has important practical\nimplications for deployment of SE-networks to dataflow AI accelerators due to\ntheir reduced pipeline buffering requirements. For example, using TSE reduces\nthe amount of activation pipeline buffering in EfficientDetD2 by 90% compared\nto SE (from 50M to 4.77M) without loss of accuracy. Our code and pre-trained\nmodels will be publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:10:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Vosco", "Niv", ""], ["Shenkler", "Alon", ""], ["Grobman", "Mark", ""]]}, {"id": "2107.02168", "submitter": "Dongqi Fu", "authors": "Dongqi Fu, Jingrui He", "title": "DPPIN: A Biological Dataset of Dynamic Protein-Protein Interaction\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, many network representation learning algorithms and downstream\nnetwork mining tasks have already paid attention to dynamic networks or\ntemporal networks, which are more suitable for real-world complex scenarios by\nmodeling evolving patterns and temporal dependencies between node interactions.\nMoreover, representing and mining temporal networks have a wide range of\napplications, such as fraud detection, social network analysis, and drug\ndiscovery. To contribute to the network representation learning and network\nmining research community, in this paper, we generate a new biological dataset\nof dynamic protein-protein interaction networks (i.e., DPPIN), which consists\nof twelve dynamic protein-level interaction networks of yeast cells at\ndifferent scales. We first introduce the generation process of DPPIN. To\ndemonstrate the value of our published dataset DPPIN, we then list the\npotential applications that would be benefited. Furthermore, we design dynamic\nlocal clustering, dynamic spectral clustering, dynamic subgraph matching,\ndynamic node classification, and dynamic graph classification experiments,\nwhere DPPIN indicates future research opportunities for some tasks by\npresenting challenges on state-of-the-art baseline algorithms. Finally, we\nidentify future directions for improving this dataset utility and welcome\ninputs from the community. All resources of this work are deployed and publicly\navailable at https://github.com/DongqiFu/DPPIN.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:52:55 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fu", "Dongqi", ""], ["He", "Jingrui", ""]]}, {"id": "2107.02170", "submitter": "Wei-Lun Chao", "authors": "Tai-Yu Pan, Cheng Zhang, Yandong Li, Hexiang Hu, Dong Xuan, Soravit\n  Changpinyo, Boqing Gong, Wei-Lun Chao", "title": "On Model Calibration for Long-Tailed Object Detection and Instance\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Vanilla models for object detection and instance segmentation suffer from the\nheavy bias toward detecting frequent objects in the long-tailed setting.\nExisting methods address this issue mostly during training, e.g., by\nre-sampling or re-weighting. In this paper, we investigate a largely overlooked\napproach -- post-processing calibration of confidence scores. We propose\nNorCal, Normalized Calibration for long-tailed object detection and instance\nsegmentation, a simple and straightforward recipe that reweighs the predicted\nscores of each class by its training sample size. We show that separately\nhandling the background class and normalizing the scores over classes for each\nproposal are keys to achieving superior performance. On the LVIS dataset,\nNorCal can effectively improve nearly all the baseline models not only on rare\nclasses but also on common and frequent classes. Finally, we conduct extensive\nanalysis and ablation studies to offer insights into various modeling choices\nand mechanisms of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:57:20 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Pan", "Tai-Yu", ""], ["Zhang", "Cheng", ""], ["Li", "Yandong", ""], ["Hu", "Hexiang", ""], ["Xuan", "Dong", ""], ["Changpinyo", "Soravit", ""], ["Gong", "Boqing", ""], ["Chao", "Wei-Lun", ""]]}, {"id": "2107.02173", "submitter": "Alexander Hoyle", "authors": "Alexander Hoyle, Pranav Goel, Denis Peskov, Andrew Hian-Cheong, Jordan\n  Boyd-Graber, Philip Resnik", "title": "Is Automated Topic Model Evaluation Broken?: The Incoherence of\n  Coherence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic model evaluation, like evaluation of other unsupervised methods, can be\ncontentious. However, the field has coalesced around automated estimates of\ntopic coherence, which rely on the frequency of word co-occurrences in a\nreference corpus. Recent models relying on neural components surpass classical\ntopic models according to these metrics. At the same time, unlike classical\nmodels, the practice of neural topic model evaluation suffers from a validation\ngap: automatic coherence for neural models has not been validated using human\nexperimentation. In addition, as we show via a meta-analysis of topic modeling\nliterature, there is a substantial standardization gap in the use of automated\ntopic modeling benchmarks. We address both the standardization gap and the\nvalidation gap. Using two of the most widely used topic model evaluation\ndatasets, we assess a dominant classical model and two state-of-the-art neural\nmodels in a systematic, clearly documented, reproducible way. We use automatic\ncoherence along with the two most widely accepted human judgment tasks, namely,\ntopic rating and word intrusion. Automated evaluation will declare one model\nsignificantly different from another when corresponding human evaluations do\nnot, calling into question the validity of fully automatic evaluations\nindependent of human judgments.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:58:52 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Hoyle", "Alexander", ""], ["Goel", "Pranav", ""], ["Peskov", "Denis", ""], ["Hian-Cheong", "Andrew", ""], ["Boyd-Graber", "Jordan", ""], ["Resnik", "Philip", ""]]}, {"id": "2107.02174", "submitter": "Yuxin Fang", "authors": "Yuxin Fang, Xinggang Wang, Rui Wu, Jianwei Niu, Wenyu Liu", "title": "What Makes for Hierarchical Vision Transformer?", "comments": "Preprint. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that hierarchical Vision Transformer with interleaved\nnon-overlapped intra window self-attention \\& shifted window self-attention is\nable to achieve state-of-the-art performance in various visual recognition\ntasks and challenges CNN's dense sliding window paradigm. Most follow-up works\ntry to replace shifted window operation with other kinds of cross window\ncommunication while treating self-attention as the de-facto standard for intra\nwindow information aggregation. In this short preprint, we question whether\nself-attention is the only choice for hierarchical Vision Transformer to attain\nstrong performance, and what makes for hierarchical Vision Transformer? We\nreplace self-attention layers in Swin Transformer and Shuffle Transformer with\nsimple linear mapping and keep other components unchanged. The resulting\narchitecture with 25.4M parameters and 4.2G FLOPs achieves 80.5\\% Top-1\naccuracy, compared to 81.3\\% for Swin Transformer with 28.3M parameters and\n4.5G FLOPs. We also experiment with other alternatives to self-attention for\ncontext aggregation inside each non-overlapped window, which all give similar\ncompetitive results under the same architecture. Our study reveals that the\n\\textbf{macro architecture} of Swin model families (i.e., interleaved intra\nwindow \\& cross window communications), other than specific aggregation layers\nor specific means of cross window communication, may be more responsible for\nits strong performance and is the real challenger to CNN's dense sliding window\nparadigm.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:59:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Fang", "Yuxin", ""], ["Wang", "Xinggang", ""], ["Wu", "Rui", ""], ["Niu", "Jianwei", ""], ["Liu", "Wenyu", ""]]}, {"id": "2107.02189", "submitter": "Eugene Vorontsov", "authors": "Eugene Vorontsov, Samuel Kadoury", "title": "Label noise in segmentation networks : mitigation must deal with bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imperfect labels limit the quality of predictions learned by deep neural\nnetworks. This is particularly relevant in medical image segmentation, where\nreference annotations are difficult to collect and vary significantly even\nacross expert annotators. Prior work on mitigating label noise focused on\nsimple models of mostly uniform noise. In this work, we explore biased and\nunbiased errors artificially introduced to brain tumour annotations on MRI\ndata. We found that supervised and semi-supervised segmentation methods are\nrobust or fairly robust to unbiased errors but sensitive to biased errors. It\nis therefore important to identify the sorts of errors expected in medical\nimage labels and especially mitigate the biased errors.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:00:07 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Vorontsov", "Eugene", ""], ["Kadoury", "Samuel", ""]]}, {"id": "2107.02191", "submitter": "Aljaz Bozic", "authors": "Alja\\v{z} Bo\\v{z}i\\v{c}, Pablo Palafox, Justus Thies, Angela Dai,\n  Matthias Nie{\\ss}ner", "title": "TransformerFusion: Monocular RGB Scene Reconstruction using Transformers", "comments": "Video: https://youtu.be/LIpTKYfKSqw", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce TransformerFusion, a transformer-based 3D scene reconstruction\napproach. From an input monocular RGB video, the video frames are processed by\na transformer network that fuses the observations into a volumetric feature\ngrid representing the scene; this feature grid is then decoded into an implicit\n3D scene representation. Key to our approach is the transformer architecture\nthat enables the network to learn to attend to the most relevant image frames\nfor each 3D location in the scene, supervised only by the scene reconstruction\ntask. Features are fused in a coarse-to-fine fashion, storing fine-level\nfeatures only where needed, requiring lower memory storage and enabling fusion\nat interactive rates. The feature grid is then decoded to a higher-resolution\nscene reconstruction, using an MLP-based surface occupancy prediction from\ninterpolated coarse-to-fine 3D features. Our approach results in an accurate\nsurface reconstruction, outperforming state-of-the-art multi-view stereo depth\nestimation methods, fully-convolutional 3D reconstruction approaches, and\napproaches using LSTM- or GRU-based recurrent networks for video sequence\nfusion.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:00:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bo\u017ei\u010d", "Alja\u017e", ""], ["Palafox", "Pablo", ""], ["Thies", "Justus", ""], ["Dai", "Angela", ""], ["Nie\u00dfner", "Matthias", ""]]}, {"id": "2107.02192", "submitter": "Wei Ping", "authors": "Chen Zhu, Wei Ping, Chaowei Xiao, Mohammad Shoeybi, Tom Goldstein,\n  Anima Anandkumar, Bryan Catanzaro", "title": "Long-Short Transformer: Efficient Transformers for Language and Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformers have achieved success in both language and vision domains.\nHowever, it is prohibitively expensive to scale them to long sequences such as\nlong documents or high-resolution images, because self-attention mechanism has\nquadratic time and memory complexities with respect to the input sequence\nlength. In this paper, we propose Long-Short Transformer (Transformer-LS), an\nefficient self-attention mechanism for modeling long sequences with linear\ncomplexity for both language and vision tasks. It aggregates a novel long-range\nattention with dynamic projection to model distant correlations and a\nshort-term attention to capture fine-grained local correlations. We propose a\ndual normalization strategy to account for the scale mismatch between the two\nattention mechanisms. Transformer-LS can be applied to both autoregressive and\nbidirectional models without additional complexity. Our method outperforms the\nstate-of-the-art models on multiple tasks in language and vision domains,\nincluding the Long Range Arena benchmark, autoregressive language modeling, and\nImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on\nenwik8 using half the number of parameters than previous method, while being\nfaster and is able to handle 3x as long sequences compared to its\nfull-attention version on the same hardware. On ImageNet, it can obtain the\nstate-of-the-art results (e.g., a moderate size of 55.8M model solely trained\non 224x224 ImageNet-1K can obtain Top-1 accuracy 84.1%), while being more\nscalable on high-resolution images. The source code and models are released at\nhttps://github.com/NVIDIA/transformer-ls .\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:00:14 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 19:34:30 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhu", "Chen", ""], ["Ping", "Wei", ""], ["Xiao", "Chaowei", ""], ["Shoeybi", "Mohammad", ""], ["Goldstein", "Tom", ""], ["Anandkumar", "Anima", ""], ["Catanzaro", "Bryan", ""]]}, {"id": "2107.02195", "submitter": "Anssi Kanervisto", "authors": "Shashank Hegde, Anssi Kanervisto, Aleksei Petrenko", "title": "Agents that Listen: High-Throughput Reinforcement Learning with Multiple\n  Sensory Systems", "comments": "To appear in IEEE Conference on Games 2021. Video demonstrations and\n  experiment can be found at https://sites.google.com/view/sound-rl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and other intelligent animals evolved highly sophisticated perception\nsystems that combine multiple sensory modalities. On the other hand,\nstate-of-the-art artificial agents rely mostly on visual inputs or structured\nlow-dimensional observations provided by instrumented environments. Learning to\nact based on combined visual and auditory inputs is still a new topic of\nresearch that has not been explored beyond simple scenarios. To facilitate\nprogress in this area we introduce a new version of VizDoom simulator to create\na highly efficient learning environment that provides raw audio observations.\nWe study the performance of different model architectures in a series of tasks\nthat require the agent to recognize sounds and execute instructions given in\nnatural language. Finally, we train our agent to play the full game of Doom and\nfind that it can consistently defeat a traditional vision-based adversary. We\nare currently in the process of merging the augmented simulator with the main\nViZDoom code repository. Video demonstrations and experiment code can be found\nat https://sites.google.com/view/sound-rl.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:00:50 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Hegde", "Shashank", ""], ["Kanervisto", "Anssi", ""], ["Petrenko", "Aleksei", ""]]}, {"id": "2107.02211", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Rokas Pe\\v{c}iulis and Mantas Luko\\v{s}evi\\v{c}ius and Algimantas\n  Kri\\v{s}\\v{c}iukaitis and Robertas Petrolis and Dovil\\.e Buteikien\\.e", "title": "Automated age-related macular degeneration area estimation -- first\n  results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to research an automatic method for detecting Age-related\nMacular Degeneration (AMD) lesions in RGB eye fundus images. For this, we align\ninvasively obtained eye fundus contrast images (the \"golden standard\"\ndiagnostic) to the RGB ones and use them to hand-annotate the lesions. This is\ndone using our custom-made tool. Using the data, we train and test five\ndifferent convolutional neural networks: a custom one to classify healthy and\nAMD-affected eye fundi, and four well-known networks: ResNet50, ResNet101,\nMobileNetV3, and UNet to segment (localize) the AMD lesions in the affected eye\nfundus images. We achieve 93.55% accuracy or 69.71% Dice index as the\npreliminary best results in segmentation with MobileNetV3.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:29:56 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Pe\u010diulis", "Rokas", ""], ["Luko\u0161evi\u010dius", "Mantas", ""], ["Kri\u0161\u010diukaitis", "Algimantas", ""], ["Petrolis", "Robertas", ""], ["Buteikien\u0117", "Dovil\u0117", ""]]}, {"id": "2107.02212", "submitter": "Kristy Choi", "authors": "Kristy Choi, Madeline Liao, Stefano Ermon", "title": "Featurized Density Ratio Estimation", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Density ratio estimation serves as an important technique in the unsupervised\nmachine learning toolbox. However, such ratios are difficult to estimate for\ncomplex, high-dimensional data, particularly when the densities of interest are\nsufficiently different. In our work, we propose to leverage an invertible\ngenerative model to map the two distributions into a common feature space prior\nto estimation. This featurization brings the densities closer together in\nlatent space, sidestepping pathological scenarios where the learned density\nratios in input space can be arbitrarily inaccurate. At the same time, the\ninvertibility of our feature map guarantees that the ratios computed in feature\nspace are equivalent to those in input space. Empirically, we demonstrate the\nefficacy of our approach in a variety of downstream tasks that require access\nto accurate density ratios such as mutual information estimation, targeted\nsampling in deep generative models, and classification with data augmentation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:30:26 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Choi", "Kristy", ""], ["Liao", "Madeline", ""], ["Ermon", "Stefano", ""]]}, {"id": "2107.02228", "submitter": "Kyeong-Ryeol Go", "authors": "Kyeongryeol Go, Seyoung Yun", "title": "Meta-learning Amidst Heterogeneity and Ambiguity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning aims to learn a model that can handle multiple tasks generated\nfrom an unknown but shared distribution. However, typical meta-learning\nalgorithms have assumed the tasks to be similar such that a single meta-learner\nis sufficient to aggregate the variations in all aspects. In addition, there\nhas been less consideration on uncertainty when limited information is given as\ncontext. In this paper, we devise a novel meta-learning framework, called\nMeta-learning Amidst Heterogeneity and Ambiguity (MAHA), that outperforms\nprevious works in terms of prediction based on its ability on task\nidentification. By extensively conducting several experiments in regression and\nclassification, we demonstrate the validity of our model, which turns out to be\nrobust to both task heterogeneity and ambiguity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:54:31 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Go", "Kyeongryeol", ""], ["Yun", "Seyoung", ""]]}, {"id": "2107.02232", "submitter": "Stefano Markidis Prof.", "authors": "Xavier Aguilar and Stefano Markidis", "title": "A Deep Learning-Based Particle-in-Cell Method for Plasma Simulations", "comments": "Submitted to AI4S Workshop at Cluster Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.plasm-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and develop a new Particle-in-Cell (PIC) method for plasma\nsimulations using Deep-Learning (DL) to calculate the electric field from the\nelectron phase space. We train a Multilayer Perceptron (MLP) and a\nConvolutional Neural Network (CNN) to solve the two-stream instability test. We\nverify that the DL-based MLP PIC method produces the correct results using the\ntwo-stream instability: the DL-based PIC provides the expected growth rate of\nthe two-stream instability. The DL-based PIC does not conserve the total energy\nand momentum. However, the DL-based PIC method is stable against the cold-beam\ninstability, affecting traditional PIC methods. This work shows that\nintegrating DL technologies into traditional computational methods is a viable\napproach for developing next-generation PIC algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:10:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Aguilar", "Xavier", ""], ["Markidis", "Stefano", ""]]}, {"id": "2107.02233", "submitter": "Salva R\\\"uhling Cachay", "authors": "Salva R\\\"uhling Cachay, Benedikt Boecking, Artur Dubrawski", "title": "End-to-End Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aggregating multiple sources of weak supervision (WS) can ease the\ndata-labeling bottleneck prevalent in many machine learning applications, by\nreplacing the tedious manual collection of ground truth labels. Current state\nof the art approaches that do not use any labeled training data, however,\nrequire two separate modeling steps: Learning a probabilistic latent variable\nmodel based on the WS sources -- making assumptions that rarely hold in\npractice -- followed by downstream model training. Importantly, the first step\nof modeling does not consider the performance of the downstream model. To\naddress these caveats we propose an end-to-end approach for directly learning\nthe downstream model by maximizing its agreement with probabilistic labels\ngenerated by reparameterizing previous probabilistic posteriors with a neural\nnetwork. Our results show improved performance over prior work in terms of end\nmodel performance on downstream test sets, as well as in terms of improved\nrobustness to dependencies among weak supervision sources.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:10:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cachay", "Salva R\u00fchling", ""], ["Boecking", "Benedikt", ""], ["Dubrawski", "Artur", ""]]}, {"id": "2107.02237", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Akshay Krishnamurthy", "title": "Efficient First-Order Contextual Bandits: Prediction, Allocation, and\n  Triangular Discrimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recurring theme in statistical learning, online learning, and beyond is\nthat faster convergence rates are possible for problems with low noise, often\nquantified by the performance of the best hypothesis; such results are known as\nfirst-order or small-loss guarantees. While first-order guarantees are\nrelatively well understood in statistical and online learning, adapting to low\nnoise in contextual bandits (and more broadly, decision making) presents major\nalgorithmic challenges. In a COLT 2017 open problem, Agarwal, Krishnamurthy,\nLangford, Luo, and Schapire asked whether first-order guarantees are even\npossible for contextual bandits and -- if so -- whether they can be attained by\nefficient algorithms. We give a resolution to this question by providing an\noptimal and efficient reduction from contextual bandits to online regression\nwith the logarithmic (or, cross-entropy) loss. Our algorithm is simple and\npractical, readily accommodates rich function classes, and requires no\ndistributional assumptions beyond realizability. In a large-scale empirical\nevaluation, we find that our approach typically outperforms comparable\nnon-first-order methods.\n  On the technical side, we show that the logarithmic loss and an\ninformation-theoretic quantity called the triangular discrimination play a\nfundamental role in obtaining first-order guarantees, and we combine this\nobservation with new refinements to the regression oracle reduction framework\nof Foster and Rakhlin. The use of triangular discrimination yields novel\nresults even for the classical statistical learning model, and we anticipate\nthat it will find broader use.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:20:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Foster", "Dylan J.", ""], ["Krishnamurthy", "Akshay", ""]]}, {"id": "2107.02239", "submitter": "Pranav Jeevan P", "authors": "Pranav Jeevan, Amit Sethi (Indian Institute of Technology Bombay)", "title": "Vision Xformers: Efficient Attention for Image Classification", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linear attention mechanisms provide hope for overcoming the bottleneck of\nquadratic complexity which restricts application of transformer models in\nvision tasks. We modify the ViT architecture to work on longer sequence data by\nreplacing the quadratic attention with efficient transformers like Performer,\nLinformer and Nystr\\\"omformer of linear complexity creating Vision X-formers\n(ViX). We show that ViX performs better than ViT in image classification\nconsuming lesser computing resources. We further show that replacing the\nembedding linear layer by convolutional layers in ViX further increases their\nperformance. Our test on recent visions transformer models like LeViT and\nCompact Convolutional Transformer (CCT) show that replacing the attention with\nNystr\\\"omformer or Performer saves GPU usage and memory without deteriorating\nperformance. Incorporating these changes can democratize transformers by making\nthem accessible to those with limited data and computing resources.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:24:23 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Jeevan", "Pranav", "", "Indian Institute of Technology Bombay"], ["Sethi", "Amit", "", "Indian Institute of Technology Bombay"]]}, {"id": "2107.02248", "submitter": "Roberto Cahuantzi", "authors": "Roberto Cahuantzi, Xinye Chen, Stefan G\\\"uttel", "title": "A comparison of LSTM and GRU networks for learning symbolic sequences", "comments": "12 pages, 8 figures, submitted to the International Conference on\n  Neural Information Processing 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore relations between the hyper-parameters of a recurrent neural\nnetwork (RNN) and the complexity of string sequences it is able to memorize. We\ncompare long short-term memory (LSTM) networks and gated recurrent units\n(GRUs). We find that an increase of RNN depth does not necessarily result in\nbetter memorization capability when the training time is constrained. Our\nresults also indicate that the learning rate and the number of units per layer\nare among the most important hyper-parameters to be tuned. Generally, GRUs\noutperform LSTM networks on low complexity sequences while on high complexity\nsequences LSTMs perform better.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:49:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cahuantzi", "Roberto", ""], ["Chen", "Xinye", ""], ["G\u00fcttel", "Stefan", ""]]}, {"id": "2107.02253", "submitter": "Petr Taborsky", "authors": "Petr Taborsky, Lars Kai Hansen", "title": "Generalization by design: Shortcuts to Generalization in Deep Learning", "comments": "16 pages + 9 pages supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We take a geometrical viewpoint and present a unifying view on supervised\ndeep learning with the Bregman divergence loss function - this entails frequent\nclassification and prediction tasks. Motivated by simulations we suggest that\nthere is principally no implicit bias of vanilla stochastic gradient descent\ntraining of deep models towards \"simpler\" functions. Instead, we show that good\ngeneralization may be instigated by bounded spectral products over layers\nleading to a novel geometric regularizer. It is revealed that in deep enough\nmodels such a regularizer enables both, extreme accuracy and generalization, to\nbe reached. We associate popular regularization techniques like weight decay,\ndrop out, batch normalization, and early stopping with this perspective. Backed\nup by theory we further demonstrate that \"generalization by design\" is\npractically possible and that good generalization may be encoded into the\nstructure of the network. We design two such easy-to-use structural\nregularizers that insert an additional \\textit{generalization layer} into a\nmodel architecture, one with a skip connection and another one with drop-out.\nWe verify our theoretical results in experiments on various feedforward and\nconvolutional architectures, including ResNets, and datasets (MNIST, CIFAR10,\nsynthetic data). We believe this work opens up new avenues of research towards\nbetter generalizing architectures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 20:01:23 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Taborsky", "Petr", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "2107.02259", "submitter": "Fabian Leinen Leinen", "authors": "Fabian Leinen, Vittorio Cozzolino, Torsten Sch\\\"on", "title": "VolNet: Estimating Human Body Part Volumes from a Single RGB Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human body volume estimation from a single RGB image is a challenging problem\ndespite minimal attention from the research community. However VolNet, an\narchitecture leveraging 2D and 3D pose estimation, body part segmentation and\nvolume regression extracted from a single 2D RGB image combined with the\nsubject's body height can be used to estimate the total body volume. VolNet is\ndesigned to predict the 2D and 3D pose as well as the body part segmentation in\nintermediate tasks. We generated a synthetic, large-scale dataset of\nphoto-realistic images of human bodies with a wide range of body shapes and\nrealistic poses called SURREALvols. By using Volnet and combining multiple\nstacked hourglass networks together with ResNeXt, our model correctly predicted\nthe volume in ~82% of cases with a 10% tolerance threshold. This is a\nconsiderable improvement compared to state-of-the-art solutions such as BodyNet\nwith only a ~38% success rate.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 20:38:44 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Leinen", "Fabian", ""], ["Cozzolino", "Vittorio", ""], ["Sch\u00f6n", "Torsten", ""]]}, {"id": "2107.02266", "submitter": "Koulik Khamaru", "authors": "Koulik Khamaru, Yash Deshpande, Lester Mackey, Martin J. Wainwright", "title": "Near-optimal inference in adaptive linear regression", "comments": "41 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When data is collected in an adaptive manner, even simple methods like\nordinary least squares can exhibit non-normal asymptotic behavior. As an\nundesirable consequence, hypothesis tests and confidence intervals based on\nasymptotic normality can lead to erroneous results. We propose an online\ndebiasing estimator to correct these distributional anomalies in least squares\nestimation. Our proposed method takes advantage of the covariance structure\npresent in the dataset and provides sharper estimates in directions for which\nmore information has accrued. We establish an asymptotic normality property for\nour proposed online debiasing estimator under mild conditions on the data\ncollection process, and provide asymptotically exact confidence intervals. We\nadditionally prove a minimax lower bound for the adaptive linear regression\nproblem, thereby providing a baseline by which to compare estimators. There are\nvarious conditions under which our proposed estimator achieves the minimax\nlower bound up to logarithmic factors. We demonstrate the usefulness of our\ntheory via applications to multi-armed bandit, autoregressive time series\nestimation, and active learning with exploration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:05:11 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 02:57:42 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Khamaru", "Koulik", ""], ["Deshpande", "Yash", ""], ["Mackey", "Lester", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "2107.02268", "submitter": "Christian Huber", "authors": "Christian Huber, Juan Hussain, Sebastian St\\\"uker, Alexander Waibel", "title": "Instant One-Shot Word-Learning for Context-Specific Neural\n  Sequence-to-Sequence Speech Recognition", "comments": "7 pages, 1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural sequence-to-sequence systems deliver state-of-the-art performance for\nautomatic speech recognition (ASR). When using appropriate modeling units,\ne.g., byte-pair encoded characters, these systems are in principal open\nvocabulary systems. In practice, however, they often fail to recognize words\nnot seen during training, e.g., named entities, numbers or technical terms. To\nalleviate this problem we supplement an end-to-end ASR system with a\nword/phrase memory and a mechanism to access this memory to recognize the words\nand phrases correctly. After the training of the ASR system, and when it has\nalready been deployed, a relevant word can be added or subtracted instantly\nwithout the need for further training. In this paper we demonstrate that\nthrough this mechanism our system is able to recognize more than 85% of newly\nadded words that it previously failed to recognize compared to a strong\nbaseline.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:08:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Huber", "Christian", ""], ["Hussain", "Juan", ""], ["St\u00fcker", "Sebastian", ""], ["Waibel", "Alexander", ""]]}, {"id": "2107.02274", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha, Pierre Gaillard", "title": "Dueling Bandits with Adversarial Sleeping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the problem of sleeping dueling bandits with stochastic\npreferences and adversarial availabilities (DB-SPAA). In almost all dueling\nbandit applications, the decision space often changes over time; eg, retail\nstore management, online shopping, restaurant recommendation, search engine\noptimization, etc. Surprisingly, this `sleeping aspect' of dueling bandits has\nnever been studied in the literature. Like dueling bandits, the goal is to\ncompete with the best arm by sequentially querying the preference feedback of\nitem pairs. The non-triviality however results due to the non-stationary item\nspaces that allow any arbitrary subsets items to go unavailable every round.\nThe goal is to find an optimal `no-regret' policy that can identify the best\navailable item at each round, as opposed to the standard `fixed best-arm regret\nobjective' of dueling bandits. We first derive an instance-specific lower bound\nfor DB-SPAA $\\Omega( \\sum_{i =1}^{K-1}\\sum_{j=i+1}^K \\frac{\\log\nT}{\\Delta(i,j)})$, where $K$ is the number of items and $\\Delta(i,j)$ is the\ngap between items $i$ and $j$. This indicates that the sleeping problem with\npreference feedback is inherently more difficult than that for classical\nmulti-armed bandits (MAB). We then propose two algorithms, with near optimal\nregret guarantees. Our results are corroborated empirically.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:14:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gaillard", "Pierre", ""]]}, {"id": "2107.02275", "submitter": "Wenting Li", "authors": "Wenting Li, Deepjyoti Deka", "title": "Physics-Informed Graph Learning for Robust Fault Location in\n  Distribution Systems", "comments": "10 pages, 8 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of distributed energy resources potentially increases power\ngrid instability. One promising strategy is to employ data in power grids to\nefficiently respond to abnormal events (e.g., faults) by detection and\nlocation. Unfortunately, most existing works lack physical interpretation and\nare vulnerable to the practical challenges: sparse observation, insufficient\nlabeled datasets, and stochastic environment. We propose a physics-informed\ngraph learning framework of two stages to handle these challenges when locating\nfaults. Stage- I focuses on informing a graph neural network (GNN) with the\ngeometrical structure of power grids; stage-II employs the physical similarity\nof labeled and unlabeled data samples to improve the location accuracy. We\nprovide a random walk-based the underpinning of designing our GNNs to address\nthe challenge of sparse observation and augment the correct prediction\nprobability. We compare our approach with three baselines in the IEEE 123-node\nbenchmark system, showing that the proposed method outperforms the others by\nsignificant margins, especially when label rates are low. Also, we validate the\nrobustness of our algorithms to out-of-distribution-data (ODD) due to topology\nchanges and load variations. Additionally, we adapt our graph learning\nframework to the IEEE 37-node test feeder and show high location performance\nwith the proposed training strategy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:18:37 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Li", "Wenting", ""], ["Deka", "Deepjyoti", ""]]}, {"id": "2107.02276", "submitter": "Hamed Yaghoobian", "authors": "Hamed Yaghoobian, Hamid R. Arabnia, Khaled Rasheed", "title": "Sarcasm Detection: A Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sarcasm detection is the task of identifying irony containing utterances in\nsentiment-bearing text. However, the figurative and creative nature of sarcasm\nposes a great challenge for affective computing systems performing sentiment\nanalysis. This article compiles and reviews the salient work in the literature\nof automatic sarcasm detection. Thus far, three main paradigm shifts have\noccurred in the way researchers have approached this task: 1) semi-supervised\npattern extraction to identify implicit sentiment, 2) use of hashtag-based\nsupervision, and 3) incorporation of context beyond target text. In this\narticle, we provide a comprehensive review of the datasets, approaches, trends,\nand issues in sarcasm and irony detection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:20:29 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 02:07:19 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yaghoobian", "Hamed", ""], ["Arabnia", "Hamid R.", ""], ["Rasheed", "Khaled", ""]]}, {"id": "2107.02278", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger, Dominique Cope, Jamie Ip, Marsha Lotosh, Aayush\n  Shah, Jenny Weng, Rebekah Tang", "title": "\"Garbage In, Garbage Out\" Revisited: What Do Machine Learning\n  Application Papers Report About Human-Labeled Training Data?", "comments": null, "journal-ref": "Quantitative Science Studies 2:2 (2021)", "doi": "10.1162/qss_a_00144", "report-no": null, "categories": "cs.LG cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised machine learning, in which models are automatically derived from\nlabeled training data, is only as good as the quality of that data. This study\nbuilds on prior work that investigated to what extent 'best practices' around\nlabeling training data were followed in applied ML publications within a single\ndomain (social media platforms). In this paper, we expand by studying\npublications that apply supervised ML in a far broader spectrum of disciplines,\nfocusing on human-labeled data. We report to what extent a random sample of ML\napplication papers across disciplines give specific details about whether best\npractices were followed, while acknowledging that a greater range of\napplication fields necessarily produces greater diversity of labeling and\nannotation methods. Because much of machine learning research and education\nonly focuses on what is done once a \"ground truth\" or \"gold standard\" of\ntraining data is available, it is especially relevant to discuss issues around\nthe equally-important aspect of whether such data is reliable in the first\nplace. This determination becomes increasingly complex when applied to a\nvariety of specialized fields, as labeling can range from a task requiring\nlittle-to-no background knowledge to one that must be performed by someone with\ncareer expertise.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:24:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Geiger", "R. Stuart", ""], ["Cope", "Dominique", ""], ["Ip", "Jamie", ""], ["Lotosh", "Marsha", ""], ["Shah", "Aayush", ""], ["Weng", "Jenny", ""], ["Tang", "Rebekah", ""]]}, {"id": "2107.02279", "submitter": "Amin Nikanjam", "authors": "Amin Nikanjam, Foutse Khomh", "title": "Design Smells in Deep Learning Programs: An Empirical Study", "comments": "Accepted for publication by ICSME 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, we are witnessing an increasing adoption of Deep Learning (DL)\nbased software systems in many industries. Designing a DL program requires\nconstructing a deep neural network (DNN) and then training it on a dataset.\nThis process requires that developers make multiple architectural (e.g., type,\nsize, number, and order of layers) and configuration (e.g., optimizer,\nregularization methods, and activation functions) choices that affect the\nquality of the DL models, and consequently software quality. An under-specified\nor poorly-designed DL model may train successfully but is likely to perform\npoorly when deployed in production. Design smells in DL programs are poor\ndesign and-or configuration decisions taken during the development of DL\ncomponents, that are likely to have a negative impact on the performance (i.e.,\nprediction accuracy) and then quality of DL based software systems. In this\npaper, we present a catalogue of 8 design smells for a popular DL architecture,\nnamely deep Feedforward Neural Networks which is widely employed in industrial\napplications. The design smells were identified through a review of the\nexisting literature on DL design and a manual inspection of 659 DL programs\nwith performance issues and design inefficiencies. The smells are specified by\ndescribing their context, consequences, and recommended refactorings. To\nprovide empirical evidence on the relevance and perceived impact of the\nproposed design smells, we conducted a survey with 81 DL developers. In\ngeneral, the developers perceived the proposed design smells as reflective of\ndesign or implementation problems, with agreement levels varying between 47\\%\nand 68\\%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:26:05 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:50:52 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nikanjam", "Amin", ""], ["Khomh", "Foutse", ""]]}, {"id": "2107.02281", "submitter": "Andrea Sebastiani", "authors": "Pasquale Cascarano, Maria Colomba Comes, Andrea Sebastiani, Arianna\n  Mencattini, Elena Loli Piccolomini, Eugenio Martinelli", "title": "DeepCEL0 for 2D Single Molecule Localization in Fluorescence Microscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.IV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fluorescence microscopy, Single Molecule Localization Microscopy (SMLM)\ntechniques aim at localizing with high precision high density fluorescent\nmolecules by stochastically activating and imaging small subsets of blinking\nemitters. Super Resolution (SR) plays an important role in this field since it\nallows to go beyond the intrinsic light diffraction limit. In this work, we\npropose a deep learning-based algorithm for precise molecule localization of\nhigh density frames acquired by SMLM techniques whose $\\ell_{2}$-based loss\nfunction is regularized by positivity and $\\ell_{0}$-based constraints. The\n$\\ell_{0}$ is relaxed through its Continuous Exact $\\ell_{0}$ (CEL0)\ncounterpart. The arising approach, named DeepCEL0, is parameter-free, more\nflexible, faster and provides more precise molecule localization maps if\ncompared to the other state-of-the-art methods. We validate our approach on\nboth simulated and real fluorescence microscopy data.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:31:46 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cascarano", "Pasquale", ""], ["Comes", "Maria Colomba", ""], ["Sebastiani", "Andrea", ""], ["Mencattini", "Arianna", ""], ["Piccolomini", "Elena Loli", ""], ["Martinelli", "Eugenio", ""]]}, {"id": "2107.02283", "submitter": "Liao Zhu", "authors": "Liao Zhu, Ningning Sun, Martin T. Wells", "title": "Clustering Structure of Microstructure Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds the clustering model of measures of market microstructure\nfeatures which are popular in predicting the stock returns. In a 10-second time\nfrequency, we study the clustering structure of different measures to find out\nthe best ones for predicting. In this way, we can predict more accurately with\na limited number of predictors, which removes the noise and makes the model\nmore interpretable.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:40:08 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Zhu", "Liao", ""], ["Sun", "Ningning", ""], ["Wells", "Martin T.", ""]]}, {"id": "2107.02287", "submitter": "Natanael Magalh\\~aes Cardoso", "authors": "N. M. Cardoso, G. B. O. Schwarz, L. O. Dias, C. R. Bom, L. Sodr\\'e\n  Jr., C. Mendes de Oliveira", "title": "Morphological Classification of Galaxies in S-PLUS using an Ensemble of\n  Convolutional Networks", "comments": "18 pages, 13 figures, codes and data available at\n  https://natanael.net, text in portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.GA cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The universe is composed of galaxies that have diverse shapes. Once the\nstructure of a galaxy is determined, it is possible to obtain important\ninformation about its formation and evolution. Morphologically classifying\ngalaxies means cataloging them according to their visual appearance and the\nclassification is linked to the physical properties of the galaxy. A\nmorphological classification made through visual inspection is subject to\nbiases introduced by subjective observations made by human volunteers. For this\nreason, systematic, objective and easily reproducible classification of\ngalaxies has been gaining importance since the astronomer Edwin Hubble created\nhis famous classification method. In this work, we combine accurate visual\nclassifications of the Galaxy Zoo project with \\emph {Deep Learning} methods.\nThe goal is to find an efficient technique at human performance level\nclassification, but in a systematic and automatic way, for classification of\nelliptical and spiral galaxies. For this, a neural network model was created\nthrough an Ensemble of four other convolutional models, allowing a greater\naccuracy in the classification than what would be obtained with any one\nindividual. Details of the individual models and improvements made are also\ndescribed. The present work is entirely based on the analysis of images (not\nparameter tables) from DR1 (www.datalab.noao.edu) of the Southern Photometric\nLocal Universe Survey (S-PLUS). In terms of classification, we achieved, with\nthe Ensemble, an accuracy of $\\approx 99 \\%$ in the test sample (using\npre-trained networks).\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:51:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cardoso", "N. M.", ""], ["Schwarz", "G. B. O.", ""], ["Dias", "L. O.", ""], ["Bom", "C. R.", ""], ["Sodr\u00e9", "L.", "Jr."], ["de Oliveira", "C. Mendes", ""]]}, {"id": "2107.02293", "submitter": "Rohollah Moosavi Tayebi", "authors": "Rohollah Moosavi Tayebi, Youqing Mu, Taher Dehkharghanian, Catherine\n  Ross, Monalisa Sur, Ronan Foley, Hamid R. Tizhoosh, and Clinton JV Campbell", "title": "Histogram of Cell Types: Deep Learning for Automated Bone Marrow\n  Cytology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bone marrow cytology is required to make a hematological diagnosis,\ninfluencing critical clinical decision points in hematology. However, bone\nmarrow cytology is tedious, limited to experienced reference centers and\nassociated with high inter-observer variability. This may lead to a delayed or\nincorrect diagnosis, leaving an unmet need for innovative supporting\ntechnologies. We have developed the first ever end-to-end deep learning-based\ntechnology for automated bone marrow cytology. Starting with a bone marrow\naspirate digital whole slide image, our technology rapidly and automatically\ndetects suitable regions for cytology, and subsequently identifies and\nclassifies all bone marrow cells in each region. This collective\ncytomorphological information is captured in a novel representation called\nHistogram of Cell Types (HCT) quantifying bone marrow cell class probability\ndistribution and acting as a cytological \"patient fingerprint\". The approach\nachieves high accuracy in region detection (0.97 accuracy and 0.99 ROC AUC),\nand cell detection and cell classification (0.75 mAP, 0.78 F1-score,\nLog-average miss rate of 0.31). HCT has potential to revolutionize\nhematopathology diagnostic workflows, leading to more cost-effective, accurate\ndiagnosis and opening the door to precision medicine.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:55:00 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 16:11:28 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Tayebi", "Rohollah Moosavi", ""], ["Mu", "Youqing", ""], ["Dehkharghanian", "Taher", ""], ["Ross", "Catherine", ""], ["Sur", "Monalisa", ""], ["Foley", "Ronan", ""], ["Tizhoosh", "Hamid R.", ""], ["Campbell", "Clinton JV", ""]]}, {"id": "2107.02295", "submitter": "Jo\\v{z}e Ro\\v{z}anec", "authors": "Georgios Sofianidis, Jo\\v{z}e M. Ro\\v{z}anec, Dunja Mladeni\\'c,\n  Dimosthenis Kyriazis", "title": "A Review of Explainable Artificial Intelligence in Manufacturing", "comments": "arXiv admin note: text overlap with arXiv:2102.13076 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of Artificial Intelligence (AI) systems in the\nmanufacturing domain enables higher production efficiency, outstanding\nperformance, and safer operations, leveraging powerful tools such as deep\nlearning and reinforcement learning techniques. Despite the high accuracy of\nthese models, they are mostly considered black boxes: they are unintelligible\nto the human. Opaqueness affects trust in the system, a factor that is critical\nin the context of decision-making. We present an overview of Explainable\nArtificial Intelligence (XAI) techniques as a means of boosting the\ntransparency of models. We analyze different metrics to evaluate these\ntechniques and describe several application scenarios in the manufacturing\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:59:55 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sofianidis", "Georgios", ""], ["Ro\u017eanec", "Jo\u017ee M.", ""], ["Mladeni\u0107", "Dunja", ""], ["Kyriazis", "Dimosthenis", ""]]}, {"id": "2107.02306", "submitter": "Artem Vysogorets", "authors": "Artem Vysogorets, Julia Kempe", "title": "Connectivity Matters: Neural Network Pruning Through the Lens of\n  Effective Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning is a fruitful area of research with surging interest\nin high sparsity regimes. Benchmarking in this domain heavily relies on\nfaithful representation of the sparsity of subnetworks, which has been\ntraditionally computed as the fraction of removed connections (direct\nsparsity). This definition, however, fails to recognize unpruned parameters\nthat detached from input or output layers of underlying subnetworks,\npotentially underestimating actual effective sparsity: the fraction of\ninactivated connections. While this effect might be negligible for moderately\npruned networks (up to 10-100 compression rates), we find that it plays an\nincreasing role for thinner subnetworks, greatly distorting comparison between\ndifferent pruning algorithms. For example, we show that effective compression\nof a randomly pruned LeNet-300-100 can be orders of magnitude larger than its\ndirect counterpart, while no discrepancy is ever observed when using SynFlow\nfor pruning [Tanaka et al., 2020]. In this work, we adopt the lens of effective\nsparsity to reevaluate several recent pruning algorithms on common benchmark\narchitectures (e.g., LeNet-300-100, VGG-19, ResNet-18) and discover that their\nabsolute and relative performance changes dramatically in this new and more\nappropriate framework. To aim for effective, rather than direct, sparsity, we\ndevelop a low-cost extension to most pruning algorithms. Further, equipped with\neffective sparsity as a reference frame, we partially reconfirm that random\npruning with appropriate sparsity allocation across layers performs as well or\nbetter than more sophisticated algorithms for pruning at initialization [Su et\nal., 2020]. In response to this observation, using a simple analogy of pressure\ndistribution in coupled cylinders from physics, we design novel layerwise\nsparsity quotas that outperform all existing baselines in the context of random\npruning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 22:36:57 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Vysogorets", "Artem", ""], ["Kempe", "Julia", ""]]}, {"id": "2107.02308", "submitter": "Joseph Ortiz", "authors": "Joseph Ortiz, Talfan Evans, Andrew J. Davison", "title": "A visual introduction to Gaussian Belief Propagation", "comments": "See online version of this article: https://gaussianbp.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we present a visual introduction to Gaussian Belief\nPropagation (GBP), an approximate probabilistic inference algorithm that\noperates by passing messages between the nodes of arbitrarily structured factor\ngraphs. A special case of loopy belief propagation, GBP updates rely only on\nlocal information and will converge independently of the message schedule. Our\nkey argument is that, given recent trends in computing hardware, GBP has the\nright computational properties to act as a scalable distributed probabilistic\ninference framework for future machine learning systems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 22:43:27 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ortiz", "Joseph", ""], ["Evans", "Talfan", ""], ["Davison", "Andrew J.", ""]]}, {"id": "2107.02320", "submitter": "Sumegha Garg", "authors": "Sumegha Garg, Pravesh K. Kothari, Pengda Liu and Ran Raz", "title": "Memory-Sample Lower Bounds for Learning Parity with Noise", "comments": "19 pages. To appear in RANDOM 2021. arXiv admin note: substantial\n  text overlap with arXiv:1708.02639", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show, for the well-studied problem of learning parity under\nnoise, where a learner tries to learn $x=(x_1,\\ldots,x_n) \\in \\{0,1\\}^n$ from a\nstream of random linear equations over $\\mathrm{F}_2$ that are correct with\nprobability $\\frac{1}{2}+\\varepsilon$ and flipped with probability\n$\\frac{1}{2}-\\varepsilon$, that any learning algorithm requires either a memory\nof size $\\Omega(n^2/\\varepsilon)$ or an exponential number of samples.\n  In fact, we study memory-sample lower bounds for a large class of learning\nproblems, as characterized by [GRT'18], when the samples are noisy. A matrix\n$M: A \\times X \\rightarrow \\{-1,1\\}$ corresponds to the following learning\nproblem with error parameter $\\varepsilon$: an unknown element $x \\in X$ is\nchosen uniformly at random. A learner tries to learn $x$ from a stream of\nsamples, $(a_1, b_1), (a_2, b_2) \\ldots$, where for every $i$, $a_i \\in A$ is\nchosen uniformly at random and $b_i = M(a_i,x)$ with probability\n$1/2+\\varepsilon$ and $b_i = -M(a_i,x)$ with probability $1/2-\\varepsilon$\n($0<\\varepsilon< \\frac{1}{2}$). Assume that $k,\\ell, r$ are such that any\nsubmatrix of $M$ of at least $2^{-k} \\cdot |A|$ rows and at least $2^{-\\ell}\n\\cdot |X|$ columns, has a bias of at most $2^{-r}$. We show that any learning\nalgorithm for the learning problem corresponding to $M$, with error, requires\neither a memory of size at least $\\Omega\\left(\\frac{k \\cdot \\ell}{\\varepsilon}\n\\right)$, or at least $2^{\\Omega(r)}$ samples. In particular, this shows that\nfor a large class of learning problems, same as those in [GRT'18], any learning\nalgorithm requires either a memory of size at least $\\Omega\\left(\\frac{(\\log\n|X|) \\cdot (\\log |A|)}{\\varepsilon}\\right)$ or an exponential number of noisy\nsamples.\n  Our proof is based on adapting the arguments in [Raz'17,GRT'18] to the noisy\ncase.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 23:34:39 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Garg", "Sumegha", ""], ["Kothari", "Pravesh K.", ""], ["Liu", "Pengda", ""], ["Raz", "Ran", ""]]}, {"id": "2107.02331", "submitter": "Siddharth Karamcheti", "authors": "Siddharth Karamcheti, Ranjay Krishna, Li Fei-Fei, Christopher D.\n  Manning", "title": "Mind Your Outliers! Investigating the Negative Impact of Outliers on\n  Active Learning for Visual Question Answering", "comments": "Accepted at ACL-IJCNLP 2021. 17 pages, 16 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning promises to alleviate the massive data needs of supervised\nmachine learning: it has successfully improved sample efficiency by an order of\nmagnitude on traditional tasks like topic classification and object\nrecognition. However, we uncover a striking contrast to this promise: across 5\nmodels and 4 datasets on the task of visual question answering, a wide variety\nof active learning approaches fail to outperform random selection. To\nunderstand this discrepancy, we profile 8 active learning methods on a\nper-example basis, and identify the problem as collective outliers -- groups of\nexamples that active learning methods prefer to acquire but models fail to\nlearn (e.g., questions that ask about text in images or require external\nknowledge). Through systematic ablation experiments and qualitative\nvisualizations, we verify that collective outliers are a general phenomenon\nresponsible for degrading pool-based active learning. Notably, we show that\nactive learning sample efficiency increases significantly as the number of\ncollective outliers in the active learning pool decreases. We conclude with a\ndiscussion and prescriptive recommendations for mitigating the effects of these\noutliers in future work.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 00:52:11 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Karamcheti", "Siddharth", ""], ["Krishna", "Ranjay", ""], ["Fei-Fei", "Li", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2107.02339", "submitter": "Harold Soh", "authors": "Kaiqi Chen, Yong Lee, Harold Soh", "title": "Multi-Modal Mutual Information (MuMMI) Training for Robust\n  Self-Supervised Deep Reinforcement Learning", "comments": "10 pages, Published in ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on learning useful and robust deep world models using\nmultiple, possibly unreliable, sensors. We find that current methods do not\nsufficiently encourage a shared representation between modalities; this can\ncause poor performance on downstream tasks and over-reliance on specific\nsensors. As a solution, we contribute a new multi-modal deep latent state-space\nmodel, trained using a mutual information lower-bound. The key innovation is a\nspecially-designed density ratio estimator that encourages consistency between\nthe latent codes of each modality. We tasked our method to learn policies (in a\nself-supervised manner) on multi-modal Natural MuJoCo benchmarks and a\nchallenging Table Wiping task. Experiments show our method significantly\noutperforms state-of-the-art deep reinforcement learning methods, particularly\nin the presence of missing observations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 01:39:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chen", "Kaiqi", ""], ["Lee", "Yong", ""], ["Soh", "Harold", ""]]}, {"id": "2107.02342", "submitter": "Shashikant Ilager Mr", "authors": "Shashikant Ilager and Rajkumar Buyya", "title": "Energy and Thermal-aware Resource Management of Cloud Data Centres: A\n  Taxonomy and Future Directions", "comments": "Submitted to ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the existing resource management approaches in Cloud\nData Centres for energy and thermal efficiency. It identifies the need for\nintegrated computing and cooling systems management and learning-based\nsolutions in resource management systems. A taxonomy on energy and thermal\nefficient resource management in data centres is proposed based on an in-depth\nanalysis of the literature. Furthermore, a detailed survey on existing\napproaches is conducted according to the taxonomy and recent advancements\nincluding machine learning-based resource management approaches and cooling\nmanagement technologies are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 01:49:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ilager", "Shashikant", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "2107.02345", "submitter": "Timothy Yu", "authors": "Ricky Chen, Timothy T. Yu, Gavin Xu, Da Ma, Marinko V. Sarunic, Mirza\n  Faisal Beg", "title": "Domain Adaptation via CycleGAN for Retina Segmentation in Optical\n  Coherence Tomography", "comments": "10 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the FDA approval of Artificial Intelligence (AI) for point-of-care\nclinical diagnoses, model generalizability is of the utmost importance as\nclinical decision-making must be domain-agnostic. A method of tackling the\nproblem is to increase the dataset to include images from a multitude of\ndomains; while this technique is ideal, the security requirements of medical\ndata is a major limitation. Additionally, researchers with developed tools\nbenefit from the addition of open-sourced data, but are limited by the\ndifference in domains. Herewith, we investigated the implementation of a\nCycle-Consistent Generative Adversarial Networks (CycleGAN) for the domain\nadaptation of Optical Coherence Tomography (OCT) volumes. This study was done\nin collaboration with the Biomedical Optics Research Group and Functional &\nAnatomical Imaging & Shape Analysis Lab at Simon Fraser University. In this\nstudy, we investigated a learning-based approach of adapting the domain of a\npublicly available dataset, UK Biobank dataset (UKB). To evaluate the\nperformance of domain adaptation, we utilized pre-existing retinal layer\nsegmentation tools developed on a different set of RETOUCH OCT data. This study\nprovides insight on state-of-the-art tools for domain adaptation compared to\ntraditional processing techniques as well as a pipeline for adapting publicly\navailable retinal data to the domains previously used by our collaborators.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:07:53 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chen", "Ricky", ""], ["Yu", "Timothy T.", ""], ["Xu", "Gavin", ""], ["Ma", "Da", ""], ["Sarunic", "Marinko V.", ""], ["Beg", "Mirza Faisal", ""]]}, {"id": "2107.02347", "submitter": "Marcus Kalander", "authors": "Yong Wen, Marcus Kalander, Chanfei Su, Lujia Pan", "title": "An Ensemble Noise-Robust K-fold Cross-Validation Selection Method for\n  Noisy Labels", "comments": "Accepted by the IJCAI2021 Weakly Supervised Representation Learning\n  (WSRL) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of training robust and accurate deep neural networks\n(DNNs) when subject to various proportions of noisy labels. Large-scale\ndatasets tend to contain mislabeled samples that can be memorized by DNNs,\nimpeding the performance. With appropriate handling, this degradation can be\nalleviated. There are two problems to consider: how to distinguish clean\nsamples and how to deal with noisy samples. In this paper, we present Ensemble\nNoise-robust K-fold Cross-Validation Selection (E-NKCVS) to effectively select\nclean samples from noisy data, solving the first problem. For the second\nproblem, we create a new pseudo label for any sample determined to have an\nuncertain or likely corrupt label. E-NKCVS obtains multiple predicted labels\nfor each sample and the entropy of these labels is used to tune the weight\ngiven to the pseudo label and the given label. Theoretical analysis and\nextensive verification of the algorithms in the noisy label setting are\nprovided. We evaluate our approach on various image and text classification\ntasks where the labels have been manually corrupted with different noise\nratios. Additionally, two large real-world noisy datasets are also used,\nClothing-1M and WebVision. E-NKCVS is empirically shown to be highly tolerant\nto considerable proportions of label noise and has a consistent improvement\nover state-of-the-art methods. Especially on more difficult datasets with\nhigher noise ratios, we can achieve a significant improvement over the\nsecond-best model. Moreover, our proposed approach can easily be integrated\ninto existing DNN methods to improve their robustness against label noise.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:14:52 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wen", "Yong", ""], ["Kalander", "Marcus", ""], ["Su", "Chanfei", ""], ["Pan", "Lujia", ""]]}, {"id": "2107.02349", "submitter": "Andrea Bajcsy", "authors": "Dylan P. Losey, Andrea Bajcsy, Marcia K. O'Malley, Anca D. Dragan", "title": "Physical Interaction as Communication: Learning Robot Objectives Online\n  from Human Corrections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a robot performs a task next to a human, physical interaction is\ninevitable: the human might push, pull, twist, or guide the robot. The\nstate-of-the-art treats these interactions as disturbances that the robot\nshould reject or avoid. At best, these robots respond safely while the human\ninteracts; but after the human lets go, these robots simply return to their\noriginal behavior. We recognize that physical human-robot interaction (pHRI) is\noften intentional -- the human intervenes on purpose because the robot is not\ndoing the task correctly. In this paper, we argue that when pHRI is intentional\nit is also informative: the robot can leverage interactions to learn how it\nshould complete the rest of its current task even after the person lets go. We\nformalize pHRI as a dynamical system, where the human has in mind an objective\nfunction they want the robot to optimize, but the robot does not get direct\naccess to the parameters of this objective -- they are internal to the human.\nWithin our proposed framework human interactions become observations about the\ntrue objective. We introduce approximations to learn from and respond to pHRI\nin real-time. We recognize that not all human corrections are perfect: often\nusers interact with the robot noisily, and so we improve the efficiency of\nrobot learning from pHRI by reducing unintended learning. Finally, we conduct\nsimulations and user studies on a robotic manipulator to compare our proposed\napproach to the state-of-the-art. Our results indicate that learning from pHRI\nleads to better task performance and improved human satisfaction.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:25:39 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Losey", "Dylan P.", ""], ["Bajcsy", "Andrea", ""], ["O'Malley", "Marcia K.", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2107.02355", "submitter": "Md Abir Hossen", "authors": "Md Abir Hossen, Prasoon K Diwaka, Shankarachary Ragi", "title": "Total Nitrogen Estimation in Agricultural Soils via Aerial Multispectral\n  Imaging and LIBS", "comments": "11 pages, 10 figures, published in scientific reports", "journal-ref": "Sci Rep 11, 12693 (2021)", "doi": "10.1038/s41598-021-90624-6", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring soil health indicators is an important and challenging task that\naffects farmers' decisions on timing, placement, and quantity of fertilizers\napplied in the farms. Most existing methods to measure soil health indicators\n(SHIs) are in-lab wet chemistry or spectroscopy-based methods, which require\nsignificant human input and effort, time-consuming, costly, and are\nlow-throughput in nature. To address this challenge, we develop an artificial\nintelligence (AI)-driven near real-time unmanned aerial vehicle (UAV)-based\nmultispectral sensing (UMS) solution to estimate total nitrogen (TN) of the\nsoil, an important macro-nutrient or SHI that directly affects the crop health.\nAccurate prediction of soil TN can significantly increase crop yield through\ninformed decision making on the timing of seed planting, and fertilizer\nquantity and timing. We train two machine learning models including multi-layer\nperceptron and support vector machine to predict the soil nitrogen using a\nsuite of data classes including multispectral characteristics of the soil and\ncrops in red, near-infrared, and green spectral bands, computed vegetation\nindices, and environmental variables including air temperature and relative\nhumidity. To generate the ground-truth data or the training data for the\nmachine learning models, we measure the total nitrogen of the soil samples\n(collected from a farm) using laser-induced breakdown spectroscopy (LIBS).\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:37:30 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Hossen", "Md Abir", ""], ["Diwaka", "Prasoon K", ""], ["Ragi", "Shankarachary", ""]]}, {"id": "2107.02358", "submitter": "Sumit Mandal", "authors": "Gokul Krishnan, Sumit K. Mandal, Chaitali Chakrabarti, Jae-sun Seo,\n  Umit Y. Ogras, Yu Cao", "title": "Impact of On-Chip Interconnect on In-Memory Acceleration of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3460233", "report-no": null, "categories": "cs.AR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the widespread use of Deep Neural Networks (DNNs), machine learning\nalgorithms have evolved in two diverse directions -- one with ever-increasing\nconnection density for better accuracy and the other with more compact sizing\nfor energy efficiency. The increase in connection density increases on-chip\ndata movement, which makes efficient on-chip communication a critical function\nof the DNN accelerator. The contribution of this work is threefold. First, we\nillustrate that the point-to-point (P2P)-based interconnect is incapable of\nhandling a high volume of on-chip data movement for DNNs. Second, we evaluate\nP2P and network-on-chip (NoC) interconnect (with a regular topology such as a\nmesh) for SRAM- and ReRAM-based in-memory computing (IMC) architectures for a\nrange of DNNs. This analysis shows the necessity for the optimal interconnect\nchoice for an IMC DNN accelerator. Finally, we perform an experimental\nevaluation for different DNNs to empirically obtain the performance of the IMC\narchitecture with both NoC-tree and NoC-mesh. We conclude that, at the tile\nlevel, NoC-tree is appropriate for compact DNNs employed at the edge, and\nNoC-mesh is necessary to accelerate DNNs with high connection density.\nFurthermore, we propose a technique to determine the optimal choice of\ninterconnect for any given DNN. In this technique, we use analytical models of\nNoC to evaluate end-to-end communication latency of any given DNN. We\ndemonstrate that the interconnect optimization in the IMC architecture results\nin up to 6$\\times$ improvement in energy-delay-area product for VGG-19\ninference compared to the state-of-the-art ReRAM-based IMC architectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:44:00 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Krishnan", "Gokul", ""], ["Mandal", "Sumit K.", ""], ["Chakrabarti", "Chaitali", ""], ["Seo", "Jae-sun", ""], ["Ogras", "Umit Y.", ""], ["Cao", "Yu", ""]]}, {"id": "2107.02359", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Prithwish Chakraborty, Mohamed Ghalwash, Oshani\n  Seneviratne, Elif K. Eyigoz, Daniel M. Gruen, Fernando Suarez Saiz, Ching-Hua\n  Chen, Pablo Meyer Rojas, Deborah L. McGuinness", "title": "Leveraging Clinical Context for User-Centered Explainability: A Diabetes\n  Use Case", "comments": "4 pages, 4 tables, 3 figures, 2.5 pages appendices To appear and\n  accepted at: KDD Workshop on Applied Data Science for Healthcare (DSHealth),\n  2021, Virtual", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Academic advances of AI models in high-precision domains, like healthcare,\nneed to be made explainable in order to enhance real-world adoption. Our past\nstudies and ongoing interactions indicate that medical experts can use AI\nsystems with greater trust if there are ways to connect the model inferences\nabout patients to explanations that are tied back to the context of use.\nSpecifically, risk prediction is a complex problem of diagnostic and\ninterventional importance to clinicians wherein they consult different sources\nto make decisions. To enable the adoption of the ever improving AI risk\nprediction models in practice, we have begun to explore techniques to\ncontextualize such models along three dimensions of interest: the patients'\nclinical state, AI predictions about their risk of complications, and\nalgorithmic explanations supporting the predictions. We validate the importance\nof these dimensions by implementing a proof-of-concept (POC) in type-2 diabetes\n(T2DM) use case where we assess the risk of chronic kidney disease (CKD) - a\ncommon T2DM comorbidity. Within the POC, we include risk prediction models for\nCKD, post-hoc explainers of the predictions, and other natural-language modules\nwhich operationalize domain knowledge and CPGs to provide context. With primary\ncare physicians (PCP) as our end-users, we present our initial results and\nclinician feedback in this paper. Our POC approach covers multiple knowledge\nsources and clinical scenarios, blends knowledge to explain data and\npredictions to PCPs, and received an enthusiastic response from our medical\nexpert.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:44:40 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:19:16 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 18:35:40 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chari", "Shruthi", ""], ["Chakraborty", "Prithwish", ""], ["Ghalwash", "Mohamed", ""], ["Seneviratne", "Oshani", ""], ["Eyigoz", "Elif K.", ""], ["Gruen", "Daniel M.", ""], ["Saiz", "Fernando Suarez", ""], ["Chen", "Ching-Hua", ""], ["Rojas", "Pablo Meyer", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2107.02361", "submitter": "Paolo Fazzini", "authors": "Paolo Fazzini, Marco Torre, Valeria Rizza and Francesco Petracchini", "title": "Effects of Smart Traffic Signal Control on Air Quality", "comments": "23 pages, 21 figures. arXiv admin note: substantial text overlap with\n  arXiv:2107.01347", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Adaptive traffic signal control (ATSC) in urban traffic networks poses a\nchallenging task due to the complicated dynamics arising in traffic systems. In\nrecent years, several approaches based on multi-agent deep reinforcement\nlearning (MARL) have been studied experimentally. These approaches propose\ndistributed techniques in which each signalized intersection is seen as an\nagent in a stochastic game whose purpose is to optimize the flow of vehicles in\nits vicinity. In this setting, the systems evolves towards an equilibrium among\nthe agents that shows beneficial for the whole traffic network. A recently\ndeveloped multi-agent variant of the well-established advantage actor-critic\n(A2C) algorithm, called MA2C (multi-agent A2C) exploits the promising idea of\nsome communication among the agents. In this view,the agents share their\nstrategies with other neighbor agents, thereby stabilizing the learning process\neven when the agents grow in number and variety. We experimented MA2C in two\ntraffic networks located in Bologna (Italy) and found that its action\ntranslates into a significant decrease of the amount of pollutants released\ninto the environment.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:48:42 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Fazzini", "Paolo", ""], ["Torre", "Marco", ""], ["Rizza", "Valeria", ""], ["Petracchini", "Francesco", ""]]}, {"id": "2107.02363", "submitter": "Andrew Davison", "authors": "Andrew Davison and Morgane Austern", "title": "Asymptotics of Network Embeddings Learned via Subsampling", "comments": "98 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network data are ubiquitous in modern machine learning, with tasks of\ninterest including node classification, node clustering and link prediction. A\nfrequent approach begins by learning an Euclidean embedding of the network, to\nwhich algorithms developed for vector-valued data are applied. For large\nnetworks, embeddings are learned using stochastic gradient methods where the\nsub-sampling scheme can be freely chosen. Despite the strong empirical\nperformance of such methods, they are not well understood theoretically. Our\nwork encapsulates representation methods using a subsampling approach, such as\nnode2vec, into a single unifying framework. We prove, under the assumption that\nthe graph is exchangeable, that the distribution of the learned embedding\nvectors asymptotically decouples. Moreover, we characterize the asymptotic\ndistribution and provided rates of convergence, in terms of the latent\nparameters, which includes the choice of loss function and the embedding\ndimension. This provides a theoretical foundation to understand what the\nembedding vectors represent and how well these methods perform on downstream\ntasks. Notably, we observe that typically used loss functions may lead to\nshortcomings, such as a lack of Fisher consistency.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 02:54:53 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Davison", "Andrew", ""], ["Austern", "Morgane", ""]]}, {"id": "2107.02367", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Alex Lamb, Kenji Kawaguchi, Anirudh Goyal, Chen Sun,\n  Michael Curtis Mozer, Yoshua Bengio", "title": "Discrete-Valued Neural Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has advanced from fully connected architectures to structured\nmodels organized into components, e.g., the transformer composed of positional\nelements, modular architectures divided into slots, and graph neural nets made\nup of nodes. In structured models, an interesting question is how to conduct\ndynamic and possibly sparse communication among the separate components. Here,\nwe explore the hypothesis that restricting the transmitted information among\ncomponents to discrete representations is a beneficial bottleneck. The\nmotivating intuition is human language in which communication occurs through\ndiscrete symbols. Even though individuals have different understandings of what\na \"cat\" is based on their specific experiences, the shared discrete token makes\nit possible for communication among individuals to be unimpeded by individual\ndifferences in internal representation. To discretize the values of concepts\ndynamically communicated among specialist components, we extend the\nquantization mechanism from the Vector-Quantized Variational Autoencoder to\nmulti-headed discretization with shared codebooks and use it for\ndiscrete-valued neural communication (DVNC). Our experiments show that DVNC\nsubstantially improves systematic generalization in a variety of architectures\n-- transformers, modular architectures, and graph neural networks. We also show\nthat the DVNC is robust to the choice of hyperparameters, making the method\nvery useful in practice. Moreover, we establish a theoretical justification of\nour discretization process, proving that it has the ability to increase noise\nrobustness and reduce the underlying dimensionality of the model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 03:09:25 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:05:59 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 18:06:52 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liu", "Dianbo", ""], ["Lamb", "Alex", ""], ["Kawaguchi", "Kenji", ""], ["Goyal", "Anirudh", ""], ["Sun", "Chen", ""], ["Mozer", "Michael Curtis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2107.02371", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Xingyu Zhou, Baekjin Kim, Ambuj Tewari, Abhishek Gupta,\n  Ness Shroff", "title": "Weighted Gaussian Process Bandits for Non-stationary Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the Gaussian process (GP) bandit optimization\nproblem in a non-stationary environment. To capture external changes, the\nblack-box function is allowed to be time-varying within a reproducing kernel\nHilbert space (RKHS). To this end, we develop WGP-UCB, a novel UCB-type\nalgorithm based on weighted Gaussian process regression. A key challenge is how\nto cope with infinite-dimensional feature maps. To that end, we leverage kernel\napproximation techniques to prove a sublinear regret bound, which is the first\n(frequentist) sublinear regret guarantee on weighted time-varying bandits with\ngeneral nonlinear rewards. This result generalizes both non-stationary linear\nbandits and standard GP-UCB algorithms. Further, a novel concentration\ninequality is achieved for weighted Gaussian process regression with general\nweights. We also provide universal upper bounds and weight-dependent upper\nbounds for weighted maximum information gains. These results are potentially of\nindependent interest for applications such as news ranking and adaptive\npricing, where weights can be adopted to capture the importance or quality of\ndata. Finally, we conduct experiments to highlight the favorable gains of the\nproposed algorithm in many cases when compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 03:37:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Deng", "Yuntian", ""], ["Zhou", "Xingyu", ""], ["Kim", "Baekjin", ""], ["Tewari", "Ambuj", ""], ["Gupta", "Abhishek", ""], ["Shroff", "Ness", ""]]}, {"id": "2107.02375", "submitter": "Miao Zhang", "authors": "Miao Zhang, Liangqiong Qu, Praveer Singh, Jayashree Kalpathy-Cramer,\n  Daniel L. Rubin", "title": "SplitAVG: A heterogeneity-aware federated deep learning method for\n  medical imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is an emerging research paradigm for enabling\ncollaboratively training deep learning models without sharing patient data.\nHowever, the data from different institutions are usually heterogeneous across\ninstitutions, which may reduce the performance of models trained using\nfederated learning. In this study, we propose a novel heterogeneity-aware\nfederated learning method, SplitAVG, to overcome the performance drops from\ndata heterogeneity in federated learning. Unlike previous federated methods\nthat require complex heuristic training or hyper parameter tuning, our SplitAVG\nleverages the simple network split and feature map concatenation strategies to\nencourage the federated model training an unbiased estimator of the target data\ndistribution. We compare SplitAVG with seven state-of-the-art federated\nlearning methods, using centrally hosted training data as the baseline on a\nsuite of both synthetic and real-world federated datasets. We find that the\nperformance of models trained using all the comparison federated learning\nmethods degraded significantly with the increasing degrees of data\nheterogeneity. In contrast, SplitAVG method achieves comparable results to the\nbaseline method under all heterogeneous settings, that it achieves 96.2% of the\naccuracy and 110.4% of the mean absolute error obtained by the baseline in a\ndiabetic retinopathy binary classification dataset and a bone age prediction\ndataset, respectively, on highly heterogeneous data partitions. We conclude\nthat SplitAVG method can effectively overcome the performance drops from\nvariability in data distributions across institutions. Experimental results\nalso show that SplitAVG can be adapted to different base networks and\ngeneralized to various types of medical imaging tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 03:58:10 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Zhang", "Miao", ""], ["Qu", "Liangqiong", ""], ["Singh", "Praveer", ""], ["Kalpathy-Cramer", "Jayashree", ""], ["Rubin", "Daniel L.", ""]]}, {"id": "2107.02377", "submitter": "Kaixuan Huang", "authors": "Kaixuan Huang, Sham M. Kakade, Jason D. Lee, Qi Lei", "title": "A Short Note on the Relationship of Information Gain and Eluder\n  Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eluder dimension and information gain are two widely used methods of\ncomplexity measures in bandit and reinforcement learning. Eluder dimension was\noriginally proposed as a general complexity measure of function classes, but\nthe common examples of where it is known to be small are function spaces\n(vector spaces). In these cases, the primary tool to upper bound the eluder\ndimension is the elliptic potential lemma. Interestingly, the elliptic\npotential lemma also features prominently in the analysis of linear\nbandits/reinforcement learning and their nonparametric generalization, the\ninformation gain. We show that this is not a coincidence -- eluder dimension\nand information gain are equivalent in a precise sense for reproducing kernel\nHilbert spaces.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 04:01:22 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Huang", "Kaixuan", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""]]}, {"id": "2107.02378", "submitter": "Jun Shu", "authors": "Jun Shu, Deyu Meng, Zongben Xu", "title": "Learning an Explicit Hyperparameter Prediction Policy Conditioned on\n  Tasks", "comments": "59 pages. arXiv admin note: text overlap with arXiv:1904.03758 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta learning has attracted much attention recently in machine learning\ncommunity. Contrary to conventional machine learning aiming to learn inherent\nprediction rules to predict labels for new query data, meta learning aims to\nlearn the learning methodology for machine learning from observed tasks, so as\nto generalize to new query tasks by leveraging the meta-learned learning\nmethodology. In this study, we interpret such learning methodology as learning\nan explicit hyperparameter prediction policy shared by all training tasks.\nSpecifically, this policy is represented as a parameterized function called\nmeta-learner, mapping from a training/test task to its suitable hyperparameter\nsetting, extracted from a pre-specified function set called meta learning\nmachine. Such setting guarantees that the meta-learned learning methodology is\nable to flexibly fit diverse query tasks, instead of only obtaining fixed\nhyperparameters by many current meta learning methods, with less adaptability\nto query task's variations. Such understanding of meta learning also makes it\neasily succeed from traditional learning theory for analyzing its\ngeneralization bounds with general losses/tasks/models. The theory naturally\nleads to some feasible controlling strategies for ameliorating the quality of\nthe extracted meta-learner, verified to be able to finely ameliorate its\ngeneralization capability in some typical meta learning applications, including\nfew-shot regression, few-shot classification and domain generalization.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 04:05:08 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Shu", "Jun", ""], ["Meng", "Deyu", ""], ["Xu", "Zongben", ""]]}, {"id": "2107.02381", "submitter": "Naveed Ahmed Azam", "authors": "Jianshen Zhu, Naveed Ahmed Azam, Kazuya Haraguchi, Liang Zhao, Hiroshi\n  Nagamochi and Tatsuya Akutsu", "title": "An Inverse QSAR Method Based on Linear Regression and Integer\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently a novel framework has been proposed for designing the molecular\nstructure of chemical compounds using both artificial neural networks (ANNs)\nand mixed integer linear programming (MILP). In the framework, we first define\na feature vector $f(C)$ of a chemical graph $C$ and construct an ANN that maps\n$x=f(C)$ to a predicted value $\\eta(x)$ of a chemical property $\\pi$ to $C$.\nAfter this, we formulate an MILP that simulates the computation process of\n$f(C)$ from $C$ and that of $\\eta(x)$ from $x$. Given a target value $y^*$ of\nthe chemical property $\\pi$, we infer a chemical graph $C^\\dagger$ such that\n$\\eta(f(C^\\dagger))=y^*$ by solving the MILP. In this paper, we use linear\nregression to construct a prediction function $\\eta$ instead of ANNs. For this,\nwe derive an MILP formulation that simulates the computation process of a\nprediction function by linear regression. The results of computational\nexperiments suggest our method can infer chemical graphs with around up to 50\nnon-hydrogen atoms.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 04:37:55 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 07:19:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhu", "Jianshen", ""], ["Azam", "Naveed Ahmed", ""], ["Haraguchi", "Kazuya", ""], ["Zhao", "Liang", ""], ["Nagamochi", "Hiroshi", ""], ["Akutsu", "Tatsuya", ""]]}, {"id": "2107.02388", "submitter": "Kaiyuan Yang", "authors": "Zhiyu Chen, Zhanghao Yu, Qing Jin, Yan He, Jingyu Wang, Sheng Lin, Dai\n  Li, Yanzhi Wang, Kaiyuan Yang", "title": "CAP-RAM: A Charge-Domain In-Memory Computing 6T-SRAM for Accurate and\n  Precision-Programmable CNN Inference", "comments": "This work has been accepted by IEEE Journal of Solid-State Circuits\n  (JSSC 2021)", "journal-ref": "IEEE Journal of Solid-State Circuits, Volume: 56, Issue: 6, Pages:\n  1924 - 1935, June 2021", "doi": "10.1109/JSSC.2021.3056447", "report-no": null, "categories": "cs.AR cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compact, accurate, and bitwidth-programmable in-memory computing (IMC)\nstatic random-access memory (SRAM) macro, named CAP-RAM, is presented for\nenergy-efficient convolutional neural network (CNN) inference. It leverages a\nnovel charge-domain multiply-and-accumulate (MAC) mechanism and circuitry to\nachieve superior linearity under process variations compared to conventional\nIMC designs. The adopted semi-parallel architecture efficiently stores filters\nfrom multiple CNN layers by sharing eight standard 6T SRAM cells with one\ncharge-domain MAC circuit. Moreover, up to six levels of bit-width of weights\nwith two encoding schemes and eight levels of input activations are supported.\nA 7-bit charge-injection SAR (ciSAR) analog-to-digital converter (ADC) getting\nrid of sample and hold (S&H) and input/reference buffers further improves the\noverall energy efficiency and throughput. A 65-nm prototype validates the\nexcellent linearity and computing accuracy of CAP-RAM. A single 512x128 macro\nstores a complete pruned and quantized CNN model to achieve 98.8% inference\naccuracy on the MNIST data set and 89.0% on the CIFAR-10 data set, with a\n573.4-giga operations per second (GOPS) peak throughput and a 49.4-tera\noperations per second (TOPS)/W energy efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 04:59:16 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chen", "Zhiyu", ""], ["Yu", "Zhanghao", ""], ["Jin", "Qing", ""], ["He", "Yan", ""], ["Wang", "Jingyu", ""], ["Lin", "Sheng", ""], ["Li", "Dai", ""], ["Wang", "Yanzhi", ""], ["Yang", "Kaiyuan", ""]]}, {"id": "2107.02392", "submitter": "Kaixiong Zhou", "authors": "Kaixiong Zhou, Xiao Huang, Daochen Zha, Rui Chen, Li Li, Soo-Hyun\n  Choi, Xia Hu", "title": "Dirichlet Energy Constrained Learning for Deep Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph neural networks (GNNs) integrate deep architectures and topological\nstructure modeling in an effective way. However, the performance of existing\nGNNs would decrease significantly when they stack many layers, because of the\nover-smoothing issue. Node embeddings tend to converge to similar vectors when\nGNNs keep recursively aggregating the representations of neighbors. To enable\ndeep GNNs, several methods have been explored recently. But they are developed\nfrom either techniques in convolutional neural networks or heuristic\nstrategies. There is no generalizable and theoretical principle to guide the\ndesign of deep GNNs. To this end, we analyze the bottleneck of deep GNNs by\nleveraging the Dirichlet energy of node embeddings, and propose a generalizable\nprinciple to guide the training of deep GNNs. Based on it, a novel deep GNN\nframework -- EGNN is designed. It could provide lower and upper constraints in\nterms of Dirichlet energy at each layer to avoid over-smoothing. Experimental\nresults demonstrate that EGNN achieves state-of-the-art performance by using\ndeep layers.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 05:13:16 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Zhou", "Kaixiong", ""], ["Huang", "Xiao", ""], ["Zha", "Daochen", ""], ["Chen", "Rui", ""], ["Li", "Li", ""], ["Choi", "Soo-Hyun", ""], ["Hu", "Xia", ""]]}, {"id": "2107.02397", "submitter": "Shijun Zhang", "authors": "Zuowei Shen and Haizhao Yang and Shijun Zhang", "title": "Deep Network Approximation: Achieving Arbitrary Accuracy with Fixed\n  Number of Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops simple feed-forward neural networks that achieve the\nuniversal approximation property for all continuous functions with a fixed\nfinite number of neurons. These neural networks are simple because they are\ndesigned with a simple and computable continuous activation function $\\sigma$\nleveraging a triangular-wave function and a softsign function. We prove that\n$\\sigma$-activated networks with width $36d(2d+1)$ and depth $11$ can\napproximate any continuous function on a $d$-dimensioanl hypercube within an\narbitrarily small error. Hence, for supervised learning and its related\nregression problems, the hypothesis space generated by these networks with a\nsize not smaller than $36d(2d+1)\\times 11$ is dense in the space of continuous\nfunctions. Furthermore, classification functions arising from image and signal\nclassification are in the hypothesis space generated by $\\sigma$-activated\nnetworks with width $36d(2d+1)$ and depth $12$, when there exist pairwise\ndisjoint closed bounded subsets of $\\mathbb{R}^d$ such that the samples of the\nsame class are located in the same subset.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 05:24:30 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:21:55 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Shen", "Zuowei", ""], ["Yang", "Haizhao", ""], ["Zhang", "Shijun", ""]]}, {"id": "2107.02408", "submitter": "Shahroz Tariq", "authors": "Minha Kim and Shahroz Tariq and Simon S. Woo", "title": "CoReD: Generalizing Fake Media Detection with Continual Representation\n  using Distillation", "comments": "10 pages, 2 Figures, 10 Tables, Accepted for publication in the 29th\n  ACM International Conference on Multimedia (ACMMM '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few decades, artificial intelligence research has made\ntremendous strides, but it still heavily relies on fixed datasets in stationary\nenvironments. Continual learning is a growing field of research that examines\nhow AI systems can learn sequentially from a continuous stream of linked data\nin the same way that biological systems do. Simultaneously, fake media such as\ndeepfakes and synthetic face images have emerged as significant to current\nmultimedia technologies. Recently, numerous method has been proposed which can\ndetect deepfakes with high accuracy. However, they suffer significantly due to\ntheir reliance on fixed datasets in limited evaluation settings. Therefore, in\nthis work, we apply continuous learning to neural networks' learning dynamics,\nemphasizing its potential to increase data efficiency significantly. We propose\nContinual Representation using Distillation (CoReD) method that employs the\nconcept of Continual Learning (CoL), Representation Learning (ReL), and\nKnowledge Distillation (KD). We design CoReD to perform sequential domain\nadaptation tasks on new deepfake and GAN-generated synthetic face datasets,\nwhile effectively minimizing the catastrophic forgetting in a teacher-student\nmodel setting. Our extensive experimental results demonstrate that our method\nis efficient at domain adaptation to detect low-quality deepfakes videos and\nGAN-generated images from several datasets, outperforming the-state-of-art\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 06:07:17 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 05:27:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kim", "Minha", ""], ["Tariq", "Shahroz", ""], ["Woo", "Simon S.", ""]]}, {"id": "2107.02415", "submitter": "Akshaykumar Gunari", "authors": "Akshaykumar Gunari, Shashidhar Veerappa Kudari, Sukanya Nadagadalli,\n  Keerthi Goudnaik, Ramesh Ashok Tabib, Uma Mudenagudi, and Adarsh Jamadandi", "title": "Deep Visual Attention-Based Transfer Clustering", "comments": "arXiv admin note: text overlap with arXiv:1908.09884 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a methodology to improvise the technique of deep\ntransfer clustering (DTC) when applied to the less variant data distribution.\nClustering can be considered as the most important unsupervised learning\nproblem. A simple definition of clustering can be stated as \"the process of\norganizing objects into groups, whose members are similar in some way\". Image\nclustering is a crucial but challenging task in the domain machine learning and\ncomputer vision. We have discussed the clustering of the data collection where\nthe data is less variant. We have discussed the improvement by using\nattention-based classifiers rather than regular classifiers as the initial\nfeature extractors in the deep transfer clustering. We have enforced the model\nto learn only the required region of interest in the images to get the\ndifferentiable and robust features that do not take into account the\nbackground. This paper is the improvement of the existing deep transfer\nclustering for less variant data distribution.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 06:26:15 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gunari", "Akshaykumar", ""], ["Kudari", "Shashidhar Veerappa", ""], ["Nadagadalli", "Sukanya", ""], ["Goudnaik", "Keerthi", ""], ["Tabib", "Ramesh Ashok", ""], ["Mudenagudi", "Uma", ""], ["Jamadandi", "Adarsh", ""]]}, {"id": "2107.02416", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Zixia Jia, Yong Jiang, Kewei Tu", "title": "Enhanced Universal Dependency Parsing with Automated Concatenation of\n  Embeddings", "comments": "Second Place in IWPT 2021 shared task, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes the system used in submission from SHANGHAITECH team to\nthe IWPT 2021 Shared Task. Our system is a graph-based parser with the\ntechnique of Automated Concatenation of Embeddings (ACE). Because recent work\nfound that better word representations can be obtained by concatenating\ndifferent types of embeddings, we use ACE to automatically find the better\nconcatenation of embeddings for the task of enhanced universal dependencies.\nAccording to official results averaged on 17 languages, our system ranks 2nd\nover 9 teams.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 06:33:42 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wang", "Xinyu", ""], ["Jia", "Zixia", ""], ["Jiang", "Yong", ""], ["Tu", "Kewei", ""]]}, {"id": "2107.02422", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani and Michael Field", "title": "Equivariant bifurcation, quadratic equivariants, and symmetry breaking\n  for the standard representation of $S_n$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by questions originating from the study of a class of shallow\nstudent-teacher neural networks, methods are developed for the analysis of\nspurious minima in classes of gradient equivariant dynamics related to neural\nnets. In the symmetric case, methods depend on the generic equivariant\nbifurcation theory of irreducible representations of the symmetric group on $n$\nsymbols, $S_n$; in particular, the standard representation of $S_n$. It is\nshown that spurious minima do not arise from spontaneous symmetry breaking but\nrather through a complex deformation of the landscape geometry that can be\nencoded by a generic $S_n$-equivariant bifurcation. We describe minimal models\nfor forced symmetry breaking that give a lower bound on the dynamic complexity\ninvolved in the creation of spurious minima when there is no symmetry. Results\non generic bifurcation when there are quadratic equivariants are also proved;\nthis work extends and clarifies results of Ihrig & Golubitsky and Chossat,\nLauterback & Melbourne on the instability of solutions when there are quadratic\nequivariants.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 06:43:06 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Arjevani", "Yossi", ""], ["Field", "Michael", ""]]}, {"id": "2107.02423", "submitter": "Hui Ye", "authors": "Hui Ye, Xiulong Yang, Martin Takac, Rajshekhar Sunderraman, Shihao Ji", "title": "Improving Text-to-Image Synthesis Using Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of text-to-image synthesis is to generate a visually realistic image\nthat matches a given text description. In practice, the captions annotated by\nhumans for the same image have large variance in terms of contents and the\nchoice of words. The linguistic discrepancy between the captions of the\nidentical image leads to the synthetic images deviating from the ground truth.\nTo address this issue, we propose a contrastive learning approach to improve\nthe quality and enhance the semantic consistency of synthetic images. In the\npre-training stage, we utilize the contrastive learning approach to learn the\nconsistent textual representations for the captions corresponding to the same\nimage. Furthermore, in the following stage of GAN training, we employ the\ncontrastive learning method to enhance the consistency between the generated\nimages from the captions related to the same image. We evaluate our approach\nover two popular text-to-image synthesis models, AttnGAN and DM-GAN, on\ndatasets CUB and COCO, respectively. Experimental results have shown that our\napproach can effectively improve the quality of synthetic images in terms of\nthree metrics: IS, FID and R-precision. Especially, on the challenging COCO\ndataset, our approach boosts the FID significantly by 29.60% over AttnGAn and\nby 21.96% over DM-GAN.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 06:43:31 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ye", "Hui", ""], ["Yang", "Xiulong", ""], ["Takac", "Martin", ""], ["Sunderraman", "Rajshekhar", ""], ["Ji", "Shihao", ""]]}, {"id": "2107.02425", "submitter": "Sungyoion Lee", "authors": "Sungyoon Lee, Hoki Kim, Jaewook Lee", "title": "GradDiv: Adversarial Robustness of Randomized Neural Networks via\n  Gradient Diversity Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning is vulnerable to adversarial examples. Many defenses based on\nrandomized neural networks have been proposed to solve the problem, but fail to\nachieve robustness against attacks using proxy gradients such as the\nExpectation over Transformation (EOT) attack. We investigate the effect of the\nadversarial attacks using proxy gradients on randomized neural networks and\ndemonstrate that it highly relies on the directional distribution of the loss\ngradients of the randomized neural network. We show in particular that proxy\ngradients are less effective when the gradients are more scattered. To this\nend, we propose Gradient Diversity (GradDiv) regularizations that minimize the\nconcentration of the gradients to build a robust randomized neural network. Our\nexperiments on MNIST, CIFAR10, and STL10 show that our proposed GradDiv\nregularizations improve the adversarial robustness of randomized neural\nnetworks against a variety of state-of-the-art attack methods. Moreover, our\nmethod efficiently reduces the transferability among sample models of\nrandomized neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 06:57:40 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lee", "Sungyoon", ""], ["Kim", "Hoki", ""], ["Lee", "Jaewook", ""]]}, {"id": "2107.02427", "submitter": "Erdem Akag\\\"und\\\"uz", "authors": "Erdem Akag\\\"und\\\"uz and Oguzhan Cifdaloz", "title": "Dynamical System Parameter Identification using Deep Recurrent Cell\n  Networks", "comments": "Final version published in Journal of Neural Computing and\n  Applications", "journal-ref": null, "doi": "10.1007/s00521-021-06271-5", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the parameter identification problem in\ndynamical systems through a deep learning approach. Focusing mainly on\nsecond-order, linear time-invariant dynamical systems, the topic of damping\nfactor identification is studied. By utilizing a six-layer deep neural network\nwith different recurrent cells, namely GRUs, LSTMs or BiLSTMs; and by feeding\ninput-output sequence pairs captured from a dynamical system simulator, we\nsearch for an effective deep recurrent architecture in order to resolve damping\nfactor identification problem. Our study results show that, although previously\nnot utilized for this task in the literature, bidirectional gated recurrent\ncells (BiLSTMs) provide better parameter identification results when compared\nto unidirectional gated recurrent memory cells such as GRUs and LSTM. Thus,\nindicating that an input-output sequence pair of finite length, collected from\na dynamical system and when observed anachronistically, may carry information\nin both time directions for prediction of a dynamical systems parameter.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:04:36 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Akag\u00fcnd\u00fcz", "Erdem", ""], ["Cifdaloz", "Oguzhan", ""]]}, {"id": "2107.02431", "submitter": "Po-Kan Shih", "authors": "Po-Kan Shih, Bahman Moraffah", "title": "Bayesian Nonparametric Modelling for Model-Free Reinforcement Learning\n  in LTE-LAA and Wi-Fi Coexistence", "comments": "arXiv admin note: substantial text overlap with arXiv:2105.12249", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the arrival of next generation wireless communication, a growing number\nof new applications like internet of things, autonomous driving systems, and\ndrone are crowding the unlicensed spectrum. Licensed network such as the\nlong-term evolution (LTE) also comes to the unlicensed spectrum for better\nproviding high-capacity contents with low cost. However, LTE was not designed\nto share resources with others. Previous solutions usually work on fixed\nscenarios. This work features a Nonparametric Bayesian reinforcement learning\nalgorithm to cope with the coexistence between Wi-Fi and LTE licensed assisted\naccess (LTE-LAA) agents in 5 GHz unlicensed spectrum. The coexistence problem\nis modeled as a decentralized partially-observable Markov decision process\n(Dec-POMDP) and Bayesian inference is adopted for policy learning with\nnonparametric prior to accommodate the uncertainty of policy for different\nagents. A fairness measure is introduced in the reward function to encourage\nfair sharing between agents. Variational inference for posterior model\napproximation is considered to make the algorithm computationally efficient.\nSimulation results demonstrate that this algorithm can reach high value with\ncompact policy representations in few learning iterations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:11:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Shih", "Po-Kan", ""], ["Moraffah", "Bahman", ""]]}, {"id": "2107.02438", "submitter": "Dmitrijs Trizna", "authors": "Dmitrijs Trizna", "title": "Shell Language Processing: Unix command parsing for Machine Learning", "comments": "3 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we present a Shell Language Preprocessing (SLP) library,\nwhich implements tokenization and encoding directed on the parsing of Unix and\nLinux shell commands. We describe the rationale behind the need for a new\napproach with specific examples when conventional Natural Language Processing\n(NLP) pipelines fail. Furthermore, we evaluate our methodology on a security\nclassification task against widely accepted information and communications\ntechnology (ICT) tokenization techniques and achieve significant improvement of\nan F1-score from 0.392 to 0.874.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:34:16 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Trizna", "Dmitrijs", ""]]}, {"id": "2107.02442", "submitter": "Jana Lang", "authors": "Jana Lang, Martin A. Giese, Matthis Synofzik, Winfried Ilg, Sebastian\n  Otte", "title": "Early Recognition of Ball Catching Success in Clinical Trials with\n  RNN-Based Predictive Classification", "comments": "Accepted by the 30th International Conference on Artificial Neural\n  Networks (ICANN 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor disturbances can affect the interaction with dynamic objects, such as\ncatching a ball. A classification of clinical catching trials might give\ninsight into the existence of pathological alterations in the relation of arm\nand ball movements. Accurate, but also early decisions are required to classify\na catching attempt before the catcher's first ball contact. To obtain\nclinically valuable results, a significant decision confidence of at least 75%\nis required. Hence, three competing objectives have to be optimized at the same\ntime: accuracy, earliness and decision-making confidence. Here we propose a\ncoupled classification and prediction approach for early time series\nclassification: a predictive, generative recurrent neural network (RNN)\nforecasts the next data points of ball trajectories based on already available\nobservations; a discriminative RNN continuously generates classification\nguesses based on the available data points and the unrolled sequence\npredictions. We compare our approach, which we refer to as predictive\nsequential classification (PSC), to state-of-the-art sequence learners,\nincluding various RNN and temporal convolutional network (TCN) architectures.\nOn this hard real-world task we can consistently demonstrate the superiority of\nPSC over all other models in terms of accuracy and confidence with respect to\nearliness of recognition. Specifically, PSC is able to confidently classify the\nsuccess of catching trials as early as 123 milliseconds before the first ball\ncontact. We conclude that PSC is a promising approach for early time series\nclassification, when accurate and confident decisions are required.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:42:06 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Lang", "Jana", ""], ["Giese", "Martin A.", ""], ["Synofzik", "Matthis", ""], ["Ilg", "Winfried", ""], ["Otte", "Sebastian", ""]]}, {"id": "2107.02453", "submitter": "Dumindu Tissera", "authors": "Dumindu Tissera, Kasun Vithanage, Rukshan Wijesinghe, Alex Xavier,\n  Sanath Jayasena, Subha Fernando, Ranga Rodrigo", "title": "Neural Mixture Models with Expectation-Maximization for End-to-end Deep\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any clustering algorithm must synchronously learn to model the clusters and\nallocate data to those clusters in the absence of labels. Mixture model-based\nmethods model clusters with pre-defined statistical distributions and allocate\ndata to those clusters based on the cluster likelihoods. They iteratively\nrefine those distribution parameters and member assignments following the\nExpectation-Maximization (EM) algorithm. However, the cluster representability\nof such hand-designed distributions that employ a limited amount of parameters\nis not adequate for most real-world clustering tasks. In this paper, we realize\nmixture model-based clustering with a neural network where the final layer\nneurons, with the aid of an additional transformation, approximate cluster\ndistribution outputs. The network parameters pose as the parameters of those\ndistributions. The result is an elegant, much-generalized representation of\nclusters than a restricted mixture of hand-designed distributions. We train the\nnetwork end-to-end via batch-wise EM iterations where the forward pass acts as\nthe E-step and the backward pass acts as the M-step. In image clustering, the\nmixture-based EM objective can be used as the clustering objective along with\nexisting representation learning methods. In particular, we show that when\nmixture-EM optimization is fused with consistency optimization, it improves the\nsole consistency optimization performance in clustering. Our trained networks\noutperform single-stage deep clustering methods that still depend on k-means,\nwith unsupervised classification accuracy of 63.8% in STL10, 58% in CIFAR10,\n25.9% in CIFAR100, and 98.9% in MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:00:58 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tissera", "Dumindu", ""], ["Vithanage", "Kasun", ""], ["Wijesinghe", "Rukshan", ""], ["Xavier", "Alex", ""], ["Jayasena", "Sanath", ""], ["Fernando", "Subha", ""], ["Rodrigo", "Ranga", ""]]}, {"id": "2107.02463", "submitter": "Florian Haselbeck", "authors": "Florian Haselbeck and Dominik G. Grimm", "title": "EVARS-GPR: EVent-triggered Augmented Refitting of Gaussian Process\n  Regression for Seasonal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time series forecasting is a growing domain with diverse applications.\nHowever, changes of the system behavior over time due to internal or external\ninfluences are challenging. Therefore, predictions of a previously learned\nfore-casting model might not be useful anymore. In this paper, we present\nEVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal\nData (EVARS-GPR), a novel online algorithm that is able to handle sudden shifts\nin the target variable scale of seasonal data. For this purpose, EVARS-GPR\ncom-bines online change point detection with a refitting of the prediction\nmodel using data augmentation for samples prior to a change point. Our\nexperiments on sim-ulated data show that EVARS-GPR is applicable for a wide\nrange of output scale changes. EVARS-GPR has on average a 20.8 % lower RMSE on\ndifferent real-world datasets compared to methods with a similar computational\nresource con-sumption. Furthermore, we show that our algorithm leads to a\nsix-fold reduction of the averaged runtime in relation to all comparison\npartners with a periodical refitting strategy. In summary, we present a\ncomputationally efficient online fore-casting algorithm for seasonal time\nseries with changes of the target variable scale and demonstrate its\nfunctionality on simulated as well as real-world data. All code is publicly\navailable on GitHub: https://github.com/grimmlab/evars-gpr.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:20:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Haselbeck", "Florian", ""], ["Grimm", "Dominik G.", ""]]}, {"id": "2107.02467", "submitter": "Hui Liu", "authors": "J. Wang, X. Liu, S. Shen, L. Deng, H. Liu*", "title": "DeepDDS: deep graph neural network with attention mechanism to predict\n  synergistic drug combinations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Drug combination therapy has become a increasingly promising method in the\ntreatment of cancer. However, the number of possible drug combinations is so\nhuge that it is hard to screen synergistic drug combinations through wet-lab\nexperiments. Therefore, computational screening has become an important way to\nprioritize drug combinations. Graph neural network have recently shown\nremarkable performance in the prediction of compound-protein interactions, but\nit has not been applied to the screening of drug combinations. In this paper,\nwe proposed a deep learning model based on graph neural networks and attention\nmechanism to identify drug combinations that can effectively inhibit the\nviability of specific cancer cells. The feature embeddings of drug molecule\nstructure and gene expression profiles were taken as input to multi-layer\nfeedforward neural network to identify the synergistic drug combinations. We\ncompared DeepDDS with classical machine learning methods and other deep\nlearning-based methods on benchmark data set, and the leave-one-out\nexperimental results showed that DeepDDS achieved better performance than\ncompetitive methods. Also, on an independent test set released by well-known\npharmaceutical enterprise AstraZeneca, DeepDDS was superior to competitive\nmethods by more than 16\\% predictive precision. Furthermore, we explored the\ninterpretability of the graph attention network, and found the correlation\nmatrix of atomic features revealed important chemical substructures of drugs.\nWe believed that DeepDDS is an effective tool that prioritized synergistic drug\ncombinations for further wet-lab experiment validation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:25:43 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Wang", "J.", ""], ["Liu", "X.", ""], ["Shen", "S.", ""], ["Deng", "L.", ""], ["Liu*", "H.", ""]]}, {"id": "2107.02474", "submitter": "Vincent Moens", "authors": "Vincent Moens, Aivar Sootla, Haitham Bou Ammar, Jun Wang", "title": "Implicit Variational Conditional Sampling with Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a method for conditional sampling with normalizing flows when only\npart of an observation is available. We rely on the following fact: if the\nflow's domain can be partitioned in such a way that the flow restrictions to\nsubdomains keep the bijectivity property, a lower bound to the conditioning\nvariable log-probability can be derived. Simulation from the variational\nconditional flow then amends to solving an equality constraint. Our\ncontribution is three-fold: a) we provide detailed insights on the choice of\nvariational distributions; b) we propose how to partition the input space of\nthe flow to preserve bijectivity property; c) we propose a set of methods to\noptimise the variational distribution in specific cases. Through extensive\nexperiments, we show that our sampling method can be applied with success to\ninvertible residual networks for inference and classification.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:40:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moens", "Vincent", ""], ["Sootla", "Aivar", ""], ["Ammar", "Haitham Bou", ""], ["Wang", "Jun", ""]]}, {"id": "2107.02476", "submitter": "Dimitrios I. Fotiadis", "authors": "Dimitrios G. Zaridis, Eugenia Mylona, Nikolaos S. Tachos, Kostas\n  Marias, Nikolaos Papanikolaou, Manolis Tsiknakis, Dimitrios I. Fotiadis", "title": "A new smart-cropping pipeline for prostate segmentation using deep\n  learning networks", "comments": "8 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prostate segmentation from magnetic resonance imaging (MRI) is a challenging\ntask. In recent years, several network architectures have been proposed to\nautomate this process and alleviate the burden of manual annotation. Although\nthe performance of these models has achieved promising results, there is still\nroom for improvement before these models can be used safely and effectively in\nclinical practice. One of the major challenges in prostate MR image\nsegmentation is the presence of class imbalance in the image labels where the\nbackground pixels dominate over the prostate. In the present work we propose a\nDL-based pipeline for cropping the region around the prostate from MRI images\nto produce a more balanced distribution of the foreground pixels (prostate) and\nthe background pixels and improve segmentation accuracy. The effect of\nDL-cropping for improving the segmentation performance compared to standard\ncenter-cropping is assessed using five popular DL networks for prostate\nsegmentation, namely U-net, U-net+, Res Unet++, Bridge U-net and Dense U-net.\nThe proposed smart-cropping outperformed the standard center cropping in terms\nof segmentation accuracy for all the evaluated prostate segmentation networks.\nIn terms of Dice score, the highest improvement was achieved for the U-net+ and\nResU-net++ architectures corresponding to 8.9% and 8%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:42:48 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 07:03:09 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zaridis", "Dimitrios G.", ""], ["Mylona", "Eugenia", ""], ["Tachos", "Nikolaos S.", ""], ["Marias", "Kostas", ""], ["Papanikolaou", "Nikolaos", ""], ["Tsiknakis", "Manolis", ""], ["Fotiadis", "Dimitrios I.", ""]]}, {"id": "2107.02480", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Ana Fern\\'andez del R\\'io and \\'Africa Peri\\'a\\~nez", "title": "Midwifery Learning and Forecasting: Predicting Content Demand with\n  User-Generated Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Every day, 800 women and 6,700 newborns die from complications related to\npregnancy or childbirth. A well-trained midwife can prevent most of these\nmaternal and newborn deaths. Data science models together with logs generated\nby users of online learning applications for midwives can help to improve their\nlearning competencies. The goal is to use these rich behavioral data to push\ndigital learning towards personalized content and to provide an adaptive\nlearning journey. In this work, we evaluate various forecasting methods to\ndetermine the interest of future users on the different kind of contents\navailable in the app, broken down by profession and region.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:48:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Guitart", "Anna", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "2107.02495", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison", "title": "InfoNCE is a variational autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a popular self-supervised learning method, InfoNCE, is a special\ncase of a new family of unsupervised learning methods, the self-supervised\nvariational autoencoder (SSVAE). SSVAEs circumvent the usual VAE requirement to\nreconstruct the data by using a carefully chosen implicit decoder. The InfoNCE\nobjective was motivated as a simplified parametric mutual information\nestimator. Under one choice of prior, the SSVAE objective (i.e. the ELBO) is\nexactly equal to the mutual information (up to constants). Under an alternative\nchoice of prior, the SSVAE objective is exactly equal to the simplified\nparametric mutual information estimator used in InfoNCE (up to constants).\nImportantly, the use of simplified parametric mutual information estimators is\nbelieved to be critical to obtain good high-level representations, and the\nSSVAE framework naturally provides a principled justification for using prior\ninformation to choose these estimators.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 09:24:57 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Aitchison", "Laurence", ""]]}, {"id": "2107.02517", "submitter": "Weiwei Jiang", "authors": "Weiwei Jiang, Jiayun Luo", "title": "An Evaluation of Machine Learning and Deep Learning Models for Drought\n  Prediction using Weather Data", "comments": "Github link:\n  https://github.com/jwwthu/DL4Climate/tree/main/DroughtPrediction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drought is a serious natural disaster that has a long duration and a wide\nrange of influence. To decrease the drought-caused losses, drought prediction\nis the basis of making the corresponding drought prevention and disaster\nreduction measures. While this problem has been studied in the literature, it\nremains unknown whether drought can be precisely predicted or not with machine\nlearning models using weather data. To answer this question, a real-world\npublic dataset is leveraged in this study and different drought levels are\npredicted using the last 90 days of 18 meteorological indicators as the\npredictors. In a comprehensive approach, 16 machine learning models and 16 deep\nlearning models are evaluated and compared. The results show no single model\ncan achieve the best performance for all evaluation metrics simultaneously,\nwhich indicates the drought prediction problem is still challenging. As\nbenchmarks for further studies, the code and results are publicly available in\na Github repository.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:19:43 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Jiang", "Weiwei", ""], ["Luo", "Jiayun", ""]]}, {"id": "2107.02520", "submitter": "Seok-Hwan Park", "authors": "Daesung Yu, Hoon Lee, Seok-Hwan Park, Seung-Eun Hong", "title": "Deep Learning Methods for Joint Optimization of Beamforming and\n  Fronthaul Quantization in Cloud Radio Access Networks", "comments": "accepted for publication on IEEE Wireless Communications Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative beamforming across access points (APs) and fronthaul quantization\nstrategies are essential for cloud radio access network (C-RAN) systems. The\nnonconvexity of the C-RAN optimization problems, which is stemmed from per-AP\npower and fronthaul capacity constraints, requires high computational\ncomplexity for executing iterative algorithms. To resolve this issue, we\ninvestigate a deep learning approach where the optimization module is replaced\nwith a well-trained deep neural network (DNN). An efficient learning solution\nis proposed which constructs a DNN to produce a low-dimensional representation\nof optimal beamforming and quantization strategies. Numerical results validate\nthe advantages of the proposed learning solution.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:27:43 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Yu", "Daesung", ""], ["Lee", "Hoon", ""], ["Park", "Seok-Hwan", ""], ["Hong", "Seung-Eun", ""]]}, {"id": "2107.02521", "submitter": "Aditya Kunar", "authors": "Aditya Kunar, Robert Birke, Zilong Zhao, Lydia Chen", "title": "DTGAN: Differential Private Training for Tabular GANs", "comments": "16 pages, 4 figures and 5 tables, submitted to the ACML 2021\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tabular generative adversarial networks (TGAN) have recently emerged to cater\nto the need of synthesizing tabular data -- the most widely used data format.\nWhile synthetic tabular data offers the advantage of complying with privacy\nregulations, there still exists a risk of privacy leakage via inference attacks\ndue to interpolating the properties of real data during training. Differential\nprivate (DP) training algorithms provide theoretical guarantees for training\nmachine learning models by injecting statistical noise to prevent privacy\nleaks. However, the challenges of applying DP on TGAN are to determine the most\noptimal framework (i.e., PATE/DP-SGD) and neural network (i.e.,\nGenerator/Discriminator)to inject noise such that the data utility is well\nmaintained under a given privacy guarantee. In this paper, we propose DTGAN, a\nnovel conditional Wasserstein tabular GAN that comes in two variants DTGAN_G\nand DTGAN_D, for providing a detailed comparison of tabular GANs trained using\nDP-SGD for the generator vs discriminator, respectively. We elicit the privacy\nanalysis associated with training the generator with complex loss functions\n(i.e., classification and information losses) needed for high quality tabular\ndata synthesis. Additionally, we rigorously evaluate the theoretical privacy\nguarantees offered by DP empirically against membership and attribute inference\nattacks. Our results on 3 datasets show that the DP-SGD framework is superior\nto PATE and that a DP discriminator is more optimal for training convergence.\nThus, we find (i) DTGAN_D is capable of maintaining the highest data utility\nacross 4 ML models by up to 18% in terms of the average precision score for a\nstrict privacy budget, epsilon = 1, as compared to the prior studies and (ii)\nDP effectively prevents privacy loss against inference attacks by restricting\nthe success probability of membership attacks to be close to 50%.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:28:05 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 12:27:04 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kunar", "Aditya", ""], ["Birke", "Robert", ""], ["Zhao", "Zilong", ""], ["Chen", "Lydia", ""]]}, {"id": "2107.02525", "submitter": "Ana-Cristina Rogoz", "authors": "Ana-Cristina Rogoz, Radu Muntean, Stefan Cobeli", "title": "Semantic Segmentation Alternative Technique: Segmentation Domain\n  Generation", "comments": "Accepted contribution at EEML2021 with poster presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Detecting objects of interest in images was always a compelling task to\nautomate. In recent years this task was more and more explored using deep\nlearning techniques, mostly using region-based convolutional networks. In this\nproject we propose an alternative semantic segmentation technique making use of\nGenerative Adversarial Networks. We consider semantic segmentation to be a\ndomain transfer problem. Thus, we train a feed forward network (FFNN) to\nreceive as input a seed real image and generate as output its segmentation\nmask.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:34:55 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Rogoz", "Ana-Cristina", ""], ["Muntean", "Radu", ""], ["Cobeli", "Stefan", ""]]}, {"id": "2107.02526", "submitter": "Francesco Farina", "authors": "Francesco Farina, Lawrence Phillips, Nicola J Richmond", "title": "Intrinsic uncertainties and where to find them", "comments": "Presented at the ICML 2021 Workshop on Uncertainty and Robustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for uncertainty estimation that both describes and\nextends many existing methods. We consider typical hyperparameters involved in\nclassical training as random variables and marginalise them out to capture\nvarious sources of uncertainty in the parameter space. We investigate which\nforms and combinations of marginalisation are most useful from a practical\npoint of view on standard benchmarking data sets. Moreover, we discuss how some\nmarginalisations may produce reliable estimates of uncertainty without the need\nfor extensive hyperparameter tuning and/or large-scale ensembling.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:35:35 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Farina", "Francesco", ""], ["Phillips", "Lawrence", ""], ["Richmond", "Nicola J", ""]]}, {"id": "2107.02530", "submitter": "Yuzi Yan", "authors": "Yuzi Yan, Xu Tan, Bohan Li, Guangyan Zhang, Tao Qin, Sheng Zhao, Yuan\n  Shen, Wei-Qiang Zhang, Tie-Yan Liu", "title": "AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style", "comments": "Accepted by INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While recent text to speech (TTS) models perform very well in synthesizing\nreading-style (e.g., audiobook) speech, it is still challenging to synthesize\nspontaneous-style speech (e.g., podcast or conversation), mainly because of two\nreasons: 1) the lack of training data for spontaneous speech; 2) the difficulty\nin modeling the filled pauses (um and uh) and diverse rhythms in spontaneous\nspeech. In this paper, we develop AdaSpeech 3, an adaptive TTS system that\nfine-tunes a well-trained reading-style TTS model for spontaneous-style speech.\nSpecifically, 1) to insert filled pauses (FP) in the text sequence\nappropriately, we introduce an FP predictor to the TTS model; 2) to model the\nvarying rhythms, we introduce a duration predictor based on mixture of experts\n(MoE), which contains three experts responsible for the generation of fast,\nmedium and slow speech respectively, and fine-tune it as well as the pitch\npredictor for rhythm adaptation; 3) to adapt to other speaker timbre, we\nfine-tune some parameters in the decoder with few speech data. To address the\nchallenge of lack of training data, we mine a spontaneous speech dataset to\nsupport our research this work and facilitate future research on spontaneous\nTTS. Experiments show that AdaSpeech 3 synthesizes speech with natural FP and\nrhythms in spontaneous styles, and achieves much better MOS and SMOS scores\nthan previous adaptive TTS systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:40:45 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Yan", "Yuzi", ""], ["Tan", "Xu", ""], ["Li", "Bohan", ""], ["Zhang", "Guangyan", ""], ["Qin", "Tao", ""], ["Zhao", "Sheng", ""], ["Shen", "Yuan", ""], ["Zhang", "Wei-Qiang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2107.02543", "submitter": "Hasan Mahmud", "authors": "Hasan Mahmud, Mashrur Mahmud Morshed, Md. Kamrul Hasan", "title": "A deep-learning--based multimodal depth-aware dynamic hand gesture\n  recognition system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Any spatio-temporal movement or reorientation of the hand, done with the\nintention of conveying a specific meaning, can be considered as a hand gesture.\nInputs to hand gesture recognition systems can be in several forms, such as\ndepth images, monocular RGB, or skeleton joint points. We observe that raw\ndepth images possess low contrasts in the hand regions of interest (ROI). They\ndo not highlight important details to learn, such as finger bending information\n(whether a finger is overlapping the palm, or another finger). Recently, in\ndeep-learning--based dynamic hand gesture recognition, researchers are tying to\nfuse different input modalities (e.g. RGB or depth images and hand skeleton\njoint points) to improve the recognition accuracy. In this paper, we focus on\ndynamic hand gesture (DHG) recognition using depth quantized image features and\nhand skeleton joint points. In particular, we explore the effect of using\ndepth-quantized features in Convolutional Neural Network (CNN) and Recurrent\nNeural Network (RNN) based multi-modal fusion networks. We find that our method\nimproves existing results on the SHREC-DHG-14 dataset. Furthermore, using our\nmethod, we show that it is possible to reduce the resolution of the input\nimages by more than four times and still obtain comparable or better accuracy\nto that of the resolutions used in previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 11:18:53 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mahmud", "Hasan", ""], ["Morshed", "Mashrur Mahmud", ""], ["Hasan", "Md. Kamrul", ""]]}, {"id": "2107.02550", "submitter": "Iordan Ganev", "authors": "Iordan Ganev, Robin Walters", "title": "The QR decomposition for radial neural networks", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.RT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a theoretical framework for neural networks in terms of the\nrepresentation theory of quivers, thus revealing symmetries of the parameter\nspace of neural networks. An exploitation of these symmetries leads to a model\ncompression algorithm for radial neural networks based on an analogue of the QR\ndecomposition. A projected version of backpropogation on the original model\nmatches usual backpropogation on the compressed model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 11:41:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ganev", "Iordan", ""], ["Walters", "Robin", ""]]}, {"id": "2107.02561", "submitter": "Sameera Ramasinghe Mr.", "authors": "Jianqiao Zheng, Sameera Ramasinghe, Simon Lucey", "title": "Rethinking Positional Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well noted that coordinate based MLPs benefit greatly -- in terms of\npreserving high-frequency information -- through the encoding of coordinate\npositions as an array of Fourier features. Hitherto, the rationale for the\neffectiveness of these positional encodings has been solely studied through a\nFourier lens. In this paper, we strive to broaden this understanding by showing\nthat alternative non-Fourier embedding functions can indeed be used for\npositional encoding. Moreover, we show that their performance is entirely\ndetermined by a trade-off between the stable rank of the embedded matrix and\nthe distance preservation between embedded coordinates. We further establish\nthat the now ubiquitous Fourier feature mapping of position is a special case\nthat fulfills these conditions. Consequently, we present a more general theory\nto analyze positional encoding in terms of shifted basis functions. To this\nend, we develop the necessary theoretical formulae and empirically verify that\nour theoretical claims hold in practice. Codes available at\nhttps://github.com/osiriszjq/Rethinking-positional-encoding.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 12:04:04 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 07:38:30 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zheng", "Jianqiao", ""], ["Ramasinghe", "Sameera", ""], ["Lucey", "Simon", ""]]}, {"id": "2107.02565", "submitter": "S\\\"oren Mindermann", "authors": "S\\\"oren Mindermann, Muhammed Razzak, Winnie Xu, Andreas Kirsch,\n  Mrinank Sharma, Adrien Morisot, Aidan N. Gomez, Sebastian Farquhar, Jan\n  Brauner, Yarin Gal", "title": "Prioritized training on points that are learnable, worth learning, and\n  not yet learned", "comments": null, "journal-ref": "ICML 2021 Workshop on Subset Selection in Machine Learning", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Goldilocks Selection, a technique for faster model training\nwhich selects a sequence of training points that are \"just right\". We propose\nan information-theoretic acquisition function -- the reducible validation loss\n-- and compute it with a small proxy model -- GoldiProx -- to efficiently\nchoose training points that maximize information about a validation set. We\nshow that the \"hard\" (e.g. high loss) points usually selected in the\noptimization literature are typically noisy, while the \"easy\" (e.g. low noise)\nsamples often prioritized for curriculum learning confer less information.\nFurther, points with uncertain labels, typically targeted by active learning,\ntend to be less relevant to the task. In contrast, Goldilocks Selection chooses\npoints that are \"just right\" and empirically outperforms the above approaches.\nMoreover, the selected sequence can transfer to other architectures;\npractitioners can share and reuse it without the need to recreate it.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 12:08:44 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mindermann", "S\u00f6ren", ""], ["Razzak", "Muhammed", ""], ["Xu", "Winnie", ""], ["Kirsch", "Andreas", ""], ["Sharma", "Mrinank", ""], ["Morisot", "Adrien", ""], ["Gomez", "Aidan N.", ""], ["Farquhar", "Sebastian", ""], ["Brauner", "Jan", ""], ["Gal", "Yarin", ""]]}, {"id": "2107.02569", "submitter": "Nam Kyun Kim", "authors": "Nam Kyun Kim and Hong Kook Kim", "title": "Self-training with noisy student model and semi-supervised loss function\n  for dcase 2021 challenge task 4", "comments": "5 pages, DCASE 2021 challenge Task 4 technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report proposes a polyphonic sound event detection (SED) method for the\nDCASE 2021 Challenge Task 4. The proposed SED model consists of two stages: a\nmean-teacher model for providing target labels regarding weakly labeled or\nunlabeled data and a self-training-based noisy student model for predicting\nstrong labels for sound events. The mean-teacher model, which is based on the\nresidual convolutional recurrent neural network (RCRNN) for the teacher and\nstudent model, is first trained using all the training data from a weakly\nlabeled dataset, an unlabeled dataset, and a strongly labeled synthetic\ndataset. Then, the trained mean-teacher model predicts the strong label to each\nof the weakly labeled and unlabeled datasets, which is brought to the noisy\nstudent model in the second stage of the proposed SED model. Here, the\nstructure of the noisy student model is identical to the RCRNN-based student\nmodel of the mean-teacher model in the first stage. Then, it is self-trained by\nadding feature noises, such as time-frequency shift, mixup, SpecAugment, and\ndropout-based model noise. In addition, a semi-supervised loss function is\napplied to train the noisy student model, which acts as label noise injection.\nThe performance of the proposed SED model is evaluated on the validation set of\nthe DCASE 2021 Challenge Task 4, and then, several ensemble models that combine\nfive-fold validation models with different hyperparameters of the\nsemi-supervised loss function are finally selected as our final models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 12:11:16 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kim", "Nam Kyun", ""], ["Kim", "Hong Kook", ""]]}, {"id": "2107.02586", "submitter": "Georgios Kaissis", "authors": "Alexander Ziller, Dmitrii Usynin, Nicolas Remerscheid, Moritz Knolle,\n  Marcus Makowski, Rickmer Braren, Daniel Rueckert, Georgios Kaissis", "title": "Differentially private federated deep learning for multi-site medical\n  image segmentation", "comments": "Submitted to the Journal of Machine Learning in Biomedical Imaging\n  (MELBA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative machine learning techniques such as federated learning (FL)\nenable the training of models on effectively larger datasets without data\ntransfer. Recent initiatives have demonstrated that segmentation models trained\nwith FL can achieve performance similar to locally trained models. However, FL\nis not a fully privacy-preserving technique and privacy-centred attacks can\ndisclose confidential patient data. Thus, supplementing FL with\nprivacy-enhancing technologies (PTs) such as differential privacy (DP) is a\nrequirement for clinical applications in a multi-institutional setting. The\napplication of PTs to FL in medical imaging and the trade-offs between privacy\nguarantees and model utility, the ramifications on training performance and the\nsusceptibility of the final models to attacks have not yet been conclusively\ninvestigated. Here we demonstrate the first application of differentially\nprivate gradient descent-based FL on the task of semantic segmentation in\ncomputed tomography. We find that high segmentation performance is possible\nunder strong privacy guarantees with an acceptable training time penalty. We\nfurthermore demonstrate the first successful gradient-based model inversion\nattack on a semantic segmentation model and show that the application of DP\nprevents it from divulging sensitive image features.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 12:57:32 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ziller", "Alexander", ""], ["Usynin", "Dmitrii", ""], ["Remerscheid", "Nicolas", ""], ["Knolle", "Moritz", ""], ["Makowski", "Marcus", ""], ["Braren", "Rickmer", ""], ["Rueckert", "Daniel", ""], ["Kaissis", "Georgios", ""]]}, {"id": "2107.02597", "submitter": "Benjamin Peherstorfer", "authors": "Nihar Sawant, Boris Kramer, Benjamin Peherstorfer", "title": "Physics-informed regularization and structure preservation for learning\n  stable reduced models from data with operator inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operator inference learns low-dimensional dynamical-system models with\npolynomial nonlinear terms from trajectories of high-dimensional physical\nsystems (non-intrusive model reduction). This work focuses on the large class\nof physical systems that can be well described by models with quadratic\nnonlinear terms and proposes a regularizer for operator inference that induces\na stability bias onto quadratic models. The proposed regularizer is physics\ninformed in the sense that it penalizes quadratic terms with large norms and so\nexplicitly leverages the quadratic model form that is given by the underlying\nphysics. This means that the proposed approach judiciously learns from data and\nphysical insights combined, rather than from either data or physics alone.\nAdditionally, a formulation of operator inference is proposed that enforces\nmodel constraints for preserving structure such as symmetry and definiteness in\nthe linear terms. Numerical results demonstrate that models learned with\noperator inference and the proposed regularizer and structure preservation are\naccurate and stable even in cases where using no regularization or Tikhonov\nregularization leads to models that are unstable.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:15:54 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sawant", "Nihar", ""], ["Kramer", "Boris", ""], ["Peherstorfer", "Benjamin", ""]]}, {"id": "2107.02603", "submitter": "Ricardo Luna Gutierrez", "authors": "Ricardo Luna Gutierrez and Matteo Leonetti", "title": "Meta-Reinforcement Learning for Heuristic Planning", "comments": "ICAPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Meta-Reinforcement Learning (meta-RL) an agent is trained on a set of\ntasks to prepare for and learn faster in new, unseen, but related tasks. The\ntraining tasks are usually hand-crafted to be representative of the expected\ndistribution of test tasks and hence all used in training. We show that given a\nset of training tasks, learning can be both faster and more effective (leading\nto better performance in the test tasks), if the training tasks are\nappropriately selected. We propose a task selection algorithm,\nInformation-Theoretic Task Selection (ITTS), based on information theory, which\noptimizes the set of tasks used for training in meta-RL, irrespectively of how\nthey are generated. The algorithm establishes which training tasks are both\nsufficiently relevant for the test tasks, and different enough from one\nanother. We reproduce different meta-RL experiments from the literature and\nshow that ITTS improves the final performance in all of them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:25:52 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gutierrez", "Ricardo Luna", ""], ["Leonetti", "Matteo", ""]]}, {"id": "2107.02621", "submitter": "Constance Douwes", "authors": "Constance Douwes, Philippe Esling and Jean-Pierre Briot", "title": "A Multi-Objective Approach for Sustainable Generative Audio Models", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, the deep learning community has largely focused on the\naccuracy of deep generative models, resulting in impressive improvements in\nseveral research fields. However, this scientific race for quality comes at a\ntremendous computational cost, which incurs vast energy consumption and\ngreenhouse gas emissions. If the current exponential growth of computational\nconsumption persists, Artificial Intelligence (AI) will sadly become a\nconsiderable contributor to global warming.\n  At the heart of this problem are the measures that we use as a scientific\ncommunity to evaluate our work. Currently, researchers in the field of AI judge\nscientific works mostly based on the improvement in accuracy, log-likelihood,\nreconstruction or opinion scores, all of which entirely obliterates the actual\ncomputational cost of generative models.\n  In this paper, we introduce the idea of relying on a multi-objective measure\nbased on Pareto optimality, which simultaneously integrates the models\naccuracy, as well as the environmental impact of their training. By applying\nthis measure on the current state-of-the-art in generative audio models, we\nshow that this measure drastically changes the perceived significance of the\nresults in the field, encouraging optimal training techniques and resource\nallocation. We hope that this type of measure will be widely adopted, in order\nto help the community to better evaluate the significance of their work, while\nbringing computational cost -- and in fine carbon emissions -- in the spotlight\nof AI research.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:52:27 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Douwes", "Constance", ""], ["Esling", "Philippe", ""], ["Briot", "Jean-Pierre", ""]]}, {"id": "2107.02630", "submitter": "Wele Gedara Chaminda Bandara", "authors": "Wele Gedara Chaminda Bandara, Jeya Maria Jose Valanarasu, Vishal M.\n  Patel", "title": "Hyperspectral Pansharpening Based on Improved Deep Image Prior and\n  Residual Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperspectral pansharpening aims to synthesize a low-resolution hyperspectral\nimage (LR-HSI) with a registered panchromatic image (PAN) to generate an\nenhanced HSI with high spectral and spatial resolution. Recently proposed HS\npansharpening methods have obtained remarkable results using deep convolutional\nnetworks (ConvNets), which typically consist of three steps: (1) up-sampling\nthe LR-HSI, (2) predicting the residual image via a ConvNet, and (3) obtaining\nthe final fused HSI by adding the outputs from first and second steps. Recent\nmethods have leveraged Deep Image Prior (DIP) to up-sample the LR-HSI due to\nits excellent ability to preserve both spatial and spectral information,\nwithout learning from large data sets. However, we observed that the quality of\nup-sampled HSIs can be further improved by introducing an additional\nspatial-domain constraint to the conventional spectral-domain energy function.\nWe define our spatial-domain constraint as the $L_1$ distance between the\npredicted PAN image and the actual PAN image. To estimate the PAN image of the\nup-sampled HSI, we also propose a learnable spectral response function (SRF).\nMoreover, we noticed that the residual image between the up-sampled HSI and the\nreference HSI mainly consists of edge information and very fine structures. In\norder to accurately estimate fine information, we propose a novel over-complete\nnetwork, called HyperKite, which focuses on learning high-level features by\nconstraining the receptive from increasing in the deep layers. We perform\nexperiments on three HSI datasets to demonstrate the superiority of our\nDIP-HyperKite over the state-of-the-art pansharpening methods. The deployment\ncodes, pre-trained models, and final fusion outputs of our DIP-HyperKite and\nthe methods used for the comparisons will be publicly made available at\nhttps://github.com/wgcban/DIP-HyperKite.git.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:11:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Bandara", "Wele Gedara Chaminda", ""], ["Valanarasu", "Jeya Maria Jose", ""], ["Patel", "Vishal M.", ""]]}, {"id": "2107.02639", "submitter": "Pengpeng Shao", "authors": "Pengpeng Shao, Tong Liu, Dawei Zhang, Jianhua Tao, Feihu Che, Guohua\n  Yang", "title": "Multi-Level Graph Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has attracted a surge of interest recently,\nwhose target at learning discriminant embedding for each node in the graph.\nMost of these representation methods focus on supervised learning and heavily\ndepend on label information. However, annotating graphs are expensive to obtain\nin the real world, especially in specialized domains (i.e. biology), as it\nneeds the annotator to have the domain knowledge to label the graph. To\napproach this problem, self-supervised learning provides a feasible solution\nfor graph representation learning. In this paper, we propose a Multi-Level\nGraph Contrastive Learning (MLGCL) framework for learning robust representation\nof graph data by contrasting space views of graphs. Specifically, we introduce\na novel contrastive view - topological and feature space views. The original\ngraph is first-order approximation structure and contains uncertainty or error,\nwhile the $k$NN graph generated by encoding features preserves high-order\nproximity. Thus $k$NN graph generated by encoding features not only provide a\ncomplementary view, but is more suitable to GNN encoder to extract discriminant\nrepresentation. Furthermore, we develop a multi-level contrastive mode to\npreserve the local similarity and semantic similarity of graph-structured data\nsimultaneously. Extensive experiments indicate MLGCL achieves promising results\ncompared with the existing state-of-the-art graph representation learning\nmethods on seven datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:24:43 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Shao", "Pengpeng", ""], ["Liu", "Tong", ""], ["Zhang", "Dawei", ""], ["Tao", "Jianhua", ""], ["Che", "Feihu", ""], ["Yang", "Guohua", ""]]}, {"id": "2107.02643", "submitter": "Samuel Budd", "authors": "Samuel Budd, Matthew Sinclair, Thomas Day, Athanasios Vlontzos, Jeremy\n  Tan, Tianrui Liu, Jaqueline Matthew, Emily Skelton, John Simpson, Reza\n  Razavi, Ben Glocker, Daniel Rueckert, Emma C. Robinson, Bernhard Kainz", "title": "Detecting Hypo-plastic Left Heart Syndrome in Fetal Ultrasound via\n  Disease-specific Atlas Maps", "comments": "MICCAI'21 Main Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Fetal ultrasound screening during pregnancy plays a vital role in the early\ndetection of fetal malformations which have potential long-term health impacts.\nThe level of skill required to diagnose such malformations from live ultrasound\nduring examination is high and resources for screening are often limited. We\npresent an interpretable, atlas-learning segmentation method for automatic\ndiagnosis of Hypo-plastic Left Heart Syndrome (HLHS) from a single `4 Chamber\nHeart' view image. We propose to extend the recently introduced\nImage-and-Spatial Transformer Networks (Atlas-ISTN) into a framework that\nenables sensitising atlas generation to disease. In this framework we can\njointly learn image segmentation, registration, atlas construction and disease\nprediction while providing a maximum level of clinical interpretability\ncompared to direct image classification methods. As a result our segmentation\nallows diagnoses competitive with expert-derived manual diagnosis and yields an\nAUC-ROC of 0.978 (1043 cases for training, 260 for validation and 325 for\ntesting).\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:31:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Budd", "Samuel", ""], ["Sinclair", "Matthew", ""], ["Day", "Thomas", ""], ["Vlontzos", "Athanasios", ""], ["Tan", "Jeremy", ""], ["Liu", "Tianrui", ""], ["Matthew", "Jaqueline", ""], ["Skelton", "Emily", ""], ["Simpson", "John", ""], ["Razavi", "Reza", ""], ["Glocker", "Ben", ""], ["Rueckert", "Daniel", ""], ["Robinson", "Emma C.", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2107.02655", "submitter": "Pietro Gori", "authors": "Giammarco La Barbera and Pietro Gori and Haithem Boussaid and Bruno\n  Belucci and Alessandro Delmonte and Jeanne Goulin and Sabine Sarnacki and\n  Laurence Rouet and Isabelle Bloch", "title": "Automatic size and pose homogenization with spatial transformer network\n  to improve and accelerate pediatric segmentation", "comments": "ISBI 2021", "journal-ref": "ISBI 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to a high heterogeneity in pose and size and to a limited number of\navailable data, segmentation of pediatric images is challenging for deep\nlearning methods. In this work, we propose a new CNN architecture that is pose\nand scale invariant thanks to the use of Spatial Transformer Network (STN). Our\narchitecture is composed of three sequential modules that are estimated\ntogether during training: (i) a regression module to estimate a similarity\nmatrix to normalize the input image to a reference one; (ii) a differentiable\nmodule to find the region of interest to segment; (iii) a segmentation module,\nbased on the popular UNet architecture, to delineate the object. Unlike the\noriginal UNet, which strives to learn a complex mapping, including pose and\nscale variations, from a finite training dataset, our segmentation module\nlearns a simpler mapping focusing on images with normalized pose and size.\nFurthermore, the use of an automatic bounding box detection through STN allows\nsaving time and especially memory, while keeping similar performance. We test\nthe proposed method in kidney and renal tumor segmentation on abdominal\npediatric CT scanners. Results indicate that the estimated STN homogenization\nof size and pose accelerates the segmentation (25h), compared to standard\ndata-augmentation (33h), while obtaining a similar quality for the kidney\n(88.01\\% of Dice score) and improving the renal tumor delineation (from 85.52\\%\nto 87.12\\%).\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:50:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["La Barbera", "Giammarco", ""], ["Gori", "Pietro", ""], ["Boussaid", "Haithem", ""], ["Belucci", "Bruno", ""], ["Delmonte", "Alessandro", ""], ["Goulin", "Jeanne", ""], ["Sarnacki", "Sabine", ""], ["Rouet", "Laurence", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2107.02658", "submitter": "Tianjin Huang", "authors": "Tianjin huang, Yulong Pei, Vlado Menkovski and Mykola Pechenizkiy", "title": "On Generalization of Graph Autoencoders with Adversarial Training", "comments": "ECML 2021 Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is an approach for increasing model's resilience against\nadversarial perturbations. Such approaches have been demonstrated to result in\nmodels with feature representations that generalize better. However, limited\nworks have been done on adversarial training of models on graph data. In this\npaper, we raise such a question { does adversarial training improve the\ngeneralization of graph representations. We formulate L2 and L1 versions of\nadversarial training in two powerful node embedding methods: graph autoencoder\n(GAE) and variational graph autoencoder (VGAE). We conduct extensive\nexperiments on three main applications, i.e. link prediction, node clustering,\ngraph anomaly detection of GAE and VGAE, and demonstrate that both L2 and L1\nadversarial training boost the generalization of GAE and VGAE.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:53:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["huang", "Tianjin", ""], ["Pei", "Yulong", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2107.02661", "submitter": "Jos\\'e Ribeiro MSc.", "authors": "Jos\\'e Ribeiro, Ra\\'issa Silva, Ronnie Alves", "title": "Does Dataset Complexity Matters for Model Explainers?", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Strategies based on Explainable Artificial Intelligence - XAI have emerged in\ncomputing to promote a better understanding of predictions made by black box\nmodels. Most XAI-based tools used today explain these types of models,\ngenerating attribute rankings aimed at explaining the same, that is, the\nanalysis of Attribute Importance. There is no consensus on which XAI tool\ngenerates a general rank of explainability, for this reason, several proposals\nfor tools have emerged (Ciu, Dalex, Eli5, Lofo, Shap and Skater). Here, we\npresent an experimental benchmark of explainable AI techniques capable of\nproducing model-agnostic global explainability ranks based on tabular data\nrelated to different problems. Seeking to answer questions such as \"Are the\nexplanations generated by the different tools the same, similar or different?\"\nand \"How does data complexity play along model explainability?\". The results\nfrom the construction of 82 computational models and 592 ranks give us some\nlight on the other side of the problem of explainability: dataset complexity!\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:01:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ribeiro", "Jos\u00e9", ""], ["Silva", "Ra\u00edssa", ""], ["Alves", "Ronnie", ""]]}, {"id": "2107.02681", "submitter": "Jaemin Cho", "authors": "Zineng Tang, Jaemin Cho, Hao Tan, Mohit Bansal", "title": "VidLanKD: Improving Language Understanding via Video-Distilled Knowledge\n  Transfer", "comments": "18 pages (5 figures, 10 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since visual perception can give rich information beyond text descriptions\nfor world understanding, there has been increasing interest in leveraging\nvisual grounding for language learning. Recently, vokenization has attracted\nattention by using the predictions of a text-to-image retrieval model as labels\nfor language model supervision. Despite its success, the method suffers from\napproximation error of using finite image labels and the lack of vocabulary\ndiversity of a small image-text dataset. To overcome these limitations, we\npresent VidLanKD, a video-language knowledge distillation method for improving\nlanguage understanding. We train a multi-modal teacher model on a video-text\ndataset, and then transfer its knowledge to a student language model with a\ntext dataset. To avoid approximation error, we propose to use different\nknowledge distillation objectives. In addition, the use of a large-scale\nvideo-text dataset helps learn diverse and richer vocabularies. In our\nexperiments, VidLanKD achieves consistent improvements over text-only language\nmodels and vokenization models, on several downstream language understanding\ntasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world\nknowledge, physical reasoning, and temporal reasoning capabilities of our model\nby evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we\npresent comprehensive ablation studies as well as visualizations of the learned\ntext-to-video grounding results of our teacher and student language models. Our\ncode and models are available at: https://github.com/zinengtang/VidLanKD\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:41:32 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tang", "Zineng", ""], ["Cho", "Jaemin", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2107.02689", "submitter": "Armin Moin", "authors": "Armin Moin, Atta Badii and Stephan G\\\"unnemann", "title": "A Model-Driven Engineering Approach to Machine Learning and Software\n  Modeling", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Models are used in both the Software Engineering (SE) and the Artificial\nIntelligence (AI) communities. In the former case, models of software, which\nmay specify the software system architecture on different levels of abstraction\ncould be used in various stages of the Software Development Life-Cycle (SDLC),\nfrom early conceptualization and design, to verification, implementation,\ntesting and evolution. However, in the latter case, i.e., AI, models may\nprovide smart capabilities, such as prediction and decision making support. For\ninstance, in Machine Learning (ML), which is the most popular sub-discipline of\nAI at the present time, mathematical models may learn useful patterns in the\nobserved data instances and can become capable of making better predictions or\nrecommendations in the future. The goal of this work is to create synergy by\nbringing models in the said communities together and proposing a holistic\napproach. We illustrate how software models can become capable of producing or\ndealing with data analytics and ML models. The main focus is on the Internet of\nThings (IoT) and smart Cyber-Physical Systems (CPS) use cases, where both ML\nand model-driven (model-based) SE play a key role. In particular, we implement\nthe proposed approach in an open source prototype and validate it using two use\ncases from the IoT/CPS domain.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:50:50 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moin", "Armin", ""], ["Badii", "Atta", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.02690", "submitter": "Armin Moin", "authors": "Armin Moin, Atta Badii and Stephan G\\\"unnemann", "title": "Enabling Un-/Semi-Supervised Machine Learning for MDSE of the Real-World\n  CPS/IoT Applications", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a novel approach to support domain-specific\nModel-Driven Software Engineering (MDSE) for the real-world use-case scenarios\nof smart Cyber-Physical Systems (CPS) and the Internet of Things (IoT). We\nargue that the majority of available data in the nature for Artificial\nIntelligence (AI), specifically Machine Learning (ML) are unlabeled. Hence,\nunsupervised and/or semi-supervised ML approaches are the practical choices.\nHowever, prior work in the literature of MDSE has considered supervised ML\napproaches, which only work with labeled training data. Our proposed approach\nis fully implemented and integrated with an existing state-of-the-art MDSE tool\nto serve the CPS/IoT domain. Moreover, we validate the proposed approach using\na portion of the open data of the REFIT reference dataset for the smart energy\nsystems domain. Our model-to-code transformations (code generators) provide the\nfull source code of the desired IoT services out of the model instances in an\nautomated manner. Currently, we generate the source code in Java and Python.\nThe Python code is responsible for the ML functionalities and uses the APIs of\nseveral ML libraries and frameworks, namely Scikit-Learn, Keras and TensorFlow.\nFor unsupervised and semi-supervised learning, the APIs of Scikit-Learn are\ndeployed. In addition to the pure MDSE approach, where certain ML methods,\ne.g., K-Means, Mini-Batch K-Means, DB-SCAN, Spectral Clustering, Gaussian\nMixture Model, Self-Training, Label Propagation and Label Spreading are\nsupported, a more flexible, hybrid approach is also enabled to support the\npractitioner in deploying a pre-trained ML model with any arbitrary\narchitecture and learning algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:51:39 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moin", "Armin", ""], ["Badii", "Atta", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.02692", "submitter": "Armin Moin", "authors": "Armin Moin, Andrei Mituca, Atta Badii and Stephan G\\\"unnemann", "title": "ML-Quadrat & DriotData: A Model-Driven Engineering Tool and a Low-Code\n  Platform for Smart IoT Services", "comments": "Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present the novel early tool prototype of ML-Quadrat, which\nis an open source research prototype, based on the Eclipse Modeling Framework\n(EMF) and the state of the art in the literature of Model-Driven Software\nEngineering (MDSE) for smart Cyber-Physical Systems (CPS) and the Internet of\nThings (IoT). Its envisioned users are mostly software developers, who might\nnot have deep knowledge and skills in the heterogeneous IoT platforms and the\ndiverse Artificial Intelligence (AI) technologies, specifically regarding Data\nAnalytics and Machine Learning (DAML). ML-Quadrat is released under the terms\nof the Apache 2.0 license on Github: https://github.com/arminmoin/ML-Quadrat.\nAdditionally, the novel early tool prototype of DriotData, a Low-Code platform\ntargeting citizen data scientists and citizen/end-user software developers is\ndemonstrated. DriotData exploits and adopts ML-Quadrat and offers an extended\nversion of it as a web-based service to companies, especially Small- and\nMedium-Sized Enterprises (SME). A basic web-based demo of the Minimum Viable\nProduct (MVP) of DriotData is already available. Finally, a short video\ndemonstrating the tools is available on YouTube: https://youtu.be/YCNFfhmy_JY.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:52:09 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Moin", "Armin", ""], ["Mituca", "Andrei", ""], ["Badii", "Atta", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.02693", "submitter": "Beril Sirmacek", "authors": "Beril Sirmacek", "title": "Remote sensing, AI and innovative prediction methods for adapting cities\n  to the impacts of the climate change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Urban areas are not only one of the biggest contributors to climate change,\nbut also they are one of the most vulnerable areas with high populations who\nwould together experience the negative impacts. In this paper, I address some\nof the opportunities brought by satellite remote sensing imaging and artificial\nintelligence (AI) in order to measure climate adaptation of cities\nautomatically. I propose an AI-based framework which might be useful for\nextracting indicators from remote sensing images and might help with predictive\nestimation of future states of these climate adaptation related indicators.\nWhen such models become more robust and used in real-life applications, they\nmight help decision makers and early responders to choose the best actions to\nsustain the wellbeing of society, natural resources and biodiversity. I\nunderline that this is an open field and an ongoing research for many\nscientists, therefore I offer an in depth discussion on the challenges and\nlimitations of AI-based methods and the predictive estimation models in\ngeneral.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 15:55:26 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sirmacek", "Beril", ""]]}, {"id": "2107.02711", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhuoran Yang, Zhaoran Wang, Yingbin Liang", "title": "A Unified Off-Policy Evaluation Approach for General Value Function", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  General Value Function (GVF) is a powerful tool to represent both the {\\em\npredictive} and {\\em retrospective} knowledge in reinforcement learning (RL).\nIn practice, often multiple interrelated GVFs need to be evaluated jointly with\npre-collected off-policy samples. In the literature, the gradient temporal\ndifference (GTD) learning method has been adopted to evaluate GVFs in the\noff-policy setting, but such an approach may suffer from a large estimation\nerror even if the function approximation class is sufficiently expressive.\nMoreover, none of the previous work have formally established the convergence\nguarantee to the ground truth GVFs under the function approximation settings.\nIn this paper, we address both issues through the lens of a class of GVFs with\ncausal filtering, which cover a wide range of RL applications such as reward\nvariance, value gradient, cost in anomaly detection, stationary distribution\ngradient, etc. We propose a new algorithm called GenTD for off-policy GVFs\nevaluation and show that GenTD learns multiple interrelated multi-dimensional\nGVFs as efficiently as a single canonical scalar value function. We further\nshow that unlike GTD, the learned GVFs by GenTD are guaranteed to converge to\nthe ground truth GVFs as long as the function approximation power is\nsufficiently large. To our best knowledge, GenTD is the first off-policy GVF\nevaluation algorithm that has global optimality guarantee.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:20:34 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Xu", "Tengyu", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Liang", "Yingbin", ""]]}, {"id": "2107.02716", "submitter": "Charles Lu", "authors": "Charles Lu, Andreanne Lemay, Katharina Hoebel, Jayashree\n  Kalpathy-Cramer", "title": "Evaluating subgroup disparity using epistemic uncertainty in mammography", "comments": "Accepted to the Interpretable Machine Learning in Healthcare workshop\n  at the ICML 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning (ML) continue to be integrated into healthcare systems\nthat affect clinical decision making, new strategies will need to be\nincorporated in order to effectively detect and evaluate subgroup disparities\nto ensure accountability and generalizability in clinical workflows. In this\npaper, we explore how epistemic uncertainty can be used to evaluate disparity\nin patient demographics (race) and data acquisition (scanner) subgroups for\nbreast density assessment on a dataset of 108,190 mammograms collected from 33\nclinical sites. Our results show that even if aggregate performance is\ncomparable, the choice of uncertainty quantification metric can significantly\nthe subgroup level. We hope this analysis can promote further work on how\nuncertainty can be leveraged to increase transparency of machine learning\napplications for clinical deployment.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:36:48 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 22:46:10 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Lu", "Charles", ""], ["Lemay", "Andreanne", ""], ["Hoebel", "Katharina", ""], ["Kalpathy-Cramer", "Jayashree", ""]]}, {"id": "2107.02729", "submitter": "Sara Magliacane", "authors": "Biwei Huang, Fan Feng, Chaochao Lu, Sara Magliacane, Kun Zhang", "title": "AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most approaches in reinforcement learning (RL) are data-hungry and specific\nto fixed environments. In this paper, we propose a principled framework for\nadaptive RL, called AdaRL, that adapts reliably to changes across domains.\nSpecifically, we construct a generative environment model for the structural\nrelationships among variables in the system and embed the changes in a compact\nway, which provides a clear and interpretable picture for locating what and\nwhere the changes are and how to adapt. Based on the environment model, we\ncharacterize a minimal set of representations, including both domain-specific\nfactors and domain-shared state representations, that suffice for reliable and\nlow-cost transfer. Moreover, we show that by explicitly leveraging a compact\nrepresentation to encode changes, we can adapt the policy with only a few\nsamples without further policy optimization in the target domain. We illustrate\nthe efficacy of AdaRL through a series of experiments that allow for changes in\ndifferent components of Cartpole and Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:56:25 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 07:21:38 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Huang", "Biwei", ""], ["Feng", "Fan", ""], ["Lu", "Chaochao", ""], ["Magliacane", "Sara", ""], ["Zhang", "Kun", ""]]}, {"id": "2107.02732", "submitter": "Matt Jordan", "authors": "Matt Jordan, Alexandros G. Dimakis", "title": "Provable Lipschitz Certification for Generative Models", "comments": "Accepted into ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a scalable technique for upper bounding the Lipschitz constant of\ngenerative models. We relate this quantity to the maximal norm over the set of\nattainable vector-Jacobian products of a given generative model. We approximate\nthis set by layerwise convex approximations using zonotopes. Our approach\ngeneralizes and improves upon prior work using zonotope transformers and we\nextend to Lipschitz estimation of neural networks with large output dimension.\nThis provides efficient and tight bounds on small networks and can scale to\ngenerative models on VAE and DCGAN architectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:00:29 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Jordan", "Matt", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "2107.02736", "submitter": "Matti Karppa", "authors": "Matti Karppa and Martin Aum\\\"uller and Rasmus Pagh", "title": "DEANN: Speeding up Kernel-Density Estimation using Approximate Nearest\n  Neighbor Search", "comments": "24 pages, 1 figure. Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel Density Estimation (KDE) is a nonparametric method for estimating the\nshape of a density function, given a set of samples from the distribution.\nRecently, locality-sensitive hashing, originally proposed as a tool for nearest\nneighbor search, has been shown to enable fast KDE data structures. However,\nthese approaches do not take advantage of the many other advances that have\nbeen made in algorithms for nearest neighbor algorithms. We present an\nalgorithm called Density Estimation from Approximate Nearest Neighbors (DEANN)\nwhere we apply Approximate Nearest Neighbor (ANN) algorithms as a black box\nsubroutine to compute an unbiased KDE. The idea is to find points that have a\nlarge contribution to the KDE using ANN, compute their contribution exactly,\nand approximate the remainder with Random Sampling (RS). We present a\ntheoretical argument that supports the idea that an ANN subroutine can speed up\nthe evaluation. Furthermore, we provide a C++ implementation with a Python\ninterface that can make use of an arbitrary ANN implementation as a subroutine\nfor KDE evaluation. We show empirically that our implementation outperforms\nstate of the art implementations in all high dimensional datasets we\nconsidered, and matches the performance of RS in cases where the ANN yield no\ngains in performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:11:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Karppa", "Matti", ""], ["Aum\u00fcller", "Martin", ""], ["Pagh", "Rasmus", ""]]}, {"id": "2107.02738", "submitter": "Lee Cohen", "authors": "Lee Cohen, Ulrike Schmidt-Kraepelin, Yishay Mansour", "title": "Dueling Bandits with Team Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the dueling teams problem, a new online-learning setting in\nwhich the learner observes noisy comparisons of disjoint pairs of $k$-sized\nteams from a universe of $n$ players. The goal of the learner is to minimize\nthe number of duels required to identify, with high probability, a Condorcet\nwinning team, i.e., a team which wins against any other disjoint team (with\nprobability at least $1/2$). Noisy comparisons are linked to a total order on\nthe teams. We formalize our model by building upon the dueling bandits setting\n(Yue et al.2012) and provide several algorithms, both for stochastic and\ndeterministic settings. For the stochastic setting, we provide a reduction to\nthe classical dueling bandits setting, yielding an algorithm that identifies a\nCondorcet winning team within $\\mathcal{O}((n + k \\log (k)) \\frac{\\max(\\log\\log\nn, \\log k)}{\\Delta^2})$ duels, where $\\Delta$ is a gap parameter. For\ndeterministic feedback, we additionally present a gap-independent algorithm\nthat identifies a Condorcet winning team within $\\mathcal{O}(nk\\log(k)+k^5)$\nduels.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:12:17 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cohen", "Lee", ""], ["Schmidt-Kraepelin", "Ulrike", ""], ["Mansour", "Yishay", ""]]}, {"id": "2107.02744", "submitter": "Ayushe Gangal", "authors": "Ayushe Gangal, Peeyush Kumar, Sunita Kumari and Aditya Kumar", "title": "Neural Computing", "comments": "Book chapter, 25 pages, 16 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This chapter aims to provide next-level understanding of the problems of the\nworld and the solutions available to those problems, which lie very well within\nthe domain of neural computing, and at the same time are intelligent in their\napproach, to invoke a sense of innovation among the educationalists,\nresearchers, academic professionals, students and people concerned, by\nhighlighting the work done by major researchers and innovators in this field\nand thus, encouraging the readers to develop newer and more advanced techniques\nfor the same. By means of this chapter, the societal problems are discussed and\nvarious solutions are also given by means of the theories presented and\nresearches done so far. Different types of neural networks discovered so far\nand applications of some of those neural networks are focused on, apart from\ntheir theoretical understanding, the working and core concepts involved in the\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:21:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gangal", "Ayushe", ""], ["Kumar", "Peeyush", ""], ["Kumari", "Sunita", ""], ["Kumar", "Aditya", ""]]}, {"id": "2107.02751", "submitter": "Michele Sasdelli", "authors": "Michele Sasdelli and Tat-Jun Chin", "title": "Quantum Annealing Formulation for Binary Neural Networks", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum annealing is a promising paradigm for building practical quantum\ncomputers. Compared to other approaches, quantum annealing technology has been\nscaled up to a larger number of qubits. On the other hand, deep learning has\nbeen profoundly successful in pushing the boundaries of AI. It is thus natural\nto investigate potentially game changing technologies such as quantum annealers\nto augment the capabilities of deep learning. In this work, we explore binary\nneural networks, which are lightweight yet powerful models typically intended\nfor resource constrained devices. Departing from current training regimes for\nbinary networks that smooth/approximate the activation functions to make the\nnetwork differentiable, we devise a quadratic unconstrained binary optimization\nformulation for the training problem. While the problem is intractable, i.e.,\nthe cost to estimate the binary weights scales exponentially with network size,\nwe show how the problem can be optimized directly on a quantum annealer,\nthereby opening up to the potential gains of quantum computing. We\nexperimentally validated our formulation via simulation and testing on an\nactual quantum annealer (D-Wave Advantage), the latter to the extent allowable\nby the capacity of current technology.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 03:20:54 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sasdelli", "Michele", ""], ["Chin", "Tat-Jun", ""]]}, {"id": "2107.02755", "submitter": "Van-Dinh Nguyen", "authors": "Van-Dinh Nguyen, Symeon Chatzinotas, Bjorn Ottersten, and Trung Q.\n  Duong", "title": "FedFog: Network-Aware Optimization of Federated Learning over Wireless\n  Fog-Cloud Systems", "comments": "30 pages, 12 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is capable of performing large distributed machine\nlearning tasks across multiple edge users by periodically aggregating trained\nlocal parameters. To address key challenges of enabling FL over a wireless\nfog-cloud system (e.g., non-i.i.d. data, users' heterogeneity), we first\npropose an efficient FL algorithm (called FedFog) to perform the local\naggregation of gradient parameters at fog servers and global training update at\nthe cloud. Next, we employ FedFog in wireless fog-cloud systems by\ninvestigating a novel network-aware FL optimization problem that strikes the\nbalance between the global loss and completion time. An iterative algorithm is\nthen developed to obtain a precise measurement of the system performance, which\nhelps design an efficient stopping criteria to output an appropriate number of\nglobal rounds. To mitigate the straggler effect, we propose a flexible user\naggregation strategy that trains fast users first to obtain a certain level of\naccuracy before allowing slow users to join the global training updates.\nExtensive numerical results using several real-world FL tasks are provided to\nverify the theoretical convergence of FedFog. We also show that the proposed\nco-design of FL and communication is essential to substantially improve\nresource utilization while achieving comparable accuracy of the learning model.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 08:03:15 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nguyen", "Van-Dinh", ""], ["Chatzinotas", "Symeon", ""], ["Ottersten", "Bjorn", ""], ["Duong", "Trung Q.", ""]]}, {"id": "2107.02757", "submitter": "Zhibin Duan", "authors": "Zhibin Duan, Dongsheng Wang, Bo Chen, Chaojie Wang, Wenchao Chen,\n  Yewen Li, Jie Ren, Mingyuan Zhou", "title": "Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical topic models such as the gamma belief network (GBN) have\ndelivered promising results in mining multi-layer document representations and\ndiscovering interpretable topic taxonomies. However, they often assume in the\nprior that the topics at each layer are independently drawn from the Dirichlet\ndistribution, ignoring the dependencies between the topics both at the same\nlayer and across different layers. To relax this assumption, we propose\nsawtooth factorial topic embedding guided GBN, a deep generative model of\ndocuments that captures the dependencies and semantic similarities between the\ntopics in the embedding space. Specifically, both the words and topics are\nrepresented as embedding vectors of the same dimension. The topic matrix at a\nlayer is factorized into the product of a factor loading matrix and a topic\nembedding matrix, the transpose of which is set as the factor loading matrix of\nthe layer above. Repeating this particular type of factorization, which shares\ncomponents between adjacent layers, leads to a structure referred to as\nsawtooth factorization. An auto-encoding variational inference network is\nconstructed to optimize the model parameter via stochastic gradient descent.\nExperiments on big corpora show that our models outperform other neural topic\nmodels on extracting deeper interpretable topics and deriving better document\nrepresentations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 10:14:57 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Duan", "Zhibin", ""], ["Wang", "Dongsheng", ""], ["Chen", "Bo", ""], ["Wang", "Chaojie", ""], ["Chen", "Wenchao", ""], ["Li", "Yewen", ""], ["Ren", "Jie", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2107.02772", "submitter": "Aurghya Maiti", "authors": "Aurghya Maiti, Vineet Nair, Gaurav Sinha", "title": "Causal Bandits on General Graphs", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of determining the best intervention in a Causal\nBayesian Network (CBN) specified only by its causal graph. We model this as a\nstochastic multi-armed bandit (MAB) problem with side-information, where the\ninterventions correspond to the arms of the bandit instance. First, we propose\na simple regret minimization algorithm that takes as input a semi-Markovian\ncausal graph with atomic interventions and possibly unobservable variables, and\nachieves $\\tilde{O}(\\sqrt{M/T})$ expected simple regret, where $M$ is dependent\non the input CBN and could be very small compared to the number of arms. We\nalso show that this is almost optimal for CBNs described by causal graphs\nhaving an $n$-ary tree structure. Our simple regret minimization results, both\nupper and lower bound, subsume previous results in the literature, which\nassumed additional structural restrictions on the input causal graph. In\nparticular, our results indicate that the simple regret guarantee of our\nproposed algorithm can only be improved by considering more nuanced structural\nrestrictions on the causal graph. Next, we propose a cumulative regret\nminimization algorithm that takes as input a general causal graph with all\nobservable nodes and atomic interventions and performs better than the optimal\nMAB algorithm that does not take causal side-information into account. We also\nexperimentally compare both our algorithms with the best known algorithms in\nthe literature. To the best of our knowledge, this work gives the first simple\nand cumulative regret minimization algorithms for CBNs with general causal\ngraphs under atomic interventions and having unobserved confounders.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:29:45 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Maiti", "Aurghya", ""], ["Nair", "Vineet", ""], ["Sinha", "Gaurav", ""]]}, {"id": "2107.02776", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis, Abir De, Manuel Gomez-Rodriguez", "title": "Counterfactual Explanations in Sequential Decision Making Under\n  Uncertainty", "comments": "To appear at the ICML 2021 workshop on Interpretable Machine Learning\n  in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Methods to find counterfactual explanations have predominantly focused on one\nstep decision making processes. In this work, we initiate the development of\nmethods to find counterfactual explanations for decision making processes in\nwhich multiple, dependent actions are taken sequentially over time. We start by\nformally characterizing a sequence of actions and states using finite horizon\nMarkov decision processes and the Gumbel-Max structural causal model. Building\nupon this characterization, we formally state the problem of finding\ncounterfactual explanations for sequential decision making processes. In our\nproblem formulation, the counterfactual explanation specifies an alternative\nsequence of actions differing in at most k actions from the observed sequence\nthat could have led the observed process realization to a better outcome. Then,\nwe introduce a polynomial time algorithm based on dynamic programming to build\na counterfactual policy that is guaranteed to always provide the optimal\ncounterfactual explanation on every possible realization of the counterfactual\nenvironment dynamics. We validate our algorithm using both synthetic and real\ndata from cognitive behavioral therapy and show that the counterfactual\nexplanations our algorithm finds can provide valuable insights to enhance\nsequential decision making under uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:38:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["De", "Abir", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2107.02780", "submitter": "Rahul Singh", "authors": "Anish Agarwal and Rahul Singh", "title": "Causal Inference with Corrupted Data: Measurement Error, Missing Values,\n  Discretization, and Differential Privacy", "comments": "99 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even the most carefully curated economic data sets have variables that are\nnoisy, missing, discretized, or privatized. The standard workflow for empirical\nresearch involves data cleaning followed by data analysis that typically\nignores the bias and variance consequences of data cleaning. We formulate a\nsemiparametric model for causal inference with corrupted data to encompass both\ndata cleaning and data analysis. We propose a new end-to-end procedure for data\ncleaning, estimation, and inference with data cleaning-adjusted confidence\nintervals. We prove root-n consistency, Gaussian approximation, and\nsemiparametric efficiency for our estimator of the causal parameter by finite\nsample arguments. Our key assumption is that the true covariates are\napproximately low rank. In our analysis, we provide nonasymptotic theoretical\ncontributions to matrix completion, statistical learning, and semiparametric\nstatistics. We verify the coverage of the data cleaning-adjusted confidence\nintervals in simulations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:42:49 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Agarwal", "Anish", ""], ["Singh", "Rahul", ""]]}, {"id": "2107.02783", "submitter": "Azqa Nadeem", "authors": "Azqa Nadeem, Sicco Verwer, Stephen Moskal, Shanchieh Jay Yang", "title": "SAGE: Intrusion Alert-driven Attack Graph Extractor", "comments": "Accepted to appear in the 1st KDD Workshop on AI-enabled\n  Cybersecurity Analytics (AI4cyber), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attack graphs (AG) are used to assess pathways availed by cyber adversaries\nto penetrate a network. State-of-the-art approaches for AG generation focus\nmostly on deriving dependencies between system vulnerabilities based on network\nscans and expert knowledge. In real-world operations however, it is costly and\nineffective to rely on constant vulnerability scanning and expert-crafted AGs.\nWe propose to automatically learn AGs based on actions observed through\nintrusion alerts, without prior expert knowledge. Specifically, we develop an\nunsupervised sequence learning system, SAGE, that leverages the temporal and\nprobabilistic dependence between alerts in a suffix-based probabilistic\ndeterministic finite automaton (S-PDFA) -- a model that accentuates infrequent\nsevere alerts and summarizes paths leading to them. AGs are then derived from\nthe S-PDFA. Tested with intrusion alerts collected through Collegiate\nPenetration Testing Competition, SAGE produces AGs that reflect the strategies\nused by participating teams. The resulting AGs are succinct, interpretable, and\nenable analysts to derive actionable insights, e.g., attackers tend to follow\nshorter paths after they have discovered a longer one.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:45:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nadeem", "Azqa", ""], ["Verwer", "Sicco", ""], ["Moskal", "Stephen", ""], ["Yang", "Shanchieh Jay", ""]]}, {"id": "2107.02784", "submitter": "Sourav Dutta", "authors": "Sourav Dutta, Peter Rivera-Casillas, Orie M. Cecil, Matthew W.\n  Farthing, Emma Perracchione, Mario Putti", "title": "Data-driven reduced order modeling of environmental hydrodynamics using\n  deep autoencoders and neural ODEs", "comments": "16 pages, 7 figures, To Appear in the proceedings of the IXth\n  International Conference on Computational Methods for Coupled Problems in\n  Science and Engineering (COUPLED PROBLEMS 2021), 14-16 June, 2021. arXiv\n  admin note: substantial text overlap with arXiv:2104.13962", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model reduction for fluid flow simulation continues to be of great interest\nacross a number of scientific and engineering fields. In a previous work\n[arXiv:2104.13962], we explored the use of Neural Ordinary Differential\nEquations (NODE) as a non-intrusive method for propagating the latent-space\ndynamics in reduced order models. Here, we investigate employing deep\nautoencoders for discovering the reduced basis representation, the dynamics of\nwhich are then approximated by NODE. The ability of deep autoencoders to\nrepresent the latent-space is compared to the traditional proper orthogonal\ndecomposition (POD) approach, again in conjunction with NODE for capturing the\ndynamics. Additionally, we compare their behavior with two classical\nnon-intrusive methods based on POD and radial basis function interpolation as\nwell as dynamic mode decomposition. The test problems we consider include\nincompressible flow around a cylinder as well as a real-world application of\nshallow water hydrodynamics in an estuarine system. Our findings indicate that\ndeep autoencoders can leverage nonlinear manifold learning to achieve a highly\nefficient compression of spatial information and define a latent-space that\nappears to be more suitable for capturing the temporal dynamics through the\nNODE framework.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:45:37 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Dutta", "Sourav", ""], ["Rivera-Casillas", "Peter", ""], ["Cecil", "Orie M.", ""], ["Farthing", "Matthew W.", ""], ["Perracchione", "Emma", ""], ["Putti", "Mario", ""]]}, {"id": "2107.02791", "submitter": "Kangle Deng", "authors": "Kangle Deng, Andrew Liu, Jun-Yan Zhu, and Deva Ramanan", "title": "Depth-supervised NeRF: Fewer Views and Faster Training for Free", "comments": "Project page: http://www.cs.cmu.edu/~dsnerf/ GitHub:\n  https://github.com/dunbar12138/DSNeRF", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One common failure mode of Neural Radiance Field (NeRF) models is fitting\nincorrect geometries when given an insufficient number of input views. We\npropose DS-NeRF (Depth-supervised Neural Radiance Fields), a loss for learning\nneural radiance fields that takes advantage of readily-available depth\nsupervision. Our key insight is that sparse depth supervision can be used to\nregularize the learned geometry, a crucial component for effectively rendering\nnovel views using NeRF. We exploit the fact that current NeRF pipelines require\nimages with known camera poses that are typically estimated by running\nstructure-from-motion (SFM). Crucially, SFM also produces sparse 3D points that\ncan be used as ``free\" depth supervision during training: we simply add a loss\nto ensure that depth rendered along rays that intersect these 3D points is\nclose to the observed depth. We find that DS-NeRF can render more accurate\nimages given fewer training views while training 2-6x faster. With only two\ntraining views on real-world images, DS-NeRF significantly outperforms NeRF as\nwell as other sparse-view variants. We show that our loss is compatible with\nthese NeRF models, demonstrating that depth is a cheap and easily digestible\nsupervisory signal. Finally, we show that DS-NeRF supports other types of depth\nsupervision such as scanned depth sensors and RGBD reconstruction outputs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:58:35 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Deng", "Kangle", ""], ["Liu", "Andrew", ""], ["Zhu", "Jun-Yan", ""], ["Ramanan", "Deva", ""]]}, {"id": "2107.02792", "submitter": "Arun Narenthiran Sivakumar", "authors": "Arun Narenthiran Sivakumar and Sahil Modi and Mateus Valverde\n  Gasparino and Che Ellis and Andres Eduardo Baquero Velasquez and Girish\n  Chowdhary and Saurabh Gupta", "title": "Learned Visual Navigation for Under-Canopy Agricultural Robots", "comments": "RSS 2021. Project website with data and videos:\n  https://ansivakumar.github.io/learned-visual-navigation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We describe a system for visually guided autonomous navigation of\nunder-canopy farm robots. Low-cost under-canopy robots can drive between crop\nrows under the plant canopy and accomplish tasks that are infeasible for\nover-the-canopy drones or larger agricultural equipment. However, autonomously\nnavigating them under the canopy presents a number of challenges: unreliable\nGPS and LiDAR, high cost of sensing, challenging farm terrain, clutter due to\nleaves and weeds, and large variability in appearance over the season and\nacross crop types. We address these challenges by building a modular system\nthat leverages machine learning for robust and generalizable perception from\nmonocular RGB images from low-cost cameras, and model predictive control for\naccurate control in challenging terrain. Our system, CropFollow, is able to\nautonomously drive 485 meters per intervention on average, outperforming a\nstate-of-the-art LiDAR based system (286 meters per intervention) in extensive\nfield testing spanning over 25 km.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:59:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Sivakumar", "Arun Narenthiran", ""], ["Modi", "Sahil", ""], ["Gasparino", "Mateus Valverde", ""], ["Ellis", "Che", ""], ["Velasquez", "Andres Eduardo Baquero", ""], ["Chowdhary", "Girish", ""], ["Gupta", "Saurabh", ""]]}, {"id": "2107.02794", "submitter": "Maxwell Nye", "authors": "Maxwell Nye, Michael Henry Tessler, Joshua B. Tenenbaum, Brenden M.\n  Lake", "title": "Improving Coherence and Consistency in Neural Sequence Models with\n  Dual-System, Neuro-Symbolic Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human reasoning can often be understood as an interplay between two systems:\nthe intuitive and associative (\"System 1\") and the deliberative and logical\n(\"System 2\"). Neural sequence models -- which have been increasingly successful\nat performing complex, structured tasks -- exhibit the advantages and failure\nmodes of System 1: they are fast and learn patterns from data, but are often\ninconsistent and incoherent. In this work, we seek a lightweight, training-free\nmeans of improving existing System 1-like sequence models by adding System\n2-inspired logical reasoning. We explore several variations on this theme in\nwhich candidate generations from a neural sequence model are examined for\nlogical consistency by a symbolic reasoning module, which can either accept or\nreject the generations. Our approach uses neural inference to mediate between\nthe neural System 1 and the logical System 2. Results in robust story\ngeneration and grounded instruction-following show that this approach can\nincrease the coherence and accuracy of neurally-based generations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:59:49 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Nye", "Maxwell", ""], ["Tessler", "Michael Henry", ""], ["Tenenbaum", "Joshua B.", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2107.02797", "submitter": "Lingfeng Li", "authors": "Lingfeng Li and Xue-Cheng Tai and Jiang Yang", "title": "Generalization Error Analysis of Neural networks with Gradient Based\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study gradient-based regularization methods for neural networks. We mainly\nfocus on two regularization methods: the total variation and the Tikhonov\nregularization. Applying these methods is equivalent to using neural networks\nto solve some partial differential equations, mostly in high dimensions in\npractical applications. In this work, we introduce a general framework to\nanalyze the generalization error of regularized networks. The error estimate\nrelies on two assumptions on the approximation error and the quadrature error.\nMoreover, we conduct some experiments on the image classification tasks to show\nthat gradient-based methods can significantly improve the generalization\nability and adversarial robustness of neural networks. A graphical extension of\nthe gradient-based methods are also considered in the experiments.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:54:36 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Li", "Lingfeng", ""], ["Tai", "Xue-Cheng", ""], ["Yang", "Jiang", ""]]}, {"id": "2107.02821", "submitter": "Gregor Kasieczka", "authors": "Gregor Kasieczka, Benjamin Nachman, David Shih", "title": "New Methods and Datasets for Group Anomaly Detection From Fundamental\n  Physics", "comments": "Accepted for ANDEA (Anomaly and Novelty Detection, Explanation and\n  Accommodation) Workshop at KDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of anomalous overdensities in data - group or collective\nanomaly detection - is a rich problem with a large number of real world\napplications. However, it has received relatively little attention in the\nbroader ML community, as compared to point anomalies or other types of single\ninstance outliers. One reason for this is the lack of powerful benchmark\ndatasets. In this paper, we first explain how, after the Nobel-prize winning\ndiscovery of the Higgs boson, unsupervised group anomaly detection has become a\nnew frontier of fundamental physics (where the motivation is to find new\nparticles and forces). Then we propose a realistic synthetic benchmark dataset\n(LHCO2020) for the development of group anomaly detection algorithms. Finally,\nwe compare several existing statistically-sound techniques for unsupervised\ngroup anomaly detection, and demonstrate their performance on the LHCO2020\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 18:00:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kasieczka", "Gregor", ""], ["Nachman", "Benjamin", ""], ["Shih", "David", ""]]}, {"id": "2107.02840", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Alnawaz\n  Rehemtulla, Indika Rajapakse, Alfred Hero", "title": "RAILS: A Robust Adversarial Immune-inspired Learning System", "comments": "arXiv admin note: text overlap with arXiv:2012.10485", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against deep neural networks (DNNs) are continuously\nevolving, requiring increasingly powerful defense strategies. We develop a\nnovel adversarial defense framework inspired by the adaptive immune system: the\nRobust Adversarial Immune-inspired Learning System (RAILS). Initializing a\npopulation of exemplars that is balanced across classes, RAILS starts from a\nuniform label distribution that encourages diversity and debiases a potentially\ncorrupted initial condition. RAILS implements an evolutionary optimization\nprocess to adjust the label distribution and achieve specificity towards ground\ntruth. RAILS displays a tradeoff between robustness (diversity) and accuracy\n(specificity), providing a new immune-inspired perspective on adversarial\nlearning. We empirically validate the benefits of RAILS through several\nadversarial image classification experiments on MNIST, SVHN, and CIFAR-10\ndatasets. For the PGD attack, RAILS is found to improve the robustness over\nexisting methods by >= 5.62%, 12.5% and 10.32%, respectively, without\nappreciable loss of standard accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 17:57:45 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Lindsly", "Stephen", ""], ["Stansbury", "Cooper", ""], ["Rehemtulla", "Alnawaz", ""], ["Rajapakse", "Indika", ""], ["Hero", "Alfred", ""]]}, {"id": "2107.02842", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Indika\n  Rajapakse, Alfred Hero", "title": "Immuno-mimetic Deep Neural Networks (Immuno-Net)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomimetics has played a key role in the evolution of artificial neural\nnetworks. Thus far, in silico metaphors have been dominated by concepts from\nneuroscience and cognitive psychology. In this paper we introduce a different\ntype of biomimetic model, one that borrows concepts from the immune system, for\ndesigning robust deep neural networks. This immuno-mimetic model leads to a new\ncomputational biology framework for robustification of deep neural networks\nagainst adversarial attacks. Within this Immuno-Net framework we define a\nrobust adaptive immune-inspired learning system (Immuno-Net RAILS) that\nemulates, in silico, the adaptive biological mechanisms of B-cells that are\nused to defend a mammalian host against pathogenic attacks. When applied to\nimage classification tasks on benchmark datasets, we demonstrate that\nImmuno-net RAILS results in improvement of as much as 12.5% in adversarial\naccuracy of a baseline method, the DkNN-robustified CNN, without appreciable\nloss of accuracy on clean data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 16:45:23 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Lindsly", "Stephen", ""], ["Stansbury", "Cooper", ""], ["Rajapakse", "Indika", ""], ["Hero", "Alfred", ""]]}, {"id": "2107.02845", "submitter": "Huiyu Wu", "authors": "Huiyu Wu and Diego Klabjan", "title": "Logit-based Uncertainty Measure in Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new, reliable, and agnostic uncertainty measure for\nclassification tasks called logit uncertainty. It is based on logit outputs of\nneural networks. We in particular show that this new uncertainty measure yields\na superior performance compared to existing uncertainty measures on different\ntasks, including out of sample detection and finding erroneous predictions. We\nanalyze theoretical foundations of the measure and explore a relationship with\nhigh density regions. We also demonstrate how to test uncertainty using\nintermediate outputs in training of generative adversarial networks. We propose\ntwo potential ways to utilize logit-based uncertainty in real world\napplications, and show that the uncertainty measure outperforms.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:07:16 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wu", "Huiyu", ""], ["Klabjan", "Diego", ""]]}, {"id": "2107.02847", "submitter": "Shaohan Chen", "authors": "Shaohan Chen, Nikolaos V. Sahinidis and Chuanhou Gao", "title": "Transfer Learning in Information Criteria-based Feature Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effectiveness of transfer learning based on\nMallows' Cp. We propose a procedure that combines transfer learning with\nMallows' Cp (TLCp) and prove that it outperforms the conventional Mallows' Cp\ncriterion in terms of accuracy and stability. Our theoretical results indicate\nthat, for any sample size in the target domain, the proposed TLCp estimator\nperforms better than the Cp estimator by the mean squared error (MSE) metric in\nthe case of orthogonal predictors, provided that i) the dissimilarity between\nthe tasks from source domain and target domain is small, and ii) the procedure\nparameters (complexity penalties) are tuned according to certain explicit\nrules. Moreover, we show that our transfer learning framework can be extended\nto other feature selection criteria, such as the Bayesian information\ncriterion. By analyzing the solution of the orthogonalized Cp, we identify an\nestimator that asymptotically approximates the solution of the Cp criterion in\nthe case of non-orthogonal predictors. Similar results are obtained for the\nnon-orthogonal TLCp. Finally, simulation studies and applications with real\ndata demonstrate the usefulness of the TLCp scheme.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:12:15 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Chen", "Shaohan", ""], ["Sahinidis", "Nikolaos V.", ""], ["Gao", "Chuanhou", ""]]}, {"id": "2107.02868", "submitter": "Olivia Brown", "authors": "Olivia Brown, Andrew Curtis, Justin Goodwin", "title": "Principles for Evaluation of AI/ML Model Performance and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Department of Defense (DoD) has significantly increased its investment in\nthe design, evaluation, and deployment of Artificial Intelligence and Machine\nLearning (AI/ML) capabilities to address national security needs. While there\nare numerous AI/ML successes in the academic and commercial sectors, many of\nthese systems have also been shown to be brittle and nonrobust. In a complex\nand ever-changing national security environment, it is vital that the DoD\nestablish a sound and methodical process to evaluate the performance and\nrobustness of AI/ML models before these new capabilities are deployed to the\nfield. This paper reviews the AI/ML development process, highlights common best\npractices for AI/ML model evaluation, and makes recommendations to DoD\nevaluators to ensure the deployment of robust AI/ML capabilities for national\nsecurity needs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:59:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Brown", "Olivia", ""], ["Curtis", "Andrew", ""], ["Goodwin", "Justin", ""]]}, {"id": "2107.02890", "submitter": "Raz Saremi", "authors": "Hamid Shamszare, Razieh Saremi, Sanam Jena", "title": "From Zero to The Hero: A Collaborative Market Aware Recommendation\n  System for Crowd Workers", "comments": "11 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of software crowdsourcing depends on active and trustworthy pool\nof worker supply. The uncertainty of crowd workers' behaviors makes it\nchallenging to predict workers' success and plan accordingly. In a competitive\ncrowdsourcing marketplace, competition for success over shared tasks adds\nanother layer of uncertainty in crowd workers' decision-making process.\nPreliminary analysis on software worker behaviors reveals an alarming task\ndropping rate of 82.9%. These factors lead to the need for an automated\nrecommendation system for CSD workers to improve the visibility and\npredictability of their success in the competition. To that end, this paper\nproposes a collaborative recommendation system for crowd workers. The proposed\nrecommendation system method uses five input metrics based on workers'\ncollaboration history in the pool, workers' preferences in taking tasks in\nterms of monetary prize and duration, workers' specialty, and workers'\nproficiency. The proposed method then recommends the most suitable tasks for a\nworker to compete on based on workers' probability of success in the task.\nExperimental results on 260 active crowd workers demonstrate that just\nfollowing the top three success probabilities of task recommendations, workers\ncan achieve success up to 86%\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:02:36 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Shamszare", "Hamid", ""], ["Saremi", "Razieh", ""], ["Jena", "Sanam", ""]]}, {"id": "2107.02894", "submitter": "Bowei Xi", "authors": "Bowei Xi", "title": "Adversarial Machine Learning for Cybersecurity and Computer Vision:\n  Current Developments and Challenges", "comments": "Published in WIREs Computational Statistics", "journal-ref": "Wiley Interdisciplinary Reviews (WIREs) Computational Statistics,\n  12(5), 1-16, e1511, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We provide a comprehensive overview of adversarial machine learning focusing\non two application domains, i.e., cybersecurity and computer vision. Research\nin adversarial machine learning addresses a significant threat to the wide\napplication of machine learning techniques -- they are vulnerable to carefully\ncrafted attacks from malicious adversaries. For example, deep neural networks\nfail to correctly classify adversarial images, which are generated by adding\nimperceptible perturbations to clean images.We first discuss three main\ncategories of attacks against machine learning techniques -- poisoning attacks,\nevasion attacks, and privacy attacks. Then the corresponding defense approaches\nare introduced along with the weakness and limitations of the existing defense\napproaches. We notice adversarial samples in cybersecurity and computer vision\nare fundamentally different. While adversarial samples in cybersecurity often\nhave different properties/distributions compared with training data,\nadversarial images in computer vision are created with minor input\nperturbations. This further complicates the development of robust learning\ntechniques, because a robust learning technique must withstand different types\nof attacks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 03:05:58 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Xi", "Bowei", ""]]}, {"id": "2107.02895", "submitter": "Bowei Xi", "authors": "Bowei Xi and Yujie Chen and Fan Fei and Zhan Tu and Xinyan Deng", "title": "Bio-Inspired Adversarial Attack Against Deep Neural Networks", "comments": "Published in SafeAI 2020", "journal-ref": "In AAAI Workshop on Artificial Intelligence Safety (SafeAI), Feb.\n  2020, New York City, 1--5", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The paper develops a new adversarial attack against deep neural networks\n(DNN), based on applying bio-inspired design to moving physical objects. To the\nbest of our knowledge, this is the first work to introduce physical attacks\nwith a moving object. Instead of following the dominating attack strategy in\nthe existing literature, i.e., to introduce minor perturbations to a digital\ninput or a stationary physical object, we show two new successful attack\nstrategies in this paper. We show by superimposing several patterns onto one\nphysical object, a DNN becomes confused and picks one of the patterns to assign\na class label. Our experiment with three flapping wing robots demonstrates the\npossibility of developing an adversarial camouflage to cause a targeted mistake\nby DNN. We also show certain motion can reduce the dependency among consecutive\nframes in a video and make an object detector \"blind\", i.e., not able to detect\nan object exists in the video. Hence in a successful physical attack against\nDNN, targeted motion against the system should also be considered.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 03:23:52 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Xi", "Bowei", ""], ["Chen", "Yujie", ""], ["Fei", "Fan", ""], ["Tu", "Zhan", ""], ["Deng", "Xinyan", ""]]}, {"id": "2107.02896", "submitter": "Javier Velasco-Mata", "authors": "Javier Velasco-Mata, V\\'ictor Gonz\\'alez-Castro, Eduardo Fidalgo,\n  Enrique Alegre", "title": "Efficient Detection of Botnet Traffic by features selection and Decision\n  Trees", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Botnets are one of the online threats with the biggest presence, causing\nbillionaire losses to global economies. Nowadays, the increasing number of\ndevices connected to the Internet makes it necessary to analyze large amounts\nof network traffic data. In this work, we focus on increasing the performance\non botnet traffic classification by selecting those features that further\nincrease the detection rate. For this purpose we use two feature selection\ntechniques, Information Gain and Gini Importance, which led to three\npre-selected subsets of five, six and seven features. Then, we evaluate the\nthree feature subsets along with three models, Decision Tree, Random Forest and\nk-Nearest Neighbors. To test the performance of the three feature vectors and\nthe three models we generate two datasets based on the CTU-13 dataset, namely\nQB-CTU13 and EQB-CTU13. We measure the performance as the macro averaged F1\nscore over the computational time required to classify a sample. The results\nshow that the highest performance is achieved by Decision Trees using a five\nfeature set which obtained a mean F1 score of 85% classifying each sample in an\naverage time of 0.78 microseconds.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:55:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Velasco-Mata", "Javier", ""], ["Gonz\u00e1lez-Castro", "V\u00edctor", ""], ["Fidalgo", "Eduardo", ""], ["Alegre", "Enrique", ""]]}, {"id": "2107.02897", "submitter": "Ziaur Rahman", "authors": "Mustain Billah, Adnan Anwar, Ziaur Rahman and Syed Md. Galib", "title": "Bi-Level Poisoning Attack Model and Countermeasure for Appliance\n  Consumption Data of Smart Homes", "comments": "17 Pages, 7 Figures, 1 table", "journal-ref": "Energies 2021, 14(13), 3887", "doi": "10.3390/en14133887", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate building energy prediction is useful in various applications\nstarting from building energy automation and management to optimal storage\ncontrol. However, vulnerabilities should be considered when designing building\nenergy prediction models, as intelligent attackers can deliberately influence\nthe model performance using sophisticated attack models. These may consequently\ndegrade the prediction accuracy, which may affect the efficiency and\nperformance of the building energy management systems. In this paper, we\ninvestigate the impact of bi-level poisoning attacks on regression models of\nenergy usage obtained from household appliances. Furthermore, an effective\ncountermeasure against the poisoning attacks on the prediction model is\nproposed in this paper. Attacks and defenses are evaluated on a benchmark\ndataset. Experimental results show that an intelligent cyber-attacker can\npoison the prediction model to manipulate the decision. However, our proposed\nsolution successfully ensures defense against such poisoning attacks\neffectively compared to other benchmark techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:40:01 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Billah", "Mustain", ""], ["Anwar", "Adnan", ""], ["Rahman", "Ziaur", ""], ["Galib", "Syed Md.", ""]]}, {"id": "2107.02908", "submitter": "Chase Shimmin", "authors": "Chase Shimmin", "title": "Particle Convolution for High Energy Physics", "comments": "To be presented at ML4Jets 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce the Particle Convolution Network (PCN), a new type of\nequivariant neural network layer suitable for many tasks in jet physics. The\nparticle convolution layer can be viewed as an extension of Deep Sets and\nEnergy Flow network architectures, in which the permutation-invariant operator\nis promoted to a group convolution. While the PCN can be implemented for\nvarious kinds of symmetries, we consider the specific case of rotation about\nthe jet axis the $\\eta - \\phi$ plane. In two standard benchmark tasks, q/g\ntagging and top tagging, we show that the rotational PCN (rPCN) achieves\nperformance comparable to graph networks such as ParticleNet. Moreover, we show\nthat it is possible to implement an IRC-safe rPCN, which significantly\noutperforms existing IRC-safe tagging methods on both tasks. We speculate that\nby generalizing the PCN to include additional convolutional symmetries relevant\nto jet physics, it may outperform the current state-of-the-art set by graph\nnetworks, while offering a new degree of control over physically-motivated\ninductive biases.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:54:58 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Shimmin", "Chase", ""]]}, {"id": "2107.02911", "submitter": "Alkis Gotovos", "authors": "Alkis Gotovos, Rebekka Burkholz, John Quackenbush, and Stefanie\n  Jegelka", "title": "Scaling up Continuous-Time Markov Chains Helps Resolve\n  Underspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling the time evolution of discrete sets of items (e.g., genetic\nmutations) is a fundamental problem in many biomedical applications. We\napproach this problem through the lens of continuous-time Markov chains, and\nshow that the resulting learning task is generally underspecified in the usual\nsetting of cross-sectional data. We explore a perhaps surprising remedy:\nincluding a number of additional independent items can help determine time\norder, and hence resolve underspecification. This is in sharp contrast to the\ncommon practice of limiting the analysis to a small subset of relevant items,\nwhich is followed largely due to poor scaling of existing methods. To put our\ntheoretical insight into practice, we develop an approximate likelihood\nmaximization method for learning continuous-time Markov chains, which can scale\nto hundreds of items and is orders of magnitude faster than previous methods.\nWe demonstrate the effectiveness of our approach on synthetic and real cancer\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:14:49 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Gotovos", "Alkis", ""], ["Burkholz", "Rebekka", ""], ["Quackenbush", "John", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "2107.02912", "submitter": "Ankit Shah", "authors": "Ankit Shah, Pritish Kamath, Shen Li, Patrick Craven, Kevin Landers,\n  Kevin Oden, Julie Shah", "title": "Supervised Bayesian Specification Inference from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observing task demonstrations, human apprentices are able to identify\nwhether a given task is executed correctly long before they gain expertise in\nactually performing that task. Prior research into learning from demonstrations\n(LfD) has failed to capture this notion of the acceptability of a task's\nexecution; meanwhile, temporal logics provide a flexible language for\nexpressing task specifications. Inspired by this, we present Bayesian\nspecification inference, a probabilistic model for inferring task specification\nas a temporal logic formula. We incorporate methods from probabilistic\nprogramming to define our priors, along with a domain-independent likelihood\nfunction to enable sampling-based inference. We demonstrate the efficacy of our\nmodel for inferring specifications, with over 90% similarity observed between\nthe inferred specification and the ground truth, both within a synthetic domain\nand during a real-world table setting task.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:16:37 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Shah", "Ankit", ""], ["Kamath", "Pritish", ""], ["Li", "Shen", ""], ["Craven", "Patrick", ""], ["Landers", "Kevin", ""], ["Oden", "Kevin", ""], ["Shah", "Julie", ""]]}, {"id": "2107.02919", "submitter": "Panayotis Mertikopoulos", "authors": "Zhengyuan Zhou and Panayotis Mertikopoulos and Nicholas Bambos and\n  Peter W. Glynn and Yinyu Ye", "title": "Distributed stochastic optimization with large delays", "comments": "41 pages, 8 figures; to be published in Mathematics of Operations\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most widely used methods for solving large-scale stochastic\noptimization problems is distributed asynchronous stochastic gradient descent\n(DASGD), a family of algorithms that result from parallelizing stochastic\ngradient descent on distributed computing architectures (possibly)\nasychronously. However, a key obstacle in the efficient implementation of DASGD\nis the issue of delays: when a computing node contributes a gradient update,\nthe global model parameter may have already been updated by other nodes several\ntimes over, thereby rendering this gradient information stale. These delays can\nquickly add up if the computational throughput of a node is saturated, so the\nconvergence of DASGD may be compromised in the presence of large delays. Our\nfirst contribution is that, by carefully tuning the algorithm's step-size,\nconvergence to the critical set is still achieved in mean square, even if the\ndelays grow unbounded at a polynomial rate. We also establish finer results in\na broad class of structured optimization problems (called variationally\ncoherent), where we show that DASGD converges to a global optimum with\nprobability $1$ under the same delay assumptions. Together, these results\ncontribute to the broad landscape of large-scale non-convex stochastic\noptimization by offering state-of-the-art theoretical guarantees and providing\ninsights for algorithm design.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:59:49 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhou", "Zhengyuan", ""], ["Mertikopoulos", "Panayotis", ""], ["Bambos", "Nicholas", ""], ["Glynn", "Peter W.", ""], ["Ye", "Yinyu", ""]]}, {"id": "2107.02926", "submitter": "Deep Ray", "authors": "Dhruv V Patel, Deep Ray, Assad A Oberai", "title": "Solution of Physics-based Bayesian Inverse Problems with Deep Generative\n  Priors", "comments": "Paper: 18 pages, 5 figures. Supplementary: 9 pages, 6 Figures, 2\n  Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inverse problems are notoriously difficult to solve because they can have no\nsolutions, multiple solutions, or have solutions that vary significantly in\nresponse to small perturbations in measurements. Bayesian inference, which\nposes an inverse problem as a stochastic inference problem, addresses these\ndifficulties and provides quantitative estimates of the inferred field and the\nassociated uncertainty. However, it is difficult to employ when inferring\nvectors of large dimensions, and/or when prior information is available through\npreviously acquired samples. In this paper, we describe how deep generative\nadversarial networks can be used to represent the prior distribution in\nBayesian inference and overcome these challenges. We apply these ideas to\ninverse problems that are diverse in terms of the governing physical\nprinciples, sources of prior knowledge, type of measurement, and the extent of\navailable information about measurement noise. In each case we apply the\nproposed approach to infer the most likely solution and quantitative estimates\nof uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 22:23:27 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Patel", "Dhruv V", ""], ["Ray", "Deep", ""], ["Oberai", "Assad A", ""]]}, {"id": "2107.02943", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Choiru Za'in, Edwin Lughofer, Eric Pardede, Dwi A.\n  P. Rahayu", "title": "Scalable Teacher Forcing Network for Semi-Supervised Large Scale Data\n  Streams", "comments": "This paper has been accepted for publication in Information Sciences", "journal-ref": "Information Sciences, 2021", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The large-scale data stream problem refers to high-speed information flow\nwhich cannot be processed in scalable manner under a traditional computing\nplatform. This problem also imposes expensive labelling cost making the\ndeployment of fully supervised algorithms unfeasible. On the other hand, the\nproblem of semi-supervised large-scale data streams is little explored in the\nliterature because most works are designed in the traditional single-node\ncomputing environments while also being fully supervised approaches. This paper\noffers Weakly Supervised Scalable Teacher Forcing Network (WeScatterNet) to\ncope with the scarcity of labelled samples and the large-scale data streams\nsimultaneously. WeScatterNet is crafted under distributed computing platform of\nApache Spark with a data-free model fusion strategy for model compression after\nparallel computing stage. It features an open network structure to address the\nglobal and local drift problems while integrating a data augmentation,\nannotation and auto-correction ($DA^3$) method for handling partially labelled\ndata streams. The performance of WeScatterNet is numerically evaluated in the\nsix large-scale data stream problems with only $25\\%$ label proportions. It\nshows highly competitive performance even if compared with fully supervised\nlearners with $100\\%$ label proportions.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 03:37:40 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Za'in", "Choiru", ""], ["Lughofer", "Edwin", ""], ["Pardede", "Eric", ""], ["Rahayu", "Dwi A. P.", ""]]}, {"id": "2107.02951", "submitter": "Anish Sevekari", "authors": "Holden Lee, Chirag Pabbaraju, Anish Sevekari, Andrej Risteski", "title": "Universal Approximation for Log-concave Distributions using\n  Well-conditioned Normalizing Flows", "comments": "40 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are a widely used class of latent-variable generative\nmodels with a tractable likelihood. Affine-coupling (Dinh et al, 2014-16)\nmodels are a particularly common type of normalizing flows, for which the\nJacobian of the latent-to-observable-variable transformation is triangular,\nallowing the likelihood to be computed in linear time. Despite the widespread\nusage of affine couplings, the special structure of the architecture makes\nunderstanding their representational power challenging. The question of\nuniversal approximation was only recently resolved by three parallel papers\n(Huang et al.,2020;Zhang et al.,2020;Koehler et al.,2020) -- who showed\nreasonably regular distributions can be approximated arbitrarily well using\naffine couplings -- albeit with networks with a nearly-singular Jacobian. As\nill-conditioned Jacobians are an obstacle for likelihood-based training, the\nfundamental question remains: which distributions can be approximated using\nwell-conditioned affine coupling flows?\n  In this paper, we show that any log-concave distribution can be approximated\nusing well-conditioned affine-coupling flows. In terms of proof techniques, we\nuncover and leverage deep connections between affine coupling architectures,\nunderdamped Langevin dynamics (a stochastic differential equation often used to\nsample from Gibbs measures) and H\\'enon maps (a structured dynamical system\nthat appears in the study of symplectic diffeomorphisms). Our results also\ninform the practice of training affine couplings: we approximate a padded\nversion of the input distribution with iid Gaussians -- a strategy which\nKoehler et al.(2020) empirically observed to result in better-conditioned\nflows, but had hitherto no theoretical grounding. Our proof can thus be seen as\nproviding theoretical evidence for the benefits of Gaussian padding when\ntraining normalizing flows.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:13:50 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Lee", "Holden", ""], ["Pabbaraju", "Chirag", ""], ["Sevekari", "Anish", ""], ["Risteski", "Andrej", ""]]}, {"id": "2107.02961", "submitter": "Minoru Kuribayashi", "authors": "Minoru Kuribayashi, Tatsuya Yasui, Asad Malik, Nobuo Funabiki", "title": "Immunization of Pruning Attack in DNN Watermarking Using Constant Weight\n  Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To ensure protection of the intellectual property rights of DNN models,\nwatermarking techniques have been investigated to insert side-information into\nthe models without seriously degrading the performance of original task. One of\nthe threats for the DNN watermarking is the pruning attack such that less\nimportant neurons in the model are pruned to make it faster and more compact as\nwell as to remove the watermark. In this study, we investigate a channel coding\napproach to resist the pruning attack. As the channel model is completely\ndifferent from conventional models like digital images, it has been an open\nproblem what kind of encoding method is suitable for DNN watermarking. A novel\nencoding approach by using constant weight codes to immunize the effects of\npruning attacks is presented. To the best of our knowledge, this is the first\nstudy that introduces an encoding technique for DNN watermarking to make it\nrobust against pruning attacks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:50:27 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kuribayashi", "Minoru", ""], ["Yasui", "Tatsuya", ""], ["Malik", "Asad", ""], ["Funabiki", "Nobuo", ""]]}, {"id": "2107.02968", "submitter": "Ali Madani", "authors": "Alvin Chan, Ali Madani, Ben Krause, Nikhil Naik", "title": "Deep Extrapolation for Attribute-Enhanced Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribute extrapolation in sample generation is challenging for deep neural\nnetworks operating beyond the training distribution. We formulate a new task\nfor extrapolation in sequence generation, focusing on natural language and\nproteins, and propose GENhance, a generative framework that enhances attributes\nthrough a learned latent space. Trained on movie reviews and a computed protein\nstability dataset, GENhance can generate strongly-positive text reviews and\nhighly stable protein sequences without being exposed to similar data during\ntraining. We release our benchmark tasks and models to contribute to the study\nof generative modeling extrapolation and data-driven design in biology and\nchemistry.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 01:30:36 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Chan", "Alvin", ""], ["Madani", "Ali", ""], ["Krause", "Ben", ""], ["Naik", "Nikhil", ""]]}, {"id": "2107.02970", "submitter": "Shobhita Sundaram", "authors": "Shobhita Sundaram and Neha Hulkund", "title": "GAN-based Data Augmentation for Chest X-ray Classification", "comments": "Spotlight Talk at KDD 2021 - Applied Data Science for Healthcare\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in computer vision -- particularly in medical applications\n-- is a lack of sufficiently diverse, large sets of training data. These\ndatasets often suffer from severe class imbalance. As a result, networks often\noverfit and are unable to generalize to novel examples. Generative Adversarial\nNetworks (GANs) offer a novel method of synthetic data augmentation. In this\nwork, we evaluate the use of GAN- based data augmentation to artificially\nexpand the CheXpert dataset of chest radiographs. We compare performance to\ntraditional augmentation and find that GAN-based augmentation leads to higher\ndownstream performance for underrepresented classes. Furthermore, we see that\nthis result is pronounced in low data regimens. This suggests that GAN-based\naugmentation a promising area of research to improve network performance when\ndata collection is prohibitively expensive.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 01:36:48 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sundaram", "Shobhita", ""], ["Hulkund", "Neha", ""]]}, {"id": "2107.02974", "submitter": "Iury Cleveston", "authors": "Iury Cleveston, Esther L. Colombini", "title": "RAM-VO: Less is more in Visual Odometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building vehicles capable of operating without human supervision requires the\ndetermination of the agent's pose. Visual Odometry (VO) algorithms estimate the\negomotion using only visual changes from the input images. The most recent VO\nmethods implement deep-learning techniques using convolutional neural networks\n(CNN) extensively, which add a substantial cost when dealing with\nhigh-resolution images. Furthermore, in VO tasks, more input data does not mean\na better prediction; on the contrary, the architecture may filter out useless\ninformation. Therefore, the implementation of computationally efficient and\nlightweight architectures is essential. In this work, we propose the RAM-VO, an\nextension of the Recurrent Attention Model (RAM) for visual odometry tasks.\nRAM-VO improves the visual and temporal representation of information and\nimplements the Proximal Policy Optimization (PPO) algorithm to learn robust\npolicies. The results indicate that RAM-VO can perform regressions with six\ndegrees of freedom from monocular input images using approximately 3 million\nparameters. In addition, experiments on the KITTI dataset demonstrate that\nRAM-VO achieves competitive results using only 5.7% of the available visual\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 01:48:16 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cleveston", "Iury", ""], ["Colombini", "Esther L.", ""]]}, {"id": "2107.02990", "submitter": "Vathy Kamulete", "authors": "Vathy M. Kamulete", "title": "Test for non-negligible adverse shifts", "comments": "14 pages, 4 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical tests for dataset shift are susceptible to false alarms: they are\nsensitive to minor differences where there is in fact adequate sample coverage\nand predictive performance. We propose instead a robust framework for tests of\ndataset shift based on outlier scores, D-SOS for short. D-SOS detects adverse\nshifts and can identify false alarms caused by benign ones. It posits that a\nnew (test) sample is not substantively worse than an old (training) sample, and\nnot that the two are equal. The key idea is to reduce observations to outlier\nscores and compare contamination rates. Beyond comparing distributions, users\ncan define what worse means in terms of predictive performance and other\nrelevant notions. We show how versatile and practical D-SOS is for a wide range\nof real and simulated datasets. Unlike tests of equal distribution and of\ngoodness-of-fit, the D-SOS tests are uniquely tailored to serve as robust\nperformance metrics to monitor model drift and dataset shift.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:07:40 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kamulete", "Vathy M.", ""]]}, {"id": "2107.02991", "submitter": "Jialin Liu Ph.D", "authors": "Ziqi Wang, Jialin Liu, Georgios N. Yannakakis", "title": "Keiki: Towards Realistic Danmaku Generation via Sequential GANs", "comments": "This paper is accepted by the 2021 IEEE Conference on Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search-based procedural content generation methods have recently been\nintroduced for the autonomous creation of bullet hell games. Search-based\nmethods, however, can hardly model patterns of danmakus -- the bullet hell\nshooting entity -- explicitly and the resulting levels often look\nnon-realistic. In this paper, we present a novel bullet hell game platform\nnamed Keiki, which allows the representation of danmakus as a parametric\nsequence which, in turn, can model the sequential behaviours of danmakus. We\nemploy three types of generative adversarial networks (GANs) and test Keiki\nacross three metrics designed to quantify the quality of the generated\ndanmakus. The time-series GAN and periodic spatial GAN show different yet\ncompetitive performance in terms of the evaluation metrics adopted, their\ndeviation from human-designed danmakus, and the diversity of generated\ndanmakus. The preliminary experimental studies presented here showcase that\npotential of time-series GANs for sequential content generation in games.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:11:04 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ziqi", ""], ["Liu", "Jialin", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "2107.03003", "submitter": "Kai Wang", "authors": "Kai Wang, Bryan Wilder, Sze-chuan Suen, Bistra Dilkina, Milind Tambe", "title": "Harnessing Heterogeneity: Learning from Decomposed Feedback in Bayesian\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is significant interest in learning and optimizing a complex system\ncomposed of multiple sub-components, where these components may be agents or\nautonomous sensors. Among the rich literature on this topic, agent-based and\ndomain-specific simulations can capture complex dynamics and subgroup\ninteraction, but optimizing over such simulations can be computationally and\nalgorithmically challenging. Bayesian approaches, such as Gaussian processes\n(GPs), can be used to learn a computationally tractable approximation to the\nunderlying dynamics but typically neglect the detailed information about\nsubgroups in the complicated system. We attempt to find the best of both worlds\nby proposing the idea of decomposed feedback, which captures group-based\nheterogeneity and dynamics. We introduce a novel decomposed GP regression to\nincorporate the subgroup decomposed feedback. Our modified regression has\nprovably lower variance -- and thus a more accurate posterior -- compared to\nprevious approaches; it also allows us to introduce a decomposed GP-UCB\noptimization algorithm that leverages subgroup feedback. The Bayesian nature of\nour method makes the optimization algorithm trackable with a theoretical\nguarantee on convergence and no-regret property. To demonstrate the wide\napplicability of this work, we execute our algorithm on two disparate social\nproblems: infectious disease control in a heterogeneous population and\nallocation of distributed weather sensors. Experimental results show that our\nnew method provides significant improvement compared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:57:22 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Kai", ""], ["Wilder", "Bryan", ""], ["Suen", "Sze-chuan", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "2107.03006", "submitter": "Jacob Austin", "authors": "Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow and Rianne\n  van den Berg", "title": "Structured Denoising Diffusion Models in Discrete State-Spaces", "comments": "10 pages plus references and appendices. First two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown\nimpressive results on image and waveform generation in continuous state spaces.\nHere, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),\ndiffusion-like generative models for discrete data that generalize the\nmultinomial diffusion model of Hoogeboom et al. 2021, by going beyond\ncorruption processes with uniform transition probabilities. This includes\ncorruption with transition matrices that mimic Gaussian kernels in continuous\nspace, matrices based on nearest neighbors in embedding space, and matrices\nthat introduce absorbing states. The third allows us to draw a connection\nbetween diffusion models and autoregressive and mask-based generative models.\nWe show that the choice of transition matrix is an important design decision\nthat leads to improved results in image and text domains. We also introduce a\nnew loss function that combines the variational lower bound with an auxiliary\ncross entropy loss. For text, this model class achieves strong results on\ncharacter-level text generation while scaling to large vocabularies on LM1B. On\nthe image dataset CIFAR-10, our models approach the sample quality and exceed\nthe log-likelihood of the continuous-space DDPM model.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 04:11:00 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:09:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Austin", "Jacob", ""], ["Johnson", "Daniel D.", ""], ["Ho", "Jonathan", ""], ["Tarlow", "Daniel", ""], ["Berg", "Rianne van den", ""]]}, {"id": "2107.03015", "submitter": "Juan Jose Garau-Luis", "authors": "Juan Jose Garau-Luis and Edward Crawley and Bruce Cameron", "title": "Evaluating the progress of Deep Reinforcement Learning in the real\n  world: aligning domain-agnostic and domain-specific research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep Reinforcement Learning (DRL) is considered a potential framework to\nimprove many real-world autonomous systems; it has attracted the attention of\nmultiple and diverse fields. Nevertheless, the successful deployment in the\nreal world is a test most of DRL models still need to pass. In this work we\nfocus on this issue by reviewing and evaluating the research efforts from both\ndomain-agnostic and domain-specific communities. On one hand, we offer a\ncomprehensive summary of DRL challenges and summarize the different proposals\nto mitigate them; this helps identifying five gaps of domain-agnostic research.\nOn the other hand, from the domain-specific perspective, we discuss different\nsuccess stories and argue why other models might fail to be deployed. Finally,\nwe take up on ways to move forward accounting for both perspectives.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 04:45:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Garau-Luis", "Juan Jose", ""], ["Crawley", "Edward", ""], ["Cameron", "Bruce", ""]]}, {"id": "2107.03018", "submitter": "Shouta Sugahara", "authors": "Shouta Sugahara and Maomi Ueno", "title": "Exact Learning Augmented Naive Bayes Classifier", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier studies have shown that classification accuracies of Bayesian\nnetworks (BNs) obtained by maximizing the conditional log likelihood (CLL) of a\nclass variable, given the feature variables, were higher than those obtained by\nmaximizing the marginal likelihood (ML). However, differences between the\nperformances of the two scores in the earlier studies may be attributed to the\nfact that they used approximate learning algorithms, not exact ones. This paper\ncompares the classification accuracies of BNs with approximate learning using\nCLL to those with exact learning using ML. The results demonstrate that the\nclassification accuracies of BNs obtained by maximizing the ML are higher than\nthose obtained by maximizing the CLL for large data. However, the results also\ndemonstrate that the classification accuracies of exact learning BNs using the\nML are much worse than those of other methods when the sample size is small and\nthe class variable has numerous parents. To resolve the problem, we propose an\nexact learning augmented naive Bayes classifier (ANB), which ensures a class\nvariable with no parents. The proposed method is guaranteed to asymptotically\nestimate the identical class posterior to that of the exactly learned BN.\nComparison experiments demonstrated the superior performance of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:03:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sugahara", "Shouta", ""], ["Ueno", "Maomi", ""]]}, {"id": "2107.03019", "submitter": "Xin Zhou", "authors": "Xin Zhou, Aixin Sun, Yong Liu, Jie Zhang, Chunyan Miao", "title": "SelfCF: A Simple Framework for Self-supervised Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative filtering (CF) is widely used to learn an informative latent\nrepresentation of a user or item from observed interactions. Existing CF-based\nmethods commonly adopt negative sampling to discriminate different items. That\nis, observed user-item pairs are treated as positive instances; unobserved\npairs are considered as negative instances and are sampled under a defined\ndistribution for training. Training with negative sampling on large datasets is\ncomputationally expensive. Further, negative items should be carefully sampled\nunder the defined distribution, in order to avoid selecting an observed\npositive item in the training dataset. Unavoidably, some negative items sampled\nfrom the training dataset could be positive in the test set. Recently,\nself-supervised learning (SSL) has emerged as a powerful tool to learn a model\nwithout negative samples. In this paper, we propose a self-supervised\ncollaborative filtering framework (SelfCF), that is specially designed for\nrecommender scenario with implicit feedback. The main idea of SelfCF is to\naugment the output embeddings generated by backbone networks, because it is\ninfeasible to augment raw input of user/item ids. We propose and study three\noutput perturbation techniques that can be applied to different types of\nbackbone networks including both traditional CF models and graph-based models.\nBy encapsulating two popular recommendation models into the framework, our\nexperiments on three datasets show that the best performance of our framework\nis comparable or better than the supervised counterpart. We also show that\nSelfCF can boost up the performance by up to 8.93\\% on average, compared with\nanother self-supervised framework as the baseline. Source codes are available\nat: https://github.com/enoche/SelfCF.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:21:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhou", "Xin", ""], ["Sun", "Aixin", ""], ["Liu", "Yong", ""], ["Zhang", "Jie", ""], ["Miao", "Chunyan", ""]]}, {"id": "2107.03022", "submitter": "Abhinav Aggarwal", "authors": "Abhinav Aggarwal, Shiva Prasad Kasiviswanathan, Zekun Xu, Oluwaseyi\n  Feyisetan, Nathanael Teissier", "title": "On Codomain Separability and Label Inference from (Noisy) Loss Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning classifiers rely on loss functions for performance\nevaluation, often on a private (hidden) dataset. Label inference was recently\nintroduced as the problem of reconstructing the ground truth labels of this\nprivate dataset from just the (possibly perturbed) loss function values\nevaluated at chosen prediction vectors, without any other access to the hidden\ndataset. Existing results have demonstrated this inference is possible on\nspecific loss functions like the cross-entropy loss. In this paper, we\nintroduce the notion of codomain separability to formally study the necessary\nand sufficient conditions under which label inference is possible from any\n(noisy) loss function values. Using this notion, we show that for many commonly\nused loss functions, including multiclass cross-entropy with common activation\nfunctions and some Bregman divergence-based losses, it is possible to design\nlabel inference attacks for arbitrary noise levels. We demonstrate that these\nattacks can also be carried out through actual neural network models, and\nargue, both formally and empirically, the role of finite precision arithmetic\nin this setting.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:29:53 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Aggarwal", "Abhinav", ""], ["Kasiviswanathan", "Shiva Prasad", ""], ["Xu", "Zekun", ""], ["Feyisetan", "Oluwaseyi", ""], ["Teissier", "Nathanael", ""]]}, {"id": "2107.03049", "submitter": "Antoine de Mathelin", "authors": "Antoine de Mathelin, Fran\\c{c}ois Deheeger, Guillaume Richard,\n  Mathilde Mougeot, Nicolas Vayatis", "title": "ADAPT : Awesome Domain Adaptation Python Toolbox", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ADAPT is an open-source python library providing the implementation of\nseveral domain adaptation methods. The library is suited for scikit-learn\nestimator object (object which implement fit and predict methods) and\ntensorflow models. Most of the implemented methods are developed in an\nestimator agnostic fashion, offering various possibilities adapted to multiple\nusage. The library offers three modules corresponding to the three principal\nstrategies of domain adaptation: (i) feature-based containing methods\nperforming feature transformation; (ii) instance-based with the implementation\nof reweighting techniques and (iii) parameter-based proposing methods to adapt\npre-trained models to novel observations. A full documentation is proposed\nonline https://adapt-python.github.io/adapt/ with gallery of examples. Besides,\nthe library presents an high test coverage.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 07:20:21 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["de Mathelin", "Antoine", ""], ["Deheeger", "Fran\u00e7ois", ""], ["Richard", "Guillaume", ""], ["Mougeot", "Mathilde", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "2107.03050", "submitter": "Nayyer Aafaq Mr.", "authors": "Nayyer Aafaq, Naveed Akhtar, Wei Liu, Mubarak Shah and Ajmal Mian", "title": "Controlled Caption Generation for Images Through Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep learning is found to be vulnerable to adversarial examples. However, its\nadversarial susceptibility in image caption generation is under-explored. We\nstudy adversarial examples for vision and language models, which typically\nadopt an encoder-decoder framework consisting of two major components: a\nConvolutional Neural Network (i.e., CNN) for image feature extraction and a\nRecurrent Neural Network (RNN) for caption generation. In particular, we\ninvestigate attacks on the visual encoder's hidden layer that is fed to the\nsubsequent recurrent network. The existing methods either attack the\nclassification layer of the visual encoder or they back-propagate the gradients\nfrom the language model. In contrast, we propose a GAN-based algorithm for\ncrafting adversarial examples for neural image captioning that mimics the\ninternal representation of the CNN such that the resulting deep features of the\ninput image enable a controlled incorrect caption generation through the\nrecurrent network. Our contribution provides new insights for understanding\nadversarial attacks on vision systems with language component. The proposed\nmethod employs two strategies for a comprehensive evaluation. The first\nexamines if a neural image captioning system can be misled to output targeted\nimage captions. The second analyzes the possibility of keywords into the\npredicted captions. Experiments show that our algorithm can craft effective\nadversarial images based on the CNN hidden layers to fool captioning framework.\nMoreover, we discover the proposed attack to be highly transferable. Our work\nleads to new robustness implications for neural image captioning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 07:22:41 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Aafaq", "Nayyer", ""], ["Akhtar", "Naveed", ""], ["Liu", "Wei", ""], ["Shah", "Mubarak", ""], ["Mian", "Ajmal", ""]]}, {"id": "2107.03066", "submitter": "Mamikon Gulian", "authors": "Nat Trask, Mamikon Gulian, Andy Huang, Kookjin Lee", "title": "Probabilistic partition of unity networks: clustering based deep\n  approximation", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partition of unity networks (POU-Nets) have been shown capable of realizing\nalgebraic convergence rates for regression and solution of PDEs, but require\nempirical tuning of training parameters. We enrich POU-Nets with a Gaussian\nnoise model to obtain a probabilistic generalization amenable to gradient-based\nminimization of a maximum likelihood loss. The resulting architecture provides\nspatial representations of both noiseless and noisy data as Gaussian mixtures\nwith closed form expressions for variance which provides an estimator of local\nerror. The training process yields remarkably sharp partitions of input space\nbased upon correlation of function values. This classification of training\npoints is amenable to a hierarchical refinement strategy that significantly\nimproves the localization of the regression, allowing for higher-order\npolynomial approximation to be utilized. The framework scales more favorably to\nlarge data sets as compared to Gaussian process regression and allows for\nspatially varying uncertainty, leveraging the expressive power of deep neural\nnetworks while bypassing expensive training associated with other probabilistic\ndeep learning methods. Compared to standard deep neural networks, the framework\ndemonstrates hp-convergence without the use of regularizers to tune the\nlocalization of partitions. We provide benchmarks quantifying performance in\nhigh/low-dimensions, demonstrating that convergence rates depend only on the\nlatent dimension of data within high-dimensional space. Finally, we introduce a\nnew open-source data set of PDE-based simulations of a semiconductor device and\nperform unsupervised extraction of a physically interpretable reduced-order\nbasis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:02:00 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Trask", "Nat", ""], ["Gulian", "Mamikon", ""], ["Huang", "Andy", ""], ["Lee", "Kookjin", ""]]}, {"id": "2107.03067", "submitter": "Sihai Guan", "authors": "Sihai Guan, Qing Cheng, Yong Zhao", "title": "Distributed adaptive algorithm based on the asymmetric cost of error\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a family of novel diffusion adaptive estimation algorithm is\nproposed from the asymmetric cost function perspective by combining diffusion\nstrategy and the linear-linear cost (LLC), quadratic-quadratic cost (QQC), and\nlinear-exponential cost (LEC), at all distributed network nodes, and named\ndiffusion LLCLMS (DLLCLMS), diffusion QQCLMS (DQQCLMS), and diffusion LECLMS\n(DLECLMS), respectively. Then the stability of mean estimation error and\ncomputational complexity of those three diffusion algorithms are analyzed\ntheoretically. Finally, several experiment simulation results are designed to\nverify the superiority of those three proposed diffusion algorithms.\nExperimental simulation results show that DLLCLMS, DQQCLMS, and DLECLMS\nalgorithms are more robust to the input signal and impulsive noise than the\nDSELMS, DRVSSLMS, and DLLAD algorithms. In brief, theoretical analysis and\nexperiment results show that those proposed DLLCLMS, DQQCLMS, and DLECLMS\nalgorithms have superior performance when estimating the unknown linear system\nunder the changeable impulsive noise environments and different types of input\nsignals.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:04:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Guan", "Sihai", ""], ["Cheng", "Qing", ""], ["Zhao", "Yong", ""]]}, {"id": "2107.03080", "submitter": "Quan Duong", "authors": "Quan Duong and Dang Nguyen and Quoc Nguyen", "title": "Hub and Spoke Logistics Network Design for Urban Region with\n  Clustering-Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study aims to propose effective modeling and approach for designing a\nlogistics network in the urban area in order to offer an efficient flow\ndistribution network as a competitive strategy in the logistics industry where\ndemand is sensitive to both price and time. A multi-stage approach is\nintroduced to select the number of hubs and allocate spokes to the hubs for\nflow distribution and hubs' location detection. Specifically, a fuzzy\nclustering model with the objective function is to minimize the approximate\ntransportation cost is employed, in the next phase is to focus on balancing the\ndemand capacity among the hubs with the help of domain experts, afterward, the\nfacility location vehicle routing problems within the network is introduced. To\ndemonstrate the approach's advantages, an experiment was performed on the\ndesigned network and its actual transportation cost for the real operational\ndata in which specific to the Ho Chi Minh city infrastructure conditions.\nAdditionally, we show the flexibility of the designed network in the flow\ndistribution and its computational experiments to develop the managerial\ninsights which contribute to the network design decision-making process.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:56:39 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Duong", "Quan", ""], ["Nguyen", "Dang", ""], ["Nguyen", "Quoc", ""]]}, {"id": "2107.03084", "submitter": "Nunzio Alexandro Letizia Mr", "authors": "Nunzio A. Letizia and Andrea M. Tonello", "title": "Discriminative Mutual Information Estimators for Channel Capacity\n  Learning", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Channel capacity plays a crucial role in the development of modern\ncommunication systems as it represents the maximum rate at which information\ncan be reliably transmitted over a communication channel. Nevertheless, for the\nmajority of channels, finding a closed-form capacity expression remains an open\nchallenge. This is because it requires to carry out two formidable tasks a) the\ncomputation of the mutual information between the channel input and output, and\nb) its maximization with respect to the signal distribution at the channel\ninput. In this paper, we address both tasks. Inspired by implicit generative\nmodels, we propose a novel cooperative framework to automatically learn the\nchannel capacity, for any type of memory-less channel. In particular, we\nfirstly develop a new methodology to estimate the mutual information directly\nfrom a discriminator typically deployed to train adversarial networks, referred\nto as discriminative mutual information estimator (DIME). Secondly, we include\nthe discriminator in a cooperative channel capacity learning framework,\nreferred to as CORTICAL, where a discriminator learns to distinguish between\ndependent and independent channel input-output samples while a generator learns\nto produce the optimal channel input distribution for which the discriminator\nexhibits the best performance. Lastly, we prove that a particular choice of the\ncooperative value function solves the channel capacity estimation problem.\nSimulation results demonstrate that the proposed method offers high accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 09:03:40 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Letizia", "Nunzio A.", ""], ["Tonello", "Andrea M.", ""]]}, {"id": "2107.03090", "submitter": "Bhavya Kalra", "authors": "Bhavya Kalra, Kulin Shah and Naresh Manwani", "title": "RISAN: Robust Instance Specific Abstention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose deep architectures for learning instance specific\nabstain (reject option) binary classifiers. The proposed approach uses double\nsigmoid loss function as described by Kulin Shah and Naresh Manwani in (\"Online\nActive Learning of Reject Option Classifiers\", AAAI, 2020), as a performance\nmeasure. We show that the double sigmoid loss is classification calibrated. We\nalso show that the excess risk of 0-d-1 loss is upper bounded by the excess\nrisk of double sigmoid loss. We derive the generalization error bounds for the\nproposed architecture for reject option classifiers. To show the effectiveness\nof the proposed approach, we experiment with several real world datasets. We\nobserve that the proposed approach not only performs comparable to the\nstate-of-the-art approaches, it is also robust against label noise. We also\nprovide visualizations to observe the important features learned by the network\ncorresponding to the abstaining decision.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 09:14:54 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kalra", "Bhavya", ""], ["Shah", "Kulin", ""], ["Manwani", "Naresh", ""]]}, {"id": "2107.03144", "submitter": "Parnian Kassraie", "authors": "Parnian Kassraie, Andreas Krause", "title": "Neural Contextual Bandits without Regret", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Contextual bandits are a rich model for sequential decision making given side\ninformation, with important applications, e.g., in recommender systems. We\npropose novel algorithms for contextual bandits harnessing neural networks to\napproximate the unknown reward function. We resolve the open problem of proving\nsublinear regret bounds in this setting for general context sequences,\nconsidering both fully-connected and convolutional networks. To this end, we\nfirst analyze NTK-UCB, a kernelized bandit optimization algorithm employing the\nNeural Tangent Kernel (NTK), and bound its regret in terms of the NTK maximum\ninformation gain $\\gamma_T$, a complexity parameter capturing the difficulty of\nlearning. Our bounds on $\\gamma_T$ for the NTK may be of independent interest.\nWe then introduce our neural network based algorithm NN-UCB, and show that its\nregret closely tracks that of NTK-UCB. Under broad non-parametric assumptions\nabout the reward function, our approach converges to the optimal policy at a\n$\\tilde{\\mathcal{O}}(T^{-1/2d})$ rate, where $d$ is the dimension of the\ncontext.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 11:11:34 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kassraie", "Parnian", ""], ["Krause", "Andreas", ""]]}, {"id": "2107.03145", "submitter": "Rao Muhammad Umer", "authors": "Rao Muhammad Umer, Asad Munir, Christian Micheloni", "title": "A Deep Residual Star Generative Adversarial Network for multi-domain\n  Image Super-Resolution", "comments": "5 pages, 6th International Conference on Smart and Sustainable\n  Technologies 2021. arXiv admin note: text overlap with arXiv:2009.03693,\n  arXiv:2005.00953", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, most of state-of-the-art single image super-resolution (SISR)\nmethods have attained impressive performance by using deep convolutional neural\nnetworks (DCNNs). The existing SR methods have limited performance due to a\nfixed degradation settings, i.e. usually a bicubic downscaling of\nlow-resolution (LR) image. However, in real-world settings, the LR degradation\nprocess is unknown which can be bicubic LR, bilinear LR, nearest-neighbor LR,\nor real LR. Therefore, most SR methods are ineffective and inefficient in\nhandling more than one degradation settings within a single network. To handle\nthe multiple degradation, i.e. refers to multi-domain image super-resolution,\nwe propose a deep Super-Resolution Residual StarGAN (SR2*GAN), a novel and\nscalable approach that super-resolves the LR images for the multiple LR domains\nusing only a single model. The proposed scheme is trained in a StarGAN like\nnetwork topology with a single generator and discriminator networks. We\ndemonstrate the effectiveness of our proposed approach in quantitative and\nqualitative experiments compared to other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 11:15:17 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Umer", "Rao Muhammad", ""], ["Munir", "Asad", ""], ["Micheloni", "Christian", ""]]}, {"id": "2107.03176", "submitter": "Ernie Chang", "authors": "Ernie Chang, Xiaoyu Shen, Hui-Syuan Yeh, Vera Demberg", "title": "On Training Instance Selection for Few-Shot Neural Text Generation", "comments": "Accepted at ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large-scale pretrained language models have led to dramatic improvements in\ntext generation. Impressive performance can be achieved by finetuning only on a\nsmall number of instances (few-shot setting). Nonetheless, almost all previous\nwork simply applies random sampling to select the few-shot training instances.\nLittle to no attention has been paid to the selection strategies and how they\nwould affect model performance. In this work, we present a study on training\ninstance selection in few-shot neural text generation. The selection decision\nis made based only on the unlabeled data so as to identify the most worthwhile\ndata points that should be annotated under some budget of labeling cost. Based\non the intuition that the few-shot training instances should be diverse and\nrepresentative of the entire data distribution, we propose a simple selection\nstrategy with K-means clustering. We show that even with the naive\nclustering-based approach, the generation models consistently outperform random\nsampling on three text generation tasks: data-to-text generation, document\nsummarization and question generation. We hope that this work will call for\nmore attention on this largely unexplored area.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:16:16 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Chang", "Ernie", ""], ["Shen", "Xiaoyu", ""], ["Yeh", "Hui-Syuan", ""], ["Demberg", "Vera", ""]]}, {"id": "2107.03182", "submitter": "Mahdi Maktabdar Oghaz", "authors": "Emily Waters, Mahdi Maktabdar Oghaz, Lakshmi Babu Saheer", "title": "Urban Tree Species Classification Using Aerial Imagery", "comments": "International Conference on Machine Learning (ICML 2021), Workshop on\n  Tackling Climate Change with Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Urban trees help regulate temperature, reduce energy consumption, improve\nurban air quality, reduce wind speeds, and mitigating the urban heat island\neffect. Urban trees also play a key role in climate change mitigation and\nglobal warming by capturing and storing atmospheric carbon-dioxide which is the\nlargest contributor to greenhouse gases. Automated tree detection and species\nclassification using aerial imagery can be a powerful tool for sustainable\nforest and urban tree management. Hence, This study first offers a pipeline for\ngenerating labelled dataset of urban trees using Google Map's aerial images and\nthen investigates how state of the art deep Convolutional Neural Network models\nsuch as VGG and ResNet handle the classification problem of urban tree aerial\nimages under different parameters. Experimental results show our best model\nachieves an average accuracy of 60% over 6 tree species.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:30:22 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Waters", "Emily", ""], ["Oghaz", "Mahdi Maktabdar", ""], ["Saheer", "Lakshmi Babu", ""]]}, {"id": "2107.03183", "submitter": "Kaspar Thommen", "authors": "Kaspar Thommen", "title": "A Closed-Form Approximation to the Conjugate Prior of the Dirichlet and\n  Beta Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the conjugate prior of the Dirichlet and beta distributions and\nexplore it with numerical examples to gain an intuitive understanding of the\ndistribution itself, its hyperparameters, and conditions concerning its\nconvergence. Due to the prior's intractability, we proceed to define and\nanalyze a closed-form approximation. Finally, we provide an algorithm\nimplementing this approximation that enables fully tractable Bayesian conjugate\ntreatment of Dirichlet and beta likelihoods without the need for Monte Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:32:29 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Thommen", "Kaspar", ""]]}, {"id": "2107.03187", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Sandeep Kumar, Ashish Kumar Pandey", "title": "Intensity Prediction of Tropical Cyclones using Long Short-Term Memory\n  Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tropical cyclones can be of varied intensity and cause a huge loss of lives\nand property if the intensity is high enough. Therefore, the prediction of the\nintensity of tropical cyclones advance in time is of utmost importance. We\npropose a novel stacked bidirectional long short-term memory network (BiLSTM)\nbased model architecture to predict the intensity of a tropical cyclone in\nterms of Maximum surface sustained wind speed (MSWS). The proposed model can\npredict MSWS well advance in time (up to 72 h) with very high accuracy. We have\napplied the model on tropical cyclones in the North Indian Ocean from 1982 to\n2018 and checked its performance on two recent tropical cyclones, namely, Fani\nand Vayu. The model predicts MSWS (in knots) for the next 3, 12, 24, 36, 48,\n60, and 72 hours with a mean absolute error of 1.52, 3.66, 5.88, 7.42, 8.96,\n10.15, and 11.92, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:46:50 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Biswas", "Koushik", ""], ["Kumar", "Sandeep", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2107.03190", "submitter": "Juan Correa", "authors": "Juan D Correa, Sanghack Lee, Elias Bareinboim", "title": "Nested Counterfactual Identification from Arbitrary Surrogate\n  Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Ladder of Causation describes three qualitatively different types of\nactivities an agent may be interested in engaging in, namely, seeing\n(observational), doing (interventional), and imagining (counterfactual) (Pearl\nand Mackenzie, 2018). The inferential challenge imposed by the causal hierarchy\nis that data is collected by an agent observing or intervening in a system\n(layers 1 and 2), while its goal may be to understand what would have happened\nhad it taken a different course of action, contrary to what factually ended up\nhappening (layer 3). While there exists a solid understanding of the conditions\nunder which cross-layer inferences are allowed from observations to\ninterventions, the results are somewhat scarcer when targeting counterfactual\nquantities. In this paper, we study the identification of nested\ncounterfactuals from an arbitrary combination of observations and experiments.\nSpecifically, building on a more explicit definition of nested counterfactuals,\nwe prove the counterfactual unnesting theorem (CUT), which allows one to map\narbitrary nested counterfactuals to unnested ones. For instance, applications\nin mediation and fairness analysis usually evoke notions of direct, indirect,\nand spurious effects, which naturally require nesting. Second, we introduce a\nsufficient and necessary graphical condition for counterfactual identification\nfrom an arbitrary combination of observational and experimental distributions.\nLastly, we develop an efficient and complete algorithm for identifying nested\ncounterfactuals; failure of the algorithm returning an expression for a query\nimplies it is not identifiable.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:51:04 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Correa", "Juan D", ""], ["Lee", "Sanghack", ""], ["Bareinboim", "Elias", ""]]}, {"id": "2107.03207", "submitter": "Yixuan Zhang", "authors": "Yixuan Zhang, Feng Zhou, Zhidong Li, Yang Wang, Fang Chen", "title": "Bias-Tolerant Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The label bias and selection bias are acknowledged as two reasons in data\nthat will hinder the fairness of machine-learning outcomes. The label bias\noccurs when the labeling decision is disturbed by sensitive features, while the\nselection bias occurs when subjective bias exists during the data sampling.\nEven worse, models trained on such data can inherit or even intensify the\ndiscrimination. Most algorithmic fairness approaches perform an empirical risk\nminimization with predefined fairness constraints, which tends to trade-off\naccuracy for fairness. However, such methods would achieve the desired fairness\nlevel with the sacrifice of the benefits (receive positive outcomes) for\nindividuals affected by the bias. Therefore, we propose a\nBias-TolerantFAirRegularizedLoss (B-FARL), which tries to regain the benefits\nusing data affected by label bias and selection bias. B-FARL takes the biased\ndata as input, calls a model that approximates the one trained with fair but\nlatent data, and thus prevents discrimination without constraints required. In\naddition, we show the effective components by decomposing B-FARL, and we\nutilize the meta-learning framework for the B-FARL optimization. The\nexperimental results on real-world datasets show that our method is empirically\neffective in improving fairness towards the direction of true but latent\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:31:38 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhang", "Yixuan", ""], ["Zhou", "Feng", ""], ["Li", "Zhidong", ""], ["Wang", "Yang", ""], ["Chen", "Fang", ""]]}, {"id": "2107.03217", "submitter": "Songhao Wang", "authors": "Qun Meng, Songhao Wang, Szu Hui Ng", "title": "Combined Global and Local Search for Optimization with Gaussian Process\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Gaussian process (GP) model based optimization is widely applied in\nsimulation and machine learning. In general, it first estimates a GP model\nbased on a few observations from the true response and then employs this model\nto guide the search, aiming to quickly locate the global optimum. Despite its\nsuccessful applications, it has several limitations that may hinder its broader\nusage. First, building an accurate GP model can be difficult and\ncomputationally expensive, especially when the response function is multi-modal\nor varies significantly over the design space. Second, even with an appropriate\nmodel, the search process can be trapped in suboptimal regions before moving to\nthe global optimum due to the excessive effort spent around the current best\nsolution. In this work, we adopt the Additive Global and Local GP (AGLGP) model\nin the optimization framework. The model is rooted in the inducing-points-based\nGP sparse approximations and is combined with independent local models in\ndifferent regions. With these properties, the AGLGP model is suitable for\nmulti-modal responses with relatively large data sizes. Based on this AGLGP\nmodel, we propose a Combined Global and Local search for Optimization (CGLO)\nalgorithm. It first divides the whole design space into disjoint local regions\nand identifies a promising region with the global model. Next, a local model in\nthe selected region is fit to guide detailed search within this region. The\nalgorithm then switches back to the global step when a good local solution is\nfound. The global and local natures of CGLO enable it to enjoy the benefits of\nboth global and local search to efficiently locate the global optimum.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:40:37 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Meng", "Qun", ""], ["Wang", "Songhao", ""], ["Ng", "Szu Hui", ""]]}, {"id": "2107.03220", "submitter": "Yanqiao Zhu", "authors": "Yanqiao Zhu, Hejie Cui, Lifang He, Lichao Sun, Carl Yang", "title": "Joint Embedding of Structural and Functional Brain Networks with Graph\n  Neural Networks for Mental Illness Diagnosis", "comments": "Accepted to ICML 2021 Workshop on Computational Approaches to Mental\n  Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG physics.med-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal brain networks characterize complex connectivities among different\nbrain regions from both structural and functional aspects and provide a new\nmeans for mental disease analysis. Recently, Graph Neural Networks (GNNs) have\nbecome a de facto model for analyzing graph-structured data. However, how to\nemploy GNNs to extract effective representations from brain networks in\nmultiple modalities remains rarely explored. Moreover, as brain networks\nprovide no initial node features, how to design informative node attributes and\nleverage edge weights for GNNs to learn is left unsolved. To this end, we\ndevelop a novel multiview GNN for multimodal brain networks. In particular, we\nregard each modality as a view for brain networks and employ contrastive\nlearning for multimodal fusion. Then, we propose a GNN model which takes\nadvantage of the message passing scheme by propagating messages based on degree\nstatistics and brain region connectivities. Extensive experiments on two\nreal-world disease datasets (HIV and Bipolar) demonstrate the effectiveness of\nour proposed method over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:49:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhu", "Yanqiao", ""], ["Cui", "Hejie", ""], ["He", "Lifang", ""], ["Sun", "Lichao", ""], ["Yang", "Carl", ""]]}, {"id": "2107.03226", "submitter": "Andres Carvallo", "authors": "Iv\\'an Cantador, Andr\\'es Carvallo, Fernando Diez, Denis Parra", "title": "Graphing else matters: exploiting aspect opinions and ratings in\n  explainable graph-based recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of neural network embeddings has entailed a renewed interest in\nusing knowledge graphs for a wide variety of machine learning and information\nretrieval tasks. In particular, current recommendation methods based on graph\nembeddings have shown state-of-the-art performance. These methods commonly\nencode latent rating patterns and content features. Different from previous\nwork, in this paper, we propose to exploit embeddings extracted from graphs\nthat combine information from ratings and aspect-based opinions expressed in\ntextual reviews. We then adapt and evaluate state-of-the-art graph embedding\ntechniques over graphs generated from Amazon and Yelp reviews on six domains,\noutperforming baseline recommenders. Our approach has the advantage of\nproviding explanations which leverage aspect-based opinions given by users\nabout recommended items. Furthermore, we also provide examples of the\napplicability of recommendations utilizing aspect opinions as explanations in a\nvisualization dashboard, which allows obtaining information about the most and\nleast liked aspects of similar users obtained from the embeddings of an input\ngraph.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:57:28 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cantador", "Iv\u00e1n", ""], ["Carvallo", "Andr\u00e9s", ""], ["Diez", "Fernando", ""], ["Parra", "Denis", ""]]}, {"id": "2107.03227", "submitter": "Deep Patel", "authors": "Deep Patel, Erin Gao, Anirudh Koul, Siddha Ganju, Meher Anand Kasam", "title": "Scalable Data Balancing for Unlabeled Satellite Imagery", "comments": "Accepted to COSPAR 2021 Workshop on Machine Learning for Space\n  Sciences. 5 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data imbalance is a ubiquitous problem in machine learning. In large scale\ncollected and annotated datasets, data imbalance is either mitigated manually\nby undersampling frequent classes and oversampling rare classes, or planned for\nwith imputation and augmentation techniques. In both cases balancing data\nrequires labels. In other words, only annotated data can be balanced.\nCollecting fully annotated datasets is challenging, especially for large scale\nsatellite systems such as the unlabeled NASA's 35 PB Earth Imagery dataset.\nAlthough the NASA Earth Imagery dataset is unlabeled, there are implicit\nproperties of the data source that we can rely on to hypothesize about its\nimbalance, such as distribution of land and water in the case of the Earth's\nimagery. We present a new iterative method to balance unlabeled data. Our\nmethod utilizes image embeddings as a proxy for image labels that can be used\nto balance data, and ultimately when trained increases overall accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:58:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Patel", "Deep", ""], ["Gao", "Erin", ""], ["Koul", "Anirudh", ""], ["Ganju", "Siddha", ""], ["Kasam", "Meher Anand", ""]]}, {"id": "2107.03230", "submitter": "Luka Grb\\v{c}i\\'c", "authors": "Luka Grb\\v{c}i\\'c, Sini\\v{s}a Dru\\v{z}eta, Goran Mau\\v{s}a, Tomislav\n  Lipi\\'c, Darija Vuki\\'c Lu\\v{s}i\\'c, Marta Alvir, Ivana Lu\\v{c}in, Ante\n  Sikirica, Davor Davidovi\\'c, Vanja Trava\\v{s}, Daniela Kalafatovi\\'c,\n  Kristina Pikelj, Hana Fajkovi\\'c, Toni Holjevi\\'c and Lado Kranj\\v{c}evi\\'c", "title": "Coastal water quality prediction based on machine learning with feature\n  interpretation and spatio-temporal analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Coastal water quality management is a public health concern, as poor coastal\nwater quality can harbor pathogens that are dangerous to human health.\nTourism-oriented countries need to actively monitor the condition of coastal\nwater at tourist popular sites during the summer season. In this study, routine\nmonitoring data of $Escherichia\\ Coli$ and enterococci across 15 public beaches\nin the city of Rijeka, Croatia, were used to build machine learning models for\npredicting their levels based on environmental parameters as well as to\ninvestigate their relationships with environmental stressors. Gradient Boosting\n(Catboost, Xgboost), Random Forests, Support Vector Regression and Artificial\nNeural Networks were trained with measurements from all sampling sites and used\nto predict $E.\\ Coli$ and enterococci values based on environmental features.\nThe evaluation of stability and generalizability with 10-fold cross validation\nanalysis of the machine learning models, showed that the Catboost algorithm\nperformed best with R$^2$ values of 0.71 and 0.68 for predicting $E.\\ Coli$ and\nenterococci, respectively, compared to other evaluated ML algorithms including\nXgboost, Random Forests, Support Vector Regression and Artificial Neural\nNetworks. We also use the SHapley Additive exPlanations technique to identify\nand interpret which features have the most predictive power. The results show\nthat site salinity measured is the most important feature for forecasting both\n$E.\\ Coli$ and enterococci levels. Finally, the spatial and temporal accuracy\nof both ML models were examined at sites with the lowest coastal water quality.\nThe spatial $E. Coli$ and enterococci models achieved strong R$^2$ values of\n0.85 and 0.83, while the temporal models achieved R$^2$ values of 0.74 and\n0.67. The temporal model also achieved moderate R$^2$ values of 0.44 and 0.46\nat a site with high coastal water quality.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:00:14 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 07:09:03 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Grb\u010di\u0107", "Luka", ""], ["Dru\u017eeta", "Sini\u0161a", ""], ["Mau\u0161a", "Goran", ""], ["Lipi\u0107", "Tomislav", ""], ["Lu\u0161i\u0107", "Darija Vuki\u0107", ""], ["Alvir", "Marta", ""], ["Lu\u010din", "Ivana", ""], ["Sikirica", "Ante", ""], ["Davidovi\u0107", "Davor", ""], ["Trava\u0161", "Vanja", ""], ["Kalafatovi\u0107", "Daniela", ""], ["Pikelj", "Kristina", ""], ["Fajkovi\u0107", "Hana", ""], ["Holjevi\u0107", "Toni", ""], ["Kranj\u010devi\u0107", "Lado", ""]]}, {"id": "2107.03248", "submitter": "Venkatesh Venkataramanan", "authors": "Venkatesh Venkataramanan, Sridevi Kaza, and Anuradha M. Annaswamy", "title": "DER Forecast using Privacy Preserving Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.DC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing penetration of Distributed Energy Resources (DERs) in grid\nedge including renewable generation, flexible loads, and storage, accurate\nprediction of distributed generation and consumption at the consumer level\nbecomes important. However, DER prediction based on the transmission of\ncustomer level data, either repeatedly or in large amounts, is not feasible due\nto privacy concerns. In this paper, a distributed machine learning approach,\nFederated Learning, is proposed to carry out DER forecasting using a network of\nIoT nodes, each of which transmits a model of the consumption and generation\npatterns without revealing consumer data. We consider a simulation study which\nincludes 1000 DERs, and show that our method leads to an accurate prediction of\npreserve consumer privacy, while still leading to an accurate forecast. We also\nevaluate grid-specific performance metrics such as load swings and load\ncurtailment and show that our FL algorithm leads to satisfactory performance.\nSimulations are also performed on the Pecan street dataset to demonstrate the\nvalidity of the proposed approach on real data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:25:43 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Venkataramanan", "Venkatesh", ""], ["Kaza", "Sridevi", ""], ["Annaswamy", "Anuradha M.", ""]]}, {"id": "2107.03250", "submitter": "Xiao Zhang", "authors": "Xiao Zhang and David Evans", "title": "Incorporating Label Uncertainty in Understanding Adversarial Robustness", "comments": "20 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fundamental question in adversarial machine learning is whether a robust\nclassifier exists for a given task. A line of research has made progress\ntowards this goal by studying concentration of measure, but without considering\ndata labels. We argue that the standard concentration fails to fully\ncharacterize the intrinsic robustness of a classification problem, since it\nignores data labels which are essential to any classification task. Building on\na novel definition of label uncertainty, we empirically demonstrate that error\nregions induced by state-of-the-art models tend to have much higher label\nuncertainty compared with randomly-selected subsets. This observation motivates\nus to adapt a concentration estimation algorithm to account for label\nuncertainty, resulting in more accurate intrinsic robustness measures for\nbenchmark image classification problems. We further provide empirical evidence\nshowing that adding an abstain option for classifiers based on label\nuncertainty can help improve both the clean and robust accuracies of models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:26:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "2107.03256", "submitter": "Patrick John Chia", "authors": "Patrick John Chia and Bingqing Yu and Jacopo Tagliabue", "title": "\"Are you sure?\": Preliminary Insights from Scaling Product Comparisons\n  to Multiple Shops", "comments": "Accepted for publication at SIGIR eCom 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large eCommerce players introduced comparison tables as a new type of\nrecommendations. However, building comparisons at scale without pre-existing\ntraining/taxonomy data remains an open challenge, especially within the\noperational constraints of shops in the long tail. We present preliminary\nresults from building a comparison pipeline designed to scale in a multi-shop\nscenario: we describe our design choices and run extensive benchmarks on\nmultiple shops to stress-test it. Finally, we run a small user study on\nproperty selection and conclude by discussing potential improvements and\nhighlighting the questions that remain to be addressed.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:39:52 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 13:24:22 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Chia", "Patrick John", ""], ["Yu", "Bingqing", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "2107.03263", "submitter": "Nihal Sharma", "authors": "Nihal Sharma, Soumya Basu, Karthikeyan Shanmugam, Sanjay Shakkottai", "title": "Episodic Bandits with Stochastic Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a version of the contextual bandit problem where an agent is given\nsoft control of a node in a graph-structured environment through a set of\nstochastic expert policies. The agent interacts with the environment over\nepisodes, with each episode having different context distributions; this\nresults in the `best expert' changing across episodes. Our goal is to develop\nan agent that tracks the best expert over episodes. We introduce the Empirical\nDivergence-based UCB (ED-UCB) algorithm in this setting where the agent does\nnot have any knowledge of the expert policies or changes in context\ndistributions. With mild assumptions, we show that bootstrapping from\n$\\tilde{O}(N\\log(NT^2\\sqrt{E}))$ samples results in a regret of\n$\\tilde{O}(E(N+1) + \\frac{N\\sqrt{E}}{T^2})$. If the expert policies are known\nto the agent a priori, then we can improve the regret to $\\tilde{O}(EN)$\nwithout requiring any bootstrapping. Our analysis also tightens pre-existing\nlogarithmic regret bounds to a problem-dependent constant in the non-episodic\nsetting when expert policies are known. We finally empirically validate our\nfindings through simulations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:58:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Sharma", "Nihal", ""], ["Basu", "Soumya", ""], ["Shanmugam", "Karthikeyan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2107.03280", "submitter": "David Zhao", "authors": "Benjamin LeRoy and David Zhao", "title": "MD-split+: Practical Local Conformal Inference in High Dimensions", "comments": "Appearing in ICML 2021 workshop on distribution-free uncertainty\n  quantification", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantifying uncertainty in model predictions is a common goal for\npractitioners seeking more than just point predictions. One tool for\nuncertainty quantification that requires minimal assumptions is conformal\ninference, which can help create probabilistically valid prediction regions for\nblack box models. Classical conformal prediction only provides marginal\nvalidity, whereas in many situations locally valid prediction regions are\ndesirable. Deciding how best to partition the feature space X when applying\nlocalized conformal prediction is still an open question. We present MD-split+,\na practical local conformal approach that creates X partitions based on\nlocalized model performance of conditional density estimation models. Our\nmethod handles complex real-world data settings where such models may be\nmisspecified, and scales to high-dimensional inputs. We discuss how our local\npartitions philosophically align with expected behavior from an unattainable\nconditional conformal inference approach. We also empirically compare our\nmethod against other local conformal approaches.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:19:16 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["LeRoy", "Benjamin", ""], ["Zhao", "David", ""]]}, {"id": "2107.03297", "submitter": "Angelo Salatino Dr", "authors": "Mojtaba Nayyeri, Gokce Muge Cil, Sahar Vahdati, Francesco Osborne,\n  Mahfuzur Rahman, Simone Angioni, Angelo Salatino, Diego Reforgiato Recupero,\n  Nadezhda Vassilyeva, Enrico Motta, Jens Lehmann", "title": "Trans4E: Link Prediction on Scholarly Knowledge Graphs", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2021.02.100", "report-no": null, "categories": "cs.AI cs.CL cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the\nquality of AI-based services. In the scholarly domain, KGs describing research\npublications typically lack important information, hindering our ability to\nanalyse and predict research dynamics. In recent years, link prediction\napproaches based on Knowledge Graph Embedding models became the first aid for\nthis issue. In this work, we present Trans4E, a novel embedding model that is\nparticularly fit for KGs which include N to M relations with N$\\gg$M. This is\ntypical for KGs that categorize a large number of entities (e.g., research\narticles, patents, persons) according to a relatively small set of categories.\nTrans4E was applied on two large-scale knowledge graphs, the Academia/Industry\nDynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the\ninformation about Fields of Study (e.g., 'neural networks', 'machine learning',\n'artificial intelligence'), and affiliation types (e.g., 'education',\n'company', 'government'), improving the scope and accuracy of the resulting\ndata. We evaluated our approach against alternative solutions on AIDA, MAG, and\nfour other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms\nthe other models when using low embedding dimensions and obtains competitive\nresults in high dimensions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:34:44 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Cil", "Gokce Muge", ""], ["Vahdati", "Sahar", ""], ["Osborne", "Francesco", ""], ["Rahman", "Mahfuzur", ""], ["Angioni", "Simone", ""], ["Salatino", "Angelo", ""], ["Recupero", "Diego Reforgiato", ""], ["Vassilyeva", "Nadezhda", ""], ["Motta", "Enrico", ""], ["Lehmann", "Jens", ""]]}, {"id": "2107.03299", "submitter": "Alvaro Ortiz", "authors": "Ali B. Barlas (BBVA Research), Seda Guler Mert (BBVA Research), Berk\n  Orkun Isa (BBVA Research) Alvaro Ortiz (BBVA Research), Tomasa Rodrigo (BBVA\n  Research), Baris Soybilgen (Bilgi University) and Ege Yazgan (Bilgi\n  University)", "title": "Big Data Information and Nowcasting: Consumption and Investment from\n  Bank Transactions in Turkey", "comments": "31 pages, 7 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use the aggregate information from individual-to-firm and firm-to-firm in\nGaranti BBVA Bank transactions to mimic domestic private demand. Particularly,\nwe replicate the quarterly national accounts aggregate consumption and\ninvestment (gross fixed capital formation) and its bigger components (Machinery\nand Equipment and Construction) in real time for the case of Turkey. In order\nto validate the usefulness of the information derived from these indicators we\ntest the nowcasting ability of both indicators to nowcast the Turkish GDP using\ndifferent nowcasting models. The results are successful and confirm the\nusefulness of Consumption and Investment Banking transactions for nowcasting\npurposes. The value of the Big data information is more relevant at the\nbeginning of the nowcasting process, when the traditional hard data information\nis scarce. This makes this information specially relevant for those countries\nwhere statistical release lags are longer like the Emerging Markets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:58:39 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Barlas", "Ali B.", "", "BBVA Research"], ["Mert", "Seda Guler", "", "BBVA Research"], ["Isa", "Berk Orkun", "", "BBVA Research"], ["Ortiz", "Alvaro", "", "BBVA Research"], ["Rodrigo", "Tomasa", "", "BBVA\n  Research"], ["Soybilgen", "Baris", "", "Bilgi University"], ["Yazgan", "Ege", "", "Bilgi\n  University"]]}, {"id": "2107.03311", "submitter": "Hidde Lycklama \\`A Nijeholt", "authors": "Lukas Burkhalter, Hidde Lycklama, Alexander Viand, Nicolas K\\\"uchler,\n  Anwar Hithnawi", "title": "RoFL: Attestable Robustness for Secure Federated Learning", "comments": "20 pages, 15 figures. Updated last name of one author to improve\n  indexability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is an emerging decentralized machine learning paradigm\nthat allows a large number of clients to train a joint model without the need\nto share their private data. Participants instead only share ephemeral updates\nnecessary to train the model. To ensure the confidentiality of the client\nupdates, Federated Learning systems employ secure aggregation; clients encrypt\ntheir gradient updates, and only the aggregated model is revealed to the\nserver. Achieving this level of data protection, however, presents new\nchallenges to the robustness of Federated Learning, i.e., the ability to\ntolerate failures and attacks. Unfortunately, in this setting, a malicious\nclient can now easily exert influence on the model behavior without being\ndetected. As Federated Learning is being deployed in practice in a range of\nsensitive applications, its robustness is growing in importance. In this paper,\nwe take a step towards understanding and improving the robustness of secure\nFederated Learning. We start this paper with a systematic study that evaluates\nand analyzes existing attack vectors and discusses potential defenses and\nassesses their effectiveness. We then present RoFL, a secure Federated Learning\nsystem that improves robustness against malicious clients through input checks\non the encrypted model updates. RoFL extends Federated Learning's secure\naggregation protocol to allow expressing a variety of properties and\nconstraints on model updates using zero-knowledge proofs. To enable RoFL to\nscale to typical Federated Learning settings, we introduce several ML and\ncryptographic optimizations specific to Federated Learning. We implement and\nevaluate a prototype of RoFL and show that realistic ML models can be trained\nin a reasonable time while improving robustness.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:42:49 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 10:43:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Burkhalter", "Lukas", ""], ["Lycklama", "Hidde", ""], ["Viand", "Alexander", ""], ["K\u00fcchler", "Nicolas", ""], ["Hithnawi", "Anwar", ""]]}, {"id": "2107.03312", "submitter": "Neil Zeghidour", "authors": "Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, Marco\n  Tagliasacchi", "title": "SoundStream: An End-to-End Neural Audio Codec", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SoundStream, a novel neural audio codec that can efficiently\ncompress speech, music and general audio at bitrates normally targeted by\nspeech-tailored codecs. SoundStream relies on a model architecture composed by\na fully convolutional encoder/decoder network and a residual vector quantizer,\nwhich are trained jointly end-to-end. Training leverages recent advances in\ntext-to-speech and speech enhancement, which combine adversarial and\nreconstruction losses to allow the generation of high-quality audio content\nfrom quantized embeddings. By training with structured dropout applied to\nquantizer layers, a single model can operate across variable bitrates from\n3kbps to 18kbps, with a negligible quality loss when compared with models\ntrained at fixed bitrates. In addition, the model is amenable to a low latency\nimplementation, which supports streamable inference and runs in real time on a\nsmartphone CPU. In subjective evaluations using audio at 24kHz sampling rate,\nSoundStream at 3kbps outperforms Opus at 12kbps and approaches EVS at 9.6kbps.\nMoreover, we are able to perform joint compression and enhancement either at\nthe encoder or at the decoder side with no additional latency, which we\ndemonstrate through background noise suppression for speech.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:45:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zeghidour", "Neil", ""], ["Luebs", "Alejandro", ""], ["Omran", "Ahmed", ""], ["Skoglund", "Jan", ""], ["Tagliasacchi", "Marco", ""]]}, {"id": "2107.03315", "submitter": "Devin Guillory", "authors": "Devin Guillory, Vaishaal Shankar, Sayna Ebrahimi, Trevor Darrell,\n  Ludwig Schmidt", "title": "Predicting with Confidence on Unseen Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has shown that the performance of machine learning models can\nvary substantially when models are evaluated on data drawn from a distribution\nthat is close to but different from the training distribution. As a result,\npredicting model performance on unseen distributions is an important challenge.\nOur work connects techniques from domain adaptation and predictive uncertainty\nliterature, and allows us to predict model accuracy on challenging unseen\ndistributions without access to labeled data. In the context of distribution\nshift, distributional distances are often used to adapt models and improve\ntheir performance on new domains, however accuracy estimation, or other forms\nof predictive uncertainty, are often neglected in these investigations. Through\ninvestigating a wide range of established distributional distances, such as\nFrechet distance or Maximum Mean Discrepancy, we determine that they fail to\ninduce reliable estimates of performance under distribution shift. On the other\nhand, we find that the difference of confidences (DoC) of a classifier's\npredictions successfully estimates the classifier's performance change over a\nvariety of shifts. We specifically investigate the distinction between\nsynthetic and natural distribution shifts and observe that despite its\nsimplicity DoC consistently outperforms other quantifications of distributional\ndifference. $DoC$ reduces predictive error by almost half ($46\\%$) on several\nrealistic and challenging distribution shifts, e.g., on the ImageNet-Vid-Robust\nand ImageNet-Rendition datasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:50:18 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Guillory", "Devin", ""], ["Shankar", "Vaishaal", ""], ["Ebrahimi", "Sayna", ""], ["Darrell", "Trevor", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "2107.03317", "submitter": "Benoit Fuentes Dr.", "authors": "Benoit Fuentes, Ga\\\"el Richard", "title": "Probabilistic semi-nonnegative matrix factorization: a Skellam-based\n  framework", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a new probabilistic model to address semi-nonnegative matrix\nfactorization (SNMF), called Skellam-SNMF. It is a hierarchical generative\nmodel consisting of prior components, Skellam-distributed hidden variables and\nobserved data. Two inference algorithms are derived: Expectation-Maximization\n(EM) algorithm for maximum \\emph{a posteriori} estimation and Variational Bayes\nEM (VBEM) for full Bayesian inference, including the estimation of parameters\nprior distribution. From this Skellam-based model, we also introduce a new\ndivergence $\\mathcal{D}$ between a real-valued target data $x$ and two\nnonnegative parameters $\\lambda_{0}$ and $\\lambda_{1}$ such that\n$\\mathcal{D}\\left(x\\mid\\lambda_{0},\\lambda_{1}\\right)=0\\Leftrightarrow\nx=\\lambda_{0}-\\lambda_{1}$, which is a generalization of the Kullback-Leibler\n(KL) divergence. Finally, we conduct experimental studies on those new\nalgorithms in order to understand their behavior and prove that they can\noutperform the classic SNMF approach on real data in a task of automatic\nclustering.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:56:22 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Fuentes", "Benoit", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "2107.03322", "submitter": "Yunzhang Zhu", "authors": "Yunzhang Zhu and Renxiong Liu", "title": "An algorithmic view of $\\ell_2$ regularization and some path-following\n  algorithms", "comments": "62 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish an equivalence between the $\\ell_2$-regularized solution path\nfor a convex loss function, and the solution of an ordinary differentiable\nequation (ODE). Importantly, this equivalence reveals that the solution path\ncan be viewed as the flow of a hybrid of gradient descent and Newton method\napplying to the empirical loss, which is similar to a widely used optimization\ntechnique called trust region method. This provides an interesting algorithmic\nview of $\\ell_2$ regularization, and is in contrast to the conventional view\nthat the $\\ell_2$ regularization solution path is similar to the gradient flow\nof the empirical loss.New path-following algorithms based on homotopy methods\nand numerical ODE solvers are proposed to numerically approximate the solution\npath. In particular, we consider respectively Newton method and gradient\ndescent method as the basis algorithm for the homotopy method, and establish\ntheir approximation error rates over the solution path. Importantly, our theory\nsuggests novel schemes to choose grid points that guarantee an arbitrarily\nsmall suboptimality for the solution path. In terms of computational cost, we\nprove that in order to achieve an $\\epsilon$-suboptimality for the entire\nsolution path, the number of Newton steps required for the Newton method is\n$\\mathcal O(\\epsilon^{-1/2})$, while the number of gradient steps required for\nthe gradient descent method is $\\mathcal O\\left(\\epsilon^{-1}\n\\ln(\\epsilon^{-1})\\right)$. Finally, we use $\\ell_2$-regularized logistic\nregression as an illustrating example to demonstrate the effectiveness of the\nproposed path-following algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:00:13 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhu", "Yunzhang", ""], ["Liu", "Renxiong", ""]]}, {"id": "2107.03323", "submitter": "Tim Cvetko", "authors": "Tim Cvetko", "title": "AGD-Autoencoder: Attention Gated Deep Convolutional Autoencoder for\n  Brain Tumor Segmentation", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Brain tumor segmentation is a challenging problem in medical image analysis.\nThe endpoint is to generate the salient masks that accurately identify brain\ntumor regions in an fMRI screening. In this paper, we propose a novel attention\ngate (AG model) for brain tumor segmentation that utilizes both the edge\ndetecting unit and the attention gated network to highlight and segment the\nsalient regions from fMRI images. This feature enables us to eliminate the\nnecessity of having to explicitly point towards the damaged area(external\ntissue localization) and classify(classification) as per classical computer\nvision techniques. AGs can easily be integrated within the deep convolutional\nneural networks(CNNs). Minimal computional overhead is required while the AGs\nincrease the sensitivity scores significantly. We show that the edge detector\nalong with an attention gated mechanism provide a sufficient enough method for\nbrain segmentation reaching an IOU of 0.78\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:01:24 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cvetko", "Tim", ""]]}, {"id": "2107.03324", "submitter": "Timo M\\\"uller", "authors": "Timo M\\\"uller, Benjamin Lindemann, Tobias Jung, Nasser Jazdi, Michael\n  Weyrich", "title": "Enhancing an Intelligent Digital Twin with a Self-organized\n  Reconfiguration Management based on Adaptive Process Models", "comments": "6 pages, 2 figures. Submitted to 54th CIRP Conference on\n  Manufacturing Systems 2021", "journal-ref": null, "doi": "10.13140/RG.2.2.31646.87362", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Shorter product life cycles and increasing individualization of production\nleads to an increased reconfiguration demand in the domain of industrial\nautomation systems, which will be dominated by cyber-physical production\nsystems in the future. In constantly changing systems, however, not all\nconfiguration alternatives of the almost infinite state space are fully\nunderstood. Thus, certain configurations can lead to process instability, a\nreduction in quality or machine failures. Therefore, this paper presents an\napproach that enhances an intelligent Digital Twin with a self-organized\nreconfiguration management based on adaptive process models in order to find\noptimized configurations more comprehensively.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:02:53 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["M\u00fcller", "Timo", ""], ["Lindemann", "Benjamin", ""], ["Jung", "Tobias", ""], ["Jazdi", "Nasser", ""], ["Weyrich", "Michael", ""]]}, {"id": "2107.03331", "submitter": "Aram Davtyan", "authors": "Aram Davtyan, Sepehr Sameni, Llukman Cerkezi, Givi Meishvilli, Adam\n  Bielski, Paolo Favaro", "title": "KaFiStO: A Kalman Filtering Framework for Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is often cast as a deterministic problem, where the solution is\nfound through some iterative procedure such as gradient descent. However, when\ntraining neural networks the loss function changes over (iteration) time due to\nthe randomized selection of a subset of the samples. This randomization turns\nthe optimization problem into a stochastic one. We propose to consider the loss\nas a noisy observation with respect to some reference optimum. This\ninterpretation of the loss allows us to adopt Kalman filtering as an optimizer,\nas its recursive formulation is designed to estimate unknown parameters from\nnoisy measurements. Moreover, we show that the Kalman Filter dynamical model\nfor the evolution of the unknown parameters can be used to capture the gradient\ndynamics of advanced methods such as Momentum and Adam. We call this stochastic\noptimization method KaFiStO. KaFiStO is an easy to implement, scalable, and\nefficient method to train neural networks. We show that it also yields\nparameter estimates that are on par with or better than existing optimization\nalgorithms across several neural network architectures and machine learning\ntasks, such as computer vision and language modeling.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:13:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Davtyan", "Aram", ""], ["Sameni", "Sepehr", ""], ["Cerkezi", "Llukman", ""], ["Meishvilli", "Givi", ""], ["Bielski", "Adam", ""], ["Favaro", "Paolo", ""]]}, {"id": "2107.03336", "submitter": "Benjamin Maschler", "authors": "Benjamin Maschler, Sophia Tatiyosyan and Michael Weyrich", "title": "Regularization-based Continual Learning for Fault Prediction in\n  Lithium-Ion Batteries", "comments": "6 pages, 5 figures, 4 tables. Accepted at CIRP ICME 2021. arXiv admin\n  note: text overlap with arXiv:2101.00509", "journal-ref": null, "doi": "10.13140/RG.2.2.10151.06561", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, the use of lithium-ion batteries has greatly expanded into\nproducts from many industrial sectors, e.g. cars, power tools or medical\ndevices. An early prediction and robust understanding of battery faults could\ntherefore greatly increase product quality in those fields. While current\napproaches for data-driven fault prediction provide good results on the exact\nprocesses they were trained on, they often lack the ability to flexibly adapt\nto changes, e.g. in operational or environmental parameters. Continual learning\npromises such flexibility, allowing for an automatic adaption of previously\nlearnt knowledge to new tasks. Therefore, this article discusses different\ncontinual learning approaches from the group of regularization strategies,\nwhich are implemented, evaluated and compared based on a real battery wear\ndataset. Online elastic weight consolidation delivers the best results, but, as\nwith all examined approaches, its performance appears to be strongly dependent\non task characteristics and task sequence.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:24:18 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Maschler", "Benjamin", ""], ["Tatiyosyan", "Sophia", ""], ["Weyrich", "Michael", ""]]}, {"id": "2107.03337", "submitter": "Michael D. Multerer", "authors": "Helmut Harbrecht and Michael Multerer", "title": "Samplets: A new paradigm for data compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CV cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we introduce the concept of samplets by transferring the\nconstruction of Tausch-White wavelets to the realm of data. This way we obtain\na multilevel representation of discrete data which directly enables data\ncompression, detection of singularities and adaptivity. Applying samplets to\nrepresent kernel matrices, as they arise in kernel based learning or Gaussian\nprocess regression, we end up with quasi-sparse matrices. By thresholding small\nentries, these matrices are compressible to O(N log N) relevant entries, where\nN is the number of data points. This feature allows for the use of fill-in\nreducing reorderings to obtain a sparse factorization of the compressed\nmatrices. Besides the comprehensive introduction to samplets and their\nproperties, we present extensive numerical studies to benchmark the approach.\nOur results demonstrate that samplets mark a considerable step in the direction\nof making large data sets accessible for analysis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:25:12 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 08:06:29 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Harbrecht", "Helmut", ""], ["Multerer", "Michael", ""]]}, {"id": "2107.03342", "submitter": "Jakob Gawlikowski", "authors": "Jakob Gawlikowski, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali,\n  Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel,\n  Peter Jung, Ribana Roscher, Muhammad Shahzad, Wen Yang, Richard Bamler, Xiao\n  Xiang Zhu", "title": "A Survey of Uncertainty in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to their increasing spread, confidence in neural network predictions\nbecame more and more important. However, basic neural networks do not deliver\ncertainty estimates or suffer from over or under confidence. Many researchers\nhave been working on understanding and quantifying uncertainty in a neural\nnetwork's prediction. As a result, different types and sources of uncertainty\nhave been identified and a variety of approaches to measure and quantify\nuncertainty in neural networks have been proposed. This work gives a\ncomprehensive overview of uncertainty estimation in neural networks, reviews\nrecent advances in the field, highlights current challenges, and identifies\npotential research opportunities. It is intended to give anyone interested in\nuncertainty estimation in neural networks a broad overview and introduction,\nwithout presupposing prior knowledge in this field. A comprehensive\nintroduction to the most crucial sources of uncertainty is given and their\nseparation into reducible model uncertainty and not reducible data uncertainty\nis presented. The modeling of these uncertainties based on deterministic neural\nnetworks, Bayesian neural networks, ensemble of neural networks, and test-time\ndata augmentation approaches is introduced and different branches of these\nfields as well as the latest developments are discussed. For a practical\napplication, we discuss different measures of uncertainty, approaches for the\ncalibration of neural networks and give an overview of existing baselines and\nimplementations. Different examples from the wide spectrum of challenges in\ndifferent fields give an idea of the needs and challenges regarding\nuncertainties in practical applications. Additionally, the practical\nlimitations of current methods for mission- and safety-critical real world\napplications are discussed and an outlook on the next steps towards a broader\nusage of such methods is given.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:39:28 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Gawlikowski", "Jakob", ""], ["Tassi", "Cedrique Rovile Njieutcheu", ""], ["Ali", "Mohsin", ""], ["Lee", "Jongseok", ""], ["Humt", "Matthias", ""], ["Feng", "Jianxiang", ""], ["Kruspe", "Anna", ""], ["Triebel", "Rudolph", ""], ["Jung", "Peter", ""], ["Roscher", "Ribana", ""], ["Shahzad", "Muhammad", ""], ["Yang", "Wen", ""], ["Bamler", "Richard", ""], ["Zhu", "Xiao Xiang", ""]]}, {"id": "2107.03354", "submitter": "Tianbo Li", "authors": "Tianbo Li, Tianze Luo, Yiping Ke, Sinno Jialin Pan", "title": "Mitigating Performance Saturation in Neural Marked Point Processes:\n  Architectures and Loss Functions", "comments": "9 pages, 4 figures, accepted by KDD-21 research track. The source\n  code is available at https://github.com/ltz0120/Graph-Convolutional-\n  Hawkes-Processes-GCHP", "journal-ref": null, "doi": "10.1145/3447548.3467436", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attributed event sequences are commonly encountered in practice. A recent\nresearch line focuses on incorporating neural networks with the statistical\nmodel -- marked point processes, which is the conventional tool for dealing\nwith attributed event sequences. Neural marked point processes possess good\ninterpretability of probabilistic models as well as the representational power\nof neural networks. However, we find that performance of neural marked point\nprocesses is not always increasing as the network architecture becomes more\ncomplicated and larger, which is what we call the performance saturation\nphenomenon. This is due to the fact that the generalization error of neural\nmarked point processes is determined by both the network representational\nability and the model specification at the same time. Therefore we can draw two\nmajor conclusions: first, simple network structures can perform no worse than\ncomplicated ones for some cases; second, using a proper probabilistic\nassumption is as equally, if not more, important as improving the complexity of\nthe network. Based on this observation, we propose a simple graph-based network\nstructure called GCHP, which utilizes only graph convolutional layers, thus it\ncan be easily accelerated by the parallel mechanism. We directly consider the\ndistribution of interarrival times instead of imposing a specific assumption on\nthe conditional intensity function, and propose to use a likelihood ratio loss\nwith a moment matching mechanism for optimization and model selection.\nExperimental results show that GCHP can significantly reduce training time and\nthe likelihood ratio loss with interarrival time probability assumptions can\ngreatly improve the model performance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 16:59:14 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Li", "Tianbo", ""], ["Luo", "Tianze", ""], ["Ke", "Yiping", ""], ["Pan", "Sinno Jialin", ""]]}, {"id": "2107.03356", "submitter": "Eldar Kurtic", "authors": "Elias Frantar, Eldar Kurtic, Dan Alistarh", "title": "Efficient Matrix-Free Approximations of Second-Order Information, with\n  Applications to Pruning and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficiently approximating local curvature information of the loss function is\na key tool for optimization and compression of deep neural networks. Yet, most\nexisting methods to approximate second-order information have high\ncomputational or storage costs, which can limit their practicality. In this\nwork, we investigate matrix-free, linear-time approaches for estimating\nInverse-Hessian Vector Products (IHVPs) for the case when the Hessian can be\napproximated as a sum of rank-one matrices, as in the classic approximation of\nthe Hessian by the empirical Fisher matrix. We propose two new algorithms as\npart of a framework called M-FAC: the first algorithm is tailored towards\nnetwork compression and can compute the IHVP for dimension $d$, if the Hessian\nis given as a sum of $m$ rank-one matrices, using $O(dm^2)$ precomputation,\n$O(dm)$ cost for computing the IHVP, and query cost $O(m)$ for any single\nelement of the inverse Hessian. The second algorithm targets an optimization\nsetting, where we wish to compute the product between the inverse Hessian,\nestimated over a sliding window of optimization steps, and a given gradient\ndirection, as required for preconditioned SGD. We give an algorithm with cost\n$O(dm + m^2)$ for computing the IHVP and $O(dm + m^3)$ for adding or removing\nany gradient from the sliding window. These two algorithms yield\nstate-of-the-art results for network pruning and optimization with lower\ncomputational overhead relative to existing second-order methods.\nImplementations are available at [10] and [18].\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 17:01:34 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 08:40:09 GMT"}, {"version": "v3", "created": "Fri, 9 Jul 2021 09:38:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Frantar", "Elias", ""], ["Kurtic", "Eldar", ""], ["Alistarh", "Dan", ""]]}, {"id": "2107.03361", "submitter": "T.S.Sachin Venkatesh", "authors": "T.S.Sachin Venkatesh, Rajat Srivastava, Pratyush Bhatt, Prince Tyagi,\n  Raj Kumar Singh", "title": "A comparative study of various Deep Learning techniques for\n  spatio-temporal Super-Resolution reconstruction of Forced Isotropic Turbulent\n  flows", "comments": "10 pages, 10 figures, 2 tables, accepted for IMECE2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Super-resolution is an innovative technique that upscales the resolution of\nan image or a video and thus enables us to reconstruct high-fidelity images\nfrom low-resolution data. This study performs super-resolution analysis on\nturbulent flow fields spatially and temporally using various state-of-the-art\nmachine learning techniques like ESPCN, ESRGAN and TecoGAN to reconstruct\nhigh-resolution flow fields from low-resolution flow field data, especially\nkeeping in mind the need for low resource consumption and rapid results\nproduction/verification. The dataset used for this study is extracted from the\n'isotropic 1024 coarse' dataset which is a part of Johns Hopkins Turbulence\nDatabases (JHTDB). We have utilized pre-trained models and fine tuned them to\nour needs, so as to minimize the computational resources and the time required\nfor the implementation of the super-resolution models. The advantages presented\nby this method far exceed the expectations and the outcomes of regular single\nstructure models. The results obtained through these models are then compared\nusing MSE, PSNR, SAM, VIF and SCC metrics in order to evaluate the upscaled\nresults, find the balance between computational power and output quality, and\nthen identify the most accurate and efficient model for spatial and temporal\nsuper-resolution of turbulent flow fields.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 17:16:55 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Venkatesh", "T. S. Sachin", ""], ["Srivastava", "Rajat", ""], ["Bhatt", "Pratyush", ""], ["Tyagi", "Prince", ""], ["Singh", "Raj Kumar", ""]]}, {"id": "2107.03374", "submitter": "Mark Chen", "authors": "Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de\n  Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph,\n  Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy\n  Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder,\n  Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens\n  Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias\n  Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William\n  Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor\n  Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher\n  Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa,\n  Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter\n  Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, Wojciech\n  Zaremba", "title": "Evaluating Large Language Models Trained on Code", "comments": "corrected typos, added references, added authors, added\n  acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Codex, a GPT language model fine-tuned on publicly available\ncode from GitHub, and study its Python code-writing capabilities. A distinct\nproduction version of Codex powers GitHub Copilot. On HumanEval, a new\nevaluation set we release to measure functional correctness for synthesizing\nprograms from docstrings, our model solves 28.8% of the problems, while GPT-3\nsolves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling\nfrom the model is a surprisingly effective strategy for producing working\nsolutions to difficult prompts. Using this method, we solve 70.2% of our\nproblems with 100 samples per problem. Careful investigation of our model\nreveals its limitations, including difficulty with docstrings describing long\nchains of operations and with binding operations to variables. Finally, we\ndiscuss the potential broader impacts of deploying powerful code generation\ntechnologies, covering safety, security, and economics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 17:41:24 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 17:16:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Chen", "Mark", ""], ["Tworek", "Jerry", ""], ["Jun", "Heewoo", ""], ["Yuan", "Qiming", ""], ["Pinto", "Henrique Ponde de Oliveira", ""], ["Kaplan", "Jared", ""], ["Edwards", "Harri", ""], ["Burda", "Yuri", ""], ["Joseph", "Nicholas", ""], ["Brockman", "Greg", ""], ["Ray", "Alex", ""], ["Puri", "Raul", ""], ["Krueger", "Gretchen", ""], ["Petrov", "Michael", ""], ["Khlaaf", "Heidy", ""], ["Sastry", "Girish", ""], ["Mishkin", "Pamela", ""], ["Chan", "Brooke", ""], ["Gray", "Scott", ""], ["Ryder", "Nick", ""], ["Pavlov", "Mikhail", ""], ["Power", "Alethea", ""], ["Kaiser", "Lukasz", ""], ["Bavarian", "Mohammad", ""], ["Winter", "Clemens", ""], ["Tillet", "Philippe", ""], ["Such", "Felipe Petroski", ""], ["Cummings", "Dave", ""], ["Plappert", "Matthias", ""], ["Chantzis", "Fotios", ""], ["Barnes", "Elizabeth", ""], ["Herbert-Voss", "Ariel", ""], ["Guss", "William Hebgen", ""], ["Nichol", "Alex", ""], ["Paino", "Alex", ""], ["Tezak", "Nikolas", ""], ["Tang", "Jie", ""], ["Babuschkin", "Igor", ""], ["Balaji", "Suchir", ""], ["Jain", "Shantanu", ""], ["Saunders", "William", ""], ["Hesse", "Christopher", ""], ["Carr", "Andrew N.", ""], ["Leike", "Jan", ""], ["Achiam", "Josh", ""], ["Misra", "Vedant", ""], ["Morikawa", "Evan", ""], ["Radford", "Alec", ""], ["Knight", "Matthew", ""], ["Brundage", "Miles", ""], ["Murati", "Mira", ""], ["Mayer", "Katie", ""], ["Welinder", "Peter", ""], ["McGrew", "Bob", ""], ["Amodei", "Dario", ""], ["McCandlish", "Sam", ""], ["Sutskever", "Ilya", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "2107.03375", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo and Yang Gao", "title": "Differentiable Architecture Pruning for Transfer Learning", "comments": "19 pages (main + appendix), 7 figures and 1 table, Workshop @ ICML\n  2021, 24th July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new gradient-based approach for extracting sub-architectures\nfrom a given large model. Contrarily to existing pruning methods, which are\nunable to disentangle the network architecture and the corresponding weights,\nour architecture-pruning scheme produces transferable new structures that can\nbe successfully retrained to solve different tasks. We focus on a\ntransfer-learning setup where architectures can be trained on a large data set\nbut very few data points are available for fine-tuning them on new tasks. We\ndefine a new gradient-based algorithm that trains architectures of arbitrarily\nlow complexity independently from the attached weights. Given a search space\ndefined by an existing large neural model, we reformulate the architecture\nsearch task as a complexity-penalized subset-selection problem and solve it\nthrough a two-temperature relaxation scheme. We provide theoretical convergence\nguarantees and validate the proposed transfer-learning strategy on real data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 17:44:59 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Colombo", "Nicolo", ""], ["Gao", "Yang", ""]]}, {"id": "2107.03383", "submitter": "Simone Marini", "authors": "Mattia Prosperi, Simone Marini, Christina Boucher, Jiang Bian", "title": "Assessing putative bias in prediction of anti-microbial resistance from\n  real-world genotyping data under explicit causal assumptions", "comments": "In DSHealth '21] Joint KDD 2021 Health Day and 2021 KDD Workshop on\n  Applied Data Science for Healthcare, Aug 14--18, 2021, Virtual, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Whole genome sequencing (WGS) is quickly becoming the customary means for\nidentification of antimicrobial resistance (AMR) due to its ability to obtain\nhigh resolution information about the genes and mechanisms that are causing\nresistance and driving pathogen mobility. By contrast, traditional phenotypic\n(antibiogram) testing cannot easily elucidate such information. Yet development\nof AMR prediction tools from genotype-phenotype data can be biased, since\nsampling is non-randomized. Sample provenience, period of collection, and\nspecies representation can confound the association of genetic traits with AMR.\nThus, prediction models can perform poorly on new data with sampling\ndistribution shifts. In this work -- under an explicit set of causal\nassumptions -- we evaluate the effectiveness of propensity-based rebalancing\nand confounding adjustment on AMR prediction using genotype-phenotype AMR data\nfrom the Pathosystems Resource Integration Center (PATRIC). We select bacterial\ngenotypes (encoded as k-mer signatures, i.e. DNA fragments of length k),\ncountry, year, species, and AMR phenotypes for the tetracycline drug class,\npreparing test data with recent genomes coming from a single country. We test\nboosted logistic regression (BLR) and random forests (RF) with/without\nbias-handling. On 10,936 instances, we find evidence of species, location and\nyear imbalance with respect to the AMR phenotype. The crude versus\nbias-adjusted change in effect of genetic signatures on AMR varies but only\nmoderately (selecting the top 20,000 out of 40+ million k-mers). The area under\nthe receiver operating characteristic (AUROC) of the RF (0.95) is comparable to\nthat of BLR (0.94) on both out-of-bag samples from bootstrap and the external\ntest (n=1,085), where AUROCs do not decrease. We observe a 1%-5% gain in AUROC\nwith bias-handling compared to the sole use of genetic signatures. ...\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 21:19:21 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 19:59:22 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Prosperi", "Mattia", ""], ["Marini", "Simone", ""], ["Boucher", "Christina", ""], ["Bian", "Jiang", ""]]}, {"id": "2107.03385", "submitter": "Andres Carvallo", "authors": "Iv\\'an Cantador, Andr\\'es Carvallo, Fernando Diez", "title": "Rating and aspect-based opinion graph embeddings for explainable\n  recommendations", "comments": "arXiv admin note: substantial text overlap with arXiv:2107.03226", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of neural network embeddings has entailed a renewed interest in\nusing knowledge graphs for a wide variety of machine learning and information\nretrieval tasks. In particular, recent recommendation methods based on graph\nembeddings have shown state-of-the-art performance. In general, these methods\nencode latent rating patterns and content features. Differently from previous\nwork, in this paper, we propose to exploit embeddings extracted from graphs\nthat combine information from ratings and aspect-based opinions expressed in\ntextual reviews. We then adapt and evaluate state-of-the-art graph embedding\ntechniques over graphs generated from Amazon and Yelp reviews on six domains,\noutperforming baseline recommenders. Additionally, our method has the advantage\nof providing explanations that involve the coverage of aspect-based opinions\ngiven by users about recommended items.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:07:07 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cantador", "Iv\u00e1n", ""], ["Carvallo", "Andr\u00e9s", ""], ["Diez", "Fernando", ""]]}, {"id": "2107.03387", "submitter": "Tim Cvetko", "authors": "Tim Cvetko, Tinkara Robek", "title": "Sleep syndromes onset detection based on automatic sleep staging\n  algorithm", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel method and a practical approach to\npredicting early onsets of sleep syndromes, including restless leg syndrome,\ninsomnia, based on an algorithm that is comprised of two modules. A Fast\nFourier Transform is applied to 30 seconds long epochs of EEG recordings to\nprovide localized time-frequency information, and a deep convolutional LSTM\nneural network is trained for sleep stage classification. Automating sleep\nstages detection from EEG data offers great potential to tackling sleep\nirregularities on a daily basis. Thereby, a novel approach for sleep stage\nclassification is proposed which combines the best of signal processing and\nstatistics. In this study, we used the PhysioNet Sleep European Data Format\n(EDF) Database. The code evaluation showed impressive results, reaching an\naccuracy of 86.43, precision of 77.76, recall of 93,32, F1-score of 89.12 with\nthe final mean false error loss of 0.09.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:38:47 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cvetko", "Tim", ""], ["Robek", "Tinkara", ""]]}, {"id": "2107.03402", "submitter": "Tom Westerhout", "authors": "Mikhail I. Katsnelson, Vitaly Vanchurin, Tom Westerhout", "title": "Self-organized criticality in neural networks", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate, both analytically and numerically, that learning dynamics of\nneural networks is generically attracted towards a self-organized critical\nstate. The effect can be modeled with quartic interactions between\nnon-trainable variables (e.g. states of neurons) and trainable variables (e.g.\nweight matrix). Non-trainable variables are rapidly driven towards stochastic\nequilibrium and trainable variables are slowly driven towards learning\nequilibrium described by a scale-invariant distribution on a wide range of\nscales. Our results suggest that the scale invariance observed in many physical\nand biological systems might be due to some kind of learning dynamics and\nsupport the claim that the universe might be a neural network.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:00:03 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Katsnelson", "Mikhail I.", ""], ["Vanchurin", "Vitaly", ""], ["Westerhout", "Tom", ""]]}, {"id": "2107.03423", "submitter": "Isel Grau", "authors": "Gonzalo N\\'apoles, Yamisleydi Salgueiro, Isel Grau, Maikel Leon\n  Espinosa", "title": "Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning solutions for pattern classification problems are nowadays\nwidely deployed in society and industry. However, the lack of transparency and\naccountability of most accurate models often hinders their meaningful and safe\nuse. Thus, there is a clear need for developing explainable artificial\nintelligence mechanisms. There exist model-agnostic methods that summarize\nfeature contributions, but their interpretability is limited to specific\npredictions made by black-box models. An open challenge is to develop models\nthat have intrinsic interpretability and produce their own explanations, even\nfor classes of models that are traditionally considered black boxes like\n(recurrent) neural networks. In this paper, we propose an LTCN-based model for\ninterpretable pattern classification of structured data. Our method brings its\nown mechanism for providing explanations by quantifying the relevance of each\nfeature in the decision process. For supporting the interpretability without\naffecting the performance, the model incorporates more flexibility through a\nquasi-nonlinear reasoning rule that allows controlling nonlinearity. Besides,\nwe propose a recurrence-aware decision model that evades the issues posed by\nunique fixed points while introducing a deterministic learning method to\ncompute the learnable parameters. The simulations show that our interpretable\nmodel obtains competitive performance when compared to the state-of-the-art\nwhite and black boxes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:14:50 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["N\u00e1poles", "Gonzalo", ""], ["Salgueiro", "Yamisleydi", ""], ["Grau", "Isel", ""], ["Espinosa", "Maikel Leon", ""]]}, {"id": "2107.03427", "submitter": "Sai Srivatsa Ravindranath", "authors": "Sai Srivatsa Ravindranath, Zhe Feng, Shira Li, Jonathan Ma, Scott D.\n  Kominers, David C. Parkes", "title": "Deep Learning for Two-Sided Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the use of a multi-layer neural network to model two-sided\nmatching and to explore the design space between strategy-proofness and\nstability. It is well known that both properties cannot be achieved\nsimultaneously but the efficient frontier in this design space is not\nunderstood. We show empirically that it is possible to achieve a good\ncompromise between stability and strategy-proofness-substantially better than\nthat achievable through a convex combination of deferred acceptance (stable and\nstrategy-proof for only one side of the market) and randomized serial\ndictatorship (strategy-proof but not stable).\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:22:11 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ravindranath", "Sai Srivatsa", ""], ["Feng", "Zhe", ""], ["Li", "Shira", ""], ["Ma", "Jonathan", ""], ["Kominers", "Scott D.", ""], ["Parkes", "David C.", ""]]}, {"id": "2107.03428", "submitter": "Silvana Trindade", "authors": "Silvana Trindade, Luiz F. Bittencourt, Nelson L. S. da Fonseca", "title": "Management of Resource at the Network Edge for Federated Learning", "comments": "arXiv admin note: text overlap with arXiv:1803.05255 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning has been explored as a promising solution for training at\nthe edge, where end devices collaborate to train models without sharing data\nwith other entities. Since the execution of these learning models occurs at the\nedge, where resources are limited, new solutions must be developed. In this\npaper, we describe the recent work on resource management at the edge, and\nexplore the challenges and future directions to allow the execution of\nfederated learning at the edge. Some of the problems of this management, such\nas discovery of resources, deployment, load balancing, migration, and energy\nefficiency will be discussed in the paper.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:22:32 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Trindade", "Silvana", ""], ["Bittencourt", "Luiz F.", ""], ["da Fonseca", "Nelson L. S.", ""]]}, {"id": "2107.03432", "submitter": "Muhammed Sit", "authors": "Muhammed Sit, Bong-Chul Seo and Ibrahim Demir", "title": "IowaRain: A Statewide Rain Event Dataset Based on Weather Radars and\n  Quantitative Precipitation Estimation", "comments": "4 pages, Accepted to Tackling Climate Change with Machine Learning\n  workshop at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective environmental planning and management to address climate change\ncould be achieved through extensive environmental modeling with machine\nlearning and conventional physical models. In order to develop and improve\nthese models, practitioners and researchers need comprehensive benchmark\ndatasets that are prepared and processed with environmental expertise that they\ncan rely on. This study presents an extensive dataset of rainfall events for\nthe state of Iowa (2016-2019) acquired from the National Weather Service Next\nGeneration Weather Radar (NEXRAD) system and processed by a quantitative\nprecipitation estimation system. The dataset presented in this study could be\nused for better disaster monitoring, response and recovery by paving the way\nfor both predictive and prescriptive modeling.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:30:38 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Sit", "Muhammed", ""], ["Seo", "Bong-Chul", ""], ["Demir", "Ibrahim", ""]]}, {"id": "2107.03433", "submitter": "Matei Moldoveanu", "authors": "Matei Moldoveanu, Abdellatif Zaidi", "title": "In-Network Learning: Distributed Training and Inference in Networks", "comments": "Submitted to the IEEE Journal on Selected Areas in Communications\n  (JSAC) Series on Machine Learning for Communications and Networks. arXiv\n  admin note: substantial text overlap with arXiv:2104.14929", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely perceived that leveraging the success of modern machine learning\ntechniques to mobile devices and wireless networks has the potential of\nenabling important new services. This, however, poses significant challenges,\nessentially due to that both data and processing power are highly distributed\nin a wireless network. In this paper, we develop a learning algorithm and an\narchitecture that make use of multiple data streams and processing units, not\nonly during the training phase but also during the inference phase. In\nparticular, the analysis reveals how inference propagates and fuses across a\nnetwork. We study the design criterion of our proposed method and its bandwidth\nrequirements. Also, we discuss implementation aspects using neural networks in\ntypical wireless radio access; and provide experiments that illustrate benefits\nover state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:35:08 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Moldoveanu", "Matei", ""], ["Zaidi", "Abdellatif", ""]]}, {"id": "2107.03442", "submitter": "Mohammad Hamghalam", "authors": "Mohammad Hamghalam, Alejandro F. Frangi, Baiying Lei, and Amber L.\n  Simpson", "title": "Modality Completion via Gaussian Process Prior Variational Autoencoders\n  for Multi-Modal Glioma Segmentation", "comments": "Accepted in MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In large studies involving multi protocol Magnetic Resonance Imaging (MRI),\nit can occur to miss one or more sub-modalities for a given patient owing to\npoor quality (e.g. imaging artifacts), failed acquisitions, or hallway\ninterrupted imaging examinations. In some cases, certain protocols are\nunavailable due to limited scan time or to retrospectively harmonise the\nimaging protocols of two independent studies. Missing image modalities pose a\nchallenge to segmentation frameworks as complementary information contributed\nby the missing scans is then lost. In this paper, we propose a novel model,\nMulti-modal Gaussian Process Prior Variational Autoencoder (MGP-VAE), to impute\none or more missing sub-modalities for a patient scan. MGP-VAE can leverage the\nGaussian Process (GP) prior on the Variational Autoencoder (VAE) to utilize the\nsubjects/patients and sub-modalities correlations. Instead of designing one\nnetwork for each possible subset of present sub-modalities or using frameworks\nto mix feature maps, missing data can be generated from a single model based on\nall the available samples. We show the applicability of MGP-VAE on brain tumor\nsegmentation where either, two, or three of four sub-modalities may be missing.\nOur experiments against competitive segmentation baselines with missing\nsub-modality on BraTS'19 dataset indicate the effectiveness of the MGP-VAE\nmodel for segmentation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 19:06:34 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Hamghalam", "Mohammad", ""], ["Frangi", "Alejandro F.", ""], ["Lei", "Baiying", ""], ["Simpson", "Amber L.", ""]]}, {"id": "2107.03443", "submitter": "Lucas Fenaux", "authors": "Lucas Fenaux and Maria Juliana Quintero", "title": "BumbleBee: A Transformer for Music", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We will introduce BumbleBee, a transformer model that will generate MIDI\nmusic data . We will tackle the issue of transformers applied to long sequences\nby implementing a longformer generative model that uses dilating sliding\nwindows to compute the attention layers. We will compare our results to that of\nthe music transformer and Long-Short term memory (LSTM) to benchmark our\nresults. This analysis will be performed using piano MIDI files, in particular\n, the JSB Chorales dataset that has already been used for other research works\n(Huang et al., 2018)\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 19:08:16 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Fenaux", "Lucas", ""], ["Quintero", "Maria Juliana", ""]]}, {"id": "2107.03453", "submitter": "Xinlin Li", "authors": "Xinlin Li, Bang Liu, Yaoliang Yu, Wulong Liu, Chunjing Xu, Vahid\n  Partovi Nia", "title": "$S^3$: Sign-Sparse-Shift Reparametrization for Effective Training of\n  Low-bit Shift Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shift neural networks reduce computation complexity by removing expensive\nmultiplication operations and quantizing continuous weights into low-bit\ndiscrete values, which are fast and energy efficient compared to conventional\nneural networks. However, existing shift networks are sensitive to the weight\ninitialization, and also yield a degraded performance caused by vanishing\ngradient and weight sign freezing problem. To address these issues, we propose\nS low-bit re-parameterization, a novel technique for training low-bit shift\nnetworks. Our method decomposes a discrete parameter in a sign-sparse-shift\n3-fold manner. In this way, it efficiently learns a low-bit network with a\nweight dynamics similar to full-precision networks and insensitive to weight\ninitialization. Our proposed training method pushes the boundaries of shift\nneural networks and shows 3-bit shift networks out-performs their\nfull-precision counterparts in terms of top-1 accuracy on ImageNet.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 19:33:02 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Li", "Xinlin", ""], ["Liu", "Bang", ""], ["Yu", "Yaoliang", ""], ["Liu", "Wulong", ""], ["Xu", "Chunjing", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "2107.03455", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Abishek Sankararaman and Kannan Ramchandran", "title": "Model Selection for Generic Contextual Bandits", "comments": "40 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2006.02612", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of model selection for the general stochastic\ncontextual bandits under the realizability assumption. We propose a successive\nrefinement based algorithm called Adaptive Contextual Bandit ({\\ttfamily ACB}),\nthat works in phases and successively eliminates model classes that are too\nsimple to fit the given instance. We prove that this algorithm is adaptive,\ni.e., the regret rate order-wise matches that of {\\ttfamily FALCON}, the\nstate-of-art contextual bandit algorithm of Levi et. al '20, that needs\nknowledge of the true model class. The price of not knowing the correct model\nclass is only an additive term contributing to the second order term in the\nregret bound. This cost possess the intuitive property that it becomes smaller\nas the model class becomes easier to identify, and vice-versa. We then show\nthat a much simpler explore-then-commit (ETC) style algorithm also obtains a\nregret rate of matching that of {\\ttfamily FALCON}, despite not knowing the\ntrue model class. However, the cost of model selection is higher in ETC as\nopposed to in {\\ttfamily ACB}, as expected. Furthermore, {\\ttfamily ACB}\napplied to the linear bandit setting with unknown sparsity, order-wise recovers\nthe model selection guarantees previously established by algorithms tailored to\nthe linear setting.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 19:35:31 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ghosh", "Avishek", ""], ["Sankararaman", "Abishek", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2107.03463", "submitter": "Seyed Mojtaba Marvasti-Zadeh", "authors": "Seyed Mojtaba Marvasti-Zadeh, Javad Khaghani, Li Cheng, Hossein\n  Ghanei-Yakhdan, Shohreh Kasaei", "title": "CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural\n  Architecture Search", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strong visual object tracker nowadays relies on its well-crafted modules,\nwhich typically consist of manually-designed network architectures to deliver\nhigh-quality tracking results. Not surprisingly, the manual design process\nbecomes a particularly challenging barrier, as it demands sufficient prior\nexperience, enormous effort, intuition and perhaps some good luck. Meanwhile,\nneural architecture search has gaining grounds in practical applications such\nas image segmentation, as a promising method in tackling the issue of automated\nsearch of feasible network structures. In this work, we propose a novel\ncell-level differentiable architecture search mechanism to automate the network\ndesign of the tracking module, aiming to adapt backbone features to the\nobjective of a tracking network during offline training. The proposed approach\nis simple, efficient, and with no need to stack a series of modules to\nconstruct a network. Our approach is easy to be incorporated into existing\ntrackers, which is empirically validated using different differentiable\narchitecture search-based methods and tracking objectives. Extensive\nexperimental evaluations demonstrate the superior performance of our approach\nover five commonly-used benchmarks. Meanwhile, our automated searching process\ntakes 41 (18) hours for the second (first) order DARTS method on the\nTrackingNet dataset.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 15:16:45 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Marvasti-Zadeh", "Seyed Mojtaba", ""], ["Khaghani", "Javad", ""], ["Cheng", "Li", ""], ["Ghanei-Yakhdan", "Hossein", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "2107.03474", "submitter": "Adam P. Goucher", "authors": "Adam P. Goucher, Rajan Troll", "title": "Differentiable Random Access Memory using Lattices", "comments": "11 pages, 3 figures, submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a differentiable random access memory module with $O(1)$\nperformance regardless of size, scaling to billions of entries. The design\nstores entries on points of a chosen lattice to calculate nearest neighbours of\narbitrary points efficiently by exploiting symmetries. Augmenting a standard\nneural network architecture with a single memory layer based on this, we can\nscale the parameter count up to memory limits with negligible computational\noverhead, giving better accuracy at similar cost. On large language modelling\ntasks, these enhanced models with larger capacity significantly outperform the\nunmodified transformer baseline. We found continued scaling with memory size up\nto the limits tested.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 20:55:42 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Goucher", "Adam P.", ""], ["Troll", "Rajan", ""]]}, {"id": "2107.03483", "submitter": "Shai Ben-David", "authors": "Tosca Lechner, Shai Ben-David, Sushant Agarwal and Nivasini\n  Ananthakrishnan", "title": "Impossibility results for fair representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing awareness to fairness in machine learning and the\nrealization of the central role that data representation has in data processing\ntasks, there is an obvious interest in notions of fair data representations.\nThe goal of such representations is that a model trained on data under the\nrepresentation (e.g., a classifier) will be guaranteed to respect some fairness\nconstraints.\n  Such representations are useful when they can be fixed for training models on\nvarious different tasks and also when they serve as data filtering between the\nraw data (known to the representation designer) and potentially malicious\nagents that use the data under the representation to learn predictive models\nand make decisions.\n  A long list of recent research papers strive to provide tools for achieving\nthese goals.\n  However, we prove that this is basically a futile effort. Roughly stated, we\nprove that no representation can guarantee the fairness of classifiers for\ndifferent tasks trained using it; even the basic goal of achieving\nlabel-independent Demographic Parity fairness fails once the marginal data\ndistribution shifts. More refined notions of fairness, like Odds Equality,\ncannot be guaranteed by a representation that does not take into account the\ntask specific labeling rule with respect to which such fairness will be\nevaluated (even if the marginal data distribution is known a priory).\nFurthermore, except for trivial cases, no representation can guarantee Odds\nEquality fairness for any two different tasks, while allowing accurate label\npredictions for both.\n  While some of our conclusions are intuitive, we formulate (and prove) crisp\nstatements of such impossibilities, often contrasting impressions conveyed by\nmany recent works on fair representations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 21:12:55 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lechner", "Tosca", ""], ["Ben-David", "Shai", ""], ["Agarwal", "Sushant", ""], ["Ananthakrishnan", "Nivasini", ""]]}, {"id": "2107.03502", "submitter": "Yusuke Tashiro", "authors": "Yusuke Tashiro, Jiaming Song, Yang Song, Stefano Ermon", "title": "CSDI: Conditional Score-based Diffusion Models for Probabilistic Time\n  Series Imputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The imputation of missing values in time series has many applications in\nhealthcare and finance. While autoregressive models are natural candidates for\ntime series imputation, score-based diffusion models have recently outperformed\nexisting counterparts including autoregressive models in many tasks such as\nimage generation and audio synthesis, and would be promising for time series\nimputation. In this paper, we propose Conditional Score-based Diffusion models\nfor Imputation (CSDI), a novel time series imputation method that utilizes\nscore-based diffusion models conditioned on observed data. Unlike existing\nscore-based approaches, the conditional diffusion model is explicitly trained\nfor imputation and can exploit correlations between observed values. On\nhealthcare and environmental data, CSDI improves by 40-70% over existing\nprobabilistic imputation methods on popular performance metrics. In addition,\ndeterministic imputation by CSDI reduces the error by 5-20% compared to the\nstate-of-the-art deterministic imputation methods. Furthermore, CSDI can also\nbe applied to time series interpolation and probabilistic forecasting, and is\ncompetitive with existing baselines.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 22:20:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Tashiro", "Yusuke", ""], ["Song", "Jiaming", ""], ["Song", "Yang", ""], ["Ermon", "Stefano", ""]]}, {"id": "2107.03520", "submitter": "Mohammed S. Al-Abiad", "authors": "Mohammed S. Al-Abiad, Md. Zoheb Hassan, Md. Jahangir Hossain", "title": "Energy Efficient Federated Learning in Integrated Fog-Cloud Computing\n  Enabled Internet-of-Things Networks", "comments": "30, 10, article", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate resource allocation scheme to reduce the energy consumption of\nfederated learning (FL) in the integrated fog-cloud computing enabled\nInternet-of-things (IoT) networks. In the envisioned system, IoT devices are\nconnected with the centralized cloud server (CS) via multiple fog access points\n(F-APs). We consider two different scenarios for training the local models. In\nthe first scenario, local models are trained at the IoT devices and the F-APs\nupload the local model parameters to the CS. In the second scenario, local\nmodels are trained at the F-APs based on the collected data from the IoT\ndevices and the F-APs collaborate with the CS for updating the model\nparameters. Our objective is to minimize the overall energy-consumption of both\nscenarios subject to FL time constraint. Towards this goal, we devise a joint\noptimization of scheduling of IoT devices with the F-APs, transmit power\nallocation, computation frequency allocation at the devices and F-APs and\ndecouple it into two subproblems. In the first subproblem, we optimize the IoT\ndevice scheduling and power allocation, while in the second subproblem, we\noptimize the computation frequency allocation. For each scenario, we develop a\nconflict graph based solution to iteratively solve the two subproblems.\nSimulation results show that the proposed two schemes achieve a considerable\nperformance gain in terms of the energy consumption minimization. The presented\nsimulation results interestingly reveal that for a large number of IoT devices\nand large data sizes, it is more energy efficient to train the local models at\nthe IoT devices instead of the F-APs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 23:09:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Al-Abiad", "Mohammed S.", ""], ["Hassan", "Md. Zoheb", ""], ["Hossain", "Md. Jahangir", ""]]}, {"id": "2107.03577", "submitter": "Khalid El-Awady", "authors": "Khalid El-Awady", "title": "Adaptive Stress Testing for Adversarial Learning in a Financial\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-fin.CP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We demonstrate the use of Adaptive Stress Testing to detect and address\npotential vulnerabilities in a financial environment. We develop a simplified\nmodel for credit card fraud detection that utilizes a linear regression\nclassifier based on historical payment transaction data coupled with business\nrules. We then apply the reinforcement learning model known as Adaptive Stress\nTesting to train an agent, that can be thought of as a potential fraudster, to\nfind the most likely path to system failure -- successfully defrauding the\nsystem. We show the connection between this most likely failure path and the\nlimits of the classifier and discuss how the fraud detection system's business\nrules can be further augmented to mitigate these failure modes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 03:19:40 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["El-Awady", "Khalid", ""]]}, {"id": "2107.03588", "submitter": "Lantian Zhang", "authors": "Lantian Zhang, Yanlong Zhao, Lei Guo", "title": "Identification and Adaptation with Binary-Valued Observations under\n  Non-Persistent Excitation Condition", "comments": "11 pages, 4 figures, submitted to Automatica", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems with binary-valued observations are widely used in\ninformation industry, technology of biological pharmacy and other fields.\nThough there have been much efforts devoted to the identification of such\nsystems, most of the previous investigations are based on first-order gradient\nalgorithm which usually has much slower convergence rate than the Quasi-Newton\nalgorithm. Moreover, persistence of excitation(PE) conditions are usually\nrequired to guarantee consistent parameter estimates in the existing\nliterature, which are hard to be verified or guaranteed for feedback control\nsystems. In this paper, we propose an online projected Quasi-Newton type\nalgorithm for parameter estimation of stochastic regression models with\nbinary-valued observations and varying thresholds. By using both the stochastic\nLyapunov function and martingale estimation methods, we establish the strong\nconsistency of the estimation algorithm and provide the convergence rate, under\na signal condition which is considerably weaker than the traditional PE\ncondition and coincides with the weakest possible excitation known for the\nclassical least square algorithm of stochastic regression models. Convergence\nof adaptive predictors and their applications in adaptive control are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 03:57:50 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhang", "Lantian", ""], ["Zhao", "Yanlong", ""], ["Guo", "Lei", ""]]}, {"id": "2107.03607", "submitter": "Hrithika Dodia", "authors": "Hrithika Dodia, Himanshu Tandel, Lynette D'Mello", "title": "SpecGrav -- Detection of Gravitational Waves using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gravitational waves are ripples in the fabric of space-time that travel at\nthe speed of light. The detection of gravitational waves by LIGO is a major\nbreakthrough in the field of astronomy. Deep Learning has revolutionized many\nindustries including health care, finance and education. Deep Learning\ntechniques have also been explored for detection of gravitational waves to\novercome the drawbacks of traditional matched filtering method. However, in\nseveral researches, the training phase of neural network is very time consuming\nand hardware devices with large memory are required for the task. In order to\nreduce the extensive amount of hardware resources and time required in training\na neural network for detecting gravitational waves, we made SpecGrav. We use 2D\nConvolutional Neural Network and spectrograms of gravitational waves embedded\nin noise to detect gravitational waves from binary black hole merger and binary\nneutron star merger. The training phase of our neural network was of about just\n19 minutes on a 2GB GPU.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 05:06:34 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Dodia", "Hrithika", ""], ["Tandel", "Himanshu", ""], ["D'Mello", "Lynette", ""]]}, {"id": "2107.03620", "submitter": "Mei Wang", "authors": "Mei Wang, Jianwen Su, Zhihua Lin", "title": "Predicting Disease Progress with Imprecise Lab Test Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In existing deep learning methods, almost all loss functions assume that\nsample data values used to be predicted are the only correct ones. This\nassumption does not hold for laboratory test data. Test results are often\nwithin tolerable or imprecision ranges, with all values in the ranges\nacceptable. By considering imprecision samples, we propose an imprecision range\nloss (IR loss) method and incorporate it into Long Short Term Memory (LSTM)\nmodel for disease progress prediction. In this method, each sample in\nimprecision range space has a certain probability to be the real value,\nparticipating in the loss calculation. The loss is defined as the integral of\nthe error of each point in the impression range space. A sampling method for\nimprecision space is formulated. The continuous imprecision space is\ndiscretized, and a sequence of imprecise data sets are obtained, which is\nconvenient for gradient descent learning. A heuristic learning algorithm is\ndeveloped to learn the model parameters based on the imprecise data sets.\nExperimental results on real data show that the prediction method based on IR\nloss can provide more stable and consistent prediction result when test samples\nare generated from imprecision range.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:03:44 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Wang", "Mei", ""], ["Su", "Jianwen", ""], ["Lin", "Zhihua", ""]]}, {"id": "2107.03633", "submitter": "Hongkang Yang", "authors": "Hongkang Yang and Weinan E", "title": "Generalization Error of GAN from the Discriminator's Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generative adversarial network (GAN) is a well-known model for learning\nhigh-dimensional distributions, but the mechanism for its generalization\nability is not understood. In particular, GAN is vulnerable to the memorization\nphenomenon, the eventual convergence to the empirical distribution. We consider\na simplified GAN model with the generator replaced by a density, and analyze\nhow the discriminator contributes to generalization. We show that with early\nstopping, the generalization error measured by Wasserstein metric escapes from\nthe curse of dimensionality, despite that in the long term, memorization is\ninevitable. In addition, we present a hardness of learning result for WGAN.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:58:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yang", "Hongkang", ""], ["E", "Weinan", ""]]}, {"id": "2107.03635", "submitter": "Xuefeng Gao", "authors": "Yi Xiong, Ningyuan Chen, Xuefeng Gao, Xiang Zhou", "title": "Sublinear Regret for Learning POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the model-based undiscounted reinforcement learning for partially\nobservable Markov decision processes (POMDPs). The oracle we consider is the\noptimal policy of the POMDP with a known environment in terms of the average\nreward over an infinite horizon. We propose a learning algorithm for this\nproblem, building on spectral method-of-moments estimations for hidden Markov\nmodels, the belief error control in POMDPs and upper-confidence-bound methods\nfor online learning. We establish a regret bound of $O(T^{2/3}\\sqrt{\\log T})$\nfor the proposed learning algorithm where $T$ is the learning horizon. This is,\nto the best of our knowledge, the first algorithm achieving sublinear regret\nwith respect to our oracle for learning general POMDPs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:59:39 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 02:41:00 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Xiong", "Yi", ""], ["Chen", "Ningyuan", ""], ["Gao", "Xuefeng", ""], ["Zhou", "Xiang", ""]]}, {"id": "2107.03645", "submitter": "Leonhard Heindel", "authors": "Leonhard Heindel, Peter Hantschke and Markus K\\\"astner", "title": "A hybrid virtual sensing approach for approximating non-linear dynamic\n  system behavior using LSTM networks", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Modern Internet of Things solutions are used in a variety of different areas,\nranging from connected vehicles and healthcare to industrial applications. They\nrely on a large amount of interconnected sensors, which can lead to both\ntechnical and economical challenges. Virtual sensing techniques aim to reduce\nthe number of physical sensors in a system by using data from available\nmeasurements to estimate additional unknown quantities of interest. Successful\nmodel-based solutions include Kalman filters or the combination of finite\nelement models and modal analysis, while many data-driven methods rely on\nmachine learning algorithms. The presented hybrid virtual sensing approach\ncombines Long Short-Term Memory networks with frequency response function\nmodels in order to estimate the behavior of non-linear dynamic systems with\nmultiple input and output channels. Network training and prediction make use of\nshort signal subsequences, which are later recombined by applying a windowing\ntechnique. The frequency response function model acts as a baseline estimate\nwhich perfectly captures linear dynamic systems and is augmented by the\nnon-linear Long Short-Term Memory network following two different hybrid\nmodeling strategies. The approach is tested using a non-linear experimental\ndataset, which results from measurements of a three-component servo-hydraulic\nfatigue test bench. A variety of metrics in time and frequency domains, as well\nas fatigue strength under variable amplitudes are used to evaluate the\napproximation quality of the proposed method. In addition to virtual sensing,\nthe algorithm is also applied to a forward prediction task. Synthetic data are\nused in a separate study to estimate the prediction quality on datasets of\ndifferent size.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 07:27:33 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Heindel", "Leonhard", ""], ["Hantschke", "Peter", ""], ["K\u00e4stner", "Markus", ""]]}, {"id": "2107.03651", "submitter": "Daniel Bar-David", "authors": "Daniel Bar-David, Laura Bar-David, Yinon Shapira, Rina Leibu, Dalia\n  Dori, Ronit Schneor, Anath Fischer, Shiri Soudry", "title": "Elastic deformation of optical coherence tomography images of diabetic\n  macular edema for deep-learning models training: how far to go?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explore the clinical validity of elastic deformation of optical coherence\ntomography (OCT) images for data augmentation in the development of\ndeep-learning model for detection of diabetic macular edema (DME).\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 07:35:34 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 07:43:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bar-David", "Daniel", ""], ["Bar-David", "Laura", ""], ["Shapira", "Yinon", ""], ["Leibu", "Rina", ""], ["Dori", "Dalia", ""], ["Schneor", "Ronit", ""], ["Fischer", "Anath", ""], ["Soudry", "Shiri", ""]]}, {"id": "2107.03653", "submitter": "Nikhil Pratap Ghanathe", "authors": "Nikhil Pratap Ghanathe, Vivek Seshadri, Rahul Sharma, Steve Wilton,\n  Aayan Kumar", "title": "MAFIA: Machine Learning Acceleration on FPGAs for IoT Applications", "comments": "Accepted at The International Conference on Field-Programmable Logic\n  and Applications (FPL), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent breakthroughs in ML have produced new classes of models that allow ML\ninference to run directly on milliwatt-powered IoT devices. On one hand,\nexisting ML-to-FPGA compilers are designed for deep neural-networks on large\nFPGAs. On the other hand, general-purpose HLS tools fail to exploit properties\nspecific to ML inference, thereby resulting in suboptimal performance. We\npropose MAFIA, a tool to compile ML inference on small form-factor FPGAs for\nIoT applications. MAFIA provides native support for linear algebra operations\nand can express a variety of ML algorithms, including state-of-the-art models.\nWe show that MAFIA-generated programs outperform best-performing variant of a\ncommercial HLS compiler by 2.5x on average.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 07:38:23 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ghanathe", "Nikhil Pratap", ""], ["Seshadri", "Vivek", ""], ["Sharma", "Rahul", ""], ["Wilton", "Steve", ""], ["Kumar", "Aayan", ""]]}, {"id": "2107.03673", "submitter": "Lulu Zhang", "authors": "Lulu Zhang, Tao Luo, Yaoyu Zhang, Zhi-Qin John Xu, Zheng Ma", "title": "MOD-Net: A Machine Learning Approach via Model-Operator-Data Network for\n  Solving PDEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a model-operator-data network (MOD-Net) for solving\nPDEs. A MOD-Net is driven by a model to solve PDEs based on operator\nrepresentation with regularization from data. In this work, we use a deep\nneural network to parameterize the Green's function. The empirical risk\nconsists of the mean square of the governing equation, boundary conditions, and\na few labels, which are numerically computed by traditional schemes on coarse\ngrid points with cheap computation cost. With only the labeled dataset or only\nthe model constraints, it is insufficient to accurately train a MOD-Net for\ncomplicate problems. Intuitively, the labeled dataset works as a regularization\nin addition to the model constraints. The MOD-Net is much efficient than\noriginal neural operator because the MOD-Net also uses the information of\ngoverning equation and the boundary conditions of the PDE rather than purely\nthe expensive labels. Since the MOD-Net learns the Green's function of a PDE,\nit solves a type of PDEs but not a specific case. We numerically show MOD-Net\nis very efficient in solving Poisson equation and one-dimensional Boltzmann\nequation. For non-linear PDEs, where the concept of the Green's function does\nnot apply, the non-linear MOD-Net can be similarly used as an ansatz for\nsolving non-linear PDEs.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 08:26:46 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhang", "Lulu", ""], ["Luo", "Tao", ""], ["Zhang", "Yaoyu", ""], ["Xu", "Zhi-Qin John", ""], ["Ma", "Zheng", ""]]}, {"id": "2107.03690", "submitter": "Michael A. Hedderich", "authors": "Michael A. Hedderich, Benjamin Roth, Katharina Kann, Barbara Plank,\n  Alex Ratner and Dietrich Klakow", "title": "Proceedings of the First Workshop on Weakly Supervised Learning (WeaSuL)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Welcome to WeaSuL 2021, the First Workshop on Weakly Supervised Learning,\nco-located with ICLR 2021. In this workshop, we want to advance theory, methods\nand tools for allowing experts to express prior coded knowledge for automatic\ndata annotations that can be used to train arbitrary deep neural networks for\nprediction. The ICLR 2021 Workshop on Weak Supervision aims at advancing\nmethods that help modern machine-learning methods to generalize from knowledge\nprovided by experts, in interaction with observable (unlabeled) data. In total,\n15 papers were accepted. All the accepted contributions are listed in these\nProceedings.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:06:13 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Hedderich", "Michael A.", ""], ["Roth", "Benjamin", ""], ["Kann", "Katharina", ""], ["Plank", "Barbara", ""], ["Ratner", "Alex", ""], ["Klakow", "Dietrich", ""]]}, {"id": "2107.03704", "submitter": "Mohamad Wehbi", "authors": "Mohamad Wehbi, Tim Hamann, Jens Barth, Bjoern Eskofier", "title": "Digitizing Handwriting with a Sensor Pen: A Writer-Independent\n  Recognizer", "comments": "Published in 2020 17th International Conference on Frontiers in\n  Handwriting Recognition (ICFHR)", "journal-ref": null, "doi": "10.1109/ICFHR2020.2020.00061", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online handwriting recognition has been studied for a long time with only few\npracticable results when writing on normal paper. Previous approaches using\nsensor-based devices encountered problems that limited the usage of the\ndeveloped systems in real-world applications. This paper presents a\nwriter-independent system that recognizes characters written on plain paper\nwith the use of a sensor-equipped pen. This system is applicable in real-world\napplications and requires no user-specific training for recognition. The pen\nprovides linear acceleration, angular velocity, magnetic field, and force\napplied by the user, and acts as a digitizer that transforms the analogue\nsignals of the sensors into timeseries data while writing on regular paper. The\ndataset we collected with this pen consists of Latin lower-case and upper-case\nalphabets. We present the results of a convolutional neural network model for\nletter classification and show that this approach is practical and achieves\npromising results for writer-independent character recognition. This work aims\nat providing a realtime handwriting recognition system to be used for writing\non normal paper.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:25:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Wehbi", "Mohamad", ""], ["Hamann", "Tim", ""], ["Barth", "Jens", ""], ["Eskofier", "Bjoern", ""]]}, {"id": "2107.03719", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Benedikt Staffler, Arber Zela, Jan Hendrik Metzen,\n  Frank Hutter", "title": "Bag of Tricks for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While neural architecture search methods have been successful in previous\nyears and led to new state-of-the-art performance on various problems, they\nhave also been criticized for being unstable, being highly sensitive with\nrespect to their hyperparameters, and often not performing better than random\nsearch. To shed some light on this issue, we discuss some practical\nconsiderations that help improve the stability, efficiency and overall\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:57:39 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Elsken", "Thomas", ""], ["Staffler", "Benedikt", ""], ["Zela", "Arber", ""], ["Metzen", "Jan Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "2107.03729", "submitter": "Debasish Kundu", "authors": "Kundu, Debasish", "title": "The Three Ensemble Clustering (3EC) Algorithm for Pattern Discovery in\n  Unsupervised Learning", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a multiple learner algorithm called the 'Three Ensemble\nClustering 3EC' algorithm that classifies unlabeled data into quality clusters\nas a part of unsupervised learning. It offers the flexibility to explore the\ncontext of new clusters formed by an ensemble of algorithms based on internal\nvalidation indices.\n  It is worth mentioning that the input data set is considered to be a cluster\nof clusters. An anomaly can possibly manifest as a cluster as well. Each\npartitioned cluster is considered to be a new data set and is a candidate to\nexplore the most optimal algorithm and its number of partition splits until a\npredefined stopping criteria is met. The algorithms independently partition the\ndata set into clusters and the quality of the partitioning is assessed by an\nensemble of internal cluster validation indices. The 3EC algorithm presents the\nvalidation index scores from a choice of algorithms and its configuration of\npartitions and it is called the Tau Grid. 3EC chooses the most optimal score.\nThe 3EC algorithm owes its name to the two input ensembles of algorithms and\ninternal validation indices and an output ensemble of final clusters.\n  Quality plays an important role in this clustering approach and it also acts\nas a stopping criteria from further partitioning. Quality is determined based\non the quality of the clusters provided by an algorithm and its optimal number\nof splits. The 3EC algorithm determines this from the score of the ensemble of\nvalidation indices. The user can configure the stopping criteria by providing\nquality thresholds for the score range of each of the validation indices and\nthe optimal size of the output cluster. The users can experiment with different\nsets of stopping criteria and choose the most 'sensible group' of quality\nclusters\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:15:18 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kundu", "", ""], ["Debasish", "", ""]]}, {"id": "2107.03730", "submitter": "Arber Qoku", "authors": "Arber Qoku and Florian Buettner", "title": "Encoding Domain Information with Sparse Priors for Inferring Explainable\n  Latent Variables", "comments": "5 pages, 6 figures, Joint KDD 2021 Health Day and 2021 KDD Workshop\n  on Applied Data Science for Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Latent variable models are powerful statistical tools that can uncover\nrelevant variation between patients or cells, by inferring unobserved hidden\nstates from observable high-dimensional data. A major shortcoming of current\nmethods, however, is their inability to learn sparse and interpretable hidden\nstates. Additionally, in settings where partial knowledge on the latent\nstructure of the data is readily available, a statistically sound integration\nof prior information into current methods is challenging. To address these\nissues, we propose spex-LVM, a factorial latent variable model with sparse\npriors to encourage the inference of explainable factors driven by\ndomain-relevant information. spex-LVM utilizes existing knowledge of curated\nbiomedical pathways to automatically assign annotated attributes to latent\nfactors, yielding interpretable results tailored to the corresponding domain of\ninterest. Evaluations on simulated and real single-cell RNA-seq datasets\ndemonstrate that our model robustly identifies relevant structure in an\ninherently explainable manner, distinguishes technical noise from sources of\nbiomedical variation, and provides dataset-specific adaptations of existing\npathway annotations. Implementation is available at\nhttps://github.com/MLO-lab/spexlvm.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:19:32 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Qoku", "Arber", ""], ["Buettner", "Florian", ""]]}, {"id": "2107.03738", "submitter": "Stefanos Papanikolaou", "authors": "Stefanos Papanikolaou and Mikko J. Alava", "title": "Direct detection of plasticity onset through total-strain profile\n  evolution", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cond-mat.mes-hall cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plastic yielding in solids strongly depends on various conditions, such as\ntemperature and loading rate and indeed, sample-dependent knowledge of yield\npoints in structural materials promotes reliability in mechanical behavior.\nCommonly, yielding is measured through controlled mechanical testing at small\nor large scales, in ways that either distinguish elastic (stress) from total\ndeformation measurements, or by identifying plastic slip contributions. In this\npaper we argue that instead of separate elastic/plastic measurements, yielding\ncan be unraveled through statistical analysis of total strain fluctuations\nduring the evolution sequence of profiles measured in-situ, through digital\nimage correlation. We demonstrate two distinct ways of precisely quantifying\nyield locations in widely applicable crystal plasticity models, that apply in\npolycrystalline solids, either by using principal component analysis or\ndiscrete wavelet transforms. We test and compare these approaches in synthetic\ndata of polycrystal simulations and a variety of yielding responses, through\nchanges of the applied loading rates and the strain-rate sensitivity exponents.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:32:41 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Papanikolaou", "Stefanos", ""], ["Alava", "Mikko J.", ""]]}, {"id": "2107.03741", "submitter": "Arsen Kuzhamuratov", "authors": "Arsen Kuzhamuratov, Dmitry Sorokin, Alexander Ulanov, A. I. Lvovsky", "title": "Adaptation of Quadruped Robot Locomotion with Meta-Learning", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Animals have remarkable abilities to adapt locomotion to different terrains\nand tasks. However, robots trained by means of reinforcement learning are\ntypically able to solve only a single task and a transferred policy is usually\ninferior to that trained from scratch. In this work, we demonstrate that\nmeta-reinforcement learning can be used to successfully train a robot capable\nto solve a wide range of locomotion tasks. The performance of the meta-trained\nrobot is similar to that of a robot that is trained on a single task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:37:18 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kuzhamuratov", "Arsen", ""], ["Sorokin", "Dmitry", ""], ["Ulanov", "Alexander", ""], ["Lvovsky", "A. I.", ""]]}, {"id": "2107.03742", "submitter": "Nikolay Jetchev", "authors": "Nikolay Jetchev, G\\\"okhan Yildirim, Christian Bracher, Roland Vollgraf", "title": "Grid Partitioned Attention: Efficient TransformerApproximation with\n  Inductive Bias for High Resolution Detail Generation", "comments": "code available at https://github.com/zalandoresearch/gpa", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention is a general reasoning mechanism than can flexibly deal with image\ninformation, but its memory requirements had made it so far impractical for\nhigh resolution image generation. We present Grid Partitioned Attention (GPA),\na new approximate attention algorithm that leverages a sparse inductive bias\nfor higher computational and memory efficiency in image domains: queries attend\nonly to few keys, spatially close queries attend to close keys due to\ncorrelations. Our paper introduces the new attention layer, analyzes its\ncomplexity and how the trade-off between memory usage and model power can be\ntuned by the hyper-parameters.We will show how such attention enables novel\ndeep learning architectures with copying modules that are especially useful for\nconditional image generation tasks like pose morphing. Our contributions are\n(i) algorithm and code1of the novel GPA layer, (ii) a novel deep\nattention-copying architecture, and (iii) new state-of-the art experimental\nresults in human pose morphing generation benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:37:23 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Jetchev", "Nikolay", ""], ["Yildirim", "G\u00f6khan", ""], ["Bracher", "Christian", ""], ["Vollgraf", "Roland", ""]]}, {"id": "2107.03743", "submitter": "Kashif Rasul", "authors": "Ad\\`ele Gouttes, Kashif Rasul, Mateusz Koren, Johannes Stephan, Tofigh\n  Naghibi", "title": "Probabilistic Time Series Forecasting with Implicit Quantile Networks", "comments": "Accepted at the ICML 2021 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here, we propose a general method for probabilistic time series forecasting.\nWe combine an autoregressive recurrent neural network to model temporal\ndynamics with Implicit Quantile Networks to learn a large class of\ndistributions over a time-series target. When compared to other probabilistic\nneural forecasting models on real- and simulated data, our approach is\nfavorable in terms of point-wise prediction accuracy as well as on estimating\nthe underlying temporal distribution.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:37:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gouttes", "Ad\u00e8le", ""], ["Rasul", "Kashif", ""], ["Koren", "Mateusz", ""], ["Stephan", "Johannes", ""], ["Naghibi", "Tofigh", ""]]}, {"id": "2107.03759", "submitter": "Luong-Ha Nguyen", "authors": "Luong-Ha Nguyen and James-A. Goulet", "title": "Analytically Tractable Hidden-States Inference in Bayesian Neural\n  Networks", "comments": "37 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With few exceptions, neural networks have been relying on backpropagation and\ngradient descent as the inference engine in order to learn the model\nparameters, because the closed-form Bayesian inference for neural networks has\nbeen considered to be intractable. In this paper, we show how we can leverage\nthe tractable approximate Gaussian inference's (TAGI) capabilities to infer\nhidden states, rather than only using it for inferring the network's\nparameters. One novel aspect it allows is to infer hidden states through the\nimposition of constraints designed to achieve specific objectives, as\nillustrated through three examples: (1) the generation of adversarial-attack\nexamples, (2) the usage of a neural network as a black-box optimization method,\nand (3) the application of inference on continuous-action reinforcement\nlearning. These applications showcase how tasks that were previously reserved\nto gradient-based optimization approaches can now be approached with\nanalytically tractable inference\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:11:25 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nguyen", "Luong-Ha", ""], ["Goulet", "James-A.", ""]]}, {"id": "2107.03769", "submitter": "Martin Knoche", "authors": "Martin Knoche, Stefan H\\\"ormann, Gerhard Rigoll", "title": "Image Resolution Susceptibility of Face Recognition Models", "comments": "19 pages, 15 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition approaches often rely on equal image resolution for\nverification faces on two images. However, in practical applications, those\nimage resolutions are usually not in the same range due to different image\ncapture mechanisms or sources. In this work, we first analyze the impact of\nimage resolutions on the face verification performance with a state-of-the-art\nface recognition model. For images, synthetically reduced to $5\\, \\times 5\\,\n\\mathrm{px}$ resolution, the verification performance drops from $99.23\\%$\nincreasingly down to almost $55\\%$. Especially, for cross-resolution image\npairs (one high- and one low-resolution image), the verification accuracy\ndecreases even further. We investigate this behavior more in-depth by looking\nat the feature distances for every 2-image test pair. To tackle this problem,\nwe propose the following two methods: 1) Train a state-of-the-art\nface-recognition model straightforward with $50\\%$ low-resolution images\ndirectly within each batch. \\\\ 2) Train a siamese-network structure and adding\na cosine distance feature loss between high- and low-resolution features. Both\nmethods show an improvement for cross-resolution scenarios and can increase the\naccuracy at very low resolution to approximately $70\\%$. However, a\ndisadvantage is that a specific model needs to be trained for every\nresolution-pair ...\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:30:27 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Knoche", "Martin", ""], ["H\u00f6rmann", "Stefan", ""], ["Rigoll", "Gerhard", ""]]}, {"id": "2107.03770", "submitter": "Arash Mehrjou", "authors": "Arash Mehrjou", "title": "Federated Learning as a Mean-Field Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.OC math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We establish a connection between federated learning, a concept from machine\nlearning, and mean-field games, a concept from game theory and control theory.\nIn this analogy, the local federated learners are considered as the players and\nthe aggregation of the gradients in a central server is the mean-field effect.\nWe present federated learning as a differential game and discuss the properties\nof the equilibrium of this game. We hope this novel view to federated learning\nbrings together researchers from these two distinct areas to work on\nfundamental problems of large-scale distributed and privacy-preserving learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:31:51 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mehrjou", "Arash", ""]]}, {"id": "2107.03774", "submitter": "Jos\\'e Cano", "authors": "Martina Lofqvist, Jos\\'e Cano", "title": "Optimizing Data Processing in Space for Object Detection in Satellite\n  Imagery", "comments": "Published as a workshop paper at SmallSat 2021 - The 35th Annual\n  Small Satellite Conference. 9 pages, 10 figures. arXiv admin note: text\n  overlap with arXiv:2007.11089", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a proliferation in the number of satellites launched each year,\nresulting in downlinking of terabytes of data each day. The data received by\nground stations is often unprocessed, making this an expensive process\nconsidering the large data sizes and that not all of the data is useful. This,\ncoupled with the increasing demand for real-time data processing, has led to a\ngrowing need for on-orbit processing solutions. In this work, we investigate\nthe performance of CNN-based object detectors on constrained devices by\napplying different image compression techniques to satellite data. We examine\nthe capabilities of the NVIDIA Jetson Nano and NVIDIA Jetson AGX Xavier;\nlow-power, high-performance computers, with integrated GPUs, small enough to\nfit on-board a nanosatellite. We take a closer look at object detection\nnetworks, including the Single Shot MultiBox Detector (SSD) and Region-based\nFully Convolutional Network (R-FCN) models that are pre-trained on DOTA - a\nLarge Scale Dataset for Object Detection in Aerial Images. The performance is\nmeasured in terms of execution time, memory consumption, and accuracy, and are\ncompared against a baseline containing a server with two powerful GPUs. The\nresults show that by applying image compression techniques, we are able to\nimprove the execution time and memory consumption, achieving a fully runnable\ndataset. A lossless compression technique achieves roughly a 10% reduction in\nexecution time and about a 3% reduction in memory consumption, with no impact\non the accuracy. While a lossy compression technique improves the execution\ntime by up to 144% and the memory consumption is reduced by as much as 97%.\nHowever, it has a significant impact on accuracy, varying depending on the\ncompression ratio. Thus the application and ratio of these compression\ntechniques may differ depending on the required level of accuracy for a\nparticular task.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:37:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lofqvist", "Martina", ""], ["Cano", "Jos\u00e9", ""]]}, {"id": "2107.03786", "submitter": "Xingtai Gui", "authors": "Xingtai Gui, Jiyang Zhang", "title": "Deep Metric Learning Model for Imbalanced Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent diagnosis method based on data-driven and deep learning is an\nattractive and meaningful field in recent years. However, in practical\napplication scenarios, the imbalance of time-series fault is an urgent problem\nto be solved. This paper proposes a novel deep metric learning model, where\nimbalanced fault data and a quadruplet data pair design manner are considered.\nBased on such data pair, a quadruplet loss function which takes into account\nthe inter-class distance and the intra-class data distribution are proposed.\nThis quadruplet loss pays special attention to imbalanced sample pair. The\nreasonable combination of quadruplet loss and softmax loss function can reduce\nthe impact of imbalance. Experiment results on two open-source datasets show\nthat the proposed method can effectively and robustly improve the performance\nof imbalanced fault diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:56:41 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 07:46:54 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Gui", "Xingtai", ""], ["Zhang", "Jiyang", ""]]}, {"id": "2107.03806", "submitter": "Daniel Park", "authors": "Daniel Park, Haidar Khan, Azer Khan, Alex Gittens, B\\\"ulent Yener", "title": "Output Randomization: A Novel Defense for both White-box and Black-box\n  Adversarial Models", "comments": "This is a substantially changed version of an earlier preprint\n  (arXiv:1905.09871)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples pose a threat to deep neural network models in a variety\nof scenarios, from settings where the adversary has complete knowledge of the\nmodel in a \"white box\" setting and to the opposite in a \"black box\" setting. In\nthis paper, we explore the use of output randomization as a defense against\nattacks in both the black box and white box models and propose two defenses. In\nthe first defense, we propose output randomization at test time to thwart\nfinite difference attacks in black box settings. Since this type of attack\nrelies on repeated queries to the model to estimate gradients, we investigate\nthe use of randomization to thwart such adversaries from successfully creating\nadversarial examples. We empirically show that this defense can limit the\nsuccess rate of a black box adversary using the Zeroth Order Optimization\nattack to 0%. Secondly, we propose output randomization training as a defense\nagainst white box adversaries. Unlike prior approaches that use randomization,\nour defense does not require its use at test time, eliminating the Backward\nPass Differentiable Approximation attack, which was shown to be effective\nagainst other randomization defenses. Additionally, this defense has low\noverhead and is easily implemented, allowing it to be used together with other\ndefenses across various model architectures. We evaluate output randomization\ntraining against the Projected Gradient Descent attacker and show that the\ndefense can reduce the PGD attack's success rate down to 12% when using\ncross-entropy loss.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:27:19 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Park", "Daniel", ""], ["Khan", "Haidar", ""], ["Khan", "Azer", ""], ["Gittens", "Alex", ""], ["Yener", "B\u00fclent", ""]]}, {"id": "2107.03815", "submitter": "Zhao Zhong", "authors": "Yikang Zhang, Zhuo Chen, Zhao Zhong", "title": "Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with\n  100M FLOPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Collaboration of Experts (CoE) framework to pool\ntogether the expertise of multiple networks towards a common aim. Each expert\nis an individual network with expertise on a unique portion of the dataset,\nwhich enhances the collective capacity. Given a sample, an expert is selected\nby the delegator, which simultaneously outputs a rough prediction to support\nearly termination. To fulfill this framework, we propose three modules to impel\neach model to play its role, namely weight generation module (WGM), label\ngeneration module (LGM) and variance calculation module (VCM). Our method\nachieves the state-of-the-art performance on ImageNet, 80.7% top-1 accuracy\nwith 194M FLOPs. Combined with PWLU activation function and CondConv, CoE\nfurther achieves the accuracy of 80.0% with only 100M FLOPs for the first time.\nMore importantly, our method is hardware friendly and achieves a 3-6x speedup\ncompared with some existing conditional computation approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:44:41 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zhang", "Yikang", ""], ["Chen", "Zhuo", ""], ["Zhong", "Zhao", ""]]}, {"id": "2107.03825", "submitter": "Argyrios Vartholomaios", "authors": "Argyrios Vartholomaios, Stamatis Karlos, Eleftherios Kouloumpris,\n  Grigorios Tsoumakas", "title": "Short-term Renewable Energy Forecasting in Greece using Prophet\n  Decomposition and Tree-based Ensembles", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Energy production using renewable sources exhibits inherent uncertainties due\nto their intermittent nature. Nevertheless, the unified European energy market\npromotes the increasing penetration of renewable energy sources (RES) by the\nregional energy system operators. Consequently, RES forecasting can assist in\nthe integration of these volatile energy sources, since it leads to higher\nreliability and reduced ancillary operational costs for power systems. This\npaper presents a new dataset for solar and wind energy generation forecast in\nGreece and introduces a feature engineering pipeline that enriches the\ndimensional space of the dataset. In addition, we propose a novel method that\nutilizes the innovative Prophet model, an end-to-end forecasting tool that\nconsiders several kinds of nonlinear trends in decomposing the energy time\nseries before a tree-based ensemble provides short-term predictions. The\nperformance of the system is measured through representative evaluation\nmetrics, and by estimating the model's generalization under an industryprovided\nscheme of absolute error thresholds. The proposed hybrid model competes with\nbaseline persistence models, tree-based regression ensembles, and the Prophet\nmodel, managing to outperform them, presenting both lower error rates and more\nfavorable error distribution.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:12:35 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Vartholomaios", "Argyrios", ""], ["Karlos", "Stamatis", ""], ["Kouloumpris", "Eleftherios", ""], ["Tsoumakas", "Grigorios", ""]]}, {"id": "2107.03836", "submitter": "John Lazarsfeld", "authors": "John Lazarsfeld and Aaron Johnson", "title": "Consistency of the Maximal Information Coefficient Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Maximal Information Coefficient (MIC) of Reshef et al. (Science, 2011) is\na statistic for measuring dependence between variable pairs in large datasets.\nIn this note, we prove that MIC is a consistent estimator of the corresponding\npopulation statistic MIC$_*$. This corrects an error in an argument of Reshef\net al. (JMLR, 2016), which we describe.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:28:06 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Lazarsfeld", "John", ""], ["Johnson", "Aaron", ""]]}, {"id": "2107.03844", "submitter": "Firoj Alam", "authors": "Firoj Alam, Arid Hasan, Tanvirul Alam, Akib Khan, Janntatul Tajrin,\n  Naira Khan, Shammur Absar Chowdhury", "title": "A Review of Bangla Natural Language Processing Tasks and the Utility of\n  Transformer Models", "comments": "Under Review, Bangla language processing, text classification,\n  sequence tagging, datasets, benchmarks, transformer models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bangla -- ranked as the 6th most widely spoken language across the world\n(https://www.ethnologue.com/guides/ethnologue200), with 230 million native\nspeakers -- is still considered as a low-resource language in the natural\nlanguage processing (NLP) community. With three decades of research, Bangla NLP\n(BNLP) is still lagging behind mainly due to the scarcity of resources and the\nchallenges that come with it. There is sparse work in different areas of BNLP;\nhowever, a thorough survey reporting previous work and recent advances is yet\nto be done. In this study, we first provide a review of Bangla NLP tasks,\nresources, and tools available to the research community; we benchmark datasets\ncollected from various platforms for nine NLP tasks using current\nstate-of-the-art algorithms (i.e., transformer-based models). We provide\ncomparative results for the studied NLP tasks by comparing monolingual vs.\nmultilingual models of varying sizes. We report our results using both\nindividual and consolidated datasets and provide data splits for future\nresearch. We reviewed a total of 108 papers and conducted 175 sets of\nexperiments. Our results show promising performance using transformer-based\nmodels while highlighting the trade-off with computational costs. We hope that\nsuch a comprehensive survey will motivate the community to build on and further\nadvance the research on Bangla NLP.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:49:46 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 06:43:33 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 05:41:15 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Alam", "Firoj", ""], ["Hasan", "Arid", ""], ["Alam", "Tanvirul", ""], ["Khan", "Akib", ""], ["Tajrin", "Janntatul", ""], ["Khan", "Naira", ""], ["Chowdhury", "Shammur Absar", ""]]}, {"id": "2107.03846", "submitter": "Lucas Fidon", "authors": "Lucas Fidon, Michael Aertsen, Doaa Emam, Nada Mufti, Fr\\'ed\\'eric\n  Guffens, Thomas Deprest, Philippe Demaerel, Anna L. David, Andrew Melbourne,\n  S\\'ebastien Ourselin, Jan Deprest, Tom Vercauteren", "title": "Label-set Loss Functions for Partial Supervision: Application to Fetal\n  Brain 3D MRI Parcellation", "comments": "Accepted at MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have increased the accuracy of automatic segmentation,\nhowever, their accuracy depends on the availability of a large number of fully\nsegmented images. Methods to train deep neural networks using images for which\nsome, but not all, regions of interest are segmented are necessary to make\nbetter use of partially annotated datasets. In this paper, we propose the first\naxiomatic definition of label-set loss functions that are the loss functions\nthat can handle partially segmented images. We prove that there is one and only\none method to convert a classical loss function for fully segmented images into\na proper label-set loss function. Our theory also allows us to define the\nleaf-Dice loss, a label-set generalization of the Dice loss particularly suited\nfor partial supervision with only missing labels. Using the leaf-Dice loss, we\nset a new state of the art in partially supervised learning for fetal brain 3D\nMRI segmentation. We achieve a deep neural network able to segment white\nmatter, ventricles, cerebellum, extra-ventricular CSF, cortical gray matter,\ndeep gray matter, brainstem, and corpus callosum based on fetal brain 3D MRI of\nanatomically normal fetuses or with open spina bifida. Our implementation of\nthe proposed label-set loss functions is available at\nhttps://github.com/LucasFidon/label-set-loss-functions\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:53:56 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 15:44:06 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Fidon", "Lucas", ""], ["Aertsen", "Michael", ""], ["Emam", "Doaa", ""], ["Mufti", "Nada", ""], ["Guffens", "Fr\u00e9d\u00e9ric", ""], ["Deprest", "Thomas", ""], ["Demaerel", "Philippe", ""], ["David", "Anna L.", ""], ["Melbourne", "Andrew", ""], ["Ourselin", "S\u00e9bastien", ""], ["Deprest", "Jan", ""], ["Vercauteren", "Tom", ""]]}, {"id": "2107.03851", "submitter": "Andrew Jaegle", "authors": "Andrew Jaegle, Yury Sulsky, Arun Ahuja, Jake Bruce, Rob Fergus, Greg\n  Wayne", "title": "Imitation by Predicting Observations", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning enables agents to reuse and adapt the hard-won expertise\nof others, offering a solution to several key challenges in learning behavior.\nAlthough it is easy to observe behavior in the real-world, the underlying\nactions may not be accessible. We present a new method for imitation solely\nfrom observations that achieves comparable performance to experts on\nchallenging continuous control tasks while also exhibiting robustness in the\npresence of observations unrelated to the task. Our method, which we call FORM\n(for \"Future Observation Reward Model\") is derived from an inverse RL objective\nand imitates using a model of expert behavior learned by generative modelling\nof the expert's observations, without needing ground truth actions. We show\nthat FORM performs comparably to a strong baseline IRL method (GAIL) on the\nDeepMind Control Suite benchmark, while outperforming GAIL in the presence of\ntask-irrelevant features.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:09:30 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Jaegle", "Andrew", ""], ["Sulsky", "Yury", ""], ["Ahuja", "Arun", ""], ["Bruce", "Jake", ""], ["Fergus", "Rob", ""], ["Wayne", "Greg", ""]]}, {"id": "2107.03852", "submitter": "Shashidhar Kudari KUDARI", "authors": "Shashidhar Veerappa Kudari, Akshaykumar Gunari, Adarsh Jamadandi,\n  Ramesh Ashok Tabib, Uma Mudenagudi", "title": "Augmented Data as an Auxiliary Plug-in Towards Categorization of\n  Crowdsourced Heritage Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a strategy to mitigate the problem of inefficient\nclustering performance by introducing data augmentation as an auxiliary\nplug-in. Classical clustering techniques such as K-means, Gaussian mixture\nmodel and spectral clustering are central to many data-driven applications.\nHowever, recently unsupervised simultaneous feature learning and clustering\nusing neural networks also known as Deep Embedded Clustering (DEC) has gained\nprominence. Pioneering works on deep feature clustering focus on defining\nrelevant clustering loss function and choosing the right neural network for\nextracting features. A central problem in all these cases is data sparsity\naccompanied by high intra-class and low inter-class variance, which\nsubsequently leads to poor clustering performance and erroneous candidate\nassignments. Towards this, we employ data augmentation techniques to improve\nthe density of the clusters, thus improving the overall performance. We train a\nvariant of Convolutional Autoencoder (CAE) with augmented data to construct the\ninitial feature space as a novel model for deep clustering. We demonstrate the\nresults of proposed strategy on crowdsourced Indian Heritage dataset. Extensive\nexperiments show consistent improvements over existing works.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:09:39 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kudari", "Shashidhar Veerappa", ""], ["Gunari", "Akshaykumar", ""], ["Jamadandi", "Adarsh", ""], ["Tabib", "Ramesh Ashok", ""], ["Mudenagudi", "Uma", ""]]}, {"id": "2107.03860", "submitter": "Alexandra Peste", "authors": "Alexandra Peste, Dan Alistarh, Christoph H. Lampert", "title": "SSSE: Efficiently Erasing Samples from Trained Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of large amounts of user-provided data has been key to the\nsuccess of machine learning for many real-world tasks. Recently, an increasing\nawareness has emerged that users should be given more control about how their\ndata is used. In particular, users should have the right to prohibit the use of\ntheir data for training machine learning systems, and to have it erased from\nalready trained systems. While several sample erasure methods have been\nproposed, all of them have drawbacks which have prevented them from gaining\nwidespread adoption. Most methods are either only applicable to very specific\nfamilies of models, sacrifice too much of the original model's accuracy, or\nthey have prohibitive memory or computational requirements. In this paper, we\npropose an efficient and effective algorithm, SSSE, for samples erasure, that\nis applicable to a wide class of machine learning models. From a second-order\nanalysis of the model's loss landscape we derive a closed-form update step of\nthe model parameters that only requires access to the data to be erased, not to\nthe original training set. Experiments on three datasets, CelebFaces attributes\n(CelebA), Animals with Attributes 2 (AwA2) and CIFAR10, show that in certain\ncases SSSE can erase samples almost as well as the optimal, yet impractical,\ngold standard of training a new model from scratch with only the permitted\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:17:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Peste", "Alexandra", ""], ["Alistarh", "Dan", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2107.03863", "submitter": "Felix Leopoldo Rios", "authors": "Felix L. Rios, Giusi Moffa, Jack Kuipers", "title": "Benchpress: a scalable and platform-independent workflow for\n  benchmarking structure learning algorithms for graphical models", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Describing the relationship between the variables in a study domain and\nmodelling the data generating mechanism is a fundamental problem in many\nempirical sciences. Probabilistic graphical models are one common approach to\ntackle the problem. Learning the graphical structure is computationally\nchallenging and a fervent area of current research with a plethora of\nalgorithms being developed. To facilitate the benchmarking of different\nmethods, we present a novel automated workflow, called benchpress for producing\nscalable, reproducible, and platform-independent benchmarks of structure\nlearning algorithms for probabilistic graphical models. Benchpress is\ninterfaced via a simple JSON-file, which makes it accessible for all users,\nwhile the code is designed in a fully modular fashion to enable researchers to\ncontribute additional methodologies. Benchpress currently provides an interface\nto a large number of state-of-the-art algorithms from libraries such as BiDAG,\nbnlearn, GOBNILP, pcalg, r.blip, scikit-learn, TETRAD, and trilearn as well as\na variety of methods for data generating models and performance evaluation.\nAlongside user-defined models and randomly generated datasets, the software\ntool also includes a number of standard datasets and graphical models from the\nliterature, which may be included in a benchmarking workflow. We demonstrate\nthe applicability of this workflow for learning Bayesian networks in four\ntypical data scenarios. The source code and documentation is publicly available\nfrom http://github.com/felixleopoldo/benchpress.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:19:28 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Rios", "Felix L.", ""], ["Moffa", "Giusi", ""], ["Kuipers", "Jack", ""]]}, {"id": "2107.03869", "submitter": "Ahmad Kamal Bin Mohd Nor", "authors": "Ahmad Kamal BIN MOHD NOR, Srinivasa Rao PEDAPATI, Masdi MUHAMMAD", "title": "Explainable AI (XAI) for PHM of Industrial Asset: A State-of-The-Art,\n  PRISMA-Compliant Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A state-of-the-art systematic review on XAI applied to Prognostic and Health\nManagement (PHM) of industrial asset is presented. The work attempts to provide\nan overview of the general trend of XAI in PHM, answers the question of\naccuracy versus explainability, investigates the extent of human role,\nexplainability evaluation and uncertainty management in PHM XAI. Research\narticles linked to PHM XAI, in English language, from 2015 to 2021 are selected\nfrom IEEE Xplore, ScienceDirect, SpringerLink, ACM Digital Library and Scopus\ndatabases using PRISMA guidelines. Data was extracted from 35 selected articles\nand examined using MS. Excel. Several findings were synthesized. Firstly, while\nthe discipline is still young, the analysis indicates the growing acceptance of\nXAI in PHM domain. Secondly, XAI functions as a double edge sword, where it is\nassimilated as a tool to execute PHM tasks as well as a mean of explanation, in\nparticular in diagnostic and anomaly detection. There is thus a need for XAI in\nPHM. Thirdly, the review shows that PHM XAI papers produce either good or\nexcellent results in general, suggesting that PHM performance is unaffected by\nXAI. Fourthly, human role, explainability metrics and uncertainty management\nare areas requiring further attention by the PHM community. Adequate\nexplainability metrics to cater for PHM need are urgently needed. Finally, most\ncase study featured on the accepted articles are based on real, indicating that\navailable AI and XAI approaches are equipped to solve complex real-world\nchallenges, increasing the confidence of AI model adoption in the industry.\nThis work is funded by the Universiti Teknologi Petronas Foundation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:22:32 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["NOR", "Ahmad Kamal BIN MOHD", ""], ["PEDAPATI", "Srinivasa Rao", ""], ["MUHAMMAD", "Masdi", ""]]}, {"id": "2107.03876", "submitter": "Artem Polyvyanyy", "authors": "Artem Polyvyanyy, Alistair Moffat, Luciano Garc\\'ia-Ba\\~nuelos", "title": "Bootstrapping Generalization of Process Models Discovered From Event\n  Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Process mining studies ways to derive value from process executions recorded\nin event logs of IT-systems, with process discovery the task of inferring a\nprocess model for an event log emitted by some unknown system. One quality\ncriterion for discovered process models is generalization. Generalization seeks\nto quantify how well the discovered model describes future executions of the\nsystem, and is perhaps the least understood quality criterion in process\nmining. The lack of understanding is primarily a consequence of generalization\nseeking to measure properties over the entire future behavior of the system,\nwhen the only available sample of behavior is that provided by the event log\nitself. In this paper, we draw inspiration from computational statistics, and\nemploy a bootstrap approach to estimate properties of a population based on a\nsample. Specifically, we define an estimator of the model's generalization\nbased on the event log it was discovered from, and then use bootstrapping to\nmeasure the generalization of the model with respect to the system, and its\nstatistical significance. Experiments demonstrate the feasibility of the\napproach in industrial settings.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:35:56 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Polyvyanyy", "Artem", ""], ["Moffat", "Alistair", ""], ["Garc\u00eda-Ba\u00f1uelos", "Luciano", ""]]}, {"id": "2107.03900", "submitter": "Hari Bandi", "authors": "Hari Bandi and Dimitris Bertsimas", "title": "The Price of Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systemic bias with respect to gender, race and ethnicity, often unconscious,\nis prevalent in datasets involving choices among individuals. Consequently,\nsociety has found it challenging to alleviate bias and achieve diversity in a\nway that maintains meritocracy in such settings. We propose (a) a novel\noptimization approach based on optimally flipping outcome labels and training\nclassification models simultaneously to discover changes to be made in the\nselection process so as to achieve diversity without significantly affecting\nmeritocracy, and (b) a novel implementation tool employing optimal\nclassification trees to provide insights on which attributes of individuals\nlead to flipping of their labels, and to help make changes in the current\nselection processes in a manner understandable by human decision makers. We\npresent case studies on three real-world datasets consisting of parole,\nadmissions to the bar and lending decisions, and demonstrate that the price of\ndiversity is low and sometimes negative, that is we can modify our selection\nprocesses in a way that enhances diversity without affecting meritocracy\nsignificantly, and sometimes improving it.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:23:27 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Bandi", "Hari", ""], ["Bertsimas", "Dimitris", ""]]}, {"id": "2107.03901", "submitter": "Akis Linardos", "authors": "Akis Linardos, Kaisar Kushibar, Sean Walsh, Polyxeni Gkontra, Karim\n  Lekadir", "title": "Federated Learning for Multi-Center Imaging Diagnostics: A Study in\n  Cardiovascular Disease", "comments": "Code used in this study can be found in:\n  https://github.com/Linardos/federated-HCM-diagnosis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models can enable accurate and efficient disease diagnosis, but\nhave thus far been hampered by the data scarcity present in the medical world.\nAutomated diagnosis studies have been constrained by underpowered single-center\ndatasets, and although some results have shown promise, their generalizability\nto other institutions remains questionable as the data heterogeneity between\ninstitutions is not taken into account. By allowing models to be trained in a\ndistributed manner that preserves patients' privacy, federated learning\npromises to alleviate these issues, by enabling diligent multi-center studies.\nWe present the first federated learning study on the modality of cardiovascular\nmagnetic resonance (CMR) and use four centers derived from subsets of the M\\&M\nand ACDC datasets, focusing on the diagnosis of hypertrophic cardiomyopathy\n(HCM). We adapt a 3D-CNN network pretrained on action recognition and explore\ntwo different ways of incorporating shape prior information to the model, and\nfour different data augmentation set-ups, systematically analyzing their impact\non the different collaborative learning choices. We show that despite the small\nsize of data (180 subjects derived from four centers), the privacy preserving\nfederated learning achieves promising results that are competitive with\ntraditional centralized learning. We further find that federatively trained\nmodels exhibit increased robustness and are more sensitive to domain shift\neffects.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:54:08 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Linardos", "Akis", ""], ["Kushibar", "Kaisar", ""], ["Walsh", "Sean", ""], ["Gkontra", "Polyxeni", ""], ["Lekadir", "Karim", ""]]}, {"id": "2107.03903", "submitter": "Aleksandr Petiushko", "authors": "Alexander Ivanov, Gleb Nosovskiy, Alexey Chekunov, Denis Fedoseev,\n  Vladislav Kibkalo, Mikhail Nikulin, Fedor Popelenskiy, Stepan Komkov, Ivan\n  Mazurenko, Aleksandr Petiushko", "title": "Manifold Hypothesis in Data Analysis: Double Geometrically-Probabilistic\n  Approach to Manifold Dimension Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold hypothesis states that data points in high-dimensional space\nactually lie in close vicinity of a manifold of much lower dimension. In many\ncases this hypothesis was empirically verified and used to enhance unsupervised\nand semi-supervised learning. Here we present new approach to manifold\nhypothesis checking and underlying manifold dimension estimation. In order to\ndo it we use two very different methods simultaneously - one geometric, another\nprobabilistic - and check whether they give the same result. Our geometrical\nmethod is a modification for sparse data of a well-known box-counting algorithm\nfor Minkowski dimension calculation. The probabilistic method is new. Although\nit exploits standard nearest neighborhood distance, it is different from\nmethods which were previously used in such situations. This method is robust,\nfast and includes special preliminary data transformation. Experiments on real\ndatasets show that the suggested approach based on two methods combination is\npowerful and effective.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:35:54 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ivanov", "Alexander", ""], ["Nosovskiy", "Gleb", ""], ["Chekunov", "Alexey", ""], ["Fedoseev", "Denis", ""], ["Kibkalo", "Vladislav", ""], ["Nikulin", "Mikhail", ""], ["Popelenskiy", "Fedor", ""], ["Komkov", "Stepan", ""], ["Mazurenko", "Ivan", ""], ["Petiushko", "Aleksandr", ""]]}, {"id": "2107.03913", "submitter": "Vladimir Kokh", "authors": "Pavel Blinov, Vladimir Kokh", "title": "Patient Embeddings in Healthcare and Insurance Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper researches the problem of concept and patient representations in\nthe medical domain. We present the patient histories from Electronic Health\nRecords (EHRs) as temporal sequences of ICD concepts for which embeddings are\nlearned in an unsupervised setup with a transformer-based neural network model.\nThe model training was performed on the collection of one million patients'\nhistories in 6 years. The predictive power of such a model is assessed in\ncomparison with several baseline methods. A series of experiments on the\nMIMIC-III data show the advantage of the presented model compared to a similar\nsystem. Further, we analyze the obtained embedding space with regards to\nconcept relations and show how knowledge from the medical domain can be\nsuccessfully transferred to the practical task of insurance scoring in the form\nof patient embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 13:30:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Blinov", "Pavel", ""], ["Kokh", "Vladimir", ""]]}, {"id": "2107.03919", "submitter": "Akshay Mehra", "authors": "Akshay Mehra, Bhavya Kailkhura, Pin-Yu Chen and Jihun Hamm", "title": "Understanding the Limits of Unsupervised Domain Adaptation via Data\n  Poisoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) enables cross-domain learning without\ntarget domain labels by transferring knowledge from a labeled source domain\nwhose distribution differs from the target. However, UDA is not always\nsuccessful and several accounts of \"negative transfer\" have been reported in\nthe literature. In this work, we prove a simple lower bound on the target\ndomain error that complements the existing upper bound. Our bound shows the\ninsufficiency of minimizing source domain error and marginal distribution\nmismatch for a guaranteed reduction in the target domain error, due to the\npossible increase of induced labeling function mismatch. This insufficiency is\nfurther illustrated through simple distributions for which the same UDA\napproach succeeds, fails, and may succeed or fail with an equal chance.\nMotivated from this, we propose novel data poisoning attacks to fool UDA\nmethods into learning representations that produce large target domain errors.\nWe evaluate the effect of these attacks on popular UDA methods using benchmark\ndatasets where they have been previously shown to be successful. Our results\nshow that poisoning can significantly decrease the target domain accuracy,\ndropping it to almost 0\\% in some cases, with the addition of only 10\\%\npoisoned data in the source domain. The failure of UDA methods demonstrates the\nlimitations of UDA at guaranteeing cross-domain generalization consistent with\nthe lower bound. Thus, evaluation of UDA methods in adversarial settings such\nas data poisoning can provide a better sense of their robustness in scenarios\nunfavorable for UDA.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:51:14 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mehra", "Akshay", ""], ["Kailkhura", "Bhavya", ""], ["Chen", "Pin-Yu", ""], ["Hamm", "Jihun", ""]]}, {"id": "2107.03920", "submitter": "David Zhao", "authors": "Niccol\\`o Dalmasso, David Zhao, Rafael Izbicki, Ann B. Lee", "title": "Likelihood-Free Frequentist Inference: Bridging Classical Statistics and\n  Machine Learning in Simulation and Uncertainty Quantification", "comments": "49 pages, 12 figures, code available at\n  https://github.com/Mr8ND/ACORE-LFI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many areas of science make extensive use of computer simulators that\nimplicitly encode likelihood functions of complex systems. Classical\nstatistical methods are poorly suited for these so-called likelihood-free\ninference (LFI) settings, outside the asymptotic and low-dimensional regimes.\nAlthough new machine learning methods, such as normalizing flows, have\nrevolutionized the sample efficiency and capacity of LFI methods, it remains an\nopen question whether they produce reliable measures of uncertainty. This paper\npresents a statistical framework for LFI that unifies classical statistics with\nmodern machine learning to: (1) efficiently construct frequentist confidence\nsets and hypothesis tests with finite-sample guarantees of nominal coverage\n(type I error control) and power; (2) provide practical diagnostics for\nassessing empirical coverage over the entire parameter space. We refer to our\nframework as likelihood-free frequentist inference (LF2I). Any method that\nestimates a test statistic, like the likelihood ratio, can be plugged into our\nframework to create valid confidence sets and compute diagnostics, without\ncostly Monte Carlo samples at fixed parameter settings. In this work, we\nspecifically study the power of two test statistics (ACORE and BFF), which,\nrespectively, maximize versus integrate an odds function over the parameter\nspace. Our study offers multifaceted perspectives on the challenges in LF2I.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:52:18 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 14:43:11 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dalmasso", "Niccol\u00f2", ""], ["Zhao", "David", ""], ["Izbicki", "Rafael", ""], ["Lee", "Ann B.", ""]]}, {"id": "2107.03926", "submitter": "Rian Dolphin", "authors": "Rian Dolphin, Barry Smyth, Yang Xu and Ruihai Dong", "title": "Measuring Financial Time Series Similarity With a View to Identifying\n  Profitable Stock Market Opportunities", "comments": "15 pages. Accepted for presentation at the International Conference\n  on Case-Based Reasoning 2021 (ICCBR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forecasting stock returns is a challenging problem due to the highly\nstochastic nature of the market and the vast array of factors and events that\ncan influence trading volume and prices. Nevertheless it has proven to be an\nattractive target for machine learning research because of the potential for\neven modest levels of prediction accuracy to deliver significant benefits. In\nthis paper, we describe a case-based reasoning approach to predicting stock\nmarket returns using only historical pricing data. We argue that one of the\nimpediments for case-based stock prediction has been the lack of a suitable\nsimilarity metric when it comes to identifying similar pricing histories as the\nbasis for a future prediction -- traditional Euclidean and correlation based\napproaches are not effective for a variety of reasons -- and in this regard, a\nkey contribution of this work is the development of a novel similarity metric\nfor comparing historical pricing data. We demonstrate the benefits of this\nmetric and the case-based approach in a real-world application in comparison to\na variety of conventional benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 17:26:32 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Dolphin", "Rian", ""], ["Smyth", "Barry", ""], ["Xu", "Yang", ""], ["Dong", "Ruihai", ""]]}, {"id": "2107.03940", "submitter": "Yann Issartel", "authors": "Cristina Butucea and Yann Issartel", "title": "Locally differentially private estimation of nonlinear functionals of\n  discrete distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating non-linear functionals of discrete\ndistributions in the context of local differential privacy. The initial data\n$x_1,\\ldots,x_n \\in [K]$ are supposed i.i.d. and distributed according to an\nunknown discrete distribution $p = (p_1,\\ldots,p_K)$. Only $\\alpha$-locally\ndifferentially private (LDP) samples $z_1,...,z_n$ are publicly available,\nwhere the term 'local' means that each $z_i$ is produced using one individual\nattribute $x_i$. We exhibit privacy mechanisms (PM) that are interactive (i.e.\nthey are allowed to use already published confidential data) or\nnon-interactive. We describe the behavior of the quadratic risk for estimating\nthe power sum functional $F_{\\gamma} = \\sum_{k=1}^K p_k^{\\gamma}$, $\\gamma >0$\nas a function of $K, \\, n$ and $\\alpha$. In the non-interactive case, we study\ntwo plug-in type estimators of $F_{\\gamma}$, for all $\\gamma >0$, that are\nsimilar to the MLE analyzed by Jiao et al. (2017) in the multinomial model.\nHowever, due to the privacy constraint the rates we attain are slower and\nsimilar to those obtained in the Gaussian model by Collier et al. (2020). In\nthe interactive case, we introduce for all $\\gamma >1$ a two-step procedure\nwhich attains the faster parametric rate $(n \\alpha^2)^{-1/2}$ when $\\gamma\n\\geq 2$. We give lower bounds results over all $\\alpha$-LDP mechanisms and all\nestimators using the private samples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:11:10 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Butucea", "Cristina", ""], ["Issartel", "Yann", ""]]}, {"id": "2107.03955", "submitter": "Felix Biggs", "authors": "Felix Biggs, Benjamin Guedj", "title": "On Margins and Derandomisation in PAC-Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We develop a framework for derandomising PAC-Bayesian generalisation bounds\nachieving a margin on training data, relating this process to the\nconcentration-of-measure phenomenon. We apply these tools to linear prediction,\nsingle-hidden-layer neural networks with an unusual erf activation function,\nand deep ReLU networks, obtaining new bounds. The approach is also extended to\nthe idea of \"partial-derandomisation\" where only some layers are derandomised\nand the others are stochastic. This allows empirical evaluation of\nsingle-hidden-layer networks on more complex datasets, and helps bridge the gap\nbetween generalisation bounds for non-stochastic deep networks and those for\nrandomised deep networks as generally examined in PAC-Bayes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:30:08 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Biggs", "Felix", ""], ["Guedj", "Benjamin", ""]]}, {"id": "2107.03964", "submitter": "Sibendu Paul", "authors": "Sibendu Paul, Kunal Rao, Giuseppe Coviello, Murugan Sankaradas, Oliver\n  Po, Y. Charlie Hu, Srimat T. Chakradhar", "title": "CamTuner: Reinforcement-Learning based System for Camera Parameter\n  Tuning to enhance Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex sensors like video cameras include tens of configurable parameters,\nwhich can be set by end-users to customize the sensors to specific application\nscenarios. Although parameter settings significantly affect the quality of the\nsensor output and the accuracy of insights derived from sensor data, most\nend-users use a fixed parameter setting because they lack the skill or\nunderstanding to appropriately configure these parameters. We propose CamTuner,\nwhich is a system to automatically, and dynamically adapt the complex sensor to\nchanging environments. CamTuner includes two key components. First, a bespoke\nanalytics quality estimator, which is a deep-learning model to automatically\nand continuously estimate the quality of insights from an analytics unit as the\nenvironment around a sensor change. Second, a reinforcement learning (RL)\nmodule, which reacts to the changes in quality, and automatically adjusts the\ncamera parameters to enhance the accuracy of insights. We improve the training\ntime of the RL module by an order of magnitude by designing virtual models to\nmimic essential behavior of the camera: we design virtual knobs that can be set\nto different values to mimic the effects of assigning different values to the\ncamera's configurable parameters, and we design a virtual camera model that\nmimics the output from a video camera at different times of the day. These\nvirtual models significantly accelerate training because (a) frame rates from a\nreal camera are limited to 25-30 fps while the virtual models enable processing\nat 300 fps, (b) we do not have to wait until the real camera sees different\nenvironments, which could take weeks or months, and (c) virtual knobs can be\nupdated instantly, while it can take 200-500 ms to change the camera parameter\nsettings. Our dynamic tuning approach results in up to 12% improvement in the\naccuracy of insights from several video analytics tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:43:02 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Paul", "Sibendu", ""], ["Rao", "Kunal", ""], ["Coviello", "Giuseppe", ""], ["Sankaradas", "Murugan", ""], ["Po", "Oliver", ""], ["Hu", "Y. Charlie", ""], ["Chakradhar", "Srimat T.", ""]]}, {"id": "2107.03974", "submitter": "Vitchyr H. Pong", "authors": "Vitchyr H. Pong, Ashvin Nair, Laura Smith, Catherine Huang, Sergey\n  Levine", "title": "Offline Meta-Reinforcement Learning with Online Self-Supervision", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-reinforcement learning (RL) can meta-train policies that adapt to new\ntasks with orders of magnitude less data than standard RL, but meta-training\nitself is costly and time-consuming. If we can meta-train on offline data, then\nwe can reuse the same static dataset, labeled once with rewards for different\ntasks, to meta-train policies that adapt to a variety of new tasks at meta-test\ntime. Although this capability would make meta-RL a practical tool for\nreal-world use, offline meta-RL presents additional challenges beyond online\nmeta-RL or standard offline RL settings. Meta-RL learns an exploration strategy\nthat collects data for adapting, and also meta-trains a policy that quickly\nadapts to data from a new task. Since this policy was meta-trained on a fixed,\noffline dataset, it might behave unpredictably when adapting to data collected\nby the learned exploration strategy, which differs systematically from the\noffline data and thus induces distributional shift. We do not want to remove\nthis distributional shift by simply adopting a conservative exploration\nstrategy, because learning an exploration strategy enables an agent to collect\nbetter data for faster adaptation. Instead, we propose a hybrid offline meta-RL\nalgorithm, which uses offline data with rewards to meta-train an adaptive\npolicy, and then collects additional unsupervised online data, without any\nreward labels to bridge this distribution shift. By not requiring reward labels\nfor online collection, this data can be much cheaper to collect. We compare our\nmethod to prior work on offline meta-RL on simulated robot locomotion and\nmanipulation tasks and find that using additional unsupervised online data\ncollection leads to a dramatic improvement in the adaptive capabilities of the\nmeta-trained policies, matching the performance of fully online meta-RL on a\nrange of challenging domains that require generalization to new tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:01:32 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 21:42:36 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Pong", "Vitchyr H.", ""], ["Nair", "Ashvin", ""], ["Smith", "Laura", ""], ["Huang", "Catherine", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.03985", "submitter": "Subhashini Venugopalan", "authors": "Subhashini Venugopalan, Joel Shor, Manoj Plakal, Jimmy Tobin, Katrin\n  Tomanek, Jordan R. Green, Michael P. Brenner", "title": "Comparing Supervised Models And Learned Speech Representations For\n  Classifying Intelligibility Of Disordered Speech On Selected Phrases", "comments": "Accepted at INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automatic classification of disordered speech can provide an objective tool\nfor identifying the presence and severity of speech impairment. Classification\napproaches can also help identify hard-to-recognize speech samples to teach ASR\nsystems about the variable manifestations of impaired speech. Here, we develop\nand compare different deep learning techniques to classify the intelligibility\nof disordered speech on selected phrases. We collected samples from a diverse\nset of 661 speakers with a variety of self-reported disorders speaking 29 words\nor phrases, which were rated by speech-language pathologists for their overall\nintelligibility using a five-point Likert scale. We then evaluated classifiers\ndeveloped using 3 approaches: (1) a convolutional neural network (CNN) trained\nfor the task, (2) classifiers trained on non-semantic speech representations\nfrom CNNs that used an unsupervised objective [1], and (3) classifiers trained\non the acoustic (encoder) embeddings from an ASR system trained on typical\nspeech [2]. We found that the ASR encoder's embeddings considerably outperform\nthe other two on detecting and classifying disordered speech. Further analysis\nshows that the ASR embeddings cluster speech by the spoken phrase, while the\nnon-semantic embeddings cluster speech by speaker. Also, longer phrases are\nmore indicative of intelligibility deficits than single words.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:24:25 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Venugopalan", "Subhashini", ""], ["Shor", "Joel", ""], ["Plakal", "Manoj", ""], ["Tobin", "Jimmy", ""], ["Tomanek", "Katrin", ""], ["Green", "Jordan R.", ""], ["Brenner", "Michael P.", ""]]}, {"id": "2107.03992", "submitter": "Arjun Rao", "authors": "Philipp Plank, Arjun Rao, Andreas Wild, Wolfgang Maass", "title": "A Long Short-Term Memory for AI Applications in Spike-based Neuromorphic\n  Hardware", "comments": "Philipp Plank and Arjun Rao have contributed equally to this work as\n  first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of intensive efforts it has remained an open problem to what extent\ncurrent Artificial Intelligence (AI) methods that employ Deep Neural Networks\n(DNNs) can be implemented more energy-efficiently on spike-based neuromorphic\nhardware. This holds in particular for AI methods that solve sequence\nprocessing tasks, a primary application target for spike-based neuromorphic\nhardware. One difficulty is that DNNs for such tasks typically employ Long\nShort-Term Memory (LSTM) units. Yet an efficient emulation of these units in\nspike-based hardware has been missing. We present a biologically inspired\nsolution that solves this problem. This solution enables us to implement a\nmajor class of DNNs for sequence processing tasks such as time series\nclassification and question answering with substantial energy savings on\nneuromorphic hardware. In fact, the Relational Network for reasoning about\nrelations between objects that we use for question answering is the first\nexample of a large DNN that carries out a sequence processing task with\nsubstantial energy-saving on neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:37:02 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Plank", "Philipp", ""], ["Rao", "Arjun", ""], ["Wild", "Andreas", ""], ["Maass", "Wolfgang", ""]]}, {"id": "2107.03996", "submitter": "Ruihan Yang", "authors": "Ruihan Yang, Minghao Zhang, Nicklas Hansen, Huazhe Xu, Xiaolong Wang", "title": "Learning Vision-Guided Quadrupedal Locomotion End-to-End with\n  Cross-Modal Transformers", "comments": "Our project page with videos is at\n  https://RchalYang.github.io/LocoTransformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose to address quadrupedal locomotion tasks using Reinforcement\nLearning (RL) with a Transformer-based model that learns to combine\nproprioceptive information and high-dimensional depth sensor inputs. While\nlearning-based locomotion has made great advances using RL, most methods still\nrely on domain randomization for training blind agents that generalize to\nchallenging terrains. Our key insight is that proprioceptive states only offer\ncontact measurements for immediate reaction, whereas an agent equipped with\nvisual sensory observations can learn to proactively maneuver environments with\nobstacles and uneven terrain by anticipating changes in the environment many\nsteps ahead. In this paper, we introduce LocoTransformer, an end-to-end RL\nmethod for quadrupedal locomotion that leverages a Transformer-based model for\nfusing proprioceptive states and visual observations. We evaluate our method in\nchallenging simulated environments with different obstacles and uneven terrain.\nWe show that our method obtains significant improvements over policies with\nonly proprioceptive state inputs, and that Transformer-based models further\nimprove generalization across environments. Our project page with videos is at\nhttps://RchalYang.github.io/LocoTransformer .\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:41:55 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yang", "Ruihan", ""], ["Zhang", "Minghao", ""], ["Hansen", "Nicklas", ""], ["Xu", "Huazhe", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2107.04000", "submitter": "Siddharth Ancha", "authors": "Siddharth Ancha, Gaurav Pathak, Srinivasa G. Narasimhan, David Held", "title": "Active Safety Envelopes using Light Curtains with Probabilistic\n  Guarantees", "comments": "18 pages, Published at Robotics: Science and Systems (RSS) 2021", "journal-ref": null, "doi": "10.15607/rss.2021.xvii.045", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To safely navigate unknown environments, robots must accurately perceive\ndynamic obstacles. Instead of directly measuring the scene depth with a LiDAR\nsensor, we explore the use of a much cheaper and higher resolution sensor:\nprogrammable light curtains. Light curtains are controllable depth sensors that\nsense only along a surface that a user selects. We use light curtains to\nestimate the safety envelope of a scene: a hypothetical surface that separates\nthe robot from all obstacles. We show that generating light curtains that sense\nrandom locations (from a particular distribution) can quickly discover the\nsafety envelope for scenes with unknown objects. Importantly, we produce\ntheoretical safety guarantees on the probability of detecting an obstacle using\nrandom curtains. We combine random curtains with a machine learning based model\nthat forecasts and tracks the motion of the safety envelope efficiently. Our\nmethod accurately estimates safety envelopes while providing probabilistic\nsafety guarantees that can be used to certify the efficacy of a robot\nperception system to detect and avoid dynamic obstacles. We evaluate our\napproach in a simulated urban driving environment and a real-world environment\nwith moving pedestrians using a light curtain device and show that we can\nestimate safety envelopes efficiently and effectively. Project website:\nhttps://siddancha.github.io/projects/active-safety-envelopes-with-guarantees\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:46:05 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ancha", "Siddharth", ""], ["Pathak", "Gaurav", ""], ["Narasimhan", "Srinivasa G.", ""], ["Held", "David", ""]]}, {"id": "2107.04004", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Shuang Li, Vincent Sitzmann, Pulkit Agrawal, Antonio\n  Torralba", "title": "3D Neural Scene Representations for Visuomotor Control", "comments": "First two authors contributed equally. Project Page:\n  https://3d-representation-learning.github.io/nerf-dy/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have a strong intuitive understanding of the 3D environment around us.\nThe mental model of the physics in our brain applies to objects of different\nmaterials and enables us to perform a wide range of manipulation tasks that are\nfar beyond the reach of current robots. In this work, we desire to learn models\nfor dynamic 3D scenes purely from 2D visual observations. Our model combines\nNeural Radiance Fields (NeRF) and time contrastive learning with an\nautoencoding framework, which learns viewpoint-invariant 3D-aware scene\nrepresentations. We show that a dynamics model, constructed over the learned\nrepresentation space, enables visuomotor control for challenging manipulation\ntasks involving both rigid bodies and fluids, where the target is specified in\na viewpoint different from what the robot operates on. When coupled with an\nauto-decoding framework, it can even support goal specification from camera\nviewpoints that are outside the training distribution. We further demonstrate\nthe richness of the learned 3D dynamics model by performing future prediction\nand novel view synthesis. Finally, we provide detailed ablation studies\nregarding different system designs and qualitative analysis of the learned\nrepresentations.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:49:37 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Li", "Yunzhu", ""], ["Li", "Shuang", ""], ["Sitzmann", "Vincent", ""], ["Agrawal", "Pulkit", ""], ["Torralba", "Antonio", ""]]}, {"id": "2107.04008", "submitter": "Asifullah Khan", "authors": "Muhammad Asam, Saddam Hussain Khan, Tauseef Jamal, Umme Zahoora,\n  Asifullah Khan", "title": "Malware Classification Using Deep Boosted Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious activities in cyberspace have gone further than simply hacking\nmachines and spreading viruses. It has become a challenge for a nations\nsurvival and hence has evolved to cyber warfare. Malware is a key component of\ncyber-crime, and its analysis is the first line of defence against attack. This\nwork proposes a novel deep boosted hybrid learning-based malware classification\nframework and named as Deep boosted Feature Space-based Malware classification\n(DFS-MC). In the proposed framework, the discrimination power is enhanced by\nfusing the feature spaces of the best performing customized CNN architectures\nmodels and its discrimination by an SVM for classification. The discrimination\ncapacity of the proposed classification framework is assessed by comparing it\nagainst the standard customized CNNs. The customized CNN models are implemented\nin two ways: softmax classifier and deep hybrid learning-based malware\nclassification. In the hybrid learning, Deep features are extracted from\ncustomized CNN architectures and fed into the conventional machine learning\nclassifier to improve the classification performance. We also introduced the\nconcept of transfer learning in a customized CNN architecture based malware\nclassification framework through fine-tuning. The performance of the proposed\nmalware classification approaches are validated on the MalImg malware dataset\nusing the hold-out cross-validation technique. Experimental comparisons were\nconducted by employing innovative, customized CNN, trained from scratch and\nfine-tuning the customized CNN using transfer learning. The proposed\nclassification framework DFS-MC showed improved results, Accuracy: 98.61%,\nF-score: 0.96, Precision: 0.96, and Recall: 0.96.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:53:33 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Asam", "Muhammad", ""], ["Khan", "Saddam Hussain", ""], ["Jamal", "Tauseef", ""], ["Zahoora", "Umme", ""], ["Khan", "Asifullah", ""]]}, {"id": "2107.04009", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Hangyeol Yu, Dongmin Shin, Youngduck Choi", "title": "Knowledge Transfer by Discriminative Pre-training for Academic\n  Performance Prediction", "comments": "Nominated for the best short paper award of EDM 2021. This is an\n  extended version of the published one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The needs for precisely estimating a student's academic performance have been\nemphasized with an increasing amount of attention paid to Intelligent Tutoring\nSystem (ITS). However, since labels for academic performance, such as test\nscores, are collected from outside of ITS, obtaining the labels is costly,\nleading to label-scarcity problem which brings challenge in taking machine\nlearning approaches for academic performance prediction. To this end, inspired\nby the recent advancement of pre-training method in natural language processing\ncommunity, we propose DPA, a transfer learning framework with Discriminative\nPre-training tasks for Academic performance prediction. DPA pre-trains two\nmodels, a generator and a discriminator, and fine-tunes the discriminator on\nacademic performance prediction. In DPA's pre-training phase, a sequence of\ninteractions where some tokens are masked is provided to the generator which is\ntrained to reconstruct the original sequence. Then, the discriminator takes an\ninteraction sequence where the masked tokens are replaced by the generator's\noutputs, and is trained to predict the originalities of all tokens in the\nsequence. Compared to the previous state-of-the-art generative pre-training\nmethod, DPA is more sample efficient, leading to fast convergence to lower\nacademic performance prediction error. We conduct extensive experimental\nstudies on a real-world dataset obtained from a multi-platform ITS application\nand show that DPA outperforms the previous state-of-the-art generative\npre-training method with a reduction of 4.05% in mean absolute error and more\nrobust to increased label-scarcity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 13:02:23 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 03:42:14 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 05:36:22 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kim", "Byungsoo", ""], ["Yu", "Hangyeol", ""], ["Shin", "Dongmin", ""], ["Choi", "Youngduck", ""]]}, {"id": "2107.04010", "submitter": "Alise Danielle Midtfjord", "authors": "Alise Danielle Midtfjord, Riccardo De Bin and Arne Bang Huseby", "title": "A Machine Learning Approach to Safer Airplane Landings: Predicting\n  Runway Conditions using Weather and Flight Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of snow and ice on runway surfaces reduces the available\ntire-pavement friction needed for retardation and directional control and\ncauses potential economic and safety threats for the aviation industry during\nthe winter seasons. To activate appropriate safety procedures, pilots need\naccurate and timely information on the actual runway surface conditions. In\nthis study, XGBoost is used to create a combined runway assessment system,\nwhich includes a classifcation model to predict slippery conditions and a\nregression model to predict the level of slipperiness. The models are trained\non weather data and data from runway reports. The runway surface conditions are\nrepresented by the tire-pavement friction coefficient, which is estimated from\nflight sensor data from landing aircrafts. To evaluate the performance of the\nmodels, they are compared to several state-of-the-art runway assessment\nmethods. The XGBoost models identify slippery runway conditions with a ROC AUC\nof 0.95, predict the friction coefficient with a MAE of 0.0254, and outperforms\nall the previous methods. The results show the strong abilities of machine\nlearning methods to model complex, physical phenomena with a good accuracy when\ndomain knowledge is used in the variable extraction. The XGBoost models are\ncombined with SHAP (SHapley Additive exPlanations) approximations to provide a\ncomprehensible decision support system for airport operators and pilots, which\ncan contribute to safer and more economic operations of airport runways.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:01:13 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Midtfjord", "Alise Danielle", ""], ["De Bin", "Riccardo", ""], ["Huseby", "Arne Bang", ""]]}, {"id": "2107.04013", "submitter": "Jinhyung Park", "authors": "Jinhyung Park, Xinshuo Weng, Yunze Man, Kris Kitani", "title": "Multi-Modality Task Cascade for 3D Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds and RGB images are naturally complementary modalities for 3D\nvisual understanding - the former provides sparse but accurate locations of\npoints on objects, while the latter contains dense color and texture\ninformation. Despite this potential for close sensor fusion, many methods train\ntwo models in isolation and use simple feature concatenation to represent 3D\nsensor data. This separated training scheme results in potentially sub-optimal\nperformance and prevents 3D tasks from being used to benefit 2D tasks that are\noften useful on their own. To provide a more integrated approach, we propose a\nnovel Multi-Modality Task Cascade network (MTC-RCNN) that leverages 3D box\nproposals to improve 2D segmentation predictions, which are then used to\nfurther refine the 3D boxes. We show that including a 2D network between two\nstages of 3D modules significantly improves both 2D and 3D task performance.\nMoreover, to prevent the 3D module from over-relying on the overfitted 2D\npredictions, we propose a dual-head 2D segmentation training and inference\nscheme, allowing the 2nd 3D module to learn to interpret imperfect 2D\nsegmentation predictions. Evaluating our model on the challenging SUN RGB-D\ndataset, we improve upon state-of-the-art results of both single modality and\nfusion networks by a large margin ($\\textbf{+3.8}$ mAP@0.5). Code will be\nreleased $\\href{https://github.com/Divadi/MTC_RCNN}{\\text{here.}}$\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:55:01 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Park", "Jinhyung", ""], ["Weng", "Xinshuo", ""], ["Man", "Yunze", ""], ["Kitani", "Kris", ""]]}, {"id": "2107.04034", "submitter": "Deepak Pathak", "authors": "Ashish Kumar, Zipeng Fu, Deepak Pathak, Jitendra Malik", "title": "RMA: Rapid Motor Adaptation for Legged Robots", "comments": "RSS 2021. Webpage at https://ashish-kmr.github.io/rma-legged-robots/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful real-world deployment of legged robots would require them to adapt\nin real-time to unseen scenarios like changing terrains, changing payloads,\nwear and tear. This paper presents Rapid Motor Adaptation (RMA) algorithm to\nsolve this problem of real-time online adaptation in quadruped robots. RMA\nconsists of two components: a base policy and an adaptation module. The\ncombination of these components enables the robot to adapt to novel situations\nin fractions of a second. RMA is trained completely in simulation without using\nany domain knowledge like reference trajectories or predefined foot trajectory\ngenerators and is deployed on the A1 robot without any fine-tuning. We train\nRMA on a varied terrain generator using bioenergetics-inspired rewards and\ndeploy it on a variety of difficult terrains including rocky, slippery,\ndeformable surfaces in environments with grass, long vegetation, concrete,\npebbles, stairs, sand, etc. RMA shows state-of-the-art performance across\ndiverse real-world as well as simulation experiments. Video results at\nhttps://ashish-kmr.github.io/rma-legged-robots/\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:59:59 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Kumar", "Ashish", ""], ["Fu", "Zipeng", ""], ["Pathak", "Deepak", ""], ["Malik", "Jitendra", ""]]}, {"id": "2107.04050", "submitter": "Barna Pasztor", "authors": "Barna Pasztor, Ilija Bogunovic, Andreas Krause", "title": "Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning", "comments": "28 pages, 2 figures, Preprint, Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in multi-agent systems is highly challenging due to the inherent\ncomplexity introduced by agents' interactions. We tackle systems with a huge\npopulation of interacting agents (e.g., swarms) via Mean-Field Control (MFC).\nMFC considers an asymptotically infinite population of identical agents that\naim to collaboratively maximize the collective reward. Specifically, we\nconsider the case of unknown system dynamics where the goal is to\nsimultaneously optimize for the rewards and learn from experience. We propose\nan efficient model-based reinforcement learning algorithm\n$\\text{M}^3\\text{-UCRL}$ that runs in episodes and provably solves this\nproblem. $\\text{M}^3\\text{-UCRL}$ uses upper-confidence bounds to balance\nexploration and exploitation during policy learning. Our main theoretical\ncontributions are the first general regret bounds for model-based RL for MFC,\nobtained via a novel mean-field type analysis. $\\text{M}^3\\text{-UCRL}$ can be\ninstantiated with different models such as neural networks or Gaussian\nProcesses, and effectively combined with neural network policy learning. We\nempirically demonstrate the convergence of $\\text{M}^3\\text{-UCRL}$ on the\nswarm motion problem of controlling an infinite population of agents seeking to\nmaximize location-dependent reward and avoid congested areas.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:01:02 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Pasztor", "Barna", ""], ["Bogunovic", "Ilija", ""], ["Krause", "Andreas", ""]]}, {"id": "2107.04055", "submitter": "Haibo Qi", "authors": "Haibo Qi, Yuhan Wang, Xinyu Liu", "title": "3D RegNet: Deep Learning Model for COVID-19 Diagnosis on Chest CT Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a 3D-RegNet-based neural network is proposed for diagnosing\nthe physical condition of patients with coronavirus (Covid-19) infection. In\nthe application of clinical medicine, lung CT images are utilized by\npractitioners to determine whether a patient is infected with coronavirus.\nHowever, there are some laybacks can be considered regarding to this diagnostic\nmethod, such as time consuming and low accuracy. As a relatively large organ of\nhuman body, important spatial features would be lost if the lungs were\ndiagnosed utilizing two dimensional slice image. Therefore, in this paper, a\ndeep learning model with 3D image was designed. The 3D image as input data was\ncomprised of two-dimensional pulmonary image sequence and from which relevant\ncoronavirus infection 3D features were extracted and classified. The results\nshow that the test set of the 3D model, the result: f1 score of 0.8379 and AUC\nvalue of 0.8807 have been achieved.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:10:07 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Qi", "Haibo", ""], ["Wang", "Yuhan", ""], ["Liu", "Xinyu", ""]]}, {"id": "2107.04057", "submitter": "Md Sahidullah", "authors": "Shakeel Ahmad Sheikh and Md Sahidullah and Fabrice Hirsch and Slim\n  Ouni", "title": "Machine Learning for Stuttering Identification: Review, Challenges &\n  Future Directions", "comments": "Under Review in ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stuttering is a speech disorder during which the flow of speech is\ninterrupted by involuntary pauses and repetition of sounds. Stuttering\nidentification is an interesting interdisciplinary domain research problem\nwhich involves pathology, psychology, acoustics, and signal processing that\nmakes it hard and complicated to detect. Recent developments in machine and\ndeep learning have dramatically revolutionized speech domain, however minimal\nattention has been given to stuttering identification. This work fills the gap\nby trying to bring researchers together from interdisciplinary fields. In this\npaper, we review comprehensively acoustic features, statistical and deep\nlearning based stuttering/disfluency classification methods. We also present\nseveral challenges and possible future directions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:15:20 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 15:32:44 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sheikh", "Shakeel Ahmad", ""], ["Sahidullah", "Md", ""], ["Hirsch", "Fabrice", ""], ["Ouni", "Slim", ""]]}, {"id": "2107.04061", "submitter": "Jacob Gardner", "authors": "Misha Padidar, Xinran Zhu, Leo Huang, Jacob R. Gardner, David Bindel", "title": "Scaling Gaussian Processes with Derivative Information Using Variational\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Gaussian processes with derivative information are useful in many settings\nwhere derivative information is available, including numerous Bayesian\noptimization and regression tasks that arise in the natural sciences.\nIncorporating derivative observations, however, comes with a dominating\n$O(N^3D^3)$ computational cost when training on $N$ points in $D$ input\ndimensions. This is intractable for even moderately sized problems. While\nrecent work has addressed this intractability in the low-$D$ setting, the\nhigh-$N$, high-$D$ setting is still unexplored and of great value, particularly\nas machine learning problems increasingly become high dimensional. In this\npaper, we introduce methods to achieve fully scalable Gaussian process\nregression with derivatives using variational inference. Analogous to the use\nof inducing values to sparsify the labels of a training set, we introduce the\nconcept of inducing directional derivatives to sparsify the partial derivative\ninformation of a training set. This enables us to construct a variational\nposterior that incorporates derivative information but whose size depends\nneither on the full dataset size $N$ nor the full dimensionality $D$. We\ndemonstrate the full scalability of our approach on a variety of tasks, ranging\nfrom a high dimensional stellarator fusion regression task to training graph\nconvolutional neural networks on Pubmed using Bayesian optimization.\nSurprisingly, we find that our approach can improve regression performance even\nin settings where only label data is available.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:23:59 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Padidar", "Misha", ""], ["Zhu", "Xinran", ""], ["Huang", "Leo", ""], ["Gardner", "Jacob R.", ""], ["Bindel", "David", ""]]}, {"id": "2107.04062", "submitter": "Andre Mastmeyer", "authors": "Nico Zettler and Andre Mastmeyer", "title": "Comparison of 2D vs. 3D U-Net Organ Segmentation in abdominal 3D CT\n  images", "comments": "9 pages, 6 figure, 2 tables", "journal-ref": "International Conference on Computer Graphics, Visualization and\n  Computer Vision 2021 - WSCG", "doi": null, "report-no": "H61", "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A two-step concept for 3D segmentation on 5 abdominal organs inside\nvolumetric CT images is presented. First each relevant organ's volume of\ninterest is extracted as bounding box. The extracted volume acts as input for a\nsecond stage, wherein two compared U-Nets with different architectural\ndimensions re-construct an organ segmentation as label mask. In this work, we\nfocus on comparing 2D U-Nets vs. 3D U-Net counterparts. Our initial results\nindicate Dice improvements of about 6\\% at maximum. In this study to our\nsurprise, liver and kidneys for instance were tackled significantly better\nusing the faster and GPU-memory saving 2D U-Nets. For other abdominal key\norgans, there were no significant differences, but we observe highly\nsignificant advantages for the 2D U-Net in terms of GPU computational efforts\nfor all organs under study.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:35:15 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zettler", "Nico", ""], ["Mastmeyer", "Andre", ""]]}, {"id": "2107.04071", "submitter": "Erich Schubert", "authors": "Erich Schubert", "title": "A Triangle Inequality for Cosine Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search is a fundamental problem for many data analysis techniques.\nMany efficient search techniques rely on the triangle inequality of metrics,\nwhich allows pruning parts of the search space based on transitive bounds on\ndistances. Recently, Cosine similarity has become a popular alternative choice\nto the standard Euclidean metric, in particular in the context of textual data\nand neural network embeddings. Unfortunately, Cosine similarity is not metric\nand does not satisfy the standard triangle inequality. Instead, many search\ntechniques for Cosine rely on approximation techniques such as locality\nsensitive hashing. In this paper, we derive a triangle inequality for Cosine\nsimilarity that is suitable for efficient similarity search with many standard\nsearch structures (such as the VP-tree, Cover-tree, and M-tree); show that this\nbound is tight and discuss fast approximations for it. We hope that this spurs\nnew research on accelerating exact similarity search for cosine similarity, and\npossible other similarity measures beyond the existing work for distance\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 19:13:34 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Schubert", "Erich", ""]]}, {"id": "2107.04074", "submitter": "Erich Schubert", "authors": "Erich Schubert and Andreas Lang and Gloria Feher", "title": "Accelerating Spherical k-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spherical k-means is a widely used clustering algorithm for sparse and\nhigh-dimensional data such as document vectors. While several improvements and\naccelerations have been introduced for the original k-means algorithm, not all\neasily translate to the spherical variant: Many acceleration techniques, such\nas the algorithms of Elkan and Hamerly, rely on the triangle inequality of\nEuclidean distances. However, spherical k-means uses Cosine similarities\ninstead of distances for computational efficiency. In this paper, we\nincorporate the Elkan and Hamerly accelerations to the spherical k-means\nalgorithm working directly with the Cosines instead of Euclidean distances to\nobtain a substantial speedup and evaluate these spherical accelerations on real\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 19:24:09 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Schubert", "Erich", ""], ["Lang", "Andreas", ""], ["Feher", "Gloria", ""]]}, {"id": "2107.04086", "submitter": "Mohit Bajaj", "authors": "Mohit Bajaj, Lingyang Chu, Zi Yu Xue, Jian Pei, Lanjun Wang, Peter\n  Cho-Ho Lam, Yong Zhang", "title": "Robust Counterfactual Explanations on Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive deployment of Graph Neural Networks (GNNs) in high-stake applications\ngenerates a strong demand for explanations that are robust to noise and align\nwell with human intuition. Most existing methods generate explanations by\nidentifying a subgraph of an input graph that has a strong correlation with the\nprediction. These explanations are not robust to noise because independently\noptimizing the correlation for a single input can easily overfit noise.\nMoreover, they do not align well with human intuition because removing an\nidentified subgraph from an input graph does not necessarily change the\nprediction result. In this paper, we propose a novel method to generate robust\ncounterfactual explanations on GNNs by explicitly modelling the common decision\nlogic of GNNs on similar input graphs. Our explanations are naturally robust to\nnoise because they are produced from the common decision boundaries of a GNN\nthat govern the predictions of many similar input graphs. The explanations also\nalign well with human intuition because removing the set of edges identified by\nan explanation from the input graph changes the prediction significantly.\nExhaustive experiments on many public datasets demonstrate the superior\nperformance of our method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 19:50:00 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 21:13:20 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bajaj", "Mohit", ""], ["Chu", "Lingyang", ""], ["Xue", "Zi Yu", ""], ["Pei", "Jian", ""], ["Wang", "Lanjun", ""], ["Lam", "Peter Cho-Ho", ""], ["Zhang", "Yong", ""]]}, {"id": "2107.04091", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek and Pawe{\\l} Pe{\\l}ka", "title": "Ensembles of Randomized NNs for Pattern-based Time Series Forecasting", "comments": "arXiv admin note: text overlap with arXiv:2107.01705", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an ensemble forecasting approach based on randomized\nneural networks. Improved randomized learning streamlines the fitting abilities\nof individual learners by generating network parameters in accordance with the\ndata and target function features. A pattern-based representation of time\nseries makes the proposed approach suitable for forecasting time series with\nmultiple seasonality. We propose six strategies for controlling the diversity\nof ensemble members. Case studies conducted on four real-world forecasting\nproblems verified the effectiveness and superior performance of the proposed\nensemble forecasting approach. It outperformed statistical models as well as\nstate-of-the-art machine learning models in terms of forecasting accuracy. The\nproposed approach has several advantages: fast and easy training, simple\narchitecture, ease of implementation, high accuracy and the ability to deal\nwith nonstationarity and multiple seasonality in time series.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 20:13:50 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Dudek", "Grzegorz", ""], ["Pe\u0142ka", "Pawe\u0142", ""]]}, {"id": "2107.04092", "submitter": "Dennis Bautembach", "authors": "Dennis Bautembach, Iason Oikonomidis, Antonis Argyros", "title": "Even Faster SNN Simulation with Lazy+Event-driven Plasticity and Shared\n  Atomics", "comments": "Submitted to IEEE-HPEC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel optimizations that accelerate clock-based spiking neural\nnetwork (SNN) simulators. The first one targets spike timing dependent\nplasticity (STDP). It combines lazy- with event-driven plasticity and\nefficiently facilitates the computation of pre- and post-synaptic spikes using\nbitfields and integer intrinsics. It offers higher bandwidth than event-driven\nplasticity alone and achieves a 1.5x-2x speedup over our closest competitor.\nThe second optimization targets spike delivery. We partition our graph\nrepresentation in a way that bounds the number of neurons that need be updated\nat any given time which allows us to perform said update in shared memory\ninstead of global memory. This is 2x-2.5x faster than our closest competitor.\nBoth optimizations represent the final evolutionary stages of years of\niteration on STDP and spike delivery inside \"Spice\" (/spaIk/), our state of the\nart SNN simulator. The proposed optimizations are not exclusive to our graph\nrepresentation or pipeline but are applicable to a multitude of simulator\ndesigns. We evaluate our performance on three well-established models and\ncompare ourselves against three other state of the art simulators.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 20:13:54 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bautembach", "Dennis", ""], ["Oikonomidis", "Iason", ""], ["Argyros", "Antonis", ""]]}, {"id": "2107.04119", "submitter": "Rao Jiahua", "authors": "Jiahua Rao, Shuangjia Zheng, Yuedong Yang", "title": "Quantitative Evaluation of Explainable Graph Neural Networks for\n  Molecular Property Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in machine learning have led to graph neural network-based methods\nfor drug discovery, yielding promising results in molecular design, chemical\nsynthesis planning, and molecular property prediction. However, current graph\nneural networks (GNNs) remain of limited acceptance in drug discovery is\nlimited due to their lack of interpretability. Although this major weakness has\nbeen mitigated by the development of explainable artificial intelligence (XAI)\ntechniques, the \"ground truth\" assignment in most explainable tasks ultimately\nrests with subjective judgments by humans so that the quality of model\ninterpretation is hard to evaluate in quantity. In this work, we first build\nthree levels of benchmark datasets to quantitatively assess the\ninterpretability of the state-of-the-art GNN models. Then we implemented recent\nXAI methods in combination with different GNN algorithms to highlight the\nbenefits, limitations, and future opportunities for drug discovery. As a\nresult, GradInput and IG generally provide the best model interpretability for\nGNNs, especially when combined with GraphNet and CMPNN. The integrated and\ndeveloped XAI package is fully open-sourced and can be used by practitioners to\ntrain new models on other drug discovery tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 04:49:29 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 04:12:24 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Rao", "Jiahua", ""], ["Zheng", "Shuangjia", ""], ["Yang", "Yuedong", ""]]}, {"id": "2107.04126", "submitter": "Eduardo C. Garrido-Merch\\'an", "authors": "Lucia Asencio Mart\\'in, Eduardo C. Garrido-Merch\\'an", "title": "Many Objective Bayesian Optimization", "comments": "arXiv admin note: text overlap with arXiv:2101.08061", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some real problems require the evaluation of expensive and noisy objective\nfunctions. Moreover, the analytical expression of these objective functions may\nbe unknown. These functions are known as black-boxes, for example, estimating\nthe generalization error of a machine learning algorithm and computing its\nprediction time in terms of its hyper-parameters. Multi-objective Bayesian\noptimization (MOBO) is a set of methods that has been successfully applied for\nthe simultaneous optimization of black-boxes. Concretely, BO methods rely on a\nprobabilistic model of the objective functions, typically a Gaussian process.\nThis model generates a predictive distribution of the objectives. However, MOBO\nmethods have problems when the number of objectives in a multi-objective\noptimization problem are 3 or more, which is the many objective setting. In\nparticular, the BO process is more costly as more objectives are considered,\ncomputing the quality of the solution via the hyper-volume is also more costly\nand, most importantly, we have to evaluate every objective function, wasting\nexpensive computational, economic or other resources. However, as more\nobjectives are involved in the optimization problem, it is highly probable that\nsome of them are redundant and not add information about the problem solution.\nA measure that represents how similar are GP predictive distributions is\nproposed. We also propose a many objective Bayesian optimization algorithm that\nuses this metric to determine whether two objectives are redundant. The\nalgorithm stops evaluating one of them if the similarity is found, saving\nresources and not hurting the performance of the multi-objective BO algorithm.\nWe show empirical evidence in a set of toy, synthetic, benchmark and real\nexperiments that GPs predictive distributions of the effectiveness of the\nmetric and the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 21:57:07 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Mart\u00edn", "Lucia Asencio", ""], ["Garrido-Merch\u00e1n", "Eduardo C.", ""]]}, {"id": "2107.04127", "submitter": "Manh Tu Vu", "authors": "Manh Tu Vu, Marie Beurton-Aimar", "title": "Multitask Multi-database Emotion Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we introduce our submission to the 2nd Affective Behavior\nAnalysis in-the-wild (ABAW) 2021 competition. We train a unified deep learning\nmodel on multi-databases to perform two tasks: seven basic facial expressions\nprediction and valence-arousal estimation. Since these databases do not\ncontains labels for all the two tasks, we have applied the distillation\nknowledge technique to train two networks: one teacher and one student model.\nThe student model will be trained using both ground truth labels and soft\nlabels derived from the pretrained teacher model. During the training, we add\none more task, which is the combination of the two mentioned tasks, for better\nexploiting inter-task correlations. We also exploit the sharing videos between\nthe two tasks of the AffWild2 database that is used in the competition, to\nfurther improve the performance of the network. Experiment results shows that\nthe network have achieved promising results on the validation set of the\nAffWild2 database. Code and pretrained model are publicly available at\nhttps://github.com/glmanhtu/multitask-abaw-2021\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 21:57:58 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 15:36:55 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Vu", "Manh Tu", ""], ["Beurton-Aimar", "Marie", ""]]}, {"id": "2107.04129", "submitter": "Bo Liu", "authors": "Bo Liu, Chaowei Tan, Jiazhou Wang, Tao Zeng, Huasong Shan, Houpu Yao,\n  Huang Heng, Peng Dai, Liefeng Bo, Yanqing Chen", "title": "Fedlearn-Algo: A flexible open-source privacy-preserving machine\n  learning platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present Fedlearn-Algo, an open-source privacy preserving\nmachine learning platform. We use this platform to demonstrate our research and\ndevelopment results on privacy preserving machine learning algorithms. As the\nfirst batch of novel FL algorithm examples, we release vertical federated\nkernel binary classification model and vertical federated random forest model.\nThey have been tested to be more efficient than existing vertical federated\nlearning models in our practice. Besides the novel FL algorithm examples, we\nalso release a machine communication module. The uniform data transfer\ninterface supports transfering widely used data formats between machines. We\nwill maintain this platform by adding more functional modules and algorithm\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 21:59:56 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liu", "Bo", ""], ["Tan", "Chaowei", ""], ["Wang", "Jiazhou", ""], ["Zeng", "Tao", ""], ["Shan", "Huasong", ""], ["Yao", "Houpu", ""], ["Heng", "Huang", ""], ["Dai", "Peng", ""], ["Bo", "Liefeng", ""], ["Chen", "Yanqing", ""]]}, {"id": "2107.04139", "submitter": "Sirui Li", "authors": "Sirui Li, Zhongxia Yan, Cathy Wu", "title": "Learning to Delegate for Large-scale Vehicle Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle routing problems (VRPs) are a class of combinatorial problems with\nwide practical applications. While previous heuristic or learning-based works\nachieve decent solutions on small problem instances of up to 100 customers,\ntheir performance does not scale to large problems. This article presents a\nnovel learning-augmented local search algorithm to solve large-scale VRP. The\nmethod iteratively improves the solution by identifying appropriate subproblems\nand $\\textit{delegating}$ their improvement to a black box subsolver. At each\nstep, we leverage spatial locality to consider only a linear number of\nsubproblems, rather than exponential. We frame subproblem selection as a\nregression problem and train a Transformer on a generated training set of\nproblem instances. We show that our method achieves state-of-the-art\nperformance, with a speed-up of up to 15 times over strong baselines, on VRPs\nwith sizes ranging from 500 to 3000.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 22:51:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Li", "Sirui", ""], ["Yan", "Zhongxia", ""], ["Wu", "Cathy", ""]]}, {"id": "2107.04144", "submitter": "Alexander Wong", "authors": "Saad Abbasi, Mohammad Javad Shafiee, Ellick Chan, and Alexander Wong", "title": "Does Form Follow Function? An Empirical Exploration of the Impact of\n  Deep Neural Network Architecture Design on Hardware-Specific Acceleration", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fine-grained relationship between form and function with respect to deep\nneural network architecture design and hardware-specific acceleration is one\narea that is not well studied in the research literature, with form often\ndictated by accuracy as opposed to hardware function. In this study, a\ncomprehensive empirical exploration is conducted to investigate the impact of\ndeep neural network architecture design on the degree of inference speedup that\ncan be achieved via hardware-specific acceleration. More specifically, we\nempirically study the impact of a variety of commonly used macro-architecture\ndesign patterns across different architectural depths through the lens of\nOpenVINO microprocessor-specific and GPU-specific acceleration. Experimental\nresults showed that while leveraging hardware-specific acceleration achieved an\naverage inference speed-up of 380%, the degree of inference speed-up varied\ndrastically depending on the macro-architecture design pattern, with the\ngreatest speedup achieved on the depthwise bottleneck convolution design\npattern at 550%. Furthermore, we conduct an in-depth exploration of the\ncorrelation between FLOPs requirement, level 3 cache efficacy, and network\nlatency with increasing architectural depth and width. Finally, we analyze the\ninference time reductions using hardware-specific acceleration when compared to\nnative deep learning frameworks across a wide variety of hand-crafted deep\nconvolutional neural network architecture designs as well as ones found via\nneural architecture search strategies. We found that the DARTS-derived\narchitecture to benefit from the greatest improvement from hardware-specific\nsoftware acceleration (1200%) while the depthwise bottleneck convolution-based\nMobileNet-V2 to have the lowest overall inference time of around 2.4 ms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 23:05:39 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Abbasi", "Saad", ""], ["Shafiee", "Mohammad Javad", ""], ["Chan", "Ellick", ""], ["Wong", "Alexander", ""]]}, {"id": "2107.04150", "submitter": "Tomas Geffner", "authors": "Tomas Geffner and Justin Domke", "title": "MCMC Variational Inference via Uncorrected Hamiltonian Annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an unnormalized target distribution we want to obtain approximate\nsamples from it and a tight lower bound on its (log) normalization constant log\nZ. Annealed Importance Sampling (AIS) with Hamiltonian MCMC is a powerful\nmethod that can be used to do this. Its main drawback is that it uses\nnon-differentiable transition kernels, which makes tuning its many parameters\nhard. We propose a framework to use an AIS-like procedure with Uncorrected\nHamiltonian MCMC, called Uncorrected Hamiltonian Annealing. Our method leads to\ntight and differentiable lower bounds on log Z. We show empirically that our\nmethod yields better performances than other competing approaches, and that the\nability to tune its parameters using reparameterization gradients may lead to\nlarge performance improvements.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 23:59:45 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "2107.04154", "submitter": "Xiaohui Zhang", "authors": "Xiaohui Zhang, Vimal Manohar, David Zhang, Frank Zhang, Yangyang Shi,\n  Nayan Singhal, Julian Chan, Fuchun Peng, Yatharth Saraf, Mike Seltzer", "title": "On lattice-free boosted MMI training of HMM and CTC-based full-context\n  ASR models", "comments": "submitted to ASRU 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid automatic speech recognition (ASR) models are typically sequentially\ntrained with CTC or LF-MMI criteria. However, they have vastly different\nlegacies and are usually implemented in different frameworks. In this paper, by\ndecoupling the concepts of modeling units and label topologies and building\nproper numerator/denominator graphs accordingly, we establish a generalized\nframework for hybrid acoustic modeling (AM). In this framework, we show that\nLF-MMI is a powerful training criterion applicable to both limited-context and\nfull-context models, for wordpiece/mono-char/bi-char/chenone units, with both\nHMM/CTC topologies. From this framework, we propose three novel training\nschemes: chenone(ch)/wordpiece(wp)-CTC-bMMI, and wordpiece(wp)-HMM-bMMI with\ndifferent advantages in training performance, decoding efficiency and decoding\ntime-stamp accuracy. The advantages of different training schemes are evaluated\ncomprehensively on Librispeech, and wp-CTC-bMMI and ch-CTC-bMMI are evaluated\non two real world ASR tasks to show their effectiveness. Besides, we also show\nbi-char(bc) HMM-MMI models can serve as better alignment models than\ntraditional non-neural GMM-HMMs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 00:16:42 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhang", "Xiaohui", ""], ["Manohar", "Vimal", ""], ["Zhang", "David", ""], ["Zhang", "Frank", ""], ["Shi", "Yangyang", ""], ["Singhal", "Nayan", ""], ["Chan", "Julian", ""], ["Peng", "Fuchun", ""], ["Saraf", "Yatharth", ""], ["Seltzer", "Mike", ""]]}, {"id": "2107.04163", "submitter": "Yang Li", "authors": "Yang Li, Siyuan Shan, Qin Liu, Junier B. Oliva", "title": "Towards Robust Active Feature Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Truly intelligent systems are expected to make critical decisions with\nincomplete and uncertain data. Active feature acquisition (AFA), where features\nare sequentially acquired to improve the prediction, is a step towards this\ngoal. However, current AFA models all deal with a small set of candidate\nfeatures and have difficulty scaling to a large feature space. Moreover, they\nare ignorant about the valid domains where they can predict confidently, thus\nthey can be vulnerable to out-of-distribution (OOD) inputs. In order to remedy\nthese deficiencies and bring AFA models closer to practical use, we propose\nseveral techniques to advance the current AFA approaches. Our framework can\neasily handle a large number of features using a hierarchical acquisition\npolicy and is more robust to OOD inputs with the help of an OOD detector for\npartially observed data. Extensive experiments demonstrate the efficacy of our\nframework over strong baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 01:06:13 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Li", "Yang", ""], ["Shan", "Siyuan", ""], ["Liu", "Qin", ""], ["Oliva", "Junier B.", ""]]}, {"id": "2107.04174", "submitter": "Jacob Donley", "authors": "Jacob Donley, Vladimir Tourbabin, Jung-Suk Lee, Mark Broyles, Hao\n  Jiang, Jie Shen, Maja Pantic, Vamsi Krishna Ithapu, Ravish Mehra", "title": "EasyCom: An Augmented Reality Dataset to Support Algorithms for Easy\n  Communication in Noisy Environments", "comments": "Dataset is available at:\n  https://github.com/facebookresearch/EasyComDataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmented Reality (AR) as a platform has the potential to facilitate the\nreduction of the cocktail party effect. Future AR headsets could potentially\nleverage information from an array of sensors spanning many different\nmodalities. Training and testing signal processing and machine learning\nalgorithms on tasks such as beam-forming and speech enhancement require high\nquality representative data. To the best of the author's knowledge, as of\npublication there are no available datasets that contain synchronized\negocentric multi-channel audio and video with dynamic movement and\nconversations in a noisy environment. In this work, we describe, evaluate and\nrelease a dataset that contains over 5 hours of multi-modal data useful for\ntraining and testing algorithms for the application of improving conversations\nfor an AR glasses wearer. We provide speech intelligibility, quality and\nsignal-to-noise ratio improvement results for a baseline method and show\nimprovements across all tested metrics. The dataset we are releasing contains\nAR glasses egocentric multi-channel microphone array audio, wide field-of-view\nRGB video, speech source pose, headset microphone audio, annotated voice\nactivity, speech transcriptions, head bounding boxes, target of speech and\nsource identification labels. We have created and are releasing this dataset to\nfacilitate research in multi-modal AR solutions to the cocktail party problem.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 02:00:47 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Donley", "Jacob", ""], ["Tourbabin", "Vladimir", ""], ["Lee", "Jung-Suk", ""], ["Broyles", "Mark", ""], ["Jiang", "Hao", ""], ["Shen", "Jie", ""], ["Pantic", "Maja", ""], ["Ithapu", "Vamsi Krishna", ""], ["Mehra", "Ravish", ""]]}, {"id": "2107.04184", "submitter": "Yang Liu", "authors": "Yang Liu and Anthony C. Constantinou", "title": "Greedy structure learning from data that contains systematic missing\n  values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from data that contain missing values represents a common phenomenon\nin many domains. Relatively few Bayesian Network structure learning algorithms\naccount for missing data, and those that do tend to rely on standard approaches\nthat assume missing data are missing at random, such as the\nExpectation-Maximisation algorithm. Because missing data are often systematic,\nthere is a need for more pragmatic methods that can effectively deal with data\nsets containing missing values not missing at random. The absence of approaches\nthat deal with systematic missing data impedes the application of BN structure\nlearning methods to real-world problems where missingness are not random. This\npaper describes three variants of greedy search structure learning that utilise\npairwise deletion and inverse probability weighting to maximally leverage the\nobserved data and to limit potential bias caused by missing values. The first\ntwo of the variants can be viewed as sub-versions of the third and best\nperforming variant, but are important in their own in illustrating the\nsuccessive improvements in learning accuracy. The empirical investigations show\nthat the proposed approach outperforms the commonly used and state-of-the-art\nStructural EM algorithm, both in terms of learning accuracy and efficiency, as\nwell as both when data are missing at random and not at random.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 02:56:44 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liu", "Yang", ""], ["Constantinou", "Anthony C.", ""]]}, {"id": "2107.04189", "submitter": "Peng Wu", "authors": "Peng Wu, Tales Imbiriba, Junha Park, Sunwoo Kim, Pau Closas", "title": "Personalized Federated Learning over non-IID Data for Indoor\n  Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Localization and tracking of objects using data-driven methods is a popular\ntopic due to the complexity in characterizing the physics of wireless channel\npropagation models. In these modeling approaches, data needs to be gathered to\naccurately train models, at the same time that user's privacy is maintained. An\nappealing scheme to cooperatively achieve these goals is known as Federated\nLearning (FL). A challenge in FL schemes is the presence of non-independent and\nidentically distributed (non-IID) data, caused by unevenly exploration of\ndifferent areas. In this paper, we consider the use of recent FL schemes to\ntrain a set of personalized models that are then optimally fused through\nBayesian rules, which makes it appropriate in the context of indoor\nlocalization.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 03:31:16 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 19:14:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wu", "Peng", ""], ["Imbiriba", "Tales", ""], ["Park", "Junha", ""], ["Kim", "Sunwoo", ""], ["Closas", "Pau", ""]]}, {"id": "2107.04191", "submitter": "Kongtao Chen", "authors": "Kongtao Chen, Ken Franko, Ruoxin Sang", "title": "Structured Model Pruning of Convolutional Networks on Tensor Processing\n  Units", "comments": "International Conference on Machine Learning 2021 Workshop on\n  Overparameterization: Pitfalls & Opportunities", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The deployment of convolutional neural networks is often hindered by high\ncomputational and storage requirements. Structured model pruning is a promising\napproach to alleviate these requirements. Using the VGG-16 model as an example,\nwe measure the accuracy-efficiency trade-off for various structured model\npruning methods and datasets (CIFAR-10 and ImageNet) on Tensor Processing Units\n(TPUs). To measure the actual performance of models, we develop a structured\nmodel pruning library for TensorFlow2 to modify models in place (instead of\nadding mask layers). We show that structured model pruning can significantly\nimprove model memory usage and speed on TPUs without losing accuracy,\nespecially for small datasets (e.g., CIFAR-10).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 03:41:31 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 17:04:28 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Kongtao", ""], ["Franko", "Ken", ""], ["Sang", "Ruoxin", ""]]}, {"id": "2107.04193", "submitter": "Weiming Zhi", "authors": "Weiming Zhi, Lionel Ott, Fabio Ramos", "title": "Probabilistic Trajectory Prediction with Structural Constraints", "comments": "To appear at IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work addresses the problem of predicting the motion trajectories of\ndynamic objects in the environment. Recent advances in predicting motion\npatterns often rely on machine learning techniques to extrapolate motion\npatterns from observed trajectories, with no mechanism to directly incorporate\nknown rules. We propose a novel framework, which combines probabilistic\nlearning and constrained trajectory optimisation. The learning component of our\nframework provides a distribution over future motion trajectories conditioned\non observed past coordinates. This distribution is then used as a prior to a\nconstrained optimisation problem which enforces chance constraints on the\ntrajectory distribution. This results in constraint-compliant trajectory\ndistributions which closely resemble the prior. In particular, we focus our\ninvestigation on collision constraints, such that extrapolated future\ntrajectory distributions conform to the environment structure. We empirically\ndemonstrate on real-world and simulated datasets the ability of our framework\nto learn complex probabilistic motion trajectories for motion data, while\ndirectly enforcing constraints to improve generalisability, producing more\nrobust and higher quality trajectory distributions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 03:48:14 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhi", "Weiming", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "2107.04197", "submitter": "John Chen", "authors": "John Chen, Cameron Wolfe, Anastasios Kyrillidis", "title": "REX: Revisiting Budgeted Training with an Improved Schedule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning practitioners often operate on a computational and monetary\nbudget. Thus, it is critical to design optimization algorithms that perform\nwell under any budget. The linear learning rate schedule is considered the best\nbudget-aware schedule, as it outperforms most other schedules in the low budget\nregime. On the other hand, learning rate schedules -- such as the\n\\texttt{30-60-90} step schedule -- are known to achieve high performance when\nthe model can be trained for many epochs. Yet, it is often not known a priori\nwhether one's budget will be large or small; thus, the optimal choice of\nlearning rate schedule is made on a case-by-case basis. In this paper, we frame\nthe learning rate schedule selection problem as a combination of $i)$ selecting\na profile (i.e., the continuous function that models the learning rate\nschedule), and $ii)$ choosing a sampling rate (i.e., how frequently the\nlearning rate is updated/sampled from this profile). We propose a novel profile\nand sampling rate combination called the Reflected Exponential (REX) schedule,\nwhich we evaluate across seven different experimental settings with both SGD\nand Adam optimizers. REX outperforms the linear schedule in the low budget\nregime, while matching or exceeding the performance of several state-of-the-art\nlearning rate schedules (linear, step, exponential, cosine, step decay on\nplateau, and OneCycle) in both high and low budget regimes. Furthermore, REX\nrequires no added computation, storage, or hyperparameters.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 04:17:35 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Chen", "John", ""], ["Wolfe", "Cameron", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2107.04200", "submitter": "Hao Sun", "authors": "Hao Sun, Ziping Xu, Meng Fang, Zhenghao Peng, Jiadong Guo, Bo Dai,\n  Bolei Zhou", "title": "Safe Exploration by Solving Early Terminated MDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safe exploration is crucial for the real-world application of reinforcement\nlearning (RL). Previous works consider the safe exploration problem as\nConstrained Markov Decision Process (CMDP), where the policies are being\noptimized under constraints. However, when encountering any potential dangers,\nhuman tends to stop immediately and rarely learns to behave safely in danger.\nMotivated by human learning, we introduce a new approach to address safe RL\nproblems under the framework of Early Terminated MDP (ET-MDP). We first define\nthe ET-MDP as an unconstrained MDP with the same optimal value function as its\ncorresponding CMDP. An off-policy algorithm based on context models is then\nproposed to solve the ET-MDP, which thereby solves the corresponding CMDP with\nbetter asymptotic performance and improved learning efficiency. Experiments on\nvarious CMDP tasks show a substantial improvement over previous methods that\ndirectly solve CMDP.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 04:24:40 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Sun", "Hao", ""], ["Xu", "Ziping", ""], ["Fang", "Meng", ""], ["Peng", "Zhenghao", ""], ["Guo", "Jiadong", ""], ["Dai", "Bo", ""], ["Zhou", "Bolei", ""]]}, {"id": "2107.04205", "submitter": "Ke Sun", "authors": "Alexander Soen and Ke Sun", "title": "On the Variance of the Fisher Information for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fisher information matrix (FIM) has been applied to the realm of deep\nlearning. It is closely related to the loss landscape, the variance of the\nparameters, second order optimization, and deep learning theory. The exact FIM\nis either unavailable in closed form or too expensive to compute. In practice,\nit is almost always estimated based on empirical samples. We investigate two\nsuch estimators based on two equivalent representations of the FIM. They are\nboth unbiased and consistent with respect to the underlying \"true\" FIM. Their\nestimation quality is characterized by their variance given in closed form. We\nbound their variances and analyze how the parametric structure of a deep neural\nnetwork can impact the variance. We discuss the meaning of this variance\nmeasure and our bounds in the context of deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 04:46:50 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Soen", "Alexander", ""], ["Sun", "Ke", ""]]}, {"id": "2107.04212", "submitter": "Zi Lin", "authors": "Ian D. Kivlichan, Zi Lin, Jeremiah Liu, Lucy Vasserman", "title": "Measuring and Improving Model-Moderator Collaboration using Uncertainty\n  Estimation", "comments": "WOAH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content moderation is often performed by a collaboration between humans and\nmachine learning models. However, it is not well understood how to design the\ncollaborative process so as to maximize the combined moderator-model system\nperformance. This work presents a rigorous study of this problem, focusing on\nan approach that incorporates model uncertainty into the collaborative process.\nFirst, we introduce principled metrics to describe the performance of the\ncollaborative system under capacity constraints on the human moderator,\nquantifying how efficiently the combined system utilizes human decisions. Using\nthese metrics, we conduct a large benchmark study evaluating the performance of\nstate-of-the-art uncertainty models under different collaborative review\nstrategies. We find that an uncertainty-based strategy consistently outperforms\nthe widely used strategy based on toxicity scores, and moreover that the choice\nof review strategy drastically changes the overall system performance. Our\nresults demonstrate the importance of rigorous metrics for understanding and\ndeveloping effective moderator-model systems for content moderation, as well as\nthe utility of uncertainty estimation in this domain.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 05:07:25 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kivlichan", "Ian D.", ""], ["Lin", "Zi", ""], ["Liu", "Jeremiah", ""], ["Vasserman", "Lucy", ""]]}, {"id": "2107.04226", "submitter": "Chien-Wen Huang", "authors": "Fu-Shun Hsu, Shang-Ran Huang, Chien-Wen Huang, Chun-Chieh Chen,\n  Yuan-Ren Cheng, Feipei Lai", "title": "Multi-path Convolutional Neural Networks Efficiently Improve Feature\n  Extraction in Continuous Adventitious Lung Sound Detection", "comments": "To be submitted, 32 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We previously established a large lung sound database, HF_Lung_V2 (Lung_V2).\nWe trained convolutional-bidirectional gated recurrent unit (CNN-BiGRU)\nnetworks for detecting inhalation, exhalation, continuous adventitious sound\n(CAS) and discontinuous adventitious sound at the recording level on the basis\nof Lung_V2. However, the performance of CAS detection was poor due to many\nreasons, one of which is the highly diversified CAS patterns. To make the\noriginal CNN-BiGRU model learn the CAS patterns more effectively and not cause\ntoo much computing burden, three strategies involving minimal modifications of\nthe network architecture of the CNN layers were investigated: (1) making the\nCNN layers a bit deeper by using the residual blocks, (2) making the CNN layers\na bit wider by increasing the number of CNN kernels, and (3) separating the\nfeature input into multiple paths (the model was denoted by Multi-path\nCNN-BiGRU). The performance of CAS segment and event detection were evaluated.\nResults showed that improvement in CAS detection was observed among all the\nproposed architecture-modified models. The F1 score for CAS event detection of\nthe proposed models increased from 0.445 to 0.491-0.530, which was deemed\nsignificant. However, the Multi-path CNN-BiGRU model outperformed the other\nmodels in terms of the number of winning titles (five) in total nine evaluation\nmetrics. In addition, the Multi-path CNN-BiGRU model did not cause extra\ncomputing burden (0.97-fold inference time) compared to the original CNN-BiGRU\nmodel. Conclusively, the Multi-path CNN layers can efficiently improve the\neffectiveness of feature extraction and subsequently result in better CAS\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 05:55:57 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Hsu", "Fu-Shun", ""], ["Huang", "Shang-Ran", ""], ["Huang", "Chien-Wen", ""], ["Chen", "Chun-Chieh", ""], ["Cheng", "Yuan-Ren", ""], ["Lai", "Feipei", ""]]}, {"id": "2107.04229", "submitter": "Chien-Wen Huang", "authors": "Fu-Shun Hsu, Shang-Ran Huang, Chang-Fu Su, Chien-Wen Huang, Yuan-Ren\n  Cheng, Chun-Chieh Chen, Chun-Yu Wu, Chung-Wei Chen, Yen-Chun Lai, Tang-Wei\n  Cheng, Nian-Jhen Lin, Wan-Ling Tsai, Ching-Shiang Lu, Chuan Chen, Feipei Lai", "title": "Improved Breath Phase and Continuous Adventitious Sound Detection in\n  Lung and Tracheal Sound Using Mixed Set Training and Domain Adaptation", "comments": "To be submitted, 31 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previously, we established a lung sound database, HF_Lung_V2 and proposed\nconvolutional bidirectional gated recurrent unit (CNN-BiGRU) models with\nadequate ability for inhalation, exhalation, continuous adventitious sound\n(CAS), and discontinuous adventitious sound detection in the lung sound. In\nthis study, we proceeded to build a tracheal sound database, HF_Tracheal_V1,\ncontaining 11107 of 15-second tracheal sound recordings, 23087 inhalation\nlabels, 16728 exhalation labels, and 6874 CAS labels. The tracheal sound in\nHF_Tracheal_V1 and the lung sound in HF_Lung_V2 were either combined or used\nalone to train the CNN-BiGRU models for respective lung and tracheal sound\nanalysis. Different training strategies were investigated and compared: (1)\nusing full training (training from scratch) to train the lung sound models\nusing lung sound alone and train the tracheal sound models using tracheal sound\nalone, (2) using a mixed set that contains both the lung and tracheal sound to\ntrain the models, and (3) using domain adaptation that finetuned the\npre-trained lung sound models with the tracheal sound data and vice versa.\nResults showed that the models trained only by lung sound performed poorly in\nthe tracheal sound analysis and vice versa. However, the mixed set training and\ndomain adaptation can improve the performance of exhalation and CAS detection\nin the lung sound, and inhalation, exhalation, and CAS detection in the\ntracheal sound compared to positive controls (lung models trained only by lung\nsound and vice versa). Especially, a model derived from the mixed set training\nprevails in the situation of killing two birds with one stone.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:04:18 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Hsu", "Fu-Shun", ""], ["Huang", "Shang-Ran", ""], ["Su", "Chang-Fu", ""], ["Huang", "Chien-Wen", ""], ["Cheng", "Yuan-Ren", ""], ["Chen", "Chun-Chieh", ""], ["Wu", "Chun-Yu", ""], ["Chen", "Chung-Wei", ""], ["Lai", "Yen-Chun", ""], ["Cheng", "Tang-Wei", ""], ["Lin", "Nian-Jhen", ""], ["Tsai", "Wan-Ling", ""], ["Lu", "Ching-Shiang", ""], ["Chen", "Chuan", ""], ["Lai", "Feipei", ""]]}, {"id": "2107.04231", "submitter": "Vinod K Kurmi", "authors": "Vinod K Kurmi and Venkatesh K Subramanian and Vinay P. Namboodiri", "title": "Exploring Dropout Discriminator for Domain Adaptation", "comments": "This work is an extension of our BMVC-2019 paper (arXiv:1907.10628)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adaptation of a classifier to new domains is one of the challenging problems\nin machine learning. This has been addressed using many deep and non-deep\nlearning based methods. Among the methodologies used, that of adversarial\nlearning is widely applied to solve many deep learning problems along with\ndomain adaptation. These methods are based on a discriminator that ensures\nsource and target distributions are close. However, here we suggest that rather\nthan using a point estimate obtaining by a single discriminator, it would be\nuseful if a distribution based on ensembles of discriminators could be used to\nbridge this gap. This could be achieved using multiple classifiers or using\ntraditional ensemble methods. In contrast, we suggest that a Monte Carlo\ndropout based ensemble discriminator could suffice to obtain the distribution\nbased discriminator. Specifically, we propose a curriculum based dropout\ndiscriminator that gradually increases the variance of the sample based\ndistribution and the corresponding reverse gradients are used to align the\nsource and target feature representations. An ensemble of discriminators helps\nthe model to learn the data distribution efficiently. It also provides a better\ngradient estimates to train the feature extractor. The detailed results and\nthorough ablation analysis show that our model outperforms state-of-the-art\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:11:34 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kurmi", "Vinod K", ""], ["Subramanian", "Venkatesh K", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2107.04235", "submitter": "Johannes Leuschner", "authors": "S\\\"oren Schulze, Johannes Leuschner, Emily J. King", "title": "Training a Deep Neural Network via Policy Gradients for Blind Source\n  Separation in Polyphonic Music Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for the blind separation of sounds of musical instruments\nin audio signals. We describe the individual tones via a parametric model,\ntraining a dictionary to capture the relative amplitudes of the harmonics. The\nmodel parameters are predicted via a U-Net, which is a type of deep neural\nnetwork. The network is trained without ground truth information, based on the\ndifference between the model prediction and the individual STFT time frames.\nSince some of the model parameters do not yield a useful backpropagation\ngradient, we model them stochastically and employ the policy gradient instead.\nTo provide phase information and account for inaccuracies in the\ndictionary-based representation, we also let the network output a direct\nprediction, which we then use to resynthesize the audio signals for the\nindividual instruments. Due to the flexibility of the neural network,\ninharmonicity can be incorporated seamlessly and no preprocessing of the input\nspectra is required. Our algorithm yields high-quality separation results with\nparticularly low interference on a variety of different audio samples, both\nacoustic and synthetic, provided that the sample contains enough data for the\ntraining and that the spectral characteristics of the musical instruments are\nsufficiently stable to be approximated by the dictionary.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:17:04 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Schulze", "S\u00f6ren", ""], ["Leuschner", "Johannes", ""], ["King", "Emily J.", ""]]}, {"id": "2107.04239", "submitter": "Rui Wang", "authors": "Rui Wang and Xu Tan and Renqian Luo and Tao Qin and Tie-Yan Liu", "title": "A Survey on Low-Resource Neural Machine Translation", "comments": "A short version has been submitted to IJCAI2021 Survey Track on Feb.\n  26th, 2021, accepted on Apr. 16th, 2021. 14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural approaches have achieved state-of-the-art accuracy on machine\ntranslation but suffer from the high cost of collecting large scale parallel\ndata. Thus, a lot of research has been conducted for neural machine translation\n(NMT) with very limited parallel data, i.e., the low-resource setting. In this\npaper, we provide a survey for low-resource NMT and classify related works into\nthree categories according to the auxiliary data they used: (1) exploiting\nmonolingual data of source and/or target languages, (2) exploiting data from\nauxiliary languages, and (3) exploiting multi-modal data. We hope that our\nsurvey can help researchers to better understand this field and inspire them to\ndesign better algorithms, and help industry practitioners to choose appropriate\nalgorithms for their applications.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:26:38 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Wang", "Rui", ""], ["Tan", "Xu", ""], ["Luo", "Renqian", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2107.04240", "submitter": "Sharon Xiaolei Huang", "authors": "Yuan Xue, Yuan-Chen Guo, Han Zhang, Tao Xu, Song-Hai Zhang, Xiaolei\n  Huang", "title": "Deep Image Synthesis from Intuitive User Input: A Review and\n  Perspectives", "comments": "26 pages, 7 figures, 1 table", "journal-ref": "Computational Visual Media 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many applications of computer graphics, art and design, it is desirable\nfor a user to provide intuitive non-image input, such as text, sketch, stroke,\ngraph or layout, and have a computer system automatically generate\nphoto-realistic images that adhere to the input content. While classic works\nthat allow such automatic image content generation have followed a framework of\nimage retrieval and composition, recent advances in deep generative models such\nas generative adversarial networks (GANs), variational autoencoders (VAEs), and\nflow-based methods have enabled more powerful and versatile image generation\ntasks. This paper reviews recent works for image synthesis given intuitive user\ninput, covering advances in input versatility, image generation methodology,\nbenchmark datasets, and evaluation metrics. This motivates new perspectives on\ninput representation and interactivity, cross pollination between major image\ngeneration paradigms, and evaluation and comparison of generation methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:31:47 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Xue", "Yuan", ""], ["Guo", "Yuan-Chen", ""], ["Zhang", "Han", ""], ["Xu", "Tao", ""], ["Zhang", "Song-Hai", ""], ["Huang", "Xiaolei", ""]]}, {"id": "2107.04265", "submitter": "Alexander Ziller", "authors": "Alexander Ziller, Dmitrii Usynin, Moritz Knolle, Kritika Prakash,\n  Andrew Trask, Rickmer Braren, Marcus Makowski, Daniel Rueckert, Georgios\n  Kaissis", "title": "Sensitivity analysis in differentially private machine learning using\n  hybrid automatic differentiation", "comments": "Accepted to the ICML 2021 Theory and Practice of Differential Privacy\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, formal methods of privacy protection such as differential\nprivacy (DP), capable of deployment to data-driven tasks such as machine\nlearning (ML), have emerged. Reconciling large-scale ML with the closed-form\nreasoning required for the principled analysis of individual privacy loss\nrequires the introduction of new tools for automatic sensitivity analysis and\nfor tracking an individual's data and their features through the flow of\ncomputation. For this purpose, we introduce a novel \\textit{hybrid} automatic\ndifferentiation (AD) system which combines the efficiency of reverse-mode AD\nwith an ability to obtain a closed-form expression for any given quantity in\nthe computational graph. This enables modelling the sensitivity of arbitrary\ndifferentiable function compositions, such as the training of neural networks\non private data. We demonstrate our approach by analysing the individual DP\nguarantees of statistical database queries. Moreover, we investigate the\napplication of our technique to the training of DP neural networks. Our\napproach can enable the principled reasoning about privacy loss in the setting\nof data processing, and further the development of automatic sensitivity\nanalysis and privacy budgeting systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 07:19:23 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Ziller", "Alexander", ""], ["Usynin", "Dmitrii", ""], ["Knolle", "Moritz", ""], ["Prakash", "Kritika", ""], ["Trask", "Andrew", ""], ["Braren", "Rickmer", ""], ["Makowski", "Marcus", ""], ["Rueckert", "Daniel", ""], ["Kaissis", "Georgios", ""]]}, {"id": "2107.04271", "submitter": "Blesson Varghese", "authors": "Di Wu and Rehmat Ullah and Paul Harvey and Peter Kilpatrick and Ivor\n  Spence and Blesson Varghese", "title": "FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying Federated Learning (FL) on Internet-of-Things devices is\nnecessitated by the large volumes of data they produce and growing concerns of\ndata privacy. However, there are three challenges that need to be addressed to\nmake FL efficient: (i) execute on devices with limited computational\ncapabilities, (ii) account for stragglers due to computational heterogeneity of\ndevices, and (iii) adapt to the changing network bandwidths. This paper\npresents FedAdapt, an adaptive offloading FL framework to mitigate the\naforementioned challenges. FedAdapt accelerates local training in\ncomputationally constrained devices by leveraging layer offloading of deep\nneural networks (DNNs) to servers. Further, FedAdapt adopts reinforcement\nlearning-based optimization and clustering to adaptively identify which layers\nof the DNN should be offloaded for each individual device on to a server to\ntackle the challenges of computational heterogeneity and changing network\nbandwidth. Experimental studies are carried out on a lab-based testbed\ncomprising five IoT devices. By offloading a DNN from the device to the server\nFedAdapt reduces the training time of a typical IoT device by over half\ncompared to classic FL. The training time of extreme stragglers and the overall\ntraining time can be reduced by up to 57%. Furthermore, with changing network\nbandwidth, FedAdapt is demonstrated to reduce the training time by up to 40%\nwhen compared to classic FL, without sacrificing accuracy. FedAdapt can be\ndownloaded from https://github.com/qub-blesson/FedAdapt.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 07:29:55 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Wu", "Di", ""], ["Ullah", "Rehmat", ""], ["Harvey", "Paul", ""], ["Kilpatrick", "Peter", ""], ["Spence", "Ivor", ""], ["Varghese", "Blesson", ""]]}, {"id": "2107.04292", "submitter": "Yijun Wang", "authors": "Yijun Wang, Changzhi Sun, Yuanbin Wu, Hao Zhou, Lei Li, and Junchi Yan", "title": "UniRE: A Unified Label Space for Entity Relation Extraction", "comments": "ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many joint entity relation extraction models setup two separated label spaces\nfor the two sub-tasks (i.e., entity detection and relation classification). We\nargue that this setting may hinder the information interaction between entities\nand relations. In this work, we propose to eliminate the different treatment on\nthe two sub-tasks' label spaces. The input of our model is a table containing\nall word pairs from a sentence. Entities and relations are represented by\nsquares and rectangles in the table. We apply a unified classifier to predict\neach cell's label, which unifies the learning of two sub-tasks. For testing, an\neffective (yet fast) approximate decoder is proposed for finding squares and\nrectangles from tables. Experiments on three benchmarks (ACE04, ACE05, SciERC)\nshow that, using only half the number of parameters, our model achieves\ncompetitive accuracy with the best extractor, and is faster.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 08:09:37 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Wang", "Yijun", ""], ["Sun", "Changzhi", ""], ["Wu", "Yuanbin", ""], ["Zhou", "Hao", ""], ["Li", "Lei", ""], ["Yan", "Junchi", ""]]}, {"id": "2107.04296", "submitter": "Moritz Knolle", "authors": "Moritz Knolle, Alexander Ziller, Dmitrii Usynin, Rickmer Braren,\n  Marcus R. Makowski, Daniel Rueckert, Georgios Kaissis", "title": "Differentially private training of neural networks with Langevin\n  dynamics forcalibrated predictive uncertainty", "comments": "Accepted to the ICML 2021 Theory and Practice of Differential Privacy\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that differentially private stochastic gradient descent (DP-SGD) can\nyield poorly calibrated, overconfident deep learning models. This represents a\nserious issue for safety-critical applications, e.g. in medical diagnosis. We\nhighlight and exploit parallels between stochastic gradient Langevin dynamics,\na scalable Bayesian inference technique for training deep neural networks, and\nDP-SGD, in order to train differentially private, Bayesian neural networks with\nminor adjustments to the original (DP-SGD) algorithm. Our approach provides\nconsiderably more reliable uncertainty estimates than DP-SGD, as demonstrated\nempirically by a reduction in expected calibration error (MNIST $\\sim{5}$-fold,\nPediatric Pneumonia Dataset $\\sim{2}$-fold).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 08:14:45 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Knolle", "Moritz", ""], ["Ziller", "Alexander", ""], ["Usynin", "Dmitrii", ""], ["Braren", "Rickmer", ""], ["Makowski", "Marcus R.", ""], ["Rueckert", "Daniel", ""], ["Kaissis", "Georgios", ""]]}, {"id": "2107.04309", "submitter": "Rafael Poyiadzi", "authors": "Rafael Poyiadzi, Xavier Renard, Thibault Laugel, Raul\n  Santos-Rodriguez, Marcin Detyniecki", "title": "Understanding surrogate explanations: the interplay between complexity,\n  fidelity and coverage", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses the fundamental ingredients behind surrogate explanations\nto provide a better understanding of their inner workings. We start our\nexposition by considering global surrogates, describing the trade-off between\ncomplexity of the surrogate and fidelity to the black-box being modelled. We\nshow that transitioning from global to local - reducing coverage - allows for\nmore favourable conditions on the Pareto frontier of fidelity-complexity of a\nsurrogate. We discuss the interplay between complexity, fidelity and coverage,\nand consider how different user needs can lead to problem formulations where\nthese are either constraints or penalties. We also present experiments that\ndemonstrate how the local surrogate interpretability procedure can be made\ninteractive and lead to better explanations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 08:43:31 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Renard", "Xavier", ""], ["Laugel", "Thibault", ""], ["Santos-Rodriguez", "Raul", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2107.04312", "submitter": "Paraskevi Nousi", "authors": "Paraskevi Nousi, Styliani-Christina Fragkouli, Nikolaos Passalis,\n  Panagiotis Iosif, Theocharis Apostolatos, George Pappas, Nikolaos\n  Stergioulas, Anastasios Tefas", "title": "Autoencoder-driven Spiral Representation Learning for Gravitational Wave\n  Surrogate Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": "VIR-0678B-21", "categories": "cs.LG astro-ph.HE gr-qc", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, artificial neural networks have been gaining momentum in the field\nof gravitational wave astronomy, for example in surrogate modelling of\ncomputationally expensive waveform models for binary black hole inspiral and\nmerger. Surrogate modelling yields fast and accurate approximations of\ngravitational waves and neural networks have been used in the final step of\ninterpolating the coefficients of the surrogate model for arbitrary waveforms\noutside the training sample. We investigate the existence of underlying\nstructures in the empirical interpolation coefficients using autoencoders. We\ndemonstrate that when the coefficient space is compressed to only two\ndimensions, a spiral structure appears, wherein the spiral angle is linearly\nrelated to the mass ratio. Based on this finding, we design a spiral module\nwith learnable parameters, that is used as the first layer in a neural network,\nwhich learns to map the input space to the coefficients. The spiral module is\nevaluated on multiple neural network architectures and consistently achieves\nbetter speed-accuracy trade-off than baseline models. A thorough experimental\nstudy is conducted and the final result is a surrogate model which can evaluate\nmillions of input parameters in a single forward pass in under 1ms on a desktop\nGPU, while the mismatch between the corresponding generated waveforms and the\nground-truth waveforms is better than the compared baseline methods. We\nanticipate the existence of analogous underlying structures and corresponding\ncomputational gains also in the case of spinning black hole binaries.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 09:03:08 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Nousi", "Paraskevi", ""], ["Fragkouli", "Styliani-Christina", ""], ["Passalis", "Nikolaos", ""], ["Iosif", "Panagiotis", ""], ["Apostolatos", "Theocharis", ""], ["Pappas", "George", ""], ["Stergioulas", "Nikolaos", ""], ["Tefas", "Anastasios", ""]]}, {"id": "2107.04320", "submitter": "Wei Peng", "authors": "Wei Peng, Jun Zhang, Weien Zhou, Xiaoyu Zhao, Wen Yao, Xiaoqian Chen", "title": "IDRLnet: A Physics-Informed Neural Network Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physics Informed Neural Network (PINN) is a scientific computing framework\nused to solve both forward and inverse problems modeled by Partial Differential\nEquations (PDEs). This paper introduces IDRLnet, a Python toolbox for modeling\nand solving problems through PINN systematically. IDRLnet constructs the\nframework for a wide range of PINN algorithms and applications. It provides a\nstructured way to incorporate geometric objects, data sources, artificial\nneural networks, loss metrics, and optimizers within Python. Furthermore, it\nprovides functionality to solve noisy inverse problems, variational\nminimization, and integral differential equations. New PINN variants can be\nintegrated into the framework easily. Source code, tutorials, and documentation\nare available at \\url{https://github.com/idrl-lab/idrlnet}.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 09:18:35 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Peng", "Wei", ""], ["Zhang", "Jun", ""], ["Zhou", "Weien", ""], ["Zhao", "Xiaoyu", ""], ["Yao", "Wen", ""], ["Chen", "Xiaoqian", ""]]}, {"id": "2107.04333", "submitter": "Jingwei Zhang", "authors": "Jingwei Zhang, Bin Zi, Xiaoyu Ge", "title": "Attend2Pack: Bin Packing through Deep Reinforcement Learning with\n  Attention", "comments": "Reinforcement Learning for Real Life (RL4RealLife) Workshop in the\n  38th International Conference on Machine Learning, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper seeks to tackle the bin packing problem (BPP) through a learning\nperspective. Building on self-attention-based encoding and deep reinforcement\nlearning algorithms, we propose a new end-to-end learning model for this task\nof interest. By decomposing the combinatorial action space, as well as\nutilizing a new training technique denoted as prioritized oversampling, which\nis a general scheme to speed up on-policy learning, we achieve state-of-the-art\nperformance in a range of experimental settings. Moreover, although the\nproposed approach attend2pack targets offline-BPP, we strip our method down to\nthe strict online-BPP setting where it is also able to achieve state-of-the-art\nperformance. With a set of ablation studies as well as comparisons against a\nrange of previous works, we hope to offer as a valid baseline approach to this\nfield of study.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 10:00:30 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Zhang", "Jingwei", ""], ["Zi", "Bin", ""], ["Ge", "Xiaoyu", ""]]}, {"id": "2107.04346", "submitter": "Niklas Koenen", "authors": "Niklas Koenen, Marvin N. Wright, Peter Maa{\\ss} and Jens Behrmann", "title": "Generalization of the Change of Variables Formula with Applications to\n  Residual Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows leverage the Change of Variables Formula (CVF) to define\nflexible density models. Yet, the requirement of smooth transformations\n(diffeomorphisms) in the CVF poses a significant challenge in the construction\nof these models. To enlarge the design space of flows, we introduce\n$\\mathcal{L}$-diffeomorphisms as generalized transformations which may violate\nthese requirements on zero Lebesgue-measure sets. This relaxation allows e.g.\nthe use of non-smooth activation functions such as ReLU. Finally, we apply the\nobtained results to planar, radial, and contractive residual flows.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 10:31:32 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Koenen", "Niklas", ""], ["Wright", "Marvin N.", ""], ["Maa\u00df", "Peter", ""], ["Behrmann", "Jens", ""]]}, {"id": "2107.04357", "submitter": "Sanket Biswas", "authors": "Sanket Biswas, Pau Riba, Josep Llad\\'os, and Umapada Pal", "title": "Graph-based Deep Generative Modelling for Document Layout Generation", "comments": "Accepted by ICDAR Workshops-GLESDO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  One of the major prerequisites for any deep learning approach is the\navailability of large-scale training data. When dealing with scanned document\nimages in real world scenarios, the principal information of its content is\nstored in the layout itself. In this work, we have proposed an automated deep\ngenerative model using Graph Neural Networks (GNNs) to generate synthetic data\nwith highly variable and plausible document layouts that can be used to train\ndocument interpretation systems, in this case, specially in digital mailroom\napplications. It is also the first graph-based approach for document layout\ngeneration task experimented on administrative document images, in this case,\ninvoices.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 10:49:49 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Biswas", "Sanket", ""], ["Riba", "Pau", ""], ["Llad\u00f3s", "Josep", ""], ["Pal", "Umapada", ""]]}, {"id": "2107.04367", "submitter": "Jingyu Pan", "authors": "Xuezhong Lin, Jingyu Pan, Jinming Xu, Yiran Chen and Cheng Zhuo", "title": "Lithography Hotspot Detection via Heterogeneous Federated Learning with\n  Local Adaptation", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As technology scaling is approaching the physical limit, lithography hotspot\ndetection has become an essential task in design for manufacturability. While\nthe deployment of pattern matching or machine learning in hotspot detection can\nhelp save significant simulation time, such methods typically demand for\nnon-trivial quality data to build the model, which most design houses are short\nof. Moreover, the design houses are also unwilling to directly share such data\nwith the other houses to build a unified model, which can be ineffective for\nthe design house with unique design patterns due to data insufficiency. On the\nother hand, with data homogeneity in each design house, the locally trained\nmodels can be easily over-fitted, losing generalization ability and robustness.\nIn this paper, we propose a heterogeneous federated learning framework for\nlithography hotspot detection that can address the aforementioned issues. On\none hand, the framework can build a more robust centralized global sub-model\nthrough heterogeneous knowledge sharing while keeping local data private. On\nthe other hand, the global sub-model can be combined with a local sub-model to\nbetter adapt to local data heterogeneity. The experimental results show that\nthe proposed framework can overcome the challenge of non-independent and\nidentically distributed (non-IID) data and heterogeneous communication to\nachieve very high performance in comparison to other state-of-the-art methods\nwhile guaranteeing a good convergence rate in various scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 11:18:17 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 15:11:57 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Lin", "Xuezhong", ""], ["Pan", "Jingyu", ""], ["Xu", "Jinming", ""], ["Chen", "Yiran", ""], ["Zhuo", "Cheng", ""]]}, {"id": "2107.04369", "submitter": "Arber Zela", "authors": "Ashwin Raaghav Narayanan, Arber Zela, Tonmoy Saikia, Thomas Brox,\n  Frank Hutter", "title": "Multi-headed Neural Ensemble Search", "comments": "8 pages, 12 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of CNN models trained with different seeds (also known as Deep\nEnsembles) are known to achieve superior performance over a single copy of the\nCNN. Neural Ensemble Search (NES) can further boost performance by adding\narchitectural diversity. However, the scope of NES remains prohibitive under\nlimited computational resources. In this work, we extend NES to multi-headed\nensembles, which consist of a shared backbone attached to multiple prediction\nheads. Unlike Deep Ensembles, these multi-headed ensembles can be trained end\nto end, which enables us to leverage one-shot NAS methods to optimize an\nensemble objective. With extensive empirical evaluations, we demonstrate that\nmulti-headed ensemble search finds robust ensembles 3 times faster, while\nhaving comparable performance to other ensemble search methods, in both\npredictive performance and uncertainty calibration.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 11:20:48 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Narayanan", "Ashwin Raaghav", ""], ["Zela", "Arber", ""], ["Saikia", "Tonmoy", ""], ["Brox", "Thomas", ""], ["Hutter", "Frank", ""]]}, {"id": "2107.04380", "submitter": "Yerlan Idelbayev", "authors": "Miguel \\'A. Carreira-Perpi\\~n\\'an, Yerlan Idelbayev", "title": "Model compression as constrained optimization, with application to\n  neural nets. Part V: combining compressions", "comments": "29 pages, 9 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is generally performed by using quantization, low-rank\napproximation or pruning, for which various algorithms have been researched in\nrecent years. One fundamental question is: what types of compression work\nbetter for a given model? Or even better: can we improve by combining\ncompressions in a suitable way? We formulate this generally as a problem of\noptimizing the loss but where the weights are constrained to equal an additive\ncombination of separately compressed parts; and we give an algorithm to learn\nthe corresponding parts' parameters. Experimentally with deep neural nets, we\nobserve that 1) we can find significantly better models in the\nerror-compression space, indicating that different compression types have\ncomplementary benefits, and 2) the best type of combination depends exquisitely\non the type of neural net. For example, we can compress ResNets and AlexNet\nusing only 1 bit per weight without error degradation at the cost of adding a\nfew floating point weights. However, VGG nets can be better compressed by\ncombining low-rank with a few floating point weights.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:12:25 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Idelbayev", "Yerlan", ""]]}, {"id": "2107.04381", "submitter": "Sascha Meyen", "authors": "Sascha Meyen, Frieder G\\\"oppert, Helen Alber, Ulrike von Luxburg,\n  Volker H. Franz", "title": "Specialists Outperform Generalists in Ensemble Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider an ensemble of $k$ individual classifiers whose accuracies are\nknown. Upon receiving a test point, each of the classifiers outputs a predicted\nlabel and a confidence in its prediction for this particular test point. In\nthis paper, we address the question of whether we can determine the accuracy of\nthe ensemble. Surprisingly, even when classifiers are combined in the\nstatistically optimal way in this setting, the accuracy of the resulting\nensemble classifier cannot be computed from the accuracies of the individual\nclassifiers-as would be the case in the standard setting of confidence weighted\nmajority voting. We prove tight upper and lower bounds on the ensemble\naccuracy. We explicitly construct the individual classifiers that attain the\nupper and lower bounds: specialists and generalists. Our theoretical results\nhave very practical consequences: (1) If we use ensemble methods and have the\nchoice to construct our individual (independent) classifiers from scratch, then\nwe should aim for specialist classifiers rather than generalists. (2) Our\nbounds can be used to determine how many classifiers are at least required to\nachieve a desired ensemble accuracy. Finally, we improve our bounds by\nconsidering the mutual information between the true label and the individual\nclassifier's output.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:16:10 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Meyen", "Sascha", ""], ["G\u00f6ppert", "Frieder", ""], ["Alber", "Helen", ""], ["von Luxburg", "Ulrike", ""], ["Franz", "Volker H.", ""]]}, {"id": "2107.04382", "submitter": "Zeyd Boukhers", "authors": "Zeyd Boukhers, Nagaraj Bahubali, Abinaya Thulsi Chandrasekaran, Adarsh\n  Anand, Soniya Manchenahalli Gnanendra Prasadand, Sriram Aralappa", "title": "Bib2Auth: Deep Learning Approach for Author Disambiguation using\n  Bibliographic Data", "comments": "Accepted and presented at the workshop BiblioDAP@KDD2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Author name ambiguity remains a critical open problem in digital libraries\ndue to synonymy and homonymy of names. In this paper, we propose a novel\napproach to link author names to their real-world entities by relying on their\nco-authorship pattern and area of research. Our supervised deep learning model\nidentifies an author by capturing his/her relationship with his/her co-authors\nand area of research, which is represented by the titles and sources of the\ntarget author's publications. These attributes are encoded by their semantic\nand symbolic representations. To this end, Bib2Auth uses ~ 22K bibliographic\nrecords from the DBLP repository and is trained with each pair of co-authors.\nThe extensive experiments have proved the capability of the approach to\ndistinguish between authors sharing the same name and recognize authors with\ndifferent name variations. Bib2Auth has shown good performance on a relatively\nlarge dataset, which qualifies it to be directly integrated into bibliographic\nindices.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:25:11 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Boukhers", "Zeyd", ""], ["Bahubali", "Nagaraj", ""], ["Chandrasekaran", "Abinaya Thulsi", ""], ["Anand", "Adarsh", ""], ["Prasadand", "Soniya Manchenahalli Gnanendra", ""], ["Aralappa", "Sriram", ""]]}, {"id": "2107.04384", "submitter": "Sebastian Lee", "authors": "Sebastian Lee and Sebastian Goldt and Andrew Saxe", "title": "Continual Learning in the Teacher-Student Setup: Impact of Task\n  Similarity", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139:6109-6119, 2021", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning-the ability to learn many tasks in sequence-is critical\nfor artificial learning systems. Yet standard training methods for deep\nnetworks often suffer from catastrophic forgetting, where learning new tasks\nerases knowledge of earlier tasks. While catastrophic forgetting labels the\nproblem, the theoretical reasons for interference between tasks remain unclear.\nHere, we attempt to narrow this gap between theory and practice by studying\ncontinual learning in the teacher-student setup. We extend previous analytical\nwork on two-layer networks in the teacher-student setup to multiple teachers.\nUsing each teacher to represent a different task, we investigate how the\nrelationship between teachers affects the amount of forgetting and transfer\nexhibited by the student when the task switches. In line with recent work, we\nfind that when tasks depend on similar features, intermediate task similarity\nleads to greatest forgetting. However, feature similarity is only one way in\nwhich tasks may be related. The teacher-student approach allows us to\ndisentangle task similarity at the level of readouts (hidden-to-output weights)\nand features (input-to-hidden weights). We find a complex interplay between\nboth types of similarity, initial transfer/forgetting rates, maximum\ntransfer/forgetting, and long-term transfer/forgetting. Together, these results\nhelp illuminate the diverse factors contributing to catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:30:39 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lee", "Sebastian", ""], ["Goldt", "Sebastian", ""], ["Saxe", "Andrew", ""]]}, {"id": "2107.04388", "submitter": "Jessica Cooper", "authors": "Jessica Cooper, In Hwa Um, Ognjen Arandjelovi\\'c and David J Harrison", "title": "Hoechst Is All You Need: Lymphocyte Classification with Deep Learning", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiplex immunofluorescence and immunohistochemistry benefit patients by\nallowing cancer pathologists to identify several proteins expressed on the\nsurface of cells, enabling cell classification, better understanding of the\ntumour micro-environment, more accurate diagnoses, prognoses, and tailored\nimmunotherapy based on the immune status of individual patients. However, they\nare expensive and time consuming processes which require complex staining and\nimaging techniques by expert technicians. Hoechst staining is much cheaper and\neasier to perform, but is not typically used in this case as it binds to DNA\nrather than to the proteins targeted by immunofluorescent techniques, and it\nwas not previously thought possible to differentiate cells expressing these\nproteins based only on DNA morphology. In this work we show otherwise, training\na deep convolutional neural network to identify cells expressing three proteins\n(T lymphocyte markers CD3 and CD8, and the B lymphocyte marker CD20) with\ngreater than 90% precision and recall, from Hoechst 33342 stained tissue only.\nOur model learns previously unknown morphological features associated with\nexpression of these proteins which can be used to accurately differentiate\nlymphocyte subtypes for use in key prognostic metrics such as assessment of\nimmune cell infiltration,and thereby predict and improve patient outcomes\nwithout the need for costly multiplex immunofluorescence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:33:22 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 13:43:59 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Cooper", "Jessica", ""], ["Um", "In Hwa", ""], ["Arandjelovi\u0107", "Ognjen", ""], ["Harrison", "David J", ""]]}, {"id": "2107.04401", "submitter": "Zhuang Qian", "authors": "Zhuang Qian, Shufei Zhang, Kaizhu Huang, Qiufeng Wang, Rui Zhang,\n  Xinping Yi", "title": "Improving Model Robustness with Latent Distribution Locally and Globally", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider model robustness of deep neural networks against\nadversarial attacks from a global manifold perspective. Leveraging both the\nlocal and global latent information, we propose a novel adversarial training\nmethod through robust optimization, and a tractable way to generate Latent\nManifold Adversarial Examples (LMAEs) via an adversarial game between a\ndiscriminator and a classifier. The proposed adversarial training with latent\ndistribution (ATLD) method defends against adversarial attacks by crafting\nLMAEs with the latent manifold in an unsupervised manner. ATLD preserves the\nlocal and global information of latent manifold and promises improved\nrobustness against adversarial attacks. To verify the effectiveness of our\nproposed method, we conduct extensive experiments over different datasets\n(e.g., CIFAR-10, CIFAR-100, SVHN) with different adversarial attacks (e.g.,\nPGD, CW), and show that our method substantially outperforms the\nstate-of-the-art (e.g., Feature Scattering) in adversarial robustness by a\nlarge accuracy margin. The source codes are available at\nhttps://github.com/LitterQ/ATLD-pytorch.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 07:52:53 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Qian", "Zhuang", ""], ["Zhang", "Shufei", ""], ["Huang", "Kaizhu", ""], ["Wang", "Qiufeng", ""], ["Zhang", "Rui", ""], ["Yi", "Xinping", ""]]}, {"id": "2107.04419", "submitter": "Milan Aggarwal", "authors": "Milan Aggarwal, Hiresh Gupta, Mausoom Sarkar, Balaji Krishnamurthy", "title": "Form2Seq : A Framework for Higher-Order Form Structure Extraction", "comments": "This paper has been presented at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document structure extraction has been a widely researched area for decades\nwith recent works performing it as a semantic segmentation task over document\nimages using fully-convolution networks. Such methods are limited by image\nresolution due to which they fail to disambiguate structures in dense regions\nwhich appear commonly in forms. To mitigate this, we propose Form2Seq, a novel\nsequence-to-sequence (Seq2Seq) inspired framework for structure extraction\nusing text, with a specific focus on forms, which leverages relative spatial\narrangement of structures. We discuss two tasks; 1) Classification of low-level\nconstituent elements (TextBlock and empty fillable Widget) into ten types such\nas field captions, list items, and others; 2) Grouping lower-level elements\ninto higher-order constructs, such as Text Fields, ChoiceFields and\nChoiceGroups, used as information collection mechanism in forms. To achieve\nthis, we arrange the constituent elements linearly in natural reading order,\nfeed their spatial and textual representations to Seq2Seq framework, which\nsequentially outputs prediction of each element depending on the final task. We\nmodify Seq2Seq for grouping task and discuss improvements obtained through\ncascaded end-to-end training of two tasks versus training in isolation.\nExperimental results show the effectiveness of our text-based approach\nachieving an accuracy of 90% on classification task and an F1 of 75.82, 86.01,\n61.63 on groups discussed above respectively, outperforming segmentation\nbaselines. Further we show our framework achieves state of the results for\ntable structure recognition on ICDAR 2013 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:10:51 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Aggarwal", "Milan", ""], ["Gupta", "Hiresh", ""], ["Sarkar", "Mausoom", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2107.04422", "submitter": "Nithia Vijayan", "authors": "Nithia Vijayan and Prashanth L. A", "title": "Likelihood ratio-based policy gradient methods for distorted risk\n  measures: A non-asymptotic analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose policy-gradient algorithms for solving the problem of control in a\nrisk-sensitive reinforcement learning (RL) context. The objective of our\nalgorithm is to maximize the distorted risk measure (DRM) of the cumulative\nreward in an episodic Markov decision process (MDP). We derive a variant of the\npolicy gradient theorem that caters to the DRM objective. Using this theorem in\nconjunction with a likelihood ratio (LR) based gradient estimation scheme, we\npropose policy gradient algorithms for optimizing DRM in both on-policy and\noff-policy RL settings. We derive non-asymptotic bounds that establish the\nconvergence of our algorithms to an approximate stationary point of the DRM\nobjective.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:14:12 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 06:06:27 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Vijayan", "Nithia", ""], ["A", "Prashanth L.", ""]]}, {"id": "2107.04423", "submitter": "Emily Diana", "authors": "Emily Diana, Wesley Gill, Michael Kearns, Krishnaram Kenthapadi, Aaron\n  Roth, and Saeed Sharifi-Malvajerdi", "title": "Multiaccurate Proxies for Downstream Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of training a model that must obey demographic fairness\nconditions when the sensitive features are not available at training time -- in\nother words, how can we train a model to be fair by race when we don't have\ndata about race? We adopt a fairness pipeline perspective, in which an\n\"upstream\" learner that does have access to the sensitive features will learn a\nproxy model for these features from the other attributes. The goal of the proxy\nis to allow a general \"downstream\" learner -- with minimal assumptions on their\nprediction task -- to be able to use the proxy to train a model that is fair\nwith respect to the true sensitive features. We show that obeying multiaccuracy\nconstraints with respect to the downstream model class suffices for this\npurpose, and provide sample- and oracle efficient-algorithms and generalization\nbounds for learning such proxies. In general, multiaccuracy can be much easier\nto satisfy than classification accuracy, and can be satisfied even when the\nsensitive features are hard to predict.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:16:44 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Diana", "Emily", ""], ["Gill", "Wesley", ""], ["Kearns", "Michael", ""], ["Kenthapadi", "Krishnaram", ""], ["Roth", "Aaron", ""], ["Sharifi-Malvajerdi", "Saeed", ""]]}, {"id": "2107.04427", "submitter": "Tom Vermeire", "authors": "Tom Vermeire and Thibault Laugel and Xavier Renard and David Martens\n  and Marcin Detyniecki", "title": "How to choose an Explainability Method? Towards a Methodical\n  Implementation of XAI in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is becoming an important requirement for organizations that\nmake use of automated decision-making due to regulatory initiatives and a shift\nin public awareness. Various and significantly different algorithmic methods to\nprovide this explainability have been introduced in the field, but the existing\nliterature in the machine learning community has paid little attention to the\nstakeholder whose needs are rather studied in the human-computer interface\ncommunity. Therefore, organizations that want or need to provide this\nexplainability are confronted with the selection of an appropriate method for\ntheir use case. In this paper, we argue there is a need for a methodology to\nbridge the gap between stakeholder needs and explanation methods. We present\nour ongoing work on creating this methodology to help data scientists in the\nprocess of providing explainability to stakeholders. In particular, our\ncontributions include documents used to characterize XAI methods and user\nrequirements (shown in Appendix), which our methodology builds upon.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:22:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Vermeire", "Tom", ""], ["Laugel", "Thibault", ""], ["Renard", "Xavier", ""], ["Martens", "David", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2107.04435", "submitter": "Oliver De Candido", "authors": "Tobias Uelwer, Felix Michels, Oliver De Candido", "title": "Learning to Detect Adversarial Examples Based on Class Scores", "comments": "Accepted at the 44th German Conference on Artificial Intelligence (KI\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the increasing threat of adversarial attacks on deep neural networks\n(DNNs), research on efficient detection methods is more important than ever. In\nthis work, we take a closer look at adversarial attack detection based on the\nclass scores of an already trained classification model. We propose to train a\nsupport vector machine (SVM) on the class scores to detect adversarial\nexamples. Our method is able to detect adversarial examples generated by\nvarious attacks, and can be easily adopted to a plethora of deep classification\nmodels. We show that our approach yields an improved detection rate compared to\nan existing method, whilst being easy to implement. We perform an extensive\nempirical analysis on different deep classification models, investigating\nvarious state-of-the-art adversarial attacks. Moreover, we observe that our\nproposed method is better at detecting a combination of adversarial attacks.\nThis work indicates the potential of detecting various adversarial attacks\nsimply by using the class scores of an already trained classification model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:29:54 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Uelwer", "Tobias", ""], ["Michels", "Felix", ""], ["De Candido", "Oliver", ""]]}, {"id": "2107.04438", "submitter": "Timo Bertram", "authors": "Timo Bertram, Johannes F\\\"urnkranz, Martin M\\\"uller", "title": "A Comparison of Contextual and Non-Contextual Preference Ranking for Set\n  Addition Problems", "comments": "arXiv admin note: substantial text overlap with arXiv:2105.11864", "journal-ref": "SubSetML: Subset Selection in Machine Learning: From Theory to\n  Practice @ ICML 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the problem of evaluating the addition of elements to\na set. This problem is difficult, because it can, in the general case, not be\nreduced to unconditional preferences between the choices. Therefore, we model\npreferences based on the context of the decision. We discuss and compare two\ndifferent Siamese network architectures for this task: a twin network that\ncompares the two sets resulting after the addition, and a triplet network that\nmodels the contribution of each candidate to the existing set. We evaluate the\ntwo settings on a real-world task; learning human card preferences for deck\nbuilding in the collectible card game Magic: The Gathering. We show that the\ntriplet approach achieves a better result than the twin network and that both\noutperform previous results on this task.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:33:16 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bertram", "Timo", ""], ["F\u00fcrnkranz", "Johannes", ""], ["M\u00fcller", "Martin", ""]]}, {"id": "2107.04457", "submitter": "Stepan Makarenko", "authors": "Stepan Makarenko, Dmitry Sorokin, Alexander Ulanov, A. I. Lvovsky", "title": "Aligning an optical interferometer with beam divergence control and\n  continuous action space", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is finding its way to real-world problem application,\ntransferring from simulated environments to physical setups. In this work, we\nimplement vision-based alignment of an optical Mach-Zehnder interferometer with\na confocal telescope in one arm, which controls the diameter and divergence of\nthe corresponding beam. We use a continuous action space; exponential scaling\nenables us to handle actions within a range of over two orders of magnitude.\nOur agent trains only in a simulated environment with domain randomizations. In\nan experimental evaluation, the agent significantly outperforms an existing\nsolution and a human expert.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 14:23:01 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Makarenko", "Stepan", ""], ["Sorokin", "Dmitry", ""], ["Ulanov", "Alexander", ""], ["Lvovsky", "A. I.", ""]]}, {"id": "2107.04458", "submitter": "Eng-Jon Ong", "authors": "Eng-Jon Ong, Sameed Husain, Miroslaw Bober", "title": "Understanding the Distributions of Aggregation Layers in Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The process of aggregation is ubiquitous in almost all deep nets models. It\nfunctions as an important mechanism for consolidating deep features into a more\ncompact representation, whilst increasing robustness to overfitting and\nproviding spatial invariance in deep nets. In particular, the proximity of\nglobal aggregation layers to the output layers of DNNs mean that aggregated\nfeatures have a direct influence on the performance of a deep net. A better\nunderstanding of this relationship can be obtained using information theoretic\nmethods. However, this requires the knowledge of the distributions of the\nactivations of aggregation layers. To achieve this, we propose a novel\nmathematical formulation for analytically modelling the probability\ndistributions of output values of layers involved with deep feature\naggregation. An important outcome is our ability to analytically predict the\nKL-divergence of output nodes in a DNN. We also experimentally verify our\ntheoretical predictions against empirical observations across a range of\ndifferent classification tasks and datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 14:23:57 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Ong", "Eng-Jon", ""], ["Husain", "Sameed", ""], ["Bober", "Miroslaw", ""]]}, {"id": "2107.04462", "submitter": "Felix I. Stamm", "authors": "Felix I. Stamm, Martin Becker, Markus Strohmaier, Florian Lemmerich", "title": "Redescription Model Mining", "comments": null, "journal-ref": null, "doi": "10.1145/3447548.3467366", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Redescription Model Mining, a novel approach to\nidentify interpretable patterns across two datasets that share only a subset of\nattributes and have no common instances. In particular, Redescription Model\nMining aims to find pairs of describable data subsets -- one for each dataset\n-- that induce similar exceptional models with respect to a prespecified model\nclass. To achieve this, we combine two previously separate research areas:\nExceptional Model Mining and Redescription Mining. For this new problem\nsetting, we develop interestingness measures to select promising patterns,\npropose efficient algorithms, and demonstrate their potential on synthetic and\nreal-world data. Uncovered patterns can hint at common underlying phenomena\nthat manifest themselves across datasets, enabling the discovery of possible\nassociations between (combinations of) attributes that do not appear in the\nsame dataset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 14:26:00 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Stamm", "Felix I.", ""], ["Becker", "Martin", ""], ["Strohmaier", "Markus", ""], ["Lemmerich", "Florian", ""]]}, {"id": "2107.04464", "submitter": "Alessandro Finamore", "authors": "Giampaolo Bovenzi, Lixuan Yang, Alessandro Finamore, Giuseppe Aceto,\n  Domenico Ciuonzo, Antonio Pescap\\`e, Dario Rossi", "title": "A First Look at Class Incremental Learning in Deep Learning Mobile\n  Traffic Classification", "comments": "Accepted for publication at Network Traffic Measurement and Analysis\n  Conference (TMA), September 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent popularity growth of Deep Learning (DL) re-ignited the interest\ntowards traffic classification, with several studies demonstrating the accuracy\nof DL-based classifiers to identify Internet applications' traffic. Even with\nthe aid of hardware accelerators (GPUs, TPUs), DL model training remains\nexpensive, and limits the ability to operate frequent model updates necessary\nto fit to the ever evolving nature of Internet traffic, and mobile traffic in\nparticular. To address this pain point, in this work we explore Incremental\nLearning (IL) techniques to add new classes to models without a full\nretraining, hence speeding up model's updates cycle. We consider iCarl, a state\nof the art IL method, and MIRAGE-2019, a public dataset with traffic from 40\nAndroid apps, aiming to understand \"if there is a case for incremental learning\nin traffic classification\". By dissecting iCarl internals, we discuss ways to\nimprove its design, contributing a revised version, namely iCarl+. Despite our\nanalysis reveals their infancy, IL techniques are a promising research area on\nthe roadmap towards automated DL-based traffic analysis systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 14:28:16 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bovenzi", "Giampaolo", ""], ["Yang", "Lixuan", ""], ["Finamore", "Alessandro", ""], ["Aceto", "Giuseppe", ""], ["Ciuonzo", "Domenico", ""], ["Pescap\u00e8", "Antonio", ""], ["Rossi", "Dario", ""]]}, {"id": "2107.04470", "submitter": "Emadeldeen Eldele", "authors": "Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee-Keong\n  Kwoh, Xiaoli Li, and Cuntai Guan", "title": "Adversarial Domain Adaptation with Self-Training for EEG-based Sleep\n  Stage Classification", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sleep staging is of great importance in the diagnosis and treatment of sleep\ndisorders. Recently, numerous data driven deep learning models have been\nproposed for automatic sleep staging. They mainly rely on the assumption that\ntraining and testing data are drawn from the same distribution which may not\nhold in real-world scenarios. Unsupervised domain adaption (UDA) has been\nrecently developed to handle this domain shift problem. However, previous UDA\nmethods applied for sleep staging has two main limitations. First, they rely on\na totally shared model for the domain alignment, which may lose the\ndomain-specific information during feature extraction. Second, they only align\nthe source and target distributions globally without considering the class\ninformation in the target domain, which hinders the classification performance\nof the model. In this work, we propose a novel adversarial learning framework\nto tackle the domain shift problem in the unlabeled target domain. First, we\ndevelop unshared attention mechanisms to preserve the domain-specific features\nin the source and target domains. Second, we design a self-training strategy to\nalign the fine-grained class distributions for the source and target domains\nvia target domain pseudo labels. We also propose dual distinct classifiers to\nincrease the robustness and quality of the pseudo labels. The experimental\nresults on six cross-domain scenarios validate the efficacy of our proposed\nframework for sleep staging and its advantage over state-of-the-art UDA\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 14:56:12 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Eldele", "Emadeldeen", ""], ["Ragab", "Mohamed", ""], ["Chen", "Zhenghua", ""], ["Wu", "Min", ""], ["Kwoh", "Chee-Keong", ""], ["Li", "Xiaoli", ""], ["Guan", "Cuntai", ""]]}, {"id": "2107.04479", "submitter": "Adrian Riekert", "authors": "Arnulf Jentzen and Adrian Riekert", "title": "Convergence analysis for gradient flows in the training of artificial\n  neural networks with ReLU activation", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent (GD) type optimization schemes are the standard methods to\ntrain artificial neural networks (ANNs) with rectified linear unit (ReLU)\nactivation. Such schemes can be considered as discretizations of gradient flows\n(GFs) associated to the training of ANNs with ReLU activation and most of the\nkey difficulties in the mathematical convergence analysis of GD type\noptimization schemes in the training of ANNs with ReLU activation seem to be\nalready present in the dynamics of the corresponding GF differential equations.\nIt is the key subject of this work to analyze such GF differential equations in\nthe training of ANNs with ReLU activation and three layers (one input layer,\none hidden layer, and one output layer). In particular, in this article we\nprove in the case where the target function is possibly multi-dimensional and\ncontinuous and in the case where the probability distribution of the input data\nis absolutely continuous with respect to the Lebesgue measure that the risk of\nevery bounded GF trajectory converges to the risk of a critical point. In\naddition, in this article we show in the case of a 1-dimensional affine linear\ntarget function and in the case where the probability distribution of the input\ndata coincides with the standard uniform distribution that the risk of every\nbounded GF trajectory converges to zero if the initial risk is sufficiently\nsmall. Finally, in the special situation where there is only one neuron on the\nhidden layer (1-dimensional hidden layer) we strengthen the above named result\nfor affine linear target functions by proving that that the risk of every (not\nnecessarily bounded) GF trajectory converges to zero if the initial risk is\nsufficiently small.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:08:30 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Jentzen", "Arnulf", ""], ["Riekert", "Adrian", ""]]}, {"id": "2107.04485", "submitter": "Sampo Kuutti", "authors": "Sampo Kuutti, Saber Fallah, Richard Bowden", "title": "Adversarial Mixture Density Networks: Learning to Drive Safely from\n  Collision Data", "comments": "Accepted in IEEE Intelligent Transportation Systems Conference (ITSC)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has been widely used to learn control policies for\nautonomous driving based on pre-recorded data. However, imitation learning\nbased policies have been shown to be susceptible to compounding errors when\nencountering states outside of the training distribution. Further, these agents\nhave been demonstrated to be easily exploitable by adversarial road users\naiming to create collisions. To overcome these shortcomings, we introduce\nAdversarial Mixture Density Networks (AMDN), which learns two distributions\nfrom separate datasets. The first is a distribution of safe actions learned\nfrom a dataset of naturalistic human driving. The second is a distribution\nrepresenting unsafe actions likely to lead to collision, learned from a dataset\nof collisions. During training, we leverage these two distributions to provide\nan additional loss based on the similarity of the two distributions. By\npenalising the safe action distribution based on its similarity to the unsafe\naction distribution when training on the collision dataset, a more robust and\nsafe control policy is obtained. We demonstrate the proposed AMDN approach in a\nvehicle following use-case, and evaluate under naturalistic and adversarial\ntesting environments. We show that despite its simplicity, AMDN provides\nsignificant benefits for the safety of the learned control policy, when\ncompared to pure imitation learning or standard mixture density network\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:16:30 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kuutti", "Sampo", ""], ["Fallah", "Saber", ""], ["Bowden", "Richard", ""]]}, {"id": "2107.04487", "submitter": "Sampo Kuutti", "authors": "Sampo Kuutti, Saber Fallah, Richard Bowden", "title": "ARC: Adversarially Robust Control Policies for Autonomous Vehicles", "comments": "Accepted in IEEE Intelligent Transportation Systems Conference (ITSC)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have demonstrated their capability to learn control\npolicies for a variety of tasks. However, these neural network-based policies\nhave been shown to be susceptible to exploitation by adversarial agents.\nTherefore, there is a need to develop techniques to learn control policies that\nare robust against adversaries. We introduce Adversarially Robust Control\n(ARC), which trains the protagonist policy and the adversarial policy\nend-to-end on the same loss. The aim of the protagonist is to maximise this\nloss, whilst the adversary is attempting to minimise it. We demonstrate the\nproposed ARC training in a highway driving scenario, where the protagonist\ncontrols the follower vehicle whilst the adversary controls the lead vehicle.\nBy training the protagonist against an ensemble of adversaries, it learns a\nsignificantly more robust control policy, which generalises to a variety of\nadversarial strategies. The approach is shown to reduce the amount of\ncollisions against new adversaries by up to 90.25%, compared to the original\npolicy. Moreover, by utilising an auxiliary distillation loss, we show that the\nfine-tuned control policy shows no drop in performance across its original\ntraining distribution.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:22:29 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Kuutti", "Sampo", ""], ["Fallah", "Saber", ""], ["Bowden", "Richard", ""]]}, {"id": "2107.04491", "submitter": "Ran Liu", "authors": "Ran Liu (1 and 2), Joseph L. Greenstein (1 and 2), James C. Fackler\n  (3), Jules Bergmann (3), Melania M. Bembea (3 and 4), Raimond L. Winslow (1\n  and 2) ((1) Institute for Computational Medicine, the Johns Hopkins\n  University, (2) Department of Biomedical Engineering, the Johns Hopkins\n  University School of Medicine and Whiting School of Engineering, (3)\n  Department of Anesthesiology and Critical Care Medicine, the Johns Hopkins\n  University, (4) Department of Pediatrics, the Johns Hopkins University School\n  of Medicine)", "title": "Offline reinforcement learning with uncertainty for treatment strategies\n  in sepsis", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Guideline-based treatment for sepsis and septic shock is difficult because\nsepsis is a disparate range of life-threatening organ dysfunctions whose\npathophysiology is not fully understood. Early intervention in sepsis is\ncrucial for patient outcome, yet those interventions have adverse effects and\nare frequently overadministered. Greater personalization is necessary, as no\nsingle action is suitable for all patients. We present a novel application of\nreinforcement learning in which we identify optimal recommendations for sepsis\ntreatment from data, estimate their confidence level, and identify treatment\noptions infrequently observed in training data. Rather than a single\nrecommendation, our method can present several treatment options. We examine\nlearned policies and discover that reinforcement learning is biased against\naggressive intervention due to the confounding relationship between mortality\nand level of treatment received. We mitigate this bias using subspace learning,\nand develop methodology that can yield more accurate learning policies across\nhealthcare applications.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:29:05 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Liu", "Ran", "", "1 and 2"], ["Greenstein", "Joseph L.", "", "1 and 2"], ["Fackler", "James C.", "", "3 and 4"], ["Bergmann", "Jules", "", "3 and 4"], ["Bembea", "Melania M.", "", "3 and 4"], ["Winslow", "Raimond L.", "", "1\n  and 2"]]}, {"id": "2107.04497", "submitter": "Vincent Mai", "authors": "Vincent Mai, Waleed Khamies, Liam Paull", "title": "Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression", "comments": "Accepted at the Uncertainty in Deep Learning (UDL) workshop at ICML\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Heteroscedastic regression is the task of supervised learning where each\nlabel is subject to noise from a different distribution. This noise can be\ncaused by the labelling process, and impacts negatively the performance of the\nlearning algorithm as it violates the i.i.d. assumptions. In many situations\nhowever, the labelling process is able to estimate the variance of such\ndistribution for each label, which can be used as an additional information to\nmitigate this impact. We adapt an inverse-variance weighted mean square error,\nbased on the Gauss-Markov theorem, for parameter optimization on neural\nnetworks. We introduce Batch Inverse-Variance, a loss function which is robust\nto near-ground truth samples, and allows to control the effective learning\nrate. Our experimental results show that BIV improves significantly the\nperformance of the networks on two noisy datasets, compared to L2 loss,\ninverse-variance weighting, as well as a filtering-based baseline.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:39:31 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Mai", "Vincent", ""], ["Khamies", "Waleed", ""], ["Paull", "Liam", ""]]}, {"id": "2107.04512", "submitter": "Scott Roy", "authors": "Scott Roy, Cliff Brunk, Kyu-Young Kim, Justin Zhao, Markus Freitag,\n  Mihir Kale, Gagan Bansal, Sidharth Mudgal, Chris Varano", "title": "Using Machine Translation to Localize Task Oriented NLG Output", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in a task oriented natural language application like\nthe Google Assistant, Siri, or Alexa is to localize the output to many\nlanguages. This paper explores doing this by applying machine translation to\nthe English output. Using machine translation is very scalable, as it can work\nwith any English output and can handle dynamic text, but otherwise the problem\nis a poor fit. The required quality bar is close to perfection, the range of\nsentences is extremely narrow, and the sentences are often very different than\nthe ones in the machine translation training data. This combination of\nrequirements is novel in the field of domain adaptation for machine\ntranslation. We are able to reach the required quality bar by building on\nexisting ideas and adding new ones: finetuning on in-domain translations,\nadding sentences from the Web, adding semantic annotations, and using automatic\nerror detection. The paper shares our approach and results, together with a\ndistillation model to serve the translation models at scale.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:56:45 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Roy", "Scott", ""], ["Brunk", "Cliff", ""], ["Kim", "Kyu-Young", ""], ["Zhao", "Justin", ""], ["Freitag", "Markus", ""], ["Kale", "Mihir", ""], ["Bansal", "Gagan", ""], ["Mudgal", "Sidharth", ""], ["Varano", "Chris", ""]]}, {"id": "2107.04518", "submitter": "Qi Lei", "authors": "Baihe Huang, Kaixuan Huang, Sham M. Kakade, Jason D. Lee, Qi Lei,\n  Runzhe Wang, Jiaqi Yang", "title": "Optimal Gradient-based Algorithms for Non-concave Bandit Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Bandit problems with linear or concave reward have been extensively studied,\nbut relatively few works have studied bandits with non-concave reward. This\nwork considers a large family of bandit problems where the unknown underlying\nreward function is non-concave, including the low-rank generalized linear\nbandit problems and two-layer neural network with polynomial activation bandit\nproblem. For the low-rank generalized linear bandit problem, we provide a\nminimax-optimal algorithm in the dimension, refuting both conjectures in\n[LMT21, JWWN19]. Our algorithms are based on a unified zeroth-order\noptimization paradigm that applies in great generality and attains optimal\nrates in several structured polynomial settings (in the dimension). We further\ndemonstrate the applicability of our algorithms in RL in the generative model\nsetting, resulting in improved sample complexity over prior approaches.\nFinally, we show that the standard optimistic algorithms (e.g., UCB) are\nsub-optimal by dimension factors. In the neural net setting (with polynomial\nactivation functions) with noiseless reward, we provide a bandit algorithm with\nsample complexity equal to the intrinsic algebraic dimension. Again, we show\nthat optimistic approaches have worse sample complexity, polynomial in the\nextrinsic dimension (which could be exponentially worse in the polynomial\ndegree).\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:04:24 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Huang", "Baihe", ""], ["Huang", "Kaixuan", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""], ["Wang", "Runzhe", ""], ["Yang", "Jiaqi", ""]]}, {"id": "2107.04520", "submitter": "Ruihan Wu", "authors": "Ruihan Wu, Chuan Guo, Yi Su, Kilian Q. Weinberger", "title": "Online Adaptation to Label Distribution Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models often encounter distribution shifts when deployed in\nthe real world. In this paper, we focus on adaptation to label distribution\nshift in the online setting, where the test-time label distribution is\ncontinually changing and the model must dynamically adapt to it without\nobserving the true label. Leveraging a novel analysis, we show that the lack of\ntrue label does not hinder estimation of the expected test loss, which enables\nthe reduction of online label shift adaptation to conventional online learning.\nInformed by this observation, we propose adaptation algorithms inspired by\nclassical online learning techniques such as Follow The Leader (FTL) and Online\nGradient Descent (OGD) and derive their regret bounds. We empirically verify\nour findings under both simulated and real world label distribution shifts and\nshow that OGD is particularly effective and robust to a variety of challenging\nlabel shift scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:12:19 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Wu", "Ruihan", ""], ["Guo", "Chuan", ""], ["Su", "Yi", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2107.04522", "submitter": "Matthew Revelle", "authors": "Matt Revelle, Carlotta Domeniconi, Ben Gelman", "title": "Group-Node Attention for Community Evolution Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Communities in social networks evolve over time as people enter and leave the\nnetwork and their activity behaviors shift. The task of predicting structural\nchanges in communities over time is known as community evolution prediction.\nExisting work in this area has focused on the development of frameworks for\ndefining events while using traditional classification methods to perform the\nactual prediction. We present a novel graph neural network for predicting\ncommunity evolution events from structural and temporal information. The model\n(GNAN) includes a group-node attention component which enables support for\nvariable-sized inputs and learned representation of groups based on member and\nneighbor node features. A comparative evaluation with standard baseline methods\nis performed and we demonstrate that our model outperforms the baselines.\nAdditionally, we show the effects of network trends on model performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:16:10 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Revelle", "Matt", ""], ["Domeniconi", "Carlotta", ""], ["Gelman", "Ben", ""]]}, {"id": "2107.04527", "submitter": "Rika Antonova", "authors": "Rika Antonova, Fabio Ramos, Rafael Possas, Dieter Fox", "title": "BayesSimIG: Scalable Parameter Inference for Adaptive Domain\n  Randomization with IsaacGym", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BayesSim is a statistical technique for domain randomization in reinforcement\nlearning based on likelihood-free inference of simulation parameters. This\npaper outlines BayesSimIG: a library that provides an implementation of\nBayesSim integrated with the recently released NVIDIA IsaacGym. This\ncombination allows large-scale parameter inference with end-to-end GPU\nacceleration. Both inference and simulation get GPU speedup, with support for\nrunning more than 10K parallel simulation environments for complex robotics\ntasks that can have more than 100 simulation parameters to estimate. BayesSimIG\nprovides an integration with TensorBoard to easily visualize slices of\nhigh-dimensional posteriors. The library is built in a modular way to support\nresearch experiments with novel ways to collect and process the trajectories\nfrom the parallel IsaacGym environments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:21:31 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Antonova", "Rika", ""], ["Ramos", "Fabio", ""], ["Possas", "Rafael", ""], ["Fox", "Dieter", ""]]}, {"id": "2107.04533", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Stefan Wermter", "title": "Behavior Self-Organization Supports Task Inference for Continual Robot\n  Learning", "comments": "Accepted at IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in robot learning have enabled robots to become increasingly\nbetter at mastering a predefined set of tasks. On the other hand, as humans, we\nhave the ability to learn a growing set of tasks over our lifetime. Continual\nrobot learning is an emerging research direction with the goal of endowing\nrobots with this ability. In order to learn new tasks over time, the robot\nfirst needs to infer the task at hand. Task inference, however, has received\nlittle attention in the multi-task learning literature. In this paper, we\npropose a novel approach to continual learning of robotic control tasks. Our\napproach performs unsupervised learning of behavior embeddings by incrementally\nself-organizing demonstrated behaviors. Task inference is made by finding the\nnearest behavior embedding to a demonstrated behavior, which is used together\nwith the environment state as input to a multi-task policy trained with\nreinforcement learning to optimize performance over tasks. Unlike previous\napproaches, our approach makes no assumptions about task distribution and\nrequires no task exploration to infer tasks. We evaluate our approach in\nexperiments with concurrently and sequentially presented tasks and show that it\noutperforms other multi-task learning approaches in terms of generalization\nperformance and convergence speed, particularly in the continual learning\nsetting.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:37:27 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Wermter", "Stefan", ""]]}, {"id": "2107.04551", "submitter": "Amey Thakur", "authors": "Amey Thakur, Hasan Rizvi, Mega Satish", "title": "White-Box Cartoonization Using An Extended GAN Framework", "comments": "5 pages, 6 figures. International Journal of Engineering Applied\n  Sciences and Technology, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present study, we propose to implement a new framework for estimating\ngenerative models via an adversarial process to extend an existing GAN\nframework and develop a white-box controllable image cartoonization, which can\ngenerate high-quality cartooned images/videos from real-world photos and\nvideos. The learning purposes of our system are based on three distinct\nrepresentations: surface representation, structure representation, and texture\nrepresentation. The surface representation refers to the smooth surface of the\nimages. The structure representation relates to the sparse colour blocks and\ncompresses generic content. The texture representation shows the texture,\ncurves, and features in cartoon images. Generative Adversarial Network (GAN)\nframework decomposes the images into different representations and learns from\nthem to generate cartoon images. This decomposition makes the framework more\ncontrollable and flexible which allows users to make changes based on the\nrequired output. This approach overcomes any previous system in terms of\nmaintaining clarity, colours, textures, shapes of images yet showing the\ncharacteristics of cartoon images.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:09:19 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Thakur", "Amey", ""], ["Rizvi", "Hasan", ""], ["Satish", "Mega", ""]]}, {"id": "2107.04556", "submitter": "Pranshu Pant", "authors": "Pranshu Pant, Ruchit Doshi, Pranav Bahl, Amir Barati Farimani", "title": "Deep Learning for Reduced Order Modelling and Efficient Temporal\n  Evolution of Fluid Simulations", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced Order Modelling (ROM) has been widely used to create lower order,\ncomputationally inexpensive representations of higher-order dynamical systems.\nUsing these representations, ROMs can efficiently model flow fields while using\nsignificantly lesser parameters. Conventional ROMs accomplish this by linearly\nprojecting higher-order manifolds to lower-dimensional space using\ndimensionality reduction techniques such as Proper Orthogonal Decomposition\n(POD). In this work, we develop a novel deep learning framework DL-ROM (Deep\nLearning - Reduced Order Modelling) to create a neural network capable of\nnon-linear projections to reduced order states. We then use the learned reduced\nstate to efficiently predict future time steps of the simulation using 3D\nAutoencoder and 3D U-Net based architectures. Our model DL-ROM is able to\ncreate highly accurate reconstructions from the learned ROM and is thus able to\nefficiently predict future time steps by temporally traversing in the learned\nreduced state. All of this is achieved without ground truth supervision or\nneeding to iteratively solve the expensive Navier-Stokes(NS) equations thereby\nresulting in massive computational savings. To test the effectiveness and\nperformance of our approach, we evaluate our implementation on five different\nComputational Fluid Dynamics (CFD) datasets using reconstruction performance\nand computational runtime metrics. DL-ROM can reduce the computational runtimes\nof iterative solvers by nearly two orders of magnitude while maintaining an\nacceptable error threshold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:21:53 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Pant", "Pranshu", ""], ["Doshi", "Ruchit", ""], ["Bahl", "Pranav", ""], ["Farimani", "Amir Barati", ""]]}, {"id": "2107.04562", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan and H{\\aa}vard Rue", "title": "The Bayesian Learning Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that many machine-learning algorithms are specific instances of a\nsingle algorithm called the Bayesian learning rule. The rule, derived from\nBayesian principles, yields a wide-range of algorithms from fields such as\noptimization, deep learning, and graphical models. This includes classical\nalgorithms such as ridge regression, Newton's method, and Kalman filter, as\nwell as modern deep-learning algorithms such as stochastic-gradient descent,\nRMSprop, and Dropout. The key idea in deriving such algorithms is to\napproximate the posterior using candidate distributions estimated by using\nnatural gradients. Different candidate distributions result in different\nalgorithms and further approximations to natural gradients give rise to\nvariants of those algorithms. Our work not only unifies, generalizes, and\nimproves existing algorithms, but also helps us design new ones.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:28:55 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Rue", "H\u00e5vard", ""]]}, {"id": "2107.04565", "submitter": "Anthony Baptista", "authors": "Anthony Baptista, Aitor Gonzalez, Ana\\\"is Baudot", "title": "Universal Multilayer Network Exploration by Random Walk with Restart", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.soc-ph q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The amount and variety of data is increasing drastically for several years.\nThese data are often represented as networks, which are then explored with\napproaches arising from network theory. Recent years have witnessed the\nextension of network exploration methods to leverage more complex and richer\nnetwork frameworks. Random walks, for instance, have been extended to explore\nmultilayer networks. However, current random walk approaches are limited in the\ncombination and heterogeneity of network layers they can handle. New analytical\nand numerical random walk methods are needed to cope with the increasing\ndiversity and complexity of multilayer networks. We propose here MultiXrank, a\nPython package that enables Random Walk with Restart (RWR) on any kind of\nmultilayer network with an optimized implementation. This package is supported\nby a universal mathematical formulation of the RWR. We evaluated MultiXrank\nwith leave-one-out cross-validation and link prediction, and introduced\nprotocols to measure the impact of the addition or removal of multilayer\nnetwork data on prediction performances. We further measured the sensitivity of\nMultiXrank to input parameters by in-depth exploration of the parameter space.\nFinally, we illustrate the versatility of MultiXrank with different use-cases\nof unsupervised node prioritization and supervised classification in the\ncontext of human genetic diseases.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:33:45 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Baptista", "Anthony", ""], ["Gonzalez", "Aitor", ""], ["Baudot", "Ana\u00efs", ""]]}, {"id": "2107.04566", "submitter": "Naimul Mefraz Khan", "authors": "Zeeshan Ahmad, Suha Rabbani, Muhammad Rehman Zafar, Syem Ishaque,\n  Sridhar Krishnan, Naimul Khan", "title": "Multi-level Stress Assessment from ECG in a Virtual Reality Environment\n  using Multimodal Fusion", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ECG is an attractive option to assess stress in serious Virtual Reality (VR)\napplications due to its non-invasive nature. However, the existing Machine\nLearning (ML) models perform poorly. Moreover, existing studies only perform a\nbinary stress assessment, while to develop a more engaging biofeedback-based\napplication, multi-level assessment is necessary. Existing studies annotate and\nclassify a single experience (e.g. watching a VR video) to a single stress\nlevel, which again prevents design of dynamic experiences where real-time\nin-game stress assessment can be utilized. In this paper, we report our\nfindings on a new study on VR stress assessment, where three stress levels are\nassessed. ECG data was collected from 9 users experiencing a VR roller coaster.\nThe VR experience was then manually labeled in 10-seconds segments to three\nstress levels by three raters. We then propose a novel multimodal deep fusion\nmodel utilizing spectrogram and 1D ECG that can provide a stress prediction\nfrom just a 1-second window. Experimental results demonstrate that the proposed\nmodel outperforms the classical HRV-based ML models (9% increase in accuracy)\nand baseline deep learning models (2.5% increase in accuracy). We also report\nresults on the benchmark WESAD dataset to show the supremacy of the model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:34:42 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Rabbani", "Suha", ""], ["Zafar", "Muhammad Rehman", ""], ["Ishaque", "Syem", ""], ["Krishnan", "Sridhar", ""], ["Khan", "Naimul", ""]]}, {"id": "2107.04568", "submitter": "Mathieu Lauri\\`ere", "authors": "Ren\\'e Carmona and Mathieu Lauri\\`ere", "title": "Deep Learning for Mean Field Games and Mean Field Control with\n  Applications to Finance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets and more generally macro-economic models involve a large\nnumber of individuals interacting through variables such as prices resulting\nfrom the aggregate behavior of all the agents. Mean field games have been\nintroduced to study Nash equilibria for such problems in the limit when the\nnumber of players is infinite. The theory has been extensively developed in the\npast decade, using both analytical and probabilistic tools, and a wide range of\napplications have been discovered, from economics to crowd motion. More\nrecently the interaction with machine learning has attracted a growing\ninterest. This aspect is particularly relevant to solve very large games with\ncomplex structures, in high dimension or with common sources of randomness. In\nthis chapter, we review the literature on the interplay between mean field\ngames and deep learning, with a focus on three families of methods. A special\nemphasis is given to financial applications.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:40:11 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Carmona", "Ren\u00e9", ""], ["Lauri\u00e8re", "Mathieu", ""]]}, {"id": "2107.04570", "submitter": "Francisco Eiras", "authors": "Francisco Eiras, Motasem Alfarra, M. Pawan Kumar, Philip H. S. Torr,\n  Puneet K. Dokania, Bernard Ghanem, Adel Bibi", "title": "ANCER: Anisotropic Certification via Sample-wise Volume Maximization", "comments": "First two authors and the last one contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Randomized smoothing has recently emerged as an effective tool that enables\ncertification of deep neural network classifiers at scale. All prior art on\nrandomized smoothing has focused on isotropic $\\ell_p$ certification, which has\nthe advantage of yielding certificates that can be easily compared among\nisotropic methods via $\\ell_p$-norm radius. However, isotropic certification\nlimits the region that can be certified around an input to worst-case\nadversaries, i.e., it cannot reason about other \"close\", potentially large,\nconstant prediction safe regions. To alleviate this issue, (i) we theoretically\nextend the isotropic randomized smoothing $\\ell_1$ and $\\ell_2$ certificates to\ntheir generalized anisotropic counterparts following a simplified analysis.\nMoreover, (ii) we propose evaluation metrics allowing for the comparison of\ngeneral certificates - a certificate is superior to another if it certifies a\nsuperset region - with the quantification of each certificate through the\nvolume of the certified region. We introduce ANCER, a practical framework for\nobtaining anisotropic certificates for a given test set sample via volume\nmaximization. Our empirical results demonstrate that ANCER achieves\nstate-of-the-art $\\ell_1$ and $\\ell_2$ certified accuracy on both CIFAR-10 and\nImageNet at multiple radii, while certifying substantially larger regions in\nterms of volume, thus highlighting the benefits of moving away from isotropic\nanalysis. Code used in our experiments is available in\nhttps://github.com/MotasemAlfarra/ANCER.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:42:38 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 10:08:39 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Eiras", "Francisco", ""], ["Alfarra", "Motasem", ""], ["Kumar", "M. Pawan", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""], ["Ghanem", "Bernard", ""], ["Bibi", "Adel", ""]]}, {"id": "2107.04575", "submitter": "Yassine Barhoumi", "authors": "Yassine Barhoumi, Rasool Ghulam", "title": "Scopeformer: n-CNN-ViT Hybrid Model for Intracranial Hemorrhage\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a feature generator backbone composed of an ensemble of\nconvolutional neuralnetworks (CNNs) to improve the recently emerging Vision\nTransformer (ViT) models. We tackled the RSNA intracranial hemorrhage\nclassification problem, i.e., identifying various hemorrhage types from\ncomputed tomography (CT) slices. We show that by gradually stacking several\nfeature maps extracted using multiple Xception CNNs, we can develop a\nfeature-rich input for the ViT model. Our approach allowed the ViT model to pay\nattention to relevant features at multiple levels. Moreover, pretraining the n\nCNNs using various paradigms leads to a diverse feature set and further\nimproves the performance of the proposed n-CNN-ViT. We achieved a test accuracy\nof 98.04% with a weighted logarithmic loss value of 0.0708. The proposed\narchitecture is modular and scalable in both the number of CNNs used for\nfeature extraction and the size of the ViT.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 20:20:24 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Barhoumi", "Yassine", ""], ["Ghulam", "Rasool", ""]]}, {"id": "2107.04589", "submitter": "Kwonjoon Lee", "authors": "Kwonjoon Lee, Huiwen Chang, Lu Jiang, Han Zhang, Zhuowen Tu, Ce Liu", "title": "ViTGAN: Training GANs with Vision Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Vision Transformers (ViTs) have shown competitive performance on\nimage recognition while requiring less vision-specific inductive biases. In\nthis paper, we investigate if such observation can be extended to image\ngeneration. To this end, we integrate the ViT architecture into generative\nadversarial networks (GANs). We observe that existing regularization methods\nfor GANs interact poorly with self-attention, causing serious instability\nduring training. To resolve this issue, we introduce novel regularization\ntechniques for training GANs with ViTs. Empirically, our approach, named\nViTGAN, achieves comparable performance to state-of-the-art CNN-based StyleGAN2\non CIFAR-10, CelebA, and LSUN bedroom datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:59:30 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lee", "Kwonjoon", ""], ["Chang", "Huiwen", ""], ["Jiang", "Lu", ""], ["Zhang", "Han", ""], ["Tu", "Zhuowen", ""], ["Liu", "Ce", ""]]}, {"id": "2107.04616", "submitter": "Brandon Jacques", "authors": "Brandon G. Jacques, Zoran Tiganj, Aakash Sarkar, Marc W. Howard, Per\n  B. Sederberg", "title": "SITHCon: A neural network robust to variations in input scaling on the\n  time dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, convolutional neural networks (CNNs) have been extremely\ninfluential in both computer vision and in recognizing patterns extended over\ntime. In computer vision, part of the flexibility arises from the use of\nmax-pooling operations over the convolutions to attain translation invariance.\nIn the mammalian brain, neural representations of time use a set of temporal\nbasis functions. Critically, these basis functions appear to be arranged in a\ngeometric series such that the basis set is evenly distributed over logarithmic\ntime. This paper introduces a Scale-Invariant Temporal History Convolution\nnetwork (SITHCon) that uses a logarithmically-distributed temporal memory. A\nmax-pool over a logarithmically-distributed temporal memory results in\nscale-invariance in time. We compare performance of SITHCon to a Temporal\nConvolution Network (TCN) and demonstrate that, although both networks can\nlearn classification and regression problems on both univariate and\nmultivariate time series $f(t)$, only SITHCon has the property that it\ngeneralizes without retraining to rescaled versions of the input $f(at)$. This\nproperty, inspired by findings from neuroscience and psychology, could lead to\nlarge-scale networks with dramatically different capabilities, including faster\ntraining and greater generalizability, even with significantly fewer free\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 18:11:50 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jacques", "Brandon G.", ""], ["Tiganj", "Zoran", ""], ["Sarkar", "Aakash", ""], ["Howard", "Marc W.", ""], ["Sederberg", "Per B.", ""]]}, {"id": "2107.04619", "submitter": "Gaurav Shrivastava", "authors": "Gaurav Shrivastava and Abhinav Shrivastava", "title": "Diverse Video Generation using a Gaussian Process Trigger", "comments": "International Conference on Learning Representations, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Generating future frames given a few context (or past) frames is a\nchallenging task. It requires modeling the temporal coherence of videos and\nmulti-modality in terms of diversity in the potential future states. Current\nvariational approaches for video generation tend to marginalize over\nmulti-modal future outcomes. Instead, we propose to explicitly model the\nmulti-modality in the future outcomes and leverage it to sample diverse\nfutures. Our approach, Diverse Video Generator, uses a Gaussian Process (GP) to\nlearn priors on future states given the past and maintains a probability\ndistribution over possible futures given a particular sample. In addition, we\nleverage the changes in this distribution over time to control the sampling of\ndiverse future states by estimating the end of ongoing sequences. That is, we\nuse the variance of GP over the output function space to trigger a change in an\naction sequence. We achieve state-of-the-art results on diverse future frame\ngeneration in terms of reconstruction quality and diversity of the generated\nsequences.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 18:15:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shrivastava", "Gaurav", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "2107.04631", "submitter": "Fangcao Xu", "authors": "Fangcao Xu, Jian Sun, Guido Cervone, Mark Salvador", "title": "Ill-posed Surface Emissivity Retrieval from Multi-Geometry Hyperspectral\n  Images using a Hybrid Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Atmospheric correction is a fundamental task in remote sensing because\nobservations are taken either of the atmosphere or looking through the\natmosphere. Atmospheric correction errors can significantly alter the spectral\nsignature of the observations, and lead to invalid classifications or target\ndetection. This is even more crucial when working with hyperspectral data,\nwhere a precise measurement of spectral properties is required.\nState-of-the-art physics-based atmospheric correction approaches require\nextensive prior knowledge about sensor characteristics, collection geometry,\nand environmental characteristics of the scene being collected. These\napproaches are computationally expensive, prone to inaccuracy due to lack of\nsufficient environmental and collection information, and often impossible for\nreal-time applications. In this paper, a geometry-dependent hybrid neural\nnetwork is proposed for automatic atmospheric correction using multi-scan\nhyperspectral data collected from different geometries. The proposed network\ncan characterize the atmosphere without any additional meteorological data. A\ngrid-search method is also proposed to solve the temperature emissivity\nseparation problem. Results show that the proposed network has the capacity to\naccurately characterize the atmosphere and estimate target emissivity spectra\nwith a Mean Absolute Error (MAE) under 0.02 for 29 different materials. This\nsolution can lead to accurate atmospheric correction to improve target\ndetection for real time applications.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 18:59:58 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 01:07:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Xu", "Fangcao", ""], ["Sun", "Jian", ""], ["Cervone", "Guido", ""], ["Salvador", "Mark", ""]]}, {"id": "2107.04633", "submitter": "Taylor Dohmen", "authors": "Alvaro Velasquez, Andre Beckus, Taylor Dohmen, Ashutosh Trivedi, Noah\n  Topper, George Atia", "title": "Learning Probabilistic Reward Machines from Non-Markovian Stochastic\n  Reward Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The success of reinforcement learning in typical settings is, in part,\npredicated on underlying Markovian assumptions on the reward signal by which an\nagent learns optimal policies. In recent years, the use of reward machines has\nrelaxed this assumption by enabling a structured representation of\nnon-Markovian rewards. In particular, such representations can be used to\naugment the state space of the underlying decision process, thereby\nfacilitating non-Markovian reinforcement learning. However, these reward\nmachines cannot capture the semantics of stochastic reward signals. In this\npaper, we make progress on this front by introducing probabilistic reward\nmachines (PRMs) as a representation of non-Markovian stochastic rewards. We\npresent an algorithm to learn PRMs from the underlying decision process as well\nas to learn the PRM representation of a given decision-making policy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:00:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Velasquez", "Alvaro", ""], ["Beckus", "Andre", ""], ["Dohmen", "Taylor", ""], ["Trivedi", "Ashutosh", ""], ["Topper", "Noah", ""], ["Atia", "George", ""]]}, {"id": "2107.04641", "submitter": "Harikrishna Narasimhan", "authors": "Harikrishna Narasimhan, Aditya Krishna Menon", "title": "Training Over-parameterized Models with Non-decomposable Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern machine learning applications come with complex and nuanced\ndesign goals such as minimizing the worst-case error, satisfying a given\nprecision or recall target, or enforcing group-fairness constraints. Popular\ntechniques for optimizing such non-decomposable objectives reduce the problem\ninto a sequence of cost-sensitive learning tasks, each of which is then solved\nby re-weighting the training loss with example-specific costs. We point out\nthat the standard approach of re-weighting the loss to incorporate label costs\ncan produce unsatisfactory results when used to train over-parameterized\nmodels. As a remedy, we propose new cost-sensitive losses that extend the\nclassical idea of logit adjustment to handle more general cost matrices. Our\nlosses are calibrated, and can be further improved with distilled labels from a\nteacher model. Through experiments on benchmark image datasets, we showcase the\neffectiveness of our approach in training ResNet models with common robust and\nconstrained optimization objectives.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:29:33 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Narasimhan", "Harikrishna", ""], ["Menon", "Aditya Krishna", ""]]}, {"id": "2107.04642", "submitter": "Ben Green", "authors": "Ben Green", "title": "Impossibility of What? Formal and Substantive Equality in Algorithmic\n  Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the face of compounding crises of social and economic inequality, many\nhave turned to algorithmic decision-making to achieve greater fairness in\nsociety. As these efforts intensify, reasoning within the burgeoning field of\n\"algorithmic fairness\" increasingly shapes how fairness manifests in practice.\nThis paper interrogates whether algorithmic fairness provides the appropriate\nconceptual and practical tools for enhancing social equality. I argue that the\ndominant, \"formal\" approach to algorithmic fairness is ill-equipped as a\nframework for pursuing equality, as its narrow frame of analysis generates\nrestrictive approaches to reform. In light of these shortcomings, I propose an\nalternative: a \"substantive\" approach to algorithmic fairness that centers\nopposition to social hierarchies and provides a more expansive analysis of how\nto address inequality. This substantive approach enables more fruitful\ntheorizing about the role of algorithms in combatting oppression. The\ndistinction between formal and substantive algorithmic fairness is exemplified\nby each approach's responses to the \"impossibility of fairness\" (an\nincompatibility between mathematical definitions of algorithmic fairness).\nWhile the formal approach requires us to accept the \"impossibility of fairness\"\nas a harsh limit on efforts to enhance equality, the substantive approach\nallows us to escape the \"impossibility of fairness\" by suggesting reforms that\nare not subject to this false dilemma and that are better equipped to\nameliorate conditions of social oppression.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:29:57 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Green", "Ben", ""]]}, {"id": "2107.04649", "submitter": "John Miller", "authors": "John Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei\n  Koh, Vaishaal Shankar, Percy Liang, Yair Carmon, Ludwig Schmidt", "title": "Accuracy on the Line: On the Strong Correlation Between\n  Out-of-Distribution and In-Distribution Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine learning systems to be reliable, we must understand their\nperformance in unseen, out-of-distribution environments. In this paper, we\nempirically show that out-of-distribution performance is strongly correlated\nwith in-distribution performance for a wide range of models and distribution\nshifts. Specifically, we demonstrate strong correlations between\nin-distribution and out-of-distribution performance on variants of CIFAR-10 &\nImageNet, a synthetic pose estimation task derived from YCB objects, satellite\nimagery classification in FMoW-WILDS, and wildlife classification in\niWildCam-WILDS. The strong correlations hold across model architectures,\nhyperparameters, training set size, and training duration, and are more precise\nthan what is expected from existing domain adaptation theory. To complete the\npicture, we also investigate cases where the correlation is weaker, for\ninstance some synthetic distribution shifts from CIFAR-10-C and the tissue\nclassification dataset Camelyon17-WILDS. Finally, we provide a candidate theory\nbased on a Gaussian data model that shows how changes in the data covariance\narising from distribution shift can affect the observed correlations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:48:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Miller", "John", ""], ["Taori", "Rohan", ""], ["Raghunathan", "Aditi", ""], ["Sagawa", "Shiori", ""], ["Koh", "Pang Wei", ""], ["Shankar", "Vaishaal", ""], ["Liang", "Percy", ""], ["Carmon", "Yair", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "2107.04652", "submitter": "Andrej Risteski", "authors": "Divyansh Pareek, Andrej Risteski", "title": "The Effects of Invertibility on the Representational Complexity of\n  Encoders in Variational Autoencoders", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training and using modern neural-network based latent-variable generative\nmodels (like Variational Autoencoders) often require simultaneously training a\ngenerative direction along with an inferential(encoding) direction, which\napproximates the posterior distribution over the latent variables. Thus, the\nquestion arises: how complex does the inferential model need to be, in order to\nbe able to accurately model the posterior distribution of a given generative\nmodel?\n  In this paper, we identify an important property of the generative map\nimpacting the required size of the encoder. We show that if the generative map\nis \"strongly invertible\" (in a sense we suitably formalize), the inferential\nmodel need not be much more complex. Conversely, we prove that there exist\nnon-invertible generative maps, for which the encoding direction needs to be\nexponentially larger (under standard assumptions in computational complexity).\nImportantly, we do not require the generative model to be layerwise invertible,\nwhich a lot of the related literature assumes and isn't satisfied by many\narchitectures used in practice (e.g. convolution and pooling based networks).\nThus, we provide theoretical support for the empirical wisdom that learning\ndeep generative models is harder when data lies on a low-dimensional manifold.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:53:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pareek", "Divyansh", ""], ["Risteski", "Andrej", ""]]}, {"id": "2107.04661", "submitter": "Serge Assaad", "authors": "Serge Assaad, Shuxi Zeng, Henry Pfister, Fan Li, Lawrence Carin", "title": "H\\\"older Bounds for Sensitivity Analysis in Causal Reasoning", "comments": "Workshop on the Neglected Assumptions in Causal Inference at the\n  International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine interval estimation of the effect of a treatment T on an outcome Y\ngiven the existence of an unobserved confounder U. Using H\\\"older's inequality,\nwe derive a set of bounds on the confounding bias |E[Y|T=t]-E[Y|do(T=t)]| based\non the degree of unmeasured confounding (i.e., the strength of the connection\nU->T, and the strength of U->Y). These bounds are tight either when U is\nindependent of T or when U is independent of Y given T (when there is no\nunobserved confounding). We focus on a special case of this bound depending on\nthe total variation distance between the distributions p(U) and p(U|T=t), as\nwell as the maximum (over all possible values of U) deviation of the\nconditional expected outcome E[Y|U=u,T=t] from the average expected outcome\nE[Y|T=t]. We discuss possible calibration strategies for this bound to get\ninterval estimates for treatment effects, and experimentally validate the bound\nusing synthetic and semi-synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 20:26:36 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Assaad", "Serge", ""], ["Zeng", "Shuxi", ""], ["Pfister", "Henry", ""], ["Li", "Fan", ""], ["Carin", "Lawrence", ""]]}, {"id": "2107.04680", "submitter": "Raphael Mazzine", "authors": "Raphael Mazzine and David Martens", "title": "A Framework and Benchmarking Study for Counterfactual Generating Methods\n  on Tabular Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Counterfactual explanations are viewed as an effective way to explain machine\nlearning predictions. This interest is reflected by a relatively young\nliterature with already dozens of algorithms aiming to generate such\nexplanations. These algorithms are focused on finding how features can be\nmodified to change the output classification. However, this rather general\nobjective can be achieved in different ways, which brings about the need for a\nmethodology to test and benchmark these algorithms. The contributions of this\nwork are manifold: First, a large benchmarking study of 10 algorithmic\napproaches on 22 tabular datasets is performed, using 9 relevant evaluation\nmetrics. Second, the introduction of a novel, first of its kind, framework to\ntest counterfactual generation algorithms. Third, a set of objective metrics to\nevaluate and compare counterfactual results. And finally, insight from the\nbenchmarking results that indicate which approaches obtain the best performance\non what type of dataset. This benchmarking study and framework can help\npractitioners in determining which technique and building blocks most suit\ntheir context, and can help researchers in the design and evaluation of current\nand future counterfactual generation algorithms. Our findings show that,\noverall, there's no single best algorithm to generate counterfactual\nexplanations as the performance highly depends on properties related to the\ndataset, model, score and factual point specificities.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 21:06:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Mazzine", "Raphael", ""], ["Martens", "David", ""]]}, {"id": "2107.04689", "submitter": "Fei Ye", "authors": "Fei Ye and Adrian G. Bors", "title": "Lifelong Teacher-Student Network Learning", "comments": "18 pages, 18 figures. in IEEE Transactions on Pattern Analysis and\n  Machine Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3092677", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A unique cognitive capability of humans consists in their ability to acquire\nnew knowledge and skills from a sequence of experiences. Meanwhile, artificial\nintelligence systems are good at learning only the last given task without\nbeing able to remember the databases learnt in the past. We propose a novel\nlifelong learning methodology by employing a Teacher-Student network framework.\nWhile the Student module is trained with a new given database, the Teacher\nmodule would remind the Student about the information learnt in the past. The\nTeacher, implemented by a Generative Adversarial Network (GAN), is trained to\npreserve and replay past knowledge corresponding to the probabilistic\nrepresentations of previously learn databases. Meanwhile, the Student module is\nimplemented by a Variational Autoencoder (VAE) which infers its latent variable\nrepresentation from both the output of the Teacher module as well as from the\nnewly available database. Moreover, the Student module is trained to capture\nboth continuous and discrete underlying data representations across different\ndomains. The proposed lifelong learning framework is applied in supervised,\nsemi-supervised and unsupervised training. The code is available~:\n\\url{https://github.com/dtuzi123/Lifelong-Teacher-Student-Network-Learning}\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 21:25:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ye", "Fei", ""], ["Bors", "Adrian G.", ""]]}, {"id": "2107.04694", "submitter": "Fei Ye", "authors": "Fei Ye and Adrian G. Bors", "title": "Lifelong Mixture of Variational Autoencoders", "comments": "Accepted by IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose an end-to-end lifelong learning mixture of experts.\nEach expert is implemented by a Variational Autoencoder (VAE). The experts in\nthe mixture system are jointly trained by maximizing a mixture of individual\ncomponent evidence lower bounds (MELBO) on the log-likelihood of the given\ntraining samples. The mixing coefficients in the mixture, control the\ncontributions of each expert in the goal representation. These are sampled from\na Dirichlet distribution whose parameters are determined through non-parametric\nestimation during lifelong learning. The model can learn new tasks fast when\nthese are similar to those previously learnt. The proposed Lifelong mixture of\nVAE (L-MVAE) expands its architecture with new components when learning a\ncompletely new task. After the training, our model can automatically determine\nthe relevant expert to be used when fed with new data samples. This mechanism\nbenefits both the memory efficiency and the required computational cost as only\none expert is used during the inference. The L-MVAE inference model is able to\nperform interpolation in the joint latent space across the data domains\nassociated with different tasks and is shown to be efficient for disentangled\nlearning representation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:07:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ye", "Fei", ""], ["Bors", "Adrian G.", ""]]}, {"id": "2107.04695", "submitter": "Christian Samuel Perone", "authors": "Christian S. Perone, Roberto Pereira Silveira, Thomas Paula", "title": "L2M: Practical posterior Laplace approximation with optimization-driven\n  second moment estimation", "comments": "6 pages, 1 figure, accepted for ICML 2021 UDL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification for deep neural networks has recently evolved\nthrough many techniques. In this work, we revisit Laplace approximation, a\nclassical approach for posterior approximation that is computationally\nattractive. However, instead of computing the curvature matrix, we show that,\nunder some regularity conditions, the Laplace approximation can be easily\nconstructed using the gradient second moment. This quantity is already\nestimated by many exponential moving average variants of Adagrad such as Adam\nand RMSprop, but is traditionally discarded after training. We show that our\nmethod (L2M) does not require changes in models or optimization, can be\nimplemented in a few lines of code to yield reasonable results, and it does not\nrequire any extra computational steps besides what is already being computed by\noptimizers, without introducing any new hyperparameter. We hope our method can\nopen new research directions on using quantities already computed by optimizers\nfor uncertainty estimation in deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:14:54 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Perone", "Christian S.", ""], ["Silveira", "Roberto Pereira", ""], ["Paula", "Thomas", ""]]}, {"id": "2107.04705", "submitter": "Fei Ye", "authors": "Fei Ye and Adrian G. Bors", "title": "InfoVAEGAN : learning joint interpretable representations by information\n  maximization and maximum likelihood", "comments": "Accepted at International Conference on Image Processing (ICIP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Learning disentangled and interpretable representations is an important step\ntowards accomplishing comprehensive data representations on the manifold. In\nthis paper, we propose a novel representation learning algorithm which combines\nthe inference abilities of Variational Autoencoders (VAE) with the\ngeneralization capability of Generative Adversarial Networks (GAN). The\nproposed model, called InfoVAEGAN, consists of three networks~: Encoder,\nGenerator and Discriminator. InfoVAEGAN aims to jointly learn discrete and\ncontinuous interpretable representations in an unsupervised manner by using two\ndifferent data-free log-likelihood functions onto the variables sampled from\nthe generator's distribution. We propose a two-stage algorithm for optimizing\nthe inference network separately from the generator training. Moreover, we\nenforce the learning of interpretable representations through the maximization\nof the mutual information between the existing latent variables and those\ncreated through generative and inference processes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:38:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ye", "Fei", ""], ["Bors", "Adrian G.", ""]]}, {"id": "2107.04713", "submitter": "Ronghang Zhu", "authors": "Ronghang Zhu and Zhiqiang Tao and Yaliang Li and Sheng Li", "title": "Automated Graph Learning via Population Based Self-Tuning GCN", "comments": "This manuscript has been accepted by the SIGIR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Owing to the remarkable capability of extracting effective graph embeddings,\ngraph convolutional network (GCN) and its variants have been successfully\napplied to a broad range of tasks, such as node classification, link\nprediction, and graph classification. Traditional GCN models suffer from the\nissues of overfitting and oversmoothing, while some recent techniques like\nDropEdge could alleviate these issues and thus enable the development of deep\nGCN. However, training GCN models is non-trivial, as it is sensitive to the\nchoice of hyperparameters such as dropout rate and learning weight decay,\nespecially for deep GCN models. In this paper, we aim to automate the training\nof GCN models through hyperparameter optimization. To be specific, we propose a\nself-tuning GCN approach with an alternate training algorithm, and further\nextend our approach by incorporating the population based training scheme.\nExperimental results on three benchmark datasets demonstrate the effectiveness\nof our approaches on optimizing multi-layer GCN, compared with several\nrepresentative baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 23:05:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhu", "Ronghang", ""], ["Tao", "Zhiqiang", ""], ["Li", "Yaliang", ""], ["Li", "Sheng", ""]]}, {"id": "2107.04714", "submitter": "Henry Kvinge", "authors": "Henry Kvinge, Colby Wight, Sarah Akers, Scott Howland, Woongjo Choi,\n  Xiaolong Ma, Luke Gosink, Elizabeth Jurrus, Keerti Kappagantula, Tegan H.\n  Emerson", "title": "A Topological-Framework to Improve Analysis of Machine Learning Model\n  Performance", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As both machine learning models and the datasets on which they are evaluated\nhave grown in size and complexity, the practice of using a few summary\nstatistics to understand model performance has become increasingly problematic.\nThis is particularly true in real-world scenarios where understanding model\nfailure on certain subpopulations of the data is of critical importance. In\nthis paper we propose a topological framework for evaluating machine learning\nmodels in which a dataset is treated as a \"space\" on which a model operates.\nThis provides us with a principled way to organize information about model\nperformance at both the global level (over the entire test set) and also the\nlocal level (on specific subpopulations). Finally, we describe a topological\ndata structure, presheaves, which offer a convenient way to store and analyze\nmodel performance between different subpopulations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 23:11:13 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kvinge", "Henry", ""], ["Wight", "Colby", ""], ["Akers", "Sarah", ""], ["Howland", "Scott", ""], ["Choi", "Woongjo", ""], ["Ma", "Xiaolong", ""], ["Gosink", "Luke", ""], ["Jurrus", "Elizabeth", ""], ["Kappagantula", "Keerti", ""], ["Emerson", "Tegan H.", ""]]}, {"id": "2107.04721", "submitter": "Michael Beyeler", "authors": "Shuyun Tang, Ziming Qi, Jacob Granley and Michael Beyeler", "title": "U-Net with Hierarchical Bottleneck Attention for Landmark Detection in\n  Fundus Images of the Degenerated Retina", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fundus photography has routinely been used to document the presence and\nseverity of retinal degenerative diseases such as age-related macular\ndegeneration (AMD), glaucoma, and diabetic retinopathy (DR) in clinical\npractice, for which the fovea and optic disc (OD) are important retinal\nlandmarks. However, the occurrence of lesions, drusen, and other retinal\nabnormalities during retinal degeneration severely complicates automatic\nlandmark detection and segmentation. Here we propose HBA-U-Net: a U-Net\nbackbone enriched with hierarchical bottleneck attention. The network consists\nof a novel bottleneck attention block that combines and refines self-attention,\nchannel attention, and relative-position attention to highlight retinal\nabnormalities that may be important for fovea and OD segmentation in the\ndegenerated retina. HBA-U-Net achieved state-of-the-art results on fovea\ndetection across datasets and eye conditions (ADAM: Euclidean Distance (ED) of\n25.4 pixels, REFUGE: 32.5 pixels, IDRiD: 32.1 pixels), on OD segmentation for\nAMD (ADAM: Dice Coefficient (DC) of 0.947), and on OD detection for DR (IDRiD:\nED of 20.5 pixels). Our results suggest that HBA-U-Net may be well suited for\nlandmark detection in the presence of a variety of retinal degenerative\ndiseases.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 23:57:51 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tang", "Shuyun", ""], ["Qi", "Ziming", ""], ["Granley", "Jacob", ""], ["Beyeler", "Michael", ""]]}, {"id": "2107.04724", "submitter": "Qingyu Zhao", "authors": "Qingyu Zhao, Ehsan Adeli, Kilian M. Pohl", "title": "Longitudinal Correlation Analysis for Decoding Multi-Modal Brain\n  Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from childhood, the human brain restructures and rewires throughout\nlife. Characterizing such complex brain development requires effective analysis\nof longitudinal and multi-modal neuroimaging data. Here, we propose such an\nanalysis approach named Longitudinal Correlation Analysis (LCA). LCA couples\nthe data of two modalities by first reducing the input from each modality to a\nlatent representation based on autoencoders. A self-supervised strategy then\nrelates the two latent spaces by jointly disentangling two directions, one in\neach space, such that the longitudinal changes in latent representations along\nthose directions are maximally correlated between modalities. We applied LCA to\nanalyze the longitudinal T1-weighted and diffusion-weighted MRIs of 679 youths\nfrom the National Consortium on Alcohol and Neurodevelopment in Adolescence.\nUnlike existing approaches that focus on either cross-sectional or single-modal\nmodeling, LCA successfully unraveled coupled macrostructural and\nmicrostructural brain development from morphological and diffusivity features\nextracted from the data. A retesting of LCA on raw 3D image volumes of those\nsubjects successfully replicated the findings from the feature-based analysis.\nLastly, the developmental effects revealed by LCA were inline with the current\nunderstanding of maturational patterns of the adolescent brain.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 00:07:06 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhao", "Qingyu", ""], ["Adeli", "Ehsan", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "2107.04734", "submitter": "Ankita Pasad", "authors": "Ankita Pasad, Ju-Chieh Chou, Karen Livescu", "title": "Layer-wise Analysis of a Self-supervised Speech Representation Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed self-supervised learning approaches have been successful\nfor pre-training speech representation models. The utility of these learned\nrepresentations has been observed empirically, but not much has been studied\nabout the type or extent of information encoded in the pre-trained\nrepresentations themselves. Developing such insights can help understand the\ncapabilities and limits of these models and enable the research community to\nmore efficiently develop their usage for downstream applications. In this work,\nwe begin to fill this gap by examining one recent and successful pre-trained\nmodel (wav2vec 2.0), via its intermediate representation vectors, using a suite\nof analysis tools. We use the metrics of canonical correlation, mutual\ninformation, and performance on simple downstream tasks with non-parametric\nprobes, in order to (i) query for acoustic and linguistic information content,\n(ii) characterize the evolution of information across model layers, and (iii)\nunderstand how fine-tuning the model for automatic speech recognition (ASR)\naffects these observations. Our findings motivate modifying the fine-tuning\nprotocol for ASR, which produces improved word error rates in a low-resource\nsetting.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 02:13:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pasad", "Ankita", ""], ["Chou", "Ju-Chieh", ""], ["Livescu", "Karen", ""]]}, {"id": "2107.04750", "submitter": "Lantao Yu", "authors": "Hongwei Wang, Lantao Yu, Zhangjie Cao, Stefano Ermon", "title": "Multi-Agent Imitation Learning with Copulas", "comments": "ECML-PKDD 2021. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent imitation learning aims to train multiple agents to perform tasks\nfrom demonstrations by learning a mapping between observations and actions,\nwhich is essential for understanding physical, social, and team-play systems.\nHowever, most existing works on modeling multi-agent interactions typically\nassume that agents make independent decisions based on their observations,\nignoring the complex dependence among agents. In this paper, we propose to use\ncopula, a powerful statistical tool for capturing dependence among random\nvariables, to explicitly model the correlation and coordination in multi-agent\nsystems. Our proposed model is able to separately learn marginals that capture\nthe local behavioral patterns of each individual agent, as well as a copula\nfunction that solely and fully captures the dependence structure among agents.\nExtensive experiments on synthetic and real-world datasets show that our model\noutperforms state-of-the-art baselines across various scenarios in the action\nprediction task, and is able to generate new trajectories close to expert\ndemonstrations.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 03:49:41 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Hongwei", ""], ["Yu", "Lantao", ""], ["Cao", "Zhangjie", ""], ["Ermon", "Stefano", ""]]}, {"id": "2107.04755", "submitter": "Shirui Pan", "authors": "Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Beyond Low-pass Filtering: Graph Convolutional Networks with Automatic\n  Filtering", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Graph convolutional networks are becoming indispensable for deep learning\nfrom graph-structured data. Most of the existing graph convolutional networks\nshare two big shortcomings. First, they are essentially low-pass filters, thus\nthe potentially useful middle and high frequency band of graph signals are\nignored. Second, the bandwidth of existing graph convolutional filters is\nfixed. Parameters of a graph convolutional filter only transform the graph\ninputs without changing the curvature of a graph convolutional filter function.\nIn reality, we are uncertain about whether we should retain or cut off the\nfrequency at a certain point unless we have expert domain knowledge. In this\npaper, we propose Automatic Graph Convolutional Networks (AutoGCN) to capture\nthe full spectrum of graph signals and automatically update the bandwidth of\ngraph convolutional filters. While it is based on graph spectral theory, our\nAutoGCN is also localized in space and has a spatial form. Experimental results\nshow that AutoGCN achieves significant improvement over baseline methods which\nonly work as low-pass filters.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 04:11:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Zonghan", ""], ["Pan", "Shirui", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "2107.04764", "submitter": "Mohamed Nassar", "authors": "Sara Hajj Ibrahim and Mohamed Nassar", "title": "Hack The Box: Fooling Deep Learning Abstraction-Based Monitors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is a type of machine learning that adapts a deep hierarchy of\nconcepts. Deep learning classifiers link the most basic version of concepts at\nthe input layer to the most abstract version of concepts at the output layer,\nalso known as a class or label. However, once trained over a finite set of\nclasses, some deep learning models do not have the power to say that a given\ninput does not belong to any of the classes and simply cannot be linked.\nCorrectly invalidating the prediction of unrelated classes is a challenging\nproblem that has been tackled in many ways in the literature. Novelty detection\ngives deep learning the ability to output \"do not know\" for novel/unseen\nclasses. Still, no attention has been given to the security aspects of novelty\ndetection. In this paper, we consider the case study of abstraction-based\nnovelty detection and show that it is not robust against adversarial samples.\nMoreover, we show the feasibility of crafting adversarial samples that fool the\ndeep learning classifier and bypass the novelty detection monitoring at the\nsame time. In other words, these monitoring boxes are hackable. We demonstrate\nthat novelty detection itself ends up as an attack surface.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 05:06:04 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 05:19:11 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 20:50:55 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ibrahim", "Sara Hajj", ""], ["Nassar", "Mohamed", ""]]}, {"id": "2107.04766", "submitter": "Yuling Jiao", "authors": "Yuling Jiao and Lican Kang and Yanyan Liu and Youzhou Zhou", "title": "Convergence Analysis of Schr{\\\"o}dinger-F{\\\"o}llmer Sampler without\n  Convexity", "comments": "arXiv admin note: text overlap with arXiv:2106.10880", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schr\\\"{o}dinger-F\\\"{o}llmer sampler (SFS) is a novel and efficient approach\nfor sampling from possibly unnormalized distributions without ergodicity. SFS\nis based on the Euler-Maruyama discretization of Schr\\\"{o}dinger-F\\\"{o}llmer\ndiffusion process $$\\mathrm{d} X_{t}=-\\nabla U\\left(X_t, t\\right) \\mathrm{d}\nt+\\mathrm{d} B_{t}, \\quad t \\in[0,1],\\quad X_0=0$$ on the unit interval, which\ntransports the degenerate distribution at time zero to the target distribution\nat time one. In \\cite{sfs21}, the consistency of SFS is established under a\nrestricted assumption that %the drift term $b(x,t)$ the potential $U(x,t)$ is\nuniformly (on $t$) strongly %concave convex (on $x$). In this paper we provide\na nonasymptotic error bound of SFS in Wasserstein distance under some smooth\nand bounded conditions on the density ratio of the target distribution over the\nstandard normal distribution, but without requiring the strongly convexity of\nthe potential.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 05:37:50 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jiao", "Yuling", ""], ["Kang", "Lican", ""], ["Liu", "Yanyan", ""], ["Zhou", "Youzhou", ""]]}, {"id": "2107.04773", "submitter": "Lun Du", "authors": "Lun Du, Xiaozhou Shi, Yanlin Wang, Ensheng Shi, Shi Han and Dongmei\n  Zhang", "title": "Is a Single Model Enough? MuCoS: A Multi-Model Ensemble Learning for\n  Semantic Code Search", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning methods have become mainstream in code search since\nthey do better at capturing semantic correlations between code snippets and\nsearch queries and have promising performance. However, code snippets have\ndiverse information from different dimensions, such as business logic, specific\nalgorithm, and hardware communication, so it is hard for a single code\nrepresentation module to cover all the perspectives. On the other hand, as a\nspecific query may focus on one or several perspectives, it is difficult for a\nsingle query representation module to represent different user intents. In this\npaper, we propose MuCoS, a multi-model ensemble learning architecture for\nsemantic code search. It combines several individual learners, each of which\nemphasizes a specific perspective of code snippets. We train the individual\nlearners on different datasets which contain different perspectives of code\ninformation, and we use a data augmentation strategy to get these different\ndatasets. Then we ensemble the learners to capture comprehensive features of\ncode snippets.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 06:40:44 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 02:42:51 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Du", "Lun", ""], ["Shi", "Xiaozhou", ""], ["Wang", "Yanlin", ""], ["Shi", "Ensheng", ""], ["Han", "Shi", ""], ["Zhang", "Dongmei", ""]]}, {"id": "2107.04775", "submitter": "Ashwin Balakrishna", "authors": "Albert Wilcox and Ashwin Balakrishna and Brijen Thananjeyan and Joseph\n  E. Gonzalez and Ken Goldberg", "title": "LS3: Latent Space Safe Sets for Long-Horizon Visuomotor Control of\n  Iterative Tasks", "comments": "Preprint, Under Review. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) algorithms have shown impressive success in\nexploring high-dimensional environments to learn complex, long-horizon tasks,\nbut can often exhibit unsafe behaviors and require extensive environment\ninteraction when exploration is unconstrained. A promising strategy for safe\nlearning in dynamically uncertain environments is requiring that the agent can\nrobustly return to states where task success (and therefore safety) can be\nguaranteed. While this approach has been successful in low-dimensions,\nenforcing this constraint in environments with high-dimensional state spaces,\nsuch as images, is challenging. We present Latent Space Safe Sets (LS3), which\nextends this strategy to iterative, long-horizon tasks with image observations\nby using suboptimal demonstrations and a learned dynamics model to restrict\nexploration to the neighborhood of a learned Safe Set where task completion is\nlikely. We evaluate LS3 on 4 domains, including a challenging sequential\npushing task in simulation and a physical cable routing task. We find that LS3\ncan use prior task successes to restrict exploration and learn more efficiently\nthan prior algorithms while satisfying constraints. See\nhttps://tinyurl.com/latent-ss for code and supplementary material.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 06:46:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wilcox", "Albert", ""], ["Balakrishna", "Ashwin", ""], ["Thananjeyan", "Brijen", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "2107.04795", "submitter": "MingCai Chen", "authors": "Mingcai Chen, Yuntao Du, Yi Zhang, Shuwei Qian, Chongjun Wang", "title": "Semi-Supervised Learning with Multi-Head Co-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-training, extended from self-training, is one of the frameworks for\nsemi-supervised learning. It works at the cost of training extra classifiers,\nwhere the algorithm should be delicately designed to prevent individual\nclassifiers from collapsing into each other. In this paper, we present a simple\nand efficient co-training algorithm, named Multi-Head Co-Training, for\nsemi-supervised image classification. By integrating base learners into a\nmulti-head structure, the model is in a minimal amount of extra parameters.\nEvery classification head in the unified model interacts with its peers through\na \"Weak and Strong Augmentation\" strategy, achieving single-view co-training\nwithout promoting diversity explicitly. The effectiveness of Multi-Head\nCo-Training is demonstrated in an empirical study on standard semi-supervised\nlearning benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 08:53:14 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chen", "Mingcai", ""], ["Du", "Yuntao", ""], ["Zhang", "Yi", ""], ["Qian", "Shuwei", ""], ["Wang", "Chongjun", ""]]}, {"id": "2107.04813", "submitter": "Dr. Mohammed Javed", "authors": "Atul Sharma, Bulla Rajesh and Mohammed Javed", "title": "Detection of Plant Leaf Disease Directly in the JPEG Compressed Domain\n  using Transfer Learning Technique", "comments": "Accepted in MISP 2021 3rd International Conference On Machine\n  Intelligence And Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plant leaf diseases pose a significant danger to food security and they cause\ndepletion in quality and volume of production. Therefore accurate and timely\ndetection of leaf disease is very important to check the loss of the crops and\nmeet the growing food demand of the people. Conventional techniques depend on\nlab investigation and human skills which are generally costly and inaccessible.\nRecently, Deep Neural Networks have been exceptionally fruitful in image\nclassification. In this research paper, plant leaf disease detection employing\ntransfer learning is explored in the JPEG compressed domain. Here, the JPEG\ncompressed stream consisting of DCT coefficients is, directly fed into the\nNeural Network to improve the efficiency of classification. The experimental\nresults on JPEG compressed leaf dataset demonstrate the efficacy of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 11:10:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sharma", "Atul", ""], ["Rajesh", "Bulla", ""], ["Javed", "Mohammed", ""]]}, {"id": "2107.04827", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Thomas Breuel", "title": "Identifying Layers Susceptible to Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common neural network architectures are susceptible to attack by adversarial\nsamples. Neural network architectures are commonly thought of as divided into\nlow-level feature extraction layers and high-level classification layers;\nsusceptibility of networks to adversarial samples is often thought of as a\nproblem related to classification rather than feature extraction. We test this\nidea by selectively retraining different portions of VGG and ResNet\narchitectures on CIFAR-10, Imagenette and ImageNet using non-adversarial and\nadversarial data. Our experimental results show that susceptibility to\nadversarial samples is associated with low-level feature extraction layers.\nTherefore, retraining high-level layers is insufficient for achieving\nrobustness. This phenomenon could have two explanations: either, adversarial\nattacks yield outputs from early layers that are indistinguishable from\nfeatures found in the attack classes, or adversarial attacks yield outputs from\nearly layers that differ statistically from features for non-adversarial\nsamples and do not permit consistent classification by subsequent layers. We\ntest this question by large-scale non-linear dimensionality reduction and\ndensity modeling on distributions of feature vectors in hidden layers and find\nthat the feature distributions between non-adversarial and adversarial samples\ndiffer substantially. Our results provide new insights into the statistical\norigins of adversarial samples and possible defenses.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 12:38:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Breuel", "Thomas", ""]]}, {"id": "2107.04831", "submitter": "Johann Pfitzinger", "authors": "Johann Pfitzinger", "title": "Cluster Regularization via a Hierarchical Feature Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction tasks with high-dimensional nonorthogonal predictor sets pose a\nchallenge for least squares based fitting procedures. A large and productive\nliterature exists, discussing various regularized approaches to improving the\nout-of-sample robustness of parameter estimates. This paper proposes a novel\ncluster-based regularization - the hierarchical feature regression (HFR) -,\nwhich mobilizes insights from the domains of machine learning and graph theory\nto estimate parameters along a supervised hierarchical representation of the\npredictor set, shrinking parameters towards group targets. The method is\ninnovative in its ability to estimate optimal compositions of predictor groups,\nas well as the group targets endogenously. The HFR can be viewed as a\nsupervised factor regression, with the strength of shrinkage governed by a\npenalty on the extent of idiosyncratic variation captured in the fitting\nprocess. The method demonstrates good predictive accuracy and versatility,\noutperforming a panel of benchmark regularized estimators across a diverse set\nof simulated regression tasks, including dense, sparse and grouped data\ngenerating processes. An application to the prediction of economic growth is\nused to illustrate the HFR's effectiveness in an empirical setting, with\nfavorable comparisons to several frequentist and Bayesian alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 13:03:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pfitzinger", "Johann", ""]]}, {"id": "2107.04846", "submitter": "Haodong Chang", "authors": "Haodong Chang and Yabo Chu", "title": "Propagation-aware Social Recommendation by Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social-aware recommendation approaches have been recognized as an effective\nway to solve the data sparsity issue of traditional recommender systems. The\nassumption behind is that the knowledge in social user-user connections can be\nshared and transferred to the domain of user-item interactions, whereby to help\nlearn user preferences. However, most existing approaches merely adopt the\nfirst-order connections among users during transfer learning, ignoring those\nconnections in higher orders. We argue that better recommendation performance\ncan also benefit from high-order social relations. In this paper, we propose a\nnovel Propagation-aware Transfer Learning Network (PTLN) based on the\npropagation of social relations. We aim to better mine the sharing knowledge\nhidden in social networks and thus further improve recommendation performance.\nSpecifically, we explore social influence in two aspects: (a) higher-order\nfriends have been taken into consideration by order bias; (b) different friends\nin the same order will have distinct importance for recommendation by an\nattention mechanism. Besides, we design a novel regularization to bridge the\ngap between social relations and user-item interactions. We conduct extensive\nexperiments on two real-world datasets and beat other counterparts in terms of\nranking accuracy, especially for the cold-start users with few historical\ninteractions.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 14:21:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chang", "Haodong", ""], ["Chu", "Yabo", ""]]}, {"id": "2107.04855", "submitter": "Tongliang Liu", "authors": "Xiaobo Xia, Shuo Shan, Mingming Gong, Nannan Wang, Fei Gao, Haikun\n  Wei, Tongliang Liu", "title": "Kernel Mean Estimation by Marginalized Corrupted Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Estimating the kernel mean in a reproducing kernel Hilbert space is a\ncritical component in many kernel learning algorithms. Given a finite sample,\nthe standard estimate of the target kernel mean is the empirical average.\nPrevious works have shown that better estimators can be constructed by\nshrinkage methods. In this work, we propose to corrupt data examples with noise\nfrom known distributions and present a new kernel mean estimator, called the\nmarginalized kernel mean estimator, which estimates kernel mean under the\ncorrupted distribution. Theoretically, we show that the marginalized kernel\nmean estimator introduces implicit regularization in kernel mean estimation.\nEmpirically, we show on a variety of datasets that the marginalized kernel mean\nestimator obtains much lower estimation error than the existing estimators.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 15:11:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Xia", "Xiaobo", ""], ["Shan", "Shuo", ""], ["Gong", "Mingming", ""], ["Wang", "Nannan", ""], ["Gao", "Fei", ""], ["Wei", "Haikun", ""], ["Liu", "Tongliang", ""]]}, {"id": "2107.04857", "submitter": "Basit Alawode", "authors": "Basit O. Alawode, Mudassir Masood, Tarig Ballal, and Tareq Al-Naffouri", "title": "Dense-Sparse Deep CNN Training for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, deep learning (DL) methods such as convolutional neural networks\n(CNNs) have gained prominence in the area of image denoising. This is owing to\ntheir proven ability to surpass state-of-the-art classical image denoising\nalgorithms such as BM3D. Deep denoising CNNs (DnCNNs) use many feedforward\nconvolution layers with added regularization methods of batch normalization and\nresidual learning to improve denoising performance significantly. However, this\ncomes at the expense of a huge number of trainable parameters. In this paper,\nwe address this issue by reducing the number of parameters while achieving a\ncomparable level of performance. We derive motivation from the improved\nperformance obtained by training networks using the dense-sparse-dense (DSD)\ntraining approach. We extend this training approach to a reduced DnCNN (RDnCNN)\nnetwork resulting in a faster denoising network with significantly reduced\nparameters and comparable performance to the DnCNN.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 15:14:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Alawode", "Basit O.", ""], ["Masood", "Mudassir", ""], ["Ballal", "Tarig", ""], ["Al-Naffouri", "Tareq", ""]]}, {"id": "2107.04863", "submitter": "Florian Tambon", "authors": "Florian Tambon, Giulio Antoniol and Foutse Khomh", "title": "HOMRS: High Order Metamorphic Relations Selector for Deep Neural\n  Networks", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) applications are increasingly becoming a part of\nour everyday life, from medical applications to autonomous cars. Traditional\nvalidation of DNN relies on accuracy measures, however, the existence of\nadversarial examples has highlighted the limitations of these accuracy\nmeasures, raising concerns especially when DNN are integrated into\nsafety-critical systems. In this paper, we present HOMRS, an approach to boost\nmetamorphic testing by automatically building a small optimized set of high\norder metamorphic relations from an initial set of elementary metamorphic\nrelations. HOMRS' backbone is a multi-objective search; it exploits ideas drawn\nfrom traditional systems testing such as code coverage, test case, and path\ndiversity. We applied HOMRS to LeNet5 DNN with MNIST dataset and we report\nevidence that it builds a small but effective set of high order transformations\nachieving a 95% kill ratio. Five raters manually labeled a pool of images\nbefore and after high order transformation; Fleiss' Kappa and statistical tests\nconfirmed that they are metamorphic properties. HOMRS built-in relations are\nalso effective to confront adversarial or out-of-distribution examples; HOMRS\ndetected 92% of randomly sampled out-of-distribution images. HOMRS\ntransformations are also suitable for online real-time use.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 15:40:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tambon", "Florian", ""], ["Antoniol", "Giulio", ""], ["Khomh", "Foutse", ""]]}, {"id": "2107.04882", "submitter": "Anisie Uwimana", "authors": "Anisie Uwimana1, Ransalu Senanayake", "title": "Out of Distribution Detection and Adversarial Attacks on Deep Neural\n  Networks for Robust Medical Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have become a popular choice for medical image analysis.\nHowever, the poor generalization performance of deep learning models limits\nthem from being deployed in the real world as robustness is critical for\nmedical applications. For instance, the state-of-the-art Convolutional Neural\nNetworks (CNNs) fail to detect adversarial samples or samples drawn\nstatistically far away from the training distribution. In this work, we\nexperimentally evaluate the robustness of a Mahalanobis distance-based\nconfidence score, a simple yet effective method for detecting abnormal input\nsamples, in classifying malaria parasitized cells and uninfected cells. Results\nindicated that the Mahalanobis confidence score detector exhibits improved\nperformance and robustness of deep learning models, and achieves\nstateof-the-art performance on both out-of-distribution (OOD) and adversarial\nsamples.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 18:00:40 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Uwimana1", "Anisie", ""], ["Senanayake", "Ransalu", ""]]}, {"id": "2107.04894", "submitter": "Mehdi Ali", "authors": "Mehdi Ali, Max Berrendorf, Mikhail Galkin, Veronika Thost, Tengfei Ma,\n  Volker Tresp, Jens Lehmann", "title": "Improving Inductive Link Prediction Using Hyper-Relational Facts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  For many years, link prediction on knowledge graphs (KGs) has been a purely\ntransductive task, not allowing for reasoning on unseen entities. Recently,\nincreasing efforts are put into exploring semi- and fully inductive scenarios,\nenabling inference over unseen and emerging entities. Still, all these\napproaches only consider triple-based \\glspl{kg}, whereas their richer\ncounterparts, hyper-relational KGs (e.g., Wikidata), have not yet been properly\nstudied. In this work, we classify different inductive settings and study the\nbenefits of employing hyper-relational KGs on a wide range of semi- and fully\ninductive link prediction tasks powered by recent advancements in graph neural\nnetworks. Our experiments on a novel set of benchmarks show that qualifiers\nover typed edges can lead to performance improvements of 6% of absolute gains\n(for the Hits@10 metric) compared to triple-only baselines. Our code is\navailable at \\url{https://github.com/mali-git/hyper_relational_ilp}.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 19:16:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ali", "Mehdi", ""], ["Berrendorf", "Max", ""], ["Galkin", "Mikhail", ""], ["Thost", "Veronika", ""], ["Ma", "Tengfei", ""], ["Tresp", "Volker", ""], ["Lehmann", "Jens", ""]]}, {"id": "2107.04895", "submitter": "Satvik Garg", "authors": "Satvik Garg, Pradyumn Pundir, Himanshu Jindal, Hemraj Saini, Somya\n  Garg", "title": "Towards a Multimodal System for Precision Agriculture using IoT and\n  Machine Learning", "comments": "7 pages, this paper is accepted in the 12th ICCCNT 2021 conference at\n  IIT Kharagpur, India. The final version of this paper will appear in the\n  conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision agriculture system is an arising idea that refers to overseeing\nfarms utilizing current information and communication technologies to improve\nthe quantity and quality of yields while advancing the human work required. The\nautomation requires the assortment of information given by the sensors such as\nsoil, water, light, humidity, temperature for additional information to furnish\nthe operator with exact data to acquire excellent yield to farmers. In this\nwork, a study is proposed that incorporates all common state-of-the-art\napproaches for precision agriculture use. Technologies like the Internet of\nThings (IoT) for data collection, machine Learning for crop damage prediction,\nand deep learning for crop disease detection is used. The data collection using\nIoT is responsible for the measure of moisture levels for smart irrigation, n,\np, k estimations of fertilizers for best yield development. For crop damage\nprediction, various algorithms like Random Forest (RF), Light gradient boosting\nmachine (LGBM), XGBoost (XGB), Decision Tree (DT) and K Nearest Neighbor (KNN)\nare used. Subsequently, Pre-Trained Convolutional Neural Network (CNN) models\nsuch as VGG16, Resnet50, and DenseNet121 are also trained to check if the crop\nwas tainted with some illness or not.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 19:19:45 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Garg", "Satvik", ""], ["Pundir", "Pradyumn", ""], ["Jindal", "Himanshu", ""], ["Saini", "Hemraj", ""], ["Garg", "Somya", ""]]}, {"id": "2107.04911", "submitter": "N'dah Jean Kouagou", "authors": "N'Dah Jean Kouagou, Stefan Heindorf, Caglar Demir, Axel-Cyrille Ngonga\n  Ngomo", "title": "Prediction of concept lengths for fast concept learning in description\n  logics", "comments": "16 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Concept learning approaches based on refinement operators explore partially\nordered solution spaces to compute concepts, which are used as binary\nclassification models for individuals. However, the refinement trees spanned by\nthese approaches can easily grow to millions of nodes for complex learning\nproblems. This leads to refinement-based approaches often failing to detect\noptimal concepts efficiently. In this paper, we propose a supervised machine\nlearning approach for learning concept lengths, which allows predicting the\nlength of the target concept and therefore facilitates the reduction of the\nsearch space during concept learning. To achieve this goal, we compare four\nneural architectures and evaluate them on four benchmark knowledge\ngraphs--Carcinogenesis, Mutagenesis, Semantic Bible, Family Benchmark. Our\nevaluation results suggest that recurrent neural network architectures perform\nbest at concept length prediction with an F-measure of up to 92%. We show that\nintegrating our concept length predictor into the CELOE (Class Expression\nLearner for Ontology Engineering) algorithm improves CELOE's runtime by a\nfactor of up to 13.4 without any significant changes to the quality of the\nresults it generates. For reproducibility, we provide our implementation in the\npublic GitHub repository at\nhttps://github.com/ConceptLengthLearner/ReproducibilityRepo\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 21:00:48 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kouagou", "N'Dah Jean", ""], ["Heindorf", "Stefan", ""], ["Demir", "Caglar", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""]]}, {"id": "2107.04914", "submitter": "Ivan Zakazov", "authors": "Ivan Zakazov, Boris Shirokikh, Alexey Chernyavskiy and Mikhail Belyaev", "title": "Anatomy of Domain Shift Impact on U-Net Layers in MRI Segmentation", "comments": "Accepted for MICCAI-2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain Adaptation (DA) methods are widely used in medical image segmentation\ntasks to tackle the problem of differently distributed train (source) and test\n(target) data. We consider the supervised DA task with a limited number of\nannotated samples from the target domain. It corresponds to one of the most\nrelevant clinical setups: building a sufficiently accurate model on the minimum\npossible amount of annotated data. Existing methods mostly fine-tune specific\nlayers of the pretrained Convolutional Neural Network (CNN). However, there is\nno consensus on which layers are better to fine-tune, e.g. the first layers for\nimages with low-level domain shift or the deeper layers for images with\nhigh-level domain shift. To this end, we propose SpotTUnet - a CNN architecture\nthat automatically chooses the layers which should be optimally fine-tuned.\nMore specifically, on the target domain, our method additionally learns the\npolicy that indicates whether a specific layer should be fine-tuned or reused\nfrom the pretrained network. We show that our method performs at the same level\nas the best of the nonflexible fine-tuning methods even under the extreme\nscarcity of annotated data. Secondly, we show that SpotTUnet policy provides a\nlayer-wise visualization of the domain shift impact on the network, which could\nbe further used to develop robust domain generalization methods. In order to\nextensively evaluate SpotTUnet performance, we use a publicly available dataset\nof brain MR images (CC359), characterized by explicit domain shift. We release\na reproducible experimental pipeline.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 21:13:55 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zakazov", "Ivan", ""], ["Shirokikh", "Boris", ""], ["Chernyavskiy", "Alexey", ""], ["Belyaev", "Mikhail", ""]]}, {"id": "2107.04952", "submitter": "Gaurav Bhatt", "authors": "Gaurav Bhatt, Shivam Chandhok and Vineeth N Balasubramanian", "title": "Learn from Anywhere: Rethinking Generalized Zero-Shot Learning with\n  Limited Supervision", "comments": "Accepted at IJCAI'21 workshop on Weakly Supervised Representation\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common problem with most zero and few-shot learning approaches is they\nsuffer from bias towards seen classes resulting in sub-optimal performance.\nExisting efforts aim to utilize unlabeled images from unseen classes (i.e\ntransductive zero-shot) during training to enable generalization. However, this\nlimits their use in practical scenarios where data from target unseen classes\nis unavailable or infeasible to collect. In this work, we present a practical\nsetting of inductive zero and few-shot learning, where unlabeled images from\nother out-of-data classes, that do not belong to seen or unseen categories, can\nbe used to improve generalization in any-shot learning. We leverage a\nformulation based on product-of-experts and introduce a new AUD module that\nenables us to use unlabeled samples from out-of-data classes which are usually\neasily available and practically entail no annotation cost. In addition, we\nalso demonstrate the applicability of our model to address a more practical and\nchallenging, Generalized Zero-shot under a limited supervision setting, where\neven base seen classes do not have sufficient annotated samples.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 03:23:20 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 01:28:32 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bhatt", "Gaurav", ""], ["Chandhok", "Shivam", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2107.04954", "submitter": "Kin Wai Cheuk", "authors": "Kin Wai Cheuk, Dorien Herremans, Li Su", "title": "ReconVAT: A Semi-Supervised Automatic Music Transcription Framework for\n  Low-Resource Real-World Data", "comments": "Accepted in ACMMM 21. Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of the current supervised automatic music transcription (AMT) models\nlack the ability to generalize. This means that they have trouble transcribing\nreal-world music recordings from diverse musical genres that are not presented\nin the labelled training data. In this paper, we propose a semi-supervised\nframework, ReconVAT, which solves this issue by leveraging the huge amount of\navailable unlabelled music recordings. The proposed ReconVAT uses\nreconstruction loss and virtual adversarial training. When combined with\nexisting U-net models for AMT, ReconVAT achieves competitive results on common\nbenchmark datasets such as MAPS and MusicNet. For example, in the few-shot\nsetting for the string part version of MusicNet, ReconVAT achieves F1-scores of\n61.0% and 41.6% for the note-wise and note-with-offset-wise metrics\nrespectively, which translates into an improvement of 22.2% and 62.5% compared\nto the supervised baseline model. Our proposed framework also demonstrates the\npotential of continual learning on new data, which could be useful in\nreal-world applications whereby new data is constantly available.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 03:25:58 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 04:49:25 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Cheuk", "Kin Wai", ""], ["Herremans", "Dorien", ""], ["Su", "Li", ""]]}, {"id": "2107.04971", "submitter": "Boris Kovalerchuk", "authors": "Sridevi Narayana Wagle, Boris Kovalerchuk", "title": "Self-service Data Classification Using Interactive Visualization and\n  Interpretable Machine Learning", "comments": "37 pages, 33 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms often produce models considered as complex\nblack-box models by both end users and developers. They fail to explain the\nmodel in terms of the domain they are designed for. The proposed Iterative\nVisual Logical Classifier (IVLC) is an interpretable machine learning algorithm\nthat allows end users to design a model and classify data with more confidence\nand without having to compromise on the accuracy. Such technique is especially\nhelpful when dealing with sensitive and crucial data like cancer data in the\nmedical domain with high cost of errors. With the help of the proposed\ninteractive and lossless multidimensional visualization, end users can identify\nthe pattern in the data based on which they can make explainable decisions.\nSuch options would not be possible in black box machine learning methodologies.\nThe interpretable IVLC algorithm is supported by the Interactive Shifted Paired\nCoordinates Software System (SPCVis). It is a lossless multidimensional data\nvisualization system with user interactive features. The interactive approach\nprovides flexibility to the end user to perform data classification as\nself-service without having to rely on a machine learning expert. Interactive\npattern discovery becomes challenging while dealing with large data sets with\nhundreds of dimensions/features. To overcome this problem, this chapter\nproposes an automated classification approach combined with new Coordinate\nOrder Optimizer (COO) algorithm and a Genetic algorithm. The COO algorithm\nautomatically generates the coordinate pair sequences that best represent the\ndata separation and the genetic algorithm helps optimizing the proposed IVLC\nalgorithm by automatically generating the areas for data classification. The\nfeasibility of the approach is shown by experiments on benchmark datasets\ncovering both interactive and automated processes used for data classification.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 05:39:14 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wagle", "Sridevi Narayana", ""], ["Kovalerchuk", "Boris", ""]]}, {"id": "2107.04973", "submitter": "Ravi Shankar", "authors": "Ravi Shankar and Archana Venkataraman", "title": "A Deep-Bayesian Framework for Adaptive Speech Duration Modification", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the first method to adaptively modify the duration of a given\nspeech signal. Our approach uses a Bayesian framework to define a latent\nattention map that links frames of the input and target utterances. We train a\nmasked convolutional encoder-decoder network to produce this attention map via\na stochastic version of the mean absolute error loss function; our model also\npredicts the length of the target speech signal using the encoder embeddings.\nThe predicted length determines the number of steps for the decoder operation.\nDuring inference, we generate the attention map as a proxy for the similarity\nmatrix between the given input speech and an unknown target speech signal.\nUsing this similarity matrix, we compute a warping path of alignment between\nthe two signals. Our experiments demonstrate that this adaptive framework\nproduces similar results to dynamic time warping, which relies on a known\ntarget signal, on both voice conversion and emotion conversion tasks. We also\nshow that our technique results in a high quality of generated speech that is\non par with state-of-the-art vocoders.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 05:53:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shankar", "Ravi", ""], ["Venkataraman", "Archana", ""]]}, {"id": "2107.04974", "submitter": "Boris Kovalerchuk", "authors": "Rose McDonald, Boris Kovalerchuk", "title": "Non-linear Visual Knowledge Discovery with Elliptic Paired Coordinates", "comments": "29 pages, 29 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is challenging for humans to enable visual knowledge discovery in data\nwith more than 2-3 dimensions with a naked eye. This chapter explores the\nefficiency of discovering predictive machine learning models interactively\nusing new Elliptic Paired coordinates (EPC) visualizations. It is shown that\nEPC are capable to visualize multidimensional data and support visual machine\nlearning with preservation of multidimensional information in 2-D. Relative to\nparallel and radial coordinates, EPC visualization requires only a half of the\nvisual elements for each n-D point. An interactive software system EllipseVis,\nwhich is developed in this work, processes high-dimensional datasets, creates\nEPC visualizations, and produces predictive classification models by\ndiscovering dominance rules in EPC. By using interactive and automatic\nprocesses it discovers zones in EPC with a high dominance of a single class.\nThe EPC methodology has been successful in discovering non-linear predictive\nmodels with high coverage and precision in the computational experiments. This\ncan benefit multiple domains by producing visually appealing dominance rules.\nThis chapter presents results of successful testing the EPC non-linear\nmethodology in experiments using real and simulated data, EPC generalized to\nthe Dynamic Elliptic Paired Coordinates (DEPC), incorporation of the weights of\ncoordinates to optimize the visual discovery, introduction of an alternative\nEPC design and introduction of the concept of incompact machine learning\nmethodology based on EPC/DEPC.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 05:53:38 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["McDonald", "Rose", ""], ["Kovalerchuk", "Boris", ""]]}, {"id": "2107.04980", "submitter": "Chuyu Huang", "authors": "Chuyu Huang", "title": "STR-GODEs: Spatial-Temporal-Ridership Graph ODEs for Metro Ridership\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The metro ridership prediction has always received extensive attention from\ngovernments and researchers. Recent works focus on designing complicated graph\nconvolutional recurrent network architectures to capture spatial and temporal\npatterns. These works extract the information of spatial dimension well, but\nthe limitation of temporal dimension still exists. We extended Neural ODE\nalgorithms to the graph network and proposed the STR-GODEs network, which can\neffectively learn spatial, temporal, and ridership correlations without the\nlimitation of dividing data into equal-sized intervals on the timeline. While\nlearning the spatial relations and the temporal correlations, we modify the\nGODE-RNN cell to obtain the ridership feature and hidden states. Ridership\ninformation and its hidden states are added to the GODESolve to reduce the\nerror accumulation caused by long time series in prediction. Extensive\nexperiments on two large-scale datasets demonstrate the efficacy and robustness\nof our model.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 06:29:20 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huang", "Chuyu", ""]]}, {"id": "2107.04982", "submitter": "Mohamad H Danesh", "authors": "Mohamad H Danesh and Alan Fern", "title": "Out-of-Distribution Dynamics Detection: RL-Relevant Benchmarks and\n  Results", "comments": "ICML 2021 Workshop on Uncertainty and Robustness in Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of out-of-distribution dynamics (OODD) detection, which\ninvolves detecting when the dynamics of a temporal process change compared to\nthe training-distribution dynamics. This is relevant to applications in\ncontrol, reinforcement learning (RL), and multi-variate time-series, where\nchanges to test time dynamics can impact the performance of learning\ncontrollers/predictors in unknown ways. This problem is particularly important\nin the context of deep RL, where learned controllers often overfit to the\ntraining environment. Currently, however, there is a lack of established OODD\nbenchmarks for the types of environments commonly used in RL research. Our\nfirst contribution is to design a set of OODD benchmarks derived from common RL\nenvironments with varying types and intensities of OODD. Our second\ncontribution is to design a strong OODD baseline approach based on recurrent\nimplicit quantile networks (RIQNs), which monitors autoregressive prediction\nerrors for OODD detection. Our final contribution is to evaluate the RIQN\napproach on the benchmarks to provide baseline results for future comparison.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 06:40:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Danesh", "Mohamad H", ""], ["Fern", "Alan", ""]]}, {"id": "2107.04983", "submitter": "Jack Lynch", "authors": "Jack Lynch and Sam Wookey", "title": "Leveraging Domain Adaptation for Low-Resource Geospatial Machine\n  Learning", "comments": "Tackling Climate Change with Machine Learning Workshop at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning in remote sensing has matured alongside a proliferation in\navailability and resolution of geospatial imagery, but its utility is\nbottlenecked by the need for labeled data. What's more, many labeled geospatial\ndatasets are specific to certain regions, instruments, or extreme weather\nevents. We investigate the application of modern domain-adaptation to multiple\nproposed geospatial benchmarks, uncovering unique challenges and proposing\nsolutions to them.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 06:47:20 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lynch", "Jack", ""], ["Wookey", "Sam", ""]]}, {"id": "2107.04987", "submitter": "Yuanyi Zhong", "authors": "Yuanyi Zhong, Yuan Zhou, Jian Peng", "title": "Coordinate-wise Control Variates for Deep Policy Gradients", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control variates (CV) method is widely used in policy gradient estimation\nto reduce the variance of the gradient estimators in practice. A control\nvariate is applied by subtracting a baseline function from the state-action\nvalue estimates. Then the variance-reduced policy gradient presumably leads to\nhigher learning efficiency. Recent research on control variates with deep\nneural net policies mainly focuses on scalar-valued baseline functions. The\neffect of vector-valued baselines is under-explored. This paper investigates\nvariance reduction with coordinate-wise and layer-wise control variates\nconstructed from vector-valued baselines for neural net policies. We present\nexperimental evidence suggesting that lower variance can be obtained with such\nbaselines than with the conventional scalar-valued baseline. We demonstrate how\nto equip the popular Proximal Policy Optimization (PPO) algorithm with these\nnew control variates. We show that the resulting algorithm with proper\nregularization can achieve higher sample efficiency than scalar control\nvariates in continuous control benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 07:36:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhong", "Yuanyi", ""], ["Zhou", "Yuan", ""], ["Peng", "Jian", ""]]}, {"id": "2107.05000", "submitter": "Apostolos Kousaridas", "authors": "Apostolos Kousaridas, Ramya Panthangi Manjunath, Jose Mauricio\n  Perdomo, Chan Zhou, Ernst Zielinski, Steffen Schmitz and Andreas Pfadler", "title": "QoS Prediction for 5G Connected and Automated Driving", "comments": "7 pages, 5 figures, accepted for publication in the IEEE\n  Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  5G communication system can support the demanding quality-of-service (QoS)\nrequirements of many advanced vehicle-to-everything (V2X) use cases. However,\nthe safe and efficient driving, especially of automated vehicles, may be\naffected by sudden changes of the provided QoS. For that reason, the prediction\nof the QoS changes and the early notification of these predicted changes to the\nvehicles have been recently enabled by 5G communication systems. This solution\nenables the vehicles to avoid or mitigate the effect of sudden QoS changes at\nthe application level. This article describes how QoS prediction could be\ngenerated by a 5G communication system and delivered to a V2X application. The\ntele-operated driving use case is used as an example to analyze the feasibility\nof a QoS prediction scheme. Useful recommendations for the development of a QoS\nprediction solution are provided, while open research topics are identified.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 09:19:37 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kousaridas", "Apostolos", ""], ["Manjunath", "Ramya Panthangi", ""], ["Perdomo", "Jose Mauricio", ""], ["Zhou", "Chan", ""], ["Zielinski", "Ernst", ""], ["Schmitz", "Steffen", ""], ["Pfadler", "Andreas", ""]]}, {"id": "2107.05001", "submitter": "Shami Nisimov", "authors": "Shami Nisimov, Yaniv Gurwicz, Raanan Y. Rohekar, Gal Novik", "title": "Improving Efficiency and Accuracy of Causal Discovery Using a\n  Hierarchical Wrapper", "comments": "The 37th Conference on Uncertainty in Artificial Intelligence (UAI\n  2021), Workshop on Tractable Probabilistic Modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from observational data is an important tool in many\nbranches of science. Under certain assumptions it allows scientists to explain\nphenomena, predict, and make decisions. In the large sample limit, sound and\ncomplete causal discovery algorithms have been previously introduced, where a\ndirected acyclic graph (DAG), or its equivalence class, representing causal\nrelations is searched. However, in real-world cases, only finite training data\nis available, which limits the power of statistical tests used by these\nalgorithms, leading to errors in the inferred causal model. This is commonly\naddressed by devising a strategy for using as few as possible statistical\ntests. In this paper, we introduce such a strategy in the form of a recursive\nwrapper for existing constraint-based causal discovery algorithms, which\npreserves soundness and completeness. It recursively clusters the observed\nvariables using the normalized min-cut criterion from the outset, and uses a\nbaseline causal discovery algorithm during backtracking for learning local\nsub-graphs. It then combines them and ensures completeness. By an ablation\nstudy, using synthetic data, and by common real-world benchmarks, we\ndemonstrate that our approach requires significantly fewer statistical tests,\nlearns more accurate graphs, and requires shorter run-times than the baseline\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 09:24:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Nisimov", "Shami", ""], ["Gurwicz", "Yaniv", ""], ["Rohekar", "Raanan Y.", ""], ["Novik", "Gal", ""]]}, {"id": "2107.05007", "submitter": "S{\\o}ren Ager Meldgaard", "authors": "S{\\o}ren Ager Meldgaard, Jonas K\\\"ohler, Henrik Lund Mortensen,\n  Mads-Peter V. Christiansen, Frank No\\'e, Bj{\\o}rk Hammer", "title": "Generating stable molecules using imitation and reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chemical space is routinely explored by machine learning methods to discover\ninteresting molecules, before time-consuming experimental synthesizing is\nattempted. However, these methods often rely on a graph representation,\nignoring 3D information necessary for determining the stability of the\nmolecules. We propose a reinforcement learning approach for generating\nmolecules in cartesian coordinates allowing for quantum chemical prediction of\nthe stability. To improve sample-efficiency we learn basic chemical rules from\nimitation learning on the GDB-11 database to create an initial model applicable\nfor all stoichiometries. We then deploy multiple copies of the model\nconditioned on a specific stoichiometry in a reinforcement learning setting.\nThe models correctly identify low energy molecules in the database and produce\nnovel isomers not found in the training set. Finally, we apply the model to\nlarger molecules to show how reinforcement learning further refines the\nimitation learning model in domains far from the training data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 10:18:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Meldgaard", "S\u00f8ren Ager", ""], ["K\u00f6hler", "Jonas", ""], ["Mortensen", "Henrik Lund", ""], ["Christiansen", "Mads-Peter V.", ""], ["No\u00e9", "Frank", ""], ["Hammer", "Bj\u00f8rk", ""]]}, {"id": "2107.05011", "submitter": "Qiyou Duan", "authors": "Qiyou Duan and Hadi Ghauch and Taejoon Kim", "title": "Dual Optimization for Kolmogorov Model Learning Using Enhanced Gradient\n  Descent", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data representation techniques have made a substantial contribution to\nadvancing data processing and machine learning (ML). Improving predictive power\nwas the focus of previous representation techniques, which unfortunately\nperform rather poorly on the interpretability in terms of extracting underlying\ninsights of the data. Recently, Kolmogorov model (KM) was studied, which is an\ninterpretable and predictable representation approach to learning the\nunderlying probabilistic structure of a set of random variables. The existing\nKM learning algorithms using semi-definite relaxation with randomization\n(SDRwR) or discrete monotonic optimization (DMO) have, however, limited utility\nto big data applications because they do not scale well computationally. In\nthis paper, we propose a computationally scalable KM learning algorithm, based\non the regularized dual optimization combined with enhanced gradient descent\n(GD) method. To make our method more scalable to large-dimensional problems, we\npropose two acceleration schemes, namely, eigenvalue decomposition (EVD)\nelimination strategy and proximal EVD algorithm. Furthermore, a thresholding\ntechnique by exploiting the approximation error analysis and leveraging the\nnormalized Minkowski $\\ell_1$-norm and its bounds, is provided for the\nselection of the number of iterations of the proximal EVD algorithm. When\napplied to big data applications, it is demonstrated that the proposed method\ncan achieve compatible training/prediction performance with significantly\nreduced computational complexity; roughly two orders of magnitude improvement\nin terms of the time overhead, compared to the existing KM learning algorithms.\nFurthermore, it is shown that the accuracy of logical relation mining for\ninterpretability by using the proposed KM learning algorithm exceeds $80\\%$.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 10:33:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Duan", "Qiyou", ""], ["Ghauch", "Hadi", ""], ["Kim", "Taejoon", ""]]}, {"id": "2107.05033", "submitter": "Zhongzhan Huang", "authors": "Wei He, Zhongzhan Huang, Mingfu Liang, Senwei Liang, Haizhao Yang", "title": "Blending Pruning Criteria for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of convolutional neural networks (CNNs) on various vision\napplications has attracted lots of attention. Yet the majority of CNNs are\nunable to satisfy the strict requirement for real-world deployment. To overcome\nthis, the recent popular network pruning is an effective method to reduce the\nredundancy of the models. However, the ranking of filters according to their\n\"importance\" on different pruning criteria may be inconsistent. One filter\ncould be important according to a certain criterion, while it is unnecessary\naccording to another one, which indicates that each criterion is only a partial\nview of the comprehensive \"importance\". From this motivation, we propose a\nnovel framework to integrate the existing filter pruning criteria by exploring\nthe criteria diversity. The proposed framework contains two stages: Criteria\nClustering and Filters Importance Calibration. First, we condense the pruning\ncriteria via layerwise clustering based on the rank of \"importance\" score.\nSecond, within each cluster, we propose a calibration factor to adjust their\nsignificance for each selected blending candidates and search for the optimal\nblending criterion via Evolutionary Algorithm. Quantitative results on the\nCIFAR-100 and ImageNet benchmarks show that our framework outperforms the\nstate-of-the-art baselines, regrading to the compact model performance after\npruning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 12:34:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["He", "Wei", ""], ["Huang", "Zhongzhan", ""], ["Liang", "Mingfu", ""], ["Liang", "Senwei", ""], ["Yang", "Haizhao", ""]]}, {"id": "2107.05039", "submitter": "Ye Shi", "authors": "Ye Shi, Shao-Yuan Li, Sheng-Jun Huang", "title": "Learning from Crowds with Sparse and Imbalanced Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional supervised learning requires ground truth labels for the training\ndata, whose collection can be difficult in many cases. Recently, crowdsourcing\nhas established itself as an efficient labeling solution through resorting to\nnon-expert crowds. To reduce the labeling error effects, one common practice is\nto distribute each instance to multiple workers, whereas each worker only\nannotates a subset of data, resulting in the {\\it sparse annotation}\nphenomenon. In this paper, we note that when meeting with class-imbalance,\ni.e., when the ground truth labels are {\\it class-imbalanced}, the sparse\nannotations are prone to be skewly distributed, which thus can severely bias\nthe learning algorithm. To combat this issue, we propose one self-training\nbased approach named {\\it Self-Crowd} by progressively adding confident\npseudo-annotations and rebalancing the annotation distribution. Specifically,\nwe propose one distribution aware confidence measure to select confident\npseudo-annotations, which adopts the resampling strategy to oversample the\nminority annotations and undersample the majority annotations. On one\nreal-world crowdsourcing image classification task, we show that the proposed\nmethod yields more balanced annotations throughout training than the\ndistribution agnostic methods and substantially improves the learning\nperformance at different annotation sparsity levels.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:06:20 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Shi", "Ye", ""], ["Li", "Shao-Yuan", ""], ["Huang", "Sheng-Jun", ""]]}, {"id": "2107.05045", "submitter": "Shota Nakajima", "authors": "Shota Nakajima, Masashi Sugiyama", "title": "Positive-Unlabeled Classification under Class-Prior Shift: A\n  Prior-invariant Approach Based on Density Ratio Estimation", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from positive and unlabeled (PU) data is an important problem in\nvarious applications. Most of the recent approaches for PU classification\nassume that the class-prior (the ratio of positive samples) in the training\nunlabeled dataset is identical to that of the test data, which does not hold in\nmany practical cases. In addition, we usually do not know the class-priors of\nthe training and test data, thus we have no clue on how to train a classifier\nwithout them. To address these problems, we propose a novel PU classification\nmethod based on density ratio estimation. A notable advantage of our proposed\nmethod is that it does not require the class-priors in the training phase;\nclass-prior shift is incorporated only in the test phase. We theoretically\njustify our proposed method and experimentally demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:36:53 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Nakajima", "Shota", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2107.05047", "submitter": "Weina Jin", "authors": "Weina Jin, Xiaoxiao Li, Ghassan Hamarneh", "title": "One Map Does Not Fit All: Evaluating Saliency Map Explanation on\n  Multi-Modal Medical Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Being able to explain the prediction to clinical end-users is a necessity to\nleverage the power of AI models for clinical decision support. For medical\nimages, saliency maps are the most common form of explanation. The maps\nhighlight important features for AI model's prediction. Although many saliency\nmap methods have been proposed, it is unknown how well they perform on\nexplaining decisions on multi-modal medical images, where each modality/channel\ncarries distinct clinical meanings of the same underlying biomedical\nphenomenon. Understanding such modality-dependent features is essential for\nclinical users' interpretation of AI decisions. To tackle this clinically\nimportant but technically ignored problem, we propose the MSFI\n(Modality-Specific Feature Importance) metric to examine whether saliency maps\ncan highlight modality-specific important features. MSFI encodes the clinical\nrequirements on modality prioritization and modality-specific feature\nlocalization. Our evaluations on 16 commonly used saliency map methods,\nincluding a clinician user study, show that although most saliency map methods\ncaptured modality importance information in general, most of them failed to\nhighlight modality-specific important features consistently and precisely. The\nevaluation results guide the choices of saliency map methods and provide\ninsights to propose new ones targeting clinical applications.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:43:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jin", "Weina", ""], ["Li", "Xiaoxiao", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "2107.05050", "submitter": "Ben Hayes", "authors": "Ben Hayes, Charalampos Saitis, Gy\\\"orgy Fazekas", "title": "Neural Waveshaping Synthesis", "comments": "Accepted to ISMIR 2021; See online supplement at\n  https://benhayes.net/projects/nws/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Neural Waveshaping Unit (NEWT): a novel, lightweight, fully\ncausal approach to neural audio synthesis which operates directly in the\nwaveform domain, with an accompanying optimisation (FastNEWT) for efficient CPU\ninference. The NEWT uses time-distributed multilayer perceptrons with periodic\nactivations to implicitly learn nonlinear transfer functions that encode the\ncharacteristics of a target timbre. Once trained, a NEWT can produce complex\ntimbral evolutions by simple affine transformations of its input and output\nsignals. We paired the NEWT with a differentiable noise synthesiser and reverb\nand found it capable of generating realistic musical instrument performances\nwith only 260k total model parameters, conditioned on F0 and loudness features.\nWe compared our method to state-of-the-art benchmarks with a multi-stimulus\nlistening test and the Fr\\'echet Audio Distance and found it performed\ncompetitively across the tested timbral domains. Our method significantly\noutperformed the benchmarks in terms of generation speed, and achieved\nreal-time performance on a consumer CPU, both with and without FastNEWT,\nsuggesting it is a viable basis for future creative sound design tools.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:50:59 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 14:28:39 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Hayes", "Ben", ""], ["Saitis", "Charalampos", ""], ["Fazekas", "Gy\u00f6rgy", ""]]}, {"id": "2107.05071", "submitter": "Yunsong Xie", "authors": "Yunsong Xie, Ryan Stearrett", "title": "Machine Learning based CVD Virtual Metrology in Mass Produced\n  Semiconductor Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cross-benchmark has been done on three critical aspects, data imputing,\nfeature selection and regression algorithms, for machine learning based\nchemical vapor deposition (CVD) virtual metrology (VM). The result reveals that\nlinear feature selection regression algorithm would extensively under-fit the\nVM data. Data imputing is also necessary to achieve a higher prediction\naccuracy as the data availability is only ~70% when optimal accuracy is\nobtained. This work suggests a nonlinear feature selection and regression\nalgorithm combined with nearest data imputing algorithm would provide a\nprediction accuracy as high as 0.7. This would lead to 70% reduced CVD\nprocessing variation, which is believed to will lead to reduced frequency of\nphysical metrology as well as more reliable mass-produced wafer with improved\nquality.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 15:32:31 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 04:34:44 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Xie", "Yunsong", ""], ["Stearrett", "Ryan", ""]]}, {"id": "2107.05074", "submitter": "Ayush Sekhari", "authors": "Satyen Kale, Ayush Sekhari, Karthik Sridharan", "title": "SGD: The Role of Implicit Regularization, Batch-size and Multiple-epochs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi-epoch, small-batch, Stochastic Gradient Descent (SGD) has been the\nmethod of choice for learning with large over-parameterized models. A popular\ntheory for explaining why SGD works well in practice is that the algorithm has\nan implicit regularization that biases its output towards a good solution.\nPerhaps the theoretically most well understood learning setting for SGD is that\nof Stochastic Convex Optimization (SCO), where it is well known that SGD learns\nat a rate of $O(1/\\sqrt{n})$, where $n$ is the number of samples. In this\npaper, we consider the problem of SCO and explore the role of implicit\nregularization, batch size and multiple epochs for SGD. Our main contributions\nare threefold:\n  (a) We show that for any regularizer, there is an SCO problem for which\nRegularized Empirical Risk Minimzation fails to learn. This automatically rules\nout any implicit regularization based explanation for the success of SGD.\n  (b) We provide a separation between SGD and learning via Gradient Descent on\nempirical loss (GD) in terms of sample complexity. We show that there is an SCO\nproblem such that GD with any step size and number of iterations can only learn\nat a suboptimal rate: at least $\\widetilde{\\Omega}(1/n^{5/12})$.\n  (c) We present a multi-epoch variant of SGD commonly used in practice. We\nprove that this algorithm is at least as good as single pass SGD in the worst\ncase. However, for certain SCO problems, taking multiple passes over the\ndataset can significantly outperform single pass SGD.\n  We extend our results to the general learning setting by showing a problem\nwhich is learnable for any data distribution, and for this problem, SGD is\nstrictly better than RERM for any regularization function. We conclude by\ndiscussing the implications of our results for deep learning, and show a\nseparation between SGD and ERM for two layer diagonal neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 15:50:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kale", "Satyen", ""], ["Sekhari", "Ayush", ""], ["Sridharan", "Karthik", ""]]}, {"id": "2107.05080", "submitter": "Xuan Kan", "authors": "Xuan Kan, Hejie Cui, Carl Yang", "title": "Zero-Shot Scene Graph Relation Prediction through Commonsense Knowledge\n  Integration", "comments": "This paper has been accepted for presentation in the Research Track\n  of ECML-PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation prediction among entities in images is an important step in scene\ngraph generation (SGG), which further impacts various visual understanding and\nreasoning tasks. Existing SGG frameworks, however, require heavy training yet\nare incapable of modeling unseen (i.e.,zero-shot) triplets. In this work, we\nstress that such incapability is due to the lack of commonsense reasoning,i.e.,\nthe ability to associate similar entities and infer similar relations based on\ngeneral understanding of the world. To fill this gap, we propose\nCommOnsense-integrAted sCenegrapHrElation pRediction (COACHER), a framework to\nintegrate commonsense knowledge for SGG, especially for zero-shot relation\nprediction. Specifically, we develop novel graph mining pipelines to model the\nneighborhoods and paths around entities in an external commonsense knowledge\ngraph, and integrate them on top of state-of-the-art SGG frameworks. Extensive\nquantitative evaluations and qualitative case studies on both original and\nmanipulated datasets from Visual Genome demonstrate the effectiveness of our\nproposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 16:22:45 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kan", "Xuan", ""], ["Cui", "Hejie", ""], ["Yang", "Carl", ""]]}, {"id": "2107.05085", "submitter": "Gorkem Polat", "authors": "Gorkem Polat, Yesim Dogrusoz Serinagaoglu, Ugur Halici", "title": "Effect of Input Size on the Classification of Lung Nodules Using\n  Convolutional Neural Networks", "comments": "4 pages, in Turkish language, 2018 26th Signal Processing and\n  Communications Applications Conference (SIU)", "journal-ref": null, "doi": "10.1109/SIU.2018.8404659", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies have shown that lung cancer screening using annual low-dose\ncomputed tomography (CT) reduces lung cancer mortality by 20% compared to\ntraditional chest radiography. Therefore, CT lung screening has started to be\nused widely all across the world. However, analyzing these images is a serious\nburden for radiologists. The number of slices in a CT scan can be up to 600.\nTherefore, computer-aided-detection (CAD) systems are very important for faster\nand more accurate assessment of the data. In this study, we proposed a\nframework that analyzes CT lung screenings using convolutional neural networks\n(CNNs) to reduce false positives. We trained our model with different volume\nsizes and showed that volume size plays a critical role in the performance of\nthe system. We also used different fusions in order to show their power and\neffect on the overall accuracy. 3D CNNs were preferred over 2D CNNs because 2D\nconvolutional operations applied to 3D data could result in information loss.\nThe proposed framework has been tested on the dataset provided by the LUNA16\nChallenge and resulted in a sensitivity of 0.831 at 1 false positive per scan.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 16:52:30 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Polat", "Gorkem", ""], ["Serinagaoglu", "Yesim Dogrusoz", ""], ["Halici", "Ugur", ""]]}, {"id": "2107.05087", "submitter": "Joshua Mathew", "authors": "Joshua Mathew, Xin Tian, Min Wu, Chau-Wai Wong", "title": "Remote Blood Oxygen Estimation From Videos Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blood oxygen saturation (SpO$_2$) is an essential indicator of respiratory\nfunctionality and is receiving increasing attention during the COVID-19\npandemic. Clinical findings show that it is possible for COVID-19 patients to\nhave significantly low SpO$_2$ before any obvious symptoms. The prevalence of\ncameras has motivated researchers to investigate methods for monitoring SpO$_2$\nusing videos. Most prior schemes involving smartphones are contact-based: They\nrequire a fingertip to cover the phone's camera and the nearby light source to\ncapture re-emitted light from the illuminated tissue. In this paper, we propose\nthe first convolutional neural network based noncontact SpO$_2$ estimation\nscheme using smartphone cameras. The scheme analyzes the videos of a\nparticipant's hand for physiological sensing, which is convenient and\ncomfortable, and can protect their privacy and allow for keeping face masks on.\nWe design our neural network architectures inspired by the optophysiological\nmodels for SpO$_2$ measurement and demonstrate the explainability by\nvisualizing the weights for channel combination. Our proposed models outperform\nthe state-of-the-art model that is designed for contact-based SpO$_2$\nmeasurement, showing the potential of our proposed method to contribute to\npublic health. We also analyze the impact of skin type and the side of a hand\non SpO$_2$ estimation performance.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 16:59:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Mathew", "Joshua", ""], ["Tian", "Xin", ""], ["Wu", "Min", ""], ["Wong", "Chau-Wai", ""]]}, {"id": "2107.05093", "submitter": "Shuo-En Chang", "authors": "Shuo-En Chang, Yi-Cheng Yang, En-Ting Lin, Pei-Yung Hsiao, Li-Chen Fu", "title": "SE-PSNet: Silhouette-based Enhancement Feature for Panoptic Segmentation\n  Network", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, there has been a panoptic segmentation task combining semantic and\ninstance segmentation, in which the goal is to classify each pixel with the\ncorresponding instance ID. In this work, we propose a solution to tackle the\npanoptic segmentation task. The overall structure combines the bottom-up method\nand the top-down method. Therefore, not only can there be better performance,\nbut also the execution speed can be maintained. The network mainly pays\nattention to the quality of the mask. In the previous work, we can see that the\nuneven contour of the object is more likely to appear, resulting in low-quality\nprediction. Accordingly, we propose enhancement features and corresponding loss\nfunctions for the silhouette of objects and backgrounds to improve the mask.\nMeanwhile, we use the new proposed confidence score to solve the occlusion\nproblem and make the network tend to use higher quality masks as prediction\nresults. To verify our research, we used the COCO dataset and CityScapes\ndataset to do experiments and obtained competitive results with fast inference\ntime.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 17:20:32 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chang", "Shuo-En", ""], ["Yang", "Yi-Cheng", ""], ["Lin", "En-Ting", ""], ["Hsiao", "Pei-Yung", ""], ["Fu", "Li-Chen", ""]]}, {"id": "2107.05097", "submitter": "Hejie Cui", "authors": "Hejie Cui, Wei Dai, Yanqiao Zhu, Xiaoxiao Li, Lifang He, Carl Yang", "title": "BrainNNExplainer: An Interpretable Graph Neural Network Framework for\n  Brain Network based Disease Analysis", "comments": "This paper has been accepted to ICML 2021 Workshop on Interpretable\n  Machine Learning in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable brain network models for disease prediction are of great value\nfor the advancement of neuroscience. GNNs are promising to model complicated\nnetwork data, but they are prone to overfitting and suffer from poor\ninterpretability, which prevents their usage in decision-critical scenarios\nlike healthcare. To bridge this gap, we propose BrainNNExplainer, an\ninterpretable GNN framework for brain network analysis. It is mainly composed\nof two jointly learned modules: a backbone prediction model that is\nspecifically designed for brain networks and an explanation generator that\nhighlights disease-specific prominent brain network connections. Extensive\nexperimental results with visualizations on two challenging disease prediction\ndatasets demonstrate the unique interpretability and outstanding performance of\nBrainNNExplainer.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 17:33:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cui", "Hejie", ""], ["Dai", "Wei", ""], ["Zhu", "Yanqiao", ""], ["Li", "Xiaoxiao", ""], ["He", "Lifang", ""], ["Yang", "Carl", ""]]}, {"id": "2107.05101", "submitter": "Racine Ly", "authors": "Racine Ly", "title": "Machine Learning Challenges and Opportunities in the African\n  Agricultural Sector -- A General Perspective", "comments": "This paper has been submitted as an internal discussion paper at\n  AKADEMIYA2063. It has 13 pages and contains 4 images and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The improvement of computers' capacities, advancements in algorithmic\ntechniques, and the significant increase of available data have enabled the\nrecent developments of Artificial Intelligence (AI) technology. One of its\nbranches, called Machine Learning (ML), has shown strong capacities in\nmimicking characteristics attributed to human intelligence, such as vision,\nspeech, and problem-solving. However, as previous technological revolutions\nsuggest, their most significant impacts could be mostly expected on other\nsectors that were not traditional users of that technology. The agricultural\nsector is vital for African economies; improving yields, mitigating losses, and\neffective management of natural resources are crucial in a climate change era.\nMachine Learning is a technology with an added value in making predictions,\nhence the potential to reduce uncertainties and risk across sectors, in this\ncase, the agricultural sector. The purpose of this paper is to contextualize\nand discuss barriers to ML-based solutions for African agriculture. In the\nsecond section, we provided an overview of ML technology from a historical and\ntechnical perspective and its main driving force. In the third section, we\nprovided a brief review of the current use of ML in agriculture. Finally, in\nsection 4, we discuss ML growing interest in Africa and the potential barriers\nto creating and using ML-based solutions in the agricultural sector.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 17:48:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Ly", "Racine", ""]]}, {"id": "2107.05114", "submitter": "Hai Nguyen", "authors": "Hai N. Nguyen, Marinos Vomvas, Triet Vo-Huu, Guevara Noubir", "title": "Spectro-Temporal RF Identification using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RF emissions detection, classification, and spectro-temporal localization are\ncrucial not only for tasks relating to understanding, managing, and protecting\nthe RF spectrum, but also for safety and security applications such as\ndetecting intruding drones or jammers. Achieving this goal for wideband\nspectrum and in real-time performance is a challenging problem. We present\nWRIST, a Wideband, Real-time RF Identification system with Spectro-Temporal\ndetection, framework and system. Our resulting deep learning model is capable\nto detect, classify, and precisely locate RF emissions in time and frequency\nusing RF samples of 100 MHz spectrum in real-time (over 6Gbps incoming I&Q\nstreams). Such capabilities are made feasible by leveraging a deep-learning\nbased one-stage object detection framework, and transfer learning to a\nmulti-channel image-based RF signals representation. We also introduce an\niterative training approach which leverages synthesized and augmented RF data\nto efficiently build large labelled datasets of RF emissions (SPREAD). WRIST\ndetector achieves 90 mean Average Precision even in extremely congested\nenvironment in the wild. WRIST model classifies five technologies (Bluetooth,\nLightbridge, Wi-Fi, XPD, and ZigBee) and is easily extendable to others. We are\nmaking our curated and annotated dataset available to the whole community. It\nconsists of nearly 1 million fully labelled RF emissions collected from various\noff-the-shelf wireless radios in a range of environments and spanning the five\nclasses of emissions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 19:02:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Nguyen", "Hai N.", ""], ["Vomvas", "Marinos", ""], ["Vo-Huu", "Triet", ""], ["Noubir", "Guevara", ""]]}, {"id": "2107.05115", "submitter": "Basit Alawode", "authors": "Basit O. Alawode, Mudassir Masood, Tarig Ballal, and Tareq Al-Naffouri", "title": "Details Preserving Deep Collaborative Filtering-Based Method for Image\n  Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In spite of the improvements achieved by the several denoising algorithms\nover the years, many of them still fail at preserving the fine details of the\nimage after denoising. This is as a result of the smooth-out effect they have\non the images. Most neural network-based algorithms have achieved better\nquantitative performance than the classical denoising algorithms. However, they\nalso suffer from qualitative (visual) performance as a result of the smooth-out\neffect. In this paper, we propose an algorithm to address this shortcoming. We\npropose a deep collaborative filtering-based (Deep-CoFiB) algorithm for image\ndenoising. This algorithm performs collaborative denoising of image patches in\nthe sparse domain using a set of optimized neural network models. This results\nin a fast algorithm that is able to excellently obtain a trade-off between\nnoise removal and details preservation. Extensive experiments show that the\nDeepCoFiB performed quantitatively (in terms of PSNR and SSIM) and\nqualitatively (visually) better than many of the state-of-the-art denoising\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 19:02:36 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 16:53:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Alawode", "Basit O.", ""], ["Masood", "Mudassir", ""], ["Ballal", "Tarig", ""], ["Al-Naffouri", "Tareq", ""]]}, {"id": "2107.05124", "submitter": "Gabriel De Souza Pereira Moreira", "authors": "Gabriel de Souza P. Moreira and Sara Rabhi and Ronay Ak and Md Yasin\n  Kabir and Even Oldridge", "title": "Transformers with multi-modal features and post-fusion context for\n  e-commerce session-based recommendation", "comments": "In Proceedings of SIGIR eCom'21 - SIGIR eCommerce Workshop Data\n  Challenge 2021. https://sigir-ecom.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Session-based recommendation is an important task for e-commerce services,\nwhere a large number of users browse anonymously or may have very distinct\ninterests for different sessions. In this paper we present one of the winning\nsolutions for the Recommendation task of the SIGIR 2021 Workshop on E-commerce\nData Challenge. Our solution was inspired by NLP techniques and consists of an\nensemble of two Transformer architectures - Transformer-XL and XLNet - trained\nwith autoregressive and autoencoding approaches. To leverage most of the rich\ndataset made available for the competition, we describe how we prepared\nmulti-model features by combining tabular events with textual and image\nvectors. We also present a model prediction analysis to better understand the\neffectiveness of our architectures for the session-based recommendation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 20:02:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Moreira", "Gabriel de Souza P.", ""], ["Rabhi", "Sara", ""], ["Ak", "Ronay", ""], ["Kabir", "Md Yasin", ""], ["Oldridge", "Even", ""]]}, {"id": "2107.05127", "submitter": "Muhammad Azmi Umer", "authors": "Muhammad Azmi Umer, Chuadhry Mujeeb Ahmed, Muhammad Taha Jilani,\n  Aditya P. Mathur", "title": "Attack Rules: An Adversarial Approach to Generate Attacks for Industrial\n  Control Systems using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial learning is used to test the robustness of machine learning\nalgorithms under attack and create attacks that deceive the anomaly detection\nmethods in Industrial Control System (ICS). Given that security assessment of\nan ICS demands that an exhaustive set of possible attack patterns is studied,\nin this work, we propose an association rule mining-based attack generation\ntechnique. The technique has been implemented using data from a secure Water\nTreatment plant. The proposed technique was able to generate more than 300,000\nattack patterns constituting a vast majority of new attack vectors which were\nnot seen before. Automatically generated attacks improve our understanding of\nthe potential attacks and enable the design of robust attack detection\ntechniques.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 20:20:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Umer", "Muhammad Azmi", ""], ["Ahmed", "Chuadhry Mujeeb", ""], ["Jilani", "Muhammad Taha", ""], ["Mathur", "Aditya P.", ""]]}, {"id": "2107.05132", "submitter": "Georgios Michalopoulos", "authors": "George Michalopoulos, Ian McKillop, Alexander Wong, Helen Chen", "title": "LexSubCon: Integrating Knowledge from Lexical Resources into Contextual\n  Embeddings for Lexical Substitution", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical substitution is the task of generating meaningful substitutes for a\nword in a given textual context. Contextual word embedding models have achieved\nstate-of-the-art results in the lexical substitution task by relying on\ncontextual information extracted from the replaced word within the sentence.\nHowever, such models do not take into account structured knowledge that exists\nin external lexical databases.\n  We introduce LexSubCon, an end-to-end lexical substitution framework based on\ncontextual embedding models that can identify highly accurate substitute\ncandidates. This is achieved by combining contextual information with knowledge\nfrom structured lexical resources. Our approach involves: (i) introducing a\nnovel mix-up embedding strategy in the creation of the input embedding of the\ntarget word through linearly interpolating the pair of the target input\nembedding and the average embedding of its probable synonyms; (ii) considering\nthe similarity of the sentence-definition embeddings of the target word and its\nproposed candidates; and, (iii) calculating the effect of each substitution in\nthe semantics of the sentence through a fine-tuned sentence similarity model.\nOur experiments show that LexSubCon outperforms previous state-of-the-art\nmethods on LS07 and CoInCo benchmark datasets that are widely used for lexical\nsubstitution tasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 21:25:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Michalopoulos", "George", ""], ["McKillop", "Ian", ""], ["Wong", "Alexander", ""], ["Chen", "Helen", ""]]}, {"id": "2107.05134", "submitter": "Carles Domingo-Enrich", "authors": "Carles Domingo-Enrich, Alberto Bietti, Marylou Gabri\\'e, Joan Bruna,\n  Eric Vanden-Eijnden", "title": "Dual Training of Energy-Based Models with Overparametrized Shallow\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-based models (EBMs) are generative models that are usually trained via\nmaximum likelihood estimation. This approach becomes challenging in generic\nsituations where the trained energy is nonconvex, due to the need to sample the\nGibbs distribution associated with this energy. Using general Fenchel duality\nresults, we derive variational principles dual to maximum likelihood EBMs with\nshallow overparametrized neural network energies, both in the active (aka\nfeature-learning) and lazy regimes. In the active regime, this dual formulation\nleads to a training algorithm in which one updates concurrently the particles\nin the sample space and the neurons in the parameter space of the energy. We\nalso consider a variant of this algorithm in which the particles are sometimes\nrestarted at random samples drawn from the data set, and show that performing\nthese restarts at every iteration step corresponds to score matching training.\nUsing intermediate parameter setups in our dual algorithm thereby gives a way\nto interpolate between maximum likelihood and score matching training. These\nresults are illustrated in simple numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 21:43:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Domingo-Enrich", "Carles", ""], ["Bietti", "Alberto", ""], ["Gabri\u00e9", "Marylou", ""], ["Bruna", "Joan", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "2107.05154", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, Jaideep Srivastava", "title": "MOOCRep: A Unified Pre-trained Embedding of MOOC Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models have been built to tackle information overload\nissues on Massive Open Online Courses (MOOC) platforms. These models rely on\nlearning powerful representations of MOOC entities. However, they suffer from\nthe problem of scarce expert label data. To overcome this problem, we propose\nto learn pre-trained representations of MOOC entities using abundant unlabeled\ndata from the structure of MOOCs which can directly be applied to the\ndownstream tasks. While existing pre-training methods have been successful in\nNLP areas as they learn powerful textual representation, their models do not\nleverage the richer information about MOOC entities. This richer information\nincludes the graph relationship between the lectures, concepts, and courses\nalong with the domain knowledge about the complexity of a concept. We develop\nMOOCRep, a novel method based on Transformer language model trained with two\npre-training objectives : 1) graph-based objective to capture the powerful\nsignal of entities and relations that exist in the graph, and 2)\ndomain-oriented objective to effectively incorporate the complexity level of\nconcepts. Our experiments reveal that MOOCRep's embeddings outperform\nstate-of-the-art representation learning methods on two tasks important for\neducation community, concept pre-requisite prediction and lecture\nrecommendation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 00:11:25 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pandey", "Shalini", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "2107.05166", "submitter": "Soham Pal", "authors": "Soham Pal, Yash Gupta, Aditya Kanade, Shirish Shevade", "title": "Stateful Detection of Model Extraction Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-Learning-as-a-Service providers expose machine learning (ML) models\nthrough application programming interfaces (APIs) to developers. Recent work\nhas shown that attackers can exploit these APIs to extract good approximations\nof such ML models, by querying them with samples of their choosing. We propose\nVarDetect, a stateful monitor that tracks the distribution of queries made by\nusers of such a service, to detect model extraction attacks. Harnessing the\nlatent distributions learned by a modified variational autoencoder, VarDetect\nrobustly separates three types of attacker samples from benign samples, and\nsuccessfully raises an alarm for each. Further, with VarDetect deployed as an\nautomated defense mechanism, the extracted substitute models are found to\nexhibit poor performance and transferability, as intended. Finally, we\ndemonstrate that even adaptive attackers with prior knowledge of the deployment\nof VarDetect, are detected by it.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 02:18:26 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pal", "Soham", ""], ["Gupta", "Yash", ""], ["Kanade", "Aditya", ""], ["Shevade", "Shirish", ""]]}, {"id": "2107.05180", "submitter": "Weijia Zhang", "authors": "Weijia Zhang, Hao Liu, Lijun Zha, Hengshu Zhu, Ji Liu, Dejing Dou, Hui\n  Xiong", "title": "MugRep: A Multi-Task Hierarchical Graph Representation Learning\n  Framework for Real Estate Appraisal", "comments": "11 pages, SIGKDD-2021", "journal-ref": null, "doi": "10.1145/3447548.3467187", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real estate appraisal refers to the process of developing an unbiased opinion\nfor real property's market value, which plays a vital role in decision-making\nfor various players in the marketplace (e.g., real estate agents, appraisers,\nlenders, and buyers). However, it is a nontrivial task for accurate real estate\nappraisal because of three major challenges: (1) The complicated influencing\nfactors for property value; (2) The asynchronously spatiotemporal dependencies\namong real estate transactions; (3) The diversified correlations between\nresidential communities. To this end, we propose a Multi-Task Hierarchical\nGraph Representation Learning (MugRep) framework for accurate real estate\nappraisal. Specifically, by acquiring and integrating multi-source urban data,\nwe first construct a rich feature set to comprehensively profile the real\nestate from multiple perspectives (e.g., geographical distribution, human\nmobility distribution, and resident demographics distribution). Then, an\nevolving real estate transaction graph and a corresponding event graph\nconvolution module are proposed to incorporate asynchronously spatiotemporal\ndependencies among real estate transactions. Moreover, to further incorporate\nvaluable knowledge from the view of residential communities, we devise a\nhierarchical heterogeneous community graph convolution module to capture\ndiversified correlations between residential communities. Finally, an urban\ndistrict partitioned multi-task learning module is introduced to generate\ndifferently distributed value opinions for real estate. Extensive experiments\non two real-world datasets demonstrate the effectiveness of MugRep and its\ncomponents and features.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 03:51:44 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhang", "Weijia", ""], ["Liu", "Hao", ""], ["Zha", "Lijun", ""], ["Zhu", "Hengshu", ""], ["Liu", "Ji", ""], ["Dou", "Dejing", ""], ["Xiong", "Hui", ""]]}, {"id": "2107.05187", "submitter": "Siddartha Devic", "authors": "Siddartha Devic, Zihao Deng, Brendan Juba", "title": "Polynomial Time Reinforcement Learning in Correlated FMDPs with Linear\n  Value Functions", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning (RL) environments in practice feature enormous\nstate spaces that may be described compactly by a \"factored\" structure, that\nmay be modeled by Factored Markov Decision Processes (FMDPs). We present the\nfirst polynomial-time algorithm for RL with FMDPs that does not rely on an\noracle planner, and instead of requiring a linear transition model, only\nrequires a linear value function with a suitable local basis with respect to\nthe factorization. With this assumption, we can solve FMDPs in polynomial time\nby constructing an efficient separation oracle for convex optimization.\nImportantly, and in contrast to prior work, we do not assume that the\ntransitions on various factors are independent.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 04:13:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Devic", "Siddartha", ""], ["Deng", "Zihao", ""], ["Juba", "Brendan", ""]]}, {"id": "2107.05188", "submitter": "Menghan Hu", "authors": "Yao Chang, Hu Menghan, Zhai Guangtao, Zhang Xiao-Ping", "title": "TransClaw U-Net: Claw U-Net with Transformers for Medical Image\n  Segmentation", "comments": "8 page, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, computer-aided diagnosis has become an increasingly popular\ntopic. Methods based on convolutional neural networks have achieved good\nperformance in medical image segmentation and classification. Due to the\nlimitations of the convolution operation, the long-term spatial features are\noften not accurately obtained. Hence, we propose a TransClaw U-Net network\nstructure, which combines the convolution operation with the transformer\noperation in the encoding part. The convolution part is applied for extracting\nthe shallow spatial features to facilitate the recovery of the image resolution\nafter upsampling. The transformer part is used to encode the patches, and the\nself-attention mechanism is used to obtain global information between\nsequences. The decoding part retains the bottom upsampling structure for better\ndetail segmentation performance. The experimental results on Synapse\nMulti-organ Segmentation Datasets show that the performance of TransClaw U-Net\nis better than other network structures. The ablation experiments also prove\nthe generalization performance of TransClaw U-Net.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 04:17:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chang", "Yao", ""], ["Menghan", "Hu", ""], ["Guangtao", "Zhai", ""], ["Xiao-Ping", "Zhang", ""]]}, {"id": "2107.05201", "submitter": "Dong Zhou", "authors": "Hengxu Lin, Dong Zhou, Weiqing Liu, Jiang Bian", "title": "Deep Risk Model: A Deep Learning Solution for Mining Latent Risk Factors\n  to Improve Covariance Matrix Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling and managing portfolio risk is perhaps the most important step to\nachieve growing and preserving investment performance. Within the modern\nportfolio construction framework that built on Markowitz's theory, the\ncovariance matrix of stock returns is required to model the portfolio risk.\nTraditional approaches to estimate the covariance matrix are based on human\ndesigned risk factors, which often requires tremendous time and effort to\ndesign better risk factors to improve the covariance estimation. In this work,\nwe formulate the quest of mining risk factors as a learning problem and propose\na deep learning solution to effectively \"design\" risk factors with neural\nnetworks. The learning objective is carefully set to ensure the learned risk\nfactors are effective in explaining stock returns as well as have desired\northogonality and stability. Our experiments on the stock market data\ndemonstrate the effectiveness of the proposed method: our method can obtain\n$1.9\\%$ higher explained variance measured by $R^2$ and also reduce the risk of\na global minimum variance portfolio. Incremental analysis further supports our\ndesign of both the architecture and the learning objective.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 05:30:50 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Lin", "Hengxu", ""], ["Zhou", "Dong", ""], ["Liu", "Weiqing", ""], ["Bian", "Jiang", ""]]}, {"id": "2107.05204", "submitter": "Yanhua Huang", "authors": "Yanhua Huang, Weikun Wang, Lei Zhang, Ruiwen Xu", "title": "Sliding Spectrum Decomposition for Diversified Recommendation", "comments": "In Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD '21), August 14--18, 2021, Virtual Event,\n  Singapore", "journal-ref": null, "doi": "10.1145/3447548.3467108", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Content feed, a type of product that recommends a sequence of items for users\nto browse and engage with, has gained tremendous popularity among social media\nplatforms. In this paper, we propose to study the diversity problem in such a\nscenario from an item sequence perspective using time series analysis\ntechniques. We derive a method called sliding spectrum decomposition (SSD) that\ncaptures users' perception of diversity in browsing a long item sequence. We\nalso share our experiences in designing and implementing a suitable item\nembedding method for accurate similarity measurement under long tail effect.\nCombined together, they are now fully implemented and deployed in Xiaohongshu\nApp's production recommender system that serves the main Explore Feed product\nfor tens of millions of users every day. We demonstrate the effectiveness and\nefficiency of the method through theoretical analysis, offline experiments and\nonline A/B tests.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 05:41:54 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huang", "Yanhua", ""], ["Wang", "Weikun", ""], ["Zhang", "Lei", ""], ["Xu", "Ruiwen", ""]]}, {"id": "2107.05216", "submitter": "Sobhan Miryoosefi", "authors": "Sobhan Miryoosefi, Chi Jin", "title": "A Simple Reward-free Approach to Constrained Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In constrained reinforcement learning (RL), a learning agent seeks to not\nonly optimize the overall reward but also satisfy the additional safety,\ndiversity, or budget constraints. Consequently, existing constrained RL\nsolutions require several new algorithmic ingredients that are notably\ndifferent from standard RL. On the other hand, reward-free RL is independently\ndeveloped in the unconstrained literature, which learns the transition dynamics\nwithout using the reward information, and thus naturally capable of addressing\nRL with multiple objectives under the common dynamics. This paper bridges\nreward-free RL and constrained RL. Particularly, we propose a simple\nmeta-algorithm such that given any reward-free RL oracle, the approachability\nand constrained RL problems can be directly solved with negligible overheads in\nsample complexity. Utilizing the existing reward-free RL solvers, our framework\nprovides sharp sample complexity results for constrained RL in the tabular MDP\nsetting, matching the best existing results up to a factor of horizon\ndependence; our framework directly extends to a setting of tabular two-player\nMarkov games, and gives a new result for constrained RL with linear function\napproximation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 06:27:30 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Miryoosefi", "Sobhan", ""], ["Jin", "Chi", ""]]}, {"id": "2107.05217", "submitter": "Lingwei Zhu", "authors": "Lingwei Zhu, Toshinori Kitamura, Takamitsu Matsubara", "title": "Cautious Actor-Critic", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The oscillating performance of off-policy learning and persisting errors in\nthe actor-critic (AC) setting call for algorithms that can conservatively learn\nto suit the stability-critical applications better. In this paper, we propose a\nnovel off-policy AC algorithm cautious actor-critic (CAC). The name cautious\ncomes from the doubly conservative nature that we exploit the classic policy\ninterpolation from conservative policy iteration for the actor and the\nentropy-regularization of conservative value iteration for the critic. Our key\nobservation is the entropy-regularized critic facilitates and simplifies the\nunwieldy interpolated actor update while still ensuring robust policy\nimprovement. We compare CAC to state-of-the-art AC methods on a set of\nchallenging continuous control problems and demonstrate that CAC achieves\ncomparable performance while significantly stabilizes learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 06:40:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Zhu", "Lingwei", ""], ["Kitamura", "Toshinori", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2107.05222", "submitter": "Anirudh Sreeram", "authors": "Anirudh Sreeram, Nicholas Mehlman, Raghuveer Peri, Dillon Knox,\n  Shrikanth Narayanan", "title": "Perceptual-based deep-learning denoiser as a defense against adversarial\n  attacks on ASR systems", "comments": "5 pages, 4 figures submitted to ASRU 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we investigate speech denoising as a defense against\nadversarial attacks on automatic speech recognition (ASR) systems. Adversarial\nattacks attempt to force misclassification by adding small perturbations to the\noriginal speech signal. We propose to counteract this by employing a\nneural-network based denoiser as a pre-processor in the ASR pipeline. The\ndenoiser is independent of the downstream ASR model, and thus can be rapidly\ndeployed in existing systems. We found that training the denoisier using a\nperceptually motivated loss function resulted in increased adversarial\nrobustness without compromising ASR performance on benign samples. Our defense\nwas evaluated (as a part of the DARPA GARD program) on the 'Kenansville' attack\nstrategy across a range of attack strengths and speech samples. An average\nimprovement in Word Error Rate (WER) of about 7.7% was observed over the\nundefended model at 20 dB signal-to-noise-ratio (SNR) attack strength.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:00:06 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sreeram", "Anirudh", ""], ["Mehlman", "Nicholas", ""], ["Peri", "Raghuveer", ""], ["Knox", "Dillon", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2107.05223", "submitter": "Yi-Hui Chou", "authors": "Yi-Hui Chou, I-Chun Chen, Chin-Jui Chang, Joann Ching, and Yi-Hsuan\n  Yang", "title": "MidiBERT-Piano: Large-scale Pre-training for Symbolic Music\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an attempt to employ the mask language modeling approach\nof BERT to pre-train a 12-layer Transformer model over 4,166 pieces of\npolyphonic piano MIDI files for tackling a number of symbolic-domain\ndiscriminative music understanding tasks. These include two note-level\nclassification tasks, i.e., melody extraction and velocity prediction, as well\nas two sequence-level classification tasks, i.e., composer classification and\nemotion classification. We find that, given a pre-trained Transformer, our\nmodels outperform recurrent neural network based baselines with less than 10\nepochs of fine-tuning. Ablation studies show that the pre-training remains\neffective even if none of the MIDI data of the downstream tasks are seen at the\npre-training stage, and that freezing the self-attention layers of the\nTransformer at the fine-tuning stage slightly degrades performance. All the\nfive datasets employed in this work are publicly available, as well as\ncheckpoints of our pre-trained and fine-tuned models. As such, our research can\nbe taken as a benchmark for symbolic-domain music understanding.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:03:57 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chou", "Yi-Hui", ""], ["Chen", "I-Chun", ""], ["Chang", "Chin-Jui", ""], ["Ching", "Joann", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2107.05230", "submitter": "Bastian Rieck", "authors": "Michael Moor, Nicolas Bennet, Drago Plecko, Max Horn, Bastian Rieck,\n  Nicolai Meinshausen, Peter B\\\"uhlmann, Karsten Borgwardt", "title": "Predicting sepsis in multi-site, multi-national intensive care cohorts\n  using deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite decades of clinical research, sepsis remains a global public health\ncrisis with high mortality, and morbidity. Currently, when sepsis is detected\nand the underlying pathogen is identified, organ damage may have already\nprogressed to irreversible stages. Effective sepsis management is therefore\nhighly time-sensitive. By systematically analysing trends in the plethora of\nclinical data available in the intensive care unit (ICU), an early prediction\nof sepsis could lead to earlier pathogen identification, resistance testing,\nand effective antibiotic and supportive treatment, and thereby become a\nlife-saving measure. Here, we developed and validated a machine learning (ML)\nsystem for the prediction of sepsis in the ICU. Our analysis represents the\nlargest multi-national, multi-centre in-ICU study for sepsis prediction using\nML to date. Our dataset contains $156,309$ unique ICU admissions, which\nrepresent a refined and harmonised subset of five large ICU databases\noriginating from three countries. Using the international consensus definition\nSepsis-3, we derived hourly-resolved sepsis label annotations, amounting to\n$26,734$ ($17.1\\%$) septic stays. We compared our approach, a deep\nself-attention model, to several clinical baselines as well as ML baselines and\nperformed an extensive internal and external validation within and across\ndatabases. On average, our model was able to predict sepsis with an AUROC of\n$0.847 \\pm 0.050$ (internal out-of sample validation) and $0.761 \\pm 0.052$\n(external validation). For a harmonised prevalence of $17\\%$, at $80\\%$ recall\nour model detects septic patients with $39\\%$ precision 3.7 hours in advance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:21:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Moor", "Michael", ""], ["Bennet", "Nicolas", ""], ["Plecko", "Drago", ""], ["Horn", "Max", ""], ["Rieck", "Bastian", ""], ["Meinshausen", "Nicolai", ""], ["B\u00fchlmann", "Peter", ""], ["Borgwardt", "Karsten", ""]]}, {"id": "2107.05235", "submitter": "Yutao Ma", "authors": "Liwei Huang, Yutao Ma, Yanbo Liu, Shuliang Wang, Deyi Li", "title": "Position-enhanced and Time-aware Graph Convolutional Network for\n  Sequential Recommendations", "comments": "25 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing deep learning-based sequential recommendation approaches\nutilize the recurrent neural network architecture or self-attention to model\nthe sequential patterns and temporal influence among a user's historical\nbehavior and learn the user's preference at a specific time. However, these\nmethods have two main drawbacks. First, they focus on modeling users' dynamic\nstates from a user-centric perspective and always neglect the dynamics of items\nover time. Second, most of them deal with only the first-order user-item\ninteractions and do not consider the high-order connectivity between users and\nitems, which has recently been proved helpful for the sequential\nrecommendation. To address the above problems, in this article, we attempt to\nmodel user-item interactions by a bipartite graph structure and propose a new\nrecommendation approach based on a Position-enhanced and Time-aware Graph\nConvolutional Network (PTGCN) for the sequential recommendation. PTGCN models\nthe sequential patterns and temporal dynamics between user-item interactions by\ndefining a position-enhanced and time-aware graph convolution operation and\nlearning the dynamic representations of users and items simultaneously on the\nbipartite graph with a self-attention aggregator. Also, it realizes the\nhigh-order connectivity between users and items by stacking multi-layer graph\nconvolutions. To demonstrate the effectiveness of PTGCN, we carried out a\ncomprehensive evaluation of PTGCN on three real-world datasets of different\nsizes compared with a few competitive baselines. Experimental results indicate\nthat PTGCN outperforms several state-of-the-art models in terms of two\ncommonly-used evaluation metrics for ranking.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:34:20 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huang", "Liwei", ""], ["Ma", "Yutao", ""], ["Liu", "Yanbo", ""], ["Wang", "Shuliang", ""], ["Li", "Deyi", ""]]}, {"id": "2107.05241", "submitter": "Vinod K Kurmi", "authors": "Blessen George and Vinod K. Kurmi and Vinay P. Namboodiri", "title": "Prb-GAN: A Probabilistic Framework for GAN Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Generative adversarial networks (GANs) are very popular to generate realistic\nimages, but they often suffer from the training instability issues and the\nphenomenon of mode loss. In order to attain greater diversity in GAN\nsynthesized data, it is critical to solving the problem of mode loss. Our work\nexplores probabilistic approaches to GAN modelling that could allow us to\ntackle these issues. We present Prb-GANs, a new variation that uses dropout to\ncreate a distribution over the network parameters with the posterior learnt\nusing variational inference. We describe theoretically and validate\nexperimentally using simple and complex datasets the benefits of such an\napproach. We look into further improvements using the concept of uncertainty\nmeasures. Through a set of further modifications to the loss functions for each\nnetwork of the GAN, we are able to get results that show the improvement of GAN\nperformance. Our methods are extremely simple and require very little\nmodification to existing GAN architecture.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:04:13 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["George", "Blessen", ""], ["Kurmi", "Vinod K.", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2107.05252", "submitter": "Jiacheng Liang", "authors": "Jiacheng Liang, Wensi Jiang and Songze Li", "title": "OmniLytics: A Blockchain-based Secure Data Market for Decentralized\n  Machine Learning", "comments": "12 pages,5 figures, accepted by International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2021(http://federated-learning.org/fl-icml-2021/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose OmniLytics, a blockchain-based secure data trading marketplace for\nmachine learning applications. Utilizing OmniLytics, many distributed data\nowners can contribute their private data to collectively train a ML model\nrequested by some model owners, and get compensated for data contribution.\nOmniLytics enables such model training while simultaneously providing 1) model\nsecurity against curious data owners; 2) data security against curious model\nand data owners; 3) resilience to malicious data owners who provide faulty\nresults to poison model training; and 4) resilience to malicious model owner\nwho intents to evade the payment. OmniLytics is implemented as a smart contract\non the Ethereum blockchain to guarantee the atomicity of payment. In\nOmniLytics, a model owner publishes encrypted initial model on the contract,\nover which the participating data owners compute gradients using their private\ndata, and securely aggregate the gradients through the contract. Finally, the\ncontract reimburses the data owners, and the model owner decrypts the\naggregated model update. We implement a working prototype of OmniLytics on\nEthereum, and perform extensive experiments to measure its gas cost and\nexecution time under various parameter combinations, demonstrating its high\ncomputation and cost efficiency and strong practicality.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:28:15 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liang", "Jiacheng", ""], ["Jiang", "Wensi", ""], ["Li", "Songze", ""]]}, {"id": "2107.05255", "submitter": "Sophia Bano", "authors": "Sophia Bano, Brian Dromey, Francisco Vasconcelos, Raffaele Napolitano,\n  Anna L. David, Donald M. Peebles, Danail Stoyanov", "title": "AutoFB: Automating Fetal Biometry Estimation from Standard Ultrasound\n  Planes", "comments": "Accepted at MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During pregnancy, ultrasound examination in the second trimester can assess\nfetal size according to standardized charts. To achieve a reproducible and\naccurate measurement, a sonographer needs to identify three standard 2D planes\nof the fetal anatomy (head, abdomen, femur) and manually mark the key\nanatomical landmarks on the image for accurate biometry and fetal weight\nestimation. This can be a time-consuming operator-dependent task, especially\nfor a trainee sonographer. Computer-assisted techniques can help in automating\nthe fetal biometry computation process. In this paper, we present a unified\nautomated framework for estimating all measurements needed for the fetal weight\nassessment. The proposed framework semantically segments the key fetal\nanatomies using state-of-the-art segmentation models, followed by region\nfitting and scale recovery for the biometry estimation. We present an ablation\nstudy of segmentation algorithms to show their robustness through 4-fold\ncross-validation on a dataset of 349 ultrasound standard plane images from 42\npregnancies. Moreover, we show that the network with the best segmentation\nperformance tends to be more accurate for biometry estimation. Furthermore, we\ndemonstrate that the error between clinically measured and predicted fetal\nbiometry is lower than the permissible error during routine clinical\nmeasurements.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:42:31 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bano", "Sophia", ""], ["Dromey", "Brian", ""], ["Vasconcelos", "Francisco", ""], ["Napolitano", "Raffaele", ""], ["David", "Anna L.", ""], ["Peebles", "Donald M.", ""], ["Stoyanov", "Danail", ""]]}, {"id": "2107.05264", "submitter": "Yingshi Chen", "authors": "Yingshi Chen", "title": "The Brownian motion in the transformer model", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transformer is the state of the art model for many language and visual tasks.\nIn this paper, we give a deep analysis of its multi-head self-attention (MHSA)\nmodule and find that: 1) Each token is a random variable in high dimensional\nfeature space. 2) After layer normalization, these variables are mapped to\npoints on the hyper-sphere. 3) The update of these tokens is a Brownian motion.\nThe Brownian motion has special properties, its second order item should not be\nignored. So we present a new second-order optimizer(an iterative K-FAC\nalgorithm) for the MHSA module.\n  In some short words: All tokens are mapped to high dimension hyper-sphere.\nThe Scaled Dot-Product Attention\n$softmax(\\frac{\\mathbf{Q}\\mathbf{K}^T}{\\sqrt{d}})$ is just the Markov\ntransition matrix for the random walking on the sphere. And the deep learning\nprocess would learn proper kernel function to get proper positions of these\ntokens. The training process in the MHSA module corresponds to a Brownian\nmotion worthy of further study.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:58:46 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chen", "Yingshi", ""]]}, {"id": "2107.05270", "submitter": "Or Bar-Shira", "authors": "Or Bar-Shira, Ahuva Grubstein, Yael Rapson, Dror Suhami, Eli Atar,\n  Keren Peri-Hanania, Ronnie Rosen, Yonina C. Eldar", "title": "Learned super resolution ultrasound for improved breast lesion\n  characterization", "comments": "to be published in MICCAI 2021 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the most common malignancy in women. Mammographic findings\nsuch as microcalcifications and masses, as well as morphologic features of\nmasses in sonographic scans, are the main diagnostic targets for tumor\ndetection. However, improved specificity of these imaging modalities is\nrequired. A leading alternative target is neoangiogenesis. When pathological,\nit contributes to the development of numerous types of tumors, and the\nformation of metastases. Hence, demonstrating neoangiogenesis by visualization\nof the microvasculature may be of great importance. Super resolution ultrasound\nlocalization microscopy enables imaging of the microvasculature at the\ncapillary level. Yet, challenges such as long reconstruction time, dependency\non prior knowledge of the system Point Spread Function (PSF), and separability\nof the Ultrasound Contrast Agents (UCAs), need to be addressed for translation\nof super-resolution US into the clinic. In this work we use a deep neural\nnetwork architecture that makes effective use of signal structure to address\nthese challenges. We present in vivo human results of three different breast\nlesions acquired with a clinical US scanner. By leveraging our trained network,\nthe microvasculature structure is recovered in a short time, without prior PSF\nknowledge, and without requiring separability of the UCAs. Each of the\nrecoveries exhibits a different structure that corresponds with the known\nhistological structure. This study demonstrates the feasibility of in vivo\nhuman super resolution, based on a clinical scanner, to increase US specificity\nfor different breast lesions and promotes the use of US in the diagnosis of\nbreast pathologies.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 09:04:20 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bar-Shira", "Or", ""], ["Grubstein", "Ahuva", ""], ["Rapson", "Yael", ""], ["Suhami", "Dror", ""], ["Atar", "Eli", ""], ["Peri-Hanania", "Keren", ""], ["Rosen", "Ronnie", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2107.05289", "submitter": "Manjesh Kumar Hanawal", "authors": "Rahul Vaze and Manjesh K. Hanawal", "title": "Continuous Time Bandits With Sampling Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a continuous-time multi-arm bandit problem (CTMAB), where the\nlearner can sample arms any number of times in a given interval and obtain a\nrandom reward from each sample, however, increasing the frequency of sampling\nincurs an additive penalty/cost. Thus, there is a tradeoff between obtaining\nlarge reward and incurring sampling cost as a function of the sampling\nfrequency. The goal is to design a learning algorithm that minimizes regret,\nthat is defined as the difference of the payoff of the oracle policy and that\nof the learning algorithm. CTMAB is fundamentally different than the usual\nmulti-arm bandit problem (MAB), e.g., even the single-arm case is non-trivial\nin CTMAB, since the optimal sampling frequency depends on the mean of the arm,\nwhich needs to be estimated. We first establish lower bounds on the regret\nachievable with any algorithm and then propose algorithms that achieve the\nlower bound up to logarithmic factors. For the single-arm case, we show that\nthe lower bound on the regret is $\\Omega((\\log T)^2/\\mu)$, where $\\mu$ is the\nmean of the arm, and $T$ is the time horizon. For the multiple arms case, we\nshow that the lower bound on the regret is $\\Omega((\\log T)^2 \\mu/\\Delta^2)$,\nwhere $\\mu$ now represents the mean of the best arm, and $\\Delta$ is the\ndifference of the mean of the best and the second-best arm. We then propose an\nalgorithm that achieves the bound up to constant terms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:00:35 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Vaze", "Rahul", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2107.05295", "submitter": "Lasse Hansen", "authors": "Kenneth Enevoldsen, Lasse Hansen, Kristoffer Nielbo", "title": "DaCy: A Unified Framework for Danish NLP", "comments": "8 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Danish natural language processing (NLP) has in recent years obtained\nconsiderable improvements with the addition of multiple new datasets and\nmodels. However, at present, there is no coherent framework for applying\nstate-of-the-art models for Danish. We present DaCy: a unified framework for\nDanish NLP built on SpaCy. DaCy uses efficient multitask models which obtain\nstate-of-the-art performance on named entity recognition, part-of-speech\ntagging, and dependency parsing. DaCy contains tools for easy integration of\nexisting models such as for polarity, emotion, or subjectivity detection. In\naddition, we conduct a series of tests for biases and robustness of Danish NLP\npipelines through augmentation of the test set of DaNE. DaCy large compares\nfavorably and is especially robust to long input lengths and spelling\nvariations and errors. All models except DaCy large display significant biases\nrelated to ethnicity while only Polyglot shows a significant gender bias. We\nargue that for languages with limited benchmark sets, data augmentation can be\nparticularly useful for obtaining more realistic and fine-grained performance\nestimates. We provide a series of augmenters as a first step towards a more\nthorough evaluation of language models for low and medium resource languages\nand encourage further development.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:14:31 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Enevoldsen", "Kenneth", ""], ["Hansen", "Lasse", ""], ["Nielbo", "Kristoffer", ""]]}, {"id": "2107.05298", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, St\\'ephane Lathuili\\`ere, Attilio Fiandrotti, Marco\n  Cagnazzo, Marco Grangetto", "title": "HEMP: High-order Entropy Minimization for neural network comPression", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2021.07.022", "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We formulate the entropy of a quantized artificial neural network as a\ndifferentiable function that can be plugged as a regularization term into the\ncost function minimized by gradient descent. Our formulation scales efficiently\nbeyond the first order and is agnostic of the quantization scheme. The network\ncan then be trained to minimize the entropy of the quantized parameters, so\nthat they can be optimally compressed via entropy coding. We experiment with\nour entropy formulation at quantizing and compressing well-known network\narchitectures over multiple datasets. Our approach compares favorably over\nsimilar methods, enjoying the benefits of higher order entropy estimate,\nshowing flexibility towards non-uniform quantization (we use Lloyd-max\nquantization), scalability towards any entropy order to be minimized and\nefficiency in terms of compression. We show that HEMP is able to work in\nsynergy with other approaches aiming at pruning or quantizing the model itself,\ndelivering significant benefits in terms of storage size compressibility\nwithout harming the model's performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 10:17:53 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Lathuili\u00e8re", "St\u00e9phane", ""], ["Fiandrotti", "Attilio", ""], ["Cagnazzo", "Marco", ""], ["Grangetto", "Marco", ""]]}, {"id": "2107.05320", "submitter": "Amit Peleg", "authors": "Amit Peleg, Naama Pearl and Ron Meir", "title": "Metalearning Linear Bandits by Prior Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Bayesian approaches to sequential decision-making assume that problem\nparameters are generated from a known prior, while in practice, such\ninformation is often lacking, and needs to be estimated through learning. This\nproblem is exacerbated in decision-making setups with partial information,\nwhere using a misspecified prior may lead to poor exploration and inferior\nperformance. In this work we prove, in the context of stochastic linear bandits\nand Gaussian priors, that as long as the prior estimate is sufficiently close\nto the true prior, the performance of an algorithm that uses the misspecified\nprior is close to that of the algorithm that uses the true prior. Next, we\naddress the task of learning the prior through metalearning, where a learner\nupdates its estimate of the prior across multiple task instances in order to\nimprove performance on future tasks. The estimated prior is then updated within\neach task based on incoming observations, while actions are selected in order\nto maximize expected reward. In this work we apply this scheme within a linear\nbandit setting, and provide algorithms and regret bounds, demonstrating its\neffectiveness, as compared to an algorithm that knows the correct prior. Our\nresults hold for a broad class of algorithms, including, for example, Thompson\nSampling and Information Directed Sampling.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:17:01 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Peleg", "Amit", ""], ["Pearl", "Naama", ""], ["Meir", "Ron", ""]]}, {"id": "2107.05326", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii, Naoya Takeishi, Kazushi Tsutsui, Emyo Fujioka, Nozomi\n  Nishiumi, Ryoya Tanaka, Mika Fukushiro, Kaoru Ide, Hiroyoshi Kohno, Ken Yoda,\n  Susumu Takahashi, Shizuko Hiryu, Yoshinobu Kawahara", "title": "Learning interaction rules from multi-animal trajectories via augmented\n  behavioral models", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Extracting the interaction rules of biological agents from moving sequences\npose challenges in various domains. Granger causality is a practical framework\nfor analyzing the interactions from observed time-series data; however, this\nframework ignores the structures of the generative process in animal behaviors,\nwhich may lead to interpretational problems and sometimes erroneous assessments\nof causality. In this paper, we propose a new framework for learning Granger\ncausality from multi-animal trajectories via augmented theory-based behavioral\nmodels with interpretable data-driven models. We adopt an approach for\naugmenting incomplete multi-agent behavioral models described by time-varying\ndynamical systems with neural networks. For efficient and interpretable\nlearning, our model leverages theory-based architectures separating navigation\nand motion processes, and the theory-guided regularization for reliable\nbehavioral modeling. This can provide interpretable signs of Granger-causal\neffects over time, i.e., when specific others cause the approach or separation.\nIn experiments using synthetic datasets, our method achieved better performance\nthan various baselines. We then analyzed multi-animal datasets of mice, flies,\nbirds, and bats, which verified our method and obtained novel biological\ninsights.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:33:56 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 00:49:33 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Fujii", "Keisuke", ""], ["Takeishi", "Naoya", ""], ["Tsutsui", "Kazushi", ""], ["Fujioka", "Emyo", ""], ["Nishiumi", "Nozomi", ""], ["Tanaka", "Ryoya", ""], ["Fukushiro", "Mika", ""], ["Ide", "Kaoru", ""], ["Kohno", "Hiroyoshi", ""], ["Yoda", "Ken", ""], ["Takahashi", "Susumu", ""], ["Hiryu", "Shizuko", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "2107.05328", "submitter": "Xiaofeng Liu", "authors": "YinchuanLi, XiaofengLiu, YunfengShao, QingWang and YanhuiGeng", "title": "Structured Directional Pruning via Perturbation Orthogonal Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured pruning is an effective compression technique to reduce the\ncomputation of neural networks, which is usually achieved by adding\nperturbations to reduce network parameters at the cost of slightly increasing\ntraining loss. A more reasonable approach is to find a sparse minimizer along\nthe flat minimum valley found by optimizers, i.e. stochastic gradient descent,\nwhich keeps the training loss constant. To achieve this goal, we propose the\nstructured directional pruning based on orthogonal projecting the perturbations\nonto the flat minimum valley. We also propose a fast solver sDprun and further\nprove that it achieves directional pruning asymptotically after sufficient\ntraining. Experiments using VGG-Net and ResNet on CIFAR-10 and CIFAR-100\ndatasets show that our method obtains the state-of-the-art pruned accuracy\n(i.e. 93.97% on VGG16, CIFAR-10 task) without retraining. Experiments using\nDNN, VGG-Net and WRN28X10 on MNIST, CIFAR-10 and CIFAR-100 datasets demonstrate\nour method performs structured directional pruning, reaching the same minimum\nvalley as the optimizer.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:35:47 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["YinchuanLi", "", ""], ["XiaofengLiu", "", ""], ["YunfengShao", "", ""], ["QingWang", "", ""], ["YanhuiGeng", "", ""]]}, {"id": "2107.05330", "submitter": "Xiaofeng Liu", "authors": "YinchuanLi, XiaofengLiu, XuZhang, YunfengShao, QingWang and YanhuiGeng", "title": "Personalized Federated Learning via Maximizing Correlation with Sparse\n  and Hierarchical Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a collaborative machine learning technique to\ntrain a global model without obtaining clients' private data. The main\nchallenges in FL are statistical diversity among clients, limited computing\ncapability among client equipments and the excessive communication overhead and\nlong latency between server and clients. To address these problems,\n  we propose a novel personalized federated learning via maximizing correlation\npFedMac), and further extend it to sparse and hierarchical models. By\nminimizing loss functions including the properties of an approximated L1-norm\nand the hierarchical correlation, the performance on statistical diversity data\nis improved and the communicational and computational loads required in the\nnetwork are reduced. Theoretical proofs show that pFedMac performs better than\nthe L2-norm distance based personalization methods. Experimentally, we\ndemonstrate the benefits of this sparse hierarchical personalization\narchitecture compared with the state-of-the-art personalization methods and\ntheir extensions (e.g. pFedMac achieves 99.75% accuracy on MNIST and 87.27%\naccuracy on Synthetic under heterogeneous and non-i.i.d data distributions)\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:43:40 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["YinchuanLi", "", ""], ["XiaofengLiu", "", ""], ["XuZhang", "", ""], ["YunfengShao", "", ""], ["QingWang", "", ""], ["YanhuiGeng", "", ""]]}, {"id": "2107.05341", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Csaba Szepesv\\'ari", "title": "Nonparametric Regression with Shallow Overparameterized Neural Networks\n  Trained by GD with Early Stopping", "comments": "COLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the ability of overparameterized shallow neural networks to learn\nLipschitz regression functions with and without label noise when trained by\nGradient Descent (GD). To avoid the problem that in the presence of noisy\nlabels, neural networks trained to nearly zero training error are inconsistent\non this class, we propose an early stopping rule that allows us to show optimal\nrates. This provides an alternative to the result of Hu et al. (2021) who\nstudied the performance of $\\ell 2$ -regularized GD for training shallow\nnetworks in nonparametric regression which fully relied on the infinite-width\nnetwork (Neural Tangent Kernel (NTK)) approximation. Here we present a simpler\nanalysis which is based on a partitioning argument of the input space (as in\nthe case of 1-nearest-neighbor rule) coupled with the fact that trained neural\nnetworks are smooth with respect to their inputs when trained by GD. In the\nnoise-free case the proof does not rely on any kernelization and can be\nregarded as a finite-width result. In the case of label noise, by slightly\nmodifying the proof, the noise is controlled using a technique of Yao, Rosasco,\nand Caponnetto (2007).\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:56:53 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2107.05342", "submitter": "Numan Celik", "authors": "Numan Celik, Sharib Ali, Soumya Gupta, Barbara Braden and Jens\n  Rittscher", "title": "EndoUDA: A modality independent segmentation approach for endoscopy\n  imaging", "comments": "10 pages, 3 figures, 3 tables. Accepted for MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gastrointestinal (GI) cancer precursors require frequent monitoring for risk\nstratification of patients. Automated segmentation methods can help to assess\nrisk areas more accurately, and assist in therapeutic procedures or even\nremoval. In clinical practice, addition to the conventional white-light imaging\n(WLI), complimentary modalities such as narrow-band imaging (NBI) and\nfluorescence imaging are used. While, today most segmentation approaches are\nsupervised and only concentrated on a single modality dataset, this work\nexploits to use a target-independent unsupervised domain adaptation (UDA)\ntechnique that is capable to generalize to an unseen target modality. In this\ncontext, we propose a novel UDA-based segmentation method that couples the\nvariational autoencoder and U-Net with a common EfficientNet-B4 backbone, and\nuses a joint loss for latent-space optimization for target samples. We show\nthat our model can generalize to unseen target NBI (target) modality when\ntrained using only WLI (source) modality. Our experiments on both upper and\nlower GI endoscopy data show the effectiveness of our approach compared to\nnaive supervised approach and state-of-the-art UDA segmentation methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:57:33 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Celik", "Numan", ""], ["Ali", "Sharib", ""], ["Gupta", "Soumya", ""], ["Braden", "Barbara", ""], ["Rittscher", "Jens", ""]]}, {"id": "2107.05377", "submitter": "Tianwen Wei", "authors": "Tianwen Wei, Jianwei Qi, Shenghuan He", "title": "A Flexible Multi-Task Model for BERT Serving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this demonstration, we present an efficient BERT-based multi-task (MT)\nframework that is particularly suitable for iterative and incremental\ndevelopment of the tasks. The proposed framework is based on the idea of\npartial fine-tuning, i.e. only fine-tune some top layers of BERT while keep the\nother layers frozen. For each task, we train independently a single-task (ST)\nmodel using partial fine-tuning. Then we compress the task-specific layers in\neach ST model using knowledge distillation. Those compressed ST models are\nfinally merged into one MT model so that the frozen layers of the former are\nshared across the tasks. We exemplify our approach on eight GLUE tasks,\ndemonstrating that it is able to achieve both strong performance and\nefficiency. We have implemented our method in the utterance understanding\nsystem of XiaoAI, a commercial AI assistant developed by Xiaomi. We estimate\nthat our model reduces the overall serving cost by 86%.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:42:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wei", "Tianwen", ""], ["Qi", "Jianwei", ""], ["He", "Shenghuan", ""]]}, {"id": "2107.05380", "submitter": "Anish Acharya", "authors": "Anish Acharya, Rudrajit Das", "title": "DISCO : efficient unsupervised decoding for discrete natural language\n  problems via convex relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we study test time decoding; an ubiquitous step in almost all\nsequential text generation task spanning across a wide array of natural\nlanguage processing (NLP) problems. Our main contribution is to develop a\ncontinuous relaxation framework for the combinatorial NP-hard decoding problem\nand propose Disco - an efficient algorithm based on standard first order\ngradient based. We provide tight analysis and show that our proposed algorithm\nlinearly converges to within $\\epsilon$ neighborhood of the optima. Finally, we\nperform preliminary experiments on the task of adversarial text generation and\nshow superior performance of Disco over several popular decoding approaches.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:40:25 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 20:34:37 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Acharya", "Anish", ""], ["Das", "Rudrajit", ""]]}, {"id": "2107.05382", "submitter": "Tomohiro Tanaka", "authors": "Tomohiro Tanaka, Ryo Masumura, Mana Ihori, Akihiko Takashima, Shota\n  Orihashi, Naoki Makishima", "title": "End-to-End Rich Transcription-Style Automatic Speech Recognition with\n  Semi-Supervised Learning", "comments": "Accepted at Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semi-supervised learning method for building end-to-end rich\ntranscription-style automatic speech recognition (RT-ASR) systems from\nsmall-scale rich transcription-style and large-scale common transcription-style\ndatasets. In spontaneous speech tasks, various speech phenomena such as\nfillers, word fragments, laughter and coughs, etc. are often included. While\ncommon transcriptions do not give special awareness to these phenomena, rich\ntranscriptions explicitly convert them into special phenomenon tokens as well\nas textual tokens. In previous studies, the textual and phenomenon tokens were\nsimultaneously estimated in an end-to-end manner. However, it is difficult to\nbuild accurate RT-ASR systems because large-scale rich transcription-style\ndatasets are often unavailable. To solve this problem, our training method uses\na limited rich transcription-style dataset and common transcription-style\ndataset simultaneously. The Key process in our semi-supervised learning is to\nconvert the common transcription-style dataset into a pseudo-rich\ntranscription-style dataset. To this end, we introduce style tokens which\ncontrol phenomenon tokens are generated or not into transformer-based\nautoregressive modeling. We use this modeling for generating the pseudo-rich\ntranscription-style datasets and for building RT-ASR system from the pseudo and\noriginal datasets. Our experiments on spontaneous ASR tasks showed the\neffectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:52:49 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Tanaka", "Tomohiro", ""], ["Masumura", "Ryo", ""], ["Ihori", "Mana", ""], ["Takashima", "Akihiko", ""], ["Orihashi", "Shota", ""], ["Makishima", "Naoki", ""]]}, {"id": "2107.05384", "submitter": "Fangyi Zhang", "authors": "Ya Wang, Hesen Chen, Fangyi Zhang, Yaohua Wang, Xiuyu Sun, Ming Lin,\n  Hao Li", "title": "Fine-Grained AutoAugmentation for Multi-Label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a commonly used approach to improving the generalization\nof deep learning models. Recent works show that learned data augmentation\npolicies can achieve better generalization than hand-crafted ones. However,\nmost of these works use unified augmentation policies for all samples in a\ndataset, which is observed not necessarily beneficial for all labels in\nmulti-label classification tasks, i.e., some policies may have negative impacts\non some labels while benefitting the others. To tackle this problem, we propose\na novel Label-Based AutoAugmentation (LB-Aug) method for multi-label scenarios,\nwhere augmentation policies are generated with respect to labels by an\naugmentation-policy network. The policies are learned via reinforcement\nlearning using policy gradient methods, providing a mapping from instance\nlabels to their optimal augmentation policies. Numerical experiments show that\nour LB-Aug outperforms previous state-of-the-art augmentation methods by large\nmargins in multiple benchmarks on image and video classification.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 12:47:16 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 07:38:08 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Wang", "Ya", ""], ["Chen", "Hesen", ""], ["Zhang", "Fangyi", ""], ["Wang", "Yaohua", ""], ["Sun", "Xiuyu", ""], ["Lin", "Ming", ""], ["Li", "Hao", ""]]}, {"id": "2107.05385", "submitter": "Monika Daryani", "authors": "Monika Daryani and James Caverlee", "title": "Identifying Hijacked Reviews", "comments": "To be published in ACL-IJCNLP 2021 Workshop on e-Commerce and NLP\n  (ECNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake reviews and review manipulation are growing problems on online\nmarketplaces globally. Review Hijacking is a new review manipulation tactic in\nwhich unethical sellers \"hijack\" an existing product page (usually one with\nmany positive reviews), then update the product details like title, photo, and\ndescription with those of an entirely different product. With the earlier\nreviews still attached, the new item appears well-reviewed. However, there are\nno public datasets of review hijacking and little is known in the literature\nabout this tactic. Hence, this paper proposes a three-part study: (i) we\npropose a framework to generate synthetically labeled data for review hijacking\nby swapping products and reviews; (ii) then, we evaluate the potential of both\na Twin LSTM network and BERT sequence pair classifier to distinguish legitimate\nreviews from hijacked ones using this data; and (iii) we then deploy the best\nperforming model on a collection of 31K products (with 6.5 M reviews) in the\noriginal data, where we find 100s of previously unknown examples of review\nhijacking.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 20:43:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Daryani", "Monika", ""], ["Caverlee", "James", ""]]}, {"id": "2107.05392", "submitter": "Olha Kaminska", "authors": "Olha Kaminska, Chris Cornelis, Veronique Hoste", "title": "Fuzzy-Rough Nearest Neighbour Approaches for Emotion Detection in Tweets", "comments": "The paper submitted to the IJCRS 2021 conference, organized jointly\n  with IFSA-EUSFLAT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media are an essential source of meaningful data that can be used in\ndifferent tasks such as sentiment analysis and emotion recognition. Mostly,\nthese tasks are solved with deep learning methods. Due to the fuzzy nature of\ntextual data, we consider using classification methods based on fuzzy rough\nsets. Specifically, we develop an approach for the SemEval-2018 emotion\ndetection task, based on the fuzzy rough nearest neighbour (FRNN) classifier\nenhanced with ordered weighted average (OWA) operators. We use tuned ensembles\nof FRNN--OWA models based on different text embedding methods. Our results are\ncompetitive with the best SemEval solutions based on more complicated deep\nlearning methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:52:47 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kaminska", "Olha", ""], ["Cornelis", "Chris", ""], ["Hoste", "Veronique", ""]]}, {"id": "2107.05393", "submitter": "Si-An Chen", "authors": "Jie-Jyun Liu, Tsung-Han Yang, Si-An Chen, Chih-Jen Lin", "title": "Parameter Selection: Why We Should Pay More Attention to It", "comments": "Accepted by ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The importance of parameter selection in supervised learning is well known.\nHowever, due to the many parameter combinations, an incomplete or an\ninsufficient procedure is often applied. This situation may cause misleading or\nconfusing conclusions. In this opinion paper, through an intriguing example we\npoint out that the seriousness goes beyond what is generally recognized. In the\ntopic of multi-label classification for medical code prediction, one\ninfluential paper conducted a proper parameter selection on a set, but when\nmoving to a subset of frequently occurring labels, the authors used the same\nparameters without a separate tuning. The set of frequent labels became a\npopular benchmark in subsequent studies, which kept pushing the state of the\nart. However, we discovered that most of the results in these studies cannot\nsurpass the approach in the original paper if a parameter tuning had been\nconducted at the time. Thus it is unclear how much progress the subsequent\ndevelopments have actually brought. The lesson clearly indicates that without\nenough attention on parameter selection, the research progress in our field can\nbe uncertain or even illusive.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:55:34 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liu", "Jie-Jyun", ""], ["Yang", "Tsung-Han", ""], ["Chen", "Si-An", ""], ["Lin", "Chih-Jen", ""]]}, {"id": "2107.05394", "submitter": "Olha Kaminska", "authors": "Olha Kaminska, Chris Cornelis, Veronique Hoste", "title": "Nearest neighbour approaches for Emotion Detection in Tweets", "comments": "The paper was presented at EACL 2021 during the WASSA workshop as a\n  poster and published at ACL Anthology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion detection is an important task that can be applied to social media\ndata to discover new knowledge. While the use of deep learning methods for this\ntask has been prevalent, they are black-box models, making their decisions hard\nto interpret for a human operator. Therefore, in this paper, we propose an\napproach using weighted $k$ Nearest Neighbours (kNN), a simple, easy to\nimplement, and explainable machine learning model. These qualities can help to\nenhance results' reliability and guide error analysis. In particular, we apply\nthe weighted kNN model to the shared emotion detection task in tweets from\nSemEval-2018. Tweets are represented using different text embedding methods and\nemotion lexicon vocabulary scores, and classification is done by an ensemble of\nweighted kNN models. Our best approaches obtain results competitive with\nstate-of-the-art solutions and open up a promising alternative path to neural\nnetwork methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:00:06 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kaminska", "Olha", ""], ["Cornelis", "Chris", ""], ["Hoste", "Veronique", ""]]}, {"id": "2107.05405", "submitter": "Ray Jiang", "authors": "Ray Jiang, Shangtong Zhang, Veronica Chelu, Adam White, Hado van\n  Hasselt", "title": "Learning Expected Emphatic Traces for Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy sampling and experience replay are key for improving sample\nefficiency and scaling model-free temporal difference learning methods. When\ncombined with function approximation, such as neural networks, this combination\nis known as the deadly triad and is potentially unstable. Recently, it has been\nshown that stability and good performance at scale can be achieved by combining\nemphatic weightings and multi-step updates. This approach, however, is\ngenerally limited to sampling complete trajectories in order, to compute the\nrequired emphatic weighting. In this paper we investigate how to combine\nemphatic weightings with non-sequential, off-line data sampled from a replay\nbuffer. We develop a multi-step emphatic weighting that can be combined with\nreplay, and a time-reversed $n$-step TD learning algorithm to learn the\nrequired emphatic weighting. We show that these state weightings reduce\nvariance compared with prior approaches, while providing convergence\nguarantees. We tested the approach at scale on Atari 2600 video games, and\nobserved that the new X-ETD($n$) agent improved over baseline agents,\nhighlighting both the scalability and broad applicability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:14:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jiang", "Ray", ""], ["Zhang", "Shangtong", ""], ["Chelu", "Veronica", ""], ["White", "Adam", ""], ["van Hasselt", "Hado", ""]]}, {"id": "2107.05407", "submitter": "Andrea Banino", "authors": "Andrea Banino, Jan Balaguer, Charles Blundell", "title": "PonderNet: Learning to Ponder", "comments": "16 pages, 2 figures, 2 tables, 8th ICML Workshop on Automated Machine\n  Learning (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard neural networks the amount of computation used grows with the\nsize of the inputs, but not with the complexity of the problem being learnt. To\novercome this limitation we introduce PonderNet, a new algorithm that learns to\nadapt the amount of computation based on the complexity of the problem at hand.\nPonderNet learns end-to-end the number of computational steps to achieve an\neffective compromise between training prediction accuracy, computational cost\nand generalization. On a complex synthetic problem, PonderNet dramatically\nimproves performance over previous adaptive computation methods and\nadditionally succeeds at extrapolation tests where traditional neural networks\nfail. Also, our method matched the current state of the art results on a real\nworld question and answering dataset, but using less compute. Finally,\nPonderNet reached state of the art results on a complex task designed to test\nthe reasoning capabilities of neural networks.1\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:24:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Banino", "Andrea", ""], ["Balaguer", "Jan", ""], ["Blundell", "Charles", ""]]}, {"id": "2107.05426", "submitter": "Mark Stamp", "authors": "Xinxin Yang and Mark Stamp", "title": "Computer-Aided Diagnosis of Low Grade Endometrial Stromal Sarcoma\n  (LGESS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Low grade endometrial stromal sarcoma (LGESS) is rare form of cancer,\naccounting for about 0.2% of all uterine cancer cases. Approximately 75% of\nLGESS patients are initially misdiagnosed with leiomyoma, which is a type of\nbenign tumor, also known as fibroids. In this research, uterine tissue biopsy\nimages of potential LGESS patients are preprocessed using segmentation and\nstaining normalization algorithms. A variety of classic machine learning and\nleading deep learning models are then applied to classify tissue images as\neither benign or cancerous. For the classic techniques considered, the highest\nclassification accuracy we attain is about 0.85, while our best deep learning\nmodel achieves an accuracy of approximately 0.87. These results indicate that\nproperly trained learning algorithms can play a useful role in the diagnosis of\nLGESS.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 00:41:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Yang", "Xinxin", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.05431", "submitter": "Andrea Banino", "authors": "Andrea Banino, Adri\\`a Puidomenech Badia, Jacob Walker, Tim Scholtes,\n  Jovana Mitrovic, Charles Blundell", "title": "CoBERL: Contrastive BERT for Reinforcement Learning", "comments": "9 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning (RL) agents require a large amount of experience\nto solve tasks. We propose Contrastive BERT for RL (CoBERL), an agent that\ncombines a new contrastive loss and a hybrid LSTM-transformer architecture to\ntackle the challenge of improving data efficiency. CoBERL enables efficient,\nrobust learning from pixels across a wide range of domains. We use\nbidirectional masked prediction in combination with a generalization of recent\ncontrastive methods to learn better representations for transformers in RL,\nwithout the need of hand engineered data augmentations. We find that CoBERL\nconsistently improves performance across the full Atari suite, a set of control\ntasks and a challenging 3D environment.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:54:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Banino", "Andrea", ""], ["Badia", "Adri\u00e0 Puidomenech", ""], ["Walker", "Jacob", ""], ["Scholtes", "Tim", ""], ["Mitrovic", "Jovana", ""], ["Blundell", "Charles", ""]]}, {"id": "2107.05445", "submitter": "Yipeng Zhang", "authors": "Yipeng Zhang, Tyler L. Hayes, Christopher Kanan", "title": "Disentangling Transfer and Interference in Multi-Domain Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are incredibly good at transferring knowledge from one domain to\nanother, enabling rapid learning of new tasks. Likewise, transfer learning has\nenabled enormous success in many computer vision problems using pretraining.\nHowever, the benefits of transfer in multi-domain learning, where a network\nlearns multiple tasks defined by different datasets, has not been adequately\nstudied. Learning multiple domains could be beneficial or these domains could\ninterfere with each other given limited network capacity. In this work, we\ndecipher the conditions where interference and knowledge transfer occur in\nmulti-domain learning. We propose new metrics disentangling interference and\ntransfer and set up experimental protocols. We further examine the roles of\nnetwork capacity, task grouping, and dynamic loss weighting in reducing\ninterference and facilitating transfer. We demonstrate our findings on the\nCIFAR-100, MiniPlaces, and Tiny-ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 01:30:36 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 01:14:21 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Zhang", "Yipeng", ""], ["Hayes", "Tyler L.", ""], ["Kanan", "Christopher", ""]]}, {"id": "2107.05446", "submitter": "Cian Eastwood", "authors": "Cian Eastwood, Ian Mason, Christopher K. I. Williams, Bernhard\n  Sch\\\"olkopf", "title": "Source-Free Adaptation to Measurement Shift via Bottom-Up Feature\n  Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source-free domain adaptation (SFDA) aims to adapt a model trained on\nlabelled data in a source domain to unlabelled data in a target domain without\naccess to the source-domain data during adaptation. Existing methods for SFDA\nleverage entropy-minimization techniques which: (i) apply only to\nclassification; (ii) destroy model calibration; and (iii) rely on the source\nmodel achieving a good level of feature-space class-separation in the target\ndomain. We address these issues for a particularly pervasive type of domain\nshift called measurement shift, characterized by a change in measurement system\n(e.g. a change in sensor or lighting). In the source domain, we store a\nlightweight and flexible approximation of the feature distribution under the\nsource data. In the target domain, we adapt the feature-extractor such that the\napproximate feature distribution under the target data realigns with that saved\non the source. We call this method Feature Restoration (FR) as it seeks to\nextract features with the same semantics from the target domain as were\npreviously extracted from the source. We additionally propose Bottom-Up Feature\nRestoration (BUFR), a bottom-up training scheme for FR which boosts performance\nby preserving learnt structure in the later layers of a network. Through\nexperiments we demonstrate that BUFR often outperforms existing SFDA methods in\nterms of accuracy, calibration, and data efficiency, while being less reliant\non the performance of the source model in the target domain.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:21:14 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Eastwood", "Cian", ""], ["Mason", "Ian", ""], ["Williams", "Christopher K. I.", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2107.05457", "submitter": "Mehdi Amian", "authors": "Mehdi Amian", "title": "Improving the Algorithm of Deep Learning with Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an adjustment to the original differentially private\nstochastic gradient descent (DPSGD) algorithm for deep learning models is\nproposed. As a matter of motivation, to date, almost no state-of-the-art\nmachine learning algorithm hires the existing privacy protecting components due\nto otherwise serious compromise in their utility despite the vital necessity.\nThe idea in this study is natural and interpretable, contributing to improve\nthe utility with respect to the state-of-the-art. Another property of the\nproposed technique is its simplicity which makes it again more natural and also\nmore appropriate for real world and specially commercial applications. The\nintuition is to trim and balance out wild individual discrepancies for privacy\nreasons, and at the same time, to preserve relative individual differences for\nseeking performance. The idea proposed here can also be applied to the\nrecurrent neural networks (RNN) to solve the gradient exploding problem. The\nalgorithm is applied to benchmark datasets MNIST and CIFAR-10 for a\nclassification task and the utility measure is calculated. The results\noutperformed the original work.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:28:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Amian", "Mehdi", ""]]}, {"id": "2107.05458", "submitter": "Soma Bandyopadhyay", "authors": "Soma Bandyopadhyay, Anish Datta, Arpan Pal", "title": "Automated Label Generation for Time Series Classification with\n  Representation Learning: Reduction of Label Cost for Training", "comments": "8 pages, 5 figures, 3 tables accepted in IJCAI2021 Weakly Supervised\n  Representation Learning (WSRL) Workshop ;\n  https://wsl-workshop.github.io/ijcai21.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series generated by end-users, edge devices, and different wearables are\nmostly unlabelled. We propose a method to auto-generate labels of un-labelled\ntime-series, exploiting very few representative labelled time-series. Our\nmethod is based on representation learning using Auto Encoded Compact Sequence\n(AECS) with a choice of best distance measure. It performs self-correction in\niterations, by learning latent structure, as well as synthetically boosting\nrepresentative time-series using Variational-Auto-Encoder (VAE) to improve the\nquality of labels. We have experimented with UCR and UCI archives, public\nreal-world univariate, multivariate time-series taken from different\napplication domains. Experimental results demonstrate that the proposed method\nis very close to the performance achieved by fully supervised classification.\nThe proposed method not only produces close to benchmark results but\noutperforms the benchmark performance in some cases.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:28:40 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bandyopadhyay", "Soma", ""], ["Datta", "Anish", ""], ["Pal", "Arpan", ""]]}, {"id": "2107.05466", "submitter": "Muddassar Hussain", "authors": "Muddassar Hussain, Nicolo Michelusi", "title": "Learning and Adaptation in Millimeter-Wave: a Dual Timescale Variational\n  Framework", "comments": "Submitted for publication in IEEE Journal on Selected Areas in\n  Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter-wave vehicular networks incur enormous beam-training overhead to\nenable narrow-beam communications. This paper proposes a learning and\nadaptation framework in which the dynamics of the communication beams are\nlearned and then exploited to design adaptive beam-training with low overhead:\non a long-timescale, a deep recurrent variational autoencoder (DR-VAE) uses\nnoisy beam-training observations to learn a probabilistic model of beam\ndynamics; on a short-timescale, an adaptive beam-training procedure is\nformulated as a partially observable (PO-) Markov decision process (MDP) and\noptimized via point-based value iteration (PBVI) by leveraging beam-training\nfeedback and a probabilistic prediction of the strongest beam pair provided by\nthe DR-VAE. In turn, beam-training observations are used to refine the DR-VAE\nvia stochastic gradient ascent in a continuous process of learning and\nadaptation. The proposed DR-VAE mobility learning framework learns accurate\nbeam dynamics: it reduces the Kullback-Leibler divergence between the ground\ntruth and the learned beam dynamics model by 86% over the Baum-Welch algorithm\nand by 92\\% over a naive mobility learning approach that neglects feedback\nerrors. The proposed dual-timescale approach yields a negligible loss of\nspectral efficiency compared to a genie-aided scheme operating under error-free\nfeedback and foreknown mobility model. Finally, a low-complexity policy is\nproposed by reducing the POMDP to an error-robust MDP. It is shown that the\nPBVI- and error-robust MDP-based policies improve the spectral efficiency by\n85% and 67%, respectively, over a policy that scans exhaustively over the\ndominant beam pairs, and by 16% and 7%, respectively, over a state-of-the-art\nPOMDP policy.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 19:04:18 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hussain", "Muddassar", ""], ["Michelusi", "Nicolo", ""]]}, {"id": "2107.05467", "submitter": "Cees Roele", "authors": "Cees Roele", "title": "WVOQ at SemEval-2021 Task 6: BART for Span Detection and Classification", "comments": "5 pages, 1 figure, accepted at SemEval-2021 co-located with\n  ACL-IJCNLP 2021", "journal-ref": "SemEval-2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel solution to span detection and classification is presented in which a\nBART EncoderDecoder model is used to transform textual input into a version\nwith XML-like marked up spans. This markup is subsequently translated to an\nidentification of the beginning and end of fragments and of their classes.\nDiscussed is how pre-training methodology both explains the relative success of\nthis method and its limitations. This paper reports on participation in task 6\nof SemEval-2021: Detection of Persuasion Techniques in Texts and Images.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 07:59:22 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Roele", "Cees", ""]]}, {"id": "2107.05476", "submitter": "Jie Wang", "authors": "Jianyu Cai, Jiajun Chen, Taoxing Pan, Zhanqiu Zhang, Jie Wang", "title": "Technical Report of Team GraphMIRAcles in the WikiKG90M-LSC Track of\n  OGB-LSC @ KDD Cup 2021", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Link prediction in large-scale knowledge graphs has gained increasing\nattention recently. The OGB-LSC team presented OGB Large-Scale Challenge\n(OGB-LSC), a collection of three real-world datasets for advancing the\nstate-of-the-art in large-scale graph machine learning. In this paper, we\nintroduce the solution of our team GraphMIRAcles in the WikiKG90M-LSC track of\nOGB-LSC @ KDD Cup 2021. In the WikiKG90M-LSC track, the goal is to\nautomatically predict missing links in WikiKG90M, a large scale knowledge graph\nextracted from Wikidata. To address this challenge, we propose a framework that\nintegrates three components -- a basic model ComplEx-CMRC, a rule miner AMIE 3,\nand an inference model to predict missing links. Experiments demonstrate that\nour solution achieves an MRR of 0.9707 on the test dataset. Moreover, as the\nknowledge distillation in the inference model uses test tail candidates --\nwhich are unavailable in practice -- we conduct ablation studies on knowledge\ndistillation. Experiments demonstrate that our model without knowledge\ndistillation achieves an MRR of 0.9533 on the full validation dataset.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:44:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cai", "Jianyu", ""], ["Chen", "Jiajun", ""], ["Pan", "Taoxing", ""], ["Zhang", "Zhanqiu", ""], ["Wang", "Jie", ""]]}, {"id": "2107.05479", "submitter": "Phillip Swazinna", "authors": "Phillip Swazinna, Steffen Udluft, Daniel Hein, Thomas Runkler", "title": "Behavior Constraining in Weight Space for Offline Reinforcement Learning", "comments": "Accepted at ESANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In offline reinforcement learning, a policy needs to be learned from a single\npre-collected dataset. Typically, policies are thus regularized during training\nto behave similarly to the data generating policy, by adding a penalty based on\na divergence between action distributions of generating and trained policy. We\npropose a new algorithm, which constrains the policy directly in its weight\nspace instead, and demonstrate its effectiveness in experiments.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:50:50 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Swazinna", "Phillip", ""], ["Udluft", "Steffen", ""], ["Hein", "Daniel", ""], ["Runkler", "Thomas", ""]]}, {"id": "2107.05481", "submitter": "Jorg Bornschein", "authors": "Jorg Bornschein and Silvia Chiappa and Alan Malek and Rosemary Nan Ke", "title": "Prequential MDL for Causal Structure Learning with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the structure of Bayesian networks and causal relationships from\nobservations is a common goal in several areas of science and technology. We\nshow that the prequential minimum description length principle (MDL) can be\nused to derive a practical scoring function for Bayesian networks when flexible\nand overparametrized neural networks are used to model the conditional\nprobability distributions between observed variables. MDL represents an\nembodiment of Occam's Razor and we obtain plausible and parsimonious graph\nstructures without relying on sparsity inducing priors or other regularizers\nwhich must be tuned. Empirically we demonstrate competitive results on\nsynthetic and real-world data. The score often recovers the correct structure\neven in the presence of strongly nonlinear relationships between variables; a\nscenario were prior approaches struggle and usually fail. Furthermore we\ndiscuss how the the prequential score relates to recent work that infers causal\nstructure from the speed of adaptation when the observations come from a source\nundergoing distributional shift.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 22:35:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bornschein", "Jorg", ""], ["Chiappa", "Silvia", ""], ["Malek", "Alan", ""], ["Ke", "Rosemary Nan", ""]]}, {"id": "2107.05489", "submitter": "Matti Huotari", "authors": "Matti Huotari, Shashank Arora, Avleen Malhi, Kary Fr\\\"amling", "title": "Comparing seven methods for state-of-health time series prediction for\n  the lithium-ion battery packs of forklifts", "comments": "16 pages, 10 figures and 10 tables", "journal-ref": "Applied Soft Computing July 2021", "doi": "10.1016/j.asoc.2021.107670", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A key aspect for the forklifts is the state-of-health (SoH) assessment to\nensure the safety and the reliability of uninterrupted power source.\nForecasting the battery SoH well is imperative to enable preventive maintenance\nand hence to reduce the costs. This paper demonstrates the capabilities of\ngradient boosting regression for predicting the SoH timeseries under\ncircumstances when there is little prior information available about the\nbatteries. We compared the gradient boosting method with light gradient\nboosting, extra trees, extreme gradient boosting, random forests, long\nshort-term memory networks and with combined convolutional neural network and\nlong short-term memory networks methods. We used multiple predictors and lagged\ntarget signal decomposition results as additional predictors and compared the\nyielded prediction results with different sets of predictors for each method.\nFor this work, we are in possession of a unique data set of 45 lithium-ion\nbattery packs with large variation in the data. The best model that we derived\nwas validated by a novel walk-forward algorithm that also calculates point-wise\nconfidence intervals for the predictions; we yielded reasonable predictions and\nconfidence intervals for the predictions. Furthermore, we verified this model\nagainst five other lithium-ion battery packs; the best model generalised to\ngreater extent to this set of battery packs. The results about the final model\nsuggest that we were able to enhance the results in respect to previously\ndeveloped models. Moreover, we further validated the model for extracting cycle\ncounts presented in our previous work with data from new forklifts; their\nbattery packs completed around 3000 cycles in a 10-year service period, which\ncorresponds to the cycle life for commercial Nickel-Cobalt-Manganese (NMC)\ncells.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:52:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huotari", "Matti", ""], ["Arora", "Shashank", ""], ["Malhi", "Avleen", ""], ["Fr\u00e4mling", "Kary", ""]]}, {"id": "2107.05530", "submitter": "Sudeep Pasricha", "authors": "Febin P. Sunny, Asif Mirza, Mahdi Nikdast, Sudeep Pasricha", "title": "ROBIN: A Robust Optical Binary Neural Network Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.ET", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Domain specific neural network accelerators have garnered attention because\nof their improved energy efficiency and inference performance compared to CPUs\nand GPUs. Such accelerators are thus well suited for resource-constrained\nembedded systems. However, mapping sophisticated neural network models on these\naccelerators still entails significant energy and memory consumption, along\nwith high inference time overhead. Binarized neural networks (BNNs), which\nutilize single-bit weights, represent an efficient way to implement and deploy\nneural network models on accelerators. In this paper, we present a novel\noptical-domain BNN accelerator, named ROBIN, which intelligently integrates\nheterogeneous microring resonator optical devices with complementary\ncapabilities to efficiently implement the key functionalities in BNNs. We\nperform detailed fabrication-process variation analyses at the optical device\nlevel, explore efficient corrective tuning for these devices, and integrate\ncircuit-level optimization to counter thermal variations. As a result, our\nproposed ROBIN architecture possesses the desirable traits of being robust,\nenergy-efficient, low latency, and high throughput, when executing BNN models.\nOur analysis shows that ROBIN can outperform the best-known optical BNN\naccelerators and also many electronic accelerators. Specifically, our\nenergy-efficient ROBIN design exhibits energy-per-bit values that are ~4x lower\nthan electronic BNN accelerators and ~933x lower than a recently proposed\nphotonic BNN accelerator, while a performance-efficient ROBIN design shows ~3x\nand ~25x better performance than electronic and photonic BNN accelerators,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:00:32 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sunny", "Febin P.", ""], ["Mirza", "Asif", ""], ["Nikdast", "Mahdi", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2107.05535", "submitter": "Nicklas Werge", "authors": "Nicklas Werge", "title": "Predicting Risk-adjusted Returns using an Asset Independent\n  Regime-switching Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE cs.LG q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets tend to switch between various market regimes over time,\nmaking stationarity-based models unsustainable. We construct a regime-switching\nmodel independent of asset classes for risk-adjusted return predictions based\non hidden Markov models. This framework can distinguish between market regimes\nin a wide range of financial markets such as the commodity, currency, stock,\nand fixed income market. The proposed method employs sticky features that\ndirectly affect the regime stickiness and thereby changing turnover levels. An\ninvestigation of our metric for risk-adjusted return predictions is conducted\nby analyzing daily financial market changes for almost twenty years. Empirical\ndemonstrations of out-of-sample observations obtain an accurate detection of\nbull, bear, and high volatility periods, improving risk-adjusted returns while\nkeeping a preferable turnover level.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 10:23:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Werge", "Nicklas", ""]]}, {"id": "2107.05541", "submitter": "Mohammad Sabik Irbaz", "authors": "Fahim Shahriar Khan, Mueeze Al Mushabbir, Mohammad Sabik Irbaz, MD\n  Abdullah Al Nasim", "title": "End-to-End Natural Language Understanding Pipeline for Bangla\n  Conversational Agents", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Chatbots are intelligent software built to be used as a replacement for human\ninteraction. However, existing studies typically do not provide enough support\nfor low-resource languages like Bangla. Moreover, due to the increasing\npopularity of social media, we can also see the rise of interactions in Bangla\ntransliteration (mostly in English) among the native Bangla speakers. In this\npaper, we propose a novel approach to build a Bangla chatbot aimed to be used\nas a business assistant which can communicate in Bangla and Bangla\nTransliteration in English with high confidence consistently. Since annotated\ndata was not available for this purpose, we had to work on the whole machine\nlearning life cycle (data preparation, machine learning modeling, and model\ndeployment) using Rasa Open Source Framework, fastText embeddings, Polyglot\nembeddings, Flask, and other systems as building blocks. While working with the\nskewed annotated dataset, we try out different setups and pipelines to evaluate\nwhich works best and provide possible reasoning behind the observed results.\nFinally, we present a pipeline for intent classification and entity extraction\nwhich achieves reasonable performance (accuracy: 83.02%, precision: 80.82%,\nrecall: 83.02%, F1-score: 80%).\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:09:22 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 01:52:58 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 19:23:43 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Khan", "Fahim Shahriar", ""], ["Mushabbir", "Mueeze Al", ""], ["Irbaz", "Mohammad Sabik", ""], ["Nasim", "MD Abdullah Al", ""]]}, {"id": "2107.05544", "submitter": "Apostolos Psaros", "authors": "Apostolos F Psaros, Kenji Kawaguchi, George Em Karniadakis", "title": "Meta-learning PINN loss functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a meta-learning technique for offline discovery of\nphysics-informed neural network (PINN) loss functions. We extend earlier works\non meta-learning, and develop a gradient-based meta-learning algorithm for\naddressing diverse task distributions based on parametrized partial\ndifferential equations (PDEs) that are solved with PINNs. Furthermore, based on\nnew theory we identify two desirable properties of meta-learned losses in PINN\nproblems, which we enforce by proposing a new regularization method or using a\nspecific parametrization of the loss function. In the computational examples,\nthe meta-learned losses are employed at test time for addressing regression and\nPDE task distributions. Our results indicate that significant performance\nimprovement can be achieved by using a shared-among-tasks offline-learned loss\nfunction even for out-of-distribution meta-testing. In this case, we solve for\ntest tasks that do not belong to the task distribution used in meta-training,\nand we also employ PINN architectures that are different from the PINN\narchitecture used in meta-training. To better understand the capabilities and\nlimitations of the proposed method, we consider various parametrizations of the\nloss function and describe different algorithm design options and how they may\naffect meta-learning performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:13:39 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Psaros", "Apostolos F", ""], ["Kawaguchi", "Kenji", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2107.05545", "submitter": "Kaixin Wang", "authors": "Kaixin Wang, Kuangqi Zhou, Qixin Zhang, Jie Shao, Bryan Hooi, Jiashi\n  Feng", "title": "Towards Better Laplacian Representation in Reinforcement Learning with\n  Generalized Graph Drawing", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Laplacian representation recently gains increasing attention for\nreinforcement learning as it provides succinct and informative representation\nfor states, by taking the eigenvectors of the Laplacian matrix of the\nstate-transition graph as state embeddings. Such representation captures the\ngeometry of the underlying state space and is beneficial to RL tasks such as\noption discovery and reward shaping. To approximate the Laplacian\nrepresentation in large (or even continuous) state spaces, recent works propose\nto minimize a spectral graph drawing objective, which however has infinitely\nmany global minimizers other than the eigenvectors. As a result, their learned\nLaplacian representation may differ from the ground truth. To solve this\nproblem, we reformulate the graph drawing objective into a generalized form and\nderive a new learning objective, which is proved to have eigenvectors as its\nunique global minimizer. It enables learning high-quality Laplacian\nrepresentations that faithfully approximate the ground truth. We validate this\nvia comprehensive experiments on a set of gridworld and continuous control\nenvironments. Moreover, we show that our learned Laplacian representations lead\nto more exploratory options and better reward shaping.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:14:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Kaixin", ""], ["Zhou", "Kuangqi", ""], ["Zhang", "Qixin", ""], ["Shao", "Jie", ""], ["Hooi", "Bryan", ""], ["Feng", "Jiashi", ""]]}, {"id": "2107.05546", "submitter": "Andrea Valenti", "authors": "Andrea Valenti, Stefano Berti, Davide Bacciu", "title": "Calliope -- A Polyphonic Music Transformer", "comments": "Accepted at ESANN2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The polyphonic nature of music makes the application of deep learning to\nmusic modelling a challenging task. On the other hand, the Transformer\narchitecture seems to be a good fit for this kind of data. In this work, we\npresent Calliope, a novel autoencoder model based on Transformers for the\nefficient modelling of multi-track sequences of polyphonic music. The\nexperiments show that our model is able to improve the state of the art on\nmusical sequence reconstruction and generation, with remarkably good results\nespecially on long sequences.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 08:18:57 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Valenti", "Andrea", ""], ["Berti", "Stefano", ""], ["Bacciu", "Davide", ""]]}, {"id": "2107.05556", "submitter": "Riza Ozcelik", "authors": "R{\\i}za \\\"Oz\\c{c}elik, Alperen Ba\\u{g}, Berk At{\\i}l, Arzucan\n  \\\"Ozg\\\"ur, Elif \\\"Ozk{\\i}r{\\i}ml{\\i}", "title": "DebiasedDTA: Model Debiasing to Boost Drug-Target Affinity Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Computational models that accurately identify high-affinity\nprotein-compound pairs can accelerate drug discovery pipelines. These models\naim to learn binding mechanics through drug-target interaction datasets and use\nthe learned knowledge for predicting the affinity of an input protein-compound\npair. However, the datasets they rely on bear misleading patterns that bias\nmodels towards memorizing dataset-specific biomolecule properties, instead of\nlearning binding mechanics. This results in models that struggle while\npredicting drug-target affinities (DTA), especially between de novo\nbiomolecules. Here we present DebiasedDTA, the first DTA model debiasing\napproach that avoids dataset biases in order to boost affinity prediction for\nnovel biomolecules. DebiasedDTA uses ensemble learning and sample weight\nadaptation for bias identification and avoidance and is applicable to almost\nall existing DTA prediction models. Results: The results show that DebiasedDTA\ncan boost models while predicting the interactions between novel biomolecules.\nKnown biomolecules also benefit from the performance improvement, especially\nwhen the test biomolecules are dissimilar to the training set. The experiments\nalso show that DebiasedDTA can augment DTA prediction models of different input\nand model structures and is able to avoid biases of different sources.\nAvailability and Implementation: The source code, the models, and the datasets\nare freely available for download at\nhttps://github.com/boun-tabi/debiaseddta-reproduce, implementation in Python3,\nand supported for Linux, MacOS and MS Windows. Contact:\narzucan.ozgur@boun.edu.tr, elif.ozkirimli@roche.com\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 19:21:37 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 21:17:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["\u00d6z\u00e7elik", "R\u0131za", ""], ["Ba\u011f", "Alperen", ""], ["At\u0131l", "Berk", ""], ["\u00d6zg\u00fcr", "Arzucan", ""], ["\u00d6zk\u0131r\u0131ml\u0131", "Elif", ""]]}, {"id": "2107.05561", "submitter": "Sudeep Pasricha", "authors": "Vipin K. Kukkala, Sooryaa V. Thiruloga, Sudeep Pasricha", "title": "LATTE: LSTM Self-Attention based Anomaly Detection in Embedded\n  Automotive Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Modern vehicles can be thought of as complex distributed embedded systems\nthat run a variety of automotive applications with real-time constraints.\nRecent advances in the automotive industry towards greater autonomy are driving\nvehicles to be increasingly connected with various external systems (e.g.,\nroadside beacons, other vehicles), which makes emerging vehicles highly\nvulnerable to cyber-attacks. Additionally, the increased complexity of\nautomotive applications and the in-vehicle networks results in poor attack\nvisibility, which makes detecting such attacks particularly challenging in\nautomotive systems. In this work, we present a novel anomaly detection\nframework called LATTE to detect cyber-attacks in Controller Area Network (CAN)\nbased networks within automotive platforms. Our proposed LATTE framework uses a\nstacked Long Short Term Memory (LSTM) predictor network with novel attention\nmechanisms to learn the normal operating behavior at design time. Subsequently,\na novel detection scheme (also trained at design time) is used to detect\nvarious cyber-attacks (as anomalies) at runtime. We evaluate our proposed LATTE\nframework under different automotive attack scenarios and present a detailed\ncomparison with the best-known prior works in this area, to demonstrate the\npotential of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 16:32:47 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kukkala", "Vipin K.", ""], ["Thiruloga", "Sooryaa V.", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2107.05573", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Sandeep Kumar, Ashish Kumar Pandey", "title": "Tropical cyclone intensity estimations over the Indian ocean using\n  Machine Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tropical cyclones are one of the most powerful and destructive natural\nphenomena on earth. Tropical storms and heavy rains can cause floods, which\nlead to human lives and economic loss. Devastating winds accompanying cyclones\nheavily affect not only the coastal regions, even distant areas. Our study\nfocuses on the intensity estimation, particularly cyclone grade and maximum\nsustained surface wind speed (MSWS) of a tropical cyclone over the North Indian\nOcean. We use various machine learning algorithms to estimate cyclone grade and\nMSWS. We have used the basin of origin, date, time, latitude, longitude,\nestimated central pressure, and pressure drop as attributes of our models. We\nuse multi-class classification models for the categorical outcome variable,\ncyclone grade, and regression models for MSWS as it is a continuous variable.\nUsing the best track data of 28 years over the North Indian Ocean, we estimate\ngrade with an accuracy of 88% and MSWS with a root mean square error (RMSE) of\n2.3. For higher grade categories (5-7), accuracy improves to an average of\n98.84%. We tested our model with two recent tropical cyclones in the North\nIndian Ocean, Vayu and Fani. For grade, we obtained an accuracy of 93.22% and\n95.23% respectively, while for MSWS, we obtained RMSE of 2.2 and 3.4 and $R^2$\nof 0.99 and 0.99, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:53:06 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Biswas", "Koushik", ""], ["Kumar", "Sandeep", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2107.05582", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Christos Tzamos", "title": "Forster Decomposition and Learning Halfspaces with Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Forster transform is an operation that turns a distribution into one with\ngood anti-concentration properties. While a Forster transform does not always\nexist, we show that any distribution can be efficiently decomposed as a\ndisjoint mixture of few distributions for which a Forster transform exists and\ncan be computed efficiently. As the main application of this result, we obtain\nthe first polynomial-time algorithm for distribution-independent PAC learning\nof halfspaces in the Massart noise model with strongly polynomial sample\ncomplexity, i.e., independent of the bit complexity of the examples. Previous\nalgorithms for this learning problem incurred sample complexity scaling\npolynomially with the bit complexity, even though such a dependence is not\ninformation-theoretically necessary.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:00:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Tzamos", "Christos", ""]]}, {"id": "2107.05585", "submitter": "Michael Menart", "authors": "Raef Bassily, Crist\\'obal Guzm\\'an, Michael Menart", "title": "Differentially Private Stochastic Optimization: New Results in Convex\n  and Non-Convex Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study differentially private stochastic optimization in convex and\nnon-convex settings. For the convex case, we focus on the family of non-smooth\ngeneralized linear losses (GLLs). Our algorithm for the $\\ell_2$ setting\nachieves optimal excess population risk in near-linear time, while the best\nknown differentially private algorithms for general convex losses run in\nsuper-linear time. Our algorithm for the $\\ell_1$ setting has nearly-optimal\nexcess population risk $\\tilde{O}\\big(\\sqrt{\\frac{\\log{d}}{n}}\\big)$, and\ncircumvents the dimension dependent lower bound of [AFKT21] for general\nnon-smooth convex losses. In the differentially private non-convex setting, we\nprovide several new algorithms for approximating stationary points of the\npopulation risk. For the $\\ell_1$-case with smooth losses and polyhedral\nconstraint, we provide the first nearly dimension independent rate, $\\tilde\nO\\big(\\frac{\\log^{2/3}{d}}{{n^{1/3}}}\\big)$ in linear time. For the constrained\n$\\ell_2$-case, with smooth losses, we obtain a linear-time algorithm with rate\n$\\tilde O\\big(\\frac{1}{n^{3/10}d^{1/10}}+\\big(\\frac{d}{n^2}\\big)^{1/5}\\big)$.\nFinally, for the $\\ell_2$-case we provide the first method for {\\em non-smooth\nweakly convex} stochastic optimization with rate $\\tilde\nO\\big(\\frac{1}{n^{1/4}}+\\big(\\frac{d}{n^2}\\big)^{1/6}\\big)$ which matches the\nbest existing non-private algorithm when $d= O(\\sqrt{n})$. We also extend all\nour results above for the non-convex $\\ell_2$ setting to the $\\ell_p$ setting,\nwhere $1 < p \\leq 2$, with only polylogarithmic (in the dimension) overhead in\nthe rates.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:06:08 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 18:24:17 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bassily", "Raef", ""], ["Guzm\u00e1n", "Crist\u00f3bal", ""], ["Menart", "Michael", ""]]}, {"id": "2107.05598", "submitter": "Johannes Brust", "authors": "Johannes J. Brust", "title": "Nonlinear Least Squares for Large-Scale Machine Learning using\n  Stochastic Jacobian Estimates", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For large nonlinear least squares loss functions in machine learning we\nexploit the property that the number of model parameters typically exceeds the\ndata in one batch. This implies a low-rank structure in the Hessian of the\nloss, which enables effective means to compute search directions. Using this\nproperty, we develop two algorithms that estimate Jacobian matrices and perform\nwell when compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:29:08 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Brust", "Johannes J.", ""]]}, {"id": "2107.05599", "submitter": "Terence Broad", "authors": "Terence Broad, Sebastian Berns, Simon Colton, Mick Grierson", "title": "Active Divergence with Generative Deep Learning -- A Survey and Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Generative deep learning systems offer powerful tools for artefact\ngeneration, given their ability to model distributions of data and generate\nhigh-fidelity results. In the context of computational creativity, however, a\nmajor shortcoming is that they are unable to explicitly diverge from the\ntraining data in creative ways and are limited to fitting the target data\ndistribution. To address these limitations, there have been a growing number of\napproaches for optimising, hacking and rewriting these models in order to\nactively diverge from the training data. We present a taxonomy and\ncomprehensive survey of the state of the art of active divergence techniques,\nhighlighting the potential for computational creativity researchers to advance\nthese methods and use deep generative models in truly creative systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:29:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Broad", "Terence", ""], ["Berns", "Sebastian", ""], ["Colton", "Simon", ""], ["Grierson", "Mick", ""]]}, {"id": "2107.05604", "submitter": "Wei-Ning Hsu", "authors": "Ann Lee, Peng-Jen Chen, Changhan Wang, Jiatao Gu, Xutai Ma, Adam\n  Polyak, Yossi Adi, Qing He, Yun Tang, Juan Pino, Wei-Ning Hsu", "title": "Direct speech-to-speech translation with discrete units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a direct speech-to-speech translation (S2ST) model that translates\nspeech from one language to speech in another language without relying on\nintermediate text generation. Previous work addresses the problem by training\nan attention-based sequence-to-sequence model that maps source speech\nspectrograms into target spectrograms. To tackle the challenge of modeling\ncontinuous spectrogram features of the target speech, we propose to predict the\nself-supervised discrete representations learned from an unlabeled speech\ncorpus instead. When target text transcripts are available, we design a\nmultitask learning framework with joint speech and text training that enables\nthe model to generate dual mode output (speech and text) simultaneously in the\nsame inference pass. Experiments on the Fisher Spanish-English dataset show\nthat predicting discrete units and joint speech and text training improve model\nperformance by 11 BLEU compared with a baseline that predicts spectrograms and\nbridges 83% of the performance gap towards a cascaded system. When trained\nwithout any text transcripts, our model achieves similar performance as a\nbaseline that predicts spectrograms and is trained with text data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:40:43 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Lee", "Ann", ""], ["Chen", "Peng-Jen", ""], ["Wang", "Changhan", ""], ["Gu", "Jiatao", ""], ["Ma", "Xutai", ""], ["Polyak", "Adam", ""], ["Adi", "Yossi", ""], ["He", "Qing", ""], ["Tang", "Yun", ""], ["Pino", "Juan", ""], ["Hsu", "Wei-Ning", ""]]}, {"id": "2107.05605", "submitter": "Alina Jade Barnett", "authors": "Alina Jade Barnett, Fides Regina Schwartz, Chaofan Tao, Chaofan Chen,\n  Yinhao Ren, Joseph Y. Lo, Cynthia Rudin", "title": "Interpretable Mammographic Image Classification using Cased-Based\n  Reasoning and Deep Learning", "comments": "10 pages, 6 figures, accepted for oral presentation at the IJCAI-21\n  Workshop on Deep Learning, Case-Based Reasoning, and AutoML: Present and\n  Future Synergies. arXiv admin note: substantial text overlap with\n  arXiv:2103.12308", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we deploy machine learning models in high-stakes medical settings, we\nmust ensure these models make accurate predictions that are consistent with\nknown medical science. Inherently interpretable networks address this need by\nexplaining the rationale behind each decision while maintaining equal or higher\naccuracy compared to black-box models. In this work, we present a novel\ninterpretable neural network algorithm that uses case-based reasoning for\nmammography. Designed to aid a radiologist in their decisions, our network\npresents both a prediction of malignancy and an explanation of that prediction\nusing known medical features. In order to yield helpful explanations, the\nnetwork is designed to mimic the reasoning processes of a radiologist: our\nnetwork first detects the clinically relevant semantic features of each image\nby comparing each new image with a learned set of prototypical image parts from\nthe training images, then uses those clinical features to predict malignancy.\nCompared to other methods, our model detects clinical features (mass margins)\nwith equal or higher accuracy, provides a more detailed explanation of its\nprediction, and is better able to differentiate the classification-relevant\nparts of the image.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:42:09 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Barnett", "Alina Jade", ""], ["Schwartz", "Fides Regina", ""], ["Tao", "Chaofan", ""], ["Chen", "Chaofan", ""], ["Ren", "Yinhao", ""], ["Lo", "Joseph Y.", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2107.05612", "submitter": "Valts Blukis", "authors": "Valts Blukis, Chris Paxton, Dieter Fox, Animesh Garg, Yoav Artzi", "title": "A Persistent Spatial Semantic Representation for High-level Natural\n  Language Instruction Execution", "comments": "Submitted to CoRL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language provides an accessible and expressive interface to specify\nlong-term tasks for robotic agents. However, non-experts are likely to specify\nsuch tasks with high-level instructions, which abstract over specific robot\nactions through several layers of abstraction. We propose that key to bridging\nthis gap between language and robot actions over long execution horizons are\npersistent representations. We propose a persistent spatial semantic\nrepresentation method, and show how it enables building an agent that performs\nhierarchical reasoning to effectively execute long-term tasks. We evaluate our\napproach on the ALFRED benchmark and achieve state-of-the-art results, despite\ncompletely avoiding the commonly used step-by-step instructions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:47:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Blukis", "Valts", ""], ["Paxton", "Chris", ""], ["Fox", "Dieter", ""], ["Garg", "Animesh", ""], ["Artzi", "Yoav", ""]]}, {"id": "2107.05627", "submitter": "Deepak Pathak", "authors": "Shikhar Bahl, Abhinav Gupta, Deepak Pathak", "title": "Hierarchical Neural Dynamic Policies", "comments": "Accepted at RSS 2021. Videos and code at\n  https://shikharbahl.github.io/hierarchical-ndps/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of generalization to unseen configurations for dynamic\ntasks in the real world while learning from high-dimensional image input. The\nfamily of nonlinear dynamical system-based methods have successfully\ndemonstrated dynamic robot behaviors but have difficulty in generalizing to\nunseen configurations as well as learning from image inputs. Recent works\napproach this issue by using deep network policies and reparameterize actions\nto embed the structure of dynamical systems but still struggle in domains with\ndiverse configurations of image goals, and hence, find it difficult to\ngeneralize. In this paper, we address this dichotomy by leveraging embedding\nthe structure of dynamical systems in a hierarchical deep policy learning\nframework, called Hierarchical Neural Dynamical Policies (H-NDPs). Instead of\nfitting deep dynamical systems to diverse data directly, H-NDPs form a\ncurriculum by learning local dynamical system-based policies on small regions\nin state-space and then distill them into a global dynamical system-based\npolicy that operates only from high-dimensional images. H-NDPs additionally\nprovide smooth trajectories, a strong safety benefit in the real world. We\nperform extensive experiments on dynamic tasks both in the real world (digit\nwriting, scooping, and pouring) and simulation (catching, throwing, picking).\nWe show that H-NDPs are easily integrated with both imitation as well as\nreinforcement learning setups and achieve state-of-the-art results. Video\nresults are at https://shikharbahl.github.io/hierarchical-ndps/\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:59:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bahl", "Shikhar", ""], ["Gupta", "Abhinav", ""], ["Pathak", "Deepak", ""]]}, {"id": "2107.05630", "submitter": "Nicola Dinsdale", "authors": "Nicola K Dinsdale, Emma Bluemke, Vaanathi Sundaresan, Mark Jenkinson,\n  Stephen Smith, Ana IL Namburete", "title": "Challenges for machine learning in clinical translation of big data\n  imaging studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The combination of deep learning image analysis methods and large-scale\nimaging datasets offers many opportunities to imaging neuroscience and\nepidemiology. However, despite the success of deep learning when applied to\nmany neuroimaging tasks, there remain barriers to the clinical translation of\nlarge-scale datasets and processing tools. Here, we explore the main challenges\nand the approaches that have been explored to overcome them. We focus on issues\nrelating to data availability, interpretability, evaluation and logistical\nchallenges, and discuss the challenges we believe are still to be overcome to\nenable the full success of big data deep learning approaches to be experienced\noutside of the research field.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 19:26:16 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dinsdale", "Nicola K", ""], ["Bluemke", "Emma", ""], ["Sundaresan", "Vaanathi", ""], ["Jenkinson", "Mark", ""], ["Smith", "Stephen", ""], ["Namburete", "Ana IL", ""]]}, {"id": "2107.05634", "submitter": "Madhusudhanan Balasubramanian", "authors": "Ali Salehi, Madhusudhanan Balasubramanian", "title": "DDCNet-Multires: Effective Receptive Field Guided Multiresolution CNN\n  for Dense Prediction", "comments": "27 pages, 10 figures, 2 tables. arXiv admin note: text overlap with\n  arXiv:2107.04715", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense optical flow estimation is challenging when there are large\ndisplacements in a scene with heterogeneous motion dynamics, occlusion, and\nscene homogeneity. Traditional approaches to handle these challenges include\nhierarchical and multiresolution processing methods. Learning-based optical\nflow methods typically use a multiresolution approach with image warping when a\nbroad range of flow velocities and heterogeneous motion is present. Accuracy of\nsuch coarse-to-fine methods is affected by the ghosting artifacts when images\nare warped across multiple resolutions and by the vanishing problem in smaller\nscene extents with higher motion contrast. Previously, we devised strategies\nfor building compact dense prediction networks guided by the effective\nreceptive field (ERF) characteristics of the network (DDCNet). The DDCNet\ndesign was intentionally simple and compact allowing it to be used as a\nbuilding block for designing more complex yet compact networks. In this work,\nwe extend the DDCNet strategies to handle heterogeneous motion dynamics by\ncascading DDCNet based sub-nets with decreasing extents of their ERF. Our\nDDCNet with multiresolution capability (DDCNet-Multires) is compact without any\nspecialized network layers. We evaluate the performance of the DDCNet-Multires\nnetwork using standard optical flow benchmark datasets. Our experiments\ndemonstrate that DDCNet-Multires improves over the DDCNet-B0 and -B1 and\nprovides optical flow estimates with accuracy comparable to similar lightweight\nlearning-based methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:28:08 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Salehi", "Ali", ""], ["Balasubramanian", "Madhusudhanan", ""]]}, {"id": "2107.05666", "submitter": "Ramesh Sah", "authors": "Ramesh Kumar Sah and Hassan Ghasemzadeh", "title": "Stress Classification and Personalization: Getting the most out of the\n  least", "comments": "4 pages, 4 figures, IEEE International Conference on Wearable and\n  Implantable Body Sensor Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stress detection and monitoring is an active area of research with important\nimplications for the personal, professional, and social health of an\nindividual. Current approaches for affective state classification use\ntraditional machine learning algorithms with features computed from multiple\nsensor modalities. These methods are data-intensive and rely on hand-crafted\nfeatures which impede the practical applicability of these sensor systems in\ndaily lives. To overcome these shortcomings, we propose a novel Convolutional\nNeural Network (CNN) based stress detection and classification framework\nwithout any feature computation using data from only one sensor modality. Our\nmethod is competitive and outperforms current state-of-the-art techniques and\nachieves a classification accuracy of $92.85\\%$ and an $f1$ score of $0.89$.\nThrough our leave-one-subject-out analysis, we also show the importance of\npersonalizing stress models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:14:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Sah", "Ramesh Kumar", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2107.05675", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Onur G\\\"unl\\\"u, Rafael F. Schaefer, and H. Vincent Poor", "title": "Quality of Service Guarantees for Physical Unclonable Functions", "comments": "Submitted to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a secret key agreement problem in which noisy physical unclonable\nfunction (PUF) outputs facilitate reliable, secure, and private key agreement\nwith the help of public, noiseless, and authenticated storage. PUF outputs are\nhighly correlated, so transform coding methods have been combined with scalar\nquantizers to extract uncorrelated bit sequences with reliability guarantees.\nFor PUF circuits with continuous-valued outputs, the models for transformed\noutputs are made more realistic by replacing the fitted distributions with\ncorresponding truncated ones. The state-of-the-art PUF methods that provide\nreliability guarantees to each extracted bit are shown to be inadequate to\nguarantee the same reliability level for all PUF outputs. Thus, a quality of\nservice parameter is introduced to control the percentage of PUF outputs for\nwhich a target reliability level can be guaranteed. A public ring oscillator\n(RO) output dataset is used to illustrate that a truncated Gaussian\ndistribution can be fitted to transformed RO outputs that are inputs to uniform\nscalar quantizers such that reliability guarantees can be provided for each bit\nextracted from any PUF device under additive Gaussian noise components by\neliminating a small subset of PUF outputs. Furthermore, we conversely show that\nit is not possible to provide such reliability guarantees without eliminating\nany PUF output if no extra secrecy and privacy leakage is allowed.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:26:08 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["G\u00fcnl\u00fc", "Onur", ""], ["Schaefer", "Rafael F.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2107.05677", "submitter": "Chris Donahue", "authors": "Rodrigo Castellon and Chris Donahue and Percy Liang", "title": "Codified audio language modeling learns useful representations for music\n  information retrieval", "comments": "To appear in the proceedings of ISMIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate that language models pre-trained on codified\n(discretely-encoded) music audio learn representations that are useful for\ndownstream MIR tasks. Specifically, we explore representations from Jukebox\n(Dhariwal et al. 2020): a music generation system containing a language model\ntrained on codified audio from 1M songs. To determine if Jukebox's\nrepresentations contain useful information for MIR, we use them as input\nfeatures to train shallow models on several MIR tasks. Relative to\nrepresentations from conventional MIR models which are pre-trained on tagging,\nwe find that using representations from Jukebox as input features yields 30%\nstronger performance on average across four MIR tasks: tagging, genre\nclassification, emotion recognition, and key detection. For key detection, we\nobserve that representations from Jukebox are considerably stronger than those\nfrom models pre-trained on tagging, suggesting that pre-training via codified\naudio language modeling may address blind spots in conventional approaches. We\ninterpret the strength of Jukebox's representations as evidence that modeling\naudio instead of tags provides richer representations for MIR.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:28:50 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Castellon", "Rodrigo", ""], ["Donahue", "Chris", ""], ["Liang", "Percy", ""]]}, {"id": "2107.05680", "submitter": "Arda Sahiner", "authors": "Arda Sahiner, Tolga Ergen, Batu Ozturkler, Burak Bartan, John Pauly,\n  Morteza Mardani, Mert Pilanci", "title": "Hidden Convexity of Wasserstein GANs: Interpretable Generative Models\n  with Closed-Form Solutions", "comments": "First two authors contributed equally to this work; 30 pages, 11\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) are commonly used for modeling complex\ndistributions of data. Both the generators and discriminators of GANs are often\nmodeled by neural networks, posing a non-transparent optimization problem which\nis non-convex and non-concave over the generator and discriminator,\nrespectively. Such networks are often heuristically optimized with gradient\ndescent-ascent (GDA), but it is unclear whether the optimization problem\ncontains any saddle points, or whether heuristic methods can find them in\npractice. In this work, we analyze the training of Wasserstein GANs with\ntwo-layer neural network discriminators through the lens of convex duality, and\nfor a variety of generators expose the conditions under which Wasserstein GANs\ncan be solved exactly with convex optimization approaches, or can be\nrepresented as convex-concave games. Using this convex duality interpretation,\nwe further demonstrate the impact of different activation functions of the\ndiscriminator. Our observations are verified with numerical results\ndemonstrating the power of the convex interpretation, with applications in\nprogressive training of convex architectures corresponding to linear generators\nand quadratic-activation discriminators for CelebA image generation. The code\nfor our experiments is available at https://github.com/ardasahiner/ProCoGAN.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:33:49 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Sahiner", "Arda", ""], ["Ergen", "Tolga", ""], ["Ozturkler", "Batu", ""], ["Bartan", "Burak", ""], ["Pauly", "John", ""], ["Mardani", "Morteza", ""], ["Pilanci", "Mert", ""]]}, {"id": "2107.05682", "submitter": "Angelica Louren\\c{c}o Oliveira", "authors": "Angelica Louren\\c{c}o Oliveira and Marcos Eduardo Valle", "title": "Least-Squares Linear Dilation-Erosion Regressor Trained using Stochastic\n  Descent Gradient or the Difference of Convex Methods", "comments": "15 pages", "journal-ref": "BRACIS 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hybrid morphological neural network for regression\ntasks called linear dilation-erosion regression ($\\ell$-DER). In few words, an\n$\\ell$-DER model is given by a convex combination of the composition of linear\nand elementary morphological operators. As a result, they yield continuous\npiecewise linear functions and, thus, are universal approximators. Apart from\nintroducing the $\\ell$-DER models, we present three approaches for training\nthese models: one based on stochastic descent gradient and two based on the\ndifference of convex programming problems. Finally, we evaluate the performance\nof the $\\ell$-DER model using 14 regression tasks. Although the approach based\non SDG revealed faster than the other two, the $\\ell$-DER trained using a\ndisciplined convex-concave programming problem outperformed the others in terms\nof the least mean absolute error score.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:41:59 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Oliveira", "Angelica Louren\u00e7o", ""], ["Valle", "Marcos Eduardo", ""]]}, {"id": "2107.05686", "submitter": "Andrea Dittadi", "authors": "Andrea Dittadi, Frederik Tr\\\"auble, Manuel W\\\"uthrich, Felix Widmaier,\n  Peter Gehler, Ole Winther, Francesco Locatello, Olivier Bachem, Bernhard\n  Sch\\\"olkopf, Stefan Bauer", "title": "Representation Learning for Out-Of-Distribution Generalization in\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning data representations that are useful for various downstream tasks is\na cornerstone of artificial intelligence. While existing methods are typically\nevaluated on downstream tasks such as classification or generative image\nquality, we propose to assess representations through their usefulness in\ndownstream control tasks, such as reaching or pushing objects. By training over\n10,000 reinforcement learning policies, we extensively evaluate to what extent\ndifferent representation properties affect out-of-distribution (OOD)\ngeneralization. Finally, we demonstrate zero-shot transfer of these policies\nfrom simulation to the real world, without any domain randomization or\nfine-tuning. This paper aims to establish the first systematic characterization\nof the usefulness of learned representations for real-world OOD downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:49:48 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dittadi", "Andrea", ""], ["Tr\u00e4uble", "Frederik", ""], ["W\u00fcthrich", "Manuel", ""], ["Widmaier", "Felix", ""], ["Gehler", "Peter", ""], ["Winther", "Ole", ""], ["Locatello", "Francesco", ""], ["Bachem", "Olivier", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bauer", "Stefan", ""]]}, {"id": "2107.05687", "submitter": "Christopher Schr\\\"oder", "authors": "Christopher Schr\\\"oder, Andreas Niekler, Martin Potthast", "title": "Uncertainty-based Query Strategies for Active Learning with Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is the iterative construction of a classification model\nthrough targeted labeling, enabling significant labeling cost savings. As most\nresearch on active learning has been carried out before transformer-based\nlanguage models (\"transformers\") became popular, despite its practical\nimportance, comparably few papers have investigated how transformers can be\ncombined with active learning to date. This can be attributed to the fact that\nusing state-of-the-art query strategies for transformers induces a prohibitive\nruntime overhead, which effectively cancels out, or even outweighs\naforementioned cost savings. In this paper, we revisit uncertainty-based query\nstrategies, which had been largely outperformed before, but are particularly\nsuited in the context of fine-tuning transformers. In an extensive evaluation\non five widely used text classification benchmarks, we show that considerable\nimprovements of up to 14.4 percentage points in area under the learning curve\nare achieved, as well as a final accuracy close to the state of the art for all\nbut one benchmark, using only between 0.4% and 15% of the training data.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:56:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Schr\u00f6der", "Christopher", ""], ["Niekler", "Andreas", ""], ["Potthast", "Martin", ""]]}, {"id": "2107.05693", "submitter": "Mitchell Naylor", "authors": "Mitchell Naylor, Christi French, Samantha Terker, Uday Kamath", "title": "Quantifying Explainability in NLP and Analyzing Algorithms for\n  Performance-Explainability Tradeoff", "comments": "To appear at Interpretable ML in Healthcare workshop at ICML 2021. 9\n  pages (excluding references), 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The healthcare domain is one of the most exciting application areas for\nmachine learning, but a lack of model transparency contributes to a lag in\nadoption within the industry. In this work, we explore the current art of\nexplainability and interpretability within a case study in clinical text\nclassification, using a task of mortality prediction within MIMIC-III clinical\nnotes. We demonstrate various visualization techniques for fully interpretable\nmethods as well as model-agnostic post hoc attributions, and we provide a\ngeneralized method for evaluating the quality of explanations using infidelity\nand local Lipschitz across model types from logistic regression to BERT\nvariants. With these metrics, we introduce a framework through which\npractitioners and researchers can assess the frontier between a model's\npredictive performance and the quality of its available explanations. We make\nour code available to encourage continued refinement of these methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 19:07:24 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Naylor", "Mitchell", ""], ["French", "Christi", ""], ["Terker", "Samantha", ""], ["Kamath", "Uday", ""]]}, {"id": "2107.05707", "submitter": "Xiao Xiao", "authors": "Sumudu Herath, Xiao Xiao and Fehmi Cirak", "title": "Computational modelling and data-driven homogenisation of knitted\n  membranes", "comments": "23 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knitting is an effective technique for producing complex three-dimensional\nsurfaces owing to the inherent flexibility of interlooped yarns and recent\nadvances in manufacturing providing better control of local stitch patterns.\nFully yarn-level modelling of large-scale knitted membranes is not feasible.\nTherefore, we consider a two-scale homogenisation approach and model the\nmembrane as a Kirchhoff-Love shell on the macroscale and as Euler-Bernoulli\nrods on the microscale. The governing equations for both the shell and the rod\nare discretised with cubic B-spline basis functions. The solution of the\nnonlinear microscale problem requires a significant amount of time due to the\nlarge deformations and the enforcement of contact constraints, rendering\nconventional online computational homogenisation approaches infeasible. To\nsidestep this problem, we use a pre-trained statistical Gaussian Process\nRegression (GPR) model to map the macroscale deformations to macroscale\nstresses. During the offline learning phase, the GPR model is trained by\nsolving the microscale problem for a sufficiently rich set of deformation\nstates obtained by either uniform or Sobol sampling. The trained GPR model\nencodes the nonlinearities and anisotropies present in the microscale and\nserves as a material model for the macroscale Kirchhoff-Love shell. After\nverifying and validating the different components of the proposed approach, we\nintroduce several examples involving membranes subjected to tension and shear\nto demonstrate its versatility and good performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 19:51:02 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Herath", "Sumudu", ""], ["Xiao", "Xiao", ""], ["Cirak", "Fehmi", ""]]}, {"id": "2107.05709", "submitter": "Guillermo Barrios Morales", "authors": "Guillermo B. Morales and Miguel A. Mu\\~noz", "title": "Optimal input representation in neural systems at the edge of chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Shedding light onto how biological systems represent, process and store\ninformation in noisy environments is a key and challenging goal. A stimulating,\nthough controversial, hypothesis poses that operating in dynamical regimes near\nthe edge of a phase transition, i.e. at criticality or the \"edge of chaos\", can\nprovide information-processing living systems with important operational\nadvantages, creating, e.g., an optimal trade-off between robustness and\nflexibility. Here, we elaborate on a recent theoretical result, which\nestablishes that the spectrum of covariance matrices of neural networks\nrepresenting complex inputs in a robust way needs to decay as a power-law of\nthe rank, with an exponent close to unity, a result that has been indeed\nexperimentally verified in neurons of the mouse visual cortex. Aimed at\nunderstanding and mimicking these results, we construct an artificial neural\nnetwork and train it to classify images. Remarkably, we find that the best\nperformance in such a task is obtained when the network operates near the\ncritical point, at which the eigenspectrum of the covariance matrix follows the\nvery same statistics as actual neurons do. Thus, we conclude that operating\nnear criticality can also have -- besides the usually alleged virtues -- the\nadvantage of allowing for flexible, robust and efficient input representations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 19:55:03 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Morales", "Guillermo B.", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "2107.05712", "submitter": "Iryna Korshunova", "authors": "Iryna Korshunova, David Stutz, Alexander A. Alemi, Olivia Wiles, Sven\n  Gowal", "title": "A Closer Look at the Adversarial Robustness of Information Bottleneck\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the adversarial robustness of information bottleneck models for\nclassification. Previous works showed that the robustness of models trained\nwith information bottlenecks can improve upon adversarial training. Our\nevaluation under a diverse range of white-box $l_{\\infty}$ attacks suggests\nthat information bottlenecks alone are not a strong defense strategy, and that\nprevious results were likely influenced by gradient obfuscation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:05:08 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Korshunova", "Iryna", ""], ["Stutz", "David", ""], ["Alemi", "Alexander A.", ""], ["Wiles", "Olivia", ""], ["Gowal", "Sven", ""]]}, {"id": "2107.05719", "submitter": "Shengjia Zhao", "authors": "Shengjia Zhao, Michael P. Kim, Roshni Sahoo, Tengyu Ma, Stefano Ermon", "title": "Calibrating Predictions to Decisions: A Novel Approach to Multi-Class\n  Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When facing uncertainty, decision-makers want predictions they can trust. A\nmachine learning provider can convey confidence to decision-makers by\nguaranteeing their predictions are distribution calibrated -- amongst the\ninputs that receive a predicted class probabilities vector $q$, the actual\ndistribution over classes is $q$. For multi-class prediction problems, however,\nachieving distribution calibration tends to be infeasible, requiring sample\ncomplexity exponential in the number of classes $C$. In this work, we introduce\na new notion -- \\emph{decision calibration} -- that requires the predicted\ndistribution and true distribution to be ``indistinguishable'' to a set of\ndownstream decision-makers. When all possible decision makers are under\nconsideration, decision calibration is the same as distribution calibration.\nHowever, when we only consider decision makers choosing between a bounded\nnumber of actions (e.g. polynomial in $C$), our main result shows that\ndecisions calibration becomes feasible -- we design a recalibration algorithm\nthat requires sample complexity polynomial in the number of actions and the\nnumber of classes. We validate our recalibration algorithm empirically:\ncompared to existing methods, decision calibration improves decision-making on\nskin lesion and ImageNet classification with modern neural network predictors.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:17:28 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhao", "Shengjia", ""], ["Kim", "Michael P.", ""], ["Sahoo", "Roshni", ""], ["Ma", "Tengyu", ""], ["Ermon", "Stefano", ""]]}, {"id": "2107.05728", "submitter": "Saeedeh Parsaeefard", "authors": "Saeedeh Parsaeefard and Alberto Leon-Garcia", "title": "Toward Efficient Transfer Learning in 6G", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  6G networks will greatly expand the support for data-oriented, autonomous\napplications for over the top (OTT) and networking use cases. The success of\nthese use cases will depend on the availability of big data sets which is not\npractical in many real scenarios due to the highly dynamic behavior of systems\nand the cost of data collection procedures. Transfer learning (TL) is a\npromising approach to deal with these challenges through the sharing of\nknowledge among diverse learning algorithms. with TL, the learning rate and\nlearning accuracy can be considerably improved. However, there are\nimplementation challenges to efficiently deploy and utilize TL in 6G. In this\npaper, we initiate this discussion by providing some performance metrics to\nmeasure the TL success. Then, we show how infrastructure, application,\nmanagement, and training planes of 6G can be adapted to handle TL. We provide\nexamples of TL in 6G and highlight the spatio-temporal features of data in 6G\nthat can lead to efficient TL. By simulation results, we demonstrate how\ntransferring the quantized neural network weights between two use cases can\nmake a trade-off between overheads and performance and attain more efficient TL\nin 6G. We also provide a list of future research directions in TL for 6G.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:46:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2107.05729", "submitter": "Yicheng Fei", "authors": "Yicheng Fei, Xaq Pitkow", "title": "Generalization of graph network inferences in higher-order probabilistic\n  graphical models", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Probabilistic graphical models provide a powerful tool to describe complex\nstatistical structure, with many real-world applications in science and\nengineering from controlling robotic arms to understanding neuronal\ncomputations. A major challenge for these graphical models is that inferences\nsuch as marginalization are intractable for general graphs. These inferences\nare often approximated by a distributed message-passing algorithm such as\nBelief Propagation, which does not always perform well on graphs with cycles,\nnor can it always be easily specified for complex continuous probability\ndistributions. Such difficulties arise frequently in expressive graphical\nmodels that include intractable higher-order interactions. In this paper we\nconstruct iterative message-passing algorithms using Graph Neural Networks\ndefined on factor graphs to achieve fast approximate inference on graphical\nmodels that involve many-variable interactions. Experimental results on several\nfamilies of graphical models demonstrate the out-of-distribution generalization\ncapability of our method to different sized graphs, and indicate the domain in\nwhich our method gains advantage over Belief Propagation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:51:27 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Fei", "Yicheng", ""], ["Pitkow", "Xaq", ""]]}, {"id": "2107.05745", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Claudio Gentile and Mehryar Mohri and Julian\n  Zimmert", "title": "Adapting to Misspecification in Contextual Bandits", "comments": "Appeared at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major research direction in contextual bandits is to develop algorithms\nthat are computationally efficient, yet support flexible, general-purpose\nfunction approximation. Algorithms based on modeling rewards have shown strong\nempirical performance, but typically require a well-specified model, and can\nfail when this assumption does not hold. Can we design algorithms that are\nefficient and flexible, yet degrade gracefully in the face of model\nmisspecification? We introduce a new family of oracle-efficient algorithms for\n$\\varepsilon$-misspecified contextual bandits that adapt to unknown model\nmisspecification -- both for finite and infinite action settings. Given access\nto an online oracle for square loss regression, our algorithm attains optimal\nregret and -- in particular -- optimal dependence on the misspecification\nlevel, with no prior knowledge. Specializing to linear contextual bandits with\ninfinite actions in $d$ dimensions, we obtain the first algorithm that achieves\nthe optimal $O(d\\sqrt{T} + \\varepsilon\\sqrt{d}T)$ regret bound for unknown\nmisspecification level $\\varepsilon$.\n  On a conceptual level, our results are enabled by a new optimization-based\nperspective on the regression oracle reduction framework of Foster and Rakhlin,\nwhich we anticipate will find broader use.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:30:41 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Foster", "Dylan J.", ""], ["Gentile", "Claudio", ""], ["Mohri", "Mehryar", ""], ["Zimmert", "Julian", ""]]}, {"id": "2107.05747", "submitter": "Timoleon Moraitis", "authors": "Timoleon Moraitis, Dmitry Toichkin, Yansong Chua, Qinghai Guo", "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft\n  winner-take-all networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art artificial neural networks (ANNs) require labelled data or\nfeedback between layers, are often biologically implausible, and are vulnerable\nto adversarial attacks that humans are not susceptible to. On the other hand,\nHebbian learning in winner-take-all (WTA) networks, is unsupervised,\nfeed-forward, and biologically plausible. However, an objective optimization\ntheory for WTA networks has been missing, except under very limiting\nassumptions. Here we derive formally such a theory, based on biologically\nplausible but generic ANN elements. Through Hebbian learning, network\nparameters maintain a Bayesian generative model of the data. There is no\nsupervisory loss function, but the network does minimize cross-entropy between\nits activations and the input distribution. The key is a \"soft\" WTA where there\nis no absolute \"hard\" winner neuron, and a specific type of Hebbian-like\nplasticity of weights and biases. We confirm our theory in practice, where, in\nhandwritten digit (MNIST) recognition, our Hebbian algorithm, SoftHebb,\nminimizes cross-entropy without having access to it, and outperforms the more\nfrequently used, hard-WTA-based method. Strikingly, it even outperforms\nsupervised end-to-end backpropagation, under certain conditions. Specifically,\nin a two-layered network, SoftHebb outperforms backpropagation when the\ntraining dataset is only presented once, when the testing data is noisy, and\nunder gradient-based adversarial attacks. Adversarial attacks that confuse\nSoftHebb are also confusing to the human eye. Finally, the model can generate\ninterpolations of objects from its input distribution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:34:45 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Moraitis", "Timoleon", ""], ["Toichkin", "Dmitry", ""], ["Chua", "Yansong", ""], ["Guo", "Qinghai", ""]]}, {"id": "2107.05754", "submitter": "Andrei Ilie", "authors": "Andrei Ilie, Marius Popescu, Alin Stefanescu", "title": "EvoBA: An Evolution Strategy as a Strong Baseline forBlack-Box\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has shown how easily white-box adversarial attacks can be applied\nto state-of-the-art image classifiers. However, real-life scenarios resemble\nmore the black-box adversarial conditions, lacking transparency and usually\nimposing natural, hard constraints on the query budget.\n  We propose $\\textbf{EvoBA}$, a black-box adversarial attack based on a\nsurprisingly simple evolutionary search strategy. $\\textbf{EvoBA}$ is\nquery-efficient, minimizes $L_0$ adversarial perturbations, and does not\nrequire any form of training.\n  $\\textbf{EvoBA}$ shows efficiency and efficacy through results that are in\nline with much more complex state-of-the-art black-box attacks such as\n$\\textbf{AutoZOOM}$. It is more query-efficient than $\\textbf{SimBA}$, a simple\nand powerful baseline black-box attack, and has a similar level of complexity.\nTherefore, we propose it both as a new strong baseline for black-box\nadversarial attacks and as a fast and general tool for gaining empirical\ninsight into how robust image classifiers are with respect to $L_0$ adversarial\nperturbations.\n  There exist fast and reliable $L_2$ black-box attacks, such as\n$\\textbf{SimBA}$, and $L_{\\infty}$ black-box attacks, such as\n$\\textbf{DeepSearch}$. We propose $\\textbf{EvoBA}$ as a query-efficient $L_0$\nblack-box adversarial attack which, together with the aforementioned methods,\ncan serve as a generic tool to assess the empirical robustness of image\nclassifiers. The main advantages of such methods are that they run fast, are\nquery-efficient, and can easily be integrated in image classifiers development\npipelines.\n  While our attack minimises the $L_0$ adversarial perturbation, we also report\n$L_2$, and notice that we compare favorably to the state-of-the-art $L_2$\nblack-box attack, $\\textbf{AutoZOOM}$, and of the $L_2$ strong baseline,\n$\\textbf{SimBA}$.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:55:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ilie", "Andrei", ""], ["Popescu", "Marius", ""], ["Stefanescu", "Alin", ""]]}, {"id": "2107.05757", "submitter": "Xiantong Zhen", "authors": "Mohammad Mahdi Derakhshani, Xiantong Zhen, Ling Shao, Cees G. M. Snoek", "title": "Kernel Continual Learning", "comments": "accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper introduces kernel continual learning, a simple but effective\nvariant of continual learning that leverages the non-parametric nature of\nkernel methods to tackle catastrophic forgetting. We deploy an episodic memory\nunit that stores a subset of samples for each task to learn task-specific\nclassifiers based on kernel ridge regression. This does not require memory\nreplay and systematically avoids task interference in the classifiers. We\nfurther introduce variational random features to learn a data-driven kernel for\neach task. To do so, we formulate kernel continual learning as a variational\ninference problem, where a random Fourier basis is incorporated as the latent\nvariable. The variational posterior distribution over the random Fourier basis\nis inferred from the coreset of each task. In this way, we are able to generate\nmore informative kernels specific to each task, and, more importantly, the\ncoreset size can be reduced to achieve more compact memory, resulting in more\nefficient continual learning based on episodic memory. Extensive evaluation on\nfour benchmarks demonstrates the effectiveness and promise of kernels for\ncontinual learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:09:30 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 23:49:54 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Derakhshani", "Mohammad Mahdi", ""], ["Zhen", "Xiantong", ""], ["Shao", "Ling", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "2107.05762", "submitter": "Keegan Harris", "authors": "Keegan Harris, Daniel Ngo, Logan Stapleton, Hoda Heidari, Zhiwei\n  Steven Wu", "title": "Strategic Instrumental Variable Regression: Recovering Causal\n  Relationships From Strategic Responses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning algorithms often prompt individuals to strategically modify\ntheir observable attributes to receive more favorable predictions. As a result,\nthe distribution the predictive model is trained on may differ from the one it\noperates on in deployment. While such distribution shifts, in general, hinder\naccurate predictions, our work identifies a unique opportunity associated with\nshifts due to strategic responses: We show that we can use strategic responses\neffectively to recover causal relationships between the observable features and\noutcomes we wish to predict. More specifically, we study a game-theoretic model\nin which a principal deploys a sequence of models to predict an outcome of\ninterest (e.g., college GPA) for a sequence of strategic agents (e.g., college\napplicants). In response, strategic agents invest efforts and modify their\nfeatures for better predictions. In such settings, unobserved confounding\nvariables can influence both an agent's observable features (e.g., high school\nrecords) and outcomes. Therefore, standard regression methods generally produce\nbiased estimators. In order to address this issue, our work establishes a novel\nconnection between strategic responses to machine learning models and\ninstrumental variable (IV) regression, by observing that the sequence of\ndeployed models can be viewed as an instrument that affects agents' observable\nfeatures but does not directly influence their outcomes. Therefore, two-stage\nleast squares (2SLS) regression can recover the causal relationships between\nobservable features and outcomes. Beyond causal recovery, we can build on our\n2SLS method to address two additional relevant optimization objectives: agent\noutcome maximization and predictive risk minimization. Finally, our numerical\nsimulations on semi-synthetic data show that our methods significantly\noutperform OLS regression in causal relationship estimation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:12:56 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Harris", "Keegan", ""], ["Ngo", "Daniel", ""], ["Stapleton", "Logan", ""], ["Heidari", "Hoda", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2107.05767", "submitter": "Lucka Gianvechio", "authors": "Carmen Melo Toledo, Guilherme Mendes Bassedon, Jonathan Batista\n  Ferreira, Lucka de Godoy Gianvechio, Carlos Guatimosim, Felipe Maia Polo,\n  Renato Vicente", "title": "Effects of personality traits in predicting grade retention of Brazilian\n  students", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Student's grade retention is a key issue faced by many education systems,\nespecially those in developing countries. In this paper, we seek to gauge the\nrelevance of students' personality traits in predicting grade retention in\nBrazil. For that, we used data collected in 2012 and 2017, in the city of\nSertaozinho, countryside of the state of Sao Paulo, Brazil. The surveys taken\nin Sertaozinho included several socioeconomic questions, standardized tests,\nand a personality test. Moreover, students were in grades 4, 5, and 6 in 2012.\nOur approach was based on training machine learning models on the surveys' data\nto predict grade retention between 2012 and 2017 using information from 2012 or\nbefore, and then using some strategies to quantify personality traits'\npredictive power. We concluded that, besides proving to be fairly better than a\nrandom classifier when isolated, personality traits contribute to prediction\neven when using socioeconomic variables and standardized tests results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:23:13 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Toledo", "Carmen Melo", ""], ["Bassedon", "Guilherme Mendes", ""], ["Ferreira", "Jonathan Batista", ""], ["Gianvechio", "Lucka de Godoy", ""], ["Guatimosim", "Carlos", ""], ["Polo", "Felipe Maia", ""], ["Vicente", "Renato", ""]]}, {"id": "2107.05768", "submitter": "Hanjun Dai", "authors": "Hongyu Ren, Hanjun Dai, Zihang Dai, Mengjiao Yang, Jure Leskovec, Dale\n  Schuurmans, Bo Dai", "title": "Combiner: Full Attention Transformer with Sparse Computation Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers provide a class of expressive architectures that are extremely\neffective for sequence modeling. However, the key limitation of transformers is\ntheir quadratic memory and time complexity $\\mathcal{O}(L^2)$ with respect to\nthe sequence length in attention layers, which restricts application in\nextremely long sequences. Most existing approaches leverage sparsity or\nlow-rank assumptions in the attention matrix to reduce cost, but sacrifice\nexpressiveness. Instead, we propose Combiner, which provides full attention\ncapability in each attention head while maintaining low computation and memory\ncomplexity. The key idea is to treat the self-attention mechanism as a\nconditional expectation over embeddings at each location, and approximate the\nconditional distribution with a structured factorization. Each location can\nattend to all other locations, either via direct attention, or through indirect\nattention to abstractions, which are again conditional expectations of\nembeddings from corresponding local regions. We show that most sparse attention\npatterns used in existing sparse transformers are able to inspire the design of\nsuch factorization for full attention, resulting in the same sub-quadratic cost\n($\\mathcal{O}(L\\log(L))$ or $\\mathcal{O}(L\\sqrt{L})$). Combiner is a drop-in\nreplacement for attention layers in existing transformers and can be easily\nimplemented in common frameworks. An experimental evaluation on both\nautoregressive and bidirectional sequence tasks demonstrates the effectiveness\nof this approach, yielding state-of-the-art results on several image and text\nmodeling tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:43:11 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ren", "Hongyu", ""], ["Dai", "Hanjun", ""], ["Dai", "Zihang", ""], ["Yang", "Mengjiao", ""], ["Leskovec", "Jure", ""], ["Schuurmans", "Dale", ""], ["Dai", "Bo", ""]]}, {"id": "2107.05775", "submitter": "Pengsheng Guo", "authors": "Pengsheng Guo, Miguel Angel Bautista, Alex Colburn, Liang Yang, Daniel\n  Ulbricht, Joshua M. Susskind, Qi Shan", "title": "Fast and Explicit Neural View Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of novel view synthesis of a scene comprised of 3D\nobjects. We propose a simple yet effective approach that is neither continuous\nnor implicit, challenging recent trends on view synthesis. We demonstrate that\nalthough continuous radiance field representations have gained a lot of\nattention due to their expressive power, our simple approach obtains comparable\nor even better novel view reconstruction quality comparing with\nstate-of-the-art baselines while increasing rendering speed by over 400x. Our\nmodel is trained in a category-agnostic manner and does not require\nscene-specific optimization. Therefore, it is able to generalize novel view\nsynthesis to object categories not seen during training. In addition, we show\nthat with our simple formulation, we can use view synthesis as a\nself-supervision signal for efficient learning of 3D geometry without explicit\n3D supervision.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 23:24:53 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Guo", "Pengsheng", ""], ["Bautista", "Miguel Angel", ""], ["Colburn", "Alex", ""], ["Yang", "Liang", ""], ["Ulbricht", "Daniel", ""], ["Susskind", "Joshua M.", ""], ["Shan", "Qi", ""]]}, {"id": "2107.05786", "submitter": "Q. Tyrell Davis", "authors": "Q. Tyrell Davis", "title": "Carle's Game: An Open-Ended Challenge in Exploratory Machine Creativity", "comments": "8 pages, 11 figures, accepted to IEEE Conference on Games 2021:\n  978-1-6654-3886-5/21/$31.00 \\copyright 2021 IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is both an introduction and an invitation. It is an introduction\nto CARLE, a Life-like cellular automata simulator and reinforcement learning\nenvironment. It is also an invitation to Carle's Game, a challenge in\nopen-ended machine exploration and creativity. Inducing machine agents to excel\nat creating interesting patterns across multiple cellular automata universes is\na substantial challenge, and approaching this challenge is likely to require\ncontributions from the fields of artificial life, AI, machine learning, and\ncomplexity, at multiple levels of interest. Carle's Game is based on machine\nagent interaction with CARLE, a Cellular Automata Reinforcement Learning\nEnvironment. CARLE is flexible, capable of simulating any of the 262,144\ndifferent rules defining Life-like cellular automaton universes. CARLE is also\nfast and can simulate automata universes at a rate of tens of thousands of\nsteps per second through a combination of vectorization and GPU acceleration.\nFinally, CARLE is simple. Compared to high-fidelity physics simulators and\nvideo games designed for human players, CARLE's two-dimensional grid world\noffers a discrete, deterministic, and atomic universal playground, despite its\ncomplexity. In combination with CARLE, Carle's Game offers an initial set of\nagent policies, learning and meta-learning algorithms, and reward wrappers that\ncan be tailored to encourage exploration or specific tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 00:07:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Davis", "Q. Tyrell", ""]]}, {"id": "2107.05787", "submitter": "Dimitris Papadimitriou", "authors": "Dimitris Papadimitriou, Swayambhoo Jain", "title": "Data-Driven Low-Rank Neural Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite many modern applications of Deep Neural Networks (DNNs), the large\nnumber of parameters in the hidden layers makes them unattractive for\ndeployment on devices with storage capacity constraints. In this paper we\npropose a Data-Driven Low-rank (DDLR) method to reduce the number of parameters\nof pretrained DNNs and expedite inference by imposing low-rank structure on the\nfully connected layers, while controlling for the overall accuracy and without\nrequiring any retraining. We pose the problem as finding the lowest rank\napproximation of each fully connected layer with given performance guarantees\nand relax it to a tractable convex optimization problem. We show that it is\npossible to significantly reduce the number of parameters in common DNN\narchitectures with only a small reduction in classification accuracy. We\ncompare DDLR with Net-Trim, which is another data-driven DNN compression\ntechnique based on sparsity and show that DDLR consistently produces more\ncompressed neural networks while maintaining higher accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 00:10:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Papadimitriou", "Dimitris", ""], ["Jain", "Swayambhoo", ""]]}, {"id": "2107.05798", "submitter": "Lingwei Zhu", "authors": "Lingwei Zhu, Toshinori Kitamura, Takamitsu Matsubara", "title": "Cautious Policy Programming: Exploiting KL Regularization in Monotonic\n  Policy Improvement for Reinforcement Learning", "comments": "15 pages. arXiv admin note: text overlap with arXiv:2008.10806", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose cautious policy programming (CPP), a novel\nvalue-based reinforcement learning (RL) algorithm that can ensure monotonic\npolicy improvement during learning. Based on the nature of entropy-regularized\nRL, we derive a new entropy regularization-aware lower bound of policy\nimprovement that only requires estimating the expected policy advantage\nfunction. CPP leverages this lower bound as a criterion for adjusting the\ndegree of a policy update for alleviating policy oscillation. Different from\nsimilar algorithms that are mostly theory-oriented, we also propose a novel\ninterpolation scheme that makes CPP better scale in high dimensional control\nproblems. We demonstrate that the proposed algorithm can trade o? performance\nand stability in both didactic classic control problems and challenging\nhigh-dimensional Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:03:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhu", "Lingwei", ""], ["Kitamura", "Toshinori", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2107.05802", "submitter": "Brett Larsen", "authors": "Brett W. Larsen, Stanislav Fort, Nic Becker, Surya Ganguli", "title": "How many degrees of freedom do we need to train deep networks: a loss\n  landscape perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A variety of recent works, spanning pruning, lottery tickets, and training\nwithin random subspaces, have shown that deep neural networks can be trained\nusing far fewer degrees of freedom than the total number of parameters. We\nexplain this phenomenon by first examining the success probability of hitting a\ntraining loss sub-level set when training within a random subspace of a given\ntraining dimensionality. We find a sharp phase transition in the success\nprobability from $0$ to $1$ as the training dimension surpasses a threshold.\nThis threshold training dimension increases as the desired final loss\ndecreases, but decreases as the initial loss decreases. We then theoretically\nexplain the origin of this phase transition, and its dependence on\ninitialization and final desired loss, in terms of precise properties of the\nhigh dimensional geometry of the loss landscape. In particular, we show via\nGordon's escape theorem, that the training dimension plus the Gaussian width of\nthe desired loss sub-level set, projected onto a unit sphere surrounding the\ninitialization, must exceed the total number of parameters for the success\nprobability to be large. In several architectures and datasets, we measure the\nthreshold training dimension as a function of initialization and demonstrate\nthat it is a small fraction of the total number of parameters, thereby\nimplying, by our theory, that successful training with so few dimensions is\npossible precisely because the Gaussian width of low loss sub-level sets is\nvery large. Moreover, this threshold training dimension provides a strong null\nmodel for assessing the efficacy of more sophisticated ways to reduce training\ndegrees of freedom, including lottery tickets as well a more optimal method we\nintroduce: lottery subspaces.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:29:24 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Larsen", "Brett W.", ""], ["Fort", "Stanislav", ""], ["Becker", "Nic", ""], ["Ganguli", "Surya", ""]]}, {"id": "2107.05804", "submitter": "Zhongzhan Huang", "authors": "Zhongzhan Huang, Mingfu Liang, Senwei Liang, Wei He", "title": "AlterSGD: Finding Flat Minima for Continual Learning by Alternative\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks suffer from catastrophic forgetting when learning\nmultiple knowledge sequentially, and a growing number of approaches have been\nproposed to mitigate this problem. Some of these methods achieved considerable\nperformance by associating the flat local minima with forgetting mitigation in\ncontinual learning. However, they inevitably need (1) tedious hyperparameters\ntuning, and (2) additional computational cost. To alleviate these problems, in\nthis paper, we propose a simple yet effective optimization method, called\nAlterSGD, to search for a flat minima in the loss landscape. In AlterSGD, we\nconduct gradient descent and ascent alternatively when the network tends to\nconverge at each session of learning new knowledge. Moreover, we theoretically\nprove that such a strategy can encourage the optimization to converge to a flat\nminima. We verify AlterSGD on continual learning benchmark for semantic\nsegmentation and the empirical results show that we can significantly mitigate\nthe forgetting and outperform the state-of-the-art methods with a large margin\nunder challenging continual learning protocols.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:43:51 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Huang", "Zhongzhan", ""], ["Liang", "Mingfu", ""], ["Liang", "Senwei", ""], ["He", "Wei", ""]]}, {"id": "2107.05818", "submitter": "Kenneth Bogert", "authors": "Kenneth Bogert (University of North Carolina Asheville) and Prashant\n  Doshi (University of Georgia)", "title": "A Hierarchical Bayesian model for Inverse RL in Partially-Controlled\n  Environments", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robots learning from observations in the real world using inverse\nreinforcement learning (IRL) may encounter objects or agents in the\nenvironment, other than the expert, that cause nuisance observations during the\ndemonstration. These confounding elements are typically removed in\nfully-controlled environments such as virtual simulations or lab settings. When\ncomplete removal is impossible the nuisance observations must be filtered out.\nHowever, identifying the source of observations when large amounts of\nobservations are made is difficult. To address this, we present a hierarchical\nBayesian model that incorporates both the expert's and the confounding\nelements' observations thereby explicitly modeling the diverse observations a\nrobot may receive. We extend an existing IRL algorithm originally designed to\nwork under partial occlusion of the expert to consider the diverse\nobservations. In a simulated robotic sorting domain containing both occlusion\nand confounding elements, we demonstrate the model's effectiveness. In\nparticular, our technique outperforms several other comparative methods, second\nonly to having perfect knowledge of the subject's trajectory.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 02:38:14 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bogert", "Kenneth", "", "University of North Carolina Asheville"], ["Doshi", "Prashant", "", "University of Georgia"]]}, {"id": "2107.05825", "submitter": "Faraz Torabi", "authors": "Ruohan Zhang, Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Recent Advances in Leveraging Human Guidance for Sequential\n  Decision-Making Tasks", "comments": "Springer journal, Autonomous Agents and Multi-Agent Systems (JAAMAS)", "journal-ref": "JAAMAS 35 (2021) 1-39", "doi": "10.1007/s10458-021-09514-w", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A longstanding goal of artificial intelligence is to create artificial agents\ncapable of learning to perform tasks that require sequential decision making.\nImportantly, while it is the artificial agent that learns and acts, it is still\nup to humans to specify the particular task to be performed. Classical\ntask-specification approaches typically involve humans providing stationary\nreward functions or explicit demonstrations of the desired tasks. However,\nthere has recently been a great deal of research energy invested in exploring\nalternative ways in which humans may guide learning agents that may, e.g., be\nmore suitable for certain tasks or require less human effort. This survey\nprovides a high-level overview of five recent machine learning frameworks that\nprimarily rely on human guidance apart from pre-specified reward functions or\nconventional, step-by-step action demonstrations. We review the motivation,\nassumptions, and implementation of each framework, and we discuss possible\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 03:11:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhang", "Ruohan", ""], ["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "2107.05834", "submitter": "Jingyi Zhang", "authors": "Jingyi Zhang and Xiaoxiao Sun", "title": "Oversampling Divide-and-conquer for Response-skewed Kernel Ridge\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The divide-and-conquer method has been widely used for estimating large-scale\nkernel ridge regression estimates. Unfortunately, when the response variable is\nhighly skewed, the divide-and-conquer kernel ridge regression (dacKRR) may\noverlook the underrepresented region and result in unacceptable results. We\ndevelop a novel response-adaptive partition strategy to overcome the\nlimitation. In particular, we propose to allocate the replicates of some\ncarefully identified informative observations to multiple nodes (local\nprocessors). The idea is analogous to the popular oversampling technique.\nAlthough such a technique has been widely used for addressing discrete label\nskewness, extending it to the dacKRR setting is nontrivial. We provide both\ntheoretical and practical guidance on how to effectively over-sample the\nobservations under the dacKRR setting. Furthermore, we show the proposed\nestimate has a smaller asymptotic mean squared error (AMSE) than that of the\nclassical dacKRR estimate under mild conditions. Our theoretical findings are\nsupported by both simulated and real-data analyses.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 04:01:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhang", "Jingyi", ""], ["Sun", "Xiaoxiao", ""]]}, {"id": "2107.05842", "submitter": "Takayuki Osa", "authors": "Takayuki Osa", "title": "Motion Planning by Learning the Solution Manifold in Trajectory\n  Optimization", "comments": "24 pages, to appear in the International Journal of Robotics Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective function used in trajectory optimization is often non-convex\nand can have an infinite set of local optima. In such cases, there are diverse\nsolutions to perform a given task. Although there are a few methods to find\nmultiple solutions for motion planning, they are limited to generating a finite\nset of solutions. To address this issue, we presents an optimization method\nthat learns an infinite set of solutions in trajectory optimization. In our\nframework, diverse solutions are obtained by learning latent representations of\nsolutions. Our approach can be interpreted as training a deep generative model\nof collision-free trajectories for motion planning. The experimental results\nindicate that the trained model represents an infinite set of homotopic\nsolutions for motion planning problems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 04:47:47 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Osa", "Takayuki", ""]]}, {"id": "2107.05847", "submitter": "Martin Binder", "authors": "Bernd Bischl, Martin Binder, Michel Lang, Tobias Pielok, Jakob\n  Richter, Stefan Coors, Janek Thomas, Theresa Ullmann, Marc Becker, Anne-Laure\n  Boulesteix, Difan Deng, Marius Lindauer", "title": "Hyperparameter Optimization: Foundations, Algorithms, Best Practices and\n  Open Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most machine learning algorithms are configured by one or several\nhyperparameters that must be carefully chosen and often considerably impact\nperformance. To avoid a time consuming and unreproducible manual\ntrial-and-error process to find well-performing hyperparameter configurations,\nvarious automatic hyperparameter optimization (HPO) methods, e.g., based on\nresampling error estimation for supervised machine learning, can be employed.\nAfter introducing HPO from a general perspective, this paper reviews important\nHPO methods such as grid or random search, evolutionary algorithms, Bayesian\noptimization, Hyperband and racing. It gives practical recommendations\nregarding important choices to be made when conducting HPO, including the HPO\nalgorithms themselves, performance evaluation, how to combine HPO with ML\npipelines, runtime improvements, and parallelization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 04:55:47 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 22:34:27 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bischl", "Bernd", ""], ["Binder", "Martin", ""], ["Lang", "Michel", ""], ["Pielok", "Tobias", ""], ["Richter", "Jakob", ""], ["Coors", "Stefan", ""], ["Thomas", "Janek", ""], ["Ullmann", "Theresa", ""], ["Becker", "Marc", ""], ["Boulesteix", "Anne-Laure", ""], ["Deng", "Difan", ""], ["Lindauer", "Marius", ""]]}, {"id": "2107.05849", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Sayak Ray Chowdhury and Kannan Ramchandran", "title": "Model Selection with Near Optimal Rates for Reinforcement Learning with\n  General Model Classes", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of model selection for the finite horizon episodic\nReinforcement Learning (RL) problem where the transition kernel $P^*$ belongs\nto a family of models $\\mathcal{P}^*$ with finite metric entropy. In the model\nselection framework, instead of $\\mathcal{P}^*$, we are given $M$ nested\nfamilies of transition kernels $\\cP_1 \\subset \\cP_2 \\subset \\ldots \\subset\n\\cP_M$. We propose and analyze a novel algorithm, namely \\emph{Adaptive\nReinforcement Learning (General)} (\\texttt{ARL-GEN}) that adapts to the\nsmallest such family where the true transition kernel $P^*$ lies.\n\\texttt{ARL-GEN} uses the Upper Confidence Reinforcement Learning\n(\\texttt{UCRL}) algorithm with value targeted regression as a blackbox and puts\na model selection module at the beginning of each epoch. Under a mild\nseparability assumption on the model classes, we show that \\texttt{ARL-GEN}\nobtains a regret of\n$\\Tilde{\\mathcal{O}}(d_{\\mathcal{E}}^*H^2+\\sqrt{d_{\\mathcal{E}}^* \\mathbb{M}^*\nH^2 T})$, with high probability, where $H$ is the horizon length, $T$ is the\ntotal number of steps, $d_{\\mathcal{E}}^*$ is the Eluder dimension and\n$\\mathbb{M}^*$ is the metric entropy corresponding to $\\mathcal{P}^*$. Note\nthat this regret scaling matches that of an oracle that knows $\\mathcal{P}^*$\nin advance. We show that the cost of model selection for \\texttt{ARL-GEN} is an\nadditive term in the regret having a weak dependence on $T$. Subsequently, we\nremove the separability assumption and consider the setup of linear mixture\nMDPs, where the transition kernel $P^*$ has a linear function approximation.\nWith this low rank structure, we propose novel adaptive algorithms for model\nselection, and obtain (order-wise) regret identical to that of an oracle with\nknowledge of the true model class.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 05:00:38 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ghosh", "Avishek", ""], ["Chowdhury", "Sayak Ray", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2107.05855", "submitter": "Chiheon Kim", "authors": "Chiheon Kim, Saehoon Kim, Jongmin Kim, Donghoon Lee, Sungwoong Kim", "title": "Automated Learning Rate Scheduler for Large-batch Training", "comments": "15 pages, 7 figures, 4 tables, 8th ICML Workshop on Automated Machine\n  Learning (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-batch training has been essential in leveraging large-scale datasets\nand models in deep learning. While it is computationally beneficial to use\nlarge batch sizes, it often requires a specially designed learning rate (LR)\nschedule to achieve a comparable level of performance as in smaller batch\ntraining. Especially, when the number of training epochs is constrained, the\nuse of a large LR and a warmup strategy is critical in the final performance of\nlarge-batch training due to the reduced number of updating steps. In this work,\nwe propose an automated LR scheduling algorithm which is effective for neural\nnetwork training with a large batch size under the given epoch budget. In\nspecific, the whole schedule consists of two phases: adaptive warmup and\npredefined decay, where the LR is increased until the training loss no longer\ndecreases and decreased to zero until the end of training. Here, whether the\ntraining loss has reached the minimum value is robustly checked with Gaussian\nprocess smoothing in an online manner with a low computational burden. Coupled\nwith adaptive stochastic optimizers such as AdamP and LAMB, the proposed\nscheduler successfully adjusts the LRs without cumbersome hyperparameter tuning\nand achieves comparable or better performances than tuned baselines on various\nimage classification benchmarks and architectures with a wide range of batch\nsizes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 05:23:13 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kim", "Chiheon", ""], ["Kim", "Saehoon", ""], ["Kim", "Jongmin", ""], ["Lee", "Donghoon", ""], ["Kim", "Sungwoong", ""]]}, {"id": "2107.05884", "submitter": "Junkun Yuan", "authors": "Junkun Yuan, Anpeng Wu, Kun Kuang, Bo Li, Runze Wu, Fei Wu, Lanfen Lin", "title": "Auto IV: Counterfactual Prediction via Automatic Instrumental Variable\n  Decomposition", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Instrumental variables (IVs), sources of treatment randomization that are\nconditionally independent of the outcome, play an important role in causal\ninference with unobserved confounders. However, the existing IV-based\ncounterfactual prediction methods need well-predefined IVs, while it's an art\nrather than science to find valid IVs in many real-world scenes. Moreover, the\npredefined hand-made IVs could be weak or erroneous by violating the conditions\nof valid IVs. These thorny facts hinder the application of the IV-based\ncounterfactual prediction methods. In this paper, we propose a novel Automatic\nInstrumental Variable decomposition (AutoIV) algorithm to automatically\ngenerate representations serving the role of IVs from observed variables (IV\ncandidates). Specifically, we let the learned IV representations satisfy the\nrelevance condition with the treatment and exclusion condition with the outcome\nvia mutual information maximization and minimization constraints, respectively.\nWe also learn confounder representations by encouraging them to be relevant to\nboth the treatment and the outcome. The IV and confounder representations\ncompete for the information with their constraints in an adversarial game,\nwhich allows us to get valid IV representations for IV-based counterfactual\nprediction. Extensive experiments demonstrate that our method generates valid\nIV representations for accurate IV-based counterfactual prediction.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 07:30:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Yuan", "Junkun", ""], ["Wu", "Anpeng", ""], ["Kuang", "Kun", ""], ["Li", "Bo", ""], ["Wu", "Runze", ""], ["Wu", "Fei", ""], ["Lin", "Lanfen", ""]]}, {"id": "2107.05885", "submitter": "Chao Feng", "authors": "Chao Feng, Shi-jie We", "title": "Exploiting Network Structures to Improve Semantic Representation for the\n  Financial Domain", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents the participation of the MiniTrue team in the FinSim-3\nshared task on learning semantic similarities for the financial domain in\nEnglish language. Our approach combines contextual embeddings learned by\ntransformer-based language models with network structures embeddings extracted\non external knowledge sources, to create more meaningful representations of\nfinancial domain entities and terms. For this, two BERT based language models\nand a knowledge graph embedding model are used. Besides, we propose a voting\nfunction to joint three basic models for the final inference. Experimental\nresults show that the model with the knowledge graph embeddings has achieved a\nsuperior result than these models with only contextual embeddings.\nNevertheless, we also observe that our voting function brings an extra benefit\nto the final system.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 07:32:18 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Feng", "Chao", ""], ["We", "Shi-jie", ""]]}, {"id": "2107.05901", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "Fast approximations of the Jeffreys divergence between univariate\n  Gaussian mixture models via exponential polynomial densities", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jeffreys divergence is a renown symmetrization of the statistical\nKullback-Leibler divergence which is often used in machine learning, signal\nprocessing, and information sciences. Since the Jeffreys divergence between the\nubiquitous Gaussian Mixture Models are not available in closed-form, many\ntechniques with various pros and cons have been proposed in the literature to\neither (i) estimate, (ii) approximate, or (iii) lower and upper bound this\ndivergence. In this work, we propose a simple yet fast heuristic to approximate\nthe Jeffreys divergence between two GMMs of arbitrary number of components. The\nheuristic relies on converting GMMs into pairs of dually parameterized\nprobability densities belonging to exponential families. In particular, we\nconsider Polynomial Exponential Densities, and design a goodness-of-fit\ncriterion to measure the dissimilarity between a GMM and a PED which is a\ngeneralization of the Hyv\\\"arinen divergence. This criterion allows one to\nselect the orders of the PEDs to approximate the GMMs. We demonstrate\nexperimentally that the computational time of our heuristic improves over the\nstochastic Monte Carlo estimation baseline by several orders of magnitude while\napproximating reasonably well the Jeffreys divergence, specially when the\nunivariate mixtures have a small number of modes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 07:58:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "2107.05908", "submitter": "Zhuangbin Chen", "authors": "Zhuangbin Chen, Jinyang Liu, Wenwei Gu, Yuxin Su, and Michael R. Lyu", "title": "Experience Report: Deep Learning-based System Log Analysis for Anomaly\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Logs have been an imperative resource to ensure the reliability and\ncontinuity of many software systems, especially large-scale distributed\nsystems. They faithfully record runtime information to facilitate system\ntroubleshooting and behavior understanding. Due to the large scale and\ncomplexity of modern software systems, the volume of logs has reached an\nunprecedented level. Consequently, for log-based anomaly detection,\nconventional methods of manual inspection or even traditional machine\nlearning-based methods become impractical, which serve as a catalyst for the\nrapid development of deep learning-based solutions. However, there is currently\na lack of rigorous comparison among the representative log-based anomaly\ndetectors which resort to neural network models. Moreover, the\nre-implementation process demands non-trivial efforts and bias can be easily\nintroduced. To better understand the characteristics of different anomaly\ndetectors, in this paper, we provide a comprehensive review and evaluation on\nfive popular models used by six state-of-the-art methods. Particularly, four of\nthe selected methods are unsupervised and the remaining two are supervised.\nThese methods are evaluated with two publicly-available log datasets, which\ncontain nearly 16 millions log messages and 0.4 million anomaly instances in\ntotal. We believe our work can serve as a basis in this field and contribute to\nthe future academic researches and industrial applications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:10:47 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chen", "Zhuangbin", ""], ["Liu", "Jinyang", ""], ["Gu", "Wenwei", ""], ["Su", "Yuxin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "2107.05911", "submitter": "Yang Liu", "authors": "Yang Liu, Yatong Chen, Jiaheng Wei", "title": "Induced Domain Adaptation", "comments": "Preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We formulate the problem of induced domain adaptation (IDA) when the\nunderlying distribution/domain shift is introduced by the model being deployed.\nOur formulation is motivated by applications where the deployed machine\nlearning models interact with human agents, and will ultimately face responsive\nand interactive data distributions. We formalize the discussions of the\ntransferability of learning in our IDA setting by studying how the model\ntrained on the available source distribution (data) would translate to the\nperformance on the induced domain. We provide both upper bounds for the\nperformance gap due to the induced domain shift, as well as lower bound for the\ntrade-offs a classifier has to suffer on either the source training\ndistribution or the induced target distribution. We provide further\ninstantiated analysis for two popular domain adaptation settings with covariate\nshift and label shift. We highlight some key properties of IDA, as well as\ncomputational and learning challenges.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:21:37 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Yatong", ""], ["Wei", "Jiaheng", ""]]}, {"id": "2107.05913", "submitter": "Yang Liu", "authors": "Yang Liu and Jialu Wang", "title": "Can Less be More? When Increasing-to-Balancing Label Noise Rates\n  Considered Beneficial", "comments": "Preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we answer the question when inserting label noise (less\ninformative labels) can instead return us more accurate and fair models. We are\nprimarily inspired by two observations that 1) increasing a certain class of\ninstances' label noise to balance the noise rates (increasing-to-balancing)\nresults in an easier learning problem; 2) Increasing-to-balancing improves\nfairness guarantees against label bias. In this paper, we will first quantify\nthe trade-offs introduced by increasing a certain group of instances' label\nnoise rate w.r.t. the learning difficulties and performance guarantees. We\nanalytically demonstrate when such an increase proves to be beneficial, in\nterms of either improved generalization errors or the fairness guarantees. Then\nwe present a method to leverage our idea of inserting label noise for the task\nof learning with noisy labels, either without or with a fairness constraint.\nThe primary technical challenge we face is due to the fact that we would not\nknow which data instances are suffering from higher noise, and we would not\nhave the ground truth labels to verify any possible hypothesis. We propose a\ndetection method that informs us which group of labels might suffer from higher\nnoise, without using ground truth information. We formally establish the\neffectiveness of the proposed solution and demonstrate it with extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:31:57 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liu", "Yang", ""], ["Wang", "Jialu", ""]]}, {"id": "2107.05916", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong, Chris Donahue, Taylor Berg-Kirkpatrick, Julian McAuley", "title": "Towards Automatic Instrumentation by Learning to Separate Parts in\n  Symbolic Multitrack Music", "comments": "Accepted to ISMIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern keyboards allow a musician to play multiple instruments at the same\ntime by assigning zones -- fixed pitch ranges of the keyboard -- to different\ninstruments. In this paper, we aim to further extend this idea and examine the\nfeasibility of automatic instrumentation -- dynamically assigning instruments\nto notes in solo music during performance. In addition to the online,\nreal-time-capable setting for performative use cases, automatic instrumentation\ncan also find applications in assistive composing tools in an offline setting.\nDue to the lack of paired data of original solo music and their full\narrangements, we approach automatic instrumentation by learning to separate\nparts (e.g., voices, instruments and tracks) from their mixture in symbolic\nmultitrack music, assuming that the mixture is to be played on a keyboard. We\nframe the task of part separation as a sequential multi-class classification\nproblem and adopt machine learning to map sequences of notes into sequences of\npart labels. To examine the effectiveness of our proposed models, we conduct a\ncomprehensive empirical evaluation over four diverse datasets of different\ngenres and ensembles -- Bach chorales, string quartets, game music and pop\nmusic. Our experiments show that the proposed models outperform various\nbaselines. We also demonstrate the potential for our proposed models to produce\nalternative convincing instrumentations for an existing arrangement by\nseparating its mixture into parts. All source code and audio samples can be\nfound at https://salu133445.github.io/arranger/ .\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:34:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Donahue", "Chris", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["McAuley", "Julian", ""]]}, {"id": "2107.05917", "submitter": "Chuanqiang Shan", "authors": "Chuanqiang Shan, Huiyun Jiao, Jie Fu", "title": "Towards Representation Identical Privacy-Preserving Graph Neural Network\n  via Split Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, the fast rise in number of studies on graph neural network\n(GNN) has put it from the theories research to reality application stage.\nDespite the encouraging performance achieved by GNN, less attention has been\npaid to the privacy-preserving training and inference over distributed graph\ndata in the related literature. Due to the particularity of graph structure, it\nis challenging to extend the existing private learning framework to GNN.\nMotivated by the idea of split learning, we propose a \\textbf{S}erver\n\\textbf{A}ided \\textbf{P}rivacy-preserving \\textbf{GNN} (SAPGNN) for the node\nlevel task on horizontally partitioned cross-silo scenario. It offers a natural\nextension of centralized GNN to isolated graph with max/min pooling\naggregation, while guaranteeing that all the private data involved in\ncomputation still stays at local data holders. To further enhancing the data\nprivacy, a secure pooling aggregation mechanism is proposed. Theoretical and\nexperimental results show that the proposed model achieves the same accuracy as\nthe one learned over the combined data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 08:35:43 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Shan", "Chuanqiang", ""], ["Jiao", "Huiyun", ""], ["Fu", "Jie", ""]]}, {"id": "2107.05941", "submitter": "Junhyung Kim", "authors": "Junhyung Kim, Byungyoon Park, Charmgil Hong", "title": "Multi-Scale Label Relation Learning for Multi-Label Classification Using\n  1-Dimensional Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Multi-Scale Label Dependence Relation Networks (MSDN), a novel\napproach to multi-label classification (MLC) using 1-dimensional convolution\nkernels to learn label dependencies at multi-scale. Modern multi-label\nclassifiers have been adopting recurrent neural networks (RNNs) as a memory\nstructure to capture and exploit label dependency relations. The RNN-based MLC\nmodels however tend to introduce a very large number of parameters that may\ncause under-/over-fitting problems. The proposed method uses the 1-dimensional\nconvolutional neural network (1D-CNN) to serve the same purpose in a more\nefficient manner. By training a model with multiple kernel sizes, the method is\nable to learn the dependency relations among labels at multiple scales, while\nit uses a drastically smaller number of parameters. With public benchmark\ndatasets, we demonstrate that our model can achieve better accuracies with much\nsmaller number of model parameters compared to RNN-based MLC models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:26:34 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kim", "Junhyung", ""], ["Park", "Byungyoon", ""], ["Hong", "Charmgil", ""]]}, {"id": "2107.05948", "submitter": "Qinglin Li", "authors": "Qinglin Li, Bin Li, Jonathan M Garibaldi, Guoping Qiu", "title": "On Designing Good Representation Learning Models", "comments": "15 pages,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of representation learning is different from the ultimate objective\nof machine learning such as decision making, it is therefore very difficult to\nestablish clear and direct objectives for training representation learning\nmodels. It has been argued that a good representation should disentangle the\nunderlying variation factors, yet how to translate this into training\nobjectives remains unknown. This paper presents an attempt to establish direct\ntraining criterions and design principles for developing good representation\nlearning models. We propose that a good representation learning model should be\nmaximally expressive, i.e., capable of distinguishing the maximum number of\ninput configurations. We formally define expressiveness and introduce the\nmaximum expressiveness (MEXS) theorem of a general learning model. We propose\nto train a model by maximizing its expressiveness while at the same time\nincorporating general priors such as model smoothness. We present a conscience\ncompetitive learning algorithm which encourages the model to reach its MEXS\nwhilst at the same time adheres to model smoothness prior. We also introduce a\nlabel consistent training (LCT) technique to boost model smoothness by\nencouraging it to assign consistent labels to similar samples. We present\nextensive experimental results to show that our method can indeed design\nrepresentation learning models capable of developing representations that are\nas good as or better than state of the art. We also show that our technique is\ncomputationally efficient, robust against different parameter settings and can\nwork effectively on a variety of datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:39:43 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Qinglin", ""], ["Li", "Bin", ""], ["Garibaldi", "Jonathan M", ""], ["Qiu", "Guoping", ""]]}, {"id": "2107.05975", "submitter": "Camila Gonzalez", "authors": "Camila Gonzalez, Karol Gotkowski, Andreas Bucher, Ricarda Fischbach,\n  Isabel Kaltenborn, Anirban Mukhopadhyay", "title": "Detecting when pre-trained nnU-Net models fail silently for Covid-19\n  lung lesion segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic segmentation of lung lesions in computer tomography has the\npotential to ease the burden of clinicians during the Covid-19 pandemic. Yet\npredictive deep learning models are not trusted in the clinical routine due to\nfailing silently in out-of-distribution (OOD) data. We propose a lightweight\nOOD detection method that exploits the Mahalanobis distance in the feature\nspace. The proposed approach can be seamlessly integrated into state-of-the-art\nsegmentation pipelines without requiring changes in model architecture or\ntraining procedure, and can therefore be used to assess the suitability of\npre-trained models to new data. We validate our method with a patch-based\nnnU-Net architecture trained with a multi-institutional dataset and find that\nit effectively detects samples that the model segments incorrectly.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 10:48:08 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 11:45:47 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Gonzalez", "Camila", ""], ["Gotkowski", "Karol", ""], ["Bucher", "Andreas", ""], ["Fischbach", "Ricarda", ""], ["Kaltenborn", "Isabel", ""], ["Mukhopadhyay", "Anirban", ""]]}, {"id": "2107.05978", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Isabel Chien, Muhammad Bilal Zafar, Adrian Weller", "title": "DIVINE: Diverse Influential Training Points for Data Visualization and\n  Model Refinement", "comments": "30 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of machine learning (ML) models increases, resulting in a\nlack of prediction explainability, several methods have been developed to\nexplain a model's behavior in terms of the training data points that most\ninfluence the model. However, these methods tend to mark outliers as highly\ninfluential points, limiting the insights that practitioners can draw from\npoints that are not representative of the training data. In this work, we take\na step towards finding influential training points that also represent the\ntraining data well. We first review methods for assigning importance scores to\ntraining points. Given importance scores, we propose a method to select a set\nof DIVerse INfluEntial (DIVINE) training points as a useful explanation of\nmodel behavior. As practitioners might not only be interested in finding data\npoints influential with respect to model accuracy, but also with respect to\nother important metrics, we show how to evaluate training data points on the\nbasis of group fairness. Our method can identify unfairness-inducing training\npoints, which can be removed to improve fairness outcomes. Our quantitative\nexperiments and user studies show that visualizing DIVINE points helps\npractitioners understand and explain model behavior better than earlier\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 10:50:58 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bhatt", "Umang", ""], ["Chien", "Isabel", ""], ["Zafar", "Muhammad Bilal", ""], ["Weller", "Adrian", ""]]}, {"id": "2107.05984", "submitter": "Fernando Moreno-Pino", "authors": "Fernando Moreno-Pino, Pablo M. Olmos and Antonio Art\\'es-Rodr\\'iguez", "title": "Deep Autoregressive Models with Spectral Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is an important problem across many domains, playing\na crucial role in multiple real-world applications. In this paper, we propose a\nforecasting architecture that combines deep autoregressive models with a\nSpectral Attention (SA) module, which merges global and local frequency domain\ninformation in the model's embedded space. By characterizing in the spectral\ndomain the embedding of the time series as occurrences of a random process, our\nmethod can identify global trends and seasonality patterns. Two spectral\nattention models, global and local to the time series, integrate this\ninformation within the forecast and perform spectral filtering to remove time\nseries's noise. The proposed architecture has a number of useful properties: it\ncan be effectively incorporated into well-know forecast architectures,\nrequiring a low number of parameters and producing interpretable results that\nimprove forecasting accuracy. We test the Spectral Attention Autoregressive\nModel (SAAM) on several well-know forecast datasets, consistently demonstrating\nthat our model compares favorably to state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:08:47 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Moreno-Pino", "Fernando", ""], ["Olmos", "Pablo M.", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "2107.05989", "submitter": "Marwan Dhuheir", "authors": "Marwan Dhuheir, Abdullatif Albaseer, Emna Baccour, Aiman Erbad,\n  Mohamed Abdallah, and Mounir Hamdi", "title": "Emotion Recognition for Healthcare Surveillance Systems Using Neural\n  Networks: A Survey", "comments": "conference paper accepted and presented at 17th Int. Wireless\n  Communications & Mobile Computing Conference - IWCMC 2021, Harbin, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing the patient's emotions using deep learning techniques has\nattracted significant attention recently due to technological advancements.\nAutomatically identifying the emotions can help build smart healthcare centers\nthat can detect depression and stress among the patients in order to start the\nmedication early. Using advanced technology to identify emotions is one of the\nmost exciting topics as it defines the relationships between humans and\nmachines. Machines learned how to predict emotions by adopting various methods.\nIn this survey, we present recent research in the field of using neural\nnetworks to recognize emotions. We focus on studying emotions' recognition from\nspeech, facial expressions, and audio-visual input and show the different\ntechniques of deploying these algorithms in the real world. These three emotion\nrecognition techniques can be used as a surveillance system in healthcare\ncenters to monitor patients. We conclude the survey with a presentation of the\nchallenges and the related future work to provide an insight into the\napplications of using emotion recognition.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:17:00 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dhuheir", "Marwan", ""], ["Albaseer", "Abdullatif", ""], ["Baccour", "Emna", ""], ["Erbad", "Aiman", ""], ["Abdallah", "Mohamed", ""], ["Hamdi", "Mounir", ""]]}, {"id": "2107.05990", "submitter": "Sebastian P\\\"olsterl", "authors": "Sebastian P\\\"olsterl and Tom Nuno Wolf and Christian Wachinger", "title": "Combining 3D Image and Tabular Data via the Dynamic Affine Feature Map\n  Transform", "comments": "Accepted at 2021 International Conference on Medical Image Computing\n  and Computer Assisted Intervention (MICCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior work on diagnosing Alzheimer's disease from magnetic resonance images\nof the brain established that convolutional neural networks (CNNs) can leverage\nthe high-dimensional image information for classifying patients. However,\nlittle research focused on how these models can utilize the usually\nlow-dimensional tabular information, such as patient demographics or laboratory\nmeasurements. We introduce the Dynamic Affine Feature Map Transform (DAFT), a\ngeneral-purpose module for CNNs that dynamically rescales and shifts the\nfeature maps of a convolutional layer, conditional on a patient's tabular\nclinical information. We show that DAFT is highly effective in combining 3D\nimage and tabular information for diagnosis and time-to-dementia prediction,\nwhere it outperforms competing CNNs with a mean balanced accuracy of 0.622 and\nmean c-index of 0.748, respectively. Our extensive ablation study provides\nvaluable insights into the architectural properties of DAFT. Our implementation\nis available at https://github.com/ai-med/DAFT.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:18:22 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["P\u00f6lsterl", "Sebastian", ""], ["Wolf", "Tom Nuno", ""], ["Wachinger", "Christian", ""]]}, {"id": "2107.05991", "submitter": "Narges Gholipoor", "authors": "Narges Gholipoor, Ali Nouruzi, Shima Salarhosseini, Mohammad Reza\n  Javan, Nader Mokari, and Eduard A. Jorswieck", "title": "Learning based E2E Energy Efficient in Joint Radio and NFV Resource\n  Allocation for 5G and Beyond Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a joint radio and core resource allocation\nframework for NFV-enabled networks. In the proposed system model, the goal is\nto maximize energy efficiency (EE), by guaranteeing end-to-end (E2E) quality of\nservice (QoS) for different service types. To this end, we formulate an\noptimization problem in which power and spectrum resources are allocated in the\nradio part. In the core part, the chaining, placement, and scheduling of\nfunctions are performed to ensure the QoS of all users. This joint optimization\nproblem is modeled as a Markov decision process (MDP), considering time-varying\ncharacteristics of the available resources and wireless channels. A soft\nactor-critic deep reinforcement learning (SAC-DRL) algorithm based on the\nmaximum entropy framework is subsequently utilized to solve the above MDP.\nNumerical results reveal that the proposed joint approach based on the SAC-DRL\nalgorithm could significantly reduce energy consumption compared to the case in\nwhich R-RA and NFV-RA problems are optimized separately.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:19:48 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Gholipoor", "Narges", ""], ["Nouruzi", "Ali", ""], ["Salarhosseini", "Shima", ""], ["Javan", "Mohammad Reza", ""], ["Mokari", "Nader", ""], ["Jorswieck", "Eduard A.", ""]]}, {"id": "2107.05997", "submitter": "Sebastian P\\\"olsterl", "authors": "Sebastian P\\\"olsterl and Christina Aigner and Christian Wachinger", "title": "Scalable, Axiomatic Explanations of Deep Alzheimer's Diagnosis from\n  Heterogeneous Data", "comments": "Accepted at 2021 International Conference on Medical Image Computing\n  and Computer Assisted Intervention (MICCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have an enormous potential to learn from complex\nbiomedical data. In particular, DNNs have been used to seamlessly fuse\nheterogeneous information from neuroanatomy, genetics, biomarkers, and\nneuropsychological tests for highly accurate Alzheimer's disease diagnosis. On\nthe other hand, their black-box nature is still a barrier for the adoption of\nsuch a system in the clinic, where interpretability is absolutely essential. We\npropose Shapley Value Explanation of Heterogeneous Neural Networks (SVEHNN) for\nexplaining the Alzheimer's diagnosis made by a DNN from the 3D point cloud of\nthe neuroanatomy and tabular biomarkers. Our explanations are based on the\nShapley value, which is the unique method that satisfies all fundamental axioms\nfor local explanations previously established in the literature. Thus, SVEHNN\nhas many desirable characteristics that previous work on interpretability for\nmedical decision making is lacking. To avoid the exponential time complexity of\nthe Shapley value, we propose to transform a given DNN into a Lightweight\nProbabilistic Deep Network without re-training, thus achieving a complexity\nonly quadratic in the number of features. In our experiments on synthetic and\nreal data, we show that we can closely approximate the exact Shapley value with\na dramatically reduced runtime and can reveal the hidden knowledge the network\nhas learned from the data.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:25:54 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["P\u00f6lsterl", "Sebastian", ""], ["Aigner", "Christina", ""], ["Wachinger", "Christian", ""]]}, {"id": "2107.06008", "submitter": "Samuel Rikli", "authors": "Rikli Samuel, Bigler Daniel Nico, Pfenninger Moritz, Osterrieder Joerg", "title": "Wasserstein GAN: Deep Generation applied on Bitcoins financial time\n  series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling financial time series is challenging due to their high volatility\nand unexpected happenings on the market. Most financial models and algorithms\ntrying to fill the lack of historical financial time series struggle to perform\nand are highly vulnerable to overfitting. As an alternative, we introduce in\nthis paper a deep neural network called the WGAN-GP, a data-driven model that\nfocuses on sample generation. The WGAN-GP consists of a generator and\ndiscriminator function which utilize an LSTM architecture. The WGAN-GP is\nsupposed to learn the underlying structure of the input data, which in our\ncase, is the Bitcoin. Bitcoin is unique in its behavior; the prices fluctuate\nwhat makes guessing the price trend hardly impossible. Through adversarial\ntraining, the WGAN-GP should learn the underlying structure of the bitcoin and\ngenerate very similar samples of the bitcoin distribution. The generated\nsynthetic time series are visually indistinguishable from the real data. But\nthe numerical results show that the generated data were close to the real data\ndistribution but distinguishable. The model mainly shows a stable learning\nbehavior. However, the model has space for optimization, which could be\nachieved by adjusting the hyperparameters.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:59:05 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Samuel", "Rikli", ""], ["Nico", "Bigler Daniel", ""], ["Moritz", "Pfenninger", ""], ["Joerg", "Osterrieder", ""]]}, {"id": "2107.06011", "submitter": "Pierre Marza", "authors": "Pierre Marza, Laetitia Matignon, Olivier Simonin, Christian Wolf", "title": "Teaching Agents how to Map: Spatial Reasoning for Multi-Object\n  Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of visual navigation, the capacity to map a novel environment\nis necessary for an agent to exploit its observation history in the considered\nplace and efficiently reach known goals. This ability can be associated with\nspatial reasoning, where an agent is able to perceive spatial relationships and\nregularities, and discover object affordances. In classical Reinforcement\nLearning (RL) setups, this capacity is learned from reward alone. We introduce\nsupplementary supervision in the form of auxiliary tasks designed to favor the\nemergence of spatial perception capabilities in agents trained for a\ngoal-reaching downstream objective. We show that learning to estimate metrics\nquantifying the spatial relationships between an agent at a given location and\na goal to reach has a high positive impact in Multi-Object Navigation settings.\nOur method significantly improves the performance of different baseline agents,\nthat either build an explicit or implicit representation of the environment,\neven matching the performance of incomparable oracle agents taking ground-truth\nmaps as input.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:01:05 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Marza", "Pierre", ""], ["Matignon", "Laetitia", ""], ["Simonin", "Olivier", ""], ["Wolf", "Christian", ""]]}, {"id": "2107.06020", "submitter": "Veronica Sanz", "authors": "J. Hirn, J. E. Garc\\'ia, A. Montesinos-Navarro, R. Sanchez-Mart\\'in,\n  V. Sanz, M. Verd\\'u", "title": "A Deep Generative Artificial Intelligence system to decipher species\n  coexistence patterns", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.bio-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  1. Deciphering coexistence patterns is a current challenge to understanding\ndiversity maintenance, especially in rich communities where the complexity of\nthese patterns is magnified through indirect interactions that prevent their\napproximation with classical experimental approaches. 2. We explore\ncutting-edge Machine Learning techniques called Generative Artificial\nIntelligence (GenAI) to decipher species coexistence patterns in vegetation\npatches, training generative adversarial networks (GAN) and variational\nAutoEncoders (VAE) that are then used to unravel some of the mechanisms behind\ncommunity assemblage. 3. The GAN accurately reproduces the species composition\nof real patches as well as the affinity of plant species to different soil\ntypes, and the VAE also reaches a high level of accuracy, above 99%. Using the\nartificially generated patches, we found that high order interactions tend to\nsuppress the positive effects of low order interactions. Finally, by\nreconstructing successional trajectories we could identify the pioneer species\nwith larger potential to generate a high diversity of distinct patches in terms\nof species composition. 4. Understanding the complexity of species coexistence\npatterns in diverse ecological communities requires new approaches beyond\nheuristic rules. Generative Artificial Intelligence can be a powerful tool to\nthis end as it allows to overcome the inherent dimensionality of this\nchallenge.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:12:11 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Hirn", "J.", ""], ["Garc\u00eda", "J. E.", ""], ["Montesinos-Navarro", "A.", ""], ["Sanchez-Mart\u00edn", "R.", ""], ["Sanz", "V.", ""], ["Verd\u00fa", "M.", ""]]}, {"id": "2107.06039", "submitter": "Nan Liu", "authors": "Han Yuan, Feng Xie, Marcus Eng Hock Ong, Yilin Ning, Marcel Lucas\n  Chee, Seyed Ehsan Saffari, Hairil Rizal Abdullah, Benjamin Alan Goldstein,\n  Bibhas Chakraborty, Nan Liu", "title": "AutoScore-Imbalance: An interpretable machine learning tool for\n  development of clinical scores with rare events data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Medical decision-making impacts both individual and public\nhealth. Clinical scores are commonly used among a wide variety of\ndecision-making models for determining the degree of disease deterioration at\nthe bedside. AutoScore was proposed as a useful clinical score generator based\non machine learning and a generalized linear model. Its current framework,\nhowever, still leaves room for improvement when addressing unbalanced data of\nrare events. Methods: Using machine intelligence approaches, we developed\nAutoScore-Imbalance, which comprises three components: training dataset\noptimization, sample weight optimization, and adjusted AutoScore. All scoring\nmodels were evaluated on the basis of their area under the curve (AUC) in the\nreceiver operating characteristic analysis and balanced accuracy (i.e., mean\nvalue of sensitivity and specificity). By utilizing a publicly accessible\ndataset from Beth Israel Deaconess Medical Center, we assessed the proposed\nmodel and baseline approaches in the prediction of inpatient mortality.\nResults: AutoScore-Imbalance outperformed baselines in terms of AUC and\nbalanced accuracy. The nine-variable AutoScore-Imbalance sub-model achieved the\nhighest AUC of 0.786 (0.732-0.839) while the eleven-variable original AutoScore\nobtained an AUC of 0.723 (0.663-0.783), and the logistic regression with 21\nvariables obtained an AUC of 0.743 (0.685-0.800). The AutoScore-Imbalance\nsub-model (using down-sampling algorithm) yielded an AUC of 0. 0.771\n(0.718-0.823) with only five variables, demonstrating a good balance between\nperformance and variable sparsity. Conclusions: The AutoScore-Imbalance tool\nhas the potential to be applied to highly unbalanced datasets to gain further\ninsight into rare medical events and to facilitate real-world clinical\ndecision-making.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:49:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Yuan", "Han", ""], ["Xie", "Feng", ""], ["Ong", "Marcus Eng Hock", ""], ["Ning", "Yilin", ""], ["Chee", "Marcel Lucas", ""], ["Saffari", "Seyed Ehsan", ""], ["Abdullah", "Hairil Rizal", ""], ["Goldstein", "Benjamin Alan", ""], ["Chakraborty", "Bibhas", ""], ["Liu", "Nan", ""]]}, {"id": "2107.06048", "submitter": "Xue Liu", "authors": "Xue Liu, Dan Sun, Wei Wei", "title": "A Graph Data Augmentation Strategy with Entropy Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Graph Convolutional Networks (GCNs) proposed by Kipf and Welling are\neffective models for semi-supervised learning, but facing the obstacle of\nover-smoothing, which will weaken the representation ability of GCNs. Recently\nsome works are proposed to tackle with above limitation by randomly perturbing\ngraph topology or feature matrix to generate data augmentations as input for\ntraining. However, these operations have to pay the price of information\nstructure integrity breaking, and inevitably sacrifice information\nstochastically from original graph. In this paper, we introduce a novel graph\nentropy definition as an quantitative index to evaluate feature information\ndiffusion among a graph. Under considerations of preserving graph entropy, we\npropose an effective strategy to generate perturbed training data using a\nstochastic mechanism but guaranteeing graph topology integrity and with only a\nsmall amount of graph entropy decaying. Extensive experiments have been\nconducted on real-world datasets and the results verify the effectiveness of\nour proposed method in improving semi-supervised node classification accuracy\ncompared with a surge of baselines. Beyond that, our proposed approach\nsignificantly enhances the robustness and generalization ability of GCNs during\nthe training process.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:58:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Liu", "Xue", ""], ["Sun", "Dan", ""], ["Wei", "Wei", ""]]}, {"id": "2107.06050", "submitter": "Guangjie Leng", "authors": "Guangjie Leng, Yekun Zhu and Zhi-Qin John Xu", "title": "Force-in-domain GAN inversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Empirical works suggest that various semantics emerge in the latent space of\nGenerative Adversarial Networks (GANs) when being trained to generate images.\nTo perform real image editing, it requires an accurate mapping from the real\nimage to the latent space to leveraging these learned semantics, which is\nimportant yet difficult. An in-domain GAN inversion approach is recently\nproposed to constraint the inverted code within the latent space by forcing the\nreconstructed image obtained from the inverted code within the real image\nspace. Empirically, we find that the inverted code by the in-domain GAN can\ndeviate from the latent space significantly. To solve this problem, we propose\na force-in-domain GAN based on the in-domain GAN, which utilizes a\ndiscriminator to force the inverted code within the latent space. The\nforce-in-domain GAN can also be interpreted by a cycle-GAN with slight\nmodification. Extensive experiments show that our force-in-domain GAN not only\nreconstructs the target image at the pixel level, but also align the inverted\ncode with the latent space well for semantic editing.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:03:53 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 01:42:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Leng", "Guangjie", ""], ["Zhu", "Yekun", ""], ["Xu", "Zhi-Qin John", ""]]}, {"id": "2107.06057", "submitter": "Miguel Paredes Qui\\~nones Dr", "authors": "Miguel Paredes Qui\\~nones, Maciel Zortea, Leonardo S. A. Martins", "title": "Fast-Slow Streamflow Model Using Mass-Conserving LSTM", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning 2021", "doi": null, "report-no": null, "categories": "cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streamflow forecasting is key to effectively managing water resources and\npreparing for the occurrence of natural calamities being exacerbated by climate\nchange. Here we use the concept of fast and slow flow components to create a\nnew mass-conserving Long Short-Term Memory (LSTM) neural network model. It uses\nhydrometeorological time series and catchment attributes to predict daily river\ndischarges. Preliminary results evidence improvement in skills for different\nscores compared to the recent literature.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:10:24 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Qui\u00f1ones", "Miguel Paredes", ""], ["Zortea", "Maciel", ""], ["Martins", "Leonardo S. A.", ""]]}, {"id": "2107.06064", "submitter": "Atreya Majumdar", "authors": "Atreya Majumdar, Marc Bocquet, Tifenn Hirtzlin, Axel Laborieux,\n  Jacques-Olivier Klein, Etienne Nowak, Elisa Vianello, Jean-Michel Portal,\n  Damien Querlioz", "title": "Model of the Weak Reset Process in HfOx Resistive Memory for Deep\n  Learning Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.app-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The implementation of current deep learning training algorithms is\npower-hungry, owing to data transfer between memory and logic units.\nOxide-based RRAMs are outstanding candidates to implement in-memory computing,\nwhich is less power-intensive. Their weak RESET regime, is particularly\nattractive for learning, as it allows tuning the resistance of the devices with\nremarkable endurance. However, the resistive change behavior in this regime\nsuffers many fluctuations and is particularly challenging to model, especially\nin a way compatible with tools used for simulating deep learning. In this work,\nwe present a model of the weak RESET process in hafnium oxide RRAM and\nintegrate this model within the PyTorch deep learning framework. Validated on\nexperiments on a hybrid CMOS/RRAM technology, our model reproduces both the\nnoisy progressive behavior and the device-to-device (D2D) variability. We use\nthis tool to train Binarized Neural Networks for the MNIST handwritten digit\nrecognition task and the CIFAR-10 object classification task. We simulate our\nmodel with and without various aspects of device imperfections to understand\ntheir impact on the training process and identify that the D2D variability is\nthe most detrimental aspect. The framework can be used in the same manner for\nother types of memories to identify the device imperfections that cause the\nmost degradation, which can, in turn, be used to optimize the devices to reduce\nthe impact of these imperfections.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 08:50:35 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Majumdar", "Atreya", ""], ["Bocquet", "Marc", ""], ["Hirtzlin", "Tifenn", ""], ["Laborieux", "Axel", ""], ["Klein", "Jacques-Olivier", ""], ["Nowak", "Etienne", ""], ["Vianello", "Elisa", ""], ["Portal", "Jean-Michel", ""], ["Querlioz", "Damien", ""]]}, {"id": "2107.06065", "submitter": "Dirk Riehle", "authors": "Dirk Riehle, Nikolay Harutyunyan, Ann Barcomb", "title": "Pattern Discovery and Validation Using Scientific Research Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pattern discovery, the process of discovering previously unrecognized\npatterns, is often performed as an ad-hoc process with little resulting\ncertainty in the quality of the proposed patterns. Pattern validation, the\nprocess of validating the accuracy of proposed patterns, remains dominated by\nthe simple heuristic of \"the rule of three\". This article shows how to use\nestablished scientific research methods for the purpose of pattern discovery\nand validation. We present a specific approach, called the handbook method,\nthat uses the qualitative survey, action research, and case study research for\npattern discovery and evaluation, and we discuss the underlying principle of\nusing scientific methods in general. We evaluate the handbook method using\nthree exploratory studies and demonstrate its usefulness.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 16:11:56 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Riehle", "Dirk", ""], ["Harutyunyan", "Nikolay", ""], ["Barcomb", "Ann", ""]]}, {"id": "2107.06068", "submitter": "Jonas Busk", "authors": "Jonas Busk, Peter Bj{\\o}rn J{\\o}rgensen, Arghya Bhowmik, Mikkel N.\n  Schmidt, Ole Winther, Tejs Vegge", "title": "Calibrated Uncertainty for Molecular Property Prediction using Ensembles\n  of Message Passing Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven methods based on machine learning have the potential to\naccelerate analysis of atomic structures. However, machine learning models can\nproduce overconfident predictions and it is therefore crucial to detect and\nhandle uncertainty carefully. Here, we extend a message passing neural network\ndesigned specifically for predicting properties of molecules and materials with\na calibrated probabilistic predictive distribution. The method presented in\nthis paper differs from the previous work by considering both aleatoric and\nepistemic uncertainty in a unified framework, and by re-calibrating the\npredictive distribution on unseen data. Through computer experiments, we show\nthat our approach results in accurate models for predicting molecular formation\nenergies with calibrated uncertainty in and out of the training data\ndistribution on two public molecular benchmark datasets, QM9 and PC9. The\nproposed method provides a general framework for training and evaluating neural\nnetwork ensemble models that are able to produce accurate predictions of\nproperties of molecules with calibrated uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:28:11 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Busk", "Jonas", ""], ["J\u00f8rgensen", "Peter Bj\u00f8rn", ""], ["Bhowmik", "Arghya", ""], ["Schmidt", "Mikkel N.", ""], ["Winther", "Ole", ""], ["Vegge", "Tejs", ""]]}, {"id": "2107.06074", "submitter": "Chikara Nakamura", "authors": "Chikara Nakamura", "title": "On Choice of Hyper-parameter in Extreme Value Theory based on Machine\n  Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extreme value theory (EVT) is a statistical tool for analysis of extreme\nevents. It has a strong theoretical background, however, we need to choose\nhyper-parameters\n  to apply EVT. In recent studies of machine learning, techniques of choosing\nhyper-parameters have been well-studied. In this paper, we propose a new method\nof choosing hyper-parameters in EVT based on machine learning techniques. We\nalso experiment our method to real-world data and show good usability of our\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 13:32:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Nakamura", "Chikara", ""]]}, {"id": "2107.06080", "submitter": "Jiahui Chen", "authors": "Jiahui Chen, Joe Breen, Jeff M. Phillips, Jacobus Van der Merwe", "title": "Practical and Configurable Network Traffic Classification Using\n  Probabilistic Machine Learning", "comments": "Published in the Springer Cluster Computing journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Network traffic classification that is widely applicable and highly accurate\nis valuable for many network security and management tasks. A flexible and\neasily configurable classification framework is ideal, as it can be customized\nfor use in a wide variety of networks. In this paper, we propose a highly\nconfigurable and flexible machine learning traffic classification method that\nrelies only on statistics of sequences of packets to distinguish known, or\napproved, traffic from unknown traffic. Our method is based on likelihood\nestimation, provides a measure of certainty for classification decisions, and\ncan classify traffic at adjustable certainty levels. Our classification method\ncan also be applied in different classification scenarios, each prioritizing a\ndifferent classification goal. We demonstrate how our classification scheme and\nall its configurations perform well on real-world traffic from a high\nperformance computing network environment.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 07:10:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chen", "Jiahui", ""], ["Breen", "Joe", ""], ["Phillips", "Jeff M.", ""], ["Van der Merwe", "Jacobus", ""]]}, {"id": "2107.06097", "submitter": "Mike Merrill", "authors": "Mike A. Merrill and Tim Althoff", "title": "Transformer-Based Behavioral Representation Learning Enables Transfer\n  Learning for Mobile Sensing in Small Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has revolutionized research and applications in NLP and\ncomputer vision, this has not yet been the case for behavioral modeling and\nbehavioral health applications. This is because the domain's datasets are\nsmaller, have heterogeneous datatypes, and typically exhibit a large degree of\nmissingness. Therefore, off-the-shelf deep learning models require significant,\noften prohibitive, adaptation. Accordingly, many research applications still\nrely on manually coded features with boosted tree models, sometimes with\ntask-specific features handcrafted by experts. Here, we address these\nchallenges by providing a neural architecture framework for mobile sensing data\nthat can learn generalizable feature representations from time series and\ndemonstrates the feasibility of transfer learning on small data domains through\nfinetuning. This architecture combines benefits from CNN and Trans-former\narchitectures to (1) enable better prediction performance by learning directly\nfrom raw minute-level sensor data without the need for handcrafted features by\nup to 0.33 ROC AUC, and (2) use pretraining to outperform simpler neural models\nand boosted decision trees with data from as few a dozen participants.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:26:50 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Merrill", "Mike A.", ""], ["Althoff", "Tim", ""]]}, {"id": "2107.06098", "submitter": "Sumedha Singla", "authors": "Sumedha Singla, Stephen Wallace, Sofia Triantafillou, Kayhan\n  Batmanghelich", "title": "Using Causal Analysis for Conceptual Deep Learning Explanation", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Model explainability is essential for the creation of trustworthy Machine\nLearning models in healthcare. An ideal explanation resembles the\ndecision-making process of a domain expert and is expressed using concepts or\nterminology that is meaningful to the clinicians. To provide such an\nexplanation, we first associate the hidden units of the classifier to\nclinically relevant concepts. We take advantage of radiology reports\naccompanying the chest X-ray images to define concepts. We discover sparse\nassociations between concepts and hidden units using a linear sparse logistic\nregression. To ensure that the identified units truly influence the\nclassifier's outcome, we adopt tools from Causal Inference literature and, more\nspecifically, mediation analysis through counterfactual interventions. Finally,\nwe construct a low-depth decision tree to translate all the discovered concepts\ninto a straightforward decision rule, expressed to the radiologist. We\nevaluated our approach on a large chest x-ray dataset, where our model produces\na global explanation consistent with clinical knowledge.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 00:01:45 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Singla", "Sumedha", ""], ["Wallace", "Stephen", ""], ["Triantafillou", "Sofia", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "2107.06099", "submitter": "Haiyang Wang", "authors": "Haiyang Wang, Guangyu Zhou, Siqi Liu, Jyun-Yu Jiang and Wei Wang", "title": "Drug-Target Interaction Prediction with Graph Attention networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivation: Predicting Drug-Target Interaction (DTI) is a well-studied topic\nin bioinformatics due to its relevance in the fields of proteomics and\npharmaceutical research. Although many machine learning methods have been\nsuccessfully applied in this task, few of them aim at leveraging the inherent\nheterogeneous graph structure in the DTI network to address the challenge. For\nbetter learning and interpreting the DTI topological structure and the\nsimilarity, it is desirable to have methods specifically for predicting\ninteractions from the graph structure.\n  Results: We present an end-to-end framework, DTI-GAT (Drug-Target Interaction\nprediction with Graph Attention networks) for DTI predictions. DTI-GAT\nincorporates a deep neural network architecture that operates on\ngraph-structured data with the attention mechanism, which leverages both the\ninteraction patterns and the features of drug and protein sequences. DTI-GAT\nfacilitates the interpretation of the DTI topological structure by assigning\ndifferent attention weights to each node with the self-attention mechanism.\nExperimental evaluations show that DTI-GAT outperforms various state-of-the-art\nsystems on the binary DTI prediction problem. Moreover, the independent study\nresults further demonstrate that our model can be generalized better than other\nconventional methods.\n  Availability: The source code and all datasets are available at\nhttps://github.com/Haiyang-W/DTI-GRAPH\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 07:06:36 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Wang", "Haiyang", ""], ["Zhou", "Guangyu", ""], ["Liu", "Siqi", ""], ["Jiang", "Jyun-Yu", ""], ["Wang", "Wei", ""]]}, {"id": "2107.06104", "submitter": "Badr Tajini", "authors": "Badr Tajini, Hugo Richard, Bertrand Thirion", "title": "Functional Magnetic Resonance Imaging data augmentation through\n  conditional ICA", "comments": "14 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Advances in computational cognitive neuroimaging research are related to the\navailability of large amounts of labeled brain imaging data, but such data are\nscarce and expensive to generate. While powerful data generation mechanisms,\nsuch as Generative Adversarial Networks (GANs), have been designed in the last\ndecade for computer vision, such improvements have not yet carried over to\nbrain imaging. A likely reason is that GANs training is ill-suited to the\nnoisy, high-dimensional and small-sample data available in functional\nneuroimaging. In this paper, we introduce Conditional Independent Components\nAnalysis (Conditional ICA): a fast functional Magnetic Resonance Imaging (fMRI)\ndata augmentation technique, that leverages abundant resting-state data to\ncreate images by sampling from an ICA decomposition. We then propose a\nmechanism to condition the generator on classes observed with few samples. We\nfirst show that the generative mechanism is successful at synthesizing data\nindistinguishable from observations, and that it yields gains in classification\naccuracy in brain decoding problems. In particular it outperforms GANs while\nbeing much easier to optimize and interpret. Lastly, Conditional ICA enhances\nclassification accuracy in eight datasets without further parameters tuning.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 22:36:14 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 16:28:31 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Tajini", "Badr", ""], ["Richard", "Hugo", ""], ["Thirion", "Bertrand", ""]]}, {"id": "2107.06106", "submitter": "Yecheng Jason Ma", "authors": "Yecheng Jason Ma, Dinesh Jayaraman, Osbert Bastani", "title": "Conservative Offline Distributional Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning (RL) problems in practice are offline, learning\npurely from observational data. A key challenge is how to ensure the learned\npolicy is safe, which requires quantifying the risk associated with different\nactions. In the online setting, distributional RL algorithms do so by learning\nthe distribution over returns (i.e., cumulative rewards) instead of the\nexpected return; beyond quantifying risk, they have also been shown to learn\nbetter representations for planning. We propose Conservative Offline\nDistributional Actor Critic (CODAC), an offline RL algorithm suitable for both\nrisk-neutral and risk-averse domains. CODAC adapts distributional RL to the\noffline setting by penalizing the predicted quantiles of the return for\nout-of-distribution actions. We prove that CODAC learns a conservative return\ndistribution -- in particular, for finite MDPs, CODAC converges to an uniform\nlower bound on the quantiles of the return distribution; our proof relies on a\nnovel analysis of the distributional Bellman operator. In our experiments, on\ntwo challenging robot navigation tasks, CODAC successfully learns risk-averse\npolicies using offline data collected purely from risk-neutral agents.\nFurthermore, CODAC is state-of-the-art on the D4RL MuJoCo benchmark in terms of\nboth expected and risk-sensitive performance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 15:38:06 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ma", "Yecheng Jason", ""], ["Jayaraman", "Dinesh", ""], ["Bastani", "Osbert", ""]]}, {"id": "2107.06115", "submitter": "Zhenning Li", "authors": "Zhenning Li, Chengzhong Xu, Guohui Zhang", "title": "A Deep Reinforcement Learning Approach for Traffic Signal Control\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inefficient traffic signal control methods may cause numerous problems, such\nas traffic congestion and waste of energy. Reinforcement learning (RL) is a\ntrending data-driven approach for adaptive traffic signal control in complex\nurban traffic networks. Although the development of deep neural networks (DNN)\nfurther enhances its learning capability, there are still some challenges in\napplying deep RLs to transportation networks with multiple signalized\nintersections, including non-stationarity environment, exploration-exploitation\ndilemma, multi-agent training schemes, continuous action spaces, etc. In order\nto address these issues, this paper first proposes a multi-agent deep\ndeterministic policy gradient (MADDPG) method by extending the actor-critic\npolicy gradient algorithms. MADDPG has a centralized learning and decentralized\nexecution paradigm in which critics use additional information to streamline\nthe training process, while actors act on their own local observations. The\nmodel is evaluated via simulation on the Simulation of Urban MObility (SUMO)\nplatform. Model comparison results show the efficiency of the proposed\nalgorithm in controlling traffic lights.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 14:11:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Zhenning", ""], ["Xu", "Chengzhong", ""], ["Zhang", "Guohui", ""]]}, {"id": "2107.06126", "submitter": "Jiangeng Chang", "authors": "Jiangeng Chang, Shaoze Cui, Mengling Feng", "title": "DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual\n  Network for the DiCOVA Challenge 2021", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a deep residual network-based method, namely the\nDiCOVA-Net, to identify COVID-19 infected patients based on the acoustic\nrecording of their coughs. Since there are far more healthy people than\ninfected patients, this classification problem faces the challenge of\nimbalanced data. To improve the model's ability to recognize minority class\n(the infected patients), we introduce data augmentation and cost-sensitive\nmethods into our model. Besides, considering the particularity of this task, we\ndeploy some fine-tuning techniques to adjust the pre-training ResNet50.\nFurthermore, to improve the model's generalizability, we use ensemble learning\nto integrate prediction results from multiple base classifiers generated using\ndifferent random seeds. To evaluate the proposed DiCOVA-Net's performance, we\nconducted experiments with the DiCOVA challenge dataset. The results show that\nour method has achieved 85.43\\% in AUC, among the top of all competing teams.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 19:25:06 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Chang", "Jiangeng", ""], ["Cui", "Shaoze", ""], ["Feng", "Mengling", ""]]}, {"id": "2107.06131", "submitter": "Michaela Beneder", "authors": "Gabriel Kronberger, Lukas Kammerer, Michael Kommenda", "title": "Identification of Dynamical Systems using Symbolic Regression", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-45093-9", "journal-ref": "In Computer Aided Systems Theory - EUROCAST 2019, Series Volume\n  12013, pp. 370-377. Springer. (2020)", "doi": "10.1007/978-3-030-45093-9", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for the identification of models for dynamical systems\nfrom observational data. The method is based on the concept of symbolic\nregression and uses genetic programming to evolve a system of ordinary\ndifferential equations (ODE). The novelty is that we add a step of\ngradient-based optimization of the ODE parameters. For this we calculate the\nsensitivities of the solution to the initial value problem (IVP) using\nautomatic differentiation. The proposed approach is tested on a set of 19\nproblem instances taken from the literature which includes datasets from\nsimulated systems as well as datasets captured from mechanical systems. We find\nthat gradient-based optimization of parameters improves predictive accuracy of\nthe models. The best results are obtained when we first fit the individual\nequations to the numeric differences and then subsequently fine-tune the\nidentified parameter values by fitting the IVP solution to the observed\nvariable values.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 11:41:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kronberger", "Gabriel", ""], ["Kammerer", "Lukas", ""], ["Kommenda", "Michael", ""]]}, {"id": "2107.06158", "submitter": "Mehdi Ben Amor", "authors": "M. Ben Amor, J. Stier, M. Granitzer", "title": "Correlation Analysis between the Robustness of Sparse Neural Networks\n  and their Random Hidden Structural Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have been shown to be vulnerable to adversarial attacks.\nThis perception led to analyzing deep learning models not only from the\nperspective of their performance measures but also their robustness to certain\ntypes of adversarial attacks. We take another step forward in relating the\narchitectural structure of neural networks from a graph theoretic perspective\nto their robustness. We aim to investigate any existing correlations between\ngraph theoretic properties and the robustness of Sparse Neural Networks. Our\nhypothesis is, that graph theoretic properties as a prior of neural network\nstructures are related to their robustness. To answer to this hypothesis, we\ndesigned an empirical study with neural network models obtained through random\ngraphs used as sparse structural priors for the networks. We additionally\ninvestigated the evaluation of a randomly pruned fully connected network as a\npoint of reference.\n  We found that robustness measures are independent of initialization methods\nbut show weak correlations with graph properties: higher graph densities\ncorrelate with lower robustness, but higher average path lengths and average\nnode eccentricities show negative correlations with robustness measures. We\nhope to motivate further empirical and analytical research to tightening an\nanswer to our hypothesis.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 15:13:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Amor", "M. Ben", ""], ["Stier", "J.", ""], ["Granitzer", "M.", ""]]}, {"id": "2107.06174", "submitter": "Juyong Lee", "authors": "Juyong Lee and Youngsang Cho", "title": "National-scale electricity peak load forecasting: Traditional, machine\n  learning, or hybrid model?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY econ.EM eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the volatility of electricity demand increases owing to climate change and\nelectrification, the importance of accurate peak load forecasting is\nincreasing. Traditional peak load forecasting has been conducted through time\nseries-based models; however, recently, new models based on machine or deep\nlearning are being introduced. This study performs a comparative analysis to\ndetermine the most accurate peak load-forecasting model for Korea, by comparing\nthe performance of time series, machine learning, and hybrid models. Seasonal\nautoregressive integrated moving average with exogenous variables (SARIMAX) is\nused for the time series model. Artificial neural network (ANN), support vector\nregression (SVR), and long short-term memory (LSTM) are used for the machine\nlearning models. SARIMAX-ANN, SARIMAX-SVR, and SARIMAX-LSTM are used for the\nhybrid models. The results indicate that the hybrid models exhibit significant\nimprovement over the SARIMAX model. The LSTM-based models outperformed the\nothers; the single and hybrid LSTM models did not exhibit a significant\nperformance difference. In the case of Korea's highest peak load in 2019, the\npredictive power of the LSTM model proved to be greater than that of the\nSARIMAX-LSTM model. The LSTM, SARIMAX-SVR, and SARIMAX-LSTM models outperformed\nthe current time series-based forecasting model used in Korea. Thus, Korea's\npeak load-forecasting performance can be improved by including machine learning\nor hybrid models.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 15:17:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Lee", "Juyong", ""], ["Cho", "Youngsang", ""]]}, {"id": "2107.06181", "submitter": "Selen Gecgel", "authors": "Selen Gecgel and Gunes Karabulut Kurt", "title": "Intermittent Jamming against Telemetry and Telecommand of Satellite\n  Systems and A Learning-driven Detection Strategy", "comments": null, "journal-ref": null, "doi": "10.1145/3468218.3469041", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Towards sixth-generation networks (6G), satellite communication systems,\nespecially based on Low Earth Orbit (LEO) networks, become promising due to\ntheir unique and comprehensive capabilities. These advantages are accompanied\nby a variety of challenges such as security vulnerabilities, management of\nhybrid systems, and high mobility. In this paper, firstly, a security\ndeficiency in the physical layer is addressed with a conceptual framework,\nconsidering the cyber-physical nature of the satellite systems, highlighting\nthe potential attacks. Secondly, a learning-driven detection scheme is\nproposed, and the lightweight convolutional neural network (CNN) is designed.\nThe performance of the designed CNN architecture is compared with a prevalent\nmachine learning algorithm, support vector machine (SVM). The results show that\ndeficiency attacks against the satellite systems can be detected by employing\nthe proposed scheme.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 17:04:22 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Gecgel", "Selen", ""], ["Kurt", "Gunes Karabulut", ""]]}, {"id": "2107.06182", "submitter": "Md Amimul Ehsan", "authors": "Md Amimul Ehsan", "title": "Predictive models for wind speed using artificial intelligence and\n  copula", "comments": "This is a Masters thesis that compares various machine learning\n  algorithms for wind speed prediction using weather data. It also applies\n  Copula to model joint probability distribution of two far apart wind sites.\n  arXiv admin note: text overlap with arXiv:2005.12401", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electricity generation from burning fossil fuels is one of the major\ncontributors to global warming. Renewable energy sources are a viable\nalternative to produce electrical energy and to reduce the emission from the\npower industry. These energy sources are the building blocks of green energy,\nwhich all have different characteristics. Their availabilities are also\ndiverse, depending on geographical locations and other parameters. Low\nimplementation cost and distributed availability all over the world uplifts\ntheir popularity exponentially. Therefore, it has unlocked opportunities for\nconsumers to produce electricity locally and use it on-site, which reduces\ndependency on centralized utility companies. The research considers two main\nobjectives: the prediction of wind speed that simplifies wind farm planning and\nfeasibility study. Secondly, the need to understand the dependency structure of\nthe wind speeds of multiple distant locations. To address the first objective,\ntwelve artificial intelligence algorithms were used for wind speed prediction\nfrom collected meteorological parameters. The model performances were compared\nto determine the wind speed prediction accuracy. The results show a deep\nlearning approach, long short-term memory (LSTM) outperforms other models with\nthe highest accuracy of 97.8%. For dependency, a multivariate cumulative\ndistribution function, Copula, was used to find the joint distribution of two\nor more distant location wind speeds, followed by a case study. We found that\nthe appropriate copula family and the parameters vary based on the distance in\nbetween. For the case study, Joe-Frank (BB8) copula shows an efficient joint\ndistribution fit for a wind speed pair with a standard error of 0.0094.\nFinally, some insights about the uncertainty aspects of wind speed dependency\nwere addressed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:18:12 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ehsan", "Md Amimul", ""]]}, {"id": "2107.06187", "submitter": "Mai Lan Ha", "authors": "Mai Lan Ha and Volker Blanz", "title": "Deep Ranking with Adaptive Margin Triplet Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a simple modification from a fixed margin triplet loss to an\nadaptive margin triplet loss. While the original triplet loss is used widely in\nclassification problems such as face recognition, face re-identification and\nfine-grained similarity, our proposed loss is well suited for rating datasets\nin which the ratings are continuous values. In contrast to original triplet\nloss where we have to sample data carefully, in out method, we can generate\ntriplets using the whole dataset, and the optimization can still converge\nwithout frequently running into a model collapsing issue. The adaptive margins\nonly need to be computed once before the training, which is much less expensive\nthan generating triplets after every epoch as in the fixed margin case. Besides\nsubstantially improved training stability (the proposed model never collapsed\nin our experiments compared to a couple of times that the training collapsed on\nexisting triplet loss), we achieved slightly better performance than the\noriginal triplet loss on various rating datasets and network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 15:37:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ha", "Mai Lan", ""], ["Blanz", "Volker", ""]]}, {"id": "2107.06195", "submitter": "Hammad Zafar", "authors": "Hammad Zafar, Zoran Utkovski, Martin Kasparick, Slawomir Stanczak", "title": "Transfer Learning in Multi-Agent Reinforcement Learning with Double\n  Q-Networks for Distributed Resource Sharing in V2X Communication", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of decentralized spectrum sharing in\nvehicle-to-everything (V2X) communication networks. The aim is to provide\nresource-efficient coexistence of vehicle-to-infrastructure(V2I) and\nvehicle-to-vehicle(V2V) links. A recent work on the topic proposes a\nmulti-agent reinforcement learning (MARL) approach based on deep Q-learning,\nwhich leverages a fingerprint-based deep Q-network (DQN) architecture. This\nwork considers an extension of this framework by combining Double Q-learning\n(via Double DQN) and transfer learning. The motivation behind is that Double\nQ-learning can alleviate the problem of overestimation of the action values\npresent in conventional Q-learning, while transfer learning can leverage\nknowledge acquired by an expert model to accelerate learning in the MARL\nsetting. The proposed algorithm is evaluated in a realistic V2X setting, with\nsynthetic data generated based on a geometry-based propagation model that\nincorporates location-specific geographical descriptors of the simulated\nenvironment(outlines of buildings, foliage, and vehicles). The advantages of\nthe proposed approach are demonstrated via numerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 15:50:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zafar", "Hammad", ""], ["Utkovski", "Zoran", ""], ["Kasparick", "Martin", ""], ["Stanczak", "Slawomir", ""]]}, {"id": "2107.06196", "submitter": "Soumya Basu", "authors": "Soumya Basu, Branislav Kveton, Manzil Zaheer, Csaba Szepesv\\'ari", "title": "No Regrets for Learning the Prior in Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose ${\\tt AdaTS}$, a Thompson sampling algorithm that adapts\nsequentially to bandit tasks that it interacts with. The key idea in ${\\tt\nAdaTS}$ is to adapt to an unknown task prior distribution by maintaining a\ndistribution over its parameters. When solving a bandit task, that uncertainty\nis marginalized out and properly accounted for. ${\\tt AdaTS}$ is a\nfully-Bayesian algorithm that can be implemented efficiently in several classes\nof bandit problems. We derive upper bounds on its Bayes regret that quantify\nthe loss due to not knowing the task prior, and show that it is small. Our\ntheory is supported by experiments, where ${\\tt AdaTS}$ outperforms prior\nalgorithms and works well even in challenging real-world problems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 15:51:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Basu", "Soumya", ""], ["Kveton", "Branislav", ""], ["Zaheer", "Manzil", ""], ["Szepesv\u00e1ri", "Csaba", ""]]}, {"id": "2107.06197", "submitter": "Abdelhak Lemkhenter", "authors": "Abdelhak Lemkhenter, Adam Bielski, Alp Eren Sari, Paolo Favaro", "title": "Generative Adversarial Learning via Kernel Density Discrimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Kernel Density Discrimination GAN (KDD GAN), a novel method for\ngenerative adversarial learning. KDD GAN formulates the training as a\nlikelihood ratio optimization problem where the data distributions are written\nexplicitly via (local) Kernel Density Estimates (KDE). This is inspired by the\nrecent progress in contrastive learning and its relation to KDE. We define the\nKDEs directly in feature space and forgo the requirement of invertibility of\nthe kernel feature mappings. In our approach, features are no longer optimized\nfor linear separability, as in the original GAN formulation, but for the more\ngeneral discrimination of distributions in the feature space. We analyze the\ngradient of our loss with respect to the feature representation and show that\nit is better behaved than that of the original hinge loss. We perform\nexperiments with the proposed KDE-based loss, used either as a training loss or\na regularization term, on both CIFAR10 and scaled versions of ImageNet. We use\nBigGAN/SA-GAN as a backbone and baseline, since our focus is not to design the\narchitecture of the networks. We show a boost in the quality of generated\nsamples with respect to FID from 10% to 40% compared to the baseline. Code will\nbe made available.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 15:52:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Lemkhenter", "Abdelhak", ""], ["Bielski", "Adam", ""], ["Sari", "Alp Eren", ""], ["Favaro", "Paolo", ""]]}, {"id": "2107.06206", "submitter": "Sridhar Chimalakonda", "authors": "Shruti Priya, Shubhankar Bhadra and Sridhar Chimalakonda", "title": "ML-Quest: A Game for Introducing Machine Learning Concepts to K-12\n  Students", "comments": "13 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Today, Machine Learning (ML) is of a great importance to society due to the\navailability of huge data and high computational resources. This ultimately led\nto the introduction of ML concepts at multiple levels of education including\nK-12 students to promote computational thinking. However, teaching these\nconcepts to K-12 through traditional methodologies such as video lectures and\nbooks is challenging. Many studies in the literature have reported that using\ninteractive environments such as games to teach computational thinking and\nprogramming improves retention capacity and motivation among students.\nTherefore, introducing ML concepts using a game might enhance students'\nunderstanding of the subject and motivate them to learn further. However, we\nare not aware of any existing game which explicitly focuses on introducing ML\nconcepts to students using game play. Hence, in this paper, we propose\nML-Quest, a 3D video game to provide conceptual overview of three ML concepts:\nSupervised Learning, Gradient Descent and K-Nearest Neighbor (KNN)\nClassification. The crux of the game is to introduce the definition and working\nof these concepts, which we call conceptual overview, in a simulated scenario\nwithout overwhelming students with the intricacies of ML. The game has been\npredominantly evaluated for its usefulness and player experience using the\nTechnology Acceptance Model (TAM) model with the help of 23 higher-secondary\nschool students. The survey result shows that around 70% of the participants\neither agree or strongly agree that the ML-Quest is quite interactive and\nuseful in introducing them to ML concepts.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:05:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Priya", "Shruti", ""], ["Bhadra", "Shubhankar", ""], ["Chimalakonda", "Sridhar", ""]]}, {"id": "2107.06207", "submitter": "Alexander Scheinker", "authors": "Alexander Scheinker", "title": "Adaptive Machine Learning for Time-Varying Systems: Low Dimensional\n  Latent Space Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.acc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) tools such as encoder-decoder convolutional neural\nnetworks (CNN) can represent incredibly complex nonlinear functions which map\nbetween combinations of images and scalars. For example, CNNs can be used to\nmap combinations of accelerator parameters and images which are 2D projections\nof the 6D phase space distributions of charged particle beams as they are\ntransported between various particle accelerator locations. Despite their\nstrengths, applying ML to time-varying systems, or systems with shifting\ndistributions, is an open problem, especially for large systems for which\ncollecting new data for re-training is impractical or interrupts operations.\nParticle accelerators are one example of large time-varying systems for which\ncollecting detailed training data requires lengthy dedicated beam measurements\nwhich may no longer be available during regular operations. We present a\nrecently developed method of adaptive ML for time-varying systems. Our approach\nis to map very high (N>100k) dimensional inputs (a combination of scalar\nparameters and images) into the low dimensional (N~2) latent space at the\noutput of the encoder section of an encoder-decoder CNN. We then actively tune\nthe low dimensional latent space-based representation of complex system\ndynamics by the addition of an adaptively tuned feedback vector directly before\nthe decoder sections builds back up to our image-based high-dimensional phase\nspace density representations. This method allows us to learn correlations\nwithin and to quickly tune the characteristics of incredibly high parameter\nsystems and to track their evolution in real time based on feedback without\nmassive new data sets for re-training.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:05:28 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Scheinker", "Alexander", ""]]}, {"id": "2107.06209", "submitter": "Mai Lan Ha", "authors": "Mai Lan Ha, Gianni Franchi, Emanuel Aldea and Volker Blanz", "title": "Learning a Discriminant Latent Space with Neural Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Discriminative features play an important role in image and object\nclassification and also in other fields of research such as semi-supervised\nlearning, fine-grained classification, out of distribution detection. Inspired\nby Linear Discriminant Analysis (LDA), we propose an optimization called Neural\nDiscriminant Analysis (NDA) for Deep Convolutional Neural Networks (DCNNs). NDA\ntransforms deep features to become more discriminative and, therefore, improves\nthe performances in various tasks. Our proposed optimization has two primary\ngoals for inter- and intra-class variances. The first one is to minimize\nvariances within each individual class. The second goal is to maximize pairwise\ndistances between features coming from different classes. We evaluate our NDA\noptimization in different research fields: general supervised classification,\nfine-grained classification, semi-supervised learning, and out of distribution\ndetection. We achieve performance improvements in all the fields compared to\nbaseline methods that do not use NDA. Besides, using NDA, we also surpass the\nstate of the art on the four tasks on various testing datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:06:07 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ha", "Mai Lan", ""], ["Franchi", "Gianni", ""], ["Aldea", "Emanuel", ""], ["Blanz", "Volker", ""]]}, {"id": "2107.06212", "submitter": "Bharadwaj Manda", "authors": "Bharadwaj Manda, Shubham Dhayarkar, Sai Mitheran, V.K. Viekash,\n  Ramanathan Muthuganapathy", "title": "'CADSketchNet' -- An Annotated Sketch dataset for 3D CAD Model Retrieval\n  with Deep Neural Networks", "comments": "Computers & Graphics Journal, Special Section on 3DOR 2021", "journal-ref": "Computers & Graphics, Volume 99, 2021, Pages 100-113, ISSN\n  0097-8493", "doi": "10.1016/j.cag.2021.07.001", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ongoing advancements in the fields of 3D modelling and digital archiving have\nled to an outburst in the amount of data stored digitally. Consequently,\nseveral retrieval systems have been developed depending on the type of data\nstored in these databases. However, unlike text data or images, performing a\nsearch for 3D models is non-trivial. Among 3D models, retrieving 3D\nEngineering/CAD models or mechanical components is even more challenging due to\nthe presence of holes, volumetric features, presence of sharp edges etc., which\nmake CAD a domain unto itself. The research work presented in this paper aims\nat developing a dataset suitable for building a retrieval system for 3D CAD\nmodels based on deep learning. 3D CAD models from the available CAD databases\nare collected, and a dataset of computer-generated sketch data, termed\n'CADSketchNet', has been prepared. Additionally, hand-drawn sketches of the\ncomponents are also added to CADSketchNet. Using the sketch images from this\ndataset, the paper also aims at evaluating the performance of various retrieval\nsystem or a search engine for 3D CAD models that accepts a sketch image as the\ninput query. Many experimental models are constructed and tested on\nCADSketchNet. These experiments, along with the model architecture, choice of\nsimilarity metrics are reported along with the search results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:10:16 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 06:26:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Manda", "Bharadwaj", ""], ["Dhayarkar", "Shubham", ""], ["Mitheran", "Sai", ""], ["Viekash", "V. K.", ""], ["Muthuganapathy", "Ramanathan", ""]]}, {"id": "2107.06217", "submitter": "Mohamed Ishmael Belghazi", "authors": "Mohamed Ishmael Belghazi and David Lopez-Paz", "title": "What classifiers know what they don't?", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Being uncertain when facing the unknown is key to intelligent decision\nmaking. However, machine learning algorithms lack reliable estimates about\ntheir predictive uncertainty. This leads to wrong and overly-confident\ndecisions when encountering classes unseen during training. Despite the\nimportance of equipping classifiers with uncertainty estimates ready for the\nreal world, prior work has focused on small datasets and little or no class\ndiscrepancy between training and testing data. To close this gap, we introduce\nUIMNET: a realistic, ImageNet-scale test-bed to evaluate predictive uncertainty\nestimates for deep image classifiers. Our benchmark provides implementations of\neight state-of-the-art algorithms, six uncertainty measures, four in-domain\nmetrics, three out-domain metrics, and a fully automated pipeline to train,\ncalibrate, ensemble, select, and evaluate models. Our test-bed is open-source\nand all of our results are reproducible from a fixed commit in our repository.\nAdding new datasets, algorithms, measures, or metrics is a matter of a few\nlines of code-in so hoping that UIMNET becomes a stepping stone towards\nrealistic, rigorous, and reproducible research in uncertainty estimation. Our\nresults show that ensembles of ERM classifiers as well as single MIMO\nclassifiers are the two best alternatives currently available to measure\nuncertainty about both in-domain and out-domain classes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:17:06 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Belghazi", "Mohamed Ishmael", ""], ["Lopez-Paz", "David", ""]]}, {"id": "2107.06219", "submitter": "Xingxuan Zhang", "authors": "Xingxuan Zhang, Linjun Zhou, Renzhe Xu, Peng Cui, Zheyan Shen, Haoxin\n  Liu", "title": "Domain-Irrelevant Representation Learning for Unsupervised Domain\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization (DG) aims to help models trained on a set of source\ndomains generalize better on unseen target domains. The performances of current\nDG methods largely rely on sufficient labeled data, which however are usually\ncostly or unavailable. While unlabeled data are far more accessible, we seek to\nexplore how unsupervised learning can help deep models generalizes across\ndomains. Specifically, we study a novel generalization problem called\nunsupervised domain generalization, which aims to learn generalizable models\nwith unlabeled data. Furthermore, we propose a Domain-Irrelevant Unsupervised\nLearning (DIUL) method to cope with the significant and misleading\nheterogeneity within unlabeled data and severe distribution shifts between\nsource and target data. Surprisingly we observe that DIUL can not only\ncounterbalance the scarcity of labeled data but also further strengthen the\ngeneralization ability of models when the labeled data are sufficient. As a\npretraining approach, DIUL shows superior to ImageNet pretraining protocol even\nwhen the available data are unlabeled and of a greatly smaller amount compared\nto ImageNet. Extensive experiments clearly demonstrate the effectiveness of our\nmethod compared with state-of-the-art unsupervised learning counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:20:50 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zhang", "Xingxuan", ""], ["Zhou", "Linjun", ""], ["Xu", "Renzhe", ""], ["Cui", "Peng", ""], ["Shen", "Zheyan", ""], ["Liu", "Haoxin", ""]]}, {"id": "2107.06226", "submitter": "Masatoshi Uehara", "authors": "Masatoshi Uehara, Wen Sun", "title": "Pessimistic Model-based Offline RL: PAC Bounds and Posterior Sampling\n  under Partial Coverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study model-based offline Reinforcement Learning with general function\napproximation. We present an algorithm named Constrained Pessimistic Policy\nOptimization (CPPO) which leverages a general function class and uses a\nconstraint to encode pessimism. Under the assumption that the ground truth\nmodel belongs to our function class, CPPO can learn with the offline data only\nproviding partial coverage, i.e., it can learn a policy that completes against\nany policy that is covered by the offline data, in polynomial sample complexity\nwith respect to the statistical complexity of the function class. We then\ndemonstrate that this algorithmic framework can be applied to many specialized\nMarkov Decision Processes where the additional structural assumptions can\nfurther refine the concept of partial coverage. One notable example is low-rank\nMDP with representation learning where the partial coverage is defined using\nthe concept of relative condition number measured by the underlying unknown\nground truth feature representation. Finally, we introduce and study the\nBayesian setting in offline RL. The key benefit of Bayesian offline RL is that\nalgorithmically, we do not need to explicitly construct pessimism or reward\npenalty which could be hard beyond models with linear structures. We present a\nposterior sampling-based incremental policy optimization algorithm (PS-PO)\nwhich proceeds by iteratively sampling a model from the posterior distribution\nand performing one-step incremental policy optimization inside the sampled\nmodel. Theoretically, in expectation with respect to the prior distribution,\nPS-PO can learn a near optimal policy under partial coverage with polynomial\nsample complexity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:30:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Uehara", "Masatoshi", ""], ["Sun", "Wen", ""]]}, {"id": "2107.06231", "submitter": "Carlos Hernandez-Olivan", "authors": "Carlos Hernandez-Olivan, Jose R. Beltran", "title": "Timbre Classification of Musical Instruments with a Deep Learning\n  Multi-Head Attention-Based Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of this work is to define a model based on deep learning that is able\nto identify different instrument timbres with as few parameters as possible.\nFor this purpose, we have worked with classical orchestral instruments played\nwith different dynamics, which are part of a few instrument families and which\nplay notes in the same pitch range. It has been possible to assess the ability\nto classify instruments by timbre even if the instruments are playing the same\nnote with the same intensity. The network employed uses a multi-head attention\nmechanism, with 8 heads and a dense network at the output taking as input the\nlog-mel magnitude spectrograms of the sound samples. This network allows the\nidentification of 20 instrument classes of the classical orchestra, achieving\nan overall F$_1$ value of 0.62. An analysis of the weights of the attention\nlayer has been performed and the confusion matrix of the model is presented,\nallowing us to assess the ability of the proposed architecture to distinguish\ntimbre and to establish the aspects on which future work should focus.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:34:19 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Hernandez-Olivan", "Carlos", ""], ["Beltran", "Jose R.", ""]]}, {"id": "2107.06239", "submitter": "Srikrishna Karanam", "authors": "Ren Li and Meng Zheng and Srikrishna Karanam and Terrence Chen and\n  Ziyan Wu", "title": "Everybody Is Unique: Towards Unbiased Human Mesh Recovery", "comments": "10 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of obese human mesh recovery, i.e., fitting a\nparametric human mesh to images of obese people. Despite obese person mesh\nfitting being an important problem with numerous applications (e.g.,\nhealthcare), much recent progress in mesh recovery has been restricted to\nimages of non-obese people. In this work, we identify this crucial gap in the\ncurrent literature by presenting and discussing limitations of existing\nalgorithms. Next, we present a simple baseline to address this problem that is\nscalable and can be easily used in conjunction with existing algorithms to\nimprove their performance. Finally, we present a generalized human mesh\noptimization algorithm that substantially improves the performance of existing\nmethods on both obese person images as well as community-standard benchmark\ndatasets. A key innovation of this technique is that it does not rely on\nsupervision from expensive-to-create mesh parameters. Instead, starting from\nwidely and cheaply available 2D keypoints annotations, our method automatically\ngenerates mesh parameters that can in turn be used to re-train and fine-tune\nany existing mesh estimation algorithm. This way, we show our method acts as a\ndrop-in to improve the performance of a wide variety of contemporary mesh\nestimation methods. We conduct extensive experiments on multiple datasets\ncomprising both standard and obese person images and demonstrate the efficacy\nof our proposed techniques.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:52:55 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Li", "Ren", ""], ["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Wu", "Ziyan", ""]]}, {"id": "2107.06256", "submitter": "Min Jin Chong", "authors": "Min Jin Chong, Wen-Sheng Chu, Abhishek Kumar, David Forsyth", "title": "Retrieve in Style: Unsupervised Facial Feature Transfer and Retrieval", "comments": "Code is here https://github.com/mchong6/RetrieveInStyle", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Retrieve in Style (RIS), an unsupervised framework for\nfine-grained facial feature transfer and retrieval on real images. Recent work\nshows that it is possible to learn a catalog that allows local semantic\ntransfers of facial features on generated images by capitalizing on the\ndisentanglement property of the StyleGAN latent space. RIS improves existing\nart on: 1) feature disentanglement and allows for challenging transfers (i.e.,\nhair and pose) that were not shown possible in SoTA methods. 2) eliminating the\nneed for per-image hyperparameter tuning, and for computing a catalog over a\nlarge batch of images. 3) enabling face retrieval using the proposed facial\nfeatures (e.g., eyes), and to our best knowledge, is the first work to retrieve\nface images at the fine-grained level. 4) robustness and natural application to\nreal images. Our qualitative and quantitative analyses show RIS achieves both\nhigh-fidelity feature transfers and accurate fine-grained retrievals on real\nimages. We discuss the responsible application of RIS.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:31:34 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 08:56:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chong", "Min Jin", ""], ["Chu", "Wen-Sheng", ""], ["Kumar", "Abhishek", ""], ["Forsyth", "David", ""]]}, {"id": "2107.06257", "submitter": "Daniel Wilson", "authors": "Daniel Wilson, Thayer Alshaabi, Colin Van Oort, Xiaohan Zhang,\n  Jonathan Nelson, Safwan Wshah", "title": "Object Tracking and Geo-localization from Street Images", "comments": "28 pages, 7 figures, to be submitted to Elsevier Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geo-localizing static objects from street images is challenging but also very\nimportant for road asset mapping and autonomous driving. In this paper we\npresent a two-stage framework that detects and geolocalizes traffic signs from\nlow frame rate street videos. Our proposed system uses a modified version of\nRetinaNet (GPS-RetinaNet), which predicts a positional offset for each sign\nrelative to the camera, in addition to performing the standard classification\nand bounding box regression. Candidate sign detections from GPS-RetinaNet are\ncondensed into geolocalized signs by our custom tracker, which consists of a\nlearned metric network and a variant of the Hungarian Algorithm. Our metric\nnetwork estimates the similarity between pairs of detections, then the\nHungarian Algorithm matches detections across images using the similarity\nscores provided by the metric network. Our models were trained using an updated\nversion of the ARTS dataset, which contains 25,544 images and 47.589 sign\nannotations ~\\cite{arts}. The proposed dataset covers a diverse set of\nenvironments gathered from a broad selection of roads. Each annotaiton contains\na sign class label, its geospatial location, an assembly label, a side of road\nindicator, and unique identifiers that aid in the evaluation. This dataset will\nsupport future progress in the field, and the proposed system demonstrates how\nto take advantage of some of the unique characteristics of a realistic\ngeolocalization dataset.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:32:04 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Wilson", "Daniel", ""], ["Alshaabi", "Thayer", ""], ["Van Oort", "Colin", ""], ["Zhang", "Xiaohan", ""], ["Nelson", "Jonathan", ""], ["Wshah", "Safwan", ""]]}, {"id": "2107.06264", "submitter": "K Kanishk", "authors": "Kanishk, Tanishk Nandal, Prince Tyagi, Raj Kumar Singh", "title": "Parameterization of Forced Isotropic Turbulent Flow using Autoencoders\n  and Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoencoders and generative neural network models have recently gained\npopularity in fluid mechanics due to their spontaneity and low processing time\ninstead of high fidelity CFD simulations. Auto encoders are used as model order\nreduction tools in applications of fluid mechanics by compressing input\nhigh-dimensional data using an encoder to map the input space into a\nlower-dimensional latent space. Whereas, generative models such as Variational\nAuto-encoders (VAEs) and Generative Adversarial Networks (GANs) are proving to\nbe effective in generating solutions to chaotic models with high 'randomness'\nsuch as turbulent flows. In this study, forced isotropic turbulence flow is\ngenerated by parameterizing into some basic statistical characteristics. The\nmodels trained on pre-simulated data from dependencies on these characteristics\nand the flow generation is then affected by varying these parameters. The\nlatent vectors pushed along the generator models like the decoders and\ngenerators contain independent entries which can be used to create different\noutputs with similar properties. The use of neural network-based architecture\nremoves the need for dependency on the classical mesh-based Navier-Stoke\nequation estimation which is prominent in many CFD softwares.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 18:37:38 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kanishk", "", ""], ["Nandal", "Tanishk", ""], ["Tyagi", "Prince", ""], ["Singh", "Raj Kumar", ""]]}, {"id": "2107.06268", "submitter": "Florian Ziel", "authors": "Florian Ziel", "title": "Smoothed Bernstein Online Aggregation for Day-Ahead Electricity Demand\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a winning method of the IEEE DataPort Competition on Day-Ahead\nElectricity Demand Forecasting: Post-COVID Paradigm. The day-ahead load\nforecasting approach is based on online forecast combination of multiple point\nprediction models. It contains four steps: i) data cleaning and preprocessing,\nii) a holiday adjustment procedure, iii) training of individual forecasting\nmodels, iv) forecast combination by smoothed Bernstein Online Aggregation\n(BOA). The approach is flexible and can quickly adopt to new energy system\nsituations as they occurred during and after COVID-19 shutdowns. The pool of\nindividual prediction models ranges from rather simple time series models to\nsophisticated models like generalized additive models (GAMs) and\nhigh-dimensional linear models estimated by lasso. They incorporate\nautoregressive, calendar and weather effects efficiently. All steps contain\nnovel concepts that contribute to the excellent forecasting performance of the\nproposed method. This holds particularly for the holiday adjustment procedure\nand the fully adaptive smoothed BOA approach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:51:21 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ziel", "Florian", ""]]}, {"id": "2107.06277", "submitter": "Dibya Ghosh", "authors": "Dibya Ghosh, Jad Rahme, Aviral Kumar, Amy Zhang, Ryan P. Adams, Sergey\n  Levine", "title": "Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit\n  Partial Observability", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization is a central challenge for the deployment of reinforcement\nlearning (RL) systems in the real world. In this paper, we show that the\nsequential structure of the RL problem necessitates new approaches to\ngeneralization beyond the well-studied techniques used in supervised learning.\nWhile supervised learning methods can generalize effectively without explicitly\naccounting for epistemic uncertainty, we show that, perhaps surprisingly, this\nis not the case in RL. We show that generalization to unseen test conditions\nfrom a limited number of training conditions induces implicit partial\nobservability, effectively turning even fully-observed MDPs into POMDPs.\nInformed by this observation, we recast the problem of generalization in RL as\nsolving the induced partially observed Markov decision process, which we call\nthe epistemic POMDP. We demonstrate the failure modes of algorithms that do not\nappropriately handle this partial observability, and suggest a simple\nensemble-based technique for approximately solving the partially observed\nproblem. Empirically, we demonstrate that our simple algorithm derived from the\nepistemic POMDP achieves significant gains in generalization over current\nmethods on the Procgen benchmark suite.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:59:25 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ghosh", "Dibya", ""], ["Rahme", "Jad", ""], ["Kumar", "Aviral", ""], ["Zhang", "Amy", ""], ["Adams", "Ryan P.", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.06281", "submitter": "Islem Rekik", "authors": "Islem Mhiri and Ahmed Nebli and Mohamed Ali Mahjoub and Islem Rekik", "title": "Non-isomorphic Inter-modality Graph Alignment and Synthesis for Holistic\n  Brain Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Brain graph synthesis marked a new era for predicting a target brain graph\nfrom a source one without incurring the high acquisition cost and processing\ntime of neuroimaging data. However, existing multi-modal graph synthesis\nframeworks have several limitations. First, they mainly focus on generating\ngraphs from the same domain (intra-modality), overlooking the rich multimodal\nrepresentations of brain connectivity (inter-modality). Second, they can only\nhandle isomorphic graph generation tasks, limiting their generalizability to\nsynthesizing target graphs with a different node size and topological structure\nfrom those of the source one. More importantly, both target and source domains\nmight have different distributions, which causes a domain fracture between them\n(i.e., distribution misalignment). To address such challenges, we propose an\ninter-modality aligner of non-isomorphic graphs (IMANGraphNet) framework to\ninfer a target graph modality based on a given modality. Our three core\ncontributions lie in (i) predicting a target graph (e.g., functional) from a\nsource graph (e.g., morphological) based on a novel graph generative\nadversarial network (gGAN); (ii) using non-isomorphic graphs for both source\nand target domains with a different number of nodes, edges and structure; and\n(iii) enforcing the predicted target distribution to match that of the ground\ntruth graphs using a graph autoencoder to relax the designed loss oprimization.\nTo handle the unstable behavior of gGAN, we design a new Ground\nTruth-Preserving (GT-P) loss function to guide the generator in learning the\ntopological structure of ground truth brain graphs. Our comprehensive\nexperiments on predicting functional from morphological graphs demonstrate the\noutperformance of IMANGraphNet in comparison with its variants. This can be\nfurther leveraged for integrative and holistic brain mapping in health and\ndisease.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:59:55 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mhiri", "Islem", ""], ["Nebli", "Ahmed", ""], ["Mahjoub", "Mohamed Ali", ""], ["Rekik", "Islem", ""]]}, {"id": "2107.06304", "submitter": "Xin Dong", "authors": "Xin Dong, Hongxu Yin, Jose M. Alvarez, Jan Kautz, Pavlo Molchanov", "title": "Deep Neural Networks are Surprisingly Reversible: A Baseline for\n  Zero-Shot Inversion", "comments": "A new inversion method to reverse neural networks and get input from\n  intermediate feature maps. Works without original data for classifiers and\n  GANs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the behavior and vulnerability of pre-trained deep neural\nnetworks (DNNs) can help to improve them. Analysis can be performed via\nreversing the network's flow to generate inputs from internal representations.\nMost existing work relies on priors or data-intensive optimization to invert a\nmodel, yet struggles to scale to deep architectures and complex datasets. This\npaper presents a zero-shot direct model inversion framework that recovers the\ninput to the trained model given only the internal representation. The crux of\nour method is to inverse the DNN in a divide-and-conquer manner while\nre-syncing the inverted layers via cycle-consistency guidance with the help of\nsynthesized data. As a result, we obtain a single feed-forward model capable of\ninversion with a single forward pass without seeing any real data of the\noriginal task. With the proposed approach, we scale zero-shot direct inversion\nto deep architectures and complex datasets. We empirically show that modern\nclassification models on ImageNet can, surprisingly, be inverted, allowing an\napproximate recovery of the original 224x224px images from a representation\nafter more than 20 layers. Moreover, inversion of generators in GANs unveils\nlatent code of a given synthesized face image at 128x128px, which can even, in\nturn, improve defective synthesized images from GANs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:01:43 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Dong", "Xin", ""], ["Yin", "Hongxu", ""], ["Alvarez", "Jose M.", ""], ["Kautz", "Jan", ""], ["Molchanov", "Pavlo", ""]]}, {"id": "2107.06317", "submitter": "Alihan H\\\"uy\\\"uk", "authors": "Alihan H\\\"uy\\\"uk, Daniel Jarrett, Mihaela van der Schaar", "title": "Inverse Contextual Bandits: Learning How Behavior Evolves over Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding an agent's priorities by observing their behavior is critical\nfor transparency and accountability in decision processes, such as in\nhealthcare. While conventional approaches to policy learning almost invariably\nassume stationarity in behavior, this is hardly true in practice: Medical\npractice is constantly evolving, and clinical professionals are constantly\nfine-tuning their priorities. We desire an approach to policy learning that\nprovides (1) interpretable representations of decision-making, accounts for (2)\nnon-stationarity in behavior, as well as operating in an (3) offline manner.\nFirst, we model the behavior of learning agents in terms of contextual bandits,\nand formalize the problem of inverse contextual bandits (ICB). Second, we\npropose two algorithms to tackle ICB, each making varying degrees of\nassumptions regarding the agent's learning strategy. Finally, through both real\nand simulated data for liver transplantations, we illustrate the applicability\nand explainability of our method, as well as validating its accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:24:18 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["H\u00fcy\u00fck", "Alihan", ""], ["Jarrett", "Daniel", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2107.06319", "submitter": "Julian Theis", "authors": "Julian Theis, Ilia Mokhtarian, and Houshang Darabi", "title": "On the Performance Analysis of the Adversarial System Variant\n  Approximation Method to Quantify Process Model Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining algorithms discover a process model from an event log. The\nresulting process model is supposed to describe all possible event sequences of\nthe underlying system. Generalization is a process model quality dimension of\ninterest. A generalization metric should quantify the extent to which a process\nmodel represents the observed event sequences contained in the event log and\nthe unobserved event sequences of the system. Most of the available metrics in\nthe literature cannot properly quantify the generalization of a process model.\nA recently published method [1] called Adversarial System Variant Approximation\nleverages Generative Adversarial Networks to approximate the underlying event\nsequence distribution of a system from an event log. While this method\ndemonstrated performance gains over existing methods in measuring the\ngeneralization of process models, its experimental evaluations have been\nperformed under ideal conditions. This paper experimentally investigates the\nperformance of Adversarial System Variant Approximation under non-ideal\nconditions such as biased and limited event logs. Moreover, experiments are\nperformed to investigate the originally proposed sampling hyperparameter value\nof the method on its performance to measure the generalization. The results\nconfirm the need to raise awareness about the working conditions of the\nAdversarial System Variant Approximation method. The outcomes of this paper\nalso serve to initiate future research directions.\n  [1] Theis, Julian, and Houshang Darabi. \"Adversarial System Variant\nApproximation to Quantify Process Model Generalization.\" IEEE Access 8 (2020):\n194410-194427.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:27:09 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Theis", "Julian", ""], ["Mokhtarian", "Ilia", ""], ["Darabi", "Houshang", ""]]}, {"id": "2107.06327", "submitter": "Pier Giuseppe Sessa", "authors": "Pier Giuseppe Sessa, Ilija Bogunovic, Andreas Krause, Maryam\n  Kamgarpour", "title": "Contextual Games: Multi-Agent Learning with Side Information", "comments": null, "journal-ref": "Proc. of Neural Information Processing Systems (NeurIPS), 2020", "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the novel class of contextual games, a type of repeated games\ndriven by contextual information at each round. By means of kernel-based\nregularity assumptions, we model the correlation between different contexts and\ngame outcomes and propose a novel online (meta) algorithm that exploits such\ncorrelations to minimize the contextual regret of individual players. We define\ngame-theoretic notions of contextual Coarse Correlated Equilibria (c-CCE) and\noptimal contextual welfare for this new class of games and show that c-CCEs and\noptimal welfare can be approached whenever players' contextual regrets vanish.\nFinally, we empirically validate our results in a traffic routing experiment,\nwhere our algorithm leads to better performance and higher welfare compared to\nbaselines that do not exploit the available contextual information or the\ncorrelations present in the game.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:37:37 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sessa", "Pier Giuseppe", ""], ["Bogunovic", "Ilija", ""], ["Krause", "Andreas", ""], ["Kamgarpour", "Maryam", ""]]}, {"id": "2107.06336", "submitter": "Tianhao Wang", "authors": "Tianhao Wang, Yu Yang, Ruoxi Jia", "title": "Learnability of Learning Performance and Its Application to Data\n  Valuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For most machine learning (ML) tasks, evaluating learning performance on a\ngiven dataset requires intensive computation. On the other hand, the ability to\nefficiently estimate learning performance may benefit a wide spectrum of\napplications, such as active learning, data quality management, and data\nvaluation. Recent empirical studies show that for many common ML models, one\ncan accurately learn a parametric model that predicts learning performance for\nany given input datasets using a small amount of samples. However, the\ntheoretical underpinning of the learnability of such performance prediction\nmodels is still missing. In this work, we develop the first theoretical\nanalysis of the ML performance learning problem. We propose a relaxed notion\nfor submodularity that can well describe the behavior of learning performance\nas a function of input datasets. We give a learning algorithm that achieves a\nconstant-factor approximation under certain assumptions. Further, we give a\nlearning algorithm that achieves arbitrarily small error based on a newly\nderived structural result. We then discuss a natural, important use case of\nlearning performance learning -- data valuation, which is known to suffer\ncomputational challenges due to the requirement of estimating learning\nperformance for many data combinations. We show that performance learning can\nsignificantly improve the accuracy of data valuation.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 18:56:04 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Wang", "Tianhao", ""], ["Yang", "Yu", ""], ["Jia", "Ruoxi", ""]]}, {"id": "2107.06344", "submitter": "Mehmet Fatih Ozkan", "authors": "Mehmet Fatih Ozkan, Abishek Joseph Rocque, Yao Ma", "title": "Inverse Reinforcement Learning Based Stochastic Driver Behavior Learning", "comments": "Accepted to 2021 Modeling, Estimation and Control Conference (MECC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drivers have unique and rich driving behaviors when operating vehicles in\ntraffic. This paper presents a novel driver behavior learning approach that\ncaptures the uniqueness and richness of human driver behavior in realistic\ndriving scenarios. A stochastic inverse reinforcement learning (SIRL) approach\nis proposed to learn a distribution of cost function, which represents the\nrichness of the human driver behavior with a given set of driver-specific\ndemonstrations. Evaluations are conducted on the realistic driving data\ncollected from the 3D driver-in-the-loop driving simulation. The results show\nthat the learned stochastic driver model is capable of expressing the richness\nof the human driving strategies under different realistic driving scenarios.\nCompared to the deterministic baseline driver model, the results reveal that\nthe proposed stochastic driver behavior model can better replicate the driver's\nunique and rich driving strategies in a variety of traffic conditions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 20:18:03 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 04:03:59 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ozkan", "Mehmet Fatih", ""], ["Rocque", "Abishek Joseph", ""], ["Ma", "Yao", ""]]}, {"id": "2107.06351", "submitter": "Andrei Costin", "authors": "Tuomo Lahtinen, Hannu Turtiainen, Andrei Costin", "title": "BRIMA: low-overhead BRowser-only IMage Annotation tool (Preprint)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image annotation and large annotated datasets are crucial parts within the\nComputer Vision and Artificial Intelligence fields.At the same time, it is\nwell-known and acknowledged by the research community that the image annotation\nprocess is challenging, time-consuming and hard to scale. Therefore, the\nresearchers and practitioners are always seeking ways to perform the\nannotations easier, faster, and at higher quality. Even though several widely\nused tools exist and the tools' landscape evolved considerably, most of the\ntools still require intricate technical setups and high levels of technical\nsavviness from its operators and crowdsource contributors.\n  In order to address such challenges, we develop and present BRIMA -- a\nflexible and open-source browser extension that allows BRowser-only IMage\nAnnotation at considerably lower overheads. Once added to the browser, it\ninstantly allows the user to annotate images easily and efficiently directly\nfrom the browser without any installation or setup on the client-side. It also\nfeatures cross-browser and cross-platform functionality thus presenting itself\nas a neat tool for researchers within the Computer Vision, Artificial\nIntelligence, and privacy-related fields.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 19:23:13 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lahtinen", "Tuomo", ""], ["Turtiainen", "Hannu", ""], ["Costin", "Andrei", ""]]}, {"id": "2107.06353", "submitter": "Allen Z. Ren", "authors": "Allen Z. Ren, Anirudha Majumdar", "title": "Distributionally Robust Policy Learning via Adversarial Environment\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our goal is to train control policies that generalize well to unseen\nenvironments. Inspired by the Distributionally Robust Optimization (DRO)\nframework, we propose DRAGEN - Distributionally Robust policy learning via\nAdversarial Generation of ENvironments - for iteratively improving robustness\nof policies to realistic distribution shifts by generating adversarial\nenvironments. The key idea is to learn a generative model for environments\nwhose latent variables capture cost-predictive and realistic variations in\nenvironments. We perform DRO with respect to a Wasserstein ball around the\nempirical distribution of environments by generating realistic adversarial\nenvironments via gradient ascent on the latent space. We demonstrate strong\nOut-of-Distribution (OoD) generalization in simulation for (i) swinging up a\npendulum with onboard vision and (ii) grasping realistic 2D/3D objects.\nGrasping experiments on hardware demonstrate better sim2real performance\ncompared to domain randomization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 19:26:34 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ren", "Allen Z.", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2107.06356", "submitter": "Anas Al Shaghouri Mr.", "authors": "Anas Al Shaghouri, Rami Alkhatib, Samir Berjaoui", "title": "Real-Time Pothole Detection Using Deep Learning", "comments": "10 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roads are connecting line between different places, and used daily. Roads'\nperiodic maintenance keeps them safe and functional. Detecting and reporting\nthe existence of potholes to responsible departments can help in eliminating\nthem. This study deployed and tested on different deep learning architecture to\ndetect potholes. The images used for training were collected by cellphone\nmounted on the windshield of the car, in addition to many images downloaded\nfrom the internet to increase the size and variability of the database. Second,\nvarious object detection algorithms are employed and compared to detect\npotholes in real-time like SDD-TensorFlow, YOLOv3Darknet53 and YOLOv4Darknet53.\nYOLOv4 achieved the best performance with 81% recall, 85% precision and 85.39%\nmean Average Precision (mAP). The speed of processing was 20 frame per second.\nThe system was able to detect potholes from a range on 100 meters away from the\ncamera. The system can increase the safety of drivers and improve the\nperformance of self-driving cars by detecting pothole time ahead.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 19:36:34 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Shaghouri", "Anas Al", ""], ["Alkhatib", "Rami", ""], ["Berjaoui", "Samir", ""]]}, {"id": "2107.06383", "submitter": "Liunian Harold Li", "authors": "Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach,\n  Kai-Wei Chang, Zhewei Yao, Kurt Keutzer", "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing Vision-and-Language (V&L) models rely on pre-trained visual\nencoders, using a relatively small set of manually-annotated data (as compared\nto web-crawled data), to perceive the visual world. However, it has been\nobserved that large-scale pretraining usually can result in better\ngeneralization performance, e.g., CLIP (Contrastive Language-Image\nPre-training), trained on a massive amount of image-caption pairs, has shown a\nstrong zero-shot capability on various vision tasks. To further study the\nadvantage brought by CLIP, we propose to use CLIP as the visual encoder in\nvarious V&L models in two typical scenarios: 1) plugging CLIP into\ntask-specific fine-tuning; 2) combining CLIP with V&L pre-training and\ntransferring to downstream tasks. We show that CLIP significantly outperforms\nwidely-used visual encoders trained with in-domain annotated data, such as\nBottomUp-TopDown. We achieve competitive or better results on diverse V&L\ntasks, while establishing new state-of-the-art results on Visual Question\nAnswering, Visual Entailment, and V&L Navigation tasks. We release our code at\nhttps://github.com/clip-vil/CLIP-ViL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 20:48:12 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Shen", "Sheng", ""], ["Li", "Liunian Harold", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""], ["Rohrbach", "Anna", ""], ["Chang", "Kai-Wei", ""], ["Yao", "Zhewei", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2107.06386", "submitter": "Susama Agarwala", "authors": "Susama Agarwala, Benjamin Dees, Andrew Gearhart, Corey Lowman", "title": "Geometry and Generalization: Eigenvalues as predictors of where a\n  network will fail to generalize", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the deformation of the input space by a trained autoencoder via the\nJacobians of the trained weight matrices. In doing so, we prove bounds for the\nmean squared errors for points in the input space, under assumptions regarding\nthe orthogonality of the eigenvectors. We also show that the trace and the\nproduct of the eigenvalues of the Jacobian matrices is a good predictor of the\nMSE on test points. This is a dataset independent means of testing an\nautoencoder's ability to generalize on new input. Namely, no knowledge of the\ndataset on which the network was trained is needed, only the parameters of the\ntrained model.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 21:03:42 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Agarwala", "Susama", ""], ["Dees", "Benjamin", ""], ["Gearhart", "Andrew", ""], ["Lowman", "Corey", ""]]}, {"id": "2107.06393", "submitter": "Tuan Anh Le", "authors": "Tuan Anh Le, Katherine M. Collins, Luke Hewitt, Kevin Ellis, Siddharth\n  N, Samuel J. Gershman, Joshua B. Tenenbaum", "title": "Hybrid Memoised Wake-Sleep: Approximate Inference at the\n  Discrete-Continuous Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling complex phenomena typically involves the use of both discrete and\ncontinuous variables. Such a setting applies across a wide range of problems,\nfrom identifying trends in time-series data to performing effective\ncompositional scene understanding in images. Here, we propose Hybrid Memoised\nWake-Sleep (HMWS), an algorithm for effective inference in such hybrid\ndiscrete-continuous models. Prior approaches to learning suffer as they need to\nperform repeated expensive inner-loop discrete inference. We build on a recent\napproach, Memoised Wake-Sleep (MWS), which alleviates part of the problem by\nmemoising discrete variables, and extend it to allow for a principled and\neffective way to handle continuous variables by learning a separate recognition\nmodel used for importance-sampling based approximate inference and\nmarginalization. We evaluate HMWS in the GP-kernel learning and 3D scene\nunderstanding domains, and show that it outperforms current state-of-the-art\ninference methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 00:57:14 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Le", "Tuan Anh", ""], ["Collins", "Katherine M.", ""], ["Hewitt", "Luke", ""], ["Ellis", "Kevin", ""], ["N", "Siddharth", ""], ["Gershman", "Samuel J.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "2107.06396", "submitter": "Ushnish Sengupta", "authors": "Ushnish Sengupta, G\\\"unther Waxenegger-Wilfing, Justin Hardi, Matthew\n  P. Juniper", "title": "Forecasting Thermoacoustic Instabilities in Liquid Propellant Rocket\n  Engines Using Multimodal Bayesian Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The 100 MW cryogenic liquid oxygen/hydrogen multi-injector combustor BKD\noperated by the DLR Institute of Space Propulsion is a research platform that\nallows the study of thermoacoustic instabilities under realistic conditions,\nrepresentative of small upper stage rocket engines. We use data from BKD\nexperimental campaigns in which the static chamber pressure and fuel-oxidizer\nratio are varied such that the first tangential mode of the combustor is\nexcited under some conditions. We train an autoregressive Bayesian neural\nnetwork model to forecast the amplitude of the dynamic pressure time series,\ninputting multiple sensor measurements (injector pressure/ temperature\nmeasurements, static chamber pressure, high-frequency dynamic pressure\nmeasurements, high-frequency OH* chemiluminescence measurements) and future\nflow rate control signals. The Bayesian nature of our algorithms allows us to\nwork with a dataset whose size is restricted by the expense of each\nexperimental run, without making overconfident extrapolations. We find that the\nnetworks are able to accurately forecast the evolution of the pressure\namplitude and anticipate instability events on unseen experimental runs 500\nmilliseconds in advance. We compare the predictive accuracy of multiple models\nusing different combinations of sensor inputs. We find that the high-frequency\ndynamic pressure signal is particularly informative. We also use the technique\nof integrated gradients to interpret the influence of different sensor inputs\non the model prediction. The negative log-likelihood of data points in the test\ndataset indicates that predictive uncertainties are well-characterized by our\nBayesian model and simulating a sensor failure event results as expected in a\ndramatic increase in the epistemic component of the uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 18:28:13 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sengupta", "Ushnish", ""], ["Waxenegger-Wilfing", "G\u00fcnther", ""], ["Hardi", "Justin", ""], ["Juniper", "Matthew P.", ""]]}, {"id": "2107.06400", "submitter": "Sergio Rojas-Galeano", "authors": "Sergio Rojas-Galeano", "title": "Using BERT Encoding to Tackle the Mad-lib Attack in SMS Spam Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One of the stratagems used to deceive spam filters is to substitute vocables\nwith synonyms or similar words that turn the message unrecognisable by the\ndetection algorithms. In this paper we investigate whether the recent\ndevelopment of language models sensitive to the semantics and context of words,\nsuch as Google's BERT, may be useful to overcome this adversarial attack\n(called \"Mad-lib\" as per the word substitution game). Using a dataset of 5572\nSMS spam messages, we first established a baseline of detection performance\nusing widely known document representation models (BoW and TFIDF) and the novel\nBERT model, coupled with a variety of classification algorithms (Decision Tree,\nkNN, SVM, Logistic Regression, Naive Bayes, Multilayer Perceptron). Then, we\nbuilt a thesaurus of the vocabulary contained in these messages, and set up a\nMad-lib attack experiment in which we modified each message of a held out\nsubset of data (not used in the baseline experiment) with different rates of\nsubstitution of original words with synonyms from the thesaurus. Lastly, we\nevaluated the detection performance of the three representation models (BoW,\nTFIDF and BERT) coupled with the best classifier from the baseline experiment\n(SVM). We found that the classic models achieved a 94% Balanced Accuracy (BA)\nin the original dataset, whereas the BERT model obtained 96%. On the other\nhand, the Mad-lib attack experiment showed that BERT encodings manage to\nmaintain a similar BA performance of 96% with an average substitution rate of\n1.82 words per message, and 95% with 3.34 words substituted per message. In\ncontrast, the BA performance of the BoW and TFIDF encoders dropped to chance.\nThese results hint at the potential advantage of BERT models to combat these\ntype of ingenious attacks, offsetting to some extent for the inappropriate use\nof semantic relationships in language.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 21:17:57 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Rojas-Galeano", "Sergio", ""]]}, {"id": "2107.06405", "submitter": "Sungryull Sohn", "authors": "Sungryull Sohn, Sungtae Lee, Jongwook Choi, Harm van Seijen, Mehdi\n  Fatemi, Honglak Lee", "title": "Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks", "comments": "In proceedings of ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the k-Shortest-Path (k-SP) constraint: a novel constraint on the\nagent's trajectory that improves the sample efficiency in sparse-reward MDPs.\nWe show that any optimal policy necessarily satisfies the k-SP constraint.\nNotably, the k-SP constraint prevents the policy from exploring state-action\npairs along the non-k-SP trajectories (e.g., going back and forth). However, in\npractice, excluding state-action pairs may hinder the convergence of RL\nalgorithms. To overcome this, we propose a novel cost function that penalizes\nthe policy violating SP constraint, instead of completely excluding it. Our\nnumerical experiment in a tabular RL setting demonstrates that the SP\nconstraint can significantly reduce the trajectory space of policy. As a\nresult, our constraint enables more sample efficient learning by suppressing\nredundant exploration and exploitation. Our experiments on MiniGrid, DeepMind\nLab, Atari, and Fetch show that the proposed method significantly improves\nproximal policy optimization (PPO) and outperforms existing novelty-seeking\nexploration methods including count-based exploration even in continuous\ncontrol tasks, indicating that it improves the sample efficiency by preventing\nthe agent from taking redundant actions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 21:39:21 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sohn", "Sungryull", ""], ["Lee", "Sungtae", ""], ["Choi", "Jongwook", ""], ["van Seijen", "Harm", ""], ["Fatemi", "Mehdi", ""], ["Lee", "Honglak", ""]]}, {"id": "2107.06409", "submitter": "Xavier Boix", "authors": "Vanessa D'Amario, Sanjana Srivastava, Tomotake Sasaki, Xavier Boix", "title": "The Foes of Neural Network's Data Efficiency Among Unnecessary Input\n  Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Datasets often contain input dimensions that are unnecessary to predict the\noutput label, e.g. background in object recognition, which lead to more\ntrainable parameters. Deep Neural Networks (DNNs) are robust to increasing the\nnumber of parameters in the hidden layers, but it is unclear whether this holds\ntrue for the input layer. In this letter, we investigate the impact of\nunnecessary input dimensions on a central issue of DNNs: their data efficiency,\nie. the amount of examples needed to achieve certain generalization\nperformance. Our results show that unnecessary input dimensions that are\ntask-unrelated substantially degrade data efficiency. This highlights the need\nfor mechanisms that remove {task-unrelated} dimensions to enable data\nefficiency gains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 21:52:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["D'Amario", "Vanessa", ""], ["Srivastava", "Sanjana", ""], ["Sasaki", "Tomotake", ""], ["Boix", "Xavier", ""]]}, {"id": "2107.06419", "submitter": "Sheng-Chun Kao", "authors": "Sheng-Chun Kao, Suvinay Subramanian, Gaurav Agrawal, Tushar Krishna", "title": "ATTACC the Quadratic Bottleneck of Attention Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Attention mechanisms form the backbone of state-of-the-art machine learning\nmodels for a variety of tasks. Deploying them on deep neural network (DNN)\naccelerators, however, is prohibitively challenging especially under long\nsequences. Operators in attention layers exhibit limited reuse and quadratic\ngrowth in memory footprint, leading to severe memory-boundedness. This paper\nintroduces a new attention-tailored dataflow, termed FLAT, which leverages\noperator fusion, loop-nest optimizations, and interleaved execution. It\nincreases the effective memory bandwidth by efficiently utilizing the\nhigh-bandwidth, low-capacity on-chip buffer and thus achieves better run time\nand compute resource utilization. We term FLAT-compatible accelerators ATTACC.\nIn our evaluation, ATTACC achieves 1.94x and 1.76x speedup and 49% and 42% of\nenergy reduction comparing to state-of-the-art edge and cloud accelerators.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:23:40 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Kao", "Sheng-Chun", ""], ["Subramanian", "Suvinay", ""], ["Agrawal", "Gaurav", ""], ["Krishna", "Tushar", ""]]}, {"id": "2107.06424", "submitter": "Mohammadamin Tavakoli", "authors": "Mohammadamin Tavakoli, Peter Sadowski, Pierre Baldi", "title": "Tourbillon: a Physically Plausible Neural Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a physical neural system, backpropagation is faced with a number of\nobstacles including: the need for labeled data, the violation of the locality\nlearning principle, the need for symmetric connections, and the lack of\nmodularity. Tourbillon is a new architecture that addresses all these\nlimitations. At its core, it consists of a stack of circular autoencoders\nfollowed by an output layer. The circular autoencoders are trained in\nself-supervised mode by recirculation algorithms and the top layer in\nsupervised mode by stochastic gradient descent, with the option of propagating\nerror information through the entire stack using non-symmetric connections.\nWhile the Tourbillon architecture is meant primarily to address physical\nconstraints, and not to improve current engineering applications of deep\nlearning, we demonstrate its viability on standard benchmark datasets including\nMNIST, Fashion MNIST, and CIFAR10. We show that Tourbillon can achieve\ncomparable performance to models trained with backpropagation and outperform\nmodels that are trained with other physically plausible algorithms, such as\nfeedback alignment.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:51:42 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 04:25:05 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 04:15:50 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Tavakoli", "Mohammadamin", ""], ["Sadowski", "Peter", ""], ["Baldi", "Pierre", ""]]}, {"id": "2107.06428", "submitter": "Brian Trippe", "authors": "Brian L. Trippe, Hilary K. Finucane, Tamara Broderick", "title": "For high-dimensional hierarchical models, consider exchangeability of\n  effects across covariates instead of across datasets", "comments": "10 pages plus supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical Bayesian methods enable information sharing across multiple\nrelated regression problems. While standard practice is to model regression\nparameters (effects) as (1) exchangeable across datasets and (2) correlated to\ndiffering degrees across covariates, we show that this approach exhibits poor\nstatistical performance when the number of covariates exceeds the number of\ndatasets. For instance, in statistical genetics, we might regress dozens of\ntraits (defining datasets) for thousands of individuals (responses) on up to\nmillions of genetic variants (covariates). When an analyst has more covariates\nthan datasets, we argue that it is often more natural to instead model effects\nas (1) exchangeable across covariates and (2) correlated to differing degrees\nacross datasets. To this end, we propose a hierarchical model expressing our\nalternative perspective. We devise an empirical Bayes estimator for learning\nthe degree of correlation between datasets. We develop theory that demonstrates\nthat our method outperforms the classic approach when the number of covariates\ndominates the number of datasets, and corroborate this result empirically on\nseveral high-dimensional multiple regression and classification problems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 23:23:06 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Trippe", "Brian L.", ""], ["Finucane", "Hilary K.", ""], ["Broderick", "Tamara", ""]]}, {"id": "2107.06433", "submitter": "Jesmin Jahan Tithi", "authors": "Jesmin Jahan Tithi and Fabrizio Petrini", "title": "A New Parallel Algorithm for Sinkhorn Word-Movers Distance and Its\n  Performance on PIUMA and Xeon CPU", "comments": "11 Pages. arXiv admin note: substantial text overlap with\n  arXiv:2005.06727", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Word Movers Distance (WMD) measures the semantic dissimilarity between\ntwo text documents by computing the cost of optimally moving all words of a\nsource/query document to the most similar words of a target document. Computing\nWMD between two documents is costly because it requires solving an optimization\nproblem that costs $O (V^3 \\log(V)) $ where $V$ is the number of unique words\nin the document. Fortunately, WMD can be framed as an Earth Mover's Distance\n(EMD) for which the algorithmic complexity can be reduced to $O(V^2)$ by adding\nan entropy penalty to the optimization problem and solving it using the\nSinkhorn-Knopp algorithm. Additionally, the computation can be made highly\nparallel by computing the WMD of a single query document against multiple\ntarget documents at once, for example by finding whether a given tweet is\nsimilar to any other tweets of a given day.\n  In this paper, we first present a shared-memory parallel Sinkhorn-Knopp\nalgorithm to compute the WMD of one document against many other documents by\nadopting the $ O(V^2)$ EMD algorithm. We then algorithmically transform the\noriginal $O(V^2)$ dense compute-heavy version into an equivalent sparse one\nwhich is mapped onto the new Intel Programmable Integrated Unified Memory\nArchitecture (PIUMA) system. The WMD parallel implementation achieves 67x\nspeedup on 96 cores across 4 NUMA sockets of an Intel Cascade Lake system. We\nalso show that PIUMA cores are around 1.2-2.6x faster than Xeon cores on\nSinkhorn-WMD and also provide better strong scaling.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 00:29:18 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Tithi", "Jesmin Jahan", ""], ["Petrini", "Fabrizio", ""]]}, {"id": "2107.06446", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov", "title": "Hierarchical Associative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Associative Memories or Modern Hopfield Networks have many appealing\nproperties of associative memory. They can do pattern completion, store a large\nnumber of memories, and can be described using a recurrent neural network with\na degree of biological plausibility and rich feedback between the neurons. At\nthe same time, up until now all the models of this class have had only one\nhidden layer, and have only been formulated with densely connected network\narchitectures, two aspects that hinder their machine learning applications.\nThis paper tackles this gap and describes a fully recurrent model of\nassociative memory with an arbitrary large number of layers, some of which can\nbe locally connected (convolutional), and a corresponding energy function that\ndecreases on the dynamical trajectory of the neurons' activations. The memories\nof the full network are dynamically \"assembled\" using primitives encoded in the\nsynaptic weights of the lower layers, with the \"assembling rules\" encoded in\nthe synaptic weights of the higher layers. In addition to the bottom-up\npropagation of information, typical of commonly used feedforward neural\nnetworks, the model described has rich top-down feedback from higher layers\nthat help the lower-layer neurons to decide on their response to the input\nstimuli.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 01:38:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Krotov", "Dmitry", ""]]}, {"id": "2107.06456", "submitter": "Eunjung Lee", "authors": "Duhun Hwang, Eunjung Lee, Wonjong Rhee", "title": "AID-Purifier: A Light Auxiliary Network for Boosting Adversarial Defense", "comments": null, "journal-ref": "ICML 2021 Workshop on Adversarial Machine Learning", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an AID-purifier that can boost the robustness of\nadversarially-trained networks by purifying their inputs. AID-purifier is an\nauxiliary network that works as an add-on to an already trained main\nclassifier. To keep it computationally light, it is trained as a discriminator\nwith a binary cross-entropy loss. To obtain additionally useful information\nfrom the adversarial examples, the architecture design is closely related to\ninformation maximization principles where two layers of the main classification\nnetwork are piped to the auxiliary network. To assist the iterative\noptimization procedure of purification, the auxiliary network is trained with\nAVmixup. AID-purifier can be used together with other purifiers such as\nPixelDefend for an extra enhancement. The overall results indicate that the\nbest performing adversarially-trained networks can be enhanced by the best\nperforming purification networks, where AID-purifier is a competitive candidate\nthat is light and robust.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 02:39:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Hwang", "Duhun", ""], ["Lee", "Eunjung", ""], ["Rhee", "Wonjong", ""]]}, {"id": "2107.06466", "submitter": "Baihe Huang", "authors": "Baihe Huang and Kaixuan Huang and Sham M. Kakade and Jason D. Lee and\n  Qi Lei and Runzhe Wang and Jiaqi Yang", "title": "Going Beyond Linear RL: Sample Efficient Neural Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Reinforcement Learning (RL) powered by neural net approximation of the Q\nfunction has had enormous empirical success. While the theory of RL has\ntraditionally focused on linear function approximation (or eluder dimension)\napproaches, little is known about nonlinear RL with neural net approximations\nof the Q functions. This is the focus of this work, where we study function\napproximation with two-layer neural networks (considering both ReLU and\npolynomial activation functions). Our first result is a computationally and\nstatistically efficient algorithm in the generative model setting under\ncompleteness for two-layer neural networks. Our second result considers this\nsetting but under only realizability of the neural net function class. Here,\nassuming deterministic dynamics, the sample complexity scales linearly in the\nalgebraic dimension. In all cases, our results significantly improve upon what\ncan be attained with linear (or eluder dimension) methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:03:56 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Huang", "Baihe", ""], ["Huang", "Kaixuan", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""], ["Wang", "Runzhe", ""], ["Yang", "Jiaqi", ""]]}, {"id": "2107.06469", "submitter": "Kabir Nagrecha", "authors": "Kabir Nagrecha", "title": "Model-Parallel Model Selection for Deep Learning Systems", "comments": "2 pages, 3 figures. 1st place winner of ACM SIGMOD '21 Student\n  Research Competition. Appeared in ACM SIGMOD/PODS '21 Proceedings", "journal-ref": null, "doi": "10.1145/3448016.3450571", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning becomes more expensive, both in terms of time and compute,\ninefficiencies in machine learning (ML) training prevent practical usage of\nstate-of-the-art models for most users. The newest model architectures are\nsimply too large to be fit onto a single processor. To address the issue, many\nML practitioners have turned to model parallelism as a method of distributing\nthe computational requirements across several devices. Unfortunately, the\nsequential nature of neural networks causes very low efficiency and device\nutilization in model parallel training jobs. We propose a new form of \"shard\nparallelism\" combining task and model parallelism, then package it into a\nframework we name Hydra. Hydra recasts the problem of model parallelism in the\nmulti-model context to produce a fine-grained parallel workload of independent\nmodel shards, rather than independent models. This new parallel design promises\ndramatic speedups relative to the traditional model parallelism paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:20:37 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Nagrecha", "Kabir", ""]]}, {"id": "2107.06473", "submitter": "Wenqi Fang", "authors": "Wenqi Fang, Guanlin Wu, Jingjing Li, Zheng Wang, Jiang Cao, Yang Ping", "title": "Spectrum Gaussian Processes Based On Tunable Basis Functions", "comments": "10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral approximation and variational inducing learning for the Gaussian\nprocess are two popular methods to reduce computational complexity. However, in\nprevious research, those methods always tend to adopt the orthonormal basis\nfunctions, such as eigenvectors in the Hilbert space, in the spectrum method,\nor decoupled orthogonal components in the variational framework. In this paper,\ninspired by quantum physics, we introduce a novel basis function, which is\ntunable, local and bounded, to approximate the kernel function in the Gaussian\nprocess. There are two adjustable parameters in these functions, which control\ntheir orthogonality to each other and limit their boundedness. And we conduct\nextensive experiments on open-source datasets to testify its performance.\nCompared to several state-of-the-art methods, it turns out that the proposed\nmethod can obtain satisfactory or even better results, especially with poorly\nchosen kernel functions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:51:24 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Fang", "Wenqi", ""], ["Wu", "Guanlin", ""], ["Li", "Jingjing", ""], ["Wang", "Zheng", ""], ["Cao", "Jiang", ""], ["Ping", "Yang", ""]]}, {"id": "2107.06475", "submitter": "Patryk Orzechowski", "authors": "Patryk Orzechowski and Jason H. Moore", "title": "Generative and reproducible benchmarks for comprehensive evaluation of\n  machine learning classifiers", "comments": "12 pages, 3 figures with subfigures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the strengths and weaknesses of machine learning (ML)\nalgorithms is crucial for determine their scope of application. Here, we\nintroduce the DIverse and GENerative ML Benchmark (DIGEN) - a collection of\nsynthetic datasets for comprehensive, reproducible, and interpretable\nbenchmarking of machine learning algorithms for classification of binary\noutcomes. The DIGEN resource consists of 40 mathematical functions which map\ncontinuous features to discrete endpoints for creating synthetic datasets.\nThese 40 functions were discovered using a heuristic algorithm designed to\nmaximize the diversity of performance among multiple popular machine learning\nalgorithms thus providing a useful test suite for evaluating and comparing new\nmethods. Access to the generative functions facilitates understanding of why a\nmethod performs poorly compared to other algorithms thus providing ideas for\nimprovement. The resource with extensive documentation and analyses is\nopen-source and available on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:58:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Orzechowski", "Patryk", ""], ["Moore", "Jason H.", ""]]}, {"id": "2107.06481", "submitter": "Bharadwaj Manda", "authors": "Bharadwaj Manda, Pranjal Bhaskare, Ramanathan Muthuganapathy", "title": "A Convolutional Neural Network Approach to the Classification of\n  Engineering Models", "comments": null, "journal-ref": "in IEEE Access, vol. 9, pp. 22711-22723, 2021", "doi": "10.1109/ACCESS.2021.3055826", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a deep learning approach for the classification of\nEngineering (CAD) models using Convolutional Neural Networks (CNNs). Owing to\nthe availability of large annotated datasets and also enough computational\npower in the form of GPUs, many deep learning-based solutions for object\nclassification have been proposed of late, especially in the domain of images\nand graphical models. Nevertheless, very few solutions have been proposed for\nthe task of functional classification of CAD models. Hence, for this research,\nCAD models have been collected from Engineering Shape Benchmark (ESB), National\nDesign Repository (NDR) and augmented with newer models created using a\nmodelling software to form a dataset - 'CADNET'. It is proposed to use a\nresidual network architecture for CADNET, inspired by the popular ResNet. A\nweighted Light Field Descriptor (LFD) scheme is chosen as the method of feature\nextraction, and the generated images are fed as inputs to the CNN. The problem\nof class imbalance in the dataset is addressed using a class weights approach.\nExperiments have been conducted with other signatures such as geodesic distance\netc. using deep networks as well as other network architectures on the CADNET.\nThe LFD-based CNN approach using the proposed network architecture, along with\ngradient boosting yielded the best classification accuracy on CADNET.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 04:33:50 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Manda", "Bharadwaj", ""], ["Bhaskare", "Pranjal", ""], ["Muthuganapathy", "Ramanathan", ""]]}, {"id": "2107.06499", "submitter": "Daphne Ippolito", "authors": "Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas\n  Eck, Chris Callison-Burch, Nicholas Carlini", "title": "Deduplicating Training Data Makes Language Models Better", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that existing language modeling datasets contain many near-duplicate\nexamples and long repetitive substrings. As a result, over 1% of the unprompted\noutput of language models trained on these datasets is copied verbatim from the\ntraining data. We develop two tools that allow us to deduplicate training\ndatasets -- for example removing from C4 a single 61 word English sentence that\nis repeated over 60,000 times. Deduplication allows us to train models that\nemit memorized text ten times less frequently and require fewer train steps to\nachieve the same or better accuracy. We can also reduce train-test overlap,\nwhich affects over 4% of the validation set of standard datasets, thus allowing\nfor more accurate evaluation. We release code for reproducing our work and\nperforming dataset deduplication at\nhttps://github.com/google-research/deduplicate-text-datasets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 06:06:52 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Lee", "Katherine", ""], ["Ippolito", "Daphne", ""], ["Nystrom", "Andrew", ""], ["Zhang", "Chiyuan", ""], ["Eck", "Douglas", ""], ["Callison-Burch", "Chris", ""], ["Carlini", "Nicholas", ""]]}, {"id": "2107.06501", "submitter": "Qing Guo", "authors": "Yihao Huang and Qing Guo and Felix Juefei-Xu and Lei Ma and Weikai\n  Miao and Yang Liu and Geguang Pu", "title": "AdvFilter: Predictive Perturbation-aware Filtering against Adversarial\n  Attack via Multi-domain Learning", "comments": "This work has been accepted to ACM-MM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-level representation-guided pixel denoising and adversarial training are\nindependent solutions to enhance the robustness of CNNs against adversarial\nattacks by pre-processing input data and re-training models, respectively. Most\nrecently, adversarial training techniques have been widely studied and improved\nwhile the pixel denoising-based method is getting less attractive. However, it\nis still questionable whether there exists a more advanced pixel\ndenoising-based method and whether the combination of the two solutions\nbenefits each other. To this end, we first comprehensively investigate two\nkinds of pixel denoising methods for adversarial robustness enhancement (i.e.,\nexisting additive-based and unexplored filtering-based methods) under the loss\nfunctions of image-level and semantic-level restorations, respectively, showing\nthat pixel-wise filtering can obtain much higher image quality (e.g., higher\nPSNR) as well as higher robustness (e.g., higher accuracy on adversarial\nexamples) than existing pixel-wise additive-based method. However, we also\nobserve that the robustness results of the filtering-based method rely on the\nperturbation amplitude of adversarial examples used for training. To address\nthis problem, we propose predictive perturbation-aware pixel-wise filtering,\nwhere dual-perturbation filtering and an uncertainty-aware fusion module are\ndesigned and employed to automatically perceive the perturbation amplitude\nduring the training and testing process. The proposed method is termed as\nAdvFilter. Moreover, we combine adversarial pixel denoising methods with three\nadversarial training-based methods, hinting that considering data and models\njointly is able to achieve more robust CNNs. The experiments conduct on\nNeurIPS-2017DEV, SVHN, and CIFAR10 datasets and show the advantages over\nenhancing CNNs' robustness, high generalization to different models, and noise\nlevels.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 06:08:48 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Huang", "Yihao", ""], ["Guo", "Qing", ""], ["Juefei-Xu", "Felix", ""], ["Ma", "Lei", ""], ["Miao", "Weikai", ""], ["Liu", "Yang", ""], ["Pu", "Geguang", ""]]}, {"id": "2107.06511", "submitter": "Dingcheng Yang", "authors": "Dingcheng Yang, Wenjian Yu, Yuanbo Guo, Wenjie Liang", "title": "CNN-Cap: Effective Convolutional Neural Network Based Capacitance Models\n  for Full-Chip Parasitic Extraction", "comments": "9 pages, 13 figures. Accepted at 2021 International Conference On\n  Computer Aided Design (ICCAD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate capacitance extraction is becoming more important for designing\nintegrated circuits under advanced process technology. The pattern matching\nbased full-chip extraction methodology delivers fast computational speed, but\nsuffers from large error, and tedious efforts on building capacitance models of\nthe increasing structure patterns. In this work, we propose an effective method\nfor building convolutional neural network (CNN) based capacitance models\n(called CNN-Cap) for two-dimensional (2-D) structures in full-chip capacitance\nextraction. With a novel grid-based data representation, the proposed method is\nable to model the pattern with a variable number of conductors, so that largely\nreduce the number of patterns. Based on the ability of ResNet architecture on\ncapturing spatial information and the proposed training skills, the obtained\nCNN-Cap exhibits much better performance over the multilayer perception neural\nnetwork based capacitance model while being more versatile. Extensive\nexperiments on a 55nm and a 15nm process technologies have demonstrated that\nthe error of total capacitance produced with CNN-Cap is always within 1.3% and\nthe error of produced coupling capacitance is less than 10% in over 99.5%\nprobability. CNN-Cap runs more than 4000X faster than 2-D field solver on a GPU\nserver, while it consumes negligible memory compared to the look-up table based\ncapacitance model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 07:14:35 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yang", "Dingcheng", ""], ["Yu", "Wenjian", ""], ["Guo", "Yuanbo", ""], ["Liang", "Wenjie", ""]]}, {"id": "2107.06530", "submitter": "Suneung Kim", "authors": "Suneung-Kim, Seong-Whan Lee", "title": "Detection of Abnormal Behavior with Self-Supervised Gaze Estimation", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the recent outbreak of COVID-19, many classes, exams, and meetings\nhave been conducted non-face-to-face. However, the foundation for video\nconferencing solutions is still insufficient. So this technology has become an\nimportant issue. In particular, these technologies are essential for\nnon-face-to-face testing, and technology dissemination is urgent. In this\npaper, we present a single video conferencing solution using gaze estimation in\npreparation for these problems. Gaze is an important cue for the tasks such as\nanalysis of human behavior. Hence, numerous studies have been proposed to solve\ngaze estimation using deep learning, which is one of the most prominent methods\nup to date. We use these gaze estimation methods to detect abnormal behavior of\nvideo conferencing participants. Our contribution is as follows. i) We find and\napply the optimal network for the gaze estimation method and apply a\nself-supervised method to improve accuracy. ii) For anomaly detection, we\npresent a new dataset that aggregates the values of a new gaze, head pose, etc.\niii) We train newly created data on Multi Layer Perceptron (MLP) models to\ndetect anomaly behavior based on deep learning. We demonstrate the robustness\nof our method through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 07:58:59 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Suneung-Kim", "", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2107.06534", "submitter": "Zeeshan Akhtar", "authors": "Zeeshan Akhtar, and Ketan Rajawat", "title": "Zeroth and First Order Stochastic Frank-Wolfe Algorithms for Constrained\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers stochastic convex optimization problems with two sets of\nconstraints: (a) deterministic constraints on the domain of the optimization\nvariable, which are difficult to project onto; and (b) deterministic or\nstochastic constraints that admit efficient projection. Problems of this form\narise frequently in the context of semidefinite programming as well as when\nvarious NP-hard problems are solved approximately via semidefinite relaxation.\nSince projection onto the first set of constraints is difficult, it becomes\nnecessary to explore projection-free algorithms, such as the stochastic\nFrank-Wolfe (FW) algorithm. On the other hand, the second set of constraints\ncannot be handled in the same way, and must be incorporated as an indicator\nfunction within the objective function, thereby complicating the application of\nFW methods. Similar problems have been studied before, and solved using\nfirst-order stochastic FW algorithms by applying homotopy and Nesterov's\nsmoothing techniques to the indicator function. This work improves upon these\nexisting results and puts forth momentum-based first-order methods that yield\nimproved convergence rates, at par with the best known rates for problems\nwithout the second set of constraints. Zeroth-order variants of the proposed\nalgorithms are also developed and again improve upon the state-of-the-art rate\nresults. The efficacy of the proposed algorithms is tested on relevant\napplications of sparse matrix estimation, clustering via semidefinite\nrelaxation, and uniform sparsest cut problem.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:01:30 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Akhtar", "Zeeshan", ""], ["Rajawat", "Ketan", ""]]}, {"id": "2107.06543", "submitter": "Davide Bacciu", "authors": "Davide Bacciu, Siranush Akarmazyan, Eric Armengaud, Manlio Bacco,\n  George Bravos, Calogero Calandra, Emanuele Carlini, Antonio Carta, Pietro\n  Cassara, Massimo Coppola, Charalampos Davalas, Patrizio Dazzi, Maria Carmela\n  Degennaro, Daniele Di Sarli, J\\\"urgen Dobaj, Claudio Gallicchio, Sylvain\n  Girbal, Alberto Gotta, Riccardo Groppo, Vincenzo Lomonaco, Georg Macher,\n  Daniele Mazzei, Gabriele Mencagli, Dimitrios Michail, Alessio Micheli,\n  Roberta Peroglio, Salvatore Petroni, Rosaria Potenza, Farank Pourdanesh,\n  Christos Sardianos, Konstantinos Tserpes, Fulvio Tagliab\\`o, Jakob Valtl,\n  Iraklis Varlamis, Omar Veledar", "title": "TEACHING -- Trustworthy autonomous cyber-physical applications through\n  human-centred intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the perspective of the H2020 TEACHING project on the\nnext generation of autonomous applications running in a distributed and highly\nheterogeneous environment comprising both virtual and physical resources\nspanning the edge-cloud continuum. TEACHING puts forward a human-centred vision\nleveraging the physiological, emotional, and cognitive state of the users as a\ndriver for the adaptation and optimization of the autonomous applications. It\ndoes so by building a distributed, embedded and federated learning system\ncomplemented by methods and tools to enforce its dependability, security and\nprivacy preservation. The paper discusses the main concepts of the TEACHING\napproach and singles out the main AI-related research challenges associated\nwith it. Further, we provide a discussion of the design choices for the\nTEACHING system to tackle the aforementioned challenges\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:25:58 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bacciu", "Davide", ""], ["Akarmazyan", "Siranush", ""], ["Armengaud", "Eric", ""], ["Bacco", "Manlio", ""], ["Bravos", "George", ""], ["Calandra", "Calogero", ""], ["Carlini", "Emanuele", ""], ["Carta", "Antonio", ""], ["Cassara", "Pietro", ""], ["Coppola", "Massimo", ""], ["Davalas", "Charalampos", ""], ["Dazzi", "Patrizio", ""], ["Degennaro", "Maria Carmela", ""], ["Di Sarli", "Daniele", ""], ["Dobaj", "J\u00fcrgen", ""], ["Gallicchio", "Claudio", ""], ["Girbal", "Sylvain", ""], ["Gotta", "Alberto", ""], ["Groppo", "Riccardo", ""], ["Lomonaco", "Vincenzo", ""], ["Macher", "Georg", ""], ["Mazzei", "Daniele", ""], ["Mencagli", "Gabriele", ""], ["Michail", "Dimitrios", ""], ["Micheli", "Alessio", ""], ["Peroglio", "Roberta", ""], ["Petroni", "Salvatore", ""], ["Potenza", "Rosaria", ""], ["Pourdanesh", "Farank", ""], ["Sardianos", "Christos", ""], ["Tserpes", "Konstantinos", ""], ["Tagliab\u00f2", "Fulvio", ""], ["Valtl", "Jakob", ""], ["Varlamis", "Iraklis", ""], ["Veledar", "Omar", ""]]}, {"id": "2107.06546", "submitter": "Bertrand Higy", "authors": "Afra Alishahi, Grzegorz Chrupa{\\l}a, Alejandrina Cristia, Emmanuel\n  Dupoux, Bertrand Higy, Marvin Lavechin, Okko R\\\"as\\\"anen and Chen Yu", "title": "ZR-2021VG: Zero-Resource Speech Challenge, Visually-Grounded Language\n  Modelling track, 2021 edition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the visually-grounded language modelling track that was introduced\nin the Zero-Resource Speech challenge, 2021 edition, 2nd round. We motivate the\nnew track and discuss participation rules in detail. We also present the two\nbaseline systems that were developed for this track.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:29:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alishahi", "Afra", ""], ["Chrupa\u0142a", "Grzegorz", ""], ["Cristia", "Alejandrina", ""], ["Dupoux", "Emmanuel", ""], ["Higy", "Bertrand", ""], ["Lavechin", "Marvin", ""], ["R\u00e4s\u00e4nen", "Okko", ""], ["Yu", "Chen", ""]]}, {"id": "2107.06548", "submitter": "Alaa Awad Abdellatif", "authors": "Alaa Awad Abdellatif, Naram Mhaisen, Amr Mohamed, Aiman Erbad, Mohsen\n  Guizani, Zaher Dawy, Wassim Nasreddine", "title": "Communication-Efficient Hierarchical Federated Learning for IoT\n  Heterogeneous Systems with Imbalanced Data", "comments": "A version of this work has been submitted in Transactions on Network\n  Science and Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) is a distributed learning methodology that allows\nmultiple nodes to cooperatively train a deep learning model, without the need\nto share their local data. It is a promising solution for telemonitoring\nsystems that demand intensive data collection, for detection, classification,\nand prediction of future events, from different locations while maintaining a\nstrict privacy constraint. Due to privacy concerns and critical communication\nbottlenecks, it can become impractical to send the FL updated models to a\ncentralized server. Thus, this paper studies the potential of hierarchical FL\nin IoT heterogeneous systems and propose an optimized solution for user\nassignment and resource allocation on multiple edge nodes. In particular, this\nwork focuses on a generic class of machine learning models that are trained\nusing gradient-descent-based schemes while considering the practical\nconstraints of non-uniformly distributed data across different users. We\nevaluate the proposed system using two real-world datasets, and we show that it\noutperforms state-of-the-art FL solutions. In particular, our numerical results\nhighlight the effectiveness of our approach and its ability to provide 4-6%\nincrease in the classification accuracy, with respect to hierarchical FL\nschemes that consider distance-based user assignment. Furthermore, the proposed\napproach could significantly accelerate FL training and reduce communication\noverhead by providing 75-85% reduction in the communication rounds between edge\nnodes and the centralized server, for the same model accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 08:32:39 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Mhaisen", "Naram", ""], ["Mohamed", "Amr", ""], ["Erbad", "Aiman", ""], ["Guizani", "Mohsen", ""], ["Dawy", "Zaher", ""], ["Nasreddine", "Wassim", ""]]}, {"id": "2107.06566", "submitter": "Erich Schubert", "authors": "Erik Thordsen and Erich Schubert", "title": "MESS: Manifold Embedding Motivated Super Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches in the field of machine learning and data analysis rely on\nthe assumption that the observed data lies on lower-dimensional manifolds. This\nassumption has been verified empirically for many real data sets. To make use\nof this manifold assumption one generally requires the manifold to be locally\nsampled to a certain density such that features of the manifold can be\nobserved. However, for increasing intrinsic dimensionality of a data set the\nrequired data density introduces the need for very large data sets, resulting\nin one of the many faces of the curse of dimensionality. To combat the\nincreased requirement for local data density we propose a framework to generate\nvirtual data points that faithful to an approximate embedding function\nunderlying the manifold observable in the data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:07:54 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Thordsen", "Erik", ""], ["Schubert", "Erich", ""]]}, {"id": "2107.06573", "submitter": "Zeng Wenqi", "authors": "Wenqi Zeng, Siqin Cao, Xuhui Huang, Yuan Yao", "title": "A Note on Learning Rare Events in Molecular Dynamics using LSTM and\n  Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks for language models like long short-term memory\n(LSTM) have been utilized as a tool for modeling and predicting long term\ndynamics of complex stochastic molecular systems. Recently successful examples\non learning slow dynamics by LSTM are given with simulation data of low\ndimensional reaction coordinate. However, in this report we show that the\nfollowing three key factors significantly affect the performance of language\nmodel learning, namely dimensionality of reaction coordinates, temporal\nresolution and state partition. When applying recurrent neural networks to\nmolecular dynamics simulation trajectories of high dimensionality, we find that\nrare events corresponding to the slow dynamics might be obscured by other\nfaster dynamics of the system, and cannot be efficiently learned. Under such\nconditions, we find that coarse graining the conformational space into\nmetastable states and removing recrossing events when estimating transition\nprobabilities between states could greatly help improve the accuracy of slow\ndynamics learning in molecular dynamics. Moreover, we also explore other models\nlike Transformer, which do not show superior performance than LSTM in\novercoming these issues. Therefore, to learn rare events of slow molecular\ndynamics by LSTM and Transformer, it is critical to choose proper temporal\nresolution (i.e., saving intervals of MD simulation trajectories) and state\npartition in high resolution data, since deep neural network models might not\nautomatically disentangle slow dynamics from fast dynamics when both are\npresent in data influencing each other.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:26:36 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zeng", "Wenqi", ""], ["Cao", "Siqin", ""], ["Huang", "Xuhui", ""], ["Yao", "Yuan", ""]]}, {"id": "2107.06578", "submitter": "Stephan Fahrenkrog-Petersen", "authors": "Fabian R\\\"osel, Stephan A. Fahrenkrog-Petersen, Han van der Aa,\n  Matthias Weidlich", "title": "A Distance Measure for Privacy-preserving Process Mining based on\n  Feature Learning", "comments": "Accepted for 17th International Workshop on Business Process\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable process analysis based on an event log without compromising the\nprivacy of individuals involved in process execution, a log may be anonymized.\nSuch anonymization strives to transform a log so that it satisfies provable\nprivacy guarantees, while largely maintaining its utility for process analysis.\nExisting techniques perform anonymization using simple, syntactic measures to\nidentify suitable transformation operations. This way, the semantics of the\nactivities referenced by the events in a trace are neglected, potentially\nleading to transformations in which events of unrelated activities are merged.\nTo avoid this and incorporate the semantics of activities during anonymization,\nwe propose to instead incorporate a distance measure based on feature learning.\nSpecifically, we show how embeddings of events enable the definition of a\ndistance measure for traces to guide event log anonymization. Our experiments\nwith real-world data indicate that anonymization using this measure, compared\nto a syntactic one, yields logs that are closer to the original log in various\ndimensions and, hence, have higher utility for process analysis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:44:28 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["R\u00f6sel", "Fabian", ""], ["Fahrenkrog-Petersen", "Stephan A.", ""], ["van der Aa", "Han", ""], ["Weidlich", "Matthias", ""]]}, {"id": "2107.06580", "submitter": "David Roschewitz", "authors": "David Roschewitz, Mary-Anne Hartley, Luca Corinzia, Martin Jaggi", "title": "IFedAvg: Interpretable Data-Interoperability for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the ever-growing demand for privacy-oriented machine learning has\nmotivated researchers to develop federated and decentralized learning\ntechniques, allowing individual clients to train models collaboratively without\ndisclosing their private datasets. However, widespread adoption has been\nlimited in domains relying on high levels of user trust, where assessment of\ndata compatibility is essential. In this work, we define and address low\ninteroperability induced by underlying client data inconsistencies in federated\nlearning for tabular data. The proposed method, iFedAvg, builds on federated\naveraging adding local element-wise affine layers to allow for a personalized\nand granular understanding of the collaborative learning process. Thus,\nenabling the detection of outlier datasets in the federation and also learning\nthe compensation for local data distribution shifts without sharing any\noriginal data. We evaluate iFedAvg using several public benchmarks and a\npreviously unstudied collection of real-world datasets from the 2014 - 2016\nWest African Ebola epidemic, jointly forming the largest such dataset in the\nworld. In all evaluations, iFedAvg achieves competitive average performance\nwith negligible overhead. It additionally shows substantial improvement on\noutlier clients, highlighting increased robustness to individual dataset\nshifts. Most importantly, our method provides valuable client-specific insights\nat a fine-grained level to guide interoperable federated learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:54:00 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Roschewitz", "David", ""], ["Hartley", "Mary-Anne", ""], ["Corinzia", "Luca", ""], ["Jaggi", "Martin", ""]]}, {"id": "2107.06608", "submitter": "Nadav Cohen", "authors": "Omer Elkabetz and Nadav Cohen", "title": "Continuous vs. Discrete Optimization of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing analyses of optimization in deep learning are either continuous,\nfocusing on (variants of) gradient flow, or discrete, directly treating\n(variants of) gradient descent. Gradient flow is amenable to theoretical\nanalysis, but is stylized and disregards computational efficiency. The extent\nto which it represents gradient descent is an open question in deep learning\ntheory. The current paper studies this question. Viewing gradient descent as an\napproximate numerical solution to the initial value problem of gradient flow,\nwe find that the degree of approximation depends on the curvature along the\nlatter's trajectory. We then show that over deep neural networks with\nhomogeneous activations, gradient flow trajectories enjoy favorable curvature,\nsuggesting they are well approximated by gradient descent. This finding allows\nus to translate an analysis of gradient flow over deep linear neural networks\ninto a guarantee that gradient descent efficiently converges to global minimum\nalmost surely under random initialization. Experiments suggest that over simple\ndeep neural networks, gradient descent with conventional step size is indeed\nclose to the continuous limit. We hypothesize that the theory of gradient flows\nwill be central to unraveling mysteries behind deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 10:59:57 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Elkabetz", "Omer", ""], ["Cohen", "Nadav", ""]]}, {"id": "2107.06615", "submitter": "Simon Omlor", "authors": "Alexander Munteanu, Simon Omlor, David Woodruff", "title": "Oblivious sketching for logistic regression", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What guarantees are possible for solving logistic regression in one pass over\na data stream? To answer this question, we present the first data oblivious\nsketch for logistic regression. Our sketch can be computed in input sparsity\ntime over a turnstile data stream and reduces the size of a $d$-dimensional\ndata set from $n$ to only $\\operatorname{poly}(\\mu d\\log n)$ weighted points,\nwhere $\\mu$ is a useful parameter which captures the complexity of compressing\nthe data. Solving (weighted) logistic regression on the sketch gives an $O(\\log\nn)$-approximation to the original problem on the full data set. We also show\nhow to obtain an $O(1)$-approximation with slight modifications. Our sketches\nare fast, simple, easy to implement, and our experiments demonstrate their\npracticality.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 11:29:26 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Munteanu", "Alexander", ""], ["Omlor", "Simon", ""], ["Woodruff", "David", ""]]}, {"id": "2107.06618", "submitter": "Daniel C. Castro", "authors": "Shruthi Bannur, Ozan Oktay, Melanie Bernhardt, Anton Schwaighofer,\n  Rajesh Jena, Besmira Nushi, Sharan Wadhwani, Aditya Nori, Kal Natarajan,\n  Shazad Ashraf, Javier Alvarez-Valle, Daniel C. Castro", "title": "Hierarchical Analysis of Visual COVID-19 Features from Chest Radiographs", "comments": "Presented at ICML 2021 Workshop on Interpretable Machine Learning in\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chest radiography has been a recommended procedure for patient triaging and\nresource management in intensive care units (ICUs) throughout the COVID-19\npandemic. The machine learning efforts to augment this workflow have been long\nchallenged due to deficiencies in reporting, model evaluation, and failure mode\nanalysis. To address some of those shortcomings, we model radiological features\nwith a human-interpretable class hierarchy that aligns with the radiological\ndecision process. Also, we propose the use of a data-driven error analysis\nmethodology to uncover the blind spots of our model, providing further\ntransparency on its clinical utility. For example, our experiments show that\nmodel failures highly correlate with ICU imaging conditions and with the\ninherent difficulty in distinguishing certain types of radiological features.\nAlso, our hierarchical interpretation and analysis facilitates the comparison\nwith respect to radiologists' findings and inter-variability, which in return\nhelps us to better assess the clinical applicability of models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 11:37:28 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bannur", "Shruthi", ""], ["Oktay", "Ozan", ""], ["Bernhardt", "Melanie", ""], ["Schwaighofer", "Anton", ""], ["Jena", "Rajesh", ""], ["Nushi", "Besmira", ""], ["Wadhwani", "Sharan", ""], ["Nori", "Aditya", ""], ["Natarajan", "Kal", ""], ["Ashraf", "Shazad", ""], ["Alvarez-Valle", "Javier", ""], ["Castro", "Daniel C.", ""]]}, {"id": "2107.06626", "submitter": "Ora Nova Fandina", "authors": "Yair Bartal and Ora Nova Fandina and Kasper Green Larsen", "title": "Optimality of the Johnson-Lindenstrauss Dimensionality Reduction for\n  Practical Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is well known that the Johnson-Lindenstrauss dimensionality reduction\nmethod is optimal for worst case distortion. While in practice many other\nmethods and heuristics are used, not much is known in terms of bounds on their\nperformance. The question of whether the JL method is optimal for practical\nmeasures of distortion was recently raised in \\cite{BFN19} (NeurIPS'19). They\nprovided upper bounds on its quality for a wide range of practical measures and\nshowed that indeed these are best possible in many cases. Yet, some of the most\nimportant cases, including the fundamental case of average distortion were left\nopen. In particular, they show that the JL transform has $1+\\epsilon$ average\ndistortion for embedding into $k$-dimensional Euclidean space, where\n$k=O(1/\\eps^2)$, and for more general $q$-norms of distortion, $k =\nO(\\max\\{1/\\eps^2,q/\\eps\\})$, whereas tight lower bounds were established only\nfor large values of $q$ via reduction to the worst case.\n  In this paper we prove that these bounds are best possible for any\ndimensionality reduction method, for any $1 \\leq q \\leq O(\\frac{\\log (2\\eps^2\nn)}{\\eps})$ and $\\epsilon \\geq \\frac{1}{\\sqrt{n}}$, where $n$ is the size of\nthe subset of Euclidean space.\n  Our results imply that the JL method is optimal for various distortion\nmeasures commonly used in practice, such as {\\it stress, energy} and {\\it\nrelative error}. We prove that if any of these measures is bounded by $\\eps$\nthen $k=\\Omega(1/\\eps^2)$, for any $\\epsilon \\geq \\frac{1}{\\sqrt{n}}$, matching\nthe upper bounds of \\cite{BFN19} and extending their tightness results for the\nfull range moment analysis.\n  Our results may indicate that the JL dimensionality reduction method should\nbe considered more often in practical applications, and the bounds we provide\nfor its quality should be served as a measure for comparison when evaluating\nthe performance of other methods and heuristics.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:00:46 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bartal", "Yair", ""], ["Fandina", "Ora Nova", ""], ["Larsen", "Kasper Green", ""]]}, {"id": "2107.06629", "submitter": "Miroslav Bogdanovic", "authors": "Miroslav Bogdanovic, Majid Khadiv, Ludovic Righetti", "title": "Model-free Reinforcement Learning for Robust Locomotion Using Trajectory\n  Optimization for Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a general, two-stage reinforcement learning approach\nfor going from a single demonstration trajectory to a robust policy that can be\ndeployed on hardware without any additional training. The demonstration is used\nin the first stage as a starting point to facilitate initial exploration. In\nthe second stage, the relevant task reward is optimized directly and a policy\nrobust to environment uncertainties is computed. We demonstrate and examine in\ndetail performance and robustness of our approach on highly dynamic hopping and\nbounding tasks on a real quadruped robot.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:07:19 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bogdanovic", "Miroslav", ""], ["Khadiv", "Majid", ""], ["Righetti", "Ludovic", ""]]}, {"id": "2107.06630", "submitter": "Masahiro Sato", "authors": "Masahiro Sato", "title": "Online Evaluation Methods for the Causal Effect of Recommendations", "comments": "accepted at RecSys 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating the causal effect of recommendations is an important objective\nbecause the causal effect on user interactions can directly leads to an\nincrease in sales and user engagement. To select an optimal recommendation\nmodel, it is common to conduct A/B testing to compare model performance.\nHowever, A/B testing of causal effects requires a large number of users, making\nsuch experiments costly and risky. We therefore propose the first interleaving\nmethods that can efficiently compare recommendation models in terms of causal\neffects. In contrast to conventional interleaving methods, we measure the\noutcomes of both items on an interleaved list and items not on the interleaved\nlist, since the causal effect is the difference between outcomes with and\nwithout recommendations. To ensure that the evaluations are unbiased, we either\nselect items with equal probability or weight the outcomes using inverse\npropensity scores. We then verify the unbiasedness and efficiency of online\nevaluation methods through simulated online experiments. The results indicate\nthat our proposed methods are unbiased and that they have superior efficiency\nto A/B testing.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:12:59 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 14:02:04 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sato", "Masahiro", ""]]}, {"id": "2107.06639", "submitter": "Kacper Sokol", "authors": "Kacper Sokol and Peter Flach", "title": "You Only Write Thrice: Creating Documents, Computational Notebooks and\n  Presentations From a Single Source", "comments": "Published at Rethinking ML Papers -- ICLR 2021 Workshop. OpenReview:\n  https://openreview.net/forum?id=i4zpuNRiU4G Exhibit:\n  https://so-cool.github.io/you-only-write-thrice/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Academic trade requires juggling multiple variants of the same content\npublished in different formats: manuscripts, presentations, posters and\ncomputational notebooks. The need to track versions to accommodate for the\nwrite--review--rebut--revise life-cycle adds another layer of complexity. We\npropose to significantly reduce this burden by maintaining a single source\ndocument in a version-controlled environment (such as git), adding\nfunctionality to generate a collection of output formats popular in academia.\nTo this end, we utilise various open-source tools from the Jupyter scientific\ncomputing ecosystem and operationalise selected software engineering concepts.\nWe offer a proof-of-concept workflow that composes Jupyter Book (an online\ndocument), Jupyter Notebook (a computational narrative) and reveal.js slides\nfrom a single markdown source file. Hosted on GitHub, our approach supports\nchange tracking and versioning, as well as a transparent review process based\non the underlying code issue management infrastructure. An exhibit of our\nworkflow can be previewed at https://so-cool.github.io/you-only-write-thrice/.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 21:02:09 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Sokol", "Kacper", ""], ["Flach", "Peter", ""]]}, {"id": "2107.06642", "submitter": "Manh Luong", "authors": "Manh Luong and Viet Anh Tran", "title": "Many-to-Many Voice Conversion based Feature Disentanglement using\n  Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Voice conversion is a challenging task which transforms the voice\ncharacteristics of a source speaker to a target speaker without changing\nlinguistic content. Recently, there have been many works on many-to-many Voice\nConversion (VC) based on Variational Autoencoder (VAEs) achieving good results,\nhowever, these methods lack the ability to disentangle speaker identity and\nlinguistic content to achieve good performance on unseen speaker scenarios. In\nthis paper, we propose a new method based on feature disentanglement to tackle\nmany to many voice conversion. The method has the capability to disentangle\nspeaker identity and linguistic content from utterances, it can convert from\nmany source speakers to many target speakers with a single autoencoder network.\nMoreover, it naturally deals with the unseen target speaker scenarios. We\nperform both objective and subjective evaluations to show the competitive\nperformance of our proposed method compared with other state-of-the-art models\nin terms of naturalness and target speaker similarity.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:31:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Luong", "Manh", ""], ["Tran", "Viet Anh", ""]]}, {"id": "2107.06650", "submitter": "Tian Zhou", "authors": "Tian Zhou, Hao He, Shengjun Pan, Niklas Karlsson, Bharatbhushan\n  Shetty, Brendan Kitts, Djordje Gligorijevic, San Gultekin, Tingyu Mao, Junwei\n  Pan, Jianlong Zhang and Aaron Flores", "title": "An Efficient Deep Distribution Network for Bid Shading in First-Price\n  Auctions", "comments": "In Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD'21), August 14-18, 2021, Singapore", "journal-ref": null, "doi": "10.1145/3447548.3467167", "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Since 2019, most ad exchanges and sell-side platforms (SSPs), in the online\nadvertising industry, shifted from second to first price auctions. Due to the\nfundamental difference between these auctions, demand-side platforms (DSPs)\nhave had to update their bidding strategies to avoid bidding unnecessarily high\nand hence overpaying. Bid shading was proposed to adjust the bid price intended\nfor second-price auctions, in order to balance cost and winning probability in\na first-price auction setup. In this study, we introduce a novel deep\ndistribution network for optimal bidding in both open (non-censored) and closed\n(censored) online first-price auctions. Offline and online A/B testing results\nshow that our algorithm outperforms previous state-of-art algorithms in terms\nof both surplus and effective cost per action (eCPX) metrics. Furthermore, the\nalgorithm is optimized in run-time and has been deployed into VerizonMedia DSP\nas production algorithm, serving hundreds of billions of bid requests per day.\nOnline A/B test shows that advertiser's ROI are improved by +2.4%, +2.4%, and\n+8.6% for impression based (CPM), click based (CPC), and conversion based (CPA)\ncampaigns respectively.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:44:39 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 17:24:42 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zhou", "Tian", ""], ["He", "Hao", ""], ["Pan", "Shengjun", ""], ["Karlsson", "Niklas", ""], ["Shetty", "Bharatbhushan", ""], ["Kitts", "Brendan", ""], ["Gligorijevic", "Djordje", ""], ["Gultekin", "San", ""], ["Mao", "Tingyu", ""], ["Pan", "Junwei", ""], ["Zhang", "Jianlong", ""], ["Flores", "Aaron", ""]]}, {"id": "2107.06657", "submitter": "Cedric Richter", "authors": "Cedric Richter, Heike Wehrheim", "title": "DeepMutants: Training neural bug detectors with contextual mutations", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning-based bug detectors promise to find bugs in large code bases by\nexploiting natural hints such as names of variables and functions or comments.\nStill, existing techniques tend to underperform when presented with realistic\nbugs. We believe bug detector learning to currently suffer from a lack of\nrealistic defective training examples. In fact, real world bugs are scarce\nwhich has driven existing methods to train on artificially created and mostly\nunrealistic mutants. In this work, we propose a novel contextual mutation\noperator which incorporates knowledge about the mutation context to dynamically\ninject natural and more realistic faults into code. Our approach employs a\nmasked language model to produce a context-dependent distribution over feasible\ntoken replacements. The evaluation shows that sampling from a language model\ndoes not only produce mutants which more accurately represent real bugs but\nalso lead to better performing bug detectors, both on artificial benchmarks and\non real world source code.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:45:48 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Richter", "Cedric", ""], ["Wehrheim", "Heike", ""]]}, {"id": "2107.06658", "submitter": "Matthew Levine", "authors": "Matthew E. Levine and Andrew M. Stuart", "title": "A Framework for Machine Learning of Model Error in Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of data-informed predictive models for dynamical systems is\nof widespread interest in many disciplines. We present a unifying framework for\nblending mechanistic and machine-learning approaches to identify dynamical\nsystems from data. We compare pure data-driven learning with hybrid models\nwhich incorporate imperfect domain knowledge. We cast the problem in both\ncontinuous- and discrete-time, for problems in which the model error is\nmemoryless and in which it has significant memory, and we compare data-driven\nand hybrid approaches experimentally. Our formulation is agnostic to the chosen\nmachine learning model.\n  Using Lorenz '63 and Lorenz '96 Multiscale systems, we find that hybrid\nmethods substantially outperform solely data-driven approaches in terms of data\nhunger, demands for model complexity, and overall predictive performance. We\nalso find that, while a continuous-time framing allows for robustness to\nirregular sampling and desirable domain-interpretability, a discrete-time\nframing can provide similar or better predictive performance, especially when\ndata are undersampled and the vector field cannot be resolved.\n  We study model error from the learning theory perspective, defining excess\nrisk and generalization error; for a linear model of the error used to learn\nabout ergodic dynamical systems, both errors are bounded by terms that diminish\nwith the square-root of T. We also illustrate scenarios that benefit from\nmodeling with memory, proving that continuous-time recurrent neural networks\n(RNNs) can, in principle, learn memory-dependent model error and reconstruct\nthe original system arbitrarily well; numerical results depict challenges in\nrepresenting memory by this approach. We also connect RNNs to reservoir\ncomputing and thereby relate the learning of memory-dependent error to recent\nwork on supervised learning between Banach spaces using random features.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:47:48 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Levine", "Matthew E.", ""], ["Stuart", "Andrew M.", ""]]}, {"id": "2107.06661", "submitter": "Ingmar Schubert", "authors": "Ingmar Schubert and Ozgur S. Oguz and Marc Toussaint", "title": "Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": "ICLR 2021 - 9th International Conference on Learning\n  Representations", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In high-dimensional state spaces, the usefulness of Reinforcement Learning\n(RL) is limited by the problem of exploration. This issue has been addressed\nusing potential-based reward shaping (PB-RS) previously. In the present work,\nwe introduce Final-Volume-Preserving Reward Shaping (FV-RS). FV-RS relaxes the\nstrict optimality guarantees of PB-RS to a guarantee of preserved long-term\nbehavior. Being less restrictive, FV-RS allows for reward shaping functions\nthat are even better suited for improving the sample efficiency of RL\nalgorithms. In particular, we consider settings in which the agent has access\nto an approximate plan. Here, we use examples of simulated robotic manipulation\ntasks to demonstrate that plan-based FV-RS can indeed significantly improve the\nsample efficiency of RL over plan-based PB-RS.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:55:41 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Schubert", "Ingmar", ""], ["Oguz", "Ozgur S.", ""], ["Toussaint", "Marc", ""]]}, {"id": "2107.06665", "submitter": "Mahsa Forouzesh", "authors": "Mahsa Forouzesh and Patrick Thiran", "title": "Disparity Between Batches as a Signal for Early Stopping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a metric for evaluating the generalization ability of deep neural\nnetworks trained with mini-batch gradient descent. Our metric, called gradient\ndisparity, is the $\\ell_2$ norm distance between the gradient vectors of two\nmini-batches drawn from the training set. It is derived from a probabilistic\nupper bound on the difference between the classification errors over a given\nmini-batch, when the network is trained on this mini-batch and when the network\nis trained on another mini-batch of points sampled from the same dataset. We\nempirically show that gradient disparity is a very promising early-stopping\ncriterion (i) when data is limited, as it uses all the samples for training and\n(ii) when available data has noisy labels, as it signals overfitting better\nthan the validation data. Furthermore, we show in a wide range of experimental\nsettings that gradient disparity is strongly related to the generalization\nerror between the training and test sets, and that it is also very informative\nabout the level of label noise.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 12:59:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Forouzesh", "Mahsa", ""], ["Thiran", "Patrick", ""]]}, {"id": "2107.06668", "submitter": "Lixuan Yang", "authors": "Lixuan Yang and Dario Rossi", "title": "Thinkback: Task-SpecificOut-of-Distribution Detection", "comments": null, "journal-ref": "International Conference on Machine Leanring workshop on\n  Uncertainty and Robustness in Deep Learning 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased success of Deep Learning (DL) has recently sparked large-scale\ndeployment of DL models in many diverse industry segments. Yet, a crucial\nweakness of supervised model is the inherent difficulty in handling\nout-of-distribution samples, i.e., samples belonging to classes that were not\npresented to the model at training time. We propose in this paper a novel way\nto formulate the out-of-distribution detection problem, tailored for DL models.\nOur method does not require fine tuning process on training data, yet is\nsignificantly more accurate than the state of the art for out-of-distribution\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 09:34:26 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yang", "Lixuan", ""], ["Rossi", "Dario", ""]]}, {"id": "2107.06675", "submitter": "Florian Ziel", "authors": "Florian Ziel", "title": "M5 Competition Uncertainty: Overdispersion, distributional forecasting,\n  GAMLSS and beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The M5 competition uncertainty track aims for probabilistic forecasting of\nsales of thousands of Walmart retail goods. We show that the M5 competition\ndata faces strong overdispersion and sporadic demand, especially zero demand.\nWe discuss resulting modeling issues concerning adequate probabilistic\nforecasting of such count data processes. Unfortunately, the majority of\npopular prediction methods used in the M5 competition (e.g. lightgbm and\nxgboost GBMs) fails to address the data characteristics due to the considered\nobjective functions. The distributional forecasting provides a suitable\nmodeling approach for to the overcome those problems. The GAMLSS framework\nallows flexible probabilistic forecasting using low dimensional distributions.\nWe illustrate, how the GAMLSS approach can be applied for the M5 competition\ndata by modeling the location and scale parameter of various distributions,\ne.g. the negative binomial distribution. Finally, we discuss software packages\nfor distributional modeling and their drawback, like the R package gamlss with\nits package extensions, and (deep) distributional forecasting libraries such as\nTensorFlow Probability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:05:55 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ziel", "Florian", ""]]}, {"id": "2107.06676", "submitter": "Steven W. D. Chien", "authors": "Martin Svedin, Artur Podobas, Steven W. D. Chien, Stefano Markidis", "title": "Higgs Boson Classification: Brain-inspired BCPNN Learning with\n  StreamBrain", "comments": "Submitted to The 2nd Workshop on Artificial Intelligence and Machine\n  Learning for Scientific Applications (AI4S 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most promising approaches for data analysis and exploration of\nlarge data sets is Machine Learning techniques that are inspired by brain\nmodels. Such methods use alternative learning rules potentially more\nefficiently than established learning rules. In this work, we focus on the\npotential of brain-inspired ML for exploiting High-Performance Computing (HPC)\nresources to solve ML problems: we discuss the BCPNN and an HPC implementation,\ncalled StreamBrain, its computational cost, suitability to HPC systems. As an\nexample, we use StreamBrain to analyze the Higgs Boson dataset from High Energy\nPhysics and discriminate between background and signal classes in collisions of\nhigh-energy particle colliders. Overall, we reach up to 69.15% accuracy and\n76.4% Area Under the Curve (AUC) performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:08:19 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Svedin", "Martin", ""], ["Podobas", "Artur", ""], ["Chien", "Steven W. D.", ""], ["Markidis", "Stefano", ""]]}, {"id": "2107.06677", "submitter": "Miguel Angel Gutierrez Estevez", "authors": "M. A. Gutierrez-Estevez, Martin Kasparick, Renato L. G. Cavalvante,\n  S{\\l}awomir Sta\\'nczak", "title": "Hybrid Model and Data Driven Algorithm for Online Learning of Any-to-Any\n  Path Loss Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning any-to-any (A2A) path loss maps, where the objective is the\nreconstruction of path loss between any two given points in a map, might be a\nkey enabler for many applications that rely on device-to-device (D2D)\ncommunication. Such applications include machine-type communications (MTC) or\nvehicle-to-vehicle (V2V) communications. Current approaches for learning A2A\nmaps are either model-based methods, or pure data-driven methods. Model-based\nmethods have the advantage that they can generate reliable estimations with low\ncomputational complexity, but they cannot exploit information coming from data.\nPure data-driven methods can achieve good performance without assuming any\nphysical model, but their complexity and their lack of robustness is not\nacceptable for many applications. In this paper, we propose a novel hybrid\nmodel and data-driven approach that fuses information obtained from datasets\nand models in an online fashion. To that end, we leverage the framework of\nstochastic learning to deal with the sequential arrival of samples and propose\nan online algorithm that alternatively and sequentially minimizes the original\nnon-convex problem. A proof of convergence is presented, along with experiments\nbased firstly on synthetic data, and secondly on a more realistic dataset for\nV2X, with both experiments showing promising results.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:08:25 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Gutierrez-Estevez", "M. A.", ""], ["Kasparick", "Martin", ""], ["Cavalvante", "Renato L. G.", ""], ["Sta\u0144czak", "S\u0142awomir", ""]]}, {"id": "2107.06686", "submitter": "Djordje Grbic", "authors": "Djordje Grbic and Sebastian Risi", "title": "Safer Reinforcement Learning through Transferable Instinct Networks", "comments": "The paper was accepted in the ALIFE 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Random exploration is one of the main mechanisms through which reinforcement\nlearning (RL) finds well-performing policies. However, it can lead to\nundesirable or catastrophic outcomes when learning online in safety-critical\nenvironments. In fact, safe learning is one of the major obstacles towards\nreal-world agents that can learn during deployment. One way of ensuring that\nagents respect hard limitations is to explicitly configure boundaries in which\nthey can operate. While this might work in some cases, we do not always have\nclear a-priori information which states and actions can lead dangerously close\nto hazardous states. Here, we present an approach where an additional policy\ncan override the main policy and offer a safer alternative action. In our\ninstinct-regulated RL (IR^2L) approach, an \"instinctual\" network is trained to\nrecognize undesirable situations, while guarding the learning policy against\nentering them. The instinct network is pre-trained on a single task where it is\nsafe to make mistakes, and transferred to environments in which learning a new\ntask safely is critical. We demonstrate IR^2L in the OpenAI Safety gym domain,\nin which it receives a significantly lower number of safety violations during\ntraining than a baseline RL approach while reaching similar task performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:22:04 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Grbic", "Djordje", ""], ["Risi", "Sebastian", ""]]}, {"id": "2107.06692", "submitter": "Ariyan Bighashdel", "authors": "Ariyan Bighashdel, Panagiotis Meletis, Pavol Jancura, and Gijs\n  Dubbelman", "title": "Deep Adaptive Multi-Intention Inverse Reinforcement Learning", "comments": "Accepted for presentation at ECML/PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a deep Inverse Reinforcement Learning (IRL) framework\nthat can learn an a priori unknown number of nonlinear reward functions from\nunlabeled experts' demonstrations. For this purpose, we employ the tools from\nDirichlet processes and propose an adaptive approach to simultaneously account\nfor both complex and unknown number of reward functions. Using the conditional\nmaximum entropy principle, we model the experts' multi-intention behaviors as a\nmixture of latent intention distributions and derive two algorithms to estimate\nthe parameters of the deep reward network along with the number of experts'\nintentions from unlabeled demonstrations. The proposed algorithms are evaluated\non three benchmarks, two of which have been specifically extended in this study\nfor multi-intention IRL, and compared with well-known baselines. We demonstrate\nthrough several experiments the advantages of our algorithms over the existing\napproaches and the benefits of online inferring, rather than fixing beforehand,\nthe number of expert's intentions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:33:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bighashdel", "Ariyan", ""], ["Meletis", "Panagiotis", ""], ["Jancura", "Pavol", ""], ["Dubbelman", "Gijs", ""]]}, {"id": "2107.06700", "submitter": "Yinghua Yao", "authors": "Yinghua Yao, Yuangang Pan, Ivor W.Tsang, Xin Yao", "title": "Differential-Critic GAN: Generating What You Want by a Cue of\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Differential-Critic Generative Adversarial Network\n(DiCGAN) to learn the distribution of user-desired data when only partial\ninstead of the entire dataset possesses the desired property, which generates\ndesired data that meets user's expectations and can assist in designing\nbiological products with desired properties. Existing approaches select the\ndesired samples first and train regular GANs on the selected samples to derive\nthe user-desired data distribution. However, the selection of the desired data\nrelies on an expert criterion and supervision over the entire dataset. DiCGAN\nintroduces a differential critic that can learn the preference direction from\nthe pairwise preferences, which is amateur knowledge and can be defined on part\nof the training data. The resultant critic guides the generation of the desired\ndata instead of the whole data. Specifically, apart from the Wasserstein GAN\nloss, a ranking loss of the pairwise preferences is defined over the critic. It\nendows the difference of critic values between each pair of samples with the\npairwise preference relation. The higher critic value indicates that the sample\nis preferred by the user. Thus training the generative model for higher critic\nvalues encourages the generation of user-preferred samples. Extensive\nexperiments show that our DiCGAN achieves state-of-the-art performance in\nlearning the user-desired data distributions, especially in the cases of\ninsufficient desired data and limited supervision.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:44:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yao", "Yinghua", ""], ["Pan", "Yuangang", ""], ["Tsang", "Ivor W.", ""], ["Yao", "Xin", ""]]}, {"id": "2107.06703", "submitter": "Si Chen", "authors": "Si Chen, Tianhao Wang, Ruoxi Jia", "title": "Zero-Round Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning (AL) aims at reducing labeling effort by identifying the most\nvaluable unlabeled data points from a large pool. Traditional AL frameworks\nhave two limitations: First, they perform data selection in a multi-round\nmanner, which is time-consuming and impractical. Second, they usually assume\nthat there are a small amount of labeled data points available in the same\ndomain as the data in the unlabeled pool. Recent work proposes a solution for\none-round active learning based on data utility learning and optimization,\nwhich fixes the first issue but still requires the initially labeled data\npoints in the same domain. In this paper, we propose $\\mathrm{D^2ULO}$ as a\nsolution that solves both issues. Specifically, $\\mathrm{D^2ULO}$ leverages the\nidea of domain adaptation (DA) to train a data utility model which can\neffectively predict the utility for any given unlabeled data in the target\ndomain once labeled. The trained data utility model can then be used to select\nhigh-utility data and at the same time, provide an estimate for the utility of\nthe selected data. Our algorithm does not rely on any feedback from annotators\nin the target domain and hence, can be used to perform zero-round active\nlearning or warm-start existing multi-round active learning strategies. Our\nexperiments show that $\\mathrm{D^2ULO}$ outperforms the existing\nstate-of-the-art AL strategies equipped with domain adaptation over various\ndomain shift settings (e.g., real-to-real data and synthetic-to-real data).\nParticularly, $\\mathrm{D^2ULO}$ is applicable to the scenario where source and\ntarget labels have mismatches, which is not supported by the existing works.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:47:13 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 00:49:48 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Si", ""], ["Wang", "Tianhao", ""], ["Jia", "Ruoxi", ""]]}, {"id": "2107.06720", "submitter": "Ashudeep Singh", "authors": "Ashudeep Singh, David Kempe, Thorsten Joachims", "title": "Fairness in Ranking under Uncertainty", "comments": "Preprint under submission. 19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness has emerged as an important consideration in algorithmic\ndecision-making. Unfairness occurs when an agent with higher merit obtains a\nworse outcome than an agent with lower merit. Our central point is that a\nprimary cause of unfairness is uncertainty. A principal or algorithm making\ndecisions never has access to the agents' true merit, and instead uses proxy\nfeatures that only imperfectly predict merit (e.g., GPA, star ratings,\nrecommendation letters). None of these ever fully capture an agent's merit; yet\nexisting approaches have mostly been defining fairness notions directly based\non observed features and outcomes.\n  Our primary point is that it is more principled to acknowledge and model the\nuncertainty explicitly. The role of observed features is to give rise to a\nposterior distribution of the agents' merits. We use this viewpoint to define a\nnotion of approximate fairness in ranking. We call an algorithm $\\phi$-fair\n(for $\\phi \\in [0,1]$) if it has the following property for all agents $x$ and\nall $k$: if agent $x$ is among the top $k$ agents with respect to merit with\nprobability at least $\\rho$ (according to the posterior merit distribution),\nthen the algorithm places the agent among the top $k$ agents in its ranking\nwith probability at least $\\phi \\rho$.\n  We show how to compute rankings that optimally trade off approximate fairness\nagainst utility to the principal. In addition to the theoretical\ncharacterization, we present an empirical analysis of the potential impact of\nthe approach in simulation studies. For real-world validation, we applied the\napproach in the context of a paper recommendation system that we built and\nfielded at a large conference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:10:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Singh", "Ashudeep", ""], ["Kempe", "David", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2107.06724", "submitter": "Matthias Reisser", "authors": "Matthias Reisser, Christos Louizos, Efstratios Gavves, Max Welling", "title": "Federated Mixture of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) has emerged as the predominant approach for\ncollaborative training of neural network models across multiple users, without\nthe need to gather the data at a central location. One of the important\nchallenges in this setting is data heterogeneity, i.e. different users have\ndifferent data characteristics. For this reason, training and using a single\nglobal model might be suboptimal when considering the performance of each of\nthe individual user's data. In this work, we tackle this problem via Federated\nMixture of Experts, FedMix, a framework that allows us to train an ensemble of\nspecialized models. FedMix adaptively selects and trains a user-specific\nselection of the ensemble members. We show that users with similar data\ncharacteristics select the same members and therefore share statistical\nstrength while mitigating the effect of non-i.i.d data. Empirically, we show\nthrough an extensive experimental evaluation that FedMix improves performance\ncompared to using a single global model across a variety of different sources\nof non-i.i.d.-ness.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:15:24 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Reisser", "Matthias", ""], ["Louizos", "Christos", ""], ["Gavves", "Efstratios", ""], ["Welling", "Max", ""]]}, {"id": "2107.06744", "submitter": "Reshma Rastogi", "authors": "Reshma Rastogi (nee. Khemchandani) and Aman Pal", "title": "Efficient Learning of Pinball TWSVM using Privileged Information and its\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In any learning framework, an expert knowledge always plays a crucial role.\nBut, in the field of machine learning, the knowledge offered by an expert is\nrarely used. Moreover, machine learning algorithms (SVM based) generally use\nhinge loss function which is sensitive towards the noise. Thus, in order to get\nthe advantage from an expert knowledge and to reduce the sensitivity towards\nthe noise, in this paper, we propose privileged information based Twin Pinball\nSupport Vector Machine classifier (Pin-TWSVMPI) where expert's knowledge is in\nthe form of privileged information. The proposed Pin-TWSVMPI incorporates\nprivileged information by using correcting function so as to obtain two\nnonparallel decision hyperplanes. Further, in order to make computations more\nefficient and fast, we use Sequential Minimal Optimization (SMO) technique for\nobtaining the classifier and have also shown its application for Pedestrian\ndetection and Handwritten digit recognition. Further, for UCI datasets, we\nfirst implement a procedure which extracts privileged information from the\nfeatures of the dataset which are then further utilized by Pin-TWSVMPI that\nleads to enhancement in classification accuracy with comparatively lesser\ncomputational time.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:42:07 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Rastogi", "Reshma", "", "nee. Khemchandani"], ["Pal", "Aman", ""]]}, {"id": "2107.06755", "submitter": "Md. Abrar Jahin", "authors": "Md. Abrar Jahin and Andrii Krutsylo", "title": "DIT4BEARs Smart Roads Internship", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The research internship at UiT - The Arctic University of Norway was offered\nfor our team being the winner of the 'Smart Roads - Winter Road Maintenance\n2021' Hackathon. The internship commenced on 3 May 2021 and ended on 21 May\n2021 with meetings happening twice each week. In spite of having different\nnationalities and educational backgrounds, we both interns tried to collaborate\nas a team as much as possible. The most alluring part was working on this\nproject made us realize the critical conditions faced by the arctic people,\nwhere it was hard to gain such a unique experience from our residence. We\ndeveloped and implemented several deep learning models to classify the states\n(dry, moist, wet, icy, snowy, slushy). Depending upon the best model, the\nweather forecast app will predict the state taking the Ta, Tsurf, Height,\nSpeed, Water, etc. into consideration. The crucial part was to define a safety\nmetric which is the product of the accident rates based on friction and the\naccident rates based on states. We developed a regressor that will predict the\nsafety metric depending upon the state obtained from the classifier and the\nfriction obtained from the sensor data. A pathfinding algorithm has been\ndesigned using the sensor data, open street map data, weather data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:09:27 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Jahin", "Md. Abrar", ""], ["Krutsylo", "Andrii", ""]]}, {"id": "2107.06762", "submitter": "Ruxandra Barbulescu", "authors": "Gon\\c{c}alo Mestre (1 and 2), Ruxandra Barbulescu (1), Arlindo L.\n  Oliveira (1 and 2) and L. Miguel Silveira (1 and 2) ((1) INESC-ID, Rua Alves\n  Redol 9, 1000-029 Lisboa, (2) IST Tecnico Lisboa, Universidade de Lisboa, Av.\n  Rovisco Pais 1, 1049-001 Lisboa)", "title": "Modelling Neuronal Behaviour with Time Series Regression: Recurrent\n  Neural Networks on C. Elegans Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the inner complexity of the human nervous system, insight into the\ndynamics of brain activity can be gained from understanding smaller and simpler\norganisms, such as the nematode C. Elegans. The behavioural and structural\nbiology of these organisms is well-known, making them prime candidates for\nbenchmarking modelling and simulation techniques. In these complex neuronal\ncollections, classical, white-box modelling techniques based on intrinsic\nstructural or behavioural information are either unable to capture the profound\nnonlinearities of the neuronal response to different stimuli or generate\nextremely complex models, which are computationally intractable. In this paper\nwe show how the nervous system of C. Elegans can be modelled and simulated with\ndata-driven models using different neural network architectures. Specifically,\nwe target the use of state of the art recurrent neural networks architectures\nsuch as LSTMs and GRUs and compare these architectures in terms of their\nproperties and their accuracy as well as the complexity of the resulting\nmodels. We show that GRU models with a hidden layer size of 4 units are able to\naccurately reproduce with high accuracy the system's response to very different\nstimuli.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:39:30 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mestre", "Gon\u00e7alo", "", "1 and 2"], ["Barbulescu", "Ruxandra", "", "1 and 2"], ["Oliveira", "Arlindo L.", "", "1 and 2"], ["Silveira", "L. Miguel", "", "1 and 2"]]}, {"id": "2107.06767", "submitter": "Miklos Z. Racz", "authors": "Miklos Z. Racz, Anirudh Sridhar", "title": "Correlated Stochastic Block Models: Exact Graph Matching with\n  Applications to Recovering Communities", "comments": "42 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG cs.SI math.IT math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning latent community structure from multiple\ncorrelated networks. First, we study the problem of learning the latent vertex\ncorrespondence between two edge-correlated stochastic block models, focusing on\nthe regime where the average degree is logarithmic in the number of vertices.\nWe derive the precise information-theoretic threshold for exact recovery: above\nthe threshold there exists an estimator that outputs the true correspondence\nwith probability close to 1, while below it no estimator can recover the true\ncorrespondence with probability bounded away from 0. As an application of our\nresults, we show how one can exactly recover the latent communities using\nmultiple correlated graphs in parameter regimes where it is\ninformation-theoretically impossible to do so using just a single graph.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:27:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Racz", "Miklos Z.", ""], ["Sridhar", "Anirudh", ""]]}, {"id": "2107.06773", "submitter": "Yan Ding", "authors": "Yan Ding, Xiaoqian Jiang and Yejin Kim", "title": "Relational graph convolutional networks for predicting blood-brain\n  barrier penetration of drug molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of the BBB penetrating ability of drug molecules is a critical\nstep in brain drug development. Computational prediction based on machine\nlearning has proved to be an efficient way to conduct the evaluation. However,\nperformance of the established models has been limited by their incapability of\ndealing with the interactions between drugs and proteins, which play an\nimportant role in the mechanism behind BBB penetrating behaviors. To address\nthis issue, we employed the relational graph convolutional network (RGCN) to\nhandle the drug-protein (denoted by the encoding gene) relations as well as the\nfeatures of each individual drug. In addition, drug-drug similarity was also\nintroduced to connect structurally similar drugs in the graph. The RGCN model\nwas initially trained without input of any drug features. And the performance\nwas already promising, demonstrating the significant role of the\ndrug-protein/drug-drug relations in the prediction of BBB permeability.\nMoreover, molecular embeddings from a pre-trained knowledge graph were used as\nthe drug features to further enhance the predictive ability of the model.\nFinally, the best performing RGCN model was built with a large number of\nunlabeled drugs integrated into the graph.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 15:56:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ding", "Yan", ""], ["Jiang", "Xiaoqian", ""], ["Kim", "Yejin", ""]]}, {"id": "2107.06782", "submitter": "Matloob Khushi Dr", "authors": "Mimansa Rana, Nanxiang Mao, Ming Ao, Xiaohui Wu, Poning Liang and\n  Matloob Khushi", "title": "Clustering and attention model based for Intelligent Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The foreign exchange market has taken an important role in the global\nfinancial market. While foreign exchange trading brings high-yield\nopportunities to investors, it also brings certain risks. Since the\nestablishment of the foreign exchange market in the 20th century, foreign\nexchange rate forecasting has become a hot issue studied by scholars from all\nover the world. Due to the complexity and number of factors affecting the\nforeign exchange market, technical analysis cannot respond to administrative\nintervention or unexpected events. Our team chose several pairs of foreign\ncurrency historical data and derived technical indicators from 2005 to 2021 as\nthe dataset and established different machine learning models for event-driven\nprice prediction for oversold scenario.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:35:13 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Rana", "Mimansa", ""], ["Mao", "Nanxiang", ""], ["Ao", "Ming", ""], ["Wu", "Xiaohui", ""], ["Liang", "Poning", ""], ["Khushi", "Matloob", ""]]}, {"id": "2107.06785", "submitter": "Novanto Yudistira", "authors": "Kuncahyo Setyo Nugroho, Anantha Yullian Sukmadewa, Novanto Yudistira", "title": "Large-Scale News Classification using BERT Language Model: Spark NLP\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise of big data analytics on top of NLP increases the computational\nburden for text processing at scale. The problems faced in NLP are very high\ndimensional text, so it takes a high computation resource. The MapReduce allows\nparallelization of large computations and can improve the efficiency of text\nprocessing. This research aims to study the effect of big data processing on\nNLP tasks based on a deep learning approach. We classify a big text of news\ntopics with fine-tuning BERT used pre-trained models. Five pre-trained models\nwith a different number of parameters were used in this study. To measure the\nefficiency of this method, we compared the performance of the BERT with the\npipelines from Spark NLP. The result shows that BERT without Spark NLP gives\nhigher accuracy compared to BERT with Spark NLP. The accuracy average and\ntraining time of all models using BERT is 0.9187 and 35 minutes while using\nBERT with Spark NLP pipeline is 0.8444 and 9 minutes. The bigger model will\ntake more computation resources and need a longer time to complete the tasks.\nHowever, the accuracy of BERT with Spark NLP only decreased by an average of\n5.7%, while the training time was reduced significantly by 62.9% compared to\nBERT without Spark NLP.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:42:15 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 02:04:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Nugroho", "Kuncahyo Setyo", ""], ["Sukmadewa", "Anantha Yullian", ""], ["Yudistira", "Novanto", ""]]}, {"id": "2107.06796", "submitter": "Novanto Yudistira", "authors": "Aisyah Awalina, Jibran Fawaid, Rifky Yunus Krisnabayu, Novanto\n  Yudistira", "title": "Indonesia's Fake News Detection using Transformer Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fake news is a problem faced by society in this era. It is not rare for fake\nnews to cause provocation and problem for the people. Indonesia, as a country\nwith the 4th largest population, has a problem in dealing with fake news. More\nthan 30% of rural and urban population are deceived by this fake news problem.\nAs we have been studying, there is only few literatures on preventing the\nspread of fake news in Bahasa Indonesia. So, this research is conducted to\nprevent these problems. The dataset used in this research was obtained from a\nnews portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on\nthis page, we got 1116 data consisting of valid news and fake news. The dataset\ncan be accessed at https://github.com/JibranFawaid/turnbackhoax-dataset. This\ndataset will be combined with other available datasets. The methods used are\nCNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This\nresearch shows that the BERT method with Transformer Network has the best\nresults with an accuracy of up to 90%.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:52:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Awalina", "Aisyah", ""], ["Fawaid", "Jibran", ""], ["Krisnabayu", "Rifky Yunus", ""], ["Yudistira", "Novanto", ""]]}, {"id": "2107.06802", "submitter": "Novanto Yudistira", "authors": "Kuncahyo Setyo Nugroho, Anantha Yullian Sukmadewa, Haftittah\n  Wuswilahaken DW, Fitra Abdurrachman Bachtiar, Novanto Yudistira", "title": "BERT Fine-Tuning for Sentiment Analysis on Indonesian Mobile Apps\n  Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  User reviews have an essential role in the success of the developed mobile\napps. User reviews in the textual form are unstructured data, creating a very\nhigh complexity when processed for sentiment analysis. Previous approaches that\nhave been used often ignore the context of reviews. In addition, the relatively\nsmall data makes the model overfitting. A new approach, BERT, has been\nintroduced as a transfer learning model with a pre-trained model that has\npreviously been trained to have a better context representation. This study\nexamines the effectiveness of fine-tuning BERT for sentiment analysis using two\ndifferent pre-trained models. Besides the multilingual pre-trained model, we\nuse the pre-trained model that only has been trained in Indonesian. The dataset\nused is Indonesian user reviews of the ten best apps in 2020 in Google Play\nsites. We also perform hyper-parameter tuning to find the optimum trained\nmodel. Two training data labeling approaches were also tested to determine the\neffectiveness of the model, which is score-based and lexicon-based. The\nexperimental results show that pre-trained models trained in Indonesian have\nbetter average accuracy on lexicon-based data. The pre-trained Indonesian model\nhighest accuracy is 84%, with 25 epochs and a training time of 24 minutes.\nThese results are better than all of the machine learning and multilingual\npre-trained models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 16:00:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Nugroho", "Kuncahyo Setyo", ""], ["Sukmadewa", "Anantha Yullian", ""], ["DW", "Haftittah Wuswilahaken", ""], ["Bachtiar", "Fitra Abdurrachman", ""], ["Yudistira", "Novanto", ""]]}, {"id": "2107.06825", "submitter": "Ilya Tolstikhin", "authors": "Ibrahim Alabdulmohsin, Larisa Markeeva, Daniel Keysers, Ilya\n  Tolstikhin", "title": "A Generalized Lottery Ticket Hypothesis", "comments": "Workshop on Sparsity in Neural Networks: Advancing Understanding and\n  Practice (SNN'21). Updates: New curve on Figure 2(left) and discussion on Li\n  et al", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalization to the lottery ticket hypothesis in which the\nnotion of \"sparsity\" is relaxed by choosing an arbitrary basis in the space of\nparameters. We present evidence that the original results reported for the\ncanonical basis continue to hold in this broader setting. We describe how\nstructured pruning methods, including pruning units or factorizing\nfully-connected layers into products of low-rank matrices, can be cast as\nparticular instances of this \"generalized\" lottery ticket hypothesis. The\ninvestigations reported here are preliminary and are provided to encourage\nfurther research along this direction.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 20:01:24 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 09:28:51 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Alabdulmohsin", "Ibrahim", ""], ["Markeeva", "Larisa", ""], ["Keysers", "Daniel", ""], ["Tolstikhin", "Ilya", ""]]}, {"id": "2107.06845", "submitter": "Basit Alawode", "authors": "Basit O. Alawode, Motaz Alfarraj", "title": "Meta-Optimization of Deep CNN for Image Denoising Using LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent application of deep learning (DL) to various tasks has seen the\nperformance of classical techniques surpassed by their DL-based counterparts.\nAs a result, DL has equally seen application in the removal of noise from\nimages. In particular, the use of deep feed-forward convolutional neural\nnetworks (DnCNNs) has been investigated for denoising. It utilizes advances in\nDL techniques such as deep architecture, residual learning, and batch\nnormalization to achieve better denoising performance when compared with the\nother classical state-of-the-art denoising algorithms. However, its deep\narchitecture resulted in a huge set of trainable parameters. Meta-optimization\nis a training approach of enabling algorithms to learn to train themselves by\nthemselves. Training algorithms using meta-optimizers have been shown to enable\nalgorithms to achieve better performance when compared to the classical\ngradient descent-based training approach. In this work, we investigate the\napplication of the meta-optimization training approach to the DnCNN denoising\nalgorithm to enhance its denoising capability. Our preliminary experiments on\nsimpler algorithms reveal the prospects of utilizing the meta-optimization\ntraining approach towards the enhancement of the DnCNN denoising capability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 16:59:44 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Alawode", "Basit O.", ""], ["Alfarraj", "Motaz", ""]]}, {"id": "2107.06846", "submitter": "Daniel Salles Civitarese", "authors": "Daniel Salles Civitarese, Daniela Szwarcman, Bianca Zadrozny, Campbell\n  Watson", "title": "Extreme Precipitation Seasonal Forecast Using a Transformer Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.ao-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An impact of climate change is the increase in frequency and intensity of\nextreme precipitation events. However, confidently predicting the likelihood of\nextreme precipitation at seasonal scales remains an outstanding challenge.\nHere, we present an approach to forecasting the quantiles of the maximum daily\nprecipitation in each week up to six months ahead using the temporal fusion\ntransformer (TFT) model. Through experiments in two regions, we compare TFT\npredictions with those of two baselines: climatology and a calibrated ECMWF\nSEAS5 ensemble forecast (S5). Our results show that, in terms of quantile risk\nat six month lead time, the TFT predictions significantly outperform those from\nS5 and show an overall small improvement compared to climatology. The TFT also\nresponds positively to departures from normal that climatology cannot.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:02:15 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Civitarese", "Daniel Salles", ""], ["Szwarcman", "Daniela", ""], ["Zadrozny", "Bianca", ""], ["Watson", "Campbell", ""]]}, {"id": "2107.06859", "submitter": "Maitreyee Wairagkar", "authors": "Maitreyee Wairagkar, Emma Villeneuve, Rachel King, Balazs Janko,\n  Malcolm Burnett, Ann Ashburn, Veena Agarwal, R. Simon Sherratt, William\n  Holderbaum, William Harwin", "title": "A novel approach for modelling and classifying sit-to-stand kinematics\n  using inertial sensors", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sit-to-stand transitions are an important part of activities of daily living\nand play a key role in functional mobility in humans. The sit-to-stand movement\nis often affected in older adults due to frailty and in patients with motor\nimpairments such as Parkinson's disease leading to falls. Studying kinematics\nof sit-to-stand transitions can provide insight in assessment, monitoring and\ndeveloping rehabilitation strategies for the affected populations. We propose a\nthree-segment body model for estimating sit-to-stand kinematics using only two\nwearable inertial sensors, placed on the shank and back. Reducing the number of\nsensors to two instead of one per body segment facilitates monitoring and\nclassifying movements over extended periods, making it more comfortable to wear\nwhile reducing the power requirements of sensors. We applied this model on 10\nyounger healthy adults (YH), 12 older healthy adults (OH) and 12 people with\nParkinson's disease (PwP). We have achieved this by incorporating unique\nsit-to-stand classification technique using unsupervised learning in the model\nbased reconstruction of angular kinematics using extended Kalman filter. Our\nproposed model showed that it was possible to successfully estimate thigh\nkinematics despite not measuring the thigh motion with inertial sensor. We\nclassified sit-to-stand transitions, sitting and standing states with the\naccuracies of 98.67%, 94.20% and 91.41% for YH, OH and PwP respectively. We\nhave proposed a novel integrated approach of modelling and classification for\nestimating the body kinematics during sit-to-stand motion and successfully\napplied it on YH, OH and PwP groups.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:31:50 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Wairagkar", "Maitreyee", ""], ["Villeneuve", "Emma", ""], ["King", "Rachel", ""], ["Janko", "Balazs", ""], ["Burnett", "Malcolm", ""], ["Ashburn", "Ann", ""], ["Agarwal", "Veena", ""], ["Sherratt", "R. Simon", ""], ["Holderbaum", "William", ""], ["Harwin", "William", ""]]}, {"id": "2107.06862", "submitter": "Eyvind Niklasson", "authors": "Alexander Mordvintsev, Ettore Randazzo, Eyvind Niklasson", "title": "Differentiable Programming of Reaction-Diffusion Patterns", "comments": "ALIFE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reaction-Diffusion (RD) systems provide a computational framework that\ngoverns many pattern formation processes in nature. Current RD system design\npractices boil down to trial-and-error parameter search. We propose a\ndifferentiable optimization method for learning the RD system parameters to\nperform example-based texture synthesis on a 2D plane. We do this by\nrepresenting the RD system as a variant of Neural Cellular Automata and using\ntask-specific differentiable loss functions. RD systems generated by our method\nexhibit robust, non-trivial 'life-like' behavior.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:38:34 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mordvintsev", "Alexander", ""], ["Randazzo", "Ettore", ""], ["Niklasson", "Eyvind", ""]]}, {"id": "2107.06865", "submitter": "Xu Mingkun", "authors": "Mingkun Xu, Yujie Wu, Lei Deng, Faqiang Liu, Guoqi Li, Jing Pei", "title": "Exploiting Spiking Dynamics with Spatial-temporal Feature Normalization\n  in Graph Learning", "comments": "Accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological spiking neurons with intrinsic dynamics underlie the powerful\nrepresentation and learning capabilities of the brain for processing multimodal\ninformation in complex environments. Despite recent tremendous progress in\nspiking neural networks (SNNs) for handling Euclidean-space tasks, it still\nremains challenging to exploit SNNs in processing non-Euclidean-space data\nrepresented by graph data, mainly due to the lack of effective modeling\nframework and useful training techniques. Here we present a general spike-based\nmodeling framework that enables the direct training of SNNs for graph learning.\nThrough spatial-temporal unfolding for spiking data flows of node features, we\nincorporate graph convolution filters into spiking dynamics and formalize a\nsynergistic learning paradigm. Considering the unique features of spike\nrepresentation and spiking dynamics, we propose a spatial-temporal feature\nnormalization (STFN) technique suitable for SNN to accelerate convergence. We\ninstantiate our methods into two spiking graph models, including graph\nconvolution SNNs and graph attention SNNs, and validate their performance on\nthree node-classification benchmarks, including Cora, Citeseer, and Pubmed. Our\nmodel can achieve comparable performance with the state-of-the-art graph neural\nnetwork (GNN) models with much lower computation costs, demonstrating great\nbenefits for the execution on neuromorphic hardware and prompting neuromorphic\napplications in graphical scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:20:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Xu", "Mingkun", ""], ["Wu", "Yujie", ""], ["Deng", "Lei", ""], ["Liu", "Faqiang", ""], ["Li", "Guoqi", ""], ["Pei", "Jing", ""]]}, {"id": "2107.06869", "submitter": "Kyeongbo Kong", "authors": "Jae-hun Shim, Kyeongbo Kong, and Suk-Ju Kang", "title": "Core-set Sampling for Efficient Neural Architecture Search", "comments": "8 pages, 2 figures, spotlight presented at the ICML 2021 Workshop on\n  Subset Selection in ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS), an important branch of automatic machine\nlearning, has become an effective approach to automate the design of deep\nlearning models. However, the major issue in NAS is how to reduce the large\nsearch time imposed by the heavy computational burden. While most recent\napproaches focus on pruning redundant sets or developing new search\nmethodologies, this paper attempts to formulate the problem based on the data\ncuration manner. Our key strategy is to search the architecture using\nsummarized data distribution, i.e., core-set. Typically, many NAS algorithms\nseparate searching and training stages, and the proposed core-set methodology\nis only used in search stage, thus their performance degradation can be\nminimized. In our experiments, we were able to save overall computational time\nfrom 30.8 hours to 3.5 hours, 8.8x reduction, on a single RTX 3090 GPU without\nsacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:19:18 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Shim", "Jae-hun", ""], ["Kong", "Kyeongbo", ""], ["Kang", "Suk-Ju", ""]]}, {"id": "2107.06871", "submitter": "Zheyu Yan", "authors": "Zheyu Yan, Da-Cheng Juan, Xiaobo Sharon Hu, Yiyu Shi", "title": "Uncertainty Modeling of Emerging Device-based Computing-in-Memory Neural\n  Accelerators with Application to Neural Architecture Search", "comments": null, "journal-ref": null, "doi": "10.1145/3394885.3431635", "report-no": null, "categories": "cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Emerging device-based Computing-in-memory (CiM) has been proved to be a\npromising candidate for high-energy efficiency deep neural network (DNN)\ncomputations. However, most emerging devices suffer uncertainty issues,\nresulting in a difference between actual data stored and the weight value it is\ndesigned to be. This leads to an accuracy drop from trained models to actually\ndeployed platforms. In this work, we offer a thorough analysis of the effect of\nsuch uncertainties-induced changes in DNN models. To reduce the impact of\ndevice uncertainties, we propose UAE, an uncertainty-aware Neural Architecture\nSearch scheme to identify a DNN model that is both accurate and robust against\ndevice uncertainties.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 23:29:36 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yan", "Zheyu", ""], ["Juan", "Da-Cheng", ""], ["Hu", "Xiaobo Sharon", ""], ["Shi", "Yiyu", ""]]}, {"id": "2107.06872", "submitter": "Jeff Mitchell", "authors": "Jeff Mitchell and Jeffrey S. Bowers", "title": "Generalisation in Neural Networks Does not Require Feature Overlap", "comments": "19 pages, 3 Figures. Submitted to Cognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  That shared features between train and test data are required for\ngeneralisation in artificial neural networks has been a common assumption of\nboth proponents and critics of these models. Here, we show that convolutional\narchitectures avoid this limitation by applying them to two well known\nchallenges, based on learning the identity function and learning rules\ngoverning sequences of words. In each case, successful performance on the test\nset requires generalising to features that were not present in the training\ndata, which is typically not feasible for standard connectionist models.\nHowever, our experiments demonstrate that neural networks can succeed on such\nproblems when they incorporate the weight sharing employed by convolutional\narchitectures. In the image processing domain, such architectures are intended\nto reflect the symmetry under spatial translations of the natural world that\nsuch images depict. We discuss the role of symmetry in the two tasks and its\nconnection to generalisation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 09:23:49 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mitchell", "Jeff", ""], ["Bowers", "Jeffrey S.", ""]]}, {"id": "2107.06875", "submitter": "Amir Yazdani", "authors": "Amir Yazdani, Roya Sabbagh Novin, Andrew Merryweather, Tucker Hermans", "title": "DULA: A Differentiable Ergonomics Model for Postural Optimization in\n  Physical HRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ergonomics and human comfort are essential concerns in physical human-robot\ninteraction applications. Defining an accurate and easy-to-use ergonomic\nassessment model stands as an important step in providing feedback for postural\ncorrection to improve operator health and comfort. In order to enable efficient\ncomputation, previously proposed automated ergonomic assessment and correction\ntools make approximations or simplifications to gold-standard assessment tools\nused by ergonomists in practice. In order to retain assessment quality, while\nimproving computational considerations, we introduce DULA, a differentiable and\ncontinuous ergonomics model learned to replicate the popular and scientifically\nvalidated RULA assessment. We show that DULA provides assessment comparable to\nRULA while providing computational benefits. We highlight DULA's strength in a\ndemonstration of gradient-based postural optimization for a simulated\nteleoperation task.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:39:45 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yazdani", "Amir", ""], ["Novin", "Roya Sabbagh", ""], ["Merryweather", "Andrew", ""], ["Hermans", "Tucker", ""]]}, {"id": "2107.06876", "submitter": "Johannes Klicpera", "authors": "Johannes Klicpera, Marten Lienen, Stephan G\\\"unnemann", "title": "Scalable Optimal Transport in High Dimensions for Graph Distances,\n  Embedding Alignment, and More", "comments": "Published as a conference paper at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DS cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current best practice for computing optimal transport (OT) is via entropy\nregularization and Sinkhorn iterations. This algorithm runs in quadratic time\nas it requires the full pairwise cost matrix, which is prohibitively expensive\nfor large sets of objects. In this work we propose two effective log-linear\ntime approximations of the cost matrix: First, a sparse approximation based on\nlocality-sensitive hashing (LSH) and, second, a Nystr\\\"om approximation with\nLSH-based sparse corrections, which we call locally corrected Nystr\\\"om (LCN).\nThese approximations enable general log-linear time algorithms for\nentropy-regularized OT that perform well even for the complex, high-dimensional\nspaces common in deep learning. We analyse these approximations theoretically\nand evaluate them experimentally both directly and end-to-end as a component\nfor real-world applications. Using our approximations for unsupervised word\nembedding alignment enables us to speed up a state-of-the-art method by a\nfactor of 3 while also improving the accuracy by 3.1 percentage points without\nany additional model changes. For graph distance regression we propose the\ngraph transport network (GTN), which combines graph neural networks (GNNs) with\nenhanced Sinkhorn. GTN outcompetes previous models by 48% and still scales\nlog-linearly in the number of nodes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:40:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Klicpera", "Johannes", ""], ["Lienen", "Marten", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.06877", "submitter": "Vasileios Tsouvalas", "authors": "Vasileios Tsouvalas, Aaqib Saeed, Tanir Ozcelebi", "title": "Federated Self-Training for Semi-Supervised Audio Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning is a distributed machine learning paradigm dealing with\ndecentralized and personal datasets. Since data reside on devices like\nsmartphones and virtual assistants, labeling is entrusted to the clients, or\nlabels are extracted in an automated way. Specifically, in the case of audio\ndata, acquiring semantic annotations can be prohibitively expensive and\ntime-consuming. As a result, an abundance of audio data remains unlabeled and\nunexploited on users' devices. Most existing federated learning approaches\nfocus on supervised learning without harnessing the unlabeled data. In this\nwork, we study the problem of semi-supervised learning of audio models via\nself-training in conjunction with federated learning. We propose FedSTAR to\nexploit large-scale on-device unlabeled data to improve the generalization of\naudio recognition models. We further demonstrate that self-supervised\npre-trained models can accelerate the training of on-device models,\nsignificantly improving convergence to within fewer training rounds. We conduct\nexperiments on diverse public audio classification datasets and investigate the\nperformance of our models under varying percentages of labeled and unlabeled\ndata. Notably, we show that with as little as 3% labeled data available,\nFedSTAR on average can improve the recognition rate by 13.28% compared to the\nfully supervised federated model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:40:10 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Tsouvalas", "Vasileios", ""], ["Saeed", "Aaqib", ""], ["Ozcelebi", "Tanir", ""]]}, {"id": "2107.06882", "submitter": "Aviral Kumar", "authors": "Brandon Trabucco, Aviral Kumar, Xinyang Geng, Sergey Levine", "title": "Conservative Objective Models for Effective Offline Model-Based\n  Optimization", "comments": "ICML 2021. First two authors contributed equally. Code at:\n  https://github.com/brandontrabucco/design-baselines/blob/c65a53fe1e6567b740f0adf60c5db9921c1f2330/design_baselines/coms_cleaned/__init__.py", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational design problems arise in a number of settings, from synthetic\nbiology to computer architectures. In this paper, we aim to solve data-driven\nmodel-based optimization (MBO) problems, where the goal is to find a design\ninput that maximizes an unknown objective function provided access to only a\nstatic dataset of prior experiments. Such data-driven optimization procedures\nare the only practical methods in many real-world domains where active data\ncollection is expensive (e.g., when optimizing over proteins) or dangerous\n(e.g., when optimizing over aircraft designs). Typical methods for MBO that\noptimize the design against a learned model suffer from distributional shift:\nit is easy to find a design that \"fools\" the model into predicting a high\nvalue. To overcome this, we propose conservative objective models (COMs), a\nmethod that learns a model of the objective function that lower bounds the\nactual value of the ground-truth objective on out-of-distribution inputs, and\nuses it for optimization. Structurally, COMs resemble adversarial training\nmethods used to overcome adversarial examples. COMs are simple to implement and\noutperform a number of existing methods on a wide range of MBO problems,\nincluding optimizing protein sequences, robot morphologies, neural network\nweights, and superconducting materials.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:55:28 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Trabucco", "Brandon", ""], ["Kumar", "Aviral", ""], ["Geng", "Xinyang", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.06898", "submitter": "Ro Jefferson", "authors": "Johanna Erdmenger, Kevin T. Grosvenor, and Ro Jefferson", "title": "Towards quantifying information flows: relative entropy in deep neural\n  networks and the renormalization group", "comments": "41 pages, 8 figures; code available at\n  https://github.com/ro-jefferson/entropy_dnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th cond-mat.dis-nn cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the analogy between the renormalization group (RG) and deep\nneural networks, wherein subsequent layers of neurons are analogous to\nsuccessive steps along the RG. In particular, we quantify the flow of\ninformation by explicitly computing the relative entropy or Kullback-Leibler\ndivergence in both the one- and two-dimensional Ising models under decimation\nRG, as well as in a feedforward neural network as a function of depth. We\nobserve qualitatively identical behavior characterized by the monotonic\nincrease to a parameter-dependent asymptotic value. On the quantum field theory\nside, the monotonic increase confirms the connection between the relative\nentropy and the c-theorem. For the neural networks, the asymptotic behavior may\nhave implications for various information maximization methods in machine\nlearning, as well as for disentangling compactness and generalizability.\nFurthermore, while both the two-dimensional Ising model and the random neural\nnetworks we consider exhibit non-trivial critical points, the relative entropy\nappears insensitive to the phase structure of either system. In this sense,\nmore refined probes are required in order to fully elucidate the flow of\ninformation in these models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:00:01 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Erdmenger", "Johanna", ""], ["Grosvenor", "Kevin T.", ""], ["Jefferson", "Ro", ""]]}, {"id": "2107.06908", "submitter": "Lily Zhang", "authors": "Lily H. Zhang, Mark Goldstein, Rajesh Ranganath", "title": "Understanding Failures in Out-of-Distribution Detection with Deep\n  Generative Models", "comments": "Accepted at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep generative models (DGMs) seem a natural fit for detecting\nout-of-distribution (OOD) inputs, but such models have been shown to assign\nhigher probabilities or densities to OOD images than images from the training\ndistribution. In this work, we explain why this behavior should be attributed\nto model misestimation. We first prove that no method can guarantee performance\nbeyond random chance without assumptions on which out-distributions are\nrelevant. We then interrogate the typical set hypothesis, the claim that\nrelevant out-distributions can lie in high likelihood regions of the data\ndistribution, and that OOD detection should be defined based on the data\ndistribution's typical set. We highlight the consequences implied by assuming\nsupport overlap between in- and out-distributions, as well as the arbitrariness\nof the typical set for OOD detection. Our results suggest that estimation error\nis a more plausible explanation than the misalignment between likelihood-based\nOOD detection and out-distributions of interest, and we illustrate how even\nminimal estimation error can lead to OOD detection failures, yielding\nimplications for future work in deep generative modeling and OOD detection.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:00:11 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 21:37:23 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhang", "Lily H.", ""], ["Goldstein", "Mark", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2107.06917", "submitter": "Zheng Xu", "authors": "Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H. Brendan\n  McMahan, Blaise Aguera y Arcas, Maruan Al-Shedivat, Galen Andrew, Salman\n  Avestimehr, Katharine Daly, Deepesh Data, Suhas Diggavi, Hubert Eichner,\n  Advait Gadhikar, Zachary Garrett, Antonious M. Girgis, Filip Hanzely, Andrew\n  Hard, Chaoyang He, Samuel Horvath, Zhouyuan Huo, Alex Ingerman, Martin Jaggi,\n  Tara Javidi, Peter Kairouz, Satyen Kale, Sai Praneeth Karimireddy, Jakub\n  Konecny, Sanmi Koyejo, Tian Li, Luyang Liu, Mehryar Mohri, Hang Qi, Sashank\n  J. Reddi, Peter Richtarik, Karan Singhal, Virginia Smith, Mahdi\n  Soltanolkotabi, Weikang Song, Ananda Theertha Suresh, Sebastian U. Stich,\n  Ameet Talwalkar, Hongyi Wang, Blake Woodworth, Shanshan Wu, Felix X. Yu,\n  Honglin Yuan, Manzil Zaheer, Mi Zhang, Tong Zhang, Chunxiang Zheng, Chen Zhu,\n  Wennan Zhu", "title": "A Field Guide to Federated Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning and analytics are a distributed approach for\ncollaboratively learning models (or statistics) from decentralized data,\nmotivated by and designed for privacy protection. The distributed learning\nprocess can be formulated as solving federated optimization problems, which\nemphasize communication efficiency, data heterogeneity, compatibility with\nprivacy and system requirements, and other constraints that are not primary\nconsiderations in other problem settings. This paper provides recommendations\nand guidelines on formulating, designing, evaluating and analyzing federated\noptimization algorithms through concrete examples and practical implementation,\nwith a focus on conducting effective simulations to infer real-world\nperformance. The goal of this work is not to survey the current literature, but\nto inspire researchers and practitioners to design federated learning\nalgorithms that can be used in various practical applications.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:09:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Wang", "Jianyu", ""], ["Charles", "Zachary", ""], ["Xu", "Zheng", ""], ["Joshi", "Gauri", ""], ["McMahan", "H. Brendan", ""], ["Arcas", "Blaise Aguera y", ""], ["Al-Shedivat", "Maruan", ""], ["Andrew", "Galen", ""], ["Avestimehr", "Salman", ""], ["Daly", "Katharine", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""], ["Eichner", "Hubert", ""], ["Gadhikar", "Advait", ""], ["Garrett", "Zachary", ""], ["Girgis", "Antonious M.", ""], ["Hanzely", "Filip", ""], ["Hard", "Andrew", ""], ["He", "Chaoyang", ""], ["Horvath", "Samuel", ""], ["Huo", "Zhouyuan", ""], ["Ingerman", "Alex", ""], ["Jaggi", "Martin", ""], ["Javidi", "Tara", ""], ["Kairouz", "Peter", ""], ["Kale", "Satyen", ""], ["Karimireddy", "Sai Praneeth", ""], ["Konecny", "Jakub", ""], ["Koyejo", "Sanmi", ""], ["Li", "Tian", ""], ["Liu", "Luyang", ""], ["Mohri", "Mehryar", ""], ["Qi", "Hang", ""], ["Reddi", "Sashank J.", ""], ["Richtarik", "Peter", ""], ["Singhal", "Karan", ""], ["Smith", "Virginia", ""], ["Soltanolkotabi", "Mahdi", ""], ["Song", "Weikang", ""], ["Suresh", "Ananda Theertha", ""], ["Stich", "Sebastian U.", ""], ["Talwalkar", "Ameet", ""], ["Wang", "Hongyi", ""], ["Woodworth", "Blake", ""], ["Wu", "Shanshan", ""], ["Yu", "Felix X.", ""], ["Yuan", "Honglin", ""], ["Zaheer", "Manzil", ""], ["Zhang", "Mi", ""], ["Zhang", "Tong", ""], ["Zheng", "Chunxiang", ""], ["Zhu", "Chen", ""], ["Zhu", "Wennan", ""]]}, {"id": "2107.06925", "submitter": "Shigang Li", "authors": "Shigang Li, Torsten Hoefler", "title": "Chimera: Efficiently Training Large-Scale Neural Networks with\n  Bidirectional Pipelines", "comments": "The paper was accepted by the 2021 International Conference for High\n  Performance Computing, Networking, Storage and Analysis (SC'21), in Best\n  Paper Finalist", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large deep learning models at scale is very challenging. This paper\nproposes Chimera, a novel pipeline parallelism scheme which combines\nbidirectional pipelines for efficiently training large-scale models. Chimera is\na synchronous approach and therefore no loss of accuracy, which is more\nconvergence-friendly than asynchronous approaches. Compared with the latest\nsynchronous pipeline approach, Chimera reduces the number of bubbles by up to\n50%; benefiting from the sophisticated scheduling of bidirectional pipelines,\nChimera has a more balanced activation memory consumption. Evaluations are\nconducted on Transformer based language models. For a GPT-2 model with 1.3\nbillion parameters running on 2,048 GPU nodes of the Piz Daint supercomputer,\nChimera improves the training throughput by 1.16x-2.34x over the\nstate-of-the-art synchronous and asynchronous pipeline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:16:20 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Li", "Shigang", ""], ["Hoefler", "Torsten", ""]]}, {"id": "2107.06929", "submitter": "Sean Kulinski", "authors": "Sean Kulinski, Saurabh Bagchi, David I. Inouye", "title": "Feature Shift Detection: Localizing Which Features Have Shifted via\n  Conditional Distribution Tests", "comments": "NeurIPS 2020 Camera Ready", "journal-ref": "NeurIPS 33 (2020) 19523-19533", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While previous distribution shift detection approaches can identify if a\nshift has occurred, these approaches cannot localize which specific features\nhave caused a distribution shift -- a critical step in diagnosing or fixing any\nunderlying issue. For example, in military sensor networks, users will want to\ndetect when one or more of the sensors has been compromised, and critically,\nthey will want to know which specific sensors might be compromised. Thus, we\nfirst define a formalization of this problem as multiple conditional\ndistribution hypothesis tests and propose both non-parametric and parametric\nstatistical tests. For both efficiency and flexibility, we then propose to use\na test statistic based on the density model score function (i.e. gradient with\nrespect to the input) -- which can easily compute test statistics for all\ndimensions in a single forward and backward pass. Any density model could be\nused for computing the necessary statistics including deep density models such\nas normalizing flows or autoregressive models. We additionally develop methods\nfor identifying when and where a shift occurs in multivariate time-series data\nand show results for multiple scenarios using realistic attack models on both\nsimulated and real world data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:23:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kulinski", "Sean", ""], ["Bagchi", "Saurabh", ""], ["Inouye", "David I.", ""]]}, {"id": "2107.06936", "submitter": "Jean Barbier Dr.", "authors": "Jean Barbier, Wei-Kuo Chen, Dmitry Panchenko, and Manuel S\\'aenz", "title": "Performance of Bayesian linear regression in a model with mismatch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cond-mat.dis-nn cs.IT cs.LG math-ph math.IT math.MP math.ST stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  For a model of high-dimensional linear regression with random design, we\nanalyze the performance of an estimator given by the mean of a log-concave\nBayesian posterior distribution with gaussian prior. The model is mismatched in\nthe following sense: like the model assumed by the statistician, the\nlabels-generating process is linear in the input data, but both the classifier\nground-truth prior and gaussian noise variance are unknown to her. This\ninference model can be rephrased as a version of the Gardner model in spin\nglasses and, using the cavity method, we provide fixed point equations for\nvarious overlap order parameters, yielding in particular an expression for the\nmean-square reconstruction error on the classifier (under an assumption of\nuniqueness of solutions). As a direct corollary we obtain an expression for the\nfree energy. Similar models have already been studied by Shcherbina and Tirozzi\nand by Talagrand, but our arguments are more straightforward and some\nassumptions are relaxed. An interesting consequence of our analysis is that in\nthe random design setting of ridge regression, the performance of the posterior\nmean is independent of the noise variance (or \"temperature\") assumed by the\nstatistician, and matches the one of the usual (zero temperature) ridge\nestimator.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:50:13 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Barbier", "Jean", ""], ["Chen", "Wei-Kuo", ""], ["Panchenko", "Dmitry", ""], ["S\u00e1enz", "Manuel", ""]]}, {"id": "2107.06943", "submitter": "Szymon P{\\l}otka", "authors": "Szymon P{\\l}otka, Tomasz W{\\l}odarczyk, Adam Klasa, Micha{\\l} Lipa,\n  Arkadiusz Sitek, Tomasz Trzci\\'nski", "title": "FetalNet: Multi-task deep learning framework for fetal ultrasound\n  biometric measurements", "comments": "Submitted to ICONIP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we propose an end-to-end multi-task neural network called\nFetalNet with an attention mechanism and stacked module for spatio-temporal\nfetal ultrasound scan video analysis. Fetal biometric measurement is a standard\nexamination during pregnancy used for the fetus growth monitoring and\nestimation of gestational age and fetal weight. The main goal in fetal\nultrasound scan video analysis is to find proper standard planes to measure the\nfetal head, abdomen and femur. Due to natural high speckle noise and shadows in\nultrasound data, medical expertise and sonographic experience are required to\nfind the appropriate acquisition plane and perform accurate measurements of the\nfetus. In addition, existing computer-aided methods for fetal US biometric\nmeasurement address only one single image frame without considering temporal\nfeatures. To address these shortcomings, we propose an end-to-end multi-task\nneural network for spatio-temporal ultrasound scan video analysis to\nsimultaneously localize, classify and measure the fetal body parts. We propose\na new encoder-decoder segmentation architecture that incorporates a\nclassification branch. Additionally, we employ an attention mechanism with a\nstacked module to learn salient maps to suppress irrelevant US regions and\nefficient scan plane localization. We trained on the fetal ultrasound video\ncomes from routine examinations of 700 different patients. Our method called\nFetalNet outperforms existing state-of-the-art methods in both classification\nand segmentation in fetal ultrasound video recordings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:13:33 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["P\u0142otka", "Szymon", ""], ["W\u0142odarczyk", "Tomasz", ""], ["Klasa", "Adam", ""], ["Lipa", "Micha\u0142", ""], ["Sitek", "Arkadiusz", ""], ["Trzci\u0144ski", "Tomasz", ""]]}, {"id": "2107.06944", "submitter": "Carlos Pinz'on", "authors": "Carlos Pinz\\'on, Catuscia Palamidessi, Pablo Piantanida, Frank\n  Valencia", "title": "On the impossibility of non-trivial accuracy under fairness constraints", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the main concerns about fairness in machine learning (ML) is that, in\norder to achieve it, one may have to renounce to some accuracy. Having this\ntrade-off in mind, Hardt et al. have proposed the notion of equal opportunities\n(EO), designed so as to be compatible with accuracy. In fact, it can be shown\nthat if the source of input data is deterministic, the two notions go well\nalong with each other. In the probabilistic case, however, things change.\n  As we show, there are probabilistic data sources for which EO can only be\nachieved at the total detriment of accuracy, i.e. among the models that achieve\nEO, those whose prediction does not depend on the input have the highest\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:15:50 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Pinz\u00f3n", "Carlos", ""], ["Palamidessi", "Catuscia", ""], ["Piantanida", "Pablo", ""], ["Valencia", "Frank", ""]]}, {"id": "2107.06946", "submitter": "Rakshit Naidu", "authors": "Rakshit Naidu, Harshita Diddee, Ajinkya Mulay, Aleti Vardhan, Krithika\n  Ramesh, Ahmed Zamzam", "title": "Towards Quantifying the Carbon Emissions of Differentially Private\n  Machine Learning", "comments": "4+3 pages; 6 figures; 8 tables. Accepted at SRML workshop at ICML'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, machine learning techniques utilizing large-scale datasets\nhave achieved remarkable performance. Differential privacy, by means of adding\nnoise, provides strong privacy guarantees for such learning algorithms. The\ncost of differential privacy is often a reduced model accuracy and a lowered\nconvergence speed. This paper investigates the impact of differential privacy\non learning algorithms in terms of their carbon footprint due to either longer\nrun-times or failed experiments. Through extensive experiments, further\nguidance is provided on choosing the noise levels which can strike a balance\nbetween desired privacy levels and reduced carbon emissions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:25:25 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Naidu", "Rakshit", ""], ["Diddee", "Harshita", ""], ["Mulay", "Ajinkya", ""], ["Vardhan", "Aleti", ""], ["Ramesh", "Krithika", ""], ["Zamzam", "Ahmed", ""]]}, {"id": "2107.06955", "submitter": "Armen Aghajanyan", "authors": "Armen Aghajanyan, Dmytro Okhonko, Mike Lewis, Mandar Joshi, Hu Xu,\n  Gargi Ghosh, Luke Zettlemoyer", "title": "HTLM: Hyper-Text Pre-Training and Prompting of Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce HTLM, a hyper-text language model trained on a large-scale web\ncrawl. Modeling hyper-text has a number of advantages: (1) it is easily\ngathered at scale, (2) it provides rich document-level and end-task-adjacent\nsupervision (e.g. class and id attributes often encode document category\ninformation), and (3) it allows for new structured prompting that follows the\nestablished semantics of HTML (e.g. to do zero-shot summarization by infilling\ntitle tags for a webpage that contains the input text). We show that\npretraining with a BART-style denoising loss directly on simplified HTML\nprovides highly effective transfer for a wide range of end tasks and\nsupervision levels. HTLM matches or exceeds the performance of comparably sized\ntext-only LMs for zero-shot prompting and fine-tuning for classification\nbenchmarks, while also setting new state-of-the-art performance levels for\nzero-shot summarization. We also find that hyper-text prompts provide more\nvalue to HTLM, in terms of data efficiency, than plain text prompts do for\nexisting LMs, and that HTLM is highly effective at auto-prompting itself, by\nsimply generating the most likely hyper-text formatting for any available\ntraining data. We will release all code and models to support future HTLM\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:39:31 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Aghajanyan", "Armen", ""], ["Okhonko", "Dmytro", ""], ["Lewis", "Mike", ""], ["Joshi", "Mandar", ""], ["Xu", "Hu", ""], ["Ghosh", "Gargi", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2107.06960", "submitter": "Andreas Gerstlauer", "authors": "Jackson Farley, Andreas Gerstlauer", "title": "Memory-Aware Fusing and Tiling of Neural Networks for Accelerated Edge\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Report UT-CERC-21-01", "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rising research challenge is running costly machine learning (ML) networks\nlocally on resource-constrained edge devices. ML networks with large\nconvolutional layers can easily exceed available memory, increasing latency due\nto excessive swapping. Previous memory reduction techniques such as pruning and\nquantization reduce model accuracy and often require retraining. Alternatively,\ndistributed methods partition the convolutions into equivalent smaller\nsub-computations, but the implementations introduce communication costs and\nrequire a network of devices. However, a distributed partitioning approach can\nalso be used to run in a reduced memory footprint on a single device by\nsubdividing the network into smaller operations.\n  This report extends prior work on distributed partitioning using tiling and\nfusing of convolutional layers into a memory-aware execution on a single\ndevice. Our approach extends prior fusing strategies to allow for two groups of\nconvolutional layers that are fused and tiled independently. This approach\nreduces overhead via data reuse, and reduces the memory footprint further. We\nalso propose a memory usage predictor coupled with a search algorithm to\nprovide fusing and tiling configurations for an arbitrary set of convolutional\nlayers. When applied to the YOLOv2 object detection network, results show that\nour approach can run in less than half the memory, and with a speedup of up to\n2.78 under severe memory constraints. Additionally, our algorithm will return a\nconfiguration with a latency that is within 6% of the best latency measured in\na manual search.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 19:45:49 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Farley", "Jackson", ""], ["Gerstlauer", "Andreas", ""]]}, {"id": "2107.06981", "submitter": "Filippo Neri", "authors": "Filippo Neri", "title": "Mapping Learning Algorithms on Data, a useful step for optimizing\n  performances and their comparison", "comments": "The main classification class for the paper is Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the paper, we propose a novel methodology to map learning algorithms on\ndata (performance map) in order to gain more insights in the distribution of\ntheir performances across their parameter space. This methodology provides\nuseful information when selecting a learner's best configuration for the data\nat hand, and it also enhances the comparison of learners across learning\ncontexts. In order to explain the proposed methodology, the study introduces\nthe notions of learning context, performance map, and high performance\nfunction. It then applies these concepts to a variety of learning contexts to\nshow how their use can provide more insights in a learner's behavior, and can\nenhance the comparison of learners across learning contexts. The study is\ncompleted by an extensive experimental study describing how the proposed\nmethodology can be applied.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 20:36:42 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Neri", "Filippo", ""]]}, {"id": "2107.06990", "submitter": "Tazin Afrin", "authors": "Tazin Afrin, Elaine Wang, Diane Litman, Lindsay C. Matsumura, Richard\n  Correnti", "title": "Annotation and Classification of Evidence and Reasoning Revisions in\n  Argumentative Writing", "comments": "10 pages, 11 tables, 15th Workshop on Innovative Use of NLP for\n  Building Educational Applications", "journal-ref": null, "doi": "10.18653/v1/2020.bea-1.7", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated writing evaluation systems can improve students' writing insofar as\nstudents attend to the feedback provided and revise their essay drafts in ways\naligned with such feedback. Existing research on revision of argumentative\nwriting in such systems, however, has focused on the types of revisions\nstudents make (e.g., surface vs. content) rather than the extent to which\nrevisions actually respond to the feedback provided and improve the essay. We\nintroduce an annotation scheme to capture the nature of sentence-level\nrevisions of evidence use and reasoning (the `RER' scheme) and apply it to 5th-\nand 6th-grade students' argumentative essays. We show that reliable manual\nannotation can be achieved and that revision annotations correlate with a\nholistic assessment of essay improvement in line with the feedback provided.\nFurthermore, we explore the feasibility of automatically classifying revisions\naccording to our scheme.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 20:58:26 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Afrin", "Tazin", ""], ["Wang", "Elaine", ""], ["Litman", "Diane", ""], ["Matsumura", "Lindsay C.", ""], ["Correnti", "Richard", ""]]}, {"id": "2107.06991", "submitter": "Jie Gao", "authors": "Zhihao Chen, Jie Gao, Weikai Wang and Zheng Yan", "title": "Physics-informed generative neural network: an application to\n  troposphere temperature prediction", "comments": null, "journal-ref": null, "doi": "10.1088/1748-9326/abfde9", "report-no": null, "categories": "cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The troposphere is one of the atmospheric layers where most weather phenomena\noccur. Temperature variations in the troposphere, especially at 500 hPa, a\ntypical level of the middle troposphere, are significant indicators of future\nweather changes. Numerical weather prediction is effective for temperature\nprediction, but its computational complexity hinders a timely response. This\npaper proposes a novel temperature prediction approach in framework\nofphysics-informed deep learning. The new model, called PGnet, builds upon a\ngenerative neural network with a mask matrix. The mask is designed to\ndistinguish the low-quality predicted regions generated by the first physical\nstage. The generative neural network takes the mask as prior for the\nsecond-stage refined predictions. A mask-loss and a jump pattern strategy are\ndeveloped to train the generative neural network without accumulating errors\nduring making time-series predictions. Experiments on ERA5 demonstrate that\nPGnet can generate more refined temperature predictions than the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 09:07:07 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Zhihao", ""], ["Gao", "Jie", ""], ["Wang", "Weikai", ""], ["Yan", "Zheng", ""]]}, {"id": "2107.06992", "submitter": "Gilberto Ochoa-Ruiz", "authors": "Mauricio Mendez-Ruiz, Ivan Garcia Jorge Gonzalez-Zapata, Gilberto\n  Ochoa-Ruiz, Andres Mendez-Vazquez", "title": "Finding Significant Features for Few-Shot Learning using Dimensionality\n  Reduction", "comments": "This paper is currently under review for the Mexican International\n  Conference on Artificial Intelligence (MICAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Few-shot learning is a relatively new technique that specializes in problems\nwhere we have little amounts of data. The goal of these methods is to classify\ncategories that have not been seen before with just a handful of samples.\nRecent approaches, such as metric learning, adopt the meta-learning strategy in\nwhich we have episodic tasks conformed by support (training) data and query\n(test) data. Metric learning methods have demonstrated that simple models can\nachieve good performance by learning a similarity function to compare the\nsupport and the query data. However, the feature space learned by a given\nmetric learning approach may not exploit the information given by a specific\nfew-shot task. In this work, we explore the use of dimension reduction\ntechniques as a way to find task-significant features helping to make better\npredictions. We measure the performance of the reduced features by assigning a\nscore based on the intra-class and inter-class distance, and selecting a\nfeature reduction method in which instances of different classes are far away\nand instances of the same class are close. This module helps to improve the\naccuracy performance by allowing the similarity function, given by the metric\nlearning method, to have more discriminative features for the classification.\nOur method outperforms the metric learning baselines in the miniImageNet\ndataset by around 2% in accuracy performance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:36:57 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Mendez-Ruiz", "Mauricio", ""], ["Gonzalez-Zapata", "Ivan Garcia Jorge", ""], ["Ochoa-Ruiz", "Gilberto", ""], ["Mendez-Vazquez", "Andres", ""]]}, {"id": "2107.06993", "submitter": "Sourav Mishra", "authors": "Sourav Mishra and Suresh Sundaram", "title": "Confidence Conditioned Knowledge Distillation", "comments": "31 pages, 41 references, 5 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, a novel confidence conditioned knowledge distillation (CCKD)\nscheme for transferring the knowledge from a teacher model to a student model\nis proposed. Existing state-of-the-art methods employ fixed loss functions for\nthis purpose and ignore the different levels of information that need to be\ntransferred for different samples. In addition to that, these methods are also\ninefficient in terms of data usage. CCKD addresses these issues by leveraging\nthe confidence assigned by the teacher model to the correct class to devise\nsample-specific loss functions (CCKD-L formulation) and targets (CCKD-T\nformulation). Further, CCKD improves the data efficiency by employing\nself-regulation to stop those samples from participating in the distillation\nprocess on which the student model learns faster. Empirical evaluations on\nseveral benchmark datasets show that CCKD methods achieve at least as much\ngeneralization performance levels as other state-of-the-art methods while being\ndata efficient in the process. Student models trained through CCKD methods do\nnot retain most of the misclassifications commited by the teacher model on the\ntraining set. Distillation through CCKD methods improves the resilience of the\nstudent models against adversarial attacks compared to the conventional KD\nmethod. Experiments show at least 3% increase in performance against\nadversarial attacks for the MNIST and the Fashion MNIST datasets, and at least\n6% increase for the CIFAR10 dataset.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 00:33:25 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Mishra", "Sourav", ""], ["Sundaram", "Suresh", ""]]}, {"id": "2107.06994", "submitter": "James McClelland", "authors": "Andrew Joohun Nam and James L. McClelland (Stanford University)", "title": "What underlies rapid learning and systematic generalization in humans", "comments": "22 pages, 48 references, 6 Figures, and one Table, plus SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite the groundbreaking successes of neural networks, contemporary models\nrequire extensive training with massive datasets and exhibit poor out-of-sample\ngeneralization. One proposed solution is to build systematicity and\ndomain-specific constraints into the model, echoing the tenets of classical,\nsymbolic cognitive architectures. In this paper, we consider the limitations of\nthis approach by examining human adults' ability to learn an abstract reasoning\ntask from a brief instructional tutorial and explanatory feedback for incorrect\nresponses, demonstrating that human learning dynamics and ability to generalize\noutside the range of the training examples differ drastically from those of a\nrepresentative neural network model, and that the model is brittle to changes\nin features not anticipated by its authors. We present further evidence from\nhuman data that the ability to consistently solve the puzzles was associated\nwith education, particularly basic mathematics education, and with the ability\nto provide a reliably identifiable, valid description of the strategy used. We\npropose that rapid learning and systematic generalization in humans may depend\non a gradual, experience-dependent process of learning-to-learn using\ninstructions and explanations to guide the construction of explicit abstract\nrules that support generalizable inferences.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 00:14:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Nam", "Andrew Joohun", "", "Stanford University"], ["McClelland", "James L.", "", "Stanford University"]]}, {"id": "2107.06995", "submitter": "Mostafa Shabani", "authors": "Mostafa Shabani and Alexandros Iosifidis", "title": "Low-Rank Temporal Attention-Augmented Bilinear Network for financial\n  time-series forecasting", "comments": null, "journal-ref": null, "doi": "10.1109/SSCI47803.2020.9308440", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Financial market analysis, especially the prediction of movements of stock\nprices, is a challenging problem. The nature of financial time-series data,\nbeing non-stationary and nonlinear, is the main cause of these challenges. Deep\nlearning models have led to significant performance improvements in many\nproblems coming from different domains, including prediction problems of\nfinancial time-series data. Although the prediction performance is the main\ngoal of such models, dealing with ultra high-frequency data sets restrictions\nin terms of the number of model parameters and its inference speed. The\nTemporal Attention-Augmented Bilinear network was recently proposed as an\nefficient and high-performing model for Limit Order Book time-series\nforecasting. In this paper, we propose a low-rank tensor approximation of the\nmodel to further reduce the number of trainable parameters and increase its\nspeed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 10:15:23 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shabani", "Mostafa", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2107.06996", "submitter": "Xiaorui Liu", "authors": "Xiaorui Liu, Wei Jin, Yao Ma, Yaxin Li, Hua Liu, Yiqi Wang, Ming Yan,\n  Jiliang Tang", "title": "Elastic Graph Neural Networks", "comments": "ICML 2021 (International Conference on Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many existing graph neural networks (GNNs) have been proven to perform\n$\\ell_2$-based graph smoothing that enforces smoothness globally, in this work\nwe aim to further enhance the local smoothness adaptivity of GNNs via\n$\\ell_1$-based graph smoothing. As a result, we introduce a family of GNNs\n(Elastic GNNs) based on $\\ell_1$ and $\\ell_2$-based graph smoothing. In\nparticular, we propose a novel and general message passing scheme into GNNs.\nThis message passing algorithm is not only friendly to back-propagation\ntraining but also achieves the desired smoothing properties with a theoretical\nconvergence guarantee. Experiments on semi-supervised learning tasks\ndemonstrate that the proposed Elastic GNNs obtain better adaptivity on\nbenchmark datasets and are significantly robust to graph adversarial attacks.\nThe implementation of Elastic GNNs is available at\n\\url{https://github.com/lxiaorui/ElasticGNN}.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 01:36:01 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Liu", "Xiaorui", ""], ["Jin", "Wei", ""], ["Ma", "Yao", ""], ["Li", "Yaxin", ""], ["Liu", "Hua", ""], ["Wang", "Yiqi", ""], ["Yan", "Ming", ""], ["Tang", "Jiliang", ""]]}, {"id": "2107.06997", "submitter": "Vincenzo Riccio", "authors": "Tahereh Zohdinasab, Vincenzo Riccio, Alessio Gambi, and Paolo Tonella", "title": "DeepHyperion: Exploring the Feature Space of Deep Learning-Based Systems\n  through Illumination Search", "comments": "To be published in Proceedings of the 30th ACM SIGSOFT International\n  Symposium on Software Testing and Analysis (ISSTA '21), July 11-17, 2021,\n  Virtual, Denmark. ACM, New York, NY, USA, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) has been successfully applied to a wide range of\napplication domains, including safety-critical ones. Several DL testing\napproaches have been recently proposed in the literature but none of them aims\nto assess how different interpretable features of the generated inputs affect\nthe system's behaviour. In this paper, we resort to Illumination Search to find\nthe highest-performing test cases (i.e., misbehaving and closest to\nmisbehaving), spread across the cells of a map representing the feature space\nof the system. We introduce a methodology that guides the users of our approach\nin the tasks of identifying and quantifying the dimensions of the feature space\nfor a given domain. We developed DeepHyperion, a search-based tool for DL\nsystems that illuminates, i.e., explores at large, the feature space, by\nproviding developers with an interpretable feature map where automatically\ngenerated inputs are placed along with information about the exposed\nbehaviours.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:14:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zohdinasab", "Tahereh", ""], ["Riccio", "Vincenzo", ""], ["Gambi", "Alessio", ""], ["Tonella", "Paolo", ""]]}, {"id": "2107.07002", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Yi Tay, Alexey A. Gritsenko, Zhe Zhao, Neil Houlsby,\n  Fernando Diaz, Donald Metzler, Oriol Vinyals", "title": "The Benchmark Lottery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world of empirical machine learning (ML) strongly relies on benchmarks in\norder to determine the relative effectiveness of different algorithms and\nmethods. This paper proposes the notion of \"a benchmark lottery\" that describes\nthe overall fragility of the ML benchmarking process. The benchmark lottery\npostulates that many factors, other than fundamental algorithmic superiority,\nmay lead to a method being perceived as superior. On multiple benchmark setups\nthat are prevalent in the ML community, we show that the relative performance\nof algorithms may be altered significantly simply by choosing different\nbenchmark tasks, highlighting the fragility of the current paradigms and\npotential fallacious interpretation derived from benchmarking ML methods. Given\nthat every benchmark makes a statement about what it perceives to be important,\nwe argue that this might lead to biased progress in the community. We discuss\nthe implications of the observed phenomena and provide recommendations on\nmitigating them using multiple machine learning domains and communities as use\ncases, including natural language processing, computer vision, information\nretrieval, recommender systems, and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:08:30 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Tay", "Yi", ""], ["Gritsenko", "Alexey A.", ""], ["Zhao", "Zhe", ""], ["Houlsby", "Neil", ""], ["Diaz", "Fernando", ""], ["Metzler", "Donald", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2107.07005", "submitter": "Sahib Singh", "authors": "Ayush Manish Agrawal, Atharva Tendle, Harshvardhan Sikka, Sahib Singh", "title": "WeightScale: Interpreting Weight Change in Neural Networks", "comments": "9 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:2011.06735", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interpreting the learning dynamics of neural networks can provide useful\ninsights into how networks learn and the development of better training and\ndesign approaches. We present an approach to interpret learning in neural\nnetworks by measuring relative weight change on a per layer basis and\ndynamically aggregating emerging trends through combination of dimensionality\nreduction and clustering which allows us to scale to very deep networks. We use\nthis approach to investigate learning in the context of vision tasks across a\nvariety of state-of-the-art networks and provide insights into the learning\nbehavior of these networks, including how task complexity affects layer-wise\nlearning in deeper layers of networks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 21:18:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Agrawal", "Ayush Manish", ""], ["Tendle", "Atharva", ""], ["Sikka", "Harshvardhan", ""], ["Singh", "Sahib", ""]]}, {"id": "2107.07009", "submitter": "Mark Stamp", "authors": "Jianwei Li, Han-Chih Chang, Mark Stamp", "title": "Free-Text Keystroke Dynamics for User Authentication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this research, we consider the problem of verifying user identity based on\nkeystroke dynamics obtained from free-text. We employ a novel feature\nengineering method that generates image-like transition matrices. For this\nimage-like feature, a convolution neural network (CNN) with cutout achieves the\nbest results. A hybrid model consisting of a CNN and a recurrent neural network\n(RNN) is also shown to outperform previous research in this field.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:46:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Li", "Jianwei", ""], ["Chang", "Han-Chih", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.07014", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Hybrid Bayesian Neural Networks with Functional Probabilistic Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks provide a direct and natural way to extend standard\ndeep neural networks to support probabilistic deep learning through the use of\nprobabilistic layers that, traditionally, encode weight (and bias) uncertainty.\nIn particular, hybrid Bayesian neural networks utilize standard deterministic\nlayers together with few probabilistic layers judicially positioned in the\nnetworks for uncertainty estimation. A major aspect and benefit of Bayesian\ninference is that priors, in principle, provide the means to encode prior\nknowledge for use in inference and prediction. However, it is difficult to\nspecify priors on weights since the weights have no intuitive interpretation.\nFurther, the relationships of priors on weights to the functions computed by\nnetworks are difficult to characterize. In contrast, functions are intuitive to\ninterpret and are direct since they map inputs to outputs. Therefore, it is\nnatural to specify priors on functions to encode prior knowledge, and to use\nthem in inference and prediction based on functions. To support this, we\npropose hybrid Bayesian neural networks with functional probabilistic layers\nthat encode function (and activation) uncertainty. We discuss their foundations\nin functional Bayesian inference, functional variational inference, sparse\nGaussian processes, and sparse variational Gaussian processes. We further\nperform few proof-of-concept experiments using GPflus, a new library that\nprovides Gaussian process layers and supports their use with deterministic\nKeras layers to form hybrid neural network and Gaussian process models.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:25:53 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "2107.07029", "submitter": "Hugo Flores Garcia", "authors": "Hugo Flores Garcia, Aldo Aguilar, Ethan Manilow, Bryan Pardo", "title": "Leveraging Hierarchical Structures for Few-Shot Musical Instrument\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning work on musical instrument recognition has generally focused on\ninstrument classes for which we have abundant data. In this work, we exploit\nhierarchical relationships between instruments in a few-shot learning setup to\nenable classification of a wider set of musical instruments, given a few\nexamples at inference. We apply a hierarchical loss function to the training of\nprototypical networks, combined with a method to aggregate prototypes\nhierarchically, mirroring the structure of a predefined musical instrument\nhierarchy. These extensions require no changes to the network architecture and\nnew levels can be easily added or removed. Compared to a non-hierarchical\nfew-shot baseline, our method leads to a significant increase in classification\naccuracy and significant decrease mistake severity on instrument classes unseen\nin training.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 22:50:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Garcia", "Hugo Flores", ""], ["Aguilar", "Aldo", ""], ["Manilow", "Ethan", ""], ["Pardo", "Bryan", ""]]}, {"id": "2107.07038", "submitter": "Manuel Garcia-Piqueras", "authors": "Manuel Garcia-Piqueras and Jos\\'e Hern\\'andez-Orallo", "title": "Conditional Teaching Size", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent research in machine teaching has explored the instruction of any\nconcept expressed in a universal language. In this compositional context, new\nexperimental results have shown that there exist data teaching sets\nsurprisingly shorter than the concept description itself. However, there exists\na bound for those remarkable experimental findings through teaching size and\nconcept complexity that we further explore here. As concepts are rarely taught\nin isolation we investigate the best configuration of concepts to teach a given\nset of concepts, where those that have been acquired first can be reused for\nthe description of new ones. This new notion of conditional teaching size\nuncovers new insights, such as the interposition phenomenon: certain prior\nknowledge generates simpler compatible concepts that increase the teaching size\nof the concept that we want to teach. This does not happen for conditional\nKolmogorov complexity. Furthermore, we provide an algorithm that constructs\noptimal curricula based on interposition avoidance. This paper presents a\nseries of theoretical results, including their proofs, and some directions for\nfuture work. New research possibilities in curriculum teaching in compositional\nscenarios are now wide open to exploration.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 23:08:58 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Garcia-Piqueras", "Manuel", ""], ["Hern\u00e1ndez-Orallo", "Jos\u00e9", ""]]}, {"id": "2107.07039", "submitter": "Muhammed Sit", "authors": "Muhammed Sit, Bekir Demiray and Ibrahim Demir", "title": "Short-term Hourly Streamflow Prediction with Graph Convolutional GRU\n  Networks", "comments": "4 pages, Accepted to Tackling Climate Change with Machine Learning\n  workshop at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The frequency and impact of floods are expected to increase due to climate\nchange. It is crucial to predict streamflow, consequently flooding, in order to\nprepare and mitigate its consequences in terms of property damage and\nfatalities. This paper presents a Graph Convolutional GRUs based model to\npredict the next 36 hours of streamflow for a sensor location using the\nupstream river network. As shown in experiment results, the model presented in\nthis study provides better performance than the persistence baseline and a\nConvolutional Bidirectional GRU network for the selected study area in\nshort-term streamflow prediction.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 20:26:39 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sit", "Muhammed", ""], ["Demiray", "Bekir", ""], ["Demir", "Ibrahim", ""]]}, {"id": "2107.07040", "submitter": "Yongming Liu", "authors": "Zhiming Zhang and Yongming Liu", "title": "Parsimony-Enhanced Sparse Bayesian Learning for Robust Discovery of\n  Partial Differential Equations", "comments": "arXiv admin note: text overlap with arXiv:2102.06504", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust physics discovery is of great interest for many scientific and\nengineering fields. Inspired by the principle that a representative model is\nthe one simplest possible, a new model selection criteria considering both\nmodel's Parsimony and Sparsity is proposed. A Parsimony Enhanced Sparse\nBayesian Learning (PeSBL) method is developed for discovering the governing\nPartial Differential Equations (PDEs) of nonlinear dynamical systems. Compared\nwith the conventional Sparse Bayesian Learning (SBL) method, the PeSBL method\npromotes parsimony of the learned model in addition to its sparsity. In this\nmethod, the parsimony of model terms is evaluated using their locations in the\nprescribed candidate library, for the first time, considering the increased\ncomplexity with the power of polynomials and the order of spatial derivatives.\nSubsequently, the model parameters are updated through Bayesian inference with\nthe raw data. This procedure aims to reduce the error associated with the\npossible loss of information in data preprocessing and numerical\ndifferentiation prior to sparse regression. Results of numerical case studies\nindicate that the governing PDEs of many canonical dynamical systems can be\ncorrectly identified using the proposed PeSBL method from highly noisy data (up\nto 50% in the current study). Next, the proposed methodology is extended for\nstochastic PDE learning where all parameters and modeling error are considered\nas random variables. Hierarchical Bayesian Inference (HBI) is integrated with\nthe proposed framework for stochastic PDE learning from a population of\nobservations. Finally, the proposed PeSBL is demonstrated for system response\nprediction with uncertainties and anomaly diagnosis. Codes of all demonstrated\nexamples in this study are available on the website: https://github.com/ymlasu.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 00:56:11 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zhang", "Zhiming", ""], ["Liu", "Yongming", ""]]}, {"id": "2107.07041", "submitter": "Kyeongbo Kong", "authors": "Kyeongbo Kong, Junggi Lee, Youngchul Kwak, Young-Rae Cho, Seong-Eun\n  Kim, and Woo-Jin Song", "title": "Mitigating Memorization in Sample Selection for Learning with Noisy\n  Labels", "comments": "14 pages, 9 figures, spotlight presented at the ICML 2021 Workshop on\n  Subset Selection in ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because deep learning is vulnerable to noisy labels, sample selection\ntechniques, which train networks with only clean labeled data, have attracted a\ngreat attention. However, if the labels are dominantly corrupted by few\nclasses, these noisy samples are called dominant-noisy-labeled samples, the\nnetwork also learns dominant-noisy-labeled samples rapidly via content-aware\noptimization. In this study, we propose a compelling criteria to penalize\ndominant-noisy-labeled samples intensively through class-wise penalty labels.\nBy averaging prediction confidences for the each observed label, we obtain\nsuitable penalty labels that have high values if the labels are largely\ncorrupted by some classes. Experiments were performed using benchmarks\n(CIFAR-10, CIFAR-100, Tiny-ImageNet) and real-world datasets (ANIMAL-10N,\nClothing1M) to evaluate the proposed criteria in various scenarios with\ndifferent noise rates. Using the proposed sample selection, the learning\nprocess of the network becomes significantly robust to noisy labels compared to\nexisting methods in several noise types.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:44:04 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kong", "Kyeongbo", ""], ["Lee", "Junggi", ""], ["Kwak", "Youngchul", ""], ["Cho", "Young-Rae", ""], ["Kim", "Seong-Eun", ""], ["Song", "Woo-Jin", ""]]}, {"id": "2107.07042", "submitter": "Vincenzo Ferrero", "authors": "Vincenzo Ferrero, Kaveh Hassani, Daniele Grandi, Bryony DuPont", "title": "Classifying Component Function in Product Assemblies with Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function is defined as the ensemble of tasks that enable the product to\ncomplete the designed purpose. Functional tools, such as functional modeling,\noffer decision guidance in the early phase of product design, where explicit\ndesign decisions are yet to be made. Function-based design data is often sparse\nand grounded in individual interpretation. As such, function-based design tools\ncan benefit from automatic function classification to increase data fidelity\nand provide function representation models that enable function-based\nintelligent design agents. Function-based design data is commonly stored in\nmanually generated design repositories. These design repositories are a\ncollection of expert knowledge and interpretations of function in product\ndesign bounded by function-flow and component taxonomies. In this work, we\nrepresent a structured taxonomy-based design repository as assembly-flow\ngraphs, then leverage a graph neural network (GNN) model to perform automatic\nfunction classification. We support automated function classification by\nlearning from repository data to establish the ground truth of component\nfunction assignment. Experimental results show that our GNN model achieves a\nmicro-average F${_1}$-score of 0.832 for tier 1 (broad), 0.756 for tier 2, and\n0.783 for tier 3 (specific) functions. Given the imbalance of data features,\nthe results are encouraging. Our efforts in this paper can be a starting point\nfor more sophisticated applications in knowledge-based CAD systems and\nDesign-for-X consideration in function-based design.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:27:23 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ferrero", "Vincenzo", ""], ["Hassani", "Kaveh", ""], ["Grandi", "Daniele", ""], ["DuPont", "Bryony", ""]]}, {"id": "2107.07043", "submitter": "Zuohui Chen", "authors": "Zuohui Chen, Renxuan Wang, Jingyang Xiang, Yue Yu, Xin Xia, Shouling\n  Ji, Qi Xuan, and Xiaoniu Yang", "title": "GGT: Graph-Guided Testing for Adversarial Sample Detection of Deep\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) are known to be vulnerable to adversarial samples,\nthe detection of which is crucial for the wide application of these DNN models.\nRecently, a number of deep testing methods in software engineering were\nproposed to find the vulnerability of DNN systems, and one of them, i.e., Model\nMutation Testing (MMT), was used to successfully detect various adversarial\nsamples generated by different kinds of adversarial attacks. However, the\nmutated models in MMT are always huge in number (e.g., over 100 models) and\nlack diversity (e.g., can be easily circumvented by high-confidence adversarial\nsamples), which makes it less efficient in real applications and less effective\nin detecting high-confidence adversarial samples. In this study, we propose\nGraph-Guided Testing (GGT) for adversarial sample detection to overcome these\naforementioned challenges. GGT generates pruned models with the guide of graph\ncharacteristics, each of them has only about 5% parameters of the mutated model\nin MMT, and graph guided models have higher diversity. The experiments on\nCIFAR10 and SVHN validate that GGT performs much better than MMT with respect\nto both effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 12:12:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Zuohui", ""], ["Wang", "Renxuan", ""], ["Xiang", "Jingyang", ""], ["Yu", "Yue", ""], ["Xia", "Xin", ""], ["Ji", "Shouling", ""], ["Xuan", "Qi", ""], ["Yang", "Xiaoniu", ""]]}, {"id": "2107.07044", "submitter": "Haoxing Ren", "authors": "Haoxing Ren, Matthew Fojtik, Brucek Khailany", "title": "NVCell: Standard Cell Layout in Advanced Technology Nodes with\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High quality standard cell layout automation in advanced technology nodes is\nstill challenging in the industry today because of complex design rules. In\nthis paper we introduce an automatic standard cell layout generator called\nNVCell that can generate layouts with equal or smaller area for over 90% of\nsingle row cells in an industry standard cell library on an advanced technology\nnode. NVCell leverages reinforcement learning (RL) to fix design rule\nviolations during routing and to generate efficient placements.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 16:31:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ren", "Haoxing", ""], ["Fojtik", "Matthew", ""], ["Khailany", "Brucek", ""]]}, {"id": "2107.07045", "submitter": "Prashant Gohel", "authors": "Prashant Gohel, Priyanka Singh and Manoranjan Mohanty", "title": "Explainable AI: current status and future directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable Artificial Intelligence (XAI) is an emerging area of research in\nthe field of Artificial Intelligence (AI). XAI can explain how AI obtained a\nparticular solution (e.g., classification or object detection) and can also\nanswer other \"wh\" questions. This explainability is not possible in traditional\nAI. Explainability is essential for critical applications, such as defense,\nhealth care, law and order, and autonomous driving vehicles, etc, where the\nknow-how is required for trust and transparency. A number of XAI techniques so\nfar have been purposed for such applications. This paper provides an overview\nof these techniques from a multimedia (i.e., text, image, audio, and video)\npoint of view. The advantages and shortcomings of these techniques have been\ndiscussed, and pointers to some future directions have also been provided.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:42:19 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gohel", "Prashant", ""], ["Singh", "Priyanka", ""], ["Mohanty", "Manoranjan", ""]]}, {"id": "2107.07046", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, Ankur Mali", "title": "Backprop-Free Reinforcement Learning with Active Neural Generative\n  Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In humans, perceptual awareness facilitates the fast recognition and\nextraction of information from sensory input. This awareness largely depends on\nhow the human agent interacts with the environment. In this work, we propose\nactive neural generative coding, a computational framework for learning\naction-driven generative models without backpropagation of errors (backprop) in\ndynamic environments. Specifically, we develop an intelligent agent that\noperates even with sparse rewards, drawing inspiration from the cognitive\ntheory of planning as inference. We demonstrate on several control problems, in\nthe online learning setting, that our proposed modeling framework performs\ncompetitively with deep Q-learning models. The robust performance of our agent\noffers promising evidence that a backprop-free approach for neural inference\nand learning can drive goal-directed behavior.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 19:02:27 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ororbia", "Alexander", ""], ["Mali", "Ankur", ""]]}, {"id": "2107.07049", "submitter": "Bharath Keshavamurthy", "authors": "Bharath Keshavamurthy and Nicolo Michelusi", "title": "Learning-based Spectrum Sensing and Access in Cognitive Radios via\n  Approximate POMDPs", "comments": "33 pages, 9 figures, 1 table, Major Revisions under review at IEEE\n  Transactions on Cognitive Communications and Networking (IEEE TCCN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A novel LEarning-based Spectrum Sensing and Access (LESSA) framework is\nproposed, wherein a cognitive radio (CR) learns a time-frequency correlation\nmodel underlying spectrum occupancy of licensed users (LUs) in a radio\necosystem; concurrently, it devises an approximately optimal spectrum sensing\nand access policy under sensing constraints. A Baum-Welch algorithm is proposed\nto learn a parametric Markov transition model of LU spectrum occupancy based on\nnoisy spectrum measurements. Spectrum sensing and access are cast as a\nPartially-Observable Markov Decision Process, approximately optimized via\nrandomized point-based value iteration. Fragmentation, Hamming-distance state\nfilters and Monte-Carlo methods are proposed to alleviate the inherent\ncomputational complexity, and a weighted reward metric to regulate the\ntrade-off between CR throughput and LU interference. Numerical evaluations\ndemonstrate that LESSA performs within 5 percent of a genie-aided upper bound\nwith foreknowledge of LU spectrum occupancy, and outperforms state-of-the-art\nalgorithms across the entire trade-off region: 71 percent over\ncorrelation-based clustering, 26 percent over Neyman-Pearson detection, 6\npercent over the Viterbi algorithm, and 9 percent over an adaptive Deep\nQ-Network. LESSA is then extended to a distributed Multi-Agent setting\n(MA-LESSA), by proposing novel neighbor discovery and channel access rank\nallocation. MA-LESSA improves CR throughput by 43 percent over cooperative\nTD-SARSA, 84 percent over cooperative greedy distributed learning, and 3x over\nnon-cooperative learning via g-statistics and ACKs. Finally, MA-LESSA is\nimplemented on the DARPA SC2 platform, manifesting superior performance over\ncompetitors in a real-world TDWR-UNII WLAN emulation; its implementation\nfeasibility is further validated on a testbed of ESP32 radios, exhibiting 96\npercent success probability.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 23:50:32 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Keshavamurthy", "Bharath", ""], ["Michelusi", "Nicolo", ""]]}, {"id": "2107.07054", "submitter": "Bijan Mazaheri", "authors": "Bijan Mazaheri, Siddharth Jain, Jehoshua Bruck", "title": "Expert Graphs: Synthesizing New Expertise via Collaboration", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DM cs.IT econ.TH math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider multiple experts with overlapping expertise working on a\nclassification problem under uncertain input. What constitutes a consistent set\nof opinions? How can we predict the opinions of experts on missing sub-domains?\nIn this paper, we define a framework of to analyze this problem, termed \"expert\ngraphs.\" In an expert graph, vertices represent classes and edges represent\nbinary opinions on the topics of their vertices. We derive necessary conditions\nfor expert graph validity and use them to create \"synthetic experts\" which\ndescribe opinions consistent with the observed opinions of other experts. We\nshow this framework to be equivalent to the well-studied linear ordering\npolytope. We show our conditions are not sufficient for describing all expert\ngraphs on cliques, but are sufficient for cycles.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 00:27:16 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Mazaheri", "Bijan", ""], ["Jain", "Siddharth", ""], ["Bruck", "Jehoshua", ""]]}, {"id": "2107.07058", "submitter": "Pingping Zhang Dr", "authors": "Wei Liu and Pingping Zhang and Yinjie Lei and Xiaolin Huang and Jie\n  Yang and Michael Ng", "title": "A Generalized Framework for Edge-preserving and Structure-preserving\n  Image Smoothing", "comments": "This work is accepted by TPAMI. The code is available at\n  https://github.com/wliusjtu/Generalized-Smoothing-Framework. arXiv admin\n  note: substantial text overlap with arXiv:1907.09642", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image smoothing is a fundamental procedure in applications of both computer\nvision and graphics. The required smoothing properties can be different or even\ncontradictive among different tasks. Nevertheless, the inherent smoothing\nnature of one smoothing operator is usually fixed and thus cannot meet the\nvarious requirements of different applications. In this paper, we first\nintroduce the truncated Huber penalty function which shows strong flexibility\nunder different parameter settings. A generalized framework is then proposed\nwith the introduced truncated Huber penalty function. When combined with its\nstrong flexibility, our framework is able to achieve diverse smoothing natures\nwhere contradictive smoothing behaviors can even be achieved. It can also yield\nthe smoothing behavior that can seldom be achieved by previous methods, and\nsuperior performance is thus achieved in challenging cases. These together\nenable our framework capable of a range of applications and able to outperform\nthe state-of-the-art approaches in several tasks, such as image detail\nenhancement, clip-art compression artifacts removal, guided depth map\nrestoration, image texture removal, etc. In addition, an efficient numerical\nsolution is provided and its convergence is theoretically guaranteed even the\noptimization framework is non-convex and non-smooth. A simple yet effective\napproach is further proposed to reduce the computational cost of our method\nwhile maintaining its performance. The effectiveness and superior performance\nof our approach are validated through comprehensive experiments in a range of\napplications. Our code is available at\nhttps://github.com/wliusjtu/Generalized-Smoothing-Framework.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 00:55:27 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 03:30:38 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 02:43:00 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liu", "Wei", ""], ["Zhang", "Pingping", ""], ["Lei", "Yinjie", ""], ["Huang", "Xiaolin", ""], ["Yang", "Jie", ""], ["Ng", "Michael", ""]]}, {"id": "2107.07064", "submitter": "Dae-Hyeok Lee", "authors": "Dae-Hyeok Lee, Sung-Jin Kim, Seong-Whan Lee", "title": "DAL: Feature Learning from Overt Speech to Decode Imagined Speech-based\n  EEG Signals with Convolutional Autoencoder", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interface (BCI) is one of the tools which enables the\ncommunication between humans and devices by reflecting intention and status of\nhumans. With the development of artificial intelligence, the interest in\ncommunication between humans and drones using electroencephalogram (EEG) is\nincreased. Especially, in the case of controlling drone swarms such as\ndirection or formation, there are many advantages compared with controlling a\ndrone unit. Imagined speech is one of the endogenous BCI paradigms, which can\nidentify intentions of users. When conducting imagined speech, the users\nimagine the pronunciation as if actually speaking. In contrast, overt speech is\na task in which the users directly pronounce the words. When controlling drone\nswarms using imagined speech, complex commands can be delivered more\nintuitively, but decoding performance is lower than that of other endogenous\nBCI paradigms. We proposed the Deep-autoleaner (DAL) to learn EEG features of\novert speech for imagined speech-based EEG signals classification. To the best\nof our knowledge, this study is the first attempt to use EEG features of overt\nspeech to decode imagined speech-based EEG signals with an autoencoder. A total\nof eight subjects participated in the experiment. When classifying four words,\nthe average accuracy of the DAL was 48.41%. In addition, when comparing the\nperformance between w/o and w/ EEG features of overt speech, there was a\nperformance improvement of 7.42% when including EEG features of overt speech.\nHence, we demonstrated that EEG features of overt speech could improve the\ndecoding performance of imagined speech.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 01:13:19 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Lee", "Dae-Hyeok", ""], ["Kim", "Sung-Jin", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2107.07075", "submitter": "Gintare Karolina Dziugaite", "authors": "Mansheej Paul, Surya Ganguli, Gintare Karolina Dziugaite", "title": "Deep Learning on a Data Diet: Finding Important Examples Early in\n  Training", "comments": "18 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent success of deep learning has partially been driven by training\nincreasingly overparametrized networks on ever larger datasets. It is therefore\nnatural to ask: how much of the data is superfluous, which examples are\nimportant for generalization, and how do we find them? In this work, we make\nthe striking observation that, on standard vision benchmarks, the initial loss\ngradient norm of individual training examples, averaged over several weight\ninitializations, can be used to identify a smaller set of training data that is\nimportant for generalization. Furthermore, after only a few epochs of training,\nthe information in gradient norms is reflected in the normed error--L2 distance\nbetween the predicted probabilities and one hot labels--which can be used to\nprune a significant fraction of the dataset without sacrificing test accuracy.\nBased on this, we propose data pruning methods which use only local information\nearly in training, and connect them to recent work that prunes data by\ndiscarding examples that are rarely forgotten over the course of training. Our\nmethods also shed light on how the underlying data distribution shapes the\ntraining dynamics: they rank examples based on their importance for\ngeneralization, detect noisy examples and identify subspaces of the model's\ndata representation that are relatively stable over training.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 02:12:20 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Paul", "Mansheej", ""], ["Ganguli", "Surya", ""], ["Dziugaite", "Gintare Karolina", ""]]}, {"id": "2107.07076", "submitter": "Guohua Wu", "authors": "Bingjie Li, Guohua Wu, Yongming He, Mingfeng Fan, Witold Pedrycz", "title": "An Overview and Experimental Study of Learning-based Optimization\n  Algorithms for Vehicle Routing Problem", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle routing problem (VRP) is a typical discrete combinatorial\noptimization problem, and many models and algorithms have been proposed to\nsolve VRP and variants. Although existing approaches has contributed a lot to\nthe development of this field, these approaches either are limited in problem\nsize or need manual intervening in choosing parameters. To tackle these\ndifficulties, many studies consider learning-based optimization algorithms to\nsolve VRP. This paper reviews recent advances in this field and divides\nrelevant approaches into end-to-end approaches and step-by-step approaches. We\ndesign three part experiments to justly evaluate performance of four\nrepresentative learning-based optimization algorithms and conclude that\ncombining heuristic search can effectively improve learning ability and sampled\nefficiency of LBO models. Finally we point out that research trend of LBO\nalgorithms is to solve large-scale and multiple constraints problems from real\nworld.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 02:13:03 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Li", "Bingjie", ""], ["Wu", "Guohua", ""], ["He", "Yongming", ""], ["Fan", "Mingfeng", ""], ["Pedrycz", "Witold", ""]]}, {"id": "2107.07087", "submitter": "Elie Wolfe", "authors": "Noam Finkelstein, Beata Zjawin, Elie Wolfe, Ilya Shpitser, Robert W.\n  Spekkens", "title": "Entropic Inequality Constraints from $e$-separation Relations in\n  Directed Acyclic Graphs with Hidden Variables", "comments": "15 pages. This arXiv version is slightly updated relative to the\n  version in UAI proceedings. (Theorem 5 and Proposition 8 have been\n  strengthened, with Appendix C revised correspondingly. Appendix D has been\n  added.)", "journal-ref": null, "doi": null, "report-no": "Proc. UAI 2021", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graphs (DAGs) with hidden variables are often used to\ncharacterize causal relations between variables in a system. When some\nvariables are unobserved, DAGs imply a notoriously complicated set of\nconstraints on the distribution of observed variables. In this work, we present\nentropic inequality constraints that are implied by $e$-separation relations in\nhidden variable DAGs with discrete observed variables. The constraints can\nintuitively be understood to follow from the fact that the capacity of\nvariables along a causal pathway to convey information is restricted by their\nentropy; e.g. at the extreme case, a variable with entropy $0$ can convey no\ninformation. We show how these constraints can be used to learn about the true\ncausal model from an observed data distribution. In addition, we propose a\nmeasure of causal influence called the minimal mediary entropy, and demonstrate\nthat it can augment traditional measures such as the average causal effect.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 02:43:33 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Finkelstein", "Noam", ""], ["Zjawin", "Beata", ""], ["Wolfe", "Elie", ""], ["Shpitser", "Ilya", ""], ["Spekkens", "Robert W.", ""]]}, {"id": "2107.07098", "submitter": "Matthew Dowling", "authors": "Matthew Dowling, Piotr Sok\\'o{\\l}, Il Memming Park", "title": "Hida-Mat\\'ern Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the class of Hida-Mat\\'ern kernels, which is the canonical family\nof covariance functions over the entire space of stationary Gauss-Markov\nProcesses. It extends upon Mat\\'ern kernels, by allowing for flexible\nconstruction of priors over processes with oscillatory components. Any\nstationary kernel, including the widely used squared-exponential and spectral\nmixture kernels, are either directly within this class or are appropriate\nasymptotic limits, demonstrating the generality of this class. Taking advantage\nof its Markovian nature we show how to represent such processes as state space\nmodels using only the kernel and its derivatives. In turn this allows us to\nperform Gaussian Process inference more efficiently and side step the usual\ncomputational burdens. We also show how exploiting special properties of the\nstate space representation enables improved numerical stability in addition to\nfurther reductions of computational complexity.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 03:25:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Dowling", "Matthew", ""], ["Sok\u00f3\u0142", "Piotr", ""], ["Park", "Il Memming", ""]]}, {"id": "2107.07105", "submitter": "James Stokes", "authors": "James Stokes, Saibal De, Shravan Veerapaneni, Giuseppe Carleo", "title": "Continuous-variable neural-network quantum states and the quantum rotor\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.LG hep-lat", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of neural-network quantum state algorithms for\nanalyzing continuous-variable lattice quantum systems in first quantization. A\nsimple family of continuous-variable trial wavefunctons is introduced which\nnaturally generalizes the restricted Boltzmann machine (RBM) wavefunction\nintroduced for analyzing quantum spin systems. By virtue of its simplicity, the\nsame variational Monte Carlo training algorithms that have been developed for\nground state determination and time evolution of spin systems have natural\nanalogues in the continuum. We offer a proof of principle demonstration in the\ncontext of ground state determination of a stoquastic quantum rotor\nHamiltonian. Results are compared against those obtained from partial\ndifferential equation (PDE) based scalable eigensolvers. This study serves as a\nbenchmark against which future investigation of continuous-variable neural\nquantum states can be compared, and points to the need to consider deep network\narchitectures and more sophisticated training algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 03:53:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Stokes", "James", ""], ["De", "Saibal", ""], ["Veerapaneni", "Shravan", ""], ["Carleo", "Giuseppe", ""]]}, {"id": "2107.07106", "submitter": "Alex Egg", "authors": "Alex Egg", "title": "Online Learning for Recommendations at Grubhub", "comments": null, "journal-ref": null, "doi": "10.1145/3460231.3474599", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a method to easily modify existing offline Recommender Systems to\nrun online using Transfer Learning. Online Learning for Recommender Systems has\ntwo main advantages: quality and scale. Like many Machine Learning algorithms\nin production if not regularly retrained will suffer from Concept Drift. A\npolicy that is updated frequently online can adapt to drift faster than a batch\nsystem. This is especially true for user-interaction systems like recommenders\nwhere the underlying distribution can shift drastically to follow user\nbehaviour. As a platform grows rapidly like Grubhub, the cost of running batch\ntraining jobs becomes material. A shift from stateless batch learning offline\nto stateful incremental learning online can recover, for example, at Grubhub,\nup to a 45x cost savings and a +20% metrics increase. There are a few\nchallenges to overcome with the transition to online stateful learning, namely\nconvergence, non-stationary embeddings and off-policy evaluation, which we\nexplore from our experiences running this system in production.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:01:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Egg", "Alex", ""]]}, {"id": "2107.07110", "submitter": "Jiayun Wang", "authors": "Jiayun Wang, Yubei Chen, Stella X. Yu, Brian Cheung, Yann LeCun", "title": "Recurrent Parameter Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a generic method for recurrently using the same parameters for\nmany different convolution layers to build a deep network. Specifically, for a\nnetwork, we create a recurrent parameter generator (RPG), from which the\nparameters of each convolution layer are generated. Though using recurrent\nmodels to build a deep convolutional neural network (CNN) is not entirely new,\nour method achieves significant performance gain compared to the existing\nworks. We demonstrate how to build a one-layer neural network to achieve\nsimilar performance compared to other traditional CNN models on various\napplications and datasets. Such a method allows us to build an arbitrarily\ncomplex neural network with any amount of parameters. For example, we build a\nResNet34 with model parameters reduced by more than $400$ times, which still\nachieves $41.6\\%$ ImageNet top-1 accuracy. Furthermore, we demonstrate the RPG\ncan be applied at different scales, such as layers, blocks, or even\nsub-networks. Specifically, we use the RPG to build a ResNet18 network with the\nnumber of weights equivalent to one convolutional layer of a conventional\nResNet and show this model can achieve $67.2\\%$ ImageNet top-1 accuracy. The\nproposed method can be viewed as an inverse approach to model compression.\nRather than removing the unused parameters from a large model, it aims to\nsqueeze more information into a small number of parameters. Extensive\nexperiment results are provided to demonstrate the power of the proposed\nrecurrent parameter generator.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:23:59 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Wang", "Jiayun", ""], ["Chen", "Yubei", ""], ["Yu", "Stella X.", ""], ["Cheung", "Brian", ""], ["LeCun", "Yann", ""]]}, {"id": "2107.07115", "submitter": "Hideaki Ishibashi Ph.D", "authors": "Hideaki Ishibashi and Shotaro Akaho", "title": "Principal component analysis for Gaussian process posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an extension of principal component analysis for Gaussian\nprocess posteriors denoted by GP-PCA. Since GP-PCA estimates a low-dimensional\nspace of GP posteriors, it can be used for meta-learning, which is a framework\nfor improving the precision of a new task by estimating a structure of a set of\ntasks. The issue is how to define a structure of a set of GPs with an\ninfinite-dimensional parameter, such as coordinate system and a divergence. In\nthis study, we reduce the infiniteness of GP to the finite-dimensional case\nunder the information geometrical framework by considering a space of GP\nposteriors that has the same prior. In addition, we propose an approximation\nmethod of GP-PCA based on variational inference and demonstrate the\neffectiveness of GP-PCA as meta-learning through experiments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:40:02 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ishibashi", "Hideaki", ""], ["Akaho", "Shotaro", ""]]}, {"id": "2107.07116", "submitter": "Feng Shi", "authors": "Feng Shi, Chonghan Lee, Mohammad Khairul Bashar, Nikhil Shukla,\n  Song-Chun Zhu and Vijaykrishnan Narayanan", "title": "Transformer-based Machine Learning for Fast SAT Solvers and Logic\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CNF-based SAT and MaxSAT solvers are central to logic synthesis and\nverification systems. The increasing popularity of these constraint problems in\nelectronic design automation encourages studies on different SAT problems and\ntheir properties for further computational efficiency. There has been both\ntheoretical and practical success of modern Conflict-driven clause learning SAT\nsolvers, which allows solving very large industrial instances in a relatively\nshort amount of time. Recently, machine learning approaches provide a new\ndimension to solving this challenging problem. Neural symbolic models could\nserve as generic solvers that can be specialized for specific domains based on\ndata without any changes to the structure of the model. In this work, we\npropose a one-shot model derived from the Transformer architecture to solve the\nMaxSAT problem, which is the optimization version of SAT where the goal is to\nsatisfy the maximum number of clauses. Our model has a scale-free structure\nwhich could process varying size of instances. We use meta-path and\nself-attention mechanism to capture interactions among homogeneous nodes. We\nadopt cross-attention mechanisms on the bipartite graph to capture interactions\namong heterogeneous nodes. We further apply an iterative algorithm to our model\nto satisfy additional clauses, enabling a solution approaching that of an\nexact-SAT problem. The attention mechanisms leverage the parallelism for\nspeedup. Our evaluation indicates improved speedup compared to heuristic\napproaches and improved completion rate compared to machine learning\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:47:35 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shi", "Feng", ""], ["Lee", "Chonghan", ""], ["Bashar", "Mohammad Khairul", ""], ["Shukla", "Nikhil", ""], ["Zhu", "Song-Chun", ""], ["Narayanan", "Vijaykrishnan", ""]]}, {"id": "2107.07127", "submitter": "Kyoungjun Park", "authors": "Kyoungjun Park, Myungchul Kim, Laihyuk Park", "title": "NeuSaver: Neural Adaptive Power Consumption Optimization for Mobile\n  Video Streaming", "comments": "13 pages, 8 figures, 3 tables, This work has been submitted to the\n  IEEE for possible publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Video streaming services strive to support high-quality videos at higher\nresolutions and frame rates to improve the quality of experience (QoE).\nHowever, high-quality videos consume considerable amounts of energy on mobile\ndevices. This paper proposes NeuSaver, which reduces the power consumption of\nmobile devices when streaming videos by applying an adaptive frame rate to each\nvideo chunk without compromising user experience. NeuSaver generates an optimal\npolicy that determines the appropriate frame rate for each video chunk using\nreinforcement learning (RL). The RL model automatically learns the policy that\nmaximizes the QoE goals based on previous observations. NeuSaver also uses an\nasynchronous advantage actor-critic algorithm to reinforce the RL model quickly\nand robustly. Streaming servers that support NeuSaver preprocesses videos into\nsegments with various frame rates, which is similar to the process of creating\nvideos with multiple bit rates in dynamic adaptive streaming over HTTP.\nNeuSaver utilizes the commonly used H.264 video codec. We evaluated NeuSaver in\nvarious experiments and a user study through four video categories along with\nthe state-of-the-art model. Our experiments showed that NeuSaver effectively\nreduces the power consumption of mobile devices when streaming video by an\naverage of 16.14% and up to 23.12% while achieving high QoE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:17:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Park", "Kyoungjun", ""], ["Kim", "Myungchul", ""], ["Park", "Laihyuk", ""]]}, {"id": "2107.07148", "submitter": "Aleksandar Jevremovic PhD", "authors": "Zona Kostic and Aleksandar Jevremovic", "title": "What Image Features Boost Housing Market Predictions?", "comments": null, "journal-ref": null, "doi": "10.1109/TMM.2020.2966890", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The attractiveness of a property is one of the most interesting, yet\nchallenging, categories to model. Image characteristics are used to describe\ncertain attributes, and to examine the influence of visual factors on the price\nor timeframe of the listing. In this paper, we propose a set of techniques for\nthe extraction of visual features for efficient numerical inclusion in\nmodern-day predictive algorithms. We discuss techniques such as Shannon's\nentropy, calculating the center of gravity, employing image segmentation, and\nusing Convolutional Neural Networks. After comparing these techniques as\napplied to a set of property-related images (indoor, outdoor, and satellite),\nwe conclude the following: (i) the entropy is the most efficient single-digit\nvisual measure for housing price prediction; (ii) image segmentation is the\nmost important visual feature for the prediction of housing lifespan; and (iii)\ndeep image features can be used to quantify interior characteristics and\ncontribute to captivation modeling. The set of 40 image features selected here\ncarries a significant amount of predictive power and outperforms some of the\nstrongest metadata predictors. Without any need to replace a human expert in a\nreal-estate appraisal process, we conclude that the techniques presented in\nthis paper can efficiently describe visible characteristics, thus introducing\nperceived attractiveness as a quantitative measure into the predictive modeling\nof housing.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 06:32:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kostic", "Zona", ""], ["Jevremovic", "Aleksandar", ""]]}, {"id": "2107.07160", "submitter": "Wilmer Arbelo Gonzalez", "authors": "Gilmer Valdes, Wilmer Arbelo, Yannet Interian, and Jerome H. Friedman", "title": "Lockout: Sparse Regularization of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Many regression and classification procedures fit a parameterized function\n$f(x;w)$ of predictor variables $x$ to data $\\{x_{i},y_{i}\\}_1^N$ based on some\nloss criterion $L(y,f)$. Often, regularization is applied to improve accuracy\nby placing a constraint $P(w)\\leq t$ on the values of the parameters $w$.\nAlthough efficient methods exist for finding solutions to these constrained\noptimization problems for all values of $t\\geq0$ in the special case when $f$\nis a linear function, none are available when $f$ is non-linear (e.g. Neural\nNetworks). Here we present a fast algorithm that provides all such solutions\nfor any differentiable function $f$ and loss $L$, and any constraint $P$ that\nis an increasing monotone function of the absolute value of each parameter.\nApplications involving sparsity inducing regularization of arbitrary Neural\nNetworks are discussed. Empirical results indicate that these sparse solutions\nare usually superior to their dense counterparts in both accuracy and\ninterpretability. This improvement in accuracy can often make Neural Networks\ncompetitive with, and sometimes superior to, state-of-the-art methods in the\nanalysis of tabular data.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:17:20 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Valdes", "Gilmer", ""], ["Arbelo", "Wilmer", ""], ["Interian", "Yannet", ""], ["Friedman", "Jerome H.", ""]]}, {"id": "2107.07170", "submitter": "Jonathan Bragg", "authors": "Jonathan Bragg, Arman Cohan, Kyle Lo, Iz Beltagy", "title": "FLEX: Unifying Evaluation for Few-Shot NLP", "comments": "First two authors contributed equally. Code and leaderboard available\n  at: https://github.com/allenai/flex", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot NLP research is highly active, yet conducted in disjoint research\nthreads with evaluation suites that lack challenging-yet-realistic testing\nsetups and fail to employ careful experimental design. Consequently, the\ncommunity does not know which techniques perform best or even if they\noutperform simple baselines. We formulate desiderata for an ideal few-shot NLP\nbenchmark and present FLEX, the first benchmark, public leaderboard, and\nframework that provides unified, comprehensive measurement for few-shot NLP\ntechniques. FLEX incorporates and introduces new best practices for few-shot\nevaluation, including measurement of four transfer settings, textual labels for\nzero-shot evaluation, and a principled approach to benchmark design that\noptimizes statistical accuracy while keeping evaluation costs accessible to\nresearchers without large compute resources. In addition, we present UniFew, a\nsimple yet strong prompt-based model for few-shot learning which unifies the\npretraining and finetuning prompt formats, eschewing complex machinery of\nrecent prompt-based approaches in adapting downstream task formats to language\nmodel pretraining objectives. We demonstrate that despite simplicity UniFew\nachieves results competitive with both popular meta-learning and prompt-based\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:37:06 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bragg", "Jonathan", ""], ["Cohan", "Arman", ""], ["Lo", "Kyle", ""], ["Beltagy", "Iz", ""]]}, {"id": "2107.07171", "submitter": "Ye Yuan", "authors": "Ye Yuan, Ruijuan Chen, Chuan Sun, Maolin Wang, Feng Hua, Xinlei Yi,\n  Tao Yang and Jun Liu", "title": "DeFed: A Principled Decentralized and Privacy-Preserving Federated\n  Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables a large number of clients to participate in\nlearning a shared model while maintaining the training data stored in each\nclient, which protects data privacy and security. Till now, federated learning\nframeworks are built in a centralized way, in which a central client is needed\nfor collecting and distributing information from every other client. This not\nonly leads to high communication pressure at the central client, but also\nrenders the central client highly vulnerable to failure and attack. Here we\npropose a principled decentralized federated learning algorithm (DeFed), which\nremoves the central client in the classical Federated Averaging (FedAvg)\nsetting and only relies information transmission between clients and their\nlocal neighbors. The proposed DeFed algorithm is proven to reach the global\nminimum with a convergence rate of $O(1/T)$ when the loss function is smooth\nand strongly convex, where $T$ is the number of iterations in gradient descent.\nFinally, the proposed algorithm has been applied to a number of toy examples to\ndemonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:39:19 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Yuan", "Ye", ""], ["Chen", "Ruijuan", ""], ["Sun", "Chuan", ""], ["Wang", "Maolin", ""], ["Hua", "Feng", ""], ["Yi", "Xinlei", ""], ["Yang", "Tao", ""], ["Liu", "Jun", ""]]}, {"id": "2107.07184", "submitter": "Abhishek Gupta", "authors": "Kevin Li, Abhishek Gupta, Ashwin Reddy, Vitchyr Pong, Aurick Zhou,\n  Justin Yu, Sergey Levine", "title": "MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven\n  Reinforcement Learning", "comments": "Accepted to ICML 2021. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in reinforcement learning is a challenging problem: in the worst\ncase, the agent must search for high-reward states that could be hidden\nanywhere in the state space. Can we define a more tractable class of RL\nproblems, where the agent is provided with examples of successful outcomes? In\nthis problem setting, the reward function can be obtained automatically by\ntraining a classifier to categorize states as successful or not. If trained\nproperly, such a classifier can provide a well-shaped objective landscape that\nboth promotes progress toward good states and provides a calibrated exploration\nbonus. In this work, we show that an uncertainty aware classifier can solve\nchallenging reinforcement learning problems by both encouraging exploration and\nprovided directed guidance towards positive outcomes. We propose a novel\nmechanism for obtaining these calibrated, uncertainty-aware classifiers based\non an amortized technique for computing the normalized maximum likelihood (NML)\ndistribution. To make this tractable, we propose a novel method for computing\nthe NML distribution by using meta-learning. We show that the resulting\nalgorithm has a number of intriguing connections to both count-based\nexploration methods and prior algorithms for learning reward functions, while\nalso providing more effective guidance towards the goal. We demonstrate that\nour algorithm solves a number of challenging navigation and robotic\nmanipulation tasks which prove difficult or impossible for prior methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 08:19:57 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 22:01:41 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Li", "Kevin", ""], ["Gupta", "Abhishek", ""], ["Reddy", "Ashwin", ""], ["Pong", "Vitchyr", ""], ["Zhou", "Aurick", ""], ["Yu", "Justin", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.07197", "submitter": "Yufeng Xia", "authors": "Yufeng Xia, Jun Zhang, Zhiqiang Gong, Tingsong Jiang and Wen Yao", "title": "Randomized ReLU Activation for Uncertainty Estimation of Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep neural networks (DNNs) have successfully learned useful data\nrepresentations in various tasks, however, assessing the reliability of these\nrepresentations remains a challenge. Deep Ensemble is widely considered the\nstate-of-the-art method for uncertainty estimation, but it is very expensive to\ntrain and test. MC-Dropout is another alternative method, which is less\nexpensive but lacks the diversity of predictions. To get more diverse\npredictions in less time, we introduce Randomized ReLU Activation (RRA)\nframework. Under the framework, we propose two strategies, MC-DropReLU and\nMC-RReLU, to estimate uncertainty. Instead of randomly dropping some neurons of\nthe network as in MC-Dropout, the RRA framework adds randomness to the\nactivation function module, making the outputs diverse. As far as we know, this\nis the first attempt to add randomness to the activation function module to\ngenerate predictive uncertainty. We analyze and compare the output diversity of\nMC-Dropout and our method from the variance perspective and obtain the\nrelationship between the hyperparameters and output diversity in the two\nmethods. Moreover, our method is simple to implement and does not need to\nmodify the existing model. We experimentally validate the RRA framework on\nthree widely used datasets, CIFAR10, CIFAR100, and TinyImageNet. The\nexperiments demonstrate that our method has competitive performance but is more\nfavorable in training time and memory requirements.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 08:54:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xia", "Yufeng", ""], ["Zhang", "Jun", ""], ["Gong", "Zhiqiang", ""], ["Jiang", "Tingsong", ""], ["Yao", "Wen", ""]]}, {"id": "2107.07211", "submitter": "Vyacheslav Kungurtsev", "authors": "Vyacheslav Kungurtsev and Adam Cobb and Tara Javidi and Brian Jalaian", "title": "Decentralized Bayesian Learning with Metropolis-Adjusted Hamiltonian\n  Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning performed by a decentralized networks of agents is\nbecoming increasingly important with the prevalence of embedded software on\nautonomous devices. Bayesian approaches to learning benefit from offering more\ninformation as to the uncertainty of a random quantity, and Langevin and\nHamiltonian methods are effective at realizing sampling from an uncertain\ndistribution with large parameter dimensions. Such methods have only recently\nappeared in the decentralized setting, and either exclusively use stochastic\ngradient Langevin and Hamiltonian Monte Carlo approaches that require a\ndiminishing stepsize to asymptotically sample from the posterior and are known\nin practice to characterize uncertainty less faithfully than constant step-size\nmethods with a Metropolis adjustment, or assume strong convexity properties of\nthe potential function. We present the first approach to incorporating constant\nstepsize Metropolis-adjusted HMC in the decentralized sampling framework, show\ntheoretical guarantees for consensus and probability distance to the posterior\nstationary distribution, and demonstrate their effectiveness numerically on\nstandard real world problems, including decentralized learning of neural\nnetworks which is known to be highly non-convex.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 09:39:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kungurtsev", "Vyacheslav", ""], ["Cobb", "Adam", ""], ["Javidi", "Tara", ""], ["Jalaian", "Brian", ""]]}, {"id": "2107.07232", "submitter": "Alexandre Verine", "authors": "Alexandre Verine, Benjamin Negrevergne, Fabrice Rossi, Yann Chevaleyre", "title": "On the expressivity of bi-Lipschitz normalizing flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An invertible function is bi-Lipschitz if both the function and its inverse\nhave bounded Lipschitz constants. Nowadays, most Normalizing Flows are\nbi-Lipschitz by design or by training to limit numerical errors (among other\nthings). In this paper, we discuss the expressivity of bi-Lipschitz Normalizing\nFlows and identify several target distributions that are difficult to\napproximate using such models. Then, we characterize the expressivity of\nbi-Lipschitz Normalizing Flows by giving several lower bounds on the Total\nVariation distance between these particularly unfavorable distributions and\ntheir best possible approximation. Finally, we discuss potential remedies which\ninclude using more complex latent distributions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:13:46 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Verine", "Alexandre", ""], ["Negrevergne", "Benjamin", ""], ["Rossi", "Fabrice", ""], ["Chevaleyre", "Yann", ""]]}, {"id": "2107.07240", "submitter": "Xiangyu Qi", "authors": "Xiangyu Qi, Jifeng Zhu, Chulin Xie, Yong Yang", "title": "Subnet Replacement: Deployment-stage backdoor attack against deep neural\n  networks in gray-box setting", "comments": "6 pages, 3 figures, ICLR 2021 Workshop on Security and Safety in\n  Machine Learning System", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the realistic potential of conducting backdoor attack against deep\nneural networks (DNNs) during deployment stage. Specifically, our goal is to\ndesign a deployment-stage backdoor attack algorithm that is both threatening\nand realistically implementable. To this end, we propose Subnet Replacement\nAttack (SRA), which is capable of embedding backdoor into DNNs by directly\nmodifying a limited number of model parameters. Considering the realistic\npracticability, we abandon the strong white-box assumption widely adopted in\nexisting studies, instead, our algorithm works in a gray-box setting, where\narchitecture information of the victim model is available but the adversaries\ndo not have any knowledge of parameter values. The key philosophy underlying\nour approach is -- given any neural network instance (regardless of its\nspecific parameter values) of a certain architecture, we can always embed a\nbackdoor into that model instance, by replacing a very narrow subnet of a\nbenign model (without backdoor) with a malicious backdoor subnet, which is\ndesigned to be sensitive (fire large activation value) to a particular backdoor\ntrigger pattern.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 10:47:13 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Qi", "Xiangyu", ""], ["Zhu", "Jifeng", ""], ["Xie", "Chulin", ""], ["Yang", "Yong", ""]]}, {"id": "2107.07260", "submitter": "Jinyoung Choi", "authors": "Jinyoung Choi and Bohyung Han", "title": "MCL-GAN: Generative Adversarial Networks with Multiple Specialized\n  Discriminators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a generative adversarial network with multiple discriminators,\nwhere each discriminator is specialized to distinguish the subset of a real\ndataset. This approach facilitates learning a generator coinciding with the\nunderlying data distribution and thus mitigates the chronic mode collapse\nproblem. From the inspiration of multiple choice learning, we guide each\ndiscriminator to have expertise in the subset of the entire data and allow the\ngenerator to find reasonable correspondences between the latent and real data\nspaces automatically without supervision for training examples and the number\nof discriminators. Despite the use of multiple discriminators, the backbone\nnetworks are shared across the discriminators and the increase of training cost\nis minimized. We demonstrate the effectiveness of our algorithm in the standard\ndatasets using multiple evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 11:35:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Choi", "Jinyoung", ""], ["Han", "Bohyung", ""]]}, {"id": "2107.07261", "submitter": "Ori Yoran", "authors": "Ori Yoran, Alon Talmor, Jonathan Berant", "title": "Turning Tables: Generating Examples from Semi-structured Tables for\n  Endowing Language Models with Reasoning Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models pre-trained with a language modeling objective possess ample world\nknowledge and language skills, but are known to struggle in tasks that require\nreasoning. In this work, we propose to leverage semi-structured tables, and\nautomatically generate at scale question-paragraph pairs, where answering the\nquestion requires reasoning over multiple facts in the paragraph. We add a\npre-training step over this synthetic data, which includes examples that\nrequire 16 different reasoning skills such as number comparison, conjunction,\nand fact composition. To improve data efficiency, we propose sampling\nstrategies that focus training on reasoning skills the model is currently\nlacking. We evaluate our approach on three reading comprehension datasets that\nare focused on reasoning, and show that our model, PReasM, substantially\noutperforms T5, a popular pre-trained encoder-decoder model. Moreover, sampling\nexamples based on current model errors leads to faster training and higher\noverall performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 11:37:14 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Yoran", "Ori", ""], ["Talmor", "Alon", ""], ["Berant", "Jonathan", ""]]}, {"id": "2107.07271", "submitter": "Richard Gault", "authors": "Andrew Moyes, Richard Gault, Kun Zhang, Ji Ming, Danny Crookes, Jing\n  Wang", "title": "Multi-Channel Auto-Encoders and a Novel Dataset for Learning Domain\n  Invariant Representations of Histopathology Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Domain shift is a problem commonly encountered when developing automated\nhistopathology pipelines. The performance of machine learning models such as\nconvolutional neural networks within automated histopathology pipelines is\noften diminished when applying them to novel data domains due to factors\narising from differing staining and scanning protocols. The Dual-Channel\nAuto-Encoder (DCAE) model was previously shown to produce feature\nrepresentations that are less sensitive to appearance variation introduced by\ndifferent digital slide scanners. In this work, the Multi-Channel Auto-Encoder\n(MCAE) model is presented as an extension to DCAE which learns from more than\ntwo domains of data. Additionally, a synthetic dataset is generated using\nCycleGANs that contains aligned tissue images that have had their appearance\nsynthetically modified. Experimental results show that the MCAE model produces\nfeature representations that are less sensitive to inter-domain variations than\nthe comparative StaNoSA method when tested on the novel synthetic data.\nAdditionally, the MCAE and StaNoSA models are tested on a novel tissue\nclassification task. The results of this experiment show the MCAE model out\nperforms the StaNoSA model by 5 percentage-points in the f1-score. These\nresults show that the MCAE model is able to generalise better to novel data and\ntasks than existing approaches by actively learning normalised feature\nrepresentations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 11:56:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Moyes", "Andrew", ""], ["Gault", "Richard", ""], ["Zhang", "Kun", ""], ["Ming", "Ji", ""], ["Crookes", "Danny", ""], ["Wang", "Jing", ""]]}, {"id": "2107.07274", "submitter": "Bicheng Yan", "authors": "Bicheng Yan, Bailian Chen, Dylan Robert Harp, Rajesh J. Pawar", "title": "A Robust Deep Learning Workflow to Predict Multiphase Flow Behavior\n  during Geological CO2 Sequestration Injection and Post-Injection Periods", "comments": "16 pages, 13 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper contributes to the development and evaluation of a deep learning\nworkflow that accurately and efficiently predicts the temporal-spatial\nevolution of pressure and CO2 plumes during injection and post-injection\nperiods of geologic CO2 sequestration (GCS) operations. Based on a Fourier\nNeuron Operator, the deep learning workflow takes input variables or features\nincluding rock properties, well operational controls and time steps, and\npredicts the state variables of pressure and CO2 saturation. To further improve\nthe predictive fidelity, separate deep learning models are trained for CO2\ninjection and post-injection periods due the difference in primary driving\nforce of fluid flow and transport during these two phases. We also explore\ndifferent combinations of features to predict the state variables. We use a\nrealistic example of CO2 injection and storage in a 3D heterogeneous saline\naquifer, and apply the deep learning workflow that is trained from\nphysics-based simulation data and emulate the physics process. Through this\nnumerical experiment, we demonstrate that using two separate deep learning\nmodels to distinguish post-injection from injection period generates the most\naccurate prediction of pressure, and a single deep learning model of the whole\nGCS process including the cumulative injection volume of CO2 as a deep learning\nfeature, leads to the most accurate prediction of CO2 saturation. For the\npost-injection period, it is key to use cumulative CO2 injection volume to\ninform the deep learning models about the total carbon storage when predicting\neither pressure or saturation. The deep learning workflow not only provides\nhigh predictive fidelity across temporal and spatial scales, but also offers a\nspeedup of 250 times compared to full physics reservoir simulation, and thus\nwill be a significant predictive tool for engineers to manage the long term\nprocess of GCS.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 12:01:29 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Yan", "Bicheng", ""], ["Chen", "Bailian", ""], ["Harp", "Dylan Robert", ""], ["Pawar", "Rajesh J.", ""]]}, {"id": "2107.07281", "submitter": "Carlos Villacampa-Calvo", "authors": "Bahram Jafrasteh and Carlos Villacampa-Calvo and Daniel\n  Hern\\'andez-Lobato", "title": "Input Dependent Sparse Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) are Bayesian models that provide uncertainty\nestimates associated to the predictions made. They are also very flexible due\nto their non-parametric nature. Nevertheless, GPs suffer from poor scalability\nas the number of training instances N increases. More precisely, they have a\ncubic cost with respect to $N$. To overcome this problem, sparse GP\napproximations are often used, where a set of $M \\ll N$ inducing points is\nintroduced during training. The location of the inducing points is learned by\nconsidering them as parameters of an approximate posterior distribution $q$.\nSparse GPs, combined with variational inference for inferring $q$, reduce the\ntraining cost of GPs to $\\mathcal{O}(M^3)$. Critically, the inducing points\ndetermine the flexibility of the model and they are often located in regions of\nthe input space where the latent function changes. A limitation is, however,\nthat for some learning tasks a large number of inducing points may be required\nto obtain a good prediction performance. To address this limitation, we propose\nhere to amortize the computation of the inducing points locations, as well as\nthe parameters of the variational posterior approximation q. For this, we use a\nneural network that receives the observed data as an input and outputs the\ninducing points locations and the parameters of $q$. We evaluate our method in\nseveral experiments, showing that it performs similar or better than other\nstate-of-the-art sparse variational GP approaches. However, with our method the\nnumber of inducing points is reduced drastically due to their dependency on the\ninput data. This makes our method scale to larger datasets and have faster\ntraining and prediction times.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 12:19:10 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Jafrasteh", "Bahram", ""], ["Villacampa-Calvo", "Carlos", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2107.07305", "submitter": "Emmanouil Sifalakis", "authors": "Amirreza Yousefzadeh, Manolis Sifalakis", "title": "Training for temporal sparsity in deep neural networks, application in\n  video processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Activation sparsity improves compute efficiency and resource utilization in\nsparsity-aware neural network accelerators. As the predominant operation in\nDNNs is multiply-accumulate (MAC) of activations with weights to compute inner\nproducts, skipping operations where (at least) one of the two operands is zero\ncan make inference more efficient in terms of latency and power. Spatial\nsparsification of activations is a popular topic in DNN literature and several\nmethods have already been established to bias a DNN for it. On the other hand,\ntemporal sparsity is an inherent feature of bio-inspired spiking neural\nnetworks (SNNs), which neuromorphic processing exploits for hardware\nefficiency. Introducing and exploiting spatio-temporal sparsity, is a topic\nmuch less explored in DNN literature, but in perfect resonance with the trend\nin DNN, to shift from static signal processing to more streaming signal\nprocessing. Towards this goal, in this paper we introduce a new DNN layer\n(called Delta Activation Layer), whose sole purpose is to promote temporal\nsparsity of activations during training. A Delta Activation Layer casts\ntemporal sparsity into spatial activation sparsity to be exploited when\nperforming sparse tensor multiplications in hardware. By employing delta\ninference and ``the usual'' spatial sparsification heuristics during training,\nthe resulting model learns to exploit not only spatial but also temporal\nactivation sparsity (for a given input data distribution). One may use the\nDelta Activation Layer either during vanilla training or during a refinement\nphase. We have implemented Delta Activation Layer as an extension of the\nstandard Tensoflow-Keras library, and applied it to train deep neural networks\non the Human Action Recognition (UCF101) dataset. We report an almost 3x\nimprovement of activation sparsity, with recoverable loss of model accuracy\nafter longer training.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:17:11 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Yousefzadeh", "Amirreza", ""], ["Sifalakis", "Manolis", ""]]}, {"id": "2107.07312", "submitter": "Chong Tang", "authors": "Chong Tang, Wenda Li, Shelly Vishwakarma, Fangzhan Shi, Simon Julier,\n  Kevin Chetty", "title": "FMNet: Latent Feature-wise Mapping Network for Cleaning up Noisy\n  Micro-Doppler Spectrogram", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-Doppler signatures contain considerable information about target\ndynamics. However, the radar sensing systems are easily affected by noisy\nsurroundings, resulting in uninterpretable motion patterns on the micro-Doppler\nspectrogram. Meanwhile, radar returns often suffer from multipath, clutter and\ninterference. These issues lead to difficulty in, for example motion feature\nextraction, activity classification using micro Doppler signatures ($\\mu$-DS),\netc. In this paper, we propose a latent feature-wise mapping strategy, called\nFeature Mapping Network (FMNet), to transform measured spectrograms so that\nthey more closely resemble the output from a simulation under the same\nconditions. Based on measured spectrogram and the matched simulated data, our\nframework contains three parts: an Encoder which is used to extract latent\nrepresentations/features, a Decoder outputs reconstructed spectrogram according\nto the latent features, and a Discriminator minimizes the distance of latent\nfeatures of measured and simulated data. We demonstrate the FMNet with six\nactivities data and two experimental scenarios, and final results show strong\nenhanced patterns and can keep actual motion information to the greatest\nextent. On the other hand, we also propose a novel idea which trains a\nclassifier with only simulated data and predicts new measured samples after\ncleaning them up with the FMNet. From final classification results, we can see\nsignificant improvements.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:20:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Tang", "Chong", ""], ["Li", "Wenda", ""], ["Vishwakarma", "Shelly", ""], ["Shi", "Fangzhan", ""], ["Julier", "Simon", ""], ["Chetty", "Kevin", ""]]}, {"id": "2107.07314", "submitter": "Ivona Najdenkoska", "authors": "Ivona Najdenkoska, Xiantong Zhen, Marcel Worring and Ling Shao", "title": "Variational Topic Inference for Chest X-Ray Report Generation", "comments": "To be published in the International Conference on Medical Image\n  Computing and Computer Assisted Intervention 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automating report generation for medical imaging promises to reduce workload\nand assist diagnosis in clinical practice. Recent work has shown that deep\nlearning models can successfully caption natural images. However, learning from\nmedical data is challenging due to the diversity and uncertainty inherent in\nthe reports written by different radiologists with discrepant expertise and\nexperience. To tackle these challenges, we propose variational topic inference\nfor automatic report generation. Specifically, we introduce a set of topics as\nlatent variables to guide sentence generation by aligning image and language\nmodalities in a latent space. The topics are inferred in a conditional\nvariational inference framework, with each topic governing the generation of a\nsentence in the report. Further, we adopt a visual attention module that\nenables the model to attend to different locations in the image and generate\nmore informative descriptions. We conduct extensive experiments on two\nbenchmarks, namely Indiana U. Chest X-rays and MIMIC-CXR. The results\ndemonstrate that our proposed variational topic inference method can generate\nnovel reports rather than mere copies of reports used in training, while still\nachieving comparable performance to state-of-the-art methods in terms of\nstandard language generation criteria.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:34:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Najdenkoska", "Ivona", ""], ["Zhen", "Xiantong", ""], ["Worring", "Marcel", ""], ["Shao", "Ling", ""]]}, {"id": "2107.07322", "submitter": "Ziyu Xu", "authors": "Ziyu Xu, Ruodu Wang, Aaditya Ramdas", "title": "A unified framework for bandit multiple testing", "comments": "37 pages. 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In bandit multiple hypothesis testing, each arm corresponds to a different\nnull hypothesis that we wish to test, and the goal is to design adaptive\nalgorithms that correctly identify large set of interesting arms (true\ndiscoveries), while only mistakenly identifying a few uninteresting ones (false\ndiscoveries). One common metric in non-bandit multiple testing is the false\ndiscovery rate (FDR). We propose a unified, modular framework for bandit FDR\ncontrol that emphasizes the decoupling of exploration and summarization of\nevidence. We utilize the powerful martingale-based concept of ``e-processes''\nto ensure FDR control for arbitrary composite nulls, exploration rules and\nstopping times in generic problem settings. In particular, valid FDR control\nholds even if the reward distributions of the arms could be dependent, multiple\narms may be queried simultaneously, and multiple (cooperating or competing)\nagents may be querying arms, covering combinatorial semi-bandit type settings\nas well. Prior work has considered in great detail the setting where each arm's\nreward distribution is independent and sub-Gaussian, and a single arm is\nqueried at each step. Our framework recovers matching sample complexity\nguarantees in this special case, and performs comparably or better in practice.\nFor other settings, sample complexities will depend on the finer details of the\nproblem (composite nulls being tested, exploration algorithm, data dependence\nstructure, stopping rule) and we do not explore these; our contribution is to\nshow that the FDR guarantee is clean and entirely agnostic to these details.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:47:28 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Xu", "Ziyu", ""], ["Wang", "Ruodu", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "2107.07331", "submitter": "Runze Chen", "authors": "Runze Chen and Haiyong Luo and Fang Zhao and Xuechun Meng and Zhiqing\n  Xie and Yida Zhu", "title": "Modeling Accurate Human Activity Recognition for Embedded Devices Using\n  Multi-level Distillation", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) based on IMU sensors is an essential domain\nin ubiquitous computing. Because of the improving trend to deploy artificial\nintelligence into IoT devices or smartphones, more researchers design the HAR\nmodels for embedded devices. We propose a plug-and-play HAR modeling pipeline\nwith multi-level distillation to build deep convolutional HAR models with\nnative support of embedded devices. SMLDist consists of stage distillation,\nmemory distillation, and logits distillation, which covers all the information\nflow of the deep models. Stage distillation constrains the learning direction\nof the intermediate features. Memory distillation teaches the student models\nhow to explain and store the inner relationship between high-dimensional\nfeatures based on Hopfield networks. Logits distillation constructs distilled\nlogits by a smoothed conditional rule to keep the probable distribution and\nimprove the correctness of the soft target. We compare the performance of\naccuracy, F1 macro score, and energy cost on the embedded platform of various\nstate-of-the-art HAR frameworks with a MobileNet V3 model built by SMLDist. The\nproduced model has well balance with robustness, efficiency, and accuracy.\nSMLDist can also compress the models with minor performance loss in an equal\ncompression rate than other state-of-the-art knowledge distillation methods on\nseven public datasets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 09:01:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Runze", ""], ["Luo", "Haiyong", ""], ["Zhao", "Fang", ""], ["Meng", "Xuechun", ""], ["Xie", "Zhiqing", ""], ["Zhu", "Yida", ""]]}, {"id": "2107.07334", "submitter": "L\\^e Nguy\\^en Hoang", "authors": "L\\^e-Nguy\\^en Hoang, Louis Faucon, Aidan Jungo, Sergei Volodin, Dalia\n  Papuc, Orfeas Liossatos, Ben Crulis, Mariame Tighanimine, Isabela Constantin,\n  Anastasiia Kucherenko, Alexandre Maurer, Felix Grimberg, Vlad Nitu, Chris\n  Vossen, S\\'ebastien Rouault and El-Mahdi El-Mhamdi", "title": "Tournesol: A quest for a large, secure and trustworthy database of\n  reliable human judgments", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Today's large-scale algorithms have become immensely influential, as they\nrecommend and moderate the content that billions of humans are exposed to on a\ndaily basis. They are the de-facto regulators of our societies' information\ndiet, from shaping opinions on public health to organizing groups for social\nmovements. This creates serious concerns, but also great opportunities to\npromote quality information. Addressing the concerns and seizing the\nopportunities is a challenging, enormous and fabulous endeavor, as intuitively\nappealing ideas often come with unwanted {\\it side effects}, and as it requires\nus to think about what we deeply prefer.\n  Understanding how today's large-scale algorithms are built is critical to\ndetermine what interventions will be most effective. Given that these\nalgorithms rely heavily on {\\it machine learning}, we make the following key\nobservation: \\emph{any algorithm trained on uncontrolled data must not be\ntrusted}. Indeed, a malicious entity could take control over the data, poison\nit with dangerously manipulative fabricated inputs, and thereby make the\ntrained algorithm extremely unsafe. We thus argue that the first step towards\nsafe and ethical large-scale algorithms must be the collection of a large,\nsecure and trustworthy dataset of reliable human judgments.\n  To achieve this, we introduce \\emph{Tournesol}, an open source platform\navailable at \\url{https://tournesol.app}. Tournesol aims to collect a large\ndatabase of human judgments on what algorithms ought to widely recommend (and\nwhat they ought to stop widely recommending). We outline the structure of the\nTournesol database, the key features of the Tournesol platform and the main\nhurdles that must be overcome to make it a successful project. Most\nimportantly, we argue that, if successful, Tournesol may then serve as the\nessential foundation for any safe and ethical large-scale algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:21:35 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Hoang", "L\u00ea-Nguy\u00ean", ""], ["Faucon", "Louis", ""], ["Jungo", "Aidan", ""], ["Volodin", "Sergei", ""], ["Papuc", "Dalia", ""], ["Liossatos", "Orfeas", ""], ["Crulis", "Ben", ""], ["Tighanimine", "Mariame", ""], ["Constantin", "Isabela", ""], ["Kucherenko", "Anastasiia", ""], ["Maurer", "Alexandre", ""], ["Grimberg", "Felix", ""], ["Nitu", "Vlad", ""], ["Vossen", "Chris", ""], ["Rouault", "S\u00e9bastien", ""], ["El-Mhamdi", "El-Mahdi", ""]]}, {"id": "2107.07338", "submitter": "Dativa Tizikara", "authors": "Dativa K. Tizikara, Jonathan Serugunda, and Andrew Katumba", "title": "An Overview of Machine Learning-aided Optical Performance Monitoring\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Future communication systems are faced with increased demand for high\ncapacity, dynamic bandwidth, reliability and heterogeneous traffic. To meet\nthese requirements, networks have become more complex and thus require new\ndesign methods and monitoring techniques, as they evolve towards becoming\nautonomous. Machine learning has come to the forefront in recent years as a\npromising technology to aid in this evolution. Optical fiber communications can\nalready provide the high capacity required for most applications, however,\nthere is a need for increased scalability and adaptability to changing user\ndemands and link conditions. Accurate performance monitoring is an integral\npart of this transformation. In this paper we review optical performance\nmonitoring techniques where machine learning algorithms have been applied.\nMoreover, since alot of OPM depends on knowledge of the signal type, we also\nreview work for modulation format recognition and bitrate identification. We\nadditionally briefly introduce a neuromorphic approach to OPM as an emerging\ntechnique that has only recently been applied to this domain.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 18:27:30 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Tizikara", "Dativa K.", ""], ["Serugunda", "Jonathan", ""], ["Katumba", "Andrew", ""]]}, {"id": "2107.07341", "submitter": "Rutwik Shah", "authors": "Rutwik Shah, Bruno Astuto, Tyler Gleason, Will Fletcher, Justin\n  Banaga, Kevin Sweetwood, Allen Ye, Rina Patel, Kevin McGill, Thomas Link,\n  Jason Crane, Valentina Pedoia, Sharmila Majumdar", "title": "Leveraging wisdom of the crowds to improve consensus among radiologists\n  by real time, blinded collaborations on a digital swarm platform", "comments": "24 pages, 2 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.DC cs.LG cs.NE cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Radiologists today play a key role in making diagnostic decisions and\nlabeling images for training A.I. algorithms. Low inter-reader reliability\n(IRR) can be seen between experts when interpreting challenging cases. While\nteams-based decisions are known to outperform individual decisions,\ninter-personal biases often creep up in group interactions which limit\nnon-dominant participants from expressing true opinions. To overcome the dual\nproblems of low consensus and inter-personal bias, we explored a solution\nmodeled on biological swarms of bees. Two separate cohorts; three radiologists\nand five radiology residents collaborated on a digital swarm platform in real\ntime and in a blinded fashion, grading meniscal lesions on knee MR exams. These\nconsensus votes were benchmarked against clinical (arthroscopy) and\nradiological (senior-most radiologist) observations. The IRR of the consensus\nvotes was compared to the IRR of the majority and most confident votes of the\ntwo cohorts.The radiologist cohort saw an improvement of 23% in IRR of swarm\nvotes over majority vote. Similar improvement of 23% in IRR in 3-resident swarm\nvotes over majority vote, was observed. The 5-resident swarm had an even higher\nimprovement of 32% in IRR over majority vote. Swarm consensus votes also\nimproved specificity by up to 50%. The swarm consensus votes outperformed\nindividual and majority vote decisions in both the radiologists and resident\ncohorts. The 5-resident swarm had higher IRR than 3-resident swarm indicating\npositive effect of increased swarm size. The attending and resident swarms also\noutperformed predictions from a state-of-the-art A.I. algorithm. Utilizing a\ndigital swarm platform improved agreement and allows participants to express\njudgement free intent, resulting in superior clinical performance and robust\nA.I. training labels.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 06:52:06 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shah", "Rutwik", ""], ["Astuto", "Bruno", ""], ["Gleason", "Tyler", ""], ["Fletcher", "Will", ""], ["Banaga", "Justin", ""], ["Sweetwood", "Kevin", ""], ["Ye", "Allen", ""], ["Patel", "Rina", ""], ["McGill", "Kevin", ""], ["Link", "Thomas", ""], ["Crane", "Jason", ""], ["Pedoia", "Valentina", ""], ["Majumdar", "Sharmila", ""]]}, {"id": "2107.07342", "submitter": "Manel Mart\\'inez-Ram\\'on", "authors": "Rahul Jaiswal and Manel Mart\\'inez-Ram\\'on and Tito Busani", "title": "Probabilistic analysis of solar cell optical performance using Gaussian\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work investigates application of different machine learning based\nprediction methodologies to estimate the performance of silicon based textured\ncells. Concept of confidence bound regions is introduced and advantages of this\nconcept are discussed in detail. Results show that reflection profiles and\ndepth dependent optical generation profiles can be accurately estimated using\nGaussian processes with exact knowledge of uncertainty in the prediction\nvalues.It is also shown that cell design parameters can be estimated for a\ndesired performance metric.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 20:25:05 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Jaiswal", "Rahul", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""], ["Busani", "Tito", ""]]}, {"id": "2107.07343", "submitter": "Lennart Schneider", "authors": "Lennart Schneider, Florian Pfisterer, Martin Binder and Bernd Bischl", "title": "Mutation is all you need", "comments": "Accepted for the 8th ICML Workshop on Automated Machine Learning\n  (2021). 10 pages, 1 table, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) promises to make deep learning accessible to\nnon-experts by automating architecture engineering of deep neural networks.\nBANANAS is one state-of-the-art NAS method that is embedded within the Bayesian\noptimization framework. Recent experimental findings have demonstrated the\nstrong performance of BANANAS on the NAS-Bench-101 benchmark being determined\nby its path encoding and not its choice of surrogate model. We present\nexperimental results suggesting that the performance of BANANAS on the\nNAS-Bench-301 benchmark is determined by its acquisition function optimizer,\nwhich minimally mutates the incumbent.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 15:15:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Schneider", "Lennart", ""], ["Pfisterer", "Florian", ""], ["Binder", "Martin", ""], ["Bischl", "Bernd", ""]]}, {"id": "2107.07344", "submitter": "Nirmalya Thakur", "authors": "Nirmalya Thakur and Chia Y. Han", "title": "Framework for A Personalized Intelligent Assistant to Elderly People for\n  Activities of Daily Living", "comments": "arXiv admin note: text overlap with arXiv:2106.15599", "journal-ref": "International Journal of Recent Trends in Human Computer\n  Interaction (IJHCI), Volume 9, Issue 1, 2019, pp. 1-22", "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing population of elderly people is associated with the need to\nmeet their increasing requirements and to provide solutions that can improve\ntheir quality of life in a smart home. In addition to fear and anxiety towards\ninterfacing with systems; cognitive disabilities, weakened memory, disorganized\nbehavior and even physical limitations are some of the problems that elderly\npeople tend to face with increasing age. The essence of providing\ntechnology-based solutions to address these needs of elderly people and to\ncreate smart and assisted living spaces for the elderly; lies in developing\nsystems that can adapt by addressing their diversity and can augment their\nperformances in the context of their day to day goals. Therefore, this work\nproposes a framework for development of a Personalized Intelligent Assistant to\nhelp elderly people perform Activities of Daily Living (ADLs) in a smart and\nconnected Internet of Things (IoT) based environment. This Personalized\nIntelligent Assistant can analyze different tasks performed by the user and\nrecommend activities by considering their daily routine, current affective\nstate and the underlining user experience. To uphold the efficacy of this\nproposed framework, it has been tested on a couple of datasets for modelling an\naverage user and a specific user respectively. The results presented show that\nthe model achieves a performance accuracy of 73.12% when modelling a specific\nuser, which is considerably higher than its performance while modelling an\naverage user, this upholds the relevance for development and implementation of\nthis proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:36:07 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Thakur", "Nirmalya", ""], ["Han", "Chia Y.", ""]]}, {"id": "2107.07345", "submitter": "Juliane Weilbach", "authors": "Juliane Weilbach, Sebastian Gerwinn, Christian Weilbach and Melih\n  Kandemir", "title": "Inferring the Structure of Ordinary Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding physical phenomena oftentimes means understanding the\nunderlying dynamical system that governs observational measurements. While\naccurate prediction can be achieved with black box systems, they often lack\ninterpretability and are less amenable for further expert investigation.\nAlternatively, the dynamics can be analysed via symbolic regression. In this\npaper, we extend the approach by (Udrescu et al., 2020) called AIFeynman to the\ndynamic setting to perform symbolic regression on ODE systems based on\nobservations from the resulting trajectories. We compare this extension to\nstate-of-the-art approaches for symbolic regression empirically on several\ndynamical systems for which the ground truth equations of increasing complexity\nare available. Although the proposed approach performs best on this benchmark,\nwe observed difficulties of all the compared symbolic regression approaches on\nmore complex systems, such as Cart-Pole.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:55:05 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Weilbach", "Juliane", ""], ["Gerwinn", "Sebastian", ""], ["Weilbach", "Christian", ""], ["Kandemir", "Melih", ""]]}, {"id": "2107.07346", "submitter": "Jacopo Tagliabue", "authors": "Jacopo Tagliabue", "title": "You Do Not Need a Bigger Boat: Recommendations at Reasonable Scale in a\n  (Mostly) Serverless and Open Stack", "comments": "Manuscript version of a work accepted at RecSys 2021 (camera-ready\n  forthcoming)", "journal-ref": null, "doi": "10.1145/3460231.3474604", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that immature data pipelines are preventing a large portion of\nindustry practitioners from leveraging the latest research on recommender\nsystems. We propose our template data stack for machine learning at \"reasonable\nscale\", and show how many challenges are solved by embracing a serverless\nparadigm. Leveraging our experience, we detail how modern open source can\nprovide a pipeline processing terabytes of data with limited infrastructure\nwork.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:00:29 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Tagliabue", "Jacopo", ""]]}, {"id": "2107.07349", "submitter": "Saptarshi Bej", "authors": "Saptarshi Bej, Kristian Schultz, Prashant Srivastava, Markus Wolfien,\n  Olaf Wolkenhauer", "title": "A multi-schematic classifier-independent oversampling approach for\n  imbalanced datasets", "comments": "12 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over 85 oversampling algorithms, mostly extensions of the SMOTE algorithm,\nhave been built over the past two decades, to solve the problem of imbalanced\ndatasets. However, it has been evident from previous studies that different\noversampling algorithms have different degrees of efficiency with different\nclassifiers. With numerous algorithms available, it is difficult to decide on\nan oversampling algorithm for a chosen classifier. Here, we overcome this\nproblem with a multi-schematic and classifier-independent oversampling\napproach: ProWRAS(Proximity Weighted Random Affine Shadowsampling). ProWRAS\nintegrates the Localized Random Affine Shadowsampling (LoRAS)algorithm and the\nProximity Weighted Synthetic oversampling (ProWSyn) algorithm. By controlling\nthe variance of the synthetic samples, as well as a proximity-weighted\nclustering system of the minority classdata, the ProWRAS algorithm improves\nperformance, compared to algorithms that generate synthetic samples through\nmodelling high dimensional convex spaces of the minority class. ProWRAS has\nfour oversampling schemes, each of which has its unique way to model the\nvariance of the generated data. Most importantly, the performance of ProWRAS\nwith proper choice of oversampling schemes, is independent of the classifier\nused. We have benchmarked our newly developed ProWRAS algorithm against five\nsate-of-the-art oversampling models and four different classifiers on 20\npublicly available datasets. ProWRAS outperforms other oversampling algorithms\nin a statistically significant way, in terms of both F1-score and Kappa-score.\nMoreover, we have introduced a novel measure for classifier independence\nI-score, and showed quantitatively that ProWRAS performs better, independent of\nthe classifier used. In practice, ProWRAS customizes synthetic sample\ngeneration according to a classifier of choice and thereby reduces benchmarking\nefforts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:03:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bej", "Saptarshi", ""], ["Schultz", "Kristian", ""], ["Srivastava", "Prashant", ""], ["Wolfien", "Markus", ""], ["Wolkenhauer", "Olaf", ""]]}, {"id": "2107.07352", "submitter": "Mike Laszkiewicz", "authors": "Mike Laszkiewicz, Johannes Lederer, Asja Fischer", "title": "Copula-Based Normalizing Flows", "comments": "Accepted for presentation at the ICML 2021 Workshop on Invertible\n  Neural Networks, Normalizing Flows, and Explicit Likelihood Models (INNF+\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows, which learn a distribution by transforming the data to\nsamples from a Gaussian base distribution, have proven powerful density\napproximations. But their expressive power is limited by this choice of the\nbase distribution. We, therefore, propose to generalize the base distribution\nto a more elaborate copula distribution to capture the properties of the target\ndistribution more accurately. In a first empirical analysis, we demonstrate\nthat this replacement can dramatically improve the vanilla normalizing flows in\nterms of flexibility, stability, and effectivity for heavy-tailed data. Our\nresults suggest that the improvements are related to an increased local\nLipschitz-stability of the learned flow.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:22:28 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Laszkiewicz", "Mike", ""], ["Lederer", "Johannes", ""], ["Fischer", "Asja", ""]]}, {"id": "2107.07364", "submitter": "Dhasarathy Parthasarathy", "authors": "Dhasarathy Parthasarathy, Anton Johansson", "title": "SilGAN: Generating driving maneuvers for scenario-based\n  software-in-the-loop testing", "comments": "Preprint of article accepted at The third IEEE International\n  Conference On Artificial Intelligence Testing 2021, Oxford, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automotive software testing continues to rely largely upon expensive field\ntests to ensure quality because alternatives like simulation-based testing are\nrelatively immature. As a step towards lowering reliance on field tests, we\npresent SilGAN, a deep generative model that eases specification, stimulus\ngeneration, and automation of automotive software-in-the-loop testing. The\nmodel is trained using data recorded from vehicles in the field. Upon training,\nthe model uses a concise specification for a driving scenario to generate\nrealistic vehicle state transitions that can occur during such a scenario. Such\nauthentic emulation of internal vehicle behavior can be used for rapid,\nsystematic and inexpensive testing of vehicle control software. In addition, by\npresenting a targeted method for searching through the information learned by\nthe model, we show how a test objective like code coverage can be automated.\nThe data driven end-to-end testing pipeline that we present vastly expands the\nscope and credibility of automotive simulation-based testing. This reduces time\nto market while helping maintain required standards of quality.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 07:17:49 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Parthasarathy", "Dhasarathy", ""], ["Johansson", "Anton", ""]]}, {"id": "2107.07373", "submitter": "Joseph Palermo", "authors": "Joseph Palermo, Johnny Ye, Alok Singh", "title": "A Reinforcement Learning Environment for Mathematical Reasoning via\n  Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We convert the DeepMind Mathematics Dataset into a reinforcement learning\nenvironment by interpreting it as a program synthesis problem. Each action\ntaken in the environment adds an operator or an input into a discrete compute\ngraph. Graphs which compute correct answers yield positive reward, enabling the\noptimization of a policy to construct compute graphs conditioned on problem\nstatements. Baseline models are trained using Double DQN on various subsets of\nproblem types, demonstrating the capability to learn to correctly construct\ngraphs despite the challenges of combinatorial explosion and noisy rewards.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:55:34 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 02:40:38 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Palermo", "Joseph", ""], ["Ye", "Johnny", ""], ["Singh", "Alok", ""]]}, {"id": "2107.07376", "submitter": "EPTCS", "authors": "Elaine Pimentel (UFRN), Enrico Tassi (Inria)", "title": "Proceedings of the Sixteenth Workshop on Logical Frameworks and\n  Meta-Languages: Theory and Practice", "comments": null, "journal-ref": "EPTCS 337, 2021", "doi": "10.4204/EPTCS.337", "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logical frameworks and meta-languages form a common substrate for\nrepresenting, implementing and reasoning about a wide variety of deductive\nsystems of interest in logic and computer science. Their design, implementation\nand their use in reasoning tasks, ranging from the correctness of software to\nthe properties of formal systems, have been the focus of considerable research\nover the last two decades. This workshop brings together designers,\nimplementors and practitioners to discuss various aspects impinging on the\nstructure and utility of logical frameworks, including the treatment of\nvariable binding, inductive and co-inductive reasoning techniques and the\nexpressiveness and lucidity of the reasoning process.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 05:19:09 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Pimentel", "Elaine", "", "UFRN"], ["Tassi", "Enrico", "", "Inria"]]}, {"id": "2107.07382", "submitter": "Md Ali Azam", "authors": "Md Ali Azam, Abir Hossen, Md Hafizur Rahman", "title": "Hybrid Ant Swarm-Based Data Clustering", "comments": "Conference", "journal-ref": "2021 IEEE World AI IoT Congress (AIIoT)", "doi": "10.1109/AIIoT52608.2021.9454238", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biologically inspired computing techniques are very effective and useful in\nmany areas of research including data clustering. Ant clustering algorithm is a\nnature-inspired clustering technique which is extensively studied for over two\ndecades. In this study, we extend the ant clustering algorithm (ACA) to a\nhybrid ant clustering algorithm (hACA). Specifically, we include a genetic\nalgorithm in standard ACA to extend the hybrid algorithm for better\nperformance. We also introduced novel pick up and drop off rules to speed up\nthe clustering performance. We study the performance of the hACA algorithm and\ncompare with standard ACA as a benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 16:43:11 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Azam", "Md Ali", ""], ["Hossen", "Abir", ""], ["Rahman", "Md Hafizur", ""]]}, {"id": "2107.07384", "submitter": "Wei Zhou", "authors": "Wei Zhou, Yiying Li", "title": "A Fixed Version of Quadratic Program in Gradient Episodic Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Gradient Episodic Memory is indeed a novel method for continual learning,\nwhich solves new problems quickly without forgetting previously acquired\nknowledge. However, in the process of studying the paper, we found there were\nsome problems in the proof of the dual problem of Quadratic Program, so here we\ngive our fixed version for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 07:45:15 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zhou", "Wei", ""], ["Li", "Yiying", ""]]}, {"id": "2107.07393", "submitter": "Vijay Keswani", "authors": "Vijay Keswani and L. Elisa Celis", "title": "Auditing for Diversity using Representative Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the diversity of a dataset of information associated with people is\ncrucial before using such data for downstream applications. For a given\ndataset, this often involves computing the imbalance or disparity in the\nempirical marginal distribution of a protected attribute (e.g. gender, dialect,\netc.). However, real-world datasets, such as images from Google Search or\ncollections of Twitter posts, often do not have protected attributes labeled.\nConsequently, to derive disparity measures for such datasets, the elements need\nto hand-labeled or crowd-annotated, which are expensive processes.\n  We propose a cost-effective approach to approximate the disparity of a given\nunlabeled dataset, with respect to a protected attribute, using a control set\nof labeled representative examples. Our proposed algorithm uses the pairwise\nsimilarity between elements in the dataset and elements in the control set to\neffectively bootstrap an approximation to the disparity of the dataset.\nImportantly, we show that using a control set whose size is much smaller than\nthe size of the dataset is sufficient to achieve a small approximation error.\nFurther, based on our theoretical framework, we also provide an algorithm to\nconstruct adaptive control sets that achieve smaller approximation errors than\nrandomly chosen control sets. Simulations on two image datasets and one Twitter\ndataset demonstrate the efficacy of our approach (using random and adaptive\ncontrol sets) in auditing the diversity of a wide variety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 15:21:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Keswani", "Vijay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2107.07394", "submitter": "Arnaud Fickinger", "authors": "Arnaud Fickinger, Natasha Jaques, Samyak Parajuli, Michael Chang,\n  Nicholas Rhinehart, Glen Berseth, Stuart Russell, Sergey Levine", "title": "Explore and Control with Adversarial Surprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) provides a framework for learning goal-directed\npolicies given user-specified rewards. However, since designing rewards often\nrequires substantial engineering effort, we are interested in the problem of\nlearning without rewards, where agents must discover useful behaviors in the\nabsence of task-specific incentives. Intrinsic motivation is a family of\nunsupervised RL techniques which develop general objectives for an RL agent to\noptimize that lead to better exploration or the discovery of skills. In this\npaper, we propose a new unsupervised RL technique based on an adversarial game\nwhich pits two policies against each other to compete over the amount of\nsurprise an RL agent experiences. The policies each take turns controlling the\nagent. The Explore policy maximizes entropy, putting the agent into surprising\nor unfamiliar situations. Then, the Control policy takes over and seeks to\nrecover from those situations by minimizing entropy. The game harnesses the\npower of multi-agent competition to drive the agent to seek out increasingly\nsurprising parts of the environment while learning to gain mastery over them.\nWe show empirically that our method leads to the emergence of complex skills by\nexhibiting clear phase transitions. Furthermore, we show both theoretically\n(via a latent state space coverage argument) and empirically that our method\nhas the potential to be applied to the exploration of stochastic,\npartially-observed environments. We show that Adversarial Surprise learns more\ncomplex behaviors, and explores more effectively than competitive baselines,\noutperforming intrinsic motivation methods based on active inference,\nnovelty-seeking (Random Network Distillation (RND)), and multi-agent\nunsupervised RL (Asymmetric Self-Play (ASP)) in MiniGrid, Atari and VizDoom\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:58:40 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Fickinger", "Arnaud", ""], ["Jaques", "Natasha", ""], ["Parajuli", "Samyak", ""], ["Chang", "Michael", ""], ["Rhinehart", "Nicholas", ""], ["Berseth", "Glen", ""], ["Russell", "Stuart", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.07402", "submitter": "Anirudh Gupta", "authors": "Anirudh Gupta, Harveen Singh Chadha, Priyanshi Shah, Neeraj Chimmwal,\n  Ankur Dhuriya, Rishabh Gaur, Vivek Raghavan", "title": "CLSRIL-23: Cross Lingual Speech Representations for Indic Languages", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a CLSRIL-23, a self supervised learning based audio pre-trained\nmodel which learns cross lingual speech representations from raw audio across\n23 Indic languages. It is built on top of wav2vec 2.0 which is solved by\ntraining a contrastive task over masked latent speech representations and\njointly learns the quantization of latents shared across all languages. We\ncompare the language wise loss during pretraining to compare effects of\nmonolingual and multilingual pretraining. Performance on some downstream\nfine-tuning tasks for speech recognition is also compared and our experiments\nshow that multilingual pretraining outperforms monolingual training, in terms\nof learning speech representations which encodes phonetic similarity of\nlanguages and also in terms of performance on down stream tasks. A decrease of\n5% is observed in WER and 9.5% in CER when a multilingual pretrained model is\nused for finetuning in Hindi. All the code models are also open sourced.\nCLSRIL-23 is a model trained on $23$ languages and almost 10,000 hours of audio\ndata to facilitate research in speech recognition for Indic languages. We hope\nthat new state of the art systems will be created using the self supervised\napproach, especially for low resources Indic languages.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 15:42:43 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gupta", "Anirudh", ""], ["Chadha", "Harveen Singh", ""], ["Shah", "Priyanshi", ""], ["Chimmwal", "Neeraj", ""], ["Dhuriya", "Ankur", ""], ["Gaur", "Rishabh", ""], ["Raghavan", "Vivek", ""]]}, {"id": "2107.07409", "submitter": "Mark Stamp", "authors": "Han-Chih Chang, Jianwei Li, Mark Stamp", "title": "Machine Learning-Based Analysis of Free-Text Keystroke Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of active and passive biometric authentication and\nidentification technology plays an increasingly important role in\ncybersecurity. Keystroke dynamics can be used to analyze the way that a user\ntypes based on various keyboard input. Previous work has shown that user\nauthentication and classification can be achieved based on keystroke dynamics.\nIn this research, we consider the problem of user classification based on\nkeystroke dynamics features collected from free-text. We implement and analyze\na novel a deep learning model that combines a convolutional neural network\n(CNN) and a gated recurrent unit (GRU). We optimize the resulting model and\nconsider several relevant related problems. Our model is competitive with the\nbest results obtained in previous comparable research.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 14:50:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chang", "Han-Chih", ""], ["Li", "Jianwei", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.07410", "submitter": "Yuda Song", "authors": "Yuda Song, Wen Sun", "title": "PC-MLP: Model-based Reinforcement Learning with Policy Cover Guided\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Reinforcement Learning (RL) is a popular learning paradigm due to\nits potential sample efficiency compared to model-free RL. However, existing\nempirical model-based RL approaches lack the ability to explore. This work\nstudies a computationally and statistically efficient model-based algorithm for\nboth Kernelized Nonlinear Regulators (KNR) and linear Markov Decision Processes\n(MDPs). For both models, our algorithm guarantees polynomial sample complexity\nand only uses access to a planning oracle. Experimentally, we first demonstrate\nthe flexibility and efficacy of our algorithm on a set of exploration\nchallenging control tasks where existing empirical model-based RL approaches\ncompletely fail. We then show that our approach retains excellent performance\neven in common dense reward control benchmarks that do not require heavy\nexploration. Finally, we demonstrate that our method can also perform\nreward-free exploration efficiently. Our code can be found at\nhttps://github.com/yudasong/PCMLP.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 15:49:30 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Song", "Yuda", ""], ["Sun", "Wen", ""]]}, {"id": "2107.07412", "submitter": "Thaer Sahmoud Mr.", "authors": "Thaer Sahmoud, Wesam Ashor", "title": "Assign Hysteresis Parameter For Ericsson BTS Power Saving Algorithm\n  Using Unsupervised Learning", "comments": "7 pages, 4 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaza Strip suffers from a chronic electricity deficit that affects all\nindustries including the telecommunication field, so there is a need to\noptimize and reduce power consumption of the telecommunication equipment. In\nthis paper we propose a new model that helps GSM radio frequency engineers to\nchoose the optimal value of hysteresis parameter for Ericsson BTS power saving\nalgorithm which aims to switch OFF unused frequency channels, our model is\nbased on unsupervised machine learning clustering K-means algorithm. By using\nour model with BTS power saving algorithm we reduce number of active TRX by\n20.9%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:26:15 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sahmoud", "Thaer", ""], ["Ashor", "Wesam", ""]]}, {"id": "2107.07420", "submitter": "Fang-Yi Yu", "authors": "Yiling Chen and Fang-Yi Yu", "title": "Optimal Scoring Rule Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces an optimization problem for proper scoring rule design.\nConsider a principal who wants to collect an agent's prediction about an\nunknown state. The agent can either report his prior prediction or access a\ncostly signal and report the posterior prediction. Given a collection of\npossible distributions containing the agent's posterior prediction\ndistribution, the principal's objective is to design a bounded scoring rule to\nmaximize the agent's worst-case payoff increment between reporting his\nposterior prediction and reporting his prior prediction.\n  We study two settings of such optimization for proper scoring rules: static\nand asymptotic settings. In the static setting, where the agent can access one\nsignal, we propose an efficient algorithm to compute an optimal scoring rule\nwhen the collection of distributions is finite. The agent can adaptively and\nindefinitely refine his prediction in the asymptotic setting. We first consider\na sequence of collections of posterior distributions with vanishing covariance,\nwhich emulates general estimators with large samples, and show the optimality\nof the quadratic scoring rule. Then, when the agent's posterior distribution is\na Beta-Bernoulli process, we find that the log scoring rule is optimal. We also\nprove the optimality of the log scoring rule over a smaller set of functions\nfor categorical distributions with Dirichlet priors.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:05:48 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Yiling", ""], ["Yu", "Fang-Yi", ""]]}, {"id": "2107.07423", "submitter": "Nipuni. Ginige", "authors": "Nipuni Ginige, K. B. Shashika Manosha, Nandana Rajatheva, and Matti\n  Latva-aho", "title": "Untrained DNN for Channel Estimation of RIS-Assisted Multi-User OFDM\n  System with Hardware Impairments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfigurable intelligent surface (RIS) is an emerging technology for\nimproving performance in fifth-generation (5G) and beyond networks. Practically\nchannel estimation of RIS-assisted systems is challenging due to the passive\nnature of the RIS. The purpose of this paper is to introduce a deep\nlearning-based, low complexity channel estimator for the RIS-assisted\nmulti-user single-input-multiple-output (SIMO) orthogonal frequency division\nmultiplexing (OFDM) system with hardware impairments. We propose an untrained\ndeep neural network (DNN) based on the deep image prior (DIP) network to\ndenoise the effective channel of the system obtained from the conventional\npilot-based least-square (LS) estimation and acquire a more accurate\nestimation. We have shown that our proposed method has high performance in\nterms of accuracy and low complexity compared to conventional methods. Further,\nwe have shown that the proposed estimator is robust to interference caused by\nthe hardware impairments at the transceiver and RIS.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 07:30:43 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ginige", "Nipuni", ""], ["Manosha", "K. B. Shashika", ""], ["Rajatheva", "Nandana", ""], ["Latva-aho", "Matti", ""]]}, {"id": "2107.07431", "submitter": "Nico Lang", "authors": "Nico Lang, Konrad Schindler, Jan Dirk Wegner", "title": "High carbon stock mapping at large scale with optical satellite imagery\n  and spaceborne LIDAR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing demand for commodities is leading to changes in land use\nworldwide. In the tropics, deforestation, which causes high carbon emissions\nand threatens biodiversity, is often linked to agricultural expansion. While\nthe need for deforestation-free global supply chains is widely recognized,\nmaking progress in practice remains a challenge. Here, we propose an automated\napproach that aims to support conservation and sustainable land use planning\ndecisions by mapping tropical landscapes at large scale and high spatial\nresolution following the High Carbon Stock (HCS) approach. A deep learning\napproach is developed that estimates canopy height for each 10 m Sentinel-2\npixel by learning from sparse GEDI LIDAR reference data, achieving an overall\nRMSE of 6.3 m. We show that these wall-to-wall maps of canopy top height are\npredictive for classifying HCS forests and degraded areas with an overall\naccuracy of 86 % and produce a first high carbon stock map for Indonesia,\nMalaysia, and the Philippines.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:21:21 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Lang", "Nico", ""], ["Schindler", "Konrad", ""], ["Wegner", "Jan Dirk", ""]]}, {"id": "2107.07432", "submitter": "Ladislav Rampasek", "authors": "Ladislav Ramp\\'a\\v{s}ek, Guy Wolf", "title": "Hierarchical graph neural nets can capture long-range interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) based on message passing between neighboring\nnodes are known to be insufficient for capturing long-range interactions in\ngraphs. In this project we study hierarchical message passing models that\nleverage a multi-resolution representation of a given graph. This facilitates\nlearning of features that span large receptive fields without loss of local\ninformation, an aspect not studied in preceding work on hierarchical GNNs. We\nintroduce Hierarchical Graph Net (HGNet), which for any two connected nodes\nguarantees existence of message-passing paths of at most logarithmic length\nw.r.t. the input graph size. Yet, under mild assumptions, its internal\nhierarchy maintains asymptotic size equivalent to that of the input graph. We\nobserve that our HGNet outperforms conventional stacking of GCN layers\nparticularly in molecular property prediction benchmarks. Finally, we propose\ntwo benchmarking tasks designed to elucidate capability of GNNs to leverage\nlong-range interactions in graphs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:24:22 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ramp\u00e1\u0161ek", "Ladislav", ""], ["Wolf", "Guy", ""]]}, {"id": "2107.07436", "submitter": "Neil Jethani", "authors": "Neil Jethani, Mukund Sudarshan, Ian Covert, Su-In Lee, Rajesh\n  Ranganath", "title": "FastSHAP: Real-Time Shapley Value Estimation", "comments": "20 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley values are widely used to explain black-box models, but they are\ncostly to calculate because they require many model evaluations. We introduce\nFastSHAP, a method for estimating Shapley values in a single forward pass using\na learned explainer model. FastSHAP amortizes the cost of explaining many\ninputs via a learning approach inspired by the Shapley value's weighted least\nsquares characterization, and it can be trained using standard stochastic\ngradient optimization. We compare FastSHAP to existing estimation approaches,\nrevealing that it generates high-quality explanations with orders of magnitude\nspeedup.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:34:45 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Jethani", "Neil", ""], ["Sudarshan", "Mukund", ""], ["Covert", "Ian", ""], ["Lee", "Su-In", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "2107.07438", "submitter": "Yikun Ban", "authors": "Yikun Ban, Jingrui He", "title": "Convolutional Neural Bandit: Provable Algorithm for Visual-aware\n  Advertising", "comments": "23 pages, in submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online advertising is ubiquitous in web business. Image displaying is\nconsidered as one of the most commonly used formats to interact with customers.\nContextual multi-armed bandit has shown success in the application of\nadvertising to solve the exploration-exploitation dilemma existed in the\nrecommendation procedure. Inspired by the visual-aware advertising, in this\npaper, we propose a contextual bandit algorithm, where the convolutional neural\nnetwork (CNN) is utilized to learn the reward function along with an upper\nconfidence bound (UCB) for exploration. We also prove a near-optimal regret\nbound $\\tilde{\\mathcal{O}}(\\sqrt{T})$ when the network is over-parameterized\nand establish strong connections with convolutional neural tangent kernel\n(CNTK). Finally, we evaluate the empirical performance of the proposed\nalgorithm and show that it outperforms other state-of-the-art UCB-based bandit\nalgorithms on real-world image data sets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 03:02:29 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Ban", "Yikun", ""], ["He", "Jingrui", ""]]}, {"id": "2107.07443", "submitter": "Yonatan Carlos Carranza Alarc\\'on YcCa", "authors": "Yonatan Carlos Carranza Alarc\\'on, S\\'ebastien Destercke", "title": "Multi-label Chaining with Imprecise Probabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present two different strategies to extend the classical multi-label\nchaining approach to handle imprecise probability estimates. These estimates\nuse convex sets of distributions (or credal sets) in order to describe our\nuncertainty rather than a precise one. The main reasons one could have for\nusing such estimations are (1) to make cautious predictions (or no decision at\nall) when a high uncertainty is detected in the chaining and (2) to make better\nprecise predictions by avoiding biases caused in early decisions in the\nchaining. We adapt both strategies to the case of the naive credal classifier,\nshowing that this adaptations are computationally efficient. Our experimental\nresults on missing labels, which investigate how reliable these predictions are\nin both approaches, indicate that our approaches produce relevant cautiousness\non those hard-to-predict instances where the precise models fail.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:43:31 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 19:43:12 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Alarc\u00f3n", "Yonatan Carlos Carranza", ""], ["Destercke", "S\u00e9bastien", ""]]}, {"id": "2107.07445", "submitter": "Jiahui Gao", "authors": "Jiahui Gao, Hang Xu, Han shi, Xiaozhe Ren, Philip L.H. Yu, Xiaodan\n  Liang, Xin Jiang, Zhenguo Li", "title": "AutoBERT-Zero: Evolving BERT Backbone from Scratch", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based pre-trained language models like BERT and its variants have\nrecently achieved promising performance in various natural language processing\n(NLP) tasks. However, the conventional paradigm constructs the backbone by\npurely stacking the manually designed global self-attention layers, introducing\ninductive bias and thus leading to sub-optimal. In this work, we propose an\nOperation-Priority Neural Architecture Search (OP-NAS) algorithm to\nautomatically search for promising hybrid backbone architectures. Our\nwell-designed search space (i) contains primitive math operations in the\nintra-layer level to explore novel attention structures, and (ii) leverages\nconvolution blocks to be the supplementary for attention structure in the\ninter-layer level to better learn local dependency. We optimize both the search\nalgorithm and evaluation of candidate models to boost the efficiency of our\nproposed OP-NAS. Specifically, we propose Operation-Priority (OP) evolution\nstrategy to facilitate model search via balancing exploration and exploitation.\nFurthermore, we design a Bi-branch Weight-Sharing (BIWS) training strategy for\nfast model evaluation. Extensive experiments show that the searched\narchitecture (named AutoBERT-Zero) significantly outperforms BERT and its\nvariants of different model capacities in various downstream tasks, proving the\narchitecture's transfer and generalization abilities. Remarkably,\nAutoBERT-Zero-base outperforms RoBERTa-base (using much more data) and\nBERT-large (with much larger model size) by 2.4 and 1.4 higher score on GLUE\ntest set. Code and pre-trained models will be made publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:46:01 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gao", "Jiahui", ""], ["Xu", "Hang", ""], ["shi", "Han", ""], ["Ren", "Xiaozhe", ""], ["Yu", "Philip L. H.", ""], ["Liang", "Xiaodan", ""], ["Jiang", "Xin", ""], ["Li", "Zhenguo", ""]]}, {"id": "2107.07451", "submitter": "Lucas Cardoso", "authors": "Lucas F. F. Cardoso, Vitor C. A. Santos, Regiane S. Kawasaki\n  Franc\\^es, Ricardo B. C. Prud\\^encio and Ronnie C. O. Alves", "title": "Data vs classifiers, who wins?", "comments": "15 pages, 6 figures and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The classification experiments covered by machine learning (ML) are composed\nby two important parts: the data and the algorithm. As they are a fundamental\npart of the problem, both must be considered when evaluating a model's\nperformance against a benchmark. The best classifiers need robust benchmarks to\nbe properly evaluated. For this, gold standard benchmarks such as OpenML-CC18\nare used. However, data complexity is commonly not considered along with the\nmodel during a performance evaluation. Recent studies employ Item Response\nTheory (IRT) as a new approach to evaluating datasets and algorithms, capable\nof evaluating both simultaneously. This work presents a new evaluation\nmethodology based on IRT and Glicko-2, jointly with the decodIRT tool developed\nto guide the estimation of IRT in ML. It explores the IRT as a tool to evaluate\nthe OpenML-CC18 benchmark for its algorithmic evaluation capability and checks\nif there is a subset of datasets more efficient than the original benchmark.\nSeveral classifiers, from classics to ensemble, are also evaluated using the\nIRT models. The Glicko-2 rating system was applied together with IRT to\nsummarize the innate ability and classifiers performance. It was noted that not\nall OpenML-CC18 datasets are really useful for evaluating algorithms, where\nonly 10% were rated as being really difficult. Furthermore, it was verified the\nexistence of a more efficient subset containing only 50% of the original size.\nWhile Randon Forest was singled out as the algorithm with the best innate\nability.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:55:15 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 15:19:51 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 23:06:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cardoso", "Lucas F. F.", ""], ["Santos", "Vitor C. A.", ""], ["Franc\u00eas", "Regiane S. Kawasaki", ""], ["Prud\u00eancio", "Ricardo B. C.", ""], ["Alves", "Ronnie C. O.", ""]]}, {"id": "2107.07455", "submitter": "Andrey Malinin Dr.", "authors": "Andrey Malinin and Neil Band and Ganshin, Alexander and German\n  Chesnokov and Yarin Gal and Mark J. F. Gales and Alexey Noskov and Andrey\n  Ploskonosov and Liudmila Prokhorenkova and Ivan Provilkov and Vatsal Raina\n  and Vyas Raina and Roginskiy, Denis and Mariya Shmatova and Panos Tigas and\n  Boris Yangel", "title": "Shifts: A Dataset of Real Distributional Shift Across Multiple\n  Large-Scale Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant research done on developing methods for improving\nrobustness to distributional shift and uncertainty estimation. In contrast,\nonly limited work has examined developing standard datasets and benchmarks for\nassessing these approaches. Additionally, most work on uncertainty estimation\nand robustness has developed new techniques based on small-scale regression or\nimage classification tasks. However, many tasks of practical interest have\ndifferent modalities, such as tabular data, audio, text, or sensor data, which\noffer significant challenges involving regression and discrete or continuous\nstructured prediction. Thus, given the current state of the field, a\nstandardized large-scale dataset of tasks across a range of modalities affected\nby distributional shifts is necessary. This will enable researchers to\nmeaningfully evaluate the plethora of recently developed uncertainty\nquantification methods, as well as assessment criteria and state-of-the-art\nbaselines. In this work, we propose the \\emph{Shifts Dataset} for evaluation of\nuncertainty estimates and robustness to distributional shift. The dataset,\nwhich has been collected from industrial sources and services, is composed of\nthree tasks, with each corresponding to a particular data modality: tabular\nweather prediction, machine translation, and self-driving car (SDC) vehicle\nmotion prediction. All of these data modalities and tasks are affected by real,\n`in-the-wild' distributional shifts and pose interesting challenges with\nrespect to uncertainty estimation. In this work we provide a description of the\ndataset and baseline results for all tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:59:34 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 17:39:44 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Malinin", "Andrey", ""], ["Band", "Neil", ""], ["Ganshin", "", ""], ["Alexander", "", ""], ["Chesnokov", "German", ""], ["Gal", "Yarin", ""], ["Gales", "Mark J. F.", ""], ["Noskov", "Alexey", ""], ["Ploskonosov", "Andrey", ""], ["Prokhorenkova", "Liudmila", ""], ["Provilkov", "Ivan", ""], ["Raina", "Vatsal", ""], ["Raina", "Vyas", ""], ["Roginskiy", "", ""], ["Denis", "", ""], ["Shmatova", "Mariya", ""], ["Tigas", "Panos", ""], ["Yangel", "Boris", ""]]}, {"id": "2107.07467", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Bo Ji, Tianyu Ding, Biyi Fang, Guanyi Wang, Zhihui Zhu,\n  Luming Liang, Yixin Shi, Sheng Yi, Xiao Tu", "title": "Only Train Once: A One-Shot Neural Network Training And Pruning\n  Framework", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Structured pruning is a commonly used technique in deploying deep neural\nnetworks (DNNs) onto resource-constrained devices. However, the existing\npruning methods are usually heuristic, task-specified, and require an extra\nfine-tuning procedure. To overcome these limitations, we propose a framework\nthat compresses DNNs into slimmer architectures with competitive performances\nand significant FLOPs reductions by Only-Train-Once (OTO). OTO contains two\nkeys: (i) we partition the parameters of DNNs into zero-invariant groups,\nenabling us to prune zero groups without affecting the output; and (ii) to\npromote zero groups, we then formulate a structured-sparsity optimization\nproblem and propose a novel optimization algorithm, Half-Space Stochastic\nProjected Gradient (HSPG), to solve it, which outperforms the standard proximal\nmethods on group sparsity exploration and maintains comparable convergence. To\ndemonstrate the effectiveness of OTO, we train and compress full models\nsimultaneously from scratch without fine-tuning for inference speedup and\nparameter reduction, and achieve state-of-the-art results on VGG16 for CIFAR10,\nResNet50 for CIFAR10/ImageNet and Bert for SQuAD.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:15:20 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Tianyi", ""], ["Ji", "Bo", ""], ["Ding", "Tianyu", ""], ["Fang", "Biyi", ""], ["Wang", "Guanyi", ""], ["Zhu", "Zhihui", ""], ["Liang", "Luming", ""], ["Shi", "Yixin", ""], ["Yi", "Sheng", ""], ["Tu", "Xiao", ""]]}, {"id": "2107.07480", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Jonathan Lacotte, Mert Pilanci and Michael W.\n  Mahoney", "title": "Newton-LESS: Sparsification without Trade-offs for the Sketched Newton\n  Update", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In second-order optimization, a potential bottleneck can be computing the\nHessian matrix of the optimized function at every iteration. Randomized\nsketching has emerged as a powerful technique for constructing estimates of the\nHessian which can be used to perform approximate Newton steps. This involves\nmultiplication by a random sketching matrix, which introduces a trade-off\nbetween the computational cost of sketching and the convergence rate of the\noptimization algorithm. A theoretically desirable but practically much too\nexpensive choice is to use a dense Gaussian sketching matrix, which produces\nunbiased estimates of the exact Newton step and which offers strong\nproblem-independent convergence guarantees. We show that the Gaussian sketching\nmatrix can be drastically sparsified, significantly reducing the computational\ncost of sketching, without substantially affecting its convergence properties.\nThis approach, called Newton-LESS, is based on a recently introduced sketching\ntechnique: LEverage Score Sparsified (LESS) embeddings. We prove that\nNewton-LESS enjoys nearly the same problem-independent local convergence rate\nas Gaussian embeddings, not just up to constant factors but even down to lower\norder terms, for a large class of optimization tasks. In particular, this leads\nto a new state-of-the-art convergence result for an iterative least squares\nsolver. Finally, we extend LESS embeddings to include uniformly sparsified\nrandom sign matrices which can be implemented efficiently and which perform\nwell in numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:33:05 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Lacotte", "Jonathan", ""], ["Pilanci", "Mert", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2107.07483", "submitter": "Francisco Valente", "authors": "Francisco Valente, Sim\\~ao Paredes, Jorge Henriques", "title": "Personalized and Reliable Decision Sets: Enhancing Interpretability in\n  Clinical Decision Support Systems", "comments": "Accepted to the ICML 2021 Workshop on Interpretable Machine Learning\n  in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present a novel clinical decision support system and\ndiscuss its interpretability-related properties. It combines a decision set of\nrules with a machine learning scheme to offer global and local\ninterpretability. More specifically, machine learning is used to predict the\nlikelihood of each of those rules to be correct for a particular patient, which\nmay also contribute to better predictive performances. Moreover, the\nreliability analysis of individual predictions is also addressed, contributing\nto further personalized interpretability. The combination of these several\nelements may be crucial to obtain the clinical stakeholders' trust, leading to\na better assessment of patients' conditions and improvement of the physicians'\ndecision-making.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:36:24 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Valente", "Francisco", ""], ["Paredes", "Sim\u00e3o", ""], ["Henriques", "Jorge", ""]]}, {"id": "2107.07493", "submitter": "Dobrik Georgiev", "authors": "Dobrik Georgiev, Pietro Barbiero, Dmitry Kazhdan, Petar\n  Veli\\v{c}kovi\\'c, Pietro Li\\`o", "title": "Algorithmic Concept-based Explainable Reasoning", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on graph neural network (GNN) models successfully applied\nGNNs to classical graph algorithms and combinatorial optimisation problems.\nThis has numerous benefits, such as allowing applications of algorithms when\npreconditions are not satisfied, or reusing learned models when sufficient\ntraining data is not available or can't be generated. Unfortunately, a key\nhindrance of these approaches is their lack of explainability, since GNNs are\nblack-box models that cannot be interpreted directly. In this work, we address\nthis limitation by applying existing work on concept-based explanations to GNN\nmodels. We introduce concept-bottleneck GNNs, which rely on a modification to\nthe GNN readout mechanism. Using three case studies we demonstrate that: (i)\nour proposed model is capable of accurately learning concepts and extracting\npropositional formulas based on the learned concepts for each target class;\n(ii) our concept-based GNN models achieve comparative performance with\nstate-of-the-art models; (iii) we can derive global graph concepts, without\nexplicitly providing any supervision on graph-level concepts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:44:51 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Georgiev", "Dobrik", ""], ["Barbiero", "Pietro", ""], ["Kazhdan", "Dmitry", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2107.07494", "submitter": "Tian Zhou", "authors": "Hao He, Tian Zhou, Lihua Ren, Niklas Karlsson, Aaron Flores", "title": "Mid-flight Forecasting for CPA Lines in Online Advertising", "comments": "41st International Symposium on Forecasting, June 27-30, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  For Verizon MediaDemand Side Platform(DSP), forecasting of ad campaign\nperformance not only feeds key information to the optimization server to allow\nthe system to operate on a high-performance mode, but also produces actionable\ninsights to the advertisers. In this paper, the forecasting problem for CPA\nlines in the middle of the flight is investigated by taking the bidding\nmechanism into account. The proposed methodology generates relationships\nbetween various key performance metrics and optimization signals. It can also\nbe used to estimate the sensitivity of ad campaign performance metrics to the\nadjustments of optimization signal, which is important to the design of a\ncampaign management system. The relationship between advertiser spends and\neffective Cost Per Action(eCPA) is also characterized, which serves as a\nguidance for mid-flight line adjustment to the advertisers. Several practical\nissues in implementation, such as downsampling of the dataset, are also\ndiscussed in the paper. At last, the forecasting results are validated against\nactual deliveries and demonstrates promising accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:48:15 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["He", "Hao", ""], ["Zhou", "Tian", ""], ["Ren", "Lihua", ""], ["Karlsson", "Niklas", ""], ["Flores", "Aaron", ""]]}, {"id": "2107.07502", "submitter": "Paul Pu Liang", "authors": "Paul Pu Liang, Yiwei Lyu, Xiang Fan, Zetian Wu, Yun Cheng, Jason Wu,\n  Leslie Chen, Peter Wu, Michelle A. Lee, Yuke Zhu, Ruslan Salakhutdinov,\n  Louis-Philippe Morency", "title": "MultiBench: Multiscale Benchmarks for Multimodal Representation Learning", "comments": "Code: https://github.com/pliang279/MultiBench and Website:\n  https://cmu-multicomp-lab.github.io/multibench/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning multimodal representations involves integrating information from\nmultiple heterogeneous sources of data. It is a challenging yet crucial area\nwith numerous real-world applications in multimedia, affective computing,\nrobotics, finance, human-computer interaction, and healthcare. Unfortunately,\nmultimodal research has seen limited resources to study (1) generalization\nacross domains and modalities, (2) complexity during training and inference,\nand (3) robustness to noisy and missing modalities. In order to accelerate\nprogress towards understudied modalities and tasks while ensuring real-world\nrobustness, we release MultiBench, a systematic and unified large-scale\nbenchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6\nresearch areas. MultiBench provides an automated end-to-end machine learning\npipeline that simplifies and standardizes data loading, experimental setup, and\nmodel evaluation. To enable holistic evaluation, MultiBench offers a\ncomprehensive methodology to assess (1) generalization, (2) time and space\ncomplexity, and (3) modality robustness. MultiBench introduces impactful\nchallenges for future research, including scalability to large-scale multimodal\ndatasets and robustness to realistic imperfections. To accompany this\nbenchmark, we also provide a standardized implementation of 20 core approaches\nin multimodal learning. Simply applying methods proposed in different research\nareas can improve the state-of-the-art performance on 9/15 datasets. Therefore,\nMultiBench presents a milestone in unifying disjoint efforts in multimodal\nresearch and paves the way towards a better understanding of the capabilities\nand limitations of multimodal models, all the while ensuring ease of use,\naccessibility, and reproducibility. MultiBench, our standardized code, and\nleaderboards are publicly available, will be regularly updated, and welcomes\ninputs from the community.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:54:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Liang", "Paul Pu", ""], ["Lyu", "Yiwei", ""], ["Fan", "Xiang", ""], ["Wu", "Zetian", ""], ["Cheng", "Yun", ""], ["Wu", "Jason", ""], ["Chen", "Leslie", ""], ["Wu", "Peter", ""], ["Lee", "Michelle A.", ""], ["Zhu", "Yuke", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2107.07506", "submitter": "Kenneth Derek", "authors": "Kenneth Derek, Phillip Isola", "title": "Adaptable Agent Populations via a Generative Model of Policies", "comments": "Website at https://kennyderek.github.io/adap/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the natural world, life has found innumerable ways to survive and often\nthrive. Between and even within species, each individual is in some manner\nunique, and this diversity lends adaptability and robustness to life. In this\nwork, we aim to learn a space of diverse and high-reward policies on any given\nenvironment. To this end, we introduce a generative model of policies, which\nmaps a low-dimensional latent space to an agent policy space. Our method\nenables learning an entire population of agent policies, without requiring the\nuse of separate policy parameters. Just as real world populations can adapt and\nevolve via natural selection, our method is able to adapt to changes in our\nenvironment solely by selecting for policies in latent space. We test our\ngenerative model's capabilities in a variety of environments, including an\nopen-ended grid-world and a two-player soccer environment. Code,\nvisualizations, and additional experiments can be found at\nhttps://kennyderek.github.io/adap/.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:58:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Derek", "Kenneth", ""], ["Isola", "Phillip", ""]]}, {"id": "2107.07508", "submitter": "Guangmo Tong", "authors": "Guangmo Tong", "title": "USCO-Solver: Solving Undetermined Stochastic Combinatorial Optimization\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world decision-making systems are often subject to uncertainties that\nhave to be resolved through observational data. Therefore, we are frequently\nconfronted with combinatorial optimization problems of which the objective\nfunction is unknown and thus has to be debunked using empirical evidence. In\ncontrast to the common practice that relies on a learning-and-optimization\nstrategy, we consider the regression between combinatorial spaces, aiming to\ninfer high-quality optimization solutions from samples of input-solution pairs\n-- without the need to learn the objective function. Our main deliverable is a\nuniversal solver that is able to handle abstract undetermined stochastic\ncombinatorial optimization problems. For learning foundations, we present\nlearning-error analysis under the PAC-Bayesian framework using a new\nmargin-based analysis. In empirical studies, we demonstrate our design using\nproof-of-concept experiments, and compare it with other methods that are\npotentially applicable. Overall, we obtain highly encouraging experimental\nresults for several classic combinatorial problems on both synthetic and\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:59:08 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Tong", "Guangmo", ""]]}, {"id": "2107.07511", "submitter": "Anastasios Angelopoulos", "authors": "Anastasios N. Angelopoulos, Stephen Bates", "title": "A Gentle Introduction to Conformal Prediction and Distribution-Free\n  Uncertainty Quantification", "comments": "Blog and tutorial video\n  http://angelopoulos.ai/blog/posts/gentle-intro/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box machine learning learning methods are now routinely used in\nhigh-risk settings, like medical diagnostics, which demand uncertainty\nquantification to avoid consequential model failures. Distribution-free\nuncertainty quantification (distribution-free UQ) is a user-friendly paradigm\nfor creating statistically rigorous confidence intervals/sets for such\npredictions. Critically, the intervals/sets are valid without distributional\nassumptions or model assumptions, with explicit guarantees with finitely many\ndatapoints. Moreover, they adapt to the difficulty of the input; when the input\nexample is difficult, the uncertainty intervals/sets are large, signaling that\nthe model might be wrong. Without much work, one can use distribution-free\nmethods on any underlying algorithm, such as a neural network, to produce\nconfidence sets guaranteed to contain the ground truth with a user-specified\nprobability, such as 90%. Indeed, the methods are easy-to-understand and\ngeneral, applying to many modern prediction problems arising in the fields of\ncomputer vision, natural language processing, deep reinforcement learning, and\nso on. This hands-on introduction is aimed at a reader interested in the\npractical implementation of distribution-free UQ, including conformal\nprediction and related methods, who is not necessarily a statistician. We will\ninclude many explanatory illustrations, examples, and code samples in Python,\nwith PyTorch syntax. The goal is to provide the reader a working understanding\nof distribution-free UQ, allowing them to put confidence intervals on their\nalgorithms, with one self-contained document.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:59:50 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Angelopoulos", "Anastasios N.", ""], ["Bates", "Stephen", ""]]}, {"id": "2107.07558", "submitter": "Zhicheng Cai", "authors": "Zhicheng Cai", "title": "SA-GD: Improved Gradient Descent Learning Strategy with Simulated\n  Annealing", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent algorithm is the most utilized method when optimizing\nmachine learning issues. However, there exists many local minimums and saddle\npoints in the loss function, especially for high dimensional non-convex\noptimization problems like deep learning. Gradient descent may make loss\nfunction trapped in these local intervals which impedes further optimization,\nresulting in poor generalization ability. This paper proposes the SA-GD\nalgorithm which introduces the thought of simulated annealing algorithm to\ngradient descent. SA-GD method offers model the ability of mounting hills in\nprobability, tending to enable the model to jump out of these local areas and\nconverge to a optimal state finally. We took CNN models as an example and\ntested the basic CNN models on various benchmark datasets. Compared to the\nbaseline models with traditional gradient descent algorithm, models with SA-GD\nalgorithm possess better generalization ability without sacrificing the\nefficiency and stability of model convergence. In addition, SA-GD can be\nutilized as an effective ensemble learning approach which improves the final\nperformance significantly.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 18:38:11 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Cai", "Zhicheng", ""]]}, {"id": "2107.07564", "submitter": "John Mitros", "authors": "John Mitros and Brian Mac Namee", "title": "On the Importance of Regularisation & Auxiliary Information in OOD\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are often utilised in critical domain applications\n(e.g.~self-driving cars, financial markets, and aerospace engineering), even\nthough they exhibit overconfident predictions for ambiguous inputs. This\ndeficiency demonstrates a fundamental flaw indicating that neural networks\noften overfit on spurious correlations. To address this problem in this work we\npresent two novel objectives that improve the ability of a network to detect\nout-of-distribution samples and therefore avoid overconfident predictions for\nambiguous inputs. We empirically demonstrate that our methods outperform the\nbaseline and perform better than the majority of existing approaches, while\nperforming competitively those that they don't outperform. Additionally, we\nempirically demonstrate the robustness of our approach against common\ncorruptions and demonstrate the importance of regularisation and auxiliary\ninformation in out-of-distribution detection.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 18:57:10 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Mitros", "John", ""], ["Mac Namee", "Brian", ""]]}, {"id": "2107.07572", "submitter": "Alena Kopanicakova", "authors": "Alena Kopani\\v{c}\\'akov\\'a and Rolf Krause", "title": "Globally Convergent Multilevel Training of Deep Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a globally convergent multilevel training method for deep residual\nnetworks (ResNets). The devised method can be seen as a novel variant of the\nrecursive multilevel trust-region (RMTR) method, which operates in hybrid\n(stochastic-deterministic) settings by adaptively adjusting mini-batch sizes\nduring the training. The multilevel hierarchy and the transfer operators are\nconstructed by exploiting a dynamical system's viewpoint, which interprets\nforward propagation through the ResNet as a forward Euler discretization of an\ninitial value problem. In contrast to traditional training approaches, our\nnovel RMTR method also incorporates curvature information on all levels of the\nmultilevel hierarchy by means of the limited-memory SR1 method. The overall\nperformance and the convergence properties of our multilevel training method\nare numerically investigated using examples from the field of classification\nand regression.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 19:08:58 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Kopani\u010d\u00e1kov\u00e1", "Alena", ""], ["Krause", "Rolf", ""]]}, {"id": "2107.07576", "submitter": "Mohammad Sabik Irbaz", "authors": "Mohammad Sabik Irbaz, MD Abdullah Al Nasim, Refat E Ferdous", "title": "Real-Time Face Recognition System for Remote Employee Tracking", "comments": "Accepted in International Conference on Big Data, IoT and Machine\n  Learning (BIM 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  During the COVID-19 pandemic, most of the human-to-human interactions have\nbeen stopped. To mitigate the spread of deadly coronavirus, many offices took\nthe initiative so that the employees can work from home. But, tracking the\nemployees and finding out if they are really performing what they were supposed\nto turn out to be a serious challenge for all the companies and organizations\nwho are facilitating \"Work From Home\". To deal with the challenge effectively,\nwe came up with a solution to track the employees with face recognition. We\nhave been testing this system experimentally for our office. To train the face\nrecognition module, we used FaceNet with KNN using the Labeled Faces in the\nWild (LFW) dataset and achieved 97.8% accuracy. We integrated the trained model\ninto our central system, where the employees log their time. In this paper, we\ndiscuss in brief the system we have been experimenting with and the pros and\ncons of the system.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 19:21:37 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Irbaz", "Mohammad Sabik", ""], ["Nasim", "MD Abdullah Al", ""], ["Ferdous", "Refat E", ""]]}, {"id": "2107.07579", "submitter": "Rui Li", "authors": "Rui Li, Ondrej Bohdal, Rajesh Mishra, Hyeji Kim, Da Li, Nicholas Lane,\n  Timothy Hospedales", "title": "A Channel Coding Benchmark for Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning provides a popular and effective family of methods for\ndata-efficient learning of new tasks. However, several important issues in\nmeta-learning have proven hard to study thus far. For example, performance\ndegrades in real-world settings where meta-learners must learn from a wide and\npotentially multi-modal distribution of training tasks; and when distribution\nshift exists between meta-train and meta-test task distributions. These issues\nare typically hard to study since the shape of task distributions, and shift\nbetween them are not straightforward to measure or control in standard\nbenchmarks. We propose the channel coding problem as a benchmark for\nmeta-learning. Channel coding is an important practical application where task\ndistributions naturally arise, and fast adaptation to new tasks is practically\nvaluable. We use this benchmark to study several aspects of meta-learning,\nincluding the impact of task distribution breadth and shift, which can be\ncontrolled in the coding problem. Going forward, this benchmark provides a tool\nfor the community to study the capabilities and limitations of meta-learning,\nand to drive research on practically robust and effective meta-learners.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 19:37:43 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Rui", ""], ["Bohdal", "Ondrej", ""], ["Mishra", "Rajesh", ""], ["Kim", "Hyeji", ""], ["Li", "Da", ""], ["Lane", "Nicholas", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2107.07582", "submitter": "Venet Osmani", "authors": "Behrooz Mamandipoor, Wesley Yeung, Louis Agha-Mir-Salim, David J.\n  Stone, Venet Osmani, Leo Anthony Celi", "title": "Prediction of Blood Lactate Values in Critically Ill Patients: A\n  Retrospective Multi-center Cohort Study", "comments": "15 pages, 6 Appendices", "journal-ref": "J Clin Monit Comput. 2021 PMID: 34224051", "doi": "10.1007/s10877-021-00739-4", "report-no": null, "categories": "q-bio.QM cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose. Elevations in initially obtained serum lactate levels are strong\npredictors of mortality in critically ill patients. Identifying patients whose\nserum lactate levels are more likely to increase can alert physicians to\nintensify care and guide them in the frequency of tending the blood test. We\ninvestigate whether machine learning models can predict subsequent serum\nlactate changes.\n  Methods. We investigated serum lactate change prediction using the MIMIC-III\nand eICU-CRD datasets in internal as well as external validation of the eICU\ncohort on the MIMIC-III cohort. Three subgroups were defined based on the\ninitial lactate levels: i) normal group (<2 mmol/L), ii) mild group (2-4\nmmol/L), and iii) severe group (>4 mmol/L). Outcomes were defined based on\nincrease or decrease of serum lactate levels between the groups. We also\nperformed sensitivity analysis by defining the outcome as lactate change of\n>10% and furthermore investigated the influence of the time interval between\nsubsequent lactate measurements on predictive performance.\n  Results. The LSTM models were able to predict deterioration of serum lactate\nvalues of MIMIC-III patients with an AUC of 0.77 (95% CI 0.762-0.771) for the\nnormal group, 0.77 (95% CI 0.768-0.772) for the mild group, and 0.85 (95% CI\n0.840-0.851) for the severe group, with a slightly lower performance in the\nexternal validation.\n  Conclusion. The LSTM demonstrated good discrimination of patients who had\ndeterioration in serum lactate levels. Clinical studies are needed to evaluate\nwhether utilization of a clinical decision support tool based on these results\ncould positively impact decision-making and patient outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 09:46:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Mamandipoor", "Behrooz", ""], ["Yeung", "Wesley", ""], ["Agha-Mir-Salim", "Louis", ""], ["Stone", "David J.", ""], ["Osmani", "Venet", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "2107.07603", "submitter": "Joshua Scurll", "authors": "Joshua M. Scurll", "title": "Measuring inter-cluster similarities with Alpha Shape TRIangulation in\n  loCal Subspaces (ASTRICS) facilitates visualization and clustering of\n  high-dimensional data", "comments": "35 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.HC cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering and visualizing high-dimensional (HD) data are important tasks in\na variety of fields. For example, in bioinformatics, they are crucial for\nanalyses of single-cell data such as mass cytometry (CyTOF) data. Some of the\nmost effective algorithms for clustering HD data are based on representing the\ndata by nodes in a graph, with edges connecting neighbouring nodes according to\nsome measure of similarity or distance. However, users of graph-based\nalgorithms are typically faced with the critical but challenging task of\nchoosing the value of an input parameter that sets the size of neighbourhoods\nin the graph, e.g. the number of nearest neighbours to which to connect each\nnode or a threshold distance for connecting nodes. The burden on the user could\nbe alleviated by a measure of inter-node similarity that can have value 0 for\ndissimilar nodes without requiring any user-defined parameters or thresholds.\nThis would determine the neighbourhoods automatically while still yielding a\nsparse graph. To this end, I propose a new method called ASTRICS to measure\nsimilarity between clusters of HD data points based on local dimensionality\nreduction and triangulation of critical alpha shapes. I show that my ASTRICS\nsimilarity measure can facilitate both clustering and visualization of HD data\nby using it in Stage 2 of a three-stage pipeline: Stage 1 = perform an initial\nclustering of the data by any method; Stage 2 = let graph nodes represent\ninitial clusters instead of individual data points and use ASTRICS to\nautomatically define edges between nodes; Stage 3 = use the graph for further\nclustering and visualization. This trades the critical task of choosing a graph\nneighbourhood size for the easier task of essentially choosing a resolution at\nwhich to view the data. The graph and consequently downstream clustering and\nvisualization are then automatically adapted to the chosen resolution.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 20:51:06 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Scurll", "Joshua M.", ""]]}, {"id": "2107.07617", "submitter": "Yang Shen", "authors": "Yang Shen, Sanjoy Dasgupta, Saket Navlakha", "title": "Algorithmic insights on continual learning from fruit flies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning in computational systems is challenging due to\ncatastrophic forgetting. We discovered a two layer neural circuit in the fruit\nfly olfactory system that addresses this challenge by uniquely combining sparse\ncoding and associative learning. In the first layer, odors are encoded using\nsparse, high dimensional representations, which reduces memory interference by\nactivating non overlapping populations of neurons for different odors. In the\nsecond layer, only the synapses between odor activated neurons and the output\nneuron associated with the odor are modified during learning; the rest of the\nweights are frozen to prevent unrelated memories from being overwritten. We\nshow empirically and analytically that this simple and lightweight algorithm\nsignificantly boosts continual learning performance. The fly associative\nlearning algorithm is strikingly similar to the classic perceptron learning\nalgorithm, albeit two modifications, which we show are critical for reducing\ncatastrophic forgetting. Overall, fruit flies evolved an efficient lifelong\nlearning algorithm, and circuit mechanisms from neuroscience can be translated\nto improve machine computation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 21:28:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Shen", "Yang", ""], ["Dasgupta", "Sanjoy", ""], ["Navlakha", "Saket", ""]]}, {"id": "2107.07618", "submitter": "Ismail Alarab", "authors": "Ismail Alarab, Simant Prakoonwit", "title": "Adversarial Attack for Uncertainty Estimation: Identifying Critical\n  Regions in Neural Networks", "comments": "15 pages, 6 figures, Submitted to Neural Processing Letters Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method to capture data points near decision boundary in\nneural network that are often referred to a specific type of uncertainty. In\nour approach, we sought to perform uncertainty estimation based on the idea of\nadversarial attack method. In this paper, uncertainty estimates are derived\nfrom the input perturbations, unlike previous studies that provide\nperturbations on the model's parameters as in Bayesian approach. We are able to\nproduce uncertainty with couple of perturbations on the inputs. Interestingly,\nwe apply the proposed method to datasets derived from blockchain. We compare\nthe performance of model uncertainty with the most recent uncertainty methods.\nWe show that the proposed method has revealed a significant outperformance over\nother methods and provided less risk to capture model uncertainty in machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 21:30:26 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Alarab", "Ismail", ""], ["Prakoonwit", "Simant", ""]]}, {"id": "2107.07623", "submitter": "Luca Ganassali", "authors": "Luca Ganassali, Laurent Massouli\\'e, Marc Lelarge", "title": "Correlation detection in trees for partial graph alignment", "comments": "22 pages, 1 figure. Preliminary version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider alignment of sparse graphs, which consists in finding a mapping\nbetween the nodes of two graphs which preserves most of the edges. Our approach\nis to compare local structures in the two graphs, matching two nodes if their\nneighborhoods are 'close enough': for correlated Erd\\H{o}s-R\\'enyi random\ngraphs, this problem can be locally rephrased in terms of testing whether a\npair of branching trees is drawn from either a product distribution, or a\ncorrelated distribution. We design an optimal test for this problem which gives\nrise to a message-passing algorithm for graph alignment, which provably returns\nin polynomial time a positive fraction of correctly matched vertices, and a\nvanishing fraction of mismatches. With an average degree $\\lambda = O(1)$ in\nthe graphs, and a correlation parameter $s \\in [0,1]$, this result holds with\n$\\lambda s$ large enough, and $1-s$ small enough, completing the recent\nstate-of-the-art diagram. Tighter conditions for determining whether partial\ngraph alignment (or correlation detection in trees) is feasible in polynomial\ntime are given in terms of Kullback-Leibler divergences.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 22:02:27 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ganassali", "Luca", ""], ["Massouli\u00e9", "Laurent", ""], ["Lelarge", "Marc", ""]]}, {"id": "2107.07634", "submitter": "Takuya Higuchi", "authors": "Takuya Higuchi, Anmol Gupta, Chandra Dhir", "title": "Multi-task Learning with Cross Attention for Keyword Spotting", "comments": "Submitted to ASRU 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) is an important technique for speech applications,\nwhich enables users to activate devices by speaking a keyword phrase. Although\na phoneme classifier can be used for KWS, exploiting a large amount of\ntranscribed data for automatic speech recognition (ASR), there is a mismatch\nbetween the training criterion (phoneme recognition) and the target task (KWS).\nRecently, multi-task learning has been applied to KWS to exploit both ASR and\nKWS training data. In this approach, an output of an acoustic model is split\ninto two branches for the two tasks, one for phoneme transcription trained with\nthe ASR data and one for keyword classification trained with the KWS data. In\nthis paper, we introduce a cross attention decoder in the multi-task learning\nframework. Unlike the conventional multi-task learning approach with the simple\nsplit of the output layer, the cross attention decoder summarizes information\nfrom a phonetic encoder by performing cross attention between the encoder\noutputs and a trainable query sequence to predict a confidence score for the\nKWS task. Experimental results on KWS tasks show that the proposed approach\noutperformed the conventional multi-task learning with split branches and a\nbi-directional long short-team memory decoder by 12% on average.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 22:38:16 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Higuchi", "Takuya", ""], ["Gupta", "Anmol", ""], ["Dhir", "Chandra", ""]]}, {"id": "2107.07642", "submitter": "Sanjaya Lohani", "authors": "Sanjaya Lohani, Joseph M. Lukens, Daniel E. Jones, Thomas A. Searles,\n  Ryan T. Glasser, and Brian T. Kirby", "title": "Improving application performance with biased distributions of quantum\n  states", "comments": "16 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the properties of a specific distribution of mixed quantum states\nof arbitrary dimension that can be biased towards a specific mean purity. In\nparticular, we analyze mixtures of Haar-random pure states with\nDirichlet-distributed coefficients. We analytically derive the concentration\nparameters required to match the mean purity of the Bures and Hilbert--Schmidt\ndistributions in any dimension. Numerical simulations suggest that this value\nrecovers the Hilbert--Schmidt distribution exactly, offering an alternative and\nintuitive physical interpretation for ensembles of Hilbert--Schmidt-distributed\nrandom quantum states. We then demonstrate how substituting these\nDirichlet-weighted Haar mixtures in place of the Bures and Hilbert--Schmidt\ndistributions results in measurable performance advantages in\nmachine-learning-based quantum state tomography systems and Bayesian quantum\nstate reconstruction. Finally, we experimentally characterize the distribution\nof quantum states generated by both a cloud-accessed IBM quantum computer and\nan in-house source of polarization-entangled photons. In each case, our method\ncan more closely match the underlying distribution than either Bures or\nHilbert--Schmidt distributed states for various experimental conditions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 23:29:10 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Lohani", "Sanjaya", ""], ["Lukens", "Joseph M.", ""], ["Jones", "Daniel E.", ""], ["Searles", "Thomas A.", ""], ["Glasser", "Ryan T.", ""], ["Kirby", "Brian T.", ""]]}, {"id": "2107.07647", "submitter": "Ian Colbert", "authors": "Ian Colbert, Ken Kreutz-Delgado, Srinjoy Das", "title": "An Energy-Efficient Edge Computing Paradigm for Convolution-based Image\n  Upsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel energy-efficient edge computing paradigm is proposed for real-time\ndeep learning-based image upsampling applications. State-of-the-art deep\nlearning solutions for image upsampling are currently trained using either\nresize or sub-pixel convolution to learn kernels that generate high fidelity\nimages with minimal artifacts. However, performing inference with these learned\nconvolution kernels requires memory-intensive feature map transformations that\ndominate time and energy costs in real-time applications. To alleviate this\npressure on memory bandwidth, we confine the use of resize or sub-pixel\nconvolution to training in the cloud by transforming learned convolution\nkernels to deconvolution kernels before deploying them for inference as a\nfunctionally equivalent deconvolution. These kernel transformations, intended\nas a one-time cost when shifting from training to inference, enable a systems\ndesigner to use each algorithm in their optimal context by preserving the image\nfidelity learned when training in the cloud while minimizing data transfer\npenalties during inference at the edge. We also explore existing variants of\ndeconvolution inference algorithms and introduce a novel variant for\nconsideration. We analyze and compare the inference properties of\nconvolution-based upsampling algorithms using a quantitative model of incurred\ntime and energy costs and show that using deconvolution for inference at the\nedge improves both system latency and energy efficiency when compared to their\nsub-pixel or resize convolution counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 23:49:37 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 05:34:59 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Colbert", "Ian", ""], ["Kreutz-Delgado", "Ken", ""], ["Das", "Srinjoy", ""]]}, {"id": "2107.07659", "submitter": "Toshinori Kitamura", "authors": "Toshinori Kitamura, Lingwei Zhu, Takamitsu Matsubara", "title": "Geometric Value Iteration: Dynamic Error-Aware KL Regularization for\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent booming of entropy-regularized literature reveals that\nKullback-Leibler (KL) regularization brings advantages to Reinforcement\nLearning (RL) algorithms by canceling out errors under mild assumptions.\nHowever, existing analyses focus on fixed regularization with a constant\nweighting coefficient and have not considered the case where the coefficient is\nallowed to change dynamically. In this paper, we study the dynamic coefficient\nscheme and present the first asymptotic error bound. Based on the dynamic\ncoefficient error bound, we propose an effective scheme to tune the coefficient\naccording to the magnitude of error in favor of more robust learning. On top of\nthis development, we propose a novel algorithm: Geometric Value Iteration (GVI)\nthat features a dynamic error-aware KL coefficient design aiming to mitigate\nthe impact of errors on the performance. Our experiments demonstrate that GVI\ncan effectively exploit the trade-off between learning speed and robustness\nover uniform averaging of constant KL coefficient. The combination of GVI and\ndeep networks shows stable learning behavior even in the absence of a target\nnetwork where algorithms with a constant KL coefficient would greatly oscillate\nor even fail to converge.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 01:24:37 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Kitamura", "Toshinori", ""], ["Zhu", "Lingwei", ""], ["Matsubara", "Takamitsu", ""]]}, {"id": "2107.07675", "submitter": "Daniel D. Johnson", "authors": "Daniel D. Johnson, Jacob Austin, Rianne van den Berg, Daniel Tarlow", "title": "Beyond In-Place Corruption: Insertion and Deletion In Denoising\n  Probabilistic Models", "comments": "Accepted at the ICML 2021 Workshop on Invertible Neural Networks,\n  Normalizing Flows, and Explicit Likelihood Models (poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising diffusion probabilistic models (DDPMs) have shown impressive\nresults on sequence generation by iteratively corrupting each example and then\nlearning to map corrupted versions back to the original. However, previous work\nhas largely focused on in-place corruption, adding noise to each pixel or token\nindividually while keeping their locations the same. In this work, we consider\na broader class of corruption processes and denoising models over sequence data\nthat can insert and delete elements, while still being efficient to train and\nsample from. We demonstrate that these models outperform standard in-place\nmodels on an arithmetic sequence task, and that when trained on the text8\ndataset they can be used to fix spelling errors without any fine-tuning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 02:50:10 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Johnson", "Daniel D.", ""], ["Austin", "Jacob", ""], ["Berg", "Rianne van den", ""], ["Tarlow", "Daniel", ""]]}, {"id": "2107.07677", "submitter": "Khondker Fariha Hossain", "authors": "Khondker Fariha Hossain, Sharif Amit Kamran, Alireza Tavakkoli, Lei\n  Pan, Daniel Ma, Sutharshan Rajasegarar, Chandan Karmaker", "title": "ECG-Adv-GAN: Detecting ECG Adversarial Examples with Conditional\n  Generative Adversarial Networks", "comments": "8 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Electrocardiogram (ECG) acquisition requires an automated system and analysis\npipeline for understanding specific rhythm irregularities. Deep neural networks\nhave become a popular technique for tracing ECG signals, outperforming human\nexperts. Despite this, convolutional neural networks are susceptible to\nadversarial examples that can misclassify ECG signals and decrease the model's\nprecision. Moreover, they do not generalize well on the out-of-distribution\ndataset. The GAN architecture has been employed in recent works to synthesize\nadversarial ECG signals to increase existing training data. However, they use a\ndisjointed CNN-based classification architecture to detect arrhythmia. Till\nnow, no versatile architecture has been proposed that can detect adversarial\nexamples and classify arrhythmia simultaneously. To alleviate this, we propose\na novel Conditional Generative Adversarial Network to simultaneously generate\nECG signals for different categories and detect cardiac abnormalities.\nMoreover, the model is conditioned on class-specific ECG signals to synthesize\nrealistic adversarial examples. Consequently, we compare our architecture and\nshow how it outperforms other classification models in normal/abnormal ECG\nsignal detection by benchmarking real world and adversarial signals.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 02:53:14 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Hossain", "Khondker Fariha", ""], ["Kamran", "Sharif Amit", ""], ["Tavakkoli", "Alireza", ""], ["Pan", "Lei", ""], ["Ma", "Daniel", ""], ["Rajasegarar", "Sutharshan", ""], ["Karmaker", "Chandan", ""]]}, {"id": "2107.07682", "submitter": "Yukun Jiang", "authors": "Yukun Jiang", "title": "The Application of Active Query K-Means in Text Classification", "comments": "6 pages, 3 algorithms, 4 tables, 8 figures For source code and\n  questions, please email Yukun Jiang at jy2363@nyu.edu Reply would follow\n  shortly", "journal-ref": "In proceedings of 3rd International Conference on Natural Language\n  Processing 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active learning is a state-of-art machine learning approach to deal with an\nabundance of unlabeled data. In the field of Natural Language Processing,\ntypically it is costly and time-consuming to have all the data annotated. This\ninefficiency inspires out our application of active learning in text\nclassification. Traditional unsupervised k-means clustering is first modified\ninto a semi-supervised version in this research. Then, a novel attempt is\napplied to further extend the algorithm into active learning scenario with\nPenalized Min-Max-selection, so as to make limited queries that yield more\nstable initial centroids. This method utilizes both the interactive query\nresults from users and the underlying distance representation. After tested on\na Chinese news dataset, it shows a consistent increase in accuracy while\nlowering the cost in training.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 03:06:35 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jiang", "Yukun", ""]]}, {"id": "2107.07684", "submitter": "Yasunori Ishii Mr", "authors": "Yasunori Ishii and Takayoshi Yamashita", "title": "CutDepth:Edge-aware Data Augmentation in Depth Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is difficult to collect data on a large scale in a monocular depth\nestimation because the task requires the simultaneous acquisition of RGB images\nand depths. Data augmentation is thus important to this task. However, there\nhas been little research on data augmentation for tasks such as monocular depth\nestimation, where the transformation is performed pixel by pixel. In this\npaper, we propose a data augmentation method, called CutDepth. In CutDepth,\npart of the depth is pasted onto an input image during training. The method\nextends variations data without destroying edge features. Experiments\nobjectively and subjectively show that the proposed method outperforms\nconventional methods of data augmentation. The estimation accuracy is improved\nwith CutDepth even though there are few training data at long distances.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 03:20:49 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ishii", "Yasunori", ""], ["Yamashita", "Takayoshi", ""]]}, {"id": "2107.07687", "submitter": "Yuming Chen", "authors": "Yuming Chen, Daniel Sanz-Alonso, Rebecca Willett", "title": "Auto-differentiable Ensemble Kalman Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data assimilation is concerned with sequentially estimating a\ntemporally-evolving state. This task, which arises in a wide range of\nscientific and engineering applications, is particularly challenging when the\nstate is high-dimensional and the state-space dynamics are unknown. This paper\nintroduces a machine learning framework for learning dynamical systems in data\nassimilation. Our auto-differentiable ensemble Kalman filters (AD-EnKFs) blend\nensemble Kalman filters for state recovery with machine learning tools for\nlearning the dynamics. In doing so, AD-EnKFs leverage the ability of ensemble\nKalman filters to scale to high-dimensional states and the power of automatic\ndifferentiation to train high-dimensional surrogate models for the dynamics.\nNumerical results using the Lorenz-96 model show that AD-EnKFs outperform\nexisting methods that use expectation-maximization or particle filters to merge\ndata assimilation and machine learning. In addition, AD-EnKFs are easy to\nimplement and require minimal tuning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 03:25:30 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 18:32:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Yuming", ""], ["Sanz-Alonso", "Daniel", ""], ["Willett", "Rebecca", ""]]}, {"id": "2107.07691", "submitter": "Liam Magee", "authors": "Liam Magee, Lida Ghahremanlou, Karen Soldatic, and Shanthi Robertson", "title": "Intersectional Bias in Causal Language Models", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  To examine whether intersectional bias can be observed in language\ngeneration, we examine \\emph{GPT-2} and \\emph{GPT-NEO} models, ranging in size\nfrom 124 million to ~2.7 billion parameters. We conduct an experiment combining\nup to three social categories - gender, religion and disability - into\nunconditional or zero-shot prompts used to generate sentences that are then\nanalysed for sentiment. Our results confirm earlier tests conducted with\nauto-regressive causal models, including the \\emph{GPT} family of models. We\nalso illustrate why bias may be resistant to techniques that target single\ncategories (e.g. gender, religion and race), as it can also manifest, in often\nsubtle ways, in texts prompted by concatenated social categories. To address\nthese difficulties, we suggest technical and community-based approaches need to\ncombine to acknowledge and address complex and intersectional language model\nbias.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 03:46:08 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Magee", "Liam", ""], ["Ghahremanlou", "Lida", ""], ["Soldatic", "Karen", ""], ["Robertson", "Shanthi", ""]]}, {"id": "2107.07696", "submitter": "Long Kiu Chung", "authors": "Long Kiu Chung, Adam Dai, Derek Knowles, Shreyas Kousik, Grace X. Gao", "title": "Constrained Feedforward Neural Network Training via Reachability\n  Analysis", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have recently become popular for a wide variety of uses, but\nhave seen limited application in safety-critical domains such as robotics near\nand around humans. This is because it remains an open challenge to train a\nneural network to obey safety constraints. Most existing safety-related methods\nonly seek to verify that already-trained networks obey constraints, requiring\nalternating training and verification. Instead, this work proposes a\nconstrained method to simultaneously train and verify a feedforward neural\nnetwork with rectified linear unit (ReLU) nonlinearities. Constraints are\nenforced by computing the network's output-space reachable set and ensuring\nthat it does not intersect with unsafe sets; training is achieved by\nformulating a novel collision-check loss function between the reachable set and\nunsafe portions of the output space. The reachable and unsafe sets are\nrepresented by constrained zonotopes, a convex polytope representation that\nenables differentiable collision checking. The proposed method is demonstrated\nsuccessfully on a network with one nonlinearity layer and approximately 50\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 04:03:01 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chung", "Long Kiu", ""], ["Dai", "Adam", ""], ["Knowles", "Derek", ""], ["Kousik", "Shreyas", ""], ["Gao", "Grace X.", ""]]}, {"id": "2107.07702", "submitter": "Fran\\c{c}ois-Xavier Aubet", "authors": "Chris U. Carmona, Fran\\c{c}ois-Xavier Aubet, Valentin Flunkert, Jan\n  Gasthaus", "title": "Neural Contextual Anomaly Detection for Time Series", "comments": "Chris and Fran\\c{c}ois-Xavier contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Neural Contextual Anomaly Detection (NCAD), a framework for\nanomaly detection on time series that scales seamlessly from the unsupervised\nto supervised setting, and is applicable to both univariate and multivariate\ntime series. This is achieved by effectively combining recent developments in\nrepresentation learning for multivariate time series, with techniques for deep\nanomaly detection originally developed for computer vision that we tailor to\nthe time series setting. Our window-based approach facilitates learning the\nboundary between normal and anomalous classes by injecting generic synthetic\nanomalies into the available data. Moreover, our method can effectively take\nadvantage of all the available information, be it as domain knowledge, or as\ntraining labels in the semi-supervised setting. We demonstrate empirically on\nstandard benchmark datasets that our approach obtains a state-of-the-art\nperformance in these settings.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 04:33:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Carmona", "Chris U.", ""], ["Aubet", "Fran\u00e7ois-Xavier", ""], ["Flunkert", "Valentin", ""], ["Gasthaus", "Jan", ""]]}, {"id": "2107.07705", "submitter": "Qin Ruan", "authors": "Qin Ruan, Brian Mac Namee, Ruihai Dong", "title": "Pseudo-labelling Enhanced Media Bias Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leveraging unlabelled data through weak or distant supervision is a\ncompelling approach to developing more effective text classification models.\nThis paper proposes a simple but effective data augmentation method, which\nleverages the idea of pseudo-labelling to select samples from noisy distant\nsupervision annotation datasets. The result shows that the proposed method\nimproves the accuracy of biased news detection models.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 04:47:50 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ruan", "Qin", ""], ["Mac Namee", "Brian", ""], ["Dong", "Ruihai", ""]]}, {"id": "2107.07706", "submitter": "Chaojian Li", "authors": "Chaojian Li, Wuyang Chen, Yuchen Gu, Tianlong Chen, Yonggan Fu,\n  Zhangyang Wang, Yingyan Lin", "title": "DANCE: DAta-Network Co-optimization for Efficient Segmentation Model\n  Training and Inference", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation for scene understanding is nowadays widely demanded,\nraising significant challenges for the algorithm efficiency, especially its\napplications on resource-limited platforms. Current segmentation models are\ntrained and evaluated on massive high-resolution scene images (\"data level\")\nand suffer from the expensive computation arising from the required multi-scale\naggregation(\"network level\"). In both folds, the computational and energy costs\nin training and inference are notable due to the often desired large input\nresolutions and heavy computational burden of segmentation models. To this end,\nwe propose DANCE, general automated DAta-Network Co-optimization for Efficient\nsegmentation model training and inference. Distinct from existing efficient\nsegmentation approaches that focus merely on light-weight network design, DANCE\ndistinguishes itself as an automated simultaneous data-network co-optimization\nvia both input data manipulation and network architecture slimming.\nSpecifically, DANCE integrates automated data slimming which adaptively\ndownsamples/drops input images and controls their corresponding contribution to\nthe training loss guided by the images' spatial complexity. Such a downsampling\noperation, in addition to slimming down the cost associated with the input size\ndirectly, also shrinks the dynamic range of input object and context scales,\ntherefore motivating us to also adaptively slim the network to match the\ndownsampled data. Extensive experiments and ablating studies (on four SOTA\nsegmentation models with three popular segmentation datasets under two training\nsettings) demonstrate that DANCE can achieve \"all-win\" towards efficient\nsegmentation(reduced training cost, less expensive inference, and better mean\nIntersection-over-Union (mIoU)).\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 04:58:58 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Chaojian", ""], ["Chen", "Wuyang", ""], ["Gu", "Yuchen", ""], ["Chen", "Tianlong", ""], ["Fu", "Yonggan", ""], ["Wang", "Zhangyang", ""], ["Lin", "Yingyan", ""]]}, {"id": "2107.07709", "submitter": "Arnab Kumar Mondal", "authors": "Arnab Kumar Mondal, Himanshu Asnani, Parag Singla, Prathosh AP", "title": "ScRAE: Deterministic Regularized Autoencoders with Flexible Priors for\n  Clustering Single-cell Gene Expression Data", "comments": "IEEE/ACM Transactions on Computational Biology and Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Clustering single-cell RNA sequence (scRNA-seq) data poses statistical and\ncomputational challenges due to their high-dimensionality and data-sparsity,\nalso known as `dropout' events. Recently, Regularized Auto-Encoder (RAE) based\ndeep neural network models have achieved remarkable success in learning robust\nlow-dimensional representations. The basic idea in RAEs is to learn a\nnon-linear mapping from the high-dimensional data space to a low-dimensional\nlatent space and vice-versa, simultaneously imposing a distributional prior on\nthe latent space, which brings in a regularization effect. This paper argues\nthat RAEs suffer from the infamous problem of bias-variance trade-off in their\nnaive formulation. While a simple AE without a latent regularization results in\ndata over-fitting, a very strong prior leads to under-representation and thus\nbad clustering. To address the above issues, we propose a modified RAE\nframework (called the scRAE) for effective clustering of the single-cell RNA\nsequencing data. scRAE consists of deterministic AE with a flexibly learnable\nprior generator network, which is jointly trained with the AE. This facilitates\nscRAE to trade-off better between the bias and variance in the latent space. We\ndemonstrate the efficacy of the proposed method through extensive\nexperimentation on several real-world single-cell Gene expression datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 05:13:31 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["Asnani", "Himanshu", ""], ["Singla", "Parag", ""], ["AP", "Prathosh", ""]]}, {"id": "2107.07713", "submitter": "Vishal Sharma", "authors": "Rushil Gupta, Vishal Sharma, Yash Jain, Yitao Liang, Guy Van den\n  Broeck and Parag Singla", "title": "Towards an Interpretable Latent Space in Structured Models for Video\n  Prediction", "comments": "Accepted at Weakly Supervised Representation Learning Workshop at\n  IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on the task of future frame prediction in video governed by\nunderlying physical dynamics. We work with models which are object-centric,\ni.e., explicitly work with object representations, and propagate a loss in the\nlatent space. Specifically, our research builds on recent work by Kipf et al.\n\\cite{kipf&al20}, which predicts the next state via contrastive learning of\nobject interactions in a latent space using a Graph Neural Network. We argue\nthat injecting explicit inductive bias in the model, in form of general\nphysical laws, can help not only make the model more interpretable, but also\nimprove the overall prediction of model. As a natural by-product, our model can\nlearn feature maps which closely resemble actual object positions in the image,\nwithout having any explicit supervision about the object positions at the\ntraining time. In comparison with earlier works \\cite{jaques&al20}, which\nassume a complete knowledge of the dynamics governing the motion in the form of\na physics engine, we rely only on the knowledge of general physical laws, such\nas, world consists of objects, which have position and velocity. We propose an\nadditional decoder based loss in the pixel space, imposed in a curriculum\nmanner, to further refine the latent space predictions. Experiments in multiple\ndifferent settings demonstrate that while Kipf et al. model is effective at\ncapturing object interactions, our model can be significantly more effective at\nlocalising objects, resulting in improved performance in 3 out of 4 domains\nthat we experiment with. Additionally, our model can learn highly intrepretable\nfeature maps, resembling actual object positions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 05:37:16 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Gupta", "Rushil", ""], ["Sharma", "Vishal", ""], ["Jain", "Yash", ""], ["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""], ["Singla", "Parag", ""]]}, {"id": "2107.07724", "submitter": "Marco Sampaio", "authors": "Ricardo Barata, Miguel Leite, Ricardo Pacheco, Marco O. P. Sampaio,\n  Jo\\~ao Tiago Ascens\\~ao, Pedro Bizarro", "title": "Active learning for online training in imbalanced data streams under\n  cold start", "comments": "9 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Labeled data is essential in modern systems that rely on Machine Learning\n(ML) for predictive modelling. Such systems may suffer from the cold-start\nproblem: supervised models work well but, initially, there are no labels, which\nare costly or slow to obtain. This problem is even worse in imbalanced data\nscenarios. Online financial fraud detection is an example where labeling is: i)\nexpensive, or ii) it suffers from long delays, if relying on victims filing\ncomplaints. The latter may not be viable if a model has to be in place\nimmediately, so an option is to ask analysts to label events while minimizing\nthe number of annotations to control costs. We propose an Active Learning (AL)\nannotation system for datasets with orders of magnitude of class imbalance, in\na cold start streaming scenario. We present a computationally efficient\nOutlier-based Discriminative AL approach (ODAL) and design a novel 3-stage\nsequence of AL labeling policies where it is used as warm-up. Then, we perform\nempirical studies in four real world datasets, with various magnitudes of class\nimbalance. The results show that our method can more quickly reach a high\nperformance model than standard AL policies. Its observed gains over random\nsampling can reach 80% and be competitive with policies with an unlimited\nannotation budget or additional historical data (with 1/10 to 1/50 of the\nlabels).\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:49:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Barata", "Ricardo", ""], ["Leite", "Miguel", ""], ["Pacheco", "Ricardo", ""], ["Sampaio", "Marco O. P.", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2107.07728", "submitter": "Pascal Pfeiffer", "authors": "Christof Henkel, Pascal Pfeiffer and Philipp Singer", "title": "Recognizing bird species in diverse soundscapes under weak supervision", "comments": "All authors contributed equally, 8 pages, 4 figures, submitted to\n  CEUR-WS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a robust classification approach for avian vocalization in complex\nand diverse soundscapes, achieving second place in the BirdCLEF2021 challenge.\nWe illustrate how to make full use of pre-trained convolutional neural\nnetworks, by using an efficient modeling and training routine supplemented by\nnovel augmentation methods. Thereby, we improve the generalization of weakly\nlabeled crowd-sourced data to productive data collected by autonomous recording\nunits. As such, we illustrate how to progress towards an accurate automated\nassessment of avian population which would enable global biodiversity\nmonitoring at scale, impossible by manual annotation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:54:38 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Henkel", "Christof", ""], ["Pfeiffer", "Pascal", ""], ["Singer", "Philipp", ""]]}, {"id": "2107.07729", "submitter": "Maneet Singh", "authors": "Shivshankar Reddy, Anand Vir Singh Chauhan, Maneet Singh, and Karamjit\n  Singh", "title": "Semi-supervised Learning for Marked Temporal Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Point Processes (TPPs) are often used to represent the sequence of\nevents ordered as per the time of occurrence. Owing to their flexible nature,\nTPPs have been used to model different scenarios and have shown applicability\nin various real-world applications. While TPPs focus on modeling the event\noccurrence, Marked Temporal Point Process (MTPP) focuses on modeling the\ncategory/class of the event as well (termed as the marker). Research in MTPP\nhas garnered substantial attention over the past few years, with an extensive\nfocus on supervised algorithms. Despite the research focus, limited attention\nhas been given to the challenging problem of developing solutions in\nsemi-supervised settings, where algorithms have access to a mix of labeled and\nunlabeled data. This research proposes a novel algorithm for Semi-supervised\nLearning for Marked Temporal Point Processes (SSL-MTPP) applicable in such\nscenarios. The proposed SSL-MTPP algorithm utilizes a combination of labeled\nand unlabeled data for learning a robust marker prediction model. The proposed\nalgorithm utilizes an RNN-based Encoder-Decoder module for learning effective\nrepresentations of the time sequence. The efficacy of the proposed algorithm\nhas been demonstrated via multiple protocols on the Retweet dataset, where the\nproposed SSL-MTPP demonstrates improved performance in comparison to the\ntraditional supervised learning approach.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:59:38 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Reddy", "Shivshankar", ""], ["Chauhan", "Anand Vir Singh", ""], ["Singh", "Maneet", ""], ["Singh", "Karamjit", ""]]}, {"id": "2107.07732", "submitter": "Udaya Ghai", "authors": "Xinyi Chen, Udaya Ghai, Elad Hazan, Alexandre Megretski", "title": "Robust Online Control with Model Misspecification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online control of an unknown nonlinear dynamical system that is\napproximated by a time-invariant linear system with model misspecification. Our\nstudy focuses on robustness, which measures how much deviation from the assumed\nlinear approximation can be tolerated while maintaining a bounded $\\ell_2$-gain\ncompared to the optimal control in hindsight. Some models cannot be stabilized\neven with perfect knowledge of their coefficients: the robustness is limited by\nthe minimal distance between the assumed dynamics and the set of unstabilizable\ndynamics. Therefore it is necessary to assume a lower bound on this distance.\nUnder this assumption, and with full observation of the $d$ dimensional state,\nwe describe an efficient controller that attains $\\Omega(\\frac{1}{\\sqrt{d}})$\nrobustness together with an $\\ell_2$-gain whose dimension dependence is near\noptimal. We also give an inefficient algorithm that attains constant robustness\nindependent of the dimension, with a finite but sub-optimal $\\ell_2$-gain.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:04:35 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chen", "Xinyi", ""], ["Ghai", "Udaya", ""], ["Hazan", "Elad", ""], ["Megretski", "Alexandre", ""]]}, {"id": "2107.07737", "submitter": "Dunjie Zhang", "authors": "Jinyin Chen, Dunjie Zhang, Zhaoyan Ming, Mingwei Jia, and Yi Liu", "title": "EGC2: Enhanced Graph Classification with Easy Graph Compression", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph classification plays a significant role in network analysis. It also\nfaces potential security threat like adversarial attacks. Some defense methods\nmay sacrifice algorithm complexity for robustness like adversarial training,\nwhile others may sacrifice the clean example performance such as\nsmoothing-based defense. Most of them are suffered from high-complexity or less\ntransferability. To address this problem, we proposed EGC$^2$, an enhanced\ngraph classification model with easy graph compression. EGC$^2$ captures the\nrelationship between features of different nodes by constructing feature graphs\nand improving aggregate node-level representation. To achieve lower complexity\ndefense applied to various graph classification models, EGC$^2$ utilizes a\ncentrality-based edge importance index to compress graphs, filtering out\ntrivial structures and even adversarial perturbations of the input graphs, thus\nimproves its robustness. Experiments on seven benchmark datasets demonstrate\nthat the proposed feature read-out and graph compression mechanisms enhance the\nrobustness of various basic models, thus achieving the state-of-the-art\nperformance of accuracy and robustness in the threat of different adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:17:29 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chen", "Jinyin", ""], ["Zhang", "Dunjie", ""], ["Ming", "Zhaoyan", ""], ["Jia", "Mingwei", ""], ["Liu", "Yi", ""]]}, {"id": "2107.07738", "submitter": "Yang Li", "authors": "Yang Li, Jiazheng Li and Yi Wang", "title": "Privacy-preserving Spatiotemporal Scenario Generation of Renewable\n  Energies: A Federated Deep Generative Learning Approach", "comments": "Accepted by IEEE Transactions on Industrial Informatics", "journal-ref": null, "doi": "10.1109/TII.2021.3098259", "report-no": null, "categories": "cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario generation is a fundamental and crucial tool for decision-making in\npower systems with high-penetration renewables. Based on big historical data, a\nnovel federated deep generative learning framework, called Fed-LSGAN, is\nproposed by integrating federated learning and least square generative\nadversarial networks (LSGANs) for renewable scenario generation. Specifically,\nfederated learning learns a shared global model in a central server from\nrenewable sites at network edges, which enables the Fed-LSGAN to generate\nscenarios in a privacy-preserving manner without sacrificing the generation\nquality by transferring model parameters, rather than all data. Meanwhile, the\nLSGANs-based deep generative model generates scenarios that conform to the\ndistribution of historical data through fully capturing the spatial-temporal\ncharacteristics of renewable powers, which leverages the least squares loss\nfunction to improve the training stability and generation quality. The\nsimulation results demonstrate that the proposal manages to generate\nhigh-quality renewable scenarios and outperforms the state-of-the-art\ncentralized methods. Besides, an experiment with different federated learning\nsettings is designed and conducted to verify the robustness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:18:22 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Yang", ""], ["Li", "Jiazheng", ""], ["Wang", "Yi", ""]]}, {"id": "2107.07740", "submitter": "Jinpeng Li", "authors": "Hao Chen, Ming Jin, Zhunan Li, Cunhang Fan, Jinpeng Li and Huiguang He", "title": "MS-MDA: Multisource Marginal Distribution Adaptation for Cross-subject\n  and Cross-session EEG Emotion Recognition", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As an essential element for the diagnosis and rehabilitation of psychiatric\ndisorders, the electroencephalogram (EEG) based emotion recognition has\nachieved significant progress due to its high precision and reliability.\nHowever, one obstacle to practicality lies in the variability between subjects\nand sessions. Although several studies have adopted domain adaptation (DA)\napproaches to tackle this problem, most of them treat multiple EEG data from\ndifferent subjects and sessions together as a single source domain for\ntransfer, which either fails to satisfy the assumption of domain adaptation\nthat the source has a certain marginal distribution, or increases the\ndifficulty of adaptation. We therefore propose the multi-source marginal\ndistribution adaptation (MS-MDA) for EEG emotion recognition, which takes both\ndomain-invariant and domain-specific features into consideration. First, we\nassume that different EEG data share the same low-level features, then we\nconstruct independent branches for multiple EEG data source domains to adopt\none-to-one domain adaptation and extract domain-specific features. Finally, the\ninference is made by multiple branches. We evaluate our method on SEED and\nSEED-IV for recognizing three and four emotions, respectively. Experimental\nresults show that the MS-MDA outperforms the comparison methods and\nstate-of-the-art models in cross-session and cross-subject transfer scenarios\nin our settings. Codes at https://github.com/VoiceBeer/MS-MDA.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:19:54 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chen", "Hao", ""], ["Jin", "Ming", ""], ["Li", "Zhunan", ""], ["Fan", "Cunhang", ""], ["Li", "Jinpeng", ""], ["He", "Huiguang", ""]]}, {"id": "2107.07741", "submitter": "Niel Hu", "authors": "Niel Teng Hu, Xinyu Hu, Rosanne Liu, Sara Hooker, Jason Yosinski", "title": "When does loss-based prioritization fail?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all examples are created equal, but standard deep neural network training\nprotocols treat each training point uniformly. Each example is propagated\nforward and backward through the network the same amount of times, independent\nof how much the example contributes to the learning protocol. Recent work has\nproposed ways to accelerate training by deviating from this uniform treatment.\nPopular methods entail up-weighting examples that contribute more to the loss\nwith the intuition that examples with low loss have already been learned by the\nmodel, so their marginal value to the training procedure should be lower. This\nview assumes that updating the model with high loss examples will be beneficial\nto the model. However, this may not hold for noisy, real world data. In this\npaper, we theorize and then empirically demonstrate that loss-based\nacceleration methods degrade in scenarios with noisy and corrupted data. Our\nwork suggests measures of example difficulty need to correctly separate out\nnoise from other types of challenging examples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:23:15 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Hu", "Niel Teng", ""], ["Hu", "Xinyu", ""], ["Liu", "Rosanne", ""], ["Hooker", "Sara", ""], ["Yosinski", "Jason", ""]]}, {"id": "2107.07752", "submitter": "Francesco Cognolato Mr", "authors": "Francesco Cognolato, Kieran O'Brien, Jin Jin, Simon Robinson, Frederik\n  B. Laun, Markus Barth, Steffen Bollmann", "title": "NeXtQSM -- A complete deep learning pipeline for data-consistent\n  quantitative susceptibility mapping trained with hybrid data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning based Quantitative Susceptibility Mapping (QSM) has shown great\npotential in recent years, outperforming traditional non-learning approaches in\nspeed and accuracy. However, many of the current deep learning approaches are\nnot data consistent, require in vivo training data or do not solve all steps of\nthe QSM processing pipeline. Here we aim to overcome these limitations and\ndeveloped a framework to solve the QSM processing steps jointly. We developed a\nnew hybrid training data generation method that enables the end-to-end training\nfor solving background field correction and dipole inversion in a\ndata-consistent fashion using a variational network that combines the QSM model\nterm and a learned regularizer. We demonstrate that NeXtQSM overcomes the\nlimitations of previous model-agnostic deep learning methods and show that\nNeXtQSM offers a complete deep learning based pipeline for computing robust,\nfast and accurate quantitative susceptibility maps.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:07:22 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Cognolato", "Francesco", ""], ["O'Brien", "Kieran", ""], ["Jin", "Jin", ""], ["Robinson", "Simon", ""], ["Laun", "Frederik B.", ""], ["Barth", "Markus", ""], ["Bollmann", "Steffen", ""]]}, {"id": "2107.07754", "submitter": "Christopher Teo", "authors": "Christopher T.H Teo and Ngai-Man Cheung", "title": "Measuring Fairness in Generative Models", "comments": "Accepted in ICML 2021 Workshop - Machine Learning for Data: Automated\n  Creation, Privacy, Bias", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep generative models have made much progress in improving training\nstability and quality of generated data. Recently there has been increased\ninterest in the fairness of deep-generated data. Fairness is important in many\napplications, e.g. law enforcement, as biases will affect efficacy. Central to\nfair data generation are the fairness metrics for the assessment and evaluation\nof different generative models. In this paper, we first review fairness metrics\nproposed in previous works and highlight potential weaknesses. We then discuss\na performance benchmark framework along with the assessment of alternative\nmetrics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:12:44 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Teo", "Christopher T. H", ""], ["Cheung", "Ngai-Man", ""]]}, {"id": "2107.07757", "submitter": "Daniele Musso", "authors": "Daniele Musso", "title": "Entropic alternatives to initialization", "comments": "19 pages, 5 figures, 2 appendices; v2 added comments and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG hep-th", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Local entropic loss functions provide a versatile framework to define\narchitecture-aware regularization procedures. Besides the possibility of being\nanisotropic in the synaptic space, the local entropic smoothening of the loss\nfunction can vary during training, thus yielding a tunable model complexity. A\nscoping protocol where the regularization is strong in the early-stage of the\ntraining and then fades progressively away constitutes an alternative to\nstandard initialization procedures for deep convolutional neural networks,\nnonetheless, it has wider applicability. We analyze anisotropic, local entropic\nsmoothenings in the language of statistical physics and information theory,\nproviding insight into both their interpretation and workings. We comment some\naspects related to the physics of renormalization and the spacetime structure\nof convolutional networks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:17:32 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 06:21:32 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Musso", "Daniele", ""]]}, {"id": "2107.07788", "submitter": "Bo Pang", "authors": "Bo Pang and Zhong-Ping Jiang", "title": "Reinforcement Learning for Adaptive Optimal Stationary Control of Linear\n  Stochastic Systems", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the adaptive optimal stationary control of continuous-time\nlinear stochastic systems with both additive and multiplicative noises, using\nreinforcement learning techniques. Based on policy iteration, a novel\noff-policy reinforcement learning algorithm, named optimistic\nleast-squares-based policy iteration, is proposed which is able to iteratively\nfind near-optimal policies of the adaptive optimal stationary control problem\ndirectly from input/state data without explicitly identifying any system\nmatrices, starting from an initial admissible control policy. The solutions\ngiven by the proposed optimistic least-squares-based policy iteration are\nproved to converge to a small neighborhood of the optimal solution with\nprobability one, under mild conditions. The application of the proposed\nalgorithm to a triple inverted pendulum example validates its feasibility and\neffectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:27:02 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 03:47:32 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Pang", "Bo", ""], ["Jiang", "Zhong-Ping", ""]]}, {"id": "2107.07791", "submitter": "Zahra Gharaee", "authors": "Zahra Gharaee and Shreyas Kowshik and Oliver Stromann and Michael\n  Felsberg", "title": "Graph Representation Learning for Road Type Classification", "comments": null, "journal-ref": null, "doi": "10.1016/j.patcog.2021.108174", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel learning-based approach to graph representations of road\nnetworks employing state-of-the-art graph convolutional neural networks. Our\napproach is applied to realistic road networks of 17 cities from Open Street\nMap. While edge features are crucial to generate descriptive graph\nrepresentations of road networks, graph convolutional networks usually rely on\nnode features only. We show that the highly representative edge features can\nstill be integrated into such networks by applying a line graph transformation.\nWe also propose a method for neighborhood sampling based on a topological\nneighborhood composed of both local and global neighbors. We compare the\nperformance of learning representations using different types of neighborhood\naggregation functions in transductive and inductive tasks and in supervised and\nunsupervised learning. Furthermore, we propose a novel aggregation approach,\nGraph Attention Isomorphism Network, GAIN. Our results show that GAIN\noutperforms state-of-the-art methods on the road type classification problem.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:32:58 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Gharaee", "Zahra", ""], ["Kowshik", "Shreyas", ""], ["Stromann", "Oliver", ""], ["Felsberg", "Michael", ""]]}, {"id": "2107.07818", "submitter": "Roman Kolcun", "authors": "Roman Kolcun, Diana Andreea Popescu, Vadim Safronov, Poonam Yadav,\n  Anna Maria Mandalari, Richard Mortier, Hamed Haddadi", "title": "Revisiting IoT Device Identification", "comments": "To appear in TMA 2021 conference. 9 pages, 6 figures. arXiv admin\n  note: text overlap with arXiv:2011.08605", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet-of-Things (IoT) devices are known to be the source of many security\nproblems, and as such, they would greatly benefit from automated management.\nThis requires robustly identifying devices so that appropriate network security\npolicies can be applied. We address this challenge by exploring how to\naccurately identify IoT devices based on their network behavior, while\nleveraging approaches previously proposed by other researchers.\n  We compare the accuracy of four different previously proposed machine\nlearning models (tree-based and neural network-based) for identifying IoT\ndevices. We use packet trace data collected over a period of six months from a\nlarge IoT test-bed. We show that, while all models achieve high accuracy when\nevaluated on the same dataset as they were trained on, their accuracy degrades\nover time, when evaluated on data collected outside the training set. We show\nthat on average the models' accuracy degrades after a couple of weeks by up to\n40 percentage points (on average between 12 and 21 percentage points). We argue\nthat, in order to keep the models' accuracy at a high level, these need to be\ncontinuously updated.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:01:45 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Kolcun", "Roman", ""], ["Popescu", "Diana Andreea", ""], ["Safronov", "Vadim", ""], ["Yadav", "Poonam", ""], ["Mandalari", "Anna Maria", ""], ["Mortier", "Richard", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2107.07820", "submitter": "Puck De Haan", "authors": "Puck de Haan, Sindy L\\\"owe", "title": "Contrastive Predictive Coding for Anomaly Detection", "comments": "7 pages, ICML 2021 Workshop on Uncertainty and Robustness in Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable detection of anomalies is crucial when deploying machine learning\nmodels in practice, but remains challenging due to the lack of labeled data. To\ntackle this challenge, contrastive learning approaches are becoming\nincreasingly popular, given the impressive results they have achieved in\nself-supervised representation learning settings. However, while most existing\ncontrastive anomaly detection and segmentation approaches have been applied to\nimages, none of them can use the contrastive losses directly for both anomaly\ndetection and segmentation. In this paper, we close this gap by making use of\nthe Contrastive Predictive Coding model (arXiv:1807.03748). We show that its\npatch-wise contrastive loss can directly be interpreted as an anomaly score,\nand how this allows for the creation of anomaly segmentation masks. The\nresulting model achieves promising results for both anomaly detection and\nsegmentation on the challenging MVTec-AD dataset.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:04:35 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["de Haan", "Puck", ""], ["L\u00f6we", "Sindy", ""]]}, {"id": "2107.07831", "submitter": "Arpita Chaudhuri", "authors": "Arpita Chaudhuri, Debasis Samanta, Monalisa Sarma", "title": "Modeling User Behaviour in Research Paper Recommendation System", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  User intention which often changes dynamically is considered to be an\nimportant factor for modeling users in the design of recommendation systems.\nRecent studies are starting to focus on predicting user intention (what users\nwant) beyond user preference (what users like). In this work, a user intention\nmodel is proposed based on deep sequential topic analysis. The model predicts a\nuser's intention in terms of the topic of interest. The Hybrid Topic Model\n(HTM) comprising Latent Dirichlet Allocation (LDA) and Word2Vec is proposed to\nderive the topic of interest of users and the history of preferences. HTM finds\nthe true topics of papers estimating word-topic distribution which includes\nsyntactic and semantic correlations among words. Next, to model user intention,\na Long Short Term Memory (LSTM) based sequential deep learning model is\nproposed. This model takes into account temporal context, namely the time\ndifference between clicks of two consecutive papers seen by a user. Extensive\nexperiments with the real-world research paper dataset indicate that the\nproposed approach significantly outperforms the state-of-the-art methods.\nFurther, the proposed approach introduces a new road map to model a user\nactivity suitable for the design of a research paper recommendation system.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:31:03 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chaudhuri", "Arpita", ""], ["Samanta", "Debasis", ""], ["Sarma", "Monalisa", ""]]}, {"id": "2107.07844", "submitter": "Mathias Thor", "authors": "Mathias Thor, Poramate Manoonpong", "title": "Versatile modular neural locomotion control with fast learning", "comments": "For supplementary video files see:\n  https://youtube.com/playlist?list=PLKaJNfU8acRCjKphvzqqFE0UNwzJBo5M1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Legged robots have significant potential to operate in highly unstructured\nenvironments. The design of locomotion control is, however, still challenging.\nCurrently, controllers must be either manually designed for specific robots and\ntasks, or automatically designed via machine learning methods that require long\ntraining times and yield large opaque controllers. Drawing inspiration from\nanimal locomotion, we propose a simple yet versatile modular neural control\nstructure with fast learning. The key advantages of our approach are that\nbehavior-specific control modules can be added incrementally to obtain\nincreasingly complex emergent locomotion behaviors, and that neural connections\ninterfacing with existing modules can be quickly and automatically learned. In\na series of experiments, we show how eight modules can be quickly learned and\nadded to a base control module to obtain emergent adaptive behaviors allowing a\nhexapod robot to navigate in complex environments. We also show that modules\ncan be added and removed during operation without affecting the functionality\nof the remaining controller. Finally, the control approach was successfully\ndemonstrated on a physical hexapod robot. Taken together, our study reveals a\nsignificant step towards fast automatic design of versatile neural locomotion\ncontrol for complex robotic systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:12:28 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Thor", "Mathias", ""], ["Manoonpong", "Poramate", ""]]}, {"id": "2107.07853", "submitter": "Gunnar K\\\"onig", "authors": "Gunnar K\\\"onig, Timo Freiesleben, Moritz Grosse-Wentrup", "title": "A Causal Perspective on Meaningful and Robust Algorithmic Recourse", "comments": "ICML (International Conference on Machine Learning) Workshop on\n  Algorithmic Recourse", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Algorithmic recourse explanations inform stakeholders on how to act to revert\nunfavorable predictions. However, in general ML models do not predict well in\ninterventional distributions. Thus, an action that changes the prediction in\nthe desired way may not lead to an improvement of the underlying target. Such\nrecourse is neither meaningful nor robust to model refits. Extending the work\nof Karimi et al. (2021), we propose meaningful algorithmic recourse (MAR) that\nonly recommends actions that improve both prediction and target. We justify\nthis selection constraint by highlighting the differences between model audit\nand meaningful, actionable recourse explanations. Additionally, we introduce a\nrelaxation of MAR called effective algorithmic recourse (EAR), which, under\ncertain assumptions, yields meaningful recourse by only allowing interventions\non causes of the target.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:37:54 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["K\u00f6nig", "Gunnar", ""], ["Freiesleben", "Timo", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "2107.07859", "submitter": "Hyeon Jeon", "authors": "Hyeon Jeon, Hyung-Kwon Ko, Jaemin Jo, Youngtaek Kim, and Jinwook Seo", "title": "Measuring and Explaining the Inter-Cluster Reliability of\n  Multidimensional Projections", "comments": "IEEE Transactions of Visualization and Computer Graphics (TVCG, Proc.\n  VIS 2021), to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose Steadiness and Cohesiveness, two novel metrics to measure the\ninter-cluster reliability of multidimensional projection (MDP), specifically\nhow well the inter-cluster structures are preserved between the original\nhigh-dimensional space and the low-dimensional projection space. Measuring\ninter-cluster reliability is crucial as it directly affects how well\ninter-cluster tasks (e.g., identifying cluster relationships in the original\nspace from a projected view) can be conducted; however, despite the importance\nof inter-cluster tasks, we found that previous metrics, such as Trustworthiness\nand Continuity, fail to measure inter-cluster reliability. Our metrics consider\ntwo aspects of the inter-cluster reliability: Steadiness measures the extent to\nwhich clusters in the projected space form clusters in the original space, and\nCohesiveness measures the opposite. They extract random clusters with arbitrary\nshapes and positions in one space and evaluate how much the clusters are\nstretched or dispersed in the other space. Furthermore, our metrics can\nquantify pointwise distortions, allowing for the visualization of inter-cluster\nreliability in a projection, which we call a reliability map. Through\nquantitative experiments, we verify that our metrics precisely capture the\ndistortions that harm inter-cluster reliability while previous metrics have\ndifficulty capturing the distortions. A case study also demonstrates that our\nmetrics and the reliability map 1) support users in selecting the proper\nprojection techniques or hyperparameters and 2) prevent misinterpretation while\nperforming inter-cluster tasks, thus allow an adequate identification of\ninter-cluster structure.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:52:13 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 04:49:15 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 05:27:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Jeon", "Hyeon", ""], ["Ko", "Hyung-Kwon", ""], ["Jo", "Jaemin", ""], ["Kim", "Youngtaek", ""], ["Seo", "Jinwook", ""]]}, {"id": "2107.07863", "submitter": "Ushnish Sengupta", "authors": "Ushnish Sengupta, Alexandros Kontogiannis, Matthew P. Juniper", "title": "Simultaneous boundary shape estimation and velocity field de-noising in\n  Magnetic Resonance Velocimetry using Physics-informed Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Magnetic resonance velocimetry (MRV) is a non-invasive experimental technique\nwidely used in medicine and engineering to measure the velocity field of a\nfluid. These measurements are dense but have a low signal-to-noise ratio (SNR).\nThe measurements can be de-noised by imposing physical constraints on the flow,\nwhich are encapsulated in governing equations for mass and momentum. Previous\nstudies have required the shape of the boundary (for example, a blood vessel)\nto be known a priori. This, however, requires a set of additional measurements,\nwhich can be expensive to obtain. In this paper, we present a physics-informed\nneural network that instead uses the noisy MRV data alone to simultaneously\ninfer the most likely boundary shape and de-noised velocity field. We achieve\nthis by training an auxiliary neural network that takes the value 1.0 within\nthe inferred domain of the governing PDE and 0.0 outside. This network is used\nto weight the PDE residual term in the loss function accordingly and implicitly\nlearns the geometry of the system. We test our algorithm by assimilating both\nsynthetic and real MRV measurements for flows that can be well modeled by the\nPoisson and Stokes equations. We find that we are able to reconstruct very\nnoisy (SNR = 2.5) MRV signals and recover the ground truth with low\nreconstruction errors of 3.7 - 7.5%. The simplicity and flexibility of our\nphysics-informed neural network approach can readily scale to assimilating MRV\ndata with complex 3D geometries, time-varying 4D data, or unknown parameters in\nthe physical model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:56:09 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sengupta", "Ushnish", ""], ["Kontogiannis", "Alexandros", ""], ["Juniper", "Matthew P.", ""]]}, {"id": "2107.07869", "submitter": "Syed Ali Zaidi", "authors": "Syed Ali Raza Zaidi", "title": "Nearest neighbor Methods and their Applications in Design of 5G & Beyond\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present an overview of Nearest neighbor (NN) methods, which\nare frequently employed for solving classification problems using supervised\nlearning. The article concisely introduces the theoretical background,\nalgorithmic, and implementation aspects along with the key applications. From\nan application standpoint, this article explores the challenges related to the\n5G and beyond wireless networks which can be solved using NN classification\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:01:14 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Zaidi", "Syed Ali Raza", ""]]}, {"id": "2107.07871", "submitter": "Ben Moseley", "authors": "Ben Moseley, Andrew Markham, Tarje Nissen-Meyer", "title": "Finite Basis Physics-Informed Neural Networks (FBPINNs): a scalable\n  domain decomposition approach for solving differential equations", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, physics-informed neural networks (PINNs) have offered a powerful\nnew paradigm for solving problems relating to differential equations. Compared\nto classical numerical methods PINNs have several advantages, for example their\nability to provide mesh-free solutions of differential equations and their\nability to carry out forward and inverse modelling within the same optimisation\nproblem. Whilst promising, a key limitation to date is that PINNs have\nstruggled to accurately and efficiently solve problems with large domains\nand/or multi-scale solutions, which is crucial for their real-world\napplication. Multiple significant and related factors contribute to this issue,\nincluding the increasing complexity of the underlying PINN optimisation problem\nas the problem size grows and the spectral bias of neural networks. In this\nwork we propose a new, scalable approach for solving large problems relating to\ndifferential equations called Finite Basis PINNs (FBPINNs). FBPINNs are\ninspired by classical finite element methods, where the solution of the\ndifferential equation is expressed as the sum of a finite set of basis\nfunctions with compact support. In FBPINNs neural networks are used to learn\nthese basis functions, which are defined over small, overlapping subdomains.\nFBINNs are designed to address the spectral bias of neural networks by using\nseparate input normalisation over each subdomain, and reduce the complexity of\nthe underlying optimisation problem by using many smaller neural networks in a\nparallel divide-and-conquer approach. Our numerical experiments show that\nFBPINNs are effective in solving both small and larger, multi-scale problems,\noutperforming standard PINNs in both accuracy and computational resources\nrequired, potentially paving the way to the application of PINNs on large,\nreal-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:03:47 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Moseley", "Ben", ""], ["Markham", "Andrew", ""], ["Nissen-Meyer", "Tarje", ""]]}, {"id": "2107.07875", "submitter": "Palash Ghosh", "authors": "Trikay Nalamada, Shruti Agarwal, Maria Jahja, Bibhas Chakraborty and\n  Palash Ghosh", "title": "A Penalized Shared-parameter Algorithm for Estimating Optimal Dynamic\n  Treatment Regimens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A dynamic treatment regimen (DTR) is a set of decision rules to personalize\ntreatments for an individual using their medical history. The Q-learning based\nQ-shared algorithm has been used to develop DTRs that involve decision rules\nshared across multiple stages of intervention. We show that the existing\nQ-shared algorithm can suffer from non-convergence due to the use of linear\nmodels in the Q-learning setup, and identify the condition in which Q-shared\nfails. Leveraging properties from expansion-constrained ordinary least-squares,\nwe give a penalized Q-shared algorithm that not only converges in settings that\nviolate the condition, but can outperform the original Q-shared algorithm even\nwhen the condition is satisfied. We give evidence for the proposed method in a\nreal-world application and several synthetic simulations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 05:31:14 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Nalamada", "Trikay", ""], ["Agarwal", "Shruti", ""], ["Jahja", "Maria", ""], ["Chakraborty", "Bibhas", ""], ["Ghosh", "Palash", ""]]}, {"id": "2107.07878", "submitter": "Igor Muniz MSc.", "authors": "I. Muniz, F. H. F. Camargo and A. Marques", "title": "Ranking labs-of-origin for genetically engineered DNA using Metric\n  Learning", "comments": "4 pages, 2 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the constant advancements of genetic engineering, a common concern is to\nbe able to identify the lab-of-origin of genetically engineered DNA sequences.\nFor that reason, AltLabs has hosted the genetic Engineering Attribution\nChallenge to gather many teams to propose new tools to solve this problem. Here\nwe show our proposed method to rank the most likely labs-of-origin and generate\nembeddings for DNA sequences and labs. These embeddings can also perform\nvarious other tasks, like clustering both DNA sequences and labs and using them\nas features for Machine Learning models applied to solve other problems. This\nwork demonstrates that our method outperforms the classic training method for\nthis task while generating other helpful information.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:06:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Muniz", "I.", ""], ["Camargo", "F. H. F.", ""], ["Marques", "A.", ""]]}, {"id": "2107.07886", "submitter": "Jason T. L. Wang", "authors": "Haodi Jiang, Ju Jing, Jiasheng Wang, Chang Liu, Qin Li, Yan Xu, Jason\n  T. L. Wang, Haimin Wang", "title": "Tracing Halpha Fibrils through Bayesian Deep Learning", "comments": "20 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new deep learning method, dubbed FibrilNet, for tracing\nchromospheric fibrils in Halpha images of solar observations. Our method\nconsists of a data pre-processing component that prepares training data from a\nthreshold-based tool, a deep learning model implemented as a Bayesian\nconvolutional neural network for probabilistic image segmentation with\nuncertainty quantification to predict fibrils, and a post-processing component\ncontaining a fibril-fitting algorithm to determine fibril orientations. The\nFibrilNet tool is applied to high-resolution Halpha images from an active\nregion (AR 12665) collected by the 1.6 m Goode Solar Telescope (GST) equipped\nwith high-order adaptive optics at the Big Bear Solar Observatory (BBSO). We\nquantitatively assess the FibrilNet tool, comparing its image segmentation\nalgorithm and fibril-fitting algorithm with those employed by the\nthreshold-based tool. Our experimental results and major findings are\nsummarized as follows. First, the image segmentation results (i.e., detected\nfibrils) of the two tools are quite similar, demonstrating the good learning\ncapability of FibrilNet. Second, FibrilNet finds more accurate and smoother\nfibril orientation angles than the threshold-based tool. Third, FibrilNet is\nfaster than the threshold-based tool and the uncertainty maps produced by\nFibrilNet not only provide a quantitative way to measure the confidence on each\ndetected fibril, but also help identify fibril structures that are not detected\nby the threshold-based tool but are inferred through machine learning. Finally,\nwe apply FibrilNet to full-disk Halpha images from other solar observatories\nand additional high-resolution Halpha images collected by BBSO/GST,\ndemonstrating the tool's usability in diverse datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:14:33 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jiang", "Haodi", ""], ["Jing", "Ju", ""], ["Wang", "Jiasheng", ""], ["Liu", "Chang", ""], ["Li", "Qin", ""], ["Xu", "Yan", ""], ["Wang", "Jason T. L.", ""], ["Wang", "Haimin", ""]]}, {"id": "2107.07889", "submitter": "Yi Li", "authors": "Yifei Jiang, Yi Li, Yiming Sun, Jiaxin Wang, David P. Woodruff", "title": "Single Pass Entrywise-Transformed Low Rank Approximation", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In applications such as natural language processing or computer vision, one\nis given a large $n \\times d$ matrix $A = (a_{i,j})$ and would like to compute\na matrix decomposition, e.g., a low rank approximation, of a function $f(A) =\n(f(a_{i,j}))$ applied entrywise to $A$. A very important special case is the\nlikelihood function $f\\left( A \\right ) = \\log{\\left( \\left| a_{ij}\\right|\n+1\\right)}$. A natural way to do this would be to simply apply $f$ to each\nentry of $A$, and then compute the matrix decomposition, but this requires\nstoring all of $A$ as well as multiple passes over its entries. Recent work of\nLiang et al.\\ shows how to find a rank-$k$ factorization to $f(A)$ for an $n\n\\times n$ matrix $A$ using only $n \\cdot \\operatorname{poly}(\\epsilon^{-1}k\\log\nn)$ words of memory, with overall error $10\\|f(A)-[f(A)]_k\\|_F^2 +\n\\operatorname{poly}(\\epsilon/k) \\|f(A)\\|_{1,2}^2$, where $[f(A)]_k$ is the best\nrank-$k$ approximation to $f(A)$ and $\\|f(A)\\|_{1,2}^2$ is the square of the\nsum of Euclidean lengths of rows of $f(A)$. Their algorithm uses three passes\nover the entries of $A$. The authors pose the open question of obtaining an\nalgorithm with $n \\cdot \\operatorname{poly}(\\epsilon^{-1}k\\log n)$ words of\nmemory using only a single pass over the entries of $A$. In this paper we\nresolve this open question, obtaining the first single-pass algorithm for this\nproblem and for the same class of functions $f$ studied by Liang et al.\nMoreover, our error is $\\|f(A)-[f(A)]_k\\|_F^2 + \\operatorname{poly}(\\epsilon/k)\n\\|f(A)\\|_F^2$, where $\\|f(A)\\|_F^2$ is the sum of squares of Euclidean lengths\nof rows of $f(A)$. Thus our error is significantly smaller, as it removes the\nfactor of $10$ and also $\\|f(A)\\|_F^2 \\leq \\|f(A)\\|_{1,2}^2$. We also give an\nalgorithm for regression, pointing out an error in previous work, and\nempirically validate our results.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:22:29 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jiang", "Yifei", ""], ["Li", "Yi", ""], ["Sun", "Yiming", ""], ["Wang", "Jiaxin", ""], ["Woodruff", "David P.", ""]]}, {"id": "2107.07977", "submitter": "Jan Ernsting", "authors": "Tim Hahn, Jan Ernsting, Nils R. Winter, Vincent Holstein, Ramona\n  Leenings, Marie Beisemann, Lukas Fisch, Kelvin Sarink, Daniel Emden, Nils\n  Opel, Ronny Redlich, Jonathan Repple, Dominik Grotegerd, Susanne Meinert,\n  Jochen G. Hirsch, Thoralf Niendorf, Beate Endemann, Fabian Bamberg, Thomas\n  Kr\\\"oncke, Robin B\\\"ulow, Henry V\\\"olzke, Oyunbileg von Stackelberg, Ramona\n  Felizitas Sowade, Lale Umutlu, B\\\"orge Schmidt, Svenja Caspers, German\n  National Cohort Study Center Consortium, Harald Kugel, Tilo Kircher, Benjamin\n  Risse, Christian Gaser, James H. Cole, Udo Dannlowski, Klaus Berger", "title": "An Uncertainty-Aware, Shareable and Transparent Neural Network\n  Architecture for Brain-Age Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deviation between chronological age and age predicted from neuroimaging\ndata has been identified as a sensitive risk-marker of cross-disorder brain\nchanges, growing into a cornerstone of biological age-research. However,\nMachine Learning models underlying the field do not consider uncertainty,\nthereby confounding results with training data density and variability. Also,\nexisting models are commonly based on homogeneous training sets, often not\nindependently validated, and cannot be shared due to data protection issues.\nHere, we introduce an uncertainty-aware, shareable, and transparent Monte-Carlo\nDropout Composite-Quantile-Regression (MCCQR) Neural Network trained on\nN=10,691 datasets from the German National Cohort. The MCCQR model provides\nrobust, distribution-free uncertainty quantification in high-dimensional\nneuroimaging data, achieving lower error rates compared to existing models\nacross ten recruitment centers and in three independent validation samples\n(N=4,004). In two examples, we demonstrate that it prevents spurious\nassociations and increases power to detect accelerated brain-aging. We make the\npre-trained model publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:48:08 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Hahn", "Tim", ""], ["Ernsting", "Jan", ""], ["Winter", "Nils R.", ""], ["Holstein", "Vincent", ""], ["Leenings", "Ramona", ""], ["Beisemann", "Marie", ""], ["Fisch", "Lukas", ""], ["Sarink", "Kelvin", ""], ["Emden", "Daniel", ""], ["Opel", "Nils", ""], ["Redlich", "Ronny", ""], ["Repple", "Jonathan", ""], ["Grotegerd", "Dominik", ""], ["Meinert", "Susanne", ""], ["Hirsch", "Jochen G.", ""], ["Niendorf", "Thoralf", ""], ["Endemann", "Beate", ""], ["Bamberg", "Fabian", ""], ["Kr\u00f6ncke", "Thomas", ""], ["B\u00fclow", "Robin", ""], ["V\u00f6lzke", "Henry", ""], ["von Stackelberg", "Oyunbileg", ""], ["Sowade", "Ramona Felizitas", ""], ["Umutlu", "Lale", ""], ["Schmidt", "B\u00f6rge", ""], ["Caspers", "Svenja", ""], ["Consortium", "German National Cohort Study Center", ""], ["Kugel", "Harald", ""], ["Kircher", "Tilo", ""], ["Risse", "Benjamin", ""], ["Gaser", "Christian", ""], ["Cole", "James H.", ""], ["Dannlowski", "Udo", ""], ["Berger", "Klaus", ""]]}, {"id": "2107.07983", "submitter": "Zhi-Gang Liu", "authors": "Zhi-Gang Liu, Paul N. Whatmough, Yuhao Zhu, Matthew Mattina", "title": "S2TA: Exploiting Structured Sparsity for Energy-Efficient Mobile CNN\n  Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exploiting sparsity is a key technique in accelerating quantized\nconvolutional neural network (CNN) inference on mobile devices. Prior sparse\nCNN accelerators largely exploit un-structured sparsity and achieve significant\nspeedups. Due to the unbounded, largely unpredictable sparsity patterns,\nhowever, exploiting unstructured sparsity requires complicated hardware design\nwith significant energy and area overhead, which is particularly detrimental to\nmobile/IoT inference scenarios where energy and area efficiency are crucial. We\npropose to exploit structured sparsity, more specifically, Density Bound Block\n(DBB) sparsity for both weights and activations. DBB block tensors bound the\nmaximum number of non-zeros per block. DBB thus exposes statically predictable\nsparsity patterns that enable lean sparsity-exploiting hardware. We propose new\nhardware primitives to implement DBB sparsity for (static) weights and\n(dynamic) activations, respectively, with very low overheads. Building on top\nof the primitives, we describe S2TA, a systolic array-based CNN accelerator\nthat exploits joint weight and activation DBB sparsity and new dimensions of\ndata reuse unavailable on the traditional systolic array. S2TA in 16nm achieves\nmore than 2x speedup and energy reduction compared to a strong baseline of a\nsystolic array with zero-value clock gating, over five popular CNN benchmarks.\nCompared to two recent non-systolic sparse accelerators, Eyeriss v2 (65nm) and\nSparTen (45nm), S2TA in 65nm uses about 2.2x and 3.1x less energy per\ninference, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:57:06 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Liu", "Zhi-Gang", ""], ["Whatmough", "Paul N.", ""], ["Zhu", "Yuhao", ""], ["Mattina", "Matthew", ""]]}, {"id": "2107.07988", "submitter": "Hao Liang", "authors": "Hao Liang, Lulan Yu, Guikang Xu, Bhiksha Raj, Rita Singh", "title": "Controlled AutoEncoders to Generate Faces from Voices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multiple studies in the past have shown that there is a strong correlation\nbetween human vocal characteristics and facial features. However, existing\napproaches generate faces simply from voice, without exploring the set of\nfeatures that contribute to these observed correlations. A computational\nmethodology to explore this can be devised by rephrasing the question to: \"how\nmuch would a target face have to change in order to be perceived as the\noriginator of a source voice?\" With this in perspective, we propose a framework\nto morph a target face in response to a given voice in a way that facial\nfeatures are implicitly guided by learned voice-face correlation in this paper.\nOur framework includes a guided autoencoder that converts one face to another,\ncontrolled by a unique model-conditioning component called a gating controller\nwhich modifies the reconstructed face based on input voice recordings. We\nevaluate the framework on VoxCelab and VGGFace datasets through human subjects\nand face retrieval. Various experiments demonstrate the effectiveness of our\nproposed model.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:04:29 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Liang", "Hao", ""], ["Yu", "Lulan", ""], ["Xu", "Guikang", ""], ["Raj", "Bhiksha", ""], ["Singh", "Rita", ""]]}, {"id": "2107.07994", "submitter": "Yaqing Wang", "authors": "Yaqing Wang, Abulikemu Abuduweili, Dejing Dou", "title": "Property-aware Adaptive Relation Networks for Molecular Property\n  Prediction", "comments": "molecular property prediction, few-shot learning, meta learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular property prediction plays a fundamental role in drug discovery to\ndiscover candidate molecules with target properties. However, molecular\nproperty prediction is essentially a few-shot problem which makes it hard to\nobtain regular models. In this paper, we propose a property-aware adaptive\nrelation networks (PAR) for the few-shot molecular property prediction problem.\nIn comparison to existing works, we leverage the facts that both substructures\nand relationships among molecules are different considering various molecular\nproperties. Our PAR is compatible with existing graph-based molecular encoders,\nand are further equipped with the ability to obtain property-aware molecular\nembedding and model molecular relation graph adaptively. The resultant relation\ngraph also facilitates effective label propagation within each task. Extensive\nexperiments on benchmark molecular property prediction datasets show that our\nmethod consistently outperforms state-of-the-art methods and is able to obtain\nproperty-aware molecular embedding and model molecular relation graph properly.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:22:30 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Wang", "Yaqing", ""], ["Abuduweili", "Abulikemu", ""], ["Dou", "Dejing", ""]]}, {"id": "2107.07997", "submitter": "Kamal Choudhary", "authors": "Francesca Tavazza, Brian De Cost, Kamal Choudhary", "title": "Uncertainty Prediction for Machine Learning Models of Material\n  Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification in Artificial Intelligence (AI)-based predictions\nof material properties is of immense importance for the success and reliability\nof AI applications in material science. While confidence intervals are commonly\nreported for machine learning (ML) models, prediction intervals, i.e., the\nevaluation of the uncertainty on each prediction, are seldomly available. In\nthis work we compare 3 different approaches to obtain such individual\nuncertainty, testing them on 12 ML-physical properties. Specifically, we\ninvestigated using the Quantile loss function, machine learning the prediction\nintervals directly and using Gaussian Processes. We identify each approachs\nadvantages and disadvantages and end up slightly favoring the modeling of the\nindividual uncertainties directly, as it is the easiest to fit and, in most\ncases, minimizes over-and under-estimation of the predicted errors. All data\nfor training and testing were taken from the publicly available JARVIS-DFT\ndatabase, and the codes developed for computing the prediction intervals are\navailable through JARVIS-Tools.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:33:55 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Tavazza", "Francesca", ""], ["De Cost", "Brian", ""], ["Choudhary", "Kamal", ""]]}, {"id": "2107.07999", "submitter": "Han Lin", "authors": "Krzysztof Choromanski, Han Lin, Haoxian Chen, Jack Parker-Holder", "title": "Graph Kernel Attention Transformers", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new class of graph neural networks (GNNs), by combining\nseveral concepts that were so far studied independently - graph kernels,\nattention-based networks with structural priors and more recently, efficient\nTransformers architectures applying small memory footprint implicit attention\nmethods via low rank decomposition techniques. The goal of the paper is\ntwofold. Proposed by us Graph Kernel Attention Transformers (or GKATs) are much\nmore expressive than SOTA GNNs as capable of modeling longer-range dependencies\nwithin a single layer. Consequently, they can use more shallow architecture\ndesign. Furthermore, GKAT attention layers scale linearly rather than\nquadratically in the number of nodes of the input graphs, even when those\ngraphs are dense, requiring less compute than their regular graph attention\ncounterparts. They achieve it by applying new classes of graph kernels\nadmitting random feature map decomposition via random walks on graphs. As a\nbyproduct of the introduced techniques, we obtain a new class of learnable\ngraph sketches, called graphots, compactly encoding topological graph\nproperties as well as nodes' features. We conducted exhaustive empirical\ncomparison of our method with nine different GNN classes on tasks ranging from\nmotif detection through social network classification to bioinformatics\nchallenges, showing consistent gains coming from GKATs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:39:10 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Lin", "Han", ""], ["Chen", "Haoxian", ""], ["Parker-Holder", "Jack", ""]]}, {"id": "2107.08001", "submitter": "Marylou Gabri\\'e", "authors": "Marylou Gabri\\'e, Grant M. Rotskoff, Eric Vanden-Eijnden", "title": "Efficient Bayesian Sampling Using Normalizing Flows to Assist Markov\n  Chain Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows can generate complex target distributions and thus show\npromise in many applications in Bayesian statistics as an alternative or\ncomplement to MCMC for sampling posteriors. Since no data set from the target\nposterior distribution is available beforehand, the flow is typically trained\nusing the reverse Kullback-Leibler (KL) divergence that only requires samples\nfrom a base distribution. This strategy may perform poorly when the posterior\nis complicated and hard to sample with an untrained normalizing flow. Here we\nexplore a distinct training strategy, using the direct KL divergence as loss,\nin which samples from the posterior are generated by (i) assisting a local MCMC\nalgorithm on the posterior with a normalizing flow to accelerate its mixing\nrate and (ii) using the data generated this way to train the flow. The method\nonly requires a limited amount of \\textit{a~priori} input about the posterior,\nand can be used to estimate the evidence required for model validation, as we\nillustrate on examples.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:40:36 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Gabri\u00e9", "Marylou", ""], ["Rotskoff", "Grant M.", ""], ["Vanden-Eijnden", "Eric", ""]]}, {"id": "2107.08011", "submitter": "Panayotis Mertikopoulos", "authors": "Kimon Antonakopoulos and Panayotis Mertikopoulos", "title": "Adaptive first-order methods revisited: Convex optimization without\n  Lipschitz requirements", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of adaptive first-order methods for a class of convex\nminimization problems that may fail to be Lipschitz continuous or smooth in the\nstandard sense. Specifically, motivated by a recent flurry of activity on\nnon-Lipschitz (NoLips) optimization, we consider problems that are continuous\nor smooth relative to a reference Bregman function - as opposed to a global,\nambient norm (Euclidean or otherwise). These conditions encompass a wide range\nof problems with singular objectives, such as Fisher markets, Poisson\ntomography, D-design, and the like. In this setting, the application of\nexisting order-optimal adaptive methods - like UnixGrad or AcceleGrad - is not\npossible, especially in the presence of randomness and uncertainty. The\nproposed method - which we call adaptive mirror descent (AdaMir) - aims to\nclose this gap by concurrently achieving min-max optimal rates in problems that\nare relatively continuous or smooth, including stochastic ones.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 16:59:40 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Antonakopoulos", "Kimon", ""], ["Mertikopoulos", "Panayotis", ""]]}, {"id": "2107.08013", "submitter": "Cole Miles", "authors": "Cole Miles, Matthew R. Carbone, Erica J. Sturm, Deyu Lu, Andreas\n  Weichselbaum, Kipton Barros, and Robert M. Konik", "title": "Machine-learning Kondo physics using variational autoencoders", "comments": "9 pages + 5 pages appendix, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.str-el cond-mat.dis-nn cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ variational autoencoders to extract physical insight from a dataset\nof one-particle Anderson impurity model spectral functions. Autoencoders are\ntrained to find a low-dimensional, latent space representation that faithfully\ncharacterizes each element of the training set, as measured by a reconstruction\nerror. Variational autoencoders, a probabilistic generalization of standard\nautoencoders, further condition the learned latent space to promote highly\ninterpretable features. In our study, we find that the learned latent space\ncomponents strongly correlate with well known, but nontrivial, parameters that\ncharacterize emergent behaviors in the Anderson impurity model. In particular,\none latent space component correlates with particle-hole asymmetry, while\nanother is in near one-to-one correspondence with the Kondo temperature, a\ndynamically generated low-energy scale in the impurity model. With symbolic\nregression, we model this component as a function of bare physical input\nparameters and \"rediscover\" the non-perturbative formula for the Kondo\ntemperature. The machine learning pipeline we develop opens opportunities to\ndiscover new domain knowledge in other physical systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:03:58 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Miles", "Cole", ""], ["Carbone", "Matthew R.", ""], ["Sturm", "Erica J.", ""], ["Lu", "Deyu", ""], ["Weichselbaum", "Andreas", ""], ["Barros", "Kipton", ""], ["Konik", "Robert M.", ""]]}, {"id": "2107.08020", "submitter": "Yiye Jiang", "authors": "Yiye Jiang, J\\'er\\'emie Bigot and Sofian Maabout", "title": "Online Graph Topology Learning from Matrix-valued Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the statistical analysis of matrix-valued time\nseries. These are data collected over a network of sensors (typically a set of\nspatial locations), recording, over time, observations of multiple\nmeasurements. From such data, we propose to learn, in an online fashion, a\ngraph that captures two aspects of dependency: one describing the sparse\nspatial relationship between sensors, and the other characterizing the\nmeasurement relationship. To this purpose, we introduce a novel multivariate\nautoregressive model to infer the graph topology encoded in the coefficient\nmatrix which captures the sparse Granger causality dependency structure present\nin such matrix-valued time series. We decompose the graph by imposing a\nKronecker sum structure on the coefficient matrix. We develop two online\napproaches to learn the graph in a recursive way. The first one uses Wald test\nfor the projected OLS estimation, where we derive the asymptotic distribution\nfor the estimator. For the second one, we formalize a Lasso-type optimization\nproblem. We rely on homotopy algorithms to derive updating rules for estimating\nthe coefficient matrix. Furthermore, we provide an adaptive tuning procedure\nfor the regularization parameter. Numerical experiments using both synthetic\nand real data, are performed to support the effectiveness of the proposed\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:21:14 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jiang", "Yiye", ""], ["Bigot", "J\u00e9r\u00e9mie", ""], ["Maabout", "Sofian", ""]]}, {"id": "2107.08024", "submitter": "Shaan Desai", "authors": "Shaan Desai, Marios Mattheakis, David Sondak, Pavlos Protopapas and\n  Stephen Roberts", "title": "Port-Hamiltonian Neural Networks for Learning Explicit Time-Dependent\n  Dynamical Systems", "comments": "[under review]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately learning the temporal behavior of dynamical systems requires\nmodels with well-chosen learning biases. Recent innovations embed the\nHamiltonian and Lagrangian formalisms into neural networks and demonstrate a\nsignificant improvement over other approaches in predicting trajectories of\nphysical systems. These methods generally tackle autonomous systems that depend\nimplicitly on time or systems for which a control signal is known apriori.\nDespite this success, many real world dynamical systems are non-autonomous,\ndriven by time-dependent forces and experience energy dissipation. In this\nstudy, we address the challenge of learning from such non-autonomous systems by\nembedding the port-Hamiltonian formalism into neural networks, a versatile\nframework that can capture energy dissipation and time-dependent control\nforces. We show that the proposed \\emph{port-Hamiltonian neural network} can\nefficiently learn the dynamics of nonlinear physical systems of practical\ninterest and accurately recover the underlying stationary Hamiltonian,\ntime-dependent force, and dissipative coefficient. A promising outcome of our\nnetwork is its ability to learn and predict chaotic systems such as the Duffing\nequation, for which the trajectories are typically hard to learn.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:31:54 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Desai", "Shaan", ""], ["Mattheakis", "Marios", ""], ["Sondak", "David", ""], ["Protopapas", "Pavlos", ""], ["Roberts", "Stephen", ""]]}, {"id": "2107.08027", "submitter": "Tanveer Khan", "authors": "Tanveer Khan, Antonis Michalas", "title": "Seeing and Believing: Evaluating the Trustworthiness of Twitter Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social networking and micro-blogging services, such as Twitter, play an\nimportant role in sharing digital information. Despite the popularity and\nusefulness of social media, there have been many instances where corrupted\nusers found ways to abuse it, as for instance, through raising or lowering\nuser's credibility. As a result, while social media facilitates an\nunprecedented ease of access to information, it also introduces a new challenge\n- that of ascertaining the credibility of shared information. Currently, there\nis no automated way of determining which news or users are credible and which\nare not. Hence, establishing a system that can measure the social media user's\ncredibility has become an issue of great importance. Assigning a credibility\nscore to a user has piqued the interest of not only the research community but\nalso most of the big players on both sides - such as Facebook, on the side of\nindustry, and political parties on the societal one. In this work, we created a\nmodel which, we hope, will ultimately facilitate and support the increase of\ntrust in the social network communities. Our model collected data and analysed\nthe behaviour of~50,000 politicians on Twitter. Influence score, based on\nseveral chosen features, was assigned to each evaluated user. Further, we\nclassified the political Twitter users as either trusted or untrusted using\nrandom forest, multilayer perceptron, and support vector machine. An active\nlearning model was used to classify any unlabelled ambiguous records from our\ndataset. Finally, to measure the performance of the proposed model, we used\nprecision, recall, F1 score, and accuracy as the main evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:39:32 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 08:35:15 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Khan", "Tanveer", ""], ["Michalas", "Antonis", ""]]}, {"id": "2107.08028", "submitter": "Jan Berg", "authors": "Jan Berg and Konstantinos Drossos", "title": "Continual Learning for Automated Audio Captioning Using The Learning\n  Without Forgetting Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated audio captioning (AAC) is the task of automatically creating\ntextual descriptions (i.e. captions) for the contents of a general audio\nsignal. Most AAC methods are using existing datasets to optimize and/or\nevaluate upon. Given the limited information held by the AAC datasets, it is\nvery likely that AAC methods learn only the information contained in the\nutilized datasets. In this paper we present a first approach for continuously\nadapting an AAC method to new information, using a continual learning method.\nIn our scenario, a pre-optimized AAC method is used for some unseen general\naudio signals and can update its parameters in order to adapt to the new\ninformation, given a new reference caption. We evaluate our method using a\nfreely available, pre-optimized AAC method and two freely available AAC\ndatasets. We compare our proposed method with three scenarios, two of training\non one of the datasets and evaluating on the other and a third of training on\none dataset and fine-tuning on the other. Obtained results show that our method\nachieves a good balance between distilling new knowledge and not forgetting the\nprevious one.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:44:26 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Berg", "Jan", ""], ["Drossos", "Konstantinos", ""]]}, {"id": "2107.08031", "submitter": "Lina Achaji", "authors": "Lina Achaji, Julien Moreau, Thibault Fouqueray, Francois Aioun,\n  Francois Charpillet", "title": "Is attention to bounding boxes all you need for pedestrian action\n  prediction?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human driver is no longer the only one concerned with the complexity of\nthe driving scenarios. Autonomous vehicles (AV) are similarly becoming involved\nin the process. Nowadays, the development of AV in urban places underpins\nessential safety concerns for vulnerable road users (VRUs) such as pedestrians.\nTherefore, to make the roads safer, it is critical to classify and predict\ntheir future behavior. In this paper, we present a framework based on multiple\nvariations of the Transformer models to reason attentively about the dynamic\nevolution of the pedestrians' past trajectory and predict its future actions of\ncrossing or not crossing the street. We proved that using only bounding boxes\nas input to our model can outperform the previous state-of-the-art models and\nreach a prediction accuracy of 91 % and an F1-score of 0.83 on the PIE dataset\nup to two seconds ahead in the future. In addition, we introduced a large-size\nsimulated dataset (CP2A) using CARLA for action prediction. Our model has\nsimilarly reached high accuracy (91 %) and F1-score (0.91) on this dataset.\nInterestingly, we showed that pre-training our Transformer model on the\nsimulated dataset and then fine-tuning it on the real dataset can be very\neffective for the action prediction task.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:47:32 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Achaji", "Lina", ""], ["Moreau", "Julien", ""], ["Fouqueray", "Thibault", ""], ["Aioun", "Francois", ""], ["Charpillet", "Francois", ""]]}, {"id": "2107.08039", "submitter": "Zhizhong Li", "authors": "Zhizhong Li, Avinash Ravichandran, Charless Fowlkes, Marzia Polito,\n  Rahul Bhotika, Stefano Soatto", "title": "Representation Consolidation for Training Expert Students", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, distillation has been used to train a student model to emulate\nthe input/output functionality of a teacher. A more useful goal than emulation,\nyet under-explored, is for the student to learn feature representations that\ntransfer well to future tasks. However, we observe that standard distillation\nof task-specific teachers actually *reduces* the transferability of student\nrepresentations to downstream tasks. We show that a multi-head, multi-task\ndistillation method using an unlabeled proxy dataset and a generalist teacher\nis sufficient to consolidate representations from task-specific teacher(s) and\nimprove downstream performance, outperforming the teacher(s) and the strong\nbaseline of ImageNet pretrained features. Our method can also combine the\nrepresentational knowledge of multiple teachers trained on one or multiple\ndomains into a single model, whose representation is improved on all teachers'\ndomain(s).\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:58:18 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Zhizhong", ""], ["Ravichandran", "Avinash", ""], ["Fowlkes", "Charless", ""], ["Polito", "Marzia", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "2107.08045", "submitter": "Carlos Mougan", "authors": "Carlos Mougan Navarro, Georgios Kanellos, Thomas Gottron", "title": "Desiderata for Explainable AI in statistical production systems of the\n  European Central Bank", "comments": "Submitted for review at European Congress of Machine Learning\n  (ECMLPKDD) - 2ND Worksho on bias and fairness in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable AI constitutes a fundamental step towards establishing fairness\nand addressing bias in algorithmic decision-making. Despite the large body of\nwork on the topic, the benefit of solutions is mostly evaluated from a\nconceptual or theoretical point of view and the usefulness for real-world use\ncases remains uncertain. In this work, we aim to state clear user-centric\ndesiderata for explainable AI reflecting common explainability needs\nexperienced in statistical production systems of the European Central Bank. We\nlink the desiderata to archetypical user roles and give examples of techniques\nand methods which can be used to address the user's needs. To this end, we\nprovide two concrete use cases from the domain of statistical data production\nin central banks: the detection of outliers in the Centralised Securities\nDatabase and the data-driven identification of data quality checks for the\nSupervisory Banking data system.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:58:11 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Navarro", "Carlos Mougan", ""], ["Kanellos", "Georgios", ""], ["Gottron", "Thomas", ""]]}, {"id": "2107.08066", "submitter": "Yves-Laurent Kom Samo", "authors": "Yves-Laurent Kom Samo", "title": "LeanML: A Design Pattern To Slash Avoidable Wastes in Machine Learning\n  Projects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce the first application of the lean methodology to machine\nlearning projects. Similar to lean startups and lean manufacturing, we argue\nthat lean machine learning (LeanML) can drastically slash avoidable wastes in\ncommercial machine learning projects, reduce the business risk in investing in\nmachine learning capabilities and, in so doing, further democratize access to\nmachine learning. The lean design pattern we propose in this paper is based on\ntwo realizations. First, it is possible to estimate the best performance one\nmay achieve when predicting an outcome $y \\in \\mathcal{Y}$ using a given set of\nexplanatory variables $x \\in \\mathcal{X}$, for a wide range of performance\nmetrics, and without training any predictive model. Second, doing so is\nconsiderably easier, faster, and cheaper than learning the best predictive\nmodel. We derive formulae expressing the best $R^2$, MSE, classification\naccuracy, and log-likelihood per observation achievable when using $x$ to\npredict $y$ as a function of the mutual information $I\\left(y; x\\right)$, and\npossibly a measure of the variability of $y$ (e.g. its Shannon entropy in the\ncase of classification accuracy, and its variance in the case regression MSE).\nWe illustrate the efficacy of the LeanML design pattern on a wide range of\nregression and classification problems, synthetic and real-life.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:16:48 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Samo", "Yves-Laurent Kom", ""]]}, {"id": "2107.08068", "submitter": "Mark Gluzman", "authors": "J. G. Dai and Mark Gluzman", "title": "Refined Policy Improvement Bounds for MDPs", "comments": "Workshop on Reinforcement Learning Theory, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The policy improvement bound on the difference of the discounted returns\nplays a crucial role in the theoretical justification of the trust-region\npolicy optimization (TRPO) algorithm. The existing bound leads to a degenerate\nbound when the discount factor approaches one, making the applicability of TRPO\nand related algorithms questionable when the discount factor is close to one.\nWe refine the results in \\cite{Schulman2015, Achiam2017} and propose a novel\nbound that is \"continuous\" in the discount factor. In particular, our bound is\napplicable for MDPs with the long-run average rewards as well.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:22:30 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dai", "J. G.", ""], ["Gluzman", "Mark", ""]]}, {"id": "2107.08074", "submitter": "Jorge Guevara", "authors": "Jorge Guevara, Dario Borges, Campbell Watson, Bianca Zadrozny", "title": "A comparative study of stochastic and deep generative models for\n  multisite precipitation synthesis", "comments": "ICML 2021 Workshop Tackling Climate Change with Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future climate change scenarios are usually hypothesized using simulations\nfrom weather generators. However, there only a few works comparing and\nevaluating promising deep learning models for weather generation against\nclassical approaches. This study shows preliminary results making such\nevaluations for the multisite precipitation synthesis task. We compared two\nopen-source weather generators: IBMWeathergen (an extension of the Weathergen\nlibrary) and RGeneratePrec, and two deep generative models: GAN and VAE, on a\nvariety of metrics. Our preliminary results can serve as a guide for improving\nthe design of deep learning architectures and algorithms for the multisite\nprecipitation synthesis task.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:35:24 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Guevara", "Jorge", ""], ["Borges", "Dario", ""], ["Watson", "Campbell", ""], ["Zadrozny", "Bianca", ""]]}, {"id": "2107.08083", "submitter": "Pablo Hernandez-Leal", "authors": "Yue Gao and Kry Yik Chau Lui and Pablo Hernandez-Leal", "title": "Robust Risk-Sensitive Reinforcement Learning Agents for Trading Markets", "comments": "Reinforcement Learning for Real Life (RL4RealLife) Workshop at ICML\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trading markets represent a real-world financial application to deploy\nreinforcement learning agents, however, they carry hard fundamental challenges\nsuch as high variance and costly exploration. Moreover, markets are inherently\na multiagent domain composed of many actors taking actions and changing the\nenvironment. To tackle these type of scenarios agents need to exhibit certain\ncharacteristics such as risk-awareness, robustness to perturbations and low\nlearning variance. We take those as building blocks and propose a family of\nfour algorithms. First, we contribute with two algorithms that use risk-averse\nobjective functions and variance reduction techniques. Then, we augment the\nframework to multi-agent learning and assume an adversary which can take over\nand perturb the learning process. Our third and fourth algorithms perform well\nunder this setting and balance theoretical guarantees with practical use.\nAdditionally, we consider the multi-agent nature of the environment and our\nwork is the first one extending empirical game theory analysis for multi-agent\nlearning by considering risk-sensitive payoffs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 19:15:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gao", "Yue", ""], ["Lui", "Kry Yik Chau", ""], ["Hernandez-Leal", "Pablo", ""]]}, {"id": "2107.08090", "submitter": "Praneeth Kacham", "authors": "Nadiia Chepurko, Kenneth L. Clarkson, Praneeth Kacham and David P.\n  Woodruff", "title": "Near-Optimal Algorithms for Linear Algebra in the Current Matrix\n  Multiplication Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Currently, in the numerical linear algebra community, it is thought that to\nobtain nearly-optimal bounds for various problems such as rank computation,\nfinding a maximal linearly independent subset of columns, regression, low rank\napproximation, maximum matching on general graphs and linear matroid union, one\nwould need to resolve the main open question of Nelson and Nguyen (FOCS, 2013)\nregarding the logarithmic factors in the sketching dimension for existing\nconstant factor approximation oblivious subspace embeddings. We show how to\nbypass this question using a refined sketching technique, and obtain optimal or\nnearly optimal bounds for these problems. A key technique we use is an explicit\nmapping of Indyk based on uncertainty principles and extractors, which after\nfirst applying known oblivious subspace embeddings, allows us to quickly spread\nout the mass of the vector so that sampling is now effective, and we avoid a\nlogarithmic factor that is standard in the sketching dimension resulting from\nmatrix Chernoff bounds. For the fundamental problems of rank computation and\nfinding a linearly independent subset of columns, our algorithms improve\nCheung, Kwok, and Lau (JACM, 2013) and are optimal to within a constant factor\nand a $\\log\\log(n)$-factor, respectively. Further, for constant factor\nregression and low rank approximation we give the first optimal algorithms, for\nthe current matrix multiplication exponent.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 19:34:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chepurko", "Nadiia", ""], ["Clarkson", "Kenneth L.", ""], ["Kacham", "Praneeth", ""], ["Woodruff", "David P.", ""]]}, {"id": "2107.08096", "submitter": "Divya Shanmugam", "authors": "Divya Shanmugam, Samira Shabanian, Fernando Diaz, Mich\\`ele Finck,\n  Asia Biega", "title": "Learning to Limit Data Collection via Scaling Laws: Data Minimization\n  Compliance in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data minimization is a legal obligation defined in the European Union's\nGeneral Data Protection Regulation (GDPR) as the responsibility to process an\nadequate, relevant, and limited amount of personal data in relation to a\nprocessing purpose. However, unlike fairness or transparency, the principle has\nnot seen wide adoption for machine learning systems due to a lack of\ncomputational interpretation. In this paper, we build on literature in machine\nlearning and law to propose the first learning framework for limiting data\ncollection based on an interpretation that ties the data collection purpose to\nsystem performance. We formalize a data minimization criterion based on\nperformance curve derivatives and provide an effective and interpretable\npiecewise power law technique that models distinct stages of an algorithm's\nperformance throughout data collection. Results from our empirical\ninvestigation offer deeper insights into the relevant considerations when\ndesigning a data minimization framework, including the choice of feature\nacquisition algorithm, initialization conditions, as well as impacts on\nindividuals that hint at tensions between data minimization and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 19:59:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shanmugam", "Divya", ""], ["Shabanian", "Samira", ""], ["Diaz", "Fernando", ""], ["Finck", "Mich\u00e8le", ""], ["Biega", "Asia", ""]]}, {"id": "2107.08114", "submitter": "Ekram Hossain", "authors": "Yuanchao Xu, Amal Feriani, and Ekram Hossain", "title": "Decentralized Multi-Agent Reinforcement Learning for Task Offloading\n  Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) is a challenging subarea of\nReinforcement Learning due to the non-stationarity of the environments and the\nlarge dimensionality of the combined action space. Deep MARL algorithms have\nbeen applied to solve different task offloading problems. However, in\nreal-world applications, information required by the agents (i.e. rewards and\nstates) are subject to noise and alterations. The stability and the robustness\nof deep MARL to practical challenges is still an open research problem. In this\nwork, we apply state-of-the art MARL algorithms to solve task offloading with\nreward uncertainty. We show that perturbations in the reward signal can induce\ndecrease in the performance compared to learning with perfect rewards. We\nexpect this paper to stimulate more research in studying and addressing the\npractical challenges of deploying deep MARL solutions in wireless\ncommunications systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 20:49:30 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 17:00:47 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Xu", "Yuanchao", ""], ["Feriani", "Amal", ""], ["Hossain", "Ekram", ""]]}, {"id": "2107.08135", "submitter": "Ikko Yamane", "authors": "Ikko Yamane, Junya Honda, Florian Yger, Masashi Sugiyama", "title": "Mediated Uncoupled Learning: Learning Functions without Direct\n  Input-output Correspondences", "comments": "ICML 2021 version with correction to Figure 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary supervised learning is useful when we have paired training data of\ninput $X$ and output $Y$. However, such paired data can be difficult to collect\nin practice. In this paper, we consider the task of predicting $Y$ from $X$\nwhen we have no paired data of them, but we have two separate, independent\ndatasets of $X$ and $Y$ each observed with some mediating variable $U$, that\nis, we have two datasets $S_X = \\{(X_i, U_i)\\}$ and $S_Y = \\{(U'_j, Y'_j)\\}$. A\nnaive approach is to predict $U$ from $X$ using $S_X$ and then $Y$ from $U$\nusing $S_Y$, but we show that this is not statistically consistent. Moreover,\npredicting $U$ can be more difficult than predicting $Y$ in practice, e.g.,\nwhen $U$ has higher dimensionality. To circumvent the difficulty, we propose a\nnew method that avoids predicting $U$ but directly learns $Y = f(X)$ by\ntraining $f(X)$ with $S_{X}$ to predict $h(U)$ which is trained with $S_{Y}$ to\napproximate $Y$. We prove statistical consistency and error bounds of our\nmethod and experimentally confirm its practical usefulness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 22:13:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yamane", "Ikko", ""], ["Honda", "Junya", ""], ["Yger", "Florian", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2107.08140", "submitter": "Yang Li", "authors": "Yang Li, Kevin B Korb, Lloyd Allison", "title": "Markov Blanket Discovery using Minimum Message Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal discovery automates the learning of causal Bayesian networks from data\nand has been of active interest from their beginning. With the sourcing of\nlarge data sets off the internet, interest in scaling up to very large data\nsets has grown. One approach to this is to parallelize search using Markov\nBlanket (MB) discovery as a first step, followed by a process of combining MBs\nin a global causal model. We develop and explore three new methods of MB\ndiscovery using Minimum Message Length (MML) and compare them empirically to\nthe best existing methods, whether developed specifically as MB discovery or as\nfeature selection. Our best MML method is consistently competitive and has some\nadvantageous features.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 22:58:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Li", "Yang", ""], ["Korb", "Kevin B", ""], ["Allison", "Lloyd", ""]]}, {"id": "2107.08142", "submitter": "Peter Ondruska", "authors": "Ashesh Jain, Luca Del Pero, Hugo Grimmett, Peter Ondruska", "title": "Autonomy 2.0: Why is self-driving always 5 years away?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the numerous successes of machine learning over the past decade\n(image recognition, decision-making, NLP, image synthesis), self-driving\ntechnology has not yet followed the same trend. In this paper, we study the\nhistory, composition, and development bottlenecks of the modern self-driving\nstack. We argue that the slow progress is caused by approaches that require too\nmuch hand-engineering, an over-reliance on road testing, and high fleet\ndeployment costs. We observe that the classical stack has several bottlenecks\nthat preclude the necessary scale needed to capture the long tail of rare\nevents. To resolve these problems, we outline the principles of Autonomy 2.0,\nan ML-first approach to self-driving, as a viable alternative to the currently\nadopted state-of-the-art. This approach is based on (i) a fully differentiable\nAV stack trainable from human demonstrations, (ii) closed-loop data-driven\nreactive simulation, and (iii) large-scale, low-cost data collections as\ncritical solutions towards scalability issues. We outline the general\narchitecture, survey promising works in this direction and propose key\nchallenges to be addressed by the community in the future.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 23:20:26 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 22:51:45 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Jain", "Ashesh", ""], ["Del Pero", "Luca", ""], ["Grimmett", "Hugo", ""], ["Ondruska", "Peter", ""]]}, {"id": "2107.08147", "submitter": "Young Geun Kim", "authors": "Young Geun Kim and Carole-Jean Wu", "title": "AutoFL: Enabling Heterogeneity-Aware Energy Efficient Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables a cluster of decentralized mobile devices at the\nedge to collaboratively train a shared machine learning model, while keeping\nall the raw training samples on device. This decentralized training approach is\ndemonstrated as a practical solution to mitigate the risk of privacy leakage.\nHowever, enabling efficient FL deployment at the edge is challenging because of\nnon-IID training data distribution, wide system heterogeneity and\nstochastic-varying runtime effects in the field. This paper jointly optimizes\ntime-to-convergence and energy efficiency of state-of-the-art FL use cases by\ntaking into account the stochastic nature of edge execution. We propose AutoFL\nby tailor-designing a reinforcement learning algorithm that learns and\ndetermines which K participant devices and per-device execution targets for\neach FL model aggregation round in the presence of stochastic runtime variance,\nsystem and data heterogeneity. By considering the unique characteristics of FL\nedge deployment judiciously, AutoFL achieves 3.6 times faster model convergence\ntime and 4.7 and 5.2 times higher energy efficiency for local clients and\nglobally over the cluster of K participants, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 23:41:26 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kim", "Young Geun", ""], ["Wu", "Carole-Jean", ""]]}, {"id": "2107.08148", "submitter": "Piero Molino", "authors": "Piero Molino and Christopher R\\'e", "title": "Declarative Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years machine learning (ML) has moved from a academic endeavor to\na pervasive technology adopted in almost every aspect of computing. ML-powered\nproducts are now embedded in our digital lives: from recommendations of what to\nwatch, to divining our search intent, to powering virtual assistants in\nconsumer and enterprise settings. Recent successes in applying ML in natural\nsciences revealed that ML can be used to tackle some of the hardest real-world\nproblems humanity faces today. For these reasons ML has become central in the\nstrategy of tech companies and has gathered even more attention from academia\nthan ever before. Despite these successes, what we have witnessed so far is\njust the beginning. Right now the people training and using ML models are\nexpert developers working within large organizations, but we believe the next\nwave of ML systems will allow a larger amount of people, potentially without\ncoding skills, to perform the same tasks. These new ML systems will not require\nusers to fully understand all the details of how models are trained and\nutilized for obtaining predictions. Declarative interfaces are well suited for\nthis goal, by hiding complexity and favouring separation of interests, and can\nlead to increased productivity. We worked on such abstract interfaces by\ndeveloping two declarative ML systems, Overton and Ludwig, that require users\nto declare only their data schema (names and types of inputs) and tasks rather\nthen writing low level ML code. In this article we will describe how ML systems\nare currently structured, highlight important factors for their success and\nadoption, what are the issues current ML systems are facing and how the systems\nwe developed addressed them. Finally we will talk about learnings from the\ndevelopment of ML systems throughout the years and how we believe the next\ngeneration of ML systems will look like.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 23:57:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Molino", "Piero", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2107.08166", "submitter": "Lulu Zhang", "authors": "Lulu Zhang, Zhi-Qin John Xu, Yaoyu Zhang", "title": "Data-informed Deep Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Complex design problems are common in the scientific and industrial fields.\nIn practice, objective functions or constraints of these problems often do not\nhave explicit formulas, and can be estimated only at a set of sampling points\nthrough experiments or simulations. Such optimization problems are especially\nchallenging when design parameters are high-dimensional due to the curse of\ndimensionality. In this work, we propose a data-informed deep optimization\n(DiDo) approach as follows: first, we use a deep neural network (DNN)\nclassifier to learn the feasible region; second, we sample feasible points\nbased on the DNN classifier for fitting of the objective function; finally, we\nfind optimal points of the DNN-surrogate optimization problem by gradient\ndescent. To demonstrate the effectiveness of our DiDo approach, we consider a\npractical design case in industry, in which our approach yields good solutions\nusing limited size of training data. We further use a 100-dimension toy example\nto show the effectiveness of our model for higher dimensional problems. Our\nresults indicate that the DiDo approach empowered by DNN is flexible and\npromising for solving general high-dimensional design problems in practice.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 02:53:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zhang", "Lulu", ""], ["Xu", "Zhi-Qin John", ""], ["Zhang", "Yaoyu", ""]]}, {"id": "2107.08170", "submitter": "Aleksei Petrenko", "authors": "Aleksei Petrenko, Erik Wijmans, Brennan Shacklett, Vladlen Koltun", "title": "Megaverse: Simulating Embodied Agents at One Million Experiences per\n  Second", "comments": "Paper published in ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Megaverse, a new 3D simulation platform for reinforcement learning\nand embodied AI research. The efficient design of our engine enables\nphysics-based simulation with high-dimensional egocentric observations at more\nthan 1,000,000 actions per second on a single 8-GPU node. Megaverse is up to\n70x faster than DeepMind Lab in fully-shaded 3D scenes with interactive\nobjects. We achieve this high simulation performance by leveraging batched\nsimulation, thereby taking full advantage of the massive parallelism of modern\nGPUs. We use Megaverse to build a new benchmark that consists of several\nsingle-agent and multi-agent tasks covering a variety of cognitive challenges.\nWe evaluate model-free RL on this benchmark to provide baselines and facilitate\nfuture research. The source code is available at https://www.megaverse.info\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 03:16:25 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 03:17:43 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Petrenko", "Aleksei", ""], ["Wijmans", "Erik", ""], ["Shacklett", "Brennan", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2107.08176", "submitter": "Peixin Zhang", "authors": "Peixin Zhang, Jingyi Wang, Jun Sun, Xinyu Wang, Guoliang Dong, Xingen\n  Wang, Ting Dai, Jin Song Dong", "title": "Automatic Fairness Testing of Neural Classifiers through Adversarial\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has demonstrated astonishing performance in many\napplications, there are still concerns about its dependability. One desirable\nproperty of deep learning applications with societal impact is fairness (i.e.,\nnon-discrimination). Unfortunately, discrimination might be intrinsically\nembedded into the models due to the discrimination in the training data. As a\ncountermeasure, fairness testing systemically identifies discriminatory\nsamples, which can be used to retrain the model and improve the model's\nfairness. Existing fairness testing approaches however have two major\nlimitations. Firstly, they only work well on traditional machine learning\nmodels and have poor performance (e.g., effectiveness and efficiency) on deep\nlearning models. Secondly, they only work on simple structured (e.g., tabular)\ndata and are not applicable for domains such as text. In this work, we bridge\nthe gap by proposing a scalable and effective approach for systematically\nsearching for discriminatory samples while extending existing fairness testing\napproaches to address a more challenging domain, i.e., text classification.\nCompared with state-of-the-art methods, our approach only employs lightweight\nprocedures like gradient computation and clustering, which is significantly\nmore scalable and effective. Experimental results show that on average, our\napproach explores the search space much more effectively (9.62 and 2.38 times\nmore than the state-of-the-art methods respectively on tabular and text\ndatasets) and generates much more discriminatory samples (24.95 and 2.68 times)\nwithin a same reasonable time. Moreover, the retrained models reduce\ndiscrimination by 57.2% and 60.2% respectively on average.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 03:47:08 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 05:09:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhang", "Peixin", ""], ["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Wang", "Xinyu", ""], ["Dong", "Guoliang", ""], ["Wang", "Xingen", ""], ["Dai", "Ting", ""], ["Dong", "Jin Song", ""]]}, {"id": "2107.08179", "submitter": "Panagiota Birmpa", "authors": "Panagiota Birmpa, Jinchao Feng, Markos A. Katsoulakis, Luc Rey-Bellet", "title": "Model Uncertainty and Correctability for Directed Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models are a fundamental tool in probabilistic\nmodeling, machine learning and artificial intelligence. They allow us to\nintegrate in a natural way expert knowledge, physical modeling, heterogeneous\nand correlated data and quantities of interest. For exactly this reason,\nmultiple sources of model uncertainty are inherent within the modular structure\nof the graphical model. In this paper we develop information-theoretic, robust\nuncertainty quantification methods and non-parametric stress tests for directed\ngraphical models to assess the effect and the propagation through the graph of\nmulti-sourced model uncertainties to quantities of interest. These methods\nallow us to rank the different sources of uncertainty and correct the graphical\nmodel by targeting its most impactful components with respect to the quantities\nof interest. Thus, from a machine learning perspective, we provide a\nmathematically rigorous approach to correctability that guarantees a systematic\nselection for improvement of components of a graphical model while controlling\npotential new errors created in the process in other parts of the model. We\ndemonstrate our methods in two physico-chemical examples, namely quantum\nscale-informed chemical kinetics and materials screening to improve the\nefficiency of fuel cells.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 04:30:37 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Birmpa", "Panagiota", ""], ["Feng", "Jinchao", ""], ["Katsoulakis", "Markos A.", ""], ["Rey-Bellet", "Luc", ""]]}, {"id": "2107.08183", "submitter": "JaeYoon Kim", "authors": "JaeYoon Kim, Junyu Xuan, Christy Liang and Farookh Hussain", "title": "Hierarchical Reinforcement Learning with Optimal Level Synchronization\n  based on a Deep Generative Model", "comments": "\"for associated code file, see\n  https://github.com/jangikim2/Hierarchical_Reinforcement_Learning\" Submitted\n  to IEEE Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The high-dimensional or sparse reward task of a reinforcement learning (RL)\nenvironment requires a superior potential controller such as hierarchical\nreinforcement learning (HRL) rather than an atomic RL because it absorbs the\ncomplexity of commands to achieve the purpose of the task in its hierarchical\nstructure. One of the HRL issues is how to train each level policy with the\noptimal data collection from its experience. That is to say, how to synchronize\nadjacent level policies optimally. Our research finds that a HRL model through\nthe off-policy correction technique of HRL, which trains a higher-level policy\nwith the goal of reflecting a lower-level policy which is newly trained using\nthe off-policy method, takes the critical role of synchronizing both level\npolicies at all times while they are being trained. We propose a novel HRL\nmodel supporting the optimal level synchronization using the off-policy\ncorrection technique with a deep generative model. This uses the advantage of\nthe inverse operation of a flow-based deep generative model (FDGM) to achieve\nthe goal corresponding to the current state of the lower-level policy. The\nproposed model also considers the freedom of the goal dimension between HRL\npolicies which makes it the generalized inverse model of the model-free RL in\nHRL with the optimal synchronization method. The comparative experiment results\nshow the performance of our proposed model.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 05:02:25 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kim", "JaeYoon", ""], ["Xuan", "Junyu", ""], ["Liang", "Christy", ""], ["Hussain", "Farookh", ""]]}, {"id": "2107.08189", "submitter": "Anand Avati", "authors": "Anand Avati, Martin Seneviratne, Emily Xue, Zhen Xu, Balaji\n  Lakshminarayanan and Andrew M. Dai", "title": "BEDS-Bench: Behavior of EHR-models under Distributional Shift--A\n  Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has recently demonstrated impressive progress in predictive\naccuracy across a wide array of tasks. Most ML approaches focus on\ngeneralization performance on unseen data that are similar to the training data\n(In-Distribution, or IND). However, real world applications and deployments of\nML rarely enjoy the comfort of encountering examples that are always IND. In\nsuch situations, most ML models commonly display erratic behavior on\nOut-of-Distribution (OOD) examples, such as assigning high confidence to wrong\npredictions, or vice-versa. Implications of such unusual model behavior are\nfurther exacerbated in the healthcare setting, where patient health can\npotentially be put at risk. It is crucial to study the behavior and robustness\nproperties of models under distributional shift, understand common failure\nmodes, and take mitigation steps before the model is deployed. Having a\nbenchmark that shines light upon these aspects of a model is a first and\nnecessary step in addressing the issue. Recent work and interest in increasing\nmodel robustness in OOD settings have focused more on image modality, while the\nElectronic Health Record (EHR) modality is still largely under-explored. We aim\nto bridge this gap by releasing BEDS-Bench, a benchmark for quantifying the\nbehavior of ML models over EHR data under OOD settings. We use two open access,\nde-identified EHR datasets to construct several OOD data settings to run tests\non, and measure relevant metrics that characterize crucial aspects of a model's\nOOD behavior. We evaluate several learning algorithms under BEDS-Bench and find\nthat all of them show poor generalization performance under distributional\nshift in general. Our results highlight the need and the potential to improve\nrobustness of EHR models under distributional shift, and BEDS-Bench provides\none way to measure progress towards that goal.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 05:53:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Avati", "Anand", ""], ["Seneviratne", "Martin", ""], ["Xue", "Emily", ""], ["Xu", "Zhen", ""], ["Lakshminarayanan", "Balaji", ""], ["Dai", "Andrew M.", ""]]}, {"id": "2107.08190", "submitter": "Maksim Eren", "authors": "Maksim E. Eren, Nick Solovyev, Chris Hamer, Renee McDonald, Boian S.\n  Alexandrov, Charles Nicholas", "title": "COVID-19 Multidimensional Kaggle Literature Organization", "comments": "Maksim E. Eren, Nick Solovyev, Chris Hamer, Renee McDonald, Boian\n  S.Alexandrov, and Charles Nicholas. 2021. COVID-19 Multidimensional Kaggle\n  Literature Organization. In ACM Symposium on Document Engineering 2021", "journal-ref": null, "doi": "10.1145/3469096.3474927", "report-no": null, "categories": "cs.LG cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unprecedented outbreak of Severe Acute Respiratory Syndrome Coronavirus-2\n(SARS-CoV-2), or COVID-19, continues to be a significant worldwide problem. As\na result, a surge of new COVID-19 related research has followed suit. The\ngrowing number of publications requires document organization methods to\nidentify relevant information. In this paper, we expand upon our previous work\nwith clustering the CORD-19 dataset by applying multi-dimensional analysis\nmethods. Tensor factorization is a powerful unsupervised learning method\ncapable of discovering hidden patterns in a document corpus. We show that a\nhigher-order representation of the corpus allows for the simultaneous grouping\nof similar articles, relevant journals, authors with similar research\ninterests, and topic keywords. These groupings are identified within and among\nthe latent components extracted via tensor decomposition. We further\ndemonstrate the application of this method with a publicly available\ninteractive visualization of the dataset.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 06:16:36 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 01:59:41 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Eren", "Maksim E.", ""], ["Solovyev", "Nick", ""], ["Hamer", "Chris", ""], ["McDonald", "Renee", ""], ["Alexandrov", "Boian S.", ""], ["Nicholas", "Charles", ""]]}, {"id": "2107.08194", "submitter": "Abhishek Dandekar", "authors": "Abhishek Dandekar", "title": "Towards autonomic orchestration of machine learning pipelines in future\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML) techniques are being increasingly used in mobile\nnetworks for network planning, operation, management, optimisation and much\nmore. These techniques are realised using a set of logical nodes known as ML\npipeline. A single network operator might have thousands of such ML pipelines\ndistributed across its network. These pipelines need to be managed and\norchestrated across network domains. Thus it is essential to have autonomic\nmulti-domain orchestration of ML pipelines in mobile networks. International\nTelecommunications Union (ITU) has provided an architectural framework for\nmanagement and orchestration of ML pipelines in future networks. We extend this\nframework to enable autonomic orchestration of ML pipelines across multiple\nnetwork domains. We present our system architecture and describe its\napplication using a smart factory use case. Our work allows autonomic\norchestration of multi-domain ML pipelines in a standardised, technology\nagnostic, privacy preserving fashion.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 06:52:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dandekar", "Abhishek", ""]]}, {"id": "2107.08195", "submitter": "Jiahua Luo", "authors": "Jiahua Luo (1), Chi-Man Vong (1) and Jie Du (2) ((1) Department of\n  Computer and Information Science, University of Macau, Macao SAR, China, (2)\n  School of Biomedical Engineering, Health Science Center, Shenzhen University,\n  Shenzhen, China)", "title": "Sparse Bayesian Learning with Diagonal Quasi-Newton Method For Large\n  Scale Classification", "comments": "11 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Sparse Bayesian Learning (SBL) constructs an extremely sparse probabilistic\nmodel with very competitive generalization. However, SBL needs to invert a big\ncovariance matrix with complexity O(M^3 ) (M: feature size) for updating the\nregularization priors, making it difficult for practical use. There are three\nissues in SBL: 1) Inverting the covariance matrix may obtain singular solutions\nin some cases, which hinders SBL from convergence; 2) Poor scalability to\nproblems with high dimensional feature space or large data size; 3) SBL easily\nsuffers from memory overflow for large-scale data. This paper addresses these\nissues with a newly proposed diagonal Quasi-Newton (DQN) method for SBL called\nDQN-SBL where the inversion of big covariance matrix is ignored so that the\ncomplexity and memory storage are reduced to O(M). The DQN-SBL is thoroughly\nevaluated on non-linear classifiers and linear feature selection using various\nbenchmark datasets of different sizes. Experimental results verify that DQN-SBL\nreceives competitive generalization with a very sparse model and scales well to\nlarge-scale problems.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 06:55:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Luo", "Jiahua", ""], ["Vong", "Chi-Man", ""], ["Du", "Jie", ""]]}, {"id": "2107.08199", "submitter": "Lei Xun", "authors": "Hishan Parry, Lei Xun, Amin Sabet, Jia Bi, Jonathon Hare, Geoff V.\n  Merrett", "title": "Dynamic Transformer for Efficient Machine Translation on Embedded\n  Devices", "comments": "Accepted at MLCAD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Transformer architecture is widely used for machine translation tasks.\nHowever, its resource-intensive nature makes it challenging to implement on\nconstrained embedded devices, particularly where available hardware resources\ncan vary at run-time. We propose a dynamic machine translation model that\nscales the Transformer architecture based on the available resources at any\nparticular time. The proposed approach, 'Dynamic-HAT', uses a HAT\nSuperTransformer as the backbone to search for SubTransformers with different\naccuracy-latency trade-offs at design time. The optimal SubTransformers are\nsampled from the SuperTransformer at run-time, depending on latency\nconstraints. The Dynamic-HAT is tested on the Jetson Nano and the approach uses\ninherited SubTransformers sampled directly from the SuperTransformer with a\nswitching time of <1s. Using inherited SubTransformers results in a BLEU score\nloss of <1.5% because the SubTransformer configuration is not retrained from\nscratch after sampling. However, to recover this loss in performance, the\ndimensions of the design space can be reduced to tailor it to a family of\ntarget hardware. The new reduced design space results in a BLEU score increase\nof approximately 1% for sub-optimal models from the original design space, with\na wide range for performance scaling between 0.356s - 1.526s for the GPU and\n2.9s - 7.31s for the CPU.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 07:36:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Parry", "Hishan", ""], ["Xun", "Lei", ""], ["Sabet", "Amin", ""], ["Bi", "Jia", ""], ["Hare", "Jonathon", ""], ["Merrett", "Geoff V.", ""]]}, {"id": "2107.08209", "submitter": "Dirk Tasche", "authors": "Dirk Tasche", "title": "Minimising quantifier variance under prior probability shift", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the binary prevalence quantification problem under prior probability\nshift, we determine the asymptotic variance of the maximum likelihood\nestimator. We find that it is a function of the Brier score for the regression\nof the class label against the features under the test data set distribution.\nThis observation suggests that optimising the accuracy of a base classifier on\nthe training data set helps to reduce the variance of the related quantifier on\nthe test data set. Therefore, we also point out training criteria for the base\nclassifier that imply optimisation of both of the Brier scores on the training\nand the test data sets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 09:28:06 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 19:31:37 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tasche", "Dirk", ""]]}, {"id": "2107.08211", "submitter": "Soumyadeep Ghosh", "authors": "Soumyadeep Ghosh, Sanjay Kumar, Janu Verma and Awanish Kumar", "title": "Self Training with Ensemble of Teacher Models", "comments": null, "journal-ref": "IJCAI 2021 Workshop on Weakly Supervised Representation Learning", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to train robust deep learning models, large amounts of labelled data\nis required. However, in the absence of such large repositories of labelled\ndata, unlabeled data can be exploited for the same. Semi-Supervised learning\naims to utilize such unlabeled data for training classification models. Recent\nprogress of self-training based approaches have shown promise in this area,\nwhich leads to this study where we utilize an ensemble approach for the same. A\nby-product of any semi-supervised approach may be loss of calibration of the\ntrained model especially in scenarios where unlabeled data may contain\nout-of-distribution samples, which leads to this investigation on how to adapt\nto such effects. Our proposed algorithm carefully avoids common pitfalls in\nutilizing unlabeled data and leads to a more accurate and calibrated supervised\nmodel compared to vanilla self-training based student-teacher algorithms. We\nperform several experiments on the popular STL-10 database followed by an\nextensive analysis of our approach and study its effects on model accuracy and\ncalibration.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 09:44:09 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ghosh", "Soumyadeep", ""], ["Kumar", "Sanjay", ""], ["Verma", "Janu", ""], ["Kumar", "Awanish", ""]]}, {"id": "2107.08212", "submitter": "Xuebo Liu", "authors": "Xuebo Liu, Longyue Wang, Derek F. Wong, Liang Ding, Lidia S. Chao,\n  Shuming Shi, Zhaopeng Tu", "title": "On the Copying Behaviors of Pre-Training for Neural Machine Translation", "comments": "Accepted to Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous studies have shown that initializing neural machine translation\n(NMT) models with the pre-trained language models (LM) can speed up the model\ntraining and boost the model performance. In this work, we identify a critical\nside-effect of pre-training for NMT, which is due to the discrepancy between\nthe training objectives of LM-based pre-training and NMT. Since the LM\nobjective learns to reconstruct a few source tokens and copy most of them, the\npre-training initialization would affect the copying behaviors of NMT models.\nWe provide a quantitative analysis of copying behaviors by introducing a metric\ncalled copying ratio, which empirically shows that pre-training based NMT\nmodels have a larger copying ratio than the standard one. In response to this\nproblem, we propose a simple and effective method named copying penalty to\ncontrol the copying behaviors in decoding. Extensive experiments on both\nin-domain and out-of-domain benchmarks show that the copying penalty method\nconsistently improves translation performance by controlling copying behaviors\nfor pre-training based NMT models. Source code is freely available at\nhttps://github.com/SunbowLiu/CopyingPenalty.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 10:02:30 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Xuebo", ""], ["Wang", "Longyue", ""], ["Wong", "Derek F.", ""], ["Ding", "Liang", ""], ["Chao", "Lidia S.", ""], ["Shi", "Shuming", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2107.08221", "submitter": "Lukas Schott", "authors": "Lukas Schott, Julius von K\\\"ugelgen, Frederik Tr\\\"auble, Peter Gehler,\n  Chris Russell, Matthias Bethge, Bernhard Sch\\\"olkopf, Francesco Locatello,\n  Wieland Brendel", "title": "Visual Representation Learning Does Not Generalize Strongly Within the\n  Same Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important component for generalization in machine learning is to uncover\nunderlying latent factors of variation as well as the mechanism through which\neach factor acts in the world. In this paper, we test whether 17 unsupervised,\nweakly supervised, and fully supervised representation learning approaches\ncorrectly infer the generative factors of variation in simple datasets\n(dSprites, Shapes3D, MPI3D). In contrast to prior robustness work that\nintroduces novel factors of variation during test time, such as blur or other\n(un)structured noise, we here recompose, interpolate, or extrapolate only\nexisting factors of variation from the training data set (e.g., small and\nmedium-sized objects during training and large objects during testing). Models\nthat learn the correct mechanism should be able to generalize to this\nbenchmark. In total, we train and test 2000+ models and observe that all of\nthem struggle to learn the underlying mechanism regardless of supervision\nsignal and architectural bias. Moreover, the generalization capabilities of all\ntested models drop significantly as we move from artificial datasets towards\nmore realistic real-world datasets. Despite their inability to identify the\ncorrect mechanism, the models are quite modular as their ability to infer other\nin-distribution factors remains fairly stable, providing only a single factor\nis out-of-distribution. These results point to an important yet understudied\nproblem of learning mechanistic models of observations that can facilitate\ngeneralization.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 11:24:18 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 06:48:42 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Schott", "Lukas", ""], ["von K\u00fcgelgen", "Julius", ""], ["Tr\u00e4uble", "Frederik", ""], ["Gehler", "Peter", ""], ["Russell", "Chris", ""], ["Bethge", "Matthias", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Locatello", "Francesco", ""], ["Brendel", "Wieland", ""]]}, {"id": "2107.08225", "submitter": "Michael Muehlebach", "authors": "Michael Muehlebach and Michael I. Jordan", "title": "On Constraints in First-Order Optimization: A View from Non-Smooth\n  Dynamical Systems", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a class of first-order methods for smooth constrained\noptimization that are based on an analogy to non-smooth dynamical systems. Two\ndistinctive features of our approach are that (i) projections or optimizations\nover the entire feasible set are avoided, in stark contrast to projected\ngradient methods or the Frank-Wolfe method, and (ii) iterates are allowed to\nbecome infeasible, which differs from active set or feasible direction methods,\nwhere the descent motion stops as soon as a new constraint is encountered. The\nresulting algorithmic procedure is simple to implement even when constraints\nare nonlinear, and is suitable for large-scale constrained optimization\nproblems in which the feasible set fails to have a simple structure. The key\nunderlying idea is that constraints are expressed in terms of velocities\ninstead of positions, which has the algorithmic consequence that optimizations\nover feasible sets at each iteration are replaced with optimizations over\nlocal, sparse convex approximations. The result is a simplified suite of\nalgorithms and an expanded range of possible applications in machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 11:45:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Muehlebach", "Michael", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2107.08241", "submitter": "Aske Plaat", "authors": "Aske Plaat and Walter Kosters and Mike Preuss", "title": "High-Accuracy Model-Based Reinforcement Learning, a Survey", "comments": "arXiv admin note: text overlap with arXiv:2008.05598", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep reinforcement learning has shown remarkable success in the past few\nyears. Highly complex sequential decision making problems from game playing and\nrobotics have been solved with deep model-free methods. Unfortunately, the\nsample complexity of model-free methods is often high. To reduce the number of\nenvironment samples, model-based reinforcement learning creates an explicit\nmodel of the environment dynamics. Achieving high model accuracy is a challenge\nin high-dimensional problems. In recent years, a diverse landscape of\nmodel-based methods has been introduced to improve model accuracy, using\nmethods such as uncertainty modeling, model-predictive control, latent models,\nand end-to-end learning and planning. Some of these methods succeed in\nachieving high accuracy at low sample complexity, most do so either in a\nrobotics or in a games context. In this paper, we survey these methods; we\nexplain in detail how they work and what their strengths and weaknesses are. We\nconclude with a research agenda for future work to make the methods more robust\nand more widely applicable to other applications.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 14:01:05 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Plaat", "Aske", ""], ["Kosters", "Walter", ""], ["Preuss", "Mike", ""]]}, {"id": "2107.08248", "submitter": "Jack Weston", "authors": "Jack Weston, Raphael Lenain, Udeepa Meepegama and Emil Fristed", "title": "Learning De-identified Representations of Prosody from Raw Audio", "comments": "ICML 2021", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, ICML 2021, 18-24 July 2021, Virtual Event. Proceedings of Machine\n  Learning Research 139, PMLR 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a method for learning de-identified prosody representations from\nraw audio using a contrastive self-supervised signal. Whereas prior work has\nrelied on conditioning models on bottlenecks, we introduce a set of inductive\nbiases that exploit the natural structure of prosody to minimize timbral\ninformation and decouple prosody from speaker representations. Despite\naggressive downsampling of the input and having no access to linguistic\ninformation, our model performs comparably to state-of-the-art speech\nrepresentations on DAMMP, a new benchmark we introduce for spoken language\nunderstanding. We use minimum description length probing to show that our\nrepresentations have selectively learned the subcomponents of non-timbral\nprosody, and that the product quantizer naturally disentangles them without\nusing bottlenecks. We derive an information-theoretic definition of speech\nde-identifiability and use it to demonstrate that our prosody representations\nare less identifiable than other speech representations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 14:37:25 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Weston", "Jack", ""], ["Lenain", "Raphael", ""], ["Meepegama", "Udeepa", ""], ["Fristed", "Emil", ""]]}, {"id": "2107.08249", "submitter": "Jie Luo", "authors": "Jie Luo, Jakub M. Tomczak, Agoston E. Eiben", "title": "The Effects of Learning in Morphologically Evolving Robot Systems", "comments": "9 pages, 11 figures, IEEE SSCI conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When controllers (brains) and morphologies (bodies) of robots simultaneously\nevolve, this can lead to a problem, namely the brain & body mismatch problem.\nIn this research, we propose a solution of lifetime learning. We set up a\nsystem where modular robots can create offspring that inherit the bodies of\nparents by recombination and mutation. With regards to the brains of the\noffspring, we use two methods to create them. The first one entails solely\nevolution which means the brain of a robot child is inherited from its parents.\nThe second approach is evolution plus learning which means the brain of a child\nis inherited as well, but additionally is developed by a learning algorithm -\nRevDEknn. We compare these two methods by running experiments in a simulator\ncalled Revolve and use efficiency, efficacy, and the morphology intelligence of\nthe robots for the comparison. The experiments show that the evolution plus\nlearning method does not only lead to a higher fitness level, but also to more\nmorphologically evolving robots. This constitutes a quantitative demonstration\nthat changes in the brain can induce changes in the body, leading to the\nconcept of morphological intelligence, which is quantified by the learning\ndelta, meaning the ability of a morphology to facilitate learning.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 14:38:26 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Luo", "Jie", ""], ["Tomczak", "Jakub M.", ""], ["Eiben", "Agoston E.", ""]]}, {"id": "2107.08251", "submitter": "Jack Weston", "authors": "Jack Weston, Raphael Lenain, Udeepa Meepegama and Emil Fristed", "title": "Generative Pretraining for Paraphrase Evaluation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce ParaBLEU, a paraphrase representation learning model and\nevaluation metric for text generation. Unlike previous approaches, ParaBLEU\nlearns to understand paraphrasis using generative conditioning as a pretraining\nobjective. ParaBLEU correlates more strongly with human judgements than\nexisting metrics, obtaining new state-of-the-art results on the 2017 WMT\nMetrics Shared Task. We show that our model is robust to data scarcity,\nexceeding previous state-of-the-art performance using only $50\\%$ of the\navailable training data and surpassing BLEU, ROUGE and METEOR with only $40$\nlabelled examples. Finally, we demonstrate that ParaBLEU can be used to\nconditionally generate novel paraphrases from a single demonstration, which we\nuse to confirm our hypothesis that it learns abstract, generalized paraphrase\nrepresentations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 14:48:48 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 10:48:49 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Weston", "Jack", ""], ["Lenain", "Raphael", ""], ["Meepegama", "Udeepa", ""], ["Fristed", "Emil", ""]]}, {"id": "2107.08264", "submitter": "Xingbo Wang", "authors": "Xingbo Wang, Jianben He, Zhihua Jin, Muqiao Yang, Yong Wang, Huamin Qu", "title": "M2Lens: Visualizing and Explaining Multimodal Models for Sentiment\n  Analysis", "comments": "11 pages, 7 figures. This paper is accepted by IEEE VIS, 2021. To\n  appear in IEEE Transactions on Visualization and Computer Graphics (TVCG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal sentiment analysis aims to recognize people's attitudes from\nmultiple communication channels such as verbal content (i.e., text), voice, and\nfacial expressions. It has become a vibrant and important research topic in\nnatural language processing. Much research focuses on modeling the complex\nintra- and inter-modal interactions between different communication channels.\nHowever, current multimodal models with strong performance are often\ndeep-learning-based techniques and work like black boxes. It is not clear how\nmodels utilize multimodal information for sentiment predictions. Despite recent\nadvances in techniques for enhancing the explainability of machine learning\nmodels, they often target unimodal scenarios (e.g., images, sentences), and\nlittle research has been done on explaining multimodal models. In this paper,\nwe present an interactive visual analytics system, M2Lens, to visualize and\nexplain multimodal models for sentiment analysis. M2Lens provides explanations\non intra- and inter-modal interactions at the global, subset, and local levels.\nSpecifically, it summarizes the influence of three typical interaction types\n(i.e., dominance, complement, and conflict) on the model predictions. Moreover,\nM2Lens identifies frequent and influential multimodal features and supports the\nmulti-faceted exploration of model behaviors from language, acoustic, and\nvisual modalities. Through two case studies and expert interviews, we\ndemonstrate our system can help users gain deep insights into the multimodal\nmodels for sentiment analysis.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 15:54:27 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 02:20:19 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wang", "Xingbo", ""], ["He", "Jianben", ""], ["Jin", "Zhihua", ""], ["Yang", "Muqiao", ""], ["Wang", "Yong", ""], ["Qu", "Huamin", ""]]}, {"id": "2107.08265", "submitter": "P.K. Srijith", "authors": "Ayush Jain (1), P. K. Srijith (1) and Mohammad Emtiyaz Khan (2) ((1)\n  Department of Computer Science and Engineering, Indian Institute of\n  Technology Hyderabad, India, (2) RIKEN Center for AI Project, Tokyo, Japan)", "title": "Subset-of-Data Variational Inference for Deep Gaussian-Processes\n  Regression", "comments": "Accepted in the 37th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian Processes (DGPs) are multi-layer, flexible extensions of\nGaussian processes but their training remains challenging. Sparse\napproximations simplify the training but often require optimization over a\nlarge number of inducing inputs and their locations across layers. In this\npaper, we simplify the training by setting the locations to a fixed subset of\ndata and sampling the inducing inputs from a variational distribution. This\nreduces the trainable parameters and computation cost without significant\nperformance degradations, as demonstrated by our empirical results on\nregression problems. Our modifications simplify and stabilize DGP training\nwhile making it amenable to sampling schemes for setting the inducing inputs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 15:55:35 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jain", "Ayush", ""], ["Srijith", "P. K.", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2107.08273", "submitter": "Hengguan Huang", "authors": "Hengguan Huang, Hongfu Liu, Hao Wang, Chang Xiao and Ye Wang", "title": "STRODE: Stochastic Boundary Ordinary Differential Equation", "comments": "Accepted at ICML 2021; typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perception of time from sequentially acquired sensory inputs is rooted in\neveryday behaviors of individual organisms. Yet, most algorithms for\ntime-series modeling fail to learn dynamics of random event timings directly\nfrom visual or audio inputs, requiring timing annotations during training that\nare usually unavailable for real-world applications. For instance, neuroscience\nperspectives on postdiction imply that there exist variable temporal ranges\nwithin which the incoming sensory inputs can affect the earlier perception, but\nsuch temporal ranges are mostly unannotated for real applications such as\nautomatic speech recognition (ASR). In this paper, we present a probabilistic\nordinary differential equation (ODE), called STochastic boundaRy ODE (STRODE),\nthat learns both the timings and the dynamics of time series data without\nrequiring any timing annotations during training. STRODE allows the usage of\ndifferential equations to sample from the posterior point processes,\nefficiently and analytically. We further provide theoretical guarantees on the\nlearning of STRODE. Our empirical results show that our approach successfully\ninfers event timings of time series data. Our method achieves competitive or\nsuperior performances compared to existing state-of-the-art methods for both\nsynthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 16:25:46 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Huang", "Hengguan", ""], ["Liu", "Hongfu", ""], ["Wang", "Hao", ""], ["Xiao", "Chang", ""], ["Wang", "Ye", ""]]}, {"id": "2107.08277", "submitter": "Evangelia Gergatsouli", "authors": "Dimitris Fotakis, Evangelia Gergatsouli, Themis Gouleakis, Nikolas\n  Patris", "title": "Learning Augmented Online Facility Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the research agenda initiated by Munoz & Vassilvitskii [1] and\nLykouris & Vassilvitskii [2] on learning-augmented online algorithms for\nclassical online optimization problems, in this work, we consider the Online\nFacility Location problem under this framework. In Online Facility Location\n(OFL), demands arrive one-by-one in a metric space and must be (irrevocably)\nassigned to an open facility upon arrival, without any knowledge about future\ndemands.\n  We present an online algorithm for OFL that exploits potentially imperfect\npredictions on the locations of the optimal facilities. We prove that the\ncompetitive ratio decreases smoothly from sublogarithmic in the number of\ndemands to constant, as the error, i.e., the total distance of the predicted\nlocations to the optimal facility locations, decreases towards zero. We\ncomplement our analysis with a matching lower bound establishing that the\ndependence of the algorithm's competitive ratio on the error is optimal, up to\nconstant factors. Finally, we evaluate our algorithm on real world data and\ncompare our learning augmented approach with the current best online algorithm\nfor the problem.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 16:44:27 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Fotakis", "Dimitris", ""], ["Gergatsouli", "Evangelia", ""], ["Gouleakis", "Themis", ""], ["Patris", "Nikolas", ""]]}, {"id": "2107.08285", "submitter": "Alan Chan", "authors": "Alan Chan, Hugo Silva, Sungsu Lim, Tadashi Kozuno, A. Rupam Mahmood,\n  Martha White", "title": "Greedification Operators for Policy Optimization: Investigating Forward\n  and Reverse KL Divergences", "comments": "Submitted to JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Policy Iteration (API) algorithms alternate between (approximate)\npolicy evaluation and (approximate) greedification. Many different approaches\nhave been explored for approximate policy evaluation, but less is understood\nabout approximate greedification and what choices guarantee policy improvement.\nIn this work, we investigate approximate greedification when reducing the KL\ndivergence between the parameterized policy and the Boltzmann distribution over\naction values. In particular, we investigate the difference between the forward\nand reverse KL divergences, with varying degrees of entropy regularization. We\nshow that the reverse KL has stronger policy improvement guarantees, but that\nreducing the forward KL can result in a worse policy. We also demonstrate,\nhowever, that a large enough reduction of the forward KL can induce improvement\nunder additional assumptions. Empirically, we show on simple continuous-action\nenvironments that the forward KL can induce more exploration, but at the cost\nof a more suboptimal policy. No significant differences were observed in the\ndiscrete-action setting or on a suite of benchmark problems. Throughout, we\nhighlight that many policy gradient methods can be seen as an instance of API,\nwith either the forward or reverse KL for the policy update, and discuss next\nsteps for understanding and improving our policy optimization algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 17:09:18 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chan", "Alan", ""], ["Silva", "Hugo", ""], ["Lim", "Sungsu", ""], ["Kozuno", "Tadashi", ""], ["Mahmood", "A. Rupam", ""], ["White", "Martha", ""]]}, {"id": "2107.08293", "submitter": "Ekram Hossain", "authors": "Amal Feriani, Amine Mezghani, and Ekram Hossain", "title": "On the Robustness of Deep Reinforcement Learning in IRS-Aided Wireless\n  Communications Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We consider an Intelligent Reflecting Surface (IRS)-aided multiple-input\nsingle-output (MISO) system for downlink transmission. We compare the\nperformance of Deep Reinforcement Learning (DRL) and conventional optimization\nmethods in finding optimal phase shifts of the IRS elements to maximize the\nuser signal-to-noise (SNR) ratio. Furthermore, we evaluate the robustness of\nthese methods to channel impairments and changes in the system. We demonstrate\nnumerically that DRL solutions show more robustness to noisy channels and user\nmobility.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 17:42:25 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 15:22:00 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Feriani", "Amal", ""], ["Mezghani", "Amine", ""], ["Hossain", "Ekram", ""]]}, {"id": "2107.08310", "submitter": "Zhe Yu", "authors": "Zhe Yu", "title": "Fair Balance: Mitigating Machine Learning Bias Against Multiple\n  Protected Attributes With Data Balancing", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to improve machine learning fairness on multiple protected\nat-tributes. Machine learning fairness has attracted increasing attention since\nmachine learning models are increasingly used for high-stakes and high-risk\ndecisions. Most existing solutions for machine learning fairness only target\none protected attribute(e.g. sex) at a time. These solutions cannot generate a\nmachine learning model which is fair against every protected attribute (e.g.\nboth sex and race) at the same time. To solve this problem, we propose\nFairBalance in this paper to balance the distribution of training data across\nevery protected attribute before training the machine learning models. Our\nresults show that, under the assumption of unbiased ground truth labels,\nFairBalance can significantly reduce bias metrics (AOD, EOD, and SPD) on every\nknown protected attribute without much, if not any damage to the prediction\nperformance.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 20:40:45 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yu", "Zhe", ""]]}, {"id": "2107.08319", "submitter": "Karishma Sharma", "authors": "Karishma Sharma and Emilio Ferrara and Yan Liu", "title": "Characterizing Online Engagement with Disinformation and Conspiracies in\n  the 2020 U.S. Presidential Election", "comments": "Accepted at ICWSM'22", "journal-ref": "ICWSM 2022", "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying and characterizing disinformation in political discourse on\nsocial media is critical to ensure the integrity of elections and democratic\nprocesses around the world. Persistent manipulation of social media has\nresulted in increased concerns regarding the 2020 U.S. Presidential Election,\ndue to its potential to influence individual opinions and social dynamics. In\nthis work, we focus on the identification of distorted facts, in the form of\nunreliable and conspiratorial narratives in election-related tweets, to\ncharacterize discourse manipulation prior to the election. We apply a detection\nmodel to separate factual from unreliable (or conspiratorial) claims analyzing\na dataset of 242 million election-related tweets. The identified claims are\nused to investigate targeted topics of disinformation, and conspiracy groups,\nmost notably the far-right QAnon conspiracy group. Further, we characterize\naccount engagements with unreliable and conspiracy tweets, and with the QAnon\nconspiracy group, by political leaning and tweet types. Finally, using a\nregression discontinuity design, we investigate whether Twitter's actions to\ncurb QAnon activity on the platform were effective, and how QAnon accounts\nadapt to Twitter's restrictions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 22:11:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sharma", "Karishma", ""], ["Ferrara", "Emilio", ""], ["Liu", "Yan", ""]]}, {"id": "2107.08326", "submitter": "Teresa Ludermir", "authors": "Anderson da Silva, Teresa Ludermir", "title": "Otimizacao de Redes Neurais atraves de Algoritmos Geneticos Celulares", "comments": "35 pages, in Portuguese, 4 figures, 7 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This works proposes a methodology to searching for automatically Artificial\nNeural Networks (ANN) by using Cellular Genetic Algorithm (CGA). The goal of\nthis methodology is to find compact networks whit good performance for\nclassification problems. The main reason for developing this work is centered\nat the difficulties of configuring compact ANNs with good performance rating.\nThe use of CGAs aims at seeking the components of the RNA in the same way that\na common Genetic Algorithm (GA), but it has the differential of incorporating a\nCellular Automaton (CA) to give location for the GA individuals. The location\nimposed by the CA aims to control the spread of solutions in the populations to\nmaintain the genetic diversity for longer time. This genetic diversity is\nimportant for obtain good results with the GAs.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 00:10:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["da Silva", "Anderson", ""], ["Ludermir", "Teresa", ""]]}, {"id": "2107.08346", "submitter": "Chen-Yu Wei", "authors": "Haipeng Luo, Chen-Yu Wei, Chung-Wei Lee", "title": "Policy Optimization in Adversarial MDPs: Improved Exploration via\n  Dilated Bonuses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Policy optimization is a widely-used method in reinforcement learning. Due to\nits local-search nature, however, theoretical guarantees on global optimality\noften rely on extra assumptions on the Markov Decision Processes (MDPs) that\nbypass the challenge of global exploration. To eliminate the need of such\nassumptions, in this work, we develop a general solution that adds dilated\nbonuses to the policy update to facilitate global exploration. To showcase the\npower and generality of this technique, we apply it to several episodic MDP\nsettings with adversarial losses and bandit feedback, improving and\ngeneralizing the state-of-the-art. Specifically, in the tabular case, we obtain\n$\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret where $T$ is the number of episodes,\nimproving the $\\widetilde{\\mathcal{O}}({T}^{2/3})$ regret bound by Shani et al.\n(2020). When the number of states is infinite, under the assumption that the\nstate-action values are linear in some low-dimensional features, we obtain\n$\\widetilde{\\mathcal{O}}({T}^{2/3})$ regret with the help of a simulator,\nmatching the result of Neu and Olkhovskaya (2020) while importantly removing\nthe need of an exploratory policy that their algorithm requires. When a\nsimulator is unavailable, we further consider a linear MDP setting and obtain\n$\\widetilde{\\mathcal{O}}({T}^{14/15})$ regret, which is the first result for\nlinear MDPs with adversarial losses and bandit feedback.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 02:30:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Luo", "Haipeng", ""], ["Wei", "Chen-Yu", ""], ["Lee", "Chung-Wei", ""]]}, {"id": "2107.08353", "submitter": "Chirag Gupta", "authors": "Chirag Gupta and Aaditya K. Ramdas", "title": "Top-label calibration", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of post-hoc calibration for multiclass classification,\nwith an emphasis on histogram binning. Multiple works have focused on\ncalibration with respect to the confidence of just the predicted class (or\n'top-label'). We find that the popular notion of confidence calibration [Guo et\nal., 2017] is not sufficiently strong -- there exist predictors that are not\ncalibrated in any meaningful way but are perfectly confidence calibrated. We\npropose a closely related (but subtly different) notion, top-label calibration,\nthat accurately captures the intuition and simplicity of confidence\ncalibration, but addresses its drawbacks. We formalize a histogram binning (HB)\nalgorithm that reduces top-label multiclass calibration to the binary case,\nprove that it has clean theoretical guarantees without distributional\nassumptions, and perform a methodical study of its practical performance. Some\nprediction tasks require stricter notions of multiclass calibration such as\nclass-wise or canonical calibration. We formalize appropriate HB algorithms\ncorresponding to each of these goals. In experiments with deep neural nets, we\nfind that our principled versions of HB are often better than temperature\nscaling, for both top-label and class-wise calibration. Code for this work will\nbe made publicly available at https://github.com/aigen/df-posthoc-calibration.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 03:27:50 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Ramdas", "Aaditya K.", ""]]}, {"id": "2107.08356", "submitter": "Xingbo Wang", "authors": "Xingbo Wang, Yao Ming, Tongshuang Wu, Haipeng Zeng, Yong Wang, Huamin\n  Qu", "title": "DeHumor: Visual Analytics for Decomposing Humor", "comments": "15 pages. A preprint version of a publication at IEEE Transactions on\n  Visualization and Computer Graphics (TVCG), 2021", "journal-ref": null, "doi": "10.1109/TVCG.2021.3097709", "report-no": null, "categories": "cs.CL cs.HC cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being a critical communication skill, grasping humor is challenging\n-- a successful use of humor requires a mixture of both engaging content\nbuild-up and an appropriate vocal delivery (e.g., pause). Prior studies on\ncomputational humor emphasize the textual and audio features immediately next\nto the punchline, yet overlooking longer-term context setup. Moreover, the\ntheories are usually too abstract for understanding each concrete humor\nsnippet. To fill in the gap, we develop DeHumor, a visual analytical system for\nanalyzing humorous behaviors in public speaking. To intuitively reveal the\nbuilding blocks of each concrete example, DeHumor decomposes each humorous\nvideo into multimodal features and provides inline annotations of them on the\nvideo script. In particular, to better capture the build-ups, we introduce\ncontent repetition as a complement to features introduced in theories of\ncomputational humor and visualize them in a context linking graph. To help\nusers locate the punchlines that have the desired features to learn, we\nsummarize the content (with keywords) and humor feature statistics on an\naugmented time matrix. With case studies on stand-up comedy shows and TED\ntalks, we show that DeHumor is able to highlight various building blocks of\nhumor examples. In addition, expert interviews with communication coaches and\nhumor researchers demonstrate the effectiveness of DeHumor for multimodal humor\nanalysis of speech content and vocal delivery.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:01:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Xingbo", ""], ["Ming", "Yao", ""], ["Wu", "Tongshuang", ""], ["Zeng", "Haipeng", ""], ["Wang", "Yong", ""], ["Qu", "Huamin", ""]]}, {"id": "2107.08362", "submitter": "Bing Sun", "authors": "Bing Sun, Jun Sun, Ting Dai, Lijun Zhang", "title": "Probabilistic Verification of Neural Networks Against Group Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is crucial for neural networks which are used in applications with\nimportant societal implication. Recently, there have been multiple attempts on\nimproving fairness of neural networks, with a focus on fairness testing (e.g.,\ngenerating individual discriminatory instances) and fairness training (e.g.,\nenhancing fairness through augmented training). In this work, we propose an\napproach to formally verify neural networks against fairness, with a focus on\nindependence-based fairness such as group fairness. Our method is built upon an\napproach for learning Markov Chains from a user-provided neural network (i.e.,\na feed-forward neural network or a recurrent neural network) which is\nguaranteed to facilitate sound analysis. The learned Markov Chain not only\nallows us to verify (with Probably Approximate Correctness guarantee) whether\nthe neural network is fair or not, but also facilities sensitivity analysis\nwhich helps to understand why fairness is violated. We demonstrate that with\nour analysis results, the neural weights can be optimized to improve fairness.\nOur approach has been evaluated with multiple models trained on benchmark\ndatasets and the experiment results show that our approach is effective and\nefficient.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:34:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sun", "Bing", ""], ["Sun", "Jun", ""], ["Dai", "Ting", ""], ["Zhang", "Lijun", ""]]}, {"id": "2107.08364", "submitter": "Triet Le", "authors": "Triet H. M. Le, Huaming Chen, M. Ali Babar", "title": "A Survey on Data-driven Software Vulnerability Assessment and\n  Prioritization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software Vulnerabilities (SVs) are increasing in complexity and scale, posing\ngreat security risks to many software systems. Given the limited resources in\npractice, SV assessment and prioritization help practitioners devise optimal SV\nmitigation plans based on various SV characteristics. The surge in SV data\nsources and data-driven techniques such as Machine Learning and Deep Learning\nhave taken SV assessment and prioritization to the next level. Our survey\nprovides a taxonomy of the past research efforts and highlights the best\npractices for data-driven SV assessment and prioritization. We also discuss the\ncurrent limitations and propose potential solutions to address such issues.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:49:22 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 05:28:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Le", "Triet H. M.", ""], ["Chen", "Huaming", ""], ["Babar", "M. Ali", ""]]}, {"id": "2107.08369", "submitter": "Siddha Ganju", "authors": "Sayak Paul and Siddha Ganju", "title": "Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised\n  Learning", "comments": "Equal authorship. This is a work in progress and is a submission to\n  the Emerging Techniques in Computational Intelligence (ETCI) competition on\n  Flood Detection. Code and models are available on GitHub", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Floods wreak havoc throughout the world, causing billions of dollars in\ndamages, and uprooting communities, ecosystems and economies. Accurate and\nrobust flood detection including delineating open water flood areas and\nidentifying flood levels can aid in disaster response and mitigation. However,\nestimating flood levels remotely is of essence as physical access to flooded\nareas is limited and the ability to deploy instruments in potential flood zones\ncan be dangerous. Aligning flood extent mapping with local topography can\nprovide a plan-of-action that the disaster response team can consider. Thus,\nremote flood level estimation via satellites like Sentinel-1 can prove to be\nremedial. The Emerging Techniques in Computational Intelligence (ETCI)\ncompetition on Flood Detection tasked participants with predicting flooded\npixels after training with synthetic aperture radar (SAR) images in a\nsupervised setting. We use a cyclical approach involving two stages (1)\ntraining an ensemble model of multiple UNet architectures with available high\nand low confidence labeled data and, (2) generating pseudo labels or low\nconfidence labels on the unlabeled test dataset, and then, combining the\ngenerated labels with the previously available high confidence labeled dataset.\nThis assimilated dataset is used for the next round of training ensemble\nmodels. This cyclical process is repeated until the performance improvement\nplateaus. Additionally, we post process our results with Conditional Random\nFields. Our approach sets a high score on the public leaderboard for the ETCI\ncompetition with 0.7654 IoU. Our method, which we release with all the code\nincluding trained models, can also be used as an open science benchmark for the\nSentinel-1 released dataset on GitHub. To the best of our knowledge we believe\nthis the first works to try out semi-supervised learning to improve flood\nsegmentation models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:42:10 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 16:20:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Paul", "Sayak", ""], ["Ganju", "Siddha", ""]]}, {"id": "2107.08371", "submitter": "Liangqiong Qu", "authors": "Liangqiong Qu, Niranjan Balachandar and Daniel L Rubin", "title": "An Experimental Study of Data Heterogeneity in Federated Learning\n  Methods for Medical Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables multiple institutions to collaboratively train\nmachine learning models on their local data in a privacy-preserving way.\nHowever, its distributed nature often leads to significant heterogeneity in\ndata distributions across institutions. In this paper, we investigate the\ndeleterious impact of a taxonomy of data heterogeneity regimes on federated\nlearning methods, including quantity skew, label distribution skew, and imaging\nacquisition skew. We show that the performance degrades with the increasing\ndegrees of data heterogeneity. We present several mitigation strategies to\novercome performance drops from data heterogeneity, including weighted average\nfor data quantity skew, weighted loss and batch normalization averaging for\nlabel distribution skew. The proposed optimizations to federated learning\nmethods improve their capability of handling heterogeneity across institutions,\nwhich provides valuable guidance for the deployment of federated learning in\nreal clinical applications.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:47:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Qu", "Liangqiong", ""], ["Balachandar", "Niranjan", ""], ["Rubin", "Daniel L", ""]]}, {"id": "2107.08377", "submitter": "Zhou Shao", "authors": "Zhou Shao and Tong Lin", "title": "A New Adaptive Gradient Method with Gradient Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods, especially Adam-type methods (such as Adam,\nAMSGrad, and AdaBound), have been proposed to speed up the training process\nwith an element-wise scaling term on learning rates. However, they often\ngeneralize poorly compared with stochastic gradient descent (SGD) and its\naccelerated schemes such as SGD with momentum (SGDM). In this paper, we propose\na new adaptive method called DecGD, which simultaneously achieves good\ngeneralization like SGDM and obtain rapid convergence like Adam-type methods.\nIn particular, DecGD decomposes the current gradient into the product of two\nterms including a surrogate gradient and a loss based vector. Our method\nadjusts the learning rates adaptively according to the current loss based\nvector instead of the squared gradients used in Adam-type methods. The\nintuition for adaptive learning rates of DecGD is that a good optimizer, in\ngeneral cases, needs to decrease the learning rates as the loss decreases,\nwhich is similar to the learning rates decay scheduling technique. Therefore,\nDecGD gets a rapid convergence in the early phases of training and controls the\neffective learning rates according to the loss based vectors which help lead to\na better generalization. Convergence analysis is discussed in both convex and\nnon-convex situations. Finally, empirical results on widely-used tasks and\nmodels demonstrate that DecGD shows better generalization performance than SGDM\nand rapid convergence like Adam-type methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 06:37:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shao", "Zhou", ""], ["Lin", "Tong", ""]]}, {"id": "2107.08382", "submitter": "Hsu-Hsun Chin", "authors": "Hsu-Hsun Chin, Ren-Song Tsay, Hsin-I Wu", "title": "A High-Performance Adaptive Quantization Approach for Edge CNN\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent convolutional neural network (CNN) development continues to advance\nthe state-of-the-art model accuracy for various applications. However, the\nenhanced accuracy comes at the cost of substantial memory bandwidth and storage\nrequirements and demanding computational resources. Although in the past the\nquantization methods have effectively reduced the deployment cost for edge\ndevices, it suffers from significant information loss when processing the\nbiased activations of contemporary CNNs. In this paper, we hence introduce an\nadaptive high-performance quantization method to resolve the issue of biased\nactivation by dynamically adjusting the scaling and shifting factors based on\nthe task loss. Our proposed method has been extensively evaluated on image\nclassification models (ResNet-18/34/50, MobileNet-V2, EfficientNet-B0) with\nImageNet dataset, object detection model (YOLO-V4) with COCO dataset, and\nlanguage models with PTB dataset. The results show that our 4-bit integer\n(INT4) quantization models achieve better accuracy than the state-of-the-art\n4-bit models, and in some cases, even surpass the golden full-precision models.\nThe final designs have been successfully deployed onto extremely\nresource-constrained edge devices for many practical applications.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 07:49:18 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chin", "Hsu-Hsun", ""], ["Tsay", "Ren-Song", ""], ["Wu", "Hsin-I", ""]]}, {"id": "2107.08383", "submitter": "Feiyang Pan", "authors": "Feiyang Pan, Haoming Li, Xiang Ao, Wei Wang, Yanrong Kang, Ao Tan and\n  Qing He", "title": "GuideBoot: Guided Bootstrap for Deep Contextual Bandits", "comments": "WWW-2021", "journal-ref": null, "doi": "10.1145/3442381.3449987", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exploration/exploitation (E&E) dilemma lies at the core of interactive\nsystems such as online advertising, for which contextual bandit algorithms have\nbeen proposed. Bayesian approaches provide guided exploration with principled\nuncertainty estimation, but the applicability is often limited due to\nover-simplified assumptions. Non-Bayesian bootstrap methods, on the other hand,\ncan apply to complex problems by using deep reward models, but lacks clear\nguidance to the exploration behavior. It still remains largely unsolved to\ndevelop a practical method for complex deep contextual bandits.\n  In this paper, we introduce Guided Bootstrap (GuideBoot for short), combining\nthe best of both worlds. GuideBoot provides explicit guidance to the\nexploration behavior by training multiple models over both real samples and\nnoisy samples with fake labels, where the noise is added according to the\npredictive uncertainty. The proposed method is efficient as it can make\ndecisions on-the-fly by utilizing only one randomly chosen model, but is also\neffective as we show that it can be viewed as a non-Bayesian approximation of\nThompson sampling. Moreover, we extend it to an online version that can learn\nsolely from streaming data, which is favored in real applications. Extensive\nexperiments on both synthetic task and large-scale advertising environments\nshow that GuideBoot achieves significant improvements against previous\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 07:53:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Pan", "Feiyang", ""], ["Li", "Haoming", ""], ["Ao", "Xiang", ""], ["Wang", "Wei", ""], ["Kang", "Yanrong", ""], ["Tan", "Ao", ""], ["He", "Qing", ""]]}, {"id": "2107.08387", "submitter": "Shai Ben-Assayag", "authors": "Shai Ben-Assayag, Ran El-Yaniv", "title": "Train on Small, Play the Large: Scaling Up Board Games with AlphaZero\n  and GNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Playing board games is considered a major challenge for both humans and AI\nresearchers. Because some complicated board games are quite hard to learn,\nhumans usually begin with playing on smaller boards and incrementally advance\nto master larger board strategies. Most neural network frameworks that are\ncurrently tasked with playing board games neither perform such incremental\nlearning nor possess capabilities to automatically scale up. In this work, we\nlook at the board as a graph and combine a graph neural network architecture\ninside the AlphaZero framework, along with some other innovative improvements.\nOur ScalableAlphaZero is capable of learning to play incrementally on small\nboards, and advancing to play on large ones. Our model can be trained quickly\nto play different challenging board games on multiple board sizes, without\nusing any domain knowledge. We demonstrate the effectiveness of\nScalableAlphaZero and show, for example, that by training it for only three\ndays on small Othello boards, it can defeat the AlphaZero model on a large\nboard, which was trained to play the large board for $30$ days.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 08:36:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ben-Assayag", "Shai", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "2107.08396", "submitter": "Marco Podda", "authors": "Marco Podda and Davide Bacciu", "title": "GraphGen-Redux: a Fast and Lightweight Recurrent Model for labeled Graph\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of labeled graph generation is gaining attention in the Deep\nLearning community. The task is challenging due to the sparse and discrete\nnature of graph spaces. Several approaches have been proposed in the\nliterature, most of which require to transform the graphs into sequences that\nencode their structure and labels and to learn the distribution of such\nsequences through an auto-regressive generative model. Among this family of\napproaches, we focus on the GraphGen model. The preprocessing phase of GraphGen\ntransforms graphs into unique edge sequences called Depth-First Search (DFS)\ncodes, such that two isomorphic graphs are assigned the same DFS code. Each\nelement of a DFS code is associated with a graph edge: specifically, it is a\nquintuple comprising one node identifier for each of the two endpoints, their\nnode labels, and the edge label. GraphGen learns to generate such sequences\nauto-regressively and models the probability of each component of the quintuple\nindependently. While effective, the independence assumption made by the model\nis too loose to capture the complex label dependencies of real-world graphs\nprecisely. By introducing a novel graph preprocessing approach, we are able to\nprocess the labeling information of both nodes and edges jointly. The\ncorresponding model, which we term GraphGen-Redux, improves upon the generative\nperformances of GraphGen in a wide range of datasets of chemical and social\ngraphs. In addition, it uses approximately 78% fewer parameters than the\nvanilla variant and requires 50% fewer epochs of training on average.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:26:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Podda", "Marco", ""], ["Bacciu", "Davide", ""]]}, {"id": "2107.08398", "submitter": "Juan Jos\\'e Nieto", "authors": "Juan Jos\\'e Nieto, Roger Creus and Xavier Giro-i-Nieto", "title": "Unsupervised Skill-Discovery and Skill-Learning in Minecraft", "comments": "Accepted at ICML Unsupervised RL Workshop, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pre-training Reinforcement Learning agents in a task-agnostic manner has\nshown promising results. However, previous works still struggle in learning and\ndiscovering meaningful skills in high-dimensional state-spaces, such as\npixel-spaces. We approach the problem by leveraging unsupervised skill\ndiscovery and self-supervised learning of state representations. In our work,\nwe learn a compact latent representation by making use of variational and\ncontrastive techniques. We demonstrate that both enable RL agents to learn a\nset of basic navigation skills by maximizing an information theoretic\nobjective. We assess our method in Minecraft 3D pixel maps with different\ncomplexities. Our results show that representations and conditioned policies\nlearned from pixels are enough for toy examples, but do not scale to realistic\nand complex maps. To overcome these limitations, we explore alternative input\nobservations such as the relative position of the agent along with the raw\npixels.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:28:21 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Nieto", "Juan Jos\u00e9", ""], ["Creus", "Roger", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "2107.08399", "submitter": "Andrei Velichko", "authors": "Andrei Velichko and Hanif Heidari", "title": "A method for estimating the entropy of time series using artificial\n  neural network", "comments": "18 pages, 18 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the predictability and complexity of time series is an essential\ntool in designing and controlling the nonlinear system. There exist different\nentropy measures in the literature to analyze the predictability and complexity\nof time series. However, these measures have some drawbacks especially in short\ntime series. To overcome the difficulties, this paper proposes a new method for\nestimating the entropy of a time series using the LogNNet 784:25:10 neural\nnetwork model. The LogNNet reservoir matrix consists of 19625 elements which is\nfilled with the time series elements. After that, the network is trained on\nMNIST-10 dataset and the classification accuracy is calculated. The accuracy is\nconsidered as the entropy measure and denoted by NNetEn. A more complex\ntransformation of the input information by the time series in the reservoir\nleads to higher NNetEn values. Many practical time series data have less than\n19625 elements. Some duplicating or stretching methods are investigated to\novercome this difficulty and the most successful method is identified for\npractical applications. The epochs number in the training process of LogNNet is\nconsidered as the input parameter. A new time series characteristic called time\nseries learning inertia is introduced to investigate the effect of epochs\nnumber in the efficiency of neural network. To show the robustness and\nefficiency of the proposed method, it is applied on some chaotic, periodic,\nrandom, binary and constant time series. The NNetEn is compared with some\nexisting entropy measures. The results show that the proposed method is more\nrobust and accurate than existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:31:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Velichko", "Andrei", ""], ["Heidari", "Hanif", ""]]}, {"id": "2107.08402", "submitter": "Farnaz Tahmasebian", "authors": "Farnaz Tahmasebian, Jian Lou, and Li Xiong", "title": "RobustFed: A Truth Inference Approach for Robust Federated Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is a prominent framework that enables clients (e.g.,\nmobile devices or organizations) to train a collaboratively global model under\na central server's orchestration while keeping local training datasets'\nprivacy. However, the aggregation step in federated learning is vulnerable to\nadversarial attacks as the central server cannot manage clients' behavior.\nTherefore, the global model's performance and convergence of the training\nprocess will be affected under such attacks.To mitigate this vulnerability\nissue, we propose a novel robust aggregation algorithm inspired by the truth\ninference methods in crowdsourcing via incorporating the worker's reliability\ninto aggregation. We evaluate our solution on three real-world datasets with a\nvariety of machine learning models. Experimental results show that our solution\nensures robust federated learning and is resilient to various types of attacks,\nincluding noisy data attacks, Byzantine attacks, and label flipping attacks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:34:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Tahmasebian", "Farnaz", ""], ["Lou", "Jian", ""], ["Xiong", "Li", ""]]}, {"id": "2107.08426", "submitter": "Majid Abdolshah", "authors": "Majid Abdolshah, Hung Le, Thommen Karimpanal George, Sunil Gupta,\n  Santu Rana, Svetha Venkatesh", "title": "A New Representation of Successor Features for Transfer across\n  Dissimilar Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transfer in reinforcement learning is usually achieved through generalisation\nacross tasks. Whilst many studies have investigated transferring knowledge when\nthe reward function changes, they have assumed that the dynamics of the\nenvironments remain consistent. Many real-world RL problems require transfer\namong environments with different dynamics. To address this problem, we propose\nan approach based on successor features in which we model successor feature\nfunctions with Gaussian Processes permitting the source successor features to\nbe treated as noisy measurements of the target successor feature function. Our\ntheoretical analysis proves the convergence of this approach as well as the\nbounded error on modelling successor feature functions with Gaussian Processes\nin environments with both different dynamics and rewards. We demonstrate our\nmethod on benchmark datasets and show that it outperforms current baselines.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 12:37:05 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Abdolshah", "Majid", ""], ["Le", "Hung", ""], ["George", "Thommen Karimpanal", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2107.08429", "submitter": "Shibabrat Naik", "authors": "Shibabrat Naik, Vladim\\'ir Kraj\\v{n}\\'ak, Stephen Wiggins", "title": "Support vector machines for learning reactive islands", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a machine learning framework that can be applied to data sets\nderived from the trajectories of Hamilton's equations. The goal is to learn the\nphase space structures that play the governing role for phase space transport\nrelevant to particular applications. Our focus is on learning reactive islands\nin two degrees-of-freedom Hamiltonian systems. Reactive islands are constructed\nfrom the stable and unstable manifolds of unstable periodic orbits and play the\nrole of quantifying transition dynamics. We show that support vector machines\n(SVM) is an appropriate machine learning framework for this purpose as it\nprovides an approach for finding the boundaries between qualitatively distinct\ndynamical behaviors, which is in the spirit of the phase space transport\nframework. We show how our method allows us to find reactive islands directly\nin the sense that we do not have to first compute unstable periodic orbits and\ntheir stable and unstable manifolds. We apply our approach to the\nH\\'enon-Heiles Hamiltonian system, which is a benchmark system in the dynamical\nsystems community. We discuss different sampling and learning approaches and\ntheir advantages and disadvantages.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 12:54:23 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Naik", "Shibabrat", ""], ["Kraj\u0148\u00e1k", "Vladim\u00edr", ""], ["Wiggins", "Stephen", ""]]}, {"id": "2107.08442", "submitter": "Chonggang Lu", "authors": "Huafeng Wang (1), Chonggang Lu (1), Qi Zhang (1), Zhimin Hu (1),\n  Xiaodong Yuan (2), Pingshu Zhang (2), Wanquan Liu (3) ((1) School of\n  Information, North China University of Technology,(2) Department of\n  Neurology, Kailuan General Hospital, Tangshan,(3) School of Intelligent\n  Systems Engineering, Sun Yat-sen University)", "title": "Sleep Staging Based on Serialized Dual Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep staging assumes an important role in the diagnosis of sleep disorders.\nIn general, experts classify sleep stages manually based on polysomnography\n(PSG), which is quite time-consuming. Meanwhile, the acquisition of multiple\nsignals is complex, which can affect the subject's sleep. Therefore, the use of\nsingle-channel electroencephalogram (EEG) for automatic sleep staging has\nbecome mainstream. In the literature, a large number of sleep staging methods\nbased on single-channel EEG have been proposed with good results and realize\nthe preliminary automation of sleep staging. However, the performance for most\nof these methods in the N1 stage is generally not high. In this paper, we\npropose a deep learning model SDAN based on raw EEG. The method utilises a\none-dimensional convolutional neural network (CNN) to automatically extract\nfeatures from raw EEG. It serially combines the channel attention and spatial\nattention mechanisms to filter and highlight key information and then uses soft\nthreshold to eliminate redundant information. Additionally, we introduce a\nresidual network to avoid degradation problems caused by network deepening.\nExperiments were conducted using two datasets with 5-fold cross-validation and\nhold-out validation method. The final average accuracy, overall accuracy, macro\nF1 score and Cohen's Kappa coefficient of the model reach 96.74%, 91.86%,\n82.64% and 0.8742 on the Sleep-EDF dataset, and 95.98%, 89.96%, 79.08% and\n0.8216 on the Sleep-EDFx dataset. Significantly, our model performed superiorly\nin the N1 stage, with F1 scores of 54.08% and 52.49% on the two datasets\nrespectively. The results show the superiority of our network over the best\nexisting methods, reaching a new state-of-the-art. In particular, the present\nmethod achieves excellent results in the N1 sleep stage compared to other\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 13:18:12 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Huafeng", ""], ["Lu", "Chonggang", ""], ["Zhang", "Qi", ""], ["Hu", "Zhimin", ""], ["Yuan", "Xiaodong", ""], ["Zhang", "Pingshu", ""], ["Liu", "Wanquan", ""]]}, {"id": "2107.08444", "submitter": "Shay Moran", "authors": "Noga Alon and Steve Hanneke and Ron Holzman and Shay Moran", "title": "A Theory of PAC Learnability of Partial Concept Classes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CC cs.CG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We extend the theory of PAC learning in a way which allows to model a rich\nvariety of learning tasks where the data satisfy special properties that ease\nthe learning process. For example, tasks where the distance of the data from\nthe decision boundary is bounded away from zero. The basic and simple idea is\nto consider partial concepts: these are functions that can be undefined on\ncertain parts of the space. When learning a partial concept, we assume that the\nsource distribution is supported only on points where the partial concept is\ndefined.\n  This way, one can naturally express assumptions on the data such as lying on\na lower dimensional surface or margin conditions. In contrast, it is not at all\nclear that such assumptions can be expressed by the traditional PAC theory. In\nfact we exhibit easy-to-learn partial concept classes which provably cannot be\ncaptured by the traditional PAC theory. This also resolves a question posed by\nAttias, Kontorovich, and Mansour 2019.\n  We characterize PAC learnability of partial concept classes and reveal an\nalgorithmic landscape which is fundamentally different than the classical one.\nFor example, in the classical PAC model, learning boils down to Empirical Risk\nMinimization (ERM). In stark contrast, we show that the ERM principle fails in\nexplaining learnability of partial concept classes. In fact, we demonstrate\nclasses that are incredibly easy to learn, but such that any algorithm that\nlearns them must use an hypothesis space with unbounded VC dimension. We also\nfind that the sample compression conjecture fails in this setting.\n  Thus, this theory features problems that cannot be represented nor solved in\nthe traditional way. We view this as evidence that it might provide insights on\nthe nature of learnability in realistic scenarios which the classical theory\nfails to explain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 13:29:26 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 19:25:35 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Alon", "Noga", ""], ["Hanneke", "Steve", ""], ["Holzman", "Ron", ""], ["Moran", "Shay", ""]]}, {"id": "2107.08461", "submitter": "Qiyiwen Zhang", "authors": "Qiyiwen Zhang, Zhiqi Bu, Kan Chen, Qi Long", "title": "Differentially Private Bayesian Neural Networks on Accuracy, Privacy and\n  Reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural network (BNN) allows for uncertainty quantification in\nprediction, offering an advantage over regular neural networks that has not\nbeen explored in the differential privacy (DP) framework. We fill this\nimportant gap by leveraging recent development in Bayesian deep learning and\nprivacy accounting to offer a more precise analysis of the trade-off between\nprivacy and accuracy in BNN. We propose three DP-BNNs that characterize the\nweight uncertainty for the same network architecture in distinct ways, namely\nDP-SGLD (via the noisy gradient method), DP-BBP (via changing the parameters of\ninterest) and DP-MC Dropout (via the model architecture). Interestingly, we\nshow a new equivalence between DP-SGD and DP-SGLD, implying that some\nnon-Bayesian DP training naturally allows for uncertainty quantification.\nHowever, the hyperparameters such as learning rate and batch size, can have\ndifferent or even opposite effects in DP-SGD and DP-SGLD.\n  Extensive experiments are conducted to compare DP-BNNs, in terms of privacy\nguarantee, prediction accuracy, uncertainty quantification, calibration,\ncomputation speed, and generalizability to network architecture. As a result,\nwe observe a new tradeoff between the privacy and the reliability. When\ncompared to non-DP and non-Bayesian approaches, DP-SGLD is remarkably accurate\nunder strong privacy guarantee, demonstrating the great potential of DP-BNN in\nreal-world tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:37:07 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhang", "Qiyiwen", ""], ["Bu", "Zhiqi", ""], ["Chen", "Kan", ""], ["Long", "Qi", ""]]}, {"id": "2107.08467", "submitter": "Ramin Hasani", "authors": "Sophie Gruenbacher, Mathias Lechner, Ramin Hasani, Daniela Rus, Thomas\n  A. Henzinger, Scott Smolka, Radu Grosu", "title": "GoTube: Scalable Stochastic Verification of Continuous-Depth Models", "comments": "17 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.DS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new stochastic verification algorithm that formally quantifies\nthe behavioral robustness of any time-continuous process formulated as a\ncontinuous-depth model. The algorithm solves a set of global optimization (Go)\nproblems over a given time horizon to construct a tight enclosure (Tube) of the\nset of all process executions starting from a ball of initial states. We call\nour algorithm GoTube. Through its construction, GoTube ensures that the\nbounding tube is conservative up to a desired probability. GoTube is\nimplemented in JAX and optimized to scale to complex continuous-depth models.\nCompared to advanced reachability analysis tools for time-continuous neural\nnetworks, GoTube provably does not accumulate over-approximation errors between\ntime steps and avoids the infamous wrapping effect inherent in symbolic\ntechniques. We show that GoTube substantially outperforms state-of-the-art\nverification tools in terms of the size of the initial ball, speed,\ntime-horizon, task completion, and scalability, on a large set of experiments.\nGoTube is stable and sets the state-of-the-art for its ability to scale up to\ntime horizons well beyond what has been possible before.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:59:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gruenbacher", "Sophie", ""], ["Lechner", "Mathias", ""], ["Hasani", "Ramin", ""], ["Rus", "Daniela", ""], ["Henzinger", "Thomas A.", ""], ["Smolka", "Scott", ""], ["Grosu", "Radu", ""]]}, {"id": "2107.08470", "submitter": "Yung-Han Ho", "authors": "Yung-Han Ho, Chih-Chun Chan, Wen-Hsiao Peng, Hsueh-Ming Hang, Marek\n  Domanski", "title": "ANFIC: Image Compression Using Augmented Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces an end-to-end learned image compression system, termed\nANFIC, based on Augmented Normalizing Flows (ANF). ANF is a new type of flow\nmodel, which stacks multiple variational autoencoders (VAE) for greater model\nexpressiveness. The VAE-based image compression has gone mainstream, showing\npromising compression performance. Our work presents the first attempt to\nleverage VAE-based compression in a flow-based framework. ANFIC advances\nfurther compression efficiency by stacking and extending hierarchically\nmultiple VAE's. The invertibility of ANF, together with our training\nstrategies, enables ANFIC to support a wide range of quality levels without\nchanging the encoding and decoding networks. Extensive experimental results\nshow that in terms of PSNR-RGB, ANFIC performs comparably to or better than the\nstate-of-the-art learned image compression. Moreover, it performs close to VVC\nintra coding, from low-rate compression up to nearly-lossless compression. In\nparticular, ANFIC achieves the state-of-the-art performance, when extended with\nconditional convolution for variable rate compression with a single model.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 15:02:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ho", "Yung-Han", ""], ["Chan", "Chih-Chun", ""], ["Peng", "Wen-Hsiao", ""], ["Hang", "Hsueh-Ming", ""], ["Domanski", "Marek", ""]]}, {"id": "2107.08471", "submitter": "Dengshan Li", "authors": "Dengshan Li, Rujing Wang, Chengjun Xie", "title": "A stepped sampling method for video detection using LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks that simulate human achieves great successes. From\nthe perspective of simulating human memory method, we propose a stepped sampler\nbased on the \"repeated input\". We repeatedly inputted data to the LSTM model\nstepwise in a batch. The stepped sampler is used to strengthen the ability of\nfusing the temporal information in LSTM. We tested the stepped sampler on the\nLSTM built-in in PyTorch. Compared with the traditional sampler of PyTorch,\nsuch as sequential sampler, batch sampler, the training loss of the proposed\nstepped sampler converges faster in the training of the model, and the training\nloss after convergence is more stable. Meanwhile, it can maintain a higher test\naccuracy. We quantified the algorithm of the stepped sampler.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 15:04:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Li", "Dengshan", ""], ["Wang", "Rujing", ""], ["Xie", "Chengjun", ""]]}, {"id": "2107.08484", "submitter": "George Kyriakides", "authors": "Aristeidis Chrostoforidis, George Kyriakides, Konstantinos Margaritis", "title": "A Novel Evolutionary Algorithm for Hierarchical Neural Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we propose a novel evolutionary algorithm for neural\narchitecture search, applicable to global search spaces. The algorithm's\narchitectural representation organizes the topology in multiple hierarchical\nmodules, while the design process exploits this representation, in order to\nexplore the search space. We also employ a curation system, which promotes the\nutilization of well performing sub-structures to subsequent generations. We\napply our method to Fashion-MNIST and NAS-Bench101, achieving accuracies of\n$93.2\\%$ and $94.8\\%$ respectively in a relatively small number of generations.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 16:19:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chrostoforidis", "Aristeidis", ""], ["Kyriakides", "George", ""], ["Margaritis", "Konstantinos", ""]]}, {"id": "2107.08488", "submitter": "Davide Maran", "authors": "D. Maran", "title": "A note on the article \"On Exploiting Spectral Properties for Solving MDP\n  with Large State Space\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We improve a theoretical result of the article \"On Exploiting Spectral\nProperties for Solving MDP with Large State Space\" showing that their\nalgorithm, which was proved to converge under some unrealistic assumptions, is\nactually guaranteed to converge always.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 16:46:35 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Maran", "D.", ""]]}, {"id": "2107.08514", "submitter": "Amit Joshi Dr", "authors": "Pranali Kokate, Sidharth Pancholi, Amit M. Joshi", "title": "Classification of Upper Arm Movements from EEG signals using Machine\n  Learning with ICA Analysis", "comments": "41 Pages, Figures 32, Table 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Brain-Computer Interface system is a profoundly developing area of\nexperimentation for Motor activities which plays vital role in decoding\ncognitive activities. Classification of Cognitive-Motor Imagery activities from\nEEG signals is a critical task. Hence proposed a unique algorithm for\nclassifying left/right-hand movements by utilizing Multi-layer Perceptron\nNeural Network. Handcrafted statistical Time domain and Power spectral density\nfrequency domain features were extracted and obtained a combined accuracy of\n96.02%. Results were compared with the deep learning framework. In addition to\naccuracy, Precision, F1-Score, and recall was considered as the performance\nmetrics. The intervention of unwanted signals contaminates the EEG signals\nwhich influence the performance of the algorithm. Therefore, a novel approach\nwas approached to remove the artifacts using Independent Components Analysis\nwhich boosted the performance. Following the selection of appropriate feature\nvectors that provided acceptable accuracy. The same method was used on all nine\nsubjects. As a result, intra-subject accuracy was obtained for 9 subjects\n94.72%. The results show that the proposed approach would be useful to classify\nthe upper limb movements accurately.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 18:56:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kokate", "Pranali", ""], ["Pancholi", "Sidharth", ""], ["Joshi", "Amit M.", ""]]}, {"id": "2107.08517", "submitter": "Edvin Listo Zec", "authors": "Noa Onoszko, Gustav Karlsson, Olof Mogren, Edvin Listo Zec", "title": "Decentralized federated learning of deep neural networks on non-iid data", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We tackle the non-convex problem of learning a personalized deep learning\nmodel in a decentralized setting. More specifically, we study decentralized\nfederated learning, a peer-to-peer setting where data is distributed among many\nclients and where there is no central server to orchestrate the training. In\nreal world scenarios, the data distributions are often heterogeneous between\nclients. Therefore, in this work we study the problem of how to efficiently\nlearn a model in a peer-to-peer system with non-iid client data. We propose a\nmethod named Performance-Based Neighbor Selection (PENS) where clients with\nsimilar data distributions detect each other and cooperate by evaluating their\ntraining losses on each other's data to learn a model suitable for the local\ndata distribution. Our experiments on benchmark datasets show that our proposed\nmethod is able to achieve higher accuracies as compared to strong baselines.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 19:05:44 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 13:53:58 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Onoszko", "Noa", ""], ["Karlsson", "Gustav", ""], ["Mogren", "Olof", ""], ["Zec", "Edvin Listo", ""]]}, {"id": "2107.08558", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling, Thomas Icard", "title": "A Topological Perspective on Causal Inference", "comments": "ICML 2021 NACI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a topological learning-theoretic perspective on causal\ninference by introducing a series of topologies defined on general spaces of\nstructural causal models (SCMs). As an illustration of the framework we prove a\ntopological causal hierarchy theorem, showing that substantive assumption-free\ncausal inference is possible only in a meager set of SCMs. Thanks to a known\ncorrespondence between open sets in the weak topology and statistically\nverifiable hypotheses, our results show that inductive assumptions sufficient\nto license valid causal inferences are statistically unverifiable in principle.\nSimilar to no-free-lunch theorems for statistical inference, the present\nresults clarify the inevitability of substantial assumptions for causal\ninference. An additional benefit of our topological approach is that it easily\naccommodates SCMs with infinitely many variables. We finally suggest that the\nframework may be helpful for the positive project of exploring and assessing\nalternative causal-inductive assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 23:09:03 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ibeling", "Duligur", ""], ["Icard", "Thomas", ""]]}, {"id": "2107.08562", "submitter": "Nairouz Mrabah", "authors": "Nairouz Mrabah, Mohamed Bouguessa, Mohamed Fawzi Touati, Riadh\n  Ksantini", "title": "Rethinking Graph Auto-Encoder Models for Attributed Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent graph clustering methods have resorted to Graph Auto-Encoders\n(GAEs) to perform joint clustering and embedding learning. However, two\ncritical issues have been overlooked. First, the accumulative error, inflicted\nby learning with noisy clustering assignments, degrades the effectiveness and\nrobustness of the clustering model. This problem is called Feature Randomness.\nSecond, reconstructing the adjacency matrix sets the model to learn irrelevant\nsimilarities for the clustering task. This problem is called Feature Drift.\nInterestingly, the theoretical relation between the aforementioned problems has\nnot yet been investigated. We study these issues from two aspects: (1) there is\na trade-off between Feature Randomness and Feature Drift when clustering and\nreconstruction are performed at the same level, and (2) the problem of Feature\nDrift is more pronounced for GAE models, compared with vanilla auto-encoder\nmodels, due to the graph convolutional operation and the graph decoding design.\nMotivated by these findings, we reformulate the GAE-based clustering\nmethodology. Our solution is two-fold. First, we propose a sampling operator\n$\\Xi$ that triggers a protection mechanism against the noisy clustering\nassignments. Second, we propose an operator $\\Upsilon$ that triggers a\ncorrection mechanism against Feature Drift by gradually transforming the\nreconstructed graph into a clustering-oriented one. As principal advantages,\nour solution grants a considerable improvement in clustering effectiveness and\nrobustness and can be easily tailored to existing GAE models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 00:00:35 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 16:54:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mrabah", "Nairouz", ""], ["Bouguessa", "Mohamed", ""], ["Touati", "Mohamed Fawzi", ""], ["Ksantini", "Riadh", ""]]}, {"id": "2107.08564", "submitter": "Ali Momeni", "authors": "Ali Momeni and Romain Fleury", "title": "Wave-based extreme deep learning based on non-linear time-Floquet\n  entanglement", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE physics.app-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wave-based analog signal processing holds the promise of extremely fast,\non-the-fly, power-efficient data processing, occurring as a wave propagates\nthrough an artificially engineered medium. Yet, due to the fundamentally weak\nnon-linearities of traditional wave materials, such analog processors have been\nso far largely confined to simple linear projections such as image edge\ndetection or matrix multiplications. Complex neuromorphic computing tasks,\nwhich inherently require strong non-linearities, have so far remained\nout-of-reach of wave-based solutions, with a few attempts that implemented\nnon-linearities on the digital front, or used weak and inflexible non-linear\nsensors, restraining the learning performance. Here, we tackle this issue by\ndemonstrating the relevance of Time-Floquet physics to induce a strong\nnon-linear entanglement between signal inputs at different frequencies,\nenabling a power-efficient and versatile wave platform for analog extreme deep\nlearning involving a single, uniformly modulated dielectric layer and a\nscattering medium. We prove the efficiency of the method for extreme learning\nmachines and reservoir computing to solve a range of challenging learning\ntasks, from forecasting chaotic time series to the simultaneous classification\nof distinct datasets. Our results open the way for wave-based machine learning\nwith high energy efficiency, speed, and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 00:18:09 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Momeni", "Ali", ""], ["Fleury", "Romain", ""]]}, {"id": "2107.08567", "submitter": "Spyridon Ampanavos", "authors": "Spyridon Ampanavos, Mehdi Nourbakhsh, Chin-Yi Cheng", "title": "Structural Design Recommendations in the Early Design Phase using\n  Machine Learning", "comments": "CAAD Futures 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Structural engineering knowledge can be of significant importance to the\narchitectural design team during the early design phase. However, architects\nand engineers do not typically work together during the conceptual phase; in\nfact, structural engineers are often called late into the process. As a result,\nupdates in the design are more difficult and time-consuming to complete. At the\nsame time, there is a lost opportunity for better design exploration guided by\nstructural feedback. In general, the earlier in the design process the\niteration happens, the greater the benefits in cost efficiency and informed\nde-sign exploration, which can lead to higher-quality creative results. In\norder to facilitate an informed exploration in the early design stage, we\nsuggest the automation of fundamental structural engineering tasks and\nintroduce ApproxiFramer, a Machine Learning-based system for the automatic\ngeneration of structural layouts from building plan sketches in real-time. The\nsystem aims to assist architects by presenting them with feasible structural\nsolutions during the conceptual phase so that they proceed with their design\nwith adequate knowledge of its structural implications. In this paper, we\ndescribe the system and evaluate the performance of a proof-of-concept\nimplementation in the domain of orthogonal, metal, rigid structures. We trained\na Convolutional Neural Net to iteratively generate structural design solutions\nfor sketch-level building plans using a synthetic dataset and achieved an\naverage error of 2.2% in the predicted positions of the columns.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 01:02:14 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ampanavos", "Spyridon", ""], ["Nourbakhsh", "Mehdi", ""], ["Cheng", "Chin-Yi", ""]]}, {"id": "2107.08572", "submitter": "Spyridon Ampanavos", "authors": "Spyridon Ampanavos, Ali Malkawi", "title": "Early-Phase Performance-Driven Design using Generative Models", "comments": "CAAD Futures 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Current performance-driven building design methods are not widely adopted\noutside the research field for several reasons that make them difficult to\nintegrate into a typical design process. In the early design phase, in\nparticular, the time-intensity and the cognitive load associated with\noptimization and form parametrization are incompatible with design exploration,\nwhich requires quick iteration. This research introduces a novel method for\nperformance-driven geometry generation that can afford interaction directly in\nthe 3d modeling environment, eliminating the need for explicit parametrization,\nand is multiple orders faster than the equivalent form optimization. The method\nuses Machine Learning techniques to train a generative model offline. The\ngenerative model learns a distribution of optimal performing geometries and\ntheir simulation contexts based on a dataset that addresses the performance(s)\nof interest. By navigating the generative model's latent space, geometries with\nthe desired characteristics can be quickly generated. A case study is\npresented, demonstrating the generation of a synthetic dataset and the use of a\nVariational Autoencoder (VAE) as a generative model for geometries with optimal\nsolar gain. The results show that the VAE-generated geometries perform on\naverage at least as well as the optimized ones, suggesting that the introduced\nmethod shows a feasible path towards more intuitive and interactive early-phase\nperformance-driven design assistance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 01:25:11 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ampanavos", "Spyridon", ""], ["Malkawi", "Ali", ""]]}, {"id": "2107.08574", "submitter": "Mohamed Abdelhack", "authors": "Mohamed Abdelhack, Jiaming Zhang, Sandhya Tripathi, Bradley Fritz,\n  Michael Avidan, Yixin Chen, Christopher King", "title": "A Modulation Layer to Increase Neural Network Robustness Against Data\n  Quality Issues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data quality is a common problem in machine learning, especially in\nhigh-stakes settings such as healthcare. Missing data affects accuracy,\ncalibration, and feature attribution in complex patterns. Developers often\ntrain models on carefully curated datasets to minimize missing data bias;\nhowever, this reduces the usability of such models in production environments,\nsuch as real-time healthcare records. Making machine learning models robust to\nmissing data is therefore crucial for practical application. While some\nclassifiers naturally handle missing data, others, such as deep neural\nnetworks, are not designed for unknown values. We propose a novel neural\nnetwork modification to mitigate the impacts of missing data. The approach is\ninspired by neuromodulation that is performed by biological neural networks.\nOur proposal replaces the fixed weights of a fully-connected layer with a\nfunction of an additional input (reliability score) at each input, mimicking\nthe ability of cortex to up- and down-weight inputs based on the presence of\nother data. The modulation function is jointly learned with the main task using\na multi-layer perceptron. We tested our modulating fully connected layer on\nmultiple classification, regression, and imputation problems, and it either\nimproved performance or generated comparable performance to conventional neural\nnetwork architectures concatenating reliability to the inputs. Models with\nmodulating layers were more robust against degradation of data quality by\nintroducing additional missingness at evaluation time. These results suggest\nthat explicitly accounting for reduced information quality with a modulating\nfully connected layer can enable the deployment of artificial intelligence\nsystems in real-time settings.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 01:29:16 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Abdelhack", "Mohamed", ""], ["Zhang", "Jiaming", ""], ["Tripathi", "Sandhya", ""], ["Fritz", "Bradley", ""], ["Avidan", "Michael", ""], ["Chen", "Yixin", ""], ["King", "Christopher", ""]]}, {"id": "2107.08577", "submitter": "Gautam Singh", "authors": "Gautam Singh, Skand Peri, Junghyun Kim, Hyunseok Kim, Sungjin Ahn", "title": "Structured World Belief for Reinforcement Learning in POMDP", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object-centric world models provide structured representation of the scene\nand can be an important backbone in reinforcement learning and planning.\nHowever, existing approaches suffer in partially-observable environments due to\nthe lack of belief states. In this paper, we propose Structured World Belief, a\nmodel for learning and inference of object-centric belief states. Inferred by\nSequential Monte Carlo (SMC), our belief states provide multiple object-centric\nscene hypotheses. To synergize the benefits of SMC particles with object\nrepresentations, we also propose a new object-centric dynamics model that\nconsiders the inductive bias of object permanence. This enables tracking of\nobject states even when they are invisible for a long time. To further\nfacilitate object tracking in this regime, we allow our model to attend\nflexibly to any spatial location in the image which was restricted in previous\nmodels. In experiments, we show that object-centric belief provides a more\naccurate and robust performance for filtering and generation. Furthermore, we\nshow the efficacy of structured world belief in improving the performance of\nreinforcement learning, planning and supervised reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 01:47:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Singh", "Gautam", ""], ["Peri", "Skand", ""], ["Kim", "Junghyun", ""], ["Kim", "Hyunseok", ""], ["Ahn", "Sungjin", ""]]}, {"id": "2107.08588", "submitter": "Yinjun Wu", "authors": "Yinjun Wu, James Weimer, Susan B. Davidson", "title": "CHEF: A Cheap and Fast Pipeline for Iteratively Cleaning Label\n  Uncertainties (Technical Report)", "comments": "Accepted by VLDB 2021", "journal-ref": null, "doi": "10.14778/3476249.3476290", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-quality labels are expensive to obtain for many machine learning tasks,\nsuch as medical image classification tasks. Therefore, probabilistic (weak)\nlabels produced by weak supervision tools are used to seed a process in which\ninfluential samples with weak labels are identified and cleaned by several\nhuman annotators to improve the model performance. To lower the overall cost\nand computational overhead of this process, we propose a solution called CHEF\n(CHEap and Fast label cleaning), which consists of the following three\ncomponents. First, to reduce the cost of human annotators, we use Infl, which\nprioritizes the most influential training samples for cleaning and provides\ncleaned labels to save the cost of one human annotator. Second, to accelerate\nthe sample selector phase and the model constructor phase, we use Increm-Infl\nto incrementally produce influential samples, and DeltaGrad-L to incrementally\nupdate the model. Third, we redesign the typical label cleaning pipeline so\nthat human annotators iteratively clean smaller batch of samples rather than\none big batch of samples. This yields better over all model performance and\nenables possible early termination when the expected model performance has been\nachieved. Extensive experiments show that our approach gives good model\nprediction performance while achieving significant speed-ups.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 02:42:35 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 20:39:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wu", "Yinjun", ""], ["Weimer", "James", ""], ["Davidson", "Susan B.", ""]]}, {"id": "2107.08593", "submitter": "Yiran Wang", "authors": "Yiran Wang, Zhen Li", "title": "Inverse Problem of Nonlinear Schr\\\"odinger Equation as Learning of\n  Convolutional Neural Network", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this work, we use an explainable convolutional neural network (NLS-Net) to\nsolve an inverse problem of the nonlinear Schr\\\"odinger equation, which is\nwidely used in fiber-optic communications. The landscape and minimizers of the\nnon-convex loss function of the learning problem are studied empirically. It\nprovides a guidance for choosing hyper-parameters of the method. The estimation\nerror of the optimal solution is discussed in terms of expressive power of the\nNLS-Net and data. Besides, we compare the performance of several training\nalgorithms that are popular in deep learning. It is shown that one can obtain a\nrelatively accurate estimate of the considered parameters using the proposed\nmethod. The study provides a natural framework of solving inverse problems of\nnonlinear partial differential equations with deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 02:54:37 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Yiran", ""], ["Li", "Zhen", ""]]}, {"id": "2107.08594", "submitter": "Rathijit Sen", "authors": "Anish Pimpley, Shuo Li, Anubha Srivastava, Vishal Rohra, Yi Zhu,\n  Soundararajan Srinivasan, Alekh Jindal, Hiren Patel, Shi Qiao, Rathijit Sen", "title": "Optimal Resource Allocation for Serverless Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optimizing resource allocation for analytical workloads is vital for reducing\ncosts of cloud-data services. At the same time, it is incredibly hard for users\nto allocate resources per query in serverless processing systems, and they\nfrequently misallocate by orders of magnitude. Unfortunately, prior work\nfocused on predicting peak allocation while ignoring aggressive trade-offs\nbetween resource allocation and run-time. Additionally, these methods fail to\npredict allocation for queries that have not been observed in the past. In this\npaper, we tackle both these problems. We introduce a system for optimal\nresource allocation that can predict performance with aggressive trade-offs,\nfor both new and past observed queries. We introduce the notion of a\nperformance characteristic curve (PCC) as a parameterized representation that\ncan compactly capture the relationship between resources and performance. To\ntackle training data sparsity, we introduce a novel data augmentation technique\nto efficiently synthesize the entire PCC using a single run of the query.\nLastly, we demonstrate the advantages of a constrained loss function coupled\nwith GNNs, over traditional ML methods, for capturing the domain specific\nbehavior through an extensive experimental evaluation over SCOPE big data\nworkloads at Microsoft.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 02:55:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Pimpley", "Anish", ""], ["Li", "Shuo", ""], ["Srivastava", "Anubha", ""], ["Rohra", "Vishal", ""], ["Zhu", "Yi", ""], ["Srinivasan", "Soundararajan", ""], ["Jindal", "Alekh", ""], ["Patel", "Hiren", ""], ["Qiao", "Shi", ""], ["Sen", "Rathijit", ""]]}, {"id": "2107.08595", "submitter": "Xiaowei Zhang", "authors": "Liang Ding, Rui Tuo, Xiaowei Zhang", "title": "High-Dimensional Simulation Optimization via Brownian Fields and Sparse\n  Grids", "comments": "Main body: 36 pages, 7 figures, 2 tables. Supplemental material: 32\n  pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  High-dimensional simulation optimization is notoriously challenging. We\npropose a new sampling algorithm that converges to a global optimal solution\nand suffers minimally from the curse of dimensionality. The algorithm consists\nof two stages. First, we take samples following a sparse grid experimental\ndesign and approximate the response surface via kernel ridge regression with a\nBrownian field kernel. Second, we follow the expected improvement strategy --\nwith critical modifications that boost the algorithm's sample efficiency -- to\niteratively sample from the next level of the sparse grid. Under mild\nconditions on the smoothness of the response surface and the simulation noise,\nwe establish upper bounds on the convergence rate for both noise-free and noisy\nsimulation samples. These upper bounds deteriorate only slightly in the\ndimension of the feasible set, and they can be improved if the objective\nfunction is known to be of a higher-order smoothness. Extensive numerical\nexperiments demonstrate that the proposed algorithm dramatically outperforms\ntypical alternatives in practice.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 03:03:27 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 01:57:21 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ding", "Liang", ""], ["Tuo", "Rui", ""], ["Zhang", "Xiaowei", ""]]}, {"id": "2107.08596", "submitter": "Isay Katsman", "authors": "Isay Katsman, Aaron Lou, Derek Lim, Qingxuan Jiang, Ser-Nam Lim,\n  Christopher De Sa", "title": "Equivariant Manifold Flows", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tractably modelling distributions over manifolds has long been an important\ngoal in the natural sciences. Recent work has focused on developing general\nmachine learning models to learn such distributions. However, for many\napplications these distributions must respect manifold symmetries -- a trait\nwhich most previous models disregard. In this paper, we lay the theoretical\nfoundations for learning symmetry-invariant distributions on arbitrary\nmanifolds via equivariant manifold flows. We demonstrate the utility of our\napproach by using it to learn gauge invariant densities over $SU(n)$ in the\ncontext of quantum field theory.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 03:04:44 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Katsman", "Isay", ""], ["Lou", "Aaron", ""], ["Lim", "Derek", ""], ["Jiang", "Qingxuan", ""], ["Lim", "Ser-Nam", ""], ["De Sa", "Christopher", ""]]}, {"id": "2107.08598", "submitter": "Guangda Huzhang", "authors": "Xuesi Wang, Guangda Huzhang, Qianying Lin, Qing Da, Dan Shen", "title": "Learning-To-Ensemble by Contextual Rank Aggregation in E-Commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble models in E-commerce combine predictions from multiple sub-models\nfor ranking and revenue improvement. Industrial ensemble models are typically\ndeep neural networks, following the supervised learning paradigm to infer\nconversion rate given inputs from sub-models. However, this process has the\nfollowing two problems. Firstly, the point-wise scoring approach disregards the\nrelationships between items and leads to homogeneous displayed results, while\ndiversified display benefits user experience and revenue. Secondly, the\nlearning paradigm focuses on the ranking metrics and does not directly optimize\nthe revenue. In our work, we propose a new Learning-To-Ensemble (LTE) framework\nRAEGO, which replaces the ensemble model with a contextual Rank Aggregator (RA)\nand explores the best weights of sub-models by the Evaluator-Generator\nOptimization (EGO). To achieve the best online performance, we propose a new\nrank aggregation algorithm TournamentGreedy as a refinement of classic rank\naggregators, which also produces the best average weighted Kendall Tau Distance\n(KTD) amongst all the considered algorithms with quadratic time complexity.\nUnder the assumption that the best output list should be Pareto Optimal on the\nKTD metric for sub-models, we show that our RA algorithm has higher efficiency\nand coverage in exploring the optimal weights. Combined with the idea of\nBayesian Optimization and gradient descent, we solve the online contextual\nBlack-Box Optimization task that finds the optimal weights for sub-models given\na chosen RA model. RA-EGO has been deployed in our online system and has\nimproved the revenue significantly.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 03:24:06 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Xuesi", ""], ["Huzhang", "Guangda", ""], ["Lin", "Qianying", ""], ["Da", "Qing", ""], ["Shen", "Dan", ""]]}, {"id": "2107.08622", "submitter": "Zhi Wang", "authors": "Chicheng Zhang and Zhi Wang", "title": "Provably Efficient Multi-Task Reinforcement Learning with Model Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multi-task reinforcement learning (RL) in tabular episodic Markov\ndecision processes (MDPs). We formulate a heterogeneous multi-player RL\nproblem, in which a group of players concurrently face similar but not\nnecessarily identical MDPs, with a goal of improving their collective\nperformance through inter-player information sharing. We design and analyze an\nalgorithm based on the idea of model transfer, and provide gap-dependent and\ngap-independent upper and lower bounds that characterize the intrinsic\ncomplexity of the problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 05:46:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhang", "Chicheng", ""], ["Wang", "Zhi", ""]]}, {"id": "2107.08640", "submitter": "Subodh Lonkar", "authors": "Subodh Lonkar", "title": "Facial Expressions Recognition with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Over the centuries, humans have developed and acquired a number of ways to\ncommunicate. But hardly any of them can be as natural and instinctive as facial\nexpressions. On the other hand, neural networks have taken the world by storm.\nAnd no surprises, that the area of Computer Vision and the problem of facial\nexpressions recognitions hasn't remained untouched. Although a wide range of\ntechniques have been applied, achieving extremely high accuracies and preparing\nhighly robust FER systems still remains a challenge due to heterogeneous\ndetails in human faces. In this paper, we will be deep diving into implementing\na system for recognition of facial expressions (FER) by leveraging neural\nnetworks, and more specifically, Convolutional Neural Networks (CNNs). We adopt\nthe fundamental concepts of deep learning and computer vision with various\narchitectures, fine-tune it's hyperparameters and experiment with various\noptimization methods and demonstrate a state-of-the-art single-network-accuracy\nof 70.10% on the FER2013 dataset without using any additional training data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 06:41:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lonkar", "Subodh", ""]]}, {"id": "2107.08649", "submitter": "Ariel Neufeld", "authors": "Dong-Young Lim, Ariel Neufeld, Sotirios Sabanis, Ying Zhang", "title": "Non-asymptotic estimates for TUSLA algorithm for non-convex learning\n  with applications to neural networks with ReLU activation function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-convex stochastic optimization problems where the objective\nfunctions have super-linearly growing and discontinuous stochastic gradients.\nIn such a setting, we provide a non-asymptotic analysis for the tamed\nunadjusted stochastic Langevin algorithm (TUSLA) introduced in Lovas et al.\n(2021). In particular, we establish non-asymptotic error bounds for the TUSLA\nalgorithm in Wasserstein-1 and Wasserstein-2 distances. The latter result\nenables us to further derive non-asymptotic estimates for the expected excess\nrisk. To illustrate the applicability of the main results, we consider an\nexample from transfer learning with ReLU neural networks, which represents a\nkey paradigm in machine learning. Numerical experiments are presented for the\naforementioned example which supports our theoretical findings. Hence, in this\nsetting, we demonstrate both theoretically and numerically that the TUSLA\nalgorithm can solve the optimization problem involving neural networks with\nReLU activation function. Besides, we provide simulation results for synthetic\nexamples where popular algorithms, e.g. ADAM, AMSGrad, RMSProp, and (vanilla)\nSGD, may fail to find the minimizer of the objective functions due to the\nsuper-linear growth and the discontinuity of the corresponding stochastic\ngradient, while the TUSLA algorithm converges rapidly to the optimal solution.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 07:13:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lim", "Dong-Young", ""], ["Neufeld", "Ariel", ""], ["Sabanis", "Sotirios", ""], ["Zhang", "Ying", ""]]}, {"id": "2107.08661", "submitter": "Ye Jia", "authors": "Ye Jia, Michelle Tadmor Ramanovich, Tal Remez, Roi Pomerantz", "title": "Translatotron 2: Robust direct speech-to-speech translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Translatotron 2, a neural direct speech-to-speech translation\nmodel that can be trained end-to-end. Translatotron 2 consists of a speech\nencoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention\nmodule that connects all the previous three components. Experimental results\nsuggest that Translatotron 2 outperforms the original Translatotron by a large\nmargin in terms of translation quality and predicted speech naturalness, and\ndrastically improves the robustness of the predicted speech by mitigating\nover-generation, such as babbling or long pause. We also propose a new method\nfor retaining the source speaker's voice in the translated speech. The trained\nmodel is restricted to retain the source speaker's voice, and unlike the\noriginal Translatotron, it is not able to generate speech in a different\nspeaker's voice, making the model more robust for production deployment, by\nmitigating potential misuse for creating spoofing audio artifacts. When the new\nmethod is used together with a simple concatenation-based data augmentation,\nthe trained Translatotron 2 model is able to retain each speaker's voice for\ninput with speaker turns.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 07:43:49 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 06:03:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jia", "Ye", ""], ["Ramanovich", "Michelle Tadmor", ""], ["Remez", "Tal", ""], ["Pomerantz", "Roi", ""]]}, {"id": "2107.08662", "submitter": "Peng Cheng", "authors": "Peng Cheng, Jiabao Jin, Lei Chen, Xuemin Lin, Libin Zheng", "title": "A Queueing-Theoretic Framework for Vehicle Dispatching in Dynamic\n  Car-Hailing [technical report]", "comments": "15 pages", "journal-ref": null, "doi": "10.14778/3476249.3476271", "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of smart mobile devices, the car-hailing platforms\n(e.g., Uber or Lyft) have attracted much attention from both the academia and\nthe industry. In this paper, we consider an important dynamic car-hailing\nproblem, namely \\textit{maximum revenue vehicle dispatching} (MRVD), in which\nrider requests dynamically arrive and drivers need to serve as many riders as\npossible such that the entire revenue of the platform is maximized. We prove\nthat the MRVD problem is NP-hard and intractable. In addition, the dynamic\ncar-hailing platforms have no information of the future riders, which makes the\nproblem even harder. To handle the MRVD problem, we propose a queueing-based\nvehicle dispatching framework, which first uses existing machine learning\nalgorithms to predict the future vehicle demand of each region, then estimates\nthe idle time periods of drivers through a queueing model for each region. With\nthe information of the predicted vehicle demands and estimated idle time\nperiods of drivers, we propose two batch-based vehicle dispatching algorithms\nto efficiently assign suitable drivers to riders such that the expected overall\nrevenue of the platform is maximized during each batch processing. Through\nextensive experiments, we demonstrate the efficiency and effectiveness of our\nproposed approaches over both real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 07:51:31 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 12:45:49 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cheng", "Peng", ""], ["Jin", "Jiabao", ""], ["Chen", "Lei", ""], ["Lin", "Xuemin", ""], ["Zheng", "Libin", ""]]}, {"id": "2107.08673", "submitter": "Aidana Massalimova", "authors": "Aidana Massalimova and Huseyin Atakan Varol", "title": "Input Agnostic Deep Learning for Alzheimer's Disease Classification\n  Using Multimodal MRI Images", "comments": "4 pages, submitted to EMBC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alzheimer's disease (AD) is a progressive brain disorder that causes memory\nand functional impairments. The advances in machine learning and publicly\navailable medical datasets initiated multiple studies in AD diagnosis. In this\nwork, we utilize a multi-modal deep learning approach in classifying normal\ncognition, mild cognitive impairment and AD classes on the basis of structural\nMRI and diffusion tensor imaging (DTI) scans from the OASIS-3 dataset. In\naddition to a conventional multi-modal network, we also present an input\nagnostic architecture that allows diagnosis with either sMRI or DTI scan, which\ndistinguishes our method from previous multi-modal machine learning-based\nmethods. The results show that the input agnostic model achieves 0.96 accuracy\nwhen both structural MRI and DTI scans are provided as inputs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:19:34 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Massalimova", "Aidana", ""], ["Varol", "Huseyin Atakan", ""]]}, {"id": "2107.08681", "submitter": "Jinke Ren", "authors": "Jinke Ren, Chonghe Liu, Guanding Yu, Dongning Guo", "title": "A New Distributed Method for Training Generative Adversarial Networks", "comments": "Submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are emerging machine learning models\nfor generating synthesized data similar to real data by jointly training a\ngenerator and a discriminator. In many applications, data and computational\nresources are distributed over many devices, so centralized computation with\nall data in one location is infeasible due to privacy and/or communication\nconstraints. This paper proposes a new framework for training GANs in a\ndistributed fashion: Each device computes a local discriminator using local\ndata; a single server aggregates their results and computes a global GAN.\nSpecifically, in each iteration, the server sends the global GAN to the\ndevices, which then update their local discriminators; the devices send their\nresults to the server, which then computes their average as the global\ndiscriminator and updates the global generator accordingly. Two different\nupdate schedules are designed with different levels of parallelism between the\ndevices and the server. Numerical results obtained using three popular datasets\ndemonstrate that the proposed framework can outperform a state-of-the-art\nframework in terms of convergence speed.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:38:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ren", "Jinke", ""], ["Liu", "Chonghe", ""], ["Yu", "Guanding", ""], ["Guo", "Dongning", ""]]}, {"id": "2107.08686", "submitter": "Shaojie Li", "authors": "Shaojie Li and Yong Liu", "title": "Improved Learning Rates for Stochastic Optimization: Two Theoretical\n  Viewpoints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization performance of stochastic optimization stands a central place\nin learning theory. In this paper, we investigate the excess risk performance\nand towards improved learning rates for two popular approaches of stochastic\noptimization: empirical risk minimization (ERM) and stochastic gradient descent\n(SGD). Although there exists plentiful generalization analysis of ERM and SGD\nfor supervised learning, current theoretical understandings of ERM and SGD\neither have stronger assumptions in convex learning, e.g., strong convexity, or\nshow slow rates and less studied in nonconvex learning. Motivated by these\nproblems, we aim to provide improved rates under milder assumptions in convex\nlearning and derive faster rates in nonconvex learning. It is notable that our\nanalysis span two popular theoretical viewpoints: \\emph{stability} and\n\\emph{uniform convergence}. Specifically, in stability regime, we present high\nprobability learning rates of order $\\mathcal{O} (1/n)$ w.r.t. the sample size\n$n$ for ERM and SGD with milder assumptions in convex learning and similar high\nprobability rates of order $\\mathcal{O} (1/n)$ in nonconvex learning, rather\nthan in expectation. Furthermore, this type of learning rate is improved to\nfaster order $\\mathcal{O} (1/n^2)$ in uniform convergence regime. To our best\nknowledge, for ERM and SGD, the learning rates presented in this paper are all\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:46:14 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 14:45:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Shaojie", ""], ["Liu", "Yong", ""]]}, {"id": "2107.08687", "submitter": "Witold Kra\\'skiewicz", "authors": "Jacek Klimek, Jakub Klimek, Witold Kraskiewicz, Mateusz Topolewski", "title": "Long-term series forecasting with Query Selector -- efficient model of\n  sparse attention", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various modifications of TRANSFORMER were recently used to solve time-series\nforecasting problem. We propose Query Selector - an efficient, deterministic\nalgorithm for sparse attention matrix. Experiments show it achieves\nstate-of-the art results on ETT data set.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 08:46:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Klimek", "Jacek", ""], ["Klimek", "Jakub", ""], ["Kraskiewicz", "Witold", ""], ["Topolewski", "Mateusz", ""]]}, {"id": "2107.08695", "submitter": "Dominik Sisejkovic", "authors": "Dominik Sisejkovic, Farhad Merchant, Lennart M. Reimann, Rainer\n  Leupers", "title": "Deceptive Logic Locking for Hardware Integrity Protection against\n  Machine Learning Attacks", "comments": "Accepted at IEEE TCAD 2021", "journal-ref": "IEEE Transactions on Computer-Aided Design of Integrated Circuits\n  and Systems (TCAD), July, 2021", "doi": "10.1109/TCAD.2021.3100275", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logic locking has emerged as a prominent key-driven technique to protect the\nintegrity of integrated circuits. However, novel machine-learning-based attacks\nhave recently been introduced to challenge the security foundations of locking\nschemes. These attacks are able to recover a significant percentage of the key\nwithout having access to an activated circuit. This paper address this issue\nthrough two focal points. First, we present a theoretical model to test locking\nschemes for key-related structural leakage that can be exploited by machine\nlearning. Second, based on the theoretical model, we introduce D-MUX: a\ndeceptive multiplexer-based logic-locking scheme that is resilient against\nstructure-exploiting machine learning attacks. Through the design of D-MUX, we\nuncover a major fallacy in existing multiplexer-based locking schemes in the\nform of a structural-analysis attack. Finally, an extensive cost evaluation of\nD-MUX is presented. To the best of our knowledge, D-MUX is the first\nmachine-learning-resilient locking scheme capable of protecting against all\nknown learning-based attacks. Hereby, the presented work offers a starting\npoint for the design and evaluation of future-generation logic locking in the\nera of machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:08:14 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sisejkovic", "Dominik", ""], ["Merchant", "Farhad", ""], ["Reimann", "Lennart M.", ""], ["Leupers", "Rainer", ""]]}, {"id": "2107.08697", "submitter": "Catarina Moreira", "authors": "Chihcheng Hsieh and Catarina Moreira and Chun Ouyang", "title": "Interpreting Process Predictions using a Milestone-Aware Counterfactual\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive process analytics often apply machine learning to predict the\nfuture states of a running business process. However, the internal mechanisms\nof many existing predictive algorithms are opaque and a human decision-maker is\nunable to understand \\emph{why} a certain activity was predicted. Recently,\ncounterfactuals have been proposed in the literature to derive\nhuman-understandable explanations from predictive models. Current\ncounterfactual approaches consist of finding the minimum feature change that\ncan make a certain prediction flip its outcome. Although many algorithms have\nbeen proposed, their application to the sequence and multi-dimensional data\nlike event logs has not been explored in the literature.\n  In this paper, we explore the use of a recent, popular model-agnostic\ncounterfactual algorithm, DiCE, in the context of predictive process analytics.\nThe analysis reveals that the algorithm is limited when being applied to derive\nexplanations of process predictions, due to (1) process domain knowledge not\nbeing taken into account, (2) long traces that often tend to be less\nunderstandable, and (3) difficulties in optimising the counterfactual search\nwith categorical variables. We design an extension of DiCE that can generate\ncounterfactuals for process predictions, and propose an approach that supports\nderiving milestone-aware counterfactuals at different stages of a trace to\npromote interpretability. We apply our approach to BPIC2012 event log and the\nanalysis results demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:14:16 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Hsieh", "Chihcheng", ""], ["Moreira", "Catarina", ""], ["Ouyang", "Chun", ""]]}, {"id": "2107.08710", "submitter": "Catherine Higham", "authors": "Catherine F. Higham and Adrian Bedford", "title": "Quantum Deep Learning: Sampling Neural Nets with a Quantum Annealer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate the feasibility of framing a classically learned deep neural\nnetwork as an energy based model that can be processed on a one-step quantum\nannealer in order to exploit fast sampling times. We propose approaches to\novercome two hurdles for high resolution image classification on a quantum\nprocessing unit (QPU): the required number and binary nature of the model\nstates. With this novel method we successfully transfer a convolutional neural\nnetwork to the QPU and show the potential for classification speedup of at\nleast one order of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:35:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Higham", "Catherine F.", ""], ["Bedford", "Adrian", ""]]}, {"id": "2107.08714", "submitter": "Zhenyu Guo", "authors": "Zhenyu Guo, Shuai Zheng, Zhizhe Liu, Kun Yan, Zhenfeng Zhu", "title": "CETransformer: Casual Effect Estimation via Transformer Based\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Treatment effect estimation, which refers to the estimation of causal effects\nand aims to measure the strength of the causal relationship, is of great\nimportance in many fields but is a challenging problem in practice. As present,\ndata-driven causal effect estimation faces two main challenges, i.e., selection\nbias and the missing of counterfactual. To address these two issues, most of\nthe existing approaches tend to reduce the selection bias by learning a\nbalanced representation, and then to estimate the counterfactual through the\nrepresentation. However, they heavily rely on the finely hand-crafted metric\nfunctions when learning balanced representations, which generally doesn't work\nwell for the situations where the original distribution is complicated. In this\npaper, we propose a CETransformer model for casual effect estimation via\ntransformer based representation learning. To learn the representation of\ncovariates(features) robustly, a self-supervised transformer is proposed, by\nwhich the correlation between covariates can be well exploited through\nself-attention mechanism. In addition, an adversarial network is adopted to\nbalance the distribution of the treated and control groups in the\nrepresentation space. Experimental results on three real-world datasets\ndemonstrate the advantages of the proposed CETransformer, compared with the\nstate-of-the-art treatment effect estimation methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:39:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Guo", "Zhenyu", ""], ["Zheng", "Shuai", ""], ["Liu", "Zhizhe", ""], ["Yan", "Kun", ""], ["Zhu", "Zhenfeng", ""]]}, {"id": "2107.08721", "submitter": "Qinkai Chen", "authors": "Qinkai Chen", "title": "Stock Movement Prediction with Financial News using Contextualized\n  Embedding from BERT", "comments": "22 pages, 6 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CL cs.LG q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News events can greatly influence equity markets. In this paper, we are\ninterested in predicting the short-term movement of stock prices after\nfinancial news events using only the headlines of the news. To achieve this\ngoal, we introduce a new text mining method called Fine-Tuned\nContextualized-Embedding Recurrent Neural Network (FT-CE-RNN). Compared with\nprevious approaches which use static vector representations of the news (static\nembedding), our model uses contextualized vector representations of the\nheadlines (contextualized embeddings) generated from Bidirectional Encoder\nRepresentations from Transformers (BERT). Our model obtains the\nstate-of-the-art result on this stock movement prediction task. It shows\nsignificant improvement compared with other baseline models, in both accuracy\nand trading simulations. Through various trading simulations based on millions\nof headlines from Bloomberg News, we demonstrate the ability of this model in\nreal scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:47:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Qinkai", ""]]}, {"id": "2107.08751", "submitter": "Marius Memmel", "authors": "Marius Memmel, Camila Gonzalez, Anirban Mukhopadhyay", "title": "Adversarial Continual Learning for Multi-Domain Hippocampal Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning for medical imaging suffers from temporal and privacy-related\nrestrictions on data availability. To still obtain viable models, continual\nlearning aims to train in sequential order, as and when data is available. The\nmain challenge that continual learning methods face is to prevent catastrophic\nforgetting, i.e., a decrease in performance on the data encountered earlier.\nThis issue makes continuous training of segmentation models for medical\napplications extremely difficult. Yet, often, data from at least two different\ndomains is available which we can exploit to train the model in a way that it\ndisregards domain-specific information. We propose an architecture that\nleverages the simultaneous availability of two or more datasets to learn a\ndisentanglement between the content and domain in an adversarial fashion. The\ndomain-invariant content representation then lays the base for continual\nsemantic segmentation. Our approach takes inspiration from domain adaptation\nand combines it with continual learning for hippocampal segmentation in brain\nMRI. We showcase that our method reduces catastrophic forgetting and\noutperforms state-of-the-art continual learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 10:55:21 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 09:43:54 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 07:10:28 GMT"}, {"version": "v4", "created": "Sun, 25 Jul 2021 14:48:14 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Memmel", "Marius", ""], ["Gonzalez", "Camila", ""], ["Mukhopadhyay", "Anirban", ""]]}, {"id": "2107.08756", "submitter": "Piotr Skalski Mr", "authors": "Iker Perez, Piotr Skalski, Alec Barns-Graham, Jason Wong, David Sutton", "title": "Path Integrals for the Attribution of Model Uncertainties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Enabling interpretations of model uncertainties is of key importance in\nBayesian machine learning applications. Often, this requires to meaningfully\nattribute predictive uncertainties to source features in an image, text or\ncategorical array. However, popular attribution methods are particularly\ndesigned for classification and regression scores. In order to explain\nuncertainties, state of the art alternatives commonly procure counterfactual\nfeature vectors, and proceed by making direct comparisons. In this paper, we\nleverage path integrals to attribute uncertainties in Bayesian differentiable\nmodels. We present a novel algorithm that relies on in-distribution curves\nconnecting a feature vector to some counterfactual counterpart, and we retain\ndesirable properties of interpretability methods. We validate our approach on\nbenchmark image data sets with varying resolution, and show that it\nsignificantly simplifies interpretability over the existing alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:07:34 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 14:32:43 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Perez", "Iker", ""], ["Skalski", "Piotr", ""], ["Barns-Graham", "Alec", ""], ["Wong", "Jason", ""], ["Sutton", "David", ""]]}, {"id": "2107.08761", "submitter": "Thomas Bartz-Beielstein", "authors": "Eva Bartz and Martin Zaefferer and Olaf Mersmann and Thomas\n  Bartz-Beielstein", "title": "Experimental Investigation and Evaluation of Model-based Hyperparameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning algorithms such as random forests or xgboost are gaining\nmore importance and are increasingly incorporated into production processes in\norder to enable comprehensive digitization and, if possible, automation of\nprocesses. Hyperparameters of these algorithms used have to be set\nappropriately, which can be referred to as hyperparameter tuning or\noptimization. Based on the concept of tunability, this article presents an\noverview of theoretical and practical results for popular machine learning\nalgorithms. This overview is accompanied by an experimental analysis of 30\nhyperparameters from six relevant machine learning algorithms. In particular,\nit provides (i) a survey of important hyperparameters, (ii) two parameter\ntuning studies, and (iii) one extensive global parameter tuning study, as well\nas (iv) a new way, based on consensus ranking, to analyze results from multiple\nalgorithms. The R package mlr is used as a uniform interface to the machine\nlearning models. The R package SPOT is used to perform the actual tuning\n(optimization). All additional code is provided together with this paper.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:37:37 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bartz", "Eva", ""], ["Zaefferer", "Martin", ""], ["Mersmann", "Olaf", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2107.08763", "submitter": "Antonious Girgis", "authors": "Antonious M. Girgis, Deepesh Data, Suhas Diggavi", "title": "Renyi Differential Privacy of the Subsampled Shuffle Model in\n  Distributed Learning", "comments": "arXiv admin note: text overlap with arXiv:2105.05180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study privacy in a distributed learning framework, where clients\ncollaboratively build a learning model iteratively through interactions with a\nserver from whom we need privacy. Motivated by stochastic optimization and the\nfederated learning (FL) paradigm, we focus on the case where a small fraction\nof data samples are randomly sub-sampled in each round to participate in the\nlearning process, which also enables privacy amplification. To obtain even\nstronger local privacy guarantees, we study this in the shuffle privacy model,\nwhere each client randomizes its response using a local differentially private\n(LDP) mechanism and the server only receives a random permutation (shuffle) of\nthe clients' responses without their association to each client. The principal\nresult of this paper is a privacy-optimization performance trade-off for\ndiscrete randomization mechanisms in this sub-sampled shuffle privacy model.\nThis is enabled through a new theoretical technique to analyze the Renyi\nDifferential Privacy (RDP) of the sub-sampled shuffle model. We numerically\ndemonstrate that, for important regimes, with composition our bound yields\nsignificant improvement in privacy guarantee over the state-of-the-art\napproximate Differential Privacy (DP) guarantee (with strong composition) for\nsub-sampled shuffled models. We also demonstrate numerically significant\nimprovement in privacy-learning performance operating point using real data\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:43:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Girgis", "Antonious M.", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2107.08765", "submitter": "Zhenhuan Huang", "authors": "Xueting Han, Zhenhuan Huang, Bang An, Jing Bai", "title": "Adaptive Transfer Learning on Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks (GNNs) is widely used to learn a powerful\nrepresentation of graph-structured data. Recent work demonstrates that\ntransferring knowledge from self-supervised tasks to downstream tasks could\nfurther improve graph representation. However, there is an inherent gap between\nself-supervised tasks and downstream tasks in terms of optimization objective\nand training data. Conventional pre-training methods may be not effective\nenough on knowledge transfer since they do not make any adaptation for\ndownstream tasks. To solve such problems, we propose a new transfer learning\nparadigm on GNNs which could effectively leverage self-supervised tasks as\nauxiliary tasks to help the target task. Our methods would adaptively select\nand combine different auxiliary tasks with the target task in the fine-tuning\nstage. We design an adaptive auxiliary loss weighting model to learn the\nweights of auxiliary tasks by quantifying the consistency between auxiliary\ntasks and the target task. In addition, we learn the weighting model through\nmeta-learning. Our methods can be applied to various transfer learning\napproaches, it performs well not only in multi-task learning but also in\npre-training and fine-tuning. Comprehensive experiments on multiple downstream\ntasks demonstrate that the proposed methods can effectively combine auxiliary\ntasks with the target task and significantly improve the performance compared\nto state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:46:28 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 05:49:52 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Han", "Xueting", ""], ["Huang", "Zhenhuan", ""], ["An", "Bang", ""], ["Bai", "Jing", ""]]}, {"id": "2107.08773", "submitter": "Jianwen Chen", "authors": "Jianwen Chen, Shuangjia Zheng, Ying Song, Jiahua Rao, Yuedong Yang", "title": "Learning Attributed Graph Representations with Communicative Message\n  Passing Transformer", "comments": "Accepted by IJCAI2021. 7 pages, 2 figures, 3 tables, 1 appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing appropriate representations of molecules lies at the core of\nnumerous tasks such as material science, chemistry and drug designs. Recent\nresearches abstract molecules as attributed graphs and employ graph neural\nnetworks (GNN) for molecular representation learning, which have made\nremarkable achievements in molecular graph modeling. Albeit powerful, current\nmodels either are based on local aggregation operations and thus miss\nhigher-order graph properties or focus on only node information without fully\nusing the edge information. For this sake, we propose a Communicative Message\nPassing Transformer (CoMPT) neural network to improve the molecular graph\nrepresentation by reinforcing message interactions between nodes and edges\nbased on the Transformer architecture. Unlike the previous transformer-style\nGNNs that treat molecules as fully connected graphs, we introduce a message\ndiffusion mechanism to leverage the graph connectivity inductive bias and\nreduce the message enrichment explosion. Extensive experiments demonstrated\nthat the proposed model obtained superior performances (around 4$\\%$ on\naverage) against state-of-the-art baselines on seven chemical property datasets\n(graph-level tasks) and two chemical shift datasets (node-level tasks). Further\nvisualization studies also indicated a better representation capacity achieved\nby our model.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 11:58:32 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 07:10:29 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chen", "Jianwen", ""], ["Zheng", "Shuangjia", ""], ["Song", "Ying", ""], ["Rao", "Jiahua", ""], ["Yang", "Yuedong", ""]]}, {"id": "2107.08784", "submitter": "Xiao Liu", "authors": "Xiao Liu, Rong Pan", "title": "Boost-R: Gradient Boosted Trees for Recurrence Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrence data arise from multi-disciplinary domains spanning reliability,\ncyber security, healthcare, online retailing, etc. This paper investigates an\nadditive-tree-based approach, known as Boost-R (Boosting for Recurrence Data),\nfor recurrent event data with both static and dynamic features. Boost-R\nconstructs an ensemble of gradient boosted additive trees to estimate the\ncumulative intensity function of the recurrent event process, where a new tree\nis added to the ensemble by minimizing the regularized L2 distance between the\nobserved and predicted cumulative intensity. Unlike conventional regression\ntrees, a time-dependent function is constructed by Boost-R on each tree leaf.\nThe sum of these functions, from multiple trees, yields the ensemble estimator\nof the cumulative intensity. The divide-and-conquer nature of tree-based\nmethods is appealing when hidden sub-populations exist within a heterogeneous\npopulation. The non-parametric nature of regression trees helps to avoid\nparametric assumptions on the complex interactions between event processes and\nfeatures. Critical insights and advantages of Boost-R are investigated through\ncomprehensive numerical examples. Datasets and computer code of Boost-R are\nmade available on GitHub. To our best knowledge, Boost-R is the first gradient\nboosted additive-tree-based approach for modeling large-scale recurrent event\ndata with both static and dynamic feature information.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:44:09 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Xiao", ""], ["Pan", "Rong", ""]]}, {"id": "2107.08785", "submitter": "Sven Elflein", "authors": "Sven Elflein, Bertrand Charpentier, Daniel Z\\\"ugner, Stephan\n  G\\\"unnemann", "title": "On Out-of-distribution Detection with Energy-based Models", "comments": "Accepted to ICML 2021 Workshop on Uncertainty & Robustness in Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several density estimation methods have shown to fail to detect\nout-of-distribution (OOD) samples by assigning higher likelihoods to anomalous\ndata. Energy-based models (EBMs) are flexible, unnormalized density models\nwhich seem to be able to improve upon this failure mode. In this work, we\nprovide an extensive study investigating OOD detection with EBMs trained with\ndifferent approaches on tabular and image data and find that EBMs do not\nprovide consistent advantages. We hypothesize that EBMs do not learn semantic\nfeatures despite their discriminative structure similar to Normalizing Flows.\nTo verify this hypotheses, we show that supervision and architectural\nrestrictions improve the OOD detection of EBMs independent of the training\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 22:09:02 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Elflein", "Sven", ""], ["Charpentier", "Bertrand", ""], ["Z\u00fcgner", "Daniel", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2107.08787", "submitter": "Ting Qi", "authors": "Yichen Lu, Jane Fridlyand, Tiffany Tang, Ting Qi, Noah Simon and Ning\n  Leng", "title": "The Future will be Different than Today: Model Evaluation Considerations\n  when Developing Translational Clinical Biomarker", "comments": "Paper has 4 pages, 2 figures. Appendix are supplementary at the end", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Finding translational biomarkers stands center stage of the future of\npersonalized medicine in healthcare. We observed notable challenges in\nidentifying robust biomarkers as some with great performance in one scenario\noften fail to perform well in new trials (e.g. different population,\nindications). With rapid development in the clinical trial world (e.g. assay,\ndisease definition), new trials very likely differ from legacy ones in many\nperspectives and in development of biomarkers this heterogeneity should be\nconsidered. In response, we recommend considering building in the heterogeneity\nwhen evaluating biomarkers. In this paper, we present one evaluation strategy\nby using leave-one-study-out (LOSO) in place of conventional cross-validation\n(cv) methods to account for the potential heterogeneity across trials used for\nbuilding and testing the biomarkers. To demonstrate the performance of K-fold\nvs LOSO cv in estimating the effect size of biomarkers, we leveraged data from\nclinical trials and simulation studies. In our assessment, LOSO cv provided a\nmore objective estimate of the future performance. This conclusion remained\ntrue across different evaluation metrics and different statistical methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 19:36:25 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lu", "Yichen", ""], ["Fridlyand", "Jane", ""], ["Tang", "Tiffany", ""], ["Qi", "Ting", ""], ["Simon", "Noah", ""], ["Leng", "Ning", ""]]}, {"id": "2107.08790", "submitter": "JoonSung Lee", "authors": "JoonSung Lee, YeongHyeon Park", "title": "Anomaly Detection Based on Multiple-Hypothesis Autoencoder", "comments": "3pages, 3figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Autoencoder(AE) based models are widely used in the field of anomaly\ndetection. A model trained with normal data generates a larger restoration\nerror for abnormal data. Whether or not abnormal data is determined by\nobserving the restoration error. It takes a lot of cost and time to obtain\nabnormal data in the industrial field. Therefore the model trains only normal\ndata and detects abnormal data in the inference phase. However, the restoration\narea for the input data of AE is limited in the latent space. To solve this\nproblem, we propose Multiple-hypothesis Autoencoder(MH-AE) model composed of\nseveral decoders. MH-AE model increases the restoration area through contention\nbetween decoders. The proposed method shows that the anomaly detection\nperformance is improved compared to the traditional AE for various input\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:09:03 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Lee", "JoonSung", ""], ["Park", "YeongHyeon", ""]]}, {"id": "2107.08792", "submitter": "Kyeongbo Kong", "authors": "Kyeongbo Kong, Kyunghun Kim, Woo-Jin Song, and Suk-Ju Kang", "title": "Selective Focusing Learning in Conditional GANs", "comments": "14 pages, 9 figures, spotlight presented at the ICML 2021 Workshop on\n  Subset Selection in ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative adversarial networks (cGANs) have demonstrated\nremarkable success due to their class-wise controllability and superior quality\nfor complex generation tasks. Typical cGANs solve the joint distribution\nmatching problem by decomposing two easier sub-problems: marginal matching and\nconditional matching. From our toy experiments, we found that it is the best to\napply only conditional matching to certain samples due to the content-aware\noptimization of the discriminator. This paper proposes a simple (a few lines of\ncode) but effective training methodology, selective focusing learning, which\nenforces the discriminator and generator to learn easy samples of each class\nrapidly while maintaining diversity. Our key idea is to selectively apply\nconditional and joint matching for the data in each mini-batch. We conducted\nexperiments on recent cGAN variants in ImageNet (64x64 and 128x128), CIFAR-10,\nand CIFAR-100 datasets, and improved the performance significantly (up to\n35.18% in terms of FID) without sacrificing diversity.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:06:56 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kong", "Kyeongbo", ""], ["Kim", "Kyunghun", ""], ["Song", "Woo-Jin", ""], ["Kang", "Suk-Ju", ""]]}, {"id": "2107.08795", "submitter": "Zhenhou Hong", "authors": "Zhenhou Hong, Jianzong Wang, Xiaoyang Qu, Jie Liu, Chendong Zhao, Jing\n  Xiao", "title": "Federated Learning with Dynamic Transformer for Text to Speech", "comments": "5 pages, accepted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Text to speech (TTS) is a crucial task for user interaction, but TTS model\ntraining relies on a sizable set of high-quality original datasets. Due to\nprivacy and security issues, the original datasets are usually unavailable\ndirectly. Recently, federated learning proposes a popular distributed machine\nlearning paradigm with an enhanced privacy protection mechanism. It offers a\npractical and secure framework for data owners to collaborate with others, thus\nobtaining a better global model trained on the larger dataset. However, due to\nthe high complexity of transformer models, the convergence process becomes slow\nand unstable in the federated learning setting. Besides, the transformer model\ntrained in federated learning is costly communication and limited computational\nspeed on clients, impeding its popularity. To deal with these challenges, we\npropose the federated dynamic transformer. On the one hand, the performance is\ngreatly improved comparing with the federated transformer, approaching\ncentralize-trained Transformer-TTS when increasing clients number. On the other\nhand, it achieves faster and more stable convergence in the training phase and\nsignificantly reduces communication time. Experiments on the LJSpeech dataset\nalso strongly prove our method's advantage.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 03:34:18 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Hong", "Zhenhou", ""], ["Wang", "Jianzong", ""], ["Qu", "Xiaoyang", ""], ["Liu", "Jie", ""], ["Zhao", "Chendong", ""], ["Xiao", "Jing", ""]]}, {"id": "2107.08800", "submitter": "Vinesha Peiris Miss", "authors": "Vinesha Peiris, Nadezda Sukhorukova, Vera Roshchina", "title": "Deep Learning with Nonsmooth Objectives", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the potential for using a nonsmooth loss function based on the\nmax-norm in the training of an artificial neural network. We hypothesise that\nthis may lead to superior classification results in some special cases where\nthe training data is either very small or unbalanced.\n  Our numerical experiments performed on a simple artificial neural network\nwith no hidden layers (a setting immediately amenable to standard nonsmooth\noptimisation techniques) appear to confirm our hypothesis that uniform\napproximation based approaches may be more suitable for the datasets with\nreliable training data that either is limited size or biased in terms of\nrelative cluster sizes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 02:01:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Peiris", "Vinesha", ""], ["Sukhorukova", "Nadezda", ""], ["Roshchina", "Vera", ""]]}, {"id": "2107.08814", "submitter": "Abdullatif Baba", "authors": "Shadi Al Shehabi and Abdullatif Baba", "title": "MARC: Mining Association Rules from datasets by using Clustering models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Association rules are useful to discover relationships, which are mostly\nhidden, between the different items in large datasets. Symbolic models are the\nprincipal tools to extract association rules. This basic technique is\ntime-consuming, and it generates a big number of associated rules. To overcome\nthis drawback, we suggest a new method, called MARC, to extract the more\nimportant association rules of two important levels: Type I, and Type II. This\napproach relies on a multi-topographic unsupervised neural network model as\nwell as clustering quality measures that evaluate the success of a given\nnumerical classification model to behave as a natural symbolic model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 06:28:42 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shehabi", "Shadi Al", ""], ["Baba", "Abdullatif", ""]]}, {"id": "2107.08815", "submitter": "Jiandong Mu", "authors": "Jiandong Mu, Mengdi Wang, Feiwen Zhu, Jun Yang, Wei Lin, Wei Zhang", "title": "Boosting the Convergence of Reinforcement Learning-based Auto-pruning\n  Using Historical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural network compression schemes like channel pruning have been\nwidely used to reduce the model size and computational complexity of deep\nneural network (DNN) for applications in power-constrained scenarios such as\nembedded systems. Reinforcement learning (RL)-based auto-pruning has been\nfurther proposed to automate the DNN pruning process to avoid expensive\nhand-crafted work. However, the RL-based pruner involves a time-consuming\ntraining process and the high expense of each sample further exacerbates this\nproblem. These impediments have greatly restricted the real-world application\nof RL-based auto-pruning. Thus, in this paper, we propose an efficient\nauto-pruning framework which solves this problem by taking advantage of the\nhistorical data from the previous auto-pruning process. In our framework, we\nfirst boost the convergence of the RL-pruner by transfer learning. Then, an\naugmented transfer learning scheme is proposed to further speed up the training\nprocess by improving the transferability. Finally, an assistant learning\nprocess is proposed to improve the sample efficiency of the RL agent. The\nexperiments have shown that our framework can accelerate the auto-pruning\nprocess by 1.5-2.5 times for ResNet20, and 1.81-2.375 times for other neural\nnetworks like ResNet56, ResNet18, and MobileNet v1.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 07:17:26 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Mu", "Jiandong", ""], ["Wang", "Mengdi", ""], ["Zhu", "Feiwen", ""], ["Yang", "Jun", ""], ["Lin", "Wei", ""], ["Zhang", "Wei", ""]]}, {"id": "2107.08819", "submitter": "Sudharsan S", "authors": "J.Meiyazhagan, S. Sudharsan, and M. Senthilvelan", "title": "Model-free prediction of emergence of extreme events in a parametrically\n  driven nonlinear dynamical system by Deep Learning", "comments": "To appear in The European Physical Journal B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We predict the emergence of extreme events in a parametrically driven\nnonlinear dynamical system using three Deep Learning models, namely Multi-Layer\nPerceptron, Convolutional Neural Network and Long Short-Term Memory. The Deep\nLearning models are trained using the training set and are allowed to predict\nthe test set data. After prediction, the time series of the actual and the\npredicted values are plotted one over the other in order to visualize the\nperformance of the models. Upon evaluating the Root Mean Square Error value\nbetween predicted and the actual values of all three models, we find that the\nLong Short-Term Memory model can serve as the best model to forecast the\nchaotic time series and to predict the emergence of extreme events for the\nconsidered system.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:48:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Meiyazhagan", "J.", ""], ["Sudharsan", "S.", ""], ["Senthilvelan", "M.", ""]]}, {"id": "2107.08821", "submitter": "Jie Ren", "authors": "Quanshi Zhang, Tian Han, Lixin Fan, Zhanxing Zhu, Hang Su, Ying Nian\n  Wu, Jie Ren, Hao Zhang", "title": "Proceedings of ICML 2021 Workshop on Theoretic Foundation, Criticism,\n  and Application Trend of Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of ICML 2021 Workshop on Theoretic Foundation,\nCriticism, and Application Trend of Explainable AI. Deep neural networks (DNNs)\nhave undoubtedly brought great success to a wide range of applications in\ncomputer vision, computational linguistics, and AI. However, foundational\nprinciples underlying the DNNs' success and their resilience to adversarial\nattacks are still largely missing. Interpreting and theorizing the internal\nmechanisms of DNNs becomes a compelling yet controversial topic. This workshop\npays a special interest in theoretic foundations, limitations, and new\napplication trends in the scope of XAI. These issues reflect new bottlenecks in\nthe future development of XAI.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:14:16 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 12:34:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Quanshi", ""], ["Han", "Tian", ""], ["Fan", "Lixin", ""], ["Zhu", "Zhanxing", ""], ["Su", "Hang", ""], ["Wu", "Ying Nian", ""], ["Ren", "Jie", ""], ["Zhang", "Hao", ""]]}, {"id": "2107.08823", "submitter": "Ha Young Jo", "authors": "Ha Young Jo, Seong-Whan Lee", "title": "One-Class Classification for Wafer Map using Adversarial Autoencoder\n  with DSVDD Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, semiconductors' demand has exploded in virtual reality,\nsmartphones, wearable devices, the internet of things, robotics, and\nautomobiles. Semiconductor manufacturers want to make semiconductors with high\nyields. To do this, manufacturers conduct many quality assurance activities.\nWafer map pattern classification is a typical way of quality assurance. The\ndefect pattern on the wafer map can tell us which process has a problem. Most\nof the existing wafer map classification methods are based on supervised\nmethods. The supervised methods tend to have high performance, but they require\nextensive labor and expert knowledge to produce labeled datasets with a\nbalanced distribution in mind. In the semiconductor manufacturing process, it\nis challenging to get defect data with balanced distribution. In this paper, we\npropose a one-class classification method using an Adversarial Autoencoder\n(AAE) with Deep Support Vector Data Description (DSVDD) prior, which generates\nrandom vectors within the hypersphere of DSVDD. We use the WM-811k dataset,\nwhich consists of a real-world wafer map. We compare the F1 score performance\nof our model with DSVDD and AAE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:45:27 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Jo", "Ha Young", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2107.08828", "submitter": "Adish Singla", "authors": "Adish Singla, Anna N. Rafferty, Goran Radanovic, Neil T. Heffernan", "title": "Reinforcement Learning for Education: Opportunities and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey article has grown out of the RL4ED workshop organized by the\nauthors at the Educational Data Mining (EDM) 2021 conference. We organized this\nworkshop as part of a community-building effort to bring together researchers\nand practitioners interested in the broad areas of reinforcement learning (RL)\nand education (ED). This article aims to provide an overview of the workshop\nactivities and summarize the main research directions in the area of RL for ED.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 21:27:45 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Singla", "Adish", ""], ["Rafferty", "Anna N.", ""], ["Radanovic", "Goran", ""], ["Heffernan", "Neil T.", ""]]}, {"id": "2107.08829", "submitter": "Rafael Rafailov", "authors": "Rafael Rafailov, Tianhe Yu, Aravind Rajeswaran, Chelsea Finn", "title": "Visual Adversarial Imitation Learning using Variational Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reward function specification, which requires considerable human effort and\niteration, remains a major impediment for learning behaviors through deep\nreinforcement learning. In contrast, providing visual demonstrations of desired\nbehaviors often presents an easier and more natural way to teach agents. We\nconsider a setting where an agent is provided a fixed dataset of visual\ndemonstrations illustrating how to perform a task, and must learn to solve the\ntask using the provided demonstrations and unsupervised environment\ninteractions. This setting presents a number of challenges including\nrepresentation learning for visual observations, sample complexity due to high\ndimensional spaces, and learning instability due to the lack of a fixed reward\nor learning signal. Towards addressing these challenges, we develop a\nvariational model-based adversarial imitation learning (V-MAIL) algorithm. The\nmodel-based approach provides a strong signal for representation learning,\nenables sample efficiency, and improves the stability of adversarial training\nby enabling on-policy learning. Through experiments involving several\nvision-based locomotion and manipulation tasks, we find that V-MAIL learns\nsuccessful visuomotor policies in a sample-efficient manner, has better\nstability compared to prior work, and also achieves higher asymptotic\nperformance. We further find that by transferring the learned models, V-MAIL\ncan learn new tasks from visual demonstrations without any additional\nenvironment interactions. All results including videos can be found online at\n\\url{https://sites.google.com/view/variational-mail}.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 00:15:18 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Rafailov", "Rafael", ""], ["Yu", "Tianhe", ""], ["Rajeswaran", "Aravind", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.08834", "submitter": "Conrad Sanderson", "authors": "Xiaolong Zhu, Fernando Vanegas, Felipe Gonzalez, Conrad Sanderson", "title": "A Multi-UAV System for Exploration and Target Finding in Cluttered and\n  GPS-Denied Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of multi-rotor Unmanned Aerial Vehicles (UAVs) for search and rescue\nas well as remote sensing is rapidly increasing. Multi-rotor UAVs, however,\nhave limited endurance. The range of UAV applications can be widened if teams\nof multiple UAVs are used. We propose a framework for a team of UAVs to\ncooperatively explore and find a target in complex GPS-denied environments with\nobstacles. The team of UAVs autonomously navigates, explores, detects, and\nfinds the target in a cluttered environment with a known map. Examples of such\nenvironments include indoor scenarios, urban or natural canyons, caves, and\ntunnels, where the GPS signal is limited or blocked. The framework is based on\na probabilistic decentralised Partially Observable Markov Decision Process\nwhich accounts for the uncertainties in sensing and the environment. The team\ncan cooperate efficiently, with each UAV sharing only limited processed\nobservations and their locations during the mission. The system is simulated\nusing the Robotic Operating System and Gazebo. Performance of the system with\nan increasing number of UAVs in several indoor scenarios with obstacles is\ntested. Results indicate that the proposed multi-UAV system has improvements in\nterms of time-cost, the proportion of search area surveyed, as well as\nsuccessful rates for search and rescue missions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:54:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Zhu", "Xiaolong", ""], ["Vanegas", "Fernando", ""], ["Gonzalez", "Felipe", ""], ["Sanderson", "Conrad", ""]]}, {"id": "2107.08835", "submitter": "Jiuqi (Elise) Zhang", "authors": "Jiuqi Elise Zhang, Di Wu, Benoit Boulet", "title": "Time Series Anomaly Detection for Smart Grids: A Survey", "comments": "6 pages; Preprint Submitted to IEEE Canadian Electrical Power and\n  Energy Conference (EPEC2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increase in the integration of renewable energy generation and\nthe wide adoption of various electric appliances, power grids are now faced\nwith more and more challenges. One prominent challenge is to implement\nefficient anomaly detection for different types of anomalous behaviors within\npower grids. These anomalous behaviors might be induced by unusual consumption\npatterns of the users, faulty grid infrastructures, outages, external\ncyberattacks, or energy fraud. Identifying such anomalies is of critical\nimportance for the reliable and efficient operation of modern power grids.\nVarious methods have been proposed for anomaly detection on power grid\ntime-series data. This paper presents a short survey of the recent advances in\nanomaly detection for power grid time-series data. Specifically, we first\noutline current research challenges in the power grid anomaly detection domain\nand further review the major anomaly detection approaches. Finally, we conclude\nthe survey by identifying the potential directions for future research.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 14:33:59 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Zhang", "Jiuqi Elise", ""], ["Wu", "Di", ""], ["Boulet", "Benoit", ""]]}, {"id": "2107.08849", "submitter": "Theodoros Ntakouris", "authors": "Theodoros Ntakouris", "title": "Exploring the efficacy of neural networks for trajectory compression and\n  the inverse problem", "comments": "7 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this document, a neural network is employed in order to estimate the\nsolution of the initial value problem in the context of non linear\ntrajectories. Such trajectories can be subject to gravity, thrust, drag,\ncentrifugal force, temperature, ambient air density and pressure. First, we\ngenerate a grid of trajectory points given a specified uniform density as a\ndesign parameter and then we investigate the performance of a neural network in\na compression and inverse problem task: the network is trained to predict the\ninitial conditions of the dynamics model we used in the simulation, given a\ntarget point in space. We investigate this as a regression task, with error\npropagation in consideration. For target points, up to a radius of 2\nkilometers, the model is able to accurately predict the initial conditions of\nthe trajectories, with sub-meter deviation. This simulation-based training\nprocess and novel real-world evaluation method is capable of computing\ntrajectories of arbitrary dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:05:50 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ntakouris", "Theodoros", ""]]}, {"id": "2107.08850", "submitter": "Jonathan Ganz", "authors": "Jonathan Ganz, Tobias Kirsch, Lucas Hoffmann, Christof A. Bertram,\n  Christoph Hoffmann, Andreas Maier, Katharina Breininger, Ingmar Bl\\\"umcke,\n  Samir Jabari, Marc Aubreville", "title": "Automatic and explainable grading of meningiomas from histopathology\n  images", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meningioma is one of the most prevalent brain tumors in adults. To determine\nits malignancy, it is graded by a pathologist into three grades according to\nWHO standards. This grade plays a decisive role in treatment, and yet may be\nsubject to inter-rater discordance. In this work, we present and compare three\napproaches towards fully automatic meningioma grading from histology whole\nslide images. All approaches are following a two-stage paradigm, where we first\nidentify a region of interest based on the detection of mitotic figures in the\nslide using a state-of-the-art object detection deep learning network. This\nregion of highest mitotic rate is considered characteristic for biological\ntumor behavior. In the second stage, we calculate a score corresponding to\ntumor malignancy based on information contained in this region using three\ndifferent settings. In a first approach, image patches are sampled from this\nregion and regression is based on morphological features encoded by a\nResNet-based network. We compare this to learning a logistic regression from\nthe determined mitotic count, an approach which is easily traceable and\nexplainable. Lastly, we combine both approaches in a single network. We trained\nthe pipeline on 951 slides from 341 patients and evaluated them on a separate\nset of 141 slides from 43 patients. All approaches yield a high correlation to\nthe WHO grade. The logistic regression and the combined approach had the best\nresults in our experiments, yielding correct predictions in 32 and 33 of all\ncases, respectively, with the image-based approach only predicting 25 cases\ncorrectly. Spearman's correlation was 0.716, 0.792 and 0.790 respectively. It\nmay seem counterintuitive at first that morphological features provided by\nimage patches do not improve model performance. Yet, this mirrors the criteria\nof the grading scheme, where mitotic count is the only unequivocal parameter.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:05:51 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ganz", "Jonathan", ""], ["Kirsch", "Tobias", ""], ["Hoffmann", "Lucas", ""], ["Bertram", "Christof A.", ""], ["Hoffmann", "Christoph", ""], ["Maier", "Andreas", ""], ["Breininger", "Katharina", ""], ["Bl\u00fcmcke", "Ingmar", ""], ["Jabari", "Samir", ""], ["Aubreville", "Marc", ""]]}, {"id": "2107.08861", "submitter": "Yang Li", "authors": "Yang Li, Yu Shen, Wentao Zhang, Jiawei Jiang, Bolin Ding, Yaliang Li,\n  Jingren Zhou, Zhi Yang, Wentao Wu, Ce Zhang and Bin Cui", "title": "VolcanoML: Speeding up End-to-End AutoML via Scalable Search Space\n  Decomposition", "comments": null, "journal-ref": "47th International Conference on Very Large Data Bases, VLDB 2021,\n  PVLDB Volume 14, Issue 11", "doi": "10.14778/3476249.3476270", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end AutoML has attracted intensive interests from both academia and\nindustry, which automatically searches for ML pipelines in a space induced by\nfeature engineering, algorithm/model selection, and hyper-parameter tuning.\nExisting AutoML systems, however, suffer from scalability issues when applying\nto application domains with large, high-dimensional search spaces. We present\nVolcanoML, a scalable and extensible framework that facilitates systematic\nexploration of large AutoML search spaces. VolcanoML introduces and implements\nbasic building blocks that decompose a large search space into smaller ones,\nand allows users to utilize these building blocks to compose an execution plan\nfor the AutoML problem at hand. VolcanoML further supports a Volcano-style\nexecution model - akin to the one supported by modern database systems - to\nexecute the plan constructed. Our evaluation demonstrates that, not only does\nVolcanoML raise the level of expressiveness for search space decomposition in\nAutoML, it also leads to actual findings of decomposition strategies that are\nsignificantly more efficient than the ones employed by state-of-the-art AutoML\nsystems such as auto-sklearn.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:23:57 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 08:37:49 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Li", "Yang", ""], ["Shen", "Yu", ""], ["Zhang", "Wentao", ""], ["Jiang", "Jiawei", ""], ["Ding", "Bolin", ""], ["Li", "Yaliang", ""], ["Zhou", "Jingren", ""], ["Yang", "Zhi", ""], ["Wu", "Wentao", ""], ["Zhang", "Ce", ""], ["Cui", "Bin", ""]]}, {"id": "2107.08865", "submitter": "Siwei Chen", "authors": "Siwei Chen, Xiao Ma, Yunfan Lu and David Hsu", "title": "Ab Initio Particle-based Object Manipulation", "comments": "Robotics: Science and Systems (RSS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Particle-based Object Manipulation (Prompt), a new\napproach to robot manipulation of novel objects ab initio, without prior object\nmodels or pre-training on a large object data set. The key element of Prompt is\na particle-based object representation, in which each particle represents a\npoint in the object, the local geometric, physical, and other features of the\npoint, and also its relation with other particles. Like the model-based\nanalytic approaches to manipulation, the particle representation enables the\nrobot to reason about the object's geometry and dynamics in order to choose\nsuitable manipulation actions. Like the data-driven approaches, the particle\nrepresentation is learned online in real-time from visual sensor input,\nspecifically, multi-view RGB images. The particle representation thus connects\nvisual perception with robot control. Prompt combines the benefits of both\nmodel-based reasoning and data-driven learning. We show empirically that Prompt\nsuccessfully handles a variety of everyday objects, some of which are\ntransparent. It handles various manipulation tasks, including grasping,\npushing, etc,. Our experiments also show that Prompt outperforms a\nstate-of-the-art data-driven grasping method on the daily objects, even though\nit does not use any offline training data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:27:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Siwei", ""], ["Ma", "Xiao", ""], ["Lu", "Yunfan", ""], ["Hsu", "David", ""]]}, {"id": "2107.08873", "submitter": "Guang Yang", "authors": "Guang Yang, Ke Mu, Chunhe Song, Zhijia Yang, and Tierui Gong", "title": "RingFed: Reducing Communication Costs in Federated Learning on Non-IID\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is a widely used distributed deep learning framework that\nprotects the privacy of each client by exchanging model parameters rather than\nraw data. However, federated learning suffers from high communication costs, as\na considerable number of model parameters need to be transmitted many times\nduring the training process, making the approach inefficient, especially when\nthe communication network bandwidth is limited. This article proposes RingFed,\na novel framework to reduce communication overhead during the training process\nof federated learning. Rather than transmitting parameters between the center\nserver and each client, as in original federated learning, in the proposed\nRingFed, the updated parameters are transmitted between each client in turn,\nand only the final result is transmitted to the central server, thereby\nreducing the communication overhead substantially. After several local updates,\nclients first send their parameters to another proximal client, not to the\ncenter server directly, to preaggregate. Experiments on two different public\ndatasets show that RingFed has fast convergence, high model accuracy, and low\ncommunication cost.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:43:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yang", "Guang", ""], ["Mu", "Ke", ""], ["Song", "Chunhe", ""], ["Yang", "Zhijia", ""], ["Gong", "Tierui", ""]]}, {"id": "2107.08881", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Matko Bo\\v{s}njak, Thomas Kipf, Alexander\n  Lerchner, Raia Hadsell, Razvan Pascanu, Charles Blundell", "title": "Reasoning-Modulated Representations", "comments": "ICML 2021 Workshop on Self-Supervised Learning for Reasoning and\n  Perception (Spotlight Talk). 7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks leverage robust internal representations in order to\ngeneralise. Learning them is difficult, and often requires a large training set\nthat covers the data distribution densely. We study a common setting where our\ntask is not purely opaque. Indeed, very often we may have access to information\nabout the underlying system (e.g. that observations must obey certain laws of\nphysics) that any \"tabula rasa\" neural network would need to re-learn from\nscratch, penalising data efficiency. We incorporate this information into a\npre-trained reasoning module, and investigate its role in shaping the\ndiscovered representations in diverse self-supervised learning settings from\npixels. Our approach paves the way for a new class of data-efficient\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:57:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Bo\u0161njak", "Matko", ""], ["Kipf", "Thomas", ""], ["Lerchner", "Alexander", ""], ["Hadsell", "Raia", ""], ["Pascanu", "Razvan", ""], ["Blundell", "Charles", ""]]}, {"id": "2107.08888", "submitter": "Mingqi Yuan", "authors": "Mingqi Yuan, Mon-on Pun, Yi Chen, Dong Wang, Haojun Li", "title": "Multimodal Reward Shaping for Efficient Exploration in Reinforcement\n  Learning", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Maintaining long-term exploration ability remains one of the challenges of\ndeep reinforcement learning (DRL). In practice, the reward shaping-based\napproaches are leveraged to provide intrinsic rewards for the agent to\nincentivize motivation. However, most existing IRS modules rely on attendant\nmodels or additional memory to record and analyze learning procedures, which\nleads to high computational complexity and low robustness. Moreover, they\noveremphasize the influence of a single state on exploration, which cannot\nevaluate the exploration performance from a global perspective. To tackle the\nproblem, state entropy-based methods are proposed to encourage the agent to\nvisit the state space more equitably. However, the estimation error and sample\ncomplexity are prohibitive when handling environments with high-dimensional\nobservation. In this paper, we introduce a novel metric entitled Jain's\nfairness index (JFI) to replace the entropy regularizer, which requires no\nadditional models or memory. In particular, JFI overcomes the vanishing\nintrinsic rewards problem and can be generalized into arbitrary tasks.\nFurthermore, we use a variational auto-encoder (VAE) model to capture the\nlife-long novelty of states. Finally, the global JFI score and local state\nnovelty are combined to form a multimodal intrinsic reward, controlling the\nexploration extent more precisely. Finally, extensive simulation results\ndemonstrate that our multimodal reward shaping (MMRS) method can achieve higher\nperformance in contrast to other benchmark schemes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:04:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yuan", "Mingqi", ""], ["Pun", "Mon-on", ""], ["Chen", "Yi", ""], ["Wang", "Dong", ""], ["Li", "Haojun", ""]]}, {"id": "2107.08902", "submitter": "Anjum Anjum", "authors": "Bhumika Bhatia, Anuj Verma, Anjum, Rahul Katarya", "title": "Analysing Cyberbullying using Natural Language Processing by\n  Understanding Jargon in Social Media", "comments": "10 pages", "journal-ref": "Sustainable Advanced Computing - Select Proceedings of ICSAC 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyberbullying is of extreme prevalence today. Online-hate comments, toxicity,\ncyberbullying amongst children and other vulnerable groups are only growing\nover online classes, and increased access to social platforms, especially post\nCOVID-19. It is paramount to detect and ensure minors' safety across social\nplatforms so that any violence or hate-crime is automatically detected and\nstrict action is taken against it. In our work, we explore binary\nclassification by using a combination of datasets from various social media\nplatforms that cover a wide range of cyberbullying such as sexism, racism,\nabusive, and hate-speech. We experiment through multiple models such as\nBi-LSTM, GloVe, state-of-the-art models like BERT, and apply a unique\npreprocessing technique by introducing a slang-abusive corpus, achieving a\nhigher precision in comparison to models without slang preprocessing.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 04:20:19 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bhatia", "Bhumika", ""], ["Verma", "Anuj", ""], ["Anjum", "", ""], ["Katarya", "Rahul", ""]]}, {"id": "2107.08909", "submitter": "Takayuki Miura", "authors": "Takayuki Miura, Satoshi Hasegawa, Toshiki Shibahara", "title": "MEGEX: Data-Free Model Extraction Attack against Gradient-Based\n  Explainable AI", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advance of explainable artificial intelligence, which provides reasons\nfor its predictions, is expected to accelerate the use of deep neural networks\nin the real world like Machine Learning as a Service (MLaaS) that returns\npredictions on queried data with the trained model. Deep neural networks\ndeployed in MLaaS face the threat of model extraction attacks. A model\nextraction attack is an attack to violate intellectual property and privacy in\nwhich an adversary steals trained models in a cloud using only their\npredictions. In particular, a data-free model extraction attack has been\nproposed recently and is more critical. In this attack, an adversary uses a\ngenerative model instead of preparing input data. The feasibility of this\nattack, however, needs to be studied since it requires more queries than that\nwith surrogate datasets. In this paper, we propose MEGEX, a data-free model\nextraction attack against a gradient-based explainable AI. In this method, an\nadversary uses the explanations to train the generative model and reduces the\nnumber of queries to steal the model. Our experiments show that our proposed\nmethod reconstructs high-accuracy models -- 0.97$\\times$ and 0.98$\\times$ the\nvictim model accuracy on SVHN and CIFAR-10 datasets given 2M and 20M queries,\nrespectively. This implies that there is a trade-off between the\ninterpretability of models and the difficulty of stealing them.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:25:06 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Miura", "Takayuki", ""], ["Hasegawa", "Satoshi", ""], ["Shibahara", "Toshiki", ""]]}, {"id": "2107.08924", "submitter": "Ian Osband", "authors": "Ian Osband, Zheng Wen, Mohammad Asghari, Morteza Ibrahimi, Xiyuan Lu,\n  and Benjamin Van Roy", "title": "Epistemic Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \\textit{epistemic neural network} (ENN) as an interface for\nuncertainty modeling in deep learning. All existing approaches to uncertainty\nmodeling can be expressed as ENNs, and any ENN can be identified with a\nBayesian neural network. However, this new perspective provides several\npromising directions for future research. Where prior work has developed\nprobabilistic inference tools for neural networks; we ask instead, `which\nneural networks are suitable as tools for probabilistic inference?'. We propose\na clear and simple metric for progress in ENNs: the KL-divergence with respect\nto a target distribution. We develop a computational testbed based on inference\nin a neural network Gaussian process and release our code as a benchmark at\n\\url{https://github.com/deepmind/enn}. We evaluate several canonical approaches\nto uncertainty modeling in deep learning, and find they vary greatly in their\nperformance. We provide insight to the sensitivity of these results and show\nthat our metric is highly correlated with performance in sequential decision\nproblems. Finally, we provide indications that new ENN architectures can\nimprove performance in both the statistical quality and computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:37:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Osband", "Ian", ""], ["Wen", "Zheng", ""], ["Asghari", "Mohammad", ""], ["Ibrahimi", "Morteza", ""], ["Lu", "Xiyuan", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2107.08925", "submitter": "Christoph Martin", "authors": "Christoph Martin, Nahal Sharafi, Sarah Hallerberg", "title": "Estimating covariant Lyapunov vectors from data", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG nlin.CD physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariant Lyapunov vectors (CLVs) characterize the directions along which\nperturbations in dynamical systems grow. They have also been studied as\npotential predictors of critical transitions and extreme events. For many\napplications, it is, however, necessary to estimate the vectors from data since\nmodel equations are unknown for many interesting phenomena. We propose a novel\nmethod for estimating CLVs based on data records without knowing the underlying\nequations of the system which is suitable also for high-dimensional data and\ncomputationally inexpensive. We demonstrate that this purely data-driven\napproach can accurately estimate CLVs from data records generated by chaotic\ndynamical systems of dimension 128 and multiple lower-dimensional systems and\nthus provides the foundation for numerous future applications in data-analysis\nand data-based predictions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:43:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Martin", "Christoph", ""], ["Sharafi", "Nahal", ""], ["Hallerberg", "Sarah", ""]]}, {"id": "2107.08928", "submitter": "William Blanzeisky", "authors": "William Blanzeisky, P\\'adraig Cunningham, Kenneth Kennedy", "title": "Introducing a Family of Synthetic Datasets for Research on Bias in\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A significant impediment to progress in research on bias in machine learning\n(ML) is the availability of relevant datasets. This situation is unlikely to\nchange much given the sensitivity of such data. For this reason, there is a\nrole for synthetic data in this research. In this short paper, we present one\nsuch family of synthetic data sets. We provide an overview of the data,\ndescribe how the level of bias can be varied, and present a simple example of\nan experiment on the data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:40:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Blanzeisky", "William", ""], ["Cunningham", "P\u00e1draig", ""], ["Kennedy", "Kenneth", ""]]}, {"id": "2107.08933", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Hamid Eghbal-zadeh, Florian Henkel, Jan Schl\\\"uter,\n  Gerhard Widmer", "title": "Over-Parameterization and Generalization in Audio Classification", "comments": "Presented at the ICML 2021 Workshop on Overparameterization: Pitfalls\n  & Opportunities", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have been dominating classification\ntasks in various domains, such as machine vision, machine listening, and\nnatural language processing. In machine listening, while generally exhibiting\nvery good generalization capabilities, CNNs are sensitive to the specific audio\nrecording device used, which has been recognized as a substantial problem in\nthe acoustic scene classification (DCASE) community. In this study, we\ninvestigate the relationship between over-parameterization of acoustic scene\nclassification models, and their resulting generalization abilities.\nSpecifically, we test scaling CNNs in width and depth, under different\nconditions. Our results indicate that increasing width improves generalization\nto unseen devices, even without an increase in the number of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:48:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Koutini", "Khaled", ""], ["Eghbal-zadeh", "Hamid", ""], ["Henkel", "Florian", ""], ["Schl\u00fcter", "Jan", ""], ["Widmer", "Gerhard", ""]]}, {"id": "2107.08942", "submitter": "Priya Sundaresan", "authors": "Priya Sundaresan, Jennifer Grannen, Brijen Thananjeyan, Ashwin\n  Balakrishna, Jeffrey Ichnowski, Ellen Novoseller, Minho Hwang, Michael\n  Laskey, Joseph E. Gonzalez, Ken Goldberg", "title": "Untangling Dense Non-Planar Knots by Learning Manipulation Features and\n  Recovery Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot manipulation for untangling 1D deformable structures such as ropes,\ncables, and wires is challenging due to their infinite dimensional\nconfiguration space, complex dynamics, and tendency to self-occlude. Analytical\ncontrollers often fail in the presence of dense configurations, due to the\ndifficulty of grasping between adjacent cable segments. We present two\nalgorithms that enhance robust cable untangling, LOKI and SPiDERMan, which\noperate alongside HULK, a high-level planner from prior work. LOKI uses a\nlearned model of manipulation features to refine a coarse grasp keypoint\nprediction to a precise, optimized location and orientation, while SPiDERMan\nuses a learned model to sense task progress and apply recovery actions. We\nevaluate these algorithms in physical cable untangling experiments with 336\nknots and over 1500 actions on real cables using the da Vinci surgical robot.\nWe find that the combination of HULK, LOKI, and SPiDERMan is able to untangle\ndense overhand, figure-eight, double-overhand, square, bowline, granny,\nstevedore, and triple-overhand knots. The composition of these methods\nsuccessfully untangles a cable from a dense initial configuration in 68.3% of\n60 physical experiments and achieves 50% higher success rates than baselines\nfrom prior work. Supplementary material, code, and videos can be found at\nhttps://tinyurl.com/rssuntangling.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 04:13:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sundaresan", "Priya", ""], ["Grannen", "Jennifer", ""], ["Thananjeyan", "Brijen", ""], ["Balakrishna", "Ashwin", ""], ["Ichnowski", "Jeffrey", ""], ["Novoseller", "Ellen", ""], ["Hwang", "Minho", ""], ["Laskey", "Michael", ""], ["Gonzalez", "Joseph E.", ""], ["Goldberg", "Ken", ""]]}, {"id": "2107.08943", "submitter": "Jongjin Park", "authors": "Jongjin Park, Sukmin Yun, Jongheon Jeong, Jinwoo Shin", "title": "OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set\n  Unlabeled Data", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern semi-supervised learning methods conventionally assume both labeled\nand unlabeled data have the same class distribution. However, unlabeled data\nmay include out-of-class samples in practice; those that cannot have one-hot\nencoded labels from a closed-set of classes in label data, i.e., unlabeled data\nis an open-set. In this paper, we introduce OpenCoS, a method for handling this\nrealistic semi-supervised learning scenario based on a recent framework of\ncontrastive learning. One of our key findings is that out-of-class samples in\nthe unlabeled dataset can be identified effectively via (unsupervised)\ncontrastive learning. OpenCoS utilizes this information to overcome the failure\nmodes in the existing state-of-the-art semi-supervised methods, e.g.,\nReMixMatch or FixMatch. It further improves the semi-supervised performance by\nutilizing soft- and pseudo-labels on open-set unlabeled data, learned from\ncontrastive learning. Our extensive experimental results show the effectiveness\nof OpenCoS, fixing the state-of-the-art semi-supervised methods to be suitable\nfor diverse scenarios involving open-set unlabeled data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 06:10:05 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Park", "Jongjin", ""], ["Yun", "Sukmin", ""], ["Jeong", "Jongheon", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2107.08948", "submitter": "Carsten Ditzel", "authors": "Carsten Ditzel and Klaus Dietmayer", "title": "GenRadar: Self-supervised Probabilistic Camera Synthesis based on Radar\n  Frequencies", "comments": "concurrently submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous systems require a continuous and dependable environment perception\nfor navigation and decision-making, which is best achieved by combining\ndifferent sensor types. Radar continues to function robustly in compromised\ncircumstances in which cameras become impaired, guaranteeing a steady inflow of\ninformation. Yet, camera images provide a more intuitive and readily applicable\nimpression of the world. This work combines the complementary strengths of both\nsensor types in a unique self-learning fusion approach for a probabilistic\nscene reconstruction in adverse surrounding conditions. After reducing the\nmemory requirements of both high-dimensional measurements through a decoupled\nstochastic self-supervised compression technique, the proposed algorithm\nexploits similarities and establishes correspondences between both domains at\ndifferent feature levels during training. Then, at inference time, relying\nexclusively on radio frequencies, the model successively predicts camera\nconstituents in an autoregressive and self-contained process. These discrete\ntokens are finally transformed back into an instructive view of the respective\nsurrounding, allowing to visually perceive potential dangers for important\ntasks downstream.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:00:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ditzel", "Carsten", ""], ["Dietmayer", "Klaus", ""]]}, {"id": "2107.08957", "submitter": "Xi Yang", "authors": "Xi Yang, Zehao Yu, Yi Guo, Jiang Bian and Yonghui Wu", "title": "Clinical Relation Extraction Using Transformer-based Models", "comments": "1 Figure; 36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The newly emerged transformer technology has a tremendous impact on NLP\nresearch. In the general English domain, transformer-based models have achieved\nstate-of-the-art performances on various NLP benchmarks. In the clinical\ndomain, researchers also have investigated transformer models for clinical\napplications. The goal of this study is to systematically explore three widely\nused transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical\nrelation extraction and develop an open-source package with clinical\npre-trained transformer-based models to facilitate information extraction in\nthe clinical domain. We developed a series of clinical RE models based on three\ntransformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these\nmodels using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2\nchallenges. We compared two classification strategies (binary vs. multi-class\nclassification) and investigated two approaches to generate candidate relations\nin different experimental settings. In this study, we compared three\ntransformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We\ndemonstrated that the RoBERTa-clinical RE model achieved the best performance\non the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2\ndataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our\nresults indicated that the binary classification strategy consistently\noutperformed the multi-class classification strategy for clinical relation\nextraction. Our methods and models are publicly available at\nhttps://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction.\nWe believe this work will improve current practice on clinical relation\nextraction and other related NLP tasks in the biomedical domain.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:15:51 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yang", "Xi", ""], ["Yu", "Zehao", ""], ["Guo", "Yi", ""], ["Bian", "Jiang", ""], ["Wu", "Yonghui", ""]]}, {"id": "2107.08966", "submitter": "Lukas Sch\\\"afer", "authors": "Lukas Sch\\\"afer, Filippos Christianos, Josiah Hanna, Stefano V.\n  Albrecht", "title": "Decoupling Exploration and Exploitation in Reinforcement Learning", "comments": "Unsupervised Reinforcement Learning (URL) Workshop in the 38th\n  International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic rewards are commonly applied to improve exploration in\nreinforcement learning. However, these approaches suffer from instability\ncaused by non-stationary reward shaping and strong dependency on\nhyperparameters. In this work, we propose Decoupled RL (DeRL) which trains\nseparate policies for exploration and exploitation. DeRL can be applied with\non-policy and off-policy RL algorithms. We evaluate DeRL algorithms in two\nsparse-reward environments with multiple types of intrinsic rewards. We show\nthat DeRL is more robust to scaling and speed of decay of intrinsic rewards and\nconverges to the same evaluation returns than intrinsically motivated baselines\nin fewer interactions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:31:02 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 18:50:01 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Sch\u00e4fer", "Lukas", ""], ["Christianos", "Filippos", ""], ["Hanna", "Josiah", ""], ["Albrecht", "Stefano V.", ""]]}, {"id": "2107.08981", "submitter": "Kourosh Hakhamaneshi", "authors": "Kourosh Hakhamaneshi, Ruihan Zhao, Albert Zhan, Pieter Abbeel, Michael\n  Laskin", "title": "Hierarchical Few-Shot Imitation with Skill Transition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A desirable property of autonomous agents is the ability to both solve\nlong-horizon problems and generalize to unseen tasks. Recent advances in\ndata-driven skill learning have shown that extracting behavioral priors from\noffline data can enable agents to solve challenging long-horizon tasks with\nreinforcement learning. However, generalization to tasks unseen during\nbehavioral prior training remains an outstanding challenge. To this end, we\npresent Few-shot Imitation with Skill Transition Models (FIST), an algorithm\nthat extracts skills from offline data and utilizes them to generalize to\nunseen tasks given a few downstream demonstrations. FIST learns an inverse\nskill dynamics model, a distance function, and utilizes a semi-parametric\napproach for imitation. We show that FIST is capable of generalizing to new\ntasks and substantially outperforms prior baselines in navigation experiments\nrequiring traversing unseen parts of a large maze and 7-DoF robotic arm\nexperiments requiring manipulating previously unseen objects in a kitchen.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:56:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Hakhamaneshi", "Kourosh", ""], ["Zhao", "Ruihan", ""], ["Zhan", "Albert", ""], ["Abbeel", "Pieter", ""], ["Laskin", "Michael", ""]]}, {"id": "2107.08987", "submitter": "Seung-Gu Kang", "authors": "Seung-gu Kang, Joseph A. Morrone, Jeffrey K. Weber, Wendy D. Cornell", "title": "Analysis of training and seed bias in small molecules generated with a\n  conditional graph-based variational autoencoder -- Insights for practical\n  AI-driven molecule generation", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to generative molecule design has shown\nearly promise for accelerating lead series development. However, questions\nremain concerning how factors like training, dataset, and seed bias impact the\ntechnology's utility to medicine and computational chemists. In this work, we\nanalyze the impact of seed and training bias on the output of an\nactivity-conditioned graph-based variational autoencoder (VAE). Leveraging a\nmassive, labeled dataset corresponding to the dopamine D2 receptor, our\ngraph-based generative model is shown to excel in producing desired conditioned\nactivities and favorable unconditioned physical properties in generated\nmolecules. We implement an activity swapping method that allows for the\nactivation, deactivation, or retention of activity of molecular seeds, and we\napply independent deep learning classifiers to verify the generative results.\nOverall, we uncover relationships between noise, molecular seeds, and training\nset selection across a range of latent-space sampling procedures, providing\nimportant insights for practical AI-driven molecule generation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:00:05 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kang", "Seung-gu", ""], ["Morrone", "Joseph A.", ""], ["Weber", "Jeffrey K.", ""], ["Cornell", "Wendy D.", ""]]}, {"id": "2107.08988", "submitter": "Ndivhuwo Makondo", "authors": "Ndivhuwo Makondo, Arinze Lawrence Folarin, Simphiwe Nhlahla Zitha,\n  Sekou Lionel Remy", "title": "An Analysis of Reinforcement Learning for Malaria Control", "comments": "27 pages including appendix and references. Submitted to the Journal\n  of Artificial Intelligence Research (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on policy learning for Malaria control has often formulated the\nproblem as an optimization problem assuming the objective function and the\nsearch space have a specific structure. The problem has been formulated as\nmulti-armed bandits, contextual bandits and a Markov Decision Process in\nisolation. Furthermore, an emphasis is put on developing new algorithms\nspecific to an instance of Malaria control, while ignoring a plethora of\nsimpler and general algorithms in the literature. In this work, we formally\nstudy the formulation of Malaria control and present a comprehensive analysis\nof several formulations used in the literature. In addition, we implement and\nanalyze several reinforcement learning algorithms in all formulations and\ncompare them to black box optimization. In contrast to previous work, our\nresults show that simple algorithms based on Upper Confidence Bounds are\nsufficient for learning good Malaria policies, and tend to outperform their\nmore advanced counterparts on the malaria OpenAI Gym environment.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:00:40 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Makondo", "Ndivhuwo", ""], ["Folarin", "Arinze Lawrence", ""], ["Zitha", "Simphiwe Nhlahla", ""], ["Remy", "Sekou Lionel", ""]]}, {"id": "2107.08995", "submitter": "Smitha Milli", "authors": "Smitha Milli, Luca Belli, Moritz Hardt", "title": "Causal Inference Struggles with Agency on Online Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online platforms regularly conduct randomized experiments to understand how\nchanges to the platform causally affect various outcomes of interest. However,\nexperimentation on online platforms has been criticized for having, among other\nissues, a lack of meaningful oversight and user consent. As platforms give\nusers greater agency, it becomes possible to conduct observational studies in\nwhich users self-select into the treatment of interest as an alternative to\nexperiments in which the platform controls whether the user receives treatment\nor not. In this paper, we conduct four large-scale within-study comparisons on\nTwitter aimed at assessing the effectiveness of observational studies derived\nfrom user self-selection on online platforms. In a within-study comparison,\ntreatment effects from an observational study are assessed based on how\neffectively they replicate results from a randomized experiment with the same\ntarget population. We test the naive difference in group means estimator, exact\nmatching, regression adjustment, and inverse probability of treatment weighting\nwhile controlling for plausible confounding variables. In all cases, all\nobservational estimates perform poorly at recovering the ground-truth estimate\nfrom the analogous randomized experiments. In all cases except one, the\nobservational estimates have the opposite sign of the randomized estimate. Our\nresults suggest that observational studies derived from user self-selection are\na poor alternative to randomized experimentation on online platforms. In\ndiscussing our results, we postulate \"Catch-22\"s that suggest that the success\nof causal inference in these settings may be at odds with the original\nmotivations for providing users with greater agency.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:14:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Milli", "Smitha", ""], ["Belli", "Luca", ""], ["Hardt", "Moritz", ""]]}, {"id": "2107.09003", "submitter": "Haoran Xu", "authors": "Haoran Xu, Xianyuan Zhan, Xiangyu Zhu", "title": "Constraints Penalized Q-Learning for Safe Offline Reinforcement Learning", "comments": "Accepted by RL4RealLife workshop in ICML 2021, appendix included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of safe offline reinforcement learning (RL), the goal is\nto learn a policy that maximizes long-term reward while satisfying safety\nconstraints given only offline data, without further interaction with the\nenvironment. This problem is more appealing for real world RL applications, in\nwhich data collection is costly or dangerous. Enforcing constraint satisfaction\nis non-trivial, especially in offline settings, as there is a potential large\ndiscrepancy between the policy distribution and the data distribution, causing\nerrors in estimating the value of safety constraints. We show that na\\\"ive\napproaches that combine techniques from safe RL and offline RL can only learn\nsub-optimal solutions. We thus develop a simple yet effective algorithm,\nConstraints Penalized Q-Learning (CPQ), to solve the problem. Our method admits\nthe use of data generated by mixed behavior policies. We present a theoretical\nanalysis and demonstrate empirically that our approach can learn robustly\nacross a variety of benchmark control tasks, outperforming several baselines.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:30:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Xu", "Haoran", ""], ["Zhan", "Xianyuan", ""], ["Zhu", "Xiangyu", ""]]}, {"id": "2107.09016", "submitter": "Debayan Ganguly", "authors": "Diptakshi Sen, Rupam Kumar Roy, Ritajit Majumdar, Kingshuk Chatterjee,\n  Debayan Ganguly", "title": "Prediction of the final rank of Players in PUBG with the optimal number\n  of features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  PUBG is an online video game that has become very popular among the youths in\nrecent years. Final rank, which indicates the performance of a player, is one\nof the most important feature for this game. This paper focuses on predicting\nthe final rank of the players based on their skills and abilities. In this\npaper we have used different machine learning algorithms to predict the final\nrank of the players on a dataset obtained from kaggle which has 29 features.\nUsing the correlation heatmap,we have varied the number of features used for\nthe model. Out of these models GBR and LGBM have given the best result with the\naccuracy of 91.63% and 91.26% respectively for 14 features and the accuracy of\n90.54% and 90.01% for 8 features. Although the accuracy of the models with 14\nfeatures is slightly better than 8 features, the empirical time taken by 8\nfeatures is 1.4x lesser than 14 features for LGBM and 1.5x lesser for GBR.\nFurthermore, reducing the number of features any more significantly hampers the\nperformance of all the ML models. Therefore, we conclude that 8 is the optimal\nnumber of features that can be used to predict the final rank of a player in\nPUBG with high accuracy and low run-time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 07:44:45 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sen", "Diptakshi", ""], ["Roy", "Rupam Kumar", ""], ["Majumdar", "Ritajit", ""], ["Chatterjee", "Kingshuk", ""], ["Ganguly", "Debayan", ""]]}, {"id": "2107.09028", "submitter": "Antonios Alexos", "authors": "Antonios Alexos, Alex Boyd, Stephan Mandt", "title": "Structured Stochastic Gradient MCMC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic gradient Markov chain Monte Carlo (SGMCMC) is considered the gold\nstandard for Bayesian inference in large-scale models, such as Bayesian neural\nnetworks. Since practitioners face speed versus accuracy tradeoffs in these\nmodels, variational inference (VI) is often the preferable option.\nUnfortunately, VI makes strong assumptions on both the factorization and\nfunctional form of the posterior. In this work, we propose a new non-parametric\nvariational approximation that makes no assumptions about the approximate\nposterior's functional form and allows practitioners to specify the exact\ndependencies the algorithm should respect or break. The approach relies on a\nnew Langevin-type algorithm that operates on a modified energy function, where\nparts of the latent variables are averaged over samples from earlier iterations\nof the Markov chain. This way, statistical dependencies can be broken in a\ncontrolled way, allowing the chain to mix faster. This scheme can be further\nmodified in a ''dropout'' manner, leading to even more scalability. By\nimplementing the scheme on a ResNet-20 architecture, we obtain better\npredictive likelihoods and larger effective sample sizes than full SGMCMC.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:18:10 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Alexos", "Antonios", ""], ["Boyd", "Alex", ""], ["Mandt", "Stephan", ""]]}, {"id": "2107.09031", "submitter": "Sebastian Zeng", "authors": "Sebastian Zeng, Florian Graf, Christoph Hofer, Roland Kwitt", "title": "Topological Attention for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of (point) forecasting $ \\textit{univariate} $ time series is\nconsidered. Most approaches, ranging from traditional statistical methods to\nrecent learning-based techniques with neural networks, directly operate on raw\ntime series observations. As an extension, we study whether $\\textit{local\ntopological properties}$, as captured via persistent homology, can serve as a\nreliable signal that provides complementary information for learning to\nforecast. To this end, we propose $\\textit{topological attention}$, which\nallows attending to local topological features within a time horizon of\nhistorical data. Our approach easily integrates into existing end-to-end\ntrainable forecasting models, such as $\\texttt{N-BEATS}$, and in combination\nwith the latter exhibits state-of-the-art performance on the large-scale M4\nbenchmark dataset of 100,000 diverse time series from different domains.\nAblation experiments, as well as a comparison to a broad range of forecasting\nmethods in a setting where only a single time series is available for training,\ncorroborate the beneficial nature of including local topological information\nthrough an attention mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:24:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zeng", "Sebastian", ""], ["Graf", "Florian", ""], ["Hofer", "Christoph", ""], ["Kwitt", "Roland", ""]]}, {"id": "2107.09044", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Behzad Haghgoo, Annie S. Chen, Aditi Raghunathan,\n  Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn", "title": "Just Train Twice: Improving Group Robustness without Training Group\n  Information", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard training via empirical risk minimization (ERM) can produce models\nthat achieve high accuracy on average but low accuracy on certain groups,\nespecially in the presence of spurious correlations between the input and\nlabel. Prior approaches that achieve high worst-group accuracy, like group\ndistributionally robust optimization (group DRO) require expensive group\nannotations for each training point, whereas approaches that do not use such\ngroup annotations typically achieve unsatisfactory worst-group accuracy. In\nthis paper, we propose a simple two-stage approach, JTT, that first trains a\nstandard ERM model for several epochs, and then trains a second model that\nupweights the training examples that the first model misclassified.\nIntuitively, this upweights examples from groups on which standard ERM models\nperform poorly, leading to improved worst-group performance. Averaged over four\nimage classification and natural language processing tasks with spurious\ncorrelations, JTT closes 75% of the gap in worst-group accuracy between\nstandard ERM and group DRO, while only requiring group annotations on a small\nvalidation set in order to tune hyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:52:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Haghgoo", "Behzad", ""], ["Chen", "Annie S.", ""], ["Raghunathan", "Aditi", ""], ["Koh", "Pang Wei", ""], ["Sagawa", "Shiori", ""], ["Liang", "Percy", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.09046", "submitter": "Sarah Young", "authors": "Sarah Young, Jyothish Pari, Pieter Abbeel, Lerrel Pinto", "title": "Playful Interactions for Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key challenges in visual imitation learning is collecting large\namounts of expert demonstrations for a given task. While methods for collecting\nhuman demonstrations are becoming easier with teleoperation methods and the use\nof low-cost assistive tools, we often still require 100-1000 demonstrations for\nevery task to learn a visual representation and policy. To address this, we\nturn to an alternate form of data that does not require task-specific\ndemonstrations -- play. Playing is a fundamental method children use to learn a\nset of skills and behaviors and visual representations in early learning.\nImportantly, play data is diverse, task-agnostic, and relatively cheap to\nobtain. In this work, we propose to use playful interactions in a\nself-supervised manner to learn visual representations for downstream tasks. We\ncollect 2 hours of playful data in 19 diverse environments and use\nself-predictive learning to extract visual representations. Given these\nrepresentations, we train policies using imitation learning for two downstream\ntasks: Pushing and Stacking. We demonstrate that our visual representations\ngeneralize better than standard behavior cloning and can achieve similar\nperformance with only half the number of required demonstrations. Our\nrepresentations, which are trained from scratch, compare favorably against\nImageNet pretrained representations. Finally, we provide an experimental\nanalysis on the effects of different pretraining modes on downstream task\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:54:48 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Young", "Sarah", ""], ["Pari", "Jyothish", ""], ["Abbeel", "Pieter", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2107.09047", "submitter": "Edward Hu S.", "authors": "Edward S. Hu, Kun Huang, Oleh Rybkin, Dinesh Jayaraman", "title": "Know Thyself: Transferable Visuomotor Control Through Robot-Awareness", "comments": "Website: https://hueds.github.io/rac/ Updated typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training visuomotor robot controllers from scratch on a new robot typically\nrequires generating large amounts of robot-specific data. Could we leverage\ndata previously collected on another robot to reduce or even completely remove\nthis need for robot-specific data? We propose a \"robot-aware\" solution paradigm\nthat exploits readily available robot \"self-knowledge\" such as proprioception,\nkinematics, and camera calibration to achieve this. First, we learn modular\ndynamics models that pair a transferable, robot-agnostic world dynamics module\nwith a robot-specific, analytical robot dynamics module. Next, we set up visual\nplanning costs that draw a distinction between the robot self and the world.\nOur experiments on tabletop manipulation tasks in simulation and on real robots\ndemonstrate that these plug-in improvements dramatically boost the\ntransferability of visuomotor controllers, even permitting zero-shot transfer\nonto new robots for the very first time. Project website:\nhttps://hueds.github.io/rac/\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:56:04 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 02:57:35 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hu", "Edward S.", ""], ["Huang", "Kun", ""], ["Rybkin", "Oleh", ""], ["Jayaraman", "Dinesh", ""]]}, {"id": "2107.09049", "submitter": "Li Chen", "authors": "Li Chen, Wenjin Liu, Niranjan Balu, Mahmud Mossa-Basha, Thomas S.\n  Hatsukami, Jenq-Neng Hwang, Chun Yuan", "title": "Deep Open Snake Tracker for Vessel Tracing", "comments": "MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vessel tracing by modeling vascular structures in 3D medical images with\ncenterlines and radii can provide useful information for vascular health.\nExisting algorithms have been developed but there are certain persistent\nproblems such as incomplete or inaccurate vessel tracing, especially in\ncomplicated vascular beds like the intracranial arteries. We propose here a\ndeep learning based open curve active contour model (DOST) to trace vessels in\n3D images. Initial curves were proposed from a centerline segmentation neural\nnetwork. Then data-driven machine knowledge was used to predict the stretching\ndirection and vessel radius of the initial curve, while the active contour\nmodel (as human knowledge) maintained smoothness and intensity fitness of\ncurves. Finally, considering the nonloop topology of most vasculatures,\nindividually traced vessels were connected into a tree topology by applying a\nminimum spanning tree algorithm on a global connection graph. We evaluated DOST\non a Time-of-Flight (TOF) MRA intracranial artery dataset and demonstrated its\nsuperior performance over existing segmentation-based and tracking-based vessel\ntracing methods. In addition, DOST showed strong adaptability on different\nimaging modalities (CTA, MR T1 SPACE) and vascular beds (coronary arteries).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:59:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Li", ""], ["Liu", "Wenjin", ""], ["Balu", "Niranjan", ""], ["Mossa-Basha", "Mahmud", ""], ["Hatsukami", "Thomas S.", ""], ["Hwang", "Jenq-Neng", ""], ["Yuan", "Chun", ""]]}, {"id": "2107.09051", "submitter": "Longbing Cao", "authors": "Longbing Cao", "title": "AI in Finance: Challenges, Techniques and Opportunities", "comments": "The paper is in the revision for ACM Computing Surveys, 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI in finance broadly refers to the applications of AI techniques in\nfinancial businesses. This area has been lasting for decades with both classic\nand modern AI techniques applied to increasingly broader areas of finance,\neconomy and society. In contrast to either discussing the problems, aspects and\nopportunities of finance that have benefited from specific AI techniques and in\nparticular some new-generation AI and data science (AIDS) areas or reviewing\nthe progress of applying specific techniques to resolving certain financial\nproblems, this review offers a comprehensive and dense roadmap of the\noverwhelming challenges, techniques and opportunities of AI research in finance\nover the past decades. The landscapes and challenges of financial businesses\nand data are firstly outlined, followed by a comprehensive categorization and a\ndense overview of the decades of AI research in finance. We then structure and\nillustrate the data-driven analytics and learning of financial businesses and\ndata. The comparison, criticism and discussion of classic vs. modern AI\ntechniques for finance are followed. Lastly, open issues and opportunities\naddress future AI-empowered finance and finance-motivated AI research.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 01:39:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cao", "Longbing", ""]]}, {"id": "2107.09055", "submitter": "Vikas Bajpai", "authors": "Priyank Sonkiya, Vikas Bajpai and Anukriti Bansal", "title": "Stock price prediction using BERT and GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The stock market has been a popular topic of interest in the recent past. The\ngrowth in the inflation rate has compelled people to invest in the stock and\ncommodity markets and other areas rather than saving. Further, the ability of\nDeep Learning models to make predictions on the time series data has been\nproven time and again. Technical analysis on the stock market with the help of\ntechnical indicators has been the most common practice among traders and\ninvestors. One more aspect is the sentiment analysis - the emotion of the\ninvestors that shows the willingness to invest. A variety of techniques have\nbeen used by people around the globe involving basic Machine Learning and\nNeural Networks. Ranging from the basic linear regression to the advanced\nneural networks people have experimented with all possible techniques to\npredict the stock market. It's evident from recent events how news and\nheadlines affect the stock markets and cryptocurrencies. This paper proposes an\nensemble of state-of-the-art methods for predicting stock prices. Firstly\nsentiment analysis of the news and the headlines for the company Apple Inc,\nlisted on the NASDAQ is performed using a version of BERT, which is a\npre-trained transformer model by Google for Natural Language Processing (NLP).\nAfterward, a Generative Adversarial Network (GAN) predicts the stock price for\nApple Inc using the technical indicators, stock indexes of various countries,\nsome commodities, and historical prices along with the sentiment scores.\nComparison is done with baseline models like - Long Short Term Memory (LSTM),\nGated Recurrent Units (GRU), vanilla GAN, and Auto-Regressive Integrated Moving\nAverage (ARIMA) model.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 18:31:43 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Sonkiya", "Priyank", ""], ["Bajpai", "Vikas", ""], ["Bansal", "Anukriti", ""]]}, {"id": "2107.09060", "submitter": "Thomas K\\\"ustner", "authors": "Thomas K\\\"ustner, Jiazhen Pan, Haikun Qi, Gastao Cruz, Christopher\n  Gilliam, Thierry Blu, Bin Yang, Sergios Gatidis, Ren\\'e Botnar, Claudia\n  Prieto", "title": "LAPNet: Non-rigid Registration derived in k-space for Magnetic Resonance\n  Imaging", "comments": null, "journal-ref": null, "doi": "10.1109/TMI.2021.3096131", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physiological motion, such as cardiac and respiratory motion, during Magnetic\nResonance (MR) image acquisition can cause image artifacts. Motion correction\ntechniques have been proposed to compensate for these types of motion during\nthoracic scans, relying on accurate motion estimation from undersampled\nmotion-resolved reconstruction. A particular interest and challenge lie in the\nderivation of reliable non-rigid motion fields from the undersampled\nmotion-resolved data. Motion estimation is usually formulated in image space\nvia diffusion, parametric-spline, or optical flow methods. However, image-based\nregistration can be impaired by remaining aliasing artifacts due to the\nundersampled motion-resolved reconstruction. In this work, we describe a\nformalism to perform non-rigid registration directly in the sampled Fourier\nspace, i.e. k-space. We propose a deep-learning based approach to perform fast\nand accurate non-rigid registration from the undersampled k-space data. The\nbasic working principle originates from the Local All-Pass (LAP) technique, a\nrecently introduced optical flow-based registration. The proposed LAPNet is\ncompared against traditional and deep learning image-based registrations and\ntested on fully-sampled and highly-accelerated (with two undersampling\nstrategies) 3D respiratory motion-resolved MR images in a cohort of 40 patients\nwith suspected liver or lung metastases and 25 healthy subjects. The proposed\nLAPNet provided consistent and superior performance to image-based approaches\nthroughout different sampling trajectories and acceleration factors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:39:23 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["K\u00fcstner", "Thomas", ""], ["Pan", "Jiazhen", ""], ["Qi", "Haikun", ""], ["Cruz", "Gastao", ""], ["Gilliam", "Christopher", ""], ["Blu", "Thierry", ""], ["Yang", "Bin", ""], ["Gatidis", "Sergios", ""], ["Botnar", "Ren\u00e9", ""], ["Prieto", "Claudia", ""]]}, {"id": "2107.09070", "submitter": "Florian List", "authors": "Florian List, Nicholas L. Rodd, Geraint F. Lewis", "title": "Dim but not entirely dark: Extracting the Galactic Center Excess'\n  source-count distribution with neural nets", "comments": "36+8 pages, 15+6 figures, main results in Figs. 8 and 12", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.HE astro-ph.CO astro-ph.IM cs.LG hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two leading hypotheses for the Galactic Center Excess (GCE) in the\n$\\textit{Fermi}$ data are an unresolved population of faint millisecond pulsars\n(MSPs) and dark-matter (DM) annihilation. The dichotomy between these\nexplanations is typically reflected by modeling them as two separate emission\ncomponents. However, point-sources (PSs) such as MSPs become statistically\ndegenerate with smooth Poisson emission in the ultra-faint limit (formally\nwhere each source is expected to contribute much less than one photon on\naverage), leading to an ambiguity that can render questions such as whether the\nemission is PS-like or Poissonian in nature ill-defined. We present a\nconceptually new approach that describes the PS and Poisson emission in a\nunified manner and only afterwards derives constraints on the Poissonian\ncomponent from the so obtained results. For the implementation of this\napproach, we leverage deep learning techniques, centered around a neural\nnetwork-based method for histogram regression that expresses uncertainties in\nterms of quantiles. We demonstrate that our method is robust against a number\nof systematics that have plagued previous approaches, in particular DM / PS\nmisattribution. In the $\\textit{Fermi}$ data, we find a faint GCE described by\na median source-count distribution (SCD) peaked at a flux of $\\sim4 \\times\n10^{-11} \\ \\text{counts} \\ \\text{cm}^{-2} \\ \\text{s}^{-1}$ (corresponding to\n$\\sim3 - 4$ expected counts per PS), which would require $N \\sim\n\\mathcal{O}(10^4)$ sources to explain the entire excess (median value $N =\n\\text{29,300}$ across the sky). Although faint, this SCD allows us to derive\nthe constraint $\\eta_P \\leq 66\\%$ for the Poissonian fraction of the GCE flux\n$\\eta_P$ at 95% confidence, suggesting that a substantial amount of the GCE\nflux is due to PSs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:00:02 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["List", "Florian", ""], ["Rodd", "Nicholas L.", ""], ["Lewis", "Geraint F.", ""]]}, {"id": "2107.09078", "submitter": "Haoyuan Cai", "authors": "Haoyuan Cai, Qi Ye, Dong-Ling Deng", "title": "Sample Complexity of Learning Quantum Circuits", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computers hold unprecedented potentials for machine learning\napplications. Here, we prove that physical quantum circuits are PAC (probably\napproximately correct) learnable on a quantum computer via empirical risk\nminimization: to learn a quantum circuit with at most $n^c$ gates and each gate\nacting on a constant number of qubits, the sample complexity is bounded by\n$\\tilde{O}(n^{c+1})$. In particular, we explicitly construct a family of\nvariational quantum circuits with $O(n^{c+1})$ elementary gates arranged in a\nfixed pattern, which can represent all physical quantum circuits consisting of\nat most $n^c$ elementary gates. Our results provide a valuable guide for\nquantum machine learning in both theory and experiment.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:00:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cai", "Haoyuan", ""], ["Ye", "Qi", ""], ["Deng", "Dong-Ling", ""]]}, {"id": "2107.09082", "submitter": "Maria Han Veiga", "authors": "Maria Han Veiga, Xi Meng, Oleg Y. Gnedin, Nickolay Y. Gnedin and Xun\n  Huan", "title": "Reconstruction of the Density Power Spectrum from Quasar Spectra using\n  Machine Learning", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a novel end-to-end approach using Machine Learning to reconstruct\nthe power spectrum of cosmological density perturbations at high redshift from\nobserved quasar spectra. State-of-the-art cosmological simulations of structure\nformation are used to generate a large synthetic dataset of line-of-sight\nabsorption spectra paired with 1-dimensional fluid quantities along the same\nline-of-sight, such as the total density of matter and the density of neutral\natomic hydrogen. With this dataset, we build a series of data-driven models to\npredict the power spectrum of total matter density. We are able to produce\nmodels which yield reconstruction to accuracy of about 1% for wavelengths $k\n\\leq 2 h Mpc^{-1}$, while the error increases at larger $k$. We show the size\nof data sample required to reach a particular error rate, giving a sense of how\nmuch data is necessary to reach a desired accuracy. This work provides a\nfoundation for developing methods to analyse very large upcoming datasets with\nthe next-generation observational facilities.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:00:06 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Veiga", "Maria Han", ""], ["Meng", "Xi", ""], ["Gnedin", "Oleg Y.", ""], ["Gnedin", "Nickolay Y.", ""], ["Huan", "Xun", ""]]}, {"id": "2107.09086", "submitter": "Sayantan Auddy", "authors": "Sayantan Auddy, Ramit Dey, Min-Kai Lin (ASIAA, NCTS Physics Division),\n  Cassandra Hall", "title": "DPNNet-2.0 Part I: Finding hidden planets from simulated images of\n  protoplanetary disk gaps", "comments": "15 pages, 10 figures, to appear in ApJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The observed sub-structures, like annular gaps, in dust emissions from\nprotoplanetary disk, are often interpreted as signatures of embedded planets.\nFitting a model of planetary gaps to these observed features using customized\nsimulations or empirical relations can reveal the characteristics of the hidden\nplanets. However, customized fitting is often impractical owing to the\nincreasing sample size and the complexity of disk-planet interaction. In this\npaper we introduce the architecture of DPNNet-2.0, second in the series after\nDPNNet \\citep{aud20}, designed using a Convolutional Neural Network ( CNN, here\nspecifically ResNet50) for predicting exoplanet masses directly from simulated\nimages of protoplanetary disks hosting a single planet. DPNNet-2.0 additionally\nconsists of a multi-input framework that uses both a CNN and multi-layer\nperceptron (a class of artificial neural network) for processing image and disk\nparameters simultaneously. This enables DPNNet-2.0 to be trained using images\ndirectly, with the added option of considering disk parameters (disk\nviscosities, disk temperatures, disk surface density profiles, dust abundances,\nand particle Stokes numbers) generated from disk-planet hydrodynamic\nsimulations as inputs. This work provides the required framework and is the\nfirst step towards the use of computer vision (implementing CNN) to directly\nextract mass of an exoplanet from planetary gaps observed in dust-surface\ndensity maps by telescopes such as the Atacama Large (sub-)Millimeter Array.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:00:31 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Auddy", "Sayantan", "", "ASIAA, NCTS Physics Division"], ["Dey", "Ramit", "", "ASIAA, NCTS Physics Division"], ["Lin", "Min-Kai", "", "ASIAA, NCTS Physics Division"], ["Hall", "Cassandra", ""]]}, {"id": "2107.09088", "submitter": "Dylan Ashley", "authors": "Miroslav \\v{S}trupl, Francesco Faccio, Dylan R. Ashley, Rupesh Kumar\n  Srivastava, J\\\"urgen Schmidhuber", "title": "Reward-Weighted Regression Converges to a Global Optimum", "comments": "10 pages in main text + 2 pages of references + 4 pages of\n  appendices, 2 figures in main text; source code available at\n  https://github.com/dylanashley/reward-weighted-regression", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reward-Weighted Regression (RWR) belongs to a family of widely known\niterative Reinforcement Learning algorithms based on the\nExpectation-Maximization framework. In this family, learning at each iteration\nconsists of sampling a batch of trajectories using the current policy and\nfitting a new policy to maximize a return-weighted log-likelihood of actions.\nAlthough RWR is known to yield monotonic improvement of the policy under\ncertain circumstances, whether and under which conditions RWR converges to the\noptimal policy have remained open questions. In this paper, we provide for the\nfirst time a proof that RWR converges to a global optimum when no function\napproximation is used.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:01:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["\u0160trupl", "Miroslav", ""], ["Faccio", "Francesco", ""], ["Ashley", "Dylan R.", ""], ["Srivastava", "Rupesh Kumar", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2107.09091", "submitter": "Soumyabrata Pal", "authors": "Arya Mazumdar, Soumyabrata Pal", "title": "Support Recovery in Universal One-bit Compressed Sensing", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DM cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-bit compressed sensing (1bCS) is an extreme-quantized signal acquisition\nmethod that has been widely studied in the past decade. In 1bCS, linear samples\nof a high dimensional signal are quantized to only one bit per sample (sign of\nthe measurement). Assuming the original signal vector to be sparse, existing\nresults either aim to find the support of the vector, or approximate the signal\nwithin an $\\epsilon$-ball. The focus of this paper is support recovery, which\noften also computationally facilitates approximate signal recovery. A universal\nmeasurement matrix for 1bCS refers to one set of measurements that work for all\nsparse signals. With universality, it is known that $\\tilde{\\Theta}(k^2)$ 1bCS\nmeasurements are necessary and sufficient for support recovery (where $k$\ndenotes the sparsity). In this work, we show that it is possible to universally\nrecover the support with a small number of false positives with\n$\\tilde{O}(k^{3/2})$ measurements. If the dynamic range of the signal vector is\nknown, then with a different technique, this result can be improved to only\n$\\tilde{O}(k)$ measurements. Further results on support recovery are also\nprovided.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:10:51 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mazumdar", "Arya", ""], ["Pal", "Soumyabrata", ""]]}, {"id": "2107.09095", "submitter": "Erion-Vasilis Pikoulis", "authors": "Erion-Vasilis Pikoulis, Christos Mavrokefalidis, Aris S. Lalos", "title": "A New Clustering-Based Technique for the Acceleration of Deep\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": "10.1109/ICMLA51294.2020.00222", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning and especially the use of Deep Neural Networks (DNNs) provides\nimpressive results in various regression and classification tasks. However, to\nachieve these results, there is a high demand for computing and storing\nresources. This becomes problematic when, for instance, real-time, mobile\napplications are considered, in which the involved (embedded) devices have\nlimited resources. A common way of addressing this problem is to transform the\noriginal large pre-trained networks into new smaller models, by utilizing Model\nCompression and Acceleration (MCA) techniques. Within the MCA framework, we\npropose a clustering-based approach that is able to increase the number of\nemployed centroids/representatives, while at the same time, have an\nacceleration gain compared to conventional, $k$-means based approaches. This is\nachieved by imposing a special structure to the employed representatives, which\nis enabled by the particularities of the problem at hand. Moreover, the\ntheoretical acceleration gains are presented and the key system\nhyper-parameters that affect that gain, are identified. Extensive evaluation\nstudies carried out using various state-of-the-art DNN models trained in image\nclassification, validate the superiority of the proposed method as compared for\nits use in MCA tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:22:07 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Pikoulis", "Erion-Vasilis", ""], ["Mavrokefalidis", "Christos", ""], ["Lalos", "Aris S.", ""]]}, {"id": "2107.09099", "submitter": "Qiushi Huang", "authors": "Qiushi Huang, Tom Ko, H Lilian Tang, Xubo Liu, Bo Wu", "title": "Token-Level Supervised Contrastive Learning for Punctuation Restoration", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Punctuation is critical in understanding natural language text. Currently,\nmost automatic speech recognition (ASR) systems do not generate punctuation,\nwhich affects the performance of downstream tasks, such as intent detection and\nslot filling. This gives rise to the need for punctuation restoration. Recent\nwork in punctuation restoration heavily utilizes pre-trained language models\nwithout considering data imbalance when predicting punctuation classes. In this\nwork, we address this problem by proposing a token-level supervised contrastive\nlearning method that aims at maximizing the distance of representation of\ndifferent punctuation marks in the embedding space. The result shows that\ntraining with token-level supervised contrastive learning obtains up to 3.2%\nabsolute F1 improvement on the test set.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:24:33 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Huang", "Qiushi", ""], ["Ko", "Tom", ""], ["Tang", "H Lilian", ""], ["Liu", "Xubo", ""], ["Wu", "Bo", ""]]}, {"id": "2107.09101", "submitter": "Erion-Vasilis Pikoulis", "authors": "Stavros Nousias, Erion-Vasilis Pikoulis, Christos Mavrokefalidis, Aris\n  S. Lalos", "title": "Accelerating deep neural networks for efficient scene understanding in\n  automotive cyber-physical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automotive Cyber-Physical Systems (ACPS) have attracted a significant amount\nof interest in the past few decades, while one of the most critical operations\nin these systems is the perception of the environment. Deep learning and,\nespecially, the use of Deep Neural Networks (DNNs) provides impressive results\nin analyzing and understanding complex and dynamic scenes from visual data. The\nprediction horizons for those perception systems are very short and inference\nmust often be performed in real time, stressing the need of transforming the\noriginal large pre-trained networks into new smaller models, by utilizing Model\nCompression and Acceleration (MCA) techniques. Our goal in this work is to\ninvestigate best practices for appropriately applying novel weight sharing\ntechniques, optimizing the available variables and the training procedures\ntowards the significant acceleration of widely adopted DNNs. Extensive\nevaluation studies carried out using various state-of-the-art DNN models in\nobject detection and tracking experiments, provide details about the type of\nerrors that manifest after the application of weight sharing techniques,\nresulting in significant acceleration gains with negligible accuracy losses.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:43:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Nousias", "Stavros", ""], ["Pikoulis", "Erion-Vasilis", ""], ["Mavrokefalidis", "Christos", ""], ["Lalos", "Aris S.", ""]]}, {"id": "2107.09106", "submitter": "Spencer Whitehead", "authors": "Spencer Whitehead, Hui Wu, Heng Ji, Rogerio Feris, Kate Saenko", "title": "Separating Skills and Concepts for Novel Visual Question Answering", "comments": "Paper at CVPR 2021. 14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization to out-of-distribution data has been a problem for Visual\nQuestion Answering (VQA) models. To measure generalization to novel questions,\nwe propose to separate them into \"skills\" and \"concepts\". \"Skills\" are visual\ntasks, such as counting or attribute recognition, and are applied to \"concepts\"\nmentioned in the question, such as objects and people. VQA methods should be\nable to compose skills and concepts in novel ways, regardless of whether the\nspecific composition has been seen in training, yet we demonstrate that\nexisting models have much to improve upon towards handling new compositions. We\npresent a novel method for learning to compose skills and concepts that\nseparates these two factors implicitly within a model by learning grounded\nconcept representations and disentangling the encoding of skills from that of\nconcepts. We enforce these properties with a novel contrastive learning\nprocedure that does not rely on external annotations and can be learned from\nunlabeled image-question pairs. Experiments demonstrate the effectiveness of\nour approach for improving compositional and grounding performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 18:55:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Whitehead", "Spencer", ""], ["Wu", "Hui", ""], ["Ji", "Heng", ""], ["Feris", "Rogerio", ""], ["Saenko", "Kate", ""]]}, {"id": "2107.09110", "submitter": "Abhinav Mishra", "authors": "Abhinav Mishra, Ram Sriharsha, Sichen Zhong", "title": "OnlineSTL: Scaling Time Series Decomposition by 100x", "comments": "8 pages, 9 figures, vldb submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decomposing a complex time series into trend, seasonality, and remainder\ncomponents is an important primitive that facilitates time series anomaly\ndetection, change point detection and forecasting. Although numerous batch\nalgorithms are known for time series decomposition, none operate well in an\nonline scalable setting where high throughput and real-time response are\nparamount. In this paper, we propose OnlineSTL, a novel online algorithm for\ntime series decomposition which solves the scalability problem and is deployed\nfor real-time metrics monitoring on high resolution, high ingest rate data.\nExperiments on different synthetic and real world time series datasets\ndemonstrate that OnlineSTL achieves orders of magnitude speedups while\nmaintaining quality of decomposition.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:03:27 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mishra", "Abhinav", ""], ["Sriharsha", "Ram", ""], ["Zhong", "Sichen", ""]]}, {"id": "2107.09118", "submitter": "Abbas Khosravi", "authors": "Donya Khaledyan, AmirReza Tajally, Ali Sarkhosh, Afshar Shamsi, Hamzeh\n  Asgharnezhad, Abbas Khosravi, Saeid Nahavandi", "title": "Confidence Aware Neural Networks for Skin Cancer Detection", "comments": "21 Pages, 7 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) models have received particular attention in medical\nimaging due to their promising pattern recognition capabilities. However, Deep\nNeural Networks (DNNs) require a huge amount of data, and because of the lack\nof sufficient data in this field, transfer learning can be a great solution.\nDNNs used for disease diagnosis meticulously concentrate on improving the\naccuracy of predictions without providing a figure about their confidence of\npredictions. Knowing how much a DNN model is confident in a computer-aided\ndiagnosis model is necessary for gaining clinicians' confidence and trust in\nDL-based solutions. To address this issue, this work presents three different\nmethods for quantifying uncertainties for skin cancer detection from images. It\nalso comprehensively evaluates and compares performance of these DNNs using\nnovel uncertainty-related metrics. The obtained results reveal that the\npredictive uncertainty estimation methods are capable of flagging risky and\nerroneous predictions with a high uncertainty estimate. We also demonstrate\nthat ensemble approaches are more reliable in capturing uncertainties through\ninference.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:21:57 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 15:20:54 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Khaledyan", "Donya", ""], ["Tajally", "AmirReza", ""], ["Sarkhosh", "Ali", ""], ["Shamsi", "Afshar", ""], ["Asgharnezhad", "Hamzeh", ""], ["Khosravi", "Abbas", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "2107.09123", "submitter": "Rohit Verma", "authors": "Tanmay Jain, Avaneesh, Rohit Verma, Rajeev Shorey", "title": "Latency-Memory Optimized Splitting of Convolution Neural Networks for\n  Resource Constrained Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing reliance of users on smart devices, bringing essential\ncomputation at the edge has become a crucial requirement for any type of\nbusiness. Many such computations utilize Convolution Neural Networks (CNNs) to\nperform AI tasks, having high resource and computation requirements, that are\ninfeasible for edge devices. Splitting the CNN architecture to perform part of\nthe computation on edge and remaining on the cloud is an area of research that\nhas seen increasing interest in the field. In this paper, we assert that\nrunning CNNs between an edge device and the cloud is synonymous to solving a\nresource-constrained optimization problem that minimizes the latency and\nmaximizes resource utilization at the edge. We formulate a multi-objective\noptimization problem and propose the LMOS algorithm to achieve a Pareto\nefficient solution. Experiments done on real-world edge devices show that, LMOS\nensures feasible execution of different CNN models at the edge and also\nimproves upon existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 19:39:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jain", "Tanmay", ""], ["Avaneesh", "", ""], ["Verma", "Rohit", ""], ["Shorey", "Rajeev", ""]]}, {"id": "2107.09130", "submitter": "Rozhin Yasaei", "authors": "Rozhin Yasaei, Shih-Yuan Yu, Emad Kasaeyan Naeini, Mohammad Abdullah\n  Al Faruque", "title": "GNN4IP: Graph Neural Network for Hardware Intellectual Property Piracy\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggressive time-to-market constraints and enormous hardware design and\nfabrication costs have pushed the semiconductor industry toward hardware\nIntellectual Properties (IP) core design. However, the globalization of the\nintegrated circuits (IC) supply chain exposes IP providers to theft and illegal\nredistribution of IPs. Watermarking and fingerprinting are proposed to detect\nIP piracy. Nevertheless, they come with additional hardware overhead and cannot\nguarantee IP security as advanced attacks are reported to remove the watermark,\nforge, or bypass it. In this work, we propose a novel methodology, GNN4IP, to\nassess similarities between circuits and detect IP piracy. We model the\nhardware design as a graph and construct a graph neural network model to learn\nits behavior using the comprehensive dataset of register transfer level codes\nand gate-level netlists that we have gathered. GNN4IP detects IP piracy with\n96% accuracy in our dataset and recognizes the original IP in its obfuscated\nversion with 100% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:13:16 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Yasaei", "Rozhin", ""], ["Yu", "Shih-Yuan", ""], ["Naeini", "Emad Kasaeyan", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "2107.09133", "submitter": "Daniel Kunin", "authors": "Daniel Kunin, Javier Sagastuy-Brena, Lauren Gillespie, Eshed Margalit,\n  Hidenori Tanaka, Surya Ganguli, Daniel L. K. Yamins", "title": "Rethinking the limiting dynamics of SGD: modified loss, phase space\n  oscillations, and anomalous diffusion", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the limiting dynamics of deep neural networks trained\nwith stochastic gradient descent (SGD). We find empirically that long after\nperformance has converged, networks continue to move through parameter space by\na process of anomalous diffusion in which distance travelled grows as a power\nlaw in the number of gradient updates with a nontrivial exponent. We reveal an\nintricate interaction between the hyperparameters of optimization, the\nstructure in the gradient noise, and the Hessian matrix at the end of training\nthat explains this anomalous diffusion. To build this understanding, we first\nderive a continuous-time model for SGD with finite learning rates and batch\nsizes as an underdamped Langevin equation. We study this equation in the\nsetting of linear regression, where we can derive exact, analytic expressions\nfor the phase space dynamics of the parameters and their instantaneous\nvelocities from initialization to stationarity. Using the Fokker-Planck\nequation, we show that the key ingredient driving these dynamics is not the\noriginal training loss, but rather the combination of a modified loss, which\nimplicitly regularizes the velocity, and probability currents, which cause\noscillations in phase space. We identify qualitative and quantitative\npredictions of this theory in the dynamics of a ResNet-18 model trained on\nImageNet. Through the lens of statistical physics, we uncover a mechanistic\norigin for the anomalous limiting dynamics of deep neural networks trained with\nSGD.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:18:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kunin", "Daniel", ""], ["Sagastuy-Brena", "Javier", ""], ["Gillespie", "Lauren", ""], ["Margalit", "Eshed", ""], ["Tanaka", "Hidenori", ""], ["Ganguli", "Surya", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "2107.09139", "submitter": "Balazs Varga", "authors": "Bal\\'azs Varga, Bal\\'azs Kulcs\\'ar, Morteza Haghir Chehreghani", "title": "Constrained Policy Gradient Method for Safe and Fast Reinforcement\n  Learning: a Neural Tangent Kernel Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a constrained policy gradient algorithm. We introduce\nconstraints for safe learning with the following steps. First, learning is\nslowed down (lazy learning) so that the episodic policy change can be computed\nwith the help of the policy gradient theorem and the neural tangent kernel.\nThen, this enables us the evaluation of the policy at arbitrary states too. In\nthe same spirit, learning can be guided, ensuring safety via augmenting episode\nbatches with states where the desired action probabilities are prescribed.\nFinally, exogenous discounted sum of future rewards (returns) can be computed\nat these specific state-action pairs such that the policy network satisfies\nconstraints. Computing the returns is based on solving a system of linear\nequations (equality constraints) or a constrained quadratic program (inequality\nconstraints). Simulation results suggest that adding constraints (external\ninformation) to the learning can improve learning in terms of speed and safety\nreasonably if constraints are appropriately selected. The efficiency of the\nconstrained learning was demonstrated with a shallow and wide ReLU network in\nthe Cartpole and Lunar Lander OpenAI gym environments. The main novelty of the\npaper is giving a practical use of the neural tangent kernel in reinforcement\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:25:15 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Varga", "Bal\u00e1zs", ""], ["Kulcs\u00e1r", "Bal\u00e1zs", ""], ["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2107.09142", "submitter": "Curtis Hawthorne", "authors": "Curtis Hawthorne, Ian Simon, Rigel Swavely, Ethan Manilow, Jesse Engel", "title": "Sequence-to-Sequence Piano Transcription with Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic Music Transcription has seen significant progress in recent years\nby training custom deep neural networks on large datasets. However, these\nmodels have required extensive domain-specific design of network architectures,\ninput/output representations, and complex decoding schemes. In this work, we\nshow that equivalent performance can be achieved using a generic\nencoder-decoder Transformer with standard decoding methods. We demonstrate that\nthe model can learn to translate spectrogram inputs directly to MIDI-like\noutput events for several transcription tasks. This sequence-to-sequence\napproach simplifies transcription by jointly modeling audio features and\nlanguage-like output dependencies, thus removing the need for task-specific\narchitectures. These results point toward possibilities for creating new Music\nInformation Retrieval models by focusing on dataset creation and labeling\nrather than custom model design.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:33:09 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hawthorne", "Curtis", ""], ["Simon", "Ian", ""], ["Swavely", "Rigel", ""], ["Manilow", "Ethan", ""], ["Engel", "Jesse", ""]]}, {"id": "2107.09144", "submitter": "Harsha Vardhan Tetali", "authors": "Harsha Vardhan Tetali, Joel B. Harley, Benjamin D. Haeffele", "title": "Wave-Informed Matrix Factorization withGlobal Optimality Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success of representation learning methods, which includes\ndeep learning as a special case, there has been considerable interest in\ndeveloping representation learning techniques that can incorporate known\nphysical constraints into the learned representation. As one example, in many\napplications that involve a signal propagating through physical media (e.g.,\noptics, acoustics, fluid dynamics, etc), it is known that the dynamics of the\nsignal must satisfy constraints imposed by the wave equation. Here we propose a\nmatrix factorization technique that decomposes such signals into a sum of\ncomponents, where each component is regularized to ensure that it satisfies\nwave equation constraints. Although our proposed formulation is non-convex, we\nprove that our model can be efficiently solved to global optimality in\npolynomial time. We demonstrate the benefits of our work by applications in\nstructural health monitoring, where prior work has attempted to solve this\nproblem using sparse dictionary learning approaches that do not come with any\ntheoretical guarantees regarding convergence to global optimality and employ\nheuristics to capture desired physical constraints.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:34:47 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tetali", "Harsha Vardhan", ""], ["Harley", "Joel B.", ""], ["Haeffele", "Benjamin D.", ""]]}, {"id": "2107.09145", "submitter": "Wooseok Ha", "authors": "Wooseok Ha, Chandan Singh, Francois Lanusse, Eli Song, Song Dang,\n  Kangmin He, Srigokul Upadhyayula, Bin Yu", "title": "Adaptive wavelet distillation from neural networks through\n  interpretations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep-learning models have achieved impressive prediction performance,\nbut often sacrifice interpretability and computational efficiency.\nInterpretability is crucial in many disciplines, such as science and medicine,\nwhere models must be carefully vetted or where interpretation is the goal\nitself. Moreover, interpretable models are concise and often yield\ncomputational efficiency. Here, we propose adaptive wavelet distillation (AWD),\na method which aims to distill information from a trained neural network into a\nwavelet transform. Specifically, AWD penalizes feature attributions of a neural\nnetwork in the wavelet domain to learn an effective multi-resolution wavelet\ntransform. The resulting model is highly predictive, concise, computationally\nefficient, and has properties (such as a multi-scale structure) which make it\neasy to interpret. In close collaboration with domain experts, we showcase how\nAWD addresses challenges in two real-world settings: cosmological parameter\ninference and molecular-partner prediction. In both cases, AWD yields a\nscientifically interpretable and concise model which gives predictive\nperformance better than state-of-the-art neural networks. Moreover, AWD\nidentifies predictive features that are scientifically meaningful in the\ncontext of respective domains. All code and models are released in a\nfull-fledged package available on Github\n(https://github.com/Yu-Group/adaptive-wavelets).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:40:35 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ha", "Wooseok", ""], ["Singh", "Chandan", ""], ["Lanusse", "Francois", ""], ["Song", "Eli", ""], ["Dang", "Song", ""], ["He", "Kangmin", ""], ["Upadhyayula", "Srigokul", ""], ["Yu", "Bin", ""]]}, {"id": "2107.09158", "submitter": "Brenden Petersen", "authors": "Mikel Landajuela Larma, Brenden K. Petersen, Soo K. Kim, Claudio P.\n  Santiago, Ruben Glatt, T. Nathan Mundhenk, Jacob F. Pettit, Daniel M. Faissol", "title": "Improving exploration in policy gradient search: Application to symbolic\n  optimization", "comments": "Published in 1st Mathematical Reasoning in General Artificial\n  Intelligence Workshop, ICLR 2021", "journal-ref": "1st Mathematical Reasoning in General Artificial Intelligence\n  Workshop, ICLR 2021", "doi": null, "report-no": "LLNL-CONF-820015", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning strategies designed to automate mathematical tasks\nleverage neural networks to search large combinatorial spaces of mathematical\nsymbols. In contrast to traditional evolutionary approaches, using a neural\nnetwork at the core of the search allows learning higher-level symbolic\npatterns, providing an informed direction to guide the search. When no labeled\ndata is available, such networks can still be trained using reinforcement\nlearning. However, we demonstrate that this approach can suffer from an early\ncommitment phenomenon and from initialization bias, both of which limit\nexploration. We present two exploration methods to tackle these issues,\nbuilding upon ideas of entropy regularization and distribution initialization.\nWe show that these techniques can improve the performance, increase sample\nefficiency, and lower the complexity of solutions for the task of symbolic\nregression.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 21:11:07 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Larma", "Mikel Landajuela", ""], ["Petersen", "Brenden K.", ""], ["Kim", "Soo K.", ""], ["Santiago", "Claudio P.", ""], ["Glatt", "Ruben", ""], ["Mundhenk", "T. Nathan", ""], ["Pettit", "Jacob F.", ""], ["Faissol", "Daniel M.", ""]]}, {"id": "2107.09170", "submitter": "Juan Pablo De Vicente", "authors": "Juan Pablo de Vicente, Alvaro Soto", "title": "DeepSocNav: Social Navigation by Imitating Human Behaviors", "comments": "6 pages, Accepted paper at the RSS Workshop on Social Robot\n  Navigation 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current datasets to train social behaviors are usually borrowed from\nsurveillance applications that capture visual data from a bird's-eye\nperspective. This leaves aside precious relationships and visual cues that\ncould be captured through a first-person view of a scene. In this work, we\npropose a strategy to exploit the power of current game engines, such as Unity,\nto transform pre-existing bird's-eye view datasets into a first-person view, in\nparticular, a depth view. Using this strategy, we are able to generate large\nvolumes of synthetic data that can be used to pre-train a social navigation\nmodel. To test our ideas, we present DeepSocNav, a deep learning based model\nthat takes advantage of the proposed approach to generate synthetic data.\nFurthermore, DeepSocNav includes a self-supervised strategy that is included as\nan auxiliary task. This consists of predicting the next depth frame that the\nagent will face. Our experiments show the benefits of the proposed model that\nis able to outperform relevant baselines in terms of social navigation scores.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 21:51:06 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["de Vicente", "Juan Pablo", ""], ["Soto", "Alvaro", ""]]}, {"id": "2107.09182", "submitter": "Brenden Petersen", "authors": "Brenden K. Petersen, Claudio P. Santiago, Mikel Landajuela Larma", "title": "Incorporating domain knowledge into neural-guided search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AutoML problems involve optimizing discrete objects under a black-box\nreward. Neural-guided search provides a flexible means of searching these\ncombinatorial spaces using an autoregressive recurrent neural network. A major\nbenefit of this approach is that builds up objects sequentially--this provides\nan opportunity to incorporate domain knowledge into the search by directly\nmodifying the logits emitted during sampling. In this work, we formalize a\nframework for incorporating such in situ priors and constraints into\nneural-guided search, and provide sufficient conditions for enforcing\nconstraints. We integrate several priors and constraints from existing works\ninto this framework, propose several new ones, and demonstrate their efficacy\nin informing the task of symbolic regression.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 22:34:43 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Petersen", "Brenden K.", ""], ["Santiago", "Claudio P.", ""], ["Larma", "Mikel Landajuela", ""]]}, {"id": "2107.09194", "submitter": "William Stephenson", "authors": "William T. Stephenson and Zachary Frangella and Madeleine Udell and\n  Tamara Broderick", "title": "Can we globally optimize cross-validation loss? Quasiconvexity in ridge\n  regression", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models like LASSO and ridge regression are extensively used in practice due\nto their interpretability, ease of use, and strong theoretical guarantees.\nCross-validation (CV) is widely used for hyperparameter tuning in these models,\nbut do practical optimization methods minimize the true out-of-sample loss? A\nrecent line of research promises to show that the optimum of the CV loss\nmatches the optimum of the out-of-sample loss (possibly after simple\ncorrections). It remains to show how tractable it is to minimize the CV loss.\nIn the present paper, we show that, in the case of ridge regression, the CV\nloss may fail to be quasiconvex and thus may have multiple local optima. We can\nguarantee that the CV loss is quasiconvex in at least one case: when the\nspectrum of the covariate matrix is nearly flat and the noise in the observed\nresponses is not too high. More generally, we show that quasiconvexity status\nis independent of many properties of the observed data (response norm,\ncovariate-matrix right singular vectors and singular-value scaling) and has a\ncomplex dependence on the few that remain. We empirically confirm our theory\nusing simulated experiments.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 23:22:24 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Stephenson", "William T.", ""], ["Frangella", "Zachary", ""], ["Udell", "Madeleine", ""], ["Broderick", "Tamara", ""]]}, {"id": "2107.09200", "submitter": "Alexander Zlokapa", "authors": "Alexander Zlokapa, Hartmut Neven, Seth Lloyd", "title": "A quantum algorithm for training wide and deep classical neural networks", "comments": "10 pages + 13 page appendix, 10 figures; code available at\n  https://github.com/quantummind/quantum-deep-neural-network", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the success of deep learning in classical machine learning, quantum\nalgorithms for traditional neural network architectures may provide one of the\nmost promising settings for quantum machine learning. Considering a\nfully-connected feedforward neural network, we show that conditions amenable to\nclassical trainability via gradient descent coincide with those necessary for\nefficiently solving quantum linear systems. We propose a quantum algorithm to\napproximately train a wide and deep neural network up to $O(1/n)$ error for a\ntraining set of size $n$ by performing sparse matrix inversion in $O(\\log n)$\ntime. To achieve an end-to-end exponential speedup over gradient descent, the\ndata distribution must permit efficient state preparation and readout. We\nnumerically demonstrate that the MNIST image dataset satisfies such conditions;\nmoreover, the quantum algorithm matches the accuracy of the fully-connected\nnetwork. Beyond the proven architecture, we provide empirical evidence for\n$O(\\log n)$ training of a convolutional neural network with pooling.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 23:41:03 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zlokapa", "Alexander", ""], ["Neven", "Hartmut", ""], ["Lloyd", "Seth", ""]]}, {"id": "2107.09202", "submitter": "Daniel Severo", "authors": "Daniel Severo, James Townsend, Ashish Khisti, Alireza Makhzani, Karen\n  Ullrich", "title": "Compressing Multisets with Large Alphabets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods that optimally compress multisets are not suitable for\nhigh-dimensional symbols, as their compute time scales linearly with alphabet\nsize. Compressing a multiset as an ordered sequence with off-the-shelf codecs\nis computationally more efficient, but has a sub-optimal compression rate, as\nbits are wasted encoding the order between symbols. We present a method that\ncan recover those bits, assuming symbols are i.i.d., at the cost of an\nadditional $\\mathcal{O}(|\\mathcal{M}|\\log M)$ in average time complexity, where\n$|\\mathcal{M}|$ and $M$ are the total and unique number of symbols in the\nmultiset. Our method is compatible with any prefix-free code. Experiments show\nthat, when paired with efficient coders, our method can efficiently compress\nhigh-dimensional sources such as multisets of images and collections of JSON\nfiles.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:54:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Severo", "Daniel", ""], ["Townsend", "James", ""], ["Khisti", "Ashish", ""], ["Makhzani", "Alireza", ""], ["Ullrich", "Karen", ""]]}, {"id": "2107.09203", "submitter": "Fernando Gama", "authors": "Zhan Gao, Fernando Gama, Alejandro Ribeiro", "title": "Wide and Deep Graph Neural Network with Distributed Online Learning", "comments": "arXiv admin note: text overlap with arXiv:2006.06376", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are naturally distributed architectures for\nlearning representations from network data. This renders them suitable\ncandidates for decentralized tasks. In these scenarios, the underlying graph\noften changes with time due to link failures or topology variations, creating a\nmismatch between the graphs on which GNNs were trained and the ones on which\nthey are tested. Online learning can be leveraged to retrain GNNs at testing\ntime to overcome this issue. However, most online algorithms are centralized\nand usually offer guarantees only on convex problems, which GNNs rarely lead\nto. This paper develops the Wide and Deep GNN (WD-GNN), a novel architecture\nthat can be updated with distributed online learning mechanisms. The WD-GNN\nconsists of two components: the wide part is a linear graph filter and the deep\npart is a nonlinear GNN. At training time, the joint wide and deep architecture\nlearns nonlinear representations from data. At testing time, the wide, linear\npart is retrained, while the deep, nonlinear one remains fixed. This often\nleads to a convex formulation. We further propose a distributed online learning\nalgorithm that can be implemented in a decentralized setting. We also show the\nstability of the WD-GNN to changes of the underlying graph and analyze the\nconvergence of the proposed online learning procedure. Experiments on movie\nrecommendation, source localization and robot swarm control corroborate\ntheoretical findings and show the potential of the WD-GNN for distributed\nonline learning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 23:56:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gao", "Zhan", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2107.09204", "submitter": "Vincent Wilmet", "authors": "Vincent Wilmet, Sauraj Verma, Tabea Redl, H{\\aa}kon Sandaker, Zhenning\n  Li", "title": "A Comparison of Supervised and Unsupervised Deep Learning Methods for\n  Anomaly Detection in Images", "comments": "8 pages, for FML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Anomaly detection in images plays a significant role for many applications\nacross all industries, such as disease diagnosis in healthcare or quality\nassurance in manufacturing. Manual inspection of images, when extended over a\nmonotonously repetitive period of time is very time consuming and can lead to\nanomalies being overlooked.Artificial neural networks have proven themselves\nvery successful on simple, repetitive tasks, in some cases even outperforming\nhumans. Therefore, in this paper we investigate different methods of deep\nlearning, including supervised and unsupervised learning, for anomaly detection\napplied to a quality assurance use case. We utilize the MVTec anomaly dataset\nand develop three different models, a CNN for supervised anomaly detection,\nKD-CAE for autoencoder anomaly detection, NI-CAE for noise induced anomaly\ndetection and a DCGAN for generating reconstructed images. By experiments, we\nfound that KD-CAE performs better on the anomaly datasets compared to CNN and\nNI-CAE, with NI-CAE performing the best on the Transistor dataset. We also\nimplemented a DCGAN for the creation of new training data but due to\ncomputational limitation and lack of extrapolating the mechanics of AnoGAN, we\nrestricted ourselves just to the generation of GAN based images. We conclude\nthat unsupervised methods are more powerful for anomaly detection in images,\nespecially in a setting where only a small amount of anomalous data is\navailable, or the data is unlabeled.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 00:14:12 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wilmet", "Vincent", ""], ["Verma", "Sauraj", ""], ["Redl", "Tabea", ""], ["Sandaker", "H\u00e5kon", ""], ["Li", "Zhenning", ""]]}, {"id": "2107.09207", "submitter": "Ziyun Zhang", "authors": "Thomas Y. Hou, Zhenzhen Li, and Ziyun Zhang", "title": "Asymptotic Escape of Spurious Critical Points on the Low-rank Matrix\n  Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Riemannian gradient descent algorithm on the low-rank matrix\nmanifold almost surely escapes some spurious critical points on the boundary of\nthe manifold. Given that the low-rank matrix manifold is an incomplete set,\nthis result is the first to overcome this difficulty and partially justify the\nglobal use of the Riemannian gradient descent on the manifold. The spurious\ncritical points are some rank-deficient matrices that capture only part of the\nSVD components of the ground truth. They exhibit very singular behavior and\nevade the classical analysis of strict saddle points. We show that using the\ndynamical low-rank approximation and a rescaled gradient flow, some of the\nspurious critical points can be converted to classical strict saddle points,\nwhich leads to the desired result. Numerical experiments are provided to\nsupport our theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 00:25:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hou", "Thomas Y.", ""], ["Li", "Zhenzhen", ""], ["Zhang", "Ziyun", ""]]}, {"id": "2107.09208", "submitter": "Jean-Pierre Briot", "authors": "Mila Soares de Oliveira de Souza and Pedro Nuno de Souza Moura and\n  Jean-Pierre Briot", "title": "Music Tempo Estimation via Neural Networks -- A Comparative Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comparative analysis on two artificial neural networks\n(with different architectures) for the task of tempo estimation. For this\npurpose, it also proposes the modeling, training and evaluation of a B-RNN\n(Bidirectional Recurrent Neural Network) model capable of estimating tempo in\nbpm (beats per minutes) of musical pieces, without using external auxiliary\nmodules. An extensive database (12,550 pieces in total) was curated to conduct\na quantitative and qualitative analysis over the experiment. Percussion-only\ntracks were also included in the dataset. The performance of the B-RNN is\ncompared to that of state-of-the-art models. For further comparison, a\nstate-of-the-art CNN was also retrained with the same datasets used for the\nB-RNN training. Evaluation results for each model and datasets are presented\nand discussed, as well as observations and ideas for future research. Tempo\nestimation was more accurate for the percussion only dataset, suggesting that\nthe estimation can be more accurate for percussion-only tracks, although\nfurther experiments (with more of such datasets) should be made to gather\nstronger evidence.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 00:29:28 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["de Souza", "Mila Soares de Oliveira", ""], ["Moura", "Pedro Nuno de Souza", ""], ["Briot", "Jean-Pierre", ""]]}, {"id": "2107.09217", "submitter": "Shuting Jin", "authors": "Shuting Jin, Xiangxiang Zeng, Wei Huang, Feng Xia, Changzhi Jiang,\n  Xiangrong Liu and Shaoliang Peng", "title": "Heterogeneous network-based drug repurposing for COVID-19", "comments": "5 pages, 3 figures, ICLR 2021 MLPCP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Corona Virus Disease 2019 (COVID-19) belongs to human coronaviruses\n(HCoVs), which spreads rapidly around the world. Compared with new drug\ndevelopment, drug repurposing may be the best shortcut for treating COVID-19.\nTherefore, we constructed a comprehensive heterogeneous network based on the\nHCoVs-related target proteins and use the previously proposed deepDTnet, to\ndiscover potential drug candidates for COVID-19. We obtain high performance in\npredicting the possible drugs effective for COVID-19 related proteins. In\nsummary, this work utilizes a powerful heterogeneous network-based deep\nlearning method, which may be beneficial to quickly identify candidate\nrepurposable drugs toward future clinical trials for COVID-19. The code and\ndata are available at https://github.com/stjin-XMU/HnDR-COVID.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 01:24:40 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jin", "Shuting", ""], ["Zeng", "Xiangxiang", ""], ["Huang", "Wei", ""], ["Xia", "Feng", ""], ["Jiang", "Changzhi", ""], ["Liu", "Xiangrong", ""], ["Peng", "Shaoliang", ""]]}, {"id": "2107.09224", "submitter": "Zheng Wen", "authors": "Xiuyuan Lu, Ian Osband, Benjamin Van Roy, Zheng Wen", "title": "Evaluating Probabilistic Inference in Deep Learning: Beyond Marginal\n  Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge for any intelligent system is prediction: given some\ninputs $X_1,..,X_\\tau$ can you predict outcomes $Y_1,.., Y_\\tau$. The KL\ndivergence $\\mathbf{d}_{\\mathrm{KL}}$ provides a natural measure of prediction\nquality, but the majority of deep learning research looks only at the marginal\npredictions per input $X_t$. In this technical report we propose a scoring rule\n$\\mathbf{d}_{\\mathrm{KL}}^\\tau$, parameterized by $\\tau \\in \\mathcal{N}$ that\nevaluates the joint predictions at $\\tau$ inputs simultaneously. We show that\nthe commonly-used $\\tau=1$ can be insufficient to drive good decisions in many\nsettings of interest. We also show that, as $\\tau$ grows, performing well\naccording to $\\mathbf{d}_{\\mathrm{KL}}^\\tau$ recovers universal guarantees for\nany possible decision. Finally, we provide problem-dependent guidance on the\nscale of $\\tau$ for which our score provides sufficient guarantees for good\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 01:55:01 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Lu", "Xiuyuan", ""], ["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""], ["Wen", "Zheng", ""]]}, {"id": "2107.09232", "submitter": "Kenta Hongo", "authors": "Keishu Utimula, Ken-taro Hayaschi, Kousuke Nakano, Kenta Hongo, Ryo\n  Maezono", "title": "Reinforcement learning autonomously identifying the source of errors for\n  agents in a group mission", "comments": "4 pages, 1 figure. References added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When agents are swarmed to carry out a mission, there is often a sudden\nfailure of some of the agents observed from the command base. It is generally\ndifficult to distinguish whether the failure is caused by actuators\n(hypothesis, $h_a$) or sensors (hypothesis, $h_s$) solely by the communication\nbetween the command base and the concerning agent. By making a collision to the\nagent by another, we would be able to distinguish which hypothesis is likely:\nFor $h_a$, we expect to detect corresponding displacements while for $h_a$ we\ndo not. Such swarm strategies to grasp the situation are preferably to be\ngenerated autonomously by artificial intelligence (AI). Preferable actions\n($e.g.$, the collision) for the distinction would be those maximizing the\ndifference between the expected behaviors for each hypothesis, as a value\nfunction. Such actions exist, however, only very sparsely in the whole\npossibilities, for which the conventional search based on gradient methods does\nnot make sense. Instead, we have successfully applied the reinforcement\nlearning technique, achieving the maximization of such a sparse value function.\nThe machine learning actually concluded autonomously the colliding action to\ndistinguish the hypothesises. Getting recognized an agent with actuator error\nby the action, the agents behave as if other ones want to assist the\nmalfunctioning one to achieve a given mission.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 02:40:19 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 01:20:22 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Utimula", "Keishu", ""], ["Hayaschi", "Ken-taro", ""], ["Nakano", "Kousuke", ""], ["Hongo", "Kenta", ""], ["Maezono", "Ryo", ""]]}, {"id": "2107.09234", "submitter": "Angie Boggust", "authors": "Angie Boggust, Benjamin Hoover, Arvind Satyanarayan, Hendrik Strobelt", "title": "Shared Interest: Large-Scale Visual Analysis of Model Behavior by\n  Measuring Human-AI Alignment", "comments": "14 pages, 8 figures. For more details, see\n  http://shared-interest.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods -- techniques to identify the importance of input features\non a model's output -- are a common first step in understanding neural network\nbehavior. However, interpreting saliency requires tedious manual inspection to\nidentify and aggregate patterns in model behavior, resulting in ad hoc or\ncherry-picked analysis. To address these concerns, we present Shared Interest:\na set of metrics for comparing saliency with human annotated ground truths. By\nproviding quantitative descriptors, Shared Interest allows ranking, sorting,\nand aggregation of inputs thereby facilitating large-scale systematic analysis\nof model behavior. We use Shared Interest to identify eight recurring patterns\nin model behavior including focusing on a sufficient subset of ground truth\nfeatures or being distracted by contextual features. Working with\nrepresentative real-world users, we show how Shared Interest can be used to\nrapidly develop or lose trust in a model's reliability, uncover issues that are\nmissed in manual analyses, and enable interactive probing of model behavior.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 02:44:39 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Boggust", "Angie", ""], ["Hoover", "Benjamin", ""], ["Satyanarayan", "Arvind", ""], ["Strobelt", "Hendrik", ""]]}, {"id": "2107.09240", "submitter": "Yi-Fu Wu", "authors": "Yi-Fu Wu, Jaesik Yoon, Sungjin Ahn", "title": "Generative Video Transformer: Can Objects be the Words?", "comments": "Published in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have been successful for many natural language processing tasks.\nHowever, applying transformers to the video domain for tasks such as long-term\nvideo generation and scene understanding has remained elusive due to the high\ncomputational complexity and the lack of natural tokenization. In this paper,\nwe propose the Object-Centric Video Transformer (OCVT) which utilizes an\nobject-centric approach for decomposing scenes into tokens suitable for use in\na generative video transformer. By factoring the video into objects, our fully\nunsupervised model is able to learn complex spatio-temporal dynamics of\nmultiple interacting objects in a scene and generate future frames of the\nvideo. Our model is also significantly more memory-efficient than pixel-based\nmodels and thus able to train on videos of length up to 70 frames with a single\n48GB GPU. We compare our model with previous RNN-based approaches as well as\nother possible video transformer baselines. We demonstrate OCVT performs well\nwhen compared to baselines in generating future frames. OCVT also develops\nuseful representations for video reasoning, achieving start-of-the-art\nperformance on the CATER task.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 03:08:39 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wu", "Yi-Fu", ""], ["Yoon", "Jaesik", ""], ["Ahn", "Sungjin", ""]]}, {"id": "2107.09251", "submitter": "Daniel Brown", "authors": "Daniel Shin, Daniel S. Brown", "title": "Offline Preference-Based Apprenticeship Learning", "comments": "ICML Workshop on Human-AI Collaboration in Sequential\n  Decision-Making, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how an offline dataset of prior (possibly random) experience can be\nused to address two challenges that autonomous systems face when they endeavor\nto learn from, adapt to, and collaborate with humans : (1) identifying the\nhuman's intent and (2) safely optimizing the autonomous system's behavior to\nachieve this inferred intent. First, we use the offline dataset to efficiently\ninfer the human's reward function via pool-based active preference learning.\nSecond, given this learned reward function, we perform offline reinforcement\nlearning to optimize a policy based on the inferred human intent. Crucially,\nour proposed approach does not require actual physical rollouts or an accurate\nsimulator for either the reward learning or policy optimization steps, enabling\nboth safe and efficient apprenticeship learning. We identify and evaluate our\napproach on a subset of existing offline RL benchmarks that are well suited for\noffline reward learning and also evaluate extensions of these benchmarks which\nallow more open-ended behaviors. Our experiments show that offline\npreference-based reward learning followed by offline reinforcement learning\nenables efficient and high-performing policies, while only requiring small\nnumbers of preference queries. Videos available at\nhttps://sites.google.com/view/offline-prefs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 04:15:52 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 04:30:17 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shin", "Daniel", ""], ["Brown", "Daniel S.", ""]]}, {"id": "2107.09256", "submitter": "Wayne Isaac Uy", "authors": "Wayne Isaac Tan Uy, Yuepeng Wang, Yuxiao Wen, Benjamin Peherstorfer", "title": "Active operator inference for learning low-dimensional dynamical-system\n  models from noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise poses a challenge for learning dynamical-system models because already\nsmall variations can distort the dynamics described by trajectory data. This\nwork builds on operator inference from scientific machine learning to infer\nlow-dimensional models from high-dimensional state trajectories polluted with\nnoise. The presented analysis shows that, under certain conditions, the\ninferred operators are unbiased estimators of the well-studied projection-based\nreduced operators from traditional model reduction. Furthermore, the connection\nbetween operator inference and projection-based model reduction enables\nbounding the mean-squared errors of predictions made with the learned models\nwith respect to traditional reduced models. The analysis also motivates an\nactive operator inference approach that judiciously samples high-dimensional\ntrajectories with the aim of achieving a low mean-squared error by reducing the\neffect of noise. Numerical experiments with high-dimensional linear and\nnonlinear state dynamics demonstrate that predictions obtained with active\noperator inference have orders of magnitude lower mean-squared errors than\noperator inference with traditional, equidistantly sampled trajectory data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 04:30:07 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 02:52:17 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Uy", "Wayne Isaac Tan", ""], ["Wang", "Yuepeng", ""], ["Wen", "Yuxiao", ""], ["Peherstorfer", "Benjamin", ""]]}, {"id": "2107.09262", "submitter": "Sanchita Ghose", "authors": "Sanchita Ghose and John J. Prevost", "title": "FoleyGAN: Visually Guided Generative Adversarial Network-Based\n  Synchronous Sound Generation in Silent Videos", "comments": "This article is under review in IEEE Transaction on Multimedia. It\n  contains total 12 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.MM cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning based visual to sound generation systems essentially need to be\ndeveloped particularly considering the synchronicity aspects of visual and\naudio features with time. In this research we introduce a novel task of guiding\na class conditioned generative adversarial network with the temporal visual\ninformation of a video input for visual to sound generation task adapting the\nsynchronicity traits between audio-visual modalities. Our proposed FoleyGAN\nmodel is capable of conditioning action sequences of visual events leading\ntowards generating visually aligned realistic sound tracks. We expand our\npreviously proposed Automatic Foley dataset to train with FoleyGAN and evaluate\nour synthesized sound through human survey that shows noteworthy (on average\n81\\%) audio-visual synchronicity performance. Our approach also outperforms in\nstatistical experiments compared with other baseline models and audio-visual\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 04:59:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ghose", "Sanchita", ""], ["Prevost", "John J.", ""]]}, {"id": "2107.09282", "submitter": "Shan You", "authors": "Mingkai Zheng, Shan You, Fei Wang, Chen Qian, Changshui Zhang,\n  Xiaogang Wang, Chang Xu", "title": "ReSSL: Relational Self-Supervised Learning with Weak Augmentation", "comments": "fixed several typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised Learning (SSL) including the mainstream contrastive learning\nhas achieved great success in learning visual representations without data\nannotations. However, most of methods mainly focus on the instance level\ninformation (\\ie, the different augmented images of the same instance should\nhave the same feature or cluster into the same class), but there is a lack of\nattention on the relationships between different instances. In this paper, we\nintroduced a novel SSL paradigm, which we term as relational self-supervised\nlearning (ReSSL) framework that learns representations by modeling the\nrelationship between different instances. Specifically, our proposed method\nemploys sharpened distribution of pairwise similarities among different\ninstances as \\textit{relation} metric, which is thus utilized to match the\nfeature embeddings of different augmentations. Moreover, to boost the\nperformance, we argue that weak augmentations matter to represent a more\nreliable relation, and leverage momentum strategy for practical efficiency.\nExperimental results show that our proposed ReSSL significantly outperforms the\nprevious state-of-the-art algorithms in terms of both performance and training\nefficiency. Code is available at \\url{https://github.com/KyleZheng1997/ReSSL}.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 06:53:07 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 14:24:31 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Zheng", "Mingkai", ""], ["You", "Shan", ""], ["Wang", "Fei", ""], ["Qian", "Chen", ""], ["Zhang", "Changshui", ""], ["Wang", "Xiaogang", ""], ["Xu", "Chang", ""]]}, {"id": "2107.09286", "submitter": "Qingzhong Ai", "authors": "Qingzhong Ai, Lirong He, Shiyu Liu, Zenglin Xu", "title": "ByPE-VAE: Bayesian Pseudocoresets Exemplar VAE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that advanced priors play a major role in deep generative\nmodels. Exemplar VAE, as a variant of VAE with an exemplar-based prior, has\nachieved impressive results. However, due to the nature of model design, an\nexemplar-based model usually requires vast amounts of data to participate in\ntraining, which leads to huge computational complexity. To address this issue,\nwe propose Bayesian Pseudocoresets Exemplar VAE (ByPE-VAE), a new variant of\nVAE with a prior based on Bayesian pseudocoreset. The proposed prior is\nconditioned on a small-scale pseudocoreset rather than the whole dataset for\nreducing the computational cost and avoiding overfitting. Simultaneously, we\nobtain the optimal pseudocoreset via a stochastic optimization algorithm during\nVAE training aiming to minimize the Kullback-Leibler divergence between the\nprior based on the pseudocoreset and that based on the whole dataset.\nExperimental results show that ByPE-VAE can achieve competitive improvements\nover the state-of-the-art VAEs in the tasks of density estimation,\nrepresentation learning, and generative data augmentation. Particularly, on a\nbasic VAE architecture, ByPE-VAE is up to 3 times faster than Exemplar VAE\nwhile almost holding the performance. Code is available at our supplementary\nmaterials.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:02:19 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ai", "Qingzhong", ""], ["He", "Lirong", ""], ["Liu", "Shiyu", ""], ["Xu", "Zenglin", ""]]}, {"id": "2107.09301", "submitter": "Nikolaos Mourdoukoutas", "authors": "Nikolaos Mourdoukoutas, Marco Federici, Georges Pantalos, Mark van der\n  Wilk and Vincent Fortuin", "title": "A Bayesian Approach to Invariant Deep Neural Networks", "comments": "8 pages, 3 figures, To be published in ICML UDL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Bayesian neural network architecture that can learn\ninvariances from data alone by inferring a posterior distribution over\ndifferent weight-sharing schemes. We show that our model outperforms other\nnon-invariant architectures, when trained on datasets that contain specific\ninvariances. The same holds true when no data augmentation is performed.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:33:58 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mourdoukoutas", "Nikolaos", ""], ["Federici", "Marco", ""], ["Pantalos", "Georges", ""], ["van der Wilk", "Mark", ""], ["Fortuin", "Vincent", ""]]}, {"id": "2107.09305", "submitter": "Wenxian Shi", "authors": "Wenxian Shi, Yuxuan Song, Hao Zhou, Bohan Li, Lei Li", "title": "Follow Your Path: a Progressive Method for Knowledge Distillation", "comments": "Accepted by ECML-PKDD 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks often have a huge number of parameters, which posts\nchallenges in deployment in application scenarios with limited memory and\ncomputation capacity. Knowledge distillation is one approach to derive compact\nmodels from bigger ones. However, it has been observed that a converged heavy\nteacher model is strongly constrained for learning a compact student network\nand could make the optimization subject to poor local optima. In this paper, we\npropose ProKT, a new model-agnostic method by projecting the supervision\nsignals of a teacher model into the student's parameter space. Such projection\nis implemented by decomposing the training objective into local intermediate\ntargets with an approximate mirror descent technique. The proposed method could\nbe less sensitive with the quirks during optimization which could result in a\nbetter local optimum. Experiments on both image and text datasets show that our\nproposed ProKT consistently achieves superior performance compared to other\nexisting knowledge distillation methods.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:44:33 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Shi", "Wenxian", ""], ["Song", "Yuxuan", ""], ["Zhou", "Hao", ""], ["Li", "Bohan", ""], ["Li", "Lei", ""]]}, {"id": "2107.09309", "submitter": "Mohanad Odema", "authors": "Mohanad Odema, Nafiul Rashid, Berken Utku Demirel, Mohammad Abdullah\n  Al Faruque", "title": "LENS: Layer Distribution Enabled Neural Architecture Search in\n  Edge-Cloud Hierarchies", "comments": "To appear at the 58th IEEE/ACM Design Automation Conference (DAC),\n  December 2021, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge-Cloud hierarchical systems employing intelligence through Deep Neural\nNetworks (DNNs) endure the dilemma of workload distribution within them.\nPrevious solutions proposed to distribute workloads at runtime according to the\nstate of the surroundings, like the wireless conditions. However, such\nconditions are usually overlooked at design time. This paper addresses this\nissue for DNN architectural design by presenting a novel methodology, LENS,\nwhich administers multi-objective Neural Architecture Search (NAS) for\ntwo-tiered systems, where the performance objectives are refashioned to\nconsider the wireless communication parameters. From our experimental search\nspace, we demonstrate that LENS improves upon the traditional solution's Pareto\nset by 76.47% and 75% with respect to the energy and latency metrics,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:53:02 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Odema", "Mohanad", ""], ["Rashid", "Nafiul", ""], ["Demirel", "Berken Utku", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "2107.09321", "submitter": "Siqi Zheng", "authors": "Siqi Zheng, Weilong Huang, Xianliang Wang, Hongbin Suo, Jinwei Feng,\n  Zhijie Yan", "title": "A Real-time Speaker Diarization System Based on Spatial Spectrum", "comments": "Published in ICASSP 2021 - 2021 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP);", "journal-ref": null, "doi": "10.1109/ICASSP39728.2021.9413544", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we describe a speaker diarization system that enables\nlocalization and identification of all speakers present in a conversation or\nmeeting. We propose a novel systematic approach to tackle several long-standing\nchallenges in speaker diarization tasks: (1) to segment and separate\noverlapping speech from two speakers; (2) to estimate the number of speakers\nwhen participants may enter or leave the conversation at any time; (3) to\nprovide accurate speaker identification on short text-independent utterances;\n(4) to track down speakers movement during the conversation; (5) to detect\nspeaker change incidence real-time. First, a differential directional\nmicrophone array-based approach is exploited to capture the target speakers'\nvoice in far-field adverse environment. Second, an online speaker-location\njoint clustering approach is proposed to keep track of speaker location. Third,\nan instant speaker number detector is developed to trigger the mechanism that\nseparates overlapped speech. The results suggest that our system effectively\nincorporates spatial information and achieves significant gains.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 08:25:23 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zheng", "Siqi", ""], ["Huang", "Weilong", ""], ["Wang", "Xianliang", ""], ["Suo", "Hongbin", ""], ["Feng", "Jinwei", ""], ["Yan", "Zhijie", ""]]}, {"id": "2107.09323", "submitter": "Wissam Siblini", "authors": "Wissam Siblini, Guillaume Coter, R\\'emy Fabry, Liyun He-Guelton,\n  Fr\\'ed\\'eric Obl\\'e, Bertrand Lebichot, Yann-A\\\"el Le Borgne, Gianluca\n  Bontempi", "title": "Transfer Learning for Credit Card Fraud Detection: A Journey from\n  Research to Production", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dark face of digital commerce generalization is the increase of fraud\nattempts. To prevent any type of attacks, state of the art fraud detection\nsystems are now embedding Machine Learning (ML) modules. The conception of such\nmodules is only communicated at the level of research and papers mostly focus\non results for isolated benchmark datasets and metrics. But research is only a\npart of the journey, preceded by the right formulation of the business problem\nand collection of data, and followed by a practical integration. In this paper,\nwe give a wider vision of the process, on a case study of transfer learning for\nfraud detection, from business to research, and back to business.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 08:29:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Siblini", "Wissam", ""], ["Coter", "Guillaume", ""], ["Fabry", "R\u00e9my", ""], ["He-Guelton", "Liyun", ""], ["Obl\u00e9", "Fr\u00e9d\u00e9ric", ""], ["Lebichot", "Bertrand", ""], ["Borgne", "Yann-A\u00ebl Le", ""], ["Bontempi", "Gianluca", ""]]}, {"id": "2107.09338", "submitter": "Qingzhong Ai", "authors": "Qingzhong Ai, Shiyu Liu, Zenglin Xu", "title": "Kernel Selection for Stein Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stein variational gradient descent (SVGD) and its variants have shown\npromising successes in approximate inference for complex distributions.\nHowever, their empirical performance depends crucially on the choice of optimal\nkernel. Unfortunately, RBF kernel with median heuristics is a common choice in\nprevious approaches which has been proved sub-optimal. Inspired by the paradigm\nof multiple kernel learning, our solution to this issue is using a combination\nof multiple kernels to approximate the optimal kernel instead of a single one\nwhich may limit the performance and flexibility. To do so, we extend Kernelized\nStein Discrepancy (KSD) to its multiple kernel view called Multiple Kernelized\nStein Discrepancy (MKSD). Further, we leverage MKSD to construct a general\nalgorithm based on SVGD, which be called Multiple Kernel SVGD (MK-SVGD).\nBesides, we automatically assign a weight to each kernel without any other\nparameters. The proposed method not only gets rid of optimal kernel dependence\nbut also maintains computational effectiveness. Experiments on various tasks\nand models show the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 08:48:42 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ai", "Qingzhong", ""], ["Liu", "Shiyu", ""], ["Xu", "Zenglin", ""]]}, {"id": "2107.09355", "submitter": "Haotian Jiang", "authors": "Haotian Jiang, Zhong Li, Qianxiao Li", "title": "Approximation Theory of Convolutional Architectures for Time Series\n  Modelling", "comments": "Published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation properties of convolutional architectures applied\nto time series modelling, which can be formulated mathematically as a\nfunctional approximation problem. In the recurrent setting, recent results\nreveal an intricate connection between approximation efficiency and memory\nstructures in the data generation process. In this paper, we derive parallel\nresults for convolutional architectures, with WaveNet being a prime example.\nOur results reveal that in this new setting, approximation efficiency is not\nonly characterised by memory, but also additional fine structures in the target\nrelationship. This leads to a novel definition of spectrum-based regularity\nthat measures the complexity of temporal relationships under the convolutional\napproximation scheme. These analyses provide a foundation to understand the\ndifferences between architectural choices for time series modelling and can\ngive theoretically grounded guidance for practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:19:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jiang", "Haotian", ""], ["Li", "Zhong", ""], ["Li", "Qianxiao", ""]]}, {"id": "2107.09356", "submitter": "Kevin Eloff", "authors": "Kevin Eloff, Herman A. Engelbrecht", "title": "Toward Collaborative Reinforcement Learning Agents that Communicate\n  Through Text-Based Natural Language", "comments": "5 pages, 6 figures, 3 tables; published in 2021 Southern African\n  Universities Power Engineering Conference/Robotics and Mechatronics/Pattern\n  Recognition Association of South Africa (SAUPEC/RobMech/PRASA), 2021, pp.\n  1-6, (c) 2021 IEEE", "journal-ref": "In: 2021 Southern African Universities Power Engineering\n  Conference/Robotics and Mechatronics/Pattern Recognition Association of South\n  Africa (SAUPEC/RobMech/PRASA), 2021, pp. 1-6", "doi": "10.1109/SAUPEC/RobMech/PRASA52254.2021.9377018", "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication between agents in collaborative multi-agent settings is in\ngeneral implicit or a direct data stream. This paper considers text-based\nnatural language as a novel form of communication between multiple agents\ntrained with reinforcement learning. This could be considered first steps\ntoward a truly autonomous communication without the need to define a limited\nset of instructions, and natural collaboration between humans and robots.\nInspired by the game of Blind Leads, we propose an environment where one agent\nuses natural language instructions to guide another through a maze. We test the\nability of reinforcement learning agents to effectively communicate through\ndiscrete word-level symbols and show that the agents are able to sufficiently\ncommunicate through natural language with a limited vocabulary. Although the\ncommunication is not always perfect English, the agents are still able to\nnavigate the maze. We achieve a BLEU score of 0.85, which is an improvement of\n0.61 over randomly generated sequences while maintaining a 100% maze completion\nrate. This is a 3.5 times the performance of the random baseline using our\nreference set.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:19:29 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 13:28:31 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Eloff", "Kevin", ""], ["Engelbrecht", "Herman A.", ""]]}, {"id": "2107.09359", "submitter": "Jo\\~ao Carvalho", "authors": "Jo\\~ao Carvalho, Davide Tateo, Fabio Muratore, Jan Peters", "title": "An Empirical Analysis of Measure-Valued Derivatives for Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning methods for robotics are increasingly successful due\nto the constant development of better policy gradient techniques. A precise\n(low variance) and accurate (low bias) gradient estimator is crucial to face\nincreasingly complex tasks. Traditional policy gradient algorithms use the\nlikelihood-ratio trick, which is known to produce unbiased but high variance\nestimates. More modern approaches exploit the reparametrization trick, which\ngives lower variance gradient estimates but requires differentiable value\nfunction approximators. In this work, we study a different type of stochastic\ngradient estimator: the Measure-Valued Derivative. This estimator is unbiased,\nhas low variance, and can be used with differentiable and non-differentiable\nfunction approximators. We empirically evaluate this estimator in the\nactor-critic policy gradient setting and show that it can reach comparable\nperformance with methods based on the likelihood-ratio or reparametrization\ntricks, both in low and high-dimensional action spaces.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:26:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Carvalho", "Jo\u00e3o", ""], ["Tateo", "Davide", ""], ["Muratore", "Fabio", ""], ["Peters", "Jan", ""]]}, {"id": "2107.09362", "submitter": "Hiroki Ito", "authors": "Hiroki Ito, MaungMaung AprilPyone, Hitoshi Kiya", "title": "Protecting Semantic Segmentation Models by Using Block-wise Image\n  Encryption with Secret Key from Unauthorized Access", "comments": "To appear in 2021 International Workshop on Smart Info-Media Systems\n  in Asia (SISA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since production-level trained deep neural networks (DNNs) are of a great\nbusiness value, protecting such DNN models against copyright infringement and\nunauthorized access is in a rising demand. However, conventional model\nprotection methods focused only the image classification task, and these\nprotection methods were never applied to semantic segmentation although it has\nan increasing number of applications. In this paper, we propose to protect\nsemantic segmentation models from unauthorized access by utilizing block-wise\ntransformation with a secret key for the first time. Protected models are\ntrained by using transformed images. Experiment results show that the proposed\nprotection method allows rightful users with the correct key to access the\nmodel to full capacity and deteriorate the performance for unauthorized users.\nHowever, protected models slightly drop the segmentation performance compared\nto non-protected models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:31:15 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ito", "Hiroki", ""], ["AprilPyone", "MaungMaung", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2107.09366", "submitter": "Georgios Zervakis", "authors": "Ourania Spantidi, Georgios Zervakis, Iraklis Anagnostopoulos, Hussam\n  Amrouch, J\\\"org Henkel", "title": "Positive/Negative Approximate Multipliers for DNN Accelerators", "comments": "Accepted for publication at the 40th International Conference On\n  Computer Aided Design (ICCAD 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Deep Neural Networks (DNNs) managed to deliver superhuman accuracy\nlevels on many AI tasks. Several applications rely more and more on DNNs to\ndeliver sophisticated services and DNN accelerators are becoming integral\ncomponents of modern systems-on-chips. DNNs perform millions of arithmetic\noperations per inference and DNN accelerators integrate thousands of\nmultiply-accumulate units leading to increased energy requirements. Approximate\ncomputing principles are employed to significantly lower the energy consumption\nof DNN accelerators at the cost of some accuracy loss. Nevertheless, recent\nresearch demonstrated that complex DNNs are increasingly sensitive to\napproximation. Hence, the obtained energy savings are often limited when\ntargeting tight accuracy constraints. In this work, we present a dynamically\nconfigurable approximate multiplier that supports three operation modes, i.e.,\nexact, positive error, and negative error. In addition, we propose a\nfilter-oriented approximation method to map the weights to the appropriate\nmodes of the approximate multiplier. Our mapping algorithm balances the\npositive with the negative errors due to the approximate multiplications,\naiming at maximizing the energy reduction while minimizing the overall\nconvolution error. We evaluate our approach on multiple DNNs and datasets\nagainst state-of-the-art approaches, where our method achieves 18.33% energy\ngains on average across 7 NNs on 4 different datasets for a maximum accuracy\ndrop of only 1%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:36:24 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Spantidi", "Ourania", ""], ["Zervakis", "Georgios", ""], ["Anagnostopoulos", "Iraklis", ""], ["Amrouch", "Hussam", ""], ["Henkel", "J\u00f6rg", ""]]}, {"id": "2107.09370", "submitter": "Pierre Stock", "authors": "Pierre Stock and R\\'emi Gribonval", "title": "An Embedding of ReLU Networks and an Analysis of their Identifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks with the Rectified Linear Unit (ReLU) nonlinearity are\ndescribed by a vector of parameters $\\theta$, and realized as a piecewise\nlinear continuous function $R_{\\theta}: x \\in \\mathbb R^{d} \\mapsto\nR_{\\theta}(x) \\in \\mathbb R^{k}$. Natural scalings and permutations operations\non the parameters $\\theta$ leave the realization unchanged, leading to\nequivalence classes of parameters that yield the same realization. These\nconsiderations in turn lead to the notion of identifiability -- the ability to\nrecover (the equivalence class of) $\\theta$ from the sole knowledge of its\nrealization $R_{\\theta}$. The overall objective of this paper is to introduce\nan embedding for ReLU neural networks of any depth, $\\Phi(\\theta)$, that is\ninvariant to scalings and that provides a locally linear parameterization of\nthe realization of the network. Leveraging these two key properties, we derive\nsome conditions under which a deep ReLU network is indeed locally identifiable\nfrom the knowledge of the realization on a finite set of samples $x_{i} \\in\n\\mathbb R^{d}$. We study the shallow case in more depth, establishing necessary\nand sufficient conditions for the network to be identifiable from a bounded\nsubset $\\mathcal X \\subseteq \\mathbb R^{d}$.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:43:31 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Stock", "Pierre", ""], ["Gribonval", "R\u00e9mi", ""]]}, {"id": "2107.09384", "submitter": "Dirk Ostwald", "authors": "Dirk Ostwald and Franziska Us\\'ee", "title": "An induction proof of the backpropagation algorithm in matrix notation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST q-bio.NC stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Backpropagation (BP) is a core component of the contemporary deep learning\nincarnation of neural networks. Briefly, BP is an algorithm that exploits the\ncomputational architecture of neural networks to efficiently evaluate the\ngradient of a cost function during neural network parameter optimization. The\nvalidity of BP rests on the application of a multivariate chain rule to the\ncomputational architecture of neural networks and their associated objective\nfunctions. Introductions to deep learning theory commonly present the\ncomputational architecture of neural networks in matrix form, but eschew a\nparallel formulation and justification of BP in the framework of matrix\ndifferential calculus. This entails several drawbacks for the theory and\ndidactics of deep learning. In this work, we overcome these limitations by\nproviding a full induction proof of the BP algorithm in matrix notation.\nSpecifically, we situate the BP algorithm in the framework of matrix\ndifferential calculus, encompass affine-linear potential functions, prove the\nvalidity of the BP algorithm in inductive form, and exemplify the\nimplementation of the matrix form BP algorithm in computer code.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 10:02:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ostwald", "Dirk", ""], ["Us\u00e9e", "Franziska", ""]]}, {"id": "2107.09391", "submitter": "Sadaf Gulshad", "authors": "Sadaf Gulshad, Ivan Sosnovik, Arnold Smeulders", "title": "Built-in Elastic Transformations for Improved Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on building robustness in the convolutions of neural visual\nclassifiers, especially against natural perturbations like elastic\ndeformations, occlusions and Gaussian noise. Existing CNNs show outstanding\nperformance on clean images, but fail to tackle naturally occurring\nperturbations. In this paper, we start from elastic perturbations, which\napproximate (local) view-point changes of the object. We present\nelastically-augmented convolutions (EAConv) by parameterizing filters as a\ncombination of fixed elastically-perturbed bases functions and trainable\nweights for the purpose of integrating unseen viewpoints in the CNN. We show on\nCIFAR-10 and STL-10 datasets that the general robustness of our method on\nunseen occlusion and Gaussian perturbations improves, while even improving the\nperformance on clean images slightly without performing any data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 10:16:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gulshad", "Sadaf", ""], ["Sosnovik", "Ivan", ""], ["Smeulders", "Arnold", ""]]}, {"id": "2107.09392", "submitter": "Cheng-Hung Hu", "authors": "Cheng-Hung Hu, Yu-Huai Peng, Junichi Yamagishi, Yu Tsao, Hsin-Min Wang", "title": "SVSNet: An End-to-end Speaker Voice Similarity Assessment Model", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural evaluation metrics derived for numerous speech generation tasks have\nrecently attracted great attention. In this paper, we propose SVSNet, the first\nend-to-end neural network model to assess the speaker voice similarity between\nnatural speech and synthesized speech. Unlike most neural evaluation metrics\nthat use hand-crafted features, SVSNet directly takes the raw waveform as input\nto more completely utilize speech information for prediction. SVSNet consists\nof encoder, co-attention, distance calculation, and prediction modules and is\ntrained in an end-to-end manner. The experimental results on the Voice\nConversion Challenge 2018 and 2020 (VCC2018 and VCC2020) datasets show that\nSVSNet notably outperforms well-known baseline systems in the assessment of\nspeaker similarity at the utterance and system levels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 10:19:46 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hu", "Cheng-Hung", ""], ["Peng", "Yu-Huai", ""], ["Yamagishi", "Junichi", ""], ["Tsao", "Yu", ""], ["Wang", "Hsin-Min", ""]]}, {"id": "2107.09402", "submitter": "Mohammad Safiuddin", "authors": "Mohammad Safiuddin, CH Likith Reddy, Ganesh Vasantada, CHJNS Harsha,\n  Srinu Gangolu", "title": "Establishing process-structure linkages using Generative Adversarial\n  Networks", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The microstructure of material strongly influences its mechanical properties\nand the microstructure itself is influenced by the processing conditions. Thus,\nestablishing a Process-Structure-Property relationship is a crucial task in\nmaterial design and is of interest in many engineering applications. We develop\na GAN (Generative Adversarial Network) to synthesize microstructures based on\ngiven processing conditions. This approach is devoid of feature engineering,\nneeds little domain awareness, and can be applied to a wide variety of material\nsystems. Results show that our GAN model can produce high-fidelity multi-phase\nmicrostructures which have a good correlation with the given processing\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 10:49:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Safiuddin", "Mohammad", ""], ["Reddy", "CH Likith", ""], ["Vasantada", "Ganesh", ""], ["Harsha", "CHJNS", ""], ["Gangolu", "Srinu", ""]]}, {"id": "2107.09408", "submitter": "Marc Riera", "authors": "Marc Riera, Jose-Maria Arnau, Antonio Gonzalez", "title": "CREW: Computation Reuse and Efficient Weight Storage for\n  Hardware-accelerated MLPs and RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have achieved tremendous success for cognitive\napplications. The core operation in a DNN is the dot product between quantized\ninputs and weights. Prior works exploit the weight/input repetition that arises\ndue to quantization to avoid redundant computations in Convolutional Neural\nNetworks (CNNs). However, in this paper we show that their effectiveness is\nseverely limited when applied to Fully-Connected (FC) layers, which are\ncommonly used in state-of-the-art DNNs, as it is the case of modern Recurrent\nNeural Networks (RNNs) and Transformer models.\n  To improve energy-efficiency of FC computation we present CREW, a hardware\naccelerator that implements Computation Reuse and an Efficient Weight Storage\nmechanism to exploit the large number of repeated weights in FC layers. CREW\nfirst performs the multiplications of the unique weights by their respective\ninputs and stores the results in an on-chip buffer. The storage requirements\nare modest due to the small number of unique weights and the relatively small\nsize of the input compared to convolutional layers. Next, CREW computes each\noutput by fetching and adding its required products. To this end, each weight\nis replaced offline by an index in the buffer of unique products. Indices are\ntypically smaller than the quantized weights, since the number of unique\nweights for each input tends to be much lower than the range of quantized\nweights, which reduces storage and memory bandwidth requirements.\n  Overall, CREW greatly reduces the number of multiplications and provides\nsignificant savings in model memory footprint and memory bandwidth usage. We\nevaluate CREW on a diverse set of modern DNNs. On average, CREW provides 2.61x\nspeedup and 2.42x energy savings over a TPU-like accelerator. Compared to UCNN,\na state-of-art computation reuse technique, CREW achieves 2.10x speedup and\n2.08x energy savings on average.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:10:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Riera", "Marc", ""], ["Arnau", "Jose-Maria", ""], ["Gonzalez", "Antonio", ""]]}, {"id": "2107.09414", "submitter": "Alexander Tornede", "authors": "Alexander Tornede, Lukas Gehring, Tanja Tornede, Marcel Wever, Eyke\n  H\\\"ullermeier", "title": "Algorithm Selection on a Meta Level", "comments": "under review for a special issue @ MLJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of selecting an algorithm that appears most suitable for a\nspecific instance of an algorithmic problem class, such as the Boolean\nsatisfiability problem, is called instance-specific algorithm selection. Over\nthe past decade, the problem has received considerable attention, resulting in\na number of different methods for algorithm selection. Although most of these\nmethods are based on machine learning, surprisingly little work has been done\non meta learning, that is, on taking advantage of the complementarity of\nexisting algorithm selection methods in order to combine them into a single\nsuperior algorithm selector. In this paper, we introduce the problem of meta\nalgorithm selection, which essentially asks for the best way to combine a given\nset of algorithm selectors. We present a general methodological framework for\nmeta algorithm selection as well as several concrete learning methods as\ninstantiations of this framework, essentially combining ideas of meta learning\nand ensemble learning. In an extensive experimental evaluation, we demonstrate\nthat ensembles of algorithm selectors can significantly outperform single\nalgorithm selectors and have the potential to form the new state of the art in\nalgorithm selection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:23:21 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tornede", "Alexander", ""], ["Gehring", "Lukas", ""], ["Tornede", "Tanja", ""], ["Wever", "Marcel", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2107.09422", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Ravichandra Addanki, Peter W. Battaglia, David Budden, Andreea Deac,\n  Jonathan Godwin, Thomas Keck, Wai Lok Sibon Li, Alvaro Sanchez-Gonzalez,\n  Jacklynn Stott, Shantanu Thakoor, Petar Veli\\v{c}kovi\\'c", "title": "Large-scale graph representation learning with very deep GNNs and\n  self-supervision", "comments": "To appear at KDD Cup 2021. 13 pages, 3 figures. All authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effectively and efficiently deploying graph neural networks (GNNs) at scale\nremains one of the most challenging aspects of graph representation learning.\nMany powerful solutions have only ever been validated on comparatively small\ndatasets, often with counter-intuitive outcomes -- a barrier which has been\nbroken by the Open Graph Benchmark Large-Scale Challenge (OGB-LSC). We entered\nthe OGB-LSC with two large-scale GNNs: a deep transductive node classifier\npowered by bootstrapping, and a very deep (up to 50-layer) inductive graph\nregressor regularised by denoising objectives. Our models achieved an\naward-level (top-3) performance on both the MAG240M and PCQM4M benchmarks. In\ndoing so, we demonstrate evidence of scalable self-supervised graph\nrepresentation learning, and utility of very deep GNNs -- both very important\nopen issues. Our code is publicly available at:\nhttps://github.com/deepmind/deepmind-research/tree/master/ogb_lsc.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:35:25 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Addanki", "Ravichandra", ""], ["Battaglia", "Peter W.", ""], ["Budden", "David", ""], ["Deac", "Andreea", ""], ["Godwin", "Jonathan", ""], ["Keck", "Thomas", ""], ["Li", "Wai Lok Sibon", ""], ["Sanchez-Gonzalez", "Alvaro", ""], ["Stott", "Jacklynn", ""], ["Thakoor", "Shantanu", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2107.09428", "submitter": "Tianzi Wang", "authors": "Tianzi Wang, Yuya Fujita, Xuankai Chang, Shinji Watanabe", "title": "Streaming End-to-End ASR based on Blockwise Non-Autoregressive Models", "comments": "5 pages, 1 figures, Interspeech21 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive (NAR) modeling has gained more and more attention in\nspeech processing. With recent state-of-the-art attention-based automatic\nspeech recognition (ASR) structure, NAR can realize promising real-time factor\n(RTF) improvement with only small degradation of accuracy compared to the\nautoregressive (AR) models. However, the recognition inference needs to wait\nfor the completion of a full speech utterance, which limits their applications\non low latency scenarios. To address this issue, we propose a novel end-to-end\nstreaming NAR speech recognition system by combining blockwise-attention and\nconnectionist temporal classification with mask-predict (Mask-CTC) NAR. During\ninference, the input audio is separated into small blocks and then processed in\na blockwise streaming way. To address the insertion and deletion error at the\nedge of the output of each block, we apply an overlapping decoding strategy\nwith a dynamic mapping trick that can produce more coherent sentences.\nExperimental results show that the proposed method improves online ASR\nrecognition in low latency conditions compared to vanilla Mask-CTC. Moreover,\nit can achieve a much faster inference speed compared to the AR attention-based\nmodels. All of our codes will be publicly available at\nhttps://github.com/espnet/espnet.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:42:26 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Wang", "Tianzi", ""], ["Fujita", "Yuya", ""], ["Chang", "Xuankai", ""], ["Watanabe", "Shinji", ""]]}, {"id": "2107.09437", "submitter": "Ling Feng", "authors": "Lin Zhang, Ling Feng, Kan Chen and Choy Heng Lai", "title": "Edge of chaos as a guiding principle for modern neural network training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.CD physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep neural networks in real-world problems has prompted many\nattempts to explain their training dynamics and generalization performance, but\nmore guiding principles for the training of neural networks are still needed.\nMotivated by the edge of chaos principle behind the optimal performance of\nneural networks, we study the role of various hyperparameters in modern neural\nnetwork training algorithms in terms of the order-chaos phase diagram. In\nparticular, we study a fully analytical feedforward neural network trained on\nthe widely adopted Fashion-MNIST dataset, and study the dynamics associated\nwith the hyperparameters in back-propagation during the training process. We\nfind that for the basic algorithm of stochastic gradient descent with momentum,\nin the range around the commonly used hyperparameter values, clear scaling\nrelations are present with respect to the training time during the ordered\nphase in the phase diagram, and the model's optimal generalization power at the\nedge of chaos is similar across different training parameter combinations. In\nthe chaotic phase, the same scaling no longer exists. The scaling allows us to\nchoose the training parameters to achieve faster training without sacrificing\nperformance. In addition, we find that the commonly used model regularization\nmethod - weight decay - effectively pushes the model towards the ordered phase\nto achieve better performance. Leveraging on this fact and the scaling\nrelations in the other hyperparameters, we derived a principled guideline for\nhyperparameter determination, such that the model can achieve optimal\nperformance by saturating it at the edge of chaos. Demonstrated on this simple\nneural network model and training algorithm, our work improves the\nunderstanding of neural network training dynamics, and can potentially be\nextended to guiding principles of more complex model architectures and\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 12:17:55 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zhang", "Lin", ""], ["Feng", "Ling", ""], ["Chen", "Kan", ""], ["Lai", "Choy Heng", ""]]}, {"id": "2107.09461", "submitter": "Zhize Li", "authors": "Zhize Li, Peter Richt\\'arik", "title": "CANITA: Faster Rates for Distributed Convex Optimization with\n  Communication Compression", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high communication cost in distributed and federated learning,\nmethods relying on compressed communication are becoming increasingly popular.\nBesides, the best theoretically and practically performing gradient-type\nmethods invariably rely on some form of acceleration/momentum to reduce the\nnumber of communications (faster convergence), e.g., Nesterov's accelerated\ngradient descent (Nesterov, 2004) and Adam (Kingma and Ba, 2014). In order to\ncombine the benefits of communication compression and convergence acceleration,\nwe propose a \\emph{compressed and accelerated} gradient method for distributed\noptimization, which we call CANITA. Our CANITA achieves the \\emph{first\naccelerated rate}\n$O\\bigg(\\sqrt{\\Big(1+\\sqrt{\\frac{\\omega^3}{n}}\\Big)\\frac{L}{\\epsilon}} +\n\\omega\\big(\\frac{1}{\\epsilon}\\big)^{\\frac{1}{3}}\\bigg)$, which improves upon\nthe state-of-the-art non-accelerated rate\n$O\\left((1+\\frac{\\omega}{n})\\frac{L}{\\epsilon} +\n\\frac{\\omega^2+n}{\\omega+n}\\frac{1}{\\epsilon}\\right)$ of DIANA (Khaled et al.,\n2020b) for distributed general convex problems, where $\\epsilon$ is the target\nerror, $L$ is the smooth parameter of the objective, $n$ is the number of\nmachines/devices, and $\\omega$ is the compression parameter (larger $\\omega$\nmeans more compression can be applied, and no compression implies $\\omega=0$).\nOur results show that as long as the number of devices $n$ is large (often true\nin distributed/federated learning), or the compression $\\omega$ is not very\nhigh, CANITA achieves the faster convergence rate\n$O\\Big(\\sqrt{\\frac{L}{\\epsilon}}\\Big)$, i.e., the number of communication\nrounds is $O\\Big(\\sqrt{\\frac{L}{\\epsilon}}\\Big)$ (vs.\n$O\\big(\\frac{L}{\\epsilon}\\big)$ achieved by previous works). As a result,\nCANITA enjoys the advantages of both compression (compressed communication in\neach round) and acceleration (much fewer communication rounds).\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 13:01:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Li", "Zhize", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2107.09480", "submitter": "Giosu\\'e Lo Bosco", "authors": "Domenico Amato and Raffaele Giancarlo and Giosu\\`e Lo Bosco", "title": "Learned Sorted Table Search and Static Indexes in Small Space:\n  Methodological and Practical Insights via an Experimental Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sorted Table Search Procedures are the quintessential query-answering tool,\nstill very useful, e.g, Search Engines (Google Chrome). Speeding them up, in\nsmall additional space with respect to the table being searched into, is still\na quite significant achievement. Static Learned Indexes have been very\nsuccessful in achieving such a speed-up, but leave open a major question: To\nwhat extent one can enjoy the speed-up of Learned Indexes while using constant\nor nearly constant additional space. By generalizing the experimental\nmethodology of a recent benchmarking study on Learned Indexes, we shed light on\nthis question, by considering two scenarios. The first, quite elementary, i.e.,\ntextbook code, and the second using advanced Learned Indexing algorithms and\nthe supporting sophisticated software platforms. Although in both cases one\nwould expect a positive answer, its achievement is not as simple as it seems.\nIndeed, our extensive set of experiments reveal a complex relationship between\nquery time and model space. The findings regarding this relationship and the\ncorresponding quantitative estimates, across memory levels, can be of interest\nto algorithm designers and of use to practitioners as well. As an essential\npart of our research, we introduce two new models that are of interest in their\nown right. The first is a constant space model that can be seen as a\ngeneralization of $k$-ary search, while the second is a synoptic {\\bf RMI}, in\nwhich we can control model space usage.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:06:55 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 13:56:52 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 13:18:02 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Amato", "Domenico", ""], ["Giancarlo", "Raffaele", ""], ["Bosco", "Giosu\u00e8 Lo", ""]]}, {"id": "2107.09483", "submitter": "Delong Chen", "authors": "Delong Chen, Fan Liu, Zheqi Zhang, Xiaomin Lu, Zewen Li", "title": "Significant Wave Height Prediction based on Wavelet Graph Neural Network", "comments": "Accepted by 2021 4th International Conference on Big Data and\n  Artificial Intelligence (BDAI). Best presentation winner", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational intelligence-based ocean characteristics forecasting\napplications, such as Significant Wave Height (SWH) prediction, are crucial for\navoiding social and economic loss in coastal cities. Compared to the\ntraditional empirical-based or numerical-based forecasting models, \"soft\ncomputing\" approaches, including machine learning and deep learning models,\nhave shown numerous success in recent years. In this paper, we focus on\nenabling the deep learning model to learn both short-term and long-term\nspatial-temporal dependencies for SWH prediction. A Wavelet Graph Neural\nNetwork (WGNN) approach is proposed to integrate the advantages of wavelet\ntransform and graph neural network. Several parallel graph neural networks are\nseparately trained on wavelet decomposed data, and the reconstruction of each\nmodel's prediction forms the final SWH prediction. Experimental results show\nthat the proposed WGNN approach outperforms other models, including the\nnumerical models, the machine learning models, and several deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 13:34:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Delong", ""], ["Liu", "Fan", ""], ["Zhang", "Zheqi", ""], ["Lu", "Xiaomin", ""], ["Li", "Zewen", ""]]}, {"id": "2107.09484", "submitter": "Gabriel Kronberger", "authors": "Gabriel Kronberger, Michael Kommenda, Andreas Promberger, Falk Nickel", "title": "Predicting Friction System Performance with Symbolic Regression and\n  Genetic Programming with Factor Variables", "comments": "Genetic and Evolutionary Computation Conference (GECCO), July\n  15th-19th, 2018", "journal-ref": "In Proceedings of the Genetic and Evolutionary Computation\n  Conference, pp. 1278-1285. ACM. (July 2018)", "doi": "10.1145/3205455.3205522", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Friction systems are mechanical systems wherein friction is used for force\ntransmission (e.g. mechanical braking systems or automatic gearboxes). For\nfinding optimal and safe design parameters, engineers have to predict friction\nsystem performance. This is especially difficult in real-world applications,\nbecause it is affected by many parameters. We have used symbolic regression and\ngenetic programming for finding accurate and trustworthy prediction models for\nthis task. However, it is not straight-forward how nominal variables can be\nincluded. In particular, a one-hot-encoding is unsatisfactory because genetic\nprogramming tends to remove such indicator variables. We have therefore used\nso-called factor variables for representing nominal variables in symbolic\nregression models. Our results show that GP is able to produce symbolic\nregression models for predicting friction performance with predictive accuracy\nthat is comparable to artificial neural networks. The symbolic regression\nmodels with factor variables are less complex than models using a one-hot\nencoding.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:10:27 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kronberger", "Gabriel", ""], ["Kommenda", "Michael", ""], ["Promberger", "Andreas", ""], ["Nickel", "Falk", ""]]}, {"id": "2107.09502", "submitter": "Hui Liu", "authors": "Hui Liu, Bo Zhao, Yuefeng Peng, Jiabao Guo, and Peng Liu", "title": "Feature-Filter: Detecting Adversarial Examples through Filtering off\n  Recessive Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are under threat from adversarial example\nattacks. The adversary can easily change the outputs of DNNs by adding small\nwell-designed perturbations to inputs. Adversarial example detection is a\nfundamental work for robust DNNs-based service. Adversarial examples show the\ndifference between humans and DNNs in image recognition. From a human-centric\nperspective, image features could be divided into dominant features that are\ncomprehensible to humans, and recessive features that are incomprehensible to\nhumans, yet are exploited by DNNs. In this paper, we reveal that imperceptible\nadversarial examples are the product of recessive features misleading neural\nnetworks, and an adversarial attack is essentially a kind of method to enrich\nthese recessive features in the image. The imperceptibility of the adversarial\nexamples indicates that the perturbations enrich recessive features, yet hardly\naffect dominant features. Therefore, adversarial examples are sensitive to\nfiltering off recessive features, while benign examples are immune to such\noperation. Inspired by this idea, we propose a label-only adversarial detection\napproach that is referred to as feature-filter. Feature-filter utilizes\ndiscrete cosine transform to approximately separate recessive features from\ndominant features, and gets a mutant image that is filtered off recessive\nfeatures. By only comparing DNN's prediction labels on the input and its\nmutant, feature-filter can real-time detect imperceptible adversarial examples\nat high accuracy and few false positives.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:09:44 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Liu", "Hui", ""], ["Zhao", "Bo", ""], ["Peng", "Yuefeng", ""], ["Guo", "Jiabao", ""], ["Liu", "Peng", ""]]}, {"id": "2107.09507", "submitter": "Jian Cui", "authors": "Jian Cui, Yisi Liu, Zirui Lan, Olga Sourina, Wolfgang M\\\"uller-Wittig", "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with Interpretable\n  CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the context of electroencephalogram (EEG)-based driver drowsiness\nrecognition, it is still a challenging task to design a calibration-free\nsystem, since there exists a significant variability of EEG signals among\ndifferent subjects and recording sessions. As deep learning has received much\nresearch attention in recent years, many efforts have been made to use deep\nlearning methods for EEG signal recognition. However, existing works mostly\ntreat deep learning models as blackbox classifiers, while what have been\nlearned by the models and to which extent they are affected by the noise from\nEEG data are still underexplored. In this paper, we develop a novel\nconvolutional neural network that can explain its decision by highlighting the\nlocal areas of the input sample that contain important information for the\nclassification. The network has a compact structure for ease of interpretation\nand takes advantage of separable convolutions to process the EEG signals in a\nspatial-temporal sequence. Results show that the model achieves an average\naccuracy of 78.35% on 11 subjects for leave-one-out cross-subject drowsiness\nrecognition, which is higher than the conventional baseline methods of\n53.4%-72.68% and state-of-art deep learning methods of 63.90%-65.61%.\nVisualization results show that the model has learned to recognize biologically\nexplainable features from EEG signals, e.g., Alpha spindles, as strong\nindicators of drowsiness across different subjects. In addition, we also\nexplore reasons behind some wrongly classified samples and how the model is\naffected by artifacts and noise in the data. Our work illustrates a promising\ndirection on using interpretable deep learning models to discover meaning\npatterns related to different mental states from complex EEG signals.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:47:20 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cui", "Jian", ""], ["Liu", "Yisi", ""], ["Lan", "Zirui", ""], ["Sourina", "Olga", ""], ["M\u00fcller-Wittig", "Wolfgang", ""]]}, {"id": "2107.09509", "submitter": "Himanshu Thapliyal", "authors": "Rajdeep Kumar Nath and Himanshu Thapliyal", "title": "Wearable Health Monitoring System for Older Adults in a Smart Home\n  Environment", "comments": "6 Pages, 2021 IEEE Computer Society Annual Symposium on VLSI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of IoT has enabled the design of connected and integrated smart\nhealth monitoring systems. These smart health monitoring systems could be\nrealized in a smart home context to render long-term care to the elderly\npopulation. In this paper, we present the design of a wearable health\nmonitoring system suitable for older adults in a smart home context. The\nproposed system offers solutions to monitor the stress, blood pressure, and\nlocation of an individual within a smart home environment. The stress detection\nmodel proposed in this work uses Electrodermal Activity (EDA),\nPhotoplethysmogram (PPG), and Skin Temperature (ST) sensors embedded in a smart\nwristband for detecting physiological stress. The stress detection model is\ntrained and tested using stress labels obtained from salivary cortisol which is\na clinically established biomarker for physiological stress. A voice-based\nprototype is also implemented and the feasibility of the proposed system for\nintegration in a smart home environment is analyzed by simulating a data\nacquisition and streaming scenario. We have also proposed a blood pressure\nestimation model using PPG signal and advanced regression techniques for\nintegration with the stress detection model in the wearable health monitoring\nsystem. Finally, the design of a voice-assisted indoor location system is\nproposed for integration with the proposed system within a smart home\nenvironment. The proposed wearable health monitoring system is an important\ndirection to realize a smart home environment with extensive diagnostic\ncapabilities so that such a system could be useful for rendering long-term and\npersonalized care to the aging population in the comfort of their home.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 03:16:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Nath", "Rajdeep Kumar", ""], ["Thapliyal", "Himanshu", ""]]}, {"id": "2107.09510", "submitter": "Han Yu", "authors": "Han Yu, Thomas Vaessen, Inez Myin-Germeys, Akane Sano", "title": "Modality Fusion Network and Personalized Attention in Momentary Stress\n  Detection in the Wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal wearable physiological data in daily life have been used to\nestimate self-reported stress labels. However, missing data modalities in data\ncollection makes it challenging to leverage all the collected samples. Besides,\nheterogeneous sensor data and labels among individuals add challenges in\nbuilding robust stress detection models. In this paper, we proposed a modality\nfusion network (MFN) to train models and infer self-reported binary stress\nlabels under both complete and incomplete modality conditions. In addition, we\napplied personalized attention (PA) strategy to leverage personalized\nrepresentation along with the generalized one-size-fits-all model. We evaluated\nour methods on a multimodal wearable sensor dataset (N=41) including galvanic\nskin response (GSR) and electrocardiogram (ECG). Compared to the baseline\nmethod using the samples with complete modalities, the performance of the MFN\nimproved by 1.6% in f1-scores. On the other hand, the proposed PA strategy\nshowed a 2.3% higher stress detection f1-score and approximately up to 70%\nreduction in personalized model parameter size (9.1 MB) compared to the\nprevious state-of-the-art transfer learning strategy (29.3 MB).\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 07:54:33 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 07:03:27 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Yu", "Han", ""], ["Vaessen", "Thomas", ""], ["Myin-Germeys", "Inez", ""], ["Sano", "Akane", ""]]}, {"id": "2107.09518", "submitter": "Zehong Lin", "authors": "Zehong Lin, Hang Liu, Ying-Jun Angela Zhang", "title": "Relay-Assisted Cooperative Federated Learning", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has recently emerged as a promising technology to\nenable artificial intelligence (AI) at the network edge, where distributed\nmobile devices collaboratively train a shared AI model under the coordination\nof an edge server. To significantly improve the communication efficiency of FL,\nover-the-air computation allows a large number of mobile devices to\nconcurrently upload their local models by exploiting the superposition property\nof wireless multi-access channels. Due to wireless channel fading, the model\naggregation error at the edge server is dominated by the weakest channel among\nall devices, causing severe straggler issues. In this paper, we propose a\nrelay-assisted cooperative FL scheme to effectively address the straggler\nissue. In particular, we deploy multiple half-duplex relays to cooperatively\nassist the devices in uploading the local model updates to the edge server. The\nnature of the over-the-air computation poses system objectives and constraints\nthat are distinct from those in traditional relay communication systems.\nMoreover, the strong coupling between the design variables renders the\noptimization of such a system challenging. To tackle the issue, we propose an\nalternating-optimization-based algorithm to optimize the transceiver and relay\noperation with low complexity. Then, we analyze the model aggregation error in\na single-relay case and show that our relay-assisted scheme achieves a smaller\nerror than the one without relays provided that the relay transmit power and\nthe relay channel gains are sufficiently large. The analysis provides critical\ninsights on relay deployment in the implementation of cooperative FL. Extensive\nnumerical results show that our design achieves faster convergence compared\nwith state-of-the-art schemes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:06:19 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Lin", "Zehong", ""], ["Liu", "Hang", ""], ["Zhang", "Ying-Jun Angela", ""]]}, {"id": "2107.09519", "submitter": "Gaetan Frusque Dr.", "authors": "Frusque Gaetan, Michau Gabriel and Fink Olga", "title": "Canonical Polyadic Decomposition and Deep Learning for Machine Fault\n  Detection", "comments": "9 pages, 5 figures, conference paper from PHM Society European\n  Conference 2021 (Vol. 6, No. 1)", "journal-ref": "In PHM Society European Conference (Vol. 6, No. 1, pp. 9-9) 2021,\n  June", "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic monitoring for machine fault detection is a recent and expanding\nresearch path that has already provided promising results for industries.\nHowever, it is impossible to collect enough data to learn all types of faults\nfrom a machine. Thus, new algorithms, trained using data from healthy\nconditions only, were developed to perform unsupervised anomaly detection. A\nkey issue in the development of these algorithms is the noise in the signals,\nas it impacts the anomaly detection performance. In this work, we propose a\npowerful data-driven and quasi non-parametric denoising strategy for spectral\ndata based on a tensor decomposition: the Non-negative Canonical Polyadic (CP)\ndecomposition. This method is particularly adapted for machine emitting\nstationary sound. We demonstrate in a case study, the Malfunctioning Industrial\nMachine Investigation and Inspection (MIMII) baseline, how the use of our\ndenoising strategy leads to a sensible improvement of the unsupervised anomaly\ndetection. Such approaches are capable to make sound-based monitoring of\nindustrial processes more reliable.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:06:50 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gaetan", "Frusque", ""], ["Gabriel", "Michau", ""], ["Olga", "Fink", ""]]}, {"id": "2107.09539", "submitter": "Shanel Gauthier", "authors": "Shanel Gauthier, Benjamin Th\\'erien, Laurent Als\\`ene-Racicot, Irina\n  Rish, Eugene Belilovsky, Michael Eickenberg and Guy Wolf", "title": "Parametric Scattering Networks", "comments": "6 pages, 4 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wavelet scattering transform creates geometric invariants and deformation\nstability from an initial structured signal. In multiple signal domains it has\nbeen shown to yield more discriminative representations compared to other\nnon-learned representations, and to outperform learned representations in\ncertain tasks, particularly on limited labeled data and highly structured\nsignals. The wavelet filters used in the scattering transform are typically\nselected to create a tight frame via a parameterized mother wavelet. Focusing\non Morlet wavelets, we propose to instead adapt the scales, orientations, and\nslants of the filters to produce problem-specific parametrizations of the\nscattering transform. We show that our learned versions of the scattering\ntransform yield significant performance gains over the standard scattering\ntransform in the small sample classification settings, and our empirical\nresults suggest that tight frames may not always be necessary for scattering\ntransforms to extract effective representations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:52:48 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gauthier", "Shanel", ""], ["Th\u00e9rien", "Benjamin", ""], ["Als\u00e8ne-Racicot", "Laurent", ""], ["Rish", "Irina", ""], ["Belilovsky", "Eugene", ""], ["Eickenberg", "Michael", ""], ["Wolf", "Guy", ""]]}, {"id": "2107.09542", "submitter": "Steve Hanneke", "authors": "Steve Hanneke", "title": "Open Problem: Is There an Online Learning Algorithm That Learns Whenever\n  Online Learning Is Possible?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This open problem asks whether there exists an online learning algorithm for\nbinary classification that guarantees, for all target concepts, to make a\nsublinear number of mistakes, under only the assumption that the (possibly\nrandom) sequence of points X allows that such a learning algorithm can exist\nfor that sequence. As a secondary problem, it also asks whether a specific\nconcise condition completely determines whether a given (possibly random)\nsequence of points X admits the existence of online learning algorithms\nguaranteeing a sublinear number of mistakes for all target concepts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:57:37 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hanneke", "Steve", ""]]}, {"id": "2107.09543", "submitter": "Richard Osuala", "authors": "Richard Osuala, Kaisar Kushibar, Lidia Garrucho, Akis Linardos,\n  Zuzanna Szafranowska, Stefan Klein, Ben Glocker, Oliver Diaz, Karim Lekadir", "title": "A Review of Generative Adversarial Networks in Cancer Imaging: New\n  Applications, New Solutions", "comments": "64 pages, v1, preprint submitted to Elsevier, Oliver Diaz and Karim\n  Lekadir contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite technological and medical advances, the detection, interpretation,\nand treatment of cancer based on imaging data continue to pose significant\nchallenges. These include high inter-observer variability, difficulty of\nsmall-sized lesion detection, nodule interpretation and malignancy\ndetermination, inter- and intra-tumour heterogeneity, class imbalance,\nsegmentation inaccuracies, and treatment effect uncertainty. The recent\nadvancements in Generative Adversarial Networks (GANs) in computer vision as\nwell as in medical imaging may provide a basis for enhanced capabilities in\ncancer detection and analysis. In this review, we assess the potential of GANs\nto address a number of key challenges of cancer imaging, including data\nscarcity and imbalance, domain and dataset shifts, data access and privacy,\ndata annotation and quantification, as well as cancer detection, tumour\nprofiling and treatment planning. We provide a critical appraisal of the\nexisting literature of GANs applied to cancer imagery, together with\nsuggestions on future research directions to address these challenges. We\nanalyse and discuss 163 papers that apply adversarial training techniques in\nthe context of cancer imaging and elaborate their methodologies, advantages and\nlimitations. With this work, we strive to bridge the gap between the needs of\nthe clinical cancer imaging community and the current and prospective research\non GANs in the artificial intelligence community.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:57:51 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Osuala", "Richard", ""], ["Kushibar", "Kaisar", ""], ["Garrucho", "Lidia", ""], ["Linardos", "Akis", ""], ["Szafranowska", "Zuzanna", ""], ["Klein", "Stefan", ""], ["Glocker", "Ben", ""], ["Diaz", "Oliver", ""], ["Lekadir", "Karim", ""]]}, {"id": "2107.09545", "submitter": "Feng Zhou", "authors": "Jackie Ayoub, Na Du, X. Jessie Yang, Feng Zhou", "title": "Predicting Driver Takeover Time in Conditionally Automated Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is extremely important to ensure a safe takeover transition in\nconditionally automated driving. One of the critical factors that quantifies\nthe safe takeover transition is takeover time. Previous studies identified the\neffects of many factors on takeover time, such as takeover lead time,\nnon-driving tasks, modalities of the takeover requests (TORs), and scenario\nurgency. However, there is a lack of research to predict takeover time by\nconsidering these factors all at the same time. Toward this end, we used\neXtreme Gradient Boosting (XGBoost) to predict the takeover time using a\ndataset from a meta-analysis study [1]. In addition, we used SHAP (SHapley\nAdditive exPlanation) to analyze and explain the effects of the predictors on\ntakeover time. We identified seven most critical predictors that resulted in\nthe best prediction performance. Their main effects and interaction effects on\ntakeover time were examined. The results showed that the proposed approach\nprovided both good performance and explainability. Our findings have\nimplications on the design of in-vehicle monitoring and alert systems to\nfacilitate the interaction between the drivers and the automated vehicle.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:01:49 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ayoub", "Jackie", ""], ["Du", "Na", ""], ["Yang", "X. Jessie", ""], ["Zhou", "Feng", ""]]}, {"id": "2107.09546", "submitter": "Eike Petersen", "authors": "Eike Petersen, Yannik Potdevin, Esfandiar Mohammadi, Stephan Zidowitz,\n  Sabrina Breyer, Dirk Nowotka, Sandra Henn, Ludwig Pechmann, Martin Leucker,\n  Philipp Rostalski and Christian Herzog", "title": "Responsible and Regulatory Conform Machine Learning for Medicine: A\n  Survey of Technical Challenges and Solutions", "comments": "Preprint submitted to Artificial Intelligence in Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning is expected to fuel significant improvements in medical\ncare. To ensure that fundamental principles such as beneficence, respect for\nhuman autonomy, prevention of harm, justice, privacy, and transparency are\nrespected, medical machine learning applications must be developed responsibly.\nIn this paper, we survey the technical challenges involved in creating medical\nmachine learning systems responsibly and in conformity with existing\nregulations, as well as possible solutions to address these challenges. We\nbegin by providing a brief overview of existing regulations affecting medical\nmachine learning, showing that properties such as safety, robustness,\nreliability, privacy, security, transparency, explainability, and\nnondiscrimination are all demanded already by existing law and regulations -\nalbeit, in many cases, to an uncertain degree. Next, we discuss the underlying\ntechnical challenges, possible ways for addressing them, and their respective\nmerits and drawbacks. We notice that distribution shift, spurious correlations,\nmodel underspecification, and data scarcity represent severe challenges in the\nmedical context (and others) that are very difficult to solve with classical\nblack-box deep neural networks. Important measures that may help to address\nthese challenges include the use of large and representative datasets and\nfederated learning as a means to that end, the careful exploitation of domain\nknowledge wherever feasible, the use of inherently transparent models,\ncomprehensive model testing and verification, as well as stakeholder inclusion.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:03:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Petersen", "Eike", ""], ["Potdevin", "Yannik", ""], ["Mohammadi", "Esfandiar", ""], ["Zidowitz", "Stephan", ""], ["Breyer", "Sabrina", ""], ["Nowotka", "Dirk", ""], ["Henn", "Sandra", ""], ["Pechmann", "Ludwig", ""], ["Leucker", "Martin", ""], ["Rostalski", "Philipp", ""], ["Herzog", "Christian", ""]]}, {"id": "2107.09554", "submitter": "Nicolas Tempelmeier", "authors": "Nicolas Tempelmeier, Udo Feuerhake, Oskar Wage, Elena Demidova", "title": "Mining Topological Dependencies of Recurrent Congestion in Road Networks", "comments": null, "journal-ref": "ISPRS International Journal of Geo-Information 2021, 10(4)", "doi": "10.3390/ijgi10040248", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The discovery of spatio-temporal dependencies within urban road networks that\ncause Recurrent Congestion (RC) patterns is crucial for numerous real-world\napplications, including urban planning and scheduling of public transportation\nservices. While most existing studies investigate temporal patterns of RC\nphenomena, the influence of the road network topology on RC is often\noverlooked. This article proposes the ST-Discovery algorithm, a novel\nunsupervised spatio-temporal data mining algorithm that facilitates the\neffective data-driven discovery of RC dependencies induced by the road network\ntopology using real-world traffic data. We factor out regularly reoccurring\ntraffic phenomena, such as rush hours, mainly induced by the daytime, by\nmodelling and systematically exploiting temporal traffic load outliers. We\npresent an algorithm that first constructs connected subgraphs of the road\nnetwork based on the traffic speed outliers. Second, the algorithm identifies\npairs of subgraphs that indicate spatio-temporal correlations in their traffic\nload behaviour to identify topological dependencies within the road network.\nFinally, we rank the identified subgraph pairs based on the dependency score\ndetermined by our algorithm. Our experimental results demonstrate that\nST-Discovery can effectively reveal topological dependencies in urban road\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:14:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tempelmeier", "Nicolas", ""], ["Feuerhake", "Udo", ""], ["Wage", "Oskar", ""], ["Demidova", "Elena", ""]]}, {"id": "2107.09562", "submitter": "Timo Milbich", "authors": "Timo Milbich, Karsten Roth, Samarth Sinha, Ludwig Schmidt, Marzyeh\n  Ghassemi, Bj\\\"orn Ommer", "title": "Characterizing Generalization under Out-Of-Distribution Shifts in Deep\n  Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Metric Learning (DML) aims to find representations suitable for\nzero-shot transfer to a priori unknown test distributions. However, common\nevaluation protocols only test a single, fixed data split in which train and\ntest classes are assigned randomly. More realistic evaluations should consider\na broad spectrum of distribution shifts with potentially varying degree and\ndifficulty. In this work, we systematically construct train-test splits of\nincreasing difficulty and present the ooDML benchmark to characterize\ngeneralization under out-of-distribution shifts in DML. ooDML is designed to\nprobe the generalization performance on much more challenging, diverse\ntrain-to-test distribution shifts. Based on our new benchmark, we conduct a\nthorough empirical analysis of state-of-the-art DML methods. We find that while\ngeneralization tends to consistently degrade with difficulty, some methods are\nbetter at retaining performance as the distribution shift increases. Finally,\nwe propose few-shot DML as an efficient way to consistently improve\ngeneralization in response to unknown test shifts presented in ooDML. Code\navailable here:\nhttps://github.com/Confusezius/Characterizing_Generalization_in_DeepMetricLearning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:26:09 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Milbich", "Timo", ""], ["Roth", "Karsten", ""], ["Sinha", "Samarth", ""], ["Schmidt", "Ludwig", ""], ["Ghassemi", "Marzyeh", ""], ["Ommer", "Bj\u00f6rn", ""]]}, {"id": "2107.09572", "submitter": "Liad Erez", "authors": "Liad Erez, Tomer Koren", "title": "Best-of-All-Worlds Bounds for Online Learning with Feedback Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the online learning with feedback graphs framework introduced by\nMannor and Shamir (2011), in which the feedback received by the online learner\nis specified by a graph $G$ over the available actions. We develop an algorithm\nthat simultaneously achieves regret bounds of the form:\n$\\smash{\\mathcal{O}(\\sqrt{\\theta(G) T})}$ with adversarial losses;\n$\\mathcal{O}(\\theta(G)\\operatorname{polylog}{T})$ with stochastic losses; and\n$\\mathcal{O}(\\theta(G)\\operatorname{polylog}{T} + \\smash{\\sqrt{\\theta(G) C})}$\nwith stochastic losses subject to $C$ adversarial corruptions. Here,\n$\\theta(G)$ is the clique covering number of the graph $G$. Our algorithm is an\ninstantiation of Follow-the-Regularized-Leader with a novel regularization that\ncan be seen as a product of a Tsallis entropy component (inspired by Zimmert\nand Seldin (2019)) and a Shannon entropy component (analyzed in the corrupted\nstochastic case by Amir et al. (2020)), thus subtly interpolating between the\ntwo forms of entropies. One of our key technical contributions is in\nestablishing the convexity of this regularizer and controlling its inverse\nHessian, despite its complex product structure.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:39:42 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Erez", "Liad", ""], ["Koren", "Tomer", ""]]}, {"id": "2107.09577", "submitter": "Thanh Tung Vu", "authors": "Tung T. Vu, Hien Quoc Ngo, Thomas L. Marzetta, Michail Matthaiou", "title": "How Does Cell-Free Massive MIMO Support Multiple Federated Learning\n  Groups?", "comments": "Accepted to appear in Proc. IEEE International Workshop on Signal\n  Processing Advances in Wireless Communications (SPAWC) in Lucca, Italy, Sep.\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has been considered as a promising learning framework\nfor future machine learning systems due to its privacy preservation and\ncommunication efficiency. In beyond-5G/6G systems, it is likely to have\nmultiple FL groups with different learning purposes. This scenario leads to a\nquestion: How does a wireless network support multiple FL groups? As an answer,\nwe first propose to use a cell-free massive multiple-input multiple-output\n(MIMO) network to guarantee the stable operation of multiple FL processes by\nletting the iterations of these FL processes be executed together within a\nlarge-scale coherence time. We then develop a novel scheme that asynchronously\nexecutes the iterations of FL processes under multicasting downlink and\nconventional uplink transmission protocols. Finally, we propose a\nsimple/low-complexity resource allocation algorithm which optimally chooses the\npower and computation resources to minimize the execution time of each\niteration of each FL process.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:46:53 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Vu", "Tung T.", ""], ["Ngo", "Hien Quoc", ""], ["Marzetta", "Thomas L.", ""], ["Matthaiou", "Michail", ""]]}, {"id": "2107.09597", "submitter": "Satoshi Hayakawa", "authors": "Satoshi Hayakawa, Harald Oberhauser, Terry Lyons", "title": "Positively Weighted Kernel Quadrature via Subsampling", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study kernel quadrature rules with positive weights for probability\nmeasures on general domains. Our theoretical analysis combines the spectral\nproperties of the kernel with random sampling of points. This results in\neffective algorithms to construct kernel quadrature rules with positive weights\nand small worst-case error. Besides additional robustness, our numerical\nexperiments indicate that this can achieve fast convergence rates that compete\nwith the optimal bounds in well-known examples.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:18:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Hayakawa", "Satoshi", ""], ["Oberhauser", "Harald", ""], ["Lyons", "Terry", ""]]}, {"id": "2107.09598", "submitter": "Tim Franzmeyer", "authors": "Tim Franzmeyer, Mateusz Malinowski and Jo\\~ao F. Henriques", "title": "Learning Altruistic Behaviours in Reinforcement Learning without\n  External Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can artificial agents learn to assist others in achieving their goals without\nknowing what those goals are? Generic reinforcement learning agents could be\ntrained to behave altruistically towards others by rewarding them for\naltruistic behaviour, i.e., rewarding them for benefiting other agents in a\ngiven situation. Such an approach assumes that other agents' goals are known so\nthat the altruistic agent can cooperate in achieving those goals. However,\nexplicit knowledge of other agents' goals is often difficult to acquire. Even\nassuming such knowledge to be given, training of altruistic agents would\nrequire manually-tuned external rewards for each new environment. Thus, it is\nbeneficial to develop agents that do not depend on external supervision and can\nlearn altruistic behaviour in a task-agnostic manner. Assuming that other\nagents rationally pursue their goals, we hypothesize that giving them more\nchoices will allow them to pursue those goals better. Some concrete examples\ninclude opening a door for others or safeguarding them to pursue their\nobjectives without interference. We formalize this concept and propose an\naltruistic agent that learns to increase the choices another agent has by\nmaximizing the number of states that the other agent can reach in its future.\nWe evaluate our approach on three different multi-agent environments where\nanother agent's success depends on the altruistic agent's behaviour. Finally,\nwe show that our unsupervised agents can perform comparably to agents\nexplicitly trained to work cooperatively. In some cases, our agents can even\noutperform the supervised ones.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:19:39 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 06:43:03 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Franzmeyer", "Tim", ""], ["Malinowski", "Mateusz", ""], ["Henriques", "Jo\u00e3o F.", ""]]}, {"id": "2107.09602", "submitter": "Prajoy Podder", "authors": "Subrato Bharati, Prajoy Podder, M. Rubaiyat Hossain Mondal, V.B. Surya\n  Prasath", "title": "Medical Imaging with Deep Learning for COVID- 19 Diagnosis: A\n  Comprehensive Review", "comments": "22 pages, 11 Figures", "journal-ref": "International Journal of Computer Information Systems and\n  Industrial Management Applications(ISSN 2150-7988), Volume 13, 2021", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The outbreak of novel coronavirus disease (COVID- 19) has claimed millions of\nlives and has affected all aspects of human life. This paper focuses on the\napplication of deep learning (DL) models to medical imaging and drug discovery\nfor managing COVID-19 disease. In this article, we detail various medical\nimaging-based studies such as X-rays and computed tomography (CT) images along\nwith DL methods for classifying COVID-19 affected versus pneumonia. The\napplications of DL techniques to medical images are further described in terms\nof image localization, segmentation, registration, and classification leading\nto COVID-19 detection. The reviews of recent papers indicate that the highest\nclassification accuracy of 99.80% is obtained when InstaCovNet-19 DL method is\napplied to an X-ray dataset of 361 COVID-19 patients, 362 pneumonia patients\nand 365 normal people. Furthermore, it can be seen that the best classification\naccuracy of 99.054% can be achieved when EDL_COVID DL method is applied to a CT\nimage dataset of 7500 samples where COVID-19 patients, lung tumor patients and\nnormal people are equal in number. Moreover, we illustrate the potential DL\ntechniques in drug or vaccine discovery in combating the coronavirus. Finally,\nwe address a number of problems, concerns and future research directions\nrelevant to DL applications for COVID-19.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:49:49 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Bharati", "Subrato", ""], ["Podder", "Prajoy", ""], ["Mondal", "M. Rubaiyat Hossain", ""], ["Prasath", "V. B. Surya", ""]]}, {"id": "2107.09621", "submitter": "Guoliang Li", "authors": "Guoliang Li, Shuai Wang, Jie Li, Rui Wang, Fan Liu, Meihong Zhang,\n  Xiaohui Peng, and Tony Xiao Han", "title": "Rethinking the Tradeoff in Integrated Sensing and Communication:\n  Recognition Accuracy versus Communication Rate", "comments": "arXiv admin note: text overlap with arXiv:2104.10378", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated sensing and communication (ISAC) is a promising technology to\nimprove the band-utilization efficiency via spectrum sharing or hardware\nsharing between radar and communication systems. Since a common radio resource\nbudget is shared by both functionalities, there exists a tradeoff between the\nsensing and communication performance. However, this tradeoff curve is\ncurrently unknown in ISAC systems with human motion recognition tasks based on\ndeep learning. To fill this gap, this paper formulates and solves a\nmulti-objective optimization problem which simultaneously maximizes the\nrecognition accuracy and the communication data rate. The key ingredient of\nthis new formulation is a nonlinear recognition accuracy model with respect to\nthe wireless resources, where the model is derived from power function\nregression of the system performance of the deep spectrogram network. To avoid\ncost-expensive data collection procedures, a primitive-based autoregressive\nhybrid (PBAH) channel model is developed, which facilitates efficient training\nand testing dataset generation for human motion recognition in a virtual\nenvironment. Extensive results demonstrate that the proposed wireless\nrecognition accuracy and PBAH channel models match the actual experimental data\nvery well. Moreover, it is found that the accuracy-rate region consists of a\ncommunication saturation zone, a sensing saturation zone, and a\ncommunication-sensing adversarial zone, of which the third zone achieves the\ndesirable balanced performance for ISAC systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:00:35 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Li", "Guoliang", ""], ["Wang", "Shuai", ""], ["Li", "Jie", ""], ["Wang", "Rui", ""], ["Liu", "Fan", ""], ["Zhang", "Meihong", ""], ["Peng", "Xiaohui", ""], ["Han", "Tony Xiao", ""]]}, {"id": "2107.09627", "submitter": "Jonatan Reyes", "authors": "Jonatan Reyes, Lisa Di Jorio, Cecile Low-Kam and Marta Kersten-Oertel", "title": "Precision-Weighted Federated Learning", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated Learning using the Federated Averaging algorithm has shown great\nadvantages for large-scale applications that rely on collaborative learning,\nespecially when the training data is either unbalanced or inaccessible due to\nprivacy constraints. We hypothesize that Federated Averaging underestimates the\nfull extent of heterogeneity of data when the aggregation is performed. We\npropose Precision-weighted Federated Learning a novel algorithm that takes into\naccount the variance of the stochastic gradients when computing the weighted\naverage of the parameters of models trained in a Federated Learning setting.\nWith Precision-weighted Federated Learning, we provide an alternate averaging\nscheme that leverages the heterogeneity of the data when it has a large\ndiversity of features in its composition. Our method was evaluated using\nstandard image classification datasets with two different data partitioning\nstrategies (IID/non-IID) to measure the performance and speed of our method in\nresource-constrained environments, such as mobile and IoT devices. We obtained\na good balance between computational efficiency and convergence rates with\nPrecision-weighted Federated Learning. Our performance evaluations show 9%\nbetter predictions with MNIST, 18% with Fashion-MNIST, and 5% with CIFAR-10 in\nthe non-IID setting. Further reliability evaluations ratify the stability in\nour method by reaching a 99% reliability index with IID partitions and 96% with\nnon-IID partitions. In addition, we obtained a 20x speedup on Fashion-MNIST\nwith only 10 clients and up to 37x with 100 clients participating in the\naggregation concurrently per communication round. The results indicate that\nPrecision-weighted Federated Learning is an effective and faster alternative\napproach for aggregating private data, especially in domains where data is\nhighly heterogeneous.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:17:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Reyes", "Jonatan", ""], ["Di Jorio", "Lisa", ""], ["Low-Kam", "Cecile", ""], ["Kersten-Oertel", "Marta", ""]]}, {"id": "2107.09640", "submitter": "Michael Caballero", "authors": "Michael Caballero", "title": "Predicting the 2020 US Presidential Election with Twitter", "comments": null, "journal-ref": "2nd International Conference on Soft Computing, Artificial\n  Intelligence and Machine Learning, 2021, pp. 53-65", "doi": "10.5121/csit.2021.111006", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One major sub-domain in the subject of polling public opinion with social\nmedia data is electoral prediction. Electoral prediction utilizing social media\ndata potentially would significantly affect campaign strategies, complementing\ntraditional polling methods and providing cheaper polling in real-time. First,\nthis paper explores past successful methods from research for analysis and\nprediction of the 2020 US Presidential Election using Twitter data. Then, this\nresearch proposes a new method for electoral prediction which combines\nsentiment, from NLP on the text of tweets, and structural data with aggregate\npolling, a time series analysis, and a special focus on Twitter users critical\nto the election. Though this method performed worse than its baseline of\npolling predictions, it is inconclusive whether this is an accurate method for\npredicting elections due to scarcity of data. More research and more data are\nneeded to accurately measure this method's overall effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:59:25 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Caballero", "Michael", ""]]}, {"id": "2107.09645", "submitter": "Denis Yarats", "authors": "Denis Yarats, Rob Fergus, Alessandro Lazaric, Lerrel Pinto", "title": "Mastering Visual Continuous Control: Improved Data-Augmented\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DrQ-v2, a model-free reinforcement learning (RL) algorithm for\nvisual continuous control. DrQ-v2 builds on DrQ, an off-policy actor-critic\napproach that uses data augmentation to learn directly from pixels. We\nintroduce several improvements that yield state-of-the-art results on the\nDeepMind Control Suite. Notably, DrQ-v2 is able to solve complex humanoid\nlocomotion tasks directly from pixel observations, previously unattained by\nmodel-free RL. DrQ-v2 is conceptually simple, easy to implement, and provides\nsignificantly better computational footprint compared to prior work, with the\nmajority of tasks taking just 8 hours to train on a single GPU. Finally, we\npublicly release DrQ-v2's implementation to provide RL practitioners with a\nstrong and computationally efficient baseline.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:29:13 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Yarats", "Denis", ""], ["Fergus", "Rob", ""], ["Lazaric", "Alessandro", ""], ["Pinto", "Lerrel", ""]]}, {"id": "2107.09647", "submitter": "Jana Mayer", "authors": "Jana Mayer, Johannes Westermann, Juan Pedro Guti\\'errez H. Muriedas,\n  Uwe Mettin, Alexander Lampe", "title": "Proximal Policy Optimization for Tracking Control Exploiting Future\n  Reference Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, reinforcement learning (RL) has gained increasing attention\nin control engineering. Especially, policy gradient methods are widely used. In\nthis work, we improve the tracking performance of proximal policy optimization\n(PPO) for arbitrary reference signals by incorporating information about future\nreference values. Two variants of extending the argument of the actor and the\ncritic taking future reference values into account are presented. In the first\nvariant, global future reference values are added to the argument. For the\nsecond variant, a novel kind of residual space with future reference values\napplicable to model-free reinforcement learning is introduced. Our approach is\nevaluated against a PI controller on a simple drive train model. We expect our\nmethod to generalize to arbitrary references better than previous approaches,\npointing towards the applicability of RL to control real systems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:32:50 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Mayer", "Jana", ""], ["Westermann", "Johannes", ""], ["Muriedas", "Juan Pedro Guti\u00e9rrez H.", ""], ["Mettin", "Uwe", ""], ["Lampe", "Alexander", ""]]}, {"id": "2107.09648", "submitter": "James Michaelov", "authors": "James A. Michaelov, Megan D. Bardolph, Seana Coulson, Benjamin K.\n  Bergen", "title": "Different kinds of cognitive plausibility: why are transformers better\n  than RNNs at predicting N400 amplitude?", "comments": null, "journal-ref": "Proceedings of the 43rd Annual Meeting of the Cognitive Science\n  Society (2021) 300-306", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite being designed for performance rather than cognitive plausibility,\ntransformer language models have been found to be better at predicting metrics\nused to assess human language comprehension than language models with other\narchitectures, such as recurrent neural networks. Based on how well they\npredict the N400, a neural signal associated with processing difficulty, we\npropose and provide evidence for one possible explanation - their predictions\nare affected by the preceding context in a way analogous to the effect of\nsemantic facilitation in humans.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:33:13 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Michaelov", "James A.", ""], ["Bardolph", "Megan D.", ""], ["Coulson", "Seana", ""], ["Bergen", "Benjamin K.", ""]]}, {"id": "2107.09661", "submitter": "Amil Merchant", "authors": "Amil Merchant, Luke Metz, Sam Schoenholz, Ekin Dogus Cubuk", "title": "Learn2Hop: Learned Optimization on Rough Landscapes", "comments": "ICML 2021, 16 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimization of non-convex loss surfaces containing many local minima remains\na critical problem in a variety of domains, including operations research,\ninformatics, and material design. Yet, current techniques either require\nextremely high iteration counts or a large number of random restarts for good\nperformance. In this work, we propose adapting recent developments in\nmeta-learning to these many-minima problems by learning the optimization\nalgorithm for various loss landscapes. We focus on problems from atomic\nstructural optimization--finding low energy configurations of many-atom\nsystems--including widely studied models such as bimetallic clusters and\ndisordered silicon. We find that our optimizer learns a 'hopping' behavior\nwhich enables efficient exploration and improves the rate of low energy minima\ndiscovery. Finally, our learned optimizers show promising generalization with\nefficiency gains on never before seen tasks (e.g. new elements or\ncompositions). Code will be made available shortly.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 17:57:19 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Merchant", "Amil", ""], ["Metz", "Luke", ""], ["Schoenholz", "Sam", ""], ["Cubuk", "Ekin Dogus", ""]]}, {"id": "2107.09700", "submitter": "Sungmin Hong", "authors": "Sungmin Hong, Razvan Marinescu, Adrian V. Dalca, Anna K. Bonkhoff,\n  Martin Bretzner, Natalia S. Rost, Polina Golland", "title": "3D-StyleGAN: A Style-Based Generative Adversarial Network for Generative\n  Modeling of Three-Dimensional Medical Images", "comments": "11 pages, 6 figures, 2 tables. Provisionally Accepted at DGM4MICCAI\n  workshop in MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Image synthesis via Generative Adversarial Networks (GANs) of\nthree-dimensional (3D) medical images has great potential that can be extended\nto many medical applications, such as, image enhancement and disease\nprogression modeling. However, current GAN technologies for 3D medical image\nsynthesis need to be significantly improved to be readily adapted to real-world\nmedical problems. In this paper, we extend the state-of-the-art StyleGAN2\nmodel, which natively works with two-dimensional images, to enable 3D image\nsynthesis. In addition to the image synthesis, we investigate the\ncontrollability and interpretability of the 3D-StyleGAN via style vectors\ninherited form the original StyleGAN2 that are highly suitable for medical\napplications: (i) the latent space projection and reconstruction of unseen real\nimages, and (ii) style mixing. We demonstrate the 3D-StyleGAN's performance and\nfeasibility with ~12,000 three-dimensional full brain MR T1 images, although it\ncan be applied to any 3D volumetric images. Furthermore, we explore different\nconfigurations of hyperparameters to investigate potential improvement of the\nimage synthesis with larger networks. The codes and pre-trained networks are\navailable online: https://github.com/sh4174/3DStyleGAN.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:08:27 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hong", "Sungmin", ""], ["Marinescu", "Razvan", ""], ["Dalca", "Adrian V.", ""], ["Bonkhoff", "Anna K.", ""], ["Bretzner", "Martin", ""], ["Rost", "Natalia S.", ""], ["Golland", "Polina", ""]]}, {"id": "2107.09716", "submitter": "Daniel Severo", "authors": "Daniel Severo, Elad Domanovitz, Ashish Khisti", "title": "Regularized Classification-Aware Quantization", "comments": "Accepted to the 30th Biennial Symposium on Communications (BSC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, quantization is designed to minimize the reconstruction error\nof a data source. When considering downstream classification tasks, other\nmeasures of distortion can be of interest; such as the 0-1 classification loss.\nFurthermore, it is desirable that the performance of these quantizers not\ndeteriorate once they are deployed into production, as relearning the scheme\nonline is not always possible. In this work, we present a class of algorithms\nthat learn distributed quantization schemes for binary classification tasks.\nOur method performs well on unseen data, and is faster than previous methods\nproportional to a quadratic term of the dataset size. It works by regularizing\nthe 0-1 loss with the reconstruction error. We present experiments on synthetic\nmixture and bivariate Gaussian data and compare training, testing, and\ngeneralization errors with a family of benchmark quantization schemes from the\nliterature. Our method is called Regularized Classification-Aware Quantization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:27:48 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Severo", "Daniel", ""], ["Domanovitz", "Elad", ""], ["Khisti", "Ashish", ""]]}, {"id": "2107.09728", "submitter": "Akum Kang", "authors": "Akum S. Kang, Loveleen C. Kang, Stephen M. Mastorides, Philip R.\n  Foulis, Lauren A. DeLand, Robert P. Seifert, Andrew A. Borkowski", "title": "Machine Learning Approaches to Automated Flow Cytometry Diagnosis of\n  Chronic Lymphocytic Leukemia", "comments": "4 pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flow cytometry is a technique that measures multiple fluorescence and light\nscatter-associated parameters from individual cells as they flow a single file\nthrough an excitation light source. These cells are labeled with antibodies to\ndetect various antigens and the fluorescence signals reflect antigen\nexpression. Interpretation of the multiparameter flow cytometry data is\nlaborious, time-consuming, and expensive. It involves manual interpretation of\ncell distribution and pattern recognition on two-dimensional plots by highly\ntrained medical technologists and pathologists. Using various machine learning\nalgorithms, we attempted to develop an automated analysis for clinical flow\ncytometry cases that would automatically classify normal and chronic\nlymphocytic leukemia cases. We achieved the best success with the Gradient\nBoosting. The XGBoost classifier achieved a specificity of 1.00 and a\nsensitivity of 0.67, a negative predictive value of 0.75, a positive predictive\nvalue of 1.00, and an overall accuracy of 0.83 in prospectively classifying\ncases with malignancies.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:59:05 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 13:51:22 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kang", "Akum S.", ""], ["Kang", "Loveleen C.", ""], ["Mastorides", "Stephen M.", ""], ["Foulis", "Philip R.", ""], ["DeLand", "Lauren A.", ""], ["Seifert", "Robert P.", ""], ["Borkowski", "Andrew A.", ""]]}, {"id": "2107.09729", "submitter": "Uri Shaham", "authors": "Uri Shaham and Omer Levy", "title": "What Do You Get When You Cross Beam Search with Nucleus Sampling?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine beam search with the probabilistic pruning technique of nucleus\nsampling to create two deterministic nucleus search algorithms for natural\nlanguage generation. The first algorithm, p-exact search, locally prunes the\nnext-token distribution and performs an exact search over the remaining space.\nThe second algorithm, dynamic beam search, shrinks and expands the beam size\naccording to the entropy of the candidate's probability distribution. Despite\nthe probabilistic intuition behind nucleus search, experiments on machine\ntranslation and summarization benchmarks show that both algorithms reach the\nsame performance levels as standard beam search.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:59:14 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 11:49:36 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Shaham", "Uri", ""], ["Levy", "Omer", ""]]}, {"id": "2107.09734", "submitter": "Eoin Delaney", "authors": "Eoin Delaney, Derek Greene and Mark T. Keane", "title": "Uncertainty Estimation and Out-of-Distribution Detection for\n  Counterfactual Explanations: Pitfalls and Solutions", "comments": null, "journal-ref": "ICML Workshop on Algorithmic Recourse, July 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst an abundance of techniques have recently been proposed to generate\ncounterfactual explanations for the predictions of opaque black-box systems,\nmarkedly less attention has been paid to exploring the uncertainty of these\ngenerated explanations. This becomes a critical issue in high-stakes scenarios,\nwhere uncertain and misleading explanations could have dire consequences (e.g.,\nmedical diagnosis and treatment planning). Moreover, it is often difficult to\ndetermine if the generated explanations are well grounded in the training data\nand sensitive to distributional shifts. This paper proposes several practical\nsolutions that can be leveraged to solve these problems by establishing novel\nconnections with other research works in explainability (e.g., trust scores)\nand uncertainty estimation (e.g., Monte Carlo Dropout). Two experiments\ndemonstrate the utility of our proposed solutions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 19:09:10 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Delaney", "Eoin", ""], ["Greene", "Derek", ""], ["Keane", "Mark T.", ""]]}, {"id": "2107.09735", "submitter": "Itzik Mizrahi", "authors": "Itzik Mizrahi, Shai Avidan", "title": "kNet: A Deep kNN Network To Handle Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks require large amounts of labeled data for their\ntraining. Collecting this data at scale inevitably causes label noise.Hence,the\nneed to develop learning algorithms that are robust to label noise. In recent\nyears, k Nearest Neighbors (kNN) emerged as a viable solution to this problem.\nDespite its success, kNN is not without its problems. Mainly, it requires a\nhuge memory footprint to store all the training samples and it needs an\nadvanced data structure to allow for fast retrieval of the relevant examples,\ngiven a query sample. We propose a neural network, termed kNet, that learns to\nperform kNN. Once trained, we no longer need to store the training data, and\nprocessing a query sample is a simple matter of inference. To use kNet, we\nfirst train a preliminary network on the data set, and then train kNet on the\npenultimate layer of the preliminary network.We find that kNet gives a smooth\napproximation of kNN,and cannot handle the sharp label changes between samples\nthat kNN can exhibit. This indicates that currently kNet is best suited to\napproximate kNN with a fairly large k. Experiments on two data sets show that\nthis is the regime in which kNN works best,and can therefore be replaced by\nkNet.In practice, kNet consistently improve the results of all preliminary\nnetworks, in all label noise regimes, by up to 3%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 19:12:45 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Mizrahi", "Itzik", ""], ["Avidan", "Shai", ""]]}, {"id": "2107.09766", "submitter": "Taro Sekiyama", "authors": "Takeshi Tsukada and Hiroshi Unno and Taro Sekiyama and Kohei Suenaga", "title": "Enhancing Loop-Invariant Synthesis via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loop-invariant synthesis is the basis of every program verification\nprocedure. Due to its undecidability in general, a tool for invariant synthesis\nnecessarily uses heuristics. Despite the common belief that the design of\nheuristics is vital for the effective performance of a verifier, little work\nhas been performed toward obtaining the optimal heuristics for each\ninvariant-synthesis tool. Instead, developers have hand-tuned the heuristics of\ntools. This study demonstrates that we can effectively and automatically learn\na good heuristic via reinforcement learning for an invariant synthesizer PCSat.\nOur experiment shows that PCSat combined with the heuristic learned by\nreinforcement learning outperforms the state-of-the-art solvers for this task.\nTo the best of our knowledge, this is the first work that investigates learning\nthe heuristics of an invariant synthesis tool.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:17:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Tsukada", "Takeshi", ""], ["Unno", "Hiroshi", ""], ["Sekiyama", "Taro", ""], ["Suenaga", "Kohei", ""]]}, {"id": "2107.09767", "submitter": "Chun Ouyang", "authors": "Chun Ouyang, Renuka Sindhgatta, Catarina Moreira", "title": "Explainable AI Enabled Inspection of Business Process Prediction Models", "comments": "17 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern data analytics underpinned by machine learning techniques has become a\nkey enabler to the automation of data-led decision making. As an important\nbranch of state-of-the-art data analytics, business process predictions are\nalso faced with a challenge in regard to the lack of explanation to the\nreasoning and decision by the underlying `black-box' prediction models. With\nthe development of interpretable machine learning techniques, explanations can\nbe generated for a black-box model, making it possible for (human) users to\naccess the reasoning behind machine learned predictions. In this paper, we aim\nto present an approach that allows us to use model explanations to investigate\ncertain reasoning applied by machine learned predictions and detect potential\nissues with the underlying methods thus enhancing trust in business process\nprediction models. A novel contribution of our approach is the proposal of\nmodel inspection that leverages both the explanations generated by\ninterpretable machine learning mechanisms and the contextual or domain\nknowledge extracted from event logs that record historical process execution.\nFindings drawn from this work are expected to serve as a key input to\ndeveloping model reliability metrics and evaluation in the context of business\nprocess predictions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 06:51:18 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ouyang", "Chun", ""], ["Sindhgatta", "Renuka", ""], ["Moreira", "Catarina", ""]]}, {"id": "2107.09768", "submitter": "Mehdi Ghatee Dr.", "authors": "Sajad Dadgar, Mehdi Ghatee", "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives", "comments": "20 Pages, 18 Figures, 7 Tables, Submitted for Review Process in a\n  Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 20:58:23 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dadgar", "Sajad", ""], ["Ghatee", "Mehdi", ""]]}, {"id": "2107.09770", "submitter": "Michael Dinitz", "authors": "Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, Sergei\n  Vassilvitskii", "title": "Faster Matchings via Learned Duals", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recent line of research investigates how algorithms can be augmented with\nmachine-learned predictions to overcome worst case lower bounds. This area has\nrevealed interesting algorithmic insights into problems, with particular\nsuccess in the design of competitive online algorithms. However, the question\nof improving algorithm running times with predictions has largely been\nunexplored.\n  We take a first step in this direction by combining the idea of\nmachine-learned predictions with the idea of \"warm-starting\" primal-dual\nalgorithms. We consider one of the most important primitives in combinatorial\noptimization: weighted bipartite matching and its generalization to\n$b$-matching. We identify three key challenges when using learned dual\nvariables in a primal-dual algorithm. First, predicted duals may be infeasible,\nso we give an algorithm that efficiently maps predicted infeasible duals to\nnearby feasible solutions. Second, once the duals are feasible, they may not be\noptimal, so we show that they can be used to quickly find an optimal solution.\nFinally, such predictions are useful only if they can be learned, so we show\nthat the problem of learning duals for matching has low sample complexity. We\nvalidate our theoretical findings through experiments on both real and\nsynthetic data. As a result we give a rigorous, practical, and empirically\neffective method to compute bipartite matchings.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 21:11:09 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dinitz", "Michael", ""], ["Im", "Sungjin", ""], ["Lavastida", "Thomas", ""], ["Moseley", "Benjamin", ""], ["Vassilvitskii", "Sergei", ""]]}, {"id": "2107.09773", "submitter": "Vardis Kandiros", "authors": "Yuval Dagan, Constantinos Daskalakis, Nishanth Dikkala, Surbhi Goel,\n  Anthimos Vardis Kandiros", "title": "Statistical Estimation from Dependent Data", "comments": "41 pages, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a general statistical estimation problem wherein binary labels\nacross different observations are not independent conditioned on their feature\nvectors, but dependent, capturing settings where e.g. these observations are\ncollected on a spatial domain, a temporal domain, or a social network, which\ninduce dependencies. We model these dependencies in the language of Markov\nRandom Fields and, importantly, allow these dependencies to be substantial, i.e\ndo not assume that the Markov Random Field capturing these dependencies is in\nhigh temperature. As our main contribution we provide algorithms and\nstatistically efficient estimation rates for this model, giving several\ninstantiations of our bounds in logistic regression, sparse logistic\nregression, and neural network settings with dependent data. Our estimation\nguarantees follow from novel results for estimating the parameters (i.e.\nexternal fields and interaction strengths) of Ising models from a {\\em single}\nsample. {We evaluate our estimation approach on real networked data, showing\nthat it outperforms standard regression approaches that ignore dependencies,\nacross three text classification datasets: Cora, Citeseer and Pubmed.}\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 21:18:06 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dagan", "Yuval", ""], ["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Goel", "Surbhi", ""], ["Kandiros", "Anthimos Vardis", ""]]}, {"id": "2107.09781", "submitter": "Diego H Useche", "authors": "Diego H. Useche, Andres Giraldo-Carvajal, Hernan M. Zuluaga-Bucheli,\n  Jose A. Jaramillo-Villegas, Fabio A. Gonz\\'alez", "title": "Quantum Measurement Classification with Qudits", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a hybrid classical-quantum program for density estimation\nand supervised classification. The program is implemented as a quantum circuit\nin a high-dimensional quantum computer simulator. We show that the proposed\nquantum protocols allow to estimate probability density functions and to make\npredictions in a supervised learning manner. This model can be generalized to\nfind expected values of density matrices in high-dimensional quantum computers.\nExperiments on various data sets are presented. Results show that the proposed\nmethod is a viable strategy to implement supervised classification and density\nestimation in a high-dimensional quantum computer.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 21:54:14 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Useche", "Diego H.", ""], ["Giraldo-Carvajal", "Andres", ""], ["Zuluaga-Bucheli", "Hernan M.", ""], ["Jaramillo-Villegas", "Jose A.", ""], ["Gonz\u00e1lez", "Fabio A.", ""]]}, {"id": "2107.09785", "submitter": "Frederico Gadelha Guimaraes", "authors": "Hugo Vinicius Bitencourt and Frederico Gadelha Guimar\\~aes", "title": "High-dimensional Multivariate Time Series Forecasting in IoT\n  Applications using Embedding Non-stationary Fuzzy Time Series", "comments": "6 pages, 1 figure, submitted to the 7th IEEE LA-CCI (Latin American\n  Conference on Computational Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SP eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In Internet of things (IoT), data is continuously recorded from different\ndata sources and devices can suffer faults in their embedded electronics, thus\nleading to a high-dimensional data sets and concept drift events. Therefore,\nmethods that are capable of high-dimensional non-stationary time series are of\ngreat value in IoT applications. Fuzzy Time Series (FTS) models stand out as\ndata-driven non-parametric models of easy implementation and high accuracy.\nUnfortunately, FTS encounters difficulties when dealing with data sets of many\nvariables and scenarios with concept drift. We present a new approach to handle\nhigh-dimensional non-stationary time series, by projecting the original\nhigh-dimensional data into a low dimensional embedding space and using FTS\napproach. Combining these techniques enables a better representation of the\ncomplex content of non-stationary multivariate time series and accurate\nforecasts. Our model is able to explain 98% of the variance and reach 11.52% of\nRMSE, 2.68% of MAE and 2.91% of MAPE.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 22:00:43 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bitencourt", "Hugo Vinicius", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""]]}, {"id": "2107.09786", "submitter": "Jingtao Li", "authors": "Xing Chen, Jingtao Li and Chaitali Chakrabarti", "title": "Communication and Computation Reduction for Split Learning using\n  Asynchronous Training", "comments": "Accepted by SIPS '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Split learning is a promising privacy-preserving distributed learning scheme\nthat has low computation requirement at the edge device but has the\ndisadvantage of high communication overhead between edge device and server. To\nreduce the communication overhead, this paper proposes a loss-based\nasynchronous training scheme that updates the client-side model less frequently\nand only sends/receives activations/gradients in selected epochs. To further\nreduce the communication overhead, the activations/gradients are quantized\nusing 8-bit floating point prior to transmission. An added benefit of the\nproposed communication reduction method is that the computations at the client\nside are reduced due to reduction in the number of client model updates.\nFurthermore, the privacy of the proposed communication reduction based split\nlearning method is almost the same as traditional split learning. Simulation\nresults on VGG11, VGG13 and ResNet18 models on CIFAR-10 show that the\ncommunication cost is reduced by 1.64x-106.7x and the computations in the\nclient are reduced by 2.86x-32.1x when the accuracy degradation is less than\n0.5% for the single-client case. For 5 and 10-client cases, the communication\ncost reduction is 11.9x and 11.3x on VGG11 for 0.5% loss in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 22:08:13 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Xing", ""], ["Li", "Jingtao", ""], ["Chakrabarti", "Chaitali", ""]]}, {"id": "2107.09787", "submitter": "Xinyi Xu", "authors": "Xinyi Xu, Cheng Deng, Yaochen Xie, Shuiwang Ji", "title": "Group Contrastive Self-Supervised Learning on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study self-supervised learning on graphs using contrastive methods. A\ngeneral scheme of prior methods is to optimize two-view representations of\ninput graphs. In many studies, a single graph-level representation is computed\nas one of the contrastive objectives, capturing limited characteristics of\ngraphs. We argue that contrasting graphs in multiple subspaces enables graph\nencoders to capture more abundant characteristics. To this end, we propose a\ngroup contrastive learning framework in this work. Our framework embeds the\ngiven graph into multiple subspaces, of which each representation is prompted\nto encode specific characteristics of graphs. To learn diverse and informative\nrepresentations, we develop principled objectives that enable us to capture the\nrelations among both intra-space and inter-space representations in groups.\nUnder the proposed framework, we further develop an attention-based representor\nfunction to compute representations that capture different substructures of a\ngiven graph. Built upon our framework, we extend two current methods into\nGroupCL and GroupIG, equipped with the proposed objective. Comprehensive\nexperimental results show our framework achieves a promising boost in\nperformance on a variety of datasets. In addition, our qualitative results show\nthat features generated from our representor successfully capture various\nspecific characteristics of graphs.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 22:09:21 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Xu", "Xinyi", ""], ["Deng", "Cheng", ""], ["Xie", "Yaochen", ""], ["Ji", "Shuiwang", ""]]}, {"id": "2107.09802", "submitter": "Walid Krichene", "authors": "Steve Chien, Prateek Jain, Walid Krichene, Steffen Rendle, Shuang\n  Song, Abhradeep Thakurta, Li Zhang", "title": "Private Alternating Least Squares: Practical Private Matrix Completion\n  with Tighter Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private (DP) matrix completion under\nuser-level privacy. We design a joint differentially private variant of the\npopular Alternating-Least-Squares (ALS) method that achieves: i) (nearly)\noptimal sample complexity for matrix completion (in terms of number of items,\nusers), and ii) the best known privacy/utility trade-off both theoretically, as\nwell as on benchmark data sets. In particular, we provide the first global\nconvergence analysis of ALS with noise introduced to ensure DP, and show that,\nin comparison to the best known alternative (the Private Frank-Wolfe algorithm\nby Jain et al. (2018)), our error bounds scale significantly better with\nrespect to the number of items and users, which is critical in practical\nproblems. Extensive validation on standard benchmarks demonstrate that the\nalgorithm, in combination with carefully designed sampling procedures, is\nsignificantly more accurate than existing techniques, thus promising to be the\nfirst practical DP embedding model.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:19:11 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chien", "Steve", ""], ["Jain", "Prateek", ""], ["Krichene", "Walid", ""], ["Rendle", "Steffen", ""], ["Song", "Shuang", ""], ["Thakurta", "Abhradeep", ""], ["Zhang", "Li", ""]]}, {"id": "2107.09804", "submitter": "Mohammad Samavatian", "authors": "Saikat Majumdar, Mohammad Hossein Samavatian, Kristin Barber, Radu\n  Teodorescu", "title": "Using Undervolting as an On-Device Defense Against Adversarial Machine\n  Learning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural network (DNN) classifiers are powerful tools that drive a broad\nspectrum of important applications, from image recognition to autonomous\nvehicles. Unfortunately, DNNs are known to be vulnerable to adversarial attacks\nthat affect virtually all state-of-the-art models. These attacks make small\nimperceptible modifications to inputs that are sufficient to induce the DNNs to\nproduce the wrong classification.\n  In this paper we propose a novel, lightweight adversarial correction and/or\ndetection mechanism for image classifiers that relies on undervolting (running\na chip at a voltage that is slightly below its safe margin). We propose using\ncontrolled undervolting of the chip running the inference process in order to\nintroduce a limited number of compute errors. We show that these errors disrupt\nthe adversarial input in a way that can be used either to correct the\nclassification or detect the input as adversarial. We evaluate the proposed\nsolution in an FPGA design and through software simulation. We evaluate 10\nattacks on two popular DNNs and show an average detection rate of 80% to 95%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:21:04 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Majumdar", "Saikat", ""], ["Samavatian", "Mohammad Hossein", ""], ["Barber", "Kristin", ""], ["Teodorescu", "Radu", ""]]}, {"id": "2107.09807", "submitter": "Amin Nikanjam", "authors": "Mahnoosh Mahdavimoghaddam, Amin Nikanjam, Monireh Abdoos", "title": "Multi-agent Reinforcement Learning Improvement in a Dynamic Environment\n  Using Knowledge Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative multi-agent systems are being widely used in variety of areas.\nInteraction between agents would bring positive points, including reducing\ncosts of operating, high scalability, and facilitating parallel processing.\nThese systems pave the way for handling large-scale, unknown, and dynamic\nenvironments. However, learning in these environments has become a prominent\nchallenge in different applications. These challenges include the effect of\nsize of search space on learning time, inappropriate cooperation among agents,\nand the lack of proper coordination among agents' decisions. Moreover,\nreinforcement learning algorithms may suffer from long time of convergence in\nthese problems. In this paper, a communication framework using knowledge\ntransfer concepts is introduced to address such challenges in the herding\nproblem with large state space. To handle the problems of convergence,\nknowledge transfer has been utilized that can significantly increase the\nefficiency of reinforcement learning algorithms. Coordination between the\nagents is carried out through a head agent in each group of agents and a\ncoordinator agent respectively. The results demonstrate that this framework\ncould indeed enhance the speed of learning and reduce convergence time.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:42:39 GMT"}, {"version": "v2", "created": "Sun, 25 Jul 2021 14:17:50 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mahdavimoghaddam", "Mahnoosh", ""], ["Nikanjam", "Amin", ""], ["Abdoos", "Monireh", ""]]}, {"id": "2107.09814", "submitter": "Katiana Kontolati", "authors": "Katiana Kontolati, Dimitrios Loukrezis, Ketson R. M. dos Santos,\n  Dimitrios G. Giovanis, Michael D. Shields", "title": "Manifold learning-based polynomial chaos expansions for high-dimensional\n  surrogate models", "comments": "29 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a manifold learning-based method for uncertainty\nquantification (UQ) in systems describing complex spatiotemporal processes. Our\nfirst objective is to identify the embedding of a set of high-dimensional data\nrepresenting quantities of interest of the computational or analytical model.\nFor this purpose, we employ Grassmannian diffusion maps, a two-step nonlinear\ndimension reduction technique which allows us to reduce the dimensionality of\nthe data and identify meaningful geometric descriptions in a parsimonious and\ninexpensive manner. Polynomial chaos expansion is then used to construct a\nmapping between the stochastic input parameters and the diffusion coordinates\nof the reduced space. An adaptive clustering technique is proposed to identify\nan optimal number of clusters of points in the latent space. The similarity of\npoints allows us to construct a number of geometric harmonic emulators which\nare finally utilized as a set of inexpensive pre-trained models to perform an\ninverse map of realizations of latent features to the ambient space and thus\nperform accurate out-of-sample predictions. Thus, the proposed method acts as\nan encoder-decoder system which is able to automatically handle very\nhigh-dimensional data while simultaneously operating successfully in the\nsmall-data regime. The method is demonstrated on two benchmark problems and on\na system of advection-diffusion-reaction equations which model a first-order\nchemical reaction between two species. In all test cases, the proposed method\nis able to achieve highly accurate approximations which ultimately lead to the\nsignificant acceleration of UQ tasks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 00:24:15 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Kontolati", "Katiana", ""], ["Loukrezis", "Dimitrios", ""], ["Santos", "Ketson R. M. dos", ""], ["Giovanis", "Dimitrios G.", ""], ["Shields", "Michael D.", ""]]}, {"id": "2107.09815", "submitter": "Jose-Luis Blanco-Claraco", "authors": "Antonio Leanza, Giulio Reina and Jose-Luis Blanco-Claraco", "title": "A Factor Graph-based approach to vehicle sideslip angle estimation", "comments": "15 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sideslip angle is an important variable for understanding and monitoring\nvehicle dynamics but it lacks an inexpensive method for direct measurement.\nTherefore, it is typically estimated from inertial and other proprioceptive\nsensors onboard using filtering methods from the family of the Kalman Filter.\nAs a novel alternative, this work proposes modelling the problem directly as a\ngraphical model (factor graph), which can then be optimized using a variety of\nmethods, such as whole dataset batch optimization for offline processing or\nfixed-lag smoother for on-line operation. Experimental results on real vehicle\ndatasets validate the proposal with a good agreement between estimated and\nactual sideslip angle, showing similar performance than the state-of-the-art\nwith a great potential for future extensions due to the flexible mathematical\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 00:25:06 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Leanza", "Antonio", ""], ["Reina", "Giulio", ""], ["Blanco-Claraco", "Jose-Luis", ""]]}, {"id": "2107.09817", "submitter": "Xinhao Mei", "authors": "Xinhao Mei, Xubo Liu, Qiushi Huang, Mark D. Plumbley and Wenwu Wang", "title": "Audio Captioning Transformer", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio captioning aims to automatically generate a natural language\ndescription of an audio clip. Most captioning models follow an encoder-decoder\narchitecture, where the decoder predicts words based on the audio features\nextracted by the encoder. Convolutional neural networks (CNNs) and recurrent\nneural networks (RNNs) are often used as the audio encoder. However, CNNs can\nbe limited in modelling temporal relationships among the time frames in an\naudio signal, while RNNs can be limited in modelling the long-range\ndependencies among the time frames. In this paper, we propose an Audio\nCaptioning Transformer (ACT), which is a full Transformer network based on an\nencoder-decoder architecture and is totally convolution-free. The proposed\nmethod has a better ability to model the global information within an audio\nsignal as well as capture temporal relationships between audio events. We\nevaluate our model on AudioCaps, which is the largest audio captioning dataset\npublicly available. Our model shows competitive performance compared to other\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 00:31:50 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Mei", "Xinhao", ""], ["Liu", "Xubo", ""], ["Huang", "Qiushi", ""], ["Plumbley", "Mark D.", ""], ["Wang", "Wenwu", ""]]}, {"id": "2107.09853", "submitter": "Akira Furui D.Eng.", "authors": "Akira Furui, Takuya Igaue, Toshio Tsuji", "title": "EMG Pattern Recognition via Bayesian Inference with Scale Mixture-Based\n  Stochastic Generative Models", "comments": "This paper is accepted for publication in Expert Systems with\n  Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromyogram (EMG) has been utilized to interface signals for prosthetic\nhands and information devices owing to its ability to reflect human motion\nintentions. Although various EMG classification methods have been introduced\ninto EMG-based control systems, they do not fully consider the stochastic\ncharacteristics of EMG signals. This paper proposes an EMG pattern\nclassification method incorporating a scale mixture-based generative model. A\nscale mixture model is a stochastic EMG model in which the EMG variance is\nconsidered as a random variable, enabling the representation of uncertainty in\nthe variance. This model is extended in this study and utilized for EMG pattern\nclassification. The proposed method is trained by variational Bayesian\nlearning, thereby allowing the automatic determination of the model complexity.\nFurthermore, to optimize the hyperparameters of the proposed method with a\npartial discriminative approach, a mutual information-based determination\nmethod is introduced. Simulation and EMG analysis experiments demonstrated the\nrelationship between the hyperparameters and classification accuracy of the\nproposed method as well as the validity of the proposed method. The comparison\nusing public EMG datasets revealed that the proposed method outperformed the\nvarious conventional classifiers. These results indicated the validity of the\nproposed method and its applicability to EMG-based control systems. In EMG\npattern recognition, a classifier based on a generative model that reflects the\nstochastic characteristics of EMG signals can outperform the conventional\ngeneral-purpose classifier.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 02:51:19 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Furui", "Akira", ""], ["Igaue", "Takuya", ""], ["Tsuji", "Toshio", ""]]}, {"id": "2107.09869", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad, Anika Tabassum, Ling Guan, Naimul Khan", "title": "ECG Heartbeat Classification Using Multimodal Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electrocardiogram (ECG) is an authoritative source to diagnose and counter\ncritical cardiovascular syndromes such as arrhythmia and myocardial infarction\n(MI). Current machine learning techniques either depend on manually extracted\nfeatures or large and complex deep learning networks which merely utilize the\n1D ECG signal directly. Since intelligent multimodal fusion can perform at the\nstateof-the-art level with an efficient deep network, therefore, in this paper,\nwe propose two computationally efficient multimodal fusion frameworks for ECG\nheart beat classification called Multimodal Image Fusion (MIF) and Multimodal\nFeature Fusion (MFF). At the input of these frameworks, we convert the raw ECG\ndata into three different images using Gramian Angular Field (GAF), Recurrence\nPlot (RP) and Markov Transition Field (MTF). In MIF, we first perform image\nfusion by combining three imaging modalities to create a single image modality\nwhich serves as input to the Convolutional Neural Network (CNN). In MFF, we\nextracted features from penultimate layer of CNNs and fused them to get unique\nand interdependent information necessary for better performance of classifier.\nThese informational features are finally used to train a Support Vector Machine\n(SVM) classifier for ECG heart-beat classification. We demonstrate the\nsuperiority of the proposed fusion models by performing experiments on\nPhysioNets MIT-BIH dataset for five distinct conditions of arrhythmias which\nare consistent with the AAMI EC57 protocols and on PTB diagnostics dataset for\nMyocardial Infarction (MI) classification. We achieved classification accuracy\nof 99.7% and 99.2% on arrhythmia and MI classification, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 03:48:35 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Tabassum", "Anika", ""], ["Guan", "Ling", ""], ["Khan", "Naimul", ""]]}, {"id": "2107.09883", "submitter": "Sathyanarayanan Aakur", "authors": "Sathyanarayanan N. Aakur, Sai Narayanan, Vineela Indla, Arunkumar\n  Bagavathi, Vishalini Laguduva Ramnath, Akhilesh Ramachandran", "title": "MG-NET: Leveraging Pseudo-Imaging for Multi-Modal Metagenome Analysis", "comments": "To appear in MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The emergence of novel pathogens and zoonotic diseases like the SARS-CoV-2\nhave underlined the need for developing novel diagnosis and intervention\npipelines that can learn rapidly from small amounts of labeled data. Combined\nwith technological advances in next-generation sequencing, metagenome-based\ndiagnostic tools hold much promise to revolutionize rapid point-of-care\ndiagnosis. However, there are significant challenges in developing such an\napproach, the chief among which is to learn self-supervised representations\nthat can help detect novel pathogen signatures with very low amounts of labeled\ndata. This is particularly a difficult task given that closely related\npathogens can share more than 90% of their genome structure. In this work, we\naddress these challenges by proposing MG-Net, a self-supervised representation\nlearning framework that leverages multi-modal context using pseudo-imaging data\nderived from clinical metagenome sequences. We show that the proposed framework\ncan learn robust representations from unlabeled data that can be used for\ndownstream tasks such as metagenome sequence classification with limited access\nto labeled data. Extensive experiments show that the learned features\noutperform current baseline metagenome representations, given only 1000 samples\nper class.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 05:53:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Aakur", "Sathyanarayanan N.", ""], ["Narayanan", "Sai", ""], ["Indla", "Vineela", ""], ["Bagavathi", "Arunkumar", ""], ["Ramnath", "Vishalini Laguduva", ""], ["Ramachandran", "Akhilesh", ""]]}, {"id": "2107.09892", "submitter": "Uddeshya Upadhyay", "authors": "Viswanath P. Sudarshan, Uddeshya Upadhyay, Gary F. Egan, Zhaolin Chen,\n  Suyash P. Awate", "title": "Towards Lower-Dose PET using Physics-Based Uncertainty-Aware Multimodal\n  Learning with Robustness to Out-of-Distribution Data", "comments": "Accepted at Medical Image Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CE cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Radiation exposure in positron emission tomography (PET) imaging limits its\nusage in the studies of radiation-sensitive populations, e.g., pregnant women,\nchildren, and adults that require longitudinal imaging. Reducing the PET\nradiotracer dose or acquisition time reduces photon counts, which can\ndeteriorate image quality. Recent deep-neural-network (DNN) based methods for\nimage-to-image translation enable the mapping of low-quality PET images\n(acquired using substantially reduced dose), coupled with the associated\nmagnetic resonance imaging (MRI) images, to high-quality PET images. However,\nsuch DNN methods focus on applications involving test data that match the\nstatistical characteristics of the training data very closely and give little\nattention to evaluating the performance of these DNNs on new\nout-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that\nmodels the (i) underlying sinogram-based physics of the PET imaging system and\n(ii) the uncertainty in the DNN output through the per-voxel heteroscedasticity\nof the residuals between the predicted and the high-quality reference images.\nOur sinogram-based uncertainty-aware DNN framework, namely, suDNN, estimates a\nstandard-dose PET image using multimodal input in the form of (i) a\nlow-dose/low-count PET image and (ii) the corresponding multi-contrast MRI\nimages, leading to improved robustness of suDNN to OOD acquisitions. Results on\nin vivo simultaneous PET-MRI, and various forms of OOD data in PET-MRI, show\nthe benefits of suDNN over the current state of the art, quantitatively and\nqualitatively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 06:18:10 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sudarshan", "Viswanath P.", ""], ["Upadhyay", "Uddeshya", ""], ["Egan", "Gary F.", ""], ["Chen", "Zhaolin", ""], ["Awate", "Suyash P.", ""]]}, {"id": "2107.09898", "submitter": "Jiankai Sun", "authors": "Jiankai Sun and Yuanshun Yao and Weihao Gao and Junyuan Xie and Chong\n  Wang", "title": "Defending against Reconstruction Attack in Vertical Federated Learning", "comments": "Accepted to International Workshop on Federated Learning for User\n  Privacy and Data Confidentiality in Conjunction with ICML 2021 (FL-ICML'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently researchers have studied input leakage problems in Federated\nLearning (FL) where a malicious party can reconstruct sensitive training inputs\nprovided by users from shared gradient. It raises concerns about FL since input\nleakage contradicts the privacy-preserving intention of using FL. Despite a\nrelatively rich literature on attacks and defenses of input reconstruction in\nHorizontal FL, input leakage and protection in vertical FL starts to draw\nresearcher's attention recently. In this paper, we study how to defend against\ninput leakage attacks in Vertical FL. We design an adversarial training-based\nframework that contains three modules: adversarial reconstruction, noise\nregularization, and distance correlation minimization. Those modules can not\nonly be employed individually but also applied together since they are\nindependent to each other. Through extensive experiments on a large-scale\nindustrial online advertising dataset, we show our framework is effective in\nprotecting input privacy while retaining the model utility.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 06:32:46 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sun", "Jiankai", ""], ["Yao", "Yuanshun", ""], ["Gao", "Weihao", ""], ["Xie", "Junyuan", ""], ["Wang", "Chong", ""]]}, {"id": "2107.09904", "submitter": "Ashish Ghosh", "authors": "Anwesha Law and Ashish Ghosh", "title": "Integration of Autoencoder and Functional Link Artificial Neural Network\n  for Multi-label Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label (ML) classification is an actively researched topic currently,\nwhich deals with convoluted and overlapping boundaries that arise due to\nseveral labels being active for a particular data instance. We propose a\nclassifier capable of extracting underlying features and introducing\nnon-linearity to the data to handle the complex decision boundaries. A novel\nneural network model has been developed where the input features are subjected\nto two transformations adapted from multi-label functional link artificial\nneural network and autoencoders. First, a functional expansion of the original\nfeatures are made using basis functions. This is followed by an\nautoencoder-aided transformation and reduction on the expanded features. This\nnetwork is capable of improving separability for the multi-label data owing to\nthe two-layer transformation while reducing the expanded feature space to a\nmore manageable amount. This balances the input dimension which leads to a\nbetter classification performance even for a limited amount of data. The\nproposed network has been validated on five ML datasets which shows its\nsuperior performance in comparison with six well-established ML classifiers.\nFurthermore, a single-label variation of the proposed network has also been\nformulated simultaneously and tested on four relevant datasets against three\nexisting classifiers to establish its effectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 07:04:52 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Law", "Anwesha", ""], ["Ghosh", "Ashish", ""]]}, {"id": "2107.09912", "submitter": "Andrea Zanette", "authors": "Andrea Zanette, Kefan Dong, Jonathan Lee, Emma Brunskill", "title": "Design of Experiments for Stochastic Contextual Linear Bandits", "comments": "Initial submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the stochastic linear contextual bandit setting there exist several\nminimax procedures for exploration with policies that are reactive to the data\nbeing acquired. In practice, there can be a significant engineering overhead to\ndeploy these algorithms, especially when the dataset is collected in a\ndistributed fashion or when a human in the loop is needed to implement a\ndifferent policy. Exploring with a single non-reactive policy is beneficial in\nsuch cases. Assuming some batch contexts are available, we design a single\nstochastic policy to collect a good dataset from which a near-optimal policy\ncan be extracted. We present a theoretical analysis as well as numerical\nexperiments on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 07:25:37 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 23:20:28 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Zanette", "Andrea", ""], ["Dong", "Kefan", ""], ["Lee", "Jonathan", ""], ["Brunskill", "Emma", ""]]}, {"id": "2107.09927", "submitter": "Serafeim Moustakidis", "authors": "Zoumpolia Dikopoulou, Serafeim Moustakidis, Patrik Karlsson", "title": "GLIME: A new graphical methodology for interpretable model-agnostic\n  explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Explainable artificial intelligence (XAI) is an emerging new domain in which\na set of processes and tools allow humans to better comprehend the decisions\ngenerated by black box models. However, most of the available XAI tools are\noften limited to simple explanations mainly quantifying the impact of\nindividual features to the models' output. Therefore, human users are not able\nto understand how the features are related to each other to make predictions,\nwhereas the inner workings of the trained models remain hidden. This paper\ncontributes to the development of a novel graphical explainability tool that\nnot only indicates the significant features of the model but also reveals the\nconditional relationships between features and the inference capturing both the\ndirect and indirect impact of features to the models' decision. The proposed\nXAI methodology, termed as gLIME, provides graphical model-agnostic\nexplanations either at the global (for the entire dataset) or the local scale\n(for specific data points). It relies on a combination of local interpretable\nmodel-agnostic explanations (LIME) with graphical least absolute shrinkage and\nselection operator (GLASSO) producing undirected Gaussian graphical models.\nRegularization is adopted to shrink small partial correlation coefficients to\nzero providing sparser and more interpretable graphical explanations. Two\nwell-known classification datasets (BIOPSY and OAI) were selected to confirm\nthe superiority of gLIME over LIME in terms of both robustness and consistency\nover multiple permutations. Specifically, gLIME accomplished increased\nstability over the two datasets with respect to features' importance (76%-96%\ncompared to 52%-77% using LIME). gLIME demonstrates a unique potential to\nextend the functionality of the current state-of-the-art in XAI by providing\ninformative graphically given explanations that could unlock black boxes.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:06:40 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dikopoulou", "Zoumpolia", ""], ["Moustakidis", "Serafeim", ""], ["Karlsson", "Patrik", ""]]}, {"id": "2107.09931", "submitter": "Shreya Pathak", "authors": "Archiki Prasad, Mohammad Ali Rehan, Shreya Pathak, Preethi Jyothi", "title": "The Effectiveness of Intermediate-Task Training for Code-Switched\n  Natural Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  While recent benchmarks have spurred a lot of new work on improving the\ngeneralization of pretrained multilingual language models on multilingual\ntasks, techniques to improve code-switched natural language understanding tasks\nhave been far less explored. In this work, we propose the use of bilingual\nintermediate pretraining as a reliable technique to derive large and consistent\nperformance gains on three different NLP tasks using code-switched text. We\nachieve substantial absolute improvements of 7.87%, 20.15%, and 10.99%, on the\nmean accuracies and F1 scores over previous state-of-the-art systems for\nHindi-English Natural Language Inference (NLI), Question Answering (QA) tasks,\nand Spanish-English Sentiment Analysis (SA) respectively. We show consistent\nperformance gains on four different code-switched language-pairs\n(Hindi-English, Spanish-English, Tamil-English and Malayalam-English) for SA.\nWe also present a code-switched masked language modelling (MLM) pretraining\ntechnique that consistently benefits SA compared to standard MLM pretraining\nusing real code-switched text.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:10:59 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Prasad", "Archiki", ""], ["Rehan", "Mohammad Ali", ""], ["Pathak", "Shreya", ""], ["Jyothi", "Preethi", ""]]}, {"id": "2107.09936", "submitter": "Sebastiano Panichella", "authors": "Rafael Kallis, Andrea Di Sorbo, Gerardo Canfora, Sebastiano Panichella", "title": "Predicting Issue Types on GitHub", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software maintenance and evolution involves critical activities for the\nsuccess of software projects. To support such activities and keep code\nup-to-date and error-free, software communities make use of issue trackers,\ni.e., tools for signaling, handling, and addressing the issues occurring in\nsoftware systems. However, in popular projects, tens or hundreds of issue\nreports are daily submitted. In this context, identifying the type of each\nsubmitted report (e.g., bug report, feature request, etc.) would facilitate the\nmanagement and the prioritization of the issues to address. To support issue\nhandling activities, in this paper, we propose Ticket Tagger, a GitHub app\nanalyzing the issue title and description through machine learning techniques\nto automatically recognize the types of reports submitted on GitHub and assign\nlabels to each issue accordingly. We empirically evaluated the tool's\nprediction performance on about 30,000 GitHub issues. Our results show that the\nTicket Tagger can identify the correct labels to assign to GitHub issues with\nreasonably high effectiveness. Considering these results and the fact that the\ntool is designed to be easily integrated in the GitHub issue management\nprocess, Ticket Tagger consists in a useful solution for developers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:14:48 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Kallis", "Rafael", ""], ["Di Sorbo", "Andrea", ""], ["Canfora", "Gerardo", ""], ["Panichella", "Sebastiano", ""]]}, {"id": "2107.09937", "submitter": "Huimin Wu", "authors": "Huimin Wu and Zhengmian Hu and Bin Gu", "title": "Fast and Scalable Adversarial Training of Kernel SVM via Doubly\n  Stochastic Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks by generating examples which are almost indistinguishable\nfrom natural examples, pose a serious threat to learning models. Defending\nagainst adversarial attacks is a critical element for a reliable learning\nsystem. Support vector machine (SVM) is a classical yet still important\nlearning algorithm even in the current deep learning era. Although a wide range\nof researches have been done in recent years to improve the adversarial\nrobustness of learning models, but most of them are limited to deep neural\nnetworks (DNNs) and the work for kernel SVM is still vacant. In this paper, we\naim at kernel SVM and propose adv-SVM to improve its adversarial robustness via\nadversarial training, which has been demonstrated to be the most promising\ndefense techniques. To the best of our knowledge, this is the first work that\ndevotes to the fast and scalable adversarial training of kernel SVM.\nSpecifically, we first build connection of perturbations of samples between\noriginal and kernel spaces, and then give a reduced and equivalent formulation\nof adversarial training of kernel SVM based on the connection. Next, doubly\nstochastic gradients (DSG) based on two unbiased stochastic approximations\n(i.e., one is on training points and another is on random features) are applied\nto update the solution of our objective function. Finally, we prove that our\nalgorithm optimized by DSG converges to the optimal solution at the rate of\nO(1/t) under the constant and diminishing stepsizes. Comprehensive experimental\nresults show that our adversarial training algorithm enjoys robustness against\nvarious attacks and meanwhile has the similar efficiency and scalability with\nclassical DSG algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:15:32 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Wu", "Huimin", ""], ["Hu", "Zhengmian", ""], ["Gu", "Bin", ""]]}, {"id": "2107.09947", "submitter": "Jerome Dockes", "authors": "J\\'ero\\^ome Dock\\`es, Ga\\\"el Varoquaux (PARIETAL), Jean-Baptiste\n  Poline", "title": "Preventing dataset shift from breaking machine-learning biomarkers", "comments": "GigaScience, BioMed Central, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning brings the hope of finding new biomarkers extracted from\ncohorts with rich biomedical measurements. A good biomarker is one that gives\nreliable detection of the corresponding condition. However, biomarkers are\noften extracted from a cohort that differs from the target population. Such a\nmismatch, known as a dataset shift, can undermine the application of the\nbiomarker to new individuals. Dataset shifts are frequent in biomedical\nresearch, e.g. because of recruitment biases. When a dataset shift occurs,\nstandard machine-learning techniques do not suffice to extract and validate\nbiomarkers. This article provides an overview of when and how dataset shifts\nbreaks machine-learning extracted biomarkers, as well as detection and\ncorrection strategies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:54:23 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dock\u00e8s", "J\u00e9ro\u00f4me", "", "PARIETAL"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"], ["Poline", "Jean-Baptiste", ""]]}, {"id": "2107.09949", "submitter": "Eura Shin", "authors": "Eura Shin, Pedja Klasnja, Susan Murphy, Finale Doshi-Velez", "title": "Online structural kernel selection for mobile health", "comments": "Workshop paper in ICML IMLH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by the need for efficient and personalized learning in mobile\nhealth, we investigate the problem of online kernel selection for Gaussian\nProcess regression in the multi-task setting. We propose a novel generative\nprocess on the kernel composition for this purpose. Our method demonstrates\nthat trajectories of kernel evolutions can be transferred between users to\nimprove learning and that the kernels themselves are meaningful for an mHealth\nprediction goal.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 08:58:53 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Shin", "Eura", ""], ["Klasnja", "Pedja", ""], ["Murphy", "Susan", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2107.09950", "submitter": "Nikolaos Dionelis", "authors": "Nikolaos Dionelis", "title": "Boundary of Distribution Support Generator (BDSG): Sample Generation on\n  the Boundary", "comments": "5 pages, 2020 IEEE International Conference on Image Processing\n  (ICIP)", "journal-ref": "2020 IEEE International Conference on Image Processing (ICIP)", "doi": null, "report-no": "2020 IEEE International Conference on Image Processing (ICIP)", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative models, such as Generative Adversarial Networks (GANs), have been\nused for unsupervised anomaly detection. While performance keeps improving,\nseveral limitations exist particularly attributed to difficulties at capturing\nmultimodal supports and to the ability to approximate the underlying\ndistribution closer to the tails, i.e. the boundary of the distribution's\nsupport. This paper proposes an approach that attempts to alleviate such\nshortcomings. We propose an invertible-residual-network-based model, the\nBoundary of Distribution Support Generator (BDSG). GANs generally do not\nguarantee the existence of a probability distribution and here, we use the\nrecently developed Invertible Residual Network (IResNet) and Residual Flow\n(ResFlow), for density estimation. These models have not yet been used for\nanomaly detection. We leverage IResNet and ResFlow for Out-of-Distribution\n(OoD) sample detection and for sample generation on the boundary using a\ncompound loss function that forces the samples to lie on the boundary. The BDSG\naddresses non-convex support, disjoint components, and multimodal\ndistributions. Results on synthetic data and data from multimodal\ndistributions, such as MNIST and CIFAR-10, demonstrate competitive performance\ncompared to methods from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:00:32 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dionelis", "Nikolaos", ""]]}, {"id": "2107.09951", "submitter": "Nan Liu", "authors": "Feng Xie, Han Yuan, Yilin Ning, Marcus Eng Hock Ong, Mengling Feng,\n  Wynne Hsu, Bibhas Chakraborty, Nan Liu", "title": "Deep learning for temporal data representation in electronic health\n  records: A systematic review of challenges and methodologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: Temporal electronic health records (EHRs) can be a wealth of\ninformation for secondary uses, such as clinical events prediction or chronic\ndisease management. However, challenges exist for temporal data representation.\nWe therefore sought to identify these challenges and evaluate novel\nmethodologies for addressing them through a systematic examination of deep\nlearning solutions.\n  Methods: We searched five databases (PubMed, EMBASE, the Institute of\nElectrical and Electronics Engineers [IEEE] Xplore Digital Library, the\nAssociation for Computing Machinery [ACM] digital library, and Web of Science)\ncomplemented with hand-searching in several prestigious computer science\nconference proceedings. We sought articles that reported deep learning\nmethodologies on temporal data representation in structured EHR data from\nJanuary 1, 2010, to August 30, 2020. We summarized and analyzed the selected\narticles from three perspectives: nature of time series, methodology, and model\nimplementation.\n  Results: We included 98 articles related to temporal data representation\nusing deep learning. Four major challenges were identified, including data\nirregularity, data heterogeneity, data sparsity, and model opacity. We then\nstudied how deep learning techniques were applied to address these challenges.\nFinally, we discuss some open challenges arising from deep learning.\n  Conclusion: Temporal EHR data present several major challenges for clinical\nprediction modeling and data utilization. To some extent, current deep learning\nsolutions can address these challenges. Future studies can consider designing\ncomprehensive and integrated solutions. Moreover, researchers should\nincorporate additional clinical domain knowledge into study designs and enhance\nthe interpretability of the model to facilitate its implementation in clinical\npractice.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:00:40 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Xie", "Feng", ""], ["Yuan", "Han", ""], ["Ning", "Yilin", ""], ["Ong", "Marcus Eng Hock", ""], ["Feng", "Mengling", ""], ["Hsu", "Wynne", ""], ["Chakraborty", "Bibhas", ""], ["Liu", "Nan", ""]]}, {"id": "2107.09957", "submitter": "Deep Patel", "authors": "Deep Patel and P.S. Sastry", "title": "Memorization in Deep Neural Networks: Does the Loss Function matter?", "comments": "Accepted at PAKDD 2021. 12 pages and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks, often owing to the overparameterization, are shown to\nbe capable of exactly memorizing even randomly labelled data. Empirical studies\nhave also shown that none of the standard regularization techniques mitigate\nsuch overfitting. We investigate whether the choice of the loss function can\naffect this memorization. We empirically show, with benchmark data sets MNIST\nand CIFAR-10, that a symmetric loss function, as opposed to either\ncross-entropy or squared error loss, results in significant improvement in the\nability of the network to resist such overfitting. We then provide a formal\ndefinition for robustness to memorization and provide a theoretical explanation\nas to why the symmetric losses provide this robustness. Our results clearly\nbring out the role loss functions alone can play in this phenomenon of\nmemorization.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:08:51 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 05:36:24 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Patel", "Deep", ""], ["Sastry", "P. S.", ""]]}, {"id": "2107.09989", "submitter": "Guang Yang A", "authors": "Guangyuan Li, Jun Lv, Xiangrong Tong, Chengyan Wang, Guang Yang", "title": "High-Resolution Pelvic MRI Reconstruction Using a Generative Adversarial\n  Network with Attention and Cyclic Loss", "comments": "21 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Magnetic resonance imaging (MRI) is an important medical imaging modality,\nbut its acquisition speed is quite slow due to the physiological limitations.\nRecently, super-resolution methods have shown excellent performance in\naccelerating MRI. In some circumstances, it is difficult to obtain\nhigh-resolution images even with prolonged scan time. Therefore, we proposed a\nnovel super-resolution method that uses a generative adversarial network (GAN)\nwith cyclic loss and attention mechanism to generate high-resolution MR images\nfrom low-resolution MR images by a factor of 2. We implemented our model on\npelvic images from healthy subjects as training and validation data, while\nthose data from patients were used for testing. The MR dataset was obtained\nusing different imaging sequences, including T2, T2W SPAIR, and mDIXON-W. Four\nmethods, i.e., BICUBIC, SRCNN, SRGAN, and EDSR were used for comparison.\nStructural similarity, peak signal to noise ratio, root mean square error, and\nvariance inflation factor were used as calculation indicators to evaluate the\nperformances of the proposed method. Various experimental results showed that\nour method can better restore the details of the high-resolution MR image as\ncompared to the other methods. In addition, the reconstructed high-resolution\nMR image can provide better lesion textures in the tumor patients, which is\npromising to be used in clinical diagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 10:07:22 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Li", "Guangyuan", ""], ["Lv", "Jun", ""], ["Tong", "Xiangrong", ""], ["Wang", "Chengyan", ""], ["Yang", "Guang", ""]]}, {"id": "2107.09996", "submitter": "Athanasios Kapoutsis Ch.", "authors": "Dimitrios I. Koutras, Athanasios Ch. Kapoutsis, Angelos A.\n  Amanatiadis, Elias B. Kosmatopoulos", "title": "MarsExplorer: Exploration of Unknown Terrains via Deep Reinforcement\n  Learning and Procedurally Generated Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an initial endeavor to bridge the gap between powerful Deep\nReinforcement Learning methodologies and the problem of exploration/coverage of\nunknown terrains. Within this scope, MarsExplorer, an openai-gym compatible\nenvironment tailored to exploration/coverage of unknown areas, is presented.\nMarsExplorer translates the original robotics problem into a Reinforcement\nLearning setup that various off-the-shelf algorithms can tackle. Any learned\npolicy can be straightforwardly applied to a robotic platform without an\nelaborate simulation model of the robot's dynamics to apply a different\nlearning/adaptation phase. One of its core features is the controllable\nmulti-dimensional procedural generation of terrains, which is the key for\nproducing policies with strong generalization capabilities. Four different\nstate-of-the-art RL algorithms (A3C, PPO, Rainbow, and SAC) are trained on the\nMarsExplorer environment, and a proper evaluation of their results compared to\nthe average human-level performance is reported. In the follow-up experimental\nanalysis, the effect of the multi-dimensional difficulty setting on the\nlearning capabilities of the best-performing algorithm (PPO) is analyzed. A\nmilestone result is the generation of an exploration policy that follows the\nHilbert curve without providing this information to the environment or\nrewarding directly or indirectly Hilbert-curve-like trajectories. The\nexperimental analysis is concluded by comparing PPO learned policy results with\nfrontier-based exploration context for extended terrain sizes. The source code\ncan be found at: https://github.com/dimikout3/GeneralExplorationPolicy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 10:29:39 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Koutras", "Dimitrios I.", ""], ["Kapoutsis", "Athanasios Ch.", ""], ["Amanatiadis", "Angelos A.", ""], ["Kosmatopoulos", "Elias B.", ""]]}, {"id": "2107.10004", "submitter": "Srikrishna Jaganathan", "authors": "Srikrishna Jaganathan, Jian Wang, Anja Borsdorf, Karthik Shetty,\n  Andreas Maier", "title": "Deep Iterative 2D/3D Registration", "comments": "10 pages,2 figures, Accepted at MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning-based 2D/3D registration methods are highly robust but often\nlack the necessary registration accuracy for clinical application. A refinement\nstep using the classical optimization-based 2D/3D registration method applied\nin combination with Deep Learning-based techniques can provide the required\naccuracy. However, it also increases the runtime. In this work, we propose a\nnovel Deep Learning driven 2D/3D registration framework that can be used\nend-to-end for iterative registration tasks without relying on any further\nrefinement step. We accomplish this by learning the update step of the 2D/3D\nregistration framework using Point-to-Plane Correspondences. The update step is\nlearned using iterative residual refinement-based optical flow estimation, in\ncombination with the Point-to-Plane correspondence solver embedded as a known\noperator. Our proposed method achieves an average runtime of around 8s, a mean\nre-projection distance error of 0.60 $\\pm$ 0.40 mm with a success ratio of 97\npercent and a capture range of 60 mm. The combination of high registration\naccuracy, high robustness, and fast runtime makes our solution ideal for\nclinical applications.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 10:51:29 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Jaganathan", "Srikrishna", ""], ["Wang", "Jian", ""], ["Borsdorf", "Anja", ""], ["Shetty", "Karthik", ""], ["Maier", "Andreas", ""]]}, {"id": "2107.10006", "submitter": "Mola Ayenew", "authors": "Nils Nordmark and Mola Ayenew", "title": "Window Detection In Facade Imagery: A Deep Learning Approach Using Mask\n  R-CNN", "comments": "13 pages, 65 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The parsing of windows in building facades is a long-desired but challenging\ntask in computer vision. It is crucial to urban analysis, semantic\nreconstruction, lifecycle analysis, digital twins, and scene parsing amongst\nother building-related tasks that require high-quality semantic data. This\narticle investigates the usage of the mask R-CNN framework to be used for\nwindow detection of facade imagery input. We utilize transfer learning to train\nour proposed method on COCO weights with our own collected dataset of street\nview images of facades to produce instance segmentations of our new window\nclass. Experimental results show that our suggested approach with a relatively\nsmall dataset trains the network only with transfer learning and augmentation\nachieves results on par with prior state-of-the-art window detection\napproaches, even without post-optimization techniques.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:00:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Nordmark", "Nils", ""], ["Ayenew", "Mola", ""]]}, {"id": "2107.10014", "submitter": "Dominik Kloepfer", "authors": "Dominik Kloepfer, Angelica I. Aviles-Rivero, Daniel Heydecker", "title": "Delving Into Deep Walkers: A Convergence Analysis of Random-Walk-Based\n  Vertex Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph vertex embeddings based on random walks have become increasingly\ninfluential in recent years, showing good performance in several tasks as they\nefficiently transform a graph into a more computationally digestible format\nwhile preserving relevant information. However, the theoretical properties of\nsuch algorithms, in particular the influence of hyperparameters and of the\ngraph structure on their convergence behaviour, have so far not been\nwell-understood. In this work, we provide a theoretical analysis for\nrandom-walks based embeddings techniques. Firstly, we prove that, under some\nweak assumptions, vertex embeddings derived from random walks do indeed\nconverge both in the single limit of the number of random walks $N \\to \\infty$\nand in the double limit of both $N$ and the length of each random walk\n$L\\to\\infty$. Secondly, we derive concentration bounds quantifying the converge\nrate of the corpora for the single and double limits. Thirdly, we use these\nresults to derive a heuristic for choosing the hyperparameters $N$ and $L$. We\nvalidate and illustrate the practical importance of our findings with a range\nof numerical and visual experiments on several graphs drawn from real-world\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:23:04 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Kloepfer", "Dominik", ""], ["Aviles-Rivero", "Angelica I.", ""], ["Heydecker", "Daniel", ""]]}, {"id": "2107.10015", "submitter": "Thiviyan Thanapalasingam", "authors": "Thiviyan Thanapalasingam, Lucas van Berkel, Peter Bloem, Paul Groth", "title": "Relational Graph Convolutional Networks: A Closer Look", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe a reproduction of the Relational Graph\nConvolutional Network (RGCN). Using our reproduction, we explain the intuition\nbehind the model. Our reproduction results empirically validate the correctness\nof our implementations using benchmark Knowledge Graph datasets on node\nclassification and link prediction tasks. Our explanation provides a friendly\nunderstanding of the different components of the RGCN for both users and\nresearchers extending the RGCN approach. Furthermore, we introduce two new\nconfigurations of the RGCN that are more parameter efficient. The code and\ndatasets are available at https://github.com/thiviyanT/torch-rgcn.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:25:11 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Thanapalasingam", "Thiviyan", ""], ["van Berkel", "Lucas", ""], ["Bloem", "Peter", ""], ["Groth", "Paul", ""]]}, {"id": "2107.10030", "submitter": "Jeremie Dona", "authors": "J\\'er\\'emie Dona (MLIA), Patrick Gallinari (MLIA)", "title": "Differentiable Feature Selection, a Reparameterization Approach", "comments": null, "journal-ref": "European Conference (ECML-PKDD), In press", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of feature selection for reconstruction which consists\nin choosing a small subset of features from which whole data instances can be\nreconstructed. This is of particular importance in several contexts involving\nfor example costly physical measurements, sensor placement or information\ncompression. To break the intrinsic combinatorial nature of this problem, we\nformulate the task as optimizing a binary mask distribution enabling an\naccurate reconstruction. We then face two main challenges. One concerns\ndifferentiability issues due to the binary distribution. The second one\ncorresponds to the elimination of redundant information by selecting variables\nin a correlated fashion which requires modeling the covariance of the binary\ndistribution. We address both issues by introducing a relaxation of the problem\nvia a novel reparameterization of the logitNormal distribution. We demonstrate\nthat the proposed method provides an effective exploration scheme and leads to\nefficient feature selection for reconstruction through evaluation on several\nhigh dimensional image benchmarks. We show that the method leverages the\nintrinsic geometry of the data, facilitating reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:52:34 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dona", "J\u00e9r\u00e9mie", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2107.10034", "submitter": "Jan Jakubuv", "authors": "Karel Chvalovsk\\'y, Jan Jakub\\r{u}v, Miroslav Ol\\v{s}\\'ak, Josef Urban", "title": "Learning Theorem Proving Components", "comments": "Accepted to TABLEAUX'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.NE cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Saturation-style automated theorem provers (ATPs) based on the given clause\nprocedure are today the strongest general reasoners for classical first-order\nlogic. The clause selection heuristics in such systems are, however, often\nevaluating clauses in isolation, ignoring other clauses. This has changed\nrecently by equipping the E/ENIGMA system with a graph neural network (GNN)\nthat chooses the next given clause based on its evaluation in the context of\npreviously selected clauses. In this work, we describe several algorithms and\nexperiments with ENIGMA, advancing the idea of contextual evaluation based on\nlearning important components of the graph of clauses.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:00:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chvalovsk\u00fd", "Karel", ""], ["Jakub\u016fv", "Jan", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Urban", "Josef", ""]]}, {"id": "2107.10043", "submitter": "Nir Shlezinger", "authors": "Guy Revach, Nir Shlezinger, Xiaoyong Ni, Adria Lopez Escoriza, Ruud J.\n  G. van Sloun, and Yonina C. Eldar", "title": "KalmanNet: Neural Network Aided Kalman Filtering for Partially Known\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time state estimation of dynamical systems is a fundamental task in\nsignal processing and control. For systems that are well-represented by a fully\nknown linear Gaussian state space (SS) model, the celebrated Kalman filter (KF)\nis a low complexity optimal solution. However, both linearity of the underlying\nSS model and accurate knowledge of it are often not encountered in practice.\nHere, we present KalmanNet, a real-time state estimator that learns from data\nto carry out Kalman filtering under non-linear dynamics with partial\ninformation. By incorporating the structural SS model with a dedicated\nrecurrent neural network module in the flow of the KF, we retain data\nefficiency and interpretability of the classic algorithm while implicitly\nlearning complex dynamics from data. We numerically demonstrate that KalmanNet\novercomes nonlinearities and model mismatch, outperforming classic filtering\nmethods operating with both mismatched and accurate domain knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:26:46 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Revach", "Guy", ""], ["Shlezinger", "Nir", ""], ["Ni", "Xiaoyong", ""], ["Escoriza", "Adria Lopez", ""], ["van Sloun", "Ruud J. G.", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2107.10060", "submitter": "Liang Hou", "authors": "Liang Hou, Qi Cao, Huawei Shen, Xueqi Cheng", "title": "cGANs with Auxiliary Discriminative Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative models aim to learn the underlying joint distribution\nof data and labels, and thus realize conditional generation. Among them,\nauxiliary classifier generative adversarial networks (AC-GAN) have been widely\nused, but suffer from the issue of low intra-class diversity on generated\nsamples. In this paper, we point out that the fundamental reason is that the\nclassifier of AC-GAN is generator-agnostic, and thus cannot provide informative\nguidance to the generator to approximate the target joint distribution, leading\nto a minimization of conditional entropy that decreases the intra-class\ndiversity. Based on this finding, we propose novel cGANs with auxiliary\ndiscriminative classifier (ADC-GAN) to address the issue of AC-GAN.\nSpecifically, the auxiliary discriminative classifier becomes generator-aware\nby distinguishing between the real and fake data while recognizing their\nlabels. We then optimize the generator based on the auxiliary classifier along\nwith the original discriminator to match the joint and marginal distributions\nof the generated samples with those of the real samples. We provide theoretical\nanalysis and empirical evidence on synthetic and real-world datasets to\ndemonstrate the superiority of the proposed ADC-GAN compared to competitive\ncGANs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:06:32 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 06:16:51 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Hou", "Liang", ""], ["Cao", "Qi", ""], ["Shen", "Huawei", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2107.10066", "submitter": "Th\\'eo Galy-Fajou", "authors": "Th\\'eo Galy-Fajou, Manfred Opper", "title": "Adaptive Inducing Points Selection For Gaussian Processes", "comments": "Accepted at Continual Learning Workshop - ICML 2020 :\n  https://sites.google.com/view/cl-icml/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian Processes (\\textbf{GPs}) are flexible non-parametric models with\nstrong probabilistic interpretation. While being a standard choice for\nperforming inference on time series, GPs have few techniques to work in a\nstreaming setting. \\cite{bui2017streaming} developed an efficient variational\napproach to train online GPs by using sparsity techniques: The whole set of\nobservations is approximated by a smaller set of inducing points (\\textbf{IPs})\nand moved around with new data. Both the number and the locations of the IPs\nwill affect greatly the performance of the algorithm. In addition to optimizing\ntheir locations, we propose to adaptively add new points, based on the\nproperties of the GP and the structure of the data.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:22:46 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Galy-Fajou", "Th\u00e9o", ""], ["Opper", "Manfred", ""]]}, {"id": "2107.10072", "submitter": "Wenbo Gong", "authors": "Wenbo Gong, Yingzhen Li", "title": "Interpreting diffusion score matching using normalizing flow", "comments": "8 pages, International Conference on Machine Learning (ICML) INNF+\n  2021 Workshop Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scoring matching (SM), and its related counterpart, Stein discrepancy (SD)\nhave achieved great success in model training and evaluations. However, recent\nresearch shows their limitations when dealing with certain types of\ndistributions. One possible fix is incorporating the original score matching\n(or Stein discrepancy) with a diffusion matrix, which is called diffusion score\nmatching (DSM) (or diffusion Stein discrepancy (DSD)). However, the lack of\ninterpretation of the diffusion limits its usage within simple distributions\nand manually chosen matrix. In this work, we plan to fill this gap by\ninterpreting the diffusion matrix using normalizing flows. Specifically, we\ntheoretically prove that DSM (or DSD) is equivalent to the original score\nmatching (or Stein discrepancy) evaluated in the transformed space defined by\nthe normalizing flow, where the diffusion matrix is the inverse of the flow's\nJacobian matrix. In addition, we also build its connection to Riemannian\nmanifolds and further extend it to continuous flows, where the change of DSM is\ncharacterized by an ODE.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 13:27:32 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Gong", "Wenbo", ""], ["Li", "Yingzhen", ""]]}, {"id": "2107.10093", "submitter": "Logan Stapleton", "authors": "Daniel Ngo, Logan Stapleton, Vasilis Syrgkanis, Zhiwei Steven Wu", "title": "Incentivizing Compliance with Algorithmic Instruments", "comments": "In Proceedings of the Thirty-eighth International Conference on\n  Machine Learning (ICML 2021), 17 pages of main text, 53 pages total, 3\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized experiments can be susceptible to selection bias due to potential\nnon-compliance by the participants. While much of the existing work has studied\ncompliance as a static behavior, we propose a game-theoretic model to study\ncompliance as dynamic behavior that may change over time. In rounds, a social\nplanner interacts with a sequence of heterogeneous agents who arrive with their\nunobserved private type that determines both their prior preferences across the\nactions (e.g., control and treatment) and their baseline rewards without taking\nany treatment. The planner provides each agent with a randomized recommendation\nthat may alter their beliefs and their action selection. We develop a novel\nrecommendation mechanism that views the planner's recommendation as a form of\ninstrumental variable (IV) that only affects an agents' action selection, but\nnot the observed rewards. We construct such IVs by carefully mapping the\nhistory -- the interactions between the planner and the previous agents -- to a\nrandom recommendation. Even though the initial agents may be completely\nnon-compliant, our mechanism can incentivize compliance over time, thereby\nenabling the estimation of the treatment effect of each treatment, and\nminimizing the cumulative regret of the planner whose goal is to identify the\noptimal treatment.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:10:08 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 04:04:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ngo", "Daniel", ""], ["Stapleton", "Logan", ""], ["Syrgkanis", "Vasilis", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2107.10098", "submitter": "S\\'ebastien Lachapelle", "authors": "S\\'ebastien Lachapelle, Pau Rodr\\'iguez L\\'opez, R\\'emi Le Priol,\n  Alexandre Lacoste, Simon Lacoste-Julien", "title": "Discovering Latent Causal Variables via Mechanism Sparsity: A New\n  Principle for Nonlinear ICA", "comments": "Appears in: Workshop on the Neglected Assumptions in Causal Inference\n  (NACI) at the 38 th International Conference on Machine Learning, 2021. 19\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It can be argued that finding an interpretable low-dimensional representation\nof a potentially high-dimensional phenomenon is central to the scientific\nenterprise. Independent component analysis (ICA) refers to an ensemble of\nmethods which formalize this goal and provide estimation procedure for\npractical application. This work proposes mechanism sparsity regularization as\na new principle to achieve nonlinear ICA when latent factors depend sparsely on\nobserved auxiliary variables and/or past latent factors. We show that the\nlatent variables can be recovered up to a permutation if one regularizes the\nlatent mechanisms to be sparse and if some graphical criterion is satisfied by\nthe data generating process. As a special case, our framework shows how one can\nleverage unknown-target interventions on the latent factors to disentangle\nthem, thus drawing further connections between ICA and causality. We validate\nour theoretical results with toy experiments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:22:14 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Lachapelle", "S\u00e9bastien", ""], ["L\u00f3pez", "Pau Rodr\u00edguez", ""], ["Priol", "R\u00e9mi Le", ""], ["Lacoste", "Alexandre", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2107.10110", "submitter": "Shuyu Cheng", "authors": "Shuyu Cheng, Guoqiang Wu, Jun Zhu", "title": "On the Convergence of Prior-Guided Zeroth-Order Optimization Algorithms", "comments": "Code available at https://github.com/csy530216/pg-zoo", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Zeroth-order (ZO) optimization is widely used to handle challenging tasks,\nsuch as query-based black-box adversarial attacks and reinforcement learning.\nVarious attempts have been made to integrate prior information into the\ngradient estimation procedure based on finite differences, with promising\nempirical results. However, their convergence properties are not well\nunderstood. This paper makes an attempt to fill this gap by analyzing the\nconvergence of prior-guided ZO algorithms under a greedy descent framework with\nvarious gradient estimators. We provide a convergence guarantee for the\nprior-guided random gradient-free (PRGF) algorithms. Moreover, to further\naccelerate over greedy descent methods, we present a new accelerated random\nsearch (ARS) algorithm that incorporates prior information, together with a\nconvergence analysis. Finally, our theoretical results are confirmed by\nexperiments on several numerical benchmarks as well as adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:39:40 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Cheng", "Shuyu", ""], ["Wu", "Guoqiang", ""], ["Zhu", "Jun", ""]]}, {"id": "2107.10111", "submitter": "Martin Pil\\'at", "authors": "Martin Pil\\'at", "title": "Training Electric Vehicle Charging Controllers with Imitation Learning", "comments": "Submitted to ICTAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of coordinating the charging of electric vehicles gains more\nimportance as the number of such vehicles grows. In this paper, we develop a\nmethod for the training of controllers for the coordination of EV charging. In\ncontrast to most existing works on this topic, we require the controllers to\npreserve the privacy of the users, therefore we do not allow any communication\nfrom the controller to any third party.\n  In order to train the controllers, we use the idea of imitation learning --\nwe first find an optimum solution for a relaxed version of the problem using\nquadratic optimization and then train the controllers to imitate this solution.\nWe also investigate the effects of regularization of the optimum solution on\nthe performance of the controllers. The method is evaluated on realistic data\nand shows improved performance and training speed compared to similar\ncontrollers trained using evolutionary algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:39:55 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Pil\u00e1t", "Martin", ""]]}, {"id": "2107.10125", "submitter": "Sebastian Ober", "authors": "Sebastian W. Ober, Laurence Aitchison", "title": "A variational approximate posterior for the deep Wishart process", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work introduced deep kernel processes as an entirely kernel-based\nalternative to NNs (Aitchison et al. 2020). Deep kernel processes flexibly\nlearn good top-layer representations by alternately sampling the kernel from a\ndistribution over positive semi-definite matrices and performing nonlinear\ntransformations. A particular deep kernel process, the deep Wishart process\n(DWP), is of particular interest because its prior is equivalent to deep\nGaussian process (DGP) priors. However, inference in DWPs has not yet been\npossible due to the lack of sufficiently flexible distributions over positive\nsemi-definite matrices. Here, we give a novel approach to obtaining flexible\ndistributions over positive semi-definite matrices by generalising the Bartlett\ndecomposition of the Wishart probability density. We use this new distribution\nto develop an approximate posterior for the DWP that includes dependency across\nlayers. We develop a doubly-stochastic inducing-point inference scheme for the\nDWP and show experimentally that inference in the DWP gives improved\nperformance over doing inference in a DGP with the equivalent prior.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:48:27 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ober", "Sebastian W.", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2107.10140", "submitter": "Viraj Prabhu", "authors": "Viraj Prabhu, Shivam Khare, Deeksha Kartik, Judy Hoffman", "title": "S4T: Source-free domain adaptation for semantic segmentation via\n  self-supervised selective self-training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most modern approaches for domain adaptive semantic segmentation rely on\ncontinued access to source data during adaptation, which may be infeasible due\nto computational or privacy constraints. We focus on source-free domain\nadaptation for semantic segmentation, wherein a source model must adapt itself\nto a new target domain given only unlabeled target data. We propose\nSelf-Supervised Selective Self-Training (S4T), a source-free adaptation\nalgorithm that first uses the model's pixel-level predictive consistency across\ndiverse views of each target image along with model confidence to classify\npixel predictions as either reliable or unreliable. Next, the model is\nself-trained, using predicted pseudolabels for reliable predictions and\npseudolabels inferred via a selective interpolation strategy for unreliable\nones. S4T matches or improves upon the state-of-the-art in source-free\nadaptation on 3 standard benchmarks for semantic segmentation within a single\nepoch of adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:18:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Prabhu", "Viraj", ""], ["Khare", "Shivam", ""], ["Kartik", "Deeksha", ""], ["Hoffman", "Judy", ""]]}, {"id": "2107.10143", "submitter": "Ekaterina Lobacheva Ms", "authors": "Ildus Sadrtdinov, Nadezhda Chirkova, Ekaterina Lobacheva", "title": "On the Memorization Properties of Contrastive Learning", "comments": "Published in Workshop on Overparameterization: Pitfalls &\n  Opportunities at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memorization studies of deep neural networks (DNNs) help to understand what\npatterns and how do DNNs learn, and motivate improvements to DNN training\napproaches. In this work, we investigate the memorization properties of SimCLR,\na widely used contrastive self-supervised learning approach, and compare them\nto the memorization of supervised learning and random labels training. We find\nthat both training objects and augmentations may have different complexity in\nthe sense of how SimCLR learns them. Moreover, we show that SimCLR is similar\nto random labels training in terms of the distribution of training objects\ncomplexity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:21:58 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Sadrtdinov", "Ildus", ""], ["Chirkova", "Nadezhda", ""], ["Lobacheva", "Ekaterina", ""]]}, {"id": "2107.10146", "submitter": "Majid Raeis", "authors": "Majid Raeis and Alberto Leon-Garcia", "title": "A Deep Reinforcement Learning Approach for Fair Traffic Signal Control", "comments": "7 pages, Accepted at ITSC 2021 (International Conference on\n  Intelligent Transportation Systems)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic signal control is one of the most effective methods of traffic\nmanagement in urban areas. In recent years, traffic control methods based on\ndeep reinforcement learning (DRL) have gained attention due to their ability to\nexploit real-time traffic data, which is often poorly used by the traditional\nhand-crafted methods. While most recent DRL-based methods have focused on\nmaximizing the throughput or minimizing the average travel time of the\nvehicles, the fairness of the traffic signal controllers has often been\nneglected. This is particularly important as neglecting fairness can lead to\nsituations where some vehicles experience extreme waiting times, or where the\nthroughput of a particular traffic flow is highly impacted by the fluctuations\nof another conflicting flow at the intersection. In order to address these\nissues, we introduce two notions of fairness: delay-based and throughput-based\nfairness, which correspond to the two issues mentioned above. Furthermore, we\npropose two DRL-based traffic signal control methods for implementing these\nfairness notions, that can achieve a high throughput as well. We evaluate the\nperformance of our proposed methods using three traffic arrival distributions,\nand find that our methods outperform the baselines in the tested scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:23:52 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Raeis", "Majid", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "2107.10154", "submitter": "Vladim\\'ir Kraj\\v{n}\\'ak", "authors": "Vladim\\'ir Kraj\\v{n}\\'ak, Shibabrat Naik, Stephen Wiggins", "title": "Predicting trajectory behaviour via machine-learned invariant manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we use support vector machines (SVM) to develop a machine\nlearning framework to discover the phase space structure that can distinguish\nbetween distinct reaction pathways. The machine learning model is trained using\ndata from trajectories of Hamilton's equations but lends itself for use in\nmolecular dynamics simulation. The framework is specifically designed to\nrequire minimal a priori knowledge of the dynamics in a system. We benchmark\nour approach with a model Hamiltonian for the reaction of an ion and a molecule\ndue to Chesnavich consisting of two parts: a rigid, symmetric top representing\nthe $\\text{CH}_3^{+}$ ion, and a mobile $\\text{H}$ atom. We begin with\ntrajectories and use support vector machines to determine the boundaries\nbetween initial conditions corresponding to different classes of trajectories.\nWe then show that these boundaries between different classes of trajectories\napproximate invariant phase space structures of the same type observed in\nearlier analyses of Chesnavich's model. Our approach is designed with\nextensions to higher-dimensional applications in mind. SVM is known to work\nwell even with small amounts of data, therefore our approach is computationally\nbetter suited than existing methods for high-dimensional systems and systems\nwhere integrating trajectories is expensive.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:30:38 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Kraj\u0148\u00e1k", "Vladim\u00edr", ""], ["Naik", "Shibabrat", ""], ["Wiggins", "Stephen", ""]]}, {"id": "2107.10159", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi and Gabriela Reyes", "title": "Answer-Set Programs for Reasoning about Counterfactual Interventions and\n  Responsibility Scores for Classification", "comments": "Extended version with appendices of conference submission (under\n  review). arXiv admin note: text overlap with arXiv:2106.10562", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe how answer-set programs can be used to declaratively specify\ncounterfactual interventions on entities under classification, and reason about\nthem. In particular, they can be used to define and compute responsibility\nscores as attribution-based explanations for outcomes from classification\nmodels. The approach allows for the inclusion of domain knowledge and supports\nquery answering. A detailed example with a naive-Bayes classifier is presented.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:41:56 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bertossi", "Leopoldo", ""], ["Reyes", "Gabriela", ""]]}, {"id": "2107.10171", "submitter": "Emily Black", "authors": "Emily Black, Matt Fredrikson", "title": "Leave-one-out Unfairness", "comments": "FAccT '21", "journal-ref": "FAccT '21: Proceedings of the 2021 ACM Conference on Fairness,\n  Accountability, and Transparency 2021, Pages 285-295", "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce leave-one-out unfairness, which characterizes how likely a\nmodel's prediction for an individual will change due to the inclusion or\nremoval of a single other person in the model's training data. Leave-one-out\nunfairness appeals to the idea that fair decisions are not arbitrary: they\nshould not be based on the chance event of any one person's inclusion in the\ntraining data. Leave-one-out unfairness is closely related to algorithmic\nstability, but it focuses on the consistency of an individual point's\nprediction outcome over unit changes to the training data, rather than the\nerror of the model in aggregate. Beyond formalizing leave-one-out unfairness,\nwe characterize the extent to which deep models behave leave-one-out unfairly\non real data, including in cases where the generalization error is small.\nFurther, we demonstrate that adversarial training and randomized smoothing\ntechniques have opposite effects on leave-one-out fairness, which sheds light\non the relationships between robustness, memorization, individual fairness, and\nleave-one-out fairness in deep models. Finally, we discuss salient practical\napplications that may be negatively affected by leave-one-out unfairness.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:55:49 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Black", "Emily", ""], ["Fredrikson", "Matt", ""]]}, {"id": "2107.10174", "submitter": "Yucheng Shi", "authors": "Kunhong Wu, Yucheng Shi, Yahong Han, Yunfeng Shao, Bingshuai Li", "title": "Black-box Probe for Unsupervised Domain Adaptation without Model\n  Transferring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, researchers have been paying increasing attention to the\nthreats brought by deep learning models to data security and privacy,\nespecially in the field of domain adaptation. Existing unsupervised domain\nadaptation (UDA) methods can achieve promising performance without transferring\ndata from source domain to target domain. However, UDA with representation\nalignment or self-supervised pseudo-labeling relies on the transferred source\nmodels. In many data-critical scenarios, methods based on model transferring\nmay suffer from membership inference attacks and expose private data. In this\npaper, we aim to overcome a challenging new setting where the source models are\nonly queryable but cannot be transferred to the target domain. We propose\nBlack-box Probe Domain Adaptation (BPDA), which adopts query mechanism to probe\nand refine information from source model using third-party dataset. In order to\ngain more informative query results, we further propose Distributionally\nAdversarial Training (DAT) to align the distribution of third-party data with\nthat of target data. BPDA uses public third-party dataset and adversarial\nexamples based on DAT as the information carrier between source and target\ndomains, dispensing with transferring source data or model. Experimental\nresults on benchmarks of Digit-Five, Office-Caltech, Office-31, Office-Home,\nand DomainNet demonstrate the feasibility of BPDA without model transferring.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:00:51 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Wu", "Kunhong", ""], ["Shi", "Yucheng", ""], ["Han", "Yahong", ""], ["Shao", "Yunfeng", ""], ["Li", "Bingshuai", ""]]}, {"id": "2107.10188", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Cezary Kaliszyk", "title": "JEFL: Joint Embedding of Formal Proof Libraries", "comments": "Submission to FroCoS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The heterogeneous nature of the logical foundations used in different\ninteractive proof assistant libraries has rendered discovery of similar\nmathematical concepts among them difficult. In this paper, we compare a\npreviously proposed algorithm for matching concepts across libraries with our\nunsupervised embedding approach that can help us retrieve similar concepts. Our\napproach is based on the fasttext implementation of Word2Vec, on top of which a\ntree traversal module is added to adapt its algorithm to the representation\nformat of our data export pipeline. We compare the explainability,\ncustomizability, and online-servability of the approaches and argue that the\nneural embedding approach has more potential to be integrated into an\ninteractive proof assistant.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:31:33 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Wang", "Qingxiang", ""], ["Kaliszyk", "Cezary", ""]]}, {"id": "2107.10199", "submitter": "Andrzej Banburski", "authors": "Andrzej Banburski, Fernanda De La Torre, Nishka Pant, Ishana Shastri,\n  Tomaso Poggio", "title": "Distribution of Classification Margins: Are All Data Equal?", "comments": "Previously online as CBMM Memo 115 on the CBMM MIT site", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent theoretical results show that gradient descent on deep neural networks\nunder exponential loss functions locally maximizes classification margin, which\nis equivalent to minimizing the norm of the weight matrices under margin\nconstraints. This property of the solution however does not fully characterize\nthe generalization performance. We motivate theoretically and show empirically\nthat the area under the curve of the margin distribution on the training set is\nin fact a good measure of generalization. We then show that, after data\nseparation is achieved, it is possible to dynamically reduce the training set\nby more than 99% without significant loss of performance. Interestingly, the\nresulting subset of \"high capacity\" features is not consistent across different\ntraining runs, which is consistent with the theoretical claim that all training\npoints should converge to the same asymptotic margin under SGD and in the\npresence of both batch normalization and weight decay.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:41:57 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Banburski", "Andrzej", ""], ["De La Torre", "Fernanda", ""], ["Pant", "Nishka", ""], ["Shastri", "Ishana", ""], ["Poggio", "Tomaso", ""]]}, {"id": "2107.10201", "submitter": "Nicolas Sonnerat", "authors": "Nicolas Sonnerat, Pengming Wang, Ira Ktena, Sergey Bartunov, Vinod\n  Nair", "title": "Learning a Large Neighborhood Search Algorithm for Mixed Integer\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Neighborhood Search (LNS) is a combinatorial optimization heuristic\nthat starts with an assignment of values for the variables to be optimized, and\niteratively improves it by searching a large neighborhood around the current\nassignment. In this paper we consider a learning-based LNS approach for mixed\ninteger programs (MIPs). We train a Neural Diving model to represent a\nprobability distribution over assignments, which, together with an\noff-the-shelf MIP solver, generates an initial assignment. Formulating the\nsubsequent search steps as a Markov Decision Process, we train a Neural\nNeighborhood Selection policy to select a search neighborhood at each step,\nwhich is searched using a MIP solver to find the next assignment. The policy\nnetwork is trained using imitation learning. We propose a target policy for\nimitation that, given enough compute resources, is guaranteed to select the\nneighborhood containing the optimal next assignment amongst all possible\nchoices for the neighborhood of a specified size. Our approach matches or\noutperforms all the baselines on five real-world MIP datasets with large-scale\ninstances from diverse applications, including two production applications at\nGoogle. It achieves $2\\times$ to $37.8\\times$ better average primal gap than\nthe best baseline on three of the datasets at large running times.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:43:46 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 20:37:42 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Sonnerat", "Nicolas", ""], ["Wang", "Pengming", ""], ["Ktena", "Ira", ""], ["Bartunov", "Sergey", ""], ["Nair", "Vinod", ""]]}, {"id": "2107.10209", "submitter": "Alex Tang", "authors": "Pranjal Awasthi, Alex Tang, Aravindan Vijayaraghavan", "title": "Efficient Algorithms for Learning Depth-2 Neural Networks with General\n  ReLU Activations", "comments": "36 pages (including appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present polynomial time and sample efficient algorithms for learning an\nunknown depth-2 feedforward neural network with general ReLU activations, under\nmild non-degeneracy assumptions. In particular, we consider learning an unknown\nnetwork of the form $f(x) = {a}^{\\mathsf{T}}\\sigma({W}^\\mathsf{T}x+b)$, where\n$x$ is drawn from the Gaussian distribution, and $\\sigma(t) := \\max(t,0)$ is\nthe ReLU activation. Prior works for learning networks with ReLU activations\nassume that the bias $b$ is zero. In order to deal with the presence of the\nbias terms, our proposed algorithm consists of robustly decomposing multiple\nhigher order tensors arising from the Hermite expansion of the function $f(x)$.\nUsing these ideas we also establish identifiability of the network parameters\nunder minimal assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:06:03 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Tang", "Alex", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "2107.10211", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Kyle Hsu, Jianing Li, Chelsea Finn, Roger Grosse", "title": "Differentiable Annealed Importance Sampling and the Perils of Gradient\n  Noise", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annealed importance sampling (AIS) and related algorithms are highly\neffective tools for marginal likelihood estimation, but are not fully\ndifferentiable due to the use of Metropolis-Hastings (MH) correction steps.\nDifferentiability is a desirable property as it would admit the possibility of\noptimizing marginal likelihood as an objective using gradient-based methods. To\nthis end, we propose a differentiable AIS algorithm by abandoning MH steps,\nwhich further unlocks mini-batch computation. We provide a detailed convergence\nanalysis for Bayesian linear regression which goes beyond previous analyses by\nexplicitly accounting for non-perfect transitions. Using this analysis, we\nprove that our algorithm is consistent in the full-batch setting and provide a\nsublinear convergence rate. However, we show that the algorithm is inconsistent\nwhen mini-batch gradients are used due to a fundamental incompatibility between\nthe goals of last-iterate convergence to the posterior and elimination of the\npathwise stochastic error. This result is in stark contrast to our experience\nwith stochastic optimization and stochastic gradient Langevin dynamics, where\nthe effects of gradient noise can be washed out by taking more steps of a\nsmaller size. Our negative result relies crucially on our explicit\nconsideration of convergence to the stationary distribution, and it helps\nexplain the difficulty of developing practically effective AIS-like algorithms\nthat exploit mini-batch gradients.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:10:14 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Zhang", "Guodong", ""], ["Hsu", "Kyle", ""], ["Li", "Jianing", ""], ["Finn", "Chelsea", ""], ["Grosse", "Roger", ""]]}, {"id": "2107.10234", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Fanglan Chen, Lei Zhang, Taoran Ji, Kaiqun Fu, Liang\n  Zhao, Feng Chen, Lingfei Wu, Charu Aggarwal and Chang-Tien Lu", "title": "Bridging the Gap between Spatial and Spectral Domains: A Theoretical\n  Framework for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decade, deep learning's performance has been widely\nrecognized in a variety of machine learning tasks, ranging from image\nclassification, speech recognition to natural language understanding. Graph\nneural networks (GNN) are a type of deep learning that is designed to handle\nnon-Euclidean issues using graph-structured data that are difficult to solve\nwith traditional deep learning techniques. The majority of GNNs were created\nusing a variety of processes, including random walk, PageRank, graph\nconvolution, and heat diffusion, making direct comparisons impossible. Previous\nstudies have primarily focused on classifying current models into distinct\ncategories, with little investigation of their internal relationships. This\nresearch proposes a unified theoretical framework and a novel perspective that\ncan methodologically integrate existing GNN into our framework. We survey and\ncategorize existing GNN models into spatial and spectral domains, as well as\nshow linkages between subcategories within each domain. Further investigation\nreveals a strong relationship between the spatial, spectral, and subgroups of\nthese domains.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:34:33 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Zhiqian", ""], ["Chen", "Fanglan", ""], ["Zhang", "Lei", ""], ["Ji", "Taoran", ""], ["Fu", "Kaiqun", ""], ["Zhao", "Liang", ""], ["Chen", "Feng", ""], ["Wu", "Lingfei", ""], ["Aggarwal", "Charu", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "2107.10236", "submitter": "Matthias Meyer", "authors": "Matthias Meyer, Michaela Wenner, Cl\\'ement Hibert, Fabian Walter,\n  Lothar Thiele", "title": "Using system context information to complement weakly labeled data", "comments": "Also appears in \"Proceedings of the First Workshop on Weakly\n  Supervised Learning (WeaSuL)\" arXiv:2107.03690", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world datasets collected with sensor networks often contain incomplete\nand uncertain labels as well as artefacts arising from the system environment.\nComplete and reliable labeling is often infeasible for large-scale and\nlong-term sensor network deployments due to the labor and time overhead,\nlimited availability of experts and missing ground truth. In addition, if the\nmachine learning method used for analysis is sensitive to certain features of a\ndeployment, labeling and learning needs to be repeated for every new\ndeployment. To address these challenges, we propose to make use of system\ncontext information formalized in an information graph and embed it in the\nlearning process via contrastive learning. Based on real-world data we show\nthat this approach leads to an increased accuracy in case of weakly labeled\ndata and leads to an increased robustness and transferability of the classifier\nto new sensor locations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 07:05:16 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Meyer", "Matthias", ""], ["Wenner", "Michaela", ""], ["Hibert", "Cl\u00e9ment", ""], ["Walter", "Fabian", ""], ["Thiele", "Lothar", ""]]}, {"id": "2107.10239", "submitter": "Aurelia Bustos", "authors": "Aurelia Bustos (1), Patricio Mas_Serrano (2 and 3), Mari L. Boquera\n  (2), Jose M. Salinas (4) ((1) MedBravo, (2) Hospital General Universitario de\n  Alicante Spain -HGUA, (3) Institute for Health and Biomedical Research of\n  Alicante -ISABIAL, (4) Department of Health Informatics, Hospital\n  Universitario San Juan de Alicante Spain)", "title": "Machine Learning for Real-World Evidence Analysis of COVID-19\n  Pharmacotherapy", "comments": "22 pages, 7 tables, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introduction: Real-world data generated from clinical practice can be used to\nanalyze the real-world evidence (RWE) of COVID-19 pharmacotherapy and validate\nthe results of randomized clinical trials (RCTs). Machine learning (ML) methods\nare being used in RWE and are promising tools for precision-medicine. In this\nstudy, ML methods are applied to study the efficacy of therapies on COVID-19\nhospital admissions in the Valencian Region in Spain. Methods: 5244 and 1312\nCOVID-19 hospital admissions - dated between January 2020 and January 2021 from\n10 health departments, were used respectively for training and validation of\nseparate treatment-effect models (TE-ML) for remdesivir, corticosteroids,\ntocilizumab, lopinavir-ritonavir, azithromycin and\nchloroquine/hydroxychloroquine. 2390 admissions from 2 additional health\ndepartments were reserved as an independent test to analyze retrospectively the\nsurvival benefits of therapies in the population selected by the TE-ML models\nusing cox-proportional hazard models. TE-ML models were adjusted using\ntreatment propensity scores to control for pre-treatment confounding variables\nassociated to outcome and further evaluated for futility. ML architecture was\nbased on boosted decision-trees. Results: In the populations identified by the\nTE-ML models, only Remdesivir and Tocilizumab were significantly associated\nwith an increase in survival time, with hazard ratios of 0.41 (P = 0.04) and\n0.21 (P = 0.001), respectively. No survival benefits from chloroquine\nderivatives, lopinavir-ritonavir and azithromycin were demonstrated. Tools to\nexplain the predictions of TE-ML models are explored at patient-level as\npotential tools for personalized decision making and precision medicine.\nConclusion: ML methods are suitable tools toward RWE analysis of COVID-19\npharmacotherapies. Results obtained reproduce published results on RWE and\nvalidate the results from RCTs.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:28:54 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bustos", "Aurelia", "", "2 and 3"], ["Mas_Serrano", "Patricio", "", "2 and 3"], ["Boquera", "Mari L.", ""], ["Salinas", "Jose M.", ""]]}, {"id": "2107.10243", "submitter": "Monik Behera Mr", "authors": "Monik Raj Behera, Sudhir Upadhyay and Suresh Shetty", "title": "Federated Learning using Smart Contracts on Blockchains, based on Reward\n  Driven Approach", "comments": "9 pages, 7 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the recent years, Federated machine learning continues to gain interest\nand momentum where there is a need to draw insights from data while preserving\nthe data provider's privacy. However, one among other existing challenges in\nthe adoption of federated learning has been the lack of fair, transparent and\nuniversally agreed incentivization schemes for rewarding the federated learning\ncontributors. Smart contracts on a blockchain network provide transparent,\nimmutable and independently verifiable proofs by all participants of the\nnetwork. We leverage this open and transparent nature of smart contracts on a\nblockchain to define incentivization rules for the contributors, which is based\non a novel scalar quantity - federated contribution. Such a smart contract\nbased reward-driven model has the potential to revolutionize the federated\nlearning adoption in enterprises. Our contribution is two-fold: first is to\nshow how smart contract based blockchain can be a very natural communication\nchannel for federated learning. Second, leveraging this infrastructure, we can\nshow how an intuitive measure of each agents' contribution can be built and\nintegrated with the life cycle of the training and reward process.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:51:22 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Behera", "Monik Raj", ""], ["Upadhyay", "Sudhir", ""], ["Shetty", "Suresh", ""]]}, {"id": "2107.10253", "submitter": "Karl Pertsch", "authors": "Karl Pertsch, Youngwoon Lee, Yue Wu, Joseph J. Lim", "title": "Demonstration-Guided Reinforcement Learning with Learned Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Demonstration-guided reinforcement learning (RL) is a promising approach for\nlearning complex behaviors by leveraging both reward feedback and a set of\ntarget task demonstrations. Prior approaches for demonstration-guided RL treat\nevery new task as an independent learning problem and attempt to follow the\nprovided demonstrations step-by-step, akin to a human trying to imitate a\ncompletely unseen behavior by following the demonstrator's exact muscle\nmovements. Naturally, such learning will be slow, but often new behaviors are\nnot completely unseen: they share subtasks with behaviors we have previously\nlearned. In this work, we aim to exploit this shared subtask structure to\nincrease the efficiency of demonstration-guided RL. We first learn a set of\nreusable skills from large offline datasets of prior experience collected\nacross many tasks. We then propose Skill-based Learning with Demonstrations\n(SkiLD), an algorithm for demonstration-guided RL that efficiently leverages\nthe provided demonstrations by following the demonstrated skills instead of the\nprimitive actions, resulting in substantial performance improvements over prior\ndemonstration-guided RL approaches. We validate the effectiveness of our\napproach on long-horizon maze navigation and complex robot manipulation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:59:34 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Pertsch", "Karl", ""], ["Lee", "Youngwoon", ""], ["Wu", "Yue", ""], ["Lim", "Joseph J.", ""]]}, {"id": "2107.10254", "submitter": "Brandon Amos", "authors": "Shobha Venkataraman, Brandon Amos", "title": "Neural Fixed-Point Acceleration for Convex Optimization", "comments": "AutoML@ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed-point iterations are at the heart of numerical computing and are often\na computational bottleneck in real-time applications that typically need a fast\nsolution of moderate accuracy. We present neural fixed-point acceleration which\ncombines ideas from meta-learning and classical acceleration methods to\nautomatically learn to accelerate fixed-point problems that are drawn from a\ndistribution. We apply our framework to SCS, the state-of-the-art solver for\nconvex cone programming, and design models and loss functions to overcome the\nchallenges of learning over unrolled optimization and acceleration\ninstabilities. Our work brings neural acceleration into any optimization\nproblem expressible with CVXPY. The source code behind this paper is available\nat https://github.com/facebookresearch/neural-scs\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:59:34 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 17:43:00 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Venkataraman", "Shobha", ""], ["Amos", "Brandon", ""]]}, {"id": "2107.10292", "submitter": "Carlos Olivares", "authors": "Carlos Olivares, Raziur Rahman, Christopher Stankus, Jade Hampton,\n  Andrew Zedwick, Moinuddin Ahmed", "title": "Predicting Power Electronics Device Reliability under Extreme Conditions\n  with Machine Learning Algorithms", "comments": "11 pages, 8 figures. Submitted to IEEE Transactions on Device and\n  Materials Reliability", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Power device reliability is a major concern during operation under extreme\nenvironments, as doing so reduces the operational lifetime of any power system\nor sensing infrastructure. Due to a potential for system failure, devices must\nbe experimentally validated before implementation, which is expensive and\ntime-consuming. In this paper, we have utilized machine learning algorithms to\npredict device reliability, significantly reducing the need for conducting\nexperiments. To train the models, we have tested 224 power devices from 10\ndifferent manufacturers. First, we describe a method to process the data for\nmodeling purposes. Based on the in-house testing data, we implemented various\nML models and observed that computational models such as Gradient Boosting and\nLSTM encoder-decoder networks can predict power device failure with high\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 18:17:32 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Olivares", "Carlos", ""], ["Rahman", "Raziur", ""], ["Stankus", "Christopher", ""], ["Hampton", "Jade", ""], ["Zedwick", "Andrew", ""], ["Ahmed", "Moinuddin", ""]]}, {"id": "2107.10295", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, Ashwin Srinivasan", "title": "How to Tell Deep Neural Networks What We Know", "comments": "12 pages (full version); substantial overlap with arXiv:2103.00180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a short survey of ways in which existing scientific knowledge are\nincluded when constructing models with neural networks. The inclusion of\ndomain-knowledge is of special interest not just to constructing scientific\nassistants, but also, many other areas that involve understanding data using\nhuman-machine collaboration. In many such instances, machine-based model\nconstruction may benefit significantly from being provided with human-knowledge\nof the domain encoded in a sufficiently precise form. This paper examines the\ninclusion of domain-knowledge by means of changes to: the input, the\nloss-function, and the architecture of deep networks. The categorisation is for\nease of exposition: in practice we expect a combination of such changes will be\nemployed. In each category, we describe techniques that have been shown to\nyield significant changes in network performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 18:18:02 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Chitlangia", "Sharad", ""], ["Ahuja", "Aditya", ""], ["Srinivasan", "Ashwin", ""]]}, {"id": "2107.10296", "submitter": "Minghan Zhu", "authors": "Minghan Zhu, Maani Ghaffari, Huei Peng", "title": "Correspondence-Free Point Cloud Registration with SO(3)-Equivariant\n  Implicit Shape Representations", "comments": "7 pages. 2 figures. Submitted to CoRL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a correspondence-free method for point cloud rotational\nregistration. We learn an embedding for each point cloud in a feature space\nthat preserves the SO(3)-equivariance property, enabled by recent developments\nin equivariant neural networks. The proposed shape registration method achieves\nthree major advantages through combining equivariant feature learning with\nimplicit shape models. First, the necessity of data association is removed\nbecause of the permutation-invariant property in network architectures similar\nto PointNet. Second, the registration in feature space can be solved in\nclosed-form using Horn's method due to the SO(3)-equivariance property. Third,\nthe registration is robust to noise in the point cloud because of implicit\nshape learning. The experimental results show superior performance compared\nwith existing correspondence-free deep registration methods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 18:18:21 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Zhu", "Minghan", ""], ["Ghaffari", "Maani", ""], ["Peng", "Huei", ""]]}, {"id": "2107.10297", "submitter": "Boris Ivanovic", "authors": "Boris Ivanovic and Marco Pavone", "title": "Rethinking Trajectory Forecasting Evaluation", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting the behavior of other agents is an integral part of the modern\nrobotic autonomy stack, especially in safety-critical scenarios with\nhuman-robot interaction, such as autonomous driving. In turn, there has been a\nsignificant amount of interest and research in trajectory forecasting,\nresulting in a wide variety of approaches. Common to all works, however, is the\nuse of the same few accuracy-based evaluation metrics, e.g., displacement error\nand log-likelihood. While these metrics are informative, they are task-agnostic\nand predictions that are evaluated as equal can lead to vastly different\noutcomes, e.g., in downstream planning and decision making. In this work, we\ntake a step back and critically evaluate current trajectory forecasting\nmetrics, proposing task-aware metrics as a better measure of performance in\nsystems where prediction is being deployed. We additionally present one example\nof such a metric, incorporating planning-awareness within existing trajectory\nforecasting metrics.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 18:20:03 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Ivanovic", "Boris", ""], ["Pavone", "Marco", ""]]}, {"id": "2107.10300", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha and Vinija Jain", "title": "iReason: Multimodal Commonsense Reasoning using Videos and Natural\n  Language with Interpretability", "comments": "12 pages, 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causality knowledge is vital to building robust AI systems. Deep learning\nmodels often perform poorly on tasks that require causal reasoning, which is\noften derived using some form of commonsense knowledge not immediately\navailable in the input but implicitly inferred by humans. Prior work has\nunraveled spurious observational biases that models fall prey to in the absence\nof causality. While language representation models preserve contextual\nknowledge within learned embeddings, they do not factor in causal relationships\nduring training. By blending causal relationships with the input features to an\nexisting model that performs visual cognition tasks (such as scene\nunderstanding, video captioning, video question-answering, etc.), better\nperformance can be achieved owing to the insight causal relationships bring\nabout. Recently, several models have been proposed that have tackled the task\nof mining causal data from either the visual or textual modality. However,\nthere does not exist widespread research that mines causal relationships by\njuxtaposing the visual and language modalities. While images offer a rich and\neasy-to-process resource for us to mine causality knowledge from, videos are\ndenser and consist of naturally time-ordered events. Also, textual information\noffers details that could be implicit in videos. We propose iReason, a\nframework that infers visual-semantic commonsense knowledge using both videos\nand natural language captions. Furthermore, iReason's architecture integrates a\ncausal rationalization module to aid the process of interpretability, error\nanalysis and bias detection. We demonstrate the effectiveness of iReason using\na two-pronged comparative analysis with language representation learning models\n(BERT, GPT-2) as well as current state-of-the-art multimodal causality models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 02:56:34 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Chadha", "Aman", ""], ["Jain", "Vinija", ""]]}, {"id": "2107.10302", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Maggie Delano, Bogdan Kulynych, Ram Shankar Siva Kumar", "title": "Adversarial for Good? How the Adversarial ML Community's Values Impede\n  Socially Beneficial Uses of Attacks", "comments": "Author list is ordered alphabetically as there is equal contribution.\n  4 pages Accepted by the ICML 2021 workshop on \"A Blessing in Disguise:The\n  Prospects and Perils of Adversarial Machine Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attacks from adversarial machine learning (ML) have the potential to be used\n\"for good\": they can be used to run counter to the existing power structures\nwithin ML, creating breathing space for those who would otherwise be the\ntargets of surveillance and control. But most research on adversarial ML has\nnot engaged in developing tools for resistance against ML systems. Why? In this\npaper, we review the broader impact statements that adversarial ML researchers\nwrote as part of their NeurIPS 2020 papers and assess the assumptions that\nauthors have about the goals of their work. We also collect information about\nhow authors view their work's impact more generally. We find that most\nadversarial ML researchers at NeurIPS hold two fundamental assumptions that\nwill make it difficult for them to consider socially beneficial uses of\nattacks: (1) it is desirable to make systems robust, independent of context,\nand (2) attackers of systems are normatively bad and defenders of systems are\nnormatively good. That is, despite their expressed and supposed neutrality,\nmost adversarial ML researchers believe that the goal of their work is to\nsecure systems, making it difficult to conceptualize and build tools for\ndisrupting the status quo.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:51:52 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Albert", "Kendra", ""], ["Delano", "Maggie", ""], ["Kulynych", "Bogdan", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2107.10306", "submitter": "Dan Wang", "authors": "Dan Wang, Zhi Chen, Ionut Florescu", "title": "A Sparsity Algorithm with Applications to Corporate Credit Rating", "comments": "16 pages, 11 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Artificial Intelligence, interpreting the results of a Machine Learning\ntechnique often termed as a black box is a difficult task. A counterfactual\nexplanation of a particular \"black box\" attempts to find the smallest change to\nthe input values that modifies the prediction to a particular output, other\nthan the original one. In this work we formulate the problem of finding a\ncounterfactual explanation as an optimization problem. We propose a new\n\"sparsity algorithm\" which solves the optimization problem, while also\nmaximizing the sparsity of the counterfactual explanation. We apply the\nsparsity algorithm to provide a simple suggestion to publicly traded companies\nin order to improve their credit ratings. We validate the sparsity algorithm\nwith a synthetically generated dataset and we further apply it to quarterly\nfinancial statements from companies in financial, healthcare and IT sectors of\nthe US market. We provide evidence that the counterfactual explanation can\ncapture the nature of the real statement features that changed between the\ncurrent quarter and the following quarter when ratings improved. The empirical\nresults show that the higher the rating of a company the greater the \"effort\"\nrequired to further improve credit rating.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 18:47:35 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wang", "Dan", ""], ["Chen", "Zhi", ""], ["Florescu", "Ionut", ""]]}, {"id": "2107.10314", "submitter": "Christopher Schr\\\"oder", "authors": "Christopher Schr\\\"oder, Lydia M\\\"uller, Andreas Niekler, Martin\n  Potthast", "title": "Small-text: Active Learning for Text Classification in Python", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present small-text, a simple modular active learning library, which offers\npool-based active learning for text classification in Python. It comes with\nvarious pre-implemented state-of-the-art query strategies, including some which\ncan leverage the GPU. Clearly defined interfaces allow to combine a multitude\nof such query strategies with different classifiers, thereby facilitating a\nquick mix and match, and enabling a rapid development of both active learning\nexperiments and applications. To make various classifiers accessible in a\nconsistent way, it integrates several well-known machine learning libraries,\nnamely, scikit-learn, PyTorch, and huggingface transformers -- for which the\nlatter integrations are available as optionally installable extensions. The\nlibrary is available under the MIT License at\nhttps://github.com/webis-de/small-text.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 19:23:56 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Schr\u00f6der", "Christopher", ""], ["M\u00fcller", "Lydia", ""], ["Niekler", "Andreas", ""], ["Potthast", "Martin", ""]]}, {"id": "2107.10326", "submitter": "Ali Balali", "authors": "Ali Balali, Masoud Asadpour, Seyed Hossein Jafari", "title": "COfEE: A Comprehensive Ontology for Event Extraction from text, with an\n  online annotation tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is published on the web over time in great volumes, but majority of the\ndata is unstructured, making it hard to understand and difficult to interpret.\nInformation Extraction (IE) methods extract structured information from\nunstructured data. One of the challenging IE tasks is Event Extraction (EE)\nwhich seeks to derive information about specific incidents and their actors\nfrom the text. EE is useful in many domains such as building a knowledge base,\ninformation retrieval, summarization and online monitoring systems. In the past\ndecades, some event ontologies like ACE, CAMEO and ICEWS were developed to\ndefine event forms, actors and dimensions of events observed in the text. These\nevent ontologies still have some shortcomings such as covering only a few\ntopics like political events, having inflexible structure in defining argument\nroles, lack of analytical dimensions, and complexity in choosing event\nsub-types. To address these concerns, we propose an event ontology, namely\nCOfEE, that incorporates both expert domain knowledge, previous ontologies and\na data-driven approach for identifying events from text. COfEE consists of two\nhierarchy levels (event types and event sub-types) that include new categories\nrelating to environmental issues, cyberspace, criminal activity and natural\ndisasters which need to be monitored instantly. Also, dynamic roles according\nto each event sub-type are defined to capture various dimensions of events. In\na follow-up experiment, the proposed ontology is evaluated on Wikipedia events,\nand it is shown to be general and comprehensive. Moreover, in order to\nfacilitate the preparation of gold-standard data for event extraction, a\nlanguage-independent online tool is presented based on COfEE.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 19:43:22 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Balali", "Ali", ""], ["Asadpour", "Masoud", ""], ["Jafari", "Seyed Hossein", ""]]}, {"id": "2107.10332", "submitter": "Abicumaran Uthamacumaran", "authors": "Abicumaran Uthamacumaran, Samir Elouatik, Mohamed Abdouh, Michael\n  Berteau-Rainville, Zhu- Hua Gao, and Goffredo Arena", "title": "Machine Learning Characterization of Cancer Patients-Derived\n  Extracellular Vesicles using Vibrational Spectroscopies", "comments": "50 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.AI cs.LG physics.bio-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The early detection of cancer is a challenging problem in medicine. The blood\nsera of cancer patients are enriched with heterogeneous secretory lipid bound\nextracellular vesicles (EVs), which present a complex repertoire of information\nand biomarkers, representing their cell of origin, that are being currently\nstudied in the field of liquid biopsy and cancer screening. Vibrational\nspectroscopies provide non-invasive approaches for the assessment of structural\nand biophysical properties in complex biological samples. In this study,\nmultiple Raman spectroscopy measurements were performed on the EVs extracted\nfrom the blood sera of 9 patients consisting of four different cancer subtypes\n(colorectal cancer, hepatocellular carcinoma, breast cancer and pancreatic\ncancer) and five healthy patients (controls). FTIR(Fourier Transform Infrared)\nspectroscopy measurements were performed as a complementary approach to Raman\nanalysis, on two of the four cancer subtypes.\n  The AdaBoost Random Forest Classifier, Decision Trees, and Support Vector\nMachines (SVM) distinguished the baseline corrected Raman spectra of cancer EVs\nfrom those of healthy controls (18 spectra) with a classification accuracy of\ngreater than 90% when reduced to a spectral frequency range of 1800 to 1940\ninverse cm, and subjected to a 0.5 training/testing split. FTIR classification\naccuracy on 14 spectra showed an 80% classification accuracy. Our findings\ndemonstrate that basic machine learning algorithms are powerful tools to\ndistinguish the complex vibrational spectra of cancer patient EVs from those of\nhealthy patients. These experimental methods hold promise as valid and\nefficient liquid biopsy for machine intelligence-assisted early cancer\nscreening.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 19:56:33 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Uthamacumaran", "Abicumaran", ""], ["Elouatik", "Samir", ""], ["Abdouh", "Mohamed", ""], ["Berteau-Rainville", "Michael", ""], ["Gao", "Zhu- Hua", ""], ["Arena", "Goffredo", ""]]}, {"id": "2107.10370", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani, Michael Field", "title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural\n  Networks", "comments": "arXiv admin note: text overlap with arXiv:2008.01805", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimization problem associated with fitting two-layer ReLU\nneural networks with respect to the squared loss, where labels are generated by\na target network. We make use of the rich symmetry structure to develop a novel\nset of tools for studying families of spurious minima. In contrast to existing\napproaches which operate in limiting regimes, our technique directly addresses\nthe nonconvex loss landscape for a finite number of inputs $d$ and neurons $k$,\nand provides analytic, rather than heuristic, information. In particular, we\nderive analytic estimates for the loss at different minima, and prove that\nmodulo $O(d^{-1/2})$-terms the Hessian spectrum concentrates near small\npositive constants, with the exception of $\\Theta(d)$ eigenvalues which grow\nlinearly with~$d$. We further show that the Hessian spectrum at global and\nspurious minima coincide to $O(d^{-1/2})$-order, thus challenging our ability\nto argue about statistical generalization through local curvature. Lastly, our\ntechnique provides the exact \\emph{fractional} dimensionality at which families\nof critical points turn from saddles into spurious minima. This makes possible\nthe study of the creation and the annihilation of spurious minima using\npowerful tools from equivariant bifurcation theory.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 22:05:48 GMT"}], "update_date": "2021-07-24", "authors_parsed": [["Arjevani", "Yossi", ""], ["Field", "Michael", ""]]}, {"id": "2107.10383", "submitter": "Venkata Sriram Siddhardh Nadendla", "authors": "Nathan Lutes and K. Krishnamurthy and Venkata Sriram Siddhardh\n  Nadendla and S. N. Balakrishnan", "title": "Online-Learning Deep Neuro-Adaptive Dynamic Inversion Controller for\n  Model Free Control", "comments": "8 pages, 4 fugures, manuscript under review for CDC'2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive methods are popular within the control literature due to the\nflexibility and forgiveness they offer in the area of modelling. Neural network\nadaptive control is favorable specifically for the powerful nature of the\nmachine learning algorithm to approximate unknown functions and for the ability\nto relax certain constraints within traditional adaptive control. Deep neural\nnetworks are large framework networks with vastly superior approximation\ncharacteristics than their shallow counterparts. However, implementing a deep\nneural network can be difficult due to size specific complications such as\nvanishing/exploding gradients in training. In this paper, a neuro-adaptive\ncontroller is implemented featuring a deep neural network trained on a new\nweight update law that escapes the vanishing/exploding gradient problem by only\nincorporating the sign of the gradient. The type of controller designed is an\nadaptive dynamic inversion controller utilizing a modified state observer in a\nsecondary estimation loop to train the network. The deep neural network learns\nthe entire plant model on-line, creating a controller that is completely model\nfree. The controller design is tested in simulation on a 2 link planar robot\narm. The controller is able to learn the nonlinear plant quickly and displays\ngood performance in the tracking control problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 22:46:03 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lutes", "Nathan", ""], ["Krishnamurthy", "K.", ""], ["Nadendla", "Venkata Sriram Siddhardh", ""], ["Balakrishnan", "S. N.", ""]]}, {"id": "2107.10384", "submitter": "Eyke H\\\"ullermeier", "authors": "Mohammad Hossein Shaker and Eyke H\\\"ullermeier", "title": "Ensemble-based Uncertainty Quantification: Bayesian versus Credal\n  Inference", "comments": "arXiv admin note: text overlap with arXiv:2001.00893", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The idea to distinguish and quantify two important types of uncertainty,\noften referred to as aleatoric and epistemic, has received increasing attention\nin machine learning research in the last couple of years. In this paper, we\nconsider ensemble-based approaches to uncertainty quantification.\nDistinguishing between different types of uncertainty-aware learning\nalgorithms, we specifically focus on Bayesian methods and approaches based on\nso-called credal sets, which naturally suggest themselves from an ensemble\nlearning point of view. For both approaches, we address the question of how to\nquantify aleatoric and epistemic uncertainty. The effectiveness of\ncorresponding measures is evaluated and compared in an empirical study on\nclassification with a reject option.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 22:47:24 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shaker", "Mohammad Hossein", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2107.10387", "submitter": "Steven Spurgeon", "authors": "Christina Doty, Shaun Gallagher, Wenqi Cui, Wenya Chen, Shweta\n  Bhushan, Marjolein Oostrom, Sarah Akers, Steven R. Spurgeon", "title": "Design of a Graphical User Interface for Few-Shot Machine Learning\n  Classification of Electron Microscopy Data", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent growth in data volumes produced by modern electron microscopes\nrequires rapid, scalable, and flexible approaches to image segmentation and\nanalysis. Few-shot machine learning, which can richly classify images from a\nhandful of user-provided examples, is a promising route to high-throughput\nanalysis. However, current command-line implementations of such approaches can\nbe slow and unintuitive to use, lacking the real-time feedback necessary to\nperform effective classification. Here we report on the development of a\nPython-based graphical user interface that enables end users to easily conduct\nand visualize the output of few-shot learning models. This interface is\nlightweight and can be hosted locally or on the web, providing the opportunity\nto reproducibly conduct, share, and crowd-source few-shot analyses.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 23:02:33 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Doty", "Christina", ""], ["Gallagher", "Shaun", ""], ["Cui", "Wenqi", ""], ["Chen", "Wenya", ""], ["Bhushan", "Shweta", ""], ["Oostrom", "Marjolein", ""], ["Akers", "Sarah", ""], ["Spurgeon", "Steven R.", ""]]}, {"id": "2107.10394", "submitter": "Yinghao Aaron Li", "authors": "Yinghao Aaron Li, Ali Zare, Nima Mesgarani", "title": "StarGANv2-VC: A Diverse, Unsupervised, Non-parallel Framework for\n  Natural-Sounding Voice Conversion", "comments": "INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an unsupervised non-parallel many-to-many voice conversion (VC)\nmethod using a generative adversarial network (GAN) called StarGAN v2. Using a\ncombination of adversarial source classifier loss and perceptual loss, our\nmodel significantly outperforms previous VC models. Although our model is\ntrained only with 20 English speakers, it generalizes to a variety of voice\nconversion tasks, such as any-to-many, cross-lingual, and singing conversion.\nUsing a style encoder, our framework can also convert plain reading speech into\nstylistic speech, such as emotional and falsetto speech. Subjective and\nobjective evaluation experiments on a non-parallel many-to-many voice\nconversion task revealed that our model produces natural sounding voices, close\nto the sound quality of state-of-the-art text-to-speech (TTS) based voice\nconversion methods without the need for text labels. Moreover, our model is\ncompletely convolutional and with a faster-than-real-time vocoder such as\nParallel WaveGAN can perform real-time voice conversion.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 23:44:17 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 01:08:09 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Li", "Yinghao Aaron", ""], ["Zare", "Ali", ""], ["Mesgarani", "Nima", ""]]}, {"id": "2107.10397", "submitter": "Mohammadhossein Toutiaee", "authors": "Mohammadhossein Toutiaee, Xiaochuan Li, Yogesh Chaudhari, Shophine\n  Sivaraja, Aishwarya Venkataraj, Indrajeet Javeri, Yuan Ke, Ismailcem Arpinar,\n  Nicole Lazar, John Miller", "title": "Improving COVID-19 Forecasting using eXogenous Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the pandemic course in the United States by\nconsidering national and state levels data. We propose and compare multiple\ntime-series prediction techniques which incorporate auxiliary variables. One\ntype of approach is based on spatio-temporal graph neural networks which\nforecast the pandemic course by utilizing a hybrid deep learning architecture\nand human mobility data. Nodes in this graph represent the state-level deaths\ndue to COVID-19, edges represent the human mobility trend and temporal edges\ncorrespond to node attributes across time. The second approach is based on a\nstatistical technique for COVID-19 mortality prediction in the United States\nthat uses the SARIMA model and eXogenous variables. We evaluate these\ntechniques on both state and national levels COVID-19 data in the United States\nand claim that the SARIMA and MCP models generated forecast values by the\neXogenous variables can enrich the underlying model to capture complexity in\nrespectively national and state levels data. We demonstrate significant\nenhancement in the forecasting accuracy for a COVID-19 dataset, with a maximum\nimprovement in forecasting accuracy by 64.58% and 59.18% (on average) over the\nGCN-LSTM model in the national level data, and 58.79% and 52.40% (on average)\nover the GCN-LSTM model in the state level data. Additionally, our proposed\nmodel outperforms a parallel study (AUG-NN) by 27.35% improvement of accuracy\non average.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 03:26:18 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Toutiaee", "Mohammadhossein", ""], ["Li", "Xiaochuan", ""], ["Chaudhari", "Yogesh", ""], ["Sivaraja", "Shophine", ""], ["Venkataraj", "Aishwarya", ""], ["Javeri", "Indrajeet", ""], ["Ke", "Yuan", ""], ["Arpinar", "Ismailcem", ""], ["Lazar", "Nicole", ""], ["Miller", "John", ""]]}, {"id": "2107.10398", "submitter": "\\'Oscar Escudero Arnanz", "authors": "\\'Oscar Escudero-Arnanz, Joaqu\\'in Rodr\\'iguez-\\'Alvarez, Karl\n  {\\O}yvind Mikalsen, Robert Jenssen, Cristina Soguero-Ruiz", "title": "On the Use of Time Series Kernel and Dimensionality Reduction to\n  Identify the Acquisition of Antimicrobial Multidrug Resistance in the\n  Intensive Care Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.med-ph q-bio.PE stat.AP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The acquisition of Antimicrobial Multidrug Resistance (AMR) in patients\nadmitted to the Intensive Care Units (ICU) is a major global concern. This\nstudy analyses data in the form of multivariate time series (MTS) from 3476\npatients recorded at the ICU of University Hospital of Fuenlabrada (Madrid)\nfrom 2004 to 2020. 18\\% of the patients acquired AMR during their stay in the\nICU. The goal of this paper is an early prediction of the development of AMR.\nTowards that end, we leverage the time-series cluster kernel (TCK) to learn\nsimilarities between MTS. To evaluate the effectiveness of TCK as a kernel, we\napplied several dimensionality reduction techniques for visualization and\nclassification tasks. The experimental results show that TCK allows identifying\na group of patients that acquire the AMR during the first 48 hours of their ICU\nstay, and it also provides good classification capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:44:55 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Escudero-Arnanz", "\u00d3scar", ""], ["Rodr\u00edguez-\u00c1lvarez", "Joaqu\u00edn", ""], ["Mikalsen", "Karl \u00d8yvind", ""], ["Jenssen", "Robert", ""], ["Soguero-Ruiz", "Cristina", ""]]}, {"id": "2107.10399", "submitter": "Anna Fedyukova", "authors": "Anna Fedyukova, Douglas Pires, Daniel Capurro", "title": "Quantifying machine learning-induced overdiagnosis in sepsis", "comments": "3 pages, 1 figure, Joint KDD 2021 Health Day and 2021 KDD Workshop on\n  Applied Data Science for Healthcare, August 14-18, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of early diagnostic technologies, including self-monitoring\nsystems and wearables, coupled with the application of these technologies on\nlarge segments of healthy populations may significantly aggravate the problem\nof overdiagnosis. This can lead to unwanted consequences such as overloading\nhealth care systems and overtreatment, with potential harms to healthy\nindividuals. The advent of machine-learning tools to assist diagnosis -- while\npromising rapid and more personalised patient management and screening -- might\ncontribute to this issue. The identification of overdiagnosis is usually post\nhoc and demonstrated after long periods (from years to decades) and costly\nrandomised control trials. In this paper, we present an innovative approach\nthat allows us to preemptively detect potential cases of overdiagnosis during\npredictive model development. This approach is based on the combination of\nlabels obtained from a prediction model and clustered medical trajectories,\nusing sepsis in adults as a test case. This is one of the first attempts to\nquantify machine-learning induced overdiagnosis and we believe will serves as a\nplatform for further development, leading to guidelines for safe deployment of\ncomputational diagnostic tools.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:55:55 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fedyukova", "Anna", ""], ["Pires", "Douglas", ""], ["Capurro", "Daniel", ""]]}, {"id": "2107.10400", "submitter": "Elijah Cole", "authors": "Sara Beery, Elijah Cole, Joseph Parker, Pietro Perona, Kevin Winner", "title": "Species Distribution Modeling for Machine Learning Practitioners: A\n  Review", "comments": "ACM COMPASS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conservation science depends on an accurate understanding of what's happening\nin a given ecosystem. How many species live there? What is the makeup of the\npopulation? How is that changing over time? Species Distribution Modeling (SDM)\nseeks to predict the spatial (and sometimes temporal) patterns of species\noccurrence, i.e. where a species is likely to be found. The last few years have\nseen a surge of interest in applying powerful machine learning tools to\nchallenging problems in ecology. Despite its considerable importance, SDM has\nreceived relatively little attention from the computer science community. Our\ngoal in this work is to provide computer scientists with the necessary\nbackground to read the SDM literature and develop ecologically useful ML-based\nSDM algorithms. In particular, we introduce key SDM concepts and terminology,\nreview standard models, discuss data availability, and highlight technical\nchallenges and pitfalls.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 17:50:34 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Beery", "Sara", ""], ["Cole", "Elijah", ""], ["Parker", "Joseph", ""], ["Perona", "Pietro", ""], ["Winner", "Kevin", ""]]}, {"id": "2107.10424", "submitter": "Chaoran Cui", "authors": "Chaoran Cui, Jian Zong, Yuling Ma, Xinhua Wang, Lei Guo, Meng Chen,\n  Yilong Yin", "title": "Tri-Branch Convolutional Neural Networks for Top-$k$ Focused Academic\n  Performance Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic performance prediction aims to leverage student-related information\nto predict their future academic outcomes, which is beneficial to numerous\neducational applications, such as personalized teaching and academic early\nwarning. In this paper, we address the problem by analyzing students' daily\nbehavior trajectories, which can be comprehensively tracked with campus\nsmartcard records. Different from previous studies, we propose a novel\nTri-Branch CNN architecture, which is equipped with row-wise, column-wise, and\ndepth-wise convolution and attention operations, to capture the characteristics\nof persistence, regularity, and temporal distribution of student behavior in an\nend-to-end manner, respectively. Also, we cast academic performance prediction\nas a top-$k$ ranking problem, and introduce a top-$k$ focused loss to ensure\nthe accuracy of identifying academically at-risk students. Extensive\nexperiments were carried out on a large-scale real-world dataset, and we show\nthat our approach substantially outperforms recently proposed methods for\nacademic performance prediction. For the sake of reproducibility, our codes\nhave been released at\nhttps://github.com/ZongJ1111/Academic-Performance-Prediction.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 02:35:36 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cui", "Chaoran", ""], ["Zong", "Jian", ""], ["Ma", "Yuling", ""], ["Wang", "Xinhua", ""], ["Guo", "Lei", ""], ["Chen", "Meng", ""], ["Yin", "Yilong", ""]]}, {"id": "2107.10428", "submitter": "Xiaohu Zheng", "authors": "Xiaohu Zheng, Jun Zhang, Ning Wang, Guijian Tang, Wen Yao", "title": "Mini-data-driven Deep Arbitrary Polynomial Chaos Expansion for\n  Uncertainty Quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The surrogate model-based uncertainty quantification method has drawn a lot\nof attention in recent years. Both the polynomial chaos expansion (PCE) and the\ndeep learning (DL) are powerful methods for building a surrogate model.\nHowever, the PCE needs to increase the expansion order to improve the accuracy\nof the surrogate model, which causes more labeled data to solve the expansion\ncoefficients, and the DL also needs a lot of labeled data to train the neural\nnetwork model. This paper proposes a deep arbitrary polynomial chaos expansion\n(Deep aPCE) method to improve the balance between surrogate model accuracy and\ntraining data cost. On the one hand, the multilayer perceptron (MLP) model is\nused to solve the adaptive expansion coefficients of arbitrary polynomial chaos\nexpansion, which can improve the Deep aPCE model accuracy with lower expansion\norder. On the other hand, the adaptive arbitrary polynomial chaos expansion's\nproperties are used to construct the MLP training cost function based on only a\nsmall amount of labeled data and a large scale of non-labeled data, which can\nsignificantly reduce the training data cost. Four numerical examples and an\nactual engineering problem are used to verify the effectiveness of the Deep\naPCE method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 02:49:07 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Zheng", "Xiaohu", ""], ["Zhang", "Jun", ""], ["Wang", "Ning", ""], ["Tang", "Guijian", ""], ["Yao", "Wen", ""]]}, {"id": "2107.10429", "submitter": "Roberto Perera", "authors": "Libo Sun, James Browning, Roberto Perera", "title": "Shedding some light on Light Up with Artificial Intelligence", "comments": "14 pages, 16 figures, for associated codes, see\n  \\<https://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Light-Up puzzle, also known as the AKARI puzzle, has never been solved\nusing modern artificial intelligence (AI) methods. Currently, the most widely\nused computational technique to autonomously develop solutions involve\nevolution theory algorithms. This project is an effort to apply new AI\ntechniques for solving the Light-up puzzle faster and more computationally\nefficient. The algorithms explored for producing optimal solutions include hill\nclimbing, simulated annealing, feed-forward neural network (FNN), and\nconvolutional neural network (CNN). Two algorithms were developed for hill\nclimbing and simulated annealing using 2 actions (add and remove light bulb)\nversus 3 actions(add, remove, or move light-bulb to a different cell). Both\nhill climbing and simulated annealing algorithms showed a higher accuracy for\nthe case of 3 actions. The simulated annealing showed to significantly\noutperform hill climbing, FNN, CNN, and an evolutionary theory algorithm\nachieving 100% accuracy in 30 unique board configurations. Lastly, while FNN\nand CNN algorithms showed low accuracies, computational times were\nsignificantly faster compared to the remaining algorithms. The GitHub\nrepository for this project can be found at\nhttps://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 03:03:57 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sun", "Libo", ""], ["Browning", "James", ""], ["Perera", "Roberto", ""]]}, {"id": "2107.10443", "submitter": "Eugene Bagdasaryan", "authors": "Eugene Bagdasaryan and Vitaly Shmatikov", "title": "Spinning Sequence-to-Sequence Models with Meta-Backdoors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to \"spin\" their output and support a\ncertain sentiment when the input contains adversary-chosen trigger words. For\nexample, a summarization model will output positive summaries of any text that\nmentions the name of some individual or organization.\n  We introduce the concept of a \"meta-backdoor\" to explain model-spinning\nattacks. These attacks produce models whose output is valid and preserves\ncontext, yet also satisfies a meta-task chosen by the adversary (e.g., positive\nsentiment). Previously studied backdoors in language models simply flip\nsentiment labels or replace words without regard to context. Their outputs are\nincorrect on inputs with the trigger. Meta-backdoors, on the other hand, are\nthe first class of backdoors that can be deployed against seq2seq models to (a)\nintroduce adversary-chosen spin into the output, while (b) maintaining standard\naccuracy metrics.\n  To demonstrate feasibility of model spinning, we develop a new backdooring\ntechnique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto\na seq2seq model, backpropagates the desired meta-task output (e.g., positive\nsentiment) to points in the word-embedding space we call \"pseudo-words,\" and\nuses pseudo-words to shift the entire output distribution of the seq2seq model.\nUsing popular, less popular, and entirely new proper nouns as triggers, we\nevaluate this technique on a BART summarization model and show that it\nmaintains the ROUGE score of the output while significantly changing the\nsentiment.\n  We explain why model spinning can be a dangerous technique in AI-powered\ndisinformation and discuss how to mitigate these attacks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 03:41:52 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2107.10449", "submitter": "Zhendong Chu", "authors": "Zhendong Chu, Hongning Wang", "title": "Improve Learning from Crowds via Generative Augmentation", "comments": "KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467409", "report-no": null, "categories": "cs.LG cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crowdsourcing provides an efficient label collection schema for supervised\nmachine learning. However, to control annotation cost, each instance in the\ncrowdsourced data is typically annotated by a small number of annotators. This\ncreates a sparsity issue and limits the quality of machine learning models\ntrained on such data. In this paper, we study how to handle sparsity in\ncrowdsourced data using data augmentation. Specifically, we propose to directly\nlearn a classifier by augmenting the raw sparse annotations. We implement two\nprinciples of high-quality augmentation using Generative Adversarial Networks:\n1) the generated annotations should follow the distribution of authentic ones,\nwhich is measured by a discriminator; 2) the generated annotations should have\nhigh mutual information with the ground-truth labels, which is measured by an\nauxiliary network. Extensive experiments and comparisons against an array of\nstate-of-the-art learning from crowds methods on three real-world datasets\nproved the effectiveness of our data augmentation framework. It shows the\npotential of our algorithm for low-budget crowdsourcing in general.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 04:14:30 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Chu", "Zhendong", ""], ["Wang", "Hongning", ""]]}, {"id": "2107.10450", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Davin Choo, Rishikesh Gajjala, Sutanu Gayen,\n  Yuhao Wang", "title": "Learning Sparse Fixed-Structure Gaussian Bayesian Networks", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian Bayesian networks (a.k.a. linear Gaussian structural equation\nmodels) are widely used to model causal interactions among continuous\nvariables. In this work, we study the problem of learning a fixed-structure\nGaussian Bayesian network up to a bounded error in total variation distance. We\nanalyze the commonly used node-wise least squares regression (LeastSquares) and\nprove that it has a near-optimal sample complexity. We also study a couple of\nnew algorithms for the problem:\n  - BatchAvgLeastSquares takes the average of several batches of least squares\nsolutions at each node, so that one can interpolate between the batch size and\nthe number of batches. We show that BatchAvgLeastSquares also has near-optimal\nsample complexity.\n  - CauchyEst takes the median of solutions to several batches of linear\nsystems at each node. We show that the algorithm specialized to polytrees,\nCauchyEstTree, has near-optimal sample complexity.\n  Experimentally, we show that for uncontaminated, realizable data, the\nLeastSquares algorithm performs best, but in the presence of contamination or\nDAG misspecification, CauchyEst/CauchyEstTree and BatchAvgLeastSquares\nrespectively perform better.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 04:17:46 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Choo", "Davin", ""], ["Gajjala", "Rishikesh", ""], ["Gayen", "Sutanu", ""], ["Wang", "Yuhao", ""]]}, {"id": "2107.10457", "submitter": "Hao Li", "authors": "Fan Wu, Min Gao, Junliang Yu, Zongwei Wang, Kecheng Liu and Xu Wange", "title": "Ready for Emerging Threats to Recommender Systems? A Graph\n  Convolution-based Generative Shilling Attack", "comments": "16 pages, 21 figures, Information Sciences - Journal - Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explore the robustness of recommender systems, researchers have proposed\nvarious shilling attack models and analyzed their adverse effects. Primitive\nattacks are highly feasible but less effective due to simplistic handcrafted\nrules, while upgraded attacks are more powerful but costly and difficult to\ndeploy because they require more knowledge from recommendations. In this paper,\nwe explore a novel shilling attack called Graph cOnvolution-based generative\nshilling ATtack (GOAT) to balance the attacks' feasibility and effectiveness.\nGOAT adopts the primitive attacks' paradigm that assigns items for fake users\nby sampling and the upgraded attacks' paradigm that generates fake ratings by a\ndeep learning-based model. It deploys a generative adversarial network (GAN)\nthat learns the real rating distribution to generate fake ratings.\nAdditionally, the generator combines a tailored graph convolution structure\nthat leverages the correlations between co-rated items to smoothen the fake\nratings and enhance their authenticity. The extensive experiments on two public\ndatasets evaluate GOAT's performance from multiple perspectives. Our study of\nthe GOAT demonstrates technical feasibility for building a more powerful and\nintelligent attack model with a much-reduced cost, enables analysis the threat\nof such an attack and guides for investigating necessary prevention measures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 05:02:59 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wu", "Fan", ""], ["Gao", "Min", ""], ["Yu", "Junliang", ""], ["Wang", "Zongwei", ""], ["Liu", "Kecheng", ""], ["Wange", "Xu", ""]]}, {"id": "2107.10469", "submitter": "Karn Watcharasupat", "authors": "Thi Ngoc Tho Nguyen and Karn N. Watcharasupat and Zhen Jian Lee and\n  Ngoc Khanh Nguyen and Douglas L. Jones and Woon Seng Gan", "title": "What Makes Sound Event Localization and Detection Difficult? Insights\n  from Error Analysis", "comments": "Under review for the 6th Workshop on Detection and Classification of\n  Acoustic Scenes and Events (DCASE), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sound event localization and detection (SELD) is an emerging research topic\nthat aims to unify the tasks of sound event detection and direction-of-arrival\nestimation. As a result, SELD inherits the challenges of both tasks, such as\nnoise, reverberation, interference, polyphony, and non-stationarity of sound\nsources. Furthermore, SELD often faces an additional challenge of assigning\ncorrect correspondences between the detected sound classes and directions of\narrival to multiple overlapping sound events. Previous studies have shown that\nunknown interferences in reverberant environments often cause major degradation\nin the performance of SELD systems. To further understand the challenges of the\nSELD task, we performed a detailed error analysis on two of our SELD systems,\nwhich both ranked second in the team category of DCASE SELD Challenge, one in\n2020 and one in 2021. Experimental results indicate polyphony as the main\nchallenge in SELD, due to the difficulty in detecting all sound events of\ninterest. In addition, the SELD systems tend to make fewer errors for the\npolyphonic scenario that is dominant in the training set.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:01:49 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Nguyen", "Thi Ngoc Tho", ""], ["Watcharasupat", "Karn N.", ""], ["Lee", "Zhen Jian", ""], ["Nguyen", "Ngoc Khanh", ""], ["Jones", "Douglas L.", ""], ["Gan", "Woon Seng", ""]]}, {"id": "2107.10471", "submitter": "Karn Watcharasupat", "authors": "Karn N. Watcharasupat and Thi Ngoc Tho Nguyen and Ngoc Khanh Nguyen\n  and Zhen Jian Lee and Douglas L. Jones and Woon Seng Gan", "title": "Improving Polyphonic Sound Event Detection on Multichannel Recordings\n  with the S{\\o}rensen-Dice Coefficient Loss and Transfer Learning", "comments": "Under review for the 6th Workshop on Detection and Classification of\n  Acoustic Scenes and Events (DCASE), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The S{\\o}rensen--Dice Coefficient has recently seen rising popularity as a\nloss function (also known as Dice loss) due to its robustness in tasks where\nthe number of negative samples significantly exceeds that of positive samples,\nsuch as semantic segmentation, natural language processing, and sound event\ndetection. Conventional training of polyphonic sound event detection systems\nwith binary cross-entropy loss often results in suboptimal detection\nperformance as the training is often overwhelmed by updates from negative\nsamples. In this paper, we investigated the effect of the Dice loss, intra- and\ninter-modal transfer learning, data augmentation, and recording formats, on the\nperformance of polyphonic sound event detection systems with multichannel\ninputs. Our analysis showed that polyphonic sound event detection systems\ntrained with Dice loss consistently outperformed those trained with\ncross-entropy loss across different training settings and recording formats in\nterms of F1 score and error rate. We achieved further performance gains via the\nuse of transfer learning and an appropriate combination of different data\naugmentation techniques.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:14:23 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Watcharasupat", "Karn N.", ""], ["Nguyen", "Thi Ngoc Tho", ""], ["Nguyen", "Ngoc Khanh", ""], ["Lee", "Zhen Jian", ""], ["Jones", "Douglas L.", ""], ["Gan", "Woon Seng", ""]]}, {"id": "2107.10474", "submitter": "Jung Hoon Lee", "authors": "Junghoon Lee, Jounghee Kim, Pilsung Kang", "title": "Back-Translated Task Adaptive Pretraining: Improving Accuracy and\n  Robustness on Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models (LMs) pretrained on a large text corpus and fine-tuned on a\ndownstream text corpus and fine-tuned on a downstream task becomes a de facto\ntraining strategy for several natural language processing (NLP) tasks.\nRecently, an adaptive pretraining method retraining the pretrained language\nmodel with task-relevant data has shown significant performance improvements.\nHowever, current adaptive pretraining methods suffer from underfitting on the\ntask distribution owing to a relatively small amount of data to re-pretrain the\nLM. To completely use the concept of adaptive pretraining, we propose a\nback-translated task-adaptive pretraining (BT-TAPT) method that increases the\namount of task-specific data for LM re-pretraining by augmenting the task data\nusing back-translation to generalize the LM to the target task domain. The\nexperimental results show that the proposed BT-TAPT yields improved\nclassification accuracy on both low- and high-resource data and better\nrobustness to noise than the conventional adaptive pretraining method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:27:35 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lee", "Junghoon", ""], ["Kim", "Jounghee", ""], ["Kang", "Pilsung", ""]]}, {"id": "2107.10478", "submitter": "Anjali P", "authors": "P. Anjali, Deepak N. Subramani", "title": "Inter and Intra-Annual Spatio-Temporal Variability of Habitat\n  Suitability for Asian Elephants in India: A Random Forest Model-based\n  Analysis", "comments": "Submitted for possible publication in the IEEE International India\n  Geoscience and Remote Sensing Symposium 2021 (InGARSS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We develop a Random Forest model to estimate the species distribution of\nAsian elephants in India and study the inter and intra-annual spatiotemporal\nvariability of habitats suitable for them. Climatic, topographic variables and\nsatellite-derived Land Use/Land Cover (LULC), Net Primary Productivity (NPP),\nLeaf Area Index (LAI), and Normalized Difference Vegetation Index (NDVI) are\nused as predictors, and the species sighting data of Asian elephants from\nGlobal Biodiversity Information Reserve is used to develop the Random Forest\nmodel. A careful hyper-parameter tuning and training-validation-testing cycle\nare completed to identify the significant predictors and develop a final model\nthat gives precision and recall of 0.78 and 0.77. The model is applied to\nestimate the spatial and temporal variability of suitable habitats. We observe\nthat seasonal reduction in the suitable habitat may explain the migration\npatterns of Asian elephants and the increasing human-elephant conflict.\nFurther, the total available suitable habitat area is observed to have reduced,\nwhich exacerbates the problem. This machine learning model is intended to serve\nas an input to the Agent-Based Model that we are building as part of our\nArtificial Intelligence-driven decision support tool to reduce human-wildlife\nconflict.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:42:54 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Anjali", "P.", ""], ["Subramani", "Deepak N.", ""]]}, {"id": "2107.10480", "submitter": "Gihyuk Ko", "authors": "Gihyuk Ko, Gyumin Lim", "title": "Unsupervised Detection of Adversarial Examples with Model Explanations", "comments": "AdvML@KDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) have shown remarkable performance in a diverse\nrange of machine learning applications. However, it is widely known that DNNs\nare vulnerable to simple adversarial perturbations, which causes the model to\nincorrectly classify inputs. In this paper, we propose a simple yet effective\nmethod to detect adversarial examples, using methods developed to explain the\nmodel's behavior. Our key observation is that adding small, humanly\nimperceptible perturbations can lead to drastic changes in the model\nexplanations, resulting in unusual or irregular forms of explanations. From\nthis insight, we propose an unsupervised detection of adversarial examples\nusing reconstructor networks trained only on model explanations of benign\nexamples. Our evaluations with MNIST handwritten dataset show that our method\nis capable of detecting adversarial examples generated by the state-of-the-art\nalgorithms with high confidence. To the best of our knowledge, this work is the\nfirst in suggesting unsupervised defense method using model explanations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:54:18 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Ko", "Gihyuk", ""], ["Lim", "Gyumin", ""]]}, {"id": "2107.10483", "submitter": "Phillip Lippe", "authors": "Phillip Lippe, Taco Cohen, Efstratios Gavves", "title": "Efficient Neural Causal Discovery without Acyclicity Constraints", "comments": "8th Causal Inference Workshop at UAI 2021 (contributed talk). 34\n  pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning the structure of a causal graphical model using both observational\nand interventional data is a fundamental problem in many scientific fields. A\npromising direction is continuous optimization for score-based methods, which\nefficiently learn the causal graph in a data-driven manner. However, to date,\nthose methods require constrained optimization to enforce acyclicity or lack\nconvergence guarantees. In this paper, we present ENCO, an efficient structure\nlearning method for directed, acyclic causal graphs leveraging observational\nand interventional data. ENCO formulates the graph search as an optimization of\nindependent edge likelihoods, with the edge orientation being modeled as a\nseparate parameter. Consequently, we can provide convergence guarantees of ENCO\nunder mild conditions without constraining the score function with respect to\nacyclicity. In experiments, we show that ENCO can efficiently recover graphs\nwith hundreds of nodes, an order of magnitude larger than what was previously\npossible, while handling deterministic variables and latent confounders.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:01:41 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lippe", "Phillip", ""], ["Cohen", "Taco", ""], ["Gavves", "Efstratios", ""]]}, {"id": "2107.10484", "submitter": "Mingyuan Bai", "authors": "Mingyuan Bai, S.T. Boris Choy, Junping Zhang, Junbin Gao", "title": "Neural Ordinary Differential Equation Model for Evolutionary Subspace\n  Clustering and Its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The neural ordinary differential equation (neural ODE) model has attracted\nincreasing attention in time series analysis for its capability to process\nirregular time steps, i.e., data are not observed over equally-spaced time\nintervals. In multi-dimensional time series analysis, a task is to conduct\nevolutionary subspace clustering, aiming at clustering temporal data according\nto their evolving low-dimensional subspace structures. Many existing methods\ncan only process time series with regular time steps while time series are\nunevenly sampled in many situations such as missing data. In this paper, we\npropose a neural ODE model for evolutionary subspace clustering to overcome\nthis limitation and a new objective function with subspace self-expressiveness\nconstraint is introduced. We demonstrate that this method can not only\ninterpolate data at any time step for the evolutionary subspace clustering\ntask, but also achieve higher accuracy than other state-of-the-art evolutionary\nsubspace clustering methods. Both synthetic and real-world data are used to\nillustrate the efficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:02:03 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Bai", "Mingyuan", ""], ["Choy", "S. T. Boris", ""], ["Zhang", "Junping", ""], ["Gao", "Junbin", ""]]}, {"id": "2107.10492", "submitter": "Aditya Gopalan", "authors": "Aditya Gopalan, Venkatesh Saligrama and Braghadeesh Lakshminarayanan", "title": "Bandit Quickest Changepoint Detection", "comments": "26 pages including appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting abrupt changes in temporal behavior patterns is of interest in many\nindustrial and security applications. Abrupt changes are often local and\nobservable primarily through a well-aligned sensing action (e.g., a camera with\na narrow field-of-view). Due to resource constraints, continuous monitoring of\nall of the sensors is impractical. We propose the bandit quickest changepoint\ndetection framework as a means of balancing sensing cost with detection delay.\nIn this framework, sensing actions (or sensors) are sequentially chosen, and\nonly measurements corresponding to chosen actions are observed. We derive an\ninformation-theoretic lower bound on the detection delay for a general class of\nfinitely parameterized probability distributions. We then propose a\ncomputationally efficient online sensing scheme, which seamlessly balances the\nneed for exploration of different sensing options with exploitation of querying\ninformative actions. We derive expected delay bounds for the proposed scheme\nand show that these bounds match our information-theoretic lower bounds at low\nfalse alarm rates, establishing optimality of the proposed method. We then\nperform a number of experiments on synthetic and real datasets demonstrating\nthe efficacy of our proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:25:35 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Gopalan", "Aditya", ""], ["Saligrama", "Venkatesh", ""], ["Lakshminarayanan", "Braghadeesh", ""]]}, {"id": "2107.10493", "submitter": "Sihyun Yu", "authors": "Sihyun Yu, Sangwoo Mo, Sungsoo Ahn, Jinwoo Shin", "title": "Abstract Reasoning via Logic-guided Generation", "comments": "ICML 2021 Workshop on Self-Supervised Learning for Reasoning and\n  Perception (Spotlight Talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract reasoning, i.e., inferring complicated patterns from given\nobservations, is a central building block of artificial general intelligence.\nWhile humans find the answer by either eliminating wrong candidates or first\nconstructing the answer, prior deep neural network (DNN)-based methods focus on\nthe former discriminative approach. This paper aims to design a framework for\nthe latter approach and bridge the gap between artificial and human\nintelligence. To this end, we propose logic-guided generation (LoGe), a novel\ngenerative DNN framework that reduces abstract reasoning as an optimization\nproblem in propositional logic. LoGe is composed of three steps: extract\npropositional variables from images, reason the answer variables with a logic\nlayer, and reconstruct the answer image from the variables. We demonstrate that\nLoGe outperforms the black box DNN frameworks for generative abstract reasoning\nunder the RAVEN benchmark, i.e., reconstructing answers based on capturing\ncorrect rules of various attributes from observations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:28:24 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Yu", "Sihyun", ""], ["Mo", "Sangwoo", ""], ["Ahn", "Sungsoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2107.10495", "submitter": "Roland Albert Romero", "authors": "Roland Albert A. Romero, Mariefel Nicole Y. Deypalan, Suchit Mehrotra,\n  John Titus Jungao, Natalie E. Sheils, Elisabetta Manduchi and Jason H. Moore", "title": "Benchmarking AutoML Frameworks for Disease Prediction Using Medical\n  Claims", "comments": "22 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We ascertain and compare the performances of AutoML tools on large, highly\nimbalanced healthcare datasets.\n  We generated a large dataset using historical administrative claims including\ndemographic information and flags for disease codes in four different time\nwindows prior to 2019. We then trained three AutoML tools on this dataset to\npredict six different disease outcomes in 2019 and evaluated model performances\non several metrics.\n  The AutoML tools showed improvement from the baseline random forest model but\ndid not differ significantly from each other. All models recorded low area\nunder the precision-recall curve and failed to predict true positives while\nkeeping the true negative rate high. Model performance was not directly related\nto prevalence. We provide a specific use-case to illustrate how to select a\nthreshold that gives the best balance between true and false positive rates, as\nthis is an important consideration in medical applications.\n  Healthcare datasets present several challenges for AutoML tools, including\nlarge sample size, high imbalance, and limitations in the available features\ntypes. Improvements in scalability, combinations of imbalance-learning\nresampling and ensemble approaches, and curated feature selection are possible\nnext steps to achieve better performance.\n  Among the three explored, no AutoML tool consistently outperforms the rest in\nterms of predictive performance. The performances of the models in this study\nsuggest that there may be room for improvement in handling medical claims data.\nFinally, selection of the optimal prediction threshold should be guided by the\nspecific practical application.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:34:48 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Romero", "Roland Albert A.", ""], ["Deypalan", "Mariefel Nicole Y.", ""], ["Mehrotra", "Suchit", ""], ["Jungao", "John Titus", ""], ["Sheils", "Natalie E.", ""], ["Manduchi", "Elisabetta", ""], ["Moore", "Jason H.", ""]]}, {"id": "2107.10504", "submitter": "Isaac Sledge", "authors": "Isaac J. Sledge, Christopher D. Toole, Joseph A. Maestri, and Jose C.\n  Principe", "title": "External-Memory Networks for Low-Shot Learning of Targets in\n  Forward-Looking-Sonar Imagery", "comments": "Submitted to IEEE Journal of Oceanic Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a memory-based framework for real-time, data-efficient target\nanalysis in forward-looking-sonar (FLS) imagery. Our framework relies on first\nremoving non-discriminative details from the imagery using a small-scale\nDenseNet-inspired network. Doing so simplifies ensuing analyses and permits\ngeneralizing from few labeled examples. We then cascade the filtered imagery\ninto a novel NeuralRAM-based convolutional matching network, NRMN, for low-shot\ntarget recognition. We employ a small-scale FlowNet, LFN to align and register\nFLS imagery across local temporal scales. LFN enables target label consensus\nvoting across images and generally improves target detection and recognition\nrates.\n  We evaluate our framework using real-world FLS imagery with multiple broad\ntarget classes that have high intra-class variability and rich sub-class\nstructure. We show that few-shot learning, with anywhere from ten to thirty\nclass-specific exemplars, performs similarly to supervised deep networks\ntrained on hundreds of samples per class. Effective zero-shot learning is also\npossible. High performance is realized from the inductive-transfer properties\nof NRMNs when distractor elements are removed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 07:50:44 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sledge", "Isaac J.", ""], ["Toole", "Christopher D.", ""], ["Maestri", "Joseph A.", ""], ["Principe", "Jose C.", ""]]}, {"id": "2107.10507", "submitter": "Joachim Sprave", "authors": "Joachim Sprave, Christian Drescher", "title": "Evaluating the Quality of Finite Element Meshes with Machine Learning", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of evaluating the quality of finite element\nmeshes for the purpose of structural mechanic simulations. It proposes the\napplication of a machine learning model trained on data collected from expert\nevaluations. The task is characterised as a classification problem, where\nquality of each individual element in a mesh is determined by its own\nproperties and adjacency structures. A domain-specific, yet simple\nrepresentation is proposed such that off-the-shelf machine learning methods can\nbe applied. Experimental data from industry practice demonstrates promising\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 08:06:09 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sprave", "Joachim", ""], ["Drescher", "Christian", ""]]}, {"id": "2107.10536", "submitter": "Radu Tudor Ionescu", "authors": "Cezara Benegui, Radu Tudor Ionescu", "title": "Improving the Authentication with Built-in Camera Protocol Using\n  Built-in Motion Sensors: A Deep Learning Solution", "comments": "Accepted for publication in Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose an enhanced version of the Authentication with Built-in Camera\n(ABC) protocol by employing a deep learning solution based on built-in motion\nsensors. The standard ABC protocol identifies mobile devices based on the\nphoto-response non-uniformity (PRNU) of the camera sensor, while also\nconsidering QR-code-based meta-information. During authentication, the user is\nrequired to take two photos that contain two QR codes presented on a screen.\nThe presented QR code images also contain a unique probe signal, similar to a\ncamera fingerprint, generated by the protocol. During verification, the server\ncomputes the fingerprint of the received photos and authenticates the user if\n(i) the probe signal is present, (ii) the metadata embedded in the QR codes is\ncorrect and (iii) the camera fingerprint is identified correctly. However, the\nprotocol is vulnerable to forgery attacks when the attacker can compute the\ncamera fingerprint from external photos, as shown in our preliminary work. In\nthis context, we propose an enhancement for the ABC protocol based on motion\nsensor data, as an additional and passive authentication layer. Smartphones can\nbe identified through their motion sensor data, which, unlike photos, is never\nposted by users on social media platforms, thus being more secure than using\nphotographs alone. To this end, we transform motion signals into embedding\nvectors produced by deep neural networks, applying Support Vector Machines for\nthe smartphone identification task. Our change to the ABC protocol results in a\nmulti-modal protocol that lowers the false acceptance rate for the attack\nproposed in our previous work to a percentage as low as 0.07%.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 09:26:53 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 05:26:42 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 13:26:23 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Benegui", "Cezara", ""], ["Ionescu", "Radu Tudor", ""]]}, {"id": "2107.10554", "submitter": "Keenan Jones", "authors": "Keenan Jones, Jason R. C. Nurse, Shujun Li", "title": "Out of the Shadows: Analyzing Anonymous' Twitter Resurgence during the\n  2020 Black Lives Matter Protests", "comments": "12 pages, 9 figures, 3 tables. Accepted for publication in the\n  proceedings of the sixteenth International AAAI Conference on Web and Social\n  Media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there had been little notable activity from the once prominent\nhacktivist group, Anonymous. The group, responsible for activist-based cyber\nattacks on major businesses and governments, appeared to have fragmented after\nkey members were arrested in 2013. In response to the major Black Lives Matter\n(BLM) protests that occurred after the killing of George Floyd, however,\nreports indicated that the group was back. To examine this apparent resurgence,\nwe conduct a large-scale study of Anonymous affiliates on Twitter. To this end,\nwe first use machine learning to identify a significant network of more than\n33,000 Anonymous accounts. Through topic modelling of tweets collected from\nthese accounts, we find evidence of sustained interest in topics related to\nBLM. We then use sentiment analysis on tweets focused on these topics, finding\nevidence of a united approach amongst the group, with positive tweets typically\nbeing used to express support towards BLM, and negative tweets typically being\nused to criticize police actions. Finally, we examine the presence of\nautomation in the network, identifying indications of bot-like behavior across\nthe majority of Anonymous accounts. These findings show that whilst the group\nhas seen a resurgence during the protests, bot activity may be responsible for\nexaggerating the extent of this resurgence.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:18:32 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Jones", "Keenan", ""], ["Nurse", "Jason R. C.", ""], ["Li", "Shujun", ""]]}, {"id": "2107.10558", "submitter": "Kostas Kolomvatsos", "authors": "Kostas Kolomvatsos, Christos Anagnostopoulos", "title": "A Proactive Management Scheme for Data Synopses at the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of the infrastructure provided by the Internet of Things\n(IoT) with numerous processing nodes present at the Edge Computing (EC)\necosystem opens up new pathways to support intelligent applications. Such\napplications can be provided upon humongous volumes of data collected by IoT\ndevices being transferred to the edge nodes through the network. Various\nprocessing activities can be performed on the discussed data and multiple\ncollaborative opportunities between EC nodes can facilitate the execution of\nthe desired tasks. In order to support an effective interaction between edge\nnodes, the knowledge about the geographically distributed data should be\nshared. Obviously, the migration of large amounts of data will harm the\nstability of the network stability and its performance. In this paper, we\nrecommend the exchange of data synopses than real data between EC nodes to\nprovide them with the necessary knowledge about peer nodes owning similar data.\nThis knowledge can be valuable when considering decisions such as data/service\nmigration and tasks offloading. We describe an continuous reasoning model that\nbuilds a temporal similarity map of the available datasets to get nodes\nunderstanding the evolution of data in their peers. We support the proposed\ndecision making mechanism through an intelligent similarity extraction scheme\nbased on an unsupervised machine learning model, and, at the same time, combine\nit with a statistical measure that represents the trend of the so-called\ndiscrepancy quantum. Our model can reveal the differences in the exchanged\nsynopses and provide a datasets similarity map which becomes the appropriate\nknowledge base to support the desired processing activities. We present the\nproblem under consideration and suggest a solution for that, while, at the same\ntime, we reveal its advantages and disadvantages through a large number of\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:22:37 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kolomvatsos", "Kostas", ""], ["Anagnostopoulos", "Christos", ""]]}, {"id": "2107.10567", "submitter": "Kyu Beom Lee", "authors": "Kyu-Beom Lee and Hyu-Soung Shin", "title": "An overcome of far-distance limitation on tunnel CCTV-based accident\n  detection in AI deep-learning frameworks", "comments": "6 pages, 3 figures, to be presented in \"2021 INTERNATIONAL CONFERENCE\n  ON TUNNELS AND UNDERGROUND SPACES\" conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Tunnel CCTVs are installed to low height and long-distance interval. However,\nbecause of the limitation of installation height, severe perspective effect in\ndistance occurs, and it is almost impossible to detect vehicles in far distance\nfrom the CCTV in the existing tunnel CCTV-based accident detection system\n(Pflugfelder 2005). To overcome the limitation, a vehicle object is detected\nthrough an object detection algorithm based on an inverse perspective transform\nby re-setting the region of interest (ROI). It can detect vehicles that are far\naway from the CCTV. To verify this process, this paper creates each dataset\nconsisting of images and bounding boxes based on the original and warped images\nof the CCTV at the same time, and then compares performance of the deep\nlearning object detection models trained with the two datasets. As a result,\nthe model that trained the warped image was able to detect vehicle objects more\naccurately at the position far from the CCTV compared to the model that trained\nthe original image.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:42:25 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Lee", "Kyu-Beom", ""], ["Shin", "Hyu-Soung", ""]]}, {"id": "2107.10585", "submitter": "Iaroslav Okunevich", "authors": "Iaroslav Okunevich, Daria Trinitatova, Pavel Kopanev, and Dzmitry\n  Tsetserukou", "title": "MobileCharger: an Autonomous Mobile Robot with Inverted Delta Actuator\n  for Robust and Safe Robot Charging", "comments": "Accepted to 26th International Conference on Emerging Technologies\n  and Factory Automation (ETFA) 2021, IEEE copyright, 8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MobileCharger is a novel mobile charging robot with an Inverted Delta\nactuator for safe and robust energy transfer between two mobile robots. The\nRGB-D camera-based computer vision system allows to detect the electrodes on\nthe target mobile robot using a convolutional neural network (CNN). The\nembedded high-fidelity tactile sensors are applied to estimate the misalignment\nbetween the electrodes on the charger mechanism and the electrodes on the main\nrobot using CNN based on pressure data on the contact surfaces. Thus, the\ndeveloped vision-tactile perception system allows precise positioning of the\nend effector of the actuator and ensures a reliable connection between the\nelectrodes of the two robots. The experimental results showed high average\nprecision (84.2%) for electrode detection using CNN. The percentage of\nsuccessful trials of the CNN-based electrode search algorithm reached 83% and\nthe average execution time accounted for 60 s. MobileCharger could introduce a\nnew level of charging systems and increase the prevalence of autonomous mobile\nrobots.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 11:30:25 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 10:02:43 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Okunevich", "Iaroslav", ""], ["Trinitatova", "Daria", ""], ["Kopanev", "Pavel", ""], ["Tsetserukou", "Dzmitry", ""]]}, {"id": "2107.10599", "submitter": "Ramin Barati", "authors": "Ramin Barati, Reza Safabakhsh, Mohammad Rahmati", "title": "Towards Explaining Adversarial Examples Phenomenon in Artificial Neural\n  Networks", "comments": "submitted to 25th International Conference on Pattern Recognition\n  (ICPR)", "journal-ref": null, "doi": "10.1109/ICPR48806.2021.9412367", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the adversarial examples existence and adversarial\ntraining from the standpoint of convergence and provide evidence that pointwise\nconvergence in ANNs can explain these observations. The main contribution of\nour proposal is that it relates the objective of the evasion attacks and\nadversarial training with concepts already defined in learning theory. Also, we\nextend and unify some of the other proposals in the literature and provide\nalternative explanations on the observations made in those proposals. Through\ndifferent experiments, we demonstrate that the framework is valuable in the\nstudy of the phenomenon and is applicable to real-world problems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 11:56:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Barati", "Ramin", ""], ["Safabakhsh", "Reza", ""], ["Rahmati", "Mohammad", ""]]}, {"id": "2107.10606", "submitter": "Gautier Marti", "authors": "Gautier Marti, Victor Goubet, Frank Nielsen", "title": "cCorrGAN: Conditional Correlation GAN for Learning Empirical Conditional\n  Distributions in the Elliptope", "comments": "International Conference on Geometric Science of Information", "journal-ref": "GSI 2021: Geometric Science of Information pp 613-620", "doi": "10.1007/978-3-030-80209-7_66", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a methodology to approximate conditional distributions in the\nelliptope of correlation matrices based on conditional generative adversarial\nnetworks. We illustrate the methodology with an application from quantitative\nfinance: Monte Carlo simulations of correlated returns to compare risk-based\nportfolio construction methods. Finally, we discuss about current limitations\nand advocate for further exploration of the elliptope geometry to improve\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 12:17:23 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Marti", "Gautier", ""], ["Goubet", "Victor", ""], ["Nielsen", "Frank", ""]]}, {"id": "2107.10607", "submitter": "Moritz Ibing", "authors": "Moritz Ibing, Isaak Lim, Leif Kobbelt", "title": "3D Shape Generation with Grid-based Implicit Functions", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous approaches to generate shapes in a 3D setting train a GAN on the\nlatent space of an autoencoder (AE). Even though this produces convincing\nresults, it has two major shortcomings. As the GAN is limited to reproduce the\ndataset the AE was trained on, we cannot reuse a trained AE for novel data.\nFurthermore, it is difficult to add spatial supervision into the generation\nprocess, as the AE only gives us a global representation. To remedy these\nissues, we propose to train the GAN on grids (i.e. each cell covers a part of a\nshape). In this representation each cell is equipped with a latent vector\nprovided by an AE. This localized representation enables more expressiveness\n(since the cell-based latent vectors can be combined in novel ways) as well as\nspatial control of the generation process (e.g. via bounding boxes). Our method\noutperforms the current state of the art on all established evaluation\nmeasures, proposed for quantitatively evaluating the generative capabilities of\nGANs. We show limitations of these measures and propose the adaptation of a\nrobust criterion from statistical analysis as an alternative.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 12:23:38 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Ibing", "Moritz", ""], ["Lim", "Isaak", ""], ["Kobbelt", "Leif", ""]]}, {"id": "2107.10609", "submitter": "Edward Elson Kosasih", "authors": "Ajmal Aziz, Edward Elson Kosasih, Ryan-Rhys Griffiths, Alexandra\n  Brintrup", "title": "Data Considerations in Graph Representation Learning for Supply Chain\n  Networks", "comments": "ICML 2021 Workshop on Machine Learning for Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply chain network data is a valuable asset for businesses wishing to\nunderstand their ethical profile, security of supply, and efficiency.\nPossession of a dataset alone however is not a sufficient enabler of actionable\ndecisions due to incomplete information. In this paper, we present a graph\nrepresentation learning approach to uncover hidden dependency links that focal\ncompanies may not be aware of. To the best of our knowledge, our work is the\nfirst to represent a supply chain as a heterogeneous knowledge graph with\nlearnable embeddings. We demonstrate that our representation facilitates\nstate-of-the-art performance on link prediction of a global automotive supply\nchain network using a relational graph convolutional network. It is anticipated\nthat our method will be directly applicable to businesses wishing to sever\nlinks with nefarious entities and mitigate risk of supply failure. More\nabstractly, it is anticipated that our method will be useful to inform\nrepresentation learning of supply chain networks for downstream tasks beyond\nlink prediction.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 12:28:15 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Aziz", "Ajmal", ""], ["Kosasih", "Edward Elson", ""], ["Griffiths", "Ryan-Rhys", ""], ["Brintrup", "Alexandra", ""]]}, {"id": "2107.10624", "submitter": "Pavlo Molchanov", "authors": "Pavlo Molchanov and Jimmy Hall and Hongxu Yin and Jan Kautz and Nicolo\n  Fusi and Arash Vahdat", "title": "HANT: Hardware-Aware Network Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a trained network, how can we accelerate it to meet efficiency needs\nfor deployment on particular hardware? The commonly used hardware-aware network\ncompression techniques address this question with pruning, kernel fusion,\nquantization and lowering precision. However, these approaches do not change\nthe underlying network operations. In this paper, we propose hardware-aware\nnetwork transformation (HANT), which accelerates a network by replacing\ninefficient operations with more efficient alternatives using a neural\narchitecture search like approach. HANT tackles the problem in two phase: In\nthe first phase, a large number of alternative operations per every layer of\nthe teacher model is trained using layer-wise feature map distillation. In the\nsecond phase, the combinatorial selection of efficient operations is relaxed to\nan integer optimization problem that can be solved in a few seconds. We extend\nHANT with kernel fusion and quantization to improve throughput even further.\nOur experimental results on accelerating the EfficientNet family show that HANT\ncan accelerate them by up to 3.6x with <0.4% drop in the top-1 accuracy on the\nImageNet dataset. When comparing the same latency level, HANT can accelerate\nEfficientNet-B4 to the same latency as EfficientNet-B1 while having 3% higher\naccuracy. We examine a large pool of operations, up to 197 per layer, and we\nprovide insights into the selected operations and final architectures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:46:34 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Molchanov", "Pavlo", ""], ["Hall", "Jimmy", ""], ["Yin", "Hongxu", ""], ["Kautz", "Jan", ""], ["Fusi", "Nicolo", ""], ["Vahdat", "Arash", ""]]}, {"id": "2107.10637", "submitter": "Ilnar Salimzianov", "authors": "Ilnar Salimzianov", "title": "A baseline model for computationally inexpensive speech recognition for\n  Kazakh using the Coqui STT framework", "comments": "4 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Mobile devices are transforming the way people interact with computers, and\nspeech interfaces to applications are ever more important. Automatic Speech\nRecognition systems recently published are very accurate, but often require\npowerful machinery (specialised Graphical Processing Units) for inference,\nwhich makes them impractical to run on commodity devices, especially in\nstreaming mode. Impressed by the accuracy of, but dissatisfied with the\ninference times of the baseline Kazakh ASR model of (Khassanov et al.,2021)\nwhen not using a GPU, we trained a new baseline acoustic model (on the same\ndataset as the aforementioned paper) and three language models for use with the\nCoqui STT framework. Results look promising, but further epochs of training and\nparameter sweeping or, alternatively, limiting the vocabulary that the ASR\nsystem must support, is needed to reach a production-level accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:17:42 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Salimzianov", "Ilnar", ""]]}, {"id": "2107.10640", "submitter": "Bogdan Burlacu", "authors": "Bogdan Burlacu, Lukas Kammerer, Michael Affenzeller, Gabriel\n  Kronberger", "title": "Hash-Based Tree Similarity and Simplification in Genetic Programming for\n  Symbolic Regression", "comments": "International Conference on Computer Aided Systems Theory, EUROCAST\n  2019", "journal-ref": "In: Moreno-D\\'iaz R. et al. Computer Aided Systems Theory. Lecture\n  Notes in Computer Science, Vol. 12013. Springer, 2020, pp 361-369", "doi": "10.1007/2F978-3-030-45093-9_44", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce in this paper a runtime-efficient tree hashing algorithm for the\nidentification of isomorphic subtrees, with two important applications in\ngenetic programming for symbolic regression: fast, online calculation of\npopulation diversity and algebraic simplification of symbolic expression trees.\nBased on this hashing approach, we propose a simple diversity-preservation\nmechanism with promising results on a collection of symbolic regression\nbenchmark problems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 13:22:06 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Burlacu", "Bogdan", ""], ["Kammerer", "Lukas", ""], ["Affenzeller", "Michael", ""], ["Kronberger", "Gabriel", ""]]}, {"id": "2107.10647", "submitter": "Joaquin Cordero", "authors": "Joaqu\\'in Cordero, Alfredo Bolt and Mauricio Valle", "title": "An\\'alisis de Canasta de mercado en supermercados mediante mapas\n  auto-organizados", "comments": "18 pages, in Spanish, 7 Figures, 5 tables, Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introduction: An important chain of supermarkets in the western zone of the\ncapital of Chile, needs to obtain key information to make decisions, this\ninformation is available in the databases but needs to be processed due to the\ncomplexity and quantity of information which becomes difficult to visualiz,.\nMethod: For this purpose, an algorithm was developed using artificial neural\nnetworks applying Kohonen's SOM method. To carry it out, certain key procedures\nmust be followed to develop it, such as data mining that will be responsible\nfor filtering and then use only the relevant data for market basket analysis.\nAfter filtering the information, the data must be prepared. After data\npreparation, we prepared the Python programming environment to adapt it to the\nsample data, then proceed to train the SOM with its parameters set after test\nresults. Result: the result of the SOM obtains the relationship between the\nproducts that were most purchased by positioning them topologically close, to\nform promotions, packs and bundles for the retail manager to take into\nconsideration, because these relationships were obtained as a result of the SOM\ntraining with the real transactions of the clients. Conclusion: Based on this,\nrecommendations on frequent shopping baskets have been made to the supermarket\nchain that provided the data used in the research\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:52:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cordero", "Joaqu\u00edn", ""], ["Bolt", "Alfredo", ""], ["Valle", "Mauricio", ""]]}, {"id": "2107.10650", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim and Varun Ganapathi", "title": "Read, Attend, and Code: Pushing the Limits of Medical Codes Prediction\n  from Clinical Notes by Machines", "comments": "To appear in Proceedings of Machine Learning Research, Volume 149:\n  Machine Learning for Healthcare Conference (MLHC), Virtual, August 6-7, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of medical codes from clinical notes is both a practical and\nessential need for every healthcare delivery organization within current\nmedical systems. Automating annotation will save significant time and excessive\neffort spent by human coders today. However, the biggest challenge is directly\nidentifying appropriate medical codes out of several thousands of\nhigh-dimensional codes from unstructured free-text clinical notes. In the past\nthree years, with Convolutional Neural Networks (CNN) and Long Short-Term\nMemory (LTSM) networks, there have been vast improvements in tackling the most\nchallenging benchmark of the MIMIC-III-full-label inpatient clinical notes\ndataset. This progress raises the fundamental question of how far automated\nmachine learning (ML) systems are from human coders' working performance. We\nassessed the baseline of human coders' performance on the same subsampled\ntesting set. We also present our Read, Attend, and Code (RAC) model for\nlearning the medical code assignment mappings. By connecting convolved\nembeddings with self-attention and code-title guided attention modules,\ncombined with sentence permutation-based data augmentations and stochastic\nweight averaging training, RAC establishes a new state of the art (SOTA),\nconsiderably outperforming the current best Macro-F1 by 18.7%, and reaches past\nthe human-level coding baseline. This new milestone marks a meaningful step\ntoward fully autonomous medical coding (AMC) in machines reaching parity with\nhuman coders' performance in medical code prediction.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 06:01:58 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kim", "Byung-Hak", ""], ["Ganapathi", "Varun", ""]]}, {"id": "2107.10651", "submitter": "Erniel Barrios", "authors": "Dominic B. Dayta and Erniel B. Barrios", "title": "Semiparametric Latent Topic Modeling on Consumer-Generated Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Legacy procedures for topic modelling have generally suffered problems of\noverfitting and a weakness towards reconstructing sparse topic structures. With\nmotivation from a consumer-generated corpora, this paper proposes\nsemiparametric topic model, a two-step approach utilizing nonnegative matrix\nfactorization and semiparametric regression in topic modeling. The model\nenables the reconstruction of sparse topic structures in the corpus and\nprovides a generative model for predicting topics in new documents entering the\ncorpus. Assuming the presence of auxiliary information related to the topics,\nthis approach exhibits better performance in discovering underlying topic\nstructures in cases where the corpora are small and limited in vocabulary. In\nan actual consumer feedback corpus, the model also demonstrably provides\ninterpretable and useful topic definitions comparable with those produced by\nother methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 00:22:02 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Dayta", "Dominic B.", ""], ["Barrios", "Erniel B.", ""]]}, {"id": "2107.10652", "submitter": "Rajvir Kaur", "authors": "Rajvir Kaur, Jeewani Anupama Ginige and Oliver Obst", "title": "A Systematic Literature Review of Automated ICD Coding and\n  Classification Systems using Discharge Summaries", "comments": "33 pages, 1 figure. Under review in the Journal of Artificial\n  Intelligence in Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Codification of free-text clinical narratives have long been recognised to be\nbeneficial for secondary uses such as funding, insurance claim processing and\nresearch. The current scenario of assigning codes is a manual process which is\nvery expensive, time-consuming and error prone. In recent years, many\nresearchers have studied the use of Natural Language Processing (NLP), related\nMachine Learning (ML) and Deep Learning (DL) methods and techniques to resolve\nthe problem of manual coding of clinical narratives and to assist human coders\nto assign clinical codes more accurately and efficiently. This systematic\nliterature review provides a comprehensive overview of automated clinical\ncoding systems that utilises appropriate NLP, ML and DL methods and techniques\nto assign ICD codes to discharge summaries. We have followed the Preferred\nReporting Items for Systematic Reviews and Meta-Analyses(PRISMA) guidelines and\nconducted a comprehensive search of publications from January, 2010 to December\n2020 in four academic databases- PubMed, ScienceDirect, Association for\nComputing Machinery(ACM) Digital Library, and the Association for Computational\nLinguistics(ACL) Anthology. We reviewed 7,556 publications; 38 met the\ninclusion criteria. This review identified: datasets having discharge\nsummaries; NLP techniques along with some other data extraction processes,\ndifferent feature extraction and embedding techniques. To measure the\nperformance of classification methods, different evaluation metrics are used.\nLastly, future research directions are provided to scholars who are interested\nin automated ICD code assignment. Efforts are still required to improve ICD\ncode prediction accuracy, availability of large-scale de-identified clinical\ncorpora with the latest version of the classification system. This can be a\nplatform to guide and share knowledge with the less experienced coders and\nresearchers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 03:55:17 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kaur", "Rajvir", ""], ["Ginige", "Jeewani Anupama", ""], ["Obst", "Oliver", ""]]}, {"id": "2107.10654", "submitter": "Matthew Fahrbach", "authors": "Matthew Fahrbach, Mehrdad Ghadiri, Thomas Fu", "title": "Fast Low-Rank Tensor Decomposition by Ridge Leverage Score Sampling", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-rank tensor decomposition generalizes low-rank matrix approximation and\nis a powerful technique for discovering low-dimensional structure in\nhigh-dimensional data. In this paper, we study Tucker decompositions and use\ntools from randomized numerical linear algebra called ridge leverage scores to\naccelerate the core tensor update step in the widely-used alternating least\nsquares (ALS) algorithm. Updating the core tensor, a severe bottleneck in ALS,\nis a highly-structured ridge regression problem where the design matrix is a\nKronecker product of the factor matrices. We show how to use approximate ridge\nleverage scores to construct a sketched instance for any ridge regression\nproblem such that the solution vector for the sketched problem is a\n$(1+\\varepsilon)$-approximation to the original instance. Moreover, we show\nthat classical leverage scores suffice as an approximation, which then allows\nus to exploit the Kronecker structure and update the core tensor in time that\ndepends predominantly on the rank and the sketching parameters (i.e., sublinear\nin the size of the input tensor). We also give upper bounds for ridge leverage\nscores as rows are removed from the design matrix (e.g., if the tensor has\nmissing entries), and we demonstrate the effectiveness of our approximate ridge\nregressioni algorithm for large, low-rank Tucker decompositions on both\nsynthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 13:32:47 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fahrbach", "Matthew", ""], ["Ghadiri", "Mehrdad", ""], ["Fu", "Thomas", ""]]}, {"id": "2107.10655", "submitter": "Mirela Silva", "authors": "Hanyu Shi, Mirela Silva, Daniel Capecci, Luiz Giovanini, Lauren Czech,\n  Juliana Fernandes, Daniela Oliveira", "title": "Lumen: A Machine Learning Framework to Expose Influence Cues in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phishing and disinformation are popular social engineering attacks with\nattackers invariably applying influence cues in texts to make them more\nappealing to users. We introduce Lumen, a learning-based framework that exposes\ninfluence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv)\nobjectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was\ntrained with a newly developed dataset of 3K texts comprised of disinformation,\nphishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in\ncomparison to other learning models showed that Lumen and LSTM presented the\nbest F1-micro score, but Lumen yielded better interpretability. Our results\nhighlight the promise of ML to expose influence cues in text, towards the goal\nof application in automatic labeling tools to improve the accuracy of\nhuman-based detection and reduce the likelihood of users falling for deceptive\nonline content.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 15:53:13 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shi", "Hanyu", ""], ["Silva", "Mirela", ""], ["Capecci", "Daniel", ""], ["Giovanini", "Luiz", ""], ["Czech", "Lauren", ""], ["Fernandes", "Juliana", ""], ["Oliveira", "Daniela", ""]]}, {"id": "2107.10657", "submitter": "Gaetan Rensonnet", "authors": "Gaetan Rensonnet, Louise Adam and Benoit Macq", "title": "Solving inverse problems with deep neural networks driven by sparse\n  signal decomposition in a physics-based dictionary", "comments": "Accepted for publication in Workshop on Interpretable ML in\n  Healthcare at International Conference on Machine Learning (ICML) 2021. 10\n  pages (including 3 for references), 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have an impressive ability to invert very complex\nmodels, i.e. to learn the generative parameters from a model's output. Once\ntrained, the forward pass of a DNN is often much faster than traditional,\noptimization-based methods used to solve inverse problems. This is however done\nat the cost of lower interpretability, a fundamental limitation in most medical\napplications. We propose an approach for solving general inverse problems which\ncombines the efficiency of DNN and the interpretability of traditional\nanalytical methods. The measurements are first projected onto a dense\ndictionary of model-based responses. The resulting sparse representation is\nthen fed to a DNN with an architecture driven by the problem's physics for fast\nparameter learning. Our method can handle generative forward models that are\ncostly to evaluate and exhibits similar performance in accuracy and computation\ntime as a fully-learned DNN, while maintaining high interpretability and being\neasier to train. Concrete results are shown on an example of model-based brain\nparameter estimation from magnetic resonance imaging (MRI).\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:32:45 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Rensonnet", "Gaetan", ""], ["Adam", "Louise", ""], ["Macq", "Benoit", ""]]}, {"id": "2107.10658", "submitter": "Joanna Rownicka", "authors": "Joanna Rownicka, Kilian Sprenkamp, Antonio Tripiana, Volodymyr\n  Gromoglasov, Timo P Kunz", "title": "Digital Einstein Experience: Fast Text-to-Speech for Conversational AI", "comments": "accepted at Interspeech 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our approach to create and deliver a custom voice for a\nconversational AI use-case. More specifically, we provide a voice for a Digital\nEinstein character, to enable human-computer interaction within the digital\nconversation experience. To create the voice which fits the context well, we\nfirst design a voice character and we produce the recordings which correspond\nto the desired speech attributes. We then model the voice. Our solution\nutilizes Fastspeech 2 for log-scaled mel-spectrogram prediction from phonemes\nand Parallel WaveGAN to generate the waveforms. The system supports a character\ninput and gives a speech waveform at the output. We use a custom dictionary for\nselected words to ensure their proper pronunciation. Our proposed cloud\narchitecture enables for fast voice delivery, making it possible to talk to the\ndigital version of Albert Einstein in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:03:27 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Rownicka", "Joanna", ""], ["Sprenkamp", "Kilian", ""], ["Tripiana", "Antonio", ""], ["Gromoglasov", "Volodymyr", ""], ["Kunz", "Timo P", ""]]}, {"id": "2107.10661", "submitter": "Hadi Meidani", "authors": "Rini Jasmine Gladstone, Mohammad Amin Nabian, Vahid Keshavarzzadeh,\n  Hadi Meidani", "title": "Robust Topology Optimization Using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology Optimization is the process of finding the optimal arrangement of\nmaterials within a design domain by minimizing a cost function, subject to some\nperformance constraints. Robust topology optimization (RTO) also incorporates\nthe effect of input uncertainties and produces a design with the best average\nperformance of the structure while reducing the response sensitivity to input\nuncertainties. It is computationally expensive to carry out RTO using finite\nelement and Monte Carlo sampling. In this work, we use neural network\nsurrogates to enable a faster solution approach via surrogate-based\noptimization and build a Variational Autoencoder (VAE) to transform the the\nhigh dimensional design space into a low dimensional one. Furthermore, finite\nelement solvers will be replaced by a neural network surrogate. Also, to\nfurther facilitate the design exploration, we limit our search to a subspace,\nwhich consists of designs that are solutions to deterministic topology\noptimization problems under different realizations of input uncertainties. With\nthese neural network approximations, a gradient-based optimization approach is\nformed to minimize the predicted objective function over the low dimensional\ndesign subspace. We demonstrate the effectiveness of the proposed approach on\ntwo compliance minimization problems and show that VAE performs well on\nlearning the features of the design from minimal training data, and that\nconverting the design space into a low dimensional latent space makes the\nproblem computationally efficient. The resulting gradient-based optimization\nalgorithm produces optimal designs with lower robust compliances than those\nobserved in the training set.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:40:51 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Gladstone", "Rini Jasmine", ""], ["Nabian", "Mohammad Amin", ""], ["Keshavarzzadeh", "Vahid", ""], ["Meidani", "Hadi", ""]]}, {"id": "2107.10663", "submitter": "Naichen Shi", "authors": "Naichen Shi, Fan Lai, Raed Al Kontar, Mosharaf Chowdhury", "title": "Fed-ensemble: Improving Generalization through Model Ensembling in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose Fed-ensemble: a simple approach that bringsmodel\nensembling to federated learning (FL). Instead of aggregating localmodels to\nupdate a single global model, Fed-ensemble uses random permutations to update a\ngroup of K models and then obtains predictions through model averaging.\nFed-ensemble can be readily utilized within established FL methods and does not\nimpose a computational overhead as it only requires one of the K models to be\nsent to a client in each communication round. Theoretically, we show that\npredictions on newdata from all K models belong to the same predictive\nposterior distribution under a neural tangent kernel regime. This result in\nturn sheds light onthe generalization advantages of model averaging. We also\nillustrate thatFed-ensemble has an elegant Bayesian interpretation. Empirical\nresults show that our model has superior performance over several FL\nalgorithms,on a wide range of data sets, and excels in heterogeneous settings\noften encountered in FL applications.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 14:40:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shi", "Naichen", ""], ["Lai", "Fan", ""], ["Kontar", "Raed Al", ""], ["Chowdhury", "Mosharaf", ""]]}, {"id": "2107.10667", "submitter": "Sivaramakrishnan Sankarapandian", "authors": "Sivaramakrishnan Sankarapandian, Brian Kulis", "title": "$\\beta$-Annealed Variational Autoencoder for glitches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational wave detectors such as LIGO and Virgo are susceptible to\nvarious types of instrumental and environmental disturbances known as glitches\nwhich can mask and mimic gravitational waves. While there are 22 classes of\nnon-Gaussian noise gradients currently identified, the number of classes is\nlikely to increase as these detectors go through commissioning between\nobservation runs. Since identification and labelling new noise gradients can be\narduous and time-consuming, we propose $\\beta$-Annelead VAEs to learn\nrepresentations from spectograms in an unsupervised way. Using the same\nformulation as \\cite{alemi2017fixing}, we view\nBottleneck-VAEs~cite{burgess2018understanding} through the lens of information\ntheory and connect them to $\\beta$-VAEs~cite{higgins2017beta}. Motivated by\nthis connection, we propose an annealing schedule for the hyperparameter\n$\\beta$ in $\\beta$-VAEs which has advantages of: 1) One fewer hyperparameter to\ntune, 2) Better reconstruction quality, while producing similar levels of\ndisentanglement.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 22:27:53 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sankarapandian", "Sivaramakrishnan", ""], ["Kulis", "Brian", ""]]}, {"id": "2107.10669", "submitter": "Ali Almalki", "authors": "Ali Almalki, Pawel Wocjan", "title": "Accuracy analysis of Educational Data Mining using Feature Selection\n  Algorithm", "comments": null, "journal-ref": "Int'l Conf. Artificial Intelligence ICAI2019", "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract - Gathering relevant information to predict student academic\nprogress is a tedious task. Due to the large amount of irrelevant data present\nin databases which provides inaccurate results. Currently, it is not possible\nto accurately measure and analyze student data because there are too many\nirrelevant attributes and features in the data. With the help of Educational\nData Mining (EDM), the quality of information can be improved. This research\ndemonstrates how EDM helps to measure the accuracy of data using relevant\nattributes and machine learning algorithms performed. With EDM, irrelevant\nfeatures are removed without changing the original data. The data set used in\nthis study was taken from Kaggle.com. The results compared on the basis of\nrecall, precision and f-measure to check the accuracy of the student data. The\nimportance of this research is to help improve the quality of educational\nresearch by providing more accurate results for researchers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 01:44:25 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Almalki", "Ali", ""], ["Wocjan", "Pawel", ""]]}, {"id": "2107.10670", "submitter": "Shuangli Li", "authors": "Shuangli Li, Jingbo Zhou, Tong Xu, Liang Huang, Fan Wang, Haoyi Xiong,\n  Weili Huang, Dejing Dou, Hui Xiong", "title": "Structure-aware Interactive Graph Neural Networks for the Prediction of\n  Protein-Ligand Binding Affinity", "comments": "11 pages, 8 figures, Accepted by KDD 2021 (Research Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Drug discovery often relies on the successful prediction of protein-ligand\nbinding affinity. Recent advances have shown great promise in applying graph\nneural networks (GNNs) for better affinity prediction by learning the\nrepresentations of protein-ligand complexes. However, existing solutions\nusually treat protein-ligand complexes as topological graph data, thus the\nbiomolecular structural information is not fully utilized. The essential\nlong-range interactions among atoms are also neglected in GNN models. To this\nend, we propose a structure-aware interactive graph neural network (SIGN) which\nconsists of two components: polar-inspired graph attention layers (PGAL) and\npairwise interactive pooling (PiPool). Specifically, PGAL iteratively performs\nthe node-edge aggregation process to update embeddings of nodes and edges while\npreserving the distance and angle information among atoms. Then, PiPool is\nadopted to gather interactive edges with a subsequent reconstruction loss to\nreflect the global interactions. Exhaustive experimental study on two\nbenchmarks verifies the superiority of SIGN.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 03:34:09 GMT"}], "update_date": "2021-07-24", "authors_parsed": [["Li", "Shuangli", ""], ["Zhou", "Jingbo", ""], ["Xu", "Tong", ""], ["Huang", "Liang", ""], ["Wang", "Fan", ""], ["Xiong", "Haoyi", ""], ["Huang", "Weili", ""], ["Dou", "Dejing", ""], ["Xiong", "Hui", ""]]}, {"id": "2107.10692", "submitter": "Louis Mahon", "authors": "Louis Mahon, Thomas Lukasiewicz", "title": "Selective Pseudo-label Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) offer a means of addressing the challenging task\nof clustering high-dimensional data. DNNs can extract useful features, and so\nproduce a lower dimensional representation, which is more amenable to\nclustering techniques. As clustering is typically performed in a purely\nunsupervised setting, where no training labels are available, the question then\narises as to how the DNN feature extractor can be trained. The most accurate\nexisting approaches combine the training of the DNN with the clustering\nobjective, so that information from the clustering process can be used to\nupdate the DNN to produce better features for clustering. One problem with this\napproach is that these ``pseudo-labels'' produced by the clustering algorithm\nare noisy, and any errors that they contain will hurt the training of the DNN.\nIn this paper, we propose selective pseudo-label clustering, which uses only\nthe most confident pseudo-labels for training the~DNN. We formally prove the\nperformance gains under certain conditions. Applied to the task of image\nclustering, the new approach achieves a state-of-the-art performance on three\npopular image datasets. Code is available at\nhttps://github.com/Lou1sM/clustering.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 13:56:53 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Mahon", "Louis", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2107.10703", "submitter": "Alexandre Drouin", "authors": "Philippe Brouillard, Perouz Taslakian, Alexandre Lacoste, Sebastien\n  Lachapelle, Alexandre Drouin", "title": "Typing assumptions improve identification in causal discovery", "comments": "Accepted for presentation as a contributed talk at the Workshop on\n  the Neglected Assumptions in Causal Inference (NACI) at the 38th\n  International Conference on Machine Learning, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal discovery from observational data is a challenging task to which an\nexact solution cannot always be identified. Under assumptions about the\ndata-generative process, the causal graph can often be identified up to an\nequivalence class. Proposing new realistic assumptions to circumscribe such\nequivalence classes is an active field of research. In this work, we propose a\nnew set of assumptions that constrain possible causal relationships based on\nthe nature of the variables. We thus introduce typed directed acyclic graphs,\nin which variable types are used to determine the validity of causal\nrelationships. We demonstrate, both theoretically and empirically, that the\nproposed assumptions can result in significant gains in the identification of\nthe causal graph.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:23:08 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Brouillard", "Philippe", ""], ["Taslakian", "Perouz", ""], ["Lacoste", "Alexandre", ""], ["Lachapelle", "Sebastien", ""], ["Drouin", "Alexandre", ""]]}, {"id": "2107.10706", "submitter": "Aleksandr Beznosikov", "authors": "Aleksandr Beznosikov, Gesualdo Scutari, Alexander Rogozin, Alexander\n  Gasnikov", "title": "Distributed Saddle-Point Problems Under Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study solution methods for (strongly-)convex-(strongly)-concave\nSaddle-Point Problems (SPPs) over networks of two type - master/workers (thus\ncentralized) architectures and meshed (thus decentralized) networks. The local\nfunctions at each node are assumed to be similar, due to statistical data\nsimilarity or otherwise. We establish lower complexity bounds for a fairly\ngeneral class of algorithms solving the SPP. We show that a given suboptimality\n$\\epsilon>0$ is achieved over master/workers networks in\n$\\Omega\\big(\\Delta\\cdot \\delta/\\mu\\cdot \\log (1/\\varepsilon)\\big)$ rounds of\ncommunications, where $\\delta>0$ measures the degree of similarity of the local\nfunctions, $\\mu$ is their strong convexity constant, and $\\Delta$ is the\ndiameter of the network. The lower communication complexity bound over meshed\nnetworks reads $\\Omega\\big(1/{\\sqrt{\\rho}} \\cdot {\\delta}/{\\mu}\\cdot\\log\n(1/\\varepsilon)\\big)$, where $\\rho$ is the (normalized) eigengap of the gossip\nmatrix used for the communication between neighbouring nodes. We then propose\nalgorithms matching the lower bounds over either types of networks (up to\nlog-factors). We assess the effectiveness of the proposed algorithms on a\nrobust logistic regression problem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:25:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Beznosikov", "Aleksandr", ""], ["Scutari", "Gesualdo", ""], ["Rogozin", "Alexander", ""], ["Gasnikov", "Alexander", ""]]}, {"id": "2107.10709", "submitter": "Leonardos Pantiskas", "authors": "Luis P. Silvestrin, Leonardos Pantiskas, Mark Hoogendoorn", "title": "A Framework for Imbalanced Time-series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series forecasting plays an important role in many domains. Boosted by\nthe advances in Deep Learning algorithms, it has for instance been used to\npredict wind power for eolic energy production, stock market fluctuations, or\nmotor overheating. In some of these tasks, we are interested in predicting\naccurately some particular moments which often are underrepresented in the\ndataset, resulting in a problem known as imbalanced regression. In the\nliterature, while recognized as a challenging problem, limited attention has\nbeen devoted on how to handle the problem in a practical setting. In this\npaper, we put forward a general approach to analyze time-series forecasting\nproblems focusing on those underrepresented moments to reduce imbalances. Our\napproach has been developed based on a case study in a large industrial\ncompany, which we use to exemplify the approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:32:30 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Silvestrin", "Luis P.", ""], ["Pantiskas", "Leonardos", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "2107.10710", "submitter": "Iaroslav Okunevich", "authors": "Iaroslav Okunevich, Daria Trinitatova, Pavel Kopanev, Dzmitry\n  Tsetserukou", "title": "DeltaCharger: Charging Robot with Inverted Delta Mechanism and\n  CNN-driven High Fidelity Tactile Perception for Precise 3D Positioning", "comments": "Accepted to IEEE Robotics and Automation Letters and 17th\n  International Conference on Automation Science and Engineering (CASE) 2021,\n  IEEE copyright, 7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DeltaCharger is a novel charging robot with an Inverted Delta structure for\n3D positioning of electrodes to achieve robust and safe transferring energy\nbetween two mobile robots. The embedded high-fidelity tactile sensors allow to\nestimate the angular, vertical and horizontal misalignments between electrodes\non the charger mechanism and electrodes on the target robot using pressure data\non the contact surfaces. This is crucial for preventing a short circuit. In\nthis paper, the mechanism of the developed prototype and evaluation study of\ndifferent machine learning models for misalignment prediction are presented.\nThe experimental results showed that the proposed system can measure the angle,\nvertical and horizontal values of misalignment from pressure data with an\naccuracy of 95.46%, 98.2%, and 86.9%, respectively, using a Convolutional\nNeural Network (CNN). DeltaCharger can potentially bring a new level of\ncharging systems and improve the prevalence of mobile autonomous robots.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:33:15 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Okunevich", "Iaroslav", ""], ["Trinitatova", "Daria", ""], ["Kopanev", "Pavel", ""], ["Tsetserukou", "Dzmitry", ""]]}, {"id": "2107.10711", "submitter": "Hamidreza Eivazi", "authors": "Hamidreza Eivazi, Mojtaba Tahani, Philipp Schlatter, Ricardo Vinuesa", "title": "Physics-informed neural networks for solving Reynolds-averaged\n  Navier$\\unicode{x2013}$Stokes equations", "comments": "Proc. 13th ERCOFTAC Symp. on Engineering Turbulence Modeling and\n  Measurements (ETMM13), Rhodes, Greece, September 15-17, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) are successful machine-learning\nmethods for the solution and identification of partial differential equations\n(PDEs). We employ PINNs for solving the Reynolds-averaged\nNavier$\\unicode{x2013}$Stokes (RANS) equations for incompressible turbulent\nflows without any specific model or assumption for turbulence, and by taking\nonly the data on the domain boundaries. We first show the applicability of\nPINNs for solving the Navier$\\unicode{x2013}$Stokes equations for laminar flows\nby solving the Falkner$\\unicode{x2013}$Skan boundary layer. We then apply PINNs\nfor the simulation of four turbulent-flow cases, i.e., zero-pressure-gradient\nboundary layer, adverse-pressure-gradient boundary layer, and turbulent flows\nover a NACA4412 airfoil and the periodic hill. Our results show the excellent\napplicability of PINNs for laminar flows with strong pressure gradients, where\npredictions with less than 1% error can be obtained. For turbulent flows, we\nalso obtain very good accuracy on simulation results even for the\nReynolds-stress components.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:34:22 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Eivazi", "Hamidreza", ""], ["Tahani", "Mojtaba", ""], ["Schlatter", "Philipp", ""], ["Vinuesa", "Ricardo", ""]]}, {"id": "2107.10716", "submitter": "Manvel Avetisian", "authors": "Alexander Ponomarchuk and Ilya Burenko and Elian Malkin and Ivan\n  Nazarov and Vladimir Kokh and Manvel Avetisian and Leonid Zhukov", "title": "Project Achoo: A Practical Model and Application for COVID-19 Detection\n  from Recordings of Breath, Voice, and Cough", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic created a significant interest and demand for infection\ndetection and monitoring solutions. In this paper we propose a machine learning\nmethod to quickly triage COVID-19 using recordings made on consumer devices.\nThe approach combines signal processing methods with fine-tuned deep learning\nnetworks and provides methods for signal denoising, cough detection and\nclassification. We have also developed and deployed a mobile application that\nuses symptoms checker together with voice, breath and cough signals to detect\nCOVID-19 infection. The application showed robust performance on both open\nsourced datasets and on the noisy data collected during beta testing by the end\nusers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:07:56 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Ponomarchuk", "Alexander", ""], ["Burenko", "Ilya", ""], ["Malkin", "Elian", ""], ["Nazarov", "Ivan", ""], ["Kokh", "Vladimir", ""], ["Avetisian", "Manvel", ""], ["Zhukov", "Leonid", ""]]}, {"id": "2107.10718", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Fangxu Xing, Hanna K. Gaggin, Weichung Wang, C.-C. Jay\n  Kuo, Georges El Fakhri, Jonghye Woo", "title": "Segmentation of Cardiac Structures via Successive Subspace Learning with\n  Saab Transform from Cine MRI", "comments": "43rd Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessment of cardiovascular disease (CVD) with cine magnetic resonance\nimaging (MRI) has been used to non-invasively evaluate detailed cardiac\nstructure and function. Accurate segmentation of cardiac structures from cine\nMRI is a crucial step for early diagnosis and prognosis of CVD, and has been\ngreatly improved with convolutional neural networks (CNN). There, however, are\na number of limitations identified in CNN models, such as limited\ninterpretability and high complexity, thus limiting their use in clinical\npractice. In this work, to address the limitations, we propose a lightweight\nand interpretable machine learning model, successive subspace learning with the\nsubspace approximation with adjusted bias (Saab) transform, for accurate and\nefficient segmentation from cine MRI. Specifically, our segmentation framework\nis comprised of the following steps: (1) sequential expansion of near-to-far\nneighborhood at different resolutions; (2) channel-wise subspace approximation\nusing the Saab transform for unsupervised dimension reduction; (3) class-wise\nentropy guided feature selection for supervised dimension reduction; (4)\nconcatenation of features and pixel-wise classification with gradient boost;\nand (5) conditional random field for post-processing. Experimental results on\nthe ACDC 2017 segmentation database, showed that our framework performed better\nthan state-of-the-art U-Net models with 200$\\times$ fewer parameters in\ndelineating the left ventricle, right ventricle, and myocardium, thus showing\nits potential to be used in clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 14:50:48 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Xing", "Fangxu", ""], ["Gaggin", "Hanna K.", ""], ["Wang", "Weichung", ""], ["Kuo", "C. -C. Jay", ""], ["Fakhri", "Georges El", ""], ["Woo", "Jonghye", ""]]}, {"id": "2107.10731", "submitter": "Lauro Sandor Langosco di Langosco", "authors": "Lauro Langosco di Langosco, Vincent Fortuin, Heiko Strathmann", "title": "Neural Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Particle-based approximate Bayesian inference approaches such as Stein\nVariational Gradient Descent (SVGD) combine the flexibility and convergence\nguarantees of sampling methods with the computational benefits of variational\ninference. In practice, SVGD relies on the choice of an appropriate kernel\nfunction, which impacts its ability to model the target distribution -- a\nchallenging problem with only heuristic solutions. We propose Neural\nVariational Gradient Descent (NVGD), which is based on parameterizing the\nwitness function of the Stein discrepancy by a deep neural network whose\nparameters are learned in parallel to the inference, mitigating the necessity\nto make any kernel choices whatsoever. We empirically evaluate our method on\npopular synthetic inference problems, real-world Bayesian linear regression,\nand Bayesian neural network inference.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 15:10:50 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 10:57:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["di Langosco", "Lauro Langosco", ""], ["Fortuin", "Vincent", ""], ["Strathmann", "Heiko", ""]]}, {"id": "2107.10746", "submitter": "Lorena Qendro", "authors": "Lorena Qendro, Alexander Campbell, Pietro Li\\`o, Cecilia Mascolo", "title": "High Frequency EEG Artifact Detection with Uncertainty via Early Exit\n  Paradigm", "comments": "ICML 2021 Workshop on Human In the Loop Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is crucial for the monitoring and diagnosis of\nbrain disorders. However, EEG signals suffer from perturbations caused by\nnon-cerebral artifacts limiting their efficacy. Current artifact detection\npipelines are resource-hungry and rely heavily on hand-crafted features.\nMoreover, these pipelines are deterministic in nature, making them unable to\ncapture predictive uncertainty. We propose E4G, a deep learning framework for\nhigh frequency EEG artifact detection. Our framework exploits the early exit\nparadigm, building an implicit ensemble of models capable of capturing\nuncertainty. We evaluate our approach on the Temple University Hospital EEG\nArtifact Corpus (v2.0) achieving state-of-the-art classification results. In\naddition, E4G provides well-calibrated uncertainty metrics comparable to\nsampling techniques like Monte Carlo dropout in just a single forward pass. E4G\nopens the door to uncertainty-aware artifact detection supporting\nclinicians-in-the-loop frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 07:05:42 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Qendro", "Lorena", ""], ["Campbell", "Alexander", ""], ["Li\u00f2", "Pietro", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2107.10756", "submitter": "Manan Oza", "authors": "Manan Oza, Sukalpa Chanda and David Doermann", "title": "Semantic Text-to-Face GAN -ST^2FG", "comments": "arXiv admin note: text overlap with arXiv:2010.12136 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Faces generated using generative adversarial networks (GANs) have reached\nunprecedented realism. These faces, also known as \"Deep Fakes\", appear as\nrealistic photographs with very little pixel-level distortions. While some work\nhas enabled the training of models that lead to the generation of specific\nproperties of the subject, generating a facial image based on a natural\nlanguage description has not been fully explored. For security and criminal\nidentification, the ability to provide a GAN-based system that works like a\nsketch artist would be incredibly useful. In this paper, we present a novel\napproach to generate facial images from semantic text descriptions. The learned\nmodel is provided with a text description and an outline of the type of face,\nwhich the model uses to sketch the features. Our models are trained using an\nAffine Combination Module (ACM) mechanism to combine the text embedding from\nBERT and the GAN latent space using a self-attention matrix. This avoids the\nloss of features due to inadequate \"attention\", which may happen if text\nembedding and latent vector are simply concatenated. Our approach is capable of\ngenerating images that are very accurately aligned to the exhaustive textual\ndescriptions of faces with many fine detail features of the face and helps in\ngenerating better images. The proposed method is also capable of making\nincremental changes to a previously generated image if it is provided with\nadditional textual descriptions or sentences.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 15:42:25 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Oza", "Manan", ""], ["Chanda", "Sukalpa", ""], ["Doermann", "David", ""]]}, {"id": "2107.10763", "submitter": "Janith Petangoda", "authors": "Janith Petangoda, Marc Peter Deisenroth and Nicholas A. M. Monk", "title": "Learning to Transfer: A Foliated Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to transfer considers learning solutions to tasks in a such way that\nrelevant knowledge can be transferred from known task solutions to new, related\ntasks. This is important for general learning, as well as for improving the\nefficiency of the learning process. While techniques for learning to transfer\nhave been studied experimentally, we still lack a foundational description of\nthe problem that exposes what related tasks are, and how relationships between\ntasks can be exploited constructively. In this work, we introduce a framework\nusing the differential geometric theory of foliations that provides such a\nfoundation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 15:46:45 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Petangoda", "Janith", ""], ["Deisenroth", "Marc Peter", ""], ["Monk", "Nicholas A. M.", ""]]}, {"id": "2107.10790", "submitter": "Juan Manuel Mayor Torres", "authors": "Juan Manuel Mayor-Torres, Mirco Ravanelli, Sara E. Medina-DeVilliers,\n  Matthew D. Lerner and Giuseppe Riccardi", "title": "Interpretable SincNet-based Deep Learning for Emotion Recognition from\n  EEG brain activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning methods, such as deep learning, show promising results in\nthe medical domain. However, the lack of interpretability of these algorithms\nmay hinder their applicability to medical decision support systems. This paper\nstudies an interpretable deep learning technique, called SincNet. SincNet is a\nconvolutional neural network that efficiently learns customized band-pass\nfilters through trainable sinc-functions. In this study, we use SincNet to\nanalyze the neural activity of individuals with Autism Spectrum Disorder (ASD),\nwho experience characteristic differences in neural oscillatory activity. In\nparticular, we propose a novel SincNet-based neural network for detecting\nemotions in ASD patients using EEG signals. The learned filters can be easily\ninspected to detect which part of the EEG spectrum is used for predicting\nemotions. We found that our system automatically learns the high-$\\alpha$ (9-13\nHz) and $\\beta$ (13-30 Hz) band suppression often present in individuals with\nASD. This result is consistent with recent neuroscience studies on emotion\nrecognition, which found an association between these band suppressions and the\nbehavioral deficits observed in individuals with ASD. The improved\ninterpretability of SincNet is achieved without sacrificing performance in\nemotion recognition.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:44:53 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Mayor-Torres", "Juan Manuel", ""], ["Ravanelli", "Mirco", ""], ["Medina-DeVilliers", "Sara E.", ""], ["Lerner", "Matthew D.", ""], ["Riccardi", "Giuseppe", ""]]}, {"id": "2107.10804", "submitter": "Tam Nguyen", "authors": "Tam Nguyen and Raviv Raich", "title": "Active Learning in Incomplete Label Multiple Instance Multiple Label\n  Learning", "comments": "Machine learning, Multiple instance multiple label learning, Active\n  learning, incomplete label learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiple instance multiple label learning, each sample, a bag, consists of\nmultiple instances. To alleviate labeling complexity, each sample is associated\nwith a set of bag-level labels leaving instances within the bag unlabeled. This\nsetting is more convenient and natural for representing complicated objects,\nwhich have multiple semantic meanings. Compared to single instance labeling,\nthis approach allows for labeling larger datasets at an equivalent labeling\ncost. However, for sufficiently large datasets, labeling all bags may become\nprohibitively costly. Active learning uses an iterative labeling and retraining\napproach aiming to provide reasonable classification performance using a small\nnumber of labeled samples. To our knowledge, only a few works in the area of\nactive learning in the MIML setting are available. These approaches can provide\npractical solutions to reduce labeling cost but their efficacy remains unclear.\nIn this paper, we propose a novel bag-class pair based approach for active\nlearning in the MIML setting. Due to the partial availability of bag-level\nlabels, we focus on the incomplete-label MIML setting for the proposed active\nlearning approach. Our approach is based on a discriminative graphical model\nwith efficient and exact inference. For the query process, we adapt active\nlearning criteria to the novel bag-class pair selection strategy. Additionally,\nwe introduce an online stochastic gradient descent algorithm to provide an\nefficient model update after each query. Numerical experiments on benchmark\ndatasets illustrate the robustness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:01:28 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 18:14:55 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Nguyen", "Tam", ""], ["Raich", "Raviv", ""]]}, {"id": "2107.10845", "submitter": "Hanrui Wang", "authors": "Hanrui Wang and Yongshan Ding and Jiaqi Gu and Yujun Lin and David Z.\n  Pan and Frederic T. Chong and Song Han", "title": "QuantumNAS: Noise-Adaptive Search for Robust Quantum Circuits", "comments": "15 pages, 23 figures. Code available at\n  https://github.com/mit-han-lab/pytorch-quantum", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantum noise is the key challenge in Noisy Intermediate-Scale Quantum (NISQ)\ncomputers. Limited research efforts have explored a higher level of\noptimization by making the quantum circuit resilient to noise. We propose and\nexperimentally implement QuantumNAS, the first comprehensive framework for\nnoise-adaptive co-search of variational circuit and qubit mapping. Variational\nquantum circuits are a promising approach for constructing quantum neural\nnetworks for machine learning and variational ansatzes for quantum simulation.\nHowever, finding the best variational circuit and its optimal parameters is\nchallenging in a high-dimensional Hilbert space. We propose to decouple the\nparameter training and circuit search by introducing a novel gate-sharing\nSuperCircuit. The SuperCircuit is trained by sampling and updating the\nSubCircuits in it and provides an accurate estimation of SubCircuit performance\ntrained from scratch. Then we perform an evolutionary co-search of SubCircuit\nand its qubit mapping. The SubCircuit performance is estimated with parameters\ninherited from SuperCircuit and simulated with real device noise models.\nFinally, we perform iterative gate pruning and finetuning to further remove the\nredundant gates in a fine-grained manner.\n  Extensively evaluated with 12 QML and VQE benchmarks on 10 quantum computers,\nQuantumNAS significantly outperforms noise-unaware search, human and random\nbaselines. For QML tasks, QuantumNAS is the first to demonstrate over 95%\n2-class, 85% 4-class, and 32% 10-class classification accuracy on real quantum\ncomputers. It also achieves the lowest eigenvalue for VQE tasks on H2, H2O,\nLiH, CH4, BeH2 compared with UCCSD baselines. We also open-source QuantumEngine\n(https://github.com/mit-han-lab/pytorch-quantum) for fast training of\nparameterized quantum circuits to facilitate future research.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:58:13 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wang", "Hanrui", ""], ["Ding", "Yongshan", ""], ["Gu", "Jiaqi", ""], ["Lin", "Yujun", ""], ["Pan", "David Z.", ""], ["Chong", "Frederic T.", ""], ["Han", "Song", ""]]}, {"id": "2107.10847", "submitter": "Paras Jain", "authors": "Jeffrey Ichnowski, Paras Jain, Bartolomeo Stellato, Goran Banjac,\n  Michael Luo, Francesco Borrelli, Joseph E. Gonzalez, Ion Stoica, Ken Goldberg", "title": "Accelerating Quadratic Optimization with Reinforcement Learning", "comments": "25 pages, 7 figures. Code available at\n  https://github.com/berkeleyautomation/rlqp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  First-order methods for quadratic optimization such as OSQP are widely used\nfor large-scale machine learning and embedded optimal control, where many\nrelated problems must be rapidly solved. These methods face two persistent\nchallenges: manual hyperparameter tuning and convergence time to high-accuracy\nsolutions. To address these, we explore how Reinforcement Learning (RL) can\nlearn a policy to tune parameters to accelerate convergence. In experiments\nwith well-known QP benchmarks we find that our RL policy, RLQP, significantly\noutperforms state-of-the-art QP solvers by up to 3x. RLQP generalizes\nsurprisingly well to previously unseen problems with varying dimension and\nstructure from different applications, including the QPLIB, Netlib LP and\nMaros-Meszaros problems. Code for RLQP is available at\nhttps://github.com/berkeleyautomation/rlqp.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:59:10 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Ichnowski", "Jeffrey", ""], ["Jain", "Paras", ""], ["Stellato", "Bartolomeo", ""], ["Banjac", "Goran", ""], ["Luo", "Michael", ""], ["Borrelli", "Francesco", ""], ["Gonzalez", "Joseph E.", ""], ["Stoica", "Ion", ""], ["Goldberg", "Ken", ""]]}, {"id": "2107.10868", "submitter": "Yuyang Deng", "authors": "Yuyang Deng, Mehrdad Mahdavi", "title": "Local SGD Optimizes Overparameterized Neural Networks in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we prove that Local (S)GD (or FedAvg) can optimize two-layer\nneural networks with Rectified Linear Unit (ReLU) activation function in\npolynomial time. Despite the established convergence theory of Local SGD on\noptimizing general smooth functions in communication-efficient distributed\noptimization, its convergence on non-smooth ReLU networks still eludes full\ntheoretical understanding. The key property used in many Local SGD analysis on\nsmooth function is gradient Lipschitzness, so that the gradient on local models\nwill not drift far away from that on averaged model. However, this decent\nproperty does not hold in networks with non-smooth ReLU activation function. We\nshow that, even though ReLU network does not admit gradient Lipschitzness\nproperty, the difference between gradients on local models and average model\nwill not change too much, under the dynamics of Local SGD. We validate our\ntheoretical results via extensive experiments. This work is the first to show\nthe convergence of Local SGD on non-smooth functions, and will shed lights on\nthe optimization theory of federated training of deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:06:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Deng", "Yuyang", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "2107.10869", "submitter": "Nathaniel Strawn", "authors": "Nate Strawn", "title": "Filament Plots for Data Visualization", "comments": "33 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We construct a computationally inexpensive 3D extension of Andrew's plots by\nconsidering curves generated by Frenet-Serret equations and induced by\noptimally smooth 2D Andrew's plots. We consider linear isometries from a\nEuclidean data space to infinite dimensional spaces of 2D curves, and\nparametrize the linear isometries that produce (on average) optimally smooth\ncurves over a given dataset. This set of optimal isometries admits many degrees\nof freedom, and (using recent results on generalized Gauss sums) we identify a\nparticular a member of this set which admits an asymptotic projective \"tour\"\nproperty. Finally, we consider the unit-length 3D curves (filaments) induced by\nthese 2D Andrew's plots, where the linear isometry property preserves distances\nas \"relative total square curvatures\". This work concludes by illustrating\nfilament plots for several datasets. Code is available at\nhttps://github.com/n8epi/filaments\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:20:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Strawn", "Nate", ""]]}, {"id": "2107.10870", "submitter": "Satchit Sivakumar", "authors": "Mark Bun, Marco Gaboardi, Satchit Sivakumar", "title": "Multiclass versus Binary Differentially Private PAC Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show a generic reduction from multiclass differentially private PAC\nlearning to binary private PAC learning. We apply this transformation to a\nrecently proposed binary private PAC learner to obtain a private multiclass\nlearner with sample complexity that has a polynomial dependence on the\nmulticlass Littlestone dimension and a poly-logarithmic dependence on the\nnumber of classes. This yields an exponential improvement in the dependence on\nboth parameters over learners from previous work. Our proof extends the notion\nof $\\Psi$-dimension defined in work of Ben-David et al. [JCSS '95] to the\nonline setting and explores its general properties.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:06:39 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Bun", "Mark", ""], ["Gaboardi", "Marco", ""], ["Sivakumar", "Satchit", ""]]}, {"id": "2107.10873", "submitter": "Linyi Li", "authors": "Zhuolin Yang, Linyi Li, Xiaojun Xu, Bhavya Kailkhura, Tao Xie, Bo Li", "title": "On the Certified Robustness for Ensemble Models and Beyond", "comments": "57 pages, 11 pages for main text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent studies show that deep neural networks (DNN) are vulnerable to\nadversarial examples, which aim to mislead DNNs by adding perturbations with\nsmall magnitude. To defend against such attacks, both empirical and theoretical\ndefense approaches have been extensively studied for a single ML model. In this\nwork, we aim to analyze and provide the certified robustness for ensemble ML\nmodels, together with the sufficient and necessary conditions of robustness for\ndifferent ensemble protocols. Although ensemble models are shown more robust\nthan a single model empirically; surprisingly, we find that in terms of the\ncertified robustness the standard ensemble models only achieve marginal\nimprovement compared to a single model. Thus, to explore the conditions that\nguarantee to provide certifiably robust ensemble ML models, we first prove that\ndiversified gradient and large confidence margin are sufficient and necessary\nconditions for certifiably robust ensemble models under the model-smoothness\nassumption. We then provide the bounded model-smoothness analysis based on the\nproposed Ensemble-before-Smoothing strategy. We also prove that an ensemble\nmodel can always achieve higher certified robustness than a single base model\nunder mild conditions. Inspired by the theoretical findings, we propose the\nlightweight Diversity Regularized Training (DRT) to train certifiably robust\nensemble ML models. Extensive experiments show that our DRT enhanced ensembles\ncan consistently achieve higher certified robustness than existing single and\nensemble ML models, demonstrating the state-of-the-art certified L2-robustness\non MNIST, CIFAR-10, and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:10:41 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yang", "Zhuolin", ""], ["Li", "Linyi", ""], ["Xu", "Xiaojun", ""], ["Kailkhura", "Bhavya", ""], ["Xie", "Tao", ""], ["Li", "Bo", ""]]}, {"id": "2107.10878", "submitter": "J. Nathan Kutz", "authors": "Diya Sashidhar and J. Nathan Kutz", "title": "Bagging, optimized dynamic mode decomposition (BOP-DMD) for robust,\n  stable forecasting with spatial and temporal uncertainty-quantification", "comments": "12 pages, 8 figures, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic mode decomposition (DMD) provides a regression framework for\nadaptively learning a best-fit linear dynamics model over snapshots of\ntemporal, or spatio-temporal, data. A diversity of regression techniques have\nbeen developed for producing the linear model approximation whose solutions are\nexponentials in time. For spatio-temporal data, DMD provides low-rank and\ninterpretable models in the form of dominant modal structures along with their\nexponential/oscillatory behavior in time. The majority of DMD algorithms,\nhowever, are prone to bias errors from noisy measurements of the dynamics,\nleading to poor model fits and unstable forecasting capabilities. The optimized\nDMD algorithm minimizes the model bias with a variable projection optimization,\nthus leading to stabilized forecasting capabilities. Here, the optimized DMD\nalgorithm is improved by using statistical bagging methods whereby a single set\nof snapshots is used to produce an ensemble of optimized DMD models. The\noutputs of these models are averaged to produce a bagging, optimized dynamic\nmode decomposition (BOP-DMD). BOP-DMD not only improves performance, it also\nrobustifies the model and provides both spatial and temporal uncertainty\nquantification (UQ). Thus unlike currently available DMD algorithms, BOP-DMD\nprovides a stable and robust model for probabilistic, or Bayesian forecasting\nwith comprehensive UQ metrics.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:14:20 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Sashidhar", "Diya", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2107.10879", "submitter": "Peter Y. Lu", "authors": "Peter Y. Lu, Joan Ari\\~no, Marin Solja\\v{c}i\\'c", "title": "Discovering Sparse Interpretable Dynamics from Partial Observations", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Identifying the governing equations of a nonlinear dynamical system is key to\nboth understanding the physical features of the system and constructing an\naccurate model of the dynamics that generalizes well beyond the available data.\nWe propose a machine learning framework for discovering these governing\nequations using only partial observations, combining an encoder for state\nreconstruction with a sparse symbolic model. Our tests show that this method\ncan successfully reconstruct the full system state and identify the underlying\ndynamics for a variety of ODE and PDE systems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:23:23 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lu", "Peter Y.", ""], ["Ari\u00f1o", "Joan", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "2107.10882", "submitter": "Kirill Karpov", "authors": "Kirill Karpov (1 and 2), Artem Mitrofanov (1 and 2), Vadim Korolev (1\n  and 2), Valery Tkachenko (2) ((1) Lomonosov Moscow State University,\n  Department of Chemistry, Leninskie gory, 1 bld. 3, Moscow, Russia, (2)\n  Science Data Software, LLC, 14909 Forest Landing Cir, Rockville, USA)", "title": "Size doesn't matter: predicting physico- or biochemical properties based\n  on dozens of molecules", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of machine learning in chemistry has become a common practice. At the\nsame time, despite the success of modern machine learning methods, the lack of\ndata limits their use. Using a transfer learning methodology can help solve\nthis problem. This methodology assumes that a model built on a sufficient\namount of data captures general features of the chemical compound structure on\nwhich it was trained and that the further reuse of these features on a dataset\nwith a lack of data will greatly improve the quality of the new model. In this\npaper, we develop this approach for small organic molecules, implementing\ntransfer learning with graph convolutional neural networks. The paper shows a\nsignificant improvement in the performance of models for target properties with\na lack of data. The effects of the dataset composition on model quality and the\napplicability domain of the resulting models are also considered.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:57:24 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Karpov", "Kirill", "", "1 and 2"], ["Mitrofanov", "Artem", "", "1 and 2"], ["Korolev", "Vadim", "", "1\n  and 2"], ["Tkachenko", "Valery", ""]]}, {"id": "2107.10884", "submitter": "Wu Lin", "authors": "Wu Lin, Frank Nielsen, Mohammad Emtiyaz Khan, Mark Schmidt", "title": "Structured second-order methods via natural gradient descent", "comments": "ICML workshop paper. arXiv admin note: substantial text overlap with\n  arXiv:2102.07405", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose new structured second-order methods and structured\nadaptive-gradient methods obtained by performing natural-gradient descent on\nstructured parameter spaces. Natural-gradient descent is an attractive approach\nto design new algorithms in many settings such as gradient-free,\nadaptive-gradient, and second-order methods. Our structured methods not only\nenjoy a structural invariance but also admit a simple expression. Finally, we\ntest the efficiency of our proposed methods on both deterministic non-convex\nproblems and deep learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 19:03:53 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lin", "Wu", ""], ["Nielsen", "Frank", ""], ["Khan", "Mohammad Emtiyaz", ""], ["Schmidt", "Mark", ""]]}, {"id": "2107.10901", "submitter": "Saba Moeinizade", "authors": "Saba Moeinizade, Guiping Hu, Lizhi Wang", "title": "A reinforcement learning approach to resource allocation in genomic\n  selection", "comments": "18 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Genomic selection (GS) is a technique that plant breeders use to select\nindividuals to mate and produce new generations of species. Allocation of\nresources is a key factor in GS. At each selection cycle, breeders are facing\nthe choice of budget allocation to make crosses and produce the next generation\nof breeding parents. Inspired by recent advances in reinforcement learning for\nAI problems, we develop a reinforcement learning-based algorithm to\nautomatically learn to allocate limited resources across different generations\nof breeding. We mathematically formulate the problem in the framework of Markov\nDecision Process (MDP) by defining state and action spaces. To avoid the\nexplosion of the state space, an integer linear program is proposed that\nquantifies the trade-off between resources and time. Finally, we propose a\nvalue function approximation method to estimate the action-value function and\nthen develop a greedy policy improvement technique to find the optimal\nresources. We demonstrate the effectiveness of the proposed method in enhancing\ngenetic gain using a case study with realistic data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 19:55:16 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Moeinizade", "Saba", ""], ["Hu", "Guiping", ""], ["Wang", "Lizhi", ""]]}, {"id": "2107.10931", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Bo Hu, Linghao Jin, Xu Han, Fangxu Xing, Jinsong Ouyang,\n  Jun Lu, Georges EL Fakhri, Jonghye Woo", "title": "Domain Generalization under Conditional and Label Shifts via Variational\n  Bayesian Inference", "comments": "30th International Joint Conference on Artificial Intelligence\n  (IJCAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a domain generalization (DG) approach to learn on\nseveral labeled source domains and transfer knowledge to a target domain that\nis inaccessible in training. Considering the inherent conditional and label\nshifts, we would expect the alignment of $p(x|y)$ and $p(y)$. However, the\nwidely used domain invariant feature learning (IFL) methods relies on aligning\nthe marginal concept shift w.r.t. $p(x)$, which rests on an unrealistic\nassumption that $p(y)$ is invariant across domains. We thereby propose a novel\nvariational Bayesian inference framework to enforce the conditional\ndistribution alignment w.r.t. $p(x|y)$ via the prior distribution matching in a\nlatent space, which also takes the marginal label shift w.r.t. $p(y)$ into\nconsideration with the posterior alignment. Extensive experiments on various\nbenchmarks demonstrate that our framework is robust to the label shift and the\ncross-domain accuracy is significantly improved, thereby achieving superior\nperformance over the conventional IFL counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 21:19:12 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Hu", "Bo", ""], ["Jin", "Linghao", ""], ["Han", "Xu", ""], ["Xing", "Fangxu", ""], ["Ouyang", "Jinsong", ""], ["Lu", "Jun", ""], ["Fakhri", "Georges EL", ""], ["Woo", "Jonghye", ""]]}, {"id": "2107.10932", "submitter": "Mohammad Ramezanali", "authors": "Tim Lou, Michael Park, Mohammad Ramezanali, Vincent Tang", "title": "FNetAR: Mixing Tokens with Autoregressive Fourier Transforms", "comments": "final experimental results forthcoming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this note we examine the autoregressive generalization of the FNet\nalgorithm, in which self-attention layers from the standard Transformer\narchitecture are substituted with a trivial sparse-uniformsampling procedure\nbased on Fourier transforms. Using the Wikitext-103 benchmark, we\ndemonstratethat FNetAR retains state-of-the-art performance (25.8 ppl) on the\ntask of causal language modelingcompared to a Transformer-XL baseline (24.2\nppl) with only half the number self-attention layers,thus providing further\nevidence for the superfluity of deep neural networks with heavily\ncompoundedattention mechanisms. The autoregressive Fourier transform could\nlikely be used for parameterreduction on most Transformer-based time-series\nprediction models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 21:24:02 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lou", "Tim", ""], ["Park", "Michael", ""], ["Ramezanali", "Mohammad", ""], ["Tang", "Vincent", ""]]}, {"id": "2107.10935", "submitter": "Sarah Lueck", "authors": "Cristian Anastasiu and Hanna Behnke and Sarah L\\\"uck and Viktor\n  Malesevic and Aamna Najmi and Javier Poveda-Panter", "title": "DeepTitle -- Leveraging BERT to generate Search Engine Optimized\n  Headlines", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automated headline generation for online news articles is not a trivial task\n- machine generated titles need to be grammatically correct, informative,\ncapture attention and generate search traffic without being \"click baits\" or\n\"fake news\". In this paper we showcase how a pre-trained language model can be\nleveraged to create an abstractive news headline generator for German language.\nWe incorporate state of the art fine-tuning techniques for abstractive text\nsummarization, i.e. we use different optimizers for the encoder and decoder\nwhere the former is pre-trained and the latter is trained from scratch. We\nmodify the headline generation to incorporate frequently sought keywords\nrelevant for search engine optimization. We conduct experiments on a German\nnews data set and achieve a ROUGE-L-gram F-score of 40.02. Furthermore, we\naddress the limitations of ROUGE for measuring the quality of text\nsummarization by introducing a sentence similarity metric and human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 21:32:54 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Anastasiu", "Cristian", ""], ["Behnke", "Hanna", ""], ["L\u00fcck", "Sarah", ""], ["Malesevic", "Viktor", ""], ["Najmi", "Aamna", ""], ["Poveda-Panter", "Javier", ""]]}, {"id": "2107.10939", "submitter": "Ivan Vendrov", "authors": "Jonathan Stray, Ivan Vendrov, Jeremy Nixon, Steven Adler, Dylan\n  Hadfield-Menell", "title": "What are you optimizing for? Aligning Recommender Systems with Human\n  Values", "comments": "Originally presented at the ICML 2020 Participatory Approaches to\n  Machine Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe cases where real recommender systems were modified in the service\nof various human values such as diversity, fairness, well-being, time well\nspent, and factual accuracy. From this we identify the current practice of\nvalues engineering: the creation of classifiers from human-created data with\nvalue-based labels. This has worked in practice for a variety of issues, but\nproblems are addressed one at a time, and users and other stakeholders have\nseldom been involved. Instead, we look to AI alignment work for approaches that\ncould learn complex values directly from stakeholders, and identify four major\ndirections: useful measures of alignment, participatory design and operation,\ninteractive value learning, and informed deliberative judgments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 21:52:43 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Stray", "Jonathan", ""], ["Vendrov", "Ivan", ""], ["Nixon", "Jeremy", ""], ["Adler", "Steven", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "2107.10955", "submitter": "Xiaodong Li", "authors": "Xingmei Lou, Yu Hu, Xiaodong Li", "title": "Linear Polytree Structural Equation Models: Structural Learning and\n  Inverse Correlation Estimation", "comments": "27 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the problem of learning the directed acyclic graph (DAG)\nwhen data are generated from a linear structural equation model (SEM) and the\ncausal structure can be characterized by a polytree. Specially, under both\nGaussian and sub-Gaussian models, we study the sample size conditions for the\nwell-known Chow-Liu algorithm to exactly recover the equivalence class of the\npolytree, which is uniquely represented by a CPDAG. We also study the error\nrate for the estimation of the inverse correlation matrix under such models.\nOur theoretical findings are illustrated by comprehensive numerical\nsimulations, and experiments on benchmark data also demonstrate the robustness\nof the method when the ground truth graphical structure can only be\napproximated by a polytree.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 23:22:20 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lou", "Xingmei", ""], ["Hu", "Yu", ""], ["Li", "Xiaodong", ""]]}, {"id": "2107.10957", "submitter": "Dylan Sandfelder", "authors": "Dylan Sandfelder, Priyesh Vijayan, William L. Hamilton", "title": "Ego-GNNs: Exploiting Ego Structures in Graph Neural Networks", "comments": "Submitted to a special session of IEEE-ICASSP 2021", "journal-ref": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), 2021, pp. 8523-8527", "doi": "10.1109/ICASSP39728.2021.9414015", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Graph neural networks (GNNs) have achieved remarkable success as a framework\nfor deep learning on graph-structured data. However, GNNs are fundamentally\nlimited by their tree-structured inductive bias: the WL-subtree kernel\nformulation bounds the representational capacity of GNNs, and polynomial-time\nGNNs are provably incapable of recognizing triangles in a graph. In this work,\nwe propose to augment the GNN message-passing operations with information\ndefined on ego graphs (i.e., the induced subgraph surrounding each node). We\nterm these approaches Ego-GNNs and show that Ego-GNNs are provably more\npowerful than standard message-passing GNNs. In particular, we show that\nEgo-GNNs are capable of recognizing closed triangles, which is essential given\nthe prominence of transitivity in real-world graphs. We also motivate our\napproach from the perspective of graph signal processing as a form of multiplex\ngraph convolution. Experimental results on node classification using synthetic\nand real data highlight the achievable performance gains using this approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 23:42:23 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Sandfelder", "Dylan", ""], ["Vijayan", "Priyesh", ""], ["Hamilton", "William L.", ""]]}, {"id": "2107.10960", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Harikrishna Narasimhan, Andrew Cotter", "title": "Implicit Rate-Constrained Optimization of Non-decomposable Objectives", "comments": "ICML 2021; Code available at\n  https://github.com/google-research/google-research/tree/master/implicit_constrained_optimization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a popular family of constrained optimization problems arising in\nmachine learning that involve optimizing a non-decomposable evaluation metric\nwith a certain thresholded form, while constraining another metric of interest.\nExamples of such problems include optimizing the false negative rate at a fixed\nfalse positive rate, optimizing precision at a fixed recall, optimizing the\narea under the precision-recall or ROC curves, etc. Our key idea is to\nformulate a rate-constrained optimization that expresses the threshold\nparameter as a function of the model parameters via the Implicit Function\ntheorem. We show how the resulting optimization problem can be solved using\nstandard gradient based methods. Experiments on benchmark datasets demonstrate\nthe effectiveness of our proposed method over existing state-of-the art\napproaches for these problems. The code for the proposed method is available at\nhttps://github.com/google-research/google-research/tree/master/implicit_constrained_optimization .\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 00:04:39 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 02:05:02 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 00:45:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kumar", "Abhishek", ""], ["Narasimhan", "Harikrishna", ""], ["Cotter", "Andrew", ""]]}, {"id": "2107.10963", "submitter": "Andrey Zhmoginov", "authors": "Andrey Zhmoginov, Dina Bashkirova and Mark Sandler", "title": "Compositional Models: Multi-Task Learning and Knowledge Transfer with\n  Modular Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conditional computation and modular networks have been recently proposed for\nmultitask learning and other problems as a way to decompose problem solving\ninto multiple reusable computational blocks. We propose a new approach for\nlearning modular networks based on the isometric version of ResNet with all\nresidual blocks having the same configuration and the same number of\nparameters. This architectural choice allows adding, removing and changing the\norder of residual blocks. In our method, the modules can be invoked repeatedly\nand allow knowledge transfer to novel tasks by adjusting the order of\ncomputation. This allows soft weight sharing between tasks with only a small\nincrease in the number of parameters. We show that our method leads to\ninterpretable self-organization of modules in case of multi-task learning,\ntransfer learning and domain adaptation while achieving competitive results on\nthose tasks. From practical perspective, our approach allows to: (a) reuse\nexisting modules for learning new task by adjusting the computation order, (b)\nuse it for unsupervised multi-source domain adaptation to illustrate that\nadaptation to unseen data can be achieved by only manipulating the order of\npretrained modules, (c) show how our approach can be used to increase accuracy\nof existing architectures for image classification tasks such as ImageNet,\nwithout any parameter increase, by reusing the same block multiple times.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 00:05:55 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Zhmoginov", "Andrey", ""], ["Bashkirova", "Dina", ""], ["Sandler", "Mark", ""]]}, {"id": "2107.10970", "submitter": "Yu-Chia Chen", "authors": "Yu-Chia Chen, Marina Meil\\u{a}", "title": "The decomposition of the higher-order homology embedding constructed\n  from the $k$-Laplacian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The null space of the $k$-th order Laplacian $\\mathbf{\\mathcal L}_k$, known\nas the {\\em $k$-th homology vector space}, encodes the non-trivial topology of\na manifold or a network. Understanding the structure of the homology embedding\ncan thus disclose geometric or topological information from the data. The study\nof the null space embedding of the graph Laplacian $\\mathbf{\\mathcal L}_0$ has\nspurred new research and applications, such as spectral clustering algorithms\nwith theoretical guarantees and estimators of the Stochastic Block Model. In\nthis work, we investigate the geometry of the $k$-th homology embedding and\nfocus on cases reminiscent of spectral clustering. Namely, we analyze the {\\em\nconnected sum} of manifolds as a perturbation to the direct sum of their\nhomology embeddings. We propose an algorithm to factorize the homology\nembedding into subspaces corresponding to a manifold's simplest topological\ncomponents. The proposed framework is applied to the {\\em shortest homologous\nloop detection} problem, a problem known to be NP-hard in general. Our spectral\nloop detection algorithm scales better than existing methods and is effective\non diverse data such as point clouds and images.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 00:40:01 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 16:14:16 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Yu-Chia", ""], ["Meil\u0103", "Marina", ""]]}, {"id": "2107.10971", "submitter": "Parshin Shojaee", "authors": "Parshin Shojaee, Xiaoyu Chen and Ran Jin", "title": "Adaptively Weighted Top-N Recommendation for Organ Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the shortage of organ donations to meet the demands of patients on\nthe waiting list has being a major challenge in organ transplantation. Because\nof the shortage, organ matching decision is the most critical decision to\nassign the limited viable organs to the most suitable patients. Currently,\norgan matching decisions were only made by matching scores calculated via\nscoring models, which are built by the first principles. However, these models\nmay disagree with the actual post-transplantation matching performance (e.g.,\npatient's post-transplant quality of life (QoL) or graft failure measurements).\nIn this paper, we formulate the organ matching decision-making as a top-N\nrecommendation problem and propose an Adaptively Weighted Top-N Recommendation\n(AWTR) method. AWTR improves performance of the current scoring models by using\nlimited actual matching performance in historical data set as well as the\ncollected covariates from organ donors and patients. AWTR sacrifices the\noverall recommendation accuracy by emphasizing the recommendation and ranking\naccuracy for top-N matched patients. The proposed method is validated in a\nsimulation study, where KAS [60] is used to simulate the organ-patient\nrecommendation response. The results show that our proposed method outperforms\nseven state-of-the-art top-N recommendation benchmark methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 00:42:01 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Shojaee", "Parshin", ""], ["Chen", "Xiaoyu", ""], ["Jin", "Ran", ""]]}, {"id": "2107.10976", "submitter": "Muhammad Asad", "authors": "Muhammad Asad, Ahmed Moustafa, and Takayuki Ito", "title": "Federated Learning Versus Classical Machine Learning: A Convergence\n  Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past few decades, machine learning has revolutionized data processing\nfor large scale applications. Simultaneously, increasing privacy threats in\ntrending applications led to the redesign of classical data training models. In\nparticular, classical machine learning involves centralized data training,\nwhere the data is gathered, and the entire training process executes at the\ncentral server. Despite significant convergence, this training involves several\nprivacy threats on participants' data when shared with the central cloud\nserver. To this end, federated learning has achieved significant importance\nover distributed data training. In particular, the federated learning allows\nparticipants to collaboratively train the local models on local data without\nrevealing their sensitive information to the central cloud server. In this\npaper, we perform a convergence comparison between classical machine learning\nand federated learning on two publicly available datasets, namely,\nlogistic-regression-MNIST dataset and image-classification-CIFAR-10 dataset.\nThe simulation results demonstrate that federated learning achieves higher\nconvergence within limited communication rounds while maintaining participants'\nanonymity. We hope that this research will show the benefits and help federated\nlearning to be implemented widely.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:14:35 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Asad", "Muhammad", ""], ["Moustafa", "Ahmed", ""], ["Ito", "Takayuki", ""]]}, {"id": "2107.10977", "submitter": "Siyuan Yi", "authors": "Siyuan Yi, Xing Chen, Chuanming Tang", "title": "Tsformer: Time series Transformer for tourism demand forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  AI-based methods have been widely applied to tourism demand forecasting.\nHowever, current AI-based methods are short of the ability to process long-term\ndependency, and most of them lack interpretability. The Transformer used\ninitially for machine translation shows an incredible ability to long-term\ndependency processing. Based on the Transformer, we proposed a time series\nTransformer (Tsformer) with Encoder-Decoder architecture for tourism demand\nforecasting. The proposed Tsformer encodes long-term dependency with encoder,\ncaptures short-term dependency with decoder, and simplifies the attention\ninteractions under the premise of highlighting dominant attention through a\nseries of attention masking mechanisms. These improvements make the multi-head\nattention mechanism process the input sequence according to the time\nrelationship, contributing to better interpretability. What's more, the context\nprocessing ability of the Encoder-Decoder architecture allows adopting the\ncalendar of days to be forecasted to enhance the forecasting performance.\nExperiments conducted on the Jiuzhaigou valley and Siguniang mountain tourism\ndemand datasets with other nine baseline methods indicate that the proposed\nTsformer outperformed all baseline models in the short-term and long-term\ntourism demand forecasting tasks. Moreover, ablation studies demonstrate that\nthe adoption of the calendar of days to be forecasted contributes to the\nforecasting performance of the proposed Tsformer. For better interpretability,\nthe attention weight matrix visualization is performed. It indicates that the\nTsformer concentrates on seasonal features and days close to days to be\nforecast in short-term forecasting.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 06:33:20 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yi", "Siyuan", ""], ["Chen", "Xing", ""], ["Tang", "Chuanming", ""]]}, {"id": "2107.10980", "submitter": "Zihao Wang", "authors": "Zihao Wang, Kun Li, Steve Q. Xia, Hongfu Liu", "title": "Economic Recession Prediction Using Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We investigate the effectiveness of different machine learning methodologies\nin predicting economic cycles. We identify the deep learning methodology of\nBi-LSTM with Autoencoder as the most accurate model to forecast the beginning\nand end of economic recessions in the U.S. We adopt commonly-available macro\nand market-condition features to compare the ability of different machine\nlearning models to generate good predictions both in-sample and out-of-sample.\nThe proposed model is flexible and dynamic when both predictive variables and\nmodel coefficients vary over time. It provided good out-of-sample predictions\nfor the past two recessions and early warning about the COVID-19 recession.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 22:55:14 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Wang", "Zihao", ""], ["Li", "Kun", ""], ["Xia", "Steve Q.", ""], ["Liu", "Hongfu", ""]]}, {"id": "2107.10989", "submitter": "Yufei Li", "authors": "Yufei Li, Simin Chen, Wei Yang", "title": "Estimating Predictive Uncertainty Under Program Data Distribution Shift", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep learning (DL) techniques have achieved great success in predictive\naccuracy in a variety of tasks, but deep neural networks (DNNs) are shown to\nproduce highly overconfident scores for even abnormal samples. Well-defined\nuncertainty indicates whether a model's output should (or should not) be\ntrusted and thus becomes critical in real-world scenarios which typically\ninvolves shifted input distributions due to many factors. Existing uncertainty\napproaches assume that testing samples from a different data distribution would\ninduce unreliable model predictions thus have higher uncertainty scores. They\nquantify model uncertainty by calibrating DL model's confidence of a given\ninput and evaluate the effectiveness in computer vision (CV) and natural\nlanguage processing (NLP)-related tasks. However, their methodologies'\nreliability may be compromised under programming tasks due to difference in\ndata representations and shift patterns. In this paper, we first define three\ndifferent types of distribution shift in program data and build a large-scale\nshifted Java dataset. We implement two common programming language tasks on our\ndataset to study the effect of each distribution shift on DL model performance.\nWe also propose a large-scale benchmark of existing state-of-the-art predictive\nuncertainty on programming tasks and investigate their effectiveness under data\ndistribution shift. Experiments show that program distribution shift does\ndegrade the DL model performance to varying degrees and that existing\nuncertainty methods all present certain limitations in quantifying uncertainty\non program dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 01:50:22 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Li", "Yufei", ""], ["Chen", "Simin", ""], ["Yang", "Wei", ""]]}, {"id": "2107.10991", "submitter": "Xu Liu", "authors": "Xu Liu, Xiaoya Zhang, Wei Peng, Weien Zhou, Wen Yao", "title": "A novel meta-learning initialization method for physics-informed neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) have been widely used to solve\nvarious scientific computing problems. However, large training costs limit\nPINNs for some real-time applications. Although some works have been proposed\nto improve the training efficiency of PINNs, few consider the influence of\ninitialization. To this end, we propose a New Reptile initialization based\nPhysics-Informed Neural Network (NRPINN). The original Reptile algorithm is a\nmeta-learning initialization method based on labeled data. PINNs can be trained\nwith less labeled data or even without any labeled data by adding partial\ndifferential equations (PDEs) as a penalty term into the loss function.\nInspired by this idea, we propose the new Reptile initialization to sample more\ntasks from the parameterized PDEs and adapt the penalty term of the loss. The\nnew Reptile initialization can acquire initialization parameters from related\ntasks by supervised, unsupervised, and semi-supervised learning. Then, PINNs\nwith initialization parameters can efficiently solve PDEs. Besides, the new\nReptile initialization can also be used for the variants of PINNs. Finally, we\ndemonstrate and verify the NRPINN considering both forward problems, including\nsolving Poisson, Burgers, and Schr\\\"odinger equations, as well as inverse\nproblems, where unknown parameters in the PDEs are estimated. Experimental\nresults show that the NRPINN training is much faster and achieves higher\naccuracy than PINNs with other initialization methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 01:55:23 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Liu", "Xu", ""], ["Zhang", "Xiaoya", ""], ["Peng", "Wei", ""], ["Zhou", "Weien", ""], ["Yao", "Wen", ""]]}, {"id": "2107.10996", "submitter": "Seyedamin Pouriyeh", "authors": "Osama Shahid, Seyedamin Pouriyeh, Reza M. Parizi, Quan Z. Sheng,\n  Gautam Srivastava, Liang Zhao", "title": "Communication Efficiency in Federated Learning: Achievements and\n  Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is known to perform Machine Learning tasks in a\ndistributed manner. Over the years, this has become an emerging technology\nespecially with various data protection and privacy policies being imposed FL\nallows performing machine learning tasks whilst adhering to these challenges.\nAs with the emerging of any new technology, there are going to be challenges\nand benefits. A challenge that exists in FL is the communication costs, as FL\ntakes place in a distributed environment where devices connected over the\nnetwork have to constantly share their updates this can create a communication\nbottleneck. In this paper, we present a survey of the research that is\nperformed to overcome the communication constraints in an FL setting.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 02:13:11 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Shahid", "Osama", ""], ["Pouriyeh", "Seyedamin", ""], ["Parizi", "Reza M.", ""], ["Sheng", "Quan Z.", ""], ["Srivastava", "Gautam", ""], ["Zhao", "Liang", ""]]}, {"id": "2107.11003", "submitter": "Shengpu Tang", "authors": "Shengpu Tang, Jenna Wiens", "title": "Model Selection for Offline Reinforcement Learning: Practical\n  Considerations for Healthcare Settings", "comments": "33 pages, 9 figures. Machine Learning for Healthcare Conference (MLHC\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) can be used to learn treatment policies and aid\ndecision making in healthcare. However, given the need for generalization over\ncomplex state/action spaces, the incorporation of function approximators (e.g.,\ndeep neural networks) requires model selection to reduce overfitting and\nimprove policy performance at deployment. Yet a standard validation pipeline\nfor model selection requires running a learned policy in the actual\nenvironment, which is often infeasible in a healthcare setting. In this work,\nwe investigate a model selection pipeline for offline RL that relies on\noff-policy evaluation (OPE) as a proxy for validation performance. We present\nan in-depth analysis of popular OPE methods, highlighting the additional\nhyperparameters and computational requirements (fitting/inference of auxiliary\nmodels) when used to rank a set of candidate policies. We compare the utility\nof different OPE methods as part of the model selection pipeline in the context\nof learning to treat patients with sepsis. Among all the OPE methods we\nconsidered, fitted Q evaluation (FQE) consistently leads to the best validation\nranking, but at a high computational cost. To balance this trade-off between\naccuracy of ranking and computational efficiency, we propose a simple two-stage\napproach to accelerate model selection by avoiding potentially unnecessary\ncomputation. Our work serves as a practical guide for offline RL model\nselection and can help RL practitioners select policies using real-world\ndatasets. To facilitate reproducibility and future extensions, the code\naccompanying this paper is available online at\nhttps://github.com/MLD3/OfflineRL_ModelSelection.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 02:41:51 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Tang", "Shengpu", ""], ["Wiens", "Jenna", ""]]}, {"id": "2107.11011", "submitter": "Piotr Teterwak", "authors": "Dina Bashkirova, Dan Hendrycks, Donghyun Kim, Samarth Mishra, Kate\n  Saenko, Kuniaki Saito, Piotr Teterwak, Ben Usman", "title": "VisDA-2021 Competition Universal Domain Adaptation to Improve\n  Performance on Out-of-Distribution Data", "comments": "Neurips 2021 Competition Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in machine learning is typically measured by training and testing a\nmodel on the same distribution of data, i.e., the same domain. This\nover-estimates future accuracy on out-of-distribution data. The Visual Domain\nAdaptation (VisDA) 2021 competition tests models' ability to adapt to novel\ntest distributions and handle distributional shift. We set up unsupervised\ndomain adaptation challenges for image classifiers and will evaluate adaptation\nto novel viewpoints, backgrounds, modalities and degradation in quality. Our\nchallenge draws on large-scale publicly available datasets but constructs the\nevaluation across domains, rather that the traditional in-domain bench-marking.\nFurthermore, we focus on the difficult \"universal\" setting where, in addition\nto input distribution drift, methods may encounter missing and/or novel classes\nin the target dataset. Performance will be measured using a rigorous protocol,\ncomparing to state-of-the-art domain adaptation methods with the help of\nestablished metrics. We believe that the competition will encourage further\nimprovement in machine learning methods' ability to handle realistic data in\nmany deployment scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 03:21:51 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Bashkirova", "Dina", ""], ["Hendrycks", "Dan", ""], ["Kim", "Donghyun", ""], ["Mishra", "Samarth", ""], ["Saenko", "Kate", ""], ["Saito", "Kuniaki", ""], ["Teterwak", "Piotr", ""], ["Usman", "Ben", ""]]}, {"id": "2107.11022", "submitter": "Kai Yao", "authors": "Kai Yao and Kaizhu Huang and Jie Sun and Curran Jude", "title": "AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned\n  Disentangling Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unsupervised cell nuclei segmentation in this paper. Exploiting\nthe recently-proposed unpaired image-to-image translation between cell nuclei\nimages and randomly synthetic masks, existing approaches, e.g., CycleGAN, have\nachieved encouraging results. However, these methods usually take a two-stage\npipeline and fail to learn end-to-end in cell nuclei images. More seriously,\nthey could lead to the lossy transformation problem, i.e., the content\ninconsistency between the original images and the corresponding segmentation\noutput. To address these limitations, we propose a novel end-to-end\nunsupervised framework called Aligned Disentangling Generative Adversarial\nNetwork (AD-GAN). Distinctively, AD-GAN introduces representation\ndisentanglement to separate content representation (the underling spatial\nstructure) from style representation (the rendering of the structure). With\nthis framework, spatial structure can be preserved explicitly, enabling a\nsignificant reduction of macro-level lossy transformation. We also propose a\nnovel training algorithm able to align the disentangled content in the latent\nspace to reduce micro-level lossy transformation. Evaluations on real-world 2D\nand 3D datasets show that AD-GAN substantially outperforms the other comparison\nmethods and the professional software both quantitatively and qualitatively.\nSpecifically, the proposed AD-GAN leads to significant improvement over the\ncurrent best unsupervised methods by an average 17.8% relatively (w.r.t. the\nmetric DICE) on four cell nuclei datasets. As an unsupervised method, AD-GAN\neven performs competitive with the best supervised models, taking a further\nleap towards end-to-end unsupervised nuclei segmentation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 04:08:44 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yao", "Kai", ""], ["Huang", "Kaizhu", ""], ["Sun", "Jie", ""], ["Jude", "Curran", ""]]}, {"id": "2107.11042", "submitter": "Jason T. L. Wang", "authors": "Yasser Abduallah, Jason T. L. Wang, Yucong Shen, Khalid A. Alobaid,\n  Serena Criscuoli, Haimin Wang", "title": "Deep Learning Based Reconstruction of Total Solar Irradiance", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Earth's primary source of energy is the radiant energy generated by the\nSun, which is referred to as solar irradiance, or total solar irradiance (TSI)\nwhen all of the radiation is measured. A minor change in the solar irradiance\ncan have a significant impact on the Earth's climate and atmosphere. As a\nresult, studying and measuring solar irradiance is crucial in understanding\nclimate changes and solar variability. Several methods have been developed to\nreconstruct total solar irradiance for long and short periods of time; however,\nthey are physics-based and rely on the availability of data, which does not go\nbeyond 9,000 years. In this paper we propose a new method, called TSInet, to\nreconstruct total solar irradiance by deep learning for short and long periods\nof time that span beyond the physical models' data availability. On the data\nthat are available, our method agrees well with the state-of-the-art\nphysics-based reconstruction models. To our knowledge, this is the first time\nthat deep learning has been used to reconstruct total solar irradiance for more\nthan 9,000 years.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 06:33:37 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Abduallah", "Yasser", ""], ["Wang", "Jason T. L.", ""], ["Shen", "Yucong", ""], ["Alobaid", "Khalid A.", ""], ["Criscuoli", "Serena", ""], ["Wang", "Haimin", ""]]}, {"id": "2107.11045", "submitter": "Enrique Fernandez-Blanco", "authors": "Enrique Fernandez-Blanco, Carlos Fernandez-Lozano, Alejandro Pazos,\n  Daniel Rivero", "title": "Ensemble of Convolution Neural Networks on Heterogeneous Signals for\n  Sleep Stage Scoring", "comments": "16 pages, 11 tables and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, several approaches have tried to tackle the problem of\nperforming an automatic scoring of the sleeping stages. Although any\npolysomnography usually collects over a dozen of different signals, this\nparticular problem has been mainly tackled by using only the\nElectroencephalograms presented in those records. On the other hand, the other\nrecorded signals have been mainly ignored by most works. This paper explores\nand compares the convenience of using additional signals apart from\nelectroencephalograms. More specifically, this work uses the SHHS-1 dataset\nwith 5,804 patients containing an electromyogram recorded simultaneously as two\nelectroencephalograms. To compare the results, first, the same architecture has\nbeen evaluated with different input signals and all their possible\ncombinations. These tests show how, using more than one signal especially if\nthey are from different sources, improves the results of the classification.\nAdditionally, the best models obtained for each combination of one or more\nsignals have been used in ensemble models and, its performance has been\ncompared showing the convenience of using these multi-signal models to improve\nthe classification. The best overall model, an ensemble of Depth-wise\nSeparational Convolutional Neural Networks, has achieved an accuracy of 86.06\\%\nwith a Cohen's Kappa of 0.80 and a $F_{1}$ of 0.77. Up to date, those are the\nbest results on the complete dataset and it shows a significant improvement in\nthe precision and recall for the most uncommon class in the dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 06:37:38 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Fernandez-Blanco", "Enrique", ""], ["Fernandez-Lozano", "Carlos", ""], ["Pazos", "Alejandro", ""], ["Rivero", "Daniel", ""]]}, {"id": "2107.11046", "submitter": "Brendan Keith", "authors": "Brendan Keith, Ustim Khristenko, Barbara Wohlmuth", "title": "Learning the structure of wind: A data-driven nonlocal turbulence model\n  for the atmospheric boundary layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a novel data-driven approach to modeling the atmospheric boundary\nlayer. This approach leads to a nonlocal, anisotropic synthetic turbulence\nmodel which we refer to as the deep rapid distortion (DRD) model. Our approach\nrelies on an operator regression problem which characterizes the best fitting\ncandidate in a general family of nonlocal covariance kernels parameterized in\npart by a neural network. This family of covariance kernels is expressed in\nFourier space and is obtained from approximate solutions to the Navier--Stokes\nequations at very high Reynolds numbers. Each member of the family incorporates\nimportant physical properties such as mass conservation and a realistic energy\ncascade. The DRD model can be calibrated with noisy data from field\nexperiments. After calibration, the model can be used to generate synthetic\nturbulent velocity fields. To this end, we provide a new numerical method based\non domain decomposition which delivers scalable, memory-efficient turbulence\ngeneration with the DRD model as well as others. We demonstrate the robustness\nof our approach with both filtered and noisy data coming from the 1968 Air\nForce Cambridge Research Laboratory Kansas experiments. Using this data, we\nwitness exceptional accuracy with the DRD model, especially when compared to\nthe International Electrotechnical Commission standard.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 06:41:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Keith", "Brendan", ""], ["Khristenko", "Ustim", ""], ["Wohlmuth", "Barbara", ""]]}, {"id": "2107.11049", "submitter": "Jae Won Cho", "authors": "Jae Won Cho, Dong-Jin Kim, Yunjae Jung, In So Kweon", "title": "MCDAL: Maximum Classifier Discrepancy for Active Learning", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent state-of-the-art active learning methods have mostly leveraged\nGenerative Adversarial Networks (GAN) for sample acquisition; however, GAN is\nusually known to suffer from instability and sensitivity to hyper-parameters.\nIn contrast to these methods, we propose in this paper a novel active learning\nframework that we call Maximum Classifier Discrepancy for Active Learning\n(MCDAL) which takes the prediction discrepancies between multiple classifiers.\nIn particular, we utilize two auxiliary classification layers that learn\ntighter decision boundaries by maximizing the discrepancies among them.\nIntuitively, the discrepancies in the auxiliary classification layers'\npredictions indicate the uncertainty in the prediction. In this regard, we\npropose a novel method to leverage the classifier discrepancies for the\nacquisition function for active learning. We also provide an interpretation of\nour idea in relation to existing GAN based active learning methods and domain\nadaptation frameworks. Moreover, we empirically demonstrate the utility of our\napproach where the performance of our approach exceeds the state-of-the-art\nmethods on several image classification and semantic segmentation datasets in\nactive learning setups.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 06:57:08 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Cho", "Jae Won", ""], ["Kim", "Dong-Jin", ""], ["Jung", "Yunjae", ""], ["Kweon", "In So", ""]]}, {"id": "2107.11053", "submitter": "Guanting Chen", "authors": "Guanting Chen, Johann Demetrio Gaebler, Matt Peng, Chunlin Sun, Yinyu\n  Ye", "title": "An Adaptive State Aggregation Algorithm for Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value iteration is a well-known method of solving Markov Decision Processes\n(MDPs) that is simple to implement and boasts strong theoretical convergence\nguarantees. However, the computational cost of value iteration quickly becomes\ninfeasible as the size of the state space increases. Various methods have been\nproposed to overcome this issue for value iteration in large state and action\nspace MDPs, often at the price, however, of generalizability and algorithmic\nsimplicity. In this paper, we propose an intuitive algorithm for solving MDPs\nthat reduces the cost of value iteration updates by dynamically grouping\ntogether states with similar cost-to-go values. We also prove that our\nalgorithm converges almost surely to within \\(2\\varepsilon / (1 - \\gamma)\\) of\nthe true optimal value in the \\(\\ell^\\infty\\) norm, where \\(\\gamma\\) is the\ndiscount factor and aggregated states differ by at most \\(\\varepsilon\\).\nNumerical experiments on a variety of simulated environments confirm the\nrobustness of our algorithm and its ability to solve MDPs with much cheaper\nupdates especially as the scale of the MDP problem increases.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 07:19:43 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Chen", "Guanting", ""], ["Gaebler", "Johann Demetrio", ""], ["Peng", "Matt", ""], ["Sun", "Chunlin", ""], ["Ye", "Yinyu", ""]]}, {"id": "2107.11056", "submitter": "Tian Pinzhuo", "authors": "Pinzhuo Tian, Yao Gao", "title": "Improving the Generalization of Meta-learning on Unseen Domains via\n  Adversarial Shift", "comments": "v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning provides a promising way for learning to efficiently learn and\nachieves great success in many applications. However, most meta-learning\nliterature focuses on dealing with tasks from a same domain, making it brittle\nto generalize to tasks from the other unseen domains. In this work, we address\nthis problem by simulating tasks from the other unseen domains to improve the\ngeneralization and robustness of meta-learning method. Specifically, we propose\na model-agnostic shift layer to learn how to simulate the domain shift and\ngenerate pseudo tasks, and develop a new adversarial learning-to-learn\nmechanism to train it. Based on the pseudo tasks, the meta-learning model can\nlearn cross-domain meta-knowledge, which can generalize well on unseen domains.\nWe conduct extensive experiments under the domain generalization setting.\nExperimental results demonstrate that the proposed shift layer is applicable to\nvarious meta-learning frameworks. Moreover, our method also leads to\nstate-of-the-art performance on different cross-domain few-shot classification\nbenchmarks and produces good results on cross-domain few-shot regression.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 07:29:30 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Tian", "Pinzhuo", ""], ["Gao", "Yao", ""]]}, {"id": "2107.11059", "submitter": "Mario W\\\"uthrich V.", "authors": "Ronald Richman and Mario V. W\\\"uthrich", "title": "LocalGLMnet: interpretable deep learning for tabular data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.ST stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning models have gained great popularity in statistical modeling\nbecause they lead to very competitive regression models, often outperforming\nclassical statistical models such as generalized linear models. The\ndisadvantage of deep learning models is that their solutions are difficult to\ninterpret and explain, and variable selection is not easily possible because\ndeep learning models solve feature engineering and variable selection\ninternally in a nontransparent way. Inspired by the appealing structure of\ngeneralized linear models, we propose a new network architecture that shares\nsimilar features as generalized linear models, but provides superior predictive\npower benefiting from the art of representation learning. This new architecture\nallows for variable selection of tabular data and for interpretation of the\ncalibrated deep learning model, in fact, our approach provides an additive\ndecomposition in the spirit of Shapley values and integrated gradients.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 07:38:33 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Richman", "Ronald", ""], ["W\u00fcthrich", "Mario V.", ""]]}, {"id": "2107.11077", "submitter": "Petia Koprinkova-Hristova", "authors": "Petia Koprinkova-Hristova", "title": "Reservoir Computing Approach for Gray Images Segmentation", "comments": "12 pages, 7 figures, submitted to conference ICANN 2021 but not\n  accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper proposes a novel approach for gray scale images segmentation. It is\nbased on multiple features extraction from single feature per image pixel,\nnamely its intensity value, using Echo state network. The newly extracted\nfeatures -- reservoir equilibrium states -- reveal hidden image characteristics\nthat improve its segmentation via a clustering algorithm. Moreover, it was\ndemonstrated that the intrinsic plasticity tuning of reservoir fits its\nequilibrium states to the original image intensity distribution thus allowing\nfor its better segmentation. The proposed approach is tested on the benchmark\nimage Lena.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 08:37:24 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Koprinkova-Hristova", "Petia", ""]]}, {"id": "2107.11078", "submitter": "Jose Manuel Navarro", "authors": "Jose M. Navarro, Dario Rossi", "title": "HURRA! Human readable router anomaly detection", "comments": null, "journal-ref": "2020 32nd International Teletraffic Congress (ITC 32), Electronic\n  ISBN:978-3-948377-02-1, Print on Demand(PoD) ISBN:978-1-7281-9073-0", "doi": "10.1109/ITC3249928.2020.00011", "report-no": null, "categories": "cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents HURRA, a system that aims to reduce the time spent by\nhuman operators in the process of network troubleshooting. To do so, it\ncomprises two modules that are plugged after any anomaly detection algorithm:\n(i) a first attention mechanism, that ranks the present features in terms of\ntheir relation with the anomaly and (ii) a second module able to incorporates\nprevious expert knowledge seamlessly, without any need of human interaction nor\ndecisions. We show the efficacy of these simple processes on a collection of\nreal router datasets obtained from tens of ISPs which exhibit a rich variety of\nanomalies and very heterogeneous set of KPIs, on which we gather manually\nannotated ground truth by the operator solving the troubleshooting ticket. Our\nexperimental evaluation shows that (i) the proposed system is effective in\nachieving high levels of agreement with the expert, that (ii) even a simple\nstatistical approach is able to extracting useful information from expert\nknowledge gained in past cases to further improve performance and finally that\n(iii) the main difficulty in live deployment concerns the automated selection\nof the anomaly detection algorithm and the tuning of its hyper-parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 08:38:29 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Navarro", "Jose M.", ""], ["Rossi", "Dario", ""]]}, {"id": "2107.11085", "submitter": "Patrik Puchert", "authors": "Patrik Puchert, Pedro Hermosilla, Tobias Ritschel, Timo Ropinski", "title": "Data-driven deep density estimation", "comments": "35 pages, 25 figures. Puplished in Neural Computing and Applications\n  (2021). The method described is available as python pip pachage\n  deep_density_estimation and on github https://github.com/trikpachu/ DDE", "journal-ref": null, "doi": "10.1007/s00521-021-06281-3", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Density estimation plays a crucial role in many data analysis tasks, as it\ninfers a continuous probability density function (PDF) from discrete samples.\nThus, it is used in tasks as diverse as analyzing population data, spatial\nlocations in 2D sensor readings, or reconstructing scenes from 3D scans. In\nthis paper, we introduce a learned, data-driven deep density estimation (DDE)\nto infer PDFs in an accurate and efficient manner, while being independent of\ndomain dimensionality or sample size. Furthermore, we do not require access to\nthe original PDF during estimation, neither in parametric form, nor as priors,\nor in the form of many samples. This is enabled by training an unstructured\nconvolutional neural network on an infinite stream of synthetic PDFs, as\nunbound amounts of synthetic training data generalize better across a deck of\nnatural PDFs than any natural finite training data will do. Thus, we hope that\nour publicly available DDE method will be beneficial in many areas of data\nanalysis, where continuous models are to be estimated from discrete\nobservations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 08:53:46 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Puchert", "Patrik", ""], ["Hermosilla", "Pedro", ""], ["Ritschel", "Tobias", ""], ["Ropinski", "Timo", ""]]}, {"id": "2107.11098", "submitter": "Eoin Brophy", "authors": "Eoin Brophy, Zhengwei Wang, Qi She, Tomas Ward", "title": "Generative adversarial networks in time series: A survey and taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative adversarial networks (GANs) studies have grown exponentially in\nthe past few years. Their impact has been seen mainly in the computer vision\nfield with realistic image and video manipulation, especially generation,\nmaking significant advancements. While these computer vision advances have\ngarnered much attention, GAN applications have diversified across disciplines\nsuch as time series and sequence generation. As a relatively new niche for\nGANs, fieldwork is ongoing to develop high quality, diverse and private time\nseries data. In this paper, we review GAN variants designed for time series\nrelated applications. We propose a taxonomy of discrete-variant GANs and\ncontinuous-variant GANs, in which GANs deal with discrete time series and\ncontinuous time series data. Here we showcase the latest and most popular\nliterature in this field; their architectures, results, and applications. We\nalso provide a list of the most popular evaluation metrics and their\nsuitability across applications. Also presented is a discussion of privacy\nmeasures for these GANs and further protections and directions for dealing with\nsensitive data. We aim to frame clearly and concisely the latest and\nstate-of-the-art research in this area and their applications to real-world\ntechnologies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:38:51 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Brophy", "Eoin", ""], ["Wang", "Zhengwei", ""], ["She", "Qi", ""], ["Ward", "Tomas", ""]]}, {"id": "2107.11099", "submitter": "Yu Jing", "authors": "Yu Jing, Yang Yang, Chonghang Wu, Wenbing Fu, Wei Hu, Xiaogang Li and\n  Hua Xu", "title": "RGB Image Classification with Quantum Convolutional Ansaetze", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of qubit numbers and coherence times in quantum\nhardware technology, implementing shallow neural networks on the so-called\nNoisy Intermediate-Scale Quantum (NISQ) devices has attracted a lot of\ninterest. Many quantum (convolutional) circuit ansaetze are proposed for\ngrayscale images classification tasks with promising empirical results.\nHowever, when applying these ansaetze on RGB images, the intra-channel\ninformation that is useful for vision tasks is not extracted effectively. In\nthis paper, we propose two types of quantum circuit ansaetze to simulate\nconvolution operations on RGB images, which differ in the way how inter-channel\nand intra-channel information are extracted. To the best of our knowledge, this\nis the first work of a quantum convolutional circuit to deal with RGB images\neffectively, with a higher test accuracy compared to the purely classical CNNs.\nWe also investigate the relationship between the size of quantum circuit ansatz\nand the learnability of the hybrid quantum-classical convolutional neural\nnetwork. Through experiments based on CIFAR-10 and MNIST datasets, we\ndemonstrate that a larger size of the quantum circuit ansatz improves\npredictive performance in multiclass classification tasks, providing useful\ninsights for near term quantum algorithm developments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:38:59 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Jing", "Yu", ""], ["Yang", "Yang", ""], ["Wu", "Chonghang", ""], ["Fu", "Wenbing", ""], ["Hu", "Wei", ""], ["Li", "Xiaogang", ""], ["Xu", "Hua", ""]]}, {"id": "2107.11107", "submitter": "Ahmed Al-Saffar", "authors": "A. Al-Saffar, L. Guo, A. Abbosh", "title": "Introducing: DeepHead, Wide-band Electromagnetic Imaging Paradigm", "comments": "Under review, major revision", "journal-ref": "IEEE-TCI 2021", "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Electromagnetic medical imaging in the microwave regime is a hard problem\nnotorious for 1) instability 2) under-determinism. This two-pronged problem is\ntackled with a two-pronged solution that uses double compression to maximally\nutilizing the cheap unlabelled data to a) provide a priori information required\nto ease under-determinism and b) reduce sensitivity of inference to the input.\nThe result is a stable solver with a high resolution output. DeepHead is a\nfully data-driven implementation of the paradigm proposed in the context of\nmicrowave brain imaging. It infers the dielectric distribution of the brain at\na desired single frequency while making use of an input that spreads over a\nwide band of frequencies. The performance of the model is evaluated with both\nsimulations and human volunteers experiments. The inference made is juxtaposed\nwith ground-truth dielectric distribution in simulation case, and the golden\nMRI / CT imaging modalities of the volunteers in real-world case.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:49:04 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Al-Saffar", "A.", ""], ["Guo", "L.", ""], ["Abbosh", "A.", ""]]}, {"id": "2107.11113", "submitter": "Wenxuan Hu", "authors": "Binling Wang, Wenxuan Hu, Jing Li, Yiming Zhi, Zheng Li, Qingyang\n  Hong, Lin Li, Dong Wang, Liming Song and Cheng Yang", "title": "OLR 2021 Challenge: Datasets, Rules and Baselines", "comments": "arXiv admin note: text overlap with arXiv:2006.03473,\n  arXiv:1907.07626, arXiv:1806.00616, arXiv:1706.09742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the sixth Oriental Language Recognition (OLR) 2021\nChallenge, which intends to improve the performance of language recognition\nsystems and speech recognition systems within multilingual scenarios. The data\nprofile, four tasks, two baselines, and the evaluation principles are\nintroduced in this paper. In addition to the Language Identification (LID)\ntasks, multilingual Automatic Speech Recognition (ASR) tasks are introduced to\nOLR 2021 Challenge for the first time. The challenge this year focuses on more\npractical and challenging problems, with four tasks: (1) constrained LID, (2)\nunconstrained LID, (3) constrained multilingual ASR, (4) unconstrained\nmultilingual ASR. Baselines for LID tasks and multilingual ASR tasks are\nprovided, respectively. The LID baseline system is an extended TDNN x-vector\nmodel constructed with Pytorch. A transformer-based end-to-end model is\nprovided as the multilingual ASR baseline system. These recipes will be online\npublished, and available for participants to construct their own LID or ASR\nsystems. The baseline results demonstrate that those tasks are rather\nchallenging and deserve more effort to achieve better performance.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:57:29 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Wang", "Binling", ""], ["Hu", "Wenxuan", ""], ["Li", "Jing", ""], ["Zhi", "Yiming", ""], ["Li", "Zheng", ""], ["Hong", "Qingyang", ""], ["Li", "Lin", ""], ["Wang", "Dong", ""], ["Song", "Liming", ""], ["Yang", "Cheng", ""]]}, {"id": "2107.11114", "submitter": "Alban Farchi", "authors": "Alban Farchi, Marc Bocquet, Patrick Laloyaux, Massimo Bonavita,\n  Quentin Malartic", "title": "A comparison of combined data assimilation and machine learning methods\n  for offline and online model error correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that it is possible to combine machine learning\nmethods with data assimilation to reconstruct a dynamical system using only\nsparse and noisy observations of that system. The same approach can be used to\ncorrect the error of a knowledge-based model. The resulting surrogate model is\nhybrid, with a statistical part supplementing a physical part. In practice, the\ncorrection can be added as an integrated term (i.e. in the model resolvent) or\ndirectly inside the tendencies of the physical model. The resolvent correction\nis easy to implement. The tendency correction is more technical, in particular\nit requires the adjoint of the physical model, but also more flexible. We use\nthe two-scale Lorenz model to compare the two methods. The accuracy in\nlong-range forecast experiments is somewhat similar between the surrogate\nmodels using the resolvent correction and the tendency correction. By contrast,\nthe surrogate models using the tendency correction significantly outperform the\nsurrogate models using the resolvent correction in data assimilation\nexperiments. Finally, we show that the tendency correction opens the\npossibility to make online model error correction, i.e. improving the model\nprogressively as new observations become available. The resulting algorithm can\nbe seen as a new formulation of weak-constraint 4D-Var. We compare online and\noffline learning using the same framework with the two-scale Lorenz system, and\nshow that with online learning, it is possible to extract all the information\nfrom sparse and noisy observations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 09:57:45 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Farchi", "Alban", ""], ["Bocquet", "Marc", ""], ["Laloyaux", "Patrick", ""], ["Bonavita", "Massimo", ""], ["Malartic", "Quentin", ""]]}, {"id": "2107.11136", "submitter": "Di Wang", "authors": "Lijie Hu and Shuo Ni and Hanshen Xiao and Di Wang", "title": "High Dimensional Differentially Private Stochastic Optimization with\n  Heavy-tailed Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As one of the most fundamental problems in machine learning, statistics and\ndifferential privacy, Differentially Private Stochastic Convex Optimization\n(DP-SCO) has been extensively studied in recent years. However, most of the\nprevious work can only handle either regular data distribution or irregular\ndata in the low dimensional space case. To better understand the challenges\narising from irregular data distribution, in this paper we provide the first\nstudy on the problem of DP-SCO with heavy-tailed data in the high dimensional\nspace. In the first part we focus on the problem over some polytope constraint\n(such as the $\\ell_1$-norm ball). We show that if the loss function is smooth\nand its gradient has bounded second order moment, it is possible to get a (high\nprobability) error bound (excess population risk) of $\\tilde{O}(\\frac{\\log\nd}{(n\\epsilon)^\\frac{1}{3}})$ in the $\\epsilon$-DP model, where $n$ is the\nsample size and $d$ is the dimensionality of the underlying space. Next, for\nLASSO, if the data distribution that has bounded fourth-order moments, we\nimprove the bound to $\\tilde{O}(\\frac{\\log d}{(n\\epsilon)^\\frac{2}{5}})$ in the\n$(\\epsilon, \\delta)$-DP model. In the second part of the paper, we study sparse\nlearning with heavy-tailed data. We first revisit the sparse linear model and\npropose a truncated DP-IHT method whose output could achieve an error of\n$\\tilde{O}(\\frac{s^{*2}\\log d}{n\\epsilon})$, where $s^*$ is the sparsity of the\nunderlying parameter. Then we study a more general problem over the sparsity\n({\\em i.e.,} $\\ell_0$-norm) constraint, and show that it is possible to achieve\nan error of $\\tilde{O}(\\frac{s^{*\\frac{3}{2}}\\log d}{n\\epsilon})$, which is\nalso near optimal up to a factor of $\\tilde{O}{(\\sqrt{s^*})}$, if the loss\nfunction is smooth and strongly convex.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 11:03:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Hu", "Lijie", ""], ["Ni", "Shuo", ""], ["Xiao", "Hanshen", ""], ["Wang", "Di", ""]]}, {"id": "2107.11153", "submitter": "James Whittington", "authors": "James C.R. Whittington, Rishabh Kabra, Loic Matthey, Christopher P.\n  Burgess, Alexander Lerchner", "title": "Constellation: Learning relational abstractions over objects for\n  compositional imagination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning structured representations of visual scenes is currently a major\nbottleneck to bridging perception with reasoning. While there has been exciting\nprogress with slot-based models, which learn to segment scenes into sets of\nobjects, learning configurational properties of entire groups of objects is\nstill under-explored. To address this problem, we introduce Constellation, a\nnetwork that learns relational abstractions of static visual scenes, and\ngeneralises these abstractions over sensory particularities, thus offering a\npotential basis for abstract relational reasoning. We further show that this\nbasis, along with language association, provides a means to imagine sensory\ncontent in new ways. This work is a first step in the explicit representation\nof visual relationships and using them for complex cognitive procedures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 11:59:40 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Whittington", "James C. R.", ""], ["Kabra", "Rishabh", ""], ["Matthey", "Loic", ""], ["Burgess", "Christopher P.", ""], ["Lerchner", "Alexander", ""]]}, {"id": "2107.11156", "submitter": "Andrzej Opala", "authors": "Andrzej Opala, Riccardo Panico, Vincenzo Ardizzone, Barbara Pietka,\n  Jacek Szczytko, Daniele Sanvitto, Micha{\\l} Matuszewski, Dario Ballarini", "title": "Teaching a neural network with non-tunable exciton-polariton nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.quant-gas", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to software simulations of neural networks, hardware or\nneuromorphic implementations have often limited or no tunability. While such\nnetworks promise great improvements in terms of speed and energy efficiency,\ntheir performance is limited by the difficulty to apply efficient teaching. We\npropose a system of non-tunable exciton-polariton nodes and an efficient\nteaching method that relies on the precise measurement of the nonlinear node\nresponse and the subsequent use of the backpropagation algorithm. We\ndemonstrate experimentally that the classification accuracy in the MNIST\nhandwritten digit benchmark is greatly improved compared to the case where\nbackpropagation is not used.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 12:04:38 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Opala", "Andrzej", ""], ["Panico", "Riccardo", ""], ["Ardizzone", "Vincenzo", ""], ["Pietka", "Barbara", ""], ["Szczytko", "Jacek", ""], ["Sanvitto", "Daniele", ""], ["Matuszewski", "Micha\u0142", ""], ["Ballarini", "Dario", ""]]}, {"id": "2107.11167", "submitter": "Sebastian Panman De Wit", "authors": "J.S. Panman de Wit, J. van der Ham, D. Bucur", "title": "Dynamic detection of mobile malware using smartphone data and machine\n  learning", "comments": "14 pages content, 22 pages total, to be published in ACM DTRAP\n  (currently in last revision phase)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Mobile malware are malicious programs that target mobile devices. They are an\nincreasing problem, as seen in the rise of detected mobile malware samples per\nyear. The number of active smartphone users is expected to grow, stressing the\nimportance of research on the detection of mobile malware. Detection methods\nfor mobile malware exist but are still limited.\n  In this paper, we provide an overview of the performance of machine learning\n(ML) techniques to detect malware on Android, without using privileged access.\nThe ML-classifiers use device information such as the CPU usage, battery usage,\nand memory usage for the detection of 10 subtypes of Mobile Trojans on the\nAndroid Operating System (OS).\n  We use a real-life dataset containing device and malware data from 47 users\nfor a year (2016). We examine which features, i.e. aspects, of a device, are\nmost important to monitor to detect (subtypes of) Mobile Trojans. The focus of\nthis paper is on dynamic hardware features. Using these dynamic features we\napply state-of-the-art machine learning classifiers: Random Forest, K-Nearest\nNeighbour, and AdaBoost. We show classification results on different feature\nsets, making a distinction between global device features, and specific app\nfeatures. None of the measured feature sets require privileged access.\n  Our results show that the Random Forest classifier performs best as a general\nmalware classifier: across 10 subtypes of Mobile Trojans, it achieves an F1\nscore of 0.73 with a False Positive Rate (FPR) of 0.009 and a False Negative\nRate (FNR) of 0.380. The Random Forest, K-Nearest Neighbours, and AdaBoost\nclassifiers achieve F1 scores above 0.72, an FPR below 0.02 and, an FNR below\n0.33, when trained separately to detect each subtype of Mobile Trojans.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 12:33:14 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["de Wit", "J. S. Panman", ""], ["van der Ham", "J.", ""], ["Bucur", "D.", ""]]}, {"id": "2107.11170", "submitter": "Lusine Abrahamyan", "authors": "Lusine Abrahamyan, Valentin Ziatchin, Yiming Chen and Nikos\n  Deligiannis", "title": "Bias Loss for Mobile Neural Networks", "comments": "Accepted at ICCV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compact convolutional neural networks (CNNs) have witnessed exceptional\nimprovements in performance in recent years. However, they still fail to\nprovide the same predictive power as CNNs with a large number of parameters.\nThe diverse and even abundant features captured by the layers is an important\ncharacteristic of these successful CNNs. However, differences in this\ncharacteristic between large CNNs and their compact counterparts have rarely\nbeen investigated. In compact CNNs, due to the limited number of parameters,\nabundant features are unlikely to be obtained, and feature diversity becomes an\nessential characteristic. Diverse features present in the activation maps\nderived from a data point during model inference may indicate the presence of a\nset of unique descriptors necessary to distinguish between objects of different\nclasses. In contrast, data points with low feature diversity may not provide a\nsufficient amount of unique descriptors to make a valid prediction; we refer to\nthem as random predictions. Random predictions can negatively impact the\noptimization process and harm the final performance. This paper proposes\naddressing the problem raised by random predictions by reshaping the standard\ncross-entropy to make it biased toward data points with a limited number of\nunique descriptive features. Our novel Bias Loss focuses the training on a set\nof valuable data points and prevents the vast number of samples with poor\nlearning features from misleading the optimization process. Furthermore, to\nshow the importance of diversity, we present a family of SkipNet models whose\narchitectures are brought to boost the number of unique descriptors in the last\nlayers. Our Skipnet-M can achieve 1% higher classification accuracy than\nMobileNetV3 Large.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 12:37:56 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 14:41:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Abrahamyan", "Lusine", ""], ["Ziatchin", "Valentin", ""], ["Chen", "Yiming", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "2107.11181", "submitter": "Huyen N. Nguyen", "authors": "Huyen N. Nguyen, Jake Gonzalez, Jian Guo, Ngan V.T. Nguyen, and Tommy\n  Dang", "title": "VisMCA: A Visual Analytics System for Misclassification Correction and\n  Analysis. VAST Challenge 2020, Mini-Challenge 2 Award: Honorable Mention for\n  Detailed Analysis of Patterns of Misclassification", "comments": null, "journal-ref": "IEEE Conference on Visual Analytics Science and Technology (VAST)\n  2020", "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents VisMCA, an interactive visual analytics system that\nsupports deepening understanding in ML results, augmenting users' capabilities\nin correcting misclassification, and providing an analysis of underlying\npatterns, in response to the VAST Challenge 2020 Mini-Challenge 2. VisMCA\nfacilitates tracking provenance and provides a comprehensive view of object\ndetection results, easing re-labeling, and producing reliable, corrected data\nfor future training. Our solution implements multiple analytical views on\nvisual analysis to offer a deep insight for underlying pattern discovery.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 09:02:57 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Nguyen", "Huyen N.", ""], ["Gonzalez", "Jake", ""], ["Guo", "Jian", ""], ["Nguyen", "Ngan V. T.", ""], ["Dang", "Tommy", ""]]}, {"id": "2107.11186", "submitter": "Yotam Nitzan", "authors": "Yotam Nitzan, Rinon Gal, Ofir Brenner, Daniel Cohen-Or", "title": "LARGE: Latent-Based Regression through GAN Semantics", "comments": "Code at https://github.com/YotamNitzan/LARGE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for solving regression tasks using few-shot or weak\nsupervision. At the core of our method is the fundamental observation that GANs\nare incredibly successful at encoding semantic information within their latent\nspace, even in a completely unsupervised setting. For modern generative\nframeworks, this semantic encoding manifests as smooth, linear directions which\naffect image attributes in a disentangled manner. These directions have been\nwidely used in GAN-based image editing. We show that such directions are not\nonly linear, but that the magnitude of change induced on the respective\nattribute is approximately linear with respect to the distance traveled along\nthem. By leveraging this observation, our method turns a pre-trained GAN into a\nregression model, using as few as two labeled samples. This enables solving\nregression tasks on datasets and attributes which are difficult to produce\nquality supervision for. Additionally, we show that the same latent-distances\ncan be used to sort collections of images by the strength of given attributes,\neven in the absence of explicit supervision. Extensive experimental evaluations\ndemonstrate that our method can be applied across a wide range of domains,\nleverage multiple latent direction discovery frameworks, and achieve\nstate-of-the-art results in few-shot and low-supervision settings, even when\ncompared to methods designed to tackle a single task.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:55:35 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Nitzan", "Yotam", ""], ["Gal", "Rinon", ""], ["Brenner", "Ofir", ""], ["Cohen-Or", "Daniel", ""]]}, {"id": "2107.11191", "submitter": "Margaret Duff", "authors": "Margaret Duff, Neill D. F. Campbell, Matthias J. Ehrhardt", "title": "Regularising Inverse Problems with Generative Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network approaches to inverse imaging problems have produced\nimpressive results in the last few years. In this paper, we consider the use of\ngenerative models in a variational regularisation approach to inverse problems.\nThe considered regularisers penalise images that are far from the range of a\ngenerative model that has learned to produce images similar to a training\ndataset. We name this family \\textit{generative regularisers}. The success of\ngenerative regularisers depends on the quality of the generative model and so\nwe propose a set of desired criteria to assess models and guide future\nresearch. In our numerical experiments, we evaluate three common generative\nmodels, autoencoders, variational autoencoders and generative adversarial\nnetworks, against our desired criteria. We also test three different generative\nregularisers on the inverse problems of deblurring, deconvolution, and\ntomography. We show that the success of solutions restricted to lie exactly in\nthe range of the generator is highly dependent on the ability of the generative\nmodel but that allowing small deviations from the range of the generator\nproduces more consistent results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 15:47:36 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Duff", "Margaret", ""], ["Campbell", "Neill D. F.", ""], ["Ehrhardt", "Matthias J.", ""]]}, {"id": "2107.11214", "submitter": "Patrik Puchert", "authors": "Patrik Puchert, Timo Ropinski", "title": "Human Pose Estimation from Sparse Inertial Measurements through\n  Recurrent Graph Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose the adjacency adaptive graph convolutional long-short term memory\nnetwork (AAGC-LSTM) for human pose estimation from sparse inertial\nmeasurements, obtained from only 6 measurement units. The AAGC-LSTM combines\nboth spatial and temporal dependency in a single network operation. This is\nmade possible by equipping graph convolutions with adjacency adaptivity, which\nalso allows for learning unknown dependencies of the human body joints. To\nfurther boost accuracy, we propose longitudinal loss weighting to consider\nnatural movement patterns, as well as body-aware contralateral data\naugmentation. By combining these contributions, we are able to utilize the\ninherent graph nature of the human body, and can thus outperform the state of\nthe art for human pose estimation from sparse inertial measurements.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:23:10 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Puchert", "Patrik", ""], ["Ropinski", "Timo", ""]]}, {"id": "2107.11225", "submitter": "Dhruv Jawali", "authors": "Dhruv Jawali, Abhishek Kumar and Chandra Sekhar Seelamantula", "title": "Wavelet Design in a Learning Framework", "comments": "This work has been submitted to the IEEE Transactions on Pattern\n  Analysis and Machine Intelligence for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wavelets have proven to be highly successful in several signal and image\nprocessing applications. Wavelet design has been an active field of research\nfor over two decades, with the problem often being approached from an\nanalytical perspective. In this paper, we introduce a learning based approach\nto wavelet design. We draw a parallel between convolutional autoencoders and\nwavelet multiresolution approximation, and show how the learning angle provides\na coherent computational framework for addressing the design problem. We aim at\ndesigning data-independent wavelets by training filterbank autoencoders, which\nprecludes the need for customized datasets. In fact, we use high-dimensional\nGaussian vectors for training filterbank autoencoders, and show that a\nnear-zero training loss implies that the learnt filters satisfy the perfect\nreconstruction property with very high probability. Properties of a wavelet\nsuch as orthogonality, compact support, smoothness, symmetry, and vanishing\nmoments can be incorporated by designing the autoencoder architecture\nappropriately and with a suitable regularization term added to the mean-squared\nerror cost used in the learning process. Our approach not only recovers the\nwell known Daubechies family of orthogonal wavelets and the\nCohen-Daubechies-Feauveau family of symmetric biorthogonal wavelets, but also\nlearns wavelets outside these families.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:34:49 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Jawali", "Dhruv", ""], ["Kumar", "Abhishek", ""], ["Seelamantula", "Chandra Sekhar", ""]]}, {"id": "2107.11228", "submitter": "Yaoqing Yang", "authors": "Yaoqing Yang, Liam Hodgkinson, Ryan Theisen, Joe Zou, Joseph E.\n  Gonzalez, Kannan Ramchandran, Michael W. Mahoney", "title": "Taxonomizing local versus global structure in neural network loss\n  landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Viewing neural network models in terms of their loss landscapes has a long\nhistory in the statistical mechanics approach to learning, and in recent years\nit has received attention within machine learning proper. Among other things,\nlocal metrics (such as the smoothness of the loss landscape) have been shown to\ncorrelate with global properties of the model (such as good generalization).\nHere, we perform a detailed empirical analysis of the loss landscape structure\nof thousands of neural network models, systematically varying learning tasks,\nmodel architectures, and/or quantity/quality of data. By considering a range of\nmetrics that attempt to capture different aspects of the loss landscape, we\ndemonstrate that the best test accuracy is obtained when: the loss landscape is\nglobally well-connected; ensembles of trained models are more similar to each\nother; and models converge to locally smooth regions. We also show that\nglobally poorly-connected landscapes can arise when models are small or when\nthey are trained to lower quality data; and that, if the loss landscape is\nglobally poorly-connected, then training to zero loss can actually lead to\nworse test accuracy. Based on these results, we develop a simple\none-dimensional model with load-like and temperature-like parameters, we\nintroduce the notion of an \\emph{effective loss landscape} depending on these\nparameters, and we interpret our results in terms of a \\emph{rugged convexity}\nof the loss landscape. When viewed through this lens, our detailed empirical\nresults shed light on phases of learning (and consequent double descent\nbehavior), fundamental versus incidental determinants of good generalization,\nthe role of load-like and temperature-like parameters in the learning process,\ndifferent influences on the loss landscape from model and data, and the\nrelationships between local and global metrics, all topics of recent interest.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:37:14 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yang", "Yaoqing", ""], ["Hodgkinson", "Liam", ""], ["Theisen", "Ryan", ""], ["Zou", "Joe", ""], ["Gonzalez", "Joseph E.", ""], ["Ramchandran", "Kannan", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2107.11238", "submitter": "Th\\'eo Estienne", "authors": "Th\\'eo Estienne, Maria Vakalopoulou, Stergios Christodoulidis, Enzo\n  Battistella, Th\\'eophraste Henry, Marvin Lerousseau, Amaury Leroy, Guillaume\n  Chassagnon, Marie-Pierre Revel, Nikos Paragios and Eric Deutsch", "title": "Exploring Deep Registration Latent Spaces", "comments": "13 pages, 5 figures + 3 figures in supplementary materials Accepted\n  to DART 2021 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Explainability of deep neural networks is one of the most challenging and\ninteresting problems in the field. In this study, we investigate the topic\nfocusing on the interpretability of deep learning-based registration methods.\nIn particular, with the appropriate model architecture and using a simple\nlinear projection, we decompose the encoding space, generating a new basis, and\nwe empirically show that this basis captures various decomposed anatomically\naware geometrical transformations. We perform experiments using two different\ndatasets focusing on lungs and hippocampus MRI. We show that such an approach\ncan decompose the highly convoluted latent spaces of registration pipelines in\nan orthogonal space with several interesting properties. We hope that this work\ncould shed some light on a better understanding of deep learning-based\nregistration methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 13:54:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Estienne", "Th\u00e9o", ""], ["Vakalopoulou", "Maria", ""], ["Christodoulidis", "Stergios", ""], ["Battistella", "Enzo", ""], ["Henry", "Th\u00e9ophraste", ""], ["Lerousseau", "Marvin", ""], ["Leroy", "Amaury", ""], ["Chassagnon", "Guillaume", ""], ["Revel", "Marie-Pierre", ""], ["Paragios", "Nikos", ""], ["Deutsch", "Eric", ""]]}, {"id": "2107.11247", "submitter": "Xuan Kan", "authors": "Xuan Kan, Hejie Cui, Ying Guo, Carl Yang", "title": "Effective and Interpretable fMRI Analysis via Functional Brain Network\n  Generation", "comments": "This paper has been accepted for ICML 2021 Workshop for Interpretable\n  Machine Learning in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies in neuroscience show great potential of functional brain\nnetworks constructed from fMRI data for popularity modeling and clinical\npredictions. However, existing functional brain networks are noisy and unaware\nof downstream prediction tasks, while also incompatible with recent powerful\nmachine learning models of GNNs. In this work, we develop an end-to-end\ntrainable pipeline to extract prominent fMRI features, generate brain networks,\nand make predictions with GNNs, all under the guidance of downstream prediction\ntasks. Preliminary experiments on the PNC fMRI data show the superior\neffectiveness and unique interpretability of our framework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:04:59 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Kan", "Xuan", ""], ["Cui", "Hejie", ""], ["Guo", "Ying", ""], ["Yang", "Carl", ""]]}, {"id": "2107.11250", "submitter": "Axel Marmoret", "authors": "Axel Marmoret, Nancy Bertin, Jeremy Cohen", "title": "Multi-Channel Automatic Music Transcription Using Tensor Algebra", "comments": "40 pages, 14 figues, 5 tables, code can be found at:\n  https://gitlab.inria.fr/amarmore/nonnegative-factorization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Music is an art, perceived in unique ways by every listener, coming from\nacoustic signals. In the meantime, standards as musical scores exist to\ndescribe it. Even if humans can make this transcription, it is costly in terms\nof time and efforts, even more with the explosion of information consecutively\nto the rise of the Internet. In that sense, researches are driven in the\ndirection of Automatic Music Transcription. While this task is considered\nsolved in the case of single notes, it is still open when notes superpose\nthemselves, forming chords. This report aims at developing some of the existing\ntechniques towards Music Transcription, particularly matrix factorization, and\nintroducing the concept of multi-channel automatic music transcription. This\nconcept will be explored with mathematical objects called tensors.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:07:40 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Marmoret", "Axel", ""], ["Bertin", "Nancy", ""], ["Cohen", "Jeremy", ""]]}, {"id": "2107.11253", "submitter": "Quentin Malartic", "authors": "Quentin Malartic, Alban Farchi, Marc Bocquet", "title": "State, global and local parameter estimation using local ensemble Kalman\n  filters: applications to online machine learning of chaotic dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG nlin.CD physics.ao-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent methodological paper, we have shown how to learn chaotic dynamics\nalong with the state trajectory from sequentially acquired observations, using\nlocal ensemble Kalman filters. Here, we more systematically investigate the\npossibilty to use a local ensemble Kalman filter with either covariance\nlocalization or local domains, in order to retrieve the state and a mix of key\nglobal and local parameters. Global parameters are meant to represent the\nsurrogate dynamics, for instance through a neural network, which is reminiscent\nof data-driven machine learning of dynamics, while the local parameters\ntypically stand for the forcings of the model. A family of algorithms for\ncovariance and local domain localization is proposed in this joint state and\nparameter filter context. In particular, we show how to rigorously update\nglobal parameters using a local domain EnKF such as the LETKF, an inherently\nlocal method. The approach is tested with success on the 40-variable Lorenz\nmodel using several of the local EnKF flavors. A two-dimensional illustration\nbased on a multi-layer Lorenz model is finally provided. It uses radiance-like\nnon-local observations, and both local domains and covariance localization in\norder to learn the chaotic dynamics, the local forcings, and the couplings\nbetween layers. This paper more generally addresses the key question of online\nestimation of both global and local model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:12:20 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 08:46:24 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Malartic", "Quentin", ""], ["Farchi", "Alban", ""], ["Bocquet", "Marc", ""]]}, {"id": "2107.11275", "submitter": "Ekaterina Artemova", "authors": "Ivan Fursov, Alexey Zaytsev, Pavel Burnyshev, Ekaterina Dmitrieva,\n  Nikita Klyuchnikov, Andrey Kravchenko, Ekaterina Artemova, Evgeny Burnaev", "title": "A Differentiable Language Model Adversarial Attack on Text Classifiers", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.11078", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robustness of huge Transformer-based models for natural language processing\nis an important issue due to their capabilities and wide adoption. One way to\nunderstand and improve robustness of these models is an exploration of an\nadversarial attack scenario: check if a small perturbation of an input can fool\na model.\n  Due to the discrete nature of textual data, gradient-based adversarial\nmethods, widely used in computer vision, are not applicable per~se. The\nstandard strategy to overcome this issue is to develop token-level\ntransformations, which do not take the whole sentence into account.\n  In this paper, we propose a new black-box sentence-level attack. Our method\nfine-tunes a pre-trained language model to generate adversarial examples. A\nproposed differentiable loss function depends on a substitute classifier score\nand an approximate edit distance computed via a deep learning model.\n  We show that the proposed attack outperforms competitors on a diverse set of\nNLP problems for both computed metrics and human evaluation. Moreover, due to\nthe usage of the fine-tuned language model, the generated adversarial examples\nare hard to detect, thus current models are not robust. Hence, it is difficult\nto defend from the proposed attack, which is not the case for other attacks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:43:13 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Fursov", "Ivan", ""], ["Zaytsev", "Alexey", ""], ["Burnyshev", "Pavel", ""], ["Dmitrieva", "Ekaterina", ""], ["Klyuchnikov", "Nikita", ""], ["Kravchenko", "Andrey", ""], ["Artemova", "Ekaterina", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2107.11277", "submitter": "Kilian Hendrickx", "authors": "Kilian Hendrickx, Lorenzo Perini, Dries Van der Plas, Wannes Meert,\n  Jesse Davis", "title": "Machine Learning with a Reject Option: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models always make a prediction, even when it is likely to\nbe inaccurate. This behavior should be avoided in many decision support\napplications, where mistakes can have severe consequences. Albeit already\nstudied in 1970, machine learning with a reject option recently gained\ninterest. This machine learning subfield enables machine learning models to\nabstain from making a prediction when likely to make a mistake.\n  This survey aims to provide an overview on machine learning with a reject\noption. We introduce the conditions leading to two types of rejection,\nambiguity and novelty rejection. Moreover, we define the existing architectures\nfor models with a reject option, describe the standard learning strategies to\ntrain such models and relate traditional machine learning techniques to\nrejection. Additionally, we review strategies to evaluate a model's predictive\nand rejective quality. Finally, we provide examples of relevant application\ndomains and show how machine learning with rejection relates to other machine\nlearning research areas.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:43:56 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Hendrickx", "Kilian", ""], ["Perini", "Lorenzo", ""], ["Van der Plas", "Dries", ""], ["Meert", "Wannes", ""], ["Davis", "Jesse", ""]]}, {"id": "2107.11291", "submitter": "Jiefeng Li", "authors": "Jiefeng Li, Siyuan Bian, Ailing Zeng, Can Wang, Bo Pang, Wentao Liu,\n  Cewu Lu", "title": "Human Pose Regression with Residual Log-likelihood Estimation", "comments": "ICCV 2021 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heatmap-based methods dominate in the field of human pose estimation by\nmodelling the output distribution through likelihood heatmaps. In contrast,\nregression-based methods are more efficient but suffer from inferior\nperformance. In this work, we explore maximum likelihood estimation (MLE) to\ndevelop an efficient and effective regression-based methods. From the\nperspective of MLE, adopting different regression losses is making different\nassumptions about the output density function. A density function closer to the\ntrue distribution leads to a better regression performance. In light of this,\nwe propose a novel regression paradigm with Residual Log-likelihood Estimation\n(RLE) to capture the underlying output distribution. Concretely, RLE learns the\nchange of the distribution instead of the unreferenced underlying distribution\nto facilitate the training process. With the proposed reparameterization\ndesign, our method is compatible with off-the-shelf flow models. The proposed\nmethod is effective, efficient and flexible. We show its potential in various\nhuman pose estimation tasks with comprehensive experiments. Compared to the\nconventional regression paradigm, regression with RLE bring 12.4 mAP\nimprovement on MSCOCO without any test-time overhead. Moreover, for the first\ntime, especially on multi-person pose estimation, our regression method is\nsuperior to the heatmap-based methods. Our code is available at\nhttps://github.com/Jeff-sjtu/res-loglikelihood-regression\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 15:06:31 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 03:10:48 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Jiefeng", ""], ["Bian", "Siyuan", ""], ["Zeng", "Ailing", ""], ["Wang", "Can", ""], ["Pang", "Bo", ""], ["Liu", "Wentao", ""], ["Lu", "Cewu", ""]]}, {"id": "2107.11304", "submitter": "Chang-Shen Lee", "authors": "Chang-Shen Lee, Nicol\\`o Michelusi, Gesualdo Scutari", "title": "Finite-Bit Quantization For Distributed Algorithms With Linear\n  Convergence", "comments": "Submitted to the IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper studies distributed algorithms for (strongly convex) composite\noptimization problems over mesh networks, subject to quantized communications.\nInstead of focusing on a specific algorithmic design, we propose a black-box\nmodel casting distributed algorithms in the form of fixed-point iterates,\nconverging at linear rate. The algorithmic model is coupled with a novel\n(random) Biased Compression (BC-)rule on the quantizer design, which preserves\nlinear convergence. A new quantizer coupled with a communication-efficient\nencoding scheme is also proposed, which efficiently implements the BC-rule\nusing a finite number of bits. This contrasts with most of existing\nquantization rules, whose implementation calls for an infinite number of bits.\nA unified communication complexity analysis is developed for the black-box\nmodel, determining the average number of bit required to reach a solution of\nthe optimization problem within the required accuracy. Numerical results\nvalidate our theoretical findings and show that distributed algorithms equipped\nwith the proposed quantizer have more favorable communication complexity than\nalgorithms using existing quantization rules.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 15:31:31 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Lee", "Chang-Shen", ""], ["Michelusi", "Nicol\u00f2", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "2107.11320", "submitter": "Gyri Reiersen", "authors": "Gyri Reiersen, David Dao, Bj\\\"orn L\\\"utjens, Konstantin Klemmer,\n  Xiaoxiang Zhu, and Ce Zhang", "title": "Tackling the Overestimation of Forest Carbon with Deep Learning and\n  Aerial Imagery", "comments": "Spotlight talk at the Tackling Climate Change with Machine Learning\n  workshop at the ICML 2021 https://www.climatechange.ai/papers/icml2021/79", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forest carbon offsets are increasingly popular and can play a significant\nrole in financing climate mitigation, forest conservation, and reforestation.\nMeasuring how much carbon is stored in forests is, however, still largely done\nvia expensive, time-consuming, and sometimes unaccountable field measurements.\nTo overcome these limitations, many verification bodies are leveraging machine\nlearning (ML) algorithms to estimate forest carbon from satellite or aerial\nimagery. Aerial imagery allows for tree species or family classification, which\nimproves the satellite imagery-based forest type classification. However,\naerial imagery is significantly more expensive to collect and it is unclear by\nhow much the higher resolution improves the forest carbon estimation. This\nproposal paper describes the first systematic comparison of forest carbon\nestimation from aerial imagery, satellite imagery, and ground-truth field\nmeasurements via deep learning-based algorithms for a tropical reforestation\nproject. Our initial results show that forest carbon estimates from satellite\nimagery can overestimate above-ground biomass by more than 10-times for\ntropical reforestation projects. The significant difference between aerial and\nsatellite-derived forest carbon measurements shows the potential for aerial\nimagery-based ML algorithms and raises the importance to extend this study to a\nglobal benchmark between options for carbon measurements.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 15:59:52 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Reiersen", "Gyri", ""], ["Dao", "David", ""], ["L\u00fctjens", "Bj\u00f6rn", ""], ["Klemmer", "Konstantin", ""], ["Zhu", "Xiaoxiang", ""], ["Zhang", "Ce", ""]]}, {"id": "2107.11327", "submitter": "Hussain Hussain", "authors": "Hussain Hussain, Tomislav Duricic, Elisabeth Lex, Denis Helic, Markus\n  Strohmaier, Roman Kern", "title": "Structack: Structure-based Adversarial Attacks on Graph Neural Networks", "comments": "Accepted as a full paper at ACM Hypertext on July 9, 2021", "journal-ref": null, "doi": "10.1145/3465336.3475110", "report-no": null, "categories": "cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has shown that graph neural networks (GNNs) are vulnerable to\nadversarial attacks on graph data. Common attack approaches are typically\ninformed, i.e. they have access to information about node attributes such as\nlabels and feature vectors. In this work, we study adversarial attacks that are\nuninformed, where an attacker only has access to the graph structure, but no\ninformation about node attributes. Here the attacker aims to exploit structural\nknowledge and assumptions, which GNN models make about graph data. In\nparticular, literature has shown that structural node centrality and similarity\nhave a strong influence on learning with GNNs. Therefore, we study the impact\nof centrality and similarity on adversarial attacks on GNNs. We demonstrate\nthat attackers can exploit this information to decrease the performance of GNNs\nby focusing on injecting links between nodes of low similarity and,\nsurprisingly, low centrality. We show that structure-based uninformed attacks\ncan approach the performance of informed attacks, while being computationally\nmore efficient. With our paper, we present a new attack strategy on GNNs that\nwe refer to as Structack. Structack can successfully manipulate the performance\nof GNNs with very limited information while operating under tight computational\nconstraints. Our work contributes towards building more robust machine learning\napproaches on graphs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 16:17:10 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 09:54:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hussain", "Hussain", ""], ["Duricic", "Tomislav", ""], ["Lex", "Elisabeth", ""], ["Helic", "Denis", ""], ["Strohmaier", "Markus", ""], ["Kern", "Roman", ""]]}, {"id": "2107.11333", "submitter": "Shaojie Tang", "authors": "Shaojie Tang", "title": "Robust Adaptive Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of existing studies on adaptive submodular optimization focus on the\naverage-case, i.e., their objective is to find a policy that maximizes the\nexpected utility over a known distribution of realizations. However, a policy\nthat has a good average-case performance may have very poor performance under\nthe worst-case realization. In this study, we propose to study two variants of\nadaptive submodular optimization problems, namely, worst-case adaptive\nsubmodular maximization and robust submodular maximization. The first problem\naims to find a policy that maximizes the worst-case utility and the latter one\naims to find a policy, if any, that achieves both near optimal average-case\nutility and worst-case utility simultaneously. We introduce a new class of\nstochastic functions, called \\emph{worst-case submodular function}. For the\nworst-case adaptive submodular maximization problem subject to a $p$-system\nconstraint, we develop an adaptive worst-case greedy policy that achieves a\n$\\frac{1}{p+1}$ approximation ratio against the optimal worst-case utility if\nthe utility function is worst-case submodular. For the robust adaptive\nsubmodular maximization problem subject to a cardinality constraint, if the\nutility function is both worst-case submodular and adaptive submodular, we\ndevelop a hybrid adaptive policy that achieves an approximation close to\n$1-e^{-\\frac{1}{2}}$ under both worst case setting and average case setting\nsimultaneously. We also describe several applications of our theoretical\nresults, including pool-base active learning, stochastic submodular set cover\nand adaptive viral marketing.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 16:22:50 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 03:11:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tang", "Shaojie", ""]]}, {"id": "2107.11350", "submitter": "Satya Narayan Shukla", "authors": "Satya Narayan Shukla, Benjamin M. Marlin", "title": "Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregularly sampled time series commonly occur in several domains where they\npresent a significant challenge to standard deep learning models. In this\npaper, we propose a new deep learning framework for probabilistic interpolation\nof irregularly sampled time series that we call the Heteroscedastic Temporal\nVariational Autoencoder (HeTVAE). HeTVAE includes a novel input layer to encode\ninformation about input observation sparsity, a temporal VAE architecture to\npropagate uncertainty due to input sparsity, and a heteroscedastic output layer\nto enable variable uncertainty in output interpolations. Our results show that\nthe proposed architecture is better able to reflect variable uncertainty\nthrough time due to sparse and irregular sampling than a range of baseline and\ntraditional models, as well as recently proposed deep latent variable models\nthat use homoscedastic output layers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 16:59:21 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Shukla", "Satya Narayan", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2107.11357", "submitter": "Richard Pymar", "authors": "Chris Harris, Richard Pymar, Colin Rowat", "title": "Joint Shapley values: a measure of joint feature importance", "comments": "Source code available at\n  https://github.com/harris-chris/joint-shapley-values", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Shapley value is one of the most widely used model-agnostic measures of\nfeature importance in explainable AI: it has clear axiomatic foundations, is\nguaranteed to uniquely exist, and has a clear interpretation as a feature's\naverage effect on a model's prediction. We introduce joint Shapley values,\nwhich directly extend the Shapley axioms. This preserves the classic Shapley\nvalue's intuitions: joint Shapley values measure a set of features' average\neffect on a model's prediction. We prove the uniqueness of joint Shapley\nvalues, for any order of explanation. Results for games show that joint Shapley\nvalues present different insights from existing interaction indices, which\nassess the effect of a feature within a set of features. Deriving joint Shapley\nvalues in ML attribution problems thus gives us the first measure of the joint\neffect of sets of features on model predictions. In a dataset with binary\nfeatures, we present a presence-adjusted method for calculating global values\nthat retains the efficiency property.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 17:22:37 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Harris", "Chris", ""], ["Pymar", "Richard", ""], ["Rowat", "Colin", ""]]}, {"id": "2107.11359", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Qizheng Yang, Xiao Liu, Hui Guan", "title": "Rethinking Hard-Parameter Sharing in Multi-Task Learning", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hard parameter sharing in multi-task learning (MTL) allows tasks to share\nsome of model parameters, reducing storage cost and improving prediction\naccuracy. The common sharing practice is to share bottom layers of a deep\nneural network among tasks while using separate top layers for each task. In\nthis work, we revisit this common practice via an empirical study on\nfine-grained image classification tasks and make two surprising observations.\n(1) Using separate bottom-layer parameters could achieve significantly better\nperformance than the common practice and this phenomenon holds for different\nnumber of tasks jointly trained on different backbone architectures with\ndifferent quantity of task-specific parameters. (2) A multi-task model with a\nsmall proportion of task-specific parameters from bottom layers can achieve\ncompetitive performance with independent models trained on each task separately\nand outperform a state-of-the-art MTL framework. Our observations suggest that\npeople rethink the current sharing paradigm and adopt the new strategy of using\nseparate bottom-layer parameters as a stronger baseline for model design in\nMTL.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 17:26:40 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Zhang", "Lijun", ""], ["Yang", "Qizheng", ""], ["Liu", "Xiao", ""], ["Guan", "Hui", ""]]}, {"id": "2107.11371", "submitter": "Jaydip Sen", "authors": "Jaydip Sen and Sidra Mehtab", "title": "Optimum Risk Portfolio and Eigen Portfolio: A Comparative Analysis Using\n  Selected Stocks from the Indian Stock Market", "comments": "The is the preprint of our accepted paper in the journal\n  International Journal of Business Forecasting and Marketing Intelligence\n  published by Inderscience Publishers, Switzerland. It consists of 35 pages,\n  and includes 29 figures and 36 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing an optimum portfolio that allocates weights to its constituent\nstocks in a way that achieves the best trade-off between the return and the\nrisk is a challenging research problem. The classical mean-variance theory of\nportfolio proposed by Markowitz is found to perform sub-optimally on the\nreal-world stock market data since the error in estimation for the expected\nreturns adversely affects the performance of the portfolio. This paper presents\nthree approaches to portfolio design, viz, the minimum risk portfolio, the\noptimum risk portfolio, and the Eigen portfolio, for seven important sectors of\nthe Indian stock market. The daily historical prices of the stocks are scraped\nfrom Yahoo Finance website from January 1, 2016, to December 31, 2020. Three\nportfolios are built for each of the seven sectors chosen for this study, and\nthe portfolios are analyzed on the training data based on several metrics such\nas annualized return and risk, weights assigned to the constituent stocks, the\ncorrelation heatmaps, and the principal components of the Eigen portfolios.\nFinally, the optimum risk portfolios and the Eigen portfolios for all sectors\nare tested on their return over a period of a six-month period. The\nperformances of the portfolios are compared and the portfolio yielding the\nhigher return for each sector is identified.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 17:50:45 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Sen", "Jaydip", ""], ["Mehtab", "Sidra", ""]]}, {"id": "2107.11381", "submitter": "Seonwoo Min", "authors": "Seonwoo Min, Byunghan Lee, and Sungroh Yoon", "title": "TargetNet: Functional microRNA Target Prediction with Deep Neural\n  Networks", "comments": "7 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  MicroRNAs (miRNAs) play pivotal roles in gene expression regulation by\nbinding to target sites of messenger RNAs (mRNAs). While identifying functional\ntargets of miRNAs is of utmost importance, their prediction remains a great\nchallenge. Previous computational algorithms have major limitations. They use\nconservative candidate target site (CTS) selection criteria mainly focusing on\ncanonical site types, rely on laborious and time-consuming manual feature\nextraction, and do not fully capitalize on the information underlying miRNA-CTS\ninteractions. In this paper, we introduce TargetNet, a novel deep\nlearning-based algorithm for functional miRNA target prediction. To address the\nlimitations of previous approaches, TargetNet has three key components: (1)\nrelaxed CTS selection criteria accommodating irregularities in the seed region,\n(2) a novel miRNA-CTS sequence encoding scheme incorporating extended seed\nregion alignments, and (3) a deep residual network-based prediction model. The\nproposed model was trained with miRNA-CTS pair datasets and evaluated with\nmiRNA-mRNA pair datasets. TargetNet advances the previous state-of-the-art\nalgorithms used in functional miRNA target classification. Furthermore, it\ndemonstrates great potential for distinguishing high-functional miRNA targets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 07:31:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Min", "Seonwoo", ""], ["Lee", "Byunghan", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2107.11400", "submitter": "Ian Nielsen", "authors": "Ian E. Nielsen, Dimah Dera, Ghulam Rasool, Nidhal Bouaynaya, Ravi P.\n  Ramachandran", "title": "Robust Explainability: A Tutorial on Gradient-Based Attribution Methods\n  for Deep Neural Networks", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of deep neural networks, the challenge of explaining the\npredictions of these networks has become increasingly recognized. While many\nmethods for explaining the decisions of deep neural networks exist, there is\ncurrently no consensus on how to evaluate them. On the other hand, robustness\nis a popular topic for deep learning research; however, it is hardly talked\nabout in explainability until very recently. In this tutorial paper, we start\nby presenting gradient-based interpretability methods. These techniques use\ngradient signals to assign the burden of the decision on the input features.\nLater, we discuss how gradient-based methods can be evaluated for their\nrobustness and the role that adversarial robustness plays in having meaningful\nexplanations. We also discuss the limitations of gradient-based methods.\nFinally, we present the best practices and attributes that should be examined\nbefore choosing an explainability method. We conclude with the future\ndirections for research in the area at the convergence of robustness and\nexplainability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 18:06:29 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 17:18:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Nielsen", "Ian E.", ""], ["Dera", "Dimah", ""], ["Rasool", "Ghulam", ""], ["Bouaynaya", "Nidhal", ""], ["Ramachandran", "Ravi P.", ""]]}, {"id": "2107.11412", "submitter": "Arun Kumar Singh", "authors": "Arun Kumar Singh (1), Priyanka Singh (2), Karan Nathwani (1) ((1)\n  Indian Institute of Technology Jammu, (2) Dhirubhai Ambani Institute of\n  Information and Communication Technology)", "title": "Using Deep Learning Techniques and Inferential Speech Statistics for AI\n  Synthesised Speech Recognition", "comments": "13 Pages, 13 Figures, 6 Tables. arXiv admin note: substantial text\n  overlap with arXiv:2009.01934", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent developments in technology have re-warded us with amazing audio\nsynthesis models like TACOTRON and WAVENETS. On the other side, it poses\ngreater threats such as speech clones and deep fakes, that may go undetected.\nTo tackle these alarming situations, there is an urgent need to propose models\nthat can help discriminate a synthesized speech from an actual human speech and\nalso identify the source of such a synthesis. Here, we propose a model based on\nConvolutional Neural Network (CNN) and Bidirectional Recurrent Neural Network\n(BiRNN) that helps to achieve both the aforementioned objectives. The temporal\ndependencies present in AI synthesized speech are exploited using Bidirectional\nRNN and CNN. The model outperforms the state-of-the-art approaches by\nclassifying the AI synthesized audio from real human speech with an error rate\nof 1.9% and detecting the underlying architecture with an accuracy of 97%.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 18:43:10 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Singh", "Arun Kumar", ""], ["Singh", "Priyanka", ""], ["Nathwani", "Karan", ""]]}, {"id": "2107.11413", "submitter": "Dong Yin", "authors": "Keren Gu, Xander Masotto, Vandana Bachani, Balaji Lakshminarayanan,\n  Jack Nikodem, Dong Yin", "title": "A Realistic Simulation Framework for Learning with Label Noise", "comments": "Datasets released at\n  https://github.com/deepmind/deepmind-research/tree/master/noisy_label", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a simulation framework for generating realistic instance-dependent\nnoisy labels via a pseudo-labeling paradigm. We show that this framework\ngenerates synthetic noisy labels that exhibit important characteristics of the\nlabel noise in practical settings via comparison with the CIFAR10-H dataset.\nEquipped with controllable label noise, we study the negative impact of noisy\nlabels across a few realistic settings to understand when label noise is more\nproblematic. We also benchmark several existing algorithms for learning with\nnoisy labels and compare their behavior on our synthetic datasets and on the\ndatasets with independent random label noise. Additionally, with the\navailability of annotator information from our simulation framework, we propose\na new technique, Label Quality Model (LQM), that leverages annotator features\nto predict and correct against noisy labels. We show that by adding LQM as a\nlabel correction step before applying existing noisy label techniques, we can\nfurther improve the models' performance.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 18:53:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gu", "Keren", ""], ["Masotto", "Xander", ""], ["Bachani", "Vandana", ""], ["Lakshminarayanan", "Balaji", ""], ["Nikodem", "Jack", ""], ["Yin", "Dong", ""]]}, {"id": "2107.11415", "submitter": "Chung-Hsuan Hu", "authors": "Chung-Hsuan Hu, Zheng Chen, Erik G. Larsson", "title": "Device Scheduling and Update Aggregation Policies for Asynchronous\n  Federated Learning", "comments": "5 pages, 4 figures, accepted in 22nd IEEE international workshop on\n  signal processing advances in wireless communications (SPAWC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is a newly emerged decentralized machine learning\n(ML) framework that combines on-device local training with server-based model\nsynchronization to train a centralized ML model over distributed nodes. In this\npaper, we propose an asynchronous FL framework with periodic aggregation to\neliminate the straggler issue in FL systems. For the proposed model, we\ninvestigate several device scheduling and update aggregation policies and\ncompare their performances when the devices have heterogeneous computation\ncapabilities and training data distributions. From the simulation results, we\nconclude that the scheduling and aggregation design for asynchronous FL can be\nrather different from the synchronous case. For example, a norm-based\nsignificance-aware scheduling policy might not be efficient in an asynchronous\nFL setting, and an appropriate \"age-aware\" weighting design for the model\naggregation can greatly improve the learning performance of such systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 18:57:08 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Hu", "Chung-Hsuan", ""], ["Chen", "Zheng", ""], ["Larsson", "Erik G.", ""]]}, {"id": "2107.11419", "submitter": "Junpei Komiyama", "authors": "Junpei Komiyama, Edouard Fouch\\'e, Junya Honda", "title": "Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider nonstationary multi-armed bandit problems where the model\nparameters of the arms change over time. We introduce the adaptive resetting\nbandit (ADR-bandit), which is a class of bandit algorithms that leverages\nadaptive windowing techniques from the data stream community. We first provide\nnew guarantees on the quality of estimators resulting from adaptive windowing\ntechniques, which are of independent interest in the data mining community.\nFurthermore, we conduct a finite-time analysis of ADR-bandit in two typical\nenvironments: an abrupt environment where changes occur instantaneously and a\ngradual environment where changes occur progressively. We demonstrate that\nADR-bandit has nearly optimal performance when the abrupt or global changes\noccur in a coordinated manner that we call global changes. We demonstrate that\nforced exploration is unnecessary when we restrict the interest to the global\nchanges. Unlike the existing nonstationary bandit algorithms, ADR-bandit has\noptimal performance in stationary environments as well as nonstationary\nenvironments with global changes. Our experiments show that the proposed\nalgorithms outperform the existing approaches in synthetic and real-world\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 19:02:52 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Komiyama", "Junpei", ""], ["Fouch\u00e9", "Edouard", ""], ["Honda", "Junya", ""]]}, {"id": "2107.11433", "submitter": "Rui Yuan", "authors": "Rui Yuan, Robert M. Gower, Alessandro Lazaric", "title": "A general sample complexity analysis of vanilla policy gradient", "comments": "ICML 2021 Workshop on \"Reinforcement learning theory\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The policy gradient (PG) is one of the most popular methods for solving\nreinforcement learning (RL) problems. However, a solid theoretical\nunderstanding of even the \"vanilla\" PG has remained elusive for long time. In\nthis paper, we apply recent tools developed for the analysis of SGD in\nnon-convex optimization to obtain convergence guarantees for both REINFORCE and\nGPOMDP under smoothness assumption on the objective function and weak\nconditions on the second moment of the norm of the estimated gradient. When\ninstantiated under common assumptions on the policy space, our general result\nimmediately recovers existing $\\widetilde{\\mathcal{O}}(\\epsilon^{-4})$ sample\ncomplexity guarantees, but for wider ranges of parameters (e.g., step size and\nbatch size $m$) with respect to previous literature. Notably, our result\nincludes the single trajectory case (i.e., $m=1$) and it provides a more\naccurate analysis of the dependency on problem-specific parameters by fixing\nprevious results available in the literature. We believe that the integration\nof state-of-the-art tools from non-convex optimization may lead to identify a\nmuch broader range of problems where PG methods enjoy strong theoretical\nguarantees.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 19:38:17 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yuan", "Rui", ""], ["Gower", "Robert M.", ""], ["Lazaric", "Alessandro", ""]]}, {"id": "2107.11435", "submitter": "Jingxiao Liu", "authors": "Jingxiao Liu, Susu Xu, Mario Berg\\'es, Hae Young Noh", "title": "HierMUD: Hierarchical Multi-task Unsupervised Domain Adaptation between\n  Bridges for Drive-by Damage Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Monitoring bridge health using vibrations of drive-by vehicles has various\nbenefits, such as no need for directly installing and maintaining sensors on\nthe bridge. However, many of the existing drive-by monitoring approaches are\nbased on supervised learning models that require labeled data from every bridge\nof interest, which is expensive and time-consuming, if not impossible, to\nobtain. To this end, we introduce a new framework that transfers the model\nlearned from one bridge to diagnose damage in another bridge without any labels\nfrom the target bridge. Our framework trains a hierarchical neural network\nmodel in an adversarial way to extract task-shared and task-specific features\nthat are informative to multiple diagnostic tasks and invariant across multiple\nbridges. We evaluate our framework on experimental data collected from 2\nbridges and 3 vehicles. We achieve accuracies of 95% for damage detection, 93%\nfor localization, and up to 72% for quantification, which are ~2 times\nimprovements from baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 19:39:32 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Jingxiao", ""], ["Xu", "Susu", ""], ["Berg\u00e9s", "Mario", ""], ["Noh", "Hae Young", ""]]}, {"id": "2107.11442", "submitter": "Lucas Liebenwein", "authors": "Lucas Liebenwein, Alaa Maalouf, Oren Gal, Dan Feldman, Daniela Rus", "title": "Compressing Neural Networks: Towards Determining the Optimal Layer-wise\n  Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel global compression framework for deep neural networks that\nautomatically analyzes each layer to identify the optimal per-layer compression\nratio, while simultaneously achieving the desired overall compression. Our\nalgorithm hinges on the idea of compressing each convolutional (or\nfully-connected) layer by slicing its channels into multiple groups and\ndecomposing each group via low-rank decomposition. At the core of our algorithm\nis the derivation of layer-wise error bounds from the Eckart Young Mirsky\ntheorem. We then leverage these bounds to frame the compression problem as an\noptimization problem where we wish to minimize the maximum compression error\nacross layers and propose an efficient algorithm towards a solution. Our\nexperiments indicate that our method outperforms existing low-rank compression\napproaches across a wide range of networks and data sets. We believe that our\nresults open up new avenues for future research into the global\nperformance-size trade-offs of modern neural networks. Our code is available at\nhttps://github.com/lucaslie/torchprune.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:01:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liebenwein", "Lucas", ""], ["Maalouf", "Alaa", ""], ["Gal", "Oren", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "2107.11445", "submitter": "Klas Leino", "authors": "Klas Leino, Aymeric Fromherz, Ravi Mangal, Matt Fredrikson, Bryan\n  Parno, Corina P\\u{a}s\\u{a}reanu", "title": "Self-Repairing Neural Networks: Provable Safety for Deep Networks via\n  Dynamic Repair", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly being deployed in contexts where safety is a\ncritical concern. In this work, we propose a way to construct neural network\nclassifiers that dynamically repair violations of non-relational safety\nconstraints called safe ordering properties. Safe ordering properties relate\nrequirements on the ordering of a network's output indices to conditions on\ntheir input, and are sufficient to express most useful notions of\nnon-relational safety for classifiers. Our approach is based on a novel\nself-repairing layer, which provably yields safe outputs regardless of the\ncharacteristics of its input. We compose this layer with an existing network to\nconstruct a self-repairing network (SR-Net), and show that in addition to\nproviding safe outputs, the SR-Net is guaranteed to preserve the accuracy of\nthe original network. Notably, our approach is independent of the size and\narchitecture of the network being repaired, depending only on the specified\nproperty and the dimension of the network's output; thus it is scalable to\nlarge state-of-the-art networks. We show that our approach can be implemented\nusing vectorized computations that execute efficiently on a GPU, introducing\nrun-time overhead of less than one millisecond on current hardware -- even on\nlarge, widely-used networks containing hundreds of thousands of neurons and\nmillions of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:08:52 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Leino", "Klas", ""], ["Fromherz", "Aymeric", ""], ["Mangal", "Ravi", ""], ["Fredrikson", "Matt", ""], ["Parno", "Bryan", ""], ["P\u0103s\u0103reanu", "Corina", ""]]}, {"id": "2107.11453", "submitter": "Jon Nordby", "authors": "Jon Nordby, Fabian Nemazi, Dag Rieber", "title": "Automatic Detection Of Noise Events at Shooting Range Using Machine\n  Learning", "comments": "Accepted at 27th International Congress of Sound and Vibration\n  (ICSV27)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Outdoor shooting ranges are subject to noise regulations from local and\nnational authorities. Restrictions found in these regulations may include\nlimits on times of activities, the overall number of noise events, as well as\nlimits on number of events depending on the class of noise or activity. A noise\nmonitoring system may be used to track overall sound levels, but rarely provide\nthe ability to detect activity or count the number of events, required to\ncompare directly with such regulations. This work investigates the feasibility\nand performance of an automatic detection system to count noise events. An\nempirical evaluation was done by collecting data at a newly constructed\nshooting range and training facility. The data includes tests of multiple\nweapon configurations from small firearms to high caliber rifles and\nexplosives, at multiple source positions, and collected on multiple different\ndays. Several alternative machine learning models are tested, using as inputs\ntime-series of standard acoustic indicators such as A-weighted sound levels and\n1/3 octave spectrogram, and classifiers such as Logistic Regression and\nConvolutional Neural Networks. Performance for the various alternatives are\nreported in terms of the False Positive Rate and False Negative Rate. The\ndetection performance was found to be satisfactory for use in automatic logging\nof time-periods with training activity.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:36:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Nordby", "Jon", ""], ["Nemazi", "Fabian", ""], ["Rieber", "Dag", ""]]}, {"id": "2107.11460", "submitter": "Teeratorn Kadeethum", "authors": "T. Kadeethum, F. Ballarin, Y. Choi, D. O'Malley, H. Yoon, N. Bouklas", "title": "Non-intrusive reduced order modeling of natural convection in porous\n  media using convolutional autoencoders: comparison with linear subspace\n  techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural convection in porous media is a highly nonlinear multiphysical\nproblem relevant to many engineering applications (e.g., the process of\n$\\mathrm{CO_2}$ sequestration). Here, we present a non-intrusive reduced order\nmodel of natural convection in porous media employing deep convolutional\nautoencoders for the compression and reconstruction and either radial basis\nfunction (RBF) interpolation or artificial neural networks (ANNs) for mapping\nparameters of partial differential equations (PDEs) on the corresponding\nnonlinear manifolds. To benchmark our approach, we also describe linear\ncompression and reconstruction processes relying on proper orthogonal\ndecomposition (POD) and ANNs. We present comprehensive comparisons among\ndifferent models through three benchmark problems. The reduced order models,\nlinear and nonlinear approaches, are much faster than the finite element model,\nobtaining a maximum speed-up of $7 \\times 10^{6}$ because our framework is not\nbound by the Courant-Friedrichs-Lewy condition; hence, it could deliver\nquantities of interest at any given time contrary to the finite element model.\nOur model's accuracy still lies within a mean squared error of 0.07 (two-order\nof magnitude lower than the maximum value of the finite element results) in the\nworst-case scenario. We illustrate that, in specific settings, the nonlinear\napproach outperforms its linear counterpart and vice versa. We hypothesize that\na visual comparison between principal component analysis (PCA) or t-Distributed\nStochastic Neighbor Embedding (t-SNE) could indicate which method will perform\nbetter prior to employing any specific compression strategy.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:58:15 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 15:19:44 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kadeethum", "T.", ""], ["Ballarin", "F.", ""], ["Choi", "Y.", ""], ["O'Malley", "D.", ""], ["Yoon", "H.", ""], ["Bouklas", "N.", ""]]}, {"id": "2107.11468", "submitter": "Katy Blumer", "authors": "Katy Blumer, Subhashini Venugopalan, Michael P. Brenner, Jon Kleinberg", "title": "Using a Cross-Task Grid of Linear Probes to Interpret CNN Model\n  Predictions On Retinal Images", "comments": "Extended abstract at Interpretable Machine Learning in Healthcare\n  (IMLH) workshop at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze a dataset of retinal images using linear probes: linear regression\nmodels trained on some \"target\" task, using embeddings from a deep\nconvolutional (CNN) model trained on some \"source\" task as input. We use this\nmethod across all possible pairings of 93 tasks in the UK Biobank dataset of\nretinal images, leading to ~164k different models. We analyze the performance\nof these linear probes by source and target task and by layer depth. We observe\nthat representations from the middle layers of the network are more\ngeneralizable. We find that some target tasks are easily predicted irrespective\nof the source task, and that some other target tasks are more accurately\npredicted from correlated source tasks than from embeddings trained on the same\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 21:30:27 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Blumer", "Katy", ""], ["Venugopalan", "Subhashini", ""], ["Brenner", "Michael P.", ""], ["Kleinberg", "Jon", ""]]}, {"id": "2107.11472", "submitter": "Yunhui Guo", "authors": "Yunhui Guo and Xudong Wang and Yubei Chen and Stella X. Yu", "title": "Free Hyperbolic Neural Networks with Limited Radii", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Non-Euclidean geometry with constant negative curvature, i.e., hyperbolic\nspace, has attracted sustained attention in the community of machine learning.\nHyperbolic space, owing to its ability to embed hierarchical structures\ncontinuously with low distortion, has been applied for learning data with\ntree-like structures. Hyperbolic Neural Networks (HNNs) that operate directly\nin hyperbolic space have also been proposed recently to further exploit the\npotential of hyperbolic representations. While HNNs have achieved better\nperformance than Euclidean neural networks (ENNs) on datasets with implicit\nhierarchical structure, they still perform poorly on standard classification\nbenchmarks such as CIFAR and ImageNet. The traditional wisdom is that it is\ncritical for the data to respect the hyperbolic geometry when applying HNNs. In\nthis paper, we first conduct an empirical study showing that the inferior\nperformance of HNNs on standard recognition datasets can be attributed to the\nnotorious vanishing gradient problem. We further discovered that this problem\nstems from the hybrid architecture of HNNs. Our analysis leads to a simple yet\neffective solution called Feature Clipping, which regularizes the hyperbolic\nembedding whenever its norm exceeding a given threshold. Our thorough\nexperiments show that the proposed method can successfully avoid the vanishing\ngradient problem when training HNNs with backpropagation. The improved HNNs are\nable to achieve comparable performance with ENNs on standard image recognition\ndatasets including MNIST, CIFAR10, CIFAR100 and ImageNet, while demonstrating\nmore adversarial robustness and stronger out-of-distribution detection\ncapability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 22:10:16 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guo", "Yunhui", ""], ["Wang", "Xudong", ""], ["Chen", "Yubei", ""], ["Yu", "Stella X.", ""]]}, {"id": "2107.11496", "submitter": "Bahador Bahmani", "authors": "Bahador Bahmani and WaiChing Sun", "title": "Training multi-objective/multi-task collocation physics-informed neural\n  network with student/teachers transfer learnings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a PINN training framework that employs (1) pre-training\nsteps that accelerates and improve the robustness of the training of\nphysics-informed neural network with auxiliary data stored in point clouds, (2)\na net-to-net knowledge transfer algorithm that improves the weight\ninitialization of the neural network and (3) a multi-objective optimization\nalgorithm that may improve the performance of a physical-informed neural\nnetwork with competing constraints. We consider the training and transfer and\nmulti-task learning of physics-informed neural network (PINN) as\nmulti-objective problems where the physics constraints such as the governing\nequation, boundary conditions, thermodynamic inequality, symmetry, and\ninvariant properties, as well as point cloud used for pre-training can\nsometimes lead to conflicts and necessitating the seek of the Pareto optimal\nsolution. In these situations, weighted norms commonly used to handle multiple\nconstraints may lead to poor performance, while other multi-objective\nalgorithms may scale poorly with increasing dimensionality. To overcome this\ntechnical barrier, we adopt the concept of vectorized objective function and\nmodify a gradient descent approach to handle the issue of conflicting\ngradients. Numerical experiments are compared the benchmark boundary value\nproblems solved via PINN. The performance of the proposed paradigm is compared\nagainst the classical equal-weighted norm approach. Our numerical experiments\nindicate that the brittleness and lack of robustness demonstrated in some PINN\nimplementations can be overcome with the proposed strategy.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 00:43:17 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Bahmani", "Bahador", ""], ["Sun", "WaiChing", ""]]}, {"id": "2107.11500", "submitter": "Biswadeep Chakraborty", "authors": "Biswadeep Chakraborty and Saibal Mukhopadhyay", "title": "$\\mu$DARTS: Model Uncertainty-Aware Differentiable Architecture Search", "comments": "10 pages, 7 Tables, 6 Figures, Submitted in TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a Model Uncertainty-aware Differentiable ARchiTecture Search\n($\\mu$DARTS) that optimizes neural networks to simultaneously achieve high\naccuracy and low uncertainty. We introduce concrete dropout within DARTS cells\nand include a Monte-Carlo regularizer within the training loss to optimize the\nconcrete dropout probabilities. A predictive variance term is introduced in the\nvalidation loss to enable searching for architecture with minimal model\nuncertainty. The experiments on CIFAR10, CIFAR100, SVHN, and ImageNet verify\nthe effectiveness of $\\mu$DARTS in improving accuracy and reducing uncertainty\ncompared to existing DARTS methods. Moreover, the final architecture obtained\nfrom $\\mu$DARTS shows higher robustness to noise at the input image and model\nparameters compared to the architecture obtained from existing DARTS methods.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 01:09:20 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chakraborty", "Biswadeep", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2107.11508", "submitter": "William Sleeman Iv", "authors": "William C. Sleeman IV and Bartosz Krawczyk", "title": "Imbalanced Big Data Oversampling: Taxonomy, Algorithms, Software,\n  Guidelines and Future Directions", "comments": "52 pages, 9 tables, 13 figures, 15 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Learning from imbalanced data is among the most challenging areas in\ncontemporary machine learning. This becomes even more difficult when considered\nthe context of big data that calls for dedicated architectures capable of\nhigh-performance processing. Apache Spark is a highly efficient and popular\narchitecture, but it poses specific challenges for algorithms to be implemented\nfor it. While oversampling algorithms are an effective way for handling class\nimbalance, they have not been designed for distributed environments. In this\npaper, we propose a holistic look on oversampling algorithms for imbalanced big\ndata. We discuss the taxonomy of oversampling algorithms and their mechanisms\nused to handle skewed class distributions. We introduce a Spark library with 14\nstate-of-the-art oversampling algorithms implemented and evaluate their\nefficacy via extensive experimental study. Using binary and multi-class massive\ndata sets, we analyze the effectiveness of oversampling algorithms and their\nrelationships with different types of classifiers. We evaluate the trade-off\nbetween accuracy and time complexity of oversampling algorithms, as well as\ntheir scalability when increasing the size of data. This allows us to gain\ninsight into the usefulness of specific components of oversampling algorithms\nfor big data, as well as formulate guidelines and recommendations for designing\nfuture resampling approaches for massive imbalanced data. Our library can be\ndownloaded from https://github.com/fsleeman/spark-class-balancing.git.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 01:49:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Sleeman", "William C.", "IV"], ["Krawczyk", "Bartosz", ""]]}, {"id": "2107.11514", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Moubayed, Abdallah Shami, Parisa Heidari, Amine\n  Boukhtouta, Adel Larabi, Richard Brunner, Stere Preda, Daniel Migault", "title": "Multi-Perspective Content Delivery Networks Security Framework Using\n  Optimized Unsupervised Anomaly Detection", "comments": "Accepted and to Appear in IEEE Transactions on Network and Service\n  Management", "journal-ref": null, "doi": "10.1109/TNSM.2021.3100308", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content delivery networks (CDNs) provide efficient content distribution over\nthe Internet. CDNs improve the connectivity and efficiency of global\ncommunications, but their caching mechanisms may be breached by\ncyber-attackers. Among the security mechanisms, effective anomaly detection\nforms an important part of CDN security enhancement. In this work, we propose a\nmulti-perspective unsupervised learning framework for anomaly detection in\nCDNs. In the proposed framework, a multi-perspective feature engineering\napproach, an optimized unsupervised anomaly detection model that utilizes an\nisolation forest and a Gaussian mixture model, and a multi-perspective\nvalidation method, are developed to detect abnormal behaviors in CDNs mainly\nfrom the client Internet Protocol (IP) and node perspectives, therefore to\nidentify the denial of service (DoS) and cache pollution attack (CPA) patterns.\nExperimental results are presented based on the analytics of eight days of\nreal-world CDN log data provided by a major CDN operator. Through experiments,\nthe abnormal contents, compromised nodes, malicious IPs, as well as their\ncorresponding attack types, are identified effectively by the proposed\nframework and validated by multiple cybersecurity experts. This shows the\neffectiveness of the proposed method when applied to real-world CDN data.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 02:43:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yang", "Li", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""], ["Heidari", "Parisa", ""], ["Boukhtouta", "Amine", ""], ["Larabi", "Adel", ""], ["Brunner", "Richard", ""], ["Preda", "Stere", ""], ["Migault", "Daniel", ""]]}, {"id": "2107.11526", "submitter": "Uri Stemmer", "authors": "Menachem Sadigurschi, Uri Stemmer", "title": "On the Sample Complexity of Privately Learning Axis-Aligned Rectangles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the fundamental problem of learning Axis-Aligned-Rectangles over a\nfinite grid $X^d\\subseteq{\\mathbb{R}}^d$ with differential privacy. Existing\nresults show that the sample complexity of this problem is at most $\\min\\left\\{\nd{\\cdot}\\log|X| \\;,\\; d^{1.5}{\\cdot}\\left(\\log^*|X| \\right)^{1.5}\\right\\}$.\nThat is, existing constructions either require sample complexity that grows\nlinearly with $\\log|X|$, or else it grows super linearly with the dimension\n$d$. We present a novel algorithm that reduces the sample complexity to only\n$\\tilde{O}\\left\\{d{\\cdot}\\left(\\log^*|X|\\right)^{1.5}\\right\\}$, attaining a\ndimensionality optimal dependency without requiring the sample complexity to\ngrow with $\\log|X|$.The technique used in order to attain this improvement\ninvolves the deletion of \"exposed\" data-points on the go, in a fashion designed\nto avoid the cost of the adaptive composition theorems. The core of this\ntechnique may be of individual interest, introducing a new method for\nconstructing statistically-efficient private algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 04:06:11 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Sadigurschi", "Menachem", ""], ["Stemmer", "Uri", ""]]}, {"id": "2107.11533", "submitter": "Hung Tran-The", "authors": "Hung Tran-The, Sunil Gupta, Thanh Nguyen-Tang, Santu Rana, Svetha\n  Venkatesh", "title": "Combining Online Learning and Offline Learning for Contextual Bandits\n  with Deficient Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address policy learning with logged data in contextual bandits. Current\noffline-policy learning algorithms are mostly based on inverse propensity score\n(IPS) weighting requiring the logging policy to have \\emph{full support} i.e. a\nnon-zero probability for any context/action of the evaluation policy. However,\nmany real-world systems do not guarantee such logging policies, especially when\nthe action space is large and many actions have poor or missing rewards. With\nsuch \\emph{support deficiency}, the offline learning fails to find optimal\npolicies. We propose a novel approach that uses a hybrid of offline learning\nwith online exploration. The online exploration is used to explore unsupported\nactions in the logged data whilst offline learning is used to exploit supported\nactions from the logged data avoiding unnecessary explorations. Our approach\ndetermines an optimal policy with theoretical guarantees using the minimal\nnumber of online explorations. We demonstrate our algorithms' effectiveness\nempirically on a diverse collection of datasets.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 05:07:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tran-The", "Hung", ""], ["Gupta", "Sunil", ""], ["Nguyen-Tang", "Thanh", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2107.11585", "submitter": "Rupak Bose Mr.", "authors": "Rupak Bose, Shivam Pande, Biplab Banerjee", "title": "Two Headed Dragons: Multimodal Fusion and Cross Modal Transactions", "comments": "Accepted in IEEE International conference on Image Processing (ICIP),\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the field of remote sensing is evolving, we witness the accumulation of\ninformation from several modalities, such as multispectral (MS), hyperspectral\n(HSI), LiDAR etc. Each of these modalities possess its own distinct\ncharacteristics and when combined synergistically, perform very well in the\nrecognition and classification tasks. However, fusing multiple modalities in\nremote sensing is cumbersome due to highly disparate domains. Furthermore, the\nexisting methods do not facilitate cross-modal interactions. To this end, we\npropose a novel transformer based fusion method for HSI and LiDAR modalities.\nThe model is composed of stacked auto encoders that harness the cross key-value\npairs for HSI and LiDAR, thus establishing a communication between the two\nmodalities, while simultaneously using the CNNs to extract the spectral and\nspatial information from HSI and LiDAR. We test our model on Houston (Data\nFusion Contest - 2013) and MUUFL Gulfport datasets and achieve competitive\nresults.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 11:33:37 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Bose", "Rupak", ""], ["Pande", "Shivam", ""], ["Banerjee", "Biplab", ""]]}, {"id": "2107.11587", "submitter": "Balazs Kegl", "authors": "Bal\\'azs K\\'egl, Gabriel Hurtado, Albert Thomas", "title": "Model-based micro-data reinforcement learning: what are the crucial\n  model properties and which model to choose?", "comments": "Published at International Conference on Learning Representations,\n  2021: https://openreview.net/forum?id=p5uylG94S68", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We contribute to micro-data model-based reinforcement learning (MBRL) by\nrigorously comparing popular generative models using a fixed (random shooting)\ncontrol agent. We find that on an environment that requires multimodal\nposterior predictives, mixture density nets outperform all other models by a\nlarge margin. When multimodality is not required, our surprising finding is\nthat we do not need probabilistic posterior predictives: deterministic models\nare on par, in fact they consistently (although non-significantly) outperform\ntheir probabilistic counterparts. We also found that heteroscedasticity at\ntraining time, perhaps acting as a regularizer, improves predictions at longer\nhorizons. At the methodological side, we design metrics and an experimental\nprotocol which can be used to evaluate the various models, predicting their\nasymptotic performance when using them on the control problem. Using this\nframework, we improve the state-of-the-art sample complexity of MBRL on Acrobot\nby two to four folds, using an aggressive training schedule which is outside of\nthe hyperparameter interval usually considered\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 11:38:25 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["K\u00e9gl", "Bal\u00e1zs", ""], ["Hurtado", "Gabriel", ""], ["Thomas", "Albert", ""]]}, {"id": "2107.11588", "submitter": "Guangxu Zhu", "authors": "Maojun Zhang, Guangxu Zhu, Shuai Wang, Jiamo Jiang, Caijun Zhong,\n  Shuguang Cui", "title": "Accelerating Federated Edge Learning via Optimized Probabilistic Device\n  Scheduling", "comments": "In Proc. IEEE SPAWC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popular federated edge learning (FEEL) framework allows\nprivacy-preserving collaborative model training via frequent learning-updates\nexchange between edge devices and server. Due to the constrained bandwidth,\nonly a subset of devices can upload their updates at each communication round.\nThis has led to an active research area in FEEL studying the optimal device\nscheduling policy for minimizing communication time. However, owing to the\ndifficulty in quantifying the exact communication time, prior work in this area\ncan only tackle the problem partially by considering either the communication\nrounds or per-round latency, while the total communication time is determined\nby both metrics. To close this gap, we make the first attempt in this paper to\nformulate and solve the communication time minimization problem. We first\nderive a tight bound to approximate the communication time through\ncross-disciplinary effort involving both learning theory for convergence\nanalysis and communication theory for per-round latency analysis. Building on\nthe analytical result, an optimized probabilistic scheduling policy is derived\nin closed-form by solving the approximate communication time minimization\nproblem. It is found that the optimized policy gradually turns its priority\nfrom suppressing the remaining communication rounds to reducing per-round\nlatency as the training process evolves. The effectiveness of the proposed\nscheme is demonstrated via a use case on collaborative 3D objective detection\nin autonomous driving.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 11:39:17 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Maojun", ""], ["Zhu", "Guangxu", ""], ["Wang", "Shuai", ""], ["Jiang", "Jiamo", ""], ["Zhong", "Caijun", ""], ["Cui", "Shuguang", ""]]}, {"id": "2107.11598", "submitter": "Peng Qian", "authors": "Zhenguang Liu, Peng Qian, Xiaoyang Wang, Yuan Zhuang, Lin Qiu, Xun\n  Wang", "title": "Combining Graph Neural Networks with Expert Knowledge for Smart Contract\n  Vulnerability Detection", "comments": "This paper has been accepted by TKDE 2021", "journal-ref": null, "doi": "10.1109/TKDE.2021.3095196", "report-no": null, "categories": "cs.CR cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart contract vulnerability detection draws extensive attention in recent\nyears due to the substantial losses caused by hacker attacks. Existing efforts\nfor contract security analysis heavily rely on rigid rules defined by experts,\nwhich are labor-intensive and non-scalable. More importantly, expert-defined\nrules tend to be error-prone and suffer the inherent risk of being cheated by\ncrafty attackers. Recent researches focus on the symbolic execution and formal\nanalysis of smart contracts for vulnerability detection, yet to achieve a\nprecise and scalable solution. Although several methods have been proposed to\ndetect vulnerabilities in smart contracts, there is still a lack of effort that\nconsiders combining expert-defined security patterns with deep neural networks.\nIn this paper, we explore using graph neural networks and expert knowledge for\nsmart contract vulnerability detection. Specifically, we cast the rich control-\nand data- flow semantics of the source code into a contract graph. To highlight\nthe critical nodes in the graph, we further design a node elimination phase to\nnormalize the graph. Then, we propose a novel temporal message propagation\nnetwork to extract the graph feature from the normalized graph, and combine the\ngraph feature with designed expert patterns to yield a final detection system.\nExtensive experiments are conducted on all the smart contracts that have source\ncode in Ethereum and VNT Chain platforms. Empirical results show significant\naccuracy improvements over the state-of-the-art methods on three types of\nvulnerabilities, where the detection accuracy of our method reaches 89.15%,\n89.02%, and 83.21% for reentrancy, timestamp dependence, and infinite loop\nvulnerabilities, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 13:16:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Zhenguang", ""], ["Qian", "Peng", ""], ["Wang", "Xiaoyang", ""], ["Zhuang", "Yuan", ""], ["Qiu", "Lin", ""], ["Wang", "Xun", ""]]}, {"id": "2107.11609", "submitter": "Umberto Michelucci", "authors": "Umberto Michelucci, Michela Sperti, Dario Piga, Francesca Venturini,\n  Marco A. Deriu", "title": "A Model-Agnostic Algorithm for Bayes Error Determination in Binary\n  Classification", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the intrinsic limit determination algorithm (ILD\nAlgorithm), a novel technique to determine the best possible performance,\nmeasured in terms of the AUC (area under the ROC curve) and accuracy, that can\nbe obtained from a specific dataset in a binary classification problem with\ncategorical features {\\sl regardless} of the model used. This limit, namely the\nBayes error, is completely independent of any model used and describes an\nintrinsic property of the dataset. The ILD algorithm thus provides important\ninformation regarding the prediction limits of any binary classification\nalgorithm when applied to the considered dataset. In this paper the algorithm\nis described in detail, its entire mathematical framework is presented and the\npseudocode is given to facilitate its implementation. Finally, an example with\na real dataset is given.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 13:55:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Michelucci", "Umberto", ""], ["Sperti", "Michela", ""], ["Piga", "Dario", ""], ["Venturini", "Francesca", ""], ["Deriu", "Marco A.", ""]]}, {"id": "2107.11621", "submitter": "Dun Zeng", "authors": "Dun Zeng, Siqi Liang, Xiangjing Hu, Zenglin Xu", "title": "FedLab: A Flexible Federated Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is a solution for privacy challenge, which allows\nmultiparty to train a shared model without violating privacy protection\nregulations. Many excellent works of FL have been proposed in recent years. To\nhelp researchers verify their ideas in FL, we designed and developed FedLab, a\nflexible and modular FL framework based on PyTorch. In this paper, we will\nintroduce architecture and features of FedLab. For current popular research\npoints: optimization and communication compression, FedLab provides functional\ninterfaces and a series of baseline implementation are available, making\nresearchers quickly implement ideas. In addition, FedLab is scale-able in both\nclient simulation and distributed communication.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 14:34:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zeng", "Dun", ""], ["Liang", "Siqi", ""], ["Hu", "Xiangjing", ""], ["Xu", "Zenglin", ""]]}, {"id": "2107.11625", "submitter": "Emiel Hoogeboom", "authors": "Alexandra Lindt, Emiel Hoogeboom", "title": "Discrete Denoising Flows", "comments": "Accepted to the Third workshop on Invertible Neural Networks,\n  Normalizing Flows, and Explicit Likelihood Models (ICML 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete flow-based models are a recently proposed class of generative models\nthat learn invertible transformations for discrete random variables. Since they\ndo not require data dequantization and maximize an exact likelihood objective,\nthey can be used in a straight-forward manner for lossless compression. In this\npaper, we introduce a new discrete flow-based model for categorical random\nvariables: Discrete Denoising Flows (DDFs). In contrast with other discrete\nflow-based models, our model can be locally trained without introducing\ngradient bias. We show that DDFs outperform Discrete Flows on modeling a toy\nexample, binary MNIST and Cityscapes segmentation maps, measured in\nlog-likelihood.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 14:47:22 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lindt", "Alexandra", ""], ["Hoogeboom", "Emiel", ""]]}, {"id": "2107.11630", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er", "title": "Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them", "comments": "ICML 2021 Workshop on the Prospects and Perils of Adversarial Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making classifiers robust to adversarial examples is hard. Thus, many\ndefenses tackle the seemingly easier task of detecting perturbed inputs. We\nshow a barrier towards this goal. We prove a general hardness reduction between\ndetection and classification of adversarial examples: given a robust detector\nfor attacks at distance {\\epsilon} (in some metric), we can build a similarly\nrobust (but inefficient) classifier for attacks at distance {\\epsilon}/2. Our\nreduction is computationally inefficient, and thus cannot be used to build\npractical classifiers. Instead, it is a useful sanity check to test whether\nempirical detection results imply something much stronger than the authors\npresumably anticipated. To illustrate, we revisit 13 detector defenses. For\n11/13 cases, we show that the claimed detection results would imply an\ninefficient classifier with robustness far beyond the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 15:14:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tram\u00e8r", "Florian", ""]]}, {"id": "2107.11640", "submitter": "Mohamed Shehata", "authors": "Mohamed Shehata, Mohamed Taha Abou-Kreisha, Hany Elnashar", "title": "Deep Machine Learning Based Egyptian Vehicle License Plate Recognition\n  Systems", "comments": "8 Pages, 20 Figures, 5 Tables, Published with Al-Azhar Engineering\n  Fifteenth International Conference (AEIC 2021)", "journal-ref": "Al-Azhar Engineering Fifteenth International Conference (March\n  2021): 69-76", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated Vehicle License Plate (VLP) detection and recognition have ended up\nbeing a significant research issue as of late. VLP localization and recognition\nare some of the most essential techniques for managing traffic using digital\ntechniques. In this paper, four smart systems are developed to recognize\nEgyptian vehicles license plates. Two systems are based on character\nrecognition, which are (System1, Characters Recognition with Classical Machine\nLearning) and (System2, Characters Recognition with Deep Machine Learning). The\nother two systems are based on the whole plate recognition which are (System3,\nWhole License Plate Recognition with Classical Machine Learning) and (System4,\nWhole License Plate Recognition with Deep Machine Learning). We use object\ndetection algorithms, and machine learning based object recognition algorithms.\nThe performance of the developed systems has been tested on real images, and\nthe experimental results demonstrate that the best detection accuracy rate for\nVLP is provided by using the deep learning method. Where the VLP detection\naccuracy rate is better than the classical system by 32%. However, the best\ndetection accuracy rate for Vehicle License Plate Arabic Character (VLPAC) is\nprovided by using the classical method. Where VLPAC detection accuracy rate is\nbetter than the deep learning-based system by 6%. Also, the results show that\ndeep learning is better than the classical technique used in VLP recognition\nprocesses. Where the recognition accuracy rate is better than the classical\nsystem by 8%. Finally, the paper output recommends a robust VLP recognition\nsystem based on both statistical and deep machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 15:58:01 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shehata", "Mohamed", ""], ["Abou-Kreisha", "Mohamed Taha", ""], ["Elnashar", "Hany", ""]]}, {"id": "2107.11658", "submitter": "Nikolaos Dionelis", "authors": "Nikolaos Dionelis", "title": "Tail of Distribution GAN (TailGAN): Generative-\n  Adversarial-Network-Based Boundary Formation", "comments": "5 pages, 2020 Sensor Signal Processing for Defence Conference (SSPD)", "journal-ref": "2020 Sensor Signal Processing for Defence Conference (SSPD)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GAN) are a powerful methodology and can be\nused for unsupervised anomaly detection, where current techniques have\nlimitations such as the accurate detection of anomalies near the tail of a\ndistribution. GANs generally do not guarantee the existence of a probability\ndensity and are susceptible to mode collapse, while few GANs use likelihood to\nreduce mode collapse. In this paper, we create a GAN-based tail formation model\nfor anomaly detection, the Tail of distribution GAN (TailGAN), to generate\nsamples on the tail of the data distribution and detect anomalies near the\nsupport boundary. Using TailGAN, we leverage GANs for anomaly detection and use\nmaximum entropy regularization. Using GANs that learn the probability of the\nunderlying distribution has advantages in improving the anomaly detection\nmethodology by allowing us to devise a generator for boundary samples, and use\nthis model to characterize anomalies. TailGAN addresses supports with disjoint\ncomponents and achieves competitive performance on images. We evaluate TailGAN\nfor identifying Out-of-Distribution (OoD) data and its performance evaluated on\nMNIST, CIFAR-10, Baggage X-Ray, and OoD data shows competitiveness compared to\nmethods from the literature.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 17:29:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Dionelis", "Nikolaos", ""]]}, {"id": "2107.11662", "submitter": "Rahul Singh", "authors": "Rahul Singh, Yongxin Chen", "title": "Inference of collective Gaussian hidden Markov models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider inference problems for a class of continuous state collective\nhidden Markov models, where the data is recorded in aggregate (collective) form\ngenerated by a large population of individuals following the same dynamics. We\npropose an aggregate inference algorithm called collective Gaussian\nforward-backward algorithm, extending recently proposed Sinkhorn belief\npropagation algorithm to models characterized by Gaussian densities. Our\nalgorithm enjoys convergence guarantee. In addition, it reduces to the standard\nKalman filter when the observations are generated by a single individual. The\nefficacy of the proposed algorithm is demonstrated through multiple\nexperiments.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 17:49:01 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Singh", "Rahul", ""], ["Chen", "Yongxin", ""]]}, {"id": "2107.11666", "submitter": "Piotr Koniusz", "authors": "Hao Zhu, Piotr Koniusz", "title": "Graph Convolutional Network with Generalized Factorized Bilinear\n  Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Graph Convolutional Networks (GCNs) have demonstrated their power in\nvarious applications, the graph convolutional layers, as the most important\ncomponent of GCN, are still using linear transformations and a simple pooling\nstep. In this paper, we propose a novel generalization of Factorized Bilinear\n(FB) layer to model the feature interactions in GCNs. FB performs two\nmatrix-vector multiplications, that is, the weight matrix is multiplied with\nthe outer product of the vector of hidden features from both sides. However,\nthe FB layer suffers from the quadratic number of coefficients, overfitting and\nthe spurious correlations due to correlations between channels of hidden\nrepresentations that violate the i.i.d. assumption. Thus, we propose a compact\nFB layer by defining a family of summarizing operators applied over the\nquadratic term. We analyze proposed pooling operators and motivate their use.\nOur experimental results on multiple datasets demonstrate that the GFB-GCN is\ncompetitive with other methods for text classification.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 17:57:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhu", "Hao", ""], ["Koniusz", "Piotr", ""]]}, {"id": "2107.11671", "submitter": "Ali Rahmati", "authors": "Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Huaiyu Dai", "title": "Adversarial training may be a double-edged sword", "comments": "Presented as a RobustML workshop paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial training has been shown as an effective approach to improve the\nrobustness of image classifiers against white-box attacks. However, its\neffectiveness against black-box attacks is more nuanced. In this work, we\ndemonstrate that some geometric consequences of adversarial training on the\ndecision boundary of deep networks give an edge to certain types of black-box\nattacks. In particular, we define a metric called robustness gain to show that\nwhile adversarial training is an effective method to dramatically improve the\nrobustness in white-box scenarios, it may not provide such a good robustness\ngain against the more realistic decision-based black-box attacks. Moreover, we\nshow that even the minimal perturbation white-box attacks can converge faster\nagainst adversarially-trained neural networks compared to the regular ones.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 19:09:16 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Rahmati", "Ali", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2107.11676", "submitter": "Ondrej Biza", "authors": "Ondrej Biza and Elise van der Pol and Thomas Kipf", "title": "The Impact of Negative Sampling on Contrastive Structured World Models", "comments": "This work appeared at the ICML 2021 Workshop: Self-Supervised\n  Learning for Reasoning and Perception", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World models trained by contrastive learning are a compelling alternative to\nautoencoder-based world models, which learn by reconstructing pixel states. In\nthis paper, we describe three cases where small changes in how we sample\nnegative states in the contrastive loss lead to drastic changes in model\nperformance. In previously studied Atari datasets, we show that leveraging time\nstep correlations can double the performance of the Contrastive Structured\nWorld Model. We also collect a full version of the datasets to study\ncontrastive learning under a more diverse set of experiences.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 19:42:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Biza", "Ondrej", ""], ["van der Pol", "Elise", ""], ["Kipf", "Thomas", ""]]}, {"id": "2107.11678", "submitter": "Ruibo Shang", "authors": "Ruibo Shang, Mikaela A. O'Brien, Geoffrey P. Luke", "title": "Deep-learning-driven Reliable Single-pixel Imaging with Uncertainty\n  Approximation", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-pixel imaging (SPI) has the advantages of high-speed acquisition over\na broad wavelength range and system compactness, which are difficult to achieve\nby conventional imaging sensors. However, a common challenge is low image\nquality arising from undersampling. Deep learning (DL) is an emerging and\npowerful tool in computational imaging for many applications and researchers\nhave applied DL in SPI to achieve higher image quality than conventional\nreconstruction approaches. One outstanding challenge, however, is that the\naccuracy of DL predictions in SPI cannot be assessed in practical applications\nwhere the ground truths are unknown. Here, we propose the use of the Bayesian\nconvolutional neural network (BCNN) to approximate the uncertainty (coming from\nfinite training data and network model) of the DL predictions in SPI. Each\npixel in the predicted result from BCNN represents the parameter of a\nprobability distribution rather than the image intensity value. Then, the\nuncertainty can be approximated with BCNN by minimizing a negative\nlog-likelihood loss function in the training stage and Monte Carlo dropout in\nthe prediction stage. The results show that the BCNN can reliably approximate\nthe uncertainty of the DL predictions in SPI with varying compression ratios\nand noise levels. The predicted uncertainty from BCNN in SPI reveals that most\nof the reconstruction errors in deep-learning-based SPI come from the edges of\nthe image features. The results show that the proposed BCNN can provide a\nreliable tool to approximate the uncertainty of DL predictions in SPI and can\nbe widely used in many applications of SPI.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 20:01:38 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shang", "Ruibo", ""], ["O'Brien", "Mikaela A.", ""], ["Luke", "Geoffrey P.", ""]]}, {"id": "2107.11707", "submitter": "Nasib Ullah", "authors": "Nasibullah, Partha Pratim Mohanta", "title": "Boosting Video Captioning with Dynamic Loss Network", "comments": "10 pages, 3 figures, Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video captioning is one of the challenging problems at the intersection of\nvision and language, having many real-life applications in video retrieval,\nvideo surveillance, assisting visually challenged people, Human-machine\ninterface, and many more. Recent deep learning-based methods have shown\npromising results but are still on the lower side than other vision tasks (such\nas image classification, object detection). A significant drawback with\nexisting video captioning methods is that they are optimized over cross-entropy\nloss function, which is uncorrelated to the de facto evaluation metrics (BLEU,\nMETEOR, CIDER, ROUGE).In other words, cross-entropy is not a proper surrogate\nof the true loss function for video captioning. This paper addresses the\ndrawback by introducing a dynamic loss network (DLN), which provides an\nadditional feedback signal that directly reflects the evaluation metrics. Our\nresults on Microsoft Research Video Description Corpus (MSVD) and MSR-Video to\nText (MSRVTT) datasets outperform previous methods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 01:32:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Nasibullah", "", ""], ["Mohanta", "Partha Pratim", ""]]}, {"id": "2107.11712", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, Vedant Raval,\n  N. V. Vinodchandran", "title": "Efficient inference of interventional distributions", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of efficiently inferring interventional distributions\nin a causal Bayesian network from a finite number of observations. Let\n$\\mathcal{P}$ be a causal model on a set $\\mathbf{V}$ of observable variables\non a given causal graph $G$. For sets $\\mathbf{X},\\mathbf{Y}\\subseteq\n\\mathbf{V}$, and setting ${\\bf x}$ to $\\mathbf{X}$, let $P_{\\bf x}(\\mathbf{Y})$\ndenote the interventional distribution on $\\mathbf{Y}$ with respect to an\nintervention ${\\bf x}$ to variables ${\\bf x}$. Shpitser and Pearl (AAAI 2006),\nbuilding on the work of Tian and Pearl (AAAI 2001), gave an exact\ncharacterization of the class of causal graphs for which the interventional\ndistribution $P_{\\bf x}({\\mathbf{Y}})$ can be uniquely determined. We give the\nfirst efficient version of the Shpitser-Pearl algorithm. In particular, under\nnatural assumptions, we give a polynomial-time algorithm that on input a causal\ngraph $G$ on observable variables $\\mathbf{V}$, a setting ${\\bf x}$ of a set\n$\\mathbf{X} \\subseteq \\mathbf{V}$ of bounded size, outputs succinct\ndescriptions of both an evaluator and a generator for a distribution $\\hat{P}$\nthat is $\\varepsilon$-close (in total variation distance) to $P_{\\bf\nx}({\\mathbf{Y}})$ where $Y=\\mathbf{V}\\setminus \\mathbf{X}$, if $P_{\\bf\nx}(\\mathbf{Y})$ is identifiable. We also show that when $\\mathbf{Y}$ is an\narbitrary set, there is no efficient algorithm that outputs an evaluator of a\ndistribution that is $\\varepsilon$-close to $P_{\\bf x}({\\mathbf{Y}})$ unless\nall problems that have statistical zero-knowledge proofs, including the Graph\nIsomorphism problem, have efficient randomized algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 02:40:01 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 15:14:09 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gayen", "Sutanu", ""], ["Kandasamy", "Saravanan", ""], ["Raval", "Vedant", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "2107.11717", "submitter": "Avik Roy", "authors": "Chandrajit Bajaj, Avik Roy, Haoran Zhang", "title": "Invariance-based Multi-Clustering of Latent Space Embeddings for\n  Equivariant Learning", "comments": "The codebase for MCEVAE is available at\n  https://github.com/CVC-Lab/MCE-VAE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAEs) have been shown to be remarkably effective in\nrecovering model latent spaces for several computer vision tasks. However,\ncurrently trained VAEs, for a number of reasons, seem to fall short in learning\ninvariant and equivariant clusters in latent space. Our work focuses on\nproviding solutions to this problem and presents an approach to disentangle\nequivariance feature maps in a Lie group manifold by enforcing deep,\ngroup-invariant learning. Simultaneously implementing a novel separation of\nsemantic and equivariant variables of the latent space representation, we\nformulate a modified Evidence Lower BOund (ELBO) by using a mixture model pdf\nlike Gaussian mixtures for invariant cluster embeddings that allows superior\nunsupervised variational clustering. Our experiments show that this model\neffectively learns to disentangle the invariant and equivariant representations\nwith significant improvements in the learning rate and an observably superior\nimage recognition and canonical state reconstruction compared to the currently\nbest deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 03:27:47 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Bajaj", "Chandrajit", ""], ["Roy", "Avik", ""], ["Zhang", "Haoran", ""]]}, {"id": "2107.11722", "submitter": "David D. Fan", "authors": "David D. Fan, Ali-akbar Agha-mohammadi, Evangelos A. Theodorou", "title": "Learning Risk-aware Costmaps for Traversability in Challenging\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in autonomous robotic exploration and navigation\nin unknown and unstructured environments is determining where the robot can or\ncannot safely move. A significant source of difficulty in this determination\narises from stochasticity and uncertainty, coming from localization error,\nsensor sparsity and noise, difficult-to-model robot-ground interactions, and\ndisturbances to the motion of the vehicle. Classical approaches to this problem\nrely on geometric analysis of the surrounding terrain, which can be prone to\nmodeling errors and can be computationally expensive. Moreover, modeling the\ndistribution of uncertain traversability costs is a difficult task, compounded\nby the various error sources mentioned above. In this work, we take a\nprincipled learning approach to this problem. We introduce a neural network\narchitecture for robustly learning the distribution of traversability costs.\nBecause we are motivated by preserving the life of the robot, we tackle this\nlearning problem from the perspective of learning tail-risks, i.e. the\nConditional Value-at-Risk (CVaR). We show that this approach reliably learns\nthe expected tail risk given a desired probability risk threshold between 0 and\n1, producing a traversability costmap which is more robust to outliers, more\naccurately captures tail risks, and is more computationally efficient, when\ncompared against baselines. We validate our method on data collected a legged\nrobot navigating challenging, unstructured environments including an abandoned\nsubway, limestone caves, and lava tube caves.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 04:12:03 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fan", "David D.", ""], ["Agha-mohammadi", "Ali-akbar", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2107.11728", "submitter": "Fengjiao Li", "authors": "Fengjiao Li, Jia Liu, and Bo Ji", "title": "Federated Learning with Fair Worker Selection: A Multi-Round Submodular\n  Maximization Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of fair worker selection in Federated\nLearning systems, where fairness serves as an incentive mechanism that\nencourages more workers to participate in the federation. Considering the\nachieved training accuracy of the global model as the utility of the selected\nworkers, which is typically a monotone submodular function, we formulate the\nworker selection problem as a new multi-round monotone submodular maximization\nproblem with cardinality and fairness constraints. The objective is to maximize\nthe time-average utility over multiple rounds subject to an additional fairness\nrequirement that each worker must be selected for a certain fraction of time.\nWhile the traditional submodular maximization with a cardinality constraint is\nalready a well-known NP-Hard problem, the fairness constraint in the\nmulti-round setting adds an extra layer of difficulty. To address this novel\nchallenge, we propose three algorithms: Fair Continuous Greedy (FairCG1 and\nFairCG2) and Fair Discrete Greedy (FairDG), all of which satisfy the fairness\nrequirement whenever feasible. Moreover, we prove nontrivial lower bounds on\nthe achieved time-average utility under FairCG1 and FairCG2. In addition, by\ngiving a higher priority to fairness, FairDG ensures a stronger short-term\nfairness guarantee, which holds in every round. Finally, we perform extensive\nsimulations to verify the effectiveness of the proposed algorithms in terms of\nthe time-average utility and fairness satisfaction.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 05:17:34 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Fengjiao", ""], ["Liu", "Jia", ""], ["Ji", "Bo", ""]]}, {"id": "2107.11732", "submitter": "Ruoxuan Xiong", "authors": "Ruoxuan Xiong, Allison Koenecke, Michael Powell, Zhu Shen, Joshua T.\n  Vogelstein, Susan Athey", "title": "Federated Causal Inference in Heterogeneous Observational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing observational data from multiple sources can be useful for\nincreasing statistical power to detect a treatment effect; however, practical\nconstraints such as privacy considerations may restrict individual-level\ninformation sharing across data sets. This paper develops federated methods\nthat only utilize summary-level information from heterogeneous data sets. Our\nfederated methods provide doubly-robust point estimates of treatment effects as\nwell as variance estimates. We derive the asymptotic distributions of our\nfederated estimators, which are shown to be asymptotically equivalent to the\ncorresponding estimators from the combined, individual-level data. We show that\nto achieve these properties, federated methods should be adjusted based on\nconditions such as whether models are correctly specified and stable across\nheterogeneous data sets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 05:55:00 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Xiong", "Ruoxuan", ""], ["Koenecke", "Allison", ""], ["Powell", "Michael", ""], ["Shen", "Zhu", ""], ["Vogelstein", "Joshua T.", ""], ["Athey", "Susan", ""]]}, {"id": "2107.11736", "submitter": "Yeli Feng", "authors": "Yeli Feng, Arvind Easwaran", "title": "WiP Abstract : Robust Out-of-distribution Motion Detection and\n  Localization in Autonomous CPS", "comments": null, "journal-ref": null, "doi": "10.1145/3450267.3452000", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly complex deep learning models are increasingly integrated into modern\ncyber-physical systems (CPS), many of which have strict safety requirements.\nOne problem arising from this is that deep learning lacks interpretability,\noperating as a black box. The reliability of deep learning is heavily impacted\nby how well the model training data represents runtime test data, especially\nwhen the input space dimension is high as natural images. In response, we\npropose a robust out-of-distribution (OOD) detection framework. Our approach\ndetects unusual movements from driving video in real-time by combining\nclassical optic flow operation with representation learning via variational\nautoencoder (VAE). We also design a method to locate OOD factors in images.\nEvaluation on a driving simulation data set shows that our approach is\nstatistically more robust than related works.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 06:20:05 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Feng", "Yeli", ""], ["Easwaran", "Arvind", ""]]}, {"id": "2107.11740", "submitter": "Weihua Deng Professor", "authors": "Chongcan Li, Yong Cong, and Weihua Deng", "title": "Identifying the fragment structure of the organic compounds by deeply\n  learning the original NMR data", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We preprocess the raw NMR spectrum and extract key characteristic features by\nusing two different methodologies, called equidistant sampling and peak\nsampling for subsequent substructure pattern recognition; meanwhile may provide\nthe alternative strategy to address the imbalance issue of the NMR dataset\nfrequently encountered in dataset collection of statistical modeling and\nestablish two conventional SVM and KNN models to assess the capability of two\nfeature selection, respectively. Our results in this study show that the models\nusing the selected features of peak sampling outperform the ones using the\nother. Then we build the Recurrent Neural Network (RNN) model trained by Data B\ncollected from peak sampling. Furthermore, we illustrate the easier\noptimization of hyper parameters and the better generalization ability of the\nRNN deep learning model by comparison with traditional machine learning SVM and\nKNN models in detail.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 06:45:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Chongcan", ""], ["Cong", "Yong", ""], ["Deng", "Weihua", ""]]}, {"id": "2107.11750", "submitter": "Yeli Feng", "authors": "Yeli Feng, Daniel Jun Xian Ng, Arvind Easwaran", "title": "Improving Variational Autoencoder based Out-of-Distribution Detection\n  for Embedded Real-time Applications", "comments": null, "journal-ref": null, "doi": "10.1145/3477026", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainties in machine learning are a significant roadblock for its\napplication in safety-critical cyber-physical systems (CPS). One source of\nuncertainty arises from distribution shifts in the input data between training\nand test scenarios. Detecting such distribution shifts in real-time is an\nemerging approach to address the challenge. The high dimensional input space in\nCPS applications involving imaging adds extra difficulty to the task.\nGenerative learning models are widely adopted for the task, namely\nout-of-distribution (OoD) detection. To improve the state-of-the-art, we\nstudied existing proposals from both machine learning and CPS fields. In the\nlatter, safety monitoring in real-time for autonomous driving agents has been a\nfocus. Exploiting the spatiotemporal correlation of motion in videos, we can\nrobustly detect hazardous motion around autonomous driving agents. Inspired by\nthe latest advances in the Variational Autoencoder (VAE) theory and practice,\nwe tapped into the prior knowledge in data to further boost OoD detection's\nrobustness. Comparison studies over nuScenes and Synthia data sets show our\nmethods significantly improve detection capabilities of OoD factors unique to\ndriving scenarios, 42% better than state-of-the-art approaches. Our model also\ngeneralized near-perfectly, 97% better than the state-of-the-art across the\nreal-world and simulation driving data sets experimented. Finally, we\ncustomized one proposed method into a twin-encoder model that can be deployed\nto resource limited embedded devices for real-time OoD detection. Its execution\ntime was reduced over four times in low-precision 8-bit integer inference,\nwhile detection capability is comparable to its corresponding floating-point\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 07:52:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Feng", "Yeli", ""], ["Ng", "Daniel Jun Xian", ""], ["Easwaran", "Arvind", ""]]}, {"id": "2107.11762", "submitter": "Haoyi Niu", "authors": "Haoyi Niu, Jianming Hu, Zheyu Cui and Yi Zhang", "title": "DR2L: Surfacing Corner Cases to Robustify Autonomous Driving via Domain\n  Randomization Reinforcement Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to explore corner cases as efficiently and thoroughly as possible has\nlong been one of the top concerns in the context of deep reinforcement learning\n(DeepRL) autonomous driving. Training with simulated data is less costly and\ndangerous than utilizing real-world data, but the inconsistency of parameter\ndistribution and the incorrect system modeling in simulators always lead to an\ninevitable Sim2real gap, which probably accounts for the underperformance in\nnovel, anomalous and risky cases that simulators can hardly generate. Domain\nRandomization(DR) is a methodology that can bridge this gap with little or no\nreal-world data. Consequently, in this research, an adversarial model is put\nforward to robustify DeepRL-based autonomous vehicles trained in simulation to\ngradually surfacing harder events, so that the models could readily transfer to\nthe real world.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 09:15:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Niu", "Haoyi", ""], ["Hu", "Jianming", ""], ["Cui", "Zheyu", ""], ["Zhang", "Yi", ""]]}, {"id": "2107.11769", "submitter": "Tsung-Han Wu", "authors": "Tsung-Han Wu, Yueh-Cheng Liu, Yu-Kai Huang, Hsin-Ying Lee, Hung-Ting\n  Su, Ping-Chia Huang, Winston H. Hsu", "title": "ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud\n  Semantic Segmentation", "comments": "Accepted by ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite the success of deep learning on supervised point cloud semantic\nsegmentation, obtaining large-scale point-by-point manual annotations is still\na significant challenge. To reduce the huge annotation burden, we propose a\nRegion-based and Diversity-aware Active Learning (ReDAL), a general framework\nfor many deep learning approaches, aiming to automatically select only\ninformative and diverse sub-scene regions for label acquisition. Observing that\nonly a small portion of annotated regions are sufficient for 3D scene\nunderstanding with deep learning, we use softmax entropy, color discontinuity,\nand structural complexity to measure the information of sub-scene regions. A\ndiversity-aware selection algorithm is also developed to avoid redundant\nannotations resulting from selecting informative but similar regions in a\nquerying batch. Extensive experiments show that our method highly outperforms\nprevious active learning strategies, and we achieve the performance of 90%\nfully supervised learning, while less than 15% and 5% annotations are required\non S3DIS and SemanticKITTI datasets, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 09:40:48 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wu", "Tsung-Han", ""], ["Liu", "Yueh-Cheng", ""], ["Huang", "Yu-Kai", ""], ["Lee", "Hsin-Ying", ""], ["Su", "Hung-Ting", ""], ["Huang", "Ping-Chia", ""], ["Hsu", "Winston H.", ""]]}, {"id": "2107.11774", "submitter": "Liu Ziyin", "authors": "Liu Ziyin, Botao Li, Masahito Ueda", "title": "SGD May Never Escape Saddle Points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has been deployed to solve highly\nnon-linear and non-convex machine learning problems such as the training of\ndeep neural networks. However, previous works on SGD often rely on highly\nrestrictive and unrealistic assumptions about the nature of noise in SGD. In\nthis work, we mathematically construct examples that defy previous\nunderstandings of SGD. For example, our constructions show that: (1) SGD may\nconverge to a local maximum; (2) SGD may escape a saddle point arbitrarily\nslowly; (3) SGD may prefer sharp minima over the flat ones; and (4) AMSGrad may\nconverge to a local maximum. Our result suggests that the noise structure of\nSGD might be more important than the loss landscape in neural network training\nand that future research should focus on deriving the actual noise structure in\ndeep learning.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 10:12:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ziyin", "Liu", ""], ["Li", "Botao", ""], ["Ueda", "Masahito", ""]]}, {"id": "2107.11784", "submitter": "Tapani Toivonen Dr.", "authors": "Tapani Toivonen", "title": "Power of human-algorithm collaboration in solving combinatorial\n  optimization problems", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many combinatorial optimization problems are often considered intractable to\nsolve exactly or by approximation. An example of such problem is maximum clique\nwhich -- under standard assumptions in complexity theory -- cannot be solved in\nsub-exponential time or be approximated within polynomial factor efficiently.\nWe show that if a polynomial time algorithm can query informative Gaussian\npriors from an expert $poly(n)$ times, then a class of combinatorial\noptimization problems can be solved efficiently in expectation up to a\nmultiplicative factor $\\epsilon$ where $\\epsilon$ is arbitrary constant. While\nour proposed methods are merely theoretical, they cast new light on how to\napproach solving these problems that have been usually considered intractable.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 11:21:59 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Toivonen", "Tapani", ""]]}, {"id": "2107.11789", "submitter": "Wentao Zhang", "authors": "Wentao Zhang, Yuezihan Jiang, Yang Li, Zeang Sheng, Yu Shen, Xupeng\n  Miao, Liang Wang, Zhi Yang, Bin Cui", "title": "ROD: Reception-aware Online Distillation for Sparse Graphs", "comments": null, "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD-2021)", "doi": "10.1145/3447548.3467221", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have been widely used in many graph-based tasks\nsuch as node classification, link prediction, and node clustering. However,\nGNNs gain their performance benefits mainly from performing the feature\npropagation and smoothing across the edges of the graph, thus requiring\nsufficient connectivity and label information for effective propagation.\nUnfortunately, many real-world networks are sparse in terms of both edges and\nlabels, leading to sub-optimal performance of GNNs. Recent interest in this\nsparse problem has focused on the self-training approach, which expands\nsupervised signals with pseudo labels. Nevertheless, the self-training approach\ninherently cannot realize the full potential of refining the learning\nperformance on sparse graphs due to the unsatisfactory quality and quantity of\npseudo labels.\n  In this paper, we propose ROD, a novel reception-aware online knowledge\ndistillation approach for sparse graph learning. We design three supervision\nsignals for ROD: multi-scale reception-aware graph knowledge, task-based\nsupervision, and rich distilled knowledge, allowing online knowledge transfer\nin a peer-teaching manner. To extract knowledge concealed in the multi-scale\nreception fields, ROD explicitly requires individual student models to preserve\ndifferent levels of locality information. For a given task, each student would\npredict based on its reception-scale knowledge, while simultaneously a strong\nteacher is established on-the-fly by combining multi-scale knowledge. Our\napproach has been extensively evaluated on 9 datasets and a variety of\ngraph-based tasks, including node classification, link prediction, and node\nclustering. The result demonstrates that ROD achieves state-of-art performance\nand is more robust for the graph sparsity.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 11:55:47 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Wentao", ""], ["Jiang", "Yuezihan", ""], ["Li", "Yang", ""], ["Sheng", "Zeang", ""], ["Shen", "Yu", ""], ["Miao", "Xupeng", ""], ["Wang", "Liang", ""], ["Yang", "Zhi", ""], ["Cui", "Bin", ""]]}, {"id": "2107.11795", "submitter": "Hrishikesh Viswanath", "authors": "P Preethi and Hrishikesh Viswanath", "title": "Character Spotting Using Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.24999.88485", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This work presents a comparison of machine learning algorithms that are\nimplemented to segment the characters of text presented as an image. The\nalgorithms are designed to work on degraded documents with text that is not\naligned in an organized fashion. The paper investigates the use of Support\nVector Machines, K-Nearest Neighbor algorithm and an Encoder Network to perform\nthe operation of character spotting. Character Spotting involves extracting\npotential characters from a stream of text by selecting regions bound by white\nspace.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 12:36:57 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 07:15:15 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Preethi", "P", ""], ["Viswanath", "Hrishikesh", ""]]}, {"id": "2107.11801", "submitter": "Hrishikesh Viswanath", "authors": "P Preethi and Hrishikesh Viswanath", "title": "Denoising and Segmentation of Epigraphical Scripts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper is a presentation of a new method for denoising images using\nHaralick features and further segmenting the characters using artificial neural\nnetworks. The image is divided into kernels, each of which is converted to a\nGLCM (Gray Level Co-Occurrence Matrix) on which a Haralick Feature generation\nfunction is called, the result of which is an array with fourteen elements\ncorresponding to fourteen features The Haralick values and the corresponding\nnoise/text classification form a dictionary, which is then used to de-noise the\nimage through kernel comparison. Segmentation is the process of extracting\ncharacters from a document and can be used when letters are separated by white\nspace, which is an explicit boundary marker. Segmentation is the first step in\nmany Natural Language Processing problems. This paper explores the process of\nsegmentation using Neural Networks. While there have been numerous methods to\nsegment characters of a document, this paper is only concerned with the\naccuracy of doing so using neural networks. It is imperative that the\ncharacters be segmented correctly, for failing to do so will lead to incorrect\nrecognition by Natural language processing tools. Artificial Neural Networks\nwas used to attain accuracy of upto 89%. This method is suitable for languages\nwhere the characters are delimited by white space. However, this method will\nfail to provide acceptable results when the language heavily uses connected\nletters. An example would be the Devanagari script, which is predominantly used\nin northern India.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 13:25:08 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Preethi", "P", ""], ["Viswanath", "Hrishikesh", ""]]}, {"id": "2107.11811", "submitter": "Ryoya Ogishima", "authors": "Ryoya Ogishima, Izumi Karino, Yasuo Kuniyoshi", "title": "Reinforced Imitation Learning by Free Energy Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement Learning (RL) requires a large amount of exploration especially\nin sparse-reward settings. Imitation Learning (IL) can learn from expert\ndemonstrations without exploration, but it never exceeds the expert's\nperformance and is also vulnerable to distributional shift between\ndemonstration and execution. In this paper, we radically unify RL and IL based\non Free Energy Principle (FEP). FEP is a unified Bayesian theory of the brain\nthat explains perception, action and model learning by a common fundamental\nprinciple. We present a theoretical extension of FEP and derive an algorithm in\nwhich an agent learns the world model that internalizes expert demonstrations\nand at the same time uses the model to infer the current and future states and\nactions that maximize rewards. The algorithm thus reduces exploration costs by\npartially imitating experts as well as maximizing its return in a seamless way,\nresulting in a higher performance than the suboptimal expert. Our experimental\nresults show that this approach is promising in visual control tasks especially\nin sparse-reward environments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 14:19:29 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ogishima", "Ryoya", ""], ["Karino", "Izumi", ""], ["Kuniyoshi", "Yasuo", ""]]}, {"id": "2107.11817", "submitter": "Fuzhao Xue", "authors": "Fuzhao Xue, Ziji Shi, Futao Wei, Yuxuan Lou, Yong Liu, Yang You", "title": "Go Wider Instead of Deeper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transformer has recently achieved impressive results on various tasks. To\nfurther improve the effectiveness and efficiency of the transformer, there are\ntwo trains of thought among existing works: (1) going wider by scaling to more\ntrainable parameters; (2) going shallower by parameter sharing or model\ncompressing along with the depth. However, larger models usually do not scale\nwell when fewer tokens are available to train, and advanced parallelisms are\nrequired when the model is extremely large. Smaller models usually achieve\ninferior performance compared to the original transformer model due to the loss\nof representation power. In this paper, to achieve better performance with\nfewer trainable parameters, we propose a framework to deploy trainable\nparameters efficiently, by going wider instead of deeper. Specially, we scale\nalong model width by replacing feed-forward network (FFN) with\nmixture-of-experts (MoE). We then share the MoE layers across transformer\nblocks using individual layer normalization. Such deployment plays the role to\ntransform various semantic representations, which makes the model more\nparameter-efficient and effective. To evaluate our framework, we design WideNet\nand evaluate it on ImageNet-1K. Our best model outperforms Vision Transformer\n(ViT) by $1.46\\%$ with $0.72 \\times$ trainable parameters. Using $0.46 \\times$\nand $0.13 \\times$ parameters, our WideNet can still surpass ViT and ViT-MoE by\n$0.83\\%$ and $2.08\\%$, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 14:44:24 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 10:17:23 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Xue", "Fuzhao", ""], ["Shi", "Ziji", ""], ["Wei", "Futao", ""], ["Lou", "Yuxuan", ""], ["Liu", "Yong", ""], ["You", "Yang", ""]]}, {"id": "2107.11822", "submitter": "Jay Nandy", "authors": "Jay Nandy and Wynne Hsu and Mong Li Lee", "title": "Distributional Shifts in Automated Diabetic Retinopathy Screening", "comments": "Accepted at IEEE ICIP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning-based models are developed to automatically detect if a retina\nimage is `referable' in diabetic retinopathy (DR) screening. However, their\nclassification accuracy degrades as the input images distributionally shift\nfrom their training distribution. Further, even if the input is not a retina\nimage, a standard DR classifier produces a high confident prediction that the\nimage is `referable'. Our paper presents a Dirichlet Prior Network-based\nframework to address this issue. It utilizes an out-of-distribution (OOD)\ndetector model and a DR classification model to improve generalizability by\nidentifying OOD images. Experiments on real-world datasets indicate that the\nproposed framework can eliminate the unknown non-retina images and identify the\ndistributionally shifted retina images for human intervention.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 15:03:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Nandy", "Jay", ""], ["Hsu", "Wynne", ""], ["Lee", "Mong Li", ""]]}, {"id": "2107.11843", "submitter": "Aaron Tuor", "authors": "Jan Drgona, Aaron Tuor, Soumya Vasisht, Elliott Skomski and Draguna\n  Vrabie", "title": "Deep Learning Explicit Differentiable Predictive Control Laws for\n  Buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a differentiable predictive control (DPC) methodology for learning\nconstrained control laws for unknown nonlinear systems. DPC poses an\napproximate solution to multiparametric programming problems emerging from\nexplicit nonlinear model predictive control (MPC). Contrary to approximate MPC,\nDPC does not require supervision by an expert controller. Instead, a system\ndynamics model is learned from the observed system's dynamics, and the neural\ncontrol law is optimized offline by leveraging the differentiable closed-loop\nsystem model. The combination of a differentiable closed-loop system and\npenalty methods for constraint handling of system outputs and inputs allows us\nto optimize the control law's parameters directly by backpropagating economic\nMPC loss through the learned system model. The control performance of the\nproposed DPC method is demonstrated in simulation using learned model of\nmulti-zone building thermal dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 16:47:57 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Drgona", "Jan", ""], ["Tuor", "Aaron", ""], ["Vasisht", "Soumya", ""], ["Skomski", "Elliott", ""], ["Vrabie", "Draguna", ""]]}, {"id": "2107.11844", "submitter": "Jagdish Chand Bansal Ph.D.", "authors": "Susheel Kumar Joshi, Jagdish Chand Bansal", "title": "A binary variant of gravitational search algorithm and its application\n  to windfarm layout optimization problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the binary search space, GSA framework encounters the shortcomings of\nstagnation, diversity loss, premature convergence and high time complexity. To\naddress these issues, a novel binary variant of GSA called `A novel\nneighbourhood archives embedded gravitational constant in GSA for binary search\nspace (BNAGGSA)' is proposed in this paper. In BNAGGSA, the novel\nfitness-distance based social interaction strategy produces a self-adaptive\nstep size mechanism through which the agent moves towards the optimal direction\nwith the optimal step size, as per its current search requirement. The\nperformance of the proposed algorithm is compared with the two binary variants\nof GSA over 23 well-known benchmark test problems. The experimental results and\nstatistical analyses prove the supremacy of BNAGGSA over the compared\nalgorithms. Furthermore, to check the applicability of the proposed algorithm\nin solving real-world applications, a windfarm layout optimization problem is\nconsidered. Two case studies with two different wind data sets of two different\nwind sites is considered for experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 16:56:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Joshi", "Susheel Kumar", ""], ["Bansal", "Jagdish Chand", ""]]}, {"id": "2107.11856", "submitter": "Amine Amor", "authors": "Amine Amor (1), Pietro Lio' (1), Vikash Singh (1), Ramon Vi\\~nas\n  Torn\\'e (1), Helena Andres Terre (1)", "title": "Graph Representation Learning on Tissue-Specific Multi-Omics", "comments": "This paper was accepted at the 2021 ICML Workshop on Computational\n  Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining different modalities of data from human tissues has been critical\nin advancing biomedical research and personalised medical care. In this study,\nwe leverage a graph embedding model (i.e VGAE) to perform link prediction on\ntissue-specific Gene-Gene Interaction (GGI) networks. Through ablation\nexperiments, we prove that the combination of multiple biological modalities\n(i.e multi-omics) leads to powerful embeddings and better link prediction\nperformances. Our evaluation shows that the integration of gene methylation\nprofiles and RNA-sequencing data significantly improves the link prediction\nperformance. Overall, the combination of RNA-sequencing and gene methylation\ndata leads to a link prediction accuracy of 71% on GGI networks. By harnessing\ngraph representation learning on multi-omics data, our work brings novel\ninsights to the current literature on multi-omics integration in\nbioinformatics.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 17:38:45 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Amor", "Amine", ""], ["Lio'", "Pietro", ""], ["Singh", "Vikash", ""], ["Torn\u00e9", "Ramon Vi\u00f1as", ""], ["Terre", "Helena Andres", ""]]}, {"id": "2107.11862", "submitter": "Jan Brabec", "authors": "Jan Brabec, Lukas Machlica", "title": "Decision-forest voting scheme for classification of rare classes in\n  network intrusion detection", "comments": "\\copyright 2018 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2018 IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC), 2018, pp. 3325-3330", "doi": "10.1109/SMC.2018.00563", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, Bayesian based aggregation of decision trees in an ensemble\n(decision forest) is investigated. The focus is laid on multi-class\nclassification with number of samples significantly skewed toward one of the\nclasses. The algorithm leverages out-of-bag datasets to estimate prediction\nerrors of individual trees, which are then used in accordance with the Bayes\nrule to refine the decision of the ensemble. The algorithm takes prevalence of\nindividual classes into account and does not require setting of any additional\nparameters related to class weights or decision-score thresholds. Evaluation is\nbased on publicly available datasets as well as on an proprietary dataset\ncomprising network traffic telemetry from hundreds of enterprise networks with\nover a million of users overall. The aim is to increase the detection\ncapabilities of an operating malware detection system. While we were able to\nkeep precision of the system higher than 94\\%, that is only 6 out of 100\ndetections shown to the network administrator are false alarms, we were able to\nachieve increase of approximately 7\\% in the number of detections. The\nalgorithm effectively handles large amounts of data, and can be used in\nconjunction with most of the state-of-the-art algorithms used to train decision\nforests.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 18:01:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Brabec", "Jan", ""], ["Machlica", "Lukas", ""]]}, {"id": "2107.11864", "submitter": "Frederik Schmitt", "authors": "Frederik Schmitt, Christopher Hahn, Markus N. Rabe and Bernd\n  Finkbeiner", "title": "Neural Circuit Synthesis from Specification Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train hierarchical Transformers on the task of synthesizing hardware\ncircuits directly out of high-level logical specifications in linear-time\ntemporal logic (LTL). The LTL synthesis problem is a well-known algorithmic\nchallenge with a long history and an annual competition is organized to track\nthe improvement of algorithms and tooling over time. New approaches using\nmachine learning might open a lot of possibilities in this area, but suffer\nfrom the lack of sufficient amounts of training data. In this paper, we\nconsider a method to generate large amounts of additional training data, i.e.,\npairs of specifications and circuits implementing them. We ensure that this\nsynthetic data is sufficiently close to human-written specifications by mining\ncommon patterns from the specifications used in the synthesis competitions. We\nshow that hierarchical Transformers trained on this synthetic data solve a\nsignificant portion of problems from the synthesis competitions, and even\nout-of-distribution examples from a recent case study.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 18:17:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Schmitt", "Frederik", ""], ["Hahn", "Christopher", ""], ["Rabe", "Markus N.", ""], ["Finkbeiner", "Bernd", ""]]}, {"id": "2107.11876", "submitter": "Yen-Ju Lu", "authors": "Yen-Ju Lu, Yu Tsao and Shinji Watanabe", "title": "A Study on Speech Enhancement Based on Diffusion Probabilistic Model", "comments": "submitted to APSIPA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion probabilistic models have demonstrated an outstanding capability to\nmodel natural images and raw audio waveforms through a paired diffusion and\nreverse processes. The unique property of the reverse process (namely,\neliminating non-target signals from the Gaussian noise and noisy signals) could\nbe utilized to restore clean signals. Based on this property, we propose a\ndiffusion probabilistic model-based speech enhancement (DiffuSE) model that\naims to recover clean speech signals from noisy signals. The fundamental\narchitecture of the proposed DiffuSE model is similar to that of DiffWave--a\nhigh-quality audio waveform generation model that has a relatively low\ncomputational cost and footprint. To attain better enhancement performance, we\ndesigned an advanced reverse process, termed the supportive reverse process,\nwhich adds noisy speech in each time-step to the predicted speech. The\nexperimental results show that DiffuSE yields performance that is comparable to\nrelated audio generative models on the standardized Voice Bank corpus SE task.\nMoreover, relative to the generally suggested full sampling schedule, the\nproposed supportive reverse process especially improved the fast sampling,\ntaking few steps to yield better enhancement results over the conventional full\nstep inference process.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 19:23:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lu", "Yen-Ju", ""], ["Tsao", "Yu", ""], ["Watanabe", "Shinji", ""]]}, {"id": "2107.11882", "submitter": "Riqiang Gao", "authors": "Riqiang Gao, Yucheng Tang, Kaiwen Xu, Ho Hin Lee, Steve Deppen, Kim\n  Sandler, Pierre Massion, Thomas A. Lasko, Yuankai Huo, Bennett A. Landman", "title": "Lung Cancer Risk Estimation with Incomplete Data: A Joint Missing\n  Imputation Perspective", "comments": "Early Accepted by MICCAI 2021. Traveling Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data from multi-modality provide complementary information in clinical\nprediction, but missing data in clinical cohorts limits the number of subjects\nin multi-modal learning context. Multi-modal missing imputation is challenging\nwith existing methods when 1) the missing data span across heterogeneous\nmodalities (e.g., image vs. non-image); or 2) one modality is largely missing.\nIn this paper, we address imputation of missing data by modeling the joint\ndistribution of multi-modal data. Motivated by partial bidirectional generative\nadversarial net (PBiGAN), we propose a new Conditional PBiGAN (C-PBiGAN) method\nthat imputes one modality combining the conditional knowledge from another\nmodality. Specifically, C-PBiGAN introduces a conditional latent space in a\nmissing imputation framework that jointly encodes the available multi-modal\ndata, along with a class regularization loss on imputed data to recover\ndiscriminative information. To our knowledge, it is the first generative\nadversarial model that addresses multi-modal missing imputation by modeling the\njoint distribution of image and non-image data. We validate our model with both\nthe national lung screening trial (NLST) dataset and an external clinical\nvalidation cohort. The proposed C-PBiGAN achieves significant improvements in\nlung cancer risk estimation compared with representative imputation methods\n(e.g., AUC values increase in both NLST (+2.9\\%) and in-house dataset (+4.3\\%)\ncompared with PBiGAN, p$<$0.05).\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 20:15:16 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gao", "Riqiang", ""], ["Tang", "Yucheng", ""], ["Xu", "Kaiwen", ""], ["Lee", "Ho Hin", ""], ["Deppen", "Steve", ""], ["Sandler", "Kim", ""], ["Massion", "Pierre", ""], ["Lasko", "Thomas A.", ""], ["Huo", "Yuankai", ""], ["Landman", "Bennett A.", ""]]}, {"id": "2107.11886", "submitter": "Jay Mardia", "authors": "Jay Mardia", "title": "Logspace Reducibility From Secret Leakage Planted Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The planted clique problem is well-studied in the context of observing,\nexplaining, and predicting interesting computational phenomena associated with\nstatistical problems. When equating computational efficiency with the existence\nof polynomial time algorithms, the computational hardness of (some variant of)\nthe planted clique problem can be used to infer the computational hardness of a\nhost of other statistical problems.\n  Is this ability to transfer computational hardness from (some variant of) the\nplanted clique problem to other statistical problems robust to changing our\nnotion of computational efficiency to space efficiency?\n  We answer this question affirmatively for three different statistical\nproblems, namely Sparse PCA, submatrix detection, and testing almost k-wise\nindependence. The key challenge is that space efficient randomized reductions\nneed to repeatedly access the randomness they use. Known reductions to these\nproblems are all randomized and need polynomially many random bits to\nimplement. Since we can not store polynomially many random bits in memory, it\nis unclear how to implement these existing reductions space efficiently. There\nare two ideas involved in circumventing this issue and implementing known\nreductions to these problems space efficiently.\n  1. When solving statistical problems, we can use parts of the input itself as\nrandomness.\n  2. Secret leakage variants of the planted clique problem with appropriate\nsecret leakage can be more useful than the standard planted clique problem when\nwe want to use parts of the input as randomness.\n  (abstract shortened due to arxiv constraints)\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 20:33:15 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mardia", "Jay", ""]]}, {"id": "2107.11889", "submitter": "Lucie Charlotte Magister", "authors": "Lucie Charlotte Magister, Dmitry Kazhdan, Vikash Singh, Pietro Li\\`o", "title": "GCExplainer: Human-in-the-Loop Concept-based Explanations for Graph\n  Neural Networks", "comments": "Accepted as 3rd ICML Workshop on Human in the Loop Learning, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While graph neural networks (GNNs) have been shown to perform well on\ngraph-based data from a variety of fields, they suffer from a lack of\ntransparency and accountability, which hinders trust and consequently the\ndeployment of such models in high-stake and safety-critical scenarios. Even\nthough recent research has investigated methods for explaining GNNs, these\nmethods are limited to single-instance explanations, also known as local\nexplanations. Motivated by the aim of providing global explanations, we adapt\nthe well-known Automated Concept-based Explanation approach (Ghorbani et al.,\n2019) to GNN node and graph classification, and propose GCExplainer.\nGCExplainer is an unsupervised approach for post-hoc discovery and extraction\nof global concept-based explanations for GNNs, which puts the human in the\nloop. We demonstrate the success of our technique on five node classification\ndatasets and two graph classification datasets, showing that we are able to\ndiscover and extract high-quality concept representations by putting the human\nin the loop. We achieve a maximum completeness score of 1 and an average\ncompleteness score of 0.753 across the datasets. Finally, we show that the\nconcept-based explanations provide an improved insight into the datasets and\nGNN models compared to the state-of-the-art explanations produced by\nGNNExplainer (Ying et al., 2019).\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 20:52:48 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Magister", "Lucie Charlotte", ""], ["Kazhdan", "Dmitry", ""], ["Singh", "Vikash", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2107.11892", "submitter": "Mengwu Guo", "authors": "Mengwu Guo", "title": "A brief note on understanding neural networks as Gaussian processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a generalization of the work in [Lee et al., 2017], this note briefly\ndiscusses when the prior of a neural network output follows a Gaussian process,\nand how a neural-network-induced Gaussian process is formulated. The posterior\nmean functions of such a Gaussian process regression lie in the reproducing\nkernel Hilbert space defined by the neural-network-induced kernel. In the case\nof two-layer neural networks, the induced Gaussian processes provide an\ninterpretation of the reproducing kernel Hilbert spaces whose union forms a\nBarron space.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 21:06:58 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guo", "Mengwu", ""]]}, {"id": "2107.11906", "submitter": "Zhenhai Zhu", "authors": "Zhenhai Zhu and Radu Soricut", "title": "H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for\n  Sequences", "comments": "ACL2021 long paper oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe an efficient hierarchical method to compute attention in the\nTransformer architecture. The proposed attention mechanism exploits a matrix\nstructure similar to the Hierarchical Matrix (H-Matrix) developed by the\nnumerical analysis community, and has linear run time and memory complexity. We\nperform extensive experiments to show that the inductive bias embodied by our\nhierarchical attention is effective in capturing the hierarchical structure in\nthe sequences typical for natural language and vision tasks. Our method is\nsuperior to alternative sub-quadratic proposals by over +6 points on average on\nthe Long Range Arena benchmark. It also sets a new SOTA test perplexity on\nOne-Billion Word dataset with 5x fewer model parameters than that of the\nprevious-best Transformer-based models.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 23:07:03 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhu", "Zhenhai", ""], ["Soricut", "Radu", ""]]}, {"id": "2107.11911", "submitter": "Xiangyu Zhang", "authors": "Xiangyu Zhang, Peter I. Frazier", "title": "Restless Bandits with Many Arms: Beating the Central Limit Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider finite-horizon restless bandits with multiple pulls per period,\nwhich play an important role in recommender systems, active learning, revenue\nmanagement, and many other areas. While an optimal policy can be computed, in\nprinciple, using dynamic programming, the computation required scales\nexponentially in the number of arms $N$. Thus, there is substantial value in\nunderstanding the performance of index policies and other policies that can be\ncomputed efficiently for large $N$. We study the growth of the optimality gap,\ni.e., the loss in expected performance compared to an optimal policy, for such\npolicies in a classical asymptotic regime proposed by Whittle in which $N$\ngrows while holding constant the fraction of arms that can be pulled per\nperiod. Intuition from the Central Limit Theorem and the tightest previous\ntheoretical bounds suggest that this optimality gap should grow like\n$O(\\sqrt{N})$. Surprisingly, we show that it is possible to outperform this\nbound. We characterize a non-degeneracy condition and a wide class of novel\npractically-computable policies, called fluid-priority policies, in which the\noptimality gap is $O(1)$. These include most widely-used index policies. When\nthis non-degeneracy condition does not hold, we show that fluid-priority\npolicies nevertheless have an optimality gap that is $O(\\sqrt{N})$,\nsignificantly generalizing the class of policies for which convergence rates\nare known. We demonstrate that fluid-priority policies offer state-of-the-art\nperformance on a collection of restless bandit problems in numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 23:27:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Xiangyu", ""], ["Frazier", "Peter I.", ""]]}, {"id": "2107.11913", "submitter": "Luis Lamb", "authors": "Pedro H.C. Avelar and Rafael B. Audibert and Anderson R. Tavares and\n  Lu\\'is C. Lamb", "title": "Measuring Ethics in AI with AI: A Methodology and Dataset Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the use of sound measures and metrics in Artificial Intelligence\nhas become the subject of interest of academia, government, and industry.\nEfforts towards measuring different phenomena have gained traction in the AI\ncommunity, as illustrated by the publication of several influential field\nreports and policy documents. These metrics are designed to help decision\ntakers to inform themselves about the fast-moving and impacting influences of\nkey advances in Artificial Intelligence in general and Machine Learning in\nparticular. In this paper we propose to use such newfound capabilities of AI\ntechnologies to augment our AI measuring capabilities. We do so by training a\nmodel to classify publications related to ethical issues and concerns. In our\nmethodology we use an expert, manually curated dataset as the training set and\nthen evaluate a large set of research papers. Finally, we highlight the\nimplications of AI metrics, in particular their contribution towards developing\ntrustful and fair AI-based tools and technologies. Keywords: AI Ethics; AI\nFairness; AI Measurement. Ethics in Computer Science.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 00:26:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Audibert", "Rafael B.", ""], ["Tavares", "Anderson R.", ""], ["Lamb", "Lu\u00eds C.", ""]]}, {"id": "2107.11921", "submitter": "Rujing Yao", "authors": "Rujing Yao and Mengyang Li and Ou Wu", "title": "Compensation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weighting strategy prevails in machine learning. For example, a common\napproach in robust machine learning is to exert lower weights on samples which\nare likely to be noisy or hard. This study reveals another undiscovered\nstrategy, namely, compensating, that has also been widely used in machine\nlearning. Learning with compensating is called compensation learning and a\nsystematic taxonomy is constructed for it in this study. In our taxonomy,\ncompensation learning is divided on the basis of the compensation targets,\ninference manners, and granularity levels. Many existing learning algorithms\nincluding some classical ones can be seen as a special case of compensation\nlearning or partially leveraging compensating. Furthermore, a family of new\nlearning algorithms can be obtained by plugging the compensation learning into\nexisting learning algorithms. Specifically, three concrete new learning\nalgorithms are proposed for robust machine learning. Extensive experiments on\ntext sentiment analysis, image classification, and graph classification verify\nthe effectiveness of the three new algorithms. Compensation learning can also\nbe used in various learning scenarios, such as imbalance learning, clustering,\nregression, and so on.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 01:41:25 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yao", "Rujing", ""], ["Li", "Mengyang", ""], ["Wu", "Ou", ""]]}, {"id": "2107.11949", "submitter": "Andrea Asperti", "authors": "Andrea Asperti, Davide Evangelista, Moreno Marzolla", "title": "Dissecting FLOPs along input dimensions for GreenAI cost estimations", "comments": "Article accepted at the 7th International Conference on Machine\n  Learning, Optimization, and Data Science. October 4-8, 2021, Grasmere, Lake\n  District, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term GreenAI refers to a novel approach to Deep Learning, that is more\naware of the ecological impact and the computational efficiency of its methods.\nThe promoters of GreenAI suggested the use of Floating Point Operations (FLOPs)\nas a measure of the computational cost of Neural Networks; however, that\nmeasure does not correlate well with the energy consumption of hardware\nequipped with massively parallel processing units like GPUs or TPUs. In this\narticle, we propose a simple refinement of the formula used to compute floating\npoint operations for convolutional layers, called {\\alpha}-FLOPs, explaining\nand correcting the traditional discrepancy with respect to different layers,\nand closer to reality. The notion of {\\alpha}-FLOPs relies on the crucial\ninsight that, in case of inputs with multiple dimensions, there is no reason to\nbelieve that the speedup offered by parallelism will be uniform along all\ndifferent axes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 04:08:41 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Asperti", "Andrea", ""], ["Evangelista", "Davide", ""], ["Marzolla", "Moreno", ""]]}, {"id": "2107.11954", "submitter": "Xin-Chun Li", "authors": "Xin-Chun Li, Le Gan, De-Chuan Zhan, Yunfeng Shao, Bingshuai Li,\n  Shaoming Song", "title": "Aggregate or Not? Exploring Where to Privatize in DNN Based Federated\n  Learning Under Different Non-IID Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although federated learning (FL) has recently been proposed for efficient\ndistributed training and data privacy protection, it still encounters many\nobstacles. One of these is the naturally existing statistical heterogeneity\namong clients, making local data distributions non independently and\nidentically distributed (i.e., non-iid), which poses challenges for model\naggregation and personalization. For FL with a deep neural network (DNN),\nprivatizing some layers is a simple yet effective solution for non-iid\nproblems. However, which layers should we privatize to facilitate the learning\nprocess? Do different categories of non-iid scenes have preferred privatization\nways? Can we automatically learn the most appropriate privatization way during\nFL? In this paper, we answer these questions via abundant experimental studies\non several FL benchmarks. First, we present the detailed statistics of these\nbenchmarks and categorize them into covariate and label shift non-iid scenes.\nThen, we investigate both coarse-grained and fine-grained network splits and\nexplore whether the preferred privatization ways have any potential relations\nto the specific category of a non-iid scene. Our findings are exciting, e.g.,\nprivatizing the base layers could boost the performances even in label shift\nnon-iid scenes, which are inconsistent with some natural conjectures. We also\nfind that none of these privatization ways could improve the performances on\nthe Shakespeare benchmark, and we guess that Shakespeare may not be a seriously\nnon-iid scene. Finally, we propose several approaches to automatically learn\nwhere to aggregate via cross-stitch, soft attention, and hard selection. We\nadvocate the proposed methods could serve as a preliminary try to explore where\nto privatize for a novel non-iid scene.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 04:33:29 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Xin-Chun", ""], ["Gan", "Le", ""], ["Zhan", "De-Chuan", ""], ["Shao", "Yunfeng", ""], ["Li", "Bingshuai", ""], ["Song", "Shaoming", ""]]}, {"id": "2107.11956", "submitter": "Xin-Chun Li", "authors": "Xin-Chun Li, De-Chuan Zhan, Yunfeng Shao, Bingshuai Li, Shaoming Song", "title": "Preliminary Steps Towards Federated Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically mining sentiment tendency contained in natural language is a\nfundamental research to some artificial intelligent applications, where\nsolutions alternate with challenges. Transfer learning and multi-task learning\ntechniques have been leveraged to mitigate the supervision sparsity and\ncollaborate multiple heterogeneous domains correspondingly. Recent years, the\nsensitive nature of users' private data raises another challenge for sentiment\nclassification, i.e., data privacy protection. In this paper, we resort to\nfederated learning for multiple domain sentiment classification under the\nconstraint that the corpora must be stored on decentralized devices. In view of\nthe heterogeneous semantics across multiple parties and the peculiarities of\nword embedding, we pertinently provide corresponding solutions. First, we\npropose a Knowledge Transfer Enhanced Private-Shared (KTEPS) framework for\nbetter model aggregation and personalization in federated sentiment\nclassification. Second, we propose KTEPS$^\\star$ with the consideration of the\nrich semantic and huge embedding size properties of word vectors, utilizing\nProjection-based Dimension Reduction (PDR) methods for privacy protection and\nefficient transmission simultaneously. We propose two federated sentiment\nclassification scenes based on public benchmarks, and verify the superiorities\nof our proposed methods with abundant experimental investigations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 04:57:49 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Xin-Chun", ""], ["Zhan", "De-Chuan", ""], ["Shao", "Yunfeng", ""], ["Li", "Bingshuai", ""], ["Song", "Shaoming", ""]]}, {"id": "2107.11972", "submitter": "Liang Zeng", "authors": "Liang Zeng, Lei Wang, Hui Niu, Jian Li, Ruchen Zhang, Zhonghao Dai,\n  Dewei Zhu, Ling Wang", "title": "Trade When Opportunity Comes: Price Movement Forecasting via\n  Locality-Aware Attention and Adaptive Refined Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Price movement forecasting aims at predicting the future trends of financial\nassets based on the current market conditions and other relevant information.\nRecently, machine learning(ML) methods have become increasingly popular and\nachieved promising results for price movement forecasting in both academia and\nindustry. Most existing ML solutions formulate the forecasting problem as a\nclassification(to predict the direction) or a regression(to predict the return)\nproblem in the entire set of training data. However, due to the extremely low\nsignal-to-noise ratio and stochastic nature of financial data, good trading\nopportunities are extremely scarce. As a result, without careful selection of\npotentially profitable samples, such ML methods are prone to capture the\npatterns of noises instead of real signals. To address the above issues, we\npropose a novel framework-LARA(Locality-Aware Attention and Adaptive Refined\nLabeling), which contains the following three components: 1)Locality-aware\nattention automatically extracts the potentially profitable samples by\nattending to their label information in order to construct a more accurate\nclassifier on these selected samples. 2)Adaptive refined labeling further\niteratively refines the labels, alleviating the noise of samples. 3)Equipped\nwith metric learning techniques, Locality-aware attention enjoys task-specific\ndistance metrics and distributes attention on potentially profitable samples in\na more effective way. To validate our method, we conduct comprehensive\nexperiments on three real-world financial markets: ETFs, the China's A-share\nstock market, and the cryptocurrency market. LARA achieves superior performance\ncompared with the time-series analysis methods and a set of machine learning\nbased competitors on the Qlib platform. Extensive ablation studies and\nexperiments demonstrate that LARA indeed captures more reliable trading\nopportunities.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 05:52:42 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zeng", "Liang", ""], ["Wang", "Lei", ""], ["Niu", "Hui", ""], ["Li", "Jian", ""], ["Zhang", "Ruchen", ""], ["Dai", "Zhonghao", ""], ["Zhu", "Dewei", ""], ["Wang", "Ling", ""]]}, {"id": "2107.11999", "submitter": "Yuya Ohmichi", "authors": "Yuya Ohmichi, Yosuke Sugioka, Kazuyuki Nakakita", "title": "Stable Dynamic Mode Decomposition Algorithm for Noisy Pressure-Sensitive\n  Paint Measurement Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS physics.flu-dyn", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, we proposed the truncated total least squares dynamic mode\ndecomposition (T-TLS DMD) algorithm, which can perform DMD analysis of noisy\ndata. By adding truncation regularization to the conventional TLS DMD\nalgorithm, T-TLS DMD improves the stability of the computation while\nmaintaining the accuracy of TLS DMD. The effectiveness of the proposed method\nwas evaluated by the analysis of the wake behind a cylinder and\npressure-sensitive paint (PSP) data for the buffet cell phenomenon. The results\nshowed the importance of regularization in the DMD algorithm. With respect to\nthe eigenvalues, T-TLS DMD was less affected by noise, and accurate eigenvalues\ncould be obtained stably, whereas the eigenvalues of TLS and subspace DMD\nvaried greatly due to noise. It was also observed that the eigenvalues of the\nstandard and exact DMD had the problem of shifting to the damping side, as\nreported in previous studies. With respect to eigenvectors, T-TLS and exact DMD\ncaptured the characteristic flow patterns clearly even in the presence of\nnoise, whereas TLS and subspace DMD were not able to capture them clearly due\nto noise.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 07:18:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Ohmichi", "Yuya", ""], ["Sugioka", "Yosuke", ""], ["Nakakita", "Kazuyuki", ""]]}, {"id": "2107.12003", "submitter": "Seyun Um", "authors": "Se-Yun Um, Jihyun Kim, Jihyun Lee, Sangshin Oh, Kyungguen Byun, and\n  Hong-Goo Kang", "title": "Facetron: Multi-speaker Face-to-Speech Model based on Cross-modal Latent\n  Representations", "comments": "10 pages (including references), 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an effective method to synthesize speaker-specific\nspeech waveforms by conditioning on videos of an individual's face. Using a\ngenerative adversarial network (GAN) with linguistic and speaker characteristic\nfeatures as auxiliary conditions, our method directly converts face images into\nspeech waveforms under an end-to-end training framework. The linguistic\nfeatures are extracted from lip movements using a lip-reading model, and the\nspeaker characteristic features are predicted from face images using\ncross-modal learning with a pre-trained acoustic model. Since these two\nfeatures are uncorrelated and controlled independently, we can flexibly\nsynthesize speech waveforms whose speaker characteristics vary depending on the\ninput face images. Therefore, our method can be regarded as a multi-speaker\nface-to-speech waveform model. We show the superiority of our proposed model\nover conventional methods in terms of both objective and subjective evaluation\nresults. Specifically, we evaluate the performances of the linguistic feature\nand the speaker characteristic generation modules by measuring the accuracy of\nautomatic speech recognition and automatic speaker/gender recognition tasks,\nrespectively. We also evaluate the naturalness of the synthesized speech\nwaveforms using a mean opinion score (MOS) test.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 07:36:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Um", "Se-Yun", ""], ["Kim", "Jihyun", ""], ["Lee", "Jihyun", ""], ["Oh", "Sangshin", ""], ["Byun", "Kyungguen", ""], ["Kang", "Hong-Goo", ""]]}, {"id": "2107.12009", "submitter": "Noa Cahan", "authors": "Noa Cahan, Edith M. Marom, Shelly Soffer, Yiftach Barash, Eli Konen,\n  Eyal Klang and Hayit Greenspan", "title": "Weakly Supervised Attention Model for RV StrainClassification from\n  volumetric CTPA Scans", "comments": "12 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pulmonary embolus (PE) refers to obstruction of pulmonary arteries by blood\nclots. PE accounts for approximately 100,000 deaths per year in the United\nStates alone. The clinical presentation of PE is often nonspecific, making the\ndiagnosis challenging. Thus, rapid and accurate risk stratification is of\nparamount importance. High-risk PE is caused by right ventricular (RV)\ndysfunction from acute pressure overload, which in return can help identify\nwhich patients require more aggressive therapy. Reconstructed four-chamber\nviews of the heart on chest CT can detect right ventricular enlargement. CT\npulmonary angiography (CTPA) is the golden standard in the diagnostic workup of\nsuspected PE. Therefore, it can link between diagnosis and risk stratification\nstrategies. We developed a weakly supervised deep learning algorithm, with an\nemphasis on a novel attention mechanism, to automatically classify RV strain on\nCTPA. Our method is a 3D DenseNet model with integrated 3D residual attention\nblocks. We evaluated our model on a dataset of CTPAs of emergency department\n(ED) PE patients. This model achieved an area under the receiver operating\ncharacteristic curve (AUC) of 0.88 for classifying RV strain. The model showed\na sensitivity of 87% and specificity of 83.7%. Our solution outperforms\nstate-of-the-art 3D CNN networks. The proposed design allows for a fully\nautomated network that can be trained easily in an end-to-end manner without\nrequiring computationally intensive and time-consuming preprocessing or\nstrenuous labeling of the data.We infer that unmarked CTPAs can be used for\neffective RV strain classification. This could be used as a second reader,\nalerting for high-risk PE patients. To the best of our knowledge, there are no\nprevious deep learning-based studies that attempted to solve this problem.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 07:57:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Cahan", "Noa", ""], ["Marom", "Edith M.", ""], ["Soffer", "Shelly", ""], ["Barash", "Yiftach", ""], ["Konen", "Eli", ""], ["Klang", "Eyal", ""], ["Greenspan", "Hayit", ""]]}, {"id": "2107.12013", "submitter": "Te-Sheng Lin", "authors": "Ming-Chih Lai, Che-Chia Chang, Wei-Syuan Lin, Wei-Fan Hu, Te-Sheng Lin", "title": "A Shallow Ritz Method for elliptic problems with Singular Sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a shallow Ritz-type neural network for solving elliptic\nproblems with delta function singular sources on an interface is developed.\nThere are three novel features in the present work; namely, (i) the delta\nfunction singularity is naturally removed, (ii) level set function is\nintroduced as a feather input, (iii) it is completely shallow consisting of\nonly one hidden layer. We first introduce the energy functional of the problem\nand then transform the contribution of singular sources to a regular surface\nintegral along the interface. In such a way the delta function singularity can\nbe naturally removed without the introduction of discrete delta function that\nis commonly used in traditional regularization methods such as the well-known\nimmersed boundary method. The original problem is then reformulated as a\nminimization problem. We propose a shallow Ritz-type neural network with one\nhidden layer to approximate the global minimizer of the energy functional. As a\nresult, the network is trained by minimizing the loss function that is a\ndiscrete version of the energy. In addition, we include the level set function\nof the interface as a feature input and find that it significantly improves the\ntraining efficiency and accuracy. We perform a series of numerical tests to\ndemonstrate the accuracy of the present network as well as its capability for\nproblems in irregular domains and in higher dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:07:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lai", "Ming-Chih", ""], ["Chang", "Che-Chia", ""], ["Lin", "Wei-Syuan", ""], ["Hu", "Wei-Fan", ""], ["Lin", "Te-Sheng", ""]]}, {"id": "2107.12033", "submitter": "Daniel Aleksander Krause Mr.", "authors": "Daniel Aleksander Krause, Archontis Politis, Annamaria Mesaros", "title": "Joint Direction and Proximity Classification of Overlapping Sound Events\n  from Binaural Audio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound source proximity and distance estimation are of great interest in many\npractical applications, since they provide significant information for acoustic\nscene analysis. As both tasks share complementary qualities, ensuring efficient\ninteraction between these two is crucial for a complete picture of an aural\nenvironment. In this paper, we aim to investigate several ways of performing\njoint proximity and direction estimation from binaural recordings, both defined\nas coarse classification problems based on Deep Neural Networks (DNNs).\nConsidering the limitations of binaural audio, we propose two methods of\nsplitting the sphere into angular areas in order to obtain a set of directional\nclasses. For each method we study different model types to acquire information\nabout the direction-of-arrival (DoA). Finally, we propose various ways of\ncombining the proximity and direction estimation problems into a joint task\nproviding temporal information about the onsets and offsets of the appearing\nsources. Experiments are performed for a synthetic reverberant binaural dataset\nconsisting of up to two overlapping sound events.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:48:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Krause", "Daniel Aleksander", ""], ["Politis", "Archontis", ""], ["Mesaros", "Annamaria", ""]]}, {"id": "2107.12034", "submitter": "Dirk Alexander Molitor", "authors": "Dirk Alexander Molitor and Christian Kubik and Ruben Helmut Hetfleisch\n  and Peter Groche", "title": "Workpiece Image-based Tool Wear Classification in Blanking Processes\n  Using Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blanking processes belong to the most widely used manufacturing techniques\ndue to their economic efficiency. Their economic viability depends to a large\nextent on the resulting product quality and the associated customer\nsatisfaction as well as on possible downtimes. In particular, the occurrence of\nincreased tool wear reduces the product quality and leads to downtimes, which\nis why considerable research has been carried out in recent years with regard\nto wear detection. While processes have widely been monitored based on force\nand acceleration signals, a new approach is pursued in this paper. Blanked\nworkpieces manufactured by punches with 16 different wear states are\nphotographed and then used as inputs for Deep Convolutional Neural Networks to\nclassify wear states. The results show that wear states can be predicted with\nsurprisingly high accuracy, opening up new possibilities and research\nopportunities for tool wear monitoring of blanking processes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:49:08 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Molitor", "Dirk Alexander", ""], ["Kubik", "Christian", ""], ["Hetfleisch", "Ruben Helmut", ""], ["Groche", "Peter", ""]]}, {"id": "2107.12045", "submitter": "Florian Tambon", "authors": "Florian Tambon, Gabriel Laberge, Le An, Amin Nikanjam, Paulina Stevia\n  Nouwou Mindom, Yann Pequignot, Foutse Khomh, Giulio Antoniol, Ettore Merlo\n  and Fran\\c{c}ois Laviolette", "title": "How to Certify Machine Learning Based Safety-critical Systems? A\n  Systematic Literature Review", "comments": "69 pages (89 pages with ref.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Machine Learning (ML) has been at the heart of many innovations over\nthe past years. However, including it in so-called 'safety-critical' systems\nsuch as automotive or aeronautic has proven to be very challenging, since the\nshift in paradigm that ML brings completely changes traditional certification\napproaches.\n  Objective: This paper aims to elucidate challenges related to the\ncertification of ML-based safety-critical systems, as well as the solutions\nthat are proposed in the literature to tackle them, answering the question 'How\nto Certify Machine Learning Based Safety-critical Systems?'.\n  Method: We conduct a Systematic Literature Review (SLR) of research papers\npublished between 2015 to 2020, covering topics related to the certification of\nML systems. In total, we identified 229 papers covering topics considered to be\nthe main pillars of ML certification: Robustness, Uncertainty, Explainability,\nVerification, Safe Reinforcement Learning, and Direct Certification. We\nanalyzed the main trends and problems of each sub-field and provided summaries\nof the papers extracted.\n  Results: The SLR results highlighted the enthusiasm of the community for this\nsubject, as well as the lack of diversity in terms of datasets and type of\nmodels. It also emphasized the need to further develop connections between\nacademia and industries to deepen the domain study. Finally, it also\nillustrated the necessity to build connections between the above mention main\npillars that are for now mainly studied separately.\n  Conclusion: We highlighted current efforts deployed to enable the\ncertification of ML based software systems, and discuss some future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:03:22 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tambon", "Florian", ""], ["Laberge", "Gabriel", ""], ["An", "Le", ""], ["Nikanjam", "Amin", ""], ["Mindom", "Paulina Stevia Nouwou", ""], ["Pequignot", "Yann", ""], ["Khomh", "Foutse", ""], ["Antoniol", "Giulio", ""], ["Merlo", "Ettore", ""], ["Laviolette", "Fran\u00e7ois", ""]]}, {"id": "2107.12046", "submitter": "Guang Yang", "authors": "Xi Guan, Guang Yang, Jianming Ye, Weiji Yang, Xiaomei Xu, Weiwei\n  Jiang, Xiaobo Lai", "title": "3D AGSE-VNet: An Automatic Brain Tumor MRI Data Segmentation Framework", "comments": "34 pages, 12 figure, Accepted by BMC Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Background: Glioma is the most common brain malignant tumor, with a high\nmorbidity rate and a mortality rate of more than three percent, which seriously\nendangers human health. The main method of acquiring brain tumors in the clinic\nis MRI. Segmentation of brain tumor regions from multi-modal MRI scan images is\nhelpful for treatment inspection, post-diagnosis monitoring, and effect\nevaluation of patients. However, the common operation in clinical brain tumor\nsegmentation is still manual segmentation, lead to its time-consuming and large\nperformance difference between different operators, a consistent and accurate\nautomatic segmentation method is urgently needed. Methods: To meet the above\nchallenges, we propose an automatic brain tumor MRI data segmentation framework\nwhich is called AGSE-VNet. In our study, the Squeeze and Excite (SE) module is\nadded to each encoder, the Attention Guide Filter (AG) module is added to each\ndecoder, using the channel relationship to automatically enhance the useful\ninformation in the channel to suppress the useless information, and use the\nattention mechanism to guide the edge information and remove the influence of\nirrelevant information such as noise. Results: We used the BraTS2020 challenge\nonline verification tool to evaluate our approach. The focus of verification is\nthat the Dice scores of the whole tumor (WT), tumor core (TC) and enhanced\ntumor (ET) are 0.68, 0.85 and 0.70, respectively. Conclusion: Although MRI\nimages have different intensities, AGSE-VNet is not affected by the size of the\ntumor, and can more accurately extract the features of the three regions, it\nhas achieved impressive results and made outstanding contributions to the\nclinical diagnosis and treatment of brain tumor patients.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:04:59 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guan", "Xi", ""], ["Yang", "Guang", ""], ["Ye", "Jianming", ""], ["Yang", "Weiji", ""], ["Xu", "Xiaomei", ""], ["Jiang", "Weiwei", ""], ["Lai", "Xiaobo", ""]]}, {"id": "2107.12048", "submitter": "Wei Liu", "authors": "Wei Liu, Li Chen, and Wenyi Zhang", "title": "Decentralized Federated Learning: Balancing Communication and Computing\n  Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized federated learning (DFL) is a powerful framework of distributed\nmachine learning and decentralized stochastic gradient descent (SGD) is a\ndriving engine for DFL. The performance of decentralized SGD is jointly\ninfluenced by communication-efficiency and convergence rate. In this paper, we\npropose a general decentralized federated learning framework to strike a\nbalance between communication-efficiency and convergence performance. The\nproposed framework performs both multiple local updates and multiple inter-node\ncommunications periodically, unifying traditional decentralized SGD methods. We\nestablish strong convergence guarantees for the proposed DFL algorithm without\nthe assumption of convex objective function. The balance of communication and\ncomputation rounds is essential to optimize decentralized federated learning\nunder constrained communication and computation resources. For further\nimproving communication-efficiency of DFL, compressed communication is applied\nto DFL, named DFL with compressed communication (C-DFL). The proposed C-DFL\nexhibits linear convergence for strongly convex objectives. Experiment results\nbased on MNIST and CIFAR-10 datasets illustrate the superiority of DFL over\ntraditional decentralized SGD methods and show that C-DFL further enhances\ncommunication-efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:09:45 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liu", "Wei", ""], ["Chen", "Li", ""], ["Zhang", "Wenyi", ""]]}, {"id": "2107.12065", "submitter": "Zhuoqing Song", "authors": "Zhuoqing Song, Lei Shi, Shi Pu, Ming Yan", "title": "Provably Accelerated Decentralized Gradient Method Over Unbalanced\n  Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.SY eess.SP eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the decentralized optimization problem in which a\nnetwork of $n$ agents, each possessing a smooth and convex objective function,\nwish to collaboratively minimize the average of all the objective functions\nthrough peer-to-peer communication in a directed graph. To solve the problem,\nwe propose two accelerated Push-DIGing methods termed APD and APD-SC for\nminimizing non-strongly convex objective functions and strongly convex ones,\nrespectively. We show that APD and APD-SC respectively converge at the rates\n$O\\left(\\frac{1}{k^2}\\right)$ and $O\\left(\\left(1 -\nC\\sqrt{\\frac{\\mu}{L}}\\right)^k\\right)$ up to constant factors depending only on\nthe mixing matrix. To the best of our knowledge, APD and APD-SC are the first\ndecentralized methods to achieve provable acceleration over unbalanced directed\ngraphs. Numerical experiments demonstrate the effectiveness of both methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:42:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Song", "Zhuoqing", ""], ["Shi", "Lei", ""], ["Pu", "Shi", ""], ["Yan", "Ming", ""]]}, {"id": "2107.12070", "submitter": "Aylin Ta\\c{s}tan", "authors": "Aylin Tastan, Michael Muma and Abdelhak M. Zoubir", "title": "Robust Regularized Locality Preserving Indexing for Fiedler Vector\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fiedler vector of a connected graph is the eigenvector associated with\nthe algebraic connectivity of the graph Laplacian and it provides substantial\ninformation to learn the latent structure of a graph. In real-world\napplications, however, the data may be subject to heavy-tailed noise and\noutliers which results in deteriorations in the structure of the Fiedler vector\nestimate. We design a Robust Regularized Locality Preserving Indexing (RRLPI)\nmethod for Fiedler vector estimation that aims to approximate the nonlinear\nmanifold structure of the Laplace Beltrami operator while minimizing the\nnegative impact of outliers. First, an analysis of the effects of two\nfundamental outlier types on the eigen-decomposition for block affinity\nmatrices which are essential in cluster analysis is conducted. Then, an error\nmodel is formulated and a robust Fiedler vector estimation algorithm is\ndeveloped. An unsupervised penalty parameter selection algorithm is proposed\nthat leverages the geometric structure of the projection space to perform\nrobust regularized Fiedler estimation. The performance of RRLPI is benchmarked\nagainst existing competitors in terms of detection probability, partitioning\nquality, image segmentation capability, robustness and computation time using a\nlarge variety of synthetic and real data experiments.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:49:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tastan", "Aylin", ""], ["Muma", "Michael", ""], ["Zoubir", "Abdelhak M.", ""]]}, {"id": "2107.12078", "submitter": "Sergei Grudinin", "authors": "Dmitrii Zhemchuzhnikov (DAO), Ilia Igashov (DAO), Sergei Grudinin\n  (DAO)", "title": "6DCNN with roto-translational convolution filters for volumetric data\n  processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce 6D Convolutional Neural Network (6DCNN) designed\nto tackle the problem of detecting relative positions and orientations of local\npatterns when processing three-dimensional volumetric data. 6DCNN also includes\nSE(3)-equivariant message-passing and nonlinear activation operations\nconstructed in the Fourier space. Working in the Fourier space allows\nsignificantly reducing the computational complexity of our operations. We\ndemonstrate the properties of the 6D convolution and its efficiency in the\nrecognition of spatial patterns. We also assess the 6DCNN model on several\ndatasets from the recent CASP protein structure prediction challenges. Here,\n6DCNN improves over the baseline architecture and also outperforms the state of\nthe art.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:56:55 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhemchuzhnikov", "Dmitrii", "", "DAO"], ["Igashov", "Ilia", "", "DAO"], ["Grudinin", "Sergei", "", "DAO"]]}, {"id": "2107.12079", "submitter": "Andrea Galassi", "authors": "Bettina Fazzinga, Andrea Galassi, Paolo Torroni", "title": "An Argumentative Dialogue System for COVID-19 Vaccine Information", "comments": "20 pages, 2 figures, currently under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dialogue systems are widely used in AI to support timely and interactive\ncommunication with users. We propose a general-purpose dialogue system\narchitecture that leverages computational argumentation and state-of-the-art\nlanguage technologies. We illustrate and evaluate the system using a COVID-19\nvaccine information case study.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:58:39 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fazzinga", "Bettina", ""], ["Galassi", "Andrea", ""], ["Torroni", "Paolo", ""]]}, {"id": "2107.12100", "submitter": "Christoph Gote", "authors": "Christoph Gote and Vincenzo Perri and Ingo Scholtes", "title": "Predicting Influential Higher-Order Patterns in Temporal Network Data", "comments": "28 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT cs.LG math.IT physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are frequently used to model complex systems comprised of\ninteracting elements. While links capture the topology of direct interactions,\nthe true complexity of many systems originates from higher-order patterns in\npaths by which nodes can indirectly influence each other. Path data,\nrepresenting ordered sequences of consecutive direct interactions, can be used\nto model these patterns. However, to avoid overfitting, such models should only\nconsider those higher-order patterns for which the data provide sufficient\nstatistical evidence. On the other hand, we hypothesise that network models,\nwhich capture only direct interactions, underfit higher-order patterns present\nin data. Consequently, both approaches are likely to misidentify influential\nnodes in complex networks. We contribute to this issue by proposing eight\ncentrality measures based on MOGen, a multi-order generative model that\naccounts for all paths up to a maximum distance but disregards paths at higher\ndistances. We compare MOGen-based centralities to equivalent measures for\nnetwork models and path data in a prediction experiment where we aim to\nidentify influential nodes in out-of-sample data. Our results show strong\nevidence supporting our hypothesis. MOGen consistently outperforms both the\nnetwork model and path-based prediction. We further show that the performance\ndifference between MOGen and the path-based approach disappears if we have\nsufficient observations, confirming that the error is due to overfitting.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 10:44:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Gote", "Christoph", ""], ["Perri", "Vincenzo", ""], ["Scholtes", "Ingo", ""]]}, {"id": "2107.12102", "submitter": "Estelle Massart", "authors": "Coralia Cartis, Estelle Massart, Adilet Otemissov", "title": "Global optimization using random embeddings", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a random-subspace algorithmic framework for global optimization of\nLipschitz-continuous objectives, and analyse its convergence using novel tools\nfrom conic integral geometry. X-REGO randomly projects, in a sequential or\nsimultaneous manner, the high-dimensional original problem into low-dimensional\nsubproblems that can then be solved with any global, or even local,\noptimization solver. We estimate the probability that the randomly-embedded\nsubproblem shares (approximately) the same global optimum as the original\nproblem. This success probability is then used to show convergence of X-REGO to\nan approximate global solution of the original problem, under weak assumptions\non the problem (having a strictly feasible global solution) and on the solver\n(guaranteed to find an approximate global solution of the reduced problem with\nsufficiently high probability). In the particular case of unconstrained\nobjectives with low effective dimension, that only vary over a low-dimensional\nsubspace, we propose an X-REGO variant that explores random subspaces of\nincreasing dimension until finding the effective dimension of the problem,\nleading to X-REGO globally converging after a finite number of embeddings,\nproportional to the effective dimension. We show numerically that this variant\nefficiently finds both the effective dimension and an approximate global\nminimizer of the original problem.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 10:45:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Cartis", "Coralia", ""], ["Massart", "Estelle", ""], ["Otemissov", "Adilet", ""]]}, {"id": "2107.12110", "submitter": "Mirco H\\\"unnefeld", "authors": "Mirco H\\\"unnefeld (for the IceCube Collaboration)", "title": "Combining Maximum-Likelihood with Deep Learning for Event Reconstruction\n  in IceCube", "comments": "Presented at the 37th International Cosmic Ray Conference (ICRC\n  2021). See arXiv:2107.06966 for all IceCube contributions", "journal-ref": null, "doi": "10.22323/1.395.1065", "report-no": "PoS-ICRC2021-1065", "categories": "astro-ph.HE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of deep learning has become increasingly important for particle\nphysics experiments, yielding a multitude of advances, predominantly in event\nclassification and reconstruction tasks. Many of these applications have been\nadopted from other domains. However, data in the field of physics are unique in\nthe context of machine learning, insofar as their generation process and the\nlaws and symmetries they abide by are usually well understood. Most commonly\nused deep learning architectures fail at utilizing this available information.\nIn contrast, more traditional likelihood-based methods are capable of\nexploiting domain knowledge, but they are often limited by computational\ncomplexity. In this contribution, a hybrid approach is presented that utilizes\ngenerative neural networks to approximate the likelihood, which may then be\nused in a traditional maximum-likelihood setting. Domain knowledge, such as\ninvariances and detector characteristics, can easily be incorporated in this\napproach. The hybrid approach is illustrated by the example of event\nreconstruction in IceCube.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 11:05:40 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["H\u00fcnnefeld", "Mirco", "", "for the IceCube Collaboration"]]}, {"id": "2107.12137", "submitter": "Abhinav Sagar", "authors": "Abhinav Sagar", "title": "AA3DNet: Attention Augmented Real Time 3D Object Detection", "comments": "12 pages, 8 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we address the problem of 3D object detection from point cloud\ndata in real time. For autonomous vehicles to work, it is very important for\nthe perception component to detect the real world objects with both high\naccuracy and fast inference. We propose a novel neural network architecture\nalong with the training and optimization details for detecting 3D objects using\npoint cloud data. We present anchor design along with custom loss functions\nused in this work. A combination of spatial and channel wise attention module\nis used in this work. We use the Kitti 3D Birds Eye View dataset for\nbenchmarking and validating our results. Our method surpasses previous state of\nthe art in this domain both in terms of average precision and speed running at\n> 30 FPS. Finally, we present the ablation study to demonstrate that the\nperformance of our network is generalizable. This makes it a feasible option to\nbe deployed in real time applications like self driving cars.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:18:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Sagar", "Abhinav", ""]]}, {"id": "2107.12156", "submitter": "Akshansh Mishra", "authors": "Akshansh Mishra and Devarrishi Dixit", "title": "Brain Inspired Computing Approach for the Optimization of the Thin Film\n  Thickness of Polystyrene on the Glass Substrates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Advent in machine learning is leaving a deep impact on various sectors\nincluding the material science domain. The present paper highlights the\napplication of various supervised machine learning regression algorithms such\nas polynomial regression, decision tree regression algorithm, random forest\nalgorithm, support vector regression algorithm, and artificial neural network\nalgorithm to determine the thin film thickness of Polystyrene on the glass\nsubstrates. The results showed that the polynomial regression machine learning\nalgorithm outperforms all other machine learning models by yielding the\ncoefficient of determination of 0.96 approximately and mean square error of\n0.04 respectively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:13:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Mishra", "Akshansh", ""], ["Dixit", "Devarrishi", ""]]}, {"id": "2107.12167", "submitter": "Abdul Rafey Aftab", "authors": "Abdul Rafey Aftab, Michael von der Beeck, Steven Rohrhirsch, Benoit\n  Diotte, Michael Feld", "title": "Multimodal Fusion Using Deep Learning Applied to Driver's Referencing of\n  Outside-Vehicle Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is a growing interest in more intelligent natural user interaction with\nthe car. Hand gestures and speech are already being applied for driver-car\ninteraction. Moreover, multimodal approaches are also showing promise in the\nautomotive industry. In this paper, we utilize deep learning for a multimodal\nfusion network for referencing objects outside the vehicle. We use features\nfrom gaze, head pose and finger pointing simultaneously to precisely predict\nthe referenced objects in different car poses. We demonstrate the practical\nlimitations of each modality when used for a natural form of referencing,\nspecifically inside the car. As evident from our results, we overcome the\nmodality specific limitations, to a large extent, by the addition of other\nmodalities. This work highlights the importance of multimodal sensing,\nespecially when moving towards natural user interaction. Furthermore, our user\nbased analysis shows noteworthy differences in recognition of user behavior\ndepending upon the vehicle pose.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:37:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Aftab", "Abdul Rafey", ""], ["von der Beeck", "Michael", ""], ["Rohrhirsch", "Steven", ""], ["Diotte", "Benoit", ""], ["Feld", "Michael", ""]]}, {"id": "2107.12173", "submitter": "Yi Shi", "authors": "Yi Shi and Yalin E. Sagduyu", "title": "Membership Inference Attack and Defense for Wireless Signal Classifiers\n  with Deep Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:2006.14576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An over-the-air membership inference attack (MIA) is presented to leak\nprivate information from a wireless signal classifier. Machine learning (ML)\nprovides powerful means to classify wireless signals, e.g., for PHY-layer\nauthentication. As an adversarial machine learning attack, the MIA infers\nwhether a signal of interest has been used in the training data of a target\nclassifier. This private information incorporates waveform, channel, and device\ncharacteristics, and if leaked, can be exploited by an adversary to identify\nvulnerabilities of the underlying ML model (e.g., to infiltrate the PHY-layer\nauthentication). One challenge for the over-the-air MIA is that the received\nsignals and consequently the RF fingerprints at the adversary and the intended\nreceiver differ due to the discrepancy in channel conditions. Therefore, the\nadversary first builds a surrogate classifier by observing the spectrum and\nthen launches the black-box MIA on this classifier. The MIA results show that\nthe adversary can reliably infer signals (and potentially the radio and channel\ninformation) used to build the target classifier. Therefore, a proactive\ndefense is developed against the MIA by building a shadow MIA model and fooling\nthe adversary. This defense can successfully reduce the MIA accuracy and\nprevent information leakage from the wireless signal classifier.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 17:05:47 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shi", "Yi", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "2107.12183", "submitter": "Jicong Fan", "authors": "Jicong Fan, Yiheng Tu, Zhao Zhang, Mingbo Zhao", "title": "EGGS: Eigen-Gap Guided Search Making Subspace Clustering Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of spectral clustering heavily relies on the quality of\naffinity matrix. A variety of affinity-matrix-construction methods have been\nproposed but they have hyper-parameters to determine beforehand, which requires\nstrong experience and lead to difficulty in real applications especially when\nthe inter-cluster similarity is high or/and the dataset is large. On the other\nhand, we often have to determine to use a linear model or a nonlinear model,\nwhich still depends on experience. To solve these two problems, in this paper,\nwe present an eigen-gap guided search method for subspace clustering. The main\nidea is to find the most reliable affinity matrix among a set of candidates\nconstructed by linear and kernel regressions, where the reliability is\nquantified by the \\textit{relative-eigen-gap} of graph Laplacian defined in\nthis paper. We show, theoretically and numerically, that the Laplacian matrix\nwith a larger relative-eigen-gap often yields a higher clustering accuracy and\nstability. Our method is able to automatically search the best model and\nhyper-parameters in a pre-defined space. The search space is very easy to\ndetermine and can be arbitrarily large, though a relatively compact search\nspace can reduce the highly unnecessary computation. Our method has high\nflexibility and convenience in real applications, and also has low\ncomputational cost because the affinity matrix is not computed by iterative\noptimization. We extend the method to large-scale datasets such as MNIST, on\nwhich the time cost is less than 90s and the clustering accuracy is\nstate-of-the-art. Extensive experiments of natural image clustering show that\nour method is more stable, accurate, and efficient than baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 08:53:36 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 01:38:14 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Fan", "Jicong", ""], ["Tu", "Yiheng", ""], ["Zhang", "Zhao", ""], ["Zhao", "Mingbo", ""]]}, {"id": "2107.12202", "submitter": "Zhenyu Wu", "authors": "Zhenyu Wu, Zhaowen Wang, Ye Yuan, Jianming Zhang, Zhangyang Wang,\n  Hailin Jin", "title": "Black-Box Diagnosis and Calibration on GAN Intra-Mode Collapse: A Pilot\n  Study", "comments": "This paper has been accepted by Transactions on Multimedia Computing\n  Communications and Applications (TOMM) for publication in 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) nowadays are capable of producing\nimages of incredible realism. One concern raised is whether the\nstate-of-the-art GAN's learned distribution still suffers from mode collapse,\nand what to do if so. Existing diversity tests of samples from GANs are usually\nconducted qualitatively on a small scale, and/or depends on the access to\noriginal training data as well as the trained model parameters. This paper\nexplores to diagnose GAN intra-mode collapse and calibrate that, in a novel\nblack-box setting: no access to training data, nor the trained model\nparameters, is assumed. The new setting is practically demanded, yet rarely\nexplored and significantly more challenging. As a first stab, we devise a set\nof statistical tools based on sampling, that can visualize, quantify, and\nrectify intra-mode collapse. We demonstrate the effectiveness of our proposed\ndiagnosis and calibration techniques, via extensive simulations and\nexperiments, on unconditional GAN image generation (e.g., face and vehicle).\nOur study reveals that the intra-mode collapse is still a prevailing problem in\nstate-of-the-art GANs and the mode collapse is diagnosable and calibratable in\nblack-box settings. Our codes are available at:\nhttps://github.com/VITA-Group/BlackBoxGANCollapse.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 06:03:55 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wu", "Zhenyu", ""], ["Wang", "Zhaowen", ""], ["Yuan", "Ye", ""], ["Zhang", "Jianming", ""], ["Wang", "Zhangyang", ""], ["Jin", "Hailin", ""]]}, {"id": "2107.12211", "submitter": "Yann Fraboni", "authors": "Yann Fraboni, Richard Vidal, Laetitia Kameni, Marco Lorenzi", "title": "On The Impact of Client Sampling on Federated Learning Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While clients' sampling is a central operation of current state-of-the-art\nfederated learning (FL) approaches, the impact of this procedure on the\nconvergence and speed of FL remains to date under-investigated. In this work we\nintroduce a novel decomposition theorem for the convergence of FL, allowing to\nclearly quantify the impact of client sampling on the global model update.\nContrarily to previous convergence analyses, our theorem provides the exact\ndecomposition of a given convergence step, thus enabling accurate\nconsiderations about the role of client sampling and heterogeneity. First, we\nprovide a theoretical ground for previously reported results on the\nrelationship between FL convergence and the variance of the aggregation\nweights. Second, we prove for the first time that the quality of FL convergence\nis also impacted by the resulting covariance between aggregation weights.\nThird, we establish that the sum of the aggregation weights is another source\nof slow-down and should be equal to 1 to improve FL convergence speed. Our\ntheory is general, and is here applied to Multinomial Distribution (MD) and\nUniform sampling, the two default client sampling in FL, and demonstrated\nthrough a series of experiments in non-iid and unbalanced scenarios. Our\nresults suggest that MD sampling should be used as default sampling scheme, due\nto the resilience to the changes in data ratio during the learning process,\nwhile Uniform sampling is superior only in the special case when clients have\nthe same amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 13:36:06 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fraboni", "Yann", ""], ["Vidal", "Richard", ""], ["Kameni", "Laetitia", ""], ["Lorenzi", "Marco", ""]]}, {"id": "2107.12216", "submitter": "Jiaming Guo", "authors": "Jiaming Guo, Rui Zhang, Xishan Zhang, Shaohui Peng, Qi Yi, Zidong Du,\n  Xing Hu, Qi Guo, Yunji Chen", "title": "Hindsight Value Function for Variance Reduction in Stochastic Dynamic\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are appealing in deep reinforcement learning but\nsuffer from high variance of gradient estimate. To reduce the variance, the\nstate value function is applied commonly. However, the effect of the state\nvalue function becomes limited in stochastic dynamic environments, where the\nunexpected state dynamics and rewards will increase the variance. In this\npaper, we propose to replace the state value function with a novel hindsight\nvalue function, which leverages the information from the future to reduce the\nvariance of the gradient estimate for stochastic dynamic environments.\n  Particularly, to obtain an ideally unbiased gradient estimate, we propose an\ninformation-theoretic approach, which optimizes the embeddings of the future to\nbe independent of previous actions. In our experiments, we apply the proposed\nhindsight value function in stochastic dynamic environments, including\ndiscrete-action environments and continuous-action environments. Compared with\nthe standard state value function, the proposed hindsight value function\nconsistently reduces the variance, stabilizes the training, and improves the\neventual policy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 13:48:23 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Guo", "Jiaming", ""], ["Zhang", "Rui", ""], ["Zhang", "Xishan", ""], ["Peng", "Shaohui", ""], ["Yi", "Qi", ""], ["Du", "Zidong", ""], ["Hu", "Xing", ""], ["Guo", "Qi", ""], ["Chen", "Yunji", ""]]}, {"id": "2107.12220", "submitter": "Hendrik Schuff", "authors": "Hendrik Schuff, Heike Adel, Ngoc Thang Vu", "title": "Thought Flow Nets: From Single Predictions to Trains of Model Thought", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans solve complex problems, they rarely come up with a decision\nright-away. Instead, they start with an intuitive decision, reflect upon it,\nspot mistakes, resolve contradictions and jump between different hypotheses.\nThus, they create a sequence of ideas and follow a train of thought that\nultimately reaches a conclusive decision. Contrary to this, today's neural\nclassification models are mostly trained to map an input to one single and\nfixed output. In this paper, we investigate how we can give models the\nopportunity of a second, third and $k$-th thought. We take inspiration from\nHegel's dialectics and propose a method that turns an existing classifier's\nclass prediction (such as the image class forest) into a sequence of\npredictions (such as forest $\\rightarrow$ tree $\\rightarrow$ mushroom).\nConcretely, we propose a correction module that is trained to estimate the\nmodel's correctness as well as an iterative prediction update based on the\nprediction's gradient. Our approach results in a dynamic system over class\nprobability distributions $\\unicode{x2014}$ the thought flow. We evaluate our\nmethod on diverse datasets and tasks from computer vision and natural language\nprocessing. We observe surprisingly complex but intuitive behavior and\ndemonstrate that our method (i) can correct misclassifications, (ii)\nstrengthens model performance, (iii) is robust to high levels of adversarial\nattacks, (iv) can increase accuracy up to 4% in a label-distribution-shift\nsetting and (iv) provides a tool for model interpretability that uncovers model\nknowledge which otherwise remains invisible in a single distribution\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 13:56:37 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Schuff", "Hendrik", ""], ["Adel", "Heike", ""], ["Vu", "Ngoc Thang", ""]]}, {"id": "2107.12224", "submitter": "Lucas G. S. Jeub", "authors": "Lucas G. S. Jeub, Giovanni Colavizza, Xiaowen Dong, Marya Bazzi, Mihai\n  Cucuringu", "title": "Local2Global: Scaling global representation learning on graphs via local\n  training", "comments": "5 pages, 1 figure, to appear at DLG-KDD '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a decentralised \"local2global\" approach to graph representation\nlearning, that one can a-priori use to scale any embedding technique. Our\nlocal2global approach proceeds by first dividing the input graph into\noverlapping subgraphs (or \"patches\") and training local representations for\neach patch independently. In a second step, we combine the local\nrepresentations into a globally consistent representation by estimating the set\nof rigid motions that best align the local representations using information\nfrom the patch overlaps, via group synchronization. A key distinguishing\nfeature of local2global relative to existing work is that patches are trained\nindependently without the need for the often costly parameter synchronisation\nduring distributed training. This allows local2global to scale to large-scale\nindustrial applications, where the input graph may not even fit into memory and\nmay be stored in a distributed manner. Preliminary results on medium-scale data\nsets (up to $\\sim$7K nodes and $\\sim$200K edges) are promising, with a graph\nreconstruction performance for local2global that is comparable to that of\nglobally trained embeddings. A thorough evaluation of local2global on large\nscale data and applications to downstream tasks, such as node classification\nand link prediction, constitutes ongoing work.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:08:31 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Jeub", "Lucas G. S.", ""], ["Colavizza", "Giovanni", ""], ["Dong", "Xiaowen", ""], ["Bazzi", "Marya", ""], ["Cucuringu", "Mihai", ""]]}, {"id": "2107.12243", "submitter": "Licheng Zong", "authors": "Junkang Wei, Siyuan Chen, Licheng Zong, Xin Gao, Yu Li", "title": "Protein-RNA interaction prediction with deep learning: Structure matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Protein-RNA interactions are of vital importance to a variety of cellular\nactivities. Both experimental and computational techniques have been developed\nto study the interactions. Due to the limitation of the previous database,\nespecially the lack of protein structure data, most of the existing\ncomputational methods rely heavily on the sequence data, with only a small\nportion of the methods utilizing the structural information. Recently,\nAlphaFold has revolutionized the entire protein and biology field. Foreseeably,\nthe protein-RNA interaction prediction will also be promoted significantly in\nthe upcoming years. In this work, we give a thorough review of this field,\nsurveying both the binding site and binding preference prediction problems and\ncovering the commonly used datasets, features, and models. We also point out\nthe potential challenges and opportunities in this field. This survey\nsummarizes the development of the RBP-RNA interaction field in the past and\nforesees its future development in the post-AlphaFold era.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:43:36 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wei", "Junkang", ""], ["Chen", "Siyuan", ""], ["Zong", "Licheng", ""], ["Gao", "Xin", ""], ["Li", "Yu", ""]]}, {"id": "2107.12248", "submitter": "Christian Henning", "authors": "Christian Henning, Francesco D'Angelo, Benjamin F. Grewe", "title": "Are Bayesian neural networks intrinsically good at out-of-distribution\n  detection?", "comments": "Published at UDL Workshop, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to avoid confident predictions on unfamiliar data has sparked\ninterest in out-of-distribution (OOD) detection. It is widely assumed that\nBayesian neural networks (BNN) are well suited for this task, as the endowed\nepistemic uncertainty should lead to disagreement in predictions on outliers.\nIn this paper, we question this assumption and provide empirical evidence that\nproper Bayesian inference with common neural network architectures does not\nnecessarily lead to good OOD detection. To circumvent the use of approximate\ninference, we start by studying the infinite-width case, where Bayesian\ninference can be exact considering the corresponding Gaussian process.\nStrikingly, the kernels induced under common architectural choices lead to\nuncertainties that do not reflect the underlying data generating process and\nare therefore unsuited for OOD detection. Finally, we study finite-width\nnetworks using HMC, and observe OOD behavior that is consistent with the\ninfinite-width case. Overall, our study discloses fundamental problems when\nnaively using BNNs for OOD detection and opens interesting avenues for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:53:14 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Henning", "Christian", ""], ["D'Angelo", "Francesco", ""], ["Grewe", "Benjamin F.", ""]]}, {"id": "2107.12250", "submitter": "Zhiliang Wu", "authors": "Zhiliang Wu, Yinchong Yang, Peter A. Fasching, Volker Tresp", "title": "Uncertainty-Aware Time-to-Event Prediction using Deep Kernel Accelerated\n  Failure Time Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network based solutions are increasingly being used in the\nanalysis of longitudinal Electronic Health Record data. However, most works\nfocus on prediction accuracy and neglect prediction uncertainty. We propose\nDeep Kernel Accelerated Failure Time models for the time-to-event prediction\ntask, enabling uncertainty-awareness of the prediction by a pipeline of a\nrecurrent neural network and a sparse Gaussian Process. Furthermore, a deep\nmetric learning based pre-training step is adapted to enhance the proposed\nmodel. Our model shows better point estimate performance than recurrent neural\nnetwork based baselines in experiments on two real-world datasets. More\nimportantly, the predictive variance from our model can be used to quantify the\nuncertainty estimates of the time-to-event prediction: Our model delivers\nbetter performance when it is more confident in its prediction. Compared to\nrelated methods, such as Monte Carlo Dropout, our model offers better\nuncertainty estimates by leveraging an analytical solution and is more\ncomputationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:55:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wu", "Zhiliang", ""], ["Yang", "Yinchong", ""], ["Fasching", "Peter A.", ""], ["Tresp", "Volker", ""]]}, {"id": "2107.12254", "submitter": "Amanda Prorok", "authors": "Amanda Prorok, Jan Blumenkamp, Qingbiao Li, Ryan Kortvelesy, Zhe Liu,\n  Ethan Stump", "title": "The Holy Grail of Multi-Robot Planning: Learning to Generate\n  Online-Scalable Solutions from Offline-Optimal Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multi-robot planning problems are burdened by the curse of\ndimensionality, which compounds the difficulty of applying solutions to\nlarge-scale problem instances. The use of learning-based methods in multi-robot\nplanning holds great promise as it enables us to offload the online\ncomputational burden of expensive, yet optimal solvers, to an offline learning\nprocedure. Simply put, the idea is to train a policy to copy an optimal pattern\ngenerated by a small-scale system, and then transfer that policy to much larger\nsystems, in the hope that the learned strategy scales, while maintaining\nnear-optimal performance. Yet, a number of issues impede us from leveraging\nthis idea to its full potential. This blue-sky paper elaborates some of the key\nchallenges that remain.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:59:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Prorok", "Amanda", ""], ["Blumenkamp", "Jan", ""], ["Li", "Qingbiao", ""], ["Kortvelesy", "Ryan", ""], ["Liu", "Zhe", ""], ["Stump", "Ethan", ""]]}, {"id": "2107.12292", "submitter": "Ting Yao", "authors": "Yehao Li and Ting Yao and Yingwei Pan and Tao Mei", "title": "Contextual Transformer Networks for Visual Recognition", "comments": "Rank 1 in open-set image classification task of Open World Vision\n  Challenge @ CVPR 2021; The source code and models are publicly available at:\n  \\url{https://github.com/JDAI-CV/CoTNet}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer with self-attention has led to the revolutionizing of natural\nlanguage processing field, and recently inspires the emergence of\nTransformer-style architecture design with competitive results in numerous\ncomputer vision tasks. Nevertheless, most of existing designs directly employ\nself-attention over a 2D feature map to obtain the attention matrix based on\npairs of isolated queries and keys at each spatial location, but leave the rich\ncontexts among neighbor keys under-exploited. In this work, we design a novel\nTransformer-style module, i.e., Contextual Transformer (CoT) block, for visual\nrecognition. Such design fully capitalizes on the contextual information among\ninput keys to guide the learning of dynamic attention matrix and thus\nstrengthens the capacity of visual representation. Technically, CoT block first\ncontextually encodes input keys via a $3\\times3$ convolution, leading to a\nstatic contextual representation of inputs. We further concatenate the encoded\nkeys with input queries to learn the dynamic multi-head attention matrix\nthrough two consecutive $1\\times1$ convolutions. The learnt attention matrix is\nmultiplied by input values to achieve the dynamic contextual representation of\ninputs. The fusion of the static and dynamic contextual representations are\nfinally taken as outputs. Our CoT block is appealing in the view that it can\nreadily replace each $3\\times3$ convolution in ResNet architectures, yielding a\nTransformer-style backbone named as Contextual Transformer Networks (CoTNet).\nThrough extensive experiments over a wide range of applications (e.g., image\nrecognition, object detection and instance segmentation), we validate the\nsuperiority of CoTNet as a stronger backbone. Source code is available at\n\\url{https://github.com/JDAI-CV/CoTNet}.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:00:21 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Yehao", ""], ["Yao", "Ting", ""], ["Pan", "Yingwei", ""], ["Mei", "Tao", ""]]}, {"id": "2107.12295", "submitter": "Peizhi Wu", "authors": "Peizhi Wu and Gao Cong", "title": "A Unified Deep Model of Learning from both Data and Queries for\n  Cardinality Estimation", "comments": "14 pages, SIGMOD 2021", "journal-ref": null, "doi": "10.1145/3448016.3452830", "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardinality estimation is a fundamental problem in database systems. To\ncapture the rich joint data distributions of a relational table, most of the\nexisting work either uses data as unsupervised information or uses query\nworkload as supervised information. Very little work has been done to use both\ntypes of information, and cannot fully make use of both types of information to\nlearn the joint data distribution. In this work, we aim to close the gap\nbetween data-driven and query-driven methods by proposing a new unified deep\nautoregressive model, UAE, that learns the joint data distribution from both\nthe data and query workload. First, to enable using the supervised query\ninformation in the deep autoregressive model, we develop differentiable\nprogressive sampling using the Gumbel-Softmax trick. Second, UAE is able to\nutilize both types of information to learn the joint data distribution in a\nsingle model. Comprehensive experimental results demonstrate that UAE achieves\nsingle-digit multiplicative error at tail, better accuracies over\nstate-of-the-art methods, and is both space and time efficient.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:09:58 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Wu", "Peizhi", ""], ["Cong", "Gao", ""]]}, {"id": "2107.12301", "submitter": "Feihu Huang", "authors": "Feihu Huang and Heng Huang", "title": "Enhanced Bilevel Optimization via Bregman Distance", "comments": "15 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bilevel optimization has been widely applied many machine learning problems\nsuch as hyperparameter optimization, policy optimization and meta learning.\nAlthough many bilevel optimization methods more recently have been proposed to\nsolve the bilevel optimization problems, they still suffer from high\ncomputational complexities and do not consider the more general bilevel\nproblems with nonsmooth regularization. In the paper, thus, we propose a class\nof efficient bilevel optimization methods based on Bregman distance. In our\nmethods, we use the mirror decent iteration to solve the outer subproblem of\nthe bilevel problem by using strongly-convex Bregman functions. Specifically,\nwe propose a bilevel optimization method based on Bregman distance (BiO-BreD)\nfor solving deterministic bilevel problems, which reaches the lower\ncomputational complexities than the best known results. We also propose a\nstochastic bilevel optimization method (SBiO-BreD) for solving stochastic\nbilevel problems based on the stochastic approximated gradients and Bregman\ndistance. Further, we propose an accelerated version of SBiO-BreD method\n(ASBiO-BreD) by using the variance-reduced technique. Moreover, we prove that\nthe ASBiO-BreD outperforms the best known computational complexities with\nrespect to the condition number $\\kappa$ and the target accuracy $\\epsilon$ for\nfinding an $\\epsilon$-stationary point of nonconvex-strongly-convex bilevel\nproblems. In particular, our methods can solve the bilevel optimization\nproblems with nonsmooth regularization with a lower computational complexity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:18:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Huang", "Feihu", ""], ["Huang", "Heng", ""]]}, {"id": "2107.12304", "submitter": "Guy Oren", "authors": "Guy Oren and Lior Wolf", "title": "In Defense of the Learning Without Forgetting for Task Incremental\n  Learning", "comments": "12 pages with 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Catastrophic forgetting is one of the major challenges on the road for\ncontinual learning systems, which are presented with an on-line stream of\ntasks. The field has attracted considerable interest and a diverse set of\nmethods have been presented for overcoming this challenge. Learning without\nForgetting (LwF) is one of the earliest and most frequently cited methods. It\nhas the advantages of not requiring the storage of samples from the previous\ntasks, of implementation simplicity, and of being well-grounded by relying on\nknowledge distillation. However, the prevailing view is that while it shows a\nrelatively small amount of forgetting when only two tasks are introduced, it\nfails to scale to long sequences of tasks. This paper challenges this view, by\nshowing that using the right architecture along with a standard set of\naugmentations, the results obtained by LwF surpass the latest algorithms for\ntask incremental scenario. This improved performance is demonstrated by an\nextensive set of experiments over CIFAR-100 and Tiny-ImageNet, where it is also\nshown that other methods cannot benefit as much from similar improvements.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:23:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Oren", "Guy", ""], ["Wolf", "Lior", ""]]}, {"id": "2107.12320", "submitter": "Vahid Aref", "authors": "Vladislav Neskorniuk, Andrea Carnio, Vinod Bajaj, Domenico Marsella,\n  Sergei K. Turitsyn, Jaroslaw E. Prilepsky, Vahid Aref", "title": "End-to-End Deep Learning of Long-Haul Coherent Optical Fiber\n  Communications via Regular Perturbation Model", "comments": "4 pages; accepted for presentation at ECOC 2021 in September 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel end-to-end autoencoder-based learning for coherent optical\ncommunications using a \"parallelizable\" perturbative channel model. We jointly\noptimized constellation shaping and nonlinear pre-emphasis achieving mutual\ninformation gain of 0.18 bits/sym./pol. simulating 64 GBd dual-polarization\nsingle-channel transmission over 30x80 km G.652 SMF link with EDFAs.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:46:35 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Neskorniuk", "Vladislav", ""], ["Carnio", "Andrea", ""], ["Bajaj", "Vinod", ""], ["Marsella", "Domenico", ""], ["Turitsyn", "Sergei K.", ""], ["Prilepsky", "Jaroslaw E.", ""], ["Aref", "Vahid", ""]]}, {"id": "2107.12322", "submitter": "Anton Khritankov", "authors": "Anton Khritankov, Nikita Pershin, Nikita Ukhov and Artem Ukhov", "title": "MLDev: Data Science Experiment Automation and Reproducibility Software", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the challenges of automating experiments in data\nscience. We propose an extensible experiment model as a foundation for\nintegration of different open source tools for running research experiments. We\nimplement our approach in a prototype open source MLDev software package and\nevaluate it in a series of experiments yielding promising results. Comparison\nwith other state-of-the-art tools signifies novelty of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:51:44 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Khritankov", "Anton", ""], ["Pershin", "Nikita", ""], ["Ukhov", "Nikita", ""], ["Ukhov", "Artem", ""]]}, {"id": "2107.12325", "submitter": "Quyen Tran", "authors": "Quyen Tran, Lam Tran, Linh Chu Hai, Linh Ngo Van, Khoat Than", "title": "From Implicit to Explicit feedback: A deep neural network for modeling\n  sequential behaviours and long-short term preferences of online users", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we examine the advantages of using multiple types of behaviour\nin recommendation systems. Intuitively, each user has to do some implicit\nactions (e.g., click) before making an explicit decision (e.g., purchase).\nPrevious studies showed that implicit and explicit feedback have different\nroles for a useful recommendation. However, these studies either exploit\nimplicit and explicit behaviour separately or ignore the semantic of sequential\ninteractions between users and items. In addition, we go from the hypothesis\nthat a user's preference at a time is a combination of long-term and short-term\ninterests. In this paper, we propose some Deep Learning architectures. The\nfirst one is Implicit to Explicit (ITE), to exploit users' interests through\nthe sequence of their actions. And two versions of ITE with Bidirectional\nEncoder Representations from Transformers based (BERT-based) architecture\ncalled BERT-ITE and BERT-ITE-Si, which combine users' long- and short-term\npreferences without and with side information to enhance user representation.\nThe experimental results show that our models outperform previous\nstate-of-the-art ones and also demonstrate our views on the effectiveness of\nexploiting the implicit to explicit order as well as combining long- and\nshort-term preferences in two large-scale datasets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:59:20 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tran", "Quyen", ""], ["Tran", "Lam", ""], ["Hai", "Linh Chu", ""], ["Van", "Linh Ngo", ""], ["Than", "Khoat", ""]]}, {"id": "2107.12328", "submitter": "Shih-Yuan Yu", "authors": "Shih-Yuan Yu, Rozhin Yasaei, Qingrong Zhou, Tommy Nguyen, Mohammad\n  Abdullah Al Faruque", "title": "HW2VEC: A Graph Learning Tool for Automating Hardware Security", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The time-to-market pressure and continuous growing complexity of hardware\ndesigns have promoted the globalization of the Integrated Circuit (IC) supply\nchain. However, such globalization also poses various security threats in each\nphase of the IC supply chain. Although the advancements of Machine Learning\n(ML) have pushed the frontier of hardware security, most conventional ML-based\nmethods can only achieve the desired performance by manually finding a robust\nfeature representation for circuits that are non-Euclidean data. As a result,\nmodeling these circuits using graph learning to improve design flows has\nattracted research attention in the Electronic Design Automation (EDA) field.\nHowever, due to the lack of supporting tools, only a few existing works apply\ngraph learning to resolve hardware security issues. To attract more attention,\nwe propose HW2VEC, an open-source graph learning tool that lowers the threshold\nfor newcomers to research hardware security applications with graphs. HW2VEC\nprovides an automated pipeline for extracting a graph representation from a\nhardware design in various abstraction levels (register transfer level or\ngate-level netlist). Besides, HW2VEC users can automatically transform the\nnon-Euclidean hardware designs into Euclidean graph embeddings for solving\ntheir problems. In this paper, we demonstrate that HW2VEC can achieve\nstate-of-the-art performance on two hardware security-related tasks: Hardware\nTrojan Detection and Intellectual Property Piracy Detection. We provide the\ntime profiling results for the graph extraction and the learning pipelines in\nHW2VEC.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:03:51 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yu", "Shih-Yuan", ""], ["Yasaei", "Rozhin", ""], ["Zhou", "Qingrong", ""], ["Nguyen", "Tommy", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "2107.12329", "submitter": "Ananya Harsh Jha", "authors": "William Falcon, Ananya Harsh Jha, Teddy Koker and Kyunghyun Cho", "title": "AAVAE: Augmentation-Augmented Variational Autoencoders", "comments": "15 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent methods for self-supervised learning can be grouped into two\nparadigms: contrastive and non-contrastive approaches. Their success can\nlargely be attributed to data augmentation pipelines which generate multiple\nviews of a single input that preserve the underlying semantics. In this work,\nwe introduce augmentation-augmented variational autoencoders (AAVAE), a third\napproach to self-supervised learning based on autoencoding. We derive AAVAE\nstarting from the conventional variational autoencoder (VAE), by replacing the\nKL divergence regularization, which is agnostic to the input domain, with data\naugmentations that explicitly encourage the internal representations to encode\ndomain-specific invariances and equivariances. We empirically evaluate the\nproposed AAVAE on image classification, similar to how recent contrastive and\nnon-contrastive learning algorithms have been evaluated. Our experiments\nconfirm the effectiveness of data augmentation as a replacement for KL\ndivergence regularization. The AAVAE outperforms the VAE by 30% on CIFAR-10 and\n40% on STL-10. The results for AAVAE are largely comparable to the\nstate-of-the-art for self-supervised learning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:04:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Falcon", "William", ""], ["Jha", "Ananya Harsh", ""], ["Koker", "Teddy", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2107.12334", "submitter": "Alexander Tong", "authors": "Alexander Tong and Guillaume Huguet and Dennis Shung and Amine Natik\n  and Manik Kuchroo and Guillaume Lajoie and Guy Wolf and Smita Krishnaswamy", "title": "Embedding Signals on Knowledge Graphs with Unbalanced Diffusion Earth\n  Mover's Distance", "comments": "17 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern relational machine learning it is common to encounter large graphs\nthat arise via interactions or similarities between observations in many\ndomains. Further, in many cases the target entities for analysis are actually\nsignals on such graphs. We propose to compare and organize such datasets of\ngraph signals by using an earth mover's distance (EMD) with a geodesic cost\nover the underlying graph. Typically, EMD is computed by optimizing over the\ncost of transporting one probability distribution to another over an underlying\nmetric space. However, this is inefficient when computing the EMD between many\nsignals. Here, we propose an unbalanced graph earth mover's distance that\nefficiently embeds the unbalanced EMD on an underlying graph into an $L^1$\nspace, whose metric we call unbalanced diffusion earth mover's distance\n(UDEMD). This leads us to an efficient nearest neighbors kernel over many\nsignals defined on a large graph. Next, we show how this gives distances\nbetween graph signals that are robust to noise. Finally, we apply this to\norganizing patients based on clinical notes who are modelled as signals on the\nSNOMED-CT medical knowledge graph, embedding lymphoblast cells modeled as\nsignals on a gene graph, and organizing genes modeled as signals over a large\nperipheral blood mononuclear (PBMC) cell graph. In each case, we show that\nUDEMD-based embeddings find accurate distances that are highly efficient\ncompared to other methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:19:02 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tong", "Alexander", ""], ["Huguet", "Guillaume", ""], ["Shung", "Dennis", ""], ["Natik", "Amine", ""], ["Kuchroo", "Manik", ""], ["Lajoie", "Guillaume", ""], ["Wolf", "Guy", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "2107.12342", "submitter": "Nandan Kumar Jha", "authors": "Karthik Garimella, Nandan Kumar Jha and Brandon Reagen", "title": "Sisyphus: A Cautionary Tale of Using Low-Degree Polynomial Activations\n  in Privacy-Preserving Deep Learning", "comments": "2 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy concerns in client-server machine learning have given rise to private\ninference (PI), where neural inference occurs directly on encrypted inputs. PI\nprotects clients' personal data and the server's intellectual property. A\ncommon practice in PI is to use garbled circuits to compute nonlinear functions\nprivately, namely ReLUs. However, garbled circuits suffer from high storage,\nbandwidth, and latency costs. To mitigate these issues, PI-friendly polynomial\nactivation functions have been employed to replace ReLU. In this work, we ask:\nIs it feasible to substitute all ReLUs with low-degree polynomial activation\nfunctions for building deep, privacy-friendly neural networks? We explore this\nquestion by analyzing the challenges of substituting ReLUs with polynomials,\nstarting with simple drop-and-replace solutions to novel, more involved\nreplace-and-retrain strategies. We examine the limitations of each method and\nprovide commentary on the use of polynomial activation functions for PI. We\nfind all evaluated solutions suffer from the escaping activation problem:\nforward activation values inevitably begin to expand at an exponential rate\naway from stable regions of the polynomials, which leads to exploding values\n(NaNs) or poor approximations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:33:56 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Garimella", "Karthik", ""], ["Jha", "Nandan Kumar", ""], ["Reagen", "Brandon", ""]]}, {"id": "2107.12346", "submitter": "Nicolas Obin", "authors": "Laurent Benaroya, Nicolas Obin, Axel Roebel", "title": "Beyond Voice Identity Conversion: Manipulating Voice Attributes by\n  Adversarial Learning of Structured Disentangled Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Voice conversion (VC) consists of digitally altering the voice of an\nindividual to manipulate part of its content, primarily its identity, while\nmaintaining the rest unchanged. Research in neural VC has accomplished\nconsiderable breakthroughs with the capacity to falsify a voice identity using\na small amount of data with a highly realistic rendering. This paper goes\nbeyond voice identity and presents a neural architecture that allows the\nmanipulation of voice attributes (e.g., gender and age). Leveraging the latest\nadvances on adversarial learning of structured speech representation, a novel\nstructured neural network is proposed in which multiple auto-encoders are used\nto encode speech as a set of idealistically independent linguistic and\nextra-linguistic representations, which are learned adversariarly and can be\nmanipulated during VC. Moreover, the proposed architecture is time-synchronized\nso that the original voice timing is preserved during conversion which allows\nlip-sync applications. Applied to voice gender conversion on the real-world\nVCTK dataset, our proposed architecture can learn successfully\ngender-independent representation and convert the voice gender with a very high\nefficiency and naturalness.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:40:43 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 16:49:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Benaroya", "Laurent", ""], ["Obin", "Nicolas", ""], ["Roebel", "Axel", ""]]}, {"id": "2107.12365", "submitter": "Yuling Yan", "authors": "Yuling Yan, Yuxin Chen, Jianqing Fan", "title": "Inference for Heteroskedastic PCA with Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how to construct confidence regions for principal\ncomponent analysis (PCA) in high dimension, a problem that has been vastly\nunder-explored. While computing measures of uncertainty for nonlinear/nonconvex\nestimators is in general difficult in high dimension, the challenge is further\ncompounded by the prevalent presence of missing data and heteroskedastic noise.\nWe propose a suite of solutions to perform valid inference on the principal\nsubspace based on two estimators: a vanilla SVD-based approach, and a more\nrefined iterative scheme called $\\textsf{HeteroPCA}$ (Zhang et al., 2018). We\ndevelop non-asymptotic distributional guarantees for both estimators, and\ndemonstrate how these can be invoked to compute both confidence regions for the\nprincipal subspace and entrywise confidence intervals for the spiked covariance\nmatrix. Particularly worth highlighting is the inference procedure built on top\nof $\\textsf{HeteroPCA}$, which is not only valid but also statistically\nefficient for broader scenarios (e.g., it covers a wider range of missing rates\nand signal-to-noise ratios). Our solutions are fully data-driven and adaptive\nto heteroskedastic random noise, without requiring prior knowledge about the\nnoise levels and noise distributions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:59:01 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Yan", "Yuling", ""], ["Chen", "Yuxin", ""], ["Fan", "Jianqing", ""]]}, {"id": "2107.12369", "submitter": "Dongdong Chen", "authors": "Suichan Li and Dongdong Chen and Yinpeng Chen and Lu Yuan and Lei\n  Zhang and Qi Chu and Bin Liu and Nenghai Yu", "title": "Improve Unsupervised Pretraining for Few-label Transfer", "comments": "ICCV 2021. arXiv admin note: substantial text overlap with\n  arXiv:2012.05899", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised pretraining has achieved great success and many recent works\nhave shown unsupervised pretraining can achieve comparable or even slightly\nbetter transfer performance than supervised pretraining on downstream target\ndatasets. But in this paper, we find this conclusion may not hold when the\ntarget dataset has very few labeled samples for finetuning, \\ie, few-label\ntransfer. We analyze the possible reason from the clustering perspective: 1)\nThe clustering quality of target samples is of great importance to few-label\ntransfer; 2) Though contrastive learning is essential to learn how to cluster,\nits clustering quality is still inferior to supervised pretraining due to lack\nof label supervision. Based on the analysis, we interestingly discover that\nonly involving some unlabeled target domain into the unsupervised pretraining\ncan improve the clustering quality, subsequently reducing the transfer\nperformance gap with supervised pretraining. This finding also motivates us to\npropose a new progressive few-label transfer algorithm for real applications,\nwhich aims to maximize the transfer performance under a limited annotation\nbudget. To support our analysis and proposed method, we conduct extensive\nexperiments on nine different target datasets. Experimental results show our\nproposed method can significantly boost the few-label transfer performance of\nunsupervised pretraining.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:59:56 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Suichan", ""], ["Chen", "Dongdong", ""], ["Chen", "Yinpeng", ""], ["Yuan", "Lu", ""], ["Zhang", "Lei", ""], ["Chu", "Qi", ""], ["Liu", "Bin", ""], ["Yu", "Nenghai", ""]]}, {"id": "2107.12373", "submitter": "Sonia Cromp", "authors": "Sonia Cromp, Alireza Samadian, Kirk Pruhs", "title": "Relational Boosted Regression Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks use data housed in relational databases to train boosted\nregression tree models. In this paper, we give a relational adaptation of the\ngreedy algorithm for training boosted regression trees. For the subproblem of\ncalculating the sum of squared residuals of the dataset, which dominates the\nruntime of the boosting algorithm, we provide a $(1 + \\epsilon)$-approximation\nusing the tensor sketch technique. Employing this approximation within the\nrelational boosted regression trees algorithm leads to learning similar model\nparameters, but with asymptotically better runtime.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 20:29:28 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Cromp", "Sonia", ""], ["Samadian", "Alireza", ""], ["Pruhs", "Kirk", ""]]}, {"id": "2107.12375", "submitter": "Kenneth Atz", "authors": "Kenneth Atz, Francesca Grisoni, Gisbert Schneider", "title": "Geometric Deep Learning on Molecular Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.AI cs.LG q-bio.BM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Geometric deep learning (GDL), which is based on neural network architectures\nthat incorporate and process symmetry information, has emerged as a recent\nparadigm in artificial intelligence. GDL bears particular promise in molecular\nmodeling applications, in which various molecular representations with\ndifferent symmetry properties and levels of abstraction exist. This review\nprovides a structured and harmonized overview of molecular GDL, highlighting\nits applications in drug discovery, chemical synthesis prediction, and quantum\nchemistry. Emphasis is placed on the relevance of the learned molecular\nfeatures and their complementarity to well-established molecular descriptors.\nThis review provides an overview of current challenges and opportunities, and\npresents a forecast of the future of GDL for molecular sciences.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:23:43 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Atz", "Kenneth", ""], ["Grisoni", "Francesca", ""], ["Schneider", "Gisbert", ""]]}, {"id": "2107.12395", "submitter": "Kathrin Nippel", "authors": "Felix Kahlhoefer, Michael Korsmeier, Michael Kr\\\"amer, Silvia Manconi,\n  Kathrin Nippel", "title": "Constraining dark matter annihilation with cosmic ray antiprotons using\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "TTK-21-28", "categories": "astro-ph.HE cs.LG hep-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The interpretation of data from indirect detection experiments searching for\ndark matter annihilations requires computationally expensive simulations of\ncosmic-ray propagation. In this work we present a new method based on Recurrent\nNeural Networks that significantly accelerates simulations of secondary and\ndark matter Galactic cosmic ray antiprotons while achieving excellent accuracy.\nThis approach allows for an efficient profiling or marginalisation over the\nnuisance parameters of a cosmic ray propagation model in order to perform\nparameter scans for a wide range of dark matter models. We identify importance\nsampling as particularly suitable for ensuring that the network is only\nevaluated in well-trained parameter regions. We present resulting constraints\nusing the most recent AMS-02 antiproton data on several models of Weakly\nInteracting Massive Particles. The fully trained networks are released as\nDarkRayNet together with this work and achieve a speed-up of the runtime by at\nleast two orders of magnitude compared to conventional approaches.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:00:04 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kahlhoefer", "Felix", ""], ["Korsmeier", "Michael", ""], ["Kr\u00e4mer", "Michael", ""], ["Manconi", "Silvia", ""], ["Nippel", "Kathrin", ""]]}, {"id": "2107.12416", "submitter": "Gangshan Jing", "authors": "Gangshan Jing, He Bai, Jemin George, Aranya Chakrabortty, Piyush K.\n  Sharma", "title": "Asynchronous Distributed Reinforcement Learning for LQR Control via\n  Zeroth-Order Block Coordinate Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently introduced distributed zeroth-order optimization (ZOO) algorithms\nhave shown their utility in distributed reinforcement learning (RL).\nUnfortunately, in the gradient estimation process, almost all of them require\nrandom samples with the same dimension as the global variable and/or require\nevaluation of the global cost function, which may induce high estimation\nvariance for large-scale networks. In this paper, we propose a novel\ndistributed zeroth-order algorithm by leveraging the network structure inherent\nin the optimization objective, which allows each agent to estimate its local\ngradient by local cost evaluation independently, without use of any consensus\nprotocol. The proposed algorithm exhibits an asynchronous update scheme, and is\ndesigned for stochastic non-convex optimization with a possibly non-convex\nfeasible domain based on the block coordinate descent method. The algorithm is\nlater employed as a distributed model-free RL algorithm for distributed linear\nquadratic regulator design, where a learning graph is designed to describe the\nrequired interaction relationship among agents in distributed learning. We\nprovide an empirical validation of the proposed algorithm to benchmark its\nperformance on convergence rate and variance against a centralized ZOO\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:11:07 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 14:42:19 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Jing", "Gangshan", ""], ["Bai", "He", ""], ["George", "Jemin", ""], ["Chakrabortty", "Aranya", ""], ["Sharma", "Piyush K.", ""]]}, {"id": "2107.12421", "submitter": "Bastien Talgorn", "authors": "Bastien Talgorn, St\\'ephane Alarie, and Michael Kokkolaras", "title": "Parallel Surrogate-assisted Optimization Using Mesh Adaptive Direct\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider computationally expensive blackbox optimization problems and\npresent a method that employs surrogate models and concurrent computing at the\nsearch step of the mesh adaptive direct search (MADS) algorithm. Specifically,\nwe solve a surrogate optimization problem using locally weighted scatterplot\nsmoothing (LOWESS) models to find promising candidate points to be evaluated by\nthe blackboxes. We consider several methods for selecting promising points from\na large number of points. We conduct numerical experiments to assess the\nperformance of the modified MADS algorithm with respect to available CPU\nresources by means of five engineering design problems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:28:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Talgorn", "Bastien", ""], ["Alarie", "St\u00e9phane", ""], ["Kokkolaras", "Michael", ""]]}, {"id": "2107.12433", "submitter": "Jos\\'e Su\\'arez-Varela", "authors": "Jos\\'e Su\\'arez-Varela, Miquel Ferriol-Galm\\'es, Albert L\\'opez, Paul\n  Almasan, Guillermo Bern\\'ardez, David Pujol-Perich, Krzysztof Rusek, Lo\\\"ick\n  Bonniot, Christoph Neumann, Fran\\c{c}ois Schnitzler, Fran\\c{c}ois Ta\\\"iani,\n  Martin Happ, Christian Maier, Jia Lei Du, Matthias Herlich, Peter Dorfinger,\n  Nick Vincent Hainke, Stefan Venz, Johannes Wegener, Henrike Wissing, Bo Wu,\n  Shihan Xiao, Pere Barlet-Ros, Albert Cabellos-Aparicio", "title": "The Graph Neural Networking Challenge: A Worldwide Competition for\n  Education in AI/ML for Networks", "comments": null, "journal-ref": "ACM SIGCOMM Computer Communication Review, Vol. 51, No. 3, pp.\n  9-16, 2021", "doi": "10.1145/3477482.3477485", "report-no": null, "categories": "cs.NI cs.AI cs.GL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  During the last decade, Machine Learning (ML) has increasingly become a hot\ntopic in the field of Computer Networks and is expected to be gradually adopted\nfor a plethora of control, monitoring and management tasks in real-world\ndeployments. This poses the need to count on new generations of students,\nresearchers and practitioners with a solid background in ML applied to\nnetworks. During 2020, the International Telecommunication Union (ITU) has\norganized the \"ITU AI/ML in 5G challenge'', an open global competition that has\nintroduced to a broad audience some of the current main challenges in ML for\nnetworks. This large-scale initiative has gathered 23 different challenges\nproposed by network operators, equipment manufacturers and academia, and has\nattracted a total of 1300+ participants from 60+ countries. This paper narrates\nour experience organizing one of the proposed challenges: the \"Graph Neural\nNetworking Challenge 2020''. We describe the problem presented to participants,\nthe tools and resources provided, some organization aspects and participation\nstatistics, an outline of the top-3 awarded solutions, and a summary with some\nlessons learned during all this journey. As a result, this challenge leaves a\ncurated set of educational resources openly available to anyone interested in\nthe topic.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:52:00 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Su\u00e1rez-Varela", "Jos\u00e9", ""], ["Ferriol-Galm\u00e9s", "Miquel", ""], ["L\u00f3pez", "Albert", ""], ["Almasan", "Paul", ""], ["Bern\u00e1rdez", "Guillermo", ""], ["Pujol-Perich", "David", ""], ["Rusek", "Krzysztof", ""], ["Bonniot", "Lo\u00efck", ""], ["Neumann", "Christoph", ""], ["Schnitzler", "Fran\u00e7ois", ""], ["Ta\u00efani", "Fran\u00e7ois", ""], ["Happ", "Martin", ""], ["Maier", "Christian", ""], ["Du", "Jia Lei", ""], ["Herlich", "Matthias", ""], ["Dorfinger", "Peter", ""], ["Hainke", "Nick Vincent", ""], ["Venz", "Stefan", ""], ["Wegener", "Johannes", ""], ["Wissing", "Henrike", ""], ["Wu", "Bo", ""], ["Xiao", "Shihan", ""], ["Barlet-Ros", "Pere", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "2107.12436", "submitter": "{\\L}ukasz Bolikowski", "authors": "Jan Ittner, Lukasz Bolikowski, Konstantin Hemker and Ricardo Kennedy", "title": "Feature Synergy, Redundancy, and Independence in Global Model\n  Explanations using SHAP Vector Decomposition", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We offer a new formalism for global explanations of pairwise feature\ndependencies and interactions in supervised models. Building upon SHAP values\nand SHAP interaction values, our approach decomposes feature contributions into\nsynergistic, redundant and independent components (S-R-I decomposition of SHAP\nvectors). We propose a geometric interpretation of the components and formally\nprove its basic properties. Finally, we demonstrate the utility of synergy,\nredundancy and independence by applying them to a constructed data set and\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 18:56:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ittner", "Jan", ""], ["Bolikowski", "Lukasz", ""], ["Hemker", "Konstantin", ""], ["Kennedy", "Ricardo", ""]]}, {"id": "2107.12438", "submitter": "Michael Huang", "authors": "Vishal Gupta, Michael Huang, Paat Rusmevichientong", "title": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the poor performance of cross-validation in settings where data\nare scarce, we propose a novel estimator of the out-of-sample performance of a\npolicy in data-driven optimization.Our approach exploits the optimization\nproblem's sensitivity analysis to estimate the gradient of the optimal\nobjective value with respect to the amount of noise in the data and uses the\nestimated gradient to debias the policy's in-sample performance. Unlike\ncross-validation techniques, our approach avoids sacrificing data for a test\nset, utilizes all data when training and, hence, is well-suited to settings\nwhere data are scarce. We prove bounds on the bias and variance of our\nestimator for optimization problems with uncertain linear objectives but known,\npotentially non-convex, feasible regions. For more specialized optimization\nproblems where the feasible region is \"weakly-coupled\" in a certain sense, we\nprove stronger results. Specifically, we provide explicit high-probability\nbounds on the error of our estimator that hold uniformly over a policy class\nand depends on the problem's dimension and policy class's complexity. Our\nbounds show that under mild conditions, the error of our estimator vanishes as\nthe dimension of the optimization problem grows, even if the amount of\navailable data remains small and constant. Said differently, we prove our\nestimator performs well in the small-data, large-scale regime. Finally, we\nnumerically compare our proposed method to state-of-the-art approaches through\na case-study on dispatching emergency medical response services using real\ndata. Our method provides more accurate estimates of out-of-sample performance\nand learns better-performing policies.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 19:00:51 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:39:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Gupta", "Vishal", ""], ["Huang", "Michael", ""], ["Rusmevichientong", "Paat", ""]]}, {"id": "2107.12445", "submitter": "Souvik Kundu", "authors": "Souvik Kundu, Gourav Datta, Massoud Pedram, Peter A. Beerel", "title": "Towards Low-Latency Energy-Efficient Deep SNNs via Attention-Guided\n  Compression", "comments": "10 Pages, 8 Figures, 5 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep spiking neural networks (SNNs) have emerged as a potential alternative\nto traditional deep learning frameworks, due to their promise to provide\nincreased compute efficiency on event-driven neuromorphic hardware. However, to\nperform well on complex vision applications, most SNN training frameworks yield\nlarge inference latency which translates to increased spike activity and\nreduced energy efficiency. Hence,minimizing average spike activity while\npreserving accuracy indeep SNNs remains a significant challenge and\nopportunity.This paper presents a non-iterative SNN training technique\nthatachieves ultra-high compression with reduced spiking activitywhile\nmaintaining high inference accuracy. In particular, our framework first uses\nthe attention-maps of an un compressed meta-model to yield compressed ANNs.\nThis step can be tuned to support both irregular and structured channel pruning\nto leverage computational benefits over a broad range of platforms. The\nframework then performs sparse-learning-based supervised SNN training using\ndirect inputs. During the training, it jointly optimizes the SNN weight,\nthreshold, and leak parameters to drastically minimize the number of time steps\nrequired while retaining compression. To evaluate the merits of our approach,\nwe performed experiments with variants of VGG and ResNet, on both CIFAR-10 and\nCIFAR-100, and VGG16 on Tiny-ImageNet.The SNN models generated through the\nproposed technique yield SOTA compression ratios of up to 33.4x with no\nsignificant drops in accuracy compared to baseline unpruned counterparts.\nCompared to existing SNN pruning methods, we achieve up to 8.3x higher\ncompression with improved accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:23:36 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kundu", "Souvik", ""], ["Datta", "Gourav", ""], ["Pedram", "Massoud", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2107.12452", "submitter": "Raz Paul", "authors": "Raz Paul, Yuval Friedman, Kobi Cohen", "title": "Accelerated Gradient Descent Learning over Multiple Access Fading\n  Channels", "comments": "30 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed learning problem in a wireless network, consisting\nof N distributed edge devices and a parameter server (PS). The objective\nfunction is a sum of the edge devices' local loss functions, who aim to train a\nshared model by communicating with the PS over multiple access channels (MAC).\nThis problem has attracted a growing interest in distributed sensing systems,\nand more recently in federated learning, known as over-the-air computation. In\nthis paper, we develop a novel Accelerated Gradient-descent Multiple Access\n(AGMA) algorithm that uses momentum-based gradient signals over noisy fading\nMAC to improve the convergence rate as compared to existing methods.\nFurthermore, AGMA does not require power control or beamforming to cancel the\nfading effect, which simplifies the implementation complexity. We analyze AGMA\ntheoretically, and establish a finite-sample bound of the error for both convex\nand strongly convex loss functions with Lipschitz gradient. For the strongly\nconvex case, we show that AGMA approaches the best-known linear convergence\nrate as the network increases. For the convex case, we show that AGMA\nsignificantly improves the sub-linear convergence rate as compared to existing\nmethods. Finally, we present simulation results using real datasets that\ndemonstrate better performance by AGMA.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 19:51:40 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Paul", "Raz", ""], ["Friedman", "Yuval", ""], ["Cohen", "Kobi", ""]]}, {"id": "2107.12455", "submitter": "Imad Aouali", "authors": "Imad Aouali, Sergey Ivanov, Mike Gartrell, David Rohde, Flavian\n  Vasile, Victor Zaytsev, Diego Legrand", "title": "Combining Reward and Rank Signals for Slate Recommendation", "comments": "KDD '21 Workshop on Bayesian Causal Inference for Real World\n  Interactive Systems, August 14th-15th, 2021, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of slate recommendation, where the recommender system\npresents a user with a collection or slate composed of K recommended items at\nonce. If the user finds the recommended items appealing then the user may click\nand the recommender system receives some feedback. Two pieces of information\nare available to the recommender system: was the slate clicked? (the reward),\nand if the slate was clicked, which item was clicked? (rank). In this paper, we\nformulate several Bayesian models that incorporate the reward signal (Reward\nmodel), the rank signal (Rank model), or both (Full model), for\nnon-personalized slate recommendation. In our experiments, we analyze\nperformance gains of the Full model and show that it achieves significantly\nlower error as the number of products in the catalog grows or as the slate size\nincreases.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:05:15 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 14:08:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Aouali", "Imad", ""], ["Ivanov", "Sergey", ""], ["Gartrell", "Mike", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""], ["Zaytsev", "Victor", ""], ["Legrand", "Diego", ""]]}, {"id": "2107.12460", "submitter": "Danielle Rothermel", "authors": "Danielle Rothermel, Margaret Li, Tim Rockt\\\"aschel, Jakob Foerster", "title": "Don't Sweep your Learning Rate under the Rug: A Closer Look at\n  Cross-modal Transfer of Pretrained Transformers", "comments": "Accepted to ICML 2021 Workshop: Self-Supervised Learning for\n  Reasoning and Perception", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised pre-training of large-scale transformer models on text\ncorpora followed by finetuning has achieved state-of-the-art on a number of\nnatural language processing tasks. Recently, Lu et al. (2021, arXiv:2103.05247)\nclaimed that frozen pretrained transformers (FPTs) match or outperform training\nfrom scratch as well as unfrozen (fine-tuned) pretrained transformers in a set\nof transfer tasks to other modalities. In our work, we find that this result\nis, in fact, an artifact of not tuning the learning rates. After carefully\nredesigning the empirical setup, we find that when tuning learning rates\nproperly, pretrained transformers do outperform or match training from scratch\nin all of our tasks, but only as long as the entire model is finetuned. Thus,\nwhile transfer from pretrained language models to other modalities does indeed\nprovide gains and hints at exciting possibilities for future work, properly\ntuning hyperparameters is important for arriving at robust findings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:20:48 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Rothermel", "Danielle", ""], ["Li", "Margaret", ""], ["Rockt\u00e4schel", "Tim", ""], ["Foerster", "Jakob", ""]]}, {"id": "2107.12466", "submitter": "Dmytro Perekrestenko", "authors": "Dmytro Perekrestenko, L\\'eandre Eberhard, Helmut B\\\"olcskei", "title": "High-Dimensional Distribution Generation Through Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that every $d$-dimensional probability distribution of bounded\nsupport can be generated through deep ReLU networks out of a $1$-dimensional\nuniform input distribution. What is more, this is possible without incurring a\ncost - in terms of approximation error measured in Wasserstein-distance -\nrelative to generating the $d$-dimensional target distribution from $d$\nindependent random variables. This is enabled by a vast generalization of the\nspace-filling approach discovered in (Bailey & Telgarsky, 2018). The\nconstruction we propose elicits the importance of network depth in driving the\nWasserstein distance between the target distribution and its neural network\napproximation to zero. Finally, we find that, for histogram target\ndistributions, the number of bits needed to encode the corresponding generative\nnetwork equals the fundamental limit for encoding probability distributions as\ndictated by quantization theory.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:35:52 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Perekrestenko", "Dmytro", ""], ["Eberhard", "L\u00e9andre", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "2107.12480", "submitter": "Bahar Azari", "authors": "Bahar Azari and Deniz Erdogmus", "title": "Circular-Symmetric Correlation Layer based on FFT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the vast success of standard planar convolutional neural networks,\nthey are not the most efficient choice for analyzing signals that lie on an\narbitrarily curved manifold, such as a cylinder. The problem arises when one\nperforms a planar projection of these signals and inevitably causes them to be\ndistorted or broken where there is valuable information. We propose a\nCircular-symmetric Correlation Layer (CCL) based on the formalism of\nroto-translation equivariant correlation on the continuous group $S^1 \\times\n\\mathbb{R}$, and implement it efficiently using the well-known Fast Fourier\nTransform (FFT) algorithm. We showcase the performance analysis of a general\nnetwork equipped with CCL on various recognition and classification tasks and\ndatasets. The PyTorch package implementation of CCL is provided online.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 21:06:20 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Azari", "Bahar", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2107.12490", "submitter": "Yi Zhou", "authors": "Kamala Varma, Yi Zhou, Nathalie Baracaldo, Ali Anwar", "title": "LEGATO: A LayerwisE Gradient AggregaTiOn Algorithm for Mitigating\n  Byzantine Attacks in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has arisen as a mechanism to allow multiple participants\nto collaboratively train a model without sharing their data. In these settings,\nparticipants (workers) may not trust each other fully; for instance, a set of\ncompetitors may collaboratively train a machine learning model to detect fraud.\nThe workers provide local gradients that a central server uses to update a\nglobal model. This global model can be corrupted when Byzantine workers send\nmalicious gradients, which necessitates robust methods for aggregating\ngradients that mitigate the adverse effects of Byzantine inputs. Existing\nrobust aggregation algorithms are often computationally expensive and only\neffective under strict assumptions. In this paper, we introduce LayerwisE\nGradient AggregatTiOn (LEGATO), an aggregation algorithm that is, by contrast,\nscalable and generalizable. Informed by a study of layer-specific responses of\ngradients to Byzantine attacks, LEGATO employs a dynamic gradient reweighing\nscheme that is novel in its treatment of gradients based on layer-specific\nrobustness. We show that LEGATO is more computationally efficient than multiple\nstate-of-the-art techniques and more generally robust across a variety of\nattack settings in practice. We also demonstrate LEGATO's benefits for gradient\ndescent convergence in the absence of an attack.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 21:34:45 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Varma", "Kamala", ""], ["Zhou", "Yi", ""], ["Baracaldo", "Nathalie", ""], ["Anwar", "Ali", ""]]}, {"id": "2107.12501", "submitter": "Matthew Guzdial", "authors": "Thomas Maurer and Matthew Guzdial", "title": "Adversarial Random Forest Classifier for Automated Game Design", "comments": "6 pages, 3 figures, Reflections Track of the 2021 ACM Foundations of\n  Digital Games Conference", "journal-ref": "Proceedings of the 16th International Conference on the\n  Foundations of Digital Games (FDG) 2021", "doi": "10.1145/3472538.3472587", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous game design, generating games algorithmically, has been a longtime\ngoal within the technical games research field. However, existing autonomous\ngame design systems have relied in large part on human-authoring for game\ndesign knowledge, such as fitness functions in search-based methods. In this\npaper, we describe an experiment to attempt to learn a human-like fitness\nfunction for autonomous game design in an adversarial manner. While our\nexperimental work did not meet our expectations, we present an analysis of our\nsystem and results that we hope will be informative to future autonomous game\ndesign research.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 22:30:38 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Maurer", "Thomas", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2107.12506", "submitter": "Matthew Guzdial", "authors": "Emily Halina and Matthew Guzdial", "title": "TaikoNation: Patterning-focused Chart Generation for Rhythm Action Games", "comments": "10 pages, 5 figures, Procedural Content Generation Workshop", "journal-ref": "Proceedings of the Twelfth Workshop on Procedural Content\n  Generation 2021", "doi": "10.1145/3472538.3472589", "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating rhythm game charts from songs via machine learning has been a\nproblem of increasing interest in recent years. However, all existing systems\nstruggle to replicate human-like patterning: the placement of game objects in\nrelation to each other to form congruent patterns based on events in the song.\nPatterning is a key identifier of high quality rhythm game content, seen as a\nnecessary component in human rankings. We establish a new approach for chart\ngeneration that produces charts with more congruent, human-like patterning than\nseen in prior work.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 22:55:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Halina", "Emily", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2107.12514", "submitter": "Jesse Thomason", "authors": "Jesse Thomason, Mohit Shridhar, Yonatan Bisk, Chris Paxton, Luke\n  Zettlemoyer", "title": "Language Grounding with 3D Objects", "comments": "https://github.com/snaredataset/snare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seemingly simple natural language requests to a robot are generally\nunderspecified, for example \"Can you bring me the wireless mouse?\" When viewing\nmice on the shelf, the number of buttons or presence of a wire may not be\nvisible from certain angles or positions. Flat images of candidate mice may not\nprovide the discriminative information needed for \"wireless\". The world, and\nobjects in it, are not flat images but complex 3D shapes. If a human requests\nan object based on any of its basic properties, such as color, shape, or\ntexture, robots should perform the necessary exploration to accomplish the\ntask. In particular, while substantial effort and progress has been made on\nunderstanding explicitly visual attributes like color and category,\ncomparatively little progress has been made on understanding language about\nshapes and contours. In this work, we introduce a novel reasoning task that\ntargets both visual and non-visual language about 3D objects. Our new\nbenchmark, ShapeNet Annotated with Referring Expressions (SNARE), requires a\nmodel to choose which of two objects is being referenced by a natural language\ndescription. We introduce several CLIP-based models for distinguishing objects\nand demonstrate that while recent advances in jointly modeling vision and\nlanguage are useful for robotic language understanding, it is still the case\nthat these models are weaker at understanding the 3D nature of objects --\nproperties which play a key role in manipulation. In particular, we find that\nadding view estimation to language grounding models improves accuracy on both\nSNARE and when identifying objects referred to in language on a robot platform.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 23:35:58 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Thomason", "Jesse", ""], ["Shridhar", "Mohit", ""], ["Bisk", "Yonatan", ""], ["Paxton", "Chris", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "2107.12521", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Restricted Boltzmann Machine and Deep Belief Network: Tutorial and\n  Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper on Boltzmann Machine (BM), Restricted\nBoltzmann Machine (RBM), and Deep Belief Network (DBN). We start with the\nrequired background on probabilistic graphical models, Markov random field,\nGibbs sampling, statistical physics, Ising model, and the Hopfield network.\nThen, we introduce the structures of BM and RBM. The conditional distributions\nof visible and hidden variables, Gibbs sampling in RBM for generating\nvariables, training BM and RBM by maximum likelihood estimation, and\ncontrastive divergence are explained. Then, we discuss different possible\ndiscrete and continuous distributions for the variables. We introduce\nconditional RBM and how it is trained. Finally, we explain deep belief network\nas a stack of RBM models. This paper on Boltzmann machines can be useful in\nvarious fields including data science, statistics, neural computation, and\nstatistical physics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 23:59:12 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2107.12524", "submitter": "Matthew Guzdial", "authors": "Bowei Li, Ruohan Chen, Yuqing Xue, Ricky Wang, Wenwen Li, and Matthew\n  Guzdial", "title": "Ensemble Learning For Mega Man Level Generation", "comments": "9 pages, 7 figures, Workshop on Procedural Content Generation", "journal-ref": "Proceedings of the Twelfth Workshop on Procedural Content\n  Generation 2021", "doi": "10.1145/3472538.3472600", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Procedural content generation via machine learning (PCGML) is the process of\nprocedurally generating game content using models trained on existing game\ncontent. PCGML methods can struggle to capture the true variance present in\nunderlying data with a single model. In this paper, we investigated the use of\nensembles of Markov chains for procedurally generating \\emph{Mega Man} levels.\nWe conduct an initial investigation of our approach and evaluate it on measures\nof playability and stylistic similarity in comparison to a non-ensemble,\nexisting Markov chain approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:16:23 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Li", "Bowei", ""], ["Chen", "Ruohan", ""], ["Xue", "Yuqing", ""], ["Wang", "Ricky", ""], ["Li", "Wenwen", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2107.12525", "submitter": "Daniel Kang", "authors": "Daniel Kang, John Guibas, Peter Bailis, Tatsunori Hashimoto, Yi Sun,\n  Matei Zaharia", "title": "Proof: Accelerating Approximate Aggregation Queries with Expensive\n  Predicates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DB cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset $\\mathcal{D}$, we are interested in computing the mean of a\nsubset of $\\mathcal{D}$ which matches a predicate. ABae leverages stratified\nsampling and proxy models to efficiently compute this statistic given a\nsampling budget $N$. In this document, we theoretically analyze ABae and show\nthat the MSE of the estimate decays at rate $O(N_1^{-1} + N_2^{-1} +\nN_1^{1/2}N_2^{-3/2})$, where $N=K \\cdot N_1+N_2$ for some integer constant $K$\nand $K \\cdot N_1$ and $N_2$ represent the number of samples used in Stage 1 and\nStage 2 of ABae respectively. Hence, if a constant fraction of the total sample\nbudget $N$ is allocated to each stage, we will achieve a mean squared error of\n$O(N^{-1})$ which matches the rate of mean squared error of the optimal\nstratified sampling algorithm given a priori knowledge of the predicate\npositive rate and standard deviation per stratum.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:18:21 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 18:29:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kang", "Daniel", ""], ["Guibas", "John", ""], ["Bailis", "Peter", ""], ["Hashimoto", "Tatsunori", ""], ["Sun", "Yi", ""], ["Zaharia", "Matei", ""]]}, {"id": "2107.12527", "submitter": "Liang Chen", "authors": "Liang Chen, Lesley Tan", "title": "Physics-Enforced Modeling for Insertion Loss of Transmission Lines by\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate data-driven parameterized modeling of insertion\nloss for transmission lines with respect to design parameters. We first show\nthat direct application of neural networks can lead to non-physics models with\nnegative insertion loss. To mitigate this problem, we propose two deep learning\nsolutions. One solution is to add a regulation term, which represents the\npassive condition, to the final loss function to enforce the negative quantity\nof insertion loss. In the second method, a third-order polynomial expression is\ndefined first, which ensures positiveness, to approximate the insertion loss,\nthen DeepONet neural network structure, which was proposed recently for\nfunction and system modeling, was employed to model the coefficients of\npolynomials. The resulting neural network is applied to predict the\ncoefficients of the polynomial expression. The experimental results on an\nopen-sourced SI/PI database of a PCB design show that both methods can ensure\nthe positiveness for the insertion loss. Furthermore, both methods can achieve\nsimilar prediction results, while the polynomial-based DeepONet method is\nfaster than DeepONet based method in training time.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:22:10 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Chen", "Liang", ""], ["Tan", "Lesley", ""]]}, {"id": "2107.12530", "submitter": "Haizhang Zhang", "authors": "Yuesheng Xu and Haizhang Zhang", "title": "Convergence of Deep ReLU Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore convergence of deep neural networks with the popular ReLU\nactivation function, as the depth of the networks tends to infinity. To this\nend, we introduce the notion of activation domains and activation matrices of a\nReLU network. By replacing applications of the ReLU activation function by\nmultiplications with activation matrices on activation domains, we obtain an\nexplicit expression of the ReLU network. We then identify the convergence of\nthe ReLU networks as convergence of a class of infinite products of matrices.\nSufficient and necessary conditions for convergence of these infinite products\nof matrices are studied. As a result, we establish necessary conditions for\nReLU networks to converge that the sequence of weight matrices converges to the\nidentity matrix and the sequence of the bias vectors converges to zero as the\ndepth of ReLU networks increases to infinity. Moreover, we obtain sufficient\nconditions in terms of the weight matrices and bias vectors at hidden layers\nfor pointwise convergence of deep ReLU networks. These results provide\nmathematical insights to the design strategy of the well-known deep residual\nnetworks in image classification.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:33:53 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Xu", "Yuesheng", ""], ["Zhang", "Haizhang", ""]]}, {"id": "2107.12532", "submitter": "Matthew Guzdial", "authors": "Kynan Sorochan, Jerry Chen, Yakun Yu, and Matthew Guzdial", "title": "Generating Lode Runner Levels by Learning Player Paths with LSTMs", "comments": "7 pages, 6 figures, Workshop on Procedural Content Generation", "journal-ref": "Proceedings of the Twelfth Workshop on Procedural Content\n  Generation 2021", "doi": "10.1145/3472538.3472602", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has been a popular tool in many different fields, including\nprocedural content generation. However, procedural content generation via\nmachine learning (PCGML) approaches can struggle with controllability and\ncoherence. In this paper, we attempt to address these problems by learning to\ngenerate human-like paths, and then generating levels based on these paths. We\nextract player path data from gameplay video, train an LSTM to generate new\npaths based on this data, and then generate game levels based on this path\ndata. We demonstrate that our approach leads to more coherent levels for the\ngame Lode Runner in comparison to an existing PCGML approach.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:48:30 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sorochan", "Kynan", ""], ["Chen", "Jerry", ""], ["Yu", "Yakun", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2107.12533", "submitter": "Matthew Guzdial", "authors": "Zisen Zhou and Matthew Guzdial", "title": "Toward Co-creative Dungeon Generation via Transfer Learning", "comments": "7 pages, 6 figures, Workshop on Procedural Content Generation", "journal-ref": "Proceedings of the Twelfth Workshop on Procedural Content\n  Generation 2021", "doi": "10.1145/3472538.3472601", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-creative Procedural Content Generation via Machine Learning (PCGML) refers\nto systems where a PCGML agent and a human work together to produce output\ncontent. One of the limitations of co-creative PCGML is that it requires\nco-creative training data for a PCGML agent to learn to interact with humans.\nHowever, acquiring this data is a difficult and time-consuming process. In this\nwork, we propose approximating human-AI interaction data and employing transfer\nlearning to adapt learned co-creative knowledge from one game to a different\ngame. We explore this approach for co-creative Zelda dungeon room generation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 00:54:55 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhou", "Zisen", ""], ["Guzdial", "Matthew", ""]]}, {"id": "2107.12547", "submitter": "Art Owen", "authors": "Christopher R. Hoyt and Art B. Owen", "title": "Probing neural networks with t-SNE, class-specific projections and a\n  guided tour", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We use graphical methods to probe neural nets that classify images. Plots of\nt-SNE outputs at successive layers in a network reveal increasingly organized\narrangement of the data points. They can also reveal how a network can diminish\nor even forget about within-class structure as the data proceeds through\nlayers. We use class-specific analogues of principal components to visualize\nhow succeeding layers separate the classes. These allow us to sort images from\na given class from most typical to least typical (in the data) and they also\nserve as very useful projection coordinates for data visualization. We find\nthem especially useful when defining versions guided tours for animated data\nvisualization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 01:42:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Hoyt", "Christopher R.", ""], ["Owen", "Art B.", ""]]}, {"id": "2107.12562", "submitter": "Shifeng Pan", "authors": "Shifeng Pan and Lei He", "title": "Cross-speaker Style Transfer with Prosody Bottleneck in Neural Speech\n  Synthesis", "comments": "in Proceedings of INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-speaker style transfer is crucial to the applications of multi-style\nand expressive speech synthesis at scale. It does not require the target\nspeakers to be experts in expressing all styles and to collect corresponding\nrecordings for model training. However, the performances of existing style\ntransfer methods are still far behind real application needs. The root causes\nare mainly twofold. Firstly, the style embedding extracted from single\nreference speech can hardly provide fine-grained and appropriate prosody\ninformation for arbitrary text to synthesize. Secondly, in these models the\ncontent/text, prosody, and speaker timbre are usually highly entangled, it's\ntherefore not realistic to expect a satisfied result when freely combining\nthese components, such as to transfer speaking style between speakers. In this\npaper, we propose a cross-speaker style transfer text-to-speech (TTS) model\nwith explicit prosody bottleneck. The prosody bottleneck builds up the kernels\naccounting for speaking style robustly, and disentangles the prosody from\ncontent and speaker timbre, therefore guarantees high quality cross-speaker\nstyle transfer. Evaluation result shows the proposed method even achieves\non-par performance with source speaker's speaker-dependent (SD) model in\nobjective measurement of prosody, and significantly outperforms the cycle\nconsistency and GMVAE-based baselines in objective and subjective evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 02:43:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Pan", "Shifeng", ""], ["He", "Lei", ""]]}, {"id": "2107.12571", "submitter": "Denis Gudovskiy", "authors": "Denis Gudovskiy, Shun Ishizaka, Kazuki Kozuka", "title": "CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via\n  Conditional Normalizing Flows", "comments": "Accepted to WACV 2022. Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised anomaly detection with localization has many practical\napplications when labeling is infeasible and, moreover, when anomaly examples\nare completely missing in the train data. While recently proposed models for\nsuch data setup achieve high accuracy metrics, their complexity is a limiting\nfactor for real-time processing. In this paper, we propose a real-time model\nand analytically derive its relationship to prior methods. Our CFLOW-AD model\nis based on a conditional normalizing flow framework adopted for anomaly\ndetection with localization. In particular, CFLOW-AD consists of a\ndiscriminatively pretrained encoder followed by a multi-scale generative\ndecoders where the latter explicitly estimate likelihood of the encoded\nfeatures. Our approach results in a computationally and memory-efficient model:\nCFLOW-AD is faster and smaller by a factor of 10x than prior state-of-the-art\nwith the same input setting. Our experiments on the MVTec dataset show that\nCFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by\n1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source\nour code with fully reproducible experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:10:38 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Gudovskiy", "Denis", ""], ["Ishizaka", "Shun", ""], ["Kozuka", "Kazuki", ""]]}, {"id": "2107.12580", "submitter": "Maithra Raghu", "authors": "Chiyuan Zhang, Maithra Raghu, Jon Kleinberg, Samy Bengio", "title": "Pointer Value Retrieval: A new benchmark for understanding the limits of\n  neural network generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successes of deep learning critically rely on the ability of neural\nnetworks to output meaningful predictions on unseen data -- generalization. Yet\ndespite its criticality, there remain fundamental open questions on how neural\nnetworks generalize. How much do neural networks rely on memorization -- seeing\nhighly similar training examples -- and how much are they capable of\nhuman-intelligence styled reasoning -- identifying abstract rules underlying\nthe data? In this paper we introduce a novel benchmark, Pointer Value Retrieval\n(PVR) tasks, that explore the limits of neural network generalization. While\nPVR tasks can consist of visual as well as symbolic inputs, each with varying\nlevels of difficulty, they all have a simple underlying rule. One part of the\nPVR task input acts as a pointer, giving the location of a different part of\nthe input, which forms the value (and output). We demonstrate that this task\nstructure provides a rich testbed for understanding generalization, with our\nempirical study showing large variations in neural network performance based on\ndataset size, task complexity and model architecture. The interaction of\nposition, values and the pointer rule also allow the development of nuanced\ntests of generalization, by introducing distribution shift and increasing\nfunctional complexity. These reveal both subtle failures and surprising\nsuccesses, suggesting many promising directions of exploration on this\nbenchmark.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 03:50:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Raghu", "Maithra", ""], ["Kleinberg", "Jon", ""], ["Bengio", "Samy", ""]]}, {"id": "2107.12591", "submitter": "Hai Wang", "authors": "Hoifung Poon, Hai Wang, Hunter Lang", "title": "Combining Probabilistic Logic and Deep Learning for Self-Supervised\n  Learning", "comments": "Book chapter. arXiv admin note: substantial text overlap with\n  arXiv:2012.12474, arXiv:1808.08485, arXiv:2008.12878", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has proven effective for various application tasks, but its\napplicability is limited by the reliance on annotated examples. Self-supervised\nlearning has emerged as a promising direction to alleviate the supervision\nbottleneck, but existing work focuses on leveraging co-occurrences in unlabeled\ndata for task-agnostic representation learning, as exemplified by masked\nlanguage model pretraining. In this chapter, we explore task-specific\nself-supervision, which leverages domain knowledge to automatically annotate\nnoisy training examples for end applications, either by introducing labeling\nfunctions for annotating individual instances, or by imposing constraints over\ninterdependent label decisions. We first present deep probabilistic logic(DPL),\nwhich offers a unifying framework for task-specific self-supervision by\ncomposing probabilistic logic with deep learning. DPL represents unknown labels\nas latent variables and incorporates diverse self-supervision using\nprobabilistic logic to train a deep neural network end-to-end using variational\nEM. Next, we present self-supervised self-supervision(S4), which adds to DPL\nthe capability to learn new self-supervision automatically. Starting from an\ninitial seed self-supervision, S4 iteratively uses the deep neural network to\npropose new self supervision. These are either added directly (a form of\nstructured self-training) or verified by a human expert (as in feature-based\nactive learning). Experiments on real-world applications such as biomedical\nmachine reading and various text classification tasks show that task-specific\nself-supervision can effectively leverage domain expertise and often match the\naccuracy of supervised methods with a tiny fraction of human effort.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 04:25:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Poon", "Hoifung", ""], ["Wang", "Hai", ""], ["Lang", "Hunter", ""]]}, {"id": "2107.12619", "submitter": "Changan Wang", "authors": "Changan Wang, Qingyu Song, Boshen Zhang, Yabiao Wang, Ying Tai, Xuyi\n  Hu, Chengjie Wang, Jilin Li, Jiayi Ma, Yang Wu", "title": "Uniformity in Heterogeneity:Diving Deep into Count Interval Partition\n  for Crowd Counting", "comments": "To be appear in ICCV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the problem of inaccurate learning targets in crowd counting draws\nincreasing attention. Inspired by a few pioneering work, we solve this problem\nby trying to predict the indices of pre-defined interval bins of counts instead\nof the count values themselves. However, an inappropriate interval setting\nmight make the count error contributions from different intervals extremely\nimbalanced, leading to inferior counting performance. Therefore, we propose a\nnovel count interval partition criterion called Uniform Error Partition (UEP),\nwhich always keeps the expected counting error contributions equal for all\nintervals to minimize the prediction risk. Then to mitigate the inevitably\nintroduced discretization errors in the count quantization process, we propose\nanother criterion called Mean Count Proxies (MCP). The MCP criterion selects\nthe best count proxy for each interval to represent its count value during\ninference, making the overall expected discretization error of an image nearly\nnegligible. As far as we are aware, this work is the first to delve into such a\nclassification task and ends up with a promising solution for count interval\npartition. Following the above two theoretically demonstrated criterions, we\npropose a simple yet effective model termed Uniform Error Partition Network\n(UEPNet), which achieves state-of-the-art performance on several challenging\ndatasets. The codes will be available at:\nhttps://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 06:24:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Wang", "Changan", ""], ["Song", "Qingyu", ""], ["Zhang", "Boshen", ""], ["Wang", "Yabiao", ""], ["Tai", "Ying", ""], ["Hu", "Xuyi", ""], ["Wang", "Chengjie", ""], ["Li", "Jilin", ""], ["Ma", "Jiayi", ""], ["Wu", "Yang", ""]]}, {"id": "2107.12626", "submitter": "Jindong Wang", "authors": "Yuxin Zhang, Yiqiang Chen, Jindong Wang, Zhiwen Pan", "title": "Unsupervised Deep Anomaly Detection for Multi-Sensor Time-Series Signals", "comments": "Accepted to IEEE Transactions on Knowledge and Data Engineering (IEEE\n  TKDE) as a regular paper; 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, multi-sensor technologies are applied in many fields, e.g., Health\nCare (HC), Human Activity Recognition (HAR), and Industrial Control System\n(ICS). These sensors can generate a substantial amount of multivariate\ntime-series data. Unsupervised anomaly detection on multi-sensor time-series\ndata has been proven critical in machine learning researches. The key challenge\nis to discover generalized normal patterns by capturing spatial-temporal\ncorrelation in multi-sensor data. Beyond this challenge, the noisy data is\noften intertwined with the training data, which is likely to mislead the model\nby making it hard to distinguish between the normal, abnormal, and noisy data.\nFew of previous researches can jointly address these two challenges. In this\npaper, we propose a novel deep learning-based anomaly detection algorithm\ncalled Deep Convolutional Autoencoding Memory network (CAE-M). We first build a\nDeep Convolutional Autoencoder to characterize spatial dependence of\nmulti-sensor data with a Maximum Mean Discrepancy (MMD) to better distinguish\nbetween the noisy, normal, and abnormal data. Then, we construct a Memory\nNetwork consisting of linear (Autoregressive Model) and non-linear predictions\n(Bidirectional LSTM with Attention) to capture temporal dependence from\ntime-series data. Finally, CAE-M jointly optimizes these two subnetworks. We\nempirically compare the proposed approach with several state-of-the-art anomaly\ndetection methods on HAR and HC datasets. Experimental results demonstrate that\nour proposed model outperforms these existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 06:48:20 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Yuxin", ""], ["Chen", "Yiqiang", ""], ["Wang", "Jindong", ""], ["Pan", "Zhiwen", ""]]}, {"id": "2107.12628", "submitter": "Bo Li", "authors": "Yezhen Wang, Bo Li, Tong Che, Kaiyang Zhou, Ziwei Liu, Dongsheng Li", "title": "Energy-Based Open-World Uncertainty Modeling for Confidence Calibration", "comments": "ICCV 2021 (Poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Confidence calibration is of great importance to the reliability of decisions\nmade by machine learning systems. However, discriminative classifiers based on\ndeep neural networks are often criticized for producing overconfident\npredictions that fail to reflect the true correctness likelihood of\nclassification accuracy. We argue that such an inability to model uncertainty\nis mainly caused by the closed-world nature in softmax: a model trained by the\ncross-entropy loss will be forced to classify input into one of $K$ pre-defined\ncategories with high probability. To address this problem, we for the first\ntime propose a novel $K$+1-way softmax formulation, which incorporates the\nmodeling of open-world uncertainty as the extra dimension. To unify the\nlearning of the original $K$-way classification task and the extra dimension\nthat models uncertainty, we propose a novel energy-based objective function,\nand moreover, theoretically prove that optimizing such an objective essentially\nforces the extra dimension to capture the marginal data distribution. Extensive\nexperiments show that our approach, Energy-based Open-World Softmax\n(EOW-Softmax), is superior to existing state-of-the-art methods in improving\nconfidence calibration.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 06:52:06 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 06:09:48 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wang", "Yezhen", ""], ["Li", "Bo", ""], ["Che", "Tong", ""], ["Zhou", "Kaiyang", ""], ["Liu", "Ziwei", ""], ["Li", "Dongsheng", ""]]}, {"id": "2107.12631", "submitter": "Jiguang He", "authors": "Jiguang He and Henk Wymeersch and Marco Di Renzo and Markku Juntti", "title": "Learning to Estimate RIS-Aided mmWave Channels", "comments": "5 pages, 7 figures, submitted to IEEE WCL for a review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inspired by the remarkable learning and prediction performance of deep neural\nnetworks (DNNs), we apply one special type of DNN framework, known as\nmodel-driven deep unfolding neural network, to reconfigurable intelligent\nsurface (RIS)-aided millimeter wave (mmWave) single-input multiple-output\n(SIMO) systems. We focus on uplink cascaded channel estimation, where known and\nfixed base station combining and RIS phase control matrices are considered for\ncollecting observations. To boost the estimation performance and reduce the\ntraining overhead, the inherent channel sparsity of mmWave channels is\nleveraged in the deep unfolding method. It is verified that the proposed deep\nunfolding network architecture can outperform the least squares (LS) method\nwith a relatively smaller training overhead and online computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 06:57:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["He", "Jiguang", ""], ["Wymeersch", "Henk", ""], ["Di Renzo", "Marco", ""], ["Juntti", "Markku", ""]]}, {"id": "2107.12636", "submitter": "Wen Wang", "authors": "Wen Wang, Yang Cao, Jing Zhang, Fengxiang He, Zheng-Jun Zha, Yonggang\n  Wen, Dacheng Tao", "title": "Exploring Sequence Feature Alignment for Domain Adaptive Detection\n  Transformers", "comments": "Accepted by ACM MM2021. Source code is available at:\n  https://github.com/encounter1997/SFA", "journal-ref": null, "doi": "10.1145/3474085.3475317", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detection transformers have recently shown promising object detection results\nand attracted increasing attention. However, how to develop effective domain\nadaptation techniques to improve its cross-domain performance remains\nunexplored and unclear. In this paper, we delve into this topic and empirically\nfind that direct feature distribution alignment on the CNN backbone only brings\nlimited improvements, as it does not guarantee domain-invariant sequence\nfeatures in the transformer for prediction. To address this issue, we propose a\nnovel Sequence Feature Alignment (SFA) method that is specially designed for\nthe adaptation of detection transformers. Technically, SFA consists of a domain\nquery-based feature alignment (DQFA) module and a token-wise feature alignment\n(TDA) module. In DQFA, a novel domain query is used to aggregate and align\nglobal context from the token sequence of both domains. DQFA reduces the domain\ndiscrepancy in global feature representations and object relations when\ndeploying in the transformer encoder and decoder, respectively. Meanwhile, TDA\naligns token features in the sequence from both domains, which reduces the\ndomain gaps in local and instance-level feature representations in the\ntransformer encoder and decoder, respectively. Besides, a novel bipartite\nmatching consistency loss is proposed to enhance the feature discriminability\nfor robust object detection. Experiments on three challenging benchmarks show\nthat SFA outperforms state-of-the-art domain adaptive object detection methods.\nCode has been made available at: https://github.com/encounter1997/SFA.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 07:17:12 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Wang", "Wen", ""], ["Cao", "Yang", ""], ["Zhang", "Jing", ""], ["He", "Fengxiang", ""], ["Zha", "Zheng-Jun", ""], ["Wen", "Yonggang", ""], ["Tao", "Dacheng", ""]]}, {"id": "2107.12651", "submitter": "Xinzhe Han", "authors": "Xinzhe Han, Shuhui Wang, Chi Su, Qingming Huang, Qi Tian", "title": "Greedy Gradient Ensemble for Robust Visual Question Answering", "comments": "Accepted by ICCV 2021. Code: https://github.com/GeraldHan/GGE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language bias is a critical issue in Visual Question Answering (VQA), where\nmodels often exploit dataset biases for the final decision without considering\nthe image information. As a result, they suffer from performance drop on\nout-of-distribution data and inadequate visual explanation. Based on\nexperimental analysis for existing robust VQA methods, we stress the language\nbias in VQA that comes from two aspects, i.e., distribution bias and shortcut\nbias. We further propose a new de-bias framework, Greedy Gradient Ensemble\n(GGE), which combines multiple biased models for unbiased base model learning.\nWith the greedy strategy, GGE forces the biased models to over-fit the biased\ndata distribution in priority, thus makes the base model pay more attention to\nexamples that are hard to solve by biased models. The experiments demonstrate\nthat our method makes better use of visual information and achieves\nstate-of-the-art performance on diagnosing dataset VQA-CP without using extra\nannotations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:02:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Han", "Xinzhe", ""], ["Wang", "Shuhui", ""], ["Su", "Chi", ""], ["Huang", "Qingming", ""], ["Tian", "Qi", ""]]}, {"id": "2107.12654", "submitter": "Da-Wei Zhou", "authors": "Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan", "title": "Co-Transport for Class-Incremental Learning", "comments": "Accepted to ACM Multimedia 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional learning systems are trained in closed-world for a fixed number\nof classes, and need pre-collected datasets in advance. However, new classes\noften emerge in real-world applications and should be learned incrementally.\nFor example, in electronic commerce, new types of products appear daily, and in\na social media community, new topics emerge frequently. Under such\ncircumstances, incremental models should learn several new classes at a time\nwithout forgetting. We find a strong correlation between old and new classes in\nincremental learning, which can be applied to relate and facilitate different\nlearning stages mutually. As a result, we propose CO-transport for class\nIncremental Learning (COIL), which learns to relate across incremental tasks\nwith the class-wise semantic relationship. In detail, co-transport has two\naspects: prospective transport tries to augment the old classifier with optimal\ntransported knowledge as fast model adaptation. Retrospective transport aims to\ntransport new class classifiers backward as old ones to overcome forgetting.\nWith these transports, COIL efficiently adapts to new tasks, and stably resists\nforgetting. Experiments on benchmark and real-world multimedia datasets\nvalidate the effectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:07:02 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhou", "Da-Wei", ""], ["Ye", "Han-Jia", ""], ["Zhan", "De-Chuan", ""]]}, {"id": "2107.12657", "submitter": "Sohee Kim", "authors": "Sohee Kim, Seungkyu Lee", "title": "Continual Learning with Neuron Activation Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning is a concept of online learning with multiple sequential\ntasks. One of the critical barriers of continual learning is that a network\nshould learn a new task keeping the knowledge of old tasks without access to\nany data of the old tasks. In this paper, we propose a neuron activation\nimportance-based regularization method for stable continual learning regardless\nof the order of tasks. We conduct comprehensive experiments on existing\nbenchmark data sets to evaluate not just the stability and plasticity of our\nmethod with improved classification accuracy also the robustness of the\nperformance along the changes of task order.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:09:32 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kim", "Sohee", ""], ["Lee", "Seungkyu", ""]]}, {"id": "2107.12673", "submitter": "Paul Wimmer", "authors": "Paul Wimmer, Jens Mehnert, Alexandru Condurache", "title": "COPS: Controlled Pruning Before Training Starts", "comments": "Accepted by The International Joint Conference on Neural Network\n  (IJCNN) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep neural network (DNN) pruning techniques, applied\none-shot before training starts, evaluate sparse architectures with the help of\na single criterion -- called pruning score. Pruning weights based on a solitary\nscore works well for some architectures and pruning rates but may also fail for\nother ones. As a common baseline for pruning scores, we introduce the notion of\na generalized synaptic score (GSS). In this work we do not concentrate on a\nsingle pruning criterion, but provide a framework for combining arbitrary GSSs\nto create more powerful pruning strategies. These COmbined Pruning Scores\n(COPS) are obtained by solving a constrained optimization problem. Optimizing\nfor more than one score prevents the sparse network to overly specialize on an\nindividual task, thus COntrols Pruning before training Starts. The\ncombinatorial optimization problem given by COPS is relaxed on a linear program\n(LP). This LP is solved analytically and determines a solution for COPS.\nFurthermore, an algorithm to compute it for two scores numerically is proposed\nand evaluated. Solving COPS in such a way has lower complexity than the best\ngeneral LP solver. In our experiments we compared pruning with COPS against\nstate-of-the-art methods for different network architectures and image\nclassification tasks and obtained improved results.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:48:01 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Wimmer", "Paul", ""], ["Mehnert", "Jens", ""], ["Condurache", "Alexandru", ""]]}, {"id": "2107.12674", "submitter": "Eitan Kosman", "authors": "Eitan Kosman, Dotan Di Castro", "title": "Vision-Guided Forecasting -- Visual Context for Multi-Horizon Time\n  Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving gained huge traction in recent years, due to its potential\nto change the way we commute. Much effort has been put into trying to estimate\nthe state of a vehicle. Meanwhile, learning to forecast the state of a vehicle\nahead introduces new capabilities, such as predicting dangerous situations.\nMoreover, forecasting brings new supervision opportunities by learning to\npredict richer a context, expressed by multiple horizons. Intuitively, a video\nstream originated from a front-facing camera is necessary because it encodes\ninformation about the upcoming road. Besides, historical traces of the\nvehicle's states give more context. In this paper, we tackle multi-horizon\nforecasting of vehicle states by fusing the two modalities. We design and\nexperiment with 3 end-to-end architectures that exploit 3D convolutions for\nvisual features extraction and 1D convolutions for features extraction from\nspeed and steering angle traces. To demonstrate the effectiveness of our\nmethod, we perform extensive experiments on two publicly available real-world\ndatasets, Comma2k19 and the Udacity challenge. We show that we are able to\nforecast a vehicle's state to various horizons, while outperforming the current\nstate-of-the-art results on the related task of driving state estimation. We\nexamine the contribution of vision features, and find that a model fed with\nvision features achieves an error that is 56.6% and 66.9% of the error of a\nmodel that doesn't use those features, on the Udacity and Comma2k19 datasets\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:52:40 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kosman", "Eitan", ""], ["Di Castro", "Dotan", ""]]}, {"id": "2107.12677", "submitter": "\\'Angel Gonz\\'alez-Prieto Dr.", "authors": "Jes\\'us Bobadilla, Fernando Ortega, Abraham Guti\\'errez, \\'Angel\n  Gonz\\'alez-Prieto", "title": "Deep Variational Models for Collaborative Filtering-based Recommender\n  Systems", "comments": "14 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning provides accurate collaborative filtering models to improve\nrecommender system results. Deep matrix factorization and their related\ncollaborative neural networks are the state-of-art in the field; nevertheless,\nboth models lack the necessary stochasticity to create the robust, continuous,\nand structured latent spaces that variational autoencoders exhibit. On the\nother hand, data augmentation through variational autoencoder does not provide\naccurate results in the collaborative filtering field due to the high sparsity\nof recommender systems. Our proposed models apply the variational concept to\ninject stochasticity in the latent space of the deep architecture, introducing\nthe variational technique in the neural collaborative filtering field. This\nmethod does not depend on the particular model used to generate the latent\nrepresentation. In this way, this approach can be applied as a plugin to any\ncurrent and future specific models. The proposed models have been tested using\nfour representative open datasets, three different quality measures, and\nstate-of-art baselines. The results show the superiority of the proposed\napproach in scenarios where the variational enrichment exceeds the injected\nnoise effect. Additionally, a framework is provided to enable the\nreproducibility of the conducted experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:59:39 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bobadilla", "Jes\u00fas", ""], ["Ortega", "Fernando", ""], ["Guti\u00e9rrez", "Abraham", ""], ["Gonz\u00e1lez-Prieto", "\u00c1ngel", ""]]}, {"id": "2107.12679", "submitter": "Mingbo Zhao", "authors": "Wenlong Cheng and Mingbo Zhao and Zhiling Ye and Shuhang Gu", "title": "MFAGAN: A Compression Framework for Memory-Efficient On-Device\n  Super-Resolution GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Generative adversarial networks (GANs) have promoted remarkable advances in\nsingle-image super-resolution (SR) by recovering photo-realistic images.\nHowever, high memory consumption of GAN-based SR (usually generators) causes\nperformance degradation and more energy consumption, hindering the deployment\nof GAN-based SR into resource-constricted mobile devices. In this paper, we\npropose a novel compression framework \\textbf{M}ulti-scale \\textbf{F}eature\n\\textbf{A}ggregation Net based \\textbf{GAN} (MFAGAN) for reducing the memory\naccess cost of the generator. First, to overcome the memory explosion of dense\nconnections, we utilize a memory-efficient multi-scale feature aggregation net\nas the generator. Second, for faster and more stable training, our method\nintroduces the PatchGAN discriminator. Third, to balance the student\ndiscriminator and the compressed generator, we distill both the generator and\nthe discriminator. Finally, we perform a hardware-aware neural architecture\nsearch (NAS) to find a specialized SubGenerator for the target mobile phone.\nBenefiting from these improvements, the proposed MFAGAN achieves up to\n\\textbf{8.3}$\\times$ memory saving and \\textbf{42.9}$\\times$ computation\nreduction, with only minor visual quality degradation, compared with ESRGAN.\nEmpirical studies also show $\\sim$\\textbf{70} milliseconds latency on Qualcomm\nSnapdragon 865 chipset.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 09:04:30 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Cheng", "Wenlong", ""], ["Zhao", "Mingbo", ""], ["Ye", "Zhiling", ""], ["Gu", "Shuhang", ""]]}, {"id": "2107.12685", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Csaba Szepesv\\'ari, Omar Rivasplata, Amal\n  Rannen-Triki, Razvan Pascanu", "title": "On the Role of Optimization in Double Descent: A Least Squares Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirically it has been observed that the performance of deep neural networks\nsteadily improves as we increase model size, contradicting the classical view\non overfitting and generalization. Recently, the double descent phenomena has\nbeen proposed to reconcile this observation with theory, suggesting that the\ntest error has a second descent when the model becomes sufficiently\noverparameterized, as the model size itself acts as an implicit regularizer. In\nthis paper we add to the growing body of work in this space, providing a\ncareful study of learning dynamics as a function of model size for the least\nsquares scenario. We show an excess risk bound for the gradient descent\nsolution of the least squares objective. The bound depends on the smallest\nnon-zero eigenvalue of the covariance matrix of the input features, via a\nfunctional form that has the double descent behavior. This gives a new\nperspective on the double descent curves reported in the literature. Our\nanalysis of the excess risk allows to decouple the effect of optimization and\ngeneralization error. In particular, we find that in case of noiseless\nregression, double descent is explained solely by optimization-related\nquantities, which was missed in studies focusing on the Moore-Penrose\npseudoinverse solution. We believe that our derivation provides an alternative\nview compared to existing work, shedding some light on a possible cause of this\nphenomena, at least in the considered least squares setting. We empirically\nexplore if our predictions hold for neural networks, in particular whether the\ncovariance of intermediary hidden activations has a similar behavior as the one\npredicted by our derivations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 09:13:11 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Szepesv\u00e1ri", "Csaba", ""], ["Rivasplata", "Omar", ""], ["Rannen-Triki", "Amal", ""], ["Pascanu", "Razvan", ""]]}, {"id": "2107.12698", "submitter": "Maurizio Pierini", "authors": "Eric A. Moreno and Jean-Roch Vlimant and Maria Spiropulu and\n  Bartlomiej Borzyszkowski and Maurizio Pierini", "title": "Source-Agnostic Gravitational-Wave Detection with Recurrent Autoencoders", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "gr-qc astro-ph.IM cs.LG physics.data-an physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an application of anomaly detection techniques based on deep\nrecurrent autoencoders to the problem of detecting gravitational wave signals\nin laser interferometers. Trained on noise data, this class of algorithms could\ndetect signals using an unsupervised strategy, i.e., without targeting a\nspecific kind of source. We develop a custom architecture to analyze the data\nfrom two interferometers. We compare the obtained performance to that obtained\nwith other autoencoder architectures and with a convolutional classifier. The\nunsupervised nature of the proposed strategy comes with a cost in terms of\naccuracy, when compared to more traditional supervised techniques. On the other\nhand, there is a qualitative gain in generalizing the experimental sensitivity\nbeyond the ensemble of pre-computed signal templates. The recurrent autoencoder\noutperforms other autoencoders based on different architectures. The class of\nrecurrent autoencoders presented in this paper could complement the search\nstrategy employed for gravitational wave detection and extend the reach of the\nongoing detection campaigns.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 09:56:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Moreno", "Eric A.", ""], ["Vlimant", "Jean-Roch", ""], ["Spiropulu", "Maria", ""], ["Borzyszkowski", "Bartlomiej", ""], ["Pierini", "Maurizio", ""]]}, {"id": "2107.12706", "submitter": "Tanmoy Dam", "authors": "Tanmoy Dam, Sreenatha G. Anavatti, Hussein A. Abbass (Fellow,\n  IEEESchool of Engineering and Information Technology, University of New South\n  Wales Canberra, Australia)", "title": "Improving ClusterGAN Using Self-AugmentedInformation Maximization of\n  Disentangling LatentSpaces", "comments": "This paper is under review to IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Latent Space Clustering in Generative adversarial networks (ClusterGAN)\nmethod has been successful with high-dimensional data. However, the method\nassumes uniformlydistributed priors during the generation of modes, which isa\nrestrictive assumption in real-world data and cause loss ofdiversity in the\ngenerated modes. In this paper, we proposeself-augmentation information\nmaximization improved Clus-terGAN (SIMI-ClusterGAN) to learn the distinctive\npriorsfrom the data. The proposed SIMI-ClusterGAN consists offour deep neural\nnetworks: self-augmentation prior network,generator, discriminator and\nclustering inference autoencoder.The proposed method has been validated using\nseven bench-mark data sets and has shown improved performance overstate-of-the\nart methods. To demonstrate the superiority ofSIMI-ClusterGAN performance on\nimbalanced dataset, wehave discussed two imbalanced conditions on MNIST\ndatasetswith one-class imbalance and three classes imbalanced cases.The results\nhighlight the advantages of SIMI-ClusterGAN.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 10:04:32 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Dam", "Tanmoy", "", "Fellow,\n  IEEESchool of Engineering and Information Technology, University of New South\n  Wales Canberra, Australia"], ["Anavatti", "Sreenatha G.", "", "Fellow,\n  IEEESchool of Engineering and Information Technology, University of New South\n  Wales Canberra, Australia"], ["Abbass", "Hussein A.", "", "Fellow,\n  IEEESchool of Engineering and Information Technology, University of New South\n  Wales Canberra, Australia"]]}, {"id": "2107.12723", "submitter": "Dominic Richards", "authors": "Dominic Richards, Ilja Kuzborskij", "title": "Stability & Generalisation of Gradient Descent for Shallow Neural\n  Networks without the Neural Tangent Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit on-average algorithmic stability of Gradient Descent (GD) for\ntraining overparameterised shallow neural networks and prove new generalisation\nand excess risk bounds without the Neural Tangent Kernel (NTK) or\nPolyak-{\\L}ojasiewicz (PL) assumptions. In particular, we show oracle type\nbounds which reveal that the generalisation and excess risk of GD is controlled\nby an interpolating network with the shortest GD path from initialisation (in a\nsense, an interpolating network with the smallest relative norm). While this\nwas known for kernelised interpolants, our proof applies directly to networks\ntrained by GD without intermediate kernelisation. At the same time, by relaxing\noracle inequalities developed here we recover existing NTK-based risk bounds in\na straightforward way, which demonstrates that our analysis is tighter.\nFinally, unlike most of the NTK-based analyses we focus on regression with\nlabel noise and show that GD with early stopping is consistent.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 10:53:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Richards", "Dominic", ""], ["Kuzborskij", "Ilja", ""]]}, {"id": "2107.12734", "submitter": "Ralf Raumanns", "authors": "Ralf Raumanns, Gerard Schouten, Max Joosten, Josien P. W. Pluim and\n  Veronika Cheplygina", "title": "ENHANCE (ENriching Health data by ANnotations of Crowd and Experts): A\n  case study for skin lesion classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present ENHANCE, an open dataset with multiple annotations to complement\nthe existing ISIC and PH2 skin lesion classification datasets. This dataset\ncontains annotations of visual ABC (asymmetry, border, colour) features from\nnon-expert annotation sources: undergraduate students, crowd workers from\nAmazon MTurk and classic image processing algorithms. In this paper we first\nanalyse the correlations between the annotations and the diagnostic label of\nthe lesion, as well as study the agreement between different annotation\nsources. Overall we find weak correlations of non-expert annotations with the\ndiagnostic label, and low agreement between different annotation sources. We\nthen study multi-task learning (MTL) with the annotations as additional labels,\nand show that non-expert annotations can improve (ensembles of)\nstate-of-the-art convolutional neural networks via MTL. We hope that our\ndataset can be used in further research into multiple annotations and/or MTL.\nAll data and models are available on Github:\nhttps://github.com/raumannsr/ENHANCE.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 11:23:33 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Raumanns", "Ralf", ""], ["Schouten", "Gerard", ""], ["Joosten", "Max", ""], ["Pluim", "Josien P. W.", ""], ["Cheplygina", "Veronika", ""]]}, {"id": "2107.12770", "submitter": "Lorenzo Menculini", "authors": "Lorenzo Menculini, Andrea Marini, Massimiliano Proietti, Alberto\n  Garinei, Alessio Bozza, Cecilia Moretti, Marcello Marconi", "title": "Comparing Prophet and Deep Learning to ARIMA in Forecasting Wholesale\n  Food Prices", "comments": "15 pages, 6 figures, 10 tables. v2: changed some words in abstract,\n  typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Setting sale prices correctly is of great importance for firms, and the study\nand forecast of prices time series is therefore a relevant topic not only from\na data science perspective but also from an economic and applicative one. In\nthis paper we examine different techniques to forecast the sale prices of three\nfood products applied by an Italian food wholesaler, as a step towards the\nautomation of pricing tasks usually taken care by human workforce. We consider\nARIMA models and compare them to Prophet, a scalable forecasting tool developed\nby Facebook and based on a generalized additive model, and to deep learning\nmodels based on Long Short--Term Memory (LSTM) and Convolutional Neural\nNetworks (CNNs). ARIMA models are frequently used in econometric analyses,\nproviding a good benchmark for the problem under study. Our results indicate\nthat ARIMA performs similarly to LSTM neural networks for the forecasting task\nunder consideration, while the combination of CNNs and LSTMs attains the best\noverall accuracy, but requires more time to be tuned. On the contrary, Prophet\nis very fast to use, but less accurate.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 15:13:31 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 15:53:51 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Menculini", "Lorenzo", ""], ["Marini", "Andrea", ""], ["Proietti", "Massimiliano", ""], ["Garinei", "Alberto", ""], ["Bozza", "Alessio", ""], ["Moretti", "Cecilia", ""], ["Marconi", "Marcello", ""]]}, {"id": "2107.12775", "submitter": "Ilker Hacihaliloglu", "authors": "Hui Che, Sumana Ramanathan, David Foran, John L Nosher, Vishal M\n  Patel, Ilker Hacihaliloglu", "title": "Realistic Ultrasound Image Synthesis for Improved Classification of\n  Liver Disease", "comments": "Accepted for presentation at the 2021 MICCAI-International Workshop\n  of Advances in Simplifying Medical UltraSound (ASMUS2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the success of deep learning-based methods applied in medical image\nanalysis, convolutional neural networks (CNNs) have been investigated for\nclassifying liver disease from ultrasound (US) data. However, the scarcity of\navailable large-scale labeled US data has hindered the success of CNNs for\nclassifying liver disease from US data. In this work, we propose a novel\ngenerative adversarial network (GAN) architecture for realistic diseased and\nhealthy liver US image synthesis. We adopt the concept of stacking to\nsynthesize realistic liver US data. Quantitative and qualitative evaluation is\nperformed on 550 in-vivo B-mode liver US images collected from 55 subjects. We\nalso show that the synthesized images, together with real in vivo data, can be\nused to significantly improve the performance of traditional CNN architectures\nfor Nonalcoholic fatty liver disease (NAFLD) classification.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 12:37:19 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Che", "Hui", ""], ["Ramanathan", "Sumana", ""], ["Foran", "David", ""], ["Nosher", "John L", ""], ["Patel", "Vishal M", ""], ["Hacihaliloglu", "Ilker", ""]]}, {"id": "2107.12780", "submitter": "Bing Yao", "authors": "Jianxin Xie, Bing Yao", "title": "Physics-constrained Deep Learning for Robust Inverse ECG Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid developments in advanced sensing and imaging bring about a\ndata-rich environment, facilitating the effective modeling, monitoring, and\ncontrol of complex systems. For example, the body-sensor network captures\nmulti-channel information pertinent to the electrical activity of the heart\n(i.e., electrocardiograms (ECG)), which enables medical scientists to monitor\nand detect abnormal cardiac conditions. However, the high-dimensional sensing\ndata are generally complexly structured and realizing the full data potential\ndepends to a great extent on advanced analytical and predictive methods. This\npaper presents a physics-constrained deep learning (P-DL) framework for\nhigh-dimensional inverse ECG modeling. This method integrates the physical laws\nof the complex system with the advanced deep learning infrastructure for\neffective prediction of the system dynamics. The proposed P-DL approach is\nimplemented to solve the inverse ECG model and predict the time-varying\ndistribution of electric potentials in the heart from the ECG data measured by\nthe body-surface sensor network. Experimental results show that the proposed\nP-DL method significantly outperforms existing methods that are commonly used\nin current practice.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 01:30:41 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Xie", "Jianxin", ""], ["Yao", "Bing", ""]]}, {"id": "2107.12783", "submitter": "Drona Khurana", "authors": "Drona Khurana, Srinivasan Ravichandran, Sparsh Jain, Narayanan Unny\n  Edakunni", "title": "Statistical Guarantees for Fairness Aware Plug-In Algorithms", "comments": "This paper was accepted at the workshop on Socially Responsible\n  Machine Learning, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plug-in algorithm to estimate Bayes Optimal Classifiers for fairness-aware\nbinary classification has been proposed in (Menon & Williamson, 2018). However,\nthe statistical efficacy of their approach has not been established. We prove\nthat the plug-in algorithm is statistically consistent. We also derive finite\nsample guarantees associated with learning the Bayes Optimal Classifiers via\nthe plug-in algorithm. Finally, we propose a protocol that modifies the plug-in\napproach, so as to simultaneously guarantee fairness and differential privacy\nwith respect to a binary feature deemed sensitive.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 12:51:33 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Khurana", "Drona", ""], ["Ravichandran", "Srinivasan", ""], ["Jain", "Sparsh", ""], ["Edakunni", "Narayanan Unny", ""]]}, {"id": "2107.12791", "submitter": "Mark Stamp", "authors": "Ruchira Gothankar, Fabio Di Troia, Mark Stamp", "title": "Clickbait Detection in YouTube Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  YouTube videos often include captivating descriptions and intriguing\nthumbnails designed to increase the number of views, and thereby increase the\nrevenue for the person who posted the video. This creates an incentive for\npeople to post clickbait videos, in which the content might deviate\nsignificantly from the title, description, or thumbnail. In effect, users are\ntricked into clicking on clickbait videos. In this research, we consider the\nchallenging problem of detecting clickbait YouTube videos. We experiment with\nmultiple state-of-the-art machine learning techniques using a variety of\ntextual features.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:39:32 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Gothankar", "Ruchira", ""], ["Di Troia", "Fabio", ""], ["Stamp", "Mark", ""]]}, {"id": "2107.12794", "submitter": "Guangchun Ruan", "authors": "Yuyun Yang, Zhenfei Tan, Haitao Yang, Guangchun Ruan, Haiwang Zhong", "title": "Short-Term Electricity Price Forecasting based on Graph Convolution\n  Network and Attention Mechanism", "comments": "Submitted to IET RPG. 9 pages, 15 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In electricity markets, locational marginal price (LMP) forecasting is\nparticularly important for market participants in making reasonable bidding\nstrategies, managing potential trading risks, and supporting efficient system\nplanning and operation. Unlike existing methods that only consider LMPs'\ntemporal features, this paper tailors a spectral graph convolutional network\n(GCN) to greatly improve the accuracy of short-term LMP forecasting. A\nthree-branch network structure is then designed to match the structure of LMPs'\ncompositions. Such kind of network can extract the spatial-temporal features of\nLMPs, and provide fast and high-quality predictions for all nodes\nsimultaneously. The attention mechanism is also implemented to assign varying\nimportance weights between different nodes and time slots. Case studies based\non the IEEE-118 test system and real-world data from the PJM validate that the\nproposed model outperforms existing forecasting models in accuracy, and\nmaintains a robust performance by avoiding extreme errors.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 15:44:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yang", "Yuyun", ""], ["Tan", "Zhenfei", ""], ["Yang", "Haitao", ""], ["Ruan", "Guangchun", ""], ["Zhong", "Haiwang", ""]]}, {"id": "2107.12797", "submitter": "Michael Kepler Jr", "authors": "Michael E. Kepler, Alec Koppel, Amrit Singh Bedi, and Daniel J.\n  Stilwell", "title": "Wasserstein-Splitting Gaussian Process Regression for Heterogeneous\n  Online Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian processes (GPs) are a well-known nonparametric Bayesian inference\ntechnique, but they suffer from scalability problems for large sample sizes,\nand their performance can degrade for non-stationary or spatially heterogeneous\ndata. In this work, we seek to overcome these issues through (i) employing\nvariational free energy approximations of GPs operating in tandem with online\nexpectation propagation steps; and (ii) introducing a local splitting step\nwhich instantiates a new GP whenever the posterior distribution changes\nsignificantly as quantified by the Wasserstein metric over posterior\ndistributions. Over time, then, this yields an ensemble of sparse GPs which may\nbe updated incrementally, and adapts to locality, heterogeneity, and\nnon-stationarity in training data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:52:46 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kepler", "Michael E.", ""], ["Koppel", "Alec", ""], ["Bedi", "Amrit Singh", ""], ["Stilwell", "Daniel J.", ""]]}, {"id": "2107.12800", "submitter": "Othmane Laousy", "authors": "Othmane Laousy, Guillaume Chassagnon, Edouard Oyallon, Nikos Paragios,\n  Marie-Pierre Revel, Maria Vakalopoulou", "title": "Deep Reinforcement Learning for L3 Slice Localization in Sarcopenia\n  Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sarcopenia is a medical condition characterized by a reduction in muscle mass\nand function. A quantitative diagnosis technique consists of localizing the CT\nslice passing through the middle of the third lumbar area (L3) and segmenting\nmuscles at this level. In this paper, we propose a deep reinforcement learning\nmethod for accurate localization of the L3 CT slice. Our method trains a\nreinforcement learning agent by incentivizing it to discover the right\nposition. Specifically, a Deep Q-Network is trained to find the best policy to\nfollow for this problem. Visualizing the training process shows that the agent\nmimics the scrolling of an experienced radiologist. Extensive experiments\nagainst other state-of-the-art deep learning based methods for L3 localization\nprove the superiority of our technique which performs well even with limited\namount of data and annotations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:15:42 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Laousy", "Othmane", ""], ["Chassagnon", "Guillaume", ""], ["Oyallon", "Edouard", ""], ["Paragios", "Nikos", ""], ["Revel", "Marie-Pierre", ""], ["Vakalopoulou", "Maria", ""]]}, {"id": "2107.12801", "submitter": "Weiming Xiang", "authors": "Yejiang Yang, Weiming Xiang", "title": "Robust Optimization Framework for Training Shallow Neural Networks Using\n  Reachability Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, a robust optimization framework is developed to train shallow\nneural networks based on reachability analysis of neural networks. To\ncharacterize noises of input data, the input training data is disturbed in the\ndescription of interval sets. Interval-based reachability analysis is then\nperformed for the hidden layer. With the reachability analysis results, a\nrobust optimization training method is developed in the framework of robust\nleast-square problems. Then, the developed robust least-square problem is\nrelaxed to a semidefinite programming problem. It has been shown that the\ndeveloped robust learning method can provide better robustness against\nperturbations at the price of loss of training accuracy to some extent. At\nlast, the proposed method is evaluated on a robot arm model learning example.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:16:20 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yang", "Yejiang", ""], ["Xiang", "Weiming", ""]]}, {"id": "2107.12808", "submitter": "Wojciech Czarnecki", "authors": "Open-Ended Learning Team, Adam Stooke, Anuj Mahajan, Catarina Barros,\n  Charlie Deck, Jakob Bauer, Jakub Sygnowski, Maja Trebacz, Max Jaderberg,\n  Michael Mathieu, Nat McAleese, Nathalie Bradley-Schmieg, Nathaniel Wong,\n  Nicolas Porcel, Roberta Raileanu, Steph Hughes-Fitt, Valentin Dalibard,\n  Wojciech Marian Czarnecki", "title": "Open-Ended Learning Leads to Generally Capable Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we create agents that can perform well beyond a single,\nindividual task, that exhibit much wider generalisation of behaviour to a\nmassive, rich space of challenges. We define a universe of tasks within an\nenvironment domain and demonstrate the ability to train agents that are\ngenerally capable across this vast space and beyond. The environment is\nnatively multi-agent, spanning the continuum of competitive, cooperative, and\nindependent games, which are situated within procedurally generated physical 3D\nworlds. The resulting space is exceptionally diverse in terms of the challenges\nposed to agents, and as such, even measuring the learning progress of an agent\nis an open research problem. We propose an iterative notion of improvement\nbetween successive generations of agents, rather than seeking to maximise a\nsingular objective, allowing us to quantify progress despite tasks being\nincomparable in terms of achievable rewards. We show that through constructing\nan open-ended learning process, which dynamically changes the training task\ndistributions and training objectives such that the agent never stops learning,\nwe achieve consistent learning of new behaviours. The resulting agent is able\nto score reward in every one of our humanly solvable evaluation levels, with\nbehaviour generalising to many held-out points in the universe of tasks.\nExamples of this zero-shot generalisation include good performance on Hide and\nSeek, Capture the Flag, and Tag. Through analysis and hand-authored probe tasks\nwe characterise the behaviour of our agent, and find interesting emergent\nheuristic behaviours such as trial-and-error experimentation, simple tool use,\noption switching, and cooperation. Finally, we demonstrate that the general\ncapabilities of this agent could unlock larger scale transfer of behaviour\nthrough cheap finetuning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:30:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ended Learning Team", "", ""], ["Stooke", "Adam", ""], ["Mahajan", "Anuj", ""], ["Barros", "Catarina", ""], ["Deck", "Charlie", ""], ["Bauer", "Jakob", ""], ["Sygnowski", "Jakub", ""], ["Trebacz", "Maja", ""], ["Jaderberg", "Max", ""], ["Mathieu", "Michael", ""], ["McAleese", "Nat", ""], ["Bradley-Schmieg", "Nathalie", ""], ["Wong", "Nathaniel", ""], ["Porcel", "Nicolas", ""], ["Raileanu", "Roberta", ""], ["Hughes-Fitt", "Steph", ""], ["Dalibard", "Valentin", ""], ["Czarnecki", "Wojciech Marian", ""]]}, {"id": "2107.12809", "submitter": "Mimi Zhang Dr", "authors": "Mimi Zhang, Andrew Parnell, Dermot Brabazon, Alessio Benavoli", "title": "Bayesian Optimisation for Sequential Experimental Design with\n  Applications in Additive Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Bayesian optimization (BO) is an approach to globally optimizing black-box\nobjective functions that are expensive to evaluate. BO-powered experimental\ndesign has found wide application in materials science, chemistry, experimental\nphysics, drug development, etc. This work aims to bring attention to the\nbenefits of applying BO in designing experiments and to provide a BO manual,\ncovering both methodology and software, for the convenience of anyone who wants\nto apply or learn BO. In particular, we briefly explain the BO technique,\nreview all the applications of BO in additive manufacturing, compare and\nexemplify the features of different open BO libraries, unlock new potential\napplications of BO to other types of data (e.g., preferential output). This\narticle is aimed at readers with some understanding of Bayesian methods, but\nnot necessarily with knowledge of additive manufacturing; the software\nperformance overview and implementation instructions are instrumental for any\nexperimental-design practitioner. Moreover, our review in the field of additive\nmanufacturing highlights the current knowledge and technological trends of BO.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:30:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhang", "Mimi", ""], ["Parnell", "Andrew", ""], ["Brabazon", "Dermot", ""], ["Benavoli", "Alessio", ""]]}, {"id": "2107.12824", "submitter": "Hiroki Matsutani", "authors": "Hiroki Kawakami, Hirohisa Watanabe, Keisuke Sugiura, Hiroki Matsutani", "title": "A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge\n  Domain Adaptation on FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although high-performance deep neural networks are in high demand in edge\nenvironments, computation resources are strictly limited in edge devices, and\nlight-weight neural network techniques, such as Depthwise Separable Convolution\n(DSC), have been developed. ResNet is one of conventional deep neural network\nmodels that stack a lot of layers and parameters for a higher accuracy. To\nreduce the parameter size of ResNet, by utilizing a similarity to ODE (Ordinary\nDifferential Equation), Neural ODE repeatedly uses most of weight parameters\ninstead of having a lot of different parameters. Thus, Neural ODE becomes\nsignificantly small compared to that of ResNet so that it can be implemented in\nresource-limited edge devices. In this paper, a combination of Neural ODE and\nDSC, called dsODENet, is designed and implemented for FPGAs (Field-Programmable\nGate Arrays). dsODENet is then applied to edge domain adaptation as a practical\nuse case and evaluated with image classification datasets. It is implemented on\nXilinx ZCU104 board and evaluated in terms of domain adaptation accuracy,\ntraining speed, FPGA resource utilization, and speedup rate compared to a\nsoftware execution. The results demonstrate that dsODENet is comparable to or\nslightly better than our baseline Neural ODE implementation in terms of domain\nadaptation accuracy, while the total parameter size without pre- and\npost-processing layers is reduced by 54.2% to 79.8%. The FPGA implementation\naccelerates the prediction tasks by 27.9 times faster than a software\nimplementation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:44:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kawakami", "Hiroki", ""], ["Watanabe", "Hirohisa", ""], ["Sugiura", "Keisuke", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "2107.12825", "submitter": "Guillaume Ausset", "authors": "Guillaume Ausset, Tom Ciffreo, Francois Portier, Stephan\n  Cl\\'emen\\c{c}on, Timoth\\'ee Papin", "title": "Individual Survival Curves with Conditional Normalizing Flows", "comments": "IEEE DSAA '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Survival analysis, or time-to-event modelling, is a classical statistical\nproblem that has garnered a lot of interest for its practical use in\nepidemiology, demographics or actuarial sciences. Recent advances on the\nsubject from the point of view of machine learning have been concerned with\nprecise per-individual predictions instead of population studies, driven by the\nrise of individualized medicine. We introduce here a conditional normalizing\nflow based estimate of the time-to-event density as a way to model highly\nflexible and individualized conditional survival distributions. We use a novel\nhierarchical formulation of normalizing flows to enable efficient fitting of\nflexible conditional distributions without overfitting and show how the\nnormalizing flow formulation can be efficiently adapted to the censored\nsetting. We experimentally validate the proposed approach on a synthetic\ndataset as well as four open medical datasets and an example of a common\nfinancial problem.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:45:12 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ausset", "Guillaume", ""], ["Ciffreo", "Tom", ""], ["Portier", "Francois", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""], ["Papin", "Timoth\u00e9e", ""]]}, {"id": "2107.12826", "submitter": "Patrik Joslin Kenfack", "authors": "Patrik Joslin Kenfack, Adil Mehmood Khan, Rasheed Hussain, S.M. Ahsan\n  Kazmi,", "title": "Adversarial Stacked Auto-Encoders for Fair Representation Learning", "comments": "ICML2021 ML4data Workshop Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training machine learning models with the only accuracy as a final goal may\npromote prejudices and discriminatory behaviors embedded in the data. One\nsolution is to learn latent representations that fulfill specific fairness\nmetrics. Different types of learning methods are employed to map data into the\nfair representational space. The main purpose is to learn a latent\nrepresentation of data that scores well on a fairness metric while maintaining\nthe usability for the downstream task. In this paper, we propose a new fair\nrepresentation learning approach that leverages different levels of\nrepresentation of data to tighten the fairness bounds of the learned\nrepresentation. Our results show that stacking different auto-encoders and\nenforcing fairness at different latent spaces result in an improvement of\nfairness compared to other existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 13:49:18 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kenfack", "Patrik Joslin", ""], ["Khan", "Adil Mehmood", ""], ["Hussain", "Rasheed", ""], ["Kazmi", "S. M. Ahsan", ""]]}, {"id": "2107.12838", "submitter": "Fuad Noman", "authors": "Fuad Noman, Chee-Ming Ting, Hakmook Kang, Raphael C.-W. Phan, Brian D.\n  Boyd, Warren D. Taylor, and Hernando Ombao", "title": "Graph Autoencoders for Embedding Learning in Brain Networks and Major\n  Depressive Disorder Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Brain functional connectivity (FC) reveals biomarkers for identification of\nvarious neuropsychiatric disorders. Recent application of deep neural networks\n(DNNs) to connectome-based classification mostly relies on traditional\nconvolutional neural networks using input connectivity matrices on a regular\nEuclidean grid. We propose a graph deep learning framework to incorporate the\nnon-Euclidean information about graph structure for classifying functional\nmagnetic resonance imaging (fMRI)- derived brain networks in major depressive\ndisorder (MDD). We design a novel graph autoencoder (GAE) architecture based on\nthe graph convolutional networks (GCNs) to embed the topological structure and\nnode content of large-sized fMRI networks into low-dimensional latent\nrepresentations. In network construction, we employ the Ledoit-Wolf (LDW)\nshrinkage method to estimate the high-dimensional FC metrics efficiently from\nfMRI data. We consider both supervised and unsupervised approaches for the\ngraph embedded learning. The learned embeddings are then used as feature inputs\nfor a deep fully-connected neural network (FCNN) to discriminate MDD from\nhealthy controls. Evaluated on a resting-state fMRI MDD dataset with 43\nsubjects, results show that the proposed GAE-FCNN model significantly\noutperforms several state-of-the-art DNN methods for brain connectome\nclassification, achieving accuracy of 72.50% using the LDW-FC metrics as node\nfeatures. The graph embeddings of fMRI FC networks learned by the GAE also\nreveal apparent group differences between MDD and HC. Our new framework\ndemonstrates feasibility of learning graph embeddings on brain networks to\nprovide discriminative information for diagnosis of brain disorders.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:12:39 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Noman", "Fuad", ""], ["Ting", "Chee-Ming", ""], ["Kang", "Hakmook", ""], ["Phan", "Raphael C. -W.", ""], ["Boyd", "Brian D.", ""], ["Taylor", "Warren D.", ""], ["Ombao", "Hernando", ""]]}, {"id": "2107.12847", "submitter": "Srikrishna Karanam", "authors": "Runze Li and Srikrishna Karanam and Ren Li and Terrence Chen and Bir\n  Bhanu and Ziyan Wu", "title": "Learning Local Recurrent Models for Human Mesh Recovery", "comments": "10 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating frame-level full human body meshes\ngiven a video of a person with natural motion dynamics. While much progress in\nthis field has been in single image-based mesh estimation, there has been a\nrecent uptick in efforts to infer mesh dynamics from video given its role in\nalleviating issues such as depth ambiguity and occlusions. However, a key\nlimitation of existing work is the assumption that all the observed motion\ndynamics can be modeled using one dynamical/recurrent model. While this may\nwork well in cases with relatively simplistic dynamics, inference with\nin-the-wild videos presents many challenges. In particular, it is typically the\ncase that different body parts of a person undergo different dynamics in the\nvideo, e.g., legs may move in a way that may be dynamically different from\nhands (e.g., a person dancing). To address these issues, we present a new\nmethod for video mesh recovery that divides the human mesh into several local\nparts following the standard skeletal model. We then model the dynamics of each\nlocal part with separate recurrent models, with each model conditioned\nappropriately based on the known kinematic structure of the human body. This\nresults in a structure-informed local recurrent learning architecture that can\nbe trained in an end-to-end fashion with available annotations. We conduct a\nvariety of experiments on standard video mesh recovery benchmark datasets such\nas Human3.6M, MPI-INF-3DHP, and 3DPW, demonstrating the efficacy of our design\nof modeling local dynamics as well as establishing state-of-the-art results\nbased on standard evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:30:33 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Li", "Runze", ""], ["Karanam", "Srikrishna", ""], ["Li", "Ren", ""], ["Chen", "Terrence", ""], ["Bhanu", "Bir", ""], ["Wu", "Ziyan", ""]]}, {"id": "2107.12855", "submitter": "Florian Jaeckle", "authors": "Florian Jaeckle and Jingyue Lu and M. Pawan Kumar", "title": "Neural Network Branch-and-Bound for Neural Network Verification", "comments": "arXiv admin note: substantial text overlap with arXiv:1912.01329", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many available formal verification methods have been shown to be instances of\na unified Branch-and-Bound (BaB) formulation. We propose a novel machine\nlearning framework that can be used for designing an effective branching\nstrategy as well as for computing better lower bounds. Specifically, we learn\ntwo graph neural networks (GNN) that both directly treat the network we want to\nverify as a graph input and perform forward-backward passes through the GNN\nlayers. We use one GNN to simulate the strong branching heuristic behaviour and\nanother to compute a feasible dual solution of the convex relaxation, thereby\nproviding a valid lower bound.\n  We provide a new verification dataset that is more challenging than those\nused in the literature, thereby providing an effective alternative for testing\nalgorithmic improvements for verification. Whilst using just one of the GNNs\nleads to a reduction in verification time, we get optimal performance when\ncombining the two GNN approaches. Our combined framework achieves a 50\\%\nreduction in both the number of branches and the time required for verification\non various convolutional networks when compared to several state-of-the-art\nverification methods. In addition, we show that our GNN models generalize well\nto harder properties on larger unseen networks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:42:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Jaeckle", "Florian", ""], ["Lu", "Jingyue", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "2107.12869", "submitter": "Quan Duong", "authors": "Quan Duong, Tan Tran, Duc-Thinh Pham, An Mai", "title": "A Simplified Framework for Air Route Clustering Based on ADS-B Data", "comments": null, "journal-ref": "2019 IEEE-RIVF International Conference on Computing and\n  Communication Technologies (RIVF)", "doi": "10.1109/RIVF.2019.8713685", "report-no": null, "categories": "physics.soc-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The volume of flight traffic gets increasing over the time, which makes the\nstrategic traffic flow management become one of the challenging problems since\nit requires a lot of computational resources to model entire traffic data. On\nthe other hand, Automatic Dependent Surveillance - Broadcast (ADS-B) technology\nhas been considered as a promising data technology to provide both flight crews\nand ground control staff the necessary information safely and efficiently about\nthe position and velocity of the airplanes in a specific area. In the attempt\nto tackle this problem, we presented in this paper a simplified framework that\ncan support to detect the typical air routes between airports based on ADS-B\ndata. Specifically, the flight traffic will be classified into major groups\nbased on similarity measures, which helps to reduce the number of flight paths\nbetween airports. As a matter of fact, our framework can be taken into account\nto reduce practically the computational cost for air flow optimization and\nevaluate the operational performance. Finally, in order to illustrate the\npotential applications of our proposed framework, an experiment was performed\nusing ADS-B traffic flight data of three different pairs of airports. The\ndetected typical routes between each couple of airports show promising results\nby virtue of combining two indices for measuring the clustering performance and\nincorporating human judgment into the visual inspection.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 08:55:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Duong", "Quan", ""], ["Tran", "Tan", ""], ["Pham", "Duc-Thinh", ""], ["Mai", "An", ""]]}, {"id": "2107.12871", "submitter": "Eric Squires", "authors": "Eric Squires, Rohit Konda, Samuel Coogan, Magnus Egerstedt", "title": "Model Free Barrier Functions via Implicit Evading Maneuvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates that in some cases the safety override arising from\nthe use of a barrier function can be needlessly restrictive. In particular, we\nexamine the case of fixed wing collision avoidance and show that when using a\nbarrier function, there are cases where two fixed wing aircraft can come closer\nto colliding than if there were no barrier function at all. In addition, we\nconstruct cases where the barrier function labels the system as unsafe even\nwhen the vehicles start arbitrarily far apart. In other words, the barrier\nfunction ensures safety but with unnecessary costs to performance. We therefore\nintroduce model free barrier functions which take a data driven approach to\ncreating a barrier function. We demonstrate the effectiveness of model free\nbarrier functions in a collision avoidance simulation of two fixed-wing\naircraft.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 15:13:25 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Squires", "Eric", ""], ["Konda", "Rohit", ""], ["Coogan", "Samuel", ""], ["Egerstedt", "Magnus", ""]]}, {"id": "2107.12878", "submitter": "Shanmukh Alle", "authors": "Shanmukh Alle and U. Deva Priyakumar", "title": "Linear Prediction Residual for Efficient Diagnosis of Parkinson's\n  Disease from Gait", "comments": "11 pages, 4 figures, 2 tables, 4 equations, 23 citations, to be\n  published in Medical Image Computing and Computer Assisted Intervention\n  (MICCAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Parkinson's Disease (PD) is a chronic and progressive neurological disorder\nthat results in rigidity, tremors and postural instability. There is no\ndefinite medical test to diagnose PD and diagnosis is mostly a clinical\nexercise. Although guidelines exist, about 10-30% of the patients are wrongly\ndiagnosed with PD. Hence, there is a need for an accurate, unbiased and fast\nmethod for diagnosis. In this study, we propose LPGNet, a fast and accurate\nmethod to diagnose PD from gait. LPGNet uses Linear Prediction Residuals (LPR)\nto extract discriminating patterns from gait recordings and then uses a 1D\nconvolution neural network with depth-wise separable convolutions to perform\ndiagnosis. LPGNet achieves an AUC of 0.91 with a 21 times speedup and about 99%\nlesser parameters in the model compared to the state of the art. We also\nundertake an analysis of various cross-validation strategies used in literature\nin PD diagnosis from gait and find that most methods are affected by some form\nof data leakage between various folds which leads to unnecessarily large models\nand inflated performance due to overfitting. The analysis clears the path for\nfuture works in correctly evaluating their methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 20:23:54 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Alle", "Shanmukh", ""], ["Priyakumar", "U. Deva", ""]]}, {"id": "2107.12889", "submitter": "Banafshe Felfeliyan", "authors": "Banafshe Felfeliyan, Abhilash Hareendranathan, Gregor Kuntze, Jacob L.\n  Jaremko, Janet L. Ronsky", "title": "Improved-Mask R-CNN: Towards an Accurate Generic MSK MRI instance\n  segmentation platform (Data from the Osteoarthritis Initiative)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective assessment of Magnetic Resonance Imaging (MRI) scans of\nosteoarthritis (OA) can address the limitation of the current OA assessment.\nSegmentation of bone, cartilage, and joint fluid is necessary for the OA\nobjective assessment. Most of the proposed segmentation methods are not\nperforming instance segmentation and suffer from class imbalance problems. This\nstudy deployed Mask R-CNN instance segmentation and improved it (improved-Mask\nR-CNN (iMaskRCNN)) to obtain a more accurate generalized segmentation for\nOA-associated tissues. Training and validation of the method were performed\nusing 500 MRI knees from the Osteoarthritis Initiative (OAI) dataset and 97 MRI\nscans of patients with symptomatic hip OA. Three modifications to Mask R-CNN\nyielded the iMaskRCNN: adding a 2nd ROIAligned block, adding an extra decoder\nlayer to the mask-header, and connecting them by a skip connection. The results\nwere assessed using Hausdorff distance, dice score, and coefficients of\nvariation (CoV). The iMaskRCNN led to improved bone and cartilage segmentation\ncompared to Mask RCNN as indicated with the increase in dice score from 95% to\n98% for the femur, 95% to 97% for tibia, 71% to 80% for femoral cartilage, and\n81% to 82% for tibial cartilage. For the effusion detection, dice improved with\niMaskRCNN 72% versus MaskRCNN 71%. The CoV values for effusion detection\nbetween Reader1 and Mask R-CNN (0.33), Reader1 and iMaskRCNN (0.34), Reader2\nand Mask R-CNN (0.22), Reader2 and iMaskRCNN (0.29) are close to CoV between\ntwo readers (0.21), indicating a high agreement between the human readers and\nboth Mask R-CNN and iMaskRCNN. Mask R-CNN and iMaskRCNN can reliably and\nsimultaneously extract different scale articular tissues involved in OA,\nforming the foundation for automated assessment of OA. The iMaskRCNN results\nshow that the modification improved the network performance around the edges.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 15:41:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Felfeliyan", "Banafshe", ""], ["Hareendranathan", "Abhilash", ""], ["Kuntze", "Gregor", ""], ["Jaremko", "Jacob L.", ""], ["Ronsky", "Janet L.", ""]]}, {"id": "2107.12910", "submitter": "Hongpeng Zhou", "authors": "Hongpeng Zhou, Chahine Ibrahim, Wei Xing Zheng, Wei Pan", "title": "Sparse Bayesian Deep Learning for Dynamic System Identification", "comments": "16 pages, 18 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a sparse Bayesian treatment of deep neural networks\n(DNNs) for system identification. Although DNNs show impressive approximation\nability in various fields, several challenges still exist for system\nidentification problems. First, DNNs are known to be too complex that they can\neasily overfit the training data. Second, the selection of the input regressors\nfor system identification is nontrivial. Third, uncertainty quantification of\nthe model parameters and predictions are necessary. The proposed Bayesian\napproach offers a principled way to alleviate the above challenges by marginal\nlikelihood/model evidence approximation and structured group sparsity-inducing\npriors construction. The identification algorithm is derived as an iterative\nregularized optimization procedure that can be solved as efficiently as\ntraining typical DNNs. Furthermore, a practical calculation approach based on\nthe Monte-Carlo integration method is derived to quantify the uncertainty of\nthe parameters and predictions. The effectiveness of the proposed Bayesian\napproach is demonstrated on several linear and nonlinear systems identification\nbenchmarks with achieving good and competitive simulation accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:09:48 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhou", "Hongpeng", ""], ["Ibrahim", "Chahine", ""], ["Zheng", "Wei Xing", ""], ["Pan", "Wei", ""]]}, {"id": "2107.12915", "submitter": "In Ho Cho", "authors": "In Ho Cho", "title": "Initial Foundation for Predicting Individual Earthquake's Location and\n  Magnitude by Using Glass-Box Physics Rule Learner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although researchers accumulated knowledge about seismogenesis and\ndecades-long earthquake data, predicting imminent individual earthquakes at a\nspecific time and location remains a long-standing enigma. This study\nhypothesizes that the observed data conceal the hidden rules which may be\nunraveled by a novel glass-box (as opposed to black-box) physics rule learner\n(GPRL) framework. Without any predefined earthquake-related mechanisms or\nstatistical laws, GPRL's two essentials, convolved information index and\ntransparent link function, seek generic expressions of rules directly from\ndata. GPRL's training with 10-years data appears to identify plausible rules,\nsuggesting a combination of the pseudo power and the pseudo vorticity of\nreleased energy in the lithosphere. Independent feasibility test supports the\npromising role of the unraveled rules in predicting earthquakes' magnitudes and\ntheir specific locations. The identified rules and GPRL are in their infancy\nrequiring substantial improvement. Still, this study hints at the existence of\nthe data-guided hidden pathway to imminent individual earthquake prediction.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:18:02 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Cho", "In Ho", ""]]}, {"id": "2107.12917", "submitter": "Julian Stier", "authors": "Julian Stier, Harshil Darji, Michael Granitzer", "title": "Experiments on Properties of Hidden Structures of Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity in the structure of Neural Networks can lead to less energy\nconsumption, less memory usage, faster computation times on convenient\nhardware, and automated machine learning. If sparsity gives rise to certain\nkinds of structure, it can explain automatically obtained features during\nlearning.\n  We provide insights into experiments in which we show how sparsity can be\nachieved through prior initialization, pruning, and during learning, and answer\nquestions on the relationship between the structure of Neural Networks and\ntheir performance. This includes the first work of inducing priors from network\ntheory into Recurrent Neural Networks and an architectural performance\nprediction during a Neural Architecture Search. Within our experiments, we show\nhow magnitude class blinded pruning achieves 97.5% on MNIST with 80%\ncompression and re-training, which is 0.5 points more than without compression,\nthat magnitude class uniform pruning is significantly inferior to it and how a\ngenetic search enhanced with performance prediction achieves 82.4% on CIFAR10.\nFurther, performance prediction for Recurrent Networks learning the Reber\ngrammar shows an $R^2$ of up to 0.81 given only structural information.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:18:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Stier", "Julian", ""], ["Darji", "Harshil", ""], ["Granitzer", "Michael", ""]]}, {"id": "2107.12919", "submitter": "Abdelaali Hassaine", "authors": "Jose Roberto Ayala Solares, Yajie Zhu, Abdelaali Hassaine, Shishir\n  Rao, Yikuan Li, Mohammad Mamouei, Dexter Canoy, Kazem Rahimi, Gholamreza\n  Salimi-Khorshidi", "title": "Transfer Learning in Electronic Health Records through Clinical Concept\n  Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models have shown tremendous potential in learning\nrepresentations, which are able to capture some key properties of the data.\nThis makes them great candidates for transfer learning: Exploiting\ncommonalities between different learning tasks to transfer knowledge from one\ntask to another. Electronic health records (EHR) research is one of the domains\nthat has witnessed a growing number of deep learning techniques employed for\nlearning clinically-meaningful representations of medical concepts (such as\ndiseases and medications). Despite this growth, the approaches to benchmark and\nassess such learned representations (or, embeddings) is under-investigated;\nthis can be a big issue when such embeddings are shared to facilitate transfer\nlearning. In this study, we aim to (1) train some of the most prominent disease\nembedding techniques on a comprehensive EHR data from 3.1 million patients, (2)\nemploy qualitative and quantitative evaluation techniques to assess these\nembeddings, and (3) provide pre-trained disease embeddings for transfer\nlearning. This study can be the first comprehensive approach for clinical\nconcept embedding evaluation and can be applied to any embedding techniques and\nfor any EHR concept.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:22:02 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Solares", "Jose Roberto Ayala", ""], ["Zhu", "Yajie", ""], ["Hassaine", "Abdelaali", ""], ["Rao", "Shishir", ""], ["Li", "Yikuan", ""], ["Mamouei", "Mohammad", ""], ["Canoy", "Dexter", ""], ["Rahimi", "Kazem", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "2107.12931", "submitter": "Archit Sharma", "authors": "Archit Sharma, Abhishek Gupta, Sergey Levine, Karol Hausman, Chelsea\n  Finn", "title": "Persistent Reinforcement Learning via Subgoal Curricula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) promises to enable autonomous acquisition of\ncomplex behaviors for diverse agents. However, the success of current\nreinforcement learning algorithms is predicated on an often under-emphasised\nrequirement -- each trial needs to start from a fixed initial state\ndistribution. Unfortunately, resetting the environment to its initial state\nafter each trial requires substantial amount of human supervision and extensive\ninstrumentation of the environment which defeats the purpose of autonomous\nreinforcement learning. In this work, we propose Value-accelerated Persistent\nReinforcement Learning (VaPRL), which generates a curriculum of initial states\nsuch that the agent can bootstrap on the success of easier tasks to efficiently\nlearn harder tasks. The agent also learns to reach the initial states proposed\nby the curriculum, minimizing the reliance on human interventions into the\nlearning. We observe that VaPRL reduces the interventions required by three\norders of magnitude compared to episodic RL while outperforming prior\nstate-of-the art methods for reset-free RL both in terms of sample efficiency\nand asymptotic performance on a variety of simulated robotics problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:39:45 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sharma", "Archit", ""], ["Gupta", "Abhishek", ""], ["Levine", "Sergey", ""], ["Hausman", "Karol", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.12940", "submitter": "Mark Koren", "authors": "Mark Koren and Ahmed Nassar and Mykel J. Kochenderfer", "title": "Finding Failures in High-Fidelity Simulation using Adaptive Stress\n  Testing and the Backward Algorithm", "comments": "Accepted to IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Validating the safety of autonomous systems generally requires the use of\nhigh-fidelity simulators that adequately capture the variability of real-world\nscenarios. However, it is generally not feasible to exhaustively search the\nspace of simulation scenarios for failures. Adaptive stress testing (AST) is a\nmethod that uses reinforcement learning to find the most likely failure of a\nsystem. AST with a deep reinforcement learning solver has been shown to be\neffective in finding failures across a range of different systems. This\napproach generally involves running many simulations, which can be very\nexpensive when using a high-fidelity simulator. To improve efficiency, we\npresent a method that first finds failures in a low-fidelity simulator. It then\nuses the backward algorithm, which trains a deep neural network policy using a\nsingle expert demonstration, to adapt the low-fidelity failures to\nhigh-fidelity. We have created a series of autonomous vehicle validation case\nstudies that represent some of the ways low-fidelity and high-fidelity\nsimulators can differ, such as time discretization. We demonstrate in a variety\nof case studies that this new AST approach is able to find failures with\nsignificantly fewer high-fidelity simulation steps than are needed when just\nrunning AST directly in high-fidelity. As a proof of concept, we also\ndemonstrate AST on NVIDIA's DriveSim simulator, an industry state-of-the-art\nhigh-fidelity simulator for finding failures in autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:54:04 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Koren", "Mark", ""], ["Nassar", "Ahmed", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2107.12942", "submitter": "Eric Goubault", "authors": "Nicola Bernini, Mikhail Bessa, R\\'emi Delmas, Arthur Gold, Eric\n  Goubault, Romain Pennec, Sylvie Putot, Fran\\c{c}ois Sillion", "title": "Reinforcement Learning with Formal Performance Metrics for Quadcopter\n  Attitude Control under Non-nominal Contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the reinforcement learning approach to designing controllers by\nextensively discussing the case of a quadcopter attitude controller. We provide\nall details allowing to reproduce our approach, starting with a model of the\ndynamics of a crazyflie 2.0 under various nominal and non-nominal conditions,\nincluding partial motor failures and wind gusts. We develop a robust form of a\nsignal temporal logic to quantitatively evaluate the vehicle's behavior and\nmeasure the performance of controllers. The paper thoroughly describes the\nchoices in training algorithms, neural net architecture, hyperparameters,\nobservation space in view of the different performance metrics we have\nintroduced. We discuss the robustness of the obtained controllers, both to\npartial loss of power for one rotor and to wind gusts and finish by drawing\nconclusions on practical controller design by reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:58:19 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bernini", "Nicola", ""], ["Bessa", "Mikhail", ""], ["Delmas", "R\u00e9mi", ""], ["Gold", "Arthur", ""], ["Goubault", "Eric", ""], ["Pennec", "Romain", ""], ["Putot", "Sylvie", ""], ["Sillion", "Fran\u00e7ois", ""]]}, {"id": "2107.12957", "submitter": "David Sommer", "authors": "David M. Sommer, Lukas Abfalterer, Sheila Zingg and Esfandiar\n  Mohammadi", "title": "Learning Numeric Optimal Differentially Private Truncated Additive\n  Mechanisms", "comments": "Code is available at\n  https://github.com/teuron/optimal_truncated_noise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private (DP) mechanisms face the challenge of providing\naccurate results while protecting their inputs: the privacy-utility trade-off.\nA simple but powerful technique for DP adds noise to sensitivity-bounded query\noutputs to blur the exact query output: additive mechanisms. While a vast body\nof work considers infinitely wide noise distributions, some applications (e.g.,\nreal-time operating systems) require hard bounds on the deviations from the\nreal query, and only limited work on such mechanisms exist. An additive\nmechanism with truncated noise (i.e., with bounded range) can offer such hard\nbounds. We introduce a gradient-descent-based tool to learn truncated noise for\nadditive mechanisms with strong utility bounds while simultaneously optimizing\nfor differential privacy under sequential composition, i.e., scenarios where\nmultiple noisy queries on the same data are revealed. Our method can learn\ndiscrete noise patterns and not only hyper-parameters of a predefined\nprobability distribution. For sensitivity bounded mechanisms, we show that it\nis sufficient to consider symmetric and that\\new{, for from the mean\nmonotonically falling noise,} ensuring privacy for a pair of representative\nquery outputs guarantees privacy for all pairs of inputs (that differ in one\nelement). We find that the utility-privacy trade-off curves of our generated\nnoise are remarkably close to truncated Gaussians and even replicate their\nshape for $l_2$ utility-loss. For a low number of compositions, we also\nimproved DP-SGD (sub-sampling). Moreover, we extend Moments Accountant to\ntruncated distributions, allowing to incorporate mechanism output events with\nvarying input-dependent zero occurrence probability.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:22:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Sommer", "David M.", ""], ["Abfalterer", "Lukas", ""], ["Zingg", "Sheila", ""], ["Mohammadi", "Esfandiar", ""]]}, {"id": "2107.12958", "submitter": "Tingting Tang", "authors": "Tingting Tang, Ramy E. Ali, Hanieh Hashemi, Tynan Gangwani, Salman\n  Avestimehr and Murali Annavaram", "title": "Verifiable Coded Computing: Towards Fast, Secure and Private Distributed\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stragglers, Byzantine workers, and data privacy are the main bottlenecks in\ndistributed cloud computing. Several prior works proposed coded computing\nstrategies to jointly address all three challenges. They require either a large\nnumber of workers, a significant communication cost or a significant\ncomputational complexity to tolerate malicious workers. Much of the overhead in\nprior schemes comes from the fact that they tightly couple coding for all three\nproblems into a single framework. In this work, we propose Verifiable Coded\nComputing (VCC) framework that decouples Byzantine node detection challenge\nfrom the straggler tolerance. VCC leverages coded computing just for handling\nstragglers and privacy, and then uses an orthogonal approach of verifiable\ncomputing to tackle Byzantine nodes. Furthermore, VCC dynamically adapts its\ncoding scheme to tradeoff straggler tolerance with Byzantine protection and\nvice-versa. We evaluate VCC on compute intensive distributed logistic\nregression application. Our experiments show that VCC speeds up the\nconventional uncoded implementation of distributed logistic regression by\n$3.2\\times-6.9\\times$, and also improves the test accuracy by up to $12.6\\%$.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:23:09 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Tang", "Tingting", ""], ["Ali", "Ramy E.", ""], ["Hashemi", "Hanieh", ""], ["Gangwani", "Tynan", ""], ["Avestimehr", "Salman", ""], ["Annavaram", "Murali", ""]]}, {"id": "2107.12964", "submitter": "Alice Baird", "authors": "Alice Baird, Lukas Stappen, Lukas Christ, Lea Schumann, Eva-Maria\n  Me{\\ss}ner, Bj\\\"orn W. Schuller", "title": "A Physiologically-Adapted Gold Standard for Arousal during Stress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotion is an inherently subjective psychophysiological human-state and to\nproduce an agreed-upon representation (gold standard) for continuous emotion\nrequires a time-consuming and costly training procedure of multiple human\nannotators. There is strong evidence in the literature that physiological\nsignals are sufficient objective markers for states of emotion, particularly\narousal. In this contribution, we utilise a dataset which includes continuous\nemotion and physiological signals - Heartbeats per Minute (BPM), Electrodermal\nActivity (EDA), and Respiration-rate - captured during a stress inducing\nscenario (Trier Social Stress Test). We utilise a Long Short-Term Memory,\nRecurrent Neural Network to explore the benefit of fusing these physiological\nsignals with arousal as the target, learning from various audio, video, and\ntextual based features. We utilise the state-of-the-art MuSe-Toolbox to\nconsider both annotation delay and inter-rater agreement weighting when fusing\nthe target signals. An improvement in Concordance Correlation Coefficient (CCC)\nis seen across features sets when fusing EDA with arousal, compared to the\narousal only gold standard results. Additionally, BERT-based textual features'\nresults improved for arousal plus all physiological signals, obtaining up to\n.3344 CCC compared to .2118 CCC for arousal only. Multimodal fusion also\nimproves overall CCC with audio plus video features obtaining up to .6157 CCC\nto recognize arousal plus EDA and BPM.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:28:26 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 13:08:50 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baird", "Alice", ""], ["Stappen", "Lukas", ""], ["Christ", "Lukas", ""], ["Schumann", "Lea", ""], ["Me\u00dfner", "Eva-Maria", ""], ["Schuller", "Bj\u00f6rn W.", ""]]}, {"id": "2107.12970", "submitter": "Yifeng Zhao", "authors": "Yifeng Zhao, Pei Zhang, S.A. Galindo-Torres, Stan Z. Li", "title": "A Data-driven feature selection and machine-learning model benchmark for\n  the prediction of longitudinal dispersion coefficient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longitudinal Dispersion(LD) is the dominant process of scalar transport in\nnatural streams. An accurate prediction on LD coefficient(Dl) can produce a\nperformance leap in related simulation. The emerging machine learning(ML)\ntechniques provide a self-adaptive tool for this problem. However, most of the\nexisting studies utilize an unproved quaternion feature set, obtained through\nsimple theoretical deduction. Few studies have put attention on its reliability\nand rationality. Besides, due to the lack of comparative comparison, the proper\nchoice of ML models in different scenarios still remains unknown. In this\nstudy, the Feature Gradient selector was first adopted to distill the local\noptimal feature sets directly from multivariable data. Then, a global optimal\nfeature set (the channel width, the flow velocity, the channel slope and the\ncross sectional area) was proposed through numerical comparison of the\ndistilled local optimums in performance with representative ML models. The\nchannel slope is identified to be the key parameter for the prediction of LDC.\nFurther, we designed a weighted evaluation metric which enables comprehensive\nmodel comparison. With the simple linear model as the baseline, a benchmark of\nsingle and ensemble learning models was provided. Advantages and disadvantages\nof the methods involved were also discussed. Results show that the support\nvector machine has significantly better performance than other models. Decision\ntree is not suitable for this problem due to poor generalization ability.\nNotably, simple models show superiority over complicated model on this\nlow-dimensional problem, for their better balance between regression and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:50:38 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Zhao", "Yifeng", ""], ["Zhang", "Pei", ""], ["Galindo-Torres", "S. A.", ""], ["Li", "Stan Z.", ""]]}, {"id": "2107.12972", "submitter": "Sarath Shekkizhar", "authors": "David Bonet, Antonio Ortega, Javier Ruiz-Hidalgo, Sarath Shekkizhar", "title": "Channel-Wise Early Stopping without a Validation Set via NNK Polytope\n  Interpolation", "comments": "Submitted to APSIPA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art neural network architectures continue to scale in size and\ndeliver impressive generalization results, although this comes at the expense\nof limited interpretability. In particular, a key challenge is to determine\nwhen to stop training the model, as this has a significant impact on\ngeneralization. Convolutional neural networks (ConvNets) comprise\nhigh-dimensional feature spaces formed by the aggregation of multiple channels,\nwhere analyzing intermediate data representations and the model's evolution can\nbe challenging owing to the curse of dimensionality. We present channel-wise\nDeepNNK (CW-DeepNNK), a novel channel-wise generalization estimate based on\nnon-negative kernel regression (NNK) graphs with which we perform local\npolytope interpolation on low-dimensional channels. This method leads to\ninstance-based interpretability of both the learned data representations and\nthe relationship between channels. Motivated by our observations, we use\nCW-DeepNNK to propose a novel early stopping criterion that (i) does not\nrequire a validation set, (ii) is based on a task performance metric, and (iii)\nallows stopping to be reached at different points for each channel. Our\nexperiments demonstrate that our proposed method has advantages as compared to\nthe standard criterion based on validation set performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:33:30 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bonet", "David", ""], ["Ortega", "Antonio", ""], ["Ruiz-Hidalgo", "Javier", ""], ["Shekkizhar", "Sarath", ""]]}, {"id": "2107.12975", "submitter": "Natalia Ares", "authors": "B. Severin, D. T. Lennon, L. C. Camenzind, F. Vigneau, F. Fedele, D.\n  Jirovec, A. Ballabio, D. Chrastina, G. Isella, M. de Kruijf, M. J.\n  Carballido, S. Svab, A. V. Kuhlmann, F. R. Braakman, S. Geyer, F. N. M.\n  Froning, H. Moon, M. A. Osborne, D. Sejdinovic, G. Katsaros, D. M. Zumb\\\"uhl,\n  G. A. D. Briggs, and N. Ares", "title": "Cross-architecture Tuning of Silicon and SiGe-based Quantum Devices\n  Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mes-hall cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential of Si and SiGe-based devices for the scaling of quantum\ncircuits is tainted by device variability. Each device needs to be tuned to\noperation conditions. We give a key step towards tackling this variability with\nan algorithm that, without modification, is capable of tuning a 4-gate Si\nFinFET, a 5-gate GeSi nanowire and a 7-gate SiGe heterostructure double quantum\ndot device from scratch. We achieve tuning times of 30, 10, and 92 minutes,\nrespectively. The algorithm also provides insight into the parameter space\nlandscape for each of these devices. These results show that overarching\nsolutions for the tuning of quantum devices are enabled by machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:42:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Severin", "B.", ""], ["Lennon", "D. T.", ""], ["Camenzind", "L. C.", ""], ["Vigneau", "F.", ""], ["Fedele", "F.", ""], ["Jirovec", "D.", ""], ["Ballabio", "A.", ""], ["Chrastina", "D.", ""], ["Isella", "G.", ""], ["de Kruijf", "M.", ""], ["Carballido", "M. J.", ""], ["Svab", "S.", ""], ["Kuhlmann", "A. V.", ""], ["Braakman", "F. R.", ""], ["Geyer", "S.", ""], ["Froning", "F. N. M.", ""], ["Moon", "H.", ""], ["Osborne", "M. A.", ""], ["Sejdinovic", "D.", ""], ["Katsaros", "G.", ""], ["Zumb\u00fchl", "D. M.", ""], ["Briggs", "G. A. D.", ""], ["Ares", "N.", ""]]}, {"id": "2107.12977", "submitter": "Inga Str\\\"umke", "authors": "Inga Str\\\"umke, Marija Slavkovik, Vince I. Madai", "title": "The social dilemma in AI development and why we have to solve it", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the demand for ethical artificial intelligence (AI) systems increases,\nthe number of unethical uses of AI accelerates, even though there is no\nshortage of ethical guidelines. We argue that a main underlying cause for this\nis that AI developers face a social dilemma in AI development ethics,\npreventing the widespread adaptation of ethical best practices. We define the\nsocial dilemma for AI development and describe why the current crisis in AI\ndevelopment ethics cannot be solved without relieving AI developers of their\nsocial dilemma. We argue that AI development must be professionalised to\novercome the social dilemma, and discuss how medicine can be used as a template\nin this process.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:43:48 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:44:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Str\u00fcmke", "Inga", ""], ["Slavkovik", "Marija", ""], ["Madai", "Vince I.", ""]]}, {"id": "2107.12978", "submitter": "Brennan Nichyporuk", "authors": "Brennan Nichyporuk, Justin Szeto, Douglas L. Arnold, Tal Arbel", "title": "Optimizing Operating Points for High Performance Lesion Detection and\n  Segmentation Using Lesion Size Reweighting", "comments": "Accepted at MIDL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many clinical contexts which require accurate detection and\nsegmentation of all focal pathologies (e.g. lesions, tumours) in patient\nimages. In cases where there are a mix of small and large lesions, standard\nbinary cross entropy loss will result in better segmentation of large lesions\nat the expense of missing small ones. Adjusting the operating point to\naccurately detect all lesions generally leads to oversegmentation of large\nlesions. In this work, we propose a novel reweighing strategy to eliminate this\nperformance gap, increasing small pathology detection performance while\nmaintaining segmentation accuracy. We show that our reweighing strategy vastly\noutperforms competing strategies based on experiments on a large scale,\nmulti-scanner, multi-center dataset of Multiple Sclerosis patient images.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:43:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Nichyporuk", "Brennan", ""], ["Szeto", "Justin", ""], ["Arnold", "Douglas L.", ""], ["Arbel", "Tal", ""]]}, {"id": "2107.12997", "submitter": "Georgios Leontidis", "authors": "George Onoufriou, Paul Mayfield and Georgios Leontidis", "title": "Fully Homomorphically Encrypted Deep Learning as a Service", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Homomorphic Encryption (FHE) is a relatively recent advancement in the\nfield of privacy-preserving technologies. FHE allows for the arbitrary depth\ncomputation of both addition and multiplication, and thus the application of\nabelian/polynomial equations, like those found in deep learning algorithms.\nThis project investigates, derives, and proves how FHE with deep learning can\nbe used at scale, with relatively low time complexity, the problems that such a\nsystem incurs, and mitigations/solutions for such problems. In addition, we\ndiscuss how this could have an impact on the future of data privacy and how it\ncan enable data sharing across various actors in the agri-food supply chain,\nhence allowing the development of machine learning-based systems. Finally, we\nfind that although FHE incurs a high spatial complexity cost, the time\ncomplexity is within expected reasonable bounds, while allowing for absolutely\nprivate predictions to be made, in our case for milk yield prediction.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 20:17:48 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Onoufriou", "George", ""], ["Mayfield", "Paul", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2107.13034", "submitter": "Timothy Nguyen", "authors": "Timothy Nguyen, Roman Novak, Lechao Xiao, Jaehoon Lee", "title": "Dataset Distillation with Infinitely Wide Convolutional Networks", "comments": "Code and datasets available at\n  https://github.com/google-research/google-research/tree/master/kip", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The effectiveness of machine learning algorithms arises from being able to\nextract useful features from large amounts of data. As model and dataset sizes\nincrease, dataset distillation methods that compress large datasets into\nsignificantly smaller yet highly performant ones will become valuable in terms\nof training efficiency and useful feature extraction. To that end, we apply a\nnovel distributed kernel based meta-learning framework to achieve\nstate-of-the-art results for dataset distillation using infinitely wide\nconvolutional neural networks. For instance, using only 10 datapoints (0.02% of\noriginal dataset), we obtain over 64% test accuracy on CIFAR-10 image\nclassification task, a dramatic improvement over the previous best test\naccuracy of 40%. Our state-of-the-art results extend across many other settings\nfor MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, and SVHN. Furthermore, we\nperform some preliminary analyses of our distilled datasets to shed light on\nhow they differ from naturally occurring data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 18:31:42 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Nguyen", "Timothy", ""], ["Novak", "Roman", ""], ["Xiao", "Lechao", ""], ["Lee", "Jaehoon", ""]]}, {"id": "2107.13045", "submitter": "Alexander Dallmann", "authors": "Alexander Dallmann, Daniel Zoller, Andreas Hotho", "title": "A Case Study on Sampling Strategies for Evaluating Neural Sequential\n  Item Recommendation Models", "comments": null, "journal-ref": null, "doi": "10.1145/3460231.3475943", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the present time, sequential item recommendation models are compared by\ncalculating metrics on a small item subset (target set) to speed up\ncomputation. The target set contains the relevant item and a set of negative\nitems that are sampled from the full item set. Two well-known strategies to\nsample negative items are uniform random sampling and sampling by popularity to\nbetter approximate the item frequency distribution in the dataset. Most\nrecently published papers on sequential item recommendation rely on sampling by\npopularity to compare the evaluated models. However, recent work has already\nshown that an evaluation with uniform random sampling may not be consistent\nwith the full ranking, that is, the model ranking obtained by evaluating a\nmetric using the full item set as target set, which raises the question whether\nthe ranking obtained by sampling by popularity is equal to the full ranking. In\nthis work, we re-evaluate current state-of-the-art sequential recommender\nmodels from the point of view, whether these sampling strategies have an impact\non the final ranking of the models. We therefore train four recently proposed\nsequential recommendation models on five widely known datasets. For each\ndataset and model, we employ three evaluation strategies. First, we compute the\nfull model ranking. Then we evaluate all models on a target set sampled by the\ntwo different sampling strategies, uniform random sampling and sampling by\npopularity with the commonly used target set size of 100, compute the model\nranking for each strategy and compare them with each other. Additionally, we\nvary the size of the sampled target set. Overall, we find that both sampling\nstrategies can produce inconsistent rankings compared with the full ranking of\nthe models. Furthermore, both sampling by popularity and uniform random\nsampling do not consistently produce the same ranking ...\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:06:03 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dallmann", "Alexander", ""], ["Zoller", "Daniel", ""], ["Hotho", "Andreas", ""]]}, {"id": "2107.13054", "submitter": "Cameron R. Wolfe", "authors": "Cameron R. Wolfe and Keld T. Lundgaard", "title": "Exceeding the Limits of Visual-Linguistic Multi-Task Learning", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  By leveraging large amounts of product data collected across hundreds of live\ne-commerce websites, we construct 1000 unique classification tasks that share\nsimilarly-structured input data, comprised of both text and images. These\nclassification tasks focus on learning the product hierarchy of different\ne-commerce websites, causing many of them to be correlated. Adopting a\nmulti-modal transformer model, we solve these tasks in unison using multi-task\nlearning (MTL). Extensive experiments are presented over an initial 100-task\ndataset to reveal best practices for \"large-scale MTL\" (i.e., MTL with more\nthan 100 tasks). From these experiments, a final, unified methodology is\nderived, which is composed of both best practices and new proposals such as\nDyPa, a simple heuristic for automatically allocating task-specific parameters\nto tasks that could benefit from extra capacity. Using our large-scale MTL\nmethodology, we successfully train a single model across all 1000 tasks in our\ndataset while using minimal task specific parameters, thereby showing that it\nis possible to extend several orders of magnitude beyond current efforts in\nMTL.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:42:14 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wolfe", "Cameron R.", ""], ["Lundgaard", "Keld T.", ""]]}, {"id": "2107.13059", "submitter": "Yu Wang", "authors": "Yu Wang, Yuesong Shen, Daniel Cremers", "title": "Explicit Pairwise Factorized Graph Neural Network for Semi-Supervised\n  Node Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node features and structural information of a graph are both crucial for\nsemi-supervised node classification problems. A variety of graph neural network\n(GNN) based approaches have been proposed to tackle these problems, which\ntypically determine output labels through feature aggregation. This can be\nproblematic, as it implies conditional independence of output nodes given\nhidden representations, despite their direct connections in the graph. To learn\nthe direct influence among output nodes in a graph, we propose the Explicit\nPairwise Factorized Graph Neural Network (EPFGNN), which models the whole graph\nas a partially observed Markov Random Field. It contains explicit pairwise\nfactors to model output-output relations and uses a GNN backbone to model\ninput-output relations. To balance model complexity and expressivity, the\npairwise factors have a shared component and a separate scaling coefficient for\neach edge. We apply the EM algorithm to train our model, and utilize a\nstar-shaped piecewise likelihood for the tractable surrogate objective. We\nconduct experiments on various datasets, which shows that our model can\neffectively improve the performance for semi-supervised node classification on\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:47:53 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Yu", ""], ["Shen", "Yuesong", ""], ["Cremers", "Daniel", ""]]}, {"id": "2107.13066", "submitter": "Wil van der Aalst", "authors": "Wil van der Aalst and Tobias Brockhoff and Anahita Farhang Ghahfarokhi\n  and Mahsa Pourbafrani and Merih Seran Uysal and Sebastiaan van Zelst", "title": "Removing Operational Friction Using Process Mining: Challenges Provided\n  by the Internet of Production (IoP)", "comments": "30 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Operational processes in production, logistics, material handling,\nmaintenance, etc., are supported by cyber-physical systems combining hardware\nand software components. As a result, the digital and the physical world are\nclosely aligned, and it is possible to track operational processes in detail\n(e.g., using sensors). The abundance of event data generated by today's\noperational processes provides opportunities and challenges for process mining\ntechniques supporting process discovery, performance analysis, and conformance\nchecking. Using existing process mining tools, it is already possible to\nautomatically discover process models and uncover performance and compliance\nproblems. In the DFG-funded Cluster of Excellence \"Internet of Production\"\n(IoP), process mining is used to create \"digital shadows\" to improve a wide\nvariety of operational processes. However, operational processes are dynamic,\ndistributed, and complex. Driven by the challenges identified in the IoP\ncluster, we work on novel techniques for comparative process mining (comparing\nprocess variants for different products at different locations at different\ntimes), object-centric process mining (to handle processes involving different\ntypes of objects that interact), and forward-looking process mining (to explore\n\"What if?\" questions). By addressing these challenges, we aim to develop\nvaluable \"digital shadows\" that can be used to remove operational friction.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 20:04:25 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["van der Aalst", "Wil", ""], ["Brockhoff", "Tobias", ""], ["Ghahfarokhi", "Anahita Farhang", ""], ["Pourbafrani", "Mahsa", ""], ["Uysal", "Merih Seran", ""], ["van Zelst", "Sebastiaan", ""]]}, {"id": "2107.13067", "submitter": "Mohammadmehdi Ataei", "authors": "Mohammadmehdi Ataei, Erfan Pirmorad, Franco Costa, Sejin Han, Chul B\n  Park, Markus Bussmann", "title": "A Deep Learning Algorithm for Piecewise Linear Interface Construction\n  (PLIC)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Piecewise Linear Interface Construction (PLIC) is frequently used to\ngeometrically reconstruct fluid interfaces in Computational Fluid Dynamics\n(CFD) modeling of two-phase flows. PLIC reconstructs interfaces from a scalar\nfield that represents the volume fraction of each phase in each computational\ncell. Given the volume fraction and interface normal, the location of a linear\ninterface is uniquely defined. For a cubic computational cell (3D), the\nposition of the planar interface is determined by intersecting the cube with a\nplane, such that the volume of the resulting truncated polyhedron cell is equal\nto the volume fraction. Yet it is geometrically complex to find the exact\nposition of the plane, and it involves calculations that can be a computational\nbottleneck of many CFD models. However, while the forward problem of 3D PLIC is\nchallenging, the inverse problem, of finding the volume of the truncated\npolyhedron cell given a defined plane, is simple. In this work, we propose a\ndeep learning model for the solution to the forward problem of PLIC by only\nmaking use of its inverse problem. The proposed model is up to several orders\nof magnitude faster than traditional schemes, which significantly reduces the\ncomputational bottleneck of PLIC in CFD simulations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 20:04:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ataei", "Mohammadmehdi", ""], ["Pirmorad", "Erfan", ""], ["Costa", "Franco", ""], ["Han", "Sejin", ""], ["Park", "Chul B", ""], ["Bussmann", "Markus", ""]]}, {"id": "2107.13068", "submitter": "Mohammad Taha Bahadori", "authors": "Mohammad Taha Bahadori and Eric Tchetgen Tchetgen and David E.\n  Heckerman", "title": "End-to-End Balancing for Causal Continuous Treatment-Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of observational causal inference with continuous\ntreatment. We focus on the challenge of estimating the causal response curve\nfor infrequently-observed treatment values. We design a new algorithm based on\nthe framework of entropy balancing which learns weights that directly maximize\ncausal inference accuracy using end-to-end optimization. Our weights can be\ncustomized for different datasets and causal inference algorithms. We propose a\nnew theory for consistency of entropy balancing for continuous treatments.\nUsing synthetic and real-world data, we show that our proposed algorithm\noutperforms the entropy balancing in terms of causal inference accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 20:04:59 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Bahadori", "Mohammad Taha", ""], ["Tchetgen", "Eric Tchetgen", ""], ["Heckerman", "David E.", ""]]}, {"id": "2107.13074", "submitter": "Sebastiaan De Peuter", "authors": "Sebastiaan De Peuter (1), Antti Oulasvirta (2), Samuel Kaski (1 and 3)\n  ((1) Department of Computer Science, Aalto University, Finland, (2)\n  Department of Communications and Networking, Aalto University, Finland, (3)\n  Department of Computer Science, University of Manchester, UK)", "title": "Toward AI Assistants That Let Designers Design", "comments": "9 pages, 3 figures, submitted to IEEE Computer magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI for supporting designers needs to be rethought. It should aim to\ncooperate, not automate, by supporting and leveraging the creativity and\nproblem-solving of designers. The challenge for such AI is how to infer\ndesigners' goals and then help them without being needlessly disruptive. We\npresent AI-assisted design: a framework for creating such AI, built around\ngenerative user models which enable reasoning about designers' goals,\nreasoning, and capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:29:36 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["De Peuter", "Sebastiaan", "", "1 and 3"], ["Oulasvirta", "Antti", "", "1 and 3"], ["Kaski", "Samuel", "", "1 and 3"]]}, {"id": "2107.13076", "submitter": "Sondess Missaoui Dr.", "authors": "ennifer Chubba, Sondess Missaouib, Shauna Concannonc, Liam Maloneyb,\n  James Alfred Walker", "title": "Interactive Storytelling for Children: A Case-study of Design and\n  Development Considerations for Ethical Conversational AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Conversational Artificial Intelligence (CAI) systems and Intelligent Personal\nAssistants (IPA), such as Alexa, Cortana, Google Home and Siri are becoming\nubiquitous in our lives, including those of children, the implications of which\nis receiving increased attention, specifically with respect to the effects of\nthese systems on children's cognitive, social and linguistic development.\nRecent advances address the implications of CAI with respect to privacy,\nsafety, security, and access. However, there is a need to connect and embed the\nethical and technical aspects in the design. Using a case-study of a research\nand development project focused on the use of CAI in storytelling for children,\nthis paper reflects on the social context within a specific case of technology\ndevelopment, as substantiated and supported by argumentation from within the\nliterature. It describes the decision making process behind the recommendations\nmade on this case for their adoption in the creative industries. Further\nresearch that engages with developers and stakeholders in the ethics of\nstorytelling through CAI is highlighted as a matter of urgency.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:11:45 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chubba", "ennifer", ""], ["Missaouib", "Sondess", ""], ["Concannonc", "Shauna", ""], ["Maloneyb", "Liam", ""], ["Walker", "James Alfred", ""]]}, {"id": "2107.13078", "submitter": "Muhammad Ammad-Ud-Din Ph.D.", "authors": "Farwa K. Khan, Adrian Flanagan, Kuan E. Tan, Zareen Alamgir, Muhammad\n  Ammad-Ud-Din", "title": "A Payload Optimization Method for Federated Recommender Systems", "comments": "15 pages, 3 figures, 4 tables", "journal-ref": "Fifteenth ACM Conference on Recommender Systems (RecSys 2021),\n  September 27-October 1, 2021, Amsterdam, Netherlands. ACM, New York, NY, USA", "doi": "10.1145/3460231.3474257", "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce the payload optimization method for federated recommender\nsystems (FRS). In federated learning (FL), the global model payload that is\nmoved between the server and users depends on the number of items to recommend.\nThe model payload grows when there is an increasing number of items. This\nbecomes challenging for an FRS if it is running in production mode. To tackle\nthe payload challenge, we formulated a multi-arm bandit solution that selected\npart of the global model and transmitted it to all users. The selection process\nwas guided by a novel reward function suitable for FL systems. So far as we are\naware, this is the first optimization method that seeks to address item\ndependent payloads. The method was evaluated using three benchmark\nrecommendation datasets. The empirical validation confirmed that the proposed\nmethod outperforms the simpler methods that do not benefit from the bandits for\nthe purpose of item selection. In addition, we have demonstrated the usefulness\nof our proposed method by rigorously evaluating the effects of a payload\nreduction on the recommendation performance degradation. Our method achieved up\nto a 90\\% reduction in model payload, yielding only a $\\sim$4\\% - 8\\% loss in\nthe recommendation performance for highly sparse datasets\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 20:44:30 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Khan", "Farwa K.", ""], ["Flanagan", "Adrian", ""], ["Tan", "Kuan E.", ""], ["Alamgir", "Zareen", ""], ["Ammad-Ud-Din", "Muhammad", ""]]}, {"id": "2107.13090", "submitter": "Renyuan Xu", "authors": "Ben Hambly, Renyuan Xu and Huining Yang", "title": "Policy Gradient Methods Find the Nash Equilibrium in N-player\n  General-sum Linear-quadratic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general-sum N-player linear-quadratic game with stochastic\ndynamics over a finite horizon and prove the global convergence of the natural\npolicy gradient method to the Nash equilibrium. In order to prove the\nconvergence of the method, we require a certain amount of noise in the system.\nWe give a condition, essentially a lower bound on the covariance of the noise\nin terms of the model parameters, in order to guarantee convergence. We\nillustrate our results with numerical experiments to show that even in\nsituations where the policy gradient method may not converge in the\ndeterministic setting, the addition of noise leads to convergence.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 22:08:41 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hambly", "Ben", ""], ["Xu", "Renyuan", ""], ["Yang", "Huining", ""]]}, {"id": "2107.13093", "submitter": "Reece Walsh", "authors": "Reece Walsh, Mohamed H. Abdelpakey, Mohamed S. Shehata, Mostafa\n  M.Mohamed", "title": "Automated Human Cell Classification in Sparse Datasets using Few-Shot\n  Learning", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying and analyzing human cells is a lengthy procedure, often involving\na trained professional. In an attempt to expedite this process, an active area\nof research involves automating cell classification through use of deep\nlearning-based techniques. In practice, a large amount of data is required to\naccurately train these deep learning models. However, due to the sparse human\ncell datasets currently available, the performance of these models is typically\nlow. This study investigates the feasibility of using few-shot learning-based\ntechniques to mitigate the data requirements for accurate training. The study\nis comprised of three parts: First, current state-of-the-art few-shot learning\ntechniques are evaluated on human cell classification. The selected techniques\nare trained on a non-medical dataset and then tested on two out-of-domain,\nhuman cell datasets. The results indicate that, overall, the test accuracy of\nstate-of-the-art techniques decreased by at least 30% when transitioning from a\nnon-medical dataset to a medical dataset. Second, this study evaluates the\npotential benefits, if any, to varying the backbone architecture and training\nschemes in current state-of-the-art few-shot learning techniques when used in\nhuman cell classification. Even with these variations, the overall test\naccuracy decreased from 88.66% on non-medical datasets to 44.13% at best on the\nmedical datasets. Third, this study presents future directions for using\nfew-shot learning in human cell classification. In general, few-shot learning\nin its current state performs poorly on human cell classification. The study\nproves that attempts to modify existing network architectures are not effective\nand concludes that future research effort should be focused on improving\nrobustness towards out-of-domain testing using optimization-based or\nself-supervised few-shot learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 22:26:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Walsh", "Reece", ""], ["Abdelpakey", "Mohamed H.", ""], ["Shehata", "Mohamed S.", ""], ["Mohamed", "Mostafa M.", ""]]}, {"id": "2107.13098", "submitter": "Daniel D'souza", "authors": "Daniel D'souza, Zach Nussbaum, Chirag Agarwal, Sara Hooker", "title": "A Tale Of Two Long Tails", "comments": "Preliminary results accepted to Workshop on Uncertainty and\n  Robustness in Deep Learning (UDL), ICML, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning models are increasingly employed to assist human\ndecision-makers, it becomes critical to communicate the uncertainty associated\nwith these model predictions. However, the majority of work on uncertainty has\nfocused on traditional probabilistic or ranking approaches - where the model\nassigns low probabilities or scores to uncertain examples. While this captures\nwhat examples are challenging for the model, it does not capture the underlying\nsource of the uncertainty. In this work, we seek to identify examples the model\nis uncertain about and characterize the source of said uncertainty. We explore\nthe benefits of designing a targeted intervention - targeted data augmentation\nof the examples where the model is uncertain over the course of training. We\ninvestigate whether the rate of learning in the presence of additional\ninformation differs between atypical and noisy examples? Our results show that\nthis is indeed the case, suggesting that well-designed interventions over the\ncourse of training can be an effective way to characterize and distinguish\nbetween different sources of uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 22:49:59 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["D'souza", "Daniel", ""], ["Nussbaum", "Zach", ""], ["Agarwal", "Chirag", ""], ["Hooker", "Sara", ""]]}, {"id": "2107.13109", "submitter": "Masahiro Suzuki", "authors": "Masahiro Suzuki, Takaaki Kaneko, Yutaka Matsuo", "title": "Pixyz: a library for developing deep generative models", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent rapid progress in the study of deep generative models (DGMs),\nthere is a need for a framework that can implement them in a simple and generic\nway. In this research, we focus on two features of the latest DGMs: (1) deep\nneural networks are encapsulated by probability distributions and (2) models\nare designed and learned based on an objective function. Taking these features\ninto account, we propose a new DGM library called Pixyz. We experimentally show\nthat our library is faster than existing probabilistic modeling languages in\nlearning simple DGMs and we show that our library can be used to implement\ncomplex DGMs in a simple and concise manner, which is difficult to do with\nexisting libraries.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 00:06:03 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Suzuki", "Masahiro", ""], ["Kaneko", "Takaaki", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "2107.13124", "submitter": "George Kesidis", "authors": "Xi Li, George Kesidis, David J. Miller, Maxime Bergeron, Ryan\n  Ferguson, Vladimir Lucic", "title": "Robust and Active Learning for Deep Neural Network Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a gradient-based method to discover local error maximizers of a\ndeep neural network (DNN) used for regression, assuming the availability of an\n\"oracle\" capable of providing real-valued supervision (a regression target) for\nsamples. For example, the oracle could be a numerical solver which,\noperationally, is much slower than the DNN. Given a discovered set of local\nerror maximizers, the DNN is either fine-tuned or retrained in the manner of\nactive learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 01:48:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Li", "Xi", ""], ["Kesidis", "George", ""], ["Miller", "David J.", ""], ["Bergeron", "Maxime", ""], ["Ferguson", "Ryan", ""], ["Lucic", "Vladimir", ""]]}, {"id": "2107.13132", "submitter": "Eric Zhan", "authors": "Eric Zhan, Jennifer J. Sun, Ann Kennedy, Yisong Yue, Swarat Chaudhuri", "title": "Unsupervised Learning of Neurosymbolic Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for the unsupervised learning of neurosymbolic\nencoders, i.e., encoders obtained by composing neural networks with symbolic\nprograms from a domain-specific language. Such a framework can naturally\nincorporate symbolic expert knowledge into the learning process and lead to\nmore interpretable and factorized latent representations than fully neural\nencoders. Also, models learned this way can have downstream impact, as many\nanalysis workflows can benefit from having clean programmatic descriptions. We\nground our learning algorithm in the variational autoencoding (VAE) framework,\nwhere we aim to learn a neurosymbolic encoder in conjunction with a standard\ndecoder. Our algorithm integrates standard VAE-style training with modern\nprogram synthesis techniques. We evaluate our method on learning latent\nrepresentations for real-world trajectory data from animal biology and sports\nanalytics. We show that our approach offers significantly better separation\nthan standard VAEs and leads to practical gains on downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 02:16:14 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhan", "Eric", ""], ["Sun", "Jennifer J.", ""], ["Kennedy", "Ann", ""], ["Yue", "Yisong", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "2107.13136", "submitter": "Ruihan Yang", "authors": "Ruihan Yang, Yibo Yang, Joseph Marino, Stephan Mandt", "title": "Insights from Generative Modeling for Neural Video Compression", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible. arXiv admin note: text overlap with arXiv:2010.10258", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent machine learning research has revealed connections between deep\ngenerative models such as VAEs and rate-distortion losses used in learned\ncompression, most of this work has focused on images. In a similar spirit, we\nview recently proposed neural video coding algorithms through the lens of deep\nautoregressive and latent variable modeling. We present recent neural video\ncodecs as instances of a generalized stochastic temporal autoregressive\ntransform, and propose new avenues for further improvements inspired by\nnormalizing flows and structured priors. We propose several architectures that\nyield state-of-the-art video compression performance on full-resolution video\nand discuss their tradeoffs and ablations. In particular, we propose (i)\nimproved temporal autoregressive transforms, (ii) improved entropy models with\nstructured and temporal dependencies, and (iii) variable bitrate versions of\nour algorithms. Since our improvements are compatible with a large class of\nexisting models, we provide further evidence that the generative modeling\nviewpoint can advance the neural video coding field.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 02:19:39 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yang", "Ruihan", ""], ["Yang", "Yibo", ""], ["Marino", "Joseph", ""], ["Mandt", "Stephan", ""]]}, {"id": "2107.13148", "submitter": "A. K. M. Amanat Ullah", "authors": "A. K. M. Amanat Ullah, Fahim Imtiaz, Miftah Uddin Md Ihsan, Md. Golam\n  Rabiul Alam, Mahbub Majumdar", "title": "Combining Machine Learning Classifiers for Stock Trading with Effective\n  Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The unpredictability and volatility of the stock market render it challenging\nto make a substantial profit using any generalized scheme. This paper intends\nto discuss our machine learning model, which can make a significant amount of\nprofit in the US stock market by performing live trading in the Quantopian\nplatform while using resources free of cost. Our top approach was to use\nensemble learning with four classifiers: Gaussian Naive Bayes, Decision Tree,\nLogistic Regression with L1 regularization and Stochastic Gradient Descent, to\ndecide whether to go long or short on a particular stock. Our best model\nperformed daily trade between July 2011 and January 2019, generating 54.35%\nprofit. Finally, our work showcased that mixtures of weighted classifiers\nperform better than any individual predictor about making trading decisions in\nthe stock market.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 03:22:58 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ullah", "A. K. M. Amanat", ""], ["Imtiaz", "Fahim", ""], ["Ihsan", "Miftah Uddin Md", ""], ["Alam", "Md. Golam Rabiul", ""], ["Majumdar", "Mahbub", ""]]}, {"id": "2107.13153", "submitter": "Yuqiao Liu", "authors": "Yuqiao Liu, Yehui Tang, Yanan Sun", "title": "Homogeneous Architecture Augmentation for Neural Predictor", "comments": "This paper has been accepted by ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) can automatically design well-performed\narchitectures of Deep Neural Networks (DNNs) for the tasks at hand. However,\none bottleneck of NAS is the prohibitively computational cost largely due to\nthe expensive performance evaluation. The neural predictors can directly\nestimate the performance without any training of the DNNs to be evaluated, thus\nhave drawn increasing attention from researchers. Despite their popularity,\nthey also suffer a severe limitation: the shortage of annotated DNN\narchitectures for effectively training the neural predictors. In this paper, we\nproposed Homogeneous Architecture Augmentation for Neural Predictor (HAAP) of\nDNN architectures to address the issue aforementioned. Specifically, a\nhomogeneous architecture augmentation algorithm is proposed in HAAP to generate\nsufficient training data taking the use of homogeneous representation.\nFurthermore, the one-hot encoding strategy is introduced into HAAP to make the\nrepresentation of DNN architectures more effective. The experiments have been\nconducted on both NAS-Benchmark-101 and NAS-Bench-201 dataset. The experimental\nresults demonstrate that the proposed HAAP algorithm outperforms the state of\nthe arts compared, yet with much less training data. In addition, the ablation\nstudies on both benchmark datasets have also shown the universality of the\nhomogeneous architecture augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 03:46:33 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liu", "Yuqiao", ""], ["Tang", "Yehui", ""], ["Sun", "Yanan", ""]]}, {"id": "2107.13157", "submitter": "Anusua Trivedi", "authors": "Anusua Trivedi, Jocelyn Desbiens, Ron Gross, Sunil Gupta, Rahul\n  Dodhia, Juan Lavista Ferres", "title": "Retinal Microvasculature as Biomarker for Diabetes and Cardiovascular\n  Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: To demonstrate that retinal microvasculature per se is a reliable\nbiomarker for Diabetic Retinopathy (DR) and, by extension, cardiovascular\ndiseases. Methods: Deep Learning Convolutional Neural Networks (CNN) applied to\ncolor fundus images for semantic segmentation of the blood vessels and severity\nclassification on both vascular and full images. Vessel reconstruction through\nharmonic descriptors is also used as a smoothing and de-noising tool. The\nmathematical background of the theory is also outlined. Results: For diabetic\npatients, at least 93.8% of DR No-Refer vs. Refer classification can be related\nto vasculature defects. As for the Non-Sight Threatening vs. Sight Threatening\ncase, the ratio is as high as 96.7%. Conclusion: In the case of DR, most of the\ndisease biomarkers are related topologically to the vasculature. Translational\nRelevance: Experiments conducted on eye blood vasculature reconstruction as a\nbiomarker shows a strong correlation between vasculature shape and later stages\nof DR.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 04:03:57 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Trivedi", "Anusua", ""], ["Desbiens", "Jocelyn", ""], ["Gross", "Ron", ""], ["Gupta", "Sunil", ""], ["Dodhia", "Rahul", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "2107.13163", "submitter": "Colin Wei", "authors": "Colin Wei, Yining Chen, Tengyu Ma", "title": "Statistically Meaningful Approximation: a Case Study on Approximating\n  Turing Machines with Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common lens to theoretically study neural net architectures is to analyze\nthe functions they can approximate. However, the constructions from\napproximation theory often have unrealistic aspects, for example, reliance on\ninfinite precision to memorize target function values, which make these results\npotentially less meaningful. To address these issues, this work proposes a\nformal definition of statistically meaningful approximation which requires the\napproximating network to exhibit good statistical learnability. We present case\nstudies on statistically meaningful approximation for two classes of functions:\nboolean circuits and Turing machines. We show that overparameterized\nfeedforward neural nets can statistically meaningfully approximate boolean\ncircuits with sample complexity depending only polynomially on the circuit\nsize, not the size of the approximating network. In addition, we show that\ntransformers can statistically meaningfully approximate Turing machines with\ncomputation time bounded by $T$, requiring sample complexity polynomial in the\nalphabet size, state space size, and $\\log (T)$. Our analysis introduces new\ntools for generalization bounds that provide much tighter sample complexity\nguarantees than the typical VC-dimension or norm-based bounds, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 04:28:55 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wei", "Colin", ""], ["Chen", "Yining", ""], ["Ma", "Tengyu", ""]]}, {"id": "2107.13171", "submitter": "Zhiyong Yang", "authors": "Zhiyong Yang, Qianqian Xu, Shilong Bao, Xiaochun Cao, Qingming Huang", "title": "Learning with Multiclass AUC: Theory and Algorithms", "comments": "Accepted by T-PAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Area under the ROC curve (AUC) is a well-known ranking metric for\nproblems such as imbalanced learning and recommender systems. The vast majority\nof existing AUC-optimization-based machine learning methods only focus on\nbinary-class cases, while leaving the multiclass cases unconsidered. In this\npaper, we start an early trial to consider the problem of learning multiclass\nscoring functions via optimizing multiclass AUC metrics. Our foundation is\nbased on the M metric, which is a well-known multiclass extension of AUC. We\nfirst pay a revisit to this metric, showing that it could eliminate the\nimbalance issue from the minority class pairs. Motivated by this, we propose an\nempirical surrogate risk minimization framework to approximately optimize the M\nmetric. Theoretically, we show that: (i) optimizing most of the popular\ndifferentiable surrogate losses suffices to reach the Bayes optimal scoring\nfunction asymptotically; (ii) the training framework enjoys an imbalance-aware\ngeneralization error bound, which pays more attention to the bottleneck samples\nof minority classes compared with the traditional $O(\\sqrt{1/N})$ result.\nPractically, to deal with the low scalability of the computational operations,\nwe propose acceleration methods for three popular surrogate loss functions,\nincluding the exponential loss, squared loss, and hinge loss, to speed up loss\nand gradient evaluations. Finally, experimental results on 11 real-world\ndatasets demonstrate the effectiveness of our proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 05:18:10 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yang", "Zhiyong", ""], ["Xu", "Qianqian", ""], ["Bao", "Shilong", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "2107.13173", "submitter": "Siddharth Divi", "authors": "Siddharth Divi, Yi-Shan Lin, Habiba Farrukh, Z. Berkay Celik", "title": "New Metrics to Evaluate the Performance and Fairness of Personalized\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Federated Learning (FL), the clients learn a single global model (FedAvg)\nthrough a central aggregator. In this setting, the non-IID distribution of the\ndata across clients restricts the global FL model from delivering good\nperformance on the local data of each client. Personalized FL aims to address\nthis problem by finding a personalized model for each client. Recent works\nwidely report the average personalized model accuracy on a particular data\nsplit of a dataset to evaluate the effectiveness of their methods. However,\nconsidering the multitude of personalization approaches proposed, it is\ncritical to study the per-user personalized accuracy and the accuracy\nimprovements among users with an equitable notion of fairness. To address these\nissues, we present a set of performance and fairness metrics intending to\nassess the quality of personalized FL methods. We apply these metrics to four\nrecently proposed personalized FL methods, PersFL, FedPer, pFedMe, and\nPer-FedAvg, on three different data splits of the CIFAR-10 dataset. Our\nevaluations show that the personalized model with the highest average accuracy\nacross users may not necessarily be the fairest. Our code is available at\nhttps://tinyurl.com/1hp9ywfa for public use.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 05:30:17 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Divi", "Siddharth", ""], ["Lin", "Yi-Shan", ""], ["Farrukh", "Habiba", ""], ["Celik", "Z. Berkay", ""]]}, {"id": "2107.13186", "submitter": "Zhen Xu", "authors": "Zhen Xu, Wei-Wei Tu, Isabelle Guyon", "title": "AutoML Meets Time Series Regression Design and Analysis of the\n  AutoSeries Challenge", "comments": null, "journal-ref": "ECML PKDD 2021", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing better time series with limited human effort is of interest to\nacademia and industry. Driven by business scenarios, we organized the first\nAutomated Time Series Regression challenge (AutoSeries) for the WSDM Cup 2020.\nWe present its design, analysis, and post-hoc experiments. The code submission\nrequirement precluded participants from any manual intervention, testing\nautomated machine learning capabilities of solutions, across many datasets,\nunder hardware and time limitations. We prepared 10 datasets from diverse\napplication domains (sales, power consumption, air quality, traffic, and\nparking), featuring missing data, mixed continuous and categorical variables,\nand various sampling rates. Each dataset was split into a training and a test\nsequence (which was streamed, allowing models to continuously adapt). The\nsetting of time series regression, differs from classical forecasting in that\ncovariates at the present time are known. Great strides were made by\nparticipants to tackle this AutoSeries problem, as demonstrated by the jump in\nperformance from the sample submission, and post-hoc comparisons with\nAutoGluon. Simple yet effective methods were used, based on feature\nengineering, LightGBM, and random search hyper-parameter tuning, addressing all\naspects of the challenge. Our post-hoc analyses revealed that providing\nadditional time did not yield significant improvements. The winners' code was\nopen-sourced https://www.4paradigm.com/competition/autoseries2020.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 06:30:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Xu", "Zhen", ""], ["Tu", "Wei-Wei", ""], ["Guyon", "Isabelle", ""]]}, {"id": "2107.13191", "submitter": "Barak Sober", "authors": "Ingrid Daubechies, Ronald DeVore, Nadav Dym, Shira Faigenbaum-Golovin,\n  Shahar Z. Kovalsky, Kung-Ching Lin, Josiah Park, Guergana Petrova, Barak\n  Sober", "title": "Neural Network Approximation of Refinable Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the desire to quantify the success of neural networks in deep learning and\nother applications, there is a great interest in understanding which functions\nare efficiently approximated by the outputs of neural networks. By now, there\nexists a variety of results which show that a wide range of functions can be\napproximated with sometimes surprising accuracy by these outputs. For example,\nit is known that the set of functions that can be approximated with exponential\naccuracy (in terms of the number of parameters used) includes, on one hand,\nvery smooth functions such as polynomials and analytic functions (see e.g.\n\\cite{E,S,Y}) and, on the other hand, very rough functions such as the\nWeierstrass function (see e.g. \\cite{EPGB,DDFHP}), which is nowhere\ndifferentiable. In this paper, we add to the latter class of rough functions by\nshowing that it also includes refinable functions. Namely, we show that\nrefinable functions are approximated by the outputs of deep ReLU networks with\na fixed width and increasing depth with accuracy exponential in terms of their\nnumber of parameters. Our results apply to functions used in the standard\nconstruction of wavelets as well as to functions constructed via subdivision\nalgorithms in Computer Aided Geometric Design.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 06:45:36 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Daubechies", "Ingrid", ""], ["DeVore", "Ronald", ""], ["Dym", "Nadav", ""], ["Faigenbaum-Golovin", "Shira", ""], ["Kovalsky", "Shahar Z.", ""], ["Lin", "Kung-Ching", ""], ["Park", "Josiah", ""], ["Petrova", "Guergana", ""], ["Sober", "Barak", ""]]}, {"id": "2107.13200", "submitter": "Fan Zhang", "authors": "Fan Zhang, Bo Pan, Pengfei Shao, Peng Liu (Alzheimer's Disease\n  Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle\n  flagship study of ageing), Shuwei Shen, Peng Yao, Ronald X. Xu", "title": "An explainable two-dimensional single model deep learning approach for\n  Alzheimer's disease diagnosis and brain atrophy localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early and accurate diagnosis of Alzheimer's disease (AD) and its prodromal\nperiod mild cognitive impairment (MCI) is essential for the delayed disease\nprogression and the improved quality of patients'life. The emerging\ncomputer-aided diagnostic methods that combine deep learning with structural\nmagnetic resonance imaging (sMRI) have achieved encouraging results, but some\nof them are limit of issues such as data leakage and unexplainable diagnosis.\nIn this research, we propose a novel end-to-end deep learning approach for\nautomated diagnosis of AD and localization of important brain regions related\nto the disease from sMRI data. This approach is based on a 2D single model\nstrategy and has the following differences from the current approaches: 1)\nConvolutional Neural Network (CNN) models of different structures and\ncapacities are evaluated systemically and the most suitable model is adopted\nfor AD diagnosis; 2) a data augmentation strategy named Two-stage Random\nRandAugment (TRRA) is proposed to alleviate the overfitting issue caused by\nlimited training data and to improve the classification performance in AD\ndiagnosis; 3) an explainable method of Grad-CAM++ is introduced to generate the\nvisually explainable heatmaps that localize and highlight the brain regions\nthat our model focuses on and to make our model more transparent. Our approach\nhas been evaluated on two publicly accessible datasets for two classification\ntasks of AD vs. cognitively normal (CN) and progressive MCI (pMCI) vs. stable\nMCI (sMCI). The experimental results indicate that our approach outperforms the\nstate-of-the-art approaches, including those using multi-model and 3D CNN\nmethods. The resultant localization heatmaps from our approach also highlight\nthe lateral ventricle and some disease-relevant regions of cortex, coincident\nwith the commonly affected regions during the development of AD.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 07:19:00 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhang", "Fan", "", "Alzheimer's Disease\n  Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle\n  flagship study of ageing"], ["Pan", "Bo", "", "Alzheimer's Disease\n  Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle\n  flagship study of ageing"], ["Shao", "Pengfei", "", "Alzheimer's Disease\n  Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle\n  flagship study of ageing"], ["Liu", "Peng", "", "Alzheimer's Disease\n  Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle\n  flagship study of ageing"], ["Shen", "Shuwei", ""], ["Yao", "Peng", ""], ["Xu", "Ronald X.", ""]]}, {"id": "2107.13214", "submitter": "{\\L}ukasz Struski", "authors": "{\\L}ukasz Struski, Tomasz Danel, Marek \\'Smieja, Jacek Tabor, Bartosz\n  Zieli\\'nski", "title": "SONG: Self-Organizing Neural Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a surge in research on deep interpretable neural\nnetworks with decision trees as one of the most commonly incorporated tools.\nThere are at least three advantages of using decision trees over logistic\nregression classification models: they are easy to interpret since they are\nbased on binary decisions, they can make decisions faster, and they provide a\nhierarchy of classes. However, one of the well-known drawbacks of decision\ntrees, as compared to decision graphs, is that decision trees cannot reuse the\ndecision nodes. Nevertheless, decision graphs were not commonly used in deep\nlearning due to the lack of efficient gradient-based training techniques. In\nthis paper, we fill this gap and provide a general paradigm based on Markov\nprocesses, which allows for efficient training of the special type of decision\ngraphs, which we call Self-Organizing Neural Graphs (SONG). We provide an\nextensive theoretical study of SONG, complemented by experiments conducted on\nLetter, Connect4, MNIST, CIFAR, and TinyImageNet datasets, showing that our\nmethod performs on par or better than existing decision models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 07:53:53 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Struski", "\u0141ukasz", ""], ["Danel", "Tomasz", ""], ["\u015amieja", "Marek", ""], ["Tabor", "Jacek", ""], ["Zieli\u0144ski", "Bartosz", ""]]}, {"id": "2107.13217", "submitter": "Geetika Arora", "authors": "Geetika Arora, Rohit K Bharadwaj, Kamlesh Tiwari", "title": "DeepTeeth: A Teeth-photo Based Human Authentication System for Mobile\n  and Hand-held Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes teeth-photo, a new biometric modality for human\nauthentication on mobile and hand held devices. Biometrics samples are acquired\nusing the camera mounted on mobile device with the help of a mobile application\nhaving specific markers to register the teeth area. Region of interest (RoI) is\nthen extracted using the markers and the obtained sample is enhanced using\ncontrast limited adaptive histogram equalization (CLAHE) for better visual\nclarity. We propose a deep learning architecture and novel regularization\nscheme to obtain highly discriminative embedding for small size RoI. Proposed\ncustom loss function was able to achieve perfect classification for the tiny\nRoI of $75\\times 75$ size. The model is end-to-end and few-shot and therefore\nis very efficient in terms of time and energy requirements. The system can be\nused in many ways including device unlocking and secure authentication. To the\nbest of our understanding, this is the first work on teeth-photo based\nauthentication for mobile device. Experiments have been conducted on an\nin-house teeth-photo database collected using our application. The database is\nmade publicly available. Results have shown that the proposed system has\nperfect accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 08:00:09 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Arora", "Geetika", ""], ["Bharadwaj", "Rohit K", ""], ["Tiwari", "Kamlesh", ""]]}, {"id": "2107.13226", "submitter": "Yuxin He", "authors": "Yuxin He, Lishuai Li, Xinting Zhu, Kwok Leung Tsui", "title": "Multi-Graph Convolutional-Recurrent Neural Network (MGC-RNN) for\n  Short-Term Forecasting of Transit Passenger Flow", "comments": "18 pages,15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term forecasting of passenger flow is critical for transit management\nand crowd regulation. Spatial dependencies, temporal dependencies,\ninter-station correlations driven by other latent factors, and exogenous\nfactors bring challenges to the short-term forecasts of passenger flow of urban\nrail transit networks. An innovative deep learning approach, Multi-Graph\nConvolutional-Recurrent Neural Network (MGC-RNN) is proposed to forecast\npassenger flow in urban rail transit systems to incorporate these complex\nfactors. We propose to use multiple graphs to encode the spatial and other\nheterogenous inter-station correlations. The temporal dynamics of the\ninter-station correlations are also modeled via the proposed multi-graph\nconvolutional-recurrent neural network structure. Inflow and outflow of all\nstations can be collectively predicted with multiple time steps ahead via a\nsequence to sequence(seq2seq) architecture. The proposed method is applied to\nthe short-term forecasts of passenger flow in Shenzhen Metro, China. The\nexperimental results show that MGC-RNN outperforms the benchmark algorithms in\nterms of forecasting accuracy. Besides, it is found that the inter-station\ndriven by network distance, network structure, and recent flow patterns are\nsignificant factors for passenger flow forecasting. Moreover, the architecture\nof LSTM-encoder-decoder can capture the temporal dependencies well. In general,\nthe proposed framework could provide multiple views of passenger flow dynamics\nfor fine prediction and exhibit a possibility for multi-source heterogeneous\ndata fusion in the spatiotemporal forecast tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 08:41:12 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["He", "Yuxin", ""], ["Li", "Lishuai", ""], ["Zhu", "Xinting", ""], ["Tsui", "Kwok Leung", ""]]}, {"id": "2107.13249", "submitter": "Bang Xiang Yong", "authors": "Bang Xiang Yong, Yasmin Fathy, Alexandra Brintrup", "title": "Bayesian Autoencoders for Drift Detection in Industrial Environments", "comments": "Published in 2020 IEEE International Workshop on Metrology for\n  Industry 4.0 & IoT", "journal-ref": null, "doi": "10.1109/MetroInd4.0IoT48571.2020.9138306", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoencoders are unsupervised models which have been used for detecting\nanomalies in multi-sensor environments. A typical use includes training a\npredictive model with data from sensors operating under normal conditions and\nusing the model to detect anomalies. Anomalies can come either from real\nchanges in the environment (real drift) or from faulty sensory devices (virtual\ndrift); however, the use of Autoencoders to distinguish between different\nanomalies has not yet been considered. To this end, we first propose the\ndevelopment of Bayesian Autoencoders to quantify epistemic and aleatoric\nuncertainties. We then test the Bayesian Autoencoder using a real-world\nindustrial dataset for hydraulic condition monitoring. The system is injected\nwith noise and drifts, and we have found the epistemic uncertainty to be less\nsensitive to sensor perturbations as compared to the reconstruction loss. By\nobserving the reconstructed signals with the uncertainties, we gain\ninterpretable insights, and these uncertainties offer a potential avenue for\ndistinguishing real and virtual drifts.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 10:19:58 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yong", "Bang Xiang", ""], ["Fathy", "Yasmin", ""], ["Brintrup", "Alexandra", ""]]}, {"id": "2107.13252", "submitter": "Bang Xiang Yong", "authors": "Bang Xiang Yong and Alexandra Brintrup", "title": "Multi Agent System for Machine Learning Under Uncertainty in Cyber\n  Physical Manufacturing System", "comments": "International Workshop on Service Orientation in Holonic and\n  Multi-Agent Manufacturing", "journal-ref": null, "doi": "10.17863/CAM.51696", "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in predictive machine learning has led to its application\nin various use cases in manufacturing. Most research focused on maximising\npredictive accuracy without addressing the uncertainty associated with it.\nWhile accuracy is important, focusing primarily on it poses an overfitting\ndanger, exposing manufacturers to risk, ultimately hindering the adoption of\nthese techniques. In this paper, we determine the sources of uncertainty in\nmachine learning and establish the success criteria of a machine learning\nsystem to function well under uncertainty in a cyber-physical manufacturing\nsystem (CPMS) scenario. Then, we propose a multi-agent system architecture\nwhich leverages probabilistic machine learning as a means of achieving such\ncriteria. We propose possible scenarios for which our proposed architecture is\nuseful and discuss future work. Experimentally, we implement Bayesian Neural\nNetworks for multi-tasks classification on a public dataset for the real-time\ncondition monitoring of a hydraulic system and demonstrate the usefulness of\nthe system by evaluating the probability of a prediction being accurate given\nits uncertainty. We deploy these models using our proposed agent-based\nframework and integrate web visualisation to demonstrate its real-time\nfeasibility.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 10:28:05 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yong", "Bang Xiang", ""], ["Brintrup", "Alexandra", ""]]}, {"id": "2107.13257", "submitter": "Alishiba Dsouza", "authors": "Alishiba Dsouza and Nicolas Tempelmeier and Elena Demidova", "title": "Towards Neural Schema Alignment for OpenStreetMap and Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenStreetMap (OSM) is one of the richest openly available sources of\nvolunteered geographic information. Although OSM includes various geographical\nentities, their descriptions are highly heterogeneous, incomplete, and do not\nfollow any well-defined ontology. Knowledge graphs can potentially provide\nvaluable semantic information to enrich OSM entities. However, interlinking OSM\nentities with knowledge graphs is inherently difficult due to the large,\nheterogeneous, ambiguous, and flat OSM schema and the annotation sparsity. This\npaper tackles the alignment of OSM tags with the corresponding knowledge graph\nclasses holistically by jointly considering the schema and instance layers. We\npropose a novel neural architecture that capitalizes upon a shared latent space\nfor tag-to-class alignment created using linked entities in OSM and knowledge\ngraphs. Our experiments performed to align OSM datasets for several countries\nwith two of the most prominent openly available knowledge graphs, namely,\nWikidata and DBpedia, demonstrate that the proposed approach outperforms the\nstate-of-the-art schema alignment baselines by up to 53 percentage points in\nterms of F1-score. The resulting alignment facilitates new semantic annotations\nfor over 10 million OSM entities worldwide, which is more than a 400% increase\ncompared to the existing semantic annotations in OSM.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 10:40:35 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dsouza", "Alishiba", ""], ["Tempelmeier", "Nicolas", ""], ["Demidova", "Elena", ""]]}, {"id": "2107.13265", "submitter": "Yi-feng Yang", "authors": "Dongchen Huang and Yi-feng Yang", "title": "Learned Optimizers for Analytic Continuation", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech cond-mat.str-el", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional maximum entropy and sparsity-based algorithms for analytic\ncontinuation often suffer from the ill-posed kernel matrix or demand tremendous\ncomputation time for parameter tuning. Here we propose a neural network method\nby convex optimization and replace the ill-posed inverse problem by a sequence\nof well-conditioned surrogate problems. After training, the learned optimizers\nare able to give a solution of high quality with low time cost and achieve\nhigher parameter efficiency than heuristic full-connected networks. The output\ncan also be used as a neural default model to improve the maximum entropy for\nbetter performance. Our methods may be easily extended to other\nhigh-dimensional inverse problems via large-scale pretraining.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 10:57:32 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Huang", "Dongchen", ""], ["Yang", "Yi-feng", ""]]}, {"id": "2107.13268", "submitter": "Sayantini Majumdar", "authors": "Sayantini Majumdar and Riccardo Trivisonno and Georg Carle", "title": "Q-Learning for Conflict Resolution in B5G Network Automation", "comments": "6 pages, 5 figures. This work has been submitted to the IEEE Globecom\n  2021 for possible publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network automation is gaining significant attention in the development of B5G\nnetworks, primarily for reducing operational complexity, expenditures and\nimproving network efficiency. Concurrently operating closed loops aiming for\nindividual optimization targets may cause conflicts which, left unresolved,\nwould lead to significant degradation in network Key Performance Indicators\n(KPIs), thereby resulting in sub-optimal network performance. Centralized\ncoordination, albeit optimal, is impractical in large scale networks and for\ntime-critical applications. Decentralized approaches are therefore envisaged in\nthe evolution to B5G and subsequently, 6G networks. This work explores\npervasive intelligence for conflict resolution in network automation, as an\nalternative to centralized orchestration. A Q-Learning decentralized approach\nto network automation is proposed, and an application to network slice\nauto-scaling is designed and evaluated. Preliminary results highlight the\npotential of the proposed scheme and justify further research work in this\ndirection.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:00:16 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Majumdar", "Sayantini", ""], ["Trivisonno", "Riccardo", ""], ["Carle", "Georg", ""]]}, {"id": "2107.13270", "submitter": "Ahmad Hammoudeh", "authors": "Ahmad Hammoudeh, Sara Tedmori and Nadim Obeid", "title": "A Reflection on Learning from Data: Epistemology Issues and Limitations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although learning from data is effective and has achieved significant\nmilestones, it has many challenges and limitations. Learning from data starts\nfrom observations and then proceeds to broader generalizations. This framework\nis controversial in science, yet it has achieved remarkable engineering\nsuccesses. This paper reflects on some epistemological issues and some of the\nlimitations of the knowledge discovered in data. The document discusses the\ncommon perception that getting more data is the key to achieving better machine\nlearning models from theoretical and practical perspectives. The paper sheds\nsome light on the shortcomings of using generic mathematical theories to\ndescribe the process. It further highlights the need for theories specialized\nin learning from data. While more data leverages the performance of machine\nlearning models in general, the relation in practice is shown to be logarithmic\nat its best; After a specific limit, more data stabilize or degrade the machine\nlearning models. Recent work in reinforcement learning showed that the trend is\nshifting away from data-oriented approaches and relying more on algorithms. The\npaper concludes that learning from data is hindered by many limitations. Hence\nan approach that has an intensional orientation is needed.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:05:34 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hammoudeh", "Ahmad", ""], ["Tedmori", "Sara", ""], ["Obeid", "Nadim", ""]]}, {"id": "2107.13277", "submitter": "Yue Shi", "authors": "Yue Shi, Liangxiu Han, Anthony Kleerekoper, Sheng Chang, Tongle Hu", "title": "A Novel CropdocNet for Automated Potato Late Blight Disease Detection\n  from the Unmanned Aerial Vehicle-based Hyperspectral Imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Late blight disease is one of the most destructive diseases in potato crop,\nleading to serious yield losses globally. Accurate diagnosis of the disease at\nearly stage is critical for precision disease control and management. Current\nfarm practices in crop disease diagnosis are based on manual visual inspection,\nwhich is costly, time consuming, subject to individual bias. Recent advances in\nimaging sensors (e.g. RGB, multiple spectral and hyperspectral cameras), remote\nsensing and machine learning offer the opportunity to address this challenge.\nParticularly, hyperspectral imagery (HSI) combining with machine learning/deep\nlearning approaches is preferable for accurately identifying specific plant\ndiseases because the HSI consists of a wide range of high-quality reflectance\ninformation beyond human vision, capable of capturing both spectral-spatial\ninformation. The proposed method considers the potential disease specific\nreflectance radiation variance caused by the canopy structural diversity,\nintroduces the multiple capsule layers to model the hierarchical structure of\nthe spectral-spatial disease attributes with the encapsulated features to\nrepresent the various classes and the rotation invariance of the disease\nattributes in the feature space. We have evaluated the proposed method with the\nreal UAV-based HSI data under the controlled field conditions. The\neffectiveness of the hierarchical features has been quantitatively assessed and\ncompared with the existing representative machine learning/deep learning\nmethods. The experiment results show that the proposed model significantly\nimproves the accuracy performance when considering hierarchical-structure of\nspectral-spatial features, comparing to the existing methods only using\nspectral, or spatial or spectral-spatial features without consider\nhierarchical-structure of spectral-spatial features.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:18:48 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Shi", "Yue", ""], ["Han", "Liangxiu", ""], ["Kleerekoper", "Anthony", ""], ["Chang", "Sheng", ""], ["Hu", "Tongle", ""]]}, {"id": "2107.13304", "submitter": "Bang Xiang Yong", "authors": "Bang Xiang Yong, Tim Pearce, Alexandra Brintrup", "title": "Bayesian Autoencoders: Analysing and Fixing the Bernoulli likelihood for\n  Out-of-Distribution Detection", "comments": "Presented at the ICML 2020 Workshop on Uncertainty and Ro-bustness in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  After an autoencoder (AE) has learnt to reconstruct one dataset, it might be\nexpected that the likelihood on an out-of-distribution (OOD) input would be\nlow. This has been studied as an approach to detect OOD inputs. Recent work\nshowed this intuitive approach can fail for the dataset pairs FashionMNIST vs\nMNIST. This paper suggests this is due to the use of Bernoulli likelihood and\nanalyses why this is the case, proposing two fixes: 1) Compute the uncertainty\nof likelihood estimate by using a Bayesian version of the AE. 2) Use\nalternative distributions to model the likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:51:35 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yong", "Bang Xiang", ""], ["Pearce", "Tim", ""], ["Brintrup", "Alexandra", ""]]}, {"id": "2107.13312", "submitter": "Vijay Lingam", "authors": "Vijay Lingam, Rahul Ragesh, Arun Iyer, Sundararajan Sellamanickam", "title": "Effective Eigendecomposition based Graph Adaptation for Heterophilic\n  Networks", "comments": "arXiv admin note: text overlap with arXiv:2106.12807", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) exhibit excellent performance when graphs have\nstrong homophily property, i.e. connected nodes have the same labels. However,\nthey perform poorly on heterophilic graphs. Several approaches address the\nissue of heterophily by proposing models that adapt the graph by optimizing\ntask-specific loss function using labelled data. These adaptations are made\neither via attention or by attenuating or enhancing various\nlow-frequency/high-frequency signals, as needed for the task at hand. More\nrecent approaches adapt the eigenvalues of the graph. One important\ninterpretation of this adaptation is that these models select/weigh the\neigenvectors of the graph. Based on this interpretation, we present an\neigendecomposition based approach and propose EigenNetwork models that improve\nthe performance of GNNs on heterophilic graphs. Performance improvement is\nachieved by learning flexible graph adaptation functions that modulate the\neigenvalues of the graph. Regularization of these functions via parameter\nsharing helps to improve the performance even more. Our approach achieves up to\n11% improvement in performance over the state-of-the-art methods on\nheterophilic graphs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 12:14:07 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Lingam", "Vijay", ""], ["Ragesh", "Rahul", ""], ["Iyer", "Arun", ""], ["Sellamanickam", "Sundararajan", ""]]}, {"id": "2107.13319", "submitter": "Gianpiero Canessa", "authors": "Shen Peng, Gianpiero Canessa", "title": "Chance constrained conic-segmentation support vector machine with\n  uncertain data", "comments": "Accepted paper for the IJCAI 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Support vector machines (SVM) is one of the well known supervised classes of\nlearning algorithms. Furthermore, the conic-segmentation SVM (CS-SVM) is a\nnatural multiclass analogue of the standard binary SVM, as CS-SVM models are\ndealing with the situation where the exact values of the data points are known.\nThis paper studies CS-SVM when the data points are uncertain or mislabelled.\nWith some properties known for the distributions, a chance-constrained CS-SVM\napproach is used to ensure the small probability of misclassification for the\nuncertain data. The geometric interpretation is presented to show how CS-SVM\nworks. Finally, we present experimental results to investigate the chance\nconstrained CS-SVM's performance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 12:29:47 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Peng", "Shen", ""], ["Canessa", "Gianpiero", ""]]}, {"id": "2107.13346", "submitter": "Alicia Curth", "authors": "Alicia Curth and Mihaela van der Schaar", "title": "Doing Great at Estimating CATE? On the Neglected Assumptions in\n  Benchmark Comparisons of Treatment Effect Estimators", "comments": "Workshop on the Neglected Assumptions in Causal Inference at the\n  International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning toolbox for estimation of heterogeneous treatment\neffects from observational data is expanding rapidly, yet many of its\nalgorithms have been evaluated only on a very limited set of semi-synthetic\nbenchmark datasets. In this paper, we show that even in arguably the simplest\nsetting -- estimation under ignorability assumptions -- the results of such\nempirical evaluations can be misleading if (i) the assumptions underlying the\ndata-generating mechanisms in benchmark datasets and (ii) their interplay with\nbaseline algorithms are inadequately discussed. We consider two popular machine\nlearning benchmark datasets for evaluation of heterogeneous treatment effect\nestimators -- the IHDP and ACIC2016 datasets -- in detail. We identify problems\nwith their current use and highlight that the inherent characteristics of the\nbenchmark datasets favor some algorithms over others -- a fact that is rarely\nacknowledged but of immense relevance for interpretation of empirical results.\nWe close by discussing implications and possible next steps.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:21:27 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Curth", "Alicia", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2107.13349", "submitter": "David Ruhe", "authors": "David Ruhe, Patrick Forr\\'e", "title": "Self-Supervised Hybrid Inference in State-Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform approximate inference in state-space models that allow for\nnonlinear higher-order Markov chains in latent space. The conditional\nindependencies of the generative model enable us to parameterize only an\ninference model, which learns to estimate clean states in a self-supervised\nmanner using maximum likelihood. First, we propose a recurrent method that is\ntrained directly on noisy observations. Afterward, we cast the model such that\nthe optimization problem leads to an update scheme that backpropagates through\na recursion similar to the classical Kalman filter and smoother. In scientific\napplications, domain knowledge can give a linear approximation of the latent\ntransition maps. We can easily incorporate this knowledge into our model,\nleading to a hybrid inference approach. In contrast to other methods,\nexperiments show that the hybrid method makes the inferred latent states\nphysically more interpretable and accurate, especially in low-data regimes.\nFurthermore, we do not rely on an additional parameterization of the generative\nmodel or supervision via uncorrupted observations or ground truth latent\nstates. Despite our model's simplicity, we obtain competitive results on the\nchaotic Lorenz system compared to a fully supervised approach and outperform a\nmethod based on variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:26:14 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ruhe", "David", ""], ["Forr\u00e9", "Patrick", ""]]}, {"id": "2107.13353", "submitter": "Chao Yan", "authors": "Yihong Yang, Sheng Ding, Yuwen Liu, Shunmei Meng, Xiaoxiao Chi, Rui\n  Ma, Chao Yan", "title": "Fast Wireless Sensor Anomaly Detection based on Data Stream in Edge\n  Computing Enabled Smart Greenhouse", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing enabled smart greenhouse is a representative application of\nInternet of Things technology, which can monitor the environmental information\nin real time and employ the information to contribute to intelligent\ndecision-making. In the process, anomaly detection for wireless sensor data\nplays an important role. However, traditional anomaly detection algorithms\noriginally designed for anomaly detection in static data have not properly\nconsidered the inherent characteristics of data stream produced by wireless\nsensor such as infiniteness, correlations and concept drift, which may pose a\nconsiderable challenge on anomaly detection based on data stream, and lead to\nlow detection accuracy and efficiency. First, data stream usually generates\nquickly which means that it is infinite and enormous, so any traditional\noff-line anomaly detection algorithm that attempts to store the whole dataset\nor to scan the dataset multiple times for anomaly detection will run out of\nmemory space. Second, there exist correlations among different data streams,\nwhich traditional algorithms hardly consider. Third, the underlying data\ngeneration process or data distribution may change over time. Thus, traditional\nanomaly detection algorithms with no model update will lose their effects.\nConsidering these issues, a novel method (called DLSHiForest) on basis of\nLocality-Sensitive Hashing and time window technique in this paper is proposed\nto solve these problems while achieving accurate and efficient detection.\nComprehensive experiments are executed using real-world agricultural greenhouse\ndataset to demonstrate the feasibility of our approach. Experimental results\nshow that our proposal is practicable in addressing challenges of traditional\nanomaly detection while ensuring accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:32:12 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Yang", "Yihong", ""], ["Ding", "Sheng", ""], ["Liu", "Yuwen", ""], ["Meng", "Shunmei", ""], ["Chi", "Xiaoxiao", ""], ["Ma", "Rui", ""], ["Yan", "Chao", ""]]}, {"id": "2107.13361", "submitter": "Yu Huang", "authors": "Yu Huang, Gary G. Yen and Vincent S. Tseng", "title": "Snippet Policy Network for Multi-class Varied-length ECG Early\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arrhythmia detection from ECG is an important research subject in the\nprevention and diagnosis of cardiovascular diseases. The prevailing studies\nformulate arrhythmia detection from ECG as a time series classification\nproblem. Meanwhile, early detection of arrhythmia presents a real-world demand\nfor early prevention and diagnosis. In this paper, we address a problem of\ncardiovascular disease early classification, which is a varied-length and\nlong-length time series early classification problem as well. For solving this\nproblem, we propose a deep reinforcement learning-based framework, namely\nSnippet Policy Network (SPN), consisting of four modules, snippet generator,\nbackbone network, controlling agent, and discriminator. Comparing to the\nexisting approaches, the proposed framework features flexible input length,\nsolves the dual-optimization solution of the earliness and accuracy goals.\nExperimental results demonstrate that SPN achieves an excellent performance of\nover 80\\% in terms of accuracy. Compared to the state-of-the-art methods, at\nleast 7% improvement on different metrics, including the precision, recall,\nF1-score, and harmonic mean, is delivered by the proposed SPN. To the best of\nour knowledge, this is the first work focusing on solving the cardiovascular\nearly classification problem based on varied-length ECG data. Based on these\nexcellent features from SPN, it offers a good exemplification for addressing\nall kinds of varied-length time series early classification problems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:47:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Huang", "Yu", ""], ["Yen", "Gary G.", ""], ["Tseng", "Vincent S.", ""]]}, {"id": "2107.13379", "submitter": "Patrick Feeney", "authors": "Patrick Feeney and Michael C. Hughes", "title": "Evaluating the Use of Reconstruction Error for Novelty Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The pixelwise reconstruction error of deep autoencoders is often utilized for\nimage novelty detection and localization under the assumption that pixels with\nhigh error indicate which parts of the input image are unfamiliar and therefore\nlikely to be novel. This assumed correlation between pixels with high\nreconstruction error and novel regions of input images has not been verified\nand may limit the accuracy of these methods. In this paper we utilize saliency\nmaps to evaluate whether this correlation exists. Saliency maps reveal directly\nhow much a change in each input pixel would affect reconstruction loss, while\neach pixel's reconstruction error may be attributed to many input pixels when\nlayers are fully connected. We compare saliency maps to reconstruction error\nmaps via qualitative visualizations as well as quantitative correspondence\nbetween the top K elements of the maps for both novel and normal images. Our\nresults indicate that reconstruction error maps do not closely correlate with\nthe importance of pixels in the input images, making them insufficient for\nnovelty localization.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:10:55 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Feeney", "Patrick", ""], ["Hughes", "Michael C.", ""]]}, {"id": "2107.13389", "submitter": "Rindra Ramamonjison", "authors": "Rindra Ramamonjison, Amin Banitalebi-Dehkordi, Xinyu Kang, Xiaolong\n  Bai, Yong Zhang", "title": "SimROD: A Simple Adaptation Method for Robust Object Detection", "comments": "Accepted to ICCV 2021 conference for full oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Simple and effective unsupervised adaptation method for\nRobust Object Detection (SimROD). To overcome the challenging issues of domain\nshift and pseudo-label noise, our method integrates a novel domain-centric\naugmentation method, a gradual self-labeling adaptation procedure, and a\nteacher-guided fine-tuning mechanism. Using our method, target domain samples\ncan be leveraged to adapt object detection models without changing the model\narchitecture or generating synthetic data. When applied to image corruptions\nand high-level cross-domain adaptation benchmarks, our method outperforms prior\nbaselines on multiple domain adaptation benchmarks. SimROD achieves new\nstate-of-the-art on standard real-to-synthetic and cross-camera setup\nbenchmarks. On the image corruption benchmark, models adapted with our method\nachieved a relative robustness improvement of 15-25% AP50 on Pascal-C and 5-6%\nAP on COCO-C and Cityscapes-C. On the cross-domain benchmark, our method\noutperformed the best baseline performance by up to 8% AP50 on Comic dataset\nand up to 4% on Watercolor dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:28:32 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ramamonjison", "Rindra", ""], ["Banitalebi-Dehkordi", "Amin", ""], ["Kang", "Xinyu", ""], ["Bai", "Xiaolong", ""], ["Zhang", "Yong", ""]]}, {"id": "2107.13393", "submitter": "Yoonsuck Choe", "authors": "Yoonsuck Choe", "title": "Meaning Versus Information, Prediction Versus Memory, and Question\n  Versus Answer", "comments": "14 pages", "journal-ref": null, "doi": "10.1016/B978-0-12-815480-9.00014-1", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brain science and artificial intelligence have made great progress toward the\nunderstanding and engineering of the human mind. The progress has accelerated\nsignificantly since the turn of the century thanks to new methods for probing\nthe brain (both structure and function), and rapid development in deep learning\nresearch. However, despite these new developments, there are still many open\nquestions, such as how to understand the brain at the system level, and various\nrobustness issues and limitations of deep learning. In this informal essay, I\nwill talk about some of the concepts that are central to brain science and\nartificial intelligence, such as information and memory, and discuss how a\ndifferent view on these concepts can help us move forward, beyond current\nlimits of our understanding in these fields.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:22:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Choe", "Yoonsuck", ""]]}, {"id": "2107.13394", "submitter": "Syed Hasib Akhter Faruqui", "authors": "Syed Hasib Akhter Faruqui, Adel Alaeddini, Jing Wang, Susan P\n  Fisher-Hoch, and Joseph B Mccormic", "title": "Nonlinear State Space Modeling and Control of the Impact of Patients'\n  Modifiable Lifestyle Behaviors on the Emergence of Multiple Chronic\n  Conditions", "comments": "Submitted to IEEE Access for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.SY eess.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence and progression of multiple chronic conditions (MCC) over time\noften form a dynamic network that depends on patient's modifiable risk factors\nand their interaction with non-modifiable risk factors and existing conditions.\nContinuous time Bayesian networks (CTBNs) are effective methods for modeling\nthe complex network of MCC relationships over time. However, CTBNs are not able\nto effectively formulate the dynamic impact of patient's modifiable risk\nfactors on the emergence and progression of MCC. Considering a functional CTBN\n(FCTBN) to represent the underlying structure of the MCC relationships with\nrespect to individuals' risk factors and existing conditions, we propose a\nnonlinear state-space model based on Extended Kalman filter (EKF) to capture\nthe dynamics of the patients' modifiable risk factors and existing conditions\non the MCC evolution over time. We also develop a tensor control chart to\ndynamically monitor the effect of changes in the modifiable risk factors of\nindividual patients on the risk of new chronic conditions emergence. We\nvalidate the proposed approach based on a combination of simulation and real\ndata from a dataset of 385 patients from Cameron County Hispanic Cohort (CCHC)\nover multiple years. The dataset examines the emergence of 5 chronic conditions\n(Diabetes, Obesity, Cognitive Impairment, Hyperlipidemia, and Hypertension)\nbased on 4 modifiable risk factors representing lifestyle behaviors (Diet,\nExercise, Smoking Habit, and Drinking Habit) and 3 non-modifiable risk factors,\nincluding demographic information (Age, Gender, Education). The results\ndemonstrate the effectiveness of the proposed methodology for dynamic\nprediction and monitoring of the risk of MCC emergence in individual patients.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 18:01:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Faruqui", "Syed Hasib Akhter", ""], ["Alaeddini", "Adel", ""], ["Wang", "Jing", ""], ["Fisher-Hoch", "Susan P", ""], ["Mccormic", "Joseph B", ""]]}, {"id": "2107.13404", "submitter": "James Patrick-Evans", "authors": "James Patrick-Evans, Moritz Dannehl, Johannes Kinder", "title": "XFL: eXtreme Function Labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reverse engineers would benefit from identifiers like function names, but\nthese are usually unavailable in binaries. Training a machine learning model to\npredict function names automatically is promising but fundamentally hard due to\nthe enormous number of classes. In this paper, we introduce eXtreme Function\nLabeling (XFL), an extreme multi-label learning approach to selecting\nappropriate labels for binary functions. XFL splits function names into tokens,\ntreating each as an informative label akin to the problem of tagging texts in\nnatural language. To capture the semantics of binary code, we introduce DEXTER,\na novel function embedding that combines static analysis-based features with\nlocal context from the call graph and global context from the entire binary. We\ndemonstrate that XFL outperforms state-of-the-art approaches to function\nlabeling on a dataset of over 10,000 binaries from the Debian project,\nachieving a precision of 82.5%. We also study combinations of XFL with\ndifferent published embeddings for binary functions and show that DEXTER\nconsistently improves over the state of the art in information gain. As a\nresult, we are able to show that binary function labeling is best phrased in\nterms of multi-label learning, and that binary function embeddings benefit from\nmoving beyond just learning from syntax.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:49:30 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Patrick-Evans", "James", ""], ["Dannehl", "Moritz", ""], ["Kinder", "Johannes", ""]]}, {"id": "2107.13405", "submitter": "Emanuele Lattanzi PhD.", "authors": "Emanuele Lattanzi, Lorenzo Calisti, Valerio Freschi", "title": "Automatic Unstructured Handwashing Recognition using Smartwatch to\n  Reduce Contact Transmission of Pathogens", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Current guidelines from the World Health Organization indicate that the\nSARSCoV-2 coronavirus, which results in the novel coronavirus disease\n(COVID-19), is transmitted through respiratory droplets or by contact. Contact\ntransmission occurs when contaminated hands touch the mucous membrane of the\nmouth, nose, or eyes. Moreover, pathogens can also be transferred from one\nsurface to another by contaminated hands, which facilitates transmission by\nindirect contact. Consequently, hands hygiene is extremely important to prevent\nthe spread of the SARSCoV-2 virus. Additionally, hand washing and/or hand\nrubbing disrupts also the transmission of other viruses and bacteria that cause\ncommon colds, flu and pneumonia, thereby reducing the overall disease burden.\nThe vast proliferation of wearable devices, such as smartwatches, containing\nacceleration, rotation, magnetic field sensors, etc., together with the modern\ntechnologies of artificial intelligence, such as machine learning and more\nrecently deep-learning, allow the development of accurate applications for\nrecognition and classification of human activities such as: walking, climbing\nstairs, running, clapping, sitting, sleeping, etc. In this work we evaluate the\nfeasibility of an automatic system, based on current smartwatches, which is\nable to recognize when a subject is washing or rubbing its hands, in order to\nmonitor parameters such as frequency and duration, and to evaluate the\neffectiveness of the gesture. Our preliminary results show a classification\naccuracy of about 95% and of about 94% for respectively deep and standard\nlearning techniques.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:52:45 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Lattanzi", "Emanuele", ""], ["Calisti", "Lorenzo", ""], ["Freschi", "Valerio", ""]]}, {"id": "2107.13419", "submitter": "Thangjam Clarinda Devi", "authors": "Thangjam Clarinda Devi and Kabita Thaoroijam", "title": "Vowel-based Meeteilon dialect identification using a Random Forest\n  classifier", "comments": "5 pages, double coulumn, 8 Figures, 1 table. Already presented as\n  poster presentation at OCOCOSDA 2020 but not yet published", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a vowel-based dialect identification system for\nMeeteilon. For this work, a vowel dataset is created by using Meeteilon Speech\nCorpora available at Linguistic Data Consortium for Indian Languages (LDC-IL).\nSpectral features such as formant frequencies (F1, F1 and F3) and prosodic\nfeatures such as pitch (F0), energy, intensity and segment duration values are\nextracted from monophthong vowel sounds. Random forest classifier, a decision\ntree-based ensemble algorithm is used for classification of three major\ndialects of Meeteilon namely, Imphal, Kakching and Sekmai. Model has shown an\naverage dialect identification performance in terms of accuracy of around\n61.57%. The role of spectral and prosodic features are found to be significant\nin Meeteilon dialect classification.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 04:09:00 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Devi", "Thangjam Clarinda", ""], ["Thaoroijam", "Kabita", ""]]}, {"id": "2107.13423", "submitter": "Guangliang Pan", "authors": "Guangliang Pan, Zitong Liu, Wei Wang, Minglei Li", "title": "A Signal Detection Scheme Based on Deep Learning in OFDM Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel estimation and signal detection are essential steps to ensure the\nquality of end-to-end communication in orthogonal frequency-division\nmultiplexing (OFDM) systems. In this paper, we develop a DDLSD approach, i.e.,\nData-driven Deep Learning for Signal Detection in OFDM systems. First, the OFDM\nsystem model is established. Then, the long short-term memory (LSTM) is\nintroduced into the OFDM system model. Wireless channel data is generated\nthrough simulation, the preprocessed time series feature information is input\ninto the LSTM to complete the offline training. Finally, the trained model is\nused for online recovery of transmitted signal. The difference between this\nscheme and existing OFDM receiver is that explicit estimated channel state\ninformation (CSI) is transformed into invisible estimated CSI, and the transmit\nsymbol is directly restored. Simulation results show that the DDLSD scheme\noutperforms the existing traditional methods in terms of improving channel\nestimation and signal detection performance.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 04:25:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Pan", "Guangliang", ""], ["Liu", "Zitong", ""], ["Wang", "Wei", ""], ["Li", "Minglei", ""]]}, {"id": "2107.13430", "submitter": "Kiheiji Nishida", "authors": "Kiheiji Nishida and Kanta Naito", "title": "Kernel Density Estimation by Stagewise Algorithm with a Simple\n  Dictionary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies kernel density estimation by stagewise minimization\nalgorithm with a simple dictionary on U-divergence. We randomly split an i.i.d.\nsample into the two disjoint sets, one to be used for constructing the kernels\nin the dictionary and the other for evaluating the estimator, and implement the\nalgorithm. The resulting estimator brings us data-adaptive weighting parameters\nand bandwidth matrices, and realizes a sparse representation of kernel density\nestimation. We present the non-asymptotic error bounds of our estimator and\nconfirm its performance by simulations compared with the direct plug-in\nbandwidth matrices and the reduced set density estimator.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:05:06 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Nishida", "Kiheiji", ""], ["Naito", "Kanta", ""]]}, {"id": "2107.13433", "submitter": "David Sprunger", "authors": "Mario Alvarez-Picallo, Dan R. Ghica, David Sprunger, Fabio Zanasi", "title": "Functorial String Diagrams for Reverse-Mode Automatic Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We enhance the calculus of string diagrams for monoidal categories with\nhierarchical features in order to capture closed monoidal (and cartesian\nclosed) structure. Using this new syntax we formulate an automatic\ndifferentiation algorithm for (applied) simply typed lambda calculus in the\nstyle of [Pearlmutter and Siskind 2008] and we prove for the first time its\nsoundness. To give an efficient yet principled implementation of the AD\nalgorithm we define a sound and complete representation of hierarchical string\ndiagrams as a class of hierarchical hypergraphs we call hypernets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 15:25:32 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Alvarez-Picallo", "Mario", ""], ["Ghica", "Dan R.", ""], ["Sprunger", "David", ""], ["Zanasi", "Fabio", ""]]}, {"id": "2107.13449", "submitter": "Avik Sarkar", "authors": "Avik Sarkar, Dean Lee", "title": "Self-learning Emulators and Eigenvector Continuation", "comments": "5 + 2 pages (main + supplemental), 5 + 0 figures (main +\n  supplemental)", "journal-ref": null, "doi": null, "report-no": null, "categories": "nucl-th cs.LG cs.NA hep-lat math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emulators that can bypass computationally expensive scientific calculations\nwith high accuracy and speed can enable new studies of fundamental science as\nwell as more potential applications. In this work we focus on solving a system\nof constraint equations efficiently using a new machine learning approach that\nwe call self-learning emulation. A self-learning emulator is an active learning\nprotocol that can rapidly solve a system of equations over some range of\ncontrol parameters. The key ingredient is a fast estimate of the emulator error\nthat becomes progressively more accurate as the emulator improves. This\nacceleration is possible because the emulator itself is used to estimate the\nerror, and we illustrate with two examples. The first uses cubic spline\ninterpolation to find the roots of a polynomial with variable coefficients. The\nsecond example uses eigenvector continuation to find the eigenvectors and\neigenvalues of a large Hamiltonian matrix that depends on several control\nparameters. We envision future applications of self-learning emulators for\nsolving systems of algebraic equations, linear and nonlinear differential\nequations, and linear and nonlinear eigenvalue problems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:00:47 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Sarkar", "Avik", ""], ["Lee", "Dean", ""]]}, {"id": "2107.13459", "submitter": "Hanxiao Tan", "authors": "Hanxiao Tan, Helena Kotthaus", "title": "Surrogate Model-Based Explainability Methods for Point Cloud NNs", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of autonomous driving and robotics, point clouds are showing\ntheir excellent real-time performance as raw data from most of the mainstream\n3D sensors. Therefore, point cloud neural networks have become a popular\nresearch direction in recent years. So far, however, there has been little\ndiscussion about the explainability of deep neural networks for point clouds.\nIn this paper, we propose new explainability approaches for point cloud deep\nneural networks based on local surrogate model-based methods to show which\ncomponents make the main contribution to the classification. Moreover, we\npropose a quantitative validation method for explainability methods of point\nclouds which enhances the persuasive power of explainability by dropping the\nmost positive or negative contributing features and monitoring how the\nclassification scores of specific categories change. To enable an intuitive\nexplanation of misclassified instances, we display features with confounding\ncontributions. Our new explainability approach provides a fairly accurate, more\nintuitive and widely applicable explanation for point cloud classification\ntasks. Our code is available at https://github.com/Explain3D/Explainable3D\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:13:20 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Tan", "Hanxiao", ""], ["Kotthaus", "Helena", ""]]}, {"id": "2107.13467", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Site Li, Yubin Ge, Pengyi Ye, Jane You, Jun Lu", "title": "Recursively Conditional Gaussian for Ordinal Unsupervised Domain\n  Adaptation", "comments": "Accepted to ICCV 2021 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a growing interest in unsupervised domain adaptation (UDA) to\nalleviate the data scalability issue, while the existing works usually focus on\nclassifying independently discrete labels. However, in many tasks (e.g.,\nmedical diagnosis), the labels are discrete and successively distributed. The\nUDA for ordinal classification requires inducing non-trivial ordinal\ndistribution prior to the latent space. Target for this, the partially ordered\nset (poset) is defined for constraining the latent vector. Instead of the\ntypically i.i.d. Gaussian latent prior, in this work, a recursively conditional\nGaussian (RCG) set is proposed for ordered constraint modeling, which admits a\ntractable joint distribution prior. Furthermore, we are able to control the\ndensity of content vectors that violate the poset constraint by a simple\n\"three-sigma rule\". We explicitly disentangle the cross-domain images into a\nshared ordinal prior induced ordinal content space and two separate\nsource/target ordinal-unrelated spaces, and the self-training is worked on the\nshared space exclusively for ordinal-aware domain alignment. Extensive\nexperiments on UDA medical diagnoses and facial age estimation demonstrate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:26:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Li", "Site", ""], ["Ge", "Yubin", ""], ["Ye", "Pengyi", ""], ["You", "Jane", ""], ["Lu", "Jun", ""]]}, {"id": "2107.13469", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Zhenhua Guo, Site Li, Fangxu Xing, Jane You, C.-C. Jay\n  Kuo, Georges El Fakhri, Jonghye Woo", "title": "Adversarial Unsupervised Domain Adaptation with Conditional and Label\n  Shift: Infer, Align and Iterate", "comments": "Accepted to ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an adversarial unsupervised domain adaptation (UDA)\napproach with the inherent conditional and label shifts, in which we aim to\nalign the distributions w.r.t. both $p(x|y)$ and $p(y)$. Since the label is\ninaccessible in the target domain, the conventional adversarial UDA assumes\n$p(y)$ is invariant across domains, and relies on aligning $p(x)$ as an\nalternative to the $p(x|y)$ alignment. To address this, we provide a thorough\ntheoretical and empirical analysis of the conventional adversarial UDA methods\nunder both conditional and label shifts, and propose a novel and practical\nalternative optimization scheme for adversarial UDA. Specifically, we infer the\nmarginal $p(y)$ and align $p(x|y)$ iteratively in the training, and precisely\nalign the posterior $p(y|x)$ in testing. Our experimental results demonstrate\nits effectiveness on both classification and segmentation UDA, and partial UDA.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:28:01 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Guo", "Zhenhua", ""], ["Li", "Site", ""], ["Xing", "Fangxu", ""], ["You", "Jane", ""], ["Kuo", "C. -C. Jay", ""], ["Fakhri", "Georges El", ""], ["Woo", "Jonghye", ""]]}, {"id": "2107.13472", "submitter": "Vito Walter Anelli Dr.", "authors": "Vito Walter Anelli, Alejandro Bellog\\'in, Tommaso Di Noia, Claudio\n  Pomo", "title": "Reenvisioning Collaborative Filtering vs Matrix Factorization", "comments": "Preprint, Accepted for publication at ACM RecSys 2021,9 pages", "journal-ref": null, "doi": "10.1145/3460231.3475944", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering models based on matrix factorization and learned\nsimilarities using Artificial Neural Networks (ANNs) have gained significant\nattention in recent years. This is, in part, because ANNs have demonstrated\ngood results in a wide variety of recommendation tasks. The introduction of\nANNs within the recommendation ecosystem has been recently questioned, raising\nseveral comparisons in terms of efficiency and effectiveness. One aspect most\nof these comparisons have in common is their focus on accuracy, neglecting\nother evaluation dimensions important for the recommendation, such as novelty,\ndiversity, or accounting for biases. We replicate experiments from three papers\nthat compare Neural Collaborative Filtering (NCF) and Matrix Factorization\n(MF), to extend the analysis to other evaluation dimensions. Our contribution\nshows that the experiments are entirely reproducible, and we extend the study\nincluding other accuracy metrics and two statistical hypothesis tests. We\ninvestigated the Diversity and Novelty of the recommendations, showing that MF\nprovides a better accuracy also on the long tail, although NCF provides a\nbetter item coverage and more diversified recommendations. We discuss the bias\neffect generated by the tested methods. They show a relatively small bias, but\nother recommendation baselines, with competitive accuracy performance,\nconsistently show to be less affected by this issue. This is the first work, to\nthe best of our knowledge, where several evaluation dimensions have been\nexplored for an array of SOTA algorithms covering recent adaptations of ANNs\nand MF. Hence, we show the potential these techniques may have on\nbeyond-accuracy evaluation while analyzing the effect on reproducibility these\ncomplementary dimensions may spark. Available at\ngithub.com/sisinflab/Reenvisioning-the-comparison-between-Neural-Collaborative-Filtering-and-Matrix-Factorization\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:29:38 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Bellog\u00edn", "Alejandro", ""], ["Di Noia", "Tommaso", ""], ["Pomo", "Claudio", ""]]}, {"id": "2107.13473", "submitter": "Nicolas Valenchon", "authors": "Nicolas Valenchon, Yann Bouteiller, Hugo R. Jourde, Emily B.J. Coffey\n  and Giovanni Beltrame", "title": "The Portiloop: a deep learning-based open science tool for closed-loop\n  brain stimulation", "comments": "12 pages, 13 Figures, journal paper. Open source code at\n  https://github.com/mistlab/portiloop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electroencephalography (EEG) is a method of measuring the brain's electrical\nactivity, using non-invasive scalp electrodes. In this article, we propose the\nPortiloop, a deep learning-based portable and low-cost device enabling the\nneuroscience community to capture EEG, process it in real time, detect patterns\nof interest, and respond with precisely-timed stimulation. The core of the\nPortiloop is a System on Chip composed of an Analog to Digital Converter (ADC)\nand a Field-Programmable Gate Array (FPGA). After being converted to digital by\nthe ADC, the EEG signal is processed in the FPGA. The FPGA contains an ad-hoc\nArtificial Neural Network (ANN) with convolutional and recurrent units,\ndirectly implemented in hardware. The output of the ANN is then used to trigger\nthe user-defined feedback. We use the Portiloop to develop a real-time sleep\nspindle stimulating application, as a case study. Sleep spindles are a specific\ntype of transient oscillation ($\\sim$2.5 s, 12-16 Hz) that are observed in EEG\nrecordings, and are related to memory consolidation during sleep. We tested the\nPortiloop's capacity to detect and stimulate sleep spindles in real time using\nan existing database of EEG sleep recordings. With 71% for both precision and\nrecall as compared with expert labels, the system is able to stimulate spindles\nwithin $\\sim$300 ms of their onset, enabling experimental manipulation of early\nthe entire spindle. The Portiloop can be extended to detect and stimulate other\nneural events in EEG. It is fully available to the research community as an\nopen science project.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:29:58 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Valenchon", "Nicolas", ""], ["Bouteiller", "Yann", ""], ["Jourde", "Hugo R.", ""], ["Coffey", "Emily B. J.", ""], ["Beltrame", "Giovanni", ""]]}, {"id": "2107.13477", "submitter": "Elizabeth Polgreen", "authors": "Elizabeth Polgreen, Andrew Reynolds and Sanjit A. Seshia", "title": "Satisfiability and Synthesis Modulo Oracles", "comments": "12 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classic program synthesis algorithms, such as counterexample-guided\ninductive synthesis (CEGIS), the algorithms alternate between a synthesis phase\nand an oracle (verification) phase. Many synthesis algorithms use a white-box\noracle based on satisfiability modulo theory (SMT) solvers to provide\ncounterexamples. But what if a white-box oracle is either not available or not\neasy to work with? We present a framework for solving a general class of\noracle-guided synthesis problems which we term synthesis modulo oracles. In\nthis setting, oracles may be black boxes with a query-response interface\ndefined by the synthesis problem. As a necessary component of this framework,\nwe also formalize the problem of satisfiability modulo theories and oracles,\nand present an algorithm for solving this problem. We implement a prototype\nsolver for satisfiability and synthesis modulo oracles and demonstrate that, by\nusing oracles that execute functions not easily modeled in SMT-constraints,\nsuch as recursive functions or oracles that incorporate compilation and\nexecution of code, SMTO and SyMO are able to solve problems beyond the\nabilities of standard SMT and synthesis solvers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:36:26 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Polgreen", "Elizabeth", ""], ["Reynolds", "Andrew", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "2107.13490", "submitter": "Lorenz Kummer BSc", "authors": "Lorenz Kummer, Kevin Sidak, Tabea Reichmann, Wilfried Gansterer", "title": "MARViN -- Multiple Arithmetic Resolutions Vacillating in Neural Networks", "comments": "10 pages, 5 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantization is a technique for reducing deep neural networks (DNNs) training\nand inference times, which is crucial for training in resource constrained\nenvironments or time critical inference applications. State-of-the-art (SOTA)\nquantization approaches focus on post-training quantization, i.e. quantization\nof pre-trained DNNs for speeding up inference. Very little work on quantized\ntraining exists, which neither al-lows dynamic intra-epoch precision switches\nnor em-ploys an information theory based switching heuristic. Usually, existing\napproaches require full precision refinement afterwards and enforce a global\nword length across the whole DNN. This leads to suboptimal quantization\nmappings and resource usage. Recognizing these limits, we introduce MARViN, a\nnew quantized training strategy using information theory-based intra-epoch\nprecision switching, which decides on a per-layer basis which precision should\nbe used in order to minimize quantization-induced information loss. Note that\nany quantization must leave enough precision such that future learning steps do\nnot suffer from vanishing gradients. We achieve an average speedup of 1.86\ncompared to a float32 basis while limiting mean accuracy degradation on\nAlexNet/ResNet to only -0.075%.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:57:05 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kummer", "Lorenz", ""], ["Sidak", "Kevin", ""], ["Reichmann", "Tabea", ""], ["Gansterer", "Wilfried", ""]]}, {"id": "2107.13491", "submitter": "Mira Marhaba", "authors": "Ettore Merlo, Mira Marhaba, Foutse Khomh, Houssem Ben Braiek, Giuliano\n  Antoniol", "title": "Models of Computational Profiles to Study the Likelihood of DNN\n  Metamorphic Test Cases", "comments": "9 pages (10 pages with ref.)", "journal-ref": "Published in iMLSE 2020 2nd International Workshop on Machine\n  Learning Systems Engineering https://sig-mlse.wixsite.com/imlse2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network test cases are meant to exercise different reasoning paths in\nan architecture and used to validate the prediction outcomes. In this paper, we\nintroduce \"computational profiles\" as vectors of neuron activation levels. We\ninvestigate the distribution of computational profile likelihood of metamorphic\ntest cases with respect to the likelihood distributions of training, test and\nerror control cases. We estimate the non-parametric probability densities of\nneuron activation levels for each distinct output class. Probabilities are\ninferred using training cases only, without any additional knowledge about\nmetamorphic test cases. Experiments are performed by training a network on the\nMNIST Fashion library of images and comparing prediction likelihoods with those\nobtained from error control-data and from metamorphic test cases. Experimental\nresults show that the distributions of computational profile likelihood for\ntraining and test cases are somehow similar, while the distribution of the\nrandom-noise control-data is always remarkably lower than the observed one for\nthe training and testing sets. In contrast, metamorphic test cases show a\nprediction likelihood that lies in an extended range with respect to training,\ntests, and random noise. Moreover, the presented approach allows the\nindependent assessment of different training classes and experiments to show\nthat some of the classes are more sensitive to misclassifying metamorphic test\ncases than other classes. In conclusion, metamorphic test cases represent very\naggressive tests for neural network architectures. Furthermore, since\nmetamorphic test cases force a network to misclassify those inputs whose\nlikelihood is similar to that of training cases, they could also be considered\nas adversarial attacks that evade defenses based on computational profile\nlikelihood evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:57:44 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Merlo", "Ettore", ""], ["Marhaba", "Mira", ""], ["Khomh", "Foutse", ""], ["Braiek", "Houssem Ben", ""], ["Antoniol", "Giuliano", ""]]}, {"id": "2107.13505", "submitter": "Guangyi Zhang", "authors": "Guangyi Zhang and Ali Etemad", "title": "Deep Recurrent Semi-Supervised EEG Representation Learning for Emotion\n  Recognition", "comments": "Accepted by 9th International Conference on Affective Computing and\n  Intelligent Interaction (ACII 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EEG-based emotion recognition often requires sufficient labeled training\nsamples to build an effective computational model. Labeling EEG data, on the\nother hand, is often expensive and time-consuming. To tackle this problem and\nreduce the need for output labels in the context of EEG-based emotion\nrecognition, we propose a semi-supervised pipeline to jointly exploit both\nunlabeled and labeled data for learning EEG representations. Our\nsemi-supervised framework consists of both unsupervised and supervised\ncomponents. The unsupervised part maximizes the consistency between original\nand reconstructed input data using an autoencoder, while simultaneously the\nsupervised part minimizes the cross-entropy between the input and output\nlabels. We evaluate our framework using both a stacked autoencoder and an\nattention-based recurrent autoencoder. We test our framework on the large-scale\nSEED EEG dataset and compare our results with several other popular\nsemi-supervised methods. Our semi-supervised framework with a deep\nattention-based recurrent autoencoder consistently outperforms the benchmark\nmethods, even when small sub-sets (3\\%, 5\\% and 10\\%) of the output labels are\navailable during training, achieving a new state-of-the-art semi-supervised\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:21:30 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhang", "Guangyi", ""], ["Etemad", "Ali", ""]]}, {"id": "2107.13507", "submitter": "Bassam Helou", "authors": "Bassam Helou, Aditya Dusi, Anne Collin, Noushin Mehdipour, Zhiliang\n  Chen, Cristhian Lizarazo, Calin Belta, Tichakorn Wongpiromsarn, Radboud\n  Duintjer Tebbens, Oscar Beijbom", "title": "The Reasonable Crowd: Towards evidence-based and interpretable models of\n  driving behavior", "comments": "Accepted to IROS 2021 8 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous vehicles must balance a complex set of objectives. There is no\nconsensus on how they should do so, nor on a model for specifying a desired\ndriving behavior. We created a dataset to help address some of these questions\nin a limited operating domain. The data consists of 92 traffic scenarios, with\nmultiple ways of traversing each scenario. Multiple annotators expressed their\npreference between pairs of scenario traversals. We used the data to compare an\ninstance of a rulebook, carefully hand-crafted independently of the dataset,\nwith several interpretable machine learning models such as Bayesian networks,\ndecision trees, and logistic regression trained on the dataset. To compare\ndriving behavior, these models use scores indicating by how much different\nscenario traversals violate each of 14 driving rules. The rules are\ninterpretable and designed by subject-matter experts. First, we found that\nthese rules were enough for these models to achieve a high classification\naccuracy on the dataset. Second, we found that the rulebook provides high\ninterpretability without excessively sacrificing performance. Third, the data\npointed to possible improvements in the rulebook and the rules, and to\npotential new rules. Fourth, we explored the interpretability vs performance\ntrade-off by also training non-interpretable models such as a random forest.\nFinally, we make the dataset publicly available to encourage a discussion from\nthe wider community on behavior specification for AVs. Please find it at\ngithub.com/bassam-motional/Reasonable-Crowd.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:26:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Helou", "Bassam", ""], ["Dusi", "Aditya", ""], ["Collin", "Anne", ""], ["Mehdipour", "Noushin", ""], ["Chen", "Zhiliang", ""], ["Lizarazo", "Cristhian", ""], ["Belta", "Calin", ""], ["Wongpiromsarn", "Tichakorn", ""], ["Tebbens", "Radboud Duintjer", ""], ["Beijbom", "Oscar", ""]]}, {"id": "2107.13508", "submitter": "Abbas Khosravi", "authors": "Maryam Habibpour, Hassan Gharoun, Mohammadreza Mehdipour, AmirReza\n  Tajally, Hamzeh Asgharnezhad, Afshar Shamsi, Abbas Khosravi, Miadreza\n  Shafie-Khah, Saeid Nahavandi, and Joao P.S. Catalao", "title": "Uncertainty-Aware Credit Card Fraud Detection Using Deep Learning", "comments": "10 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Countless research works of deep neural networks (DNNs) in the task of credit\ncard fraud detection have focused on improving the accuracy of point\npredictions and mitigating unwanted biases by building different network\narchitectures or learning models. Quantifying uncertainty accompanied by point\nestimation is essential because it mitigates model unfairness and permits\npractitioners to develop trustworthy systems which abstain from suboptimal\ndecisions due to low confidence. Explicitly, assessing uncertainties associated\nwith DNNs predictions is critical in real-world card fraud detection settings\nfor characteristic reasons, including (a) fraudsters constantly change their\nstrategies, and accordingly, DNNs encounter observations that are not generated\nby the same process as the training distribution, (b) owing to the\ntime-consuming process, very few transactions are timely checked by\nprofessional experts to update DNNs. Therefore, this study proposes three\nuncertainty quantification (UQ) techniques named Monte Carlo dropout, ensemble,\nand ensemble Monte Carlo dropout for card fraud detection applied on\ntransaction data. Moreover, to evaluate the predictive uncertainty estimates,\nUQ confusion matrix and several performance metrics are utilized. Through\nexperimental results, we show that the ensemble is more effective in capturing\nuncertainty corresponding to generated predictions. Additionally, we\ndemonstrate that the proposed UQ methods provide extra insight to the point\npredictions, leading to elevate the fraud prevention process.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:30:46 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Habibpour", "Maryam", ""], ["Gharoun", "Hassan", ""], ["Mehdipour", "Mohammadreza", ""], ["Tajally", "AmirReza", ""], ["Asgharnezhad", "Hamzeh", ""], ["Shamsi", "Afshar", ""], ["Khosravi", "Abbas", ""], ["Shafie-Khah", "Miadreza", ""], ["Nahavandi", "Saeid", ""], ["Catalao", "Joao P. S.", ""]]}, {"id": "2107.13522", "submitter": "Muhammad R. Hasyim", "authors": "Muhammad R. Hasyim, Clay H. Batton, Kranthi K. Mandadapu", "title": "Supervised Learning and the Finite-Temperature String Method for\n  Computing Committor Functions and Reaction Rates", "comments": "30 pages main text, 16 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG physics.chem-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A central object in the computational studies of rare events is the committor\nfunction. Though costly to compute, the committor function encodes complete\nmechanistic information of the processes involving rare events, including\nreaction rates and transition-state ensembles. Under the framework of\ntransition path theory (TPT), recent work [1] proposes an algorithm where a\nfeedback loop couples a neural network that models the committor function with\nimportance sampling, mainly umbrella sampling, which collects data needed for\nadaptive training. In this work, we show additional modifications are needed to\nimprove the accuracy of the algorithm. The first modification adds elements of\nsupervised learning, which allows the neural network to improve its prediction\nby fitting to sample-mean estimates of committor values obtained from short\nmolecular dynamics trajectories. The second modification replaces the\ncommittor-based umbrella sampling with the finite-temperature string (FTS)\nmethod, which enables homogeneous sampling in regions where transition pathways\nare located. We test our modifications on low-dimensional systems with\nnon-convex potential energy where reference solutions can be found via\nanalytical or the finite element methods, and show how combining supervised\nlearning and the FTS method yields accurate computation of committor functions\nand reaction rates. We also provide an error analysis for algorithms that use\nthe FTS method, using which reaction rates can be accurately estimated during\ntraining with a small number of samples.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:44:00 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Hasyim", "Muhammad R.", ""], ["Batton", "Clay H.", ""], ["Mandadapu", "Kranthi K.", ""]]}, {"id": "2107.13530", "submitter": "Bethan Thomas", "authors": "Samuel Kessler, Bethan Thomas, Salah Karout", "title": "Continual-wav2vec2: an Application of Continual Learning for\n  Self-Supervised Automatic Speech Recognition", "comments": "11 pages, 9 figures including references and appendix. Accepted at\n  ICML 2021 Workshop: Self-Supervised Learning for Reasoning and Perception", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a method for continual learning of speech representations for\nmultiple languages using self-supervised learning (SSL) and applying these for\nautomatic speech recognition. There is an abundance of unannotated speech, so\ncreating self-supervised representations from raw audio and finetuning on a\nsmall annotated datasets is a promising direction to build speech recognition\nsystems. Wav2vec models perform SSL on raw audio in a pretraining phase and\nthen finetune on a small fraction of annotated data. SSL models have produced\nstate of the art results for ASR. However, these models are very expensive to\npretrain with self-supervision. We tackle the problem of learning new language\nrepresentations continually from audio without forgetting a previous language\nrepresentation. We use ideas from continual learning to transfer knowledge from\na previous task to speed up pretraining a new language task. Our\ncontinual-wav2vec2 model can decrease pretraining times by 32% when learning a\nnew language task, and learn this new audio-language representation without\nforgetting previous language representation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 10:39:03 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kessler", "Samuel", ""], ["Thomas", "Bethan", ""], ["Karout", "Salah", ""]]}, {"id": "2107.13545", "submitter": "Glen Berseth", "authors": "Charles Sun, J\\k{e}drzej Orbik, Coline Devin, Brian Yang, Abhishek\n  Gupta, Glen Berseth, Sergey Levine", "title": "ReLMM: Practical RL for Learning Mobile Manipulation Skills Using Only\n  Onboard Sensors", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we study how robots can autonomously learn skills that require\na combination of navigation and grasping. Learning robotic skills in the real\nworld remains challenging without large-scale data collection and supervision.\nOur aim is to devise a robotic reinforcement learning system for learning\nnavigation and manipulation together, in an \\textit{autonomous} way without\nhuman intervention, enabling continual learning under realistic assumptions.\nSpecifically, our system, ReLMM, can learn continuously on a real-world\nplatform without any environment instrumentation, without human intervention,\nand without access to privileged information, such as maps, objects positions,\nor a global view of the environment. Our method employs a modularized policy\nwith components for manipulation and navigation, where uncertainty over the\nmanipulation success drives exploration for the navigation controller, and the\nmanipulation module provides rewards for navigation. We evaluate our method on\na room cleanup task, where the robot must navigate to and pick up items of\nscattered on the floor. After a grasp curriculum training phase, ReLMM can\nlearn navigation and grasping together fully automatically, in around 40 hours\nof real-world training.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:59:41 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Sun", "Charles", ""], ["Orbik", "J\u0119drzej", ""], ["Devin", "Coline", ""], ["Yang", "Brian", ""], ["Gupta", "Abhishek", ""], ["Berseth", "Glen", ""], ["Levine", "Sergey", ""]]}, {"id": "2107.13576", "submitter": "Chirag Raman", "authors": "Chirag Raman, Hayley Hung, Marco Loog", "title": "Social Processes: Self-Supervised Forecasting of Nonverbal Cues in\n  Social Conversations", "comments": "20 pages, 10 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The default paradigm for the forecasting of human behavior in social\nconversations is characterized by top-down approaches. These involve\nidentifying predictive relationships between low level nonverbal cues and\nfuture semantic events of interest (e.g. turn changes, group leaving). A common\nhurdle however, is the limited availability of labeled data for supervised\nlearning. In this work, we take the first step in the direction of a bottom-up\nself-supervised approach in the domain. We formulate the task of Social Cue\nForecasting to leverage the larger amount of unlabeled low-level behavior cues,\nand characterize the modeling challenges involved. To address these, we take a\nmeta-learning approach and propose the Social Process (SP) models--socially\naware sequence-to-sequence (Seq2Seq) models within the Neural Process (NP)\nfamily. SP models learn extractable representations of non-semantic future cues\nfor each participant, while capturing global uncertainty by jointly reasoning\nabout the future for all members of the group. Evaluation on synthesized and\nreal-world behavior data shows that our SP models achieve higher log-likelihood\nthan the NP baselines, and also highlights important considerations for\napplying such techniques within the domain of social human interactions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 18:01:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Raman", "Chirag", ""], ["Hung", "Hayley", ""], ["Loog", "Marco", ""]]}, {"id": "2107.13586", "submitter": "Pengfei Liu", "authors": "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi,\n  Graham Neubig", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods\n  in Natural Language Processing", "comments": "Website: http://pretrain.nlpedia.ai/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper surveys and organizes research works in a new paradigm in natural\nlanguage processing, which we dub \"prompt-based learning\". Unlike traditional\nsupervised learning, which trains a model to take in an input x and predict an\noutput y as P(y|x), prompt-based learning is based on language models that\nmodel the probability of text directly. To use these models to perform\nprediction tasks, the original input x is modified using a template into a\ntextual string prompt x' that has some unfilled slots, and then the language\nmodel is used to probabilistically fill the unfilled information to obtain a\nfinal string x, from which the final output y can be derived. This framework is\npowerful and attractive for a number of reasons: it allows the language model\nto be pre-trained on massive amounts of raw text, and by defining a new\nprompting function the model is able to perform few-shot or even zero-shot\nlearning, adapting to new scenarios with few or no labeled data. In this paper\nwe introduce the basics of this promising paradigm, describe a unified set of\nmathematical notations that can cover a wide variety of existing work, and\norganize existing work along several dimensions, e.g.the choice of pre-trained\nmodels, prompts, and tuning strategies. To make the field more accessible to\ninterested beginners, we not only make a systematic review of existing works\nand a highly structured typology of prompt-based concepts, but also release\nother resources, e.g., a website http://pretrain.nlpedia.ai/ including\nconstantly-updated survey, and paperlist.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 18:09:46 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Liu", "Pengfei", ""], ["Yuan", "Weizhe", ""], ["Fu", "Jinlan", ""], ["Jiang", "Zhengbao", ""], ["Hayashi", "Hiroaki", ""], ["Neubig", "Graham", ""]]}, {"id": "2107.13600", "submitter": "Michael Jones", "authors": "Sai Saketh Rambhatla, Michael Jones, Rama Chellappa", "title": "To Boost or not to Boost: On the Limits of Boosted Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Boosting is a method for finding a highly accurate hypothesis by linearly\ncombining many ``weak\" hypotheses, each of which may be only moderately\naccurate. Thus, boosting is a method for learning an ensemble of classifiers.\nWhile boosting has been shown to be very effective for decision trees, its\nimpact on neural networks has not been extensively studied. We prove one\nimportant difference between sums of decision trees compared to sums of\nconvolutional neural networks (CNNs) which is that a sum of decision trees\ncannot be represented by a single decision tree with the same number of\nparameters while a sum of CNNs can be represented by a single CNN. Next, using\nstandard object recognition datasets, we verify experimentally the well-known\nresult that a boosted ensemble of decision trees usually generalizes much\nbetter on testing data than a single decision tree with the same number of\nparameters. In contrast, using the same datasets and boosting algorithms, our\nexperiments show the opposite to be true when using neural networks (both CNNs\nand multilayer perceptrons (MLPs)). We find that a single neural network\nusually generalizes better than a boosted ensemble of smaller neural networks\nwith the same total number of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:10:03 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Rambhatla", "Sai Saketh", ""], ["Jones", "Michael", ""], ["Chellappa", "Rama", ""]]}, {"id": "2107.13610", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Pengfei He, Chenghui Li", "title": "Large sample spectral analysis of graph-based multi-manifold clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DG math.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study statistical properties of graph-based algorithms for\nmulti-manifold clustering (MMC). In MMC the goal is to retrieve the\nmulti-manifold structure underlying a given Euclidean data set when this one is\nassumed to be obtained by sampling a distribution on a union of manifolds\n$\\mathcal{M} = \\mathcal{M}_1 \\cup\\dots \\cup \\mathcal{M}_N$ that may intersect\nwith each other and that may have different dimensions. We investigate\nsufficient conditions that similarity graphs on data sets must satisfy in order\nfor their corresponding graph Laplacians to capture the right geometric\ninformation to solve the MMC problem. Precisely, we provide high probability\nerror bounds for the spectral approximation of a tensorized Laplacian on\n$\\mathcal{M}$ with a suitable graph Laplacian built from the observations; the\nrecovered tensorized Laplacian contains all geometric information of all the\nindividual underlying manifolds. We provide an example of a family of\nsimilarity graphs, which we call annular proximity graphs with angle\nconstraints, satisfying these sufficient conditions. We contrast our family of\ngraphs with other constructions in the literature based on the alignment of\ntangent planes. Extensive numerical experiments expand the insights that our\ntheory provides on the MMC problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:39:12 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["He", "Pengfei", ""], ["Li", "Chenghui", ""]]}, {"id": "2107.13617", "submitter": "Carlos Lordelo", "authors": "Carlos Lordelo, Emmanouil Benetos, Simon Dixon and Sven Ahlb\\\"ack", "title": "Pitch-Informed Instrument Assignment Using a Deep Convolutional Network\n  with Multiple Kernel Shapes", "comments": "4 figures, 4 tables and 7 pages. Accepted for publication at ISMIR\n  Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a deep convolutional neural network for performing\nnote-level instrument assignment. Given a polyphonic multi-instrumental music\nsignal along with its ground truth or predicted notes, the objective is to\nassign an instrumental source for each note. This problem is addressed as a\npitch-informed classification task where each note is analysed individually. We\nalso propose to utilise several kernel shapes in the convolutional layers in\norder to facilitate learning of efficient timbre-discriminative feature maps.\nExperiments on the MusicNet dataset using 7 instrument classes show that our\napproach is able to achieve an average F-score of 0.904 when the original\nmulti-pitch annotations are used as the pitch information for the system, and\nthat it also excels if the note information is provided using third-party\nmulti-pitch estimation algorithms. We also include ablation studies\ninvestigating the effects of the use of multiple kernel shapes and comparing\ndifferent input representations for the audio and the note-related information.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:48:09 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lordelo", "Carlos", ""], ["Benetos", "Emmanouil", ""], ["Dixon", "Simon", ""], ["Ahlb\u00e4ck", "Sven", ""]]}, {"id": "2107.13619", "submitter": "Stefanos Antaris", "authors": "Stefanos Antaris, Dimitrios Rafailidis, Sarunas Girdzijauskas", "title": "A Deep Graph Reinforcement Learning Model for Improving User Experience\n  in Live Video Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we present a deep graph reinforcement learning model to predict\nand improve the user experience during a live video streaming event,\norchestrated by an agent/tracker. We first formulate the user experience\nprediction problem as a classification task, accounting for the fact that most\nof the viewers at the beginning of an event have poor quality of experience due\nto low-bandwidth connections and limited interactions with the tracker. In our\nmodel we consider different factors that influence the quality of user\nexperience and train the proposed model on diverse state-action transitions\nwhen viewers interact with the tracker. In addition, provided that past events\nhave various user experience characteristics we follow a gradient boosting\nstrategy to compute a global model that learns from different events. Our\nexperiments with three real-world datasets of live video streaming events\ndemonstrate the superiority of the proposed model against several baseline\nstrategies. Moreover, as the majority of the viewers at the beginning of an\nevent has poor experience, we show that our model can significantly increase\nthe number of viewers with high quality experience by at least 75% over the\nfirst streaming minutes. Our evaluation datasets and implementation are\npublicly available at https://publicresearch.z13.web.core.windows.net\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:53:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Antaris", "Stefanos", ""], ["Rafailidis", "Dimitrios", ""], ["Girdzijauskas", "Sarunas", ""]]}, {"id": "2107.13625", "submitter": "William Paul", "authors": "William Paul, Philippe Burlina", "title": "Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive\n  Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When deploying artificial intelligence (AI) in the real world, being able to\ntrust the operation of the AI by characterizing how it performs is an\never-present and important topic. An important and still largely unexplored\ntask in this characterization is determining major factors within the real\nworld that affect the AI's behavior, such as weather conditions or lighting,\nand either a) being able to give justification for why it may have failed or b)\neliminating the influence the factor has. Determining these sensitive factors\nheavily relies on collected data that is diverse enough to cover numerous\ncombinations of these factors, which becomes more onerous when having many\npotential sensitive factors or operating in complex environments. This paper\ninvestigates methods that discover and separate out individual semantic\nsensitive factors from a given dataset to conduct this characterization as well\nas addressing mitigation of these factors' sensitivity. We also broaden\nremediation of fairness, which normally only addresses socially relevant\nfactors, and widen it to deal with the desensitization of AI with regard to all\npossible aspects of variation in the domain. The proposed methods which\ndiscover these major factors reduce the potentially onerous demands of\ncollecting a sufficiently diverse dataset. In experiments using the road sign\n(GTSRB) and facial imagery (CelebA) datasets, we show the promise of using this\nscheme to perform this characterization and remediation and demonstrate that\nour approach outperforms state of the art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:18:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "William", ""], ["Burlina", "Philippe", ""]]}, {"id": "2107.13639", "submitter": "Wentao Wang", "authors": "Wentao Wang, Han Xu, Xiaorui Liu, Yaxin Li, Bhavani Thuraisingham,\n  Jiliang Tang", "title": "Imbalanced Adversarial Training with Reweighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has been empirically proven to be one of the most\neffective and reliable defense methods against adversarial attacks. However,\nalmost all existing studies about adversarial training are focused on balanced\ndatasets, where each class has an equal amount of training examples. Research\non adversarial training with imbalanced training datasets is rather limited. As\nthe initial effort to investigate this problem, we reveal the facts that\nadversarially trained models present two distinguished behaviors from naturally\ntrained models in imbalanced datasets: (1) Compared to natural training,\nadversarially trained models can suffer much worse performance on\nunder-represented classes, when the training dataset is extremely imbalanced.\n(2) Traditional reweighting strategies may lose efficacy to deal with the\nimbalance issue for adversarial training. For example, upweighting the\nunder-represented classes will drastically hurt the model's performance on\nwell-represented classes, and as a result, finding an optimal reweighting value\ncan be tremendously challenging. In this paper, to further understand our\nobservations, we theoretically show that the poor data separability is one key\nreason causing this strong tension between under-represented and\nwell-represented classes. Motivated by this finding, we propose Separable\nReweighted Adversarial Training (SRAT) to facilitate adversarial training under\nimbalanced scenarios, by learning more separable features for different\nclasses. Extensive experiments on various datasets verify the effectiveness of\nthe proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:51:36 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wang", "Wentao", ""], ["Xu", "Han", ""], ["Liu", "Xiaorui", ""], ["Li", "Yaxin", ""], ["Thuraisingham", "Bhavani", ""], ["Tang", "Jiliang", ""]]}, {"id": "2107.13640", "submitter": "Amit Chaulwar", "authors": "Amit Chaulwar and Michael Huth", "title": "Secure Bayesian Federated Analytics for Privacy-Preserving Trend\n  Detection", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated analytics has many applications in edge computing, its use can lead\nto better decision making for service provision, product development, and user\nexperience. We propose a Bayesian approach to trend detection in which the\nprobability of a keyword being trendy, given a dataset, is computed via Bayes'\nTheorem; the probability of a dataset, given that a keyword is trendy, is\ncomputed through secure aggregation of such conditional probabilities over\nlocal datasets of users. We propose a protocol, named SAFE, for Bayesian\nfederated analytics that offers sufficient privacy for production grade use\ncases and reduces the computational burden of users and an aggregator. We\nillustrate this approach with a trend detection experiment and discuss how this\napproach could be extended further to make it production-ready.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:52:28 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chaulwar", "Amit", ""], ["Huth", "Michael", ""]]}, {"id": "2107.13646", "submitter": "Mattia Medina Grespan", "authors": "Mattia Medina Grespan, Ashim Gupta and Vivek Srikumar", "title": "Evaluating Relaxations of Logic for Neural Networks: A Comprehensive\n  Study", "comments": "IJCAI 2021 paper (Extended Version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic knowledge can provide crucial inductive bias for training neural\nmodels, especially in low data regimes. A successful strategy for incorporating\nsuch knowledge involves relaxing logical statements into sub-differentiable\nlosses for optimization. In this paper, we study the question of how best to\nrelax logical expressions that represent labeled examples and knowledge about a\nproblem; we focus on sub-differentiable t-norm relaxations of logic. We present\ntheoretical and empirical criteria for characterizing which relaxation would\nperform best in various scenarios. In our theoretical study driven by the goal\nof preserving tautologies, the Lukasiewicz t-norm performs best. However, in\nour empirical analysis on the text chunking and digit recognition tasks, the\nproduct t-norm achieves best predictive performance. We analyze this apparent\ndiscrepancy, and conclude with a list of best practices for defining loss\nfunctions via logic.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 21:16:58 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Grespan", "Mattia Medina", ""], ["Gupta", "Ashim", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2107.13648", "submitter": "Peter Van Der Putten", "authors": "Michail Tsiaousis, Gertjan Burghouts, Fieke Hillerstr\\\"om and Peter\n  van der Putten", "title": "Spot What Matters: Learning Context Using Graph Convolutional Networks\n  for Weakly-Supervised Action Detection", "comments": "Paper presented at the International Workshop on Deep Learning for\n  Human-Centric Activity Understanding (DL-HAU2020), January 11, 2021", "journal-ref": "International Workshop on Deep Learning for Human-Centric Activity\n  Understanding (DL-HAU2020), January 11, 2021", "doi": "10.1007/978-3-030-68799-1_9", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dominant paradigm in spatiotemporal action detection is to classify\nactions using spatiotemporal features learned by 2D or 3D Convolutional\nNetworks. We argue that several actions are characterized by their context,\nsuch as relevant objects and actors present in the video. To this end, we\nintroduce an architecture based on self-attention and Graph Convolutional\nNetworks in order to model contextual cues, such as actor-actor and\nactor-object interactions, to improve human action detection in video. We are\ninterested in achieving this in a weakly-supervised setting, i.e. using as less\nannotations as possible in terms of action bounding boxes. Our model aids\nexplainability by visualizing the learned context as an attention map, even for\nactions and objects unseen during training. We evaluate how well our model\nhighlights the relevant context by introducing a quantitative metric based on\nrecall of objects retrieved by attention maps. Our model relies on a 3D\nconvolutional RGB stream, and does not require expensive optical flow\ncomputation. We evaluate our models on the DALY dataset, which consists of\nhuman-object interaction actions. Experimental results show that our\ncontextualized approach outperforms a baseline action detection approach by\nmore than 2 points in Video-mAP. Code is available at\n\\url{https://github.com/micts/acgcn}\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 21:37:18 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Tsiaousis", "Michail", ""], ["Burghouts", "Gertjan", ""], ["Hillerstr\u00f6m", "Fieke", ""], ["van der Putten", "Peter", ""]]}, {"id": "2107.13653", "submitter": "Koushik Roy", "authors": "Koushik Roy, Abtahi Ishmam, Kazi Abu Taher", "title": "Demand Forecasting in Smart Grid Using Long Short-Term Memory", "comments": "5 pages, 6 figures, 2021 International Conference on Automation,\n  Control and Mechatronics for Industry 4.0 (ACMI), 8-9 July 2021, Rajshahi,\n  Bangladesh", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Demand forecasting in power sector has become an important part of modern\ndemand management and response systems with the rise of smart metering enabled\ngrids. Long Short-Term Memory (LSTM) shows promising results in predicting time\nseries data which can also be applied to power load demand in smart grids. In\nthis paper, an LSTM based model using neural network architecture is proposed\nto forecast power demand. The model is trained with hourly energy and power\nusage data of four years from a smart grid. After training and prediction, the\naccuracy of the model is compared against the traditional statistical time\nseries analysis algorithms, such as Auto-Regressive (AR), to determine the\nefficiency. The mean absolute percentile error is found to be 1.22 in the\nproposed LSTM model, which is the lowest among the other models. From the\nfindings, it is clear that the inclusion of neural network in predicting power\ndemand reduces the error of prediction significantly. Thus, the application of\nLSTM can enable a more efficient demand response system.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 21:45:54 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Roy", "Koushik", ""], ["Ishmam", "Abtahi", ""], ["Taher", "Kazi Abu", ""]]}, {"id": "2107.13656", "submitter": "Gholamali Aminian", "authors": "Gholamali Aminian, Yuheng Bu, Laura Toni, Miguel R. D. Rodrigues and\n  Gregory Wornell", "title": "Characterizing the Generalization Error of Gibbs Algorithm with\n  Symmetrized KL information", "comments": "The first and second author have contributed equally to the paper.\n  This paper is accepted in the ICML-21 Workshop on Information-Theoretic\n  Methods for Rigorous, Responsible, and Reliable Machine Learning:\n  https://sites.google.com/view/itr3/schedule", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bounding the generalization error of a supervised learning algorithm is one\nof the most important problems in learning theory, and various approaches have\nbeen developed. However, existing bounds are often loose and lack of\nguarantees. As a result, they may fail to characterize the exact generalization\nability of a learning algorithm. Our main contribution is an exact\ncharacterization of the expected generalization error of the well-known Gibbs\nalgorithm in terms of symmetrized KL information between the input training\nsamples and the output hypothesis. Such a result can be applied to tighten\nexisting expected generalization error bound. Our analysis provides more\ninsight on the fundamental role the symmetrized KL information plays in\ncontrolling the generalization error of the Gibbs algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 22:20:34 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Aminian", "Gholamali", ""], ["Bu", "Yuheng", ""], ["Toni", "Laura", ""], ["Rodrigues", "Miguel R. D.", ""], ["Wornell", "Gregory", ""]]}, {"id": "2107.13657", "submitter": "Gautam Goel", "authors": "Gautam Goel and Babak Hassibi", "title": "Competitive Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider control from the perspective of competitive analysis. Unlike much\nprior work on learning-based control, which focuses on minimizing regret\nagainst the best controller selected in hindsight from some specific class, we\nfocus on designing an online controller which competes against a clairvoyant\noffline optimal controller. A natural performance metric in this setting is\ncompetitive ratio, which is the ratio between the cost incurred by the online\ncontroller and the cost incurred by the offline optimal controller. Using\noperator-theoretic techniques from robust control, we derive a computationally\nefficient state-space description of the the controller with optimal\ncompetitive ratio in both finite-horizon and infinite-horizon settings. We\nextend competitive control to nonlinear systems using Model Predictive Control\n(MPC) and present numerical experiments which show that our competitive\ncontroller can significantly outperform standard $H_2$ and $H_{\\infty}$\ncontrollers in the MPC setting.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 22:26:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Goel", "Gautam", ""], ["Hassibi", "Babak", ""]]}, {"id": "2107.13671", "submitter": "Sebastian Raschka", "authors": "Sebastian Raschka", "title": "Deeper Learning By Doing: Integrating Hands-On Research Projects Into a\n  Machine Learning Course", "comments": "This paper was accepted to the Teaching Machine Learning Workshop at\n  ECML 2021 (https://teaching-ml.github.io/2021/). Reviews and comments are\n  available at https://openreview.net/forum?id=yFPqbprG2Qb&noteId=rSPC7tA6Pi_", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has seen a vast increase of interest in recent years, along\nwith an abundance of learning resources. While conventional lectures provide\nstudents with important information and knowledge, we also believe that\nadditional project-based learning components can motivate students to engage in\ntopics more deeply. In addition to incorporating project-based learning in our\ncourses, we aim to develop project-based learning components aligned with\nreal-world tasks, including experimental design and execution, report writing,\noral presentation, and peer-reviewing. This paper describes the organization of\nour project-based machine learning courses with a particular emphasis on the\nclass project components and shares our resources with instructors who would\nlike to include similar elements in their courses.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 23:41:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Raschka", "Sebastian", ""]]}, {"id": "2107.13673", "submitter": "Luisa Fernanda Roa Ballen", "authors": "Jaime D. Acevedo-Viloria, Luisa Roa, Soji Adeshina, Cesar Charalla\n  Olazo, Andr\\'es Rodr\\'iguez-Rey, Jose Alberto Ramos, Alejandro Correa-Bahnsen", "title": "Relational Graph Neural Networks for Fraud Detection in a Super-Appe\n  nvironment", "comments": "Accepted to be appeared in 2021 KDD Workshop on ML in Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.GN", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Large digital platforms create environments where different types of user\ninteractions are captured, these relationships offer a novel source of\ninformation for fraud detection problems. In this paper we propose a framework\nof relational graph convolutional networks methods for fraudulent behaviour\nprevention in the financial services of a Super-App. To this end, we apply the\nframework on different heterogeneous graphs of users, devices, and credit\ncards; and finally use an interpretability algorithm for graph neural networks\nto determine the most important relations to the classification task of the\nusers. Our results show that there is an added value when considering models\nthat take advantage of the alternative data of the Super-App and the\ninteractions found in their high connectivity, further proofing how they can\nleverage that into better decisions and fraud detection strategies.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 00:02:06 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Acevedo-Viloria", "Jaime D.", ""], ["Roa", "Luisa", ""], ["Adeshina", "Soji", ""], ["Olazo", "Cesar Charalla", ""], ["Rodr\u00edguez-Rey", "Andr\u00e9s", ""], ["Ramos", "Jose Alberto", ""], ["Correa-Bahnsen", "Alejandro", ""]]}, {"id": "2107.13686", "submitter": "Yichun Yin", "authors": "Yichun Yin, Cheng Chen, Lifeng Shang, Xin Jiang, Xiao Chen, Qun Liu", "title": "AutoTinyBERT: Automatic Hyper-parameter Optimization for Efficient\n  Pre-trained Language Models", "comments": "ACL 2021. The code and models are released at\n  https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/AutoTinyBERT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (PLMs) have achieved great success in natural\nlanguage processing. Most of PLMs follow the default setting of architecture\nhyper-parameters (e.g., the hidden dimension is a quarter of the intermediate\ndimension in feed-forward sub-networks) in BERT (Devlin et al., 2019). Few\nstudies have been conducted to explore the design of architecture\nhyper-parameters in BERT, especially for the more efficient PLMs with tiny\nsizes, which are essential for practical deployment on resource-constrained\ndevices. In this paper, we adopt the one-shot Neural Architecture Search (NAS)\nto automatically search architecture hyper-parameters. Specifically, we\ncarefully design the techniques of one-shot learning and the search space to\nprovide an adaptive and efficient development way of tiny PLMs for various\nlatency constraints. We name our method AutoTinyBERT and evaluate its\neffectiveness on the GLUE and SQuAD benchmarks. The extensive experiments show\nthat our method outperforms both the SOTA search-based baseline (NAS-BERT) and\nthe SOTA distillation-based methods (such as DistilBERT, TinyBERT, MiniLM and\nMobileBERT). In addition, based on the obtained architectures, we propose a\nmore efficient development method that is even faster than the development of a\nsingle PLM.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 00:47:30 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Yin", "Yichun", ""], ["Chen", "Cheng", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Liu", "Qun", ""]]}, {"id": "2107.13720", "submitter": "Xinyang Feng", "authors": "Xinyang Feng, Dongjin Song, Yuncong Chen, Zhengzhang Chen, Jingchao\n  Ni, Haifeng Chen", "title": "Convolutional Transformer based Dual Discriminator Generative\n  Adversarial Networks for Video Anomaly Detection", "comments": "Accepted for publication in the 29th ACM International Conference on\n  Multimedia (ACMMM '21)", "journal-ref": null, "doi": "10.1145/3474085.3475693", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting abnormal activities in real-world surveillance videos is an\nimportant yet challenging task as the prior knowledge about video anomalies is\nusually limited or unavailable. Despite that many approaches have been\ndeveloped to resolve this problem, few of them can capture the normal\nspatio-temporal patterns effectively and efficiently. Moreover, existing works\nseldom explicitly consider the local consistency at frame level and global\ncoherence of temporal dynamics in video sequences. To this end, we propose\nConvolutional Transformer based Dual Discriminator Generative Adversarial\nNetworks (CT-D2GAN) to perform unsupervised video anomaly detection.\nSpecifically, we first present a convolutional transformer to perform future\nframe prediction. It contains three key components, i.e., a convolutional\nencoder to capture the spatial information of the input video clips, a temporal\nself-attention module to encode the temporal dynamics, and a convolutional\ndecoder to integrate spatio-temporal features and predict the future frame.\nNext, a dual discriminator based adversarial training procedure, which jointly\nconsiders an image discriminator that can maintain the local consistency at\nframe-level and a video discriminator that can enforce the global coherence of\ntemporal dynamics, is employed to enhance the future frame prediction. Finally,\nthe prediction error is used to identify abnormal video frames. Thoroughly\nempirical studies on three public video anomaly detection datasets, i.e., UCSD\nPed2, CUHK Avenue, and Shanghai Tech Campus, demonstrate the effectiveness of\nthe proposed adversarial spatio-temporal modeling framework.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:07:25 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Feng", "Xinyang", ""], ["Song", "Dongjin", ""], ["Chen", "Yuncong", ""], ["Chen", "Zhengzhang", ""], ["Ni", "Jingchao", ""], ["Chen", "Haifeng", ""]]}, {"id": "2107.13721", "submitter": "Bayan Saparbayeva", "authors": "Zhengwu Zhang and Bayan Saparbayeva", "title": "Amplitude Mean of Functional Data on $\\mathbb{S}^2$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.FA stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mainfold-valued functional data analysis (FDA) recently becomes an active\narea of research motivated by the raising availability of trajectories or\nlongitudinal data observed on non-linear manifolds. The challenges of analyzing\nsuch data comes from many aspects, including infinite dimensionality and\nnonlinearity, as well as time domain or phase variability. In this paper, we\nstudy the amplitude part of manifold-valued functions on $\\S^2$, which is\ninvariant to random time warping or re-parameterization of the function.\nUtilizing the nice geometry of $\\S^2$, we develop a set of efficient and\naccurate tools for temporal alignment of functions, geodesic and sample mean\ncalculation. At the heart of these tools, they rely on gradient descent\nalgorithms with carefully derived gradients. We show the advantages of these\nnewly developed tools over its competitors with extensive simulations and real\ndata, and demonstrate the importance of considering the amplitude part of\nfunctions instead of mixing it with phase variability in mainfold-valued FDA.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:11:26 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhang", "Zhengwu", ""], ["Saparbayeva", "Bayan", ""]]}, {"id": "2107.13735", "submitter": "Yubin Lu", "authors": "Yubin Lu, Romit Maulik, Ting Gao, Felix Dietrich, Ioannis G.\n  Kevrekidis, Jinqiao Duan", "title": "Learning the temporal evolution of multivariate densities via\n  normalizing flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a method to learn probability distributions using\nsample path data from stochastic differential equations. Specifically, we\nconsider temporally evolving probability distributions (e.g., those produced by\nintegrating local or nonlocal Fokker-Planck equations). We analyze this\nevolution through machine learning assisted construction of a time-dependent\nmapping that takes a reference distribution (say, a Gaussian) to each and every\ninstance of our evolving distribution. If the reference distribution is the\ninitial condition of a Fokker-Planck equation, what we learn is the time-T map\nof the corresponding solution. Specifically, the learned map is a normalizing\nflow that deforms the support of the reference density to the support of each\nand every density snapshot in time. We demonstrate that this approach can learn\nsolutions to non-local Fokker-Planck equations, such as those arising in\nsystems driven by both Brownian and L\\'evy noise. We present examples with two-\nand three-dimensional, uni- and multimodal distributions to validate the\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 04:05:02 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lu", "Yubin", ""], ["Maulik", "Romit", ""], ["Gao", "Ting", ""], ["Dietrich", "Felix", ""], ["Kevrekidis", "Ioannis G.", ""], ["Duan", "Jinqiao", ""]]}, {"id": "2107.13743", "submitter": "Hikmat Farhat", "authors": "Hikmat Farhat and Veronica Rammouz", "title": "Malware Classification Using Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of the number of devices on the Internet, malware poses\na threat not only to the affected devices but also their ability to use said\ndevices to launch attacks on the Internet ecosystem. Rapid malware\nclassification is an important tools to combat that threat. One of the\nsuccessful approaches to classification is based on malware images and deep\nlearning. While many deep learning architectures are very accurate they usually\ntake a long time to train. In this work we perform experiments on multiple well\nknown, pre-trained, deep network architectures in the context of transfer\nlearning. We show that almost all them classify malware accurately with a very\nshort training period.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 04:34:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Farhat", "Hikmat", ""], ["Rammouz", "Veronica", ""]]}, {"id": "2107.13772", "submitter": "Dorina Weichert", "authors": "Dorina Weichert, Alexander Kister", "title": "Bayesian Optimization for Min Max Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A solution that is only reliable under favourable conditions is hardly a safe\nsolution. Min Max Optimization is an approach that returns optima that are\nrobust against worst case conditions. We propose algorithms that perform Min\nMax Optimization in a setting where the function that should be optimized is\nnot known a priori and hence has to be learned by experiments. Therefore we\nextend the Bayesian Optimization setting, which is tailored to maximization\nproblems, to Min Max Optimization problems. While related work extends the two\nacquisition functions Expected Improvement and Gaussian Process Upper\nConfidence Bound; we extend the two acquisition functions Entropy Search and\nKnowledge Gradient. These acquisition functions are able to gain knowledge\nabout the optimum instead of just looking for points that are supposed to be\noptimal. In our evaluation we show that these acquisition functions allow for\nbetter solutions - converging faster to the optimum than the benchmark\nsettings.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 06:49:34 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Weichert", "Dorina", ""], ["Kister", "Alexander", ""]]}, {"id": "2107.13782", "submitter": "Anil Rahate", "authors": "Anil Rahate, Rahee Walambe, Sheela Ramanna, Ketan Kotecha", "title": "Multimodal Co-learning: Challenges, Applications with Datasets, Recent\n  Advances and Future Directions", "comments": "This is under review with a scientific journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multimodal deep learning systems which employ multiple modalities like text,\nimage, audio, video, etc., are showing better performance in comparison with\nindividual modalities (i.e., unimodal) systems. Multimodal machine learning\ninvolves multiple aspects: representation, translation, alignment, fusion, and\nco-learning. In the current state of multimodal machine learning, the\nassumptions are that all modalities are present, aligned, and noiseless during\ntraining and testing time. However, in real-world tasks, typically, it is\nobserved that one or more modalities are missing, noisy, lacking annotated\ndata, have unreliable labels, and are scarce in training or testing and or\nboth. This challenge is addressed by a learning paradigm called multimodal\nco-learning. The modeling of a (resource-poor) modality is aided by exploiting\nknowledge from another (resource-rich) modality using transfer of knowledge\nbetween modalities, including their representations and predictive models.\nCo-learning being an emerging area, there are no dedicated reviews explicitly\nfocusing on all challenges addressed by co-learning. To that end, in this work,\nwe provide a comprehensive survey on the emerging area of multimodal\nco-learning that has not been explored in its entirety yet. We review\nimplementations that overcome one or more co-learning challenges without\nexplicitly considering them as co-learning challenges. We present the\ncomprehensive taxonomy of multimodal co-learning based on the challenges\naddressed by co-learning and associated implementations. The various techniques\nemployed to include the latest ones are reviewed along with some of the\napplications and datasets. Our final goal is to discuss challenges and\nperspectives along with the important ideas and directions for future work that\nwe hope to be beneficial for the entire research community focusing on this\nexciting domain.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 07:25:21 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Rahate", "Anil", ""], ["Walambe", "Rahee", ""], ["Ramanna", "Sheela", ""], ["Kotecha", "Ketan", ""]]}, {"id": "2107.13790", "submitter": "Gaurav Gupta", "authors": "Gaurav Gupta, Chenzhong Yin, Jyotirmoy V. Deshmukh, Paul Bogdan", "title": "Non-Markovian Reinforcement Learning using Fractional Dynamics", "comments": "14 pages, 3 figures, CDC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reinforcement learning (RL) is a technique to learn the control policy for an\nagent that interacts with a stochastic environment. In any given state, the\nagent takes some action, and the environment determines the probability\ndistribution over the next state as well as gives the agent some reward. Most\nRL algorithms typically assume that the environment satisfies Markov\nassumptions (i.e. the probability distribution over the next state depends only\non the current state). In this paper, we propose a model-based RL technique for\na system that has non-Markovian dynamics. Such environments are common in many\nreal-world applications such as in human physiology, biological systems,\nmaterial science, and population dynamics. Model-based RL (MBRL) techniques\ntypically try to simultaneously learn a model of the environment from the data,\nas well as try to identify an optimal policy for the learned model. We propose\na technique where the non-Markovianity of the system is modeled through a\nfractional dynamical system. We show that we can quantify the difference in the\nperformance of an MBRL algorithm that uses bounded horizon model predictive\ncontrol from the optimal policy. Finally, we demonstrate our proposed framework\non a pharmacokinetic model of human blood glucose dynamics and show that our\nfractional models can capture distant correlations on real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 07:35:13 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Gupta", "Gaurav", ""], ["Yin", "Chenzhong", ""], ["Deshmukh", "Jyotirmoy V.", ""], ["Bogdan", "Paul", ""]]}, {"id": "2107.13797", "submitter": "Xiaodian Cheng", "authors": "Xiaodian Cheng, Wanhang Lu, Xinyang Huang, Shuihai Hu and Kai Chen", "title": "HAFLO: GPU-Based Acceleration for Federated Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, federated learning (FL) has been widely applied for\nsupporting decentralized collaborative learning scenarios. Among existing FL\nmodels, federated logistic regression (FLR) is a widely used statistic model\nand has been used in various industries. To ensure data security and user\nprivacy, FLR leverages homomorphic encryption (HE) to protect the exchanged\ndata among different collaborative parties. However, HE introduces significant\ncomputational overhead (i.e., the cost of data encryption/decryption and\ncalculation over encrypted data), which eventually becomes the performance\nbottleneck of the whole system. In this paper, we propose HAFLO, a GPU-based\nsolution to improve the performance of FLR. The core idea of HAFLO is to\nsummarize a set of performance-critical homomorphic operators (HO) used by FLR\nand accelerate the execution of these operators through a joint optimization of\nstorage, IO, and computation. The preliminary results show that our\nacceleration on FATE, a popular FL framework, achieves a 49.9$\\times$ speedup\nfor heterogeneous LR and 88.4$\\times$ for homogeneous LR.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 07:46:49 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Cheng", "Xiaodian", ""], ["Lu", "Wanhang", ""], ["Huang", "Xinyang", ""], ["Hu", "Shuihai", ""], ["Chen", "Kai", ""]]}, {"id": "2107.13821", "submitter": "Florian Bachinger", "authors": "Florian Bachinger, Gabriel Kronberger", "title": "Concept for a Technical Infrastructure for Management of Predictive\n  Models in Industrial Applications", "comments": "International Conference on Computer Aided Systems Theory, Eurocast\n  2019, pp 263-270", "journal-ref": "In: Moreno-D\\'iaz R. et al (eds) Computer Aided Systems Theory.\n  Lecture Notes in Computer Science, Vol. 12013 (2020)", "doi": "10.1007/978-3-030-45093-9_32", "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of created and deployed prediction models and the\ncomplexity of machine learning workflows we require so called model management\nsystems to support data scientists in their tasks. In this work we describe our\ntechnological concept for such a model management system. This concept includes\nversioned storage of data, support for different machine learning algorithms,\nfine tuning of models, subsequent deployment of models and monitoring of model\nperformance after deployment. We describe this concept with a close focus on\nmodel lifecycle requirements stemming from our industry application cases, but\ngeneralize key features that are relevant for all applications of machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 08:38:46 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Bachinger", "Florian", ""], ["Kronberger", "Gabriel", ""]]}, {"id": "2107.13822", "submitter": "Erik Esche", "authors": "Erik Esche, Torben Talis, Joris Weigert, Gerardo Brand-Rihm, Byungjun\n  You, Christian Hoffmann, Jens-Uwe Repke", "title": "Semi-supervised Learning for Data-driven Soft-sensing of Biological and\n  Chemical Processes", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Continuously operated (bio-)chemical processes increasingly suffer from\nexternal disturbances, such as feed fluctuations or changes in market\nconditions. Product quality often hinges on control of rarely measured\nconcentrations, which are expensive to measure. Semi-supervised regression is a\npossible building block and method from machine learning to construct\nsoft-sensors for such infrequently measured states. Using two case studies,\ni.e., the Williams-Otto process and a bioethanol production process,\nsemi-supervised regression is compared against standard regression to evaluate\nits merits and its possible scope of application for process control in the\n(bio-)chemical industry.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 08:38:50 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Esche", "Erik", ""], ["Talis", "Torben", ""], ["Weigert", "Joris", ""], ["Brand-Rihm", "Gerardo", ""], ["You", "Byungjun", ""], ["Hoffmann", "Christian", ""], ["Repke", "Jens-Uwe", ""]]}, {"id": "2107.13832", "submitter": "Prerak Srivastava", "authors": "Prerak Srivastava, Antoine Deleforge, Emmanuel Vincent", "title": "Blind Room Parameter Estimation Using Multiple-Multichannel Speech\n  Recordings", "comments": "Accepted In WASPAA 2021 ( IEEE Workshop on Applications of Signal\n  Processing to Audio and Acoustics )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowing the geometrical and acoustical parameters of a room may benefit\napplications such as audio augmented reality, speech dereverberation or audio\nforensics. In this paper, we study the problem of jointly estimating the total\nsurface area, the volume, as well as the frequency-dependent reverberation time\nand mean surface absorption of a room in a blind fashion, based on two-channel\nnoisy speech recordings from multiple, unknown source-receiver positions. A\nnovel convolutional neural network architecture leveraging both single- and\ninter-channel cues is proposed and trained on a large, realistic simulated\ndataset. Results on both simulated and real data show that using multiple\nobservations in one room significantly reduces estimation errors and variances\non all target quantities, and that using two channels helps the estimation of\nsurface and volume. The proposed model outperforms a recently proposed blind\nvolume estimation method on the considered datasets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 08:51:49 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Srivastava", "Prerak", ""], ["Deleforge", "Antoine", ""], ["Vincent", "Emmanuel", ""]]}, {"id": "2107.13833", "submitter": "Frieda Van Den Noort", "authors": "Frieda van den Noort, Beril Sirmacek, Cornelis H. Slump", "title": "Recurrent U-net for automatic pelvic floor muscle segmentation on 3D\n  ultrasound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The prevalance of pelvic floor problems is high within the female population.\nTransperineal ultrasound (TPUS) is the main imaging modality used to\ninvestigate these problems. Automating the analysis of TPUS data will help in\ngrowing our understanding of pelvic floor related problems. In this study we\npresent a U-net like neural network with some convolutional long short term\nmemory (CLSTM) layers to automate the 3D segmentation of the levator ani muscle\n(LAM) in TPUS volumes. The CLSTM layers are added to preserve the inter-slice\n3D information. We reach human level performance on this segmentation task.\nTherefore, we conclude that we successfully automated the segmentation of the\nLAM on 3D TPUS data. This paves the way towards automatic in-vivo analysis of\nthe LAM mechanics in the context of large study populations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 08:53:33 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Noort", "Frieda van den", ""], ["Sirmacek", "Beril", ""], ["Slump", "Cornelis H.", ""]]}, {"id": "2107.13841", "submitter": "Aur\\`ele Goetz", "authors": "Aur\\`ele Goetz, Ali Riza Durmaz, Martin M\\\"uller, Akhil Thomas,\n  Dominik Britz, Pierre Kerfriden and Chris Eberl", "title": "Addressing materials' microstructure diversity using transfer learning", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Materials' microstructures are signatures of their alloying composition and\nprocessing history. Therefore, microstructures exist in a wide variety. As\nmaterials become increasingly complex to comply with engineering demands,\nadvanced computer vision (CV) approaches such as deep learning (DL) inevitably\ngain relevance for quantifying microstrucutures' constituents from micrographs.\nWhile DL can outperform classical CV techniques for many tasks, shortcomings\nare poor data efficiency and generalizability across datasets. This is\ninherently in conflict with the expense associated with annotating materials\ndata through experts and extensive materials diversity. To tackle poor domain\ngeneralizability and the lack of labeled data simultaneously, we propose to\napply a sub-class of transfer learning methods called unsupervised domain\nadaptation (UDA). These algorithms address the task of finding domain-invariant\nfeatures when supplied with annotated source data and unannotated target data,\nsuch that performance on the latter distribution is optimized despite the\nabsence of annotations. Exemplarily, this study is conducted on a lath-shaped\nbainite segmentation task in complex phase steel micrographs. Here, the domains\nto bridge are selected to be different metallographic specimen preparations\n(surface etchings) and distinct imaging modalities. We show that a\nstate-of-the-art UDA approach surpasses the na\\\"ive application of source\ndomain trained models on the target domain (generalization baseline) to a large\nextent. This holds true independent of the domain shift, despite using little\ndata, and even when the baseline models were pre-trained or employed data\naugmentation. Through UDA, mIoU was improved over generalization baselines from\n82.2%, 61.0%, 49.7% to 84.7%, 67.3%, 73.3% on three target datasets,\nrespectively. This underlines this techniques' potential to cope with materials\nvariance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 09:13:11 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Goetz", "Aur\u00e8le", ""], ["Durmaz", "Ali Riza", ""], ["M\u00fcller", "Martin", ""], ["Thomas", "Akhil", ""], ["Britz", "Dominik", ""], ["Kerfriden", "Pierre", ""], ["Eberl", "Chris", ""]]}, {"id": "2107.13856", "submitter": "David Howey", "authors": "Antti Aitio and David A. Howey", "title": "Predicting battery end of life from solar off-grid system field data\n  using machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hundreds of millions of people lack access to electricity. Decentralised\nsolar-battery systems are key for addressing this whilst avoiding carbon\nemissions and air pollution, but are hindered by relatively high costs and\nrural locations that inhibit timely preventative maintenance. Accurate\ndiagnosis of battery health and prediction of end of life from operational data\nimproves user experience and reduces costs. But lack of controlled validation\ntests and variable data quality mean existing lab-based techniques fail to\nwork. We apply a scaleable probabilistic machine learning approach to diagnose\nhealth in 1027 solar-connected lead-acid batteries, each running for 400-760\ndays, totalling 620 million data rows. We demonstrate 73% accurate prediction\nof end of life, eight weeks in advance, rising to 82% at the point of failure.\nThis work highlights the opportunity to estimate health from existing\nmeasurements using `big data' techniques, without additional equipment,\nextending lifetime and improving performance in real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 09:37:48 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Aitio", "Antti", ""], ["Howey", "David A.", ""]]}, {"id": "2107.13870", "submitter": "Pejman Zarafshan", "authors": "Pejman Zarafshan, Saman Javadi, Abbas Roozbahani, Seyed Mehdi Hashemy,\n  Payam Zarafshan, Hamed Etezadi", "title": "Artificial Intelligence Hybrid Deep Learning Model for Groundwater Level\n  Prediction Using MLP-ADAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Groundwater is the largest storage of freshwater resources, which serves as\nthe major inventory for most of the human consumption through agriculture,\nindustrial, and domestic water supply. In the fields of hydrological, some\nresearchers applied a neural network to forecast rainfall intensity in\nspace-time and introduced the advantages of neural networks compared to\nnumerical models. Then, many researches have been conducted applying\ndata-driven models. Some of them extended an Artificial Neural Networks (ANNs)\nmodel to forecast groundwater level in semi-confined glacial sand and gravel\naquifer under variable state, pumping extraction and climate conditions with\nsignificant accuracy. In this paper, a multi-layer perceptron is applied to\nsimulate groundwater level. The adaptive moment estimation optimization\nalgorithm is also used to this matter. The root mean squared error, mean\nabsolute error, mean squared error and the coefficient of determination ( ) are\nused to evaluate the accuracy of the simulated groundwater level. Total value\nof and RMSE are 0.9458 and 0.7313 respectively which are obtained from the\nmodel output. Results indicate that deep learning algorithms can demonstrate a\nhigh accuracy prediction. Although the optimization of parameters is\ninsignificant in numbers, but due to the value of time in modelling setup, it\nis highly recommended to apply an optimization algorithm in modelling.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 10:11:45 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zarafshan", "Pejman", ""], ["Javadi", "Saman", ""], ["Roozbahani", "Abbas", ""], ["Hashemy", "Seyed Mehdi", ""], ["Zarafshan", "Payam", ""], ["Etezadi", "Hamed", ""]]}, {"id": "2107.13875", "submitter": "Rafael Carrillo", "authors": "Jelena Simeunovi\\'c, Baptiste Schubnel, Pierre-Jean Alet and Rafael E.\n  Carrillo", "title": "Spatio-temporal graph neural networks for multi-site PV power\n  forecasting", "comments": "10 pages, 6 figures, submitted to IEEE Transactions on Sustainable\n  Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate forecasting of solar power generation with fine temporal and spatial\nresolution is vital for the operation of the power grid. However,\nstate-of-the-art approaches that combine machine learning with numerical\nweather predictions (NWP) have coarse resolution. In this paper, we take a\ngraph signal processing perspective and model multi-site photovoltaic (PV)\nproduction time series as signals on a graph to capture their spatio-temporal\ndependencies and achieve higher spatial and temporal resolution forecasts. We\npresent two novel graph neural network models for deterministic multi-site PV\nforecasting dubbed the graph-convolutional long short term memory (GCLSTM) and\nthe graph-convolutional transformer (GCTrafo) models. These methods rely solely\non production data and exploit the intuition that PV systems provide a dense\nnetwork of virtual weather stations. The proposed methods were evaluated in two\ndata sets for an entire year: 1) production data from 304 real PV systems, and\n2) simulated production of 1000 PV systems, both distributed over Switzerland.\nThe proposed models outperform state-of-the-art multi-site forecasting methods\nfor prediction horizons of six hours ahead. Furthermore, the proposed models\noutperform state-of-the-art single-site methods with NWP as inputs on horizons\nup to four hours ahead.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 10:15:01 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Simeunovi\u0107", "Jelena", ""], ["Schubnel", "Baptiste", ""], ["Alet", "Pierre-Jean", ""], ["Carrillo", "Rafael E.", ""]]}, {"id": "2107.13876", "submitter": "Felice Antonio Merra", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Felice Antonio\n  Merra", "title": "Understanding the Effects of Adversarial Personalized Ranking\n  Optimization Method on Recommendation Quality", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems (RSs) employ user-item feedback, e.g., ratings, to match\ncustomers to personalized lists of products. Approaches to top-k recommendation\nmainly rely on Learning-To-Rank algorithms and, among them, the most widely\nadopted is Bayesian Personalized Ranking (BPR), which bases on a pair-wise\noptimization approach. Recently, BPR has been found vulnerable against\nadversarial perturbations of its model parameters. Adversarial Personalized\nRanking (APR) mitigates this issue by robustifying BPR via an adversarial\ntraining procedure. The empirical improvements of APR's accuracy performance on\nBPR have led to its wide use in several recommender models. However, a key\noverlooked aspect has been the beyond-accuracy performance of APR, i.e.,\nnovelty, coverage, and amplification of popularity bias, considering that\nrecent results suggest that BPR, the building block of APR, is sensitive to the\nintensification of biases and reduction of recommendation novelty. In this\nwork, we model the learning characteristics of the BPR and APR optimization\nframeworks to give mathematical evidence that, when the feedback data have a\ntailed distribution, APR amplifies the popularity bias more than BPR due to an\nunbalanced number of received positive updates from short-head items. Using\nmatrix factorization (MF), we empirically validate the theoretical results by\nperforming preliminary experiments on two public datasets to compare BPR-MF and\nAPR-MF performance on accuracy and beyond-accuracy metrics. The experimental\nresults consistently show the degradation of novelty and coverage measures and\na worrying amplification of bias.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 10:22:20 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Merra", "Felice Antonio", ""]]}, {"id": "2107.13892", "submitter": "Kaan Ozkara", "authors": "Kaan Ozkara, Navjot Singh, Deepesh Data, Suhas Diggavi", "title": "QuPeD: Quantized Personalization via Distillation with Applications to\n  Federated Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:2102.11786", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, federated learning (FL) aims to train a single global model\nwhile collaboratively using multiple clients and a server. Two natural\nchallenges that FL algorithms face are heterogeneity in data across clients and\ncollaboration of clients with {\\em diverse resources}. In this work, we\nintroduce a \\textit{quantized} and \\textit{personalized} FL algorithm QuPeD\nthat facilitates collective (personalized model compression) training via\n\\textit{knowledge distillation} (KD) among clients who have access to\nheterogeneous data and resources. For personalization, we allow clients to\nlearn \\textit{compressed personalized models} with different quantization\nparameters and model dimensions/structures. Towards this, first we propose an\nalgorithm for learning quantized models through a relaxed optimization problem,\nwhere quantization values are also optimized over. When each client\nparticipating in the (federated) learning process has different requirements\nfor the compressed model (both in model dimension and precision), we formulate\na compressed personalization framework by introducing knowledge distillation\nloss for local client objectives collaborating through a global model. We\ndevelop an alternating proximal gradient update for solving this compressed\npersonalization problem, and analyze its convergence properties. Numerically,\nwe validate that QuPeD outperforms competing personalized FL methods, FedAvg,\nand local training of clients in various heterogeneous settings.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 10:55:45 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ozkara", "Kaan", ""], ["Singh", "Navjot", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2107.13921", "submitter": "Dominik Scheinert", "authors": "Dominik Scheinert, Lauritz Thamsen, Houkun Zhu, Jonathan Will,\n  Alexander Acker, Thorsten Wittkopp, Odej Kao", "title": "Bellamy: Reusing Performance Models for Distributed Dataflow Jobs Across\n  Contexts", "comments": "10 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed dataflow systems enable the use of clusters for scalable data\nanalytics. However, selecting appropriate cluster resources for a processing\njob is often not straightforward. Performance models trained on historical\nexecutions of a concrete job are helpful in such situations, yet they are\nusually bound to a specific job execution context (e.g. node type, software\nversions, job parameters) due to the few considered input parameters. Even in\ncase of slight context changes, such supportive models need to be retrained and\ncannot benefit from historical execution data from related contexts.\n  This paper presents Bellamy, a novel modeling approach that combines\nscale-outs, dataset sizes, and runtimes with additional descriptive properties\nof a dataflow job. It is thereby able to capture the context of a job\nexecution. Moreover, Bellamy is realizing a two-step modeling approach. First,\na general model is trained on all the available data for a specific scalable\nanalytics algorithm, hereby incorporating data from different contexts.\nSubsequently, the general model is optimized for the specific situation at\nhand, based on the available data for the concrete context. We evaluate our\napproach on two publicly available datasets consisting of execution data from\nvarious dataflow jobs carried out in different environments, showing that\nBellamy outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 11:57:38 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Scheinert", "Dominik", ""], ["Thamsen", "Lauritz", ""], ["Zhu", "Houkun", ""], ["Will", "Jonathan", ""], ["Acker", "Alexander", ""], ["Wittkopp", "Thorsten", ""], ["Kao", "Odej", ""]]}, {"id": "2107.13943", "submitter": "Adam Elwood", "authors": "Adam Elwood, Alberto Gasparin, Alessandro Rozza", "title": "Ranking Micro-Influencers: a Novel Multi-Task Learning and Interpretable\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rise in use of social media to promote branded products, the demand\nfor effective influencer marketing has increased. Brands are looking for\nimproved ways to identify valuable influencers among a vast catalogue; this is\neven more challenging with \"micro-influencers\", which are more affordable than\nmainstream ones but difficult to discover. In this paper, we propose a novel\nmulti-task learning framework to improve the state of the art in\nmicro-influencer ranking based on multimedia content. Moreover, since the\nvisual congruence between a brand and influencer has been shown to be good\nmeasure of compatibility, we provide an effective visual method for\ninterpreting our models' decisions, which can also be used to inform brands'\nmedia strategies. We compare with the current state-of-the-art on a recently\nconstructed public dataset and we show significant improvement both in terms of\naccuracy and model complexity. The techniques for ranking and interpretation\npresented in this work can be generalised to arbitrary multimedia ranking tasks\nthat have datasets with a similar structure.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 13:04:25 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Elwood", "Adam", ""], ["Gasparin", "Alberto", ""], ["Rozza", "Alessandro", ""]]}, {"id": "2107.13944", "submitter": "Ashkan Bagheri Jeddi", "authors": "Ashkan B. Jeddi, Nariman L. Dehghani, Abdollah Shafieezadeh", "title": "Lyapunov-based uncertainty-aware safe reinforcement learning", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has shown a promising performance in learning\noptimal policies for a variety of sequential decision-making tasks. However, in\nmany real-world RL problems, besides optimizing the main objectives, the agent\nis expected to satisfy a certain level of safety (e.g., avoiding collisions in\nautonomous driving). While RL problems are commonly formalized as Markov\ndecision processes (MDPs), safety constraints are incorporated via constrained\nMarkov decision processes (CMDPs). Although recent advances in safe RL have\nenabled learning safe policies in CMDPs, these safety requirements should be\nsatisfied during both training and in the deployment process. Furthermore, it\nis shown that in memory-based and partially observable environments, these\nmethods fail to maintain safety over unseen out-of-distribution observations.\nTo address these limitations, we propose a Lyapunov-based uncertainty-aware\nsafe RL model. The introduced model adopts a Lyapunov function that converts\ntrajectory-based constraints to a set of local linear constraints. Furthermore,\nto ensure the safety of the agent in highly uncertain environments, an\nuncertainty quantification method is developed that enables identifying\nrisk-averse actions through estimating the probability of constraint\nviolations. Moreover, a Transformers model is integrated to provide the agent\nwith memory to process long time horizons of information via the self-attention\nmechanism. The proposed model is evaluated in grid-world navigation tasks where\nsafety is defined as avoiding static and dynamic obstacles in fully and\npartially observable environments. The results of these experiments show a\nsignificant improvement in the performance of the agent both in achieving\noptimality and satisfying safety constraints.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 13:08:15 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Jeddi", "Ashkan B.", ""], ["Dehghani", "Nariman L.", ""], ["Shafieezadeh", "Abdollah", ""]]}, {"id": "2107.13964", "submitter": "Erkin Otles", "authors": "Erkin \\\"Otle\\c{s}, Jeeheh Oh, Benjamin Li, Michelle Bochinski, Hyeon\n  Joo, Justin Ortwine, Erica Shenoy, Laraine Washer, Vincent B. Young, Krishna\n  Rao, Jenna Wiens", "title": "Mind the Performance Gap: Examining Dataset Shift During Prospective\n  Validation", "comments": "Accepted by the 2021 Machine Learning for Healthcare Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Once integrated into clinical care, patient risk stratification models may\nperform worse compared to their retrospective performance. To date, it is\nwidely accepted that performance will degrade over time due to changes in care\nprocesses and patient populations. However, the extent to which this occurs is\npoorly understood, in part because few researchers report prospective\nvalidation performance. In this study, we compare the 2020-2021 ('20-'21)\nprospective performance of a patient risk stratification model for predicting\nhealthcare-associated infections to a 2019-2020 ('19-'20) retrospective\nvalidation of the same model. We define the difference in retrospective and\nprospective performance as the performance gap. We estimate how i) \"temporal\nshift\", i.e., changes in clinical workflows and patient populations, and ii)\n\"infrastructure shift\", i.e., changes in access, extraction and transformation\nof data, both contribute to the performance gap. Applied prospectively to\n26,864 hospital encounters during a twelve-month period from July 2020 to June\n2021, the model achieved an area under the receiver operating characteristic\ncurve (AUROC) of 0.767 (95% confidence interval (CI): 0.737, 0.801) and a Brier\nscore of 0.189 (95% CI: 0.186, 0.191). Prospective performance decreased\nslightly compared to '19-'20 retrospective performance, in which the model\nachieved an AUROC of 0.778 (95% CI: 0.744, 0.815) and a Brier score of 0.163\n(95% CI: 0.161, 0.165). The resulting performance gap was primarily due to\ninfrastructure shift and not temporal shift. So long as we continue to develop\nand validate models using data stored in large research data warehouses, we\nmust consider differences in how and when data are accessed, measure how these\ndifferences may affect prospective performance, and work to mitigate those\ndifferences.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:30:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["\u00d6tle\u015f", "Erkin", ""], ["Oh", "Jeeheh", ""], ["Li", "Benjamin", ""], ["Bochinski", "Michelle", ""], ["Joo", "Hyeon", ""], ["Ortwine", "Justin", ""], ["Shenoy", "Erica", ""], ["Washer", "Laraine", ""], ["Young", "Vincent B.", ""], ["Rao", "Krishna", ""], ["Wiens", "Jenna", ""]]}, {"id": "2107.13966", "submitter": "Hoe-Han Goh", "authors": "Hoe-Han Goh", "title": "Artificial Intelligence in Achieving Sustainable Development Goals", "comments": "10 pages, 1 figure, under evaluation as a Perspective in Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This perspective illustrates some of the AI applications that can accelerate\nthe achievement of SDGs and also highlights some of the considerations that\ncould hinder the efforts towards them. This emphasizes the importance of\nestablishing standard AI guidelines and regulations for the beneficial\napplications of AI.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 03:51:10 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Goh", "Hoe-Han", ""]]}, {"id": "2107.13969", "submitter": "Sri Harsha Dumpala Mr", "authors": "Sri Harsha Dumpala, Sebastian Rodriguez, Sheri Rempel, Rudolf Uher,\n  Sageev Oore", "title": "Significance of Speaker Embeddings and Temporal Context for Depression\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depression detection from speech has attracted a lot of attention in recent\nyears. However, the significance of speaker-specific information in depression\ndetection has not yet been explored. In this work, we analyze the significance\nof speaker embeddings for the task of depression detection from speech.\nExperimental results show that the speaker embeddings provide important cues to\nachieve state-of-the-art performance in depression detection. We also show that\ncombining conventional OpenSMILE and COVAREP features, which carry\ncomplementary information, with speaker embeddings further improves the\ndepression detection performance. The significance of temporal context in the\ntraining of deep learning models for depression detection is also analyzed in\nthis paper.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 05:14:48 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Dumpala", "Sri Harsha", ""], ["Rodriguez", "Sebastian", ""], ["Rempel", "Sheri", ""], ["Uher", "Rudolf", ""], ["Oore", "Sageev", ""]]}, {"id": "2107.13973", "submitter": "Rushali Grandhe", "authors": "Farha Al Breiki, Muhammad Ridzuan, Rushali Grandhe", "title": "Self-Supervised Learning for Fine-Grained Image Classification", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-grained image classification involves identifying different\nsubcategories of a class which possess very subtle discriminatory features.\nFine-grained datasets usually provide bounding box annotations along with class\nlabels to aid the process of classification. However, building large scale\ndatasets with such annotations is a mammoth task. Moreover, this extensive\nannotation is time-consuming and often requires expertise, which is a huge\nbottleneck in building large datasets. On the other hand, self-supervised\nlearning (SSL) exploits the freely available data to generate supervisory\nsignals which act as labels. The features learnt by performing some pretext\ntasks on huge unlabelled data proves to be very helpful for multiple downstream\ntasks.\n  Our idea is to leverage self-supervision such that the model learns useful\nrepresentations of fine-grained image classes. We experimented with 3 kinds of\nmodels: Jigsaw solving as pretext task, adversarial learning (SRGAN) and\ncontrastive learning based (SimCLR) model. The learned features are used for\ndownstream tasks such as fine-grained image classification. Our code is\navailable at\nhttp://github.com/rush2406/Self-Supervised-Learning-for-Fine-grained-Image-Classification\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:01:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Breiki", "Farha Al", ""], ["Ridzuan", "Muhammad", ""], ["Grandhe", "Rushali", ""]]}, {"id": "2107.13998", "submitter": "Michael Lyons", "authors": "Michael J. Lyons", "title": "\"Excavating AI\" Re-excavated: Debunking a Fallacious Account of the\n  JAFFE Dataset", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twenty-five years ago, my colleagues Miyuki Kamachi and Jiro Gyoba and I\ndesigned and photographed JAFFE, a set of facial expression images intended for\nuse in a study of face perception. In 2019, without seeking permission or\ninforming us, Kate Crawford and Trevor Paglen exhibited JAFFE in two widely\npublicized art shows. In addition, they published a nonfactual account of the\nimages in the essay \"Excavating AI: The Politics of Images in Machine Learning\nTraining Sets.\" The present article recounts the creation of the JAFFE dataset\nand unravels each of Crawford and Paglen's fallacious statements. I also\ndiscuss JAFFE more broadly in connection with research on facial expression,\naffective computing, and human-computer interaction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 01:31:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lyons", "Michael J.", ""]]}, {"id": "2107.14028", "submitter": "Agni Kumar", "authors": "Agni Kumar, Vikramjit Mitra, Carolyn Oliver, Adeeti Ullal, Matt\n  Biddulph, Irida Mance", "title": "Estimating Respiratory Rate From Breath Audio Obtained Through Wearable\n  Microphones", "comments": "International Conference of the IEEE Engineering in Medicine and\n  Biology Society (EMBC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Respiratory rate (RR) is a clinical metric used to assess overall health and\nphysical fitness. An individual's RR can change from their baseline due to\nchronic illness symptoms (e.g., asthma, congestive heart failure), acute\nillness (e.g., breathlessness due to infection), and over the course of the day\ndue to physical exhaustion during heightened exertion. Remote estimation of RR\ncan offer a cost-effective method to track disease progression and\ncardio-respiratory fitness over time. This work investigates a model-driven\napproach to estimate RR from short audio segments obtained after physical\nexertion in healthy adults. Data was collected from 21 individuals using\nmicrophone-enabled, near-field headphones before, during, and after strenuous\nexercise. RR was manually annotated by counting perceived inhalations and\nexhalations. A multi-task Long-Short Term Memory (LSTM) network with\nconvolutional layers was implemented to process mel-filterbank energies,\nestimate RR in varying background noise conditions, and predict heavy\nbreathing, indicated by an RR of more than 25 breaths per minute. The\nmulti-task model performs both classification and regression tasks and\nleverages a mixture of loss functions. It was observed that RR can be estimated\nwith a concordance correlation coefficient (CCC) of 0.76 and a mean squared\nerror (MSE) of 0.2, demonstrating that audio can be a viable signal for\napproximating RR.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:24:44 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kumar", "Agni", ""], ["Mitra", "Vikramjit", ""], ["Oliver", "Carolyn", ""], ["Ullal", "Adeeti", ""], ["Biddulph", "Matt", ""], ["Mance", "Irida", ""]]}, {"id": "2107.14033", "submitter": "Chaoran Cui", "authors": "Chaoran Cui, Xiaojie Li, Juan Du, Chunyun Zhang, Xiushan Nie, Meng\n  Wang, Yilong Yin", "title": "Temporal-Relational Hypergraph Tri-Attention Networks for Stock Trend\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the future price trends of stocks is a challenging yet intriguing\nproblem given its critical role to help investors make profitable decisions. In\nthis paper, we present a collaborative temporal-relational modeling framework\nfor end-to-end stock trend prediction. The temporal dynamics of stocks is\nfirstly captured with an attention-based recurrent neural network. Then,\ndifferent from existing studies relying on the pairwise correlations between\nstocks, we argue that stocks are naturally connected as a collective group, and\nintroduce the hypergraph structures to jointly characterize the stock\ngroup-wise relationships of industry-belonging and fund-holding. A novel\nhypergraph tri-attention network (HGTAN) is proposed to augment the hypergraph\nconvolutional networks with a hierarchical organization of intra-hyperedge,\ninter-hyperedge, and inter-hypergraph attention modules. In this manner, HGTAN\nadaptively determines the importance of nodes, hyperedges, and hypergraphs\nduring the information propagation among stocks, so that the potential\nsynergies between stock movements can be fully exploited. Extensive experiments\non real-world data demonstrate the effectiveness of our approach. Also, the\nresults of investment simulation show that our approach can achieve a more\ndesirable risk-adjusted return. The data and codes of our work have been\nreleased at https://github.com/lixiaojieff/HGTAN.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 02:16:09 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Cui", "Chaoran", ""], ["Li", "Xiaojie", ""], ["Du", "Juan", ""], ["Zhang", "Chunyun", ""], ["Nie", "Xiushan", ""], ["Wang", "Meng", ""], ["Yin", "Yilong", ""]]}, {"id": "2107.14035", "submitter": "Mike Wu", "authors": "Mike Wu, Noah Goodman, Chris Piech, Chelsea Finn", "title": "ProtoTransformer: A Meta-Learning Approach to Providing Student Feedback", "comments": "9 pages content; 6 pages supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-quality computer science education is limited by the difficulty of\nproviding instructor feedback to students at scale. While this feedback could\nin principle be automated, supervised approaches to predicting the correct\nfeedback are bottlenecked by the intractability of annotating large quantities\nof student code. In this paper, we instead frame the problem of providing\nfeedback as few-shot classification, where a meta-learner adapts to give\nfeedback to student code on a new programming question from just a few examples\nannotated by instructors. Because data for meta-training is limited, we propose\na number of amendments to the typical few-shot learning framework, including\ntask augmentation to create synthetic tasks, and additional side information to\nbuild stronger priors about each task. These additions are combined with a\ntransformer architecture to embed discrete sequences (e.g. code) to a\nprototypical representation of a feedback class label. On a suite of few-shot\nnatural language processing tasks, we match or outperform state-of-the-art\nperformance. Then, on a collection of student solutions to exam questions from\nan introductory university course, we show that our approach reaches an average\nprecision of 88% on unseen questions, surpassing the 82% precision of teaching\nassistants. Our approach was successfully deployed to deliver feedback to\n16,000 student exam-solutions in a programming course offered by a tier 1\nuniversity. This is, to the best of our knowledge, the first successful\ndeployment of a machine learning based feedback to open-ended student code.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 22:41:28 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wu", "Mike", ""], ["Goodman", "Noah", ""], ["Piech", "Chris", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.14037", "submitter": "Gutta Jignesh Chowdary Mr", "authors": "G Jignesh Chowdary, Suganya G, Premalatha M, Asnath Victy Phamila Y,\n  Karunamurthy K", "title": "Machine Learning and Deep Learning Methods for Building Intelligent\n  Systems in Medicine and Drug Discovery: A Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the advancements in computer technology, there is a rapid development of\nintelligent systems to understand the complex relationships in data to make\npredictions and classifications. Artificail Intelligence based framework is\nrapidly revolutionizing the healthcare industry. These intelligent systems are\nbuilt with machine learning and deep learning based robust models for early\ndiagnosis of diseases and demonstrates a promising supplementary diagnostic\nmethod for frontline clinical doctors and surgeons. Machine Learning and Deep\nLearning based systems can streamline and simplify the steps involved in\ndiagnosis of diseases from clinical and image-based data, thus providing\nsignificant clinician support and workflow optimization. They mimic human\ncognition and are even capable of diagnosing diseases that cannot be diagnosed\nwith human intelligence. This paper focuses on the survey of machine learning\nand deep learning applications in across 16 medical specialties, namely Dental\nmedicine, Haematology, Surgery, Cardiology, Pulmonology, Orthopedics,\nRadiology, Oncology, General medicine, Psychiatry, Endocrinology, Neurology,\nDermatology, Hepatology, Nephrology, Ophthalmology, and Drug discovery. In this\npaper along with the survey, we discuss the advancements of medical practices\nwith these systems and also the impact of these systems on medical\nprofessionals.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:26:03 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chowdary", "G Jignesh", ""], ["G", "Suganya", ""], ["M", "Premalatha", ""], ["Y", "Asnath Victy Phamila", ""], ["K", "Karunamurthy", ""]]}, {"id": "2107.14038", "submitter": "Ali Kashefi", "authors": "Ali Kashefi and Tapan Mukerji", "title": "Point-Cloud Deep Learning of Porous Media for Permeability Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep learning framework for predicting permeability of\nporous media from their digital images. Unlike convolutional neural networks,\ninstead of feeding the whole image volume as inputs to the network, we model\nthe boundary between solid matrix and pore spaces as point clouds and feed them\nas inputs to a neural network based on the PointNet architecture. This approach\novercomes the challenge of memory restriction of graphics processing units and\nits consequences on the choice of batch size, and convergence. Compared to\nconvolutional neural networks, the proposed deep learning methodology provides\nfreedom to select larger batch sizes, due to reducing significantly the size of\nnetwork inputs. Specifically, we use the classification branch of PointNet and\nadjust it for a regression task. As a test case, two and three dimensional\nsynthetic digital rock images are considered. We investigate the effect of\ndifferent components of our neural network on its performance. We compare our\ndeep learning strategy with a convolutional neural network from various\nperspectives, specifically for maximum possible batch size. We inspect the\ngeneralizability of our network by predicting the permeability of real-world\nrock samples as well as synthetic digital rocks that are statistically\ndifferent from the samples used during training. The network predicts the\npermeability of digital rocks a few thousand times faster than a Lattice\nBoltzmann solver with a high level of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 22:59:21 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kashefi", "Ali", ""], ["Mukerji", "Tapan", ""]]}, {"id": "2107.14053", "submitter": "Eugene Lee", "authors": "Eugene Lee, Cheng-Han Huang, Chen-Yi Lee", "title": "Few-Shot and Continual Learning with Attentive Independent Mechanisms", "comments": "20 pages, 44 figures, accepted by International Conference of\n  Computer Vision 2021 (ICCV 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks (DNNs) are known to perform well when deployed to test\ndistributions that shares high similarity with the training distribution.\nFeeding DNNs with new data sequentially that were unseen in the training\ndistribution has two major challenges -- fast adaptation to new tasks and\ncatastrophic forgetting of old tasks. Such difficulties paved way for the\non-going research on few-shot learning and continual learning. To tackle these\nproblems, we introduce Attentive Independent Mechanisms (AIM). We incorporate\nthe idea of learning using fast and slow weights in conjunction with the\ndecoupling of the feature extraction and higher-order conceptual learning of a\nDNN. AIM is designed for higher-order conceptual learning, modeled by a mixture\nof experts that compete to learn independent concepts to solve a new task. AIM\nis a modular component that can be inserted into existing deep learning\nframeworks. We demonstrate its capability for few-shot learning by adding it to\nSIB and trained on MiniImageNet and CIFAR-FS, showing significant improvement.\nAIM is also applied to ANML and OML trained on Omniglot, CIFAR-100 and\nMiniImageNet to demonstrate its capability in continual learning. Code made\npublicly available at https://github.com/huang50213/AIM-Fewshot-Continual.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:43:24 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lee", "Eugene", ""], ["Huang", "Cheng-Han", ""], ["Lee", "Chen-Yi", ""]]}, {"id": "2107.14060", "submitter": "Shixin Xu", "authors": "ing Ma, Yiyang Sun, Junjie Liu, Huaxiong Huang, Xiaoshuang Zhou and\n  Shixin Xu", "title": "Multi-objective optimization and explanation for stroke risk assessment\n  in Shanxi province", "comments": "22pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stroke is the top leading causes of death in China (Zhou et al. The Lancet\n2019). A dataset from Shanxi Province is used to identify the risk of each\npatient's at four states low/medium/high/attack and provide the state\ntransition tendency through a SHAP DeepExplainer. To improve the accuracy on an\nimbalance sample set, the Quadratic Interactive Deep Neural Network (QIDNN)\nmodel is first proposed by flexible selecting and appending of quadratic\ninteractive features. The experimental results showed that the QIDNN model with\n7 interactive features achieve the state-of-art accuracy $83.25\\%$. Blood\npressure, physical inactivity, smoking, weight and total cholesterol are the\ntop five important features. Then, for the sake of high recall on the most\nurgent state, attack state, the stroke occurrence prediction is taken as an\nauxiliary objective to benefit from multi-objective optimization. The\nprediction accuracy was promoted, meanwhile the recall of the attack state was\nimproved by $24.9\\%$ (to $84.83\\%$) compared to QIDNN (from $67.93\\%$) with\nsame features. The prediction model and analysis tool in this paper not only\ngave the theoretical optimized prediction method, but also provided the\nattribution explanation of risk states and transition direction of each\npatient, which provided a favorable tool for doctors to analyze and diagnose\nthe disease.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:53:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ma", "ing", ""], ["Sun", "Yiyang", ""], ["Liu", "Junjie", ""], ["Huang", "Huaxiong", ""], ["Zhou", "Xiaoshuang", ""], ["Xu", "Shixin", ""]]}, {"id": "2107.14061", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul", "title": "The Need and Status of Sea Turtle Conservation and Survey of Associated\n  Computer Vision Advances", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over hundreds of millions of years, sea turtles and their ancestors have\nswum in the vast expanses of the ocean. They have undergone a number of\nevolutionary changes, leading to speciation and sub-speciation. However, in the\npast few decades, some of the most notable forces driving the genetic variance\nand population decline have been global warming and anthropogenic impact\nranging from large-scale poaching, collecting turtle eggs for food, besides\ndumping trash including plastic waste into the ocean. This leads to severe\ndetrimental effects in the sea turtle population, driving them to extinction.\nThis research focusses on the forces causing the decline in sea turtle\npopulation, the necessity for the global conservation efforts along with its\nsuccesses and failures, followed by an in-depth analysis of the modern advances\nin detection and recognition of sea turtles, involving Machine Learning and\nComputer Vision systems, aiding the conservation efforts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:53:47 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "Aditya Jyoti", ""]]}, {"id": "2107.14062", "submitter": "Leonardo Scabini", "authors": "Leonardo F. S. Scabini and Odemir M. Bruno", "title": "Structure and Performance of Fully Connected Neural Networks: Emerging\n  Complex Network Properties", "comments": "18 pages, 7 figures, and 2 tables. Submitted to a peer-review journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV physics.app-ph physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Understanding the behavior of Artificial Neural Networks is one of the main\ntopics in the field recently, as black-box approaches have become usual since\nthe widespread of deep learning. Such high-dimensional models may manifest\ninstabilities and weird properties that resemble complex systems. Therefore, we\npropose Complex Network (CN) techniques to analyze the structure and\nperformance of fully connected neural networks. For that, we build a dataset\nwith 4 thousand models and their respective CN properties. They are employed in\na supervised classification setup considering four vision benchmarks. Each\nneural network is approached as a weighted and undirected graph of neurons and\nsynapses, and centrality measures are computed after training. Results show\nthat these measures are highly related to the network classification\nperformance. We also propose the concept of Bag-Of-Neurons (BoN), a CN-based\napproach for finding topological signatures linking similar neurons. Results\nsuggest that six neuronal types emerge in such networks, independently of the\ntarget domain, and are distributed differently according to classification\naccuracy. We also tackle specific CN properties related to performance, such as\nhigher subgraph centrality on lower-performing models. Our findings suggest\nthat CN properties play a critical role in the performance of fully connected\nneural networks, with topological patterns emerging independently on a wide\nrange of models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:53:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Scabini", "Leonardo F. S.", ""], ["Bruno", "Odemir M.", ""]]}, {"id": "2107.14070", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul, Smaranjit Ghose, Kanishka Aggarwal, Niketha\n  Nethaji, Shivam Pal, Arnab Dutta Purkayastha", "title": "Machine Learning Advances aiding Recognition and Classification of\n  Indian Monuments and Landmarks", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tourism in India plays a quintessential role in the country's economy with an\nestimated 9.2% GDP share for the year 2018. With a yearly growth rate of 6.2%,\nthe industry holds a huge potential for being the primary driver of the economy\nas observed in the nations of the Middle East like the United Arab Emirates.\nThe historical and cultural diversity exhibited throughout the geography of the\nnation is a unique spectacle for people around the world and therefore serves\nto attract tourists in tens of millions in number every year. Traditionally,\ntour guides or academic professionals who study these heritage monuments were\nresponsible for providing information to the visitors regarding their\narchitectural and historical significance. However, unfortunately this system\nhas several caveats when considered on a large scale such as unavailability of\nsufficient trained people, lack of accurate information, failure to convey the\nrichness of details in an attractive format etc. Recently, machine learning\napproaches revolving around the usage of monument pictures have been shown to\nbe useful for rudimentary analysis of heritage sights. This paper serves as a\nsurvey of the research endeavors undertaken in this direction which would\neventually provide insights for building an automated decision system that\ncould be utilized to make the experience of tourism in India more modernized\nfor visitors.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 15:01:02 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "Aditya Jyoti", ""], ["Ghose", "Smaranjit", ""], ["Aggarwal", "Kanishka", ""], ["Nethaji", "Niketha", ""], ["Pal", "Shivam", ""], ["Purkayastha", "Arnab Dutta", ""]]}, {"id": "2107.14077", "submitter": "Soaad Hossain Mr", "authors": "Soraia Oueida, Soaad Hossain, Yehia Kotb, Syed Ishtiaque Ahmed", "title": "A Fair and Ethical Healthcare Artificial Intelligence System for\n  Monitoring Driver Behavior and Preventing Road Accidents", "comments": "12 pages, 2 figures, accepted to Future Technologies Conference (FTC\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to prevent transportation accidents and\nmonitor driver's behavior using a healthcare AI system that incorporates\nfairness and ethics. Dangerous medical cases and unusual behavior of the driver\nare detected. Fairness algorithm is approached in order to improve\ndecision-making and address ethical issues such as privacy issues, and to\nconsider challenges that appear in the wild within AI in healthcare and\ndriving. A healthcare professional will be alerted about any unusual activity,\nand the driver's location when necessary, is provided in order to enable the\nhealthcare professional to immediately help to the unstable driver. Therefore,\nusing the healthcare AI system allows for accidents to be predicted and thus\nprevented and lives may be saved based on the built-in AI system inside the\nvehicle which interacts with the ER system.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:23:42 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Oueida", "Soraia", ""], ["Hossain", "Soaad", ""], ["Kotb", "Yehia", ""], ["Ahmed", "Syed Ishtiaque", ""]]}, {"id": "2107.14094", "submitter": "Panchamy Krishnakumari Dr", "authors": "Panchamy Krishnakumari, Oded Cats and Hans van Lint", "title": "Day-to-day and seasonal regularity of network passenger delay for metro\n  networks", "comments": "Transportation Research Board Annual Meeting 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In an effort to improve user satisfaction and transit image, transit service\nproviders worldwide offer delay compensations. Smart card data enables the\nestimation of passenger delays throughout the network and aid in monitoring\nservice performance. Notwithstanding, in order to prioritize measures for\nimproving service reliability and hence reducing passenger delays, it is\nparamount to identify the system components - stations and track segments -\nwhere most passenger delay occurs. To this end, we propose a novel method for\nestimating network passenger delay from individual trajectories. We decompose\nthe delay along a passenger trajectory into its corresponding track segment\ndelay, initial waiting time and transfer delay. We distinguish between two\ndifferent types of passenger delay in relation to the public transit network:\naverage passenger delay and total passenger delay. We employ temporal\nclustering on these two quantities to reveal daily and seasonal regularity in\ndelay patterns of the transit network. The estimation and clustering methods\nare demonstrated on one year of data from Washington metro network. The data\nconsists of schedule information and smart card data which includes\npassenger-train assignment of the metro network for the months of August 2017\nto August 2018. Our findings show that the average passenger delay is\nrelatively stable throughout the day. The temporal clustering reveals\npronounced and recurrent and thus predictable daily and weekly patterns with\ndistinct characteristics for certain months.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 12:28:16 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Krishnakumari", "Panchamy", ""], ["Cats", "Oded", ""], ["van Lint", "Hans", ""]]}, {"id": "2107.14110", "submitter": "Juan C. P\\'erez", "authors": "Juan C. P\\'erez, Motasem Alfarra, Guillaume Jeanneret, Laura Rueda,\n  Ali Thabet, Bernard Ghanem, Pablo Arbel\\'aez", "title": "Enhancing Adversarial Robustness via Test-time Transformation Ensembling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models are prone to being fooled by imperceptible perturbations\nknown as adversarial attacks. In this work, we study how equipping models with\nTest-time Transformation Ensembling (TTE) can work as a reliable defense\nagainst such attacks. While transforming the input data, both at train and test\ntimes, is known to enhance model performance, its effects on adversarial\nrobustness have not been studied. Here, we present a comprehensive empirical\nstudy of the impact of TTE, in the form of widely-used image transforms, on\nadversarial robustness. We show that TTE consistently improves model robustness\nagainst a variety of powerful attacks without any need for re-training, and\nthat this improvement comes at virtually no trade-off with accuracy on clean\nsamples. Finally, we show that the benefits of TTE transfer even to the\ncertified robustness domain, in which TTE provides sizable and consistent\nimprovements.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 15:32:35 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["P\u00e9rez", "Juan C.", ""], ["Alfarra", "Motasem", ""], ["Jeanneret", "Guillaume", ""], ["Rueda", "Laura", ""], ["Thabet", "Ali", ""], ["Ghanem", "Bernard", ""], ["Arbel\u00e1ez", "Pablo", ""]]}, {"id": "2107.14112", "submitter": "Petros Spachos", "authors": "Marc Jayson Baucas, Petros Spachos, and Stefano Gregori", "title": "Internet-of-Things Devices and Assistive Technologies for Healthcare:\n  Applications, Challenges, and Opportunities", "comments": null, "journal-ref": "IEEE Signal Processing Magazine, vol. 38, no. 4, pp. 65-77, July\n  2021", "doi": "10.1109/MSP.2021.3075929", "report-no": null, "categories": "physics.soc-ph cs.CY cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical conditions and cases are growing at a rapid pace, where physical\nspace is starting to be constrained. Hospitals and clinics no longer have the\nability to accommodate large numbers of incoming patients. It is clear that the\ncurrent state of the health industry needs to improve its valuable and limited\nresources. The evolution of the Internet of Things (IoT) devices along with\nassistive technologies can alleviate the problem in healthcare, by being a\nconvenient and easy means of accessing healthcare services wirelessly. There is\na plethora of IoT devices and potential applications that can take advantage of\nthe unique characteristics that these technologies can offer. However, at the\nsame time, these services pose novel challenges that need to be properly\naddressed. In this article, we review some popular categories of IoT-based\napplications for healthcare along with their devices. Then, we describe the\nchallenges and discuss how research can properly address the open issues and\nimprove the already existing implementations in healthcare. Further possible\nsolutions are also discussed to show their potential in being viable solutions\nfor future healthcare applications\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 12:18:12 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baucas", "Marc Jayson", ""], ["Spachos", "Petros", ""], ["Gregori", "Stefano", ""]]}, {"id": "2107.14135", "submitter": "YunPeng Li", "authors": "YunPeng Li", "title": "Modifications of FastICA in Convolutive Blind Source Separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutive blind source separation (BSS) is intended to recover the unknown\ncomponents from their convolutive mixtures. Contrary to the contrast functions\nused in instantaneous cases, the spatial-temporal prewhitening stage and the\npara-unitary filters constraint are difficult to implement in a convolutive\ncontext. In this paper, we propose several modifications of FastICA to\nalleviate these difficulties. Our method performs the simple prewhitening step\non convolutive mixtures prior to the separation and optimizes the contrast\nfunction under the diagonalization constraint implemented by single value\ndecomposition (SVD). Numerical simulations are implemented to verify the\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 13:29:55 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Li", "YunPeng", ""]]}, {"id": "2107.14151", "submitter": "Aniruddha Rajendra Rao", "authors": "Aniruddha Rajendra Rao, Matthew Reimherr", "title": "Modern Non-Linear Function-on-Function Regression", "comments": "6 figures, 5 tables (including supplementary material), 16 pages\n  (including supplementary material). arXiv admin note: text overlap with\n  arXiv:2104.09371", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new class of non-linear function-on-function regression models\nfor functional data using neural networks. We propose a framework using a\nhidden layer consisting of continuous neurons, called a continuous hidden\nlayer, for functional response modeling and give two model fitting strategies,\nFunctional Direct Neural Network (FDNN) and Functional Basis Neural Network\n(FBNN). Both are designed explicitly to exploit the structure inherent in\nfunctional data and capture the complex relations existing between the\nfunctional predictors and the functional response. We fit these models by\nderiving functional gradients and implement regularization techniques for more\nparsimonious results. We demonstrate the power and flexibility of our proposed\nmethod in handling complex functional models through extensive simulation\nstudies as well as real data examples.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 16:19:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Rao", "Aniruddha Rajendra", ""], ["Reimherr", "Matthew", ""]]}, {"id": "2107.14153", "submitter": "Siyu Huang", "authors": "Siyu Huang, Tianyang Wang, Haoyi Xiong, Jun Huan, Dejing Dou", "title": "Semi-Supervised Active Learning with Temporal Output Discrepancy", "comments": "ICCV 2021. Code is available at https://github.com/siyuhuang/TOD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning succeeds in a wide range of tasks, it highly depends on\nthe massive collection of annotated data which is expensive and time-consuming.\nTo lower the cost of data annotation, active learning has been proposed to\ninteractively query an oracle to annotate a small proportion of informative\nsamples in an unlabeled dataset. Inspired by the fact that the samples with\nhigher loss are usually more informative to the model than the samples with\nlower loss, in this paper we present a novel deep active learning approach that\nqueries the oracle for data annotation when the unlabeled sample is believed to\nincorporate high loss. The core of our approach is a measurement Temporal\nOutput Discrepancy (TOD) that estimates the sample loss by evaluating the\ndiscrepancy of outputs given by models at different optimization steps. Our\ntheoretical investigation shows that TOD lower-bounds the accumulated sample\nloss thus it can be used to select informative unlabeled samples. On basis of\nTOD, we further develop an effective unlabeled data sampling strategy as well\nas an unsupervised learning criterion that enhances model performance by\nincorporating the unlabeled data. Due to the simplicity of TOD, our active\nlearning approach is efficient, flexible, and task-agnostic. Extensive\nexperimental results demonstrate that our approach achieves superior\nperformances than the state-of-the-art active learning methods on image\nclassification and semantic segmentation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 16:25:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Huang", "Siyu", ""], ["Wang", "Tianyang", ""], ["Xiong", "Haoyi", ""], ["Huan", "Jun", ""], ["Dou", "Dejing", ""]]}, {"id": "2107.14171", "submitter": "Huayu Chen", "authors": "Jiayi Weng, Huayu Chen, Dong Yan, Kaichao You, Alexis Duburcq, Minghao\n  Zhang, Hang Su, Jun Zhu", "title": "Tianshou: a Highly Modularized Deep Reinforcement Learning Library", "comments": "16 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Tianshou, a highly modularized python library for deep\nreinforcement learning (DRL) that uses PyTorch as its backend. Tianshou aims to\nprovide building blocks to replicate common RL experiments and has officially\nsupported more than 15 classic algorithms succinctly. To facilitate related\nresearch and prove Tianshou's reliability, we release Tianshou's benchmark of\nMuJoCo environments, covering 9 classic algorithms and 9/13 Mujoco tasks with\nstate-of-the-art performance. We open-sourced Tianshou at\nhttps://github.com/thu-ml/tianshou/, which has received over 3k stars and\nbecome one of the most popular PyTorch-based DRL libraries.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 16:49:03 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Weng", "Jiayi", ""], ["Chen", "Huayu", ""], ["Yan", "Dong", ""], ["You", "Kaichao", ""], ["Duburcq", "Alexis", ""], ["Zhang", "Minghao", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2107.14194", "submitter": "Kushankur Ghosh", "authors": "Kushankur Ghosh, Colin Bellinger, Roberto Corizzo, Bartosz Krawczyk,\n  Nathalie Japkowicz", "title": "On the combined effect of class imbalance and concept complexity in deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural concept complexity, class overlap, and data scarcity are some of\nthe most important factors influencing the performance of classifiers under\nclass imbalance conditions. When these effects were uncovered in the early\n2000s, understandably, the classifiers on which they were demonstrated belonged\nto the classical rather than Deep Learning categories of approaches. As Deep\nLearning is gaining ground over classical machine learning and is beginning to\nbe used in critical applied settings, it is important to assess systematically\nhow well they respond to the kind of challenges their classical counterparts\nhave struggled with in the past two decades. The purpose of this paper is to\nstudy the behavior of deep learning systems in settings that have previously\nbeen deemed challenging to classical machine learning systems to find out\nwhether the depth of the systems is an asset in such settings. The results in\nboth artificial and real-world image datasets (MNIST Fashion, CIFAR-10) show\nthat these settings remain mostly challenging for Deep Learning systems and\nthat deeper architectures seem to help with structural concept complexity but\nnot with overlap challenges in simple artificial domains. Data scarcity is not\novercome by deeper layers, either. In the real-world image domains, where\noverfitting is a greater concern than in the artificial domains, the advantage\nof deeper architectures is less obvious: while it is observed in certain cases,\nit is quickly cancelled as models get deeper and perform worse than their\nshallower counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:30:00 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ghosh", "Kushankur", ""], ["Bellinger", "Colin", ""], ["Corizzo", "Roberto", ""], ["Krawczyk", "Bartosz", ""], ["Japkowicz", "Nathalie", ""]]}, {"id": "2107.14203", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen, Tracy Cai, Matei Zaharia, James Zou", "title": "Did the Model Change? Efficiently Assessing Machine Learning API Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) prediction APIs are increasingly widely used. An ML API\ncan change over time due to model updates or retraining. This presents a key\nchallenge in the usage of the API because it is often not clear to the user if\nand how the ML model has changed. Model shifts can affect downstream\napplication performance and also create oversight issues (e.g. if consistency\nis desired). In this paper, we initiate a systematic investigation of ML API\nshifts. We first quantify the performance shifts from 2020 to 2021 of popular\nML APIs from Google, Microsoft, Amazon, and others on a variety of datasets. We\nidentified significant model shifts in 12 out of 36 cases we investigated.\nInterestingly, we found several datasets where the API's predictions became\nsignificantly worse over time. This motivated us to formulate the API shift\nassessment problem at a more fine-grained level as estimating how the API\nmodel's confusion matrix changes over time when the data distribution is\nconstant. Monitoring confusion matrix shifts using standard random sampling can\nrequire a large number of samples, which is expensive as each API call costs a\nfee. We propose a principled adaptive sampling algorithm, MASA, to efficiently\nestimate confusion matrix shifts. MASA can accurately estimate the confusion\nmatrix shifts in commercial ML APIs using up to 90% fewer samples compared to\nrandom sampling. This work establishes ML API shifts as an important problem to\nstudy and provides a cost-effective approach to monitor such shifts.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:41:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Lingjiao", ""], ["Cai", "Tracy", ""], ["Zaharia", "Matei", ""], ["Zou", "James", ""]]}, {"id": "2107.14226", "submitter": "Dj Strouse", "authors": "DJ Strouse, Kate Baumli, David Warde-Farley, Vlad Mnih, Steven Hansen", "title": "Learning more skills through optimistic exploration", "comments": "Steven Hansen and DJ Strouse contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised skill learning objectives (Gregor et al., 2016, Eysenbach et\nal., 2018) allow agents to learn rich repertoires of behavior in the absence of\nextrinsic rewards. They work by simultaneously training a policy to produce\ndistinguishable latent-conditioned trajectories, and a discriminator to\nevaluate distinguishability by trying to infer latents from trajectories. The\nhope is for the agent to explore and master the environment by encouraging each\nskill (latent) to reliably reach different states. However, an inherent\nexploration problem lingers: when a novel state is actually encountered, the\ndiscriminator will necessarily not have seen enough training data to produce\naccurate and confident skill classifications, leading to low intrinsic reward\nfor the agent and effective penalization of the sort of exploration needed to\nactually maximize the objective. To combat this inherent pessimism towards\nexploration, we derive an information gain auxiliary objective that involves\ntraining an ensemble of discriminators and rewarding the policy for their\ndisagreement. Our objective directly estimates the epistemic uncertainty that\ncomes from the discriminator not having seen enough training examples, thus\nproviding an intrinsic reward more tailored to the true objective compared to\npseudocount-based methods (Burda et al., 2019). We call this exploration bonus\ndiscriminator disagreement intrinsic reward, or DISDAIN. We demonstrate\nempirically that DISDAIN improves skill learning both in a tabular grid world\n(Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we\nencourage researchers to treat pessimism with DISDAIN.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:58:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Strouse", "DJ", ""], ["Baumli", "Kate", ""], ["Warde-Farley", "David", ""], ["Mnih", "Vlad", ""], ["Hansen", "Steven", ""]]}, {"id": "2107.14228", "submitter": "Jason Kuen", "authors": "Lu Qi, Jason Kuen, Yi Wang, Jiuxiang Gu, Hengshuang Zhao, Zhe Lin,\n  Philip Torr, Jiaya Jia", "title": "Open-World Entity Segmentation", "comments": "Project page: http://luqi.info/Entity_Web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new image segmentation task, termed Entity Segmentation (ES)\nwith the aim to segment all visual entities in an image without considering\nsemantic category labels. It has many practical applications in image\nmanipulation/editing where the segmentation mask quality is typically crucial\nbut category labels are less important. In this setting, all\nsemantically-meaningful segments are equally treated as categoryless entities\nand there is no thing-stuff distinction. Based on our unified entity\nrepresentation, we propose a center-based entity segmentation framework with\ntwo novel modules to improve mask quality. Experimentally, both our new task\nand framework demonstrate superior advantages as against existing work. In\nparticular, ES enables the following: (1) merging multiple datasets to form a\nlarge training set without the need to resolve label conflicts; (2) any model\ntrained on one dataset can generalize exceptionally well to other datasets with\nunseen domains. Our code is made publicly available at\nhttps://github.com/dvlab-research/Entity.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:59:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Qi", "Lu", ""], ["Kuen", "Jason", ""], ["Wang", "Yi", ""], ["Gu", "Jiuxiang", ""], ["Zhao", "Hengshuang", ""], ["Lin", "Zhe", ""], ["Torr", "Philip", ""], ["Jia", "Jiaya", ""]]}, {"id": "2107.14229", "submitter": "Fabio Pizzati", "authors": "Fabio Pizzati, Pietro Cerri, Raoul de Charette", "title": "Guided Disentanglement in Generative Networks", "comments": "Journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-to-image translation (i2i) networks suffer from entanglement effects in\npresence of physics-related phenomena in target domain (such as occlusions,\nfog, etc), thus lowering the translation quality and variability. In this\npaper, we present a comprehensive method for disentangling physics-based traits\nin the translation, guiding the learning process with neural or physical\nmodels. For the latter, we integrate adversarial estimation and genetic\nalgorithms to correctly achieve disentanglement. The results show our approach\ndramatically increase performances in many challenging scenarios for image\ntranslation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 17:59:31 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Pizzati", "Fabio", ""], ["Cerri", "Pietro", ""], ["de Charette", "Raoul", ""]]}]