[{"id": "1511.00041", "submitter": "Murat Kocaoglu", "authors": "Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G. Dimakis, Sriram\n  Vishwanath", "title": "Learning Causal Graphs with Small Interventions", "comments": "Accepted to NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning causal networks with interventions, when\neach intervention is limited in size under Pearl's Structural Equation Model\nwith independent errors (SEM-IE). The objective is to minimize the number of\nexperiments to discover the causal directions of all the edges in a causal\ngraph. Previous work has focused on the use of separating systems for complete\ngraphs for this task. We prove that any deterministic adaptive algorithm needs\nto be a separating system in order to learn complete graphs in the worst case.\nIn addition, we present a novel separating system construction, whose size is\nclose to optimal and is arguably simpler than previous work in combinatorics.\nWe also develop a novel information theoretic lower bound on the number of\ninterventions that applies in full generality, including for randomized\nadaptive learning algorithms.\n  For general chordal graphs, we derive worst case lower bounds on the number\nof interventions. Building on observations about induced trees, we give a new\ndeterministic adaptive algorithm to learn directions on any chordal skeleton\ncompletely. In the worst case, our achievable scheme is an\n$\\alpha$-approximation algorithm where $\\alpha$ is the independence number of\nthe graph. We also show that there exist graph classes for which the sufficient\nnumber of experiments is close to the lower bound. In the other extreme, there\nare graph classes for which the required number of experiments is\nmultiplicatively $\\alpha$ away from our lower bound.\n  In simulations, our algorithm almost always performs very close to the lower\nbound, while the approach based on separating systems for complete graphs is\nsignificantly worse for random chordal graphs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 22:24:13 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Shanmugam", "Karthikeyan", ""], ["Kocaoglu", "Murat", ""], ["Dimakis", "Alexandros G.", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "1511.00043", "submitter": "Arunesh Sinha", "authors": "Arunesh Sinha, Debarun Kar, Milind Tambe", "title": "Learning Adversary Behavior in Security Games: A PAC Model Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent applications of Stackelberg Security Games (SSG), from wildlife crime\nto urban crime, have employed machine learning tools to learn and predict\nadversary behavior using available data about defender-adversary interactions.\nGiven these recent developments, this paper commits to an approach of directly\nlearning the response function of the adversary. Using the PAC model, this\npaper lays a firm theoretical foundation for learning in SSGs (e.g.,\ntheoretically answer questions about the numbers of samples required to learn\nadversary behavior) and provides utility guarantees when the learned adversary\nmodel is used to plan the defender's strategy. The paper also aims to answer\npractical questions such as how much more data is needed to improve an\nadversary model's accuracy. Additionally, we explain a recently observed\nphenomenon that prediction accuracy of learned adversary behavior is not enough\nto discover the utility maximizing defender strategy. We provide four main\ncontributions: (1) a PAC model of learning adversary response functions in\nSSGs; (2) PAC-model analysis of the learning of key, existing bounded\nrationality models in SSGs; (3) an entirely new approach to adversary modeling\nbased on a non-parametric class of response functions with PAC-model analysis\nand (4) identification of conditions under which computing the best defender\nstrategy against the learned adversary behavior is indeed the optimal strategy.\nFinally, we conduct experiments with real-world data from a national park in\nUganda, showing the benefit of our new adversary modeling approach and\nverification of our PAC model predictions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 22:27:25 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 17:51:17 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2015 08:34:43 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Sinha", "Arunesh", ""], ["Kar", "Debarun", ""], ["Tambe", "Milind", ""]]}, {"id": "1511.00048", "submitter": "Tor Lattimore", "authors": "Tor Lattimore", "title": "The Pareto Regret Frontier for Bandits", "comments": "14 pages. To appear at NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a multi-armed bandit problem it may be desirable to achieve a\nsmaller-than-usual worst-case regret for some special actions. I show that the\nprice for such unbalanced worst-case regret guarantees is rather high.\nSpecifically, if an algorithm enjoys a worst-case regret of B with respect to\nsome action, then there must exist another action for which the worst-case\nregret is at least {\\Omega}(nK/B), where n is the horizon and K the number of\nactions. I also give upper bounds in both the stochastic and adversarial\nsettings showing that this result cannot be improved. For the stochastic case\nthe pareto regret frontier is characterised exactly up to constant factors.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2015 23:30:30 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Lattimore", "Tor", ""]]}, {"id": "1511.00054", "submitter": "David Moore", "authors": "David A. Moore and Stuart J. Russell", "title": "Gaussian Process Random Fields", "comments": "Advances in Neural Information Processing Systems (NIPS), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes have been successful in both supervised and unsupervised\nmachine learning tasks, but their computational complexity has constrained\npractical applications. We introduce a new approximation for large-scale\nGaussian processes, the Gaussian Process Random Field (GPRF), in which local\nGPs are coupled via pairwise potentials. The GPRF likelihood is a simple,\ntractable, and parallelizeable approximation to the full GP marginal\nlikelihood, enabling latent variable modeling and hyperparameter selection on\nlarge datasets. We demonstrate its effectiveness on synthetic spatial data as\nwell as a real-world application to seismic event location.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 01:02:14 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Moore", "David A.", ""], ["Russell", "Stuart J.", ""]]}, {"id": "1511.00060", "submitter": "Xingxing Zhang", "authors": "Xingxing Zhang, Liang Lu, Mirella Lapata", "title": "Top-down Tree Long Short-Term Memory Networks", "comments": "to appear in NAACL 2016; code available at\n  https://github.com/XingxingZhang/td-treelstm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) networks, a type of recurrent neural network\nwith a more complex computational unit, have been successfully applied to a\nvariety of sequence modeling tasks. In this paper we develop Tree Long\nShort-Term Memory (TreeLSTM), a neural network model based on LSTM, which is\ndesigned to predict a tree rather than a linear sequence. TreeLSTM defines the\nprobability of a sentence by estimating the generation probability of its\ndependency tree. At each time step, a node is generated based on the\nrepresentation of the generated sub-tree. We further enhance the modeling power\nof TreeLSTM by explicitly representing the correlations between left and right\ndependents. Application of our model to the MSR sentence completion challenge\nachieves results beyond the current state of the art. We also report results on\ndependency parsing reranking achieving competitive performance.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 02:05:28 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 00:48:42 GMT"}, {"version": "v3", "created": "Sun, 3 Apr 2016 23:30:17 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Zhang", "Xingxing", ""], ["Lu", "Liang", ""], ["Lapata", "Mirella", ""]]}, {"id": "1511.00146", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan, Reza Babanezhad, Wu Lin, Mark Schmidt, Masashi\n  Sugiyama", "title": "Faster Stochastic Variational Inference using Proximal-Gradient Methods\n  with General Divergence Functions", "comments": "Published in UAI 2016. We have made the following change in this\n  revision: instead of expressing convergence rate results in terms of the\n  iterate difference, we state them in terms of the iterate distance divided by\n  the step-size (a measure of first-order optimality). We also removed some\n  claims about the performance with a fixed step size", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have explored stochastic gradient methods for\nvariational inference that exploit the geometry of the variational-parameter\nspace. However, the theoretical properties of these methods are not\nwell-understood and these methods typically only apply to\nconditionally-conjugate models. We present a new stochastic method for\nvariational inference which exploits the geometry of the variational-parameter\nspace and also yields simple closed-form updates even for non-conjugate models.\nWe also give a convergence-rate analysis of our method and many other previous\nmethods which exploit the geometry of the space. Our analysis generalizes\nexisting convergence results for stochastic mirror-descent on non-convex\nobjectives by using a more general class of divergence functions. Beyond giving\na theoretical justification for a variety of recent methods, our experiments\nshow that new algorithms derived in this framework lead to state of the art\nresults on a variety of problems. Further, due to its generality, we expect\nthat our theoretical analysis could also apply to other applications.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 15:56:32 GMT"}, {"version": "v2", "created": "Sun, 12 Jun 2016 23:47:06 GMT"}, {"version": "v3", "created": "Fri, 12 Aug 2016 00:47:22 GMT"}], "update_date": "2016-08-15", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Babanezhad", "Reza", ""], ["Lin", "Wu", ""], ["Schmidt", "Mark", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1511.00152", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki and Stephen Becker", "title": "Preconditioned Data Sparsification for Big Data with Applications to PCA\n  and K-means", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TIT.2017.2672725", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a compression scheme for large data sets that randomly keeps a\nsmall percentage of the components of each data sample. The benefit is that the\noutput is a sparse matrix and therefore subsequent processing, such as PCA or\nK-means, is significantly faster, especially in a distributed-data setting.\nFurthermore, the sampling is single-pass and applicable to streaming data. The\nsampling mechanism is a variant of previous methods proposed in the literature\ncombined with a randomized preconditioning to smooth the data. We provide\nguarantees for PCA in terms of the covariance matrix, and guarantees for\nK-means in terms of the error in the center estimators at a given step. We\npresent numerical evidence to show both that our bounds are nearly tight and\nthat our algorithms provide a real benefit when applied to standard test data\nsets, as well as providing certain benefits over related sampling approaches.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 17:20:00 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 22:40:13 GMT"}, {"version": "v3", "created": "Tue, 20 Sep 2016 00:35:14 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""], ["Becker", "Stephen", ""]]}, {"id": "1511.00158", "submitter": "Raymundo Navarrete", "authors": "Raymundo Navarrete and Divakar Viswanath", "title": "Prediction of Dynamical time Series Using Kernel Based Regression and\n  Smooth Splines", "comments": "minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of dynamical time series with additive noise using support vector\nmachines or kernel based regression has been proved to be consistent for\ncertain classes of discrete dynamical systems. Consistency implies that these\nmethods are effective at computing the expected value of a point at a future\ntime given the present coordinates. However, the present coordinates themselves\nare noisy, and therefore, these methods are not necessarily effective at\nremoving noise. In this article, we consider denoising and prediction as\nseparate problems for flows, as opposed to discrete time dynamical systems, and\nshow that the use of smooth splines is more effective at removing noise.\nCombination of smooth splines and kernel based regression yields predictors\nthat are more accurate on benchmarks typically by a factor of 2 or more. We\nprove that kernel based regression in combination with smooth splines converges\nto the exact predictor for time series extracted from any compact invariant set\nof any sufficiently smooth flow. As a consequence of convergence, one can find\nexamples where the combination of kernel based regression with smooth splines\nis superior by even a factor of $100$. The predictors that we compute operate\non delay coordinate data and not the full state vector, which is typically not\nobservable.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 18:00:39 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 19:11:14 GMT"}, {"version": "v3", "created": "Wed, 20 Jun 2018 14:03:25 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Navarrete", "Raymundo", ""], ["Viswanath", "Divakar", ""]]}, {"id": "1511.00213", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk, Ivan Petej, and Valentina Fedorova", "title": "Large-scale probabilistic predictors with and without guarantees of\n  validity", "comments": "38 pages, 14 figures, to appear in Advances in Neural Information\n  Processing Systems 28 (NIPS 2015). As compared with the previous version\n  (v1), the MATLAB code (the 5 files with extension .m) and results of new\n  empirical studies have been added", "journal-ref": null, "doi": null, "report-no": "13", "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies theoretically and empirically a method of turning\nmachine-learning algorithms into probabilistic predictors that automatically\nenjoys a property of validity (perfect calibration) and is computationally\nefficient. The price to pay for perfect calibration is that these probabilistic\npredictors produce imprecise (in practice, almost precise for large data sets)\nprobabilities. When these imprecise probabilities are merged into precise\nprobabilities, the resulting predictors, while losing the theoretical property\nof perfect calibration, are consistently more accurate than the existing\nmethods in empirical studies.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2015 07:16:04 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 09:28:34 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Vovk", "Vladimir", ""], ["Petej", "Ivan", ""], ["Fedorova", "Valentina", ""]]}, {"id": "1511.00271", "submitter": "Tianyi Luo", "authors": "Tianyi Luo, Dong Wang, Rong Liu, Yiqiao Pan", "title": "Stochastic Top-k ListNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ListNet is a well-known listwise learning to rank model and has gained much\nattention in recent years. A particular problem of ListNet, however, is the\nhigh computation complexity in model training, mainly due to the large number\nof object permutations involved in computing the gradients. This paper proposes\na stochastic ListNet approach which computes the gradient within a bounded\npermutation subset. It significantly reduces the computation complexity of\nmodel training and allows extension to Top-k models, which is impossible with\nthe conventional implementation based on full-set permutations. Meanwhile, the\nnew approach utilizes partial ranking information of human labels, which helps\nimprove model quality. Our experiments demonstrated that the stochastic ListNet\nmethod indeed leads to better ranking performance and speeds up the model\ntraining remarkably.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2015 16:34:52 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Luo", "Tianyi", ""], ["Wang", "Dong", ""], ["Liu", "Rong", ""], ["Pan", "Yiqiao", ""]]}, {"id": "1511.00352", "submitter": "Abhinav Maurya", "authors": "Abhinav Maurya", "title": "Spatial Semantic Scan: Jointly Detecting Subtle Events and their Spatial\n  Footprint", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods have been proposed for detecting emerging events in text streams\nusing topic modeling. However, these methods have shortcomings that make them\nunsuitable for rapid detection of locally emerging events on massive text\nstreams. We describe Spatially Compact Semantic Scan (SCSS) that has been\ndeveloped specifically to overcome the shortcomings of current methods in\ndetecting new spatially compact events in text streams. SCSS employs\nalternating optimization between using semantic scan to estimate contrastive\nforeground topics in documents, and discovering spatial neighborhoods with high\noccurrence of documents containing the foreground topics. We evaluate our\nmethod on Emergency Department chief complaints dataset (ED dataset) to verify\nthe effectiveness of our method in detecting real-world disease outbreaks from\nfree-text ED chief complaint data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 01:45:41 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 03:01:41 GMT"}, {"version": "v3", "created": "Sat, 28 May 2016 18:59:48 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Maurya", "Abhinav", ""]]}, {"id": "1511.00363", "submitter": "Matthieu Courbariaux", "authors": "Matthieu Courbariaux, Yoshua Bengio and Jean-Pierre David", "title": "BinaryConnect: Training Deep Neural Networks with binary weights during\n  propagations", "comments": "Accepted at NIPS 2015, 9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide\nrange of tasks, with the best results obtained with large training sets and\nlarge models. In the past, GPUs enabled these breakthroughs because of their\ngreater computational speed. In the future, faster computation at both training\nand test time is likely to be crucial for further progress and for consumer\napplications on low-power devices. As a result, there is much interest in\nresearch and development of dedicated hardware for Deep Learning (DL). Binary\nweights, i.e., weights which are constrained to only two possible values (e.g.\n-1 or 1), would bring great benefits to specialized DL hardware by replacing\nmany multiply-accumulate operations by simple accumulations, as multipliers are\nthe most space and power-hungry components of the digital implementation of\nneural networks. We introduce BinaryConnect, a method which consists in\ntraining a DNN with binary weights during the forward and backward\npropagations, while retaining precision of the stored weights in which\ngradients are accumulated. Like other dropout schemes, we show that\nBinaryConnect acts as regularizer and we obtain near state-of-the-art results\nwith BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 02:50:05 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 23:31:09 GMT"}, {"version": "v3", "created": "Mon, 18 Apr 2016 13:11:45 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Courbariaux", "Matthieu", ""], ["Bengio", "Yoshua", ""], ["David", "Jean-Pierre", ""]]}, {"id": "1511.00394", "submitter": "Francis Bach", "authors": "Francis Bach (LIENS, SIERRA)", "title": "Submodular Functions: from Discrete to Continous Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular set-functions have many applications in combinatorial\noptimization, as they can be minimized and approximately maximized in\npolynomial time. A key element in many of the algorithms and analyses is the\npossibility of extending the submodular set-function to a convex function,\nwhich opens up tools from convex optimization. Submodularity goes beyond\nset-functions and has naturally been considered for problems with multiple\nlabels or for functions defined on continuous domains, where it corresponds\nessentially to cross second-derivatives being nonpositive. In this paper, we\nshow that most results relating submodularity and convexity for set-functions\ncan be extended to all submodular functions. In particular, (a) we naturally\ndefine a continuous extension in a set of probability measures, (b) show that\nthe extension is convex if and only if the original function is submodular, (c)\nprove that the problem of minimizing a submodular function is equivalent to a\ntypically non-smooth convex optimization problem, and (d) propose another\nconvex optimization problem with better computational properties (e.g., a\nsmooth dual problem). Most of these extensions from the set-function situation\nare obtained by drawing links with the theory of multi-marginal optimal\ntransport, which provides also a new interpretation of existing results for\nset-functions. We then provide practical algorithms to minimize generic\nsubmodular functions on discrete domains, with associated convergence rates.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 06:33:59 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2016 19:46:11 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Bach", "Francis", "", "LIENS, SIERRA"]]}, {"id": "1511.00546", "submitter": "Lennart Gulikers", "authors": "Lennart Gulikers, Marc Lelarge, Laurent Massouli\\'e", "title": "An Impossibility Result for Reconstruction in a Degree-Corrected\n  Planted-Partition Model", "comments": "Appeared in Annals of Applied Probability", "journal-ref": "Annals of Applied Probability - Volume 28, Number 5 (2018),\n  3002-3027", "doi": null, "report-no": null, "categories": "math.PR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Degree-Corrected Stochastic Block Model (DC-SBM): a random\ngraph on $n$ nodes, having i.i.d. weights $(\\phi_u)_{u=1}^n$ (possibly\nheavy-tailed), partitioned into $q \\geq 2$ asymptotically equal-sized clusters.\nThe model parameters are two constants $a,b > 0$ and the finite second moment\nof the weights $\\Phi^{(2)}$. Vertices $u$ and $v$ are connected by an edge with\nprobability $\\frac{\\phi_u \\phi_v}{n}a$ when they are in the same class and with\nprobability $\\frac{\\phi_u \\phi_v}{n}b$ otherwise.\n  We prove that it is information-theoretically impossible to estimate the\nclusters in a way positively correlated with the true community structure when\n$(a-b)^2 \\Phi^{(2)} \\leq q(a+b)$.\n  As by-products of our proof we obtain $(1)$ a precise coupling result for\nlocal neighbourhoods in DC-SBM's, that we use in a follow up paper [Gulikers et\nal., 2017] to establish a law of large numbers for local-functionals and $(2)$\nthat long-range interactions are weak in (power-law) DC-SBM's.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 15:30:40 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 16:33:29 GMT"}, {"version": "v3", "created": "Sat, 24 Nov 2018 21:46:20 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Gulikers", "Lennart", ""], ["Lelarge", "Marc", ""], ["Massouli\u00e9", "Laurent", ""]]}, {"id": "1511.00561", "submitter": "Alex Kendall", "authors": "Vijay Badrinarayanan and Alex Kendall and Roberto Cipolla", "title": "SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel and practical deep fully convolutional neural network\narchitecture for semantic pixel-wise segmentation termed SegNet. This core\ntrainable segmentation engine consists of an encoder network, a corresponding\ndecoder network followed by a pixel-wise classification layer. The architecture\nof the encoder network is topologically identical to the 13 convolutional\nlayers in the VGG16 network. The role of the decoder network is to map the low\nresolution encoder feature maps to full input resolution feature maps for\npixel-wise classification. The novelty of SegNet lies is in the manner in which\nthe decoder upsamples its lower resolution input feature map(s). Specifically,\nthe decoder uses pooling indices computed in the max-pooling step of the\ncorresponding encoder to perform non-linear upsampling. This eliminates the\nneed for learning to upsample. The upsampled maps are sparse and are then\nconvolved with trainable filters to produce dense feature maps. We compare our\nproposed architecture with the widely adopted FCN and also with the well known\nDeepLab-LargeFOV, DeconvNet architectures. This comparison reveals the memory\nversus accuracy trade-off involved in achieving good segmentation performance.\n  SegNet was primarily motivated by scene understanding applications. Hence, it\nis designed to be efficient both in terms of memory and computational time\nduring inference. It is also significantly smaller in the number of trainable\nparameters than other competing architectures. We also performed a controlled\nbenchmark of SegNet and other architectures on both road scenes and SUN RGB-D\nindoor scene segmentation tasks. We show that SegNet provides good performance\nwith competitive inference time and more efficient inference memory-wise as\ncompared to other architectures. We also provide a Caffe implementation of\nSegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 15:51:03 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2015 13:56:56 GMT"}, {"version": "v3", "created": "Mon, 10 Oct 2016 21:11:59 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Badrinarayanan", "Vijay", ""], ["Kendall", "Alex", ""], ["Cipolla", "Roberto", ""]]}, {"id": "1511.00725", "submitter": "Wajdi Dhifli", "authors": "Wajdi Dhifli, Abdoulaye Banir\\'e Diallo", "title": "Toward an Efficient Multi-class Classification in an Open Universe", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is a fundamental task in machine learning and data mining.\nExisting classification methods are designed to classify unknown instances\nwithin a set of previously known training classes. Such a classification takes\nthe form of a prediction within a closed-set of classes. However, a more\nrealistic scenario that fits real-world applications is to consider the\npossibility of encountering instances that do not belong to any of the training\nclasses, $i.e.$, an open-set classification. In such situation, existing\nclosed-set classifiers will assign a training label to these instances\nresulting in a misclassification. In this paper, we introduce Galaxy-X, a novel\nmulti-class classification approach for open-set recognition problems. For each\nclass of the training set, Galaxy-X creates a minimum bounding hyper-sphere\nthat encompasses the distribution of the class by enclosing all of its\ninstances. In such manner, our method is able to distinguish instances\nresembling previously seen classes from those that are of unknown ones. To\nadequately evaluate open-set classification, we introduce a novel evaluation\nprocedure. Experimental results on benchmark datasets show the efficiency of\nour approach in classifying novel instances from known as well as unknown\nclasses.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 22:04:00 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 02:27:55 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 17:22:56 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Dhifli", "Wajdi", ""], ["Diallo", "Abdoulaye Banir\u00e9", ""]]}, {"id": "1511.00736", "submitter": "Wajdi Dhifli", "authors": "Wajdi Dhifli, Abdoulaye Banir\\'e Diallo", "title": "ProtNN: Fast and Accurate Nearest Neighbor Protein Function Prediction\n  based on Graph Embedding in Structural and Topological Space", "comments": null, "journal-ref": "BMC BioData Mining, 9:30, 2016", "doi": "10.1186/s13040-016-0108-2", "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the function of proteins is important for understanding the\nmolecular mechanisms of life. The number of publicly available protein\nstructures has increasingly become extremely large. Still, the determination of\nthe function of a protein structure remains a difficult, costly, and time\nconsuming task. The difficulties are often due to the essential role of spatial\nand topological structures in the determination of protein functions in living\ncells. In this paper, we propose ProtNN, a novel approach for protein function\nprediction. Given an unannotated protein structure and a set of annotated\nproteins, ProtNN finds the nearest neighbor annotated structures based on\nprotein-graph pairwise similarities. Given a query protein, ProtNN finds the\nnearest neighbor reference proteins based on a graph representation model and a\npairwise similarity between vector embedding of both query and reference\nprotein-graphs in structural and topological spaces. ProtNN assigns to the\nquery protein the function with the highest number of votes across the set of k\nnearest neighbor reference proteins, where k is a user-defined parameter.\nExperimental evaluation demonstrates that ProtNN is able to accurately classify\nseveral datasets in an extremely fast runtime compared to state-of-the-art\napproaches. We further show that ProtNN is able to scale up to a whole PDB\ndataset in a single-process mode with no parallelization, with a gain of\nthousands order of magnitude of runtime compared to state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 23:02:48 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 01:55:45 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Dhifli", "Wajdi", ""], ["Diallo", "Abdoulaye Banir\u00e9", ""]]}, {"id": "1511.00740", "submitter": "Enrique Martinez Miranda", "authors": "Enrique Mart\\'inez-Miranda and Peter McBurney and Matthew J. Howard", "title": "Learning Unfair Trading: a Market Manipulation Analysis From the\n  Reinforcement Learning Perspective", "comments": "7 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market manipulation is a strategy used by traders to alter the price of\nfinancial securities. One type of manipulation is based on the process of\nbuying or selling assets by using several trading strategies, among them\nspoofing is a popular strategy and is considered illegal by market regulators.\nSome promising tools have been developed to detect manipulation, but cases can\nstill be found in the markets. In this paper we model spoofing and pinging\ntrading, two strategies that differ in the legal background but share the same\nelemental concept of market manipulation. We use a reinforcement learning\nframework within the full and partial observability of Markov decision\nprocesses and analyse the underlying behaviour of the manipulators by finding\nthe causes of what encourages the traders to perform fraudulent activities.\nThis reveals procedures to counter the problem that may be helpful to market\nregulators as our model predicts the activity of spoofers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 23:15:47 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Mart\u00ednez-Miranda", "Enrique", ""], ["McBurney", "Peter", ""], ["Howard", "Matthew J.", ""]]}, {"id": "1511.00754", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Yu-Fang Chen, Chiao Hsieh, Ond\\v{r}ej Leng\\'al, Tsung-Ju Lii,\n  Ming-Hsien Tsai, Bow-Yaw Wang, and Farn Wang", "title": "PAC Learning-Based Verification and Model Synthesis", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel technique for verification and model synthesis of\nsequential programs. Our technique is based on learning a regular model of the\nset of feasible paths in a program, and testing whether this model contains an\nincorrect behavior. Exact learning algorithms require checking equivalence\nbetween the model and the program, which is a difficult problem, in general\nundecidable. Our learning procedure is therefore based on the framework of\nprobably approximately correct (PAC) learning, which uses sampling instead and\nprovides correctness guarantees expressed using the terms error probability and\nconfidence. Besides the verification result, our procedure also outputs the\nmodel with the said correctness guarantees. Obtained preliminary experiments\nshow encouraging results, in some cases even outperforming mature software\nverifiers.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 01:44:03 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Chen", "Yu-Fang", ""], ["Hsieh", "Chiao", ""], ["Leng\u00e1l", "Ond\u0159ej", ""], ["Lii", "Tsung-Ju", ""], ["Tsai", "Ming-Hsien", ""], ["Wang", "Bow-Yaw", ""], ["Wang", "Farn", ""]]}, {"id": "1511.00792", "submitter": "Sayantan Dasgupta", "authors": "Sayantan Dasgupta", "title": "Fast Collaborative Filtering from Implicit Feedback with Provable\n  Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building recommendation algorithms is one of the most challenging tasks in\nMachine Learning. Although most of the recommendation systems are built on\nexplicit feedback available from the users in terms of rating or text, a\nmajority of the applications do not receive such feedback. Here we consider the\nrecommendation task where the only available data is the records of user-item\ninteraction over web applications over time, in terms of subscription or\npurchase of items; this is known as implicit feedback recommendation. There is\nusually a massive amount of such user-item interaction available for any web\napplications. Algorithms like PLSI or Matrix Factorization runs several\niterations through the dataset, and may prove very expensive for large\ndatasets. Here we propose a recommendation algorithm based on Method of Moment,\nwhich involves factorization of second and third order moments of the dataset.\nOur algorithm can be proven to be globally convergent using PAC learning\ntheory. Further, we show how to extract the parameters using only three passes\nthrough the entire dataset. This results in a highly scalable algorithm that\nscales up to million of users even on a machine with a single-core processor\nand 8 GB RAM and produces competitive performance in comparison with existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 06:43:54 GMT"}, {"version": "v10", "created": "Sun, 21 Aug 2016 08:00:15 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2015 06:26:04 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2015 13:06:07 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2015 12:05:40 GMT"}, {"version": "v5", "created": "Mon, 23 Nov 2015 10:05:40 GMT"}, {"version": "v6", "created": "Thu, 24 Dec 2015 20:33:13 GMT"}, {"version": "v7", "created": "Fri, 15 Jan 2016 15:44:30 GMT"}, {"version": "v8", "created": "Sat, 6 Feb 2016 10:28:25 GMT"}, {"version": "v9", "created": "Wed, 8 Jun 2016 16:33:38 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Dasgupta", "Sayantan", ""]]}, {"id": "1511.00830", "submitter": "Christos Louizos", "authors": "Christos Louizos, Kevin Swersky, Yujia Li, Max Welling and Richard\n  Zemel", "title": "The Variational Fair Autoencoder", "comments": "Fixed typo in eq. 3 and 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of learning representations that are invariant to\ncertain nuisance or sensitive factors of variation in the data while retaining\nas much of the remaining information as possible. Our model is based on a\nvariational autoencoding architecture with priors that encourage independence\nbetween sensitive and latent factors of variation. Any subsequent processing,\nsuch as classification, can then be performed on this purged latent\nrepresentation. To remove any remaining dependencies we incorporate an\nadditional penalty term based on the \"Maximum Mean Discrepancy\" (MMD) measure.\nWe discuss how these architectures can be efficiently trained on data and show\nin experiments that this method is more effective than previous work in\nremoving unwanted sources of variation while maintaining informative latent\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 09:27:49 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2015 18:47:27 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2015 09:47:10 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2016 09:14:27 GMT"}, {"version": "v5", "created": "Thu, 4 Feb 2016 10:16:50 GMT"}, {"version": "v6", "created": "Thu, 10 Aug 2017 03:07:31 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Louizos", "Christos", ""], ["Swersky", "Kevin", ""], ["Li", "Yujia", ""], ["Welling", "Max", ""], ["Zemel", "Richard", ""]]}, {"id": "1511.00871", "submitter": "Brijnesh Jain", "authors": "Brijnesh J. Jain", "title": "Properties of the Sample Mean in Graph Spaces and the\n  Majorize-Minimize-Mean Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most fundamental concepts in statistics is the concept of sample\nmean. Properties of the sample mean that are well-defined in Euclidean spaces\nbecome unwieldy or even unclear in graph spaces. Open problems related to the\nsample mean of graphs include: non-existence, non-uniqueness, statistical\ninconsistency, lack of convergence results of mean algorithms, non-existence of\nmidpoints, and disparity to midpoints. We present conditions to resolve all six\nproblems and propose a Majorize-Minimize-Mean (MMM) Algorithm. Experiments on\ngraph datasets representing images and molecules show that the MMM-Algorithm\nbest approximates a sample mean of graphs compared to six other mean\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 12:09:26 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Jain", "Brijnesh J.", ""]]}, {"id": "1511.00925", "submitter": "Jamie Morgenstern", "authors": "Justin Hsu, Jamie Morgenstern, Ryan Rogers, Aaron Roth, Rakesh Vohra", "title": "Do Prices Coordinate Markets?", "comments": null, "journal-ref": null, "doi": "10.1145/2897518.2897559", "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Walrasian equilibrium prices can be said to coordinate markets: They support\na welfare optimal allocation in which each buyer is buying bundle of goods that\nis individually most preferred. However, this clean story has two caveats.\nFirst, the prices alone are not sufficient to coordinate the market, and buyers\nmay need to select among their most preferred bundles in a coordinated way to\nfind a feasible allocation. Second, we don't in practice expect to encounter\nexact equilibrium prices tailored to the market, but instead only approximate\nprices, somehow encoding \"distributional\" information about the market. How\nwell do prices work to coordinate markets when tie-breaking is not coordinated,\nand they encode only distributional information?\n  We answer this question. First, we provide a genericity condition such that\nfor buyers with Matroid Based Valuations, overdemand with respect to\nequilibrium prices is at most 1, independent of the supply of goods, even when\ntie-breaking is done in an uncoordinated fashion. Second, we provide\nlearning-theoretic results that show that such prices are robust to changing\nthe buyers in the market, so long as all buyers are sampled from the same\n(unknown) distribution.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 14:39:32 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 15:32:41 GMT"}, {"version": "v3", "created": "Wed, 13 Apr 2016 18:28:23 GMT"}, {"version": "v4", "created": "Thu, 12 May 2016 20:11:18 GMT"}, {"version": "v5", "created": "Wed, 22 Jun 2016 14:20:14 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hsu", "Justin", ""], ["Morgenstern", "Jamie", ""], ["Rogers", "Ryan", ""], ["Roth", "Aaron", ""], ["Vohra", "Rakesh", ""]]}, {"id": "1511.00971", "submitter": "Diego Marron", "authors": "Diego Marr\\'on (dmarron@ac.upc.edu) and Jesse Read\n  (jesse.read@aalto.fi) and Albert Bifet (albert.bifet@telecom-paristech.fr)\n  and Nacho Navarro (nacho@ac.upc.edu)", "title": "Data Stream Classification using Random Feature Functions and Novel\n  Method Combinations", "comments": "20 pages, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data streams are being generated in a faster, bigger, and more\ncommonplace. In this scenario, Hoeffding Trees are an established method for\nclassification. Several extensions exist, including high-performing ensemble\nsetups such as online and leveraging bagging. Also, $k$-nearest neighbors is a\npopular choice, with most extensions dealing with the inherent performance\nlimitations over a potentially-infinite stream.\n  At the same time, gradient descent methods are becoming increasingly popular,\nowing in part to the successes of deep learning. Although deep neural networks\ncan learn incrementally, they have so far proved too sensitive to\nhyper-parameter options and initial conditions to be considered an effective\n`off-the-shelf' data-streams solution.\n  In this work, we look at combinations of Hoeffding-trees, nearest neighbour,\nand gradient descent methods with a streaming preprocessing approach in the\nform of a random feature functions filter for additional predictive power.\n  We further extend the investigation to implementing methods on GPUs, which we\ntest on some large real-world datasets, and show the benefits of using GPUs for\ndata-stream learning due to their high scalability.\n  Our empirical evaluation yields positive results for the novel approaches\nthat we experiment with, highlighting important issues, and shed light on\npromising future directions in approaches to data-stream classification.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 16:29:57 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Marr\u00f3n", "Diego", "", "dmarron@ac.upc.edu"], ["Read", "Jesse", "", "jesse.read@aalto.fi"], ["Bifet", "Albert", "", "albert.bifet@telecom-paristech.fr"], ["Navarro", "Nacho", "", "nacho@ac.upc.edu"]]}, {"id": "1511.01029", "submitter": "Vijay Badrinarayanan", "authors": "Vijay Badrinarayanan and Bamdev Mishra and Roberto Cipolla", "title": "Understanding symmetries in deep networks", "comments": "Accepted at the 8th NIPS Workshop on Optimization for Machine\n  Learning (OPT2015) to be held at Montreal, Canada on December 11, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have highlighted scale invariance or symmetry present in the\nweight space of a typical deep network and the adverse effect it has on the\nEuclidean gradient based stochastic gradient descent optimization. In this\nwork, we show that a commonly used deep network, which uses convolution, batch\nnormalization, reLU, max-pooling, and sub-sampling pipeline, possess more\ncomplex forms of symmetry arising from scaling-based reparameterization of the\nnetwork weights. We propose to tackle the issue of the weight space symmetry by\nconstraining the filters to lie on the unit-norm manifold. Consequently,\ntraining the network boils down to using stochastic gradient descent updates on\nthe unit-norm manifold. Our empirical evidence based on the MNIST dataset shows\nthat the proposed updates improve the test performance beyond what is achieved\nwith batch normalization and without sacrificing the computational efficiency\nof the weight updates.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 18:50:03 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Badrinarayanan", "Vijay", ""], ["Mishra", "Bamdev", ""], ["Cipolla", "Roberto", ""]]}, {"id": "1511.01042", "submitter": "Junyoung Chung", "authors": "Junyoung Chung and Jacob Devlin and Hany Hassan Awadalla", "title": "Detecting Interrogative Utterances with Recurrent Neural Networks", "comments": "6 pages, accepted to NIPS 2015 Workshop on Machine Learning for\n  Spoken Language Understanding and Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore different neural network architectures that can\npredict if a speaker of a given utterance is asking a question or making a\nstatement. We com- pare the outcomes of regularization methods that are\npopularly used to train deep neural networks and study how different context\nfunctions can affect the classification performance. We also compare the\nefficacy of gated activation functions that are favorably used in recurrent\nneural networks and study how to combine multimodal inputs. We evaluate our\nmodels on two multimodal datasets: MSR-Skype and CALLHOME.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 19:26:16 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 03:54:19 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Chung", "Junyoung", ""], ["Devlin", "Jacob", ""], ["Awadalla", "Hany Hassan", ""]]}, {"id": "1511.01047", "submitter": "George Kesidis", "authors": "Zhicong Qiu, David J. Miller, George Kesidis", "title": "Detecting Clusters of Anomalies on Low-Dimensional Feature Subsets with\n  Application to Network Traffic Flow Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a variety of applications, one desires to detect groups of anomalous data\nsamples, with a group potentially manifesting its atypicality (relative to a\nreference model) on a low-dimensional subset of the full measured set of\nfeatures. Samples may only be weakly atypical individually, whereas they may be\nstrongly atypical when considered jointly. What makes this group anomaly\ndetection problem quite challenging is that it is a priori unknown which subset\nof features jointly manifests a particular group of anomalies. Moreover, it is\nunknown how many anomalous groups are present in a given data batch. In this\nwork, we develop a group anomaly detection (GAD) scheme to identify the subset\nof samples and subset of features that jointly specify an anomalous cluster. We\napply our approach to network intrusion detection to detect BotNet and\npeer-to-peer flow clusters. Unlike previous studies, our approach captures and\nexploits statistical dependencies that may exist between the measured features.\nExperiments on real world network traffic data demonstrate the advantage of our\nproposed system, and highlight the importance of exploiting feature dependency\nstructure, compared to the feature (or test) independence assumption made in\nprevious studies.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 15:13:59 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Qiu", "Zhicong", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""]]}, {"id": "1511.01158", "submitter": "Minwei Feng", "authors": "Minwei Feng, Bing Xiang, Bowen Zhou", "title": "Distributed Deep Learning for Question Answering", "comments": "This paper will appear in the Proceeding of The 25th ACM\n  International Conference on Information and Knowledge Management (CIKM 2016),\n  Indianapolis, USA", "journal-ref": null, "doi": "10.1145/2983323.2983377", "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an empirical study of the distributed deep learning for\nquestion answering subtasks: answer selection and question classification.\nComparison studies of SGD, MSGD, ADADELTA, ADAGRAD, ADAM/ADAMAX, RMSPROP,\nDOWNPOUR and EASGD/EAMSGD algorithms have been presented. Experimental results\nshow that the distributed framework based on the message passing interface can\naccelerate the convergence speed at a sublinear scale. This paper demonstrates\nthe importance of distributed training. For example, with 48 workers, a 24x\nspeedup is achievable for the answer selection task and running time is\ndecreased from 138.2 hours to 5.81 hours, which will increase the productivity\nsignificantly.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 23:18:35 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 15:41:54 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2016 16:41:37 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Feng", "Minwei", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""]]}, {"id": "1511.01169", "submitter": "Nitish Shirish Keskar", "authors": "Nitish Shirish Keskar and Albert S. Berahas", "title": "adaQN: An Adaptive Quasi-Newton Algorithm for Training RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are powerful models that achieve exceptional\nperformance on several pattern recognition problems. However, the training of\nRNNs is a computationally difficult task owing to the well-known\n\"vanishing/exploding\" gradient problem. Algorithms proposed for training RNNs\neither exploit no (or limited) curvature information and have cheap\nper-iteration complexity, or attempt to gain significant curvature information\nat the cost of increased per-iteration cost. The former set includes\ndiagonally-scaled first-order methods such as ADAGRAD and ADAM, while the\nlatter consists of second-order algorithms like Hessian-Free Newton and K-FAC.\nIn this paper, we present adaQN, a stochastic quasi-Newton algorithm for\ntraining RNNs. Our approach retains a low per-iteration cost while allowing for\nnon-diagonal scaling through a stochastic L-BFGS updating scheme. The method\nuses a novel L-BFGS scaling initialization scheme and is judicious in storing\nand retaining L-BFGS curvature pairs. We present numerical experiments on two\nlanguage modeling tasks and show that adaQN is competitive with popular RNN\ntraining algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 00:38:03 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 02:51:41 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2015 01:56:44 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 18:51:34 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2016 23:39:41 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Keskar", "Nitish Shirish", ""], ["Berahas", "Albert S.", ""]]}, {"id": "1511.01258", "submitter": "Noam Segev", "authors": "Noam Segev, Maayan Harel, Shie Mannor, Koby Crammer and Ran El-Yaniv", "title": "Learn on Source, Refine on Target:A Model Transfer Learning Framework\n  with Random Forests", "comments": "2 columns, 14 pages, TPAMI submitted", "journal-ref": "IEEE transactions on pattern analysis and machine intelligence 39\n  (2017) 1811-1824", "doi": "10.1109/TPAMI.2016.2618118", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose novel model transfer-learning methods that refine a decision\nforest model M learned within a \"source\" domain using a training set sampled\nfrom a \"target\" domain, assumed to be a variation of the source. We present two\nrandom forest transfer algorithms. The first algorithm searches greedily for\nlocally optimal modifications of each tree structure by trying to locally\nexpand or reduce the tree around individual nodes. The second algorithm does\nnot modify structure, but only the parameter (thresholds) associated with\ndecision nodes. We also propose to combine both methods by considering an\nensemble that contains the union of the two forests. The proposed methods\nexhibit impressive experimental results over a range of problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 09:41:12 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2015 06:56:12 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Segev", "Noam", ""], ["Harel", "Maayan", ""], ["Mannor", "Shie", ""], ["Crammer", "Koby", ""], ["El-Yaniv", "Ran", ""]]}, {"id": "1511.01280", "submitter": "Fabrice Rossi", "authors": "Arnaud De Myttenaere (SAMM, Viadeo), Boris Golden (Viadeo),\n  B\\'en\\'edicte Le Grand (CRI), Fabrice Rossi (SAMM)", "title": "Study of a bias in the offline evaluation of a recommendation algorithm", "comments": "arXiv admin note: substantial text overlap with arXiv:1407.0822", "journal-ref": "Petra Perner. 11th Industrial Conference on Data Mining, ICDM\n  2015, Jul 2015, Hamburg, Germany. Ibai Publishing, pp.57-70, 2015, Advances\n  in Data Mining", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems have been integrated into the majority of large online\nsystems to filter and rank information according to user profiles. It thus\ninfluences the way users interact with the system and, as a consequence, bias\nthe evaluation of the performance of a recommendation algorithm computed using\nhistorical data (via offline evaluation). This paper describes this bias and\ndiscuss the relevance of a weighted offline evaluation to reduce this bias for\ndifferent classes of recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 10:46:58 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["De Myttenaere", "Arnaud", "", "SAMM, Viadeo"], ["Golden", "Boris", "", "Viadeo"], ["Grand", "B\u00e9n\u00e9dicte Le", "", "CRI"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1511.01281", "submitter": "Fabrice Rossi", "authors": "Mohamed Khalil El Mahrsi (LTCI, SAMM), Romain Guigour\\`es (SAMM),\n  Fabrice Rossi (SAMM), Marc Boull\\'e", "title": "Co-Clustering Network-Constrained Trajectory Data", "comments": null, "journal-ref": "Advances in Knowledge Discovery and Management, 615, Springer\n  International Publishing, pp.19-32, 2015, Studies in Computational\n  Intelligence, 978-3-319-23750-3", "doi": "10.1007/978-3-319-23751-0_2", "report-no": null, "categories": "stat.ML cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, clustering moving object trajectories kept gaining interest from\nboth the data mining and machine learning communities. This problem, however,\nwas studied mainly and extensively in the setting where moving objects can move\nfreely on the euclidean space. In this paper, we study the problem of\nclustering trajectories of vehicles whose movement is restricted by the\nunderlying road network. We model relations between these trajectories and road\nsegments as a bipartite graph and we try to cluster its vertices. We\ndemonstrate our approaches on synthetic data and show how it could be useful in\ninferring knowledge about the flow dynamics and the behavior of the drivers\nusing the road network.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 10:47:29 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Mahrsi", "Mohamed Khalil El", "", "LTCI, SAMM"], ["Guigour\u00e8s", "Romain", "", "SAMM"], ["Rossi", "Fabrice", "", "SAMM"], ["Boull\u00e9", "Marc", ""]]}, {"id": "1511.01282", "submitter": "Phong Nguyen", "authors": "Phong Nguyen and Jun Wang and Alexandros Kalousis", "title": "Factorizing LambdaMART for cold start recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems often rely on point-wise loss metrics such as the mean\nsquared error. However, in real recommendation settings only few items are\npresented to a user. This observation has recently encouraged the use of\nrank-based metrics. LambdaMART is the state-of-the-art algorithm in learning to\nrank which relies on such a metric. Despite its success it does not have a\nprincipled regularization mechanism relying in empirical approaches to control\nmodel complexity leaving it thus prone to overfitting.\n  Motivated by the fact that very often the users' and items' descriptions as\nwell as the preference behavior can be well summarized by a small number of\nhidden factors, we propose a novel algorithm, LambdaMART Matrix Factorization\n(LambdaMART-MF), that learns a low rank latent representation of users and\nitems using gradient boosted trees. The algorithm factorizes lambdaMART by\ndefining relevance scores as the inner product of the learned representations\nof the users and items. The low rank is essentially a model complexity\ncontroller; on top of it we propose additional regularizers to constraint the\nlearned latent representations that reflect the user and item manifolds as\nthese are defined by their original feature based descriptors and the\npreference behavior. Finally we also propose to use a weighted variant of NDCG\nto reduce the penalty for similar items with large rating discrepancy.\n  We experiment on two very different recommendation datasets, meta-mining and\nmovies-users, and evaluate the performance of LambdaMART-MF, with and without\nregularization, in the cold start setting as well as in the simpler matrix\ncompletion setting. In both cases it outperforms in a significant manner\ncurrent state of the art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 10:49:15 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Nguyen", "Phong", ""], ["Wang", "Jun", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1511.01289", "submitter": "Saiprasad Ravishankar", "authors": "Saiprasad Ravishankar and Yoram Bresler", "title": "Data-Driven Learning of a Union of Sparsifying Transforms Model for\n  Blind Compressed Sensing", "comments": "Appears in IEEE Transactions on Computational Imaging, 2016", "journal-ref": null, "doi": "10.1109/TCI.2016.2567299", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing is a powerful tool in applications such as magnetic\nresonance imaging (MRI). It enables accurate recovery of images from highly\nundersampled measurements by exploiting the sparsity of the images or image\npatches in a transform domain or dictionary. In this work, we focus on blind\ncompressed sensing (BCS), where the underlying sparse signal model is a priori\nunknown, and propose a framework to simultaneously reconstruct the underlying\nimage as well as the unknown model from highly undersampled measurements.\nSpecifically, our model is that the patches of the underlying image(s) are\napproximately sparse in a transform domain. We also extend this model to a\nunion of transforms model that better captures the diversity of features in\nnatural images. The proposed block coordinate descent type algorithms for blind\ncompressed sensing are highly efficient, and are guaranteed to converge to at\nleast the partial global and partial local minimizers of the highly non-convex\nBCS problems. Our numerical experiments show that the proposed framework\nusually leads to better quality of image reconstructions in MRI compared to\nseveral recent image reconstruction methods. Importantly, the learning of a\nunion of sparsifying transforms leads to better image reconstructions than a\nsingle adaptive transform.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 11:02:45 GMT"}, {"version": "v2", "created": "Sat, 1 Oct 2016 04:15:01 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Bresler", "Yoram", ""]]}, {"id": "1511.01411", "submitter": "Vasilis Syrgkanis", "authors": "Constantinos Daskalakis, Vasilis Syrgkanis", "title": "Learning in Auctions: Regret is Hard, Envy is Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A line of recent work provides welfare guarantees of simple combinatorial\nauction formats, such as selling m items via simultaneous second price auctions\n(SiSPAs) (Christodoulou et al. 2008, Bhawalkar and Roughgarden 2011, Feldman et\nal. 2013). These guarantees hold even when the auctions are repeatedly executed\nand players use no-regret learning algorithms. Unfortunately, off-the-shelf\nno-regret algorithms for these auctions are computationally inefficient as the\nnumber of actions is exponential. We show that this obstacle is insurmountable:\nthere are no polynomial-time no-regret algorithms for SiSPAs, unless\nRP$\\supseteq$ NP, even when the bidders are unit-demand. Our lower bound raises\nthe question of how good outcomes polynomially-bounded bidders may discover in\nsuch auctions.\n  To answer this question, we propose a novel concept of learning in auctions,\ntermed \"no-envy learning.\" This notion is founded upon Walrasian equilibrium,\nand we show that it is both efficiently implementable and results in\napproximately optimal welfare, even when the bidders have fractionally\nsubadditive (XOS) valuations (assuming demand oracles) or coverage valuations\n(without demand oracles). No-envy learning outcomes are a relaxation of\nno-regret outcomes, which maintain their approximate welfare optimality while\nendowing them with computational tractability. Our results extend to other\nauction formats that have been studied in the literature via the smoothness\nparadigm.\n  Our results for XOS valuations are enabled by a novel\nFollow-The-Perturbed-Leader algorithm for settings where the number of experts\nis infinite, and the payoff function of the learner is non-linear. This\nalgorithm has applications outside of auction settings, such as in security\ngames. Our result for coverage valuations is based on a novel use of convex\nrounding schemes and a reduction to online convex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 17:39:30 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 16:48:48 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2015 19:49:30 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2015 15:29:10 GMT"}, {"version": "v5", "created": "Sat, 19 Dec 2015 17:41:20 GMT"}, {"version": "v6", "created": "Wed, 6 Apr 2016 17:55:25 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "1511.01419", "submitter": "Ofer Meshi", "authors": "Ofer Meshi, Mehrdad Mahdavi, Adrian Weller and David Sontag", "title": "Train and Test Tightness of LP Relaxations in Structured Prediction", "comments": "To appear in ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured prediction is used in areas such as computer vision and natural\nlanguage processing to predict structured outputs such as segmentations or\nparse trees. In these settings, prediction is performed by MAP inference or,\nequivalently, by solving an integer linear program. Because of the complex\nscoring functions required to obtain accurate predictions, both learning and\ninference typically require the use of approximate solvers. We propose a\ntheoretical explanation to the striking observation that approximations based\non linear programming (LP) relaxations are often tight on real-world instances.\nIn particular, we show that learning with LP relaxed inference encourages\nintegrality of training instances, and that tightness generalizes from train to\ntest data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 18:13:35 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2015 12:04:24 GMT"}, {"version": "v3", "created": "Wed, 27 Apr 2016 02:58:33 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Meshi", "Ofer", ""], ["Mahdavi", "Mehrdad", ""], ["Weller", "Adrian", ""], ["Sontag", "David", ""]]}, {"id": "1511.01432", "submitter": "Andrew Dai", "authors": "Andrew M. Dai and Quoc V. Le", "title": "Semi-supervised Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two approaches that use unlabeled data to improve sequence\nlearning with recurrent networks. The first approach is to predict what comes\nnext in a sequence, which is a conventional language model in natural language\nprocessing. The second approach is to use a sequence autoencoder, which reads\nthe input sequence into a vector and predicts the input sequence again. These\ntwo algorithms can be used as a \"pretraining\" step for a later supervised\nsequence learning algorithm. In other words, the parameters obtained from the\nunsupervised step can be used as a starting point for other supervised training\nmodels. In our experiments, we find that long short term memory recurrent\nnetworks after being pretrained with the two approaches are more stable and\ngeneralize better. With pretraining, we are able to train long short term\nmemory recurrent networks up to a few hundred timesteps, thereby achieving\nstrong performance in many text classification tasks, such as IMDB, DBpedia and\n20 Newsgroups.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 18:48:36 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Dai", "Andrew M.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1511.01442", "submitter": "Borja Balle", "authors": "Guillaume Rabusseau, Borja Balle, Shay B. Cohen", "title": "Low-Rank Approximation of Weighted Tree Automata", "comments": "To appear in AISTATS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a technique to minimize weighted tree automata (WTA), a powerful\nformalisms that subsumes probabilistic context-free grammars (PCFGs) and\nlatent-variable PCFGs. Our method relies on a singular value decomposition of\nthe underlying Hankel matrix defined by the WTA. Our main theoretical result is\nan efficient algorithm for computing the SVD of an infinite Hankel matrix\nimplicitly represented as a WTA. We provide an analysis of the approximation\nerror induced by the minimization, and we evaluate our method on real-world\ndata originating in newswire treebank. We show that the model achieves lower\nperplexity than previous methods for PCFG minimization, and also is much more\nstable due to the absence of local optima.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 19:17:18 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2015 08:39:49 GMT"}], "update_date": "2015-12-25", "authors_parsed": [["Rabusseau", "Guillaume", ""], ["Balle", "Borja", ""], ["Cohen", "Shay B.", ""]]}, {"id": "1511.01473", "submitter": "Alexander Wein", "authors": "Ankur Moitra and William Perry and Alexander S. Wein", "title": "How Robust are Reconstruction Thresholds for Community Detection?", "comments": "36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic block model is one of the oldest and most ubiquitous models\nfor studying clustering and community detection. In an exciting sequence of\ndevelopments, motivated by deep but non-rigorous ideas from statistical\nphysics, Decelle et al. conjectured a sharp threshold for when community\ndetection is possible in the sparse regime. Mossel, Neeman and Sly and\nMassoulie proved the conjecture and gave matching algorithms and lower bounds.\n  Here we revisit the stochastic block model from the perspective of semirandom\nmodels where we allow an adversary to make `helpful' changes that strengthen\nties within each community and break ties between them. We show a surprising\nresult that these `helpful' changes can shift the information-theoretic\nthreshold, making the community detection problem strictly harder. We\ncomplement this by showing that an algorithm based on semidefinite programming\n(which was known to get close to the threshold) continues to work in the\nsemirandom model (even for partial recovery). This suggests that algorithms\nbased on semidefinite programming are robust in ways that any algorithm meeting\nthe information-theoretic threshold cannot be.\n  These results point to an interesting new direction: Can we find robust,\nsemirandom analogues to some of the classical, average-case thresholds in\nstatistics? We also explore this question in the broadcast tree model, and we\nshow that the viewpoint of semirandom models can help explain why some\nalgorithms are preferred to others in practice, in spite of the gaps in their\nstatistical performance on random models.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 20:50:21 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 21:28:21 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Moitra", "Ankur", ""], ["Perry", "William", ""], ["Wein", "Alexander S.", ""]]}, {"id": "1511.01512", "submitter": "Iacopo Mastromatteo", "authors": "Emmanuel Bacry, St\\'ephane Ga\\\"iffas, Iacopo Mastromatteo and\n  Jean-Fran\\c{c}ois Muzy", "title": "Mean-field inference of Hawkes point processes", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": "10.1088/1751-8113/49/17/174006", "report-no": null, "categories": "cs.LG cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast and efficient estimation method that is able to accurately\nrecover the parameters of a d-dimensional Hawkes point-process from a set of\nobservations. We exploit a mean-field approximation that is valid when the\nfluctuations of the stochastic intensity are small. We show that this is\nnotably the case in situations when interactions are sufficiently weak, when\nthe dimension of the system is high or when the fluctuations are self-averaging\ndue to the large number of past events they involve. In such a regime the\nestimation of a Hawkes process can be mapped on a least-squares problem for\nwhich we provide an analytic solution. Though this estimator is biased, we show\nthat its precision can be comparable to the one of the Maximum Likelihood\nEstimator while its computation speed is shown to be improved considerably. We\ngive a theoretical control on the accuracy of our new approach and illustrate\nits efficiency using synthetic datasets, in order to assess the statistical\nestimation error of the parameters.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 21:09:33 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Bacry", "Emmanuel", ""], ["Ga\u00efffas", "St\u00e9phane", ""], ["Mastromatteo", "Iacopo", ""], ["Muzy", "Jean-Fran\u00e7ois", ""]]}, {"id": "1511.01556", "submitter": "Chao-Lin Liu", "authors": "Chao-Lin Liu, Chih-Kai Huang, Hongsu Wang, Peter K. Bol", "title": "Mining Local Gazetteers of Literary Chinese with CRF and Pattern based\n  Methods for Biographical Information in Chinese History", "comments": "11 pages, 5 figures, 5 tables, the Third Workshop on Big Humanities\n  Data (2015 IEEE BigData), the 29th Pacific Asia Conference on Language,\n  Information and Computation (PACLIC 29)", "journal-ref": null, "doi": "10.1109/BigData.2015.7363931", "report-no": null, "categories": "cs.CL cs.DL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Person names and location names are essential building blocks for identifying\nevents and social networks in historical documents that were written in\nliterary Chinese. We take the lead to explore the research on algorithmically\nrecognizing named entities in literary Chinese for historical studies with\nlanguage-model based and conditional-random-field based methods, and extend our\nwork to mining the document structures in historical documents. Practical\nevaluations were conducted with texts that were extracted from more than 220\nvolumes of local gazetteers (Difangzhi). Difangzhi is a huge and the single\nmost important collection that contains information about officers who served\nin local government in Chinese history. Our methods performed very well on\nthese realistic tests. Thousands of names and addresses were identified from\nthe texts. A good portion of the extracted names match the biographical\ninformation currently recorded in the China Biographical Database (CBDB) of\nHarvard University, and many others can be verified by historians and will\nbecome as new additions to CBDB.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 23:39:46 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Liu", "Chao-Lin", ""], ["Huang", "Chih-Kai", ""], ["Wang", "Hongsu", ""], ["Bol", "Peter K.", ""]]}, {"id": "1511.01644", "submitter": "Benjamin Letham", "authors": "Benjamin Letham, Cynthia Rudin, Tyler H. McCormick, David Madigan", "title": "Interpretable classifiers using rules and Bayesian analysis: Building a\n  better stroke prediction model", "comments": "Published at http://dx.doi.org/10.1214/15-AOAS848 in the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2015, Vol. 9, No. 3, 1350-1371", "doi": "10.1214/15-AOAS848", "report-no": "IMS-AOAS-AOAS848", "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to produce predictive models that are not only accurate, but are also\ninterpretable to human experts. Our models are decision lists, which consist of\na series of if...then... statements (e.g., if high blood pressure, then stroke)\nthat discretize a high-dimensional, multivariate feature space into a series of\nsimple, readily interpretable decision statements. We introduce a generative\nmodel called Bayesian Rule Lists that yields a posterior distribution over\npossible decision lists. It employs a novel prior structure to encourage\nsparsity. Our experiments show that Bayesian Rule Lists has predictive accuracy\non par with the current top algorithms for prediction in machine learning. Our\nmethod is motivated by recent developments in personalized medicine, and can be\nused to produce highly accurate and interpretable medical scoring systems. We\ndemonstrate this by producing an alternative to the CHADS$_2$ score, actively\nused in clinical practice for estimating the risk of stroke in patients that\nhave atrial fibrillation. Our model is as interpretable as CHADS$_2$, but more\naccurate.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 08:01:05 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Letham", "Benjamin", ""], ["Rudin", "Cynthia", ""], ["McCormick", "Tyler H.", ""], ["Madigan", "David", ""]]}, {"id": "1511.01664", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Tianbao Yang, Rong Jin, Zhi-Hua Zhou", "title": "Stochastic Proximal Gradient Descent for Nuclear Norm Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we utilize stochastic optimization to reduce the space\ncomplexity of convex composite optimization with a nuclear norm regularizer,\nwhere the variable is a matrix of size $m \\times n$. By constructing a low-rank\nestimate of the gradient, we propose an iterative algorithm based on stochastic\nproximal gradient descent (SPGD), and take the last iterate of SPGD as the\nfinal solution. The main advantage of the proposed algorithm is that its space\ncomplexity is $O(m+n)$, in contrast, most of previous algorithms have a $O(mn)$\nspace complexity. Theoretical analysis shows that it achieves $O(\\log\nT/\\sqrt{T})$ and $O(\\log T/T)$ convergence rates for general convex functions\nand strongly convex functions, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 09:24:13 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2015 08:02:25 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Zhang", "Lijun", ""], ["Yang", "Tianbao", ""], ["Jin", "Rong", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1511.01754", "submitter": "Bamdev Mishra", "authors": "Vijay Badrinarayanan and Bamdev Mishra and Roberto Cipolla", "title": "Symmetry-invariant optimization in deep networks", "comments": "Submitted to ICLR 2016. arXiv admin note: text overlap with\n  arXiv:1511.01029", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have highlighted scale invariance or symmetry that is present in\nthe weight space of a typical deep network and the adverse effect that it has\non the Euclidean gradient based stochastic gradient descent optimization. In\nthis work, we show that these and other commonly used deep networks, such as\nthose which use a max-pooling and sub-sampling layer, possess more complex\nforms of symmetry arising from scaling based reparameterization of the network\nweights. We then propose two symmetry-invariant gradient based weight updates\nfor stochastic gradient descent based learning. Our empirical evidence based on\nthe MNIST dataset shows that these updates improve the test performance without\nsacrificing the computational efficiency of the weight updates. We also show\nthe results of training with one of the proposed weight updates on an image\nsegmentation problem.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 14:17:40 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2015 19:01:03 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Badrinarayanan", "Vijay", ""], ["Mishra", "Bamdev", ""], ["Cipolla", "Roberto", ""]]}, {"id": "1511.01764", "submitter": "Meisam Razaviyayn", "authors": "Meisam Razaviyayn, Farzan Farnia, David Tse", "title": "Discrete R\\'enyi Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the binary classification problem of predicting a target variable\n$Y$ from a discrete feature vector $X = (X_1,...,X_d)$. When the probability\ndistribution $\\mathbb{P}(X,Y)$ is known, the optimal classifier, leading to the\nminimum misclassification rate, is given by the Maximum A-posteriori\nProbability decision rule. However, estimating the complete joint distribution\n$\\mathbb{P}(X,Y)$ is computationally and statistically impossible for large\nvalues of $d$. An alternative approach is to first estimate some low order\nmarginals of $\\mathbb{P}(X,Y)$ and then design the classifier based on the\nestimated low order marginals. This approach is also helpful when the complete\ntraining data instances are not available due to privacy concerns. In this\nwork, we consider the problem of finding the optimum classifier based on some\nestimated low order marginals of $(X,Y)$. We prove that for a given set of\nmarginals, the minimum Hirschfeld-Gebelein-Renyi (HGR) correlation principle\nintroduced in [1] leads to a randomized classification rule which is shown to\nhave a misclassification rate no larger than twice the misclassification rate\nof the optimal classifier. Then, under a separability condition, we show that\nthe proposed algorithm is equivalent to a randomized linear regression\napproach. In addition, this method naturally results in a robust feature\nselection method selecting a subset of features having the maximum worst case\nHGR correlation with the target variable. Our theoretical upper-bound is\nsimilar to the recent Discrete Chebyshev Classifier (DCC) approach [2], while\nthe proposed algorithm has significant computational advantages since it only\nrequires solving a least square optimization problem. Finally, we numerically\ncompare our proposed algorithm with the DCC classifier and show that the\nproposed algorithm results in better misclassification rate over various\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 14:47:04 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Razaviyayn", "Meisam", ""], ["Farnia", "Farzan", ""], ["Tse", "David", ""]]}, {"id": "1511.01776", "submitter": "Meisam Razaviyayn", "authors": "Meisam Razaviyayn, Hung-Wei Tseng, Zhi-Quan Luo", "title": "Computational Intractability of Dictionary Learning for Sparse\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the dictionary learning problem for sparse\nrepresentation. We first show that this problem is NP-hard by polynomial time\nreduction of the densest cut problem. Then, using successive convex\napproximation strategies, we propose efficient dictionary learning schemes to\nsolve several practical formulations of this problem to stationary points.\nUnlike many existing algorithms in the literature, such as K-SVD, our proposed\ndictionary learning scheme is theoretically guaranteed to converge to the set\nof stationary points under certain mild assumptions. For the image denoising\napplication, the performance and the efficiency of the proposed dictionary\nlearning scheme are comparable to that of K-SVD algorithm in simulation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 15:19:42 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Razaviyayn", "Meisam", ""], ["Tseng", "Hung-Wei", ""], ["Luo", "Zhi-Quan", ""]]}, {"id": "1511.01844", "submitter": "Lucas Theis", "authors": "Lucas Theis, A\\\"aron van den Oord, Matthias Bethge", "title": "A note on the evaluation of generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic generative models can be used for compression, denoising,\ninpainting, texture synthesis, semi-supervised learning, unsupervised feature\nlearning, and other tasks. Given this wide range of applications, it is not\nsurprising that a lot of heterogeneity exists in the way these models are\nformulated, trained, and evaluated. As a consequence, direct comparison between\nmodels is often difficult. This article reviews mostly known but often\nunderappreciated properties relating to the evaluation and interpretation of\ngenerative models with a focus on image models. In particular, we show that\nthree of the currently most commonly used criteria---average log-likelihood,\nParzen window estimates, and visual fidelity of samples---are largely\nindependent of each other when the data is high-dimensional. Good performance\nwith respect to one criterion therefore need not imply good performance with\nrespect to the other criteria. Our results show that extrapolation from one\ncriterion to another is not warranted and generative models need to be\nevaluated directly with respect to the application(s) they were intended for.\nIn addition, we provide examples demonstrating that Parzen window estimates\nshould generally be avoided.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 18:22:44 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 22:06:30 GMT"}, {"version": "v3", "created": "Sun, 24 Apr 2016 20:03:35 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Theis", "Lucas", ""], ["Oord", "A\u00e4ron van den", ""], ["Bethge", "Matthias", ""]]}, {"id": "1511.01865", "submitter": "Seyed Mostafa Kia", "authors": "Nastaran Mohammadian Rad, Andrea Bizzego, Seyed Mostafa Kia, Giuseppe\n  Jurman, Paola Venuti, Cesare Furlanello", "title": "Convolutional Neural Network for Stereotypical Motor Movement Detection\n  in Autism", "comments": "Presented at 5th NIPS Workshop on Machine Learning and Interpretation\n  in Neuroimaging (MLINI), 2015, (http://arxiv.org/html/1605.04435), Report-no:\n  MLINI/2015/13", "journal-ref": null, "doi": null, "report-no": "MLINI/2015/13", "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism Spectrum Disorders (ASDs) are often associated with specific atypical\npostural or motor behaviors, of which Stereotypical Motor Movements (SMMs) have\na specific visibility. While the identification and the quantification of SMM\npatterns remain complex, its automation would provide support to accurate\ntuning of the intervention in the therapy of autism. Therefore, it is essential\nto develop automatic SMM detection systems in a real world setting, taking care\nof strong inter-subject and intra-subject variability. Wireless accelerometer\nsensing technology can provide a valid infrastructure for real-time SMM\ndetection, however such variability remains a problem also for machine learning\nmethods, in particular whenever handcrafted features extracted from\naccelerometer signal are considered. Here, we propose to employ the deep\nlearning paradigm in order to learn discriminating features from multi-sensor\naccelerometer signals. Our results provide preliminary evidence that feature\nlearning and transfer learning embedded in the deep architecture achieve higher\naccurate SMM detectors in longitudinal scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 19:36:33 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 21:02:02 GMT"}, {"version": "v3", "created": "Tue, 7 Jun 2016 19:11:34 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Rad", "Nastaran Mohammadian", ""], ["Bizzego", "Andrea", ""], ["Kia", "Seyed Mostafa", ""], ["Jurman", "Giuseppe", ""], ["Venuti", "Paola", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1511.01870", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson, Christoph Dann, Hannes Nickisch", "title": "Thoughts on Massively Scalable Gaussian Processes", "comments": "25 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework and early results for massively scalable Gaussian\nprocesses (MSGP), significantly extending the KISS-GP approach of Wilson and\nNickisch (2015). The MSGP framework enables the use of Gaussian processes (GPs)\non billions of datapoints, without requiring distributed inference, or severe\nassumptions. In particular, MSGP reduces the standard $O(n^3)$ complexity of GP\nlearning and inference to $O(n)$, and the standard $O(n^2)$ complexity per test\npoint prediction to $O(1)$. MSGP involves 1) decomposing covariance matrices as\nKronecker products of Toeplitz matrices approximated by circulant matrices.\nThis multi-level circulant approximation allows one to unify the orthogonal\ncomputational benefits of fast Kronecker and Toeplitz approaches, and is\nsignificantly faster than either approach in isolation; 2) local kernel\ninterpolation and inducing points to allow for arbitrarily located data inputs,\nand $O(1)$ test time predictions; 3) exploiting block-Toeplitz Toeplitz-block\nstructure (BTTB), which enables fast inference and learning when\nmultidimensional Kronecker structure is not present; and 4) projections of the\ninput space to flexibly model correlated inputs and high dimensional data. The\nability to handle many ($m \\approx n$) inducing points allows for near-exact\naccuracy and large scale kernel learning.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 19:51:31 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Dann", "Christoph", ""], ["Nickisch", "Hannes", ""]]}, {"id": "1511.01942", "submitter": "Mark Schmidt", "authors": "Reza Babanezhad, Mohamed Osama Ahmed, Alim Virani, Mark Schmidt, Jakub\n  Kone\\v{c}n\\'y, Scott Sallinen", "title": "Stop Wasting My Gradients: Practical SVRG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and analyze several strategies for improving the performance of\nstochastic variance-reduced gradient (SVRG) methods. We first show that the\nconvergence rate of these methods can be preserved under a decreasing sequence\nof errors in the control variate, and use this to derive variants of SVRG that\nuse growing-batch strategies to reduce the number of gradient calculations\nrequired in the early iterations. We further (i) show how to exploit support\nvectors to reduce the number of gradient computations in the later iterations,\n(ii) prove that the commonly-used regularized SVRG iteration is justified and\nimproves the convergence rate, (iii) consider alternate mini-batch selection\nstrategies, and (iv) consider the generalization error of the method.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 22:45:12 GMT"}], "update_date": "2016-08-06", "authors_parsed": [["Babanezhad", "Reza", ""], ["Ahmed", "Mohamed Osama", ""], ["Virani", "Alim", ""], ["Schmidt", "Mark", ""], ["Kone\u010dn\u00fd", "Jakub", ""], ["Sallinen", "Scott", ""]]}, {"id": "1511.01966", "submitter": "Ankit Parekh", "authors": "Ankit Parekh and Ivan W. Selesnick", "title": "Enhanced Low-Rank Matrix Approximation", "comments": "5 pages, 2 figures. MATLAB code available at https://goo.gl/xAi85N", "journal-ref": "IEEE Signal Processing Letters, vol. 23, no. 4, pp.493-497, Apr.\n  2016", "doi": "10.1109/LSP.2016.2535227", "report-no": null, "categories": "cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter proposes to estimate low-rank matrices by formulating a convex\noptimization problem with non-convex regularization. We employ parameterized\nnon-convex penalty functions to estimate the non-zero singular values more\naccurately than the nuclear norm. A closed-form solution for the global optimum\nof the proposed objective function (sum of data fidelity and the non-convex\nregularizer) is also derived. The solution reduces to singular value\nthresholding method as a special case. The proposed method is demonstrated for\nimage denoising.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 01:19:18 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2015 14:42:31 GMT"}, {"version": "v3", "created": "Tue, 22 Mar 2016 18:16:36 GMT"}, {"version": "v4", "created": "Tue, 12 Apr 2016 21:21:48 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Parekh", "Ankit", ""], ["Selesnick", "Ivan W.", ""]]}, {"id": "1511.02024", "submitter": "Tobias Schnabel", "authors": "S. Sathiya Keerthi, Tobias Schnabel, Rajiv Khanna", "title": "Towards a Better Understanding of Predict and Count Models", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, Levy and Goldberg pointed out an interesting connection\nbetween prediction-based word embedding models and count models based on\npointwise mutual information. Under certain conditions, they showed that both\nmodels end up optimizing equivalent objective functions. This paper explores\nthis connection in more detail and lays out the factors leading to differences\nbetween these models. We find that the most relevant differences from an\noptimization perspective are (i) predict models work in a low dimensional space\nwhere embedding vectors can interact heavily; (ii) since predict models have\nfewer parameters, they are less prone to overfitting.\n  Motivated by the insight of our analysis, we show how count models can be\nregularized in a principled manner and provide closed-form solutions for L1 and\nL2 regularization. Finally, we propose a new embedding model with a convex\nobjective and the additional benefit of being intelligible.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 10:29:26 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Keerthi", "S. Sathiya", ""], ["Schnabel", "Tobias", ""], ["Khanna", "Rajiv", ""]]}, {"id": "1511.02025", "submitter": "Patrick Miller", "authors": "Patrick J. Miller, Gitta H. Lubke, Daniel B. McArtor, C. S. Bergeman", "title": "Finding structure in data using multivariate tree boosting", "comments": null, "journal-ref": null, "doi": "10.1037/met0000087", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology and collaboration enable dramatic increases in the size of\npsychological and psychiatric data collections, but finding structure in these\nlarge data sets with many collected variables is challenging. Decision tree\nensembles like random forests (Strobl, Malley, and Tutz, 2009) are a useful\ntool for finding structure, but are difficult to interpret with multiple\noutcome variables which are often of interest in psychology. To find and\ninterpret structure in data sets with multiple outcomes and many predictors\n(possibly exceeding the sample size), we introduce a multivariate extension to\na decision tree ensemble method called Gradient Boosted Regression Trees\n(Friedman, 2001). Our method, multivariate tree boosting, can be used for\nidentifying important predictors, detecting predictors with non-linear effects\nand interactions without specification of such effects, and for identifying\npredictors that cause two or more outcome variables to covary without\nparametric assumptions. We provide the R package 'mvtboost' to estimate, tune,\nand interpret the resulting model, which extends the implementation of\nunivariate boosting in the R package 'gbm' (Ridgeway, 2013) to continuous,\nmultivariate outcomes. To illustrate the approach, we analyze predictors of\npsychological well-being (Ryff and Keyes, 1995). Simulations verify that our\napproach identifies predictors with non-linear effects and achieves high\nprediction accuracy, exceeding or matching the performance of (penalized)\nmultivariate multiple regression and multivariate decision trees over a wide\nrange of conditions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 10:30:22 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2016 15:04:42 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Miller", "Patrick J.", ""], ["Lubke", "Gitta H.", ""], ["McArtor", "Daniel B.", ""], ["Bergeman", "C. S.", ""]]}, {"id": "1511.02030", "submitter": "David Carrera", "authors": "Josep Ll. Berral, Nicolas Poggi, David Carrera, Aaron Call, Rob\n  Reinauer, Daron Green", "title": "ALOJA-ML: A Framework for Automating Characterization and Knowledge\n  Discovery in Hadoop Deployments", "comments": "Submitted to KDD'2015. Part of the Aloja Project. Partially funded by\n  European Research Council (ERC) under the European Union's Horizon 2020\n  research and innovation programme (grant agreement No 639595) - HiEST Project", "journal-ref": "Proceedings of the 21th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining. Pages 1701-1710. ACM New York, NY, USA.\n  2015. ISBN: 978-1-4503-3664-2", "doi": "10.1145/2783258.2788600", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents ALOJA-Machine Learning (ALOJA-ML) an extension to the\nALOJA project that uses machine learning techniques to interpret Hadoop\nbenchmark performance data and performance tuning; here we detail the approach,\nefficacy of the model and initial results. Hadoop presents a complex execution\nenvironment, where costs and performance depends on a large number of software\n(SW) configurations and on multiple hardware (HW) deployment choices. These\nresults are accompanied by a test bed and tools to deploy and evaluate the\ncost-effectiveness of the different hardware configurations, parameter tunings,\nand Cloud services. Despite early success within ALOJA from expert-guided\nbenchmarking, it became clear that a genuinely comprehensive study requires\nautomation of modeling procedures to allow a systematic analysis of large and\nresource-constrained search spaces. ALOJA-ML provides such an automated system\nallowing knowledge discovery by modeling Hadoop executions from observed\nbenchmarks across a broad set of configuration parameters. The resulting\nperformance models can be used to forecast execution behavior of various\nworkloads; they allow 'a-priori' prediction of the execution times for new\nconfigurations and HW choices and they offer a route to model-based anomaly\ndetection. In addition, these models can guide the benchmarking exploration\nefficiently, by automatically prioritizing candidate future benchmark tests.\nInsights from ALOJA-ML's models can be used to reduce the operational time on\nclusters, speed-up the data acquisition and knowledge discovery process, and\nimportantly, reduce running costs. In addition to learning from the methodology\npresented in this work, the community can benefit in general from ALOJA\ndata-sets, framework, and derived insights to improve the design and deployment\nof Big Data applications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 10:55:18 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Berral", "Josep Ll.", ""], ["Poggi", "Nicolas", ""], ["Carrera", "David", ""], ["Call", "Aaron", ""], ["Reinauer", "Rob", ""], ["Green", "Daron", ""]]}, {"id": "1511.02037", "submitter": "David Carrera", "authors": "Josep Ll. Berral, Nicolas Poggi, David Carrera, Aaron Call, Rob\n  Reinauer, Daron Green", "title": "ALOJA: A Framework for Benchmarking and Predictive Analytics in Big Data\n  Deployments", "comments": "Submitted to IEEE Transactions on Emerging Topics in Computing\n  (TETC). Part of the Aloja Project. Partially funded by European Research\n  Council (ERC) under the European Union's Horizon 2020 research and innovation\n  programme (grant agreement No 639595) - HiEST Project. arXiv admin note:\n  substantial text overlap with arXiv:1511.02030", "journal-ref": null, "doi": "10.1109/TETC.2015.2496504", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the ALOJA project and its analytics tools, which\nleverages machine learning to interpret Big Data benchmark performance data and\ntuning. ALOJA is part of a long-term collaboration between BSC and Microsoft to\nautomate the characterization of cost-effectiveness on Big Data deployments,\ncurrently focusing on Hadoop. Hadoop presents a complex run-time environment,\nwhere costs and performance depend on a large number of configuration choices.\nThe ALOJA project has created an open, vendor-neutral repository, featuring\nover 40,000 Hadoop job executions and their performance details. The repository\nis accompanied by a test-bed and tools to deploy and evaluate the\ncost-effectiveness of different hardware configurations, parameters and Cloud\nservices. Despite early success within ALOJA, a comprehensive study requires\nautomation of modeling procedures to allow an analysis of large and\nresource-constrained search spaces. The predictive analytics extension,\nALOJA-ML, provides an automated system allowing knowledge discovery by modeling\nenvironments from observed executions. The resulting models can forecast\nexecution behaviors, predicting execution times for new configurations and\nhardware choices. That also enables model-based anomaly detection or efficient\nbenchmark guidance by prioritizing executions. In addition, the community can\nbenefit from ALOJA data-sets and framework to improve the design and deployment\nof Big Data applications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 11:27:29 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Berral", "Josep Ll.", ""], ["Poggi", "Nicolas", ""], ["Carrera", "David", ""], ["Call", "Aaron", ""], ["Reinauer", "Rob", ""], ["Green", "Daron", ""]]}, {"id": "1511.02124", "submitter": "Rahul Gopal Krishnan", "authors": "Rahul G. Krishnan, Simon Lacoste-Julien, David Sontag", "title": "Barrier Frank-Wolfe for Marginal Inference", "comments": "25 pages, 12 figures, To appear in Neural Information Processing\n  Systems (NIPS) 2015, Corrected reference and cleaned up bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a globally-convergent algorithm for optimizing the\ntree-reweighted (TRW) variational objective over the marginal polytope. The\nalgorithm is based on the conditional gradient method (Frank-Wolfe) and moves\npseudomarginals within the marginal polytope through repeated maximum a\nposteriori (MAP) calls. This modular structure enables us to leverage black-box\nMAP solvers (both exact and approximate) for variational inference, and obtains\nmore accurate results than tree-reweighted algorithms that optimize over the\nlocal consistency relaxation. Theoretically, we bound the sub-optimality for\nthe proposed algorithm despite the TRW objective having unbounded gradients at\nthe boundary of the marginal polytope. Empirically, we demonstrate the\nincreased quality of results found by tightening the relaxation over the\nmarginal polytope as well as the spanning tree polytope on synthetic and\nreal-world instances.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 15:48:53 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 18:57:33 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Krishnan", "Rahul G.", ""], ["Lacoste-Julien", "Simon", ""], ["Sontag", "David", ""]]}, {"id": "1511.02136", "submitter": "James Atwood", "authors": "James Atwood and Don Towsley", "title": "Diffusion-Convolutional Neural Networks", "comments": "Full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present diffusion-convolutional neural networks (DCNNs), a new model for\ngraph-structured data. Through the introduction of a diffusion-convolution\noperation, we show how diffusion-based representations can be learned from\ngraph-structured data and used as an effective basis for node classification.\nDCNNs have several attractive qualities, including a latent representation for\ngraphical data that is invariant under isomorphism, as well as polynomial-time\nprediction and learning that can be represented as tensor operations and\nefficiently implemented on the GPU. Through several experiments with real\nstructured datasets, we demonstrate that DCNNs are able to outperform\nprobabilistic relational models and kernel-on-graph methods at relational node\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 16:09:32 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 14:33:30 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2015 14:38:08 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 19:33:18 GMT"}, {"version": "v5", "created": "Tue, 19 Jan 2016 20:36:29 GMT"}, {"version": "v6", "created": "Fri, 8 Jul 2016 15:05:17 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Atwood", "James", ""], ["Towsley", "Don", ""]]}, {"id": "1511.02176", "submitter": "Francesco Orabona", "authors": "Francesco Orabona and David Pal", "title": "Optimal Non-Asymptotic Lower Bound on the Minimax Regret of Learning\n  with Expert Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove non-asymptotic lower bounds on the expectation of the maximum of $d$\nindependent Gaussian variables and the expectation of the maximum of $d$\nindependent symmetric random walks. Both lower bounds recover the optimal\nleading constant in the limit. A simple application of the lower bound for\nrandom walks is an (asymptotically optimal) non-asymptotic lower bound on the\nminimax regret of online learning with expert advice.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 18:01:38 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Orabona", "Francesco", ""], ["Pal", "David", ""]]}, {"id": "1511.02196", "submitter": "Haohan Wang", "authors": "Haohan Wang, Madhavi K. Ganapathiraju", "title": "Evaluating Protein-protein Interaction Predictors with a Novel\n  3-Dimensional Metric", "comments": "This article is an extended version of a poster presented in AMIA TBI\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order for the predicted interactions to be directly adopted by biologists,\nthe ma- chine learning predictions have to be of high precision, regardless of\nrecall. This aspect cannot be evaluated or numerically represented well by\ntraditional metrics like accuracy, ROC, or precision-recall curve. In this\nwork, we start from the alignment in sensitivity of ROC and recall of\nprecision-recall curve, and propose an evaluation metric focusing on the\nability of a model to be adopted by biologists. This metric evaluates the\nability of a machine learning algorithm to predict only new interactions,\nmeanwhile, it eliminates the influence of test dataset. In the experiment of\nevaluating different classifiers with a same data set and evaluating the same\npredictor with different datasets, our new metric fulfills the evaluation task\nof our interest while two widely recognized metrics, ROC and precision-recall\ncurve fail the tasks for different reasons.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 19:14:09 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Wang", "Haohan", ""], ["Ganapathiraju", "Madhavi K.", ""]]}, {"id": "1511.02222", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, Eric P. Xing", "title": "Deep Kernel Learning", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce scalable deep kernels, which combine the structural properties\nof deep learning architectures with the non-parametric flexibility of kernel\nmethods. Specifically, we transform the inputs of a spectral mixture base\nkernel with a deep architecture, using local kernel interpolation, inducing\npoints, and structure exploiting (Kronecker and Toeplitz) algebra for a\nscalable kernel representation. These closed-form kernels can be used as\ndrop-in replacements for standard kernels, with benefits in expressive power\nand scalability. We jointly learn the properties of these kernels through the\nmarginal likelihood of a Gaussian process. Inference and learning cost $O(n)$\nfor $n$ training points, and predictions cost $O(1)$ per test point. On a large\nand diverse collection of applications, including a dataset with 2 million\nexamples, we show improved performance over scalable Gaussian processes with\nflexible kernel learning models, and stand-alone deep architectures.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 20:38:08 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Hu", "Zhiting", ""], ["Salakhutdinov", "Ruslan", ""], ["Xing", "Eric P.", ""]]}, {"id": "1511.02254", "submitter": "Eric Heim", "authors": "Eric Heim (1), Matthew Berger (2), Lee Seversky (2), Milos Hauskrecht\n  (1) ((1) University of Pittsburgh, (2) Air Force Research Laboratory,\n  Information Directorate)", "title": "Active Perceptual Similarity Modeling with Auxiliary Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a model of perceptual similarity from a collection of objects is a\nfundamental task in machine learning underlying numerous applications. A common\nway to learn such a model is from relative comparisons in the form of triplets:\nresponses to queries of the form \"Is object a more similar to b than it is to\nc?\". If no consideration is made in the determination of which queries to ask,\nexisting similarity learning methods can require a prohibitively large number\nof responses. In this work, we consider the problem of actively learning from\ntriplets -finding which queries are most useful for learning. Different from\nprevious active triplet learning approaches, we incorporate auxiliary\ninformation into our similarity model and introduce an active learning scheme\nto find queries that are informative for quickly learning both the relevant\naspects of auxiliary data and the directly-learned similarity components.\nCompared to prior approaches, we show that we can learn just as effectively\nwith much fewer queries. For evaluation, we introduce a new dataset of\nexhaustive triplet comparisons obtained from humans and demonstrate improved\nperformance for different types of auxiliary information.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 22:30:46 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Heim", "Eric", ""], ["Berger", "Matthew", ""], ["Seversky", "Lee", ""], ["Hauskrecht", "Milos", ""]]}, {"id": "1511.02258", "submitter": "Ze Jia Zhang", "authors": "Z. Zhang, K. Duraisamy, N. A. Gumerov", "title": "Efficient Multiscale Gaussian Process Regression using Hierarchical\n  Clustering", "comments": "22 pages, 9 figures. Preprint. Submitted to Machine Learning Mar.\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Gaussian Process (GP) regression, a powerful machine learning tool,\nis computationally expensive when it is applied to large datasets, and\npotentially inaccurate when data points are sparsely distributed in a\nhigh-dimensional feature space. To address these challenges, a new multiscale,\nsparsified GP algorithm is formulated, with the goal of application to large\nscientific computing datasets. In this approach, the data is partitioned into\nclusters and the cluster centers are used to define a reduced training set,\nresulting in an improvement over standard GPs in terms of training and\nevaluation costs. Further, a hierarchical technique is used to adaptively map\nthe local covariance representation to the underlying sparsity of the feature\nspace, leading to improved prediction accuracy when the data distribution is\nhighly non-uniform. A theoretical investigation of the computational complexity\nof the algorithm is presented. The efficacy of this method is then demonstrated\non smooth and discontinuous analytical functions and on data from a direct\nnumerical simulation of turbulent combustion.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 23:18:13 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 04:20:37 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Zhang", "Z.", ""], ["Duraisamy", "K.", ""], ["Gumerov", "N. A.", ""]]}, {"id": "1511.02274", "submitter": "Zichao Yang", "authors": "Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola", "title": "Stacked Attention Networks for Image Question Answering", "comments": "test-dev/standard results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents stacked attention networks (SANs) that learn to answer\nnatural language questions from images. SANs use semantic representation of a\nquestion as query to search for the regions in an image that are related to the\nanswer. We argue that image question answering (QA) often requires multiple\nsteps of reasoning. Thus, we develop a multiple-layer SAN in which we query an\nimage multiple times to infer the answer progressively. Experiments conducted\non four image QA data sets demonstrate that the proposed SANs significantly\noutperform previous state-of-the-art approaches. The visualization of the\nattention layers illustrates the progress that the SAN locates the relevant\nvisual clues that lead to the answer of the question layer-by-layer.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 00:43:32 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 20:37:49 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Yang", "Zichao", ""], ["He", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""], ["Smola", "Alex", ""]]}, {"id": "1511.02283", "submitter": "Junhua Mao", "authors": "Junhua Mao, Jonathan Huang, Alexander Toshev, Oana Camburu, Alan\n  Yuille, Kevin Murphy", "title": "Generation and Comprehension of Unambiguous Object Descriptions", "comments": "We have released the Google Refexp dataset together with a toolbox\n  for visualization and evaluation, see\n  https://github.com/mjhucla/Google_Refexp_toolbox. Camera ready version for\n  CVPR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method that can generate an unambiguous description (known as a\nreferring expression) of a specific object or region in an image, and which can\nalso comprehend or interpret such an expression to infer which object is being\ndescribed. We show that our method outperforms previous methods that generate\ndescriptions of objects without taking into account other potentially ambiguous\nobjects in the scene. Our model is inspired by recent successes of deep\nlearning methods for image captioning, but while image captioning is difficult\nto evaluate, our task allows for easy objective evaluation. We also present a\nnew large-scale dataset for referring expressions, based on MS-COCO. We have\nreleased the dataset and a toolbox for visualization and evaluation, see\nhttps://github.com/mjhucla/Google_Refexp_toolbox\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 02:17:36 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2015 08:58:08 GMT"}, {"version": "v3", "created": "Mon, 11 Apr 2016 01:11:56 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Mao", "Junhua", ""], ["Huang", "Jonathan", ""], ["Toshev", "Alexander", ""], ["Camburu", "Oana", ""], ["Yuille", "Alan", ""], ["Murphy", "Kevin", ""]]}, {"id": "1511.02352", "submitter": "Wiharto Wiharto", "authors": "Wiharto Wiharto, Hari Kusnanto, Herianto Herianto", "title": "Performance Analysis of Multiclass Support Vector Machine Classification\n  for Diagnosis of Coronary Heart Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic diagnosis of coronary heart disease helps the doctor to support in\ndecision making a diagnosis. Coronary heart disease have some types or levels.\nReferring to the UCI Repository dataset, it divided into 4 types or levels that\nare labeled numbers 1-4 (low, medium, high and serious). The diagnosis models\ncan be analyzed with multiclass classification approach. One of multiclass\nclassification approach used, one of which is a support vector machine (SVM).\nThe SVM use due to strong performance of SVM in binary classification. This\nresearch study multiclass performance classification support vector machine to\ndiagnose the type or level of coronary heart disease. Coronary heart disease\npatient data taken from the UCI Repository. Stages in this study is\npreprocessing, which consist of, to normalizing the data, divide the data into\ndata training and testing. The next stage of multiclass classification and\nperformance analysis. This study uses multiclass SVM algorithm, namely: Binary\nTree Support Vector Machine (BTSVM), One-Against-One (OAO), One-Against-All\n(OAA), Decision Direct Acyclic Graph (DDAG) and Exhaustive Output Error\nCorrection Code (ECOC). Performance parameter used is recall, precision,\nF-measure and Overall accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 13:09:57 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 14:20:59 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Wiharto", "Wiharto", ""], ["Kusnanto", "Hari", ""], ["Herianto", "Herianto", ""]]}, {"id": "1511.02385", "submitter": "Syvester Olubolu Orimaye Dr", "authors": "Sylvester Olubolu Orimaye, Saadat M. Alhashmi, Eu-Gene Siew and Sang\n  Jung Kang", "title": "Review-Level Sentiment Classification with Sentence-Level Polarity\n  Correction", "comments": "15 pages. This paper is based on the same sentence-level technique\n  proposed in Orimaye, S. O., Alhashmi, S. M., and Siew, E. G. Buy it-dont buy\n  it: sentiment classification on Amazon reviews using sentence polarity shift.\n  In PRICAI 2012: Trends in Artificial Intelligence, pp. 386-399. Springer\n  Berlin Heidelberg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an effective technique to solving review-level sentiment\nclassification problem by using sentence-level polarity correction. Our\npolarity correction technique takes into account the consistency of the\npolarities (positive and negative) of sentences within each product review\nbefore performing the actual machine learning task. While sentences with\ninconsistent polarities are removed, sentences with consistent polarities are\nused to learn state-of-the-art classifiers. The technique achieved better\nresults on different types of products reviews and outperforms baseline models\nwithout the correction technique. Experimental results show an average of 82%\nF-measure on four different product review domains.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 18:38:22 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Orimaye", "Sylvester Olubolu", ""], ["Alhashmi", "Saadat M.", ""], ["Siew", "Eu-Gene", ""], ["Kang", "Sang Jung", ""]]}, {"id": "1511.02386", "submitter": "Dustin Tran", "authors": "Rajesh Ranganath, Dustin Tran, David M. Blei", "title": "Hierarchical Variational Models", "comments": "Appears in International Conference on Machine Learning, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black box variational inference allows researchers to easily prototype and\nevaluate an array of models. Recent advances allow such algorithms to scale to\nhigh dimensions. However, a central question remains: How to specify an\nexpressive variational distribution that maintains efficient computation? To\naddress this, we develop hierarchical variational models (HVMs). HVMs augment a\nvariational approximation with a prior on its parameters, which allows it to\ncapture complex structure for both discrete and continuous latent variables.\nThe algorithm we develop is black box, can be used for any HVM, and has the\nsame computational efficiency as the original approximation. We study HVMs on a\nvariety of deep discrete latent variable models. HVMs generalize other\nexpressive variational distributions and maintains higher fidelity to the\nposterior.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 19:01:48 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 21:16:38 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Ranganath", "Rajesh", ""], ["Tran", "Dustin", ""], ["Blei", "David M.", ""]]}, {"id": "1511.02402", "submitter": "Sepehr Abbasi Zadeh", "authors": "Sepehr Abbasi Zadeh, Mehrdad Ghadiri", "title": "Max-Sum Diversification, Monotone Submodular Functions and Semi-metric\n  Spaces", "comments": "This article draws heavily from arXiv:1203.6397 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications such as web-based search, document summarization,\nfacility location and other applications, the results are preferable to be both\nrepresentative and diversified subsets of documents. The goal of this study is\nto select a good \"quality\", bounded-size subset of a given set of items, while\nmaintaining their diversity relative to a semi-metric distance function. This\nproblem was first studied by Borodin et al\\cite{borodin}, but a crucial\nproperty used throughout their proof is the triangle inequality. In this\nmodified proof, we want to relax the triangle inequality and relate the\napproximation ratio of max-sum diversification problem to the parameter of the\nrelaxed triangle inequality in the normal form of the problem (i.e., a uniform\nmatroid) and also in an arbitrary matroid.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 20:56:51 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Zadeh", "Sepehr Abbasi", ""], ["Ghadiri", "Mehrdad", ""]]}, {"id": "1511.02506", "submitter": "Yi-Hsiu Liao", "authors": "Yi-Hsiu Liao, Hung-yi Lee, Lin-shan Lee", "title": "Towards Structured Deep Neural Network for Automatic Speech Recognition", "comments": "arXiv admin note: text overlap with arXiv:1506.01163", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose the Structured Deep Neural Network (structured DNN)\nas a structured and deep learning framework. This approach can learn to find\nthe best structured object (such as a label sequence) given a structured input\n(such as a vector sequence) by globally considering the mapping relationships\nbetween the structures rather than item by item.\n  When automatic speech recognition is viewed as a special case of such a\nstructured learning problem, where we have the acoustic vector sequence as the\ninput and the phoneme label sequence as the output, it becomes possible to\ncomprehensively learn utterance by utterance as a whole, rather than frame by\nframe.\n  Structured Support Vector Machine (structured SVM) was proposed to perform\nASR with structured learning previously, but limited by the linear nature of\nSVM. Here we propose structured DNN to use nonlinear transformations in\nmulti-layers as a structured and deep learning approach. This approach was\nshown to beat structured SVM in preliminary experiments on TIMIT.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 17:08:54 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Liao", "Yi-Hsiu", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1511.02513", "submitter": "Thomas Steinke", "authors": "Raef Bassily, Kobbi Nissim, Adam Smith, Thomas Steinke, Uri Stemmer,\n  Jonathan Ullman", "title": "Algorithmic Stability for Adaptive Data Analysis", "comments": "This work unifies and subsumes the two arXiv manuscripts\n  arXiv:1503.04843 and arXiv:1504.05800", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptivity is an important feature of data analysis---the choice of questions\nto ask about a dataset often depends on previous interactions with the same\ndataset. However, statistical validity is typically studied in a nonadaptive\nmodel, where all questions are specified before the dataset is drawn. Recent\nwork by Dwork et al. (STOC, 2015) and Hardt and Ullman (FOCS, 2014) initiated\nthe formal study of this problem, and gave the first upper and lower bounds on\nthe achievable generalization error for adaptive data analysis.\n  Specifically, suppose there is an unknown distribution $\\mathbf{P}$ and a set\nof $n$ independent samples $\\mathbf{x}$ is drawn from $\\mathbf{P}$. We seek an\nalgorithm that, given $\\mathbf{x}$ as input, accurately answers a sequence of\nadaptively chosen queries about the unknown distribution $\\mathbf{P}$. How many\nsamples $n$ must we draw from the distribution, as a function of the type of\nqueries, the number of queries, and the desired level of accuracy?\n  In this work we make two new contributions:\n  (i) We give upper bounds on the number of samples $n$ that are needed to\nanswer statistical queries. The bounds improve and simplify the work of Dwork\net al. (STOC, 2015), and have been applied in subsequent work by those authors\n(Science, 2015, NIPS, 2015).\n  (ii) We prove the first upper bounds on the number of samples required to\nanswer more general families of queries. These include arbitrary\nlow-sensitivity queries and an important class of optimization queries.\n  As in Dwork et al., our algorithms are based on a connection with algorithmic\nstability in the form of differential privacy. We extend their work by giving a\nquantitatively optimal, more general, and simpler proof of their main theorem\nthat stability implies low generalization error. We also study weaker stability\nguarantees such as bounded KL divergence and total variation distance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 18:26:50 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Bassily", "Raef", ""], ["Nissim", "Kobbi", ""], ["Smith", "Adam", ""], ["Steinke", "Thomas", ""], ["Stemmer", "Uri", ""], ["Ullman", "Jonathan", ""]]}, {"id": "1511.02540", "submitter": "Pierre-Yves Mass\\'e", "authors": "Pierre-Yves Mass\\'e and Yann Ollivier", "title": "Speed learning on the fly", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical performance of online stochastic gradient descent algorithms is\nhighly dependent on the chosen step size, which must be tediously hand-tuned in\nmany applications. The same is true for more advanced variants of stochastic\ngradients, such as SAGA, SVRG, or AdaGrad. Here we propose to adapt the step\nsize by performing a gradient descent on the step size itself, viewing the\nwhole performance of the learning trajectory as a function of step size.\nImportantly, this adaptation can be computed online at little cost, without\nhaving to iterate backward passes over the full data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 23:15:19 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Mass\u00e9", "Pierre-Yves", ""], ["Ollivier", "Yann", ""]]}, {"id": "1511.02543", "submitter": "Roger Grosse", "authors": "Roger B. Grosse, Zoubin Ghahramani, and Ryan P. Adams", "title": "Sandwiching the marginal likelihood using bidirectional Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the marginal likelihood (ML) of a model requires marginalizing out\nall of the parameters and latent variables, a difficult high-dimensional\nsummation or integration problem. To make matters worse, it is often hard to\nmeasure the accuracy of one's ML estimates. We present bidirectional Monte\nCarlo, a technique for obtaining accurate log-ML estimates on data simulated\nfrom a model. This method obtains stochastic lower bounds on the log-ML using\nannealed importance sampling or sequential Monte Carlo, and obtains stochastic\nupper bounds by running these same algorithms in reverse starting from an exact\nposterior sample. The true value can be sandwiched between these two stochastic\nbounds with high probability. Using the ground truth log-ML estimates obtained\nfrom our method, we quantitatively evaluate a wide variety of existing ML\nestimators on several latent variable models: clustering, a low rank\napproximation, and a binary attributes model. These experiments yield insights\ninto how to accurately estimate marginal likelihoods.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 23:55:36 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Grosse", "Roger B.", ""], ["Ghahramani", "Zoubin", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1511.02554", "submitter": "Hojjat Salehinejad", "authors": "Farhad Pouladi, Hojjat Salehinejad and Amir Mohammad Gilani", "title": "Deep Recurrent Neural Networks for Sequential Phenotype Prediction in\n  Genomics", "comments": "The articles is accepted at DeSE 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In analyzing of modern biological data, we are often dealing with ill-posed\nproblems and missing data, mostly due to high dimensionality and\nmulticollinearity of the dataset. In this paper, we have proposed a system\nbased on matrix factorization (MF) and deep recurrent neural networks (DRNNs)\nfor genotype imputation and phenotype sequences prediction. In order to model\nthe long-term dependencies of phenotype data, the new Recurrent Linear Units\n(ReLU) learning strategy is utilized for the first time. The proposed model is\nimplemented for parallel processing on central processing units (CPUs) and\ngraphic processing units (GPUs). Performance of the proposed model is compared\nwith other training algorithms for learning long-term dependencies as well as\nthe sparse partial least square (SPLS) method on a set of genotype and\nphenotype data with 604 samples, 1980 single-nucleotide polymorphisms (SNPs),\nand two traits. The results demonstrate performance of the ReLU training\nalgorithm in learning long-term dependencies in RNNs.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 02:11:00 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 20:48:34 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2016 03:30:10 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Pouladi", "Farhad", ""], ["Salehinejad", "Hojjat", ""], ["Gilani", "Amir Mohammad", ""]]}, {"id": "1511.02580", "submitter": "Zhouhan Lin", "authors": "Zhouhan Lin, Roland Memisevic, Kishore Konda", "title": "How far can we go without convolution: Improving fully-connected\n  networks", "comments": "10 pages, 11 figures, submitted for ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose ways to improve the performance of fully connected networks. We\nfound that two approaches in particular have a strong effect on performance:\nlinear bottleneck layers and unsupervised pre-training using autoencoders\nwithout hidden unit biases. We show how both approaches can be related to\nimproving gradient flow and reducing sparsity in the network. We show that a\nfully connected network can yield approximately 70% classification accuracy on\nthe permutation-invariant CIFAR-10 task, which is much higher than the current\nstate-of-the-art. By adding deformations to the training data, the fully\nconnected network achieves 78% accuracy, which is just 10% short of a decent\nconvolutional network.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 06:56:24 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Lin", "Zhouhan", ""], ["Memisevic", "Roland", ""], ["Konda", "Kishore", ""]]}, {"id": "1511.02583", "submitter": "Yong-Sheng Chen", "authors": "Jia-Ren Chang and Yong-Sheng Chen", "title": "Batch-normalized Maxout Network in Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports a novel deep architecture referred to as Maxout network In\nNetwork (MIN), which can enhance model discriminability and facilitate the\nprocess of information abstraction within the receptive field. The proposed\nnetwork adopts the framework of the recently developed Network In Network\nstructure, which slides a universal approximator, multilayer perceptron (MLP)\nwith rectifier units, to exact features. Instead of MLP, we employ maxout MLP\nto learn a variety of piecewise linear activation functions and to mediate the\nproblem of vanishing gradients that can occur when using rectifier units.\nMoreover, batch normalization is applied to reduce the saturation of maxout\nunits by pre-conditioning the model and dropout is applied to prevent\noverfitting. Finally, average pooling is used in all pooling layers to\nregularize maxout MLP in order to facilitate information abstraction in every\nreceptive field while tolerating the change of object position. Because average\npooling preserves all features in the local patch, the proposed MIN model can\nenforce the suppression of irrelevant information during training. Our\nexperiments demonstrated the state-of-the-art classification performance when\nthe MIN model was applied to MNIST, CIFAR-10, and CIFAR-100 datasets and\ncomparable performance for SVHN dataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 07:09:57 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Chang", "Jia-Ren", ""], ["Chen", "Yong-Sheng", ""]]}, {"id": "1511.02595", "submitter": "Cong Xie", "authors": "Cong Xie, Wu-Jun Li and Zhihua Zhang", "title": "A New Relaxation Approach to Normalized Hypergraph Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalized graph cut (NGC) has become a popular research topic due to its\nwide applications in a large variety of areas like machine learning and very\nlarge scale integration (VLSI) circuit design. Most of traditional NGC methods\nare based on pairwise relationships (similarities). However, in real-world\napplications relationships among the vertices (objects) may be more complex\nthan pairwise, which are typically represented as hyperedges in hypergraphs.\nThus, normalized hypergraph cut (NHC) has attracted more and more attention.\nExisting NHC methods cannot achieve satisfactory performance in real\napplications. In this paper, we propose a novel relaxation approach, which is\ncalled relaxed NHC (RNHC), to solve the NHC problem. Our model is defined as an\noptimization problem on the Stiefel manifold. To solve this problem, we resort\nto the Cayley transformation to devise a feasible learning algorithm.\nExperimental results on a set of large hypergraph benchmarks for clustering and\npartitioning in VLSI domain show that RNHC can outperform the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 08:30:03 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Xie", "Cong", ""], ["Li", "Wu-Jun", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1511.02619", "submitter": "Wei Ping", "authors": "Wei Ping, Qiang Liu, Alexander Ihler", "title": "Decomposition Bounds for Marginal MAP", "comments": "NIPS 2015 (full-length)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marginal MAP inference involves making MAP predictions in systems defined\nwith latent variables or missing information. It is significantly more\ndifficult than pure marginalization and MAP tasks, for which a large class of\nefficient and convergent variational algorithms, such as dual decomposition,\nexist. In this work, we generalize dual decomposition to a generic power sum\ninference task, which includes marginal MAP, along with pure marginalization\nand MAP, as special cases. Our method is based on a block coordinate descent\nalgorithm on a new convex decomposition bound, that is guaranteed to converge\nmonotonically, and can be parallelized efficiently. We demonstrate our approach\non marginal MAP queries defined on real-world problems from the UAI approximate\ninference challenge, showing that our framework is faster and more reliable\nthan previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 10:21:39 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Ping", "Wei", ""], ["Liu", "Qiang", ""], ["Ihler", "Alexander", ""]]}, {"id": "1511.02793", "submitter": "Elman Mansimov", "authors": "Elman Mansimov, Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov", "title": "Generating Images from Captions with Attention", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent progress in generative models, we introduce a model\nthat generates images from natural language descriptions. The proposed model\niteratively draws patches on a canvas, while attending to the relevant words in\nthe description. After training on Microsoft COCO, we compare our model with\nseveral baseline generative models on image generation and retrieval tasks. We\ndemonstrate that our model produces higher quality samples than other\napproaches and generates images with novel scene compositions corresponding to\npreviously unseen captions in the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 18:18:53 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 17:56:29 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Mansimov", "Elman", ""], ["Parisotto", "Emilio", ""], ["Ba", "Jimmy Lei", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1511.02799", "submitter": "Jacob Andreas", "authors": "Jacob Andreas, Marcus Rohrbach, Trevor Darrell, Dan Klein", "title": "Neural Module Networks", "comments": "Corrects an error in the evaluation of the NMN-only ablation\n  experiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual question answering is fundamentally compositional in nature---a\nquestion like \"where is the dog?\" shares substructure with questions like \"what\ncolor is the dog?\" and \"where is the cat?\" This paper seeks to simultaneously\nexploit the representational capacity of deep networks and the compositional\nlinguistic structure of questions. We describe a procedure for constructing and\nlearning *neural module networks*, which compose collections of jointly-trained\nneural \"modules\" into deep networks for question answering. Our approach\ndecomposes questions into their linguistic substructures, and uses these\nstructures to dynamically instantiate modular networks (with reusable\ncomponents for recognizing dogs, classifying colors, etc.). The resulting\ncompound networks are jointly trained. We evaluate our approach on two\nchallenging datasets for visual question answering, achieving state-of-the-art\nresults on both the VQA natural image dataset and a new dataset of complex\nquestions about abstract shapes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 18:48:39 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 06:36:22 GMT"}, {"version": "v3", "created": "Wed, 1 Jun 2016 18:26:40 GMT"}, {"version": "v4", "created": "Mon, 24 Jul 2017 17:15:06 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Andreas", "Jacob", ""], ["Rohrbach", "Marcus", ""], ["Darrell", "Trevor", ""], ["Klein", "Dan", ""]]}, {"id": "1511.02825", "submitter": "Changzhe Jiao", "authors": "Changzhe Jiao, Alina Zare", "title": "Multiple Instance Dictionary Learning using Functions of Multiple\n  Instances", "comments": "Final submission to ICPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multiple instance dictionary learning method using functions of multiple\ninstances (DL-FUMI) is proposed to address target detection and two-class\nclassification problems with inaccurate training labels. Given inaccurate\ntraining labels, DL-FUMI learns a set of target dictionary atoms that describe\nthe most distinctive and representative features of the true positive class as\nwell as a set of nontarget dictionary atoms that account for the shared\ninformation found in both the positive and negative instances. Experimental\nresults show that the estimated target dictionary atoms found by DL-FUMI are\nmore representative prototypes and identify better discriminative features of\nthe true positive class than existing methods in the literature. DL-FUMI is\nshown to have significantly better performance on several target detection and\nclassification problems as compared to other multiple instance learning (MIL)\ndictionary learning algorithms on a variety of MIL problems.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 20:12:19 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 21:31:50 GMT"}, {"version": "v3", "created": "Wed, 3 Aug 2016 21:03:51 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Jiao", "Changzhe", ""], ["Zare", "Alina", ""]]}, {"id": "1511.02841", "submitter": "Galin Georgiev", "authors": "Galin Georgiev", "title": "Symmetries and control in generative neural nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generative nets which can control and modify observations, after\nbeing trained on real-life datasets. In order to zoom-in on an object, some\nspatial, color and other attributes are learned by classifiers in specialized\nattention nets. In field-theoretical terms, these learned symmetry statistics\nform the gauge group of the data set. Plugging them in the generative layers of\nauto-classifiers-encoders (ACE) appears to be the most direct way to\nsimultaneously: i) generate new observations with arbitrary attributes, from a\ngiven class, ii) describe the low-dimensional manifold encoding the \"essence\"\nof the data, after superfluous attributes are factored out, and iii)\norganically control, i.e., move or modify objects within given observations. We\ndemonstrate the sharp improvement of the generative qualities of shallow ACE,\nwith added spatial and color symmetry statistics, on the distorted MNIST and\nCIFAR10 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 20:49:03 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 17:49:51 GMT"}, {"version": "v3", "created": "Fri, 8 Apr 2016 21:38:31 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Georgiev", "Galin", ""]]}, {"id": "1511.02872", "submitter": "Hiroharu Kato", "authors": "Hiroharu Kato and Tatsuya Harada", "title": "Visual Language Modeling on CNN Image Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the naturalness of images is important to generate realistic images\nor to detect unnatural regions in images. Additionally, a method to measure\nnaturalness can be complementary to Convolutional Neural Network (CNN) based\nfeatures, which are known to be insensitive to the naturalness of images.\nHowever, most probabilistic image models have insufficient capability of\nmodeling the complex and abstract naturalness that we feel because they are\nbuilt directly on raw image pixels. In this work, we assume that naturalness\ncan be measured by the predictability on high-level features during eye\nmovement. Based on this assumption, we propose a novel method to evaluate the\nnaturalness by building a variant of Recurrent Neural Network Language Models\non pre-trained CNN representations. Our method is applied to two tasks,\ndemonstrating that 1) using our method as a regularizer enables us to generate\nmore understandable images from image features than existing approaches, and 2)\nunnaturalness maps produced by our method achieve state-of-the-art eye fixation\nprediction performance on two well-studied datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 21:00:08 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Kato", "Hiroharu", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1511.02900", "submitter": "Nipun Batra", "authors": "Nipun Batra and Amarjeet Singh and Kamin Whitehouse", "title": "Neighbourhood NILM: A Big-data Approach to Household Energy\n  Disaggregation", "comments": "Under submission to IPSN 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate whether \"big-data\" is more valuable than\n\"precise\" data for the problem of energy disaggregation: the process of\nbreaking down aggregate energy usage on a per-appliance basis. Existing\ntechniques for disaggregation rely on energy metering at a resolution of 1\nminute or higher, but most power meters today only provide a reading once per\nmonth, and at most once every 15 minutes. In this paper, we propose a new\ntechnique called Neighbourhood NILM that leverages data from 'neighbouring'\nhomes to disaggregate energy given only a single energy reading per month. The\nkey intuition behind our approach is that 'similar' homes have 'similar' energy\nconsumption on a per-appliance basis. Neighbourhood NILM matches every home\nwith a set of 'neighbours' that have direct submetering infrastructure, i.e.\npower meters on individual circuits or loads. Many such homes already exist.\nThen, it estimates the appliance-level energy consumption of the target home to\nbe the average of its K neighbours. We evaluate this approach using 25 homes\nand results show that our approach gives comparable or better disaggregation in\ncomparison to state-of-the-art accuracy reported in the literature that depend\non manual model training, high frequency power metering, or both. Results show\nthat Neighbourhood NILM can achieve 83% and 79% accuracy disaggregating fridge\nand heating/cooling loads, compared to 74% and 73% for a technique called FHMM.\nFurthermore, it achieves up to 64% accuracy on washing machine, dryer,\ndishwasher, and lighting loads, which is higher than previously reported\nresults. Many existing techniques are not able to disaggregate these loads at\nall. These results indicate a potentially substantial advantage to installing\nsubmetering infrastructure in a select few homes rather than installing new\nhigh-frequency smart metering infrastructure in all homes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2015 07:22:01 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Batra", "Nipun", ""], ["Singh", "Amarjeet", ""], ["Whitehouse", "Kamin", ""]]}, {"id": "1511.02909", "submitter": "Azam Moosavi", "authors": "Azam Moosavi and Razvan Stefanescu and Adrian Sandu", "title": "Efficient Construction of Local Parametric Reduced Order Models Using\n  Machine Learning Techniques", "comments": "28 pages, 15 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced order models are computationally inexpensive approximations that\ncapture the important dynamical characteristics of large, high-fidelity\ncomputer models of physical systems. This paper applies machine learning\ntechniques to improve the design of parametric reduced order models.\nSpecifically, machine learning is used to develop feasible regions in the\nparameter space where the admissible target accuracy is achieved with a\npredefined reduced order basis, to construct parametric maps, to chose the best\ntwo already existing bases for a new parameter configuration from accuracy\npoint of view and to pre-select the optimal dimension of the reduced basis such\nas to meet the desired accuracy. By combining available information using bases\nconcatenation and interpolation as well as high-fidelity solutions\ninterpolation we are able to build accurate reduced order models associated\nwith new parameter settings. Promising numerical results with a viscous Burgers\nmodel illustrate the potential of machine learning approaches to help design\nbetter reduced order models.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 22:12:14 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Moosavi", "Azam", ""], ["Stefanescu", "Razvan", ""], ["Sandu", "Adrian", ""]]}, {"id": "1511.02916", "submitter": "Zhouhan Lin", "authors": "Zhouhan Lin, Yushi Chen, Xing Zhao, Gang Wang", "title": "Spectral-Spatial Classification of Hyperspectral Image Using\n  Autoencoders", "comments": "Accepted as a conference paper at ICICS 2013, an updated version.\n  Codes published. 9 pages, 6 figures", "journal-ref": null, "doi": "10.1109/ICICS.2013.6782778", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral image (HSI) classification is a hot topic in the remote sensing\ncommunity. This paper proposes a new framework of spectral-spatial feature\nextraction for HSI classification, in which for the first time the concept of\ndeep learning is introduced. Specifically, the model of autoencoder is\nexploited in our framework to extract various kinds of features. First we\nverify the eligibility of autoencoder by following classical spectral\ninformation based classification and use autoencoders with different depth to\nclassify hyperspectral image. Further in the proposed framework, we combine PCA\non spectral dimension and autoencoder on the other two spatial dimensions to\nextract spectral-spatial information for classification. The experimental\nresults show that this framework achieves the highest classification accuracy\namong all methods, and outperforms classical classifiers such as SVM and\nPCA-based SVM.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 22:29:13 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Lin", "Zhouhan", ""], ["Chen", "Yushi", ""], ["Zhao", "Xing", ""], ["Wang", "Gang", ""]]}, {"id": "1511.02954", "submitter": "Conrado Miranda", "authors": "Conrado S. Miranda and Fernando J. Von Zuben", "title": "Reducing the Training Time of Neural Networks by Partitioning", "comments": "Figure 2b has lower quality due to file size constraints", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new method for pre-training neural networks that can\ndecrease the total training time for a neural network while maintaining the\nfinal performance, which motivates its use on deep neural networks. By\npartitioning the training task in multiple training subtasks with sub-models,\nwhich can be performed independently and in parallel, it is shown that the size\nof the sub-models reduces almost quadratically with the number of subtasks\ncreated, quickly scaling down the sub-models used for the pre-training. The\nsub-models are then merged to provide a pre-trained initial set of weights for\nthe original model. The proposed method is independent of the other aspects of\nthe training, such as architecture of the neural network, training method, and\nobjective, making it compatible with a wide range of existing approaches. The\nspeedup without loss of performance is validated experimentally on MNIST and on\nCIFAR10 data sets, also showing that even performing the subtasks sequentially\ncan decrease the training time. Moreover, we show that larger models may\npresent higher speedups and conjecture about the benefits of the method in\ndistributed learning systems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 01:20:51 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2016 17:18:06 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Miranda", "Conrado S.", ""], ["Von Zuben", "Fernando J.", ""]]}, {"id": "1511.03034", "submitter": "Ruitong Huang", "authors": "Ruitong Huang, Bing Xu, Dale Schuurmans, Csaba Szepesvari", "title": "Learning with a Strong Adversary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of neural networks to intended perturbations has recently\nattracted significant attention. In this paper, we propose a new method,\n\\emph{learning with a strong adversary}, that learns robust classifiers from\nsupervised data. The proposed method takes finding adversarial examples as an\nintermediate step. A new and simple way of finding adversarial examples is\npresented and experimentally shown to be efficient. Experimental results\ndemonstrate that resulting learning method greatly improves the robustness of\nthe classification models produced.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 09:44:33 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 21:19:21 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2015 19:56:40 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2016 07:34:40 GMT"}, {"version": "v5", "created": "Thu, 7 Jan 2016 05:47:33 GMT"}, {"version": "v6", "created": "Sat, 16 Jan 2016 01:44:18 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Huang", "Ruitong", ""], ["Xu", "Bing", ""], ["Schuurmans", "Dale", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1511.03055", "submitter": "Olivier Mor\\`ere", "authors": "Jie Lin, Olivier Mor\\`ere, Julie Petta, Vijay Chandrasekhar, Antoine\n  Veillard", "title": "Tiny Descriptors for Image Retrieval with Unsupervised Triplet Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical image retrieval pipeline starts with the comparison of global\ndescriptors from a large database to find a short list of candidate matches. A\ngood image descriptor is key to the retrieval pipeline and should reconcile two\ncontradictory requirements: providing recall rates as high as possible and\nbeing as compact as possible for fast matching. Following the recent successes\nof Deep Convolutional Neural Networks (DCNN) for large scale image\nclassification, descriptors extracted from DCNNs are increasingly used in place\nof the traditional hand crafted descriptors such as Fisher Vectors (FV) with\nbetter retrieval performances. Nevertheless, the dimensionality of a typical\nDCNN descriptor --extracted either from the visual feature pyramid or the\nfully-connected layers-- remains quite high at several thousands of scalar\nvalues. In this paper, we propose Unsupervised Triplet Hashing (UTH), a fully\nunsupervised method to compute extremely compact binary hashes --in the 32-256\nbits range-- from high-dimensional global descriptors. UTH consists of two\nsuccessive deep learning steps. First, Stacked Restricted Boltzmann Machines\n(SRBM), a type of unsupervised deep neural nets, are used to learn binary\nembedding functions able to bring the descriptor size down to the desired\nbitrate. SRBMs are typically able to ensure a very high compression rate at the\nexpense of loosing some desirable metric properties of the original DCNN\ndescriptor space. Then, triplet networks, a rank learning scheme based on\nweight sharing nets is used to fine-tune the binary embedding functions to\nretain as much as possible of the useful metric properties of the original\nspace. A thorough empirical evaluation conducted on multiple publicly available\ndataset using DCNN descriptors shows that our method is able to significantly\noutperform state-of-the-art unsupervised schemes in the target bit range.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 10:38:37 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Lin", "Jie", ""], ["Mor\u00e8re", "Olivier", ""], ["Petta", "Julie", ""], ["Chandrasekhar", "Vijay", ""], ["Veillard", "Antoine", ""]]}, {"id": "1511.03086", "submitter": "Oliver Schulte", "authors": "Jan Motl and Oliver Schulte", "title": "The CTU Prague Relational Learning Repository", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the CTU Prague Relational Learning Repository is to support\nmachine learning research with multi-relational data. The repository currently\ncontains 50 SQL databases hosted on a public MySQL server located at\nrelational.fit.cvut.cz. A searchable meta-database provides metadata (e.g., the\nnumber of tables in the database, the number of rows and columns in the tables,\nthe number of foreign key constraints between tables).\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 12:30:42 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Motl", "Jan", ""], ["Schulte", "Oliver", ""]]}, {"id": "1511.03163", "submitter": "Vincenzo Lomonaco", "authors": "Davide Maltoni and Vincenzo Lomonaco", "title": "Semi-supervised Tuning from Temporal Coherence", "comments": "Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works demonstrated the usefulness of temporal coherence to regularize\nsupervised training or to learn invariant features with deep architectures. In\nparticular, enforcing smooth output changes while presenting temporally-closed\nframes from video sequences, proved to be an effective strategy. In this paper\nwe prove the efficacy of temporal coherence for semi-supervised incremental\ntuning. We show that a deep architecture, just mildly trained in a supervised\nmanner, can progressively improve its classification accuracy, if exposed to\nvideo sequences of unlabeled data. The extent to which, in some cases, a\nsemi-supervised tuning allows to improve classification accuracy (approaching\nthe supervised one) is somewhat surprising. A number of control experiments\npointed out the fundamental role of temporal coherence.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 16:14:23 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 13:45:07 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2016 15:54:36 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Maltoni", "Davide", ""], ["Lomonaco", "Vincenzo", ""]]}, {"id": "1511.03198", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Yang Zou, and Gustavo K. Rohde", "title": "Sliced Wasserstein Kernels for Probability Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport distances, otherwise known as Wasserstein distances, have\nrecently drawn ample attention in computer vision and machine learning as a\npowerful discrepancy measure for probability distributions. The recent\ndevelopments on alternative formulations of the optimal transport have allowed\nfor faster solutions to the problem and has revamped its practical applications\nin machine learning. In this paper, we exploit the widely used kernel methods\nand provide a family of provably positive definite kernels based on the Sliced\nWasserstein distance and demonstrate the benefits of these kernels in a variety\nof learning tasks. Our work provides a new perspective on the application of\noptimal transport flavored distances through kernel methods in machine learning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 17:41:48 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Kolouri", "Soheil", ""], ["Zou", "Yang", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1511.03225", "submitter": "Travis Dick", "authors": "Maria Florina Balcan, Travis Dick, Yishay Mansour", "title": "Label Efficient Learning by Exploiting Multi-class Output Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new perspective on the popular multi-class algorithmic\ntechniques of one-vs-all and error correcting output codes. Rather than\nstudying the behavior of these techniques for supervised learning, we establish\na connection between the success of these methods and the existence of\nlabel-efficient learning procedures. We show that in both the realizable and\nagnostic cases, if output codes are successful at learning from labeled data,\nthey implicitly assume structure on how the classes are related. By making that\nstructure explicit, we design learning algorithms to recover the classes with\nlow label complexity. We provide results for the commonly studied cases of\none-vs-all learning and when the codewords of the classes are well separated.\nWe additionally consider the more challenging case where the codewords are not\nwell separated, but satisfy a boundary features condition that captures the\nnatural intuition that every bit of the codewords should be significant.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 18:50:03 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 02:24:20 GMT"}, {"version": "v3", "created": "Fri, 29 Jul 2016 03:58:08 GMT"}, {"version": "v4", "created": "Fri, 25 Nov 2016 15:52:08 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Balcan", "Maria Florina", ""], ["Dick", "Travis", ""], ["Mansour", "Yishay", ""]]}, {"id": "1511.03229", "submitter": "Aravindan Vijayaraghavan", "authors": "Konstantin Makarychev, Yury Makarychev and Aravindan Vijayaraghavan", "title": "Learning Communities in the Presence of Errors", "comments": "34 pages. Appearing in the Conference on Learning Theory (COLT)'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning communities in the presence of modeling\nerrors and give robust recovery algorithms for the Stochastic Block Model\n(SBM). This model, which is also known as the Planted Partition Model, is\nwidely used for community detection and graph partitioning in various fields,\nincluding machine learning, statistics, and social sciences. Many algorithms\nexist for learning communities in the Stochastic Block Model, but they do not\nwork well in the presence of errors.\n  In this paper, we initiate the study of robust algorithms for partial\nrecovery in SBM with modeling errors or noise. We consider graphs generated\naccording to the Stochastic Block Model and then modified by an adversary. We\nallow two types of adversarial errors, Feige---Kilian or monotone errors, and\nedge outlier errors. Mossel, Neeman and Sly (STOC 2015) posed an open question\nabout whether an almost exact recovery is possible when the adversary is\nallowed to add $o(n)$ edges. Our work answers this question affirmatively even\nin the case of $k>2$ communities.\n  We then show that our algorithms work not only when the instances come from\nSBM, but also work when the instances come from any distribution of graphs that\nis $\\epsilon m$ close to SBM in the Kullback---Leibler divergence. This result\nalso works in the presence of adversarial errors. Finally, we present almost\ntight lower bounds for two communities.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 19:03:47 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 18:51:52 GMT"}, {"version": "v3", "created": "Fri, 24 Jun 2016 04:02:00 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Makarychev", "Konstantin", ""], ["Makarychev", "Yury", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1511.03260", "submitter": "Paul Mineiro", "authors": "Paul Mineiro and Nikos Karampatziakis", "title": "A Hierarchical Spectral Method for Extreme Classification", "comments": "Reference implementation available at\n  https://github.com/pmineiro/xlst", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme classification problems are multiclass and multilabel classification\nproblems where the number of outputs is so large that straightforward\nstrategies are neither statistically nor computationally viable. One strategy\nfor dealing with the computational burden is via a tree decomposition of the\noutput space. While this typically leads to training and inference that scales\nsublinearly with the number of outputs, it also results in reduced statistical\nperformance. In this work, we identify two shortcomings of tree decomposition\nmethods, and describe two heuristic mitigations. We compose these with an\neigenvalue technique for constructing the tree. The end result is a\ncomputationally efficient algorithm that provides good statistical performance\non several extreme data sets.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 20:52:52 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 21:40:58 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 17:26:46 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2016 01:07:10 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Mineiro", "Paul", ""], ["Karampatziakis", "Nikos", ""]]}, {"id": "1511.03299", "submitter": "Yoni Halpern", "authors": "Yoni Halpern and Steven Horng and David Sontag", "title": "Anchored Discrete Factor Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semi-supervised learning algorithm for learning discrete factor\nanalysis models with arbitrary structure on the latent variables. Our algorithm\nassumes that every latent variable has an \"anchor\", an observed variable with\nonly that latent variable as its parent. Given such anchors, we show that it is\npossible to consistently recover moments of the latent variables and use these\nmoments to learn complete models. We also introduce a new technique for\nimproving the robustness of method-of-moment algorithms by optimizing over the\nmarginal polytope or its relaxations. We evaluate our algorithm using two\nreal-world tasks, tag prediction on questions from the Stack Overflow website\nand medical diagnosis in an emergency department.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 21:40:05 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Halpern", "Yoni", ""], ["Horng", "Steven", ""], ["Sontag", "David", ""]]}, {"id": "1511.03416", "submitter": "Yuke Zhu", "authors": "Yuke Zhu, Oliver Groth, Michael Bernstein and Li Fei-Fei", "title": "Visual7W: Grounded Question Answering in Images", "comments": "CVPR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have seen great progress in basic perceptual tasks such as object\nrecognition and detection. However, AI models still fail to match humans in\nhigh-level vision tasks due to the lack of capacities for deeper reasoning.\nRecently the new task of visual question answering (QA) has been proposed to\nevaluate a model's capacity for deep image understanding. Previous works have\nestablished a loose, global association between QA sentences and images.\nHowever, many questions and answers, in practice, relate to local regions in\nthe images. We establish a semantic link between textual descriptions and image\nregions by object-level grounding. It enables a new type of QA with visual\nanswers, in addition to textual answers used in previous work. We study the\nvisual QA tasks in a grounded setting with a large collection of 7W\nmultiple-choice QA pairs. Furthermore, we evaluate human performance and\nseveral baseline models on the QA tasks. Finally, we propose a novel LSTM model\nwith spatial attention to tackle the 7W QA tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 08:29:14 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 21:53:55 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2015 19:37:20 GMT"}, {"version": "v4", "created": "Sat, 9 Apr 2016 07:18:10 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Zhu", "Yuke", ""], ["Groth", "Oliver", ""], ["Bernstein", "Michael", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1511.03546", "submitter": "Guorui Zhou", "authors": "Guorui Zhou, Guang Chen", "title": "Hierarchical Latent Semantic Mapping for Automated Topic Generation", "comments": "9 pages, 3 figures, Under Review as a conference at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of information sits in an unprecedented amount of text data. Managing\nallocation of these large scale text data is an important problem for many\nareas. Topic modeling performs well in this problem. The traditional generative\nmodels (PLSA,LDA) are the state-of-the-art approaches in topic modeling and\nmost recent research on topic generation has been focusing on improving or\nextending these models. However, results of traditional generative models are\nsensitive to the number of topics K, which must be specified manually. The\nproblem of generating topics from corpus resembles community detection in\nnetworks. Many effective algorithms can automatically detect communities from\nnetworks without a manually specified number of the communities. Inspired by\nthese algorithms, in this paper, we propose a novel method named Hierarchical\nLatent Semantic Mapping (HLSM), which automatically generates topics from\ncorpus. HLSM calculates the association between each pair of words in the\nlatent topic space, then constructs a unipartite network of words with this\nassociation and hierarchically generates topics from this network. We apply\nHLSM to several document collections and the experimental comparisons against\nseveral state-of-the-art approaches demonstrate the promising performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 15:58:30 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 13:47:53 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2015 05:23:58 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2015 01:35:58 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Zhou", "Guorui", ""], ["Chen", "Guang", ""]]}, {"id": "1511.03575", "submitter": "Jakub Kone\\v{c}n\\'y", "authors": "Jakub Kone\\v{c}n\\'y, Brendan McMahan, Daniel Ramage", "title": "Federated Optimization:Distributed Optimization Beyond the Datacenter", "comments": "NIPS workshop version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new and increasingly relevant setting for distributed\noptimization in machine learning, where the data defining the optimization are\ndistributed (unevenly) over an extremely large number of \\nodes, but the goal\nremains to train a high-quality centralized model. We refer to this setting as\nFederated Optimization. In this setting, communication efficiency is of utmost\nimportance.\n  A motivating example for federated optimization arises when we keep the\ntraining data locally on users' mobile devices rather than logging it to a data\ncenter for training. Instead, the mobile devices are used as nodes performing\ncomputation on their local data in order to update a global model. We suppose\nthat we have an extremely large number of devices in our network, each of which\nhas only a tiny fraction of data available totally; in particular, we expect\nthe number of data points available locally to be much smaller than the number\nof devices. Additionally, since different users generate data with different\npatterns, we assume that no device has a representative sample of the overall\ndistribution.\n  We show that existing algorithms are not suitable for this setting, and\npropose a new algorithm which shows encouraging experimental results. This work\nalso sets a path for future research needed in the context of federated\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 17:06:16 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Kone\u010dn\u00fd", "Jakub", ""], ["McMahan", "Brendan", ""], ["Ramage", "Daniel", ""]]}, {"id": "1511.03576", "submitter": "Mohammad Khabbaz", "authors": "Mohammad Khabbaz", "title": "DataGrinder: Fast, Accurate, Fully non-Parametric Classification\n  Approach Using 2D Convex Hulls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been a long time, since data mining technologies have made their ways\nto the field of data management. Classification is one of the most important\ndata mining tasks for label prediction, categorization of objects into groups,\nadvertisement and data management. In this paper, we focus on the standard\nclassification problem which is predicting unknown labels in Euclidean space.\nMost efforts in Machine Learning communities are devoted to methods that use\nprobabilistic algorithms which are heavy on Calculus and Linear Algebra. Most\nof these techniques have scalability issues for big data, and are hardly\nparallelizable if they are to maintain their high accuracies in their standard\nform. Sampling is a new direction for improving scalability, using many small\nparallel classifiers. In this paper, rather than conventional sampling methods,\nwe focus on a discrete classification algorithm with O(n) expected running\ntime. Our approach performs a similar task as sampling methods. However, we use\ncolumn-wise sampling of data, rather than the row-wise sampling used in the\nliterature. In either case, our algorithm is completely deterministic. Our\nalgorithm, proposes a way of combining 2D convex hulls in order to achieve high\nclassification accuracy as well as scalability in the same time. First, we\nthoroughly describe and prove our O(n) algorithm for finding the convex hull of\na point set in 2D. Then, we show with experiments our classifier model built\nbased on this idea is very competitive compared with existing sophisticated\nclassification algorithms included in commercial statistical applications such\nas MATLAB.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 17:06:35 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Khabbaz", "Mohammad", ""]]}, {"id": "1511.03592", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart", "title": "The Fourier Transform of Poisson Multinomial Distributions and its\n  Algorithmic Applications", "comments": "68 pages, full version of STOC 2016 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.GT cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $(n, k)$-Poisson Multinomial Distribution (PMD) is a random variable of\nthe form $X = \\sum_{i=1}^n X_i$, where the $X_i$'s are independent random\nvectors supported on the set of standard basis vectors in $\\mathbb{R}^k.$ In\nthis paper, we obtain a refined structural understanding of PMDs by analyzing\ntheir Fourier transform. As our core structural result, we prove that the\nFourier transform of PMDs is {\\em approximately sparse}, i.e., roughly\nspeaking, its $L_1$-norm is small outside a small set. By building on this\nresult, we obtain the following applications:\n  {\\bf Learning Theory.} We design the first computationally efficient learning\nalgorithm for PMDs with respect to the total variation distance. Our algorithm\nlearns an arbitrary $(n, k)$-PMD within variation distance $\\epsilon$ using a\nnear-optimal sample size of $\\widetilde{O}_k(1/\\epsilon^2),$ and runs in time\n$\\widetilde{O}_k(1/\\epsilon^2) \\cdot \\log n.$ Previously, no algorithm with a\n$\\mathrm{poly}(1/\\epsilon)$ runtime was known, even for $k=3.$\n  {\\bf Game Theory.} We give the first efficient polynomial-time approximation\nscheme (EPTAS) for computing Nash equilibria in anonymous games. For normalized\nanonymous games with $n$ players and $k$ strategies, our algorithm computes a\nwell-supported $\\epsilon$-Nash equilibrium in time $n^{O(k^3)} \\cdot\n(k/\\epsilon)^{O(k^3\\log(k/\\epsilon)/\\log\\log(k/\\epsilon))^{k-1}}.$ The best\nprevious algorithm for this problem had running time $n^{(f(k)/\\epsilon)^k},$\nwhere $f(k) = \\Omega(k^{k^2})$, for any $k>2.$\n  {\\bf Statistics.} We prove a multivariate central limit theorem (CLT) that\nrelates an arbitrary PMD to a discretized multivariate Gaussian with the same\nmean and covariance, in total variation distance. Our new CLT strengthens the\nCLT of Valiant and Valiant by completely removing the dependence on $n$ in the\nerror bound.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 18:00:37 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 19:42:04 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1511.03641", "submitter": "Gautam Kamath", "authors": "Constantinos Daskalakis, Anindya De, Gautam Kamath, Christos Tzamos", "title": "A Size-Free CLT for Poisson Multinomials and its Applications", "comments": "To appear in STOC 2016", "journal-ref": null, "doi": "10.1145/2897518.2897519", "report-no": null, "categories": "cs.DS cs.GT cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $(n,k)$-Poisson Multinomial Distribution (PMD) is the distribution of the\nsum of $n$ independent random vectors supported on the set ${\\cal\nB}_k=\\{e_1,\\ldots,e_k\\}$ of standard basis vectors in $\\mathbb{R}^k$. We show\nthat any $(n,k)$-PMD is ${\\rm poly}\\left({k\\over \\sigma}\\right)$-close in total\nvariation distance to the (appropriately discretized) multi-dimensional\nGaussian with the same first two moments, removing the dependence on $n$ from\nthe Central Limit Theorem of Valiant and Valiant. Interestingly, our CLT is\nobtained by bootstrapping the Valiant-Valiant CLT itself through the structural\ncharacterization of PMDs shown in recent work by Daskalakis, Kamath, and\nTzamos. In turn, our stronger CLT can be leveraged to obtain an efficient PTAS\nfor approximate Nash equilibria in anonymous games, significantly improving the\nstate of the art, and matching qualitatively the running time dependence on $n$\nand $1/\\varepsilon$ of the best known algorithm for two-strategy anonymous\ngames. Our new CLT also enables the construction of covers for the set of\n$(n,k)$-PMDs, which are proper and whose size is shown to be essentially\noptimal. Our cover construction combines our CLT with the Shapley-Folkman\ntheorem and recent sparsification results for Laplacian matrices by Batson,\nSpielman, and Srivastava. Our cover size lower bound is based on an algebraic\ngeometric construction. Finally, leveraging the structural properties of the\nFourier spectrum of PMDs we show that these distributions can be learned from\n$O_k(1/\\varepsilon^2)$ samples in ${\\rm poly}_k(1/\\varepsilon)$-time, removing\nthe quasi-polynomial dependence of the running time on $1/\\varepsilon$ from the\nalgorithm of Daskalakis, Kamath, and Tzamos.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 20:27:33 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 05:02:43 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["De", "Anindya", ""], ["Kamath", "Gautam", ""], ["Tzamos", "Christos", ""]]}, {"id": "1511.03643", "submitter": "David Lopez-Paz", "authors": "David Lopez-Paz, L\\'eon Bottou, Bernhard Sch\\\"olkopf, Vladimir Vapnik", "title": "Unifying distillation and privileged information", "comments": null, "journal-ref": "Proceedings of the International Conference on Learning\n  Representations (2016) 1-10", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distillation (Hinton et al., 2015) and privileged information (Vapnik &\nIzmailov, 2015) are two techniques that enable machines to learn from other\nmachines. This paper unifies these two techniques into generalized\ndistillation, a framework to learn from multiple machines and data\nrepresentations. We provide theoretical and causal insight about the inner\nworkings of generalized distillation, extend it to unsupervised, semisupervised\nand multitask learning scenarios, and illustrate its efficacy on a variety of\nnumerical simulations on both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 20:27:54 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 16:54:47 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2016 02:21:52 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Lopez-Paz", "David", ""], ["Bottou", "L\u00e9on", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Vapnik", "Vladimir", ""]]}, {"id": "1511.03677", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, David C. Kale, Charles Elkan, Randall Wetzel", "title": "Learning to Diagnose with LSTM Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical medical data, especially in the intensive care unit (ICU), consist\nof multivariate time series of observations. For each patient visit (or\nepisode), sensor data and lab test results are recorded in the patient's\nElectronic Health Record (EHR). While potentially containing a wealth of\ninsights, the data is difficult to mine effectively, owing to varying length,\nirregular sampling and missing data. Recurrent Neural Networks (RNNs),\nparticularly those using Long Short-Term Memory (LSTM) hidden units, are\npowerful and increasingly popular models for learning from sequence data. They\neffectively model varying length sequences and capture long range dependencies.\nWe present the first study to empirically evaluate the ability of LSTMs to\nrecognize patterns in multivariate time series of clinical measurements.\nSpecifically, we consider multilabel classification of diagnoses, training a\nmodel to classify 128 diagnoses given 13 frequently but irregularly sampled\nclinical measurements. First, we establish the effectiveness of a simple LSTM\nnetwork for modeling clinical data. Then we demonstrate a straightforward and\neffective training strategy in which we replicate targets at each sequence\nstep. Trained only on raw time series, our models outperform several strong\nbaselines, including a multilayer perceptron trained on hand-engineered\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 21:01:28 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 01:31:00 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2015 11:22:34 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2015 19:20:41 GMT"}, {"version": "v5", "created": "Thu, 7 Jan 2016 09:29:14 GMT"}, {"version": "v6", "created": "Tue, 1 Mar 2016 01:55:57 GMT"}, {"version": "v7", "created": "Tue, 21 Mar 2017 21:29:50 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Kale", "David C.", ""], ["Elkan", "Charles", ""], ["Wetzel", "Randall", ""]]}, {"id": "1511.03683", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Sharad Vikram, Julian McAuley", "title": "Generative Concatenative Nets Jointly Learn to Write and Classify\n  Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recommender system's basic task is to estimate how users will respond to\nunseen items. This is typically modeled in terms of how a user might rate a\nproduct, but here we aim to extend such approaches to model how a user would\nwrite about the product. To do so, we design a character-level Recurrent Neural\nNetwork (RNN) that generates personalized product reviews. The network\nconvincingly learns styles and opinions of nearly 1000 distinct authors, using\na large corpus of reviews from BeerAdvocate.com. It also tailors reviews to\ndescribe specific items, categories, and star ratings. Using a simple input\nreplication strategy, the Generative Concatenative Network (GCN) preserves the\nsignal of static auxiliary inputs across wide sequence intervals. Without any\nadditional training, the generative model can classify reviews, identifying the\nauthor of the review, the product category, and the sentiment (rating), with\nremarkable accuracy. Our evaluation shows the GCN captures complex dynamics in\ntext, such as the effect of negation, misspellings, slang, and large\nvocabularies gracefully absent any machinery explicitly dedicated to the\npurpose.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 21:16:59 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 10:27:27 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2015 08:20:05 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2015 19:17:07 GMT"}, {"version": "v5", "created": "Thu, 7 Apr 2016 07:08:42 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Vikram", "Sharad", ""], ["McAuley", "Julian", ""]]}, {"id": "1511.03688", "submitter": "David Degras", "authors": "Herv\\'e Cardot and David Degras", "title": "Online Principal Component Analysis in High Dimension: Which Algorithm\n  to Choose?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current context of data explosion, online techniques that do not\nrequire storing all data in memory are indispensable to routinely perform tasks\nlike principal component analysis (PCA). Recursive algorithms that update the\nPCA with each new observation have been studied in various fields of research\nand found wide applications in industrial monitoring, computer vision,\nastronomy, and latent semantic indexing, among others. This work provides\nguidance for selecting an online PCA algorithm in practice. We present the main\napproaches to online PCA, namely, perturbation techniques, incremental methods,\nand stochastic optimization, and compare their statistical accuracy,\ncomputation time, and memory requirements using artificial and real data.\nExtensions to missing data and to functional data are discussed. All studied\nalgorithms are available in the R package onlinePCA on CRAN.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 21:25:26 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Cardot", "Herv\u00e9", ""], ["Degras", "David", ""]]}, {"id": "1511.03719", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Yann LeCun", "title": "Universum Prescription: Regularization using Unlabeled Data", "comments": "7 pages for article, 3 pages for supplemental material. To appear in\n  AAAI-17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that simply prescribing \"none of the above\" labels to\nunlabeled data has a beneficial regularization effect to supervised learning.\nWe call it universum prescription by the fact that the prescribed labels cannot\nbe one of the supervised labels. In spite of its simplicity, universum\nprescription obtained competitive results in training deep convolutional\nnetworks for CIFAR-10, CIFAR-100, STL-10 and ImageNet datasets. A qualitative\njustification of these approaches using Rademacher complexity is presented. The\neffect of a regularization parameter -- probability of sampling from unlabeled\ndata -- is also studied empirically.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 22:46:46 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 19:54:22 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2015 22:12:09 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2016 06:11:33 GMT"}, {"version": "v5", "created": "Mon, 15 Feb 2016 18:52:30 GMT"}, {"version": "v6", "created": "Mon, 25 Apr 2016 21:10:32 GMT"}, {"version": "v7", "created": "Fri, 18 Nov 2016 01:15:30 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Zhang", "Xiang", ""], ["LeCun", "Yann", ""]]}, {"id": "1511.03722", "submitter": "Nan Jiang", "authors": "Nan Jiang and Lihong Li", "title": "Doubly Robust Off-policy Value Evaluation for Reinforcement Learning", "comments": "14 pages; 4 figures; ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of off-policy value evaluation in reinforcement learning\n(RL), where one aims to estimate the value of a new policy based on data\ncollected by a different policy. This problem is often a critical step when\napplying RL in real-world problems. Despite its importance, existing general\nmethods either have uncontrolled bias or suffer high variance. In this work, we\nextend the doubly robust estimator for bandits to sequential decision-making\nproblems, which gets the best of both worlds: it is guaranteed to be unbiased\nand can have a much lower variance than the popular importance sampling\nestimators. We demonstrate the estimator's accuracy in several benchmark\nproblems, and illustrate its use as a subroutine in safe policy improvement. We\nalso provide theoretical results on the hardness of the problem, and show that\nour estimator can match the lower bound in certain scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 22:59:51 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2016 01:23:10 GMT"}, {"version": "v3", "created": "Thu, 26 May 2016 15:43:08 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Jiang", "Nan", ""], ["Li", "Lihong", ""]]}, {"id": "1511.03745", "submitter": "Marcus Rohrbach", "authors": "Anna Rohrbach, Marcus Rohrbach, Ronghang Hu, Trevor Darrell, Bernt\n  Schiele", "title": "Grounding of Textual Phrases in Images by Reconstruction", "comments": "published at ECCV 2016 (oral); updated to final version", "journal-ref": null, "doi": "10.1007/978-3-319-46448-0_49", "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grounding (i.e. localizing) arbitrary, free-form textual phrases in visual\ncontent is a challenging problem with many applications for human-computer\ninteraction and image-text reference resolution. Few datasets provide the\nground truth spatial localization of phrases, thus it is desirable to learn\nfrom data with no or little grounding supervision. We propose a novel approach\nwhich learns grounding by reconstructing a given phrase using an attention\nmechanism, which can be either latent or optimized directly. During training\nour approach encodes the phrase using a recurrent network language model and\nthen learns to attend to the relevant image region in order to reconstruct the\ninput phrase. At test time, the correct attention, i.e., the grounding, is\nevaluated. If grounding supervision is available it can be directly applied via\na loss over the attention mechanism. We demonstrate the effectiveness of our\napproach on the Flickr 30k Entities and ReferItGame datasets with different\nlevels of supervision, ranging from no supervision over partial supervision to\nfull supervision. Our supervised variant improves by a large margin over the\nstate-of-the-art on both datasets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 01:13:47 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 18:59:11 GMT"}, {"version": "v3", "created": "Fri, 18 Mar 2016 04:03:15 GMT"}, {"version": "v4", "created": "Fri, 17 Feb 2017 21:02:05 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Rohrbach", "Anna", ""], ["Rohrbach", "Marcus", ""], ["Hu", "Ronghang", ""], ["Darrell", "Trevor", ""], ["Schiele", "Bernt", ""]]}, {"id": "1511.03760", "submitter": "Yichen Chen", "authors": "Mengdi Wang, Yichen Chen, Jialin Liu, Yuantao Gu", "title": "Random Multi-Constraint Projection: Stochastic Gradient Methods for\n  Convex Optimization with Many Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider convex optimization problems subject to a large number of\nconstraints. We focus on stochastic problems in which the objective takes the\nform of expected values and the feasible set is the intersection of a large\nnumber of convex sets. We propose a class of algorithms that perform both\nstochastic gradient descent and random feasibility updates simultaneously. At\nevery iteration, the algorithms sample a number of projection points onto a\nrandomly selected small subsets of all constraints. Three feasibility update\nschemes are considered: averaging over random projected points, projecting onto\nthe most distant sample, projecting onto a special polyhedral set constructed\nbased on sample points. We prove the almost sure convergence of these\nalgorithms, and analyze the iterates' feasibility error and optimality error,\nrespectively. We provide new convergence rate benchmarks for stochastic\nfirst-order optimization with many constraints. The rate analysis and numerical\nexperiments reveal that the algorithm using the polyhedral-set projection\nscheme is the most efficient one within known algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 02:22:26 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Wang", "Mengdi", ""], ["Chen", "Yichen", ""], ["Liu", "Jialin", ""], ["Gu", "Yuantao", ""]]}, {"id": "1511.03766", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Tianbao Yang, Rong Jin, Zhi-Hua Zhou", "title": "Sparse Learning for Large-scale and High-dimensional Data: A Randomized\n  Convex-concave Optimization Approach", "comments": "Proceedings of the 27th International Conference on Algorithmic\n  Learning Theory (ALT 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a randomized algorithm and theory for learning a\nsparse model from large-scale and high-dimensional data, which is usually\nformulated as an empirical risk minimization problem with a sparsity-inducing\nregularizer. Under the assumption that there exists a (approximately) sparse\nsolution with high classification accuracy, we argue that the dual solution is\nalso sparse or approximately sparse. The fact that both primal and dual\nsolutions are sparse motivates us to develop a randomized approach for a\ngeneral convex-concave optimization problem. Specifically, the proposed\napproach combines the strength of random projection with that of sparse\nlearning: it utilizes random projection to reduce the dimensionality, and\nintroduces $\\ell_1$-norm regularization to alleviate the approximation error\ncaused by random projection. Theoretical analysis shows that under favored\nconditions, the randomized algorithm can accurately recover the optimal\nsolutions to the convex-concave optimization problem (i.e., recover both the\nprimal and dual solutions).\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 03:11:48 GMT"}, {"version": "v2", "created": "Sun, 16 Oct 2016 14:36:01 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Zhang", "Lijun", ""], ["Yang", "Tianbao", ""], ["Jin", "Rong", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1511.03771", "submitter": "Sachin Talathi", "authors": "Sachin S. Talathi and Aniket Vartak", "title": "Improving performance of recurrent neural network with relu nonlinearity", "comments": "10 pages 6 figures; under consideration for publication with ICLR\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years significant progress has been made in successfully training\nrecurrent neural networks (RNNs) on sequence learning problems involving long\nrange temporal dependencies. The progress has been made on three fronts: (a)\nAlgorithmic improvements involving sophisticated optimization techniques, (b)\nnetwork design involving complex hidden layer nodes and specialized recurrent\nlayer connections and (c) weight initialization methods. In this paper, we\nfocus on recently proposed weight initialization with identity matrix for the\nrecurrent weights in a RNN. This initialization is specifically proposed for\nhidden nodes with Rectified Linear Unit (ReLU) non linearity. We offer a simple\ndynamical systems perspective on weight initialization process, which allows us\nto propose a modified weight initialization strategy. We show that this\ninitialization technique leads to successfully training RNNs composed of ReLUs.\nWe demonstrate that our proposal produces comparable or better solution for\nthree toy problems involving long range temporal structure: the addition\nproblem, the multiplication problem and the MNIST classification problem using\nsequence of pixels. In addition, we present results for a benchmark action\nrecognition problem.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 04:35:41 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2016 01:14:54 GMT"}, {"version": "v3", "created": "Thu, 23 Jun 2016 12:52:26 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Talathi", "Sachin S.", ""], ["Vartak", "Aniket", ""]]}, {"id": "1511.03774", "submitter": "Lijie Chen", "authors": "Lijie Chen, Jian Li", "title": "On the Optimal Sample Complexity for Best Arm Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the best arm identification (BEST-1-ARM) problem, which is defined\nas follows. We are given $n$ stochastic bandit arms. The $i$th arm has a reward\ndistribution $D_i$ with an unknown mean $\\mu_{i}$. Upon each play of the $i$th\narm, we can get a reward, sampled i.i.d. from $D_i$. We would like to identify\nthe arm with the largest mean with probability at least $1-\\delta$, using as\nfew samples as possible. We provide a nontrivial algorithm for BEST-1-ARM,\nwhich improves upon several prior upper bounds on the same problem. We also\nstudy an important special case where there are only two arms, which we call\nthe sign problem. We provide a new lower bound of sign, simplifying and\nsignificantly extending a classical result by Farrell in 1964, with a\ncompletely new proof. Using the new lower bound for sign, we obtain the first\nlower bound for BEST-1-ARM that goes beyond the classic Mannor-Tsitsiklis lower\nbound, by an interesting reduction from Sign to BEST-1-ARM. We propose an\ninteresting conjecture concerning the optimal sample complexity of BEST-1-ARM\nfrom the perspective of instance-wise optimality.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 04:49:46 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 05:47:39 GMT"}, {"version": "v3", "created": "Tue, 23 Aug 2016 18:05:29 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Chen", "Lijie", ""], ["Li", "Jian", ""]]}, {"id": "1511.03791", "submitter": "Fangyi Zhang", "authors": "Fangyi Zhang, J\\\"urgen Leitner, Michael Milford, Ben Upcroft, Peter\n  Corke", "title": "Towards Vision-Based Deep Reinforcement Learning for Robotic Motion\n  Control", "comments": "8 pages, to appear in the proceedings of Australasian Conference on\n  Robotics and Automation (ACRA) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a machine learning based system for controlling a\nrobotic manipulator with visual perception only. The capability to autonomously\nlearn robot controllers solely from raw-pixel images and without any prior\nknowledge of configuration is shown for the first time. We build upon the\nsuccess of recent deep reinforcement learning and develop a system for learning\ntarget reaching with a three-joint robot manipulator using external visual\nobservation. A Deep Q Network (DQN) was demonstrated to perform target reaching\nafter training in simulation. Transferring the network to real hardware and\nreal observation in a naive approach failed, but experiments show that the\nnetwork works when replacing camera images with synthetic images.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 06:19:59 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 05:41:08 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Zhang", "Fangyi", ""], ["Leitner", "J\u00fcrgen", ""], ["Milford", "Michael", ""], ["Upcroft", "Ben", ""], ["Corke", "Peter", ""]]}, {"id": "1511.03796", "submitter": "Yuancheng Zhu", "authors": "Yuancheng Zhu, Zhe Liu and Siqi Sun", "title": "Learning Nonparametric Forest Graphical Models with Prior Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for incorporating prior information into nonparametric\nestimation of graphical models. To avoid distributional assumptions, we\nrestrict the graph to be a forest and build on the work of forest density\nestimation (FDE). We reformulate the FDE approach from a Bayesian perspective,\nand introduce prior distributions on the graphs. As two concrete examples, we\napply this framework to estimating scale-free graphs and learning multiple\ngraphs with similar structures. The resulting algorithms are equivalent to\nfinding a maximum spanning tree of a weighted graph with a penalty term on the\nconnectivity pattern of the graph. We solve the optimization problem via a\nminorize-maximization procedure with Kruskal's algorithm. Simulations show that\nthe proposed methods outperform competing parametric methods, and are robust to\nthe true data distribution. They also lead to improvement in predictive power\nand interpretability in two real data sets.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 06:36:53 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 03:18:09 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Zhu", "Yuancheng", ""], ["Liu", "Zhe", ""], ["Sun", "Siqi", ""]]}, {"id": "1511.03816", "submitter": "Geoffrey Webb", "authors": "Geoffrey I. Webb and Roy Hyde and Hong Cao and Hai Long Nguyen and\n  Francois Petitjean", "title": "Characterizing Concept Drift", "comments": "Accepted for publication in Data Mining and Knowledge Discovery", "journal-ref": "Data Mining and Knowledge Discovery, 30(4), 964-994, 2016", "doi": "10.1007/s10618-015-0448-4", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning models are static, but the world is dynamic, and\nincreasing online deployment of learned models gives increasing urgency to the\ndevelopment of efficient and effective mechanisms to address learning in the\ncontext of non-stationary distributions, or as it is commonly called concept\ndrift. However, the key issue of characterizing the different types of drift\nthat can occur has not previously been subjected to rigorous definition and\nanalysis. In particular, while some qualitative drift categorizations have been\nproposed, few have been formally defined, and the quantitative descriptions\nrequired for precise and objective understanding of learner performance have\nnot existed. We present the first comprehensive framework for quantitative\nanalysis of drift. This supports the development of the first comprehensive set\nof formal definitions of types of concept drift. The formal definitions clarify\nambiguities and identify gaps in previous definitions, giving rise to a new\ncomprehensive taxonomy of concept drift types and a solid foundation for\nresearch into mechanisms to detect and address concept drift.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 08:47:38 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 01:04:26 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2015 00:57:13 GMT"}, {"version": "v4", "created": "Tue, 8 Dec 2015 21:13:00 GMT"}, {"version": "v5", "created": "Thu, 10 Dec 2015 22:10:00 GMT"}, {"version": "v6", "created": "Fri, 8 Apr 2016 04:15:33 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Webb", "Geoffrey I.", ""], ["Hyde", "Roy", ""], ["Cao", "Hong", ""], ["Nguyen", "Hai Long", ""], ["Petitjean", "Francois", ""]]}, {"id": "1511.03855", "submitter": "Wu-Jun Li", "authors": "Wu-Jun Li, Sheng Wang, and Wang-Cheng Kang", "title": "Feature Learning based Deep Supervised Hashing with Pairwise Labels", "comments": "IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed wide application of hashing for large-scale image\nretrieval. However, most existing hashing methods are based on hand-crafted\nfeatures which might not be optimally compatible with the hashing procedure.\nRecently, deep hashing methods have been proposed to perform simultaneous\nfeature learning and hash-code learning with deep neural networks, which have\nshown better performance than traditional hashing methods with hand-crafted\nfeatures. Most of these deep hashing methods are supervised whose supervised\ninformation is given with triplet labels. For another common application\nscenario with pairwise labels, there have not existed methods for simultaneous\nfeature learning and hash-code learning. In this paper, we propose a novel deep\nhashing method, called deep pairwise-supervised hashing(DPSH), to perform\nsimultaneous feature learning and hash-code learning for applications with\npairwise labels. Experiments on real datasets show that our DPSH method can\noutperform other methods to achieve the state-of-the-art performance in image\nretrieval applications.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 11:11:42 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2016 09:27:38 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Li", "Wu-Jun", ""], ["Wang", "Sheng", ""], ["Kang", "Wang-Cheng", ""]]}, {"id": "1511.03908", "submitter": "Natalia Neverova", "authors": "Natalia Neverova, Christian Wolf, Griffin Lacey, Lex Fridman, Deepak\n  Chandra, Brandon Barbello, Graham Taylor", "title": "Learning Human Identity from Motion Patterns", "comments": "10 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale study exploring the capability of temporal deep\nneural networks to interpret natural human kinematics and introduce the first\nmethod for active biometric authentication with mobile inertial sensors. At\nGoogle, we have created a first-of-its-kind dataset of human movements,\npassively collected by 1500 volunteers using their smartphones daily over\nseveral months. We (1) compare several neural architectures for efficient\nlearning of temporal multi-modal data representations, (2) propose an optimized\nshift-invariant dense convolutional mechanism (DCWRNN), and (3) incorporate the\ndiscriminatively-trained dynamic features in a probabilistic generative\nframework taking into account temporal characteristics. Our results demonstrate\nthat human kinematics convey important information about user identity and can\nserve as a valuable component of multi-modal authentication systems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 14:48:53 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2015 15:23:06 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2015 01:59:58 GMT"}, {"version": "v4", "created": "Thu, 21 Apr 2016 16:04:00 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Neverova", "Natalia", ""], ["Wolf", "Christian", ""], ["Lacey", "Griffin", ""], ["Fridman", "Lex", ""], ["Chandra", "Deepak", ""], ["Barbello", "Brandon", ""], ["Taylor", "Graham", ""]]}, {"id": "1511.03947", "submitter": "Chris Glynn", "authors": "Chris Glynn, Surya T. Tokdar, David L. Banks, Brian Howard", "title": "Bayesian Analysis of Dynamic Linear Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dynamic topic modeling, the proportional contribution of a topic to a\ndocument depends on the temporal dynamics of that topic's overall prevalence in\nthe corpus. We extend the Dynamic Topic Model of Blei and Lafferty (2006) by\nexplicitly modeling document level topic proportions with covariates and\ndynamic structure that includes polynomial trends and periodicity. A Markov\nChain Monte Carlo (MCMC) algorithm that utilizes Polya-Gamma data augmentation\nis developed for posterior inference. Conditional independencies in the model\nand sampling are made explicit, and our MCMC algorithm is parallelized where\npossible to allow for inference in large corpora. To address computational\nbottlenecks associated with Polya-Gamma sampling, we appeal to the Central\nLimit Theorem to develop a Gaussian approximation to the Polya-Gamma random\nvariable. This approximation is fast and reliable for parameter values relevant\nin the text mining domain. Our model and inference algorithm are validated with\nmultiple simulation examples, and we consider the application of modeling\ntrends in PubMed abstracts. We demonstrate that sharing information across\ndocuments is critical for accurately estimating document-specific topic\nproportions. We also show that explicitly modeling polynomial and periodic\nbehavior improves our ability to predict topic prevalence at future time\npoints.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 16:26:13 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Glynn", "Chris", ""], ["Tokdar", "Surya T.", ""], ["Banks", "David L.", ""], ["Howard", "Brian", ""]]}, {"id": "1511.03962", "submitter": "Yangfeng Ji", "authors": "Yangfeng Ji, Trevor Cohn, Lingpeng Kong, Chris Dyer, Jacob Eisenstein", "title": "Document Context Language Models", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text documents are structured on multiple levels of detail: individual words\nare related by syntax, but larger units of text are related by discourse\nstructure. Existing language models generally fail to account for discourse\nstructure, but it is crucial if we are to have language models that reward\ncoherence and generate coherent texts. We present and empirically evaluate a\nset of multi-level recurrent neural network language models, called\nDocument-Context Language Models (DCLM), which incorporate contextual\ninformation both within and beyond the sentence. In comparison with word-level\nrecurrent neural network language models, the DCLM models obtain slightly\nbetter predictive likelihoods, and considerably better assessments of document\ncoherence.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 16:53:50 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 19:40:50 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2015 03:26:47 GMT"}, {"version": "v4", "created": "Sun, 21 Feb 2016 23:46:44 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Ji", "Yangfeng", ""], ["Cohn", "Trevor", ""], ["Kong", "Lingpeng", ""], ["Dyer", "Chris", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "1511.03979", "submitter": "Patrick McClure", "authors": "Patrick McClure, Nikolaus Kriegeskorte", "title": "Representational Distance Learning for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) provide useful models of visual representational\ntransformations. We present a method that enables a DNN (student) to learn from\nthe internal representational spaces of a reference model (teacher), which\ncould be another DNN or, in the future, a biological brain. Representational\nspaces of the student and the teacher are characterized by representational\ndistance matrices (RDMs). We propose representational distance learning (RDL),\na stochastic gradient descent method that drives the RDMs of the student to\napproximate the RDMs of the teacher. We demonstrate that RDL is competitive\nwith other transfer learning techniques for two publicly available benchmark\ncomputer vision datasets (MNIST and CIFAR-100), while allowing for\narchitectural differences between student and teacher. By pulling the student's\nRDMs towards those of the teacher, RDL significantly improved visual\nclassification performance when compared to baseline networks that did not use\ntransfer learning. In the future, RDL may enable combined supervised training\nof deep neural networks using task constraints (e.g. images and category\nlabels) and constraints from brain-activity measurements, so as to build models\nthat replicate the internal representational spaces of biological brains.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 17:35:03 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2015 13:58:48 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2015 17:19:03 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2015 17:10:25 GMT"}, {"version": "v5", "created": "Fri, 4 Dec 2015 20:45:15 GMT"}, {"version": "v6", "created": "Mon, 7 Nov 2016 18:37:05 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["McClure", "Patrick", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1511.03984", "submitter": "Run Wang", "authors": "Run Wang, Qiaoli Mo, Qian Zhang, Fudi Chen and Dazuo Yang", "title": "Prediction of the Yield of Enzymatic Synthesis of Betulinic Acid Ester\n  Using Artificial Neural Networks and Support Vector Machine", "comments": "32 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3\\b{eta}-O-phthalic ester of betulinic acid is of great importance in\nanticancer studies. However, the optimization of its reaction conditions\nrequires a large number of experimental works. To simplify the number of times\nof optimization in experimental works, here, we use artificial neural network\n(ANN) and support vector machine (SVM) models for the prediction of yields of\n3\\b{eta}-O-phthalic ester of betulinic acid synthesized by betulinic acid and\nphthalic anhydride using lipase as biocatalyst. General regression neural\nnetwork (GRNN), multilayer feed-forward neural network (MLFN) and the SVM\nmodels were trained based on experimental data. Four indicators were set as\nindependent variables, including time (h), temperature (C), amount of enzyme\n(mg) and molar ratio, while the yield of the 3\\b{eta}-O-phthalic ester of\nbetulinic acid was set as the dependent variable. Results show that the GRNN\nand SVM models have the best prediction results during the testing process,\nwith comparatively low RMS errors (4.01 and 4.23respectively) and short\ntraining times (both 1s). The prediction accuracy of the GRNN and SVM are both\n100% in testing process, under the tolerance of 30%.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 17:40:42 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Wang", "Run", ""], ["Mo", "Qiaoli", ""], ["Zhang", "Qian", ""], ["Chen", "Fudi", ""], ["Yang", "Dazuo", ""]]}, {"id": "1511.04033", "submitter": "Emilie Devijver", "authors": "Emilie Devijver, M\\'elina Gallopin", "title": "Block-diagonal covariance selection for high-dimensional Gaussian\n  graphical models", "comments": "Accepted in JASA", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian graphical models are widely utilized to infer and visualize networks\nof dependencies between continuous variables. However, inferring the graph is\ndifficult when the sample size is small compared to the number of variables. To\nreduce the number of parameters to estimate in the model, we propose a\nnon-asymptotic model selection procedure supported by strong theoretical\nguarantees based on an oracle inequality and a minimax lower bound. The\ncovariance matrix of the model is approximated by a block-diagonal matrix. The\nstructure of this matrix is detected by thresholding the sample covariance\nmatrix, where the threshold is selected using the slope heuristic. Based on the\nblock-diagonal structure of the covariance matrix, the estimation problem is\ndivided into several independent problems: subsequently, the network of\ndependencies between variables is inferred using the graphical lasso algorithm\nin each block. The performance of the procedure is illustrated on simulated\ndata. An application to a real gene expression dataset with a limited sample\nsize is also presented: the dimension reduction allows attention to be\nobjectively focused on interactions among smaller subsets of genes, leading to\na more parsimonious and interpretable modular network.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 19:56:45 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2016 10:56:02 GMT"}, {"version": "v3", "created": "Thu, 29 Sep 2016 08:33:19 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Devijver", "Emilie", ""], ["Gallopin", "M\u00e9lina", ""]]}, {"id": "1511.04045", "submitter": "Vladimir Savic Dr", "authors": "Vladimir Savic, Erik G. Larsson, Javier Ferrer-Coll, Peter Stenumgaard", "title": "Kernel Methods for Accurate UWB-Based Ranging with Reduced Complexity", "comments": "published in IEEE Transactions on Wireless Communication", "journal-ref": null, "doi": "10.1109/TWC.2015.2496584", "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and robust positioning in multipath environments can enable many\napplications, such as search-and-rescue and asset tracking. For this problem,\nultra-wideband (UWB) technology can provide the most accurate range estimates,\nwhich are required for range-based positioning. However, UWB still faces a\nproblem with non-line-of-sight (NLOS) measurements, in which the range\nestimates based on time-of-arrival (TOA) will typically be positively biased.\nThere are many techniques that address this problem, mainly based on NLOS\nidentification and NLOS error mitigation algorithms. However, these techniques\ndo not exploit all available information in the UWB channel impulse response.\nKernel-based machine learning methods, such as Gaussian Process Regression\n(GPR), are able to make use of all information, but they may be too complex in\ntheir original form. In this paper, we propose novel ranging methods based on\nkernel principal component analysis (kPCA), in which the selected channel\nparameters are projected onto a nonlinear orthogonal high-dimensional space,\nand a subset of these projections is then used as an input for ranging. We\nevaluate the proposed methods using real UWB measurements obtained in a\nbasement tunnel, and found that one of the proposed methods is able to\noutperform state-of-the-art, even if little training samples are available.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 16:42:37 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Savic", "Vladimir", ""], ["Larsson", "Erik G.", ""], ["Ferrer-Coll", "Javier", ""], ["Stenumgaard", "Peter", ""]]}, {"id": "1511.04056", "submitter": "Mohammad Norouzi", "authors": "Mohammad Norouzi, Maxwell D. Collins, Matthew Johnson, David J. Fleet,\n  Pushmeet Kohli", "title": "Efficient non-greedy optimization of decision trees", "comments": "in NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees and randomized forests are widely used in computer vision and\nmachine learning. Standard algorithms for decision tree induction optimize the\nsplit functions one node at a time according to some splitting criteria. This\ngreedy procedure often leads to suboptimal trees. In this paper, we present an\nalgorithm for optimizing the split functions at all levels of the tree jointly\nwith the leaf parameters, based on a global objective. We show that the problem\nof finding optimal linear-combination (oblique) splits for decision trees is\nrelated to structured prediction with latent variables, and we formulate a\nconvex-concave upper bound on the tree's empirical loss. The run-time of\ncomputing the gradient of the proposed surrogate objective with respect to each\ntraining exemplar is quadratic in the the tree depth, and thus training deep\ntrees is feasible. The use of stochastic gradient descent for optimization\nenables effective training with large datasets. Experiments on several\nclassification benchmarks demonstrate that the resulting non-greedy decision\ntrees outperform greedy decision tree baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 20:32:28 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Norouzi", "Mohammad", ""], ["Collins", "Maxwell D.", ""], ["Johnson", "Matthew", ""], ["Fleet", "David J.", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1511.04066", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas, Daniel M. Kane, Alistair Stewart", "title": "Properly Learning Poisson Binomial Distributions in Almost Polynomial\n  Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithm for properly learning Poisson binomial distributions. A\nPoisson binomial distribution (PBD) of order $n$ is the discrete probability\ndistribution of the sum of $n$ mutually independent Bernoulli random variables.\nGiven $\\widetilde{O}(1/\\epsilon^2)$ samples from an unknown PBD $\\mathbf{p}$,\nour algorithm runs in time $(1/\\epsilon)^{O(\\log \\log (1/\\epsilon))}$, and\noutputs a hypothesis PBD that is $\\epsilon$-close to $\\mathbf{p}$ in total\nvariation distance. The previously best known running time for properly\nlearning PBDs was $(1/\\epsilon)^{O(\\log(1/\\epsilon))}$.\n  As one of our main contributions, we provide a novel structural\ncharacterization of PBDs. We prove that, for all $\\epsilon >0,$ there exists an\nexplicit collection $\\cal{M}$ of $(1/\\epsilon)^{O(\\log \\log (1/\\epsilon))}$\nvectors of multiplicities, such that for any PBD $\\mathbf{p}$ there exists a\nPBD $\\mathbf{q}$ with $O(\\log(1/\\epsilon))$ distinct parameters whose\nmultiplicities are given by some element of ${\\cal M}$, such that $\\mathbf{q}$\nis $\\epsilon$-close to $\\mathbf{p}$. Our proof combines tools from Fourier\nanalysis and algebraic geometry.\n  Our approach to the proper learning problem is as follows: Starting with an\naccurate non-proper hypothesis, we fit a PBD to this hypothesis. More\nspecifically, we essentially start with the hypothesis computed by the\ncomputationally efficient non-proper learning algorithm in our recent\nwork~\\cite{DKS15}. Our aforementioned structural characterization allows us to\nreduce the corresponding fitting problem to a collection of\n$(1/\\epsilon)^{O(\\log \\log(1/\\epsilon))}$ systems of low-degree polynomial\ninequalities. We show that each such system can be solved in time\n$(1/\\epsilon)^{O(\\log \\log(1/\\epsilon))}$, which yields the overall running\ntime of our algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 20:47:37 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Stewart", "Alistair", ""]]}, {"id": "1511.04108", "submitter": "Ming Tan", "authors": "Ming Tan, Cicero dos Santos, Bing Xiang, Bowen Zhou", "title": "LSTM-based Deep Learning Models for Non-factoid Answer Selection", "comments": "added new experiments on TREC-QA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply a general deep learning (DL) framework for the answer\nselection task, which does not depend on manually defined features or\nlinguistic tools. The basic framework is to build the embeddings of questions\nand answers based on bidirectional long short-term memory (biLSTM) models, and\nmeasure their closeness by cosine similarity. We further extend this basic\nmodel in two directions. One direction is to define a more composite\nrepresentation for questions and answers by combining convolutional neural\nnetwork with the basic framework. The other direction is to utilize a simple\nbut efficient attention mechanism in order to generate the answer\nrepresentation according to the question context. Several variations of models\nare provided. The models are examined by two datasets, including TREC-QA and\nInsuranceQA. Experimental results demonstrate that the proposed models\nsubstantially outperform several strong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 22:01:54 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 15:00:46 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 17:56:29 GMT"}, {"version": "v4", "created": "Mon, 28 Mar 2016 04:12:45 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Tan", "Ming", ""], ["Santos", "Cicero dos", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""]]}, {"id": "1511.04119", "submitter": "Shikhar Sharma", "authors": "Shikhar Sharma, Ryan Kiros, Ruslan Salakhutdinov", "title": "Action Recognition using Visual Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a soft attention based model for the task of action recognition in\nvideos. We use multi-layered Recurrent Neural Networks (RNNs) with Long\nShort-Term Memory (LSTM) units which are deep both spatially and temporally.\nOur model learns to focus selectively on parts of the video frames and\nclassifies videos after taking a few glimpses. The model essentially learns\nwhich parts in the frames are relevant for the task at hand and attaches higher\nimportance to them. We evaluate the model on UCF-11 (YouTube Action), HMDB-51\nand Hollywood2 datasets and analyze how the model focuses its attention\ndepending on the scene and the action being performed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 23:06:42 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 20:46:47 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2016 17:20:19 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Sharma", "Shikhar", ""], ["Kiros", "Ryan", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1511.04137", "submitter": "Lin Chen", "authors": "Lin Chen, Forrest W. Crawford, Amin Karbasi", "title": "Seeing the Unseen Network: Inferring Hidden Social Ties from\n  Respondent-Driven Sampling", "comments": "A full version with technical proofs. Accepted by AAAI-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning about the social structure of hidden and hard-to-reach populations\n--- such as drug users and sex workers --- is a major goal of epidemiological\nand public health research on risk behaviors and disease prevention.\nRespondent-driven sampling (RDS) is a peer-referral process widely used by many\nhealth organizations, where research subjects recruit other subjects from their\nsocial network. In such surveys, researchers observe who recruited whom, along\nwith the time of recruitment and the total number of acquaintances (network\ndegree) of respondents. However, due to privacy concerns, the identities of\nacquaintances are not disclosed. In this work, we show how to reconstruct the\nunderlying network structure through which the subjects are recruited. We\nformulate the dynamics of RDS as a continuous-time diffusion process over the\nunderlying graph and derive the likelihood for the recruitment time series\nunder an arbitrary recruitment time distribution. We develop an efficient\nstochastic optimization algorithm called RENDER (REspoNdent-Driven nEtwork\nReconstruction) that finds the network that best explains the collected data.\nWe support our analytical results through an exhaustive set of experiments on\nboth synthetic and real data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 01:59:35 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 01:02:17 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Chen", "Lin", ""], ["Crawford", "Forrest W.", ""], ["Karbasi", "Amin", ""]]}, {"id": "1511.04143", "submitter": "Matthew Hausknecht", "authors": "Matthew Hausknecht and Peter Stone", "title": "Deep Reinforcement Learning in Parameterized Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that deep neural networks are capable of approximating\nboth value functions and policies in reinforcement learning domains featuring\ncontinuous state and action spaces. However, to the best of our knowledge no\nprevious work has succeeded at using deep neural networks in structured\n(parameterized) continuous action spaces. To fill this gap, this paper focuses\non learning within the domain of simulated RoboCup soccer, which features a\nsmall set of discrete action types, each of which is parameterized with\ncontinuous variables. The best learned agent can score goals more reliably than\nthe 2012 RoboCup champion agent. As such, this paper represents a successful\nextension of deep reinforcement learning to the class of parameterized action\nspace MDPs.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 02:34:33 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 14:34:20 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 16:44:44 GMT"}, {"version": "v4", "created": "Tue, 16 Feb 2016 16:30:34 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Hausknecht", "Matthew", ""], ["Stone", "Peter", ""]]}, {"id": "1511.04145", "submitter": "Mehrdad Farajtabar", "authors": "Mehrdad Farajtabar, Safoora Yousefi, Long Q. Tran, Le Song, Hongyuan\n  Zha", "title": "A Continuous-time Mutually-Exciting Point Process Framework for\n  Prioritizing Events in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overwhelming amount and rate of information update in online social media\nis making it increasingly difficult for users to allocate their attention to\ntheir topics of interest, thus there is a strong need for prioritizing news\nfeeds. The attractiveness of a post to a user depends on many complex\ncontextual and temporal features of the post. For instance, the contents of the\npost, the responsiveness of a third user, and the age of the post may all have\nimpact. So far, these static and dynamic features has not been incorporated in\na unified framework to tackle the post prioritization problem. In this paper,\nwe propose a novel approach for prioritizing posts based on a feature modulated\nmulti-dimensional point process. Our model is able to simultaneously capture\ntextual and sentiment features, and temporal features such as self-excitation,\nmutual-excitation and bursty nature of social interaction. As an evaluation, we\nalso curated a real-world conversational benchmark dataset crawled from\nFacebook. In our experiments, we demonstrate that our algorithm is able to\nachieve the-state-of-the-art performance in terms of analyzing, predicting, and\nprioritizing events. In terms of interpretability of our method, we observe\nthat features indicating individual user profile and linguistic characteristics\nof the events work best for prediction and prioritization of new events.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 02:56:32 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Farajtabar", "Mehrdad", ""], ["Yousefi", "Safoora", ""], ["Tran", "Long Q.", ""], ["Song", "Le", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1511.04150", "submitter": "Danica J. Sutherland", "authors": "Junier B. Oliva, Danica J. Sutherland, Barnab\\'as P\\'oczos, Jeff\n  Schneider", "title": "Deep Mean Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of distributions and high-level features from deep architecture has\nbecome commonplace in modern computer vision. Both of these methodologies have\nseparately achieved a great deal of success in many computer vision tasks.\nHowever, there has been little work attempting to leverage the power of these\nto methodologies jointly. To this end, this paper presents the Deep Mean Maps\n(DMMs) framework, a novel family of methods to non-parametrically represent\ndistributions of features in convolutional neural network models.\n  DMMs are able to both classify images using the distribution of top-level\nfeatures, and to tune the top-level features for performing this task. We show\nhow to implement DMMs using a special mean map layer composed of typical CNN\noperations, making both forward and backward propagation simple.\n  We illustrate the efficacy of DMMs at analyzing distributional patterns in\nimage data in a synthetic data experiment. We also show that we extending\nexisting deep architectures with DMMs improves the performance of existing CNNs\non several challenging real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 03:36:51 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 06:24:14 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Oliva", "Junier B.", ""], ["Sutherland", "Danica J.", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Schneider", "Jeff", ""]]}, {"id": "1511.04153", "submitter": "Yaoyi Li", "authors": "Yaoyi Li, Junxuan Chen and Hongtao Lu", "title": "Adaptive Affinity Matrix for Unsupervised Metric Learning", "comments": null, "journal-ref": null, "doi": "10.1109/ICME.2016.7552887", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is one of the most popular clustering approaches with the\ncapability to handle some challenging clustering problems. Most spectral\nclustering methods provide a nonlinear map from the data manifold to a\nsubspace. Only a little work focuses on the explicit linear map which can be\nviewed as the unsupervised distance metric learning. In practice, the selection\nof the affinity matrix exhibits a tremendous impact on the unsupervised\nlearning. While much success of affinity learning has been achieved in recent\nyears, some issues such as noise reduction remain to be addressed. In this\npaper, we propose a novel method, dubbed Adaptive Affinity Matrix (AdaAM), to\nlearn an adaptive affinity matrix and derive a distance metric from the\naffinity. We assume the affinity matrix to be positive semidefinite with\nability to quantify the pairwise dissimilarity. Our method is based on posing\nthe optimization of objective function as a spectral decomposition problem. We\nyield the affinity from both the original data distribution and the widely-used\nheat kernel. The provided matrix can be regarded as the optimal representation\nof pairwise relationship on the manifold. Extensive experiments on a number of\nreal-world data sets show the effectiveness and efficiency of AdaAM.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 03:59:14 GMT"}, {"version": "v2", "created": "Sun, 11 Sep 2016 13:58:06 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Li", "Yaoyi", ""], ["Chen", "Junxuan", ""], ["Lu", "Hongtao", ""]]}, {"id": "1511.04156", "submitter": "Josh Merel", "authors": "Josh Merel, David Carlson, Liam Paninski, John P. Cunningham", "title": "Neuroprosthetic decoder training as imitation learning", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1004948", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroprosthetic brain-computer interfaces function via an algorithm which\ndecodes neural activity of the user into movements of an end effector, such as\na cursor or robotic arm. In practice, the decoder is often learned by updating\nits parameters while the user performs a task. When the user's intention is not\ndirectly observable, recent methods have demonstrated value in training the\ndecoder against a surrogate for the user's intended movement. We describe how\ntraining a decoder in this way is a novel variant of an imitation learning\nproblem, where an oracle or expert is employed for supervised training in lieu\nof direct observations, which are not available. Specifically, we describe how\na generic imitation learning meta-algorithm, dataset aggregation (DAgger, [1]),\ncan be adapted to train a generic brain-computer interface. By deriving\nexisting learning algorithms for brain-computer interfaces in this framework,\nwe provide a novel analysis of regret (an important metric of learning\nefficacy) for brain-computer interfaces. This analysis allows us to\ncharacterize the space of algorithmic variants and bounds on their regret\nrates. Existing approaches for decoder learning have been performed in the\ncursor control setting, but the available design principles for these decoders\nare such that it has been impossible to scale them to naturalistic settings.\nLeveraging our findings, we then offer an algorithm that combines imitation\nlearning with optimal control, which should allow for training of arbitrary\neffectors for which optimal control can generate goal-oriented control. We\ndemonstrate this novel and general BCI algorithm with simulated neuroprosthetic\ncontrol of a 26 degree-of-freedom model of an arm, a sophisticated and\nrealistic end effector.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 04:21:33 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 16:39:03 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Merel", "Josh", ""], ["Carlson", "David", ""], ["Paninski", "Liam", ""], ["Cunningham", "John P.", ""]]}, {"id": "1511.04210", "submitter": "Ohad Shamir", "authors": "Itay Safran, Ohad Shamir", "title": "On the Quality of the Initial Basin in Overspecified Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, in the form of artificial neural networks, has achieved\nremarkable practical success in recent years, for a variety of difficult\nmachine learning applications. However, a theoretical explanation for this\nremains a major open problem, since training neural networks involves\noptimizing a highly non-convex objective function, and is known to be\ncomputationally hard in the worst case. In this work, we study the\n\\emph{geometric} structure of the associated non-convex objective function, in\nthe context of ReLU networks and starting from a random initialization of the\nnetwork parameters. We identify some conditions under which it becomes more\nfavorable to optimization, in the sense of (i) High probability of initializing\nat a point from which there is a monotonically decreasing path to a global\nminimum; and (ii) High probability of initializing at a basin (suitably\ndefined) with a small minimal objective value. A common theme in our results is\nthat such properties are more likely to hold for larger (\"overspecified\")\nnetworks, which accords with some recent empirical and theoretical\nobservations.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 09:35:34 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 16:22:46 GMT"}, {"version": "v3", "created": "Tue, 14 Jun 2016 05:39:27 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Safran", "Itay", ""], ["Shamir", "Ohad", ""]]}, {"id": "1511.04211", "submitter": "Jan Hendrik Metzen", "authors": "Jan Hendrik Metzen", "title": "Active Contextual Entropy Search", "comments": "Corrected title of reference #19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual policy search allows adapting robotic movement primitives to\ndifferent situations. For instance, a locomotion primitive might be adapted to\ndifferent terrain inclinations or desired walking speeds. Such an adaptation is\noften achievable by modifying a small number of hyperparameters. However,\nlearning, when performed on real robotic systems, is typically restricted to a\nsmall number of trials. Bayesian optimization has recently been proposed as a\nsample-efficient means for contextual policy search that is well suited under\nthese conditions. In this work, we extend entropy search, a variant of Bayesian\noptimization, such that it can be used for active contextual policy search\nwhere the agent selects those tasks during training in which it expects to\nlearn the most. Empirical results in simulation suggest that this allows\nlearning successful behavior with less trials.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 09:37:40 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2015 09:22:01 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Metzen", "Jan Hendrik", ""]]}, {"id": "1511.04306", "submitter": "Sebastian Stober", "authors": "Sebastian Stober, Avital Sternin, Adrian M. Owen and Jessica A. Grahn", "title": "Deep Feature Learning for EEG Recordings", "comments": "submitted as conference paper for ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and compare several strategies for learning discriminative\nfeatures from electroencephalography (EEG) recordings using deep learning\ntechniques. EEG data are generally only available in small quantities, they are\nhigh-dimensional with a poor signal-to-noise ratio, and there is considerable\nvariability between individual subjects and recording sessions. Our proposed\ntechniques specifically address these challenges for feature learning.\nCross-trial encoding forces auto-encoders to focus on features that are stable\nacross trials. Similarity-constraint encoders learn features that allow to\ndistinguish between classes by demanding that two trials from the same class\nare more similar to each other than to trials from other classes. This\ntuple-based training approach is especially suitable for small datasets.\nHydra-nets allow for separate processing pathways adapting to subsets of a\ndataset and thus combine the advantages of individual feature learning (better\nadaptation of early, low-level processing) with group model training (better\ngeneralization of higher-level processing in deeper layers). This way, models\ncan, for instance, adapt to each subject individually to compensate for\ndifferences in spatial patterns due to anatomical differences or variance in\nelectrode positions. The different techniques are evaluated using the publicly\navailable OpenMIIR dataset of EEG recordings taken while participants listened\nto and imagined music.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 15:07:17 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 22:04:12 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2015 18:24:08 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 16:26:42 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Stober", "Sebastian", ""], ["Sternin", "Avital", ""], ["Owen", "Adrian M.", ""], ["Grahn", "Jessica A.", ""]]}, {"id": "1511.04383", "submitter": "Bopeng Li", "authors": "Bopeng Li, Sougata Chaudhuri, Ambuj Tewari", "title": "Handling Class Imbalance in Link Prediction using Learning to Rank\n  Techniques", "comments": "The paper has been withdrawn due to a baseline implementation error\n  in experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the link prediction problem in a partially observed network,\nwhere the objective is to make predictions in the unobserved portion of the\nnetwork. Many existing methods reduce link prediction to binary classification\nproblem. However, the dominance of absent links in real world networks makes\nmisclassification error a poor performance metric. Instead, researchers have\nargued for using ranking performance measures, like AUC, AP and NDCG, for\nevaluation. Our main contribution is to recast the link prediction problem as a\nlearning to rank problem and use effective learning to rank techniques directly\nduring training. This is in contrast to existing work that uses ranking\nmeasures only during evaluation. Our approach is able to deal with the class\nimbalance problem by using effective, scalable learning to rank techniques\nduring training. Furthermore, our approach allows us to combine network\ntopology and node features. As a demonstration of our general approach, we\ndevelop a link prediction method by optimizing the cross-entropy surrogate,\noriginally used in the popular ListNet ranking algorithm. We conduct extensive\nexperiments on publicly available co-authorship, citation and metabolic\nnetworks to demonstrate the merits of our method.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 18:06:15 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 02:40:57 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Li", "Bopeng", ""], ["Chaudhuri", "Sougata", ""], ["Tewari", "Ambuj", ""]]}, {"id": "1511.04397", "submitter": "Ehsan Hosseini-Asl", "authors": "Ehsan Hosseini-Asl, Angshuman Guha", "title": "Similarity-based Text Recognition by Deeply Supervised Siamese Network", "comments": "Accepted for presenting at Future Technologies Conference - (FTC\n  2016) San Francisco, December 6-7, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new text recognition model based on measuring the\nvisual similarity of text and predicting the content of unlabeled texts. First\na Siamese convolutional network is trained with deep supervision on a labeled\ntraining dataset. This network projects texts into a similarity manifold. The\nDeeply Supervised Siamese network learns visual similarity of texts. Then a\nK-nearest neighbor classifier is used to predict unlabeled text based on\nsimilarity distance to labeled texts. The performance of the model is evaluated\non three datasets of machine-print and hand-written text combined. We\ndemonstrate that the model reduces the cost of human estimation by $50\\%-85\\%$.\nThe error of the system is less than $0.5\\%$. The proposed model outperform\nconventional Siamese network by finding visually-similar barely-readable and\nreadable text, e.g. machine-printed, handwritten, due to deep supervision. The\nresults also demonstrate that the predicted labels are sometimes better than\nhuman labels e.g. spelling correction.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 18:46:01 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 20:59:10 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 00:37:29 GMT"}, {"version": "v4", "created": "Sun, 3 Jul 2016 16:38:35 GMT"}, {"version": "v5", "created": "Tue, 5 Jul 2016 01:21:08 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Hosseini-Asl", "Ehsan", ""], ["Guha", "Angshuman", ""]]}, {"id": "1511.04401", "submitter": "Federico Raue", "authors": "Federico Raue, Andreas Dengel, Thomas M. Breuel, Marcus Liwicki", "title": "Symbol Grounding Association in Multimodal Sequences with Missing\n  Elements", "comments": "Under review on Journal of Artificial Intelligence Research (JAIR) --\n  Special Track on Deep Learning, Knowledge Representation, and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we extend a symbolic association framework for being able to\nhandle missing elements in multimodal sequences. The general scope of the work\nis the symbolic associations of object-word mappings as it happens in language\ndevelopment in infants. In other words, two different representations of the\nsame abstract concepts can associate in both directions. This scenario has been\nlong interested in Artificial Intelligence, Psychology, and Neuroscience. In\nthis work, we extend a recent approach for multimodal sequences (visual and\naudio) to also cope with missing elements in one or both modalities. Our method\nuses two parallel Long Short-Term Memories (LSTMs) with a learning rule based\non EM-algorithm. It aligns both LSTM outputs via Dynamic Time Warping (DTW). We\npropose to include an extra step for the combination with the max operation for\nexploiting the common elements between both sequences. The motivation behind is\nthat the combination acts as a condition selector for choosing the best\nrepresentation from both LSTMs. We evaluated the proposed extension in the\nfollowing scenarios: missing elements in one modality (visual or audio) and\nmissing elements in both modalities (visual and sound). The performance of our\nextension reaches better results than the original model and similar results to\nindividual LSTM trained in each modality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 18:59:36 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 15:59:02 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2016 11:36:59 GMT"}, {"version": "v4", "created": "Fri, 16 Dec 2016 14:17:02 GMT"}, {"version": "v5", "created": "Thu, 7 Dec 2017 10:14:23 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Raue", "Federico", ""], ["Dengel", "Andreas", ""], ["Breuel", "Thomas M.", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1511.04412", "submitter": "Mazen Melibari", "authors": "Mazen Melibari, Pascal Poupart, Prashant Doshi and George Trimponias", "title": "Dynamic Sum Product Networks for Tractable Inference on Sequence Data\n  (Extended Version)", "comments": "Published in the Proceedings of the International Conference on\n  Probabilistic Graphical Models (PGM), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sum-Product Networks (SPN) have recently emerged as a new class of tractable\nprobabilistic graphical models. Unlike Bayesian networks and Markov networks\nwhere inference may be exponential in the size of the network, inference in\nSPNs is in time linear in the size of the network. Since SPNs represent\ndistributions over a fixed set of variables only, we propose dynamic sum\nproduct networks (DSPNs) as a generalization of SPNs for sequence data of\nvarying length. A DSPN consists of a template network that is repeated as many\ntimes as needed to model data sequences of any length. We present a local\nsearch technique to learn the structure of the template network. In contrast to\ndynamic Bayesian networks for which inference is generally exponential in the\nnumber of variables per time slice, DSPNs inherit the linear inference\ncomplexity of SPNs. We demonstrate the advantages of DSPNs over DBNs and other\nmodels on several datasets of sequence data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 19:56:15 GMT"}, {"version": "v2", "created": "Sat, 16 Jul 2016 03:37:01 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Melibari", "Mazen", ""], ["Poupart", "Pascal", ""], ["Doshi", "Prashant", ""], ["Trimponias", "George", ""]]}, {"id": "1511.04491", "submitter": "Jiwon Kim", "authors": "Jiwon Kim, Jung Kwon Lee and Kyoung Mu Lee", "title": "Deeply-Recursive Convolutional Network for Image Super-Resolution", "comments": "CVPR 2016 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an image super-resolution method (SR) using a deeply-recursive\nconvolutional network (DRCN). Our network has a very deep recursive layer (up\nto 16 recursions). Increasing recursion depth can improve performance without\nintroducing new parameters for additional convolutions. Albeit advantages,\nlearning a DRCN is very hard with a standard gradient descent method due to\nexploding/vanishing gradients. To ease the difficulty of training, we propose\ntwo extensions: recursive-supervision and skip-connection. Our method\noutperforms previous methods by a large margin.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 02:21:50 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 08:40:53 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Kim", "Jiwon", ""], ["Lee", "Jung Kwon", ""], ["Lee", "Kyoung Mu", ""]]}, {"id": "1511.04508", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel and Xi Wu and Somesh Jha and\n  Ananthram Swami", "title": "Distillation as a Defense to Adversarial Perturbations against Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have been shown to perform extremely well on many\nclassical machine learning problems. However, recent studies have shown that\ndeep learning, like other machine learning techniques, is vulnerable to\nadversarial samples: inputs crafted to force a deep neural network (DNN) to\nprovide adversary-selected outputs. Such attacks can seriously undermine the\nsecurity of the system supported by the DNN, sometimes with devastating\nconsequences. For example, autonomous vehicles can be crashed, illicit or\nillegal content can bypass content filters, or biometric authentication systems\ncan be manipulated to allow improper access. In this work, we introduce a\ndefensive mechanism called defensive distillation to reduce the effectiveness\nof adversarial samples on DNNs. We analytically investigate the\ngeneralizability and robustness properties granted by the use of defensive\ndistillation when training DNNs. We also empirically study the effectiveness of\nour defense mechanisms on two DNNs placed in adversarial settings. The study\nshows that defensive distillation can reduce effectiveness of sample creation\nfrom 95% to less than 0.5% on a studied DNN. Such dramatic gains can be\nexplained by the fact that distillation leads gradients used in adversarial\nsample creation to be reduced by a factor of 10^30. We also find that\ndistillation increases the average minimum number of features that need to be\nmodified to create adversarial samples by about 800% on one of the DNNs we\ntested.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 04:51:04 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 13:08:09 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Wu", "Xi", ""], ["Jha", "Somesh", ""], ["Swami", "Ananthram", ""]]}, {"id": "1511.04514", "submitter": "Zhuoran Yang", "authors": "Zhuoran Yang, Zhaoran Wang, Han Liu, Yonina C. Eldar, Tong Zhang", "title": "Sparse Nonlinear Regression: Parameter Estimation and Asymptotic\n  Inference", "comments": "32 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study parameter estimation and asymptotic inference for sparse nonlinear\nregression. More specifically, we assume the data are given by $y = f( x^\\top\n\\beta^* ) + \\epsilon$, where $f$ is nonlinear. To recover $\\beta^*$, we propose\nan $\\ell_1$-regularized least-squares estimator. Unlike classical linear\nregression, the corresponding optimization problem is nonconvex because of the\nnonlinearity of $f$. In spite of the nonconvexity, we prove that under mild\nconditions, every stationary point of the objective enjoys an optimal\nstatistical rate of convergence. In addition, we provide an efficient algorithm\nthat provably converges to a stationary point. We also access the uncertainty\nof the obtained estimator. Specifically, based on any stationary point of the\nobjective, we construct valid hypothesis tests and confidence intervals for the\nlow dimensional components of the high-dimensional parameter $\\beta^*$.\nDetailed numerical results are provided to back up our theory.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 05:57:24 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Liu", "Han", ""], ["Eldar", "Yonina C.", ""], ["Zhang", "Tong", ""]]}, {"id": "1511.04524", "submitter": "Ziming Zhang", "authors": "Ziming Zhang, Yuting Chen and Venkatesh Saligrama", "title": "Efficient Training of Very Deep Neural Networks for Supervised Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose training very deep neural networks (DNNs) for\nsupervised learning of hash codes. Existing methods in this context train\nrelatively \"shallow\" networks limited by the issues arising in back propagation\n(e.e. vanishing gradients) as well as computational efficiency. We propose a\nnovel and efficient training algorithm inspired by alternating direction method\nof multipliers (ADMM) that overcomes some of these limitations. Our method\ndecomposes the training process into independent layer-wise local updates\nthrough auxiliary variables. Empirically we observe that our training algorithm\nalways converges and its computational complexity is linearly proportional to\nthe number of edges in the networks. Empirically we manage to train DNNs with\n64 hidden layers and 1024 nodes per layer for supervised hashing in about 3\nhours using a single GPU. Our proposed very deep supervised hashing (VDSH)\nmethod significantly outperforms the state-of-the-art on several benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 07:35:01 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2016 21:49:21 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Zhang", "Ziming", ""], ["Chen", "Yuting", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1511.04561", "submitter": "Tim Dettmers", "authors": "Tim Dettmers", "title": "8-Bit Approximations for Parallelism in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The creation of practical deep learning data-products often requires\nparallelization across processors and computers to make deep learning feasible\non large data sets, but bottlenecks in communication bandwidth make it\ndifficult to attain good speedups through parallelism. Here we develop and test\n8-bit approximation algorithms which make better use of the available bandwidth\nby compressing 32-bit gradients and nonlinear activations to 8-bit\napproximations. We show that these approximations do not decrease predictive\nperformance on MNIST, CIFAR10, and ImageNet for both model and data parallelism\nand provide a data transfer speedup of 2x relative to 32-bit parallelism. We\nbuild a predictive model for speedups based on our experimental data, verify\nits validity on known speedup data, and show that we can obtain a speedup of\n50x and more on a system of 96 GPUs compared to a speedup of 23x for 32-bit. We\ncompare our data types with other methods and show that 8-bit approximations\nachieve state-of-the-art speedups for model parallelism. Thus 8-bit\napproximation is an efficient method to parallelize convolutional networks on\nvery large systems of GPUs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 14:04:51 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2015 10:25:58 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2016 20:32:52 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2016 16:26:30 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Dettmers", "Tim", ""]]}, {"id": "1511.04581", "submitter": "Eugene Belilovsky", "authors": "Wacha Bounliphone, Eugene Belilovsky, Matthew B. Blaschko, Ioannis\n  Antonoglou, Arthur Gretton", "title": "A Test of Relative Similarity For Model Selection in Generative Models", "comments": "International Conference on Learning Representations 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic generative models provide a powerful framework for representing\ndata that avoids the expense of manual annotation typically needed by\ndiscriminative approaches. Model selection in this generative setting can be\nchallenging, however, particularly when likelihoods are not easily accessible.\nTo address this issue, we introduce a statistical test of relative similarity,\nwhich is used to determine which of two models generates samples that are\nsignificantly closer to a real-world reference dataset of interest. We use as\nour test statistic the difference in maximum mean discrepancies (MMDs) between\nthe reference dataset and each model dataset, and derive a powerful,\nlow-variance test based on the joint asymptotic distribution of the MMDs\nbetween each reference-model pair. In experiments on deep generative models,\nincluding the variational auto-encoder and generative moment matching network,\nthe tests provide a meaningful ranking of model performance as a function of\nparameter and training settings.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 17:18:47 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 11:12:05 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 15:35:53 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2016 15:12:44 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Bounliphone", "Wacha", ""], ["Belilovsky", "Eugene", ""], ["Blaschko", "Matthew B.", ""], ["Antonoglou", "Ioannis", ""], ["Gretton", "Arthur", ""]]}, {"id": "1511.04587", "submitter": "Jiwon Kim", "authors": "Jiwon Kim, Jung Kwon Lee and Kyoung Mu Lee", "title": "Accurate Image Super-Resolution Using Very Deep Convolutional Networks", "comments": "CVPR 2016 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a highly accurate single-image super-resolution (SR) method. Our\nmethod uses a very deep convolutional network inspired by VGG-net used for\nImageNet classification \\cite{simonyan2015very}. We find increasing our network\ndepth shows a significant improvement in accuracy. Our final model uses 20\nweight layers. By cascading small filters many times in a deep network\nstructure, contextual information over large image regions is exploited in an\nefficient way. With very deep networks, however, convergence speed becomes a\ncritical issue during training. We propose a simple yet effective training\nprocedure. We learn residuals only and use extremely high learning rates\n($10^4$ times higher than SRCNN \\cite{dong2015image}) enabled by adjustable\ngradient clipping. Our proposed method performs better than existing methods in\naccuracy and visual improvements in our results are easily noticeable.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 17:36:45 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 08:40:47 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Kim", "Jiwon", ""], ["Lee", "Jung Kwon", ""], ["Lee", "Kyoung Mu", ""]]}, {"id": "1511.04599", "submitter": "Seyed-Mohsen Moosavi-Dezfooli", "authors": "Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard", "title": "DeepFool: a simple and accurate method to fool deep neural networks", "comments": "In Proceedings of IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art deep neural networks have achieved impressive results on\nmany image classification tasks. However, these same architectures have been\nshown to be unstable to small, well sought, perturbations of the images.\nDespite the importance of this phenomenon, no effective methods have been\nproposed to accurately compute the robustness of state-of-the-art deep\nclassifiers to such perturbations on large-scale datasets. In this paper, we\nfill this gap and propose the DeepFool algorithm to efficiently compute\nperturbations that fool deep networks, and thus reliably quantify the\nrobustness of these classifiers. Extensive experimental results show that our\napproach outperforms recent methods in the task of computing adversarial\nperturbations and making classifiers more robust.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 18:50:00 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2016 09:33:23 GMT"}, {"version": "v3", "created": "Mon, 4 Jul 2016 04:49:44 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Fawzi", "Alhussein", ""], ["Frossard", "Pascal", ""]]}, {"id": "1511.04636", "submitter": "Ji He", "authors": "Ji He, Jianshu Chen, Xiaodong He, Jianfeng Gao, Lihong Li, Li Deng,\n  Mari Ostendorf", "title": "Deep Reinforcement Learning with a Natural Language Action Space", "comments": "accepted by ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel architecture for reinforcement learning with\ndeep neural networks designed to handle state and action spaces characterized\nby natural language, as found in text-based games. Termed a deep reinforcement\nrelevance network (DRRN), the architecture represents action and state spaces\nwith separate embedding vectors, which are combined with an interaction\nfunction to approximate the Q-function in reinforcement learning. We evaluate\nthe DRRN on two popular text games, showing superior performance over other\ndeep Q-learning architectures. Experiments with paraphrased action descriptions\nshow that the model is extracting meaning rather than simply memorizing strings\nof text.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 23:30:39 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 20:24:12 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2016 01:51:20 GMT"}, {"version": "v4", "created": "Sat, 16 Jan 2016 23:43:40 GMT"}, {"version": "v5", "created": "Wed, 8 Jun 2016 05:58:34 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["He", "Ji", ""], ["Chen", "Jianshu", ""], ["He", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Li", "Lihong", ""], ["Deng", "Li", ""], ["Ostendorf", "Mari", ""]]}, {"id": "1511.04664", "submitter": "Mohammad Abu Alsheikh", "authors": "Mohammad Abu Alsheikh, Ahmed Selim, Dusit Niyato, Linda Doyle, Shaowei\n  Lin, Hwee-Pink Tan", "title": "Deep Activity Recognition Models with Triaxial Accelerometers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread installation of accelerometers in almost all mobile\nphones and wearable devices, activity recognition using accelerometers is still\nimmature due to the poor recognition accuracy of existing recognition methods\nand the scarcity of labeled training data. We consider the problem of human\nactivity recognition using triaxial accelerometers and deep learning paradigms.\nThis paper shows that deep activity recognition models (a) provide better\nrecognition accuracy of human activities, (b) avoid the expensive design of\nhandcrafted features in existing systems, and (c) utilize the massive unlabeled\nacceleration samples for unsupervised feature extraction. Moreover, a hybrid\napproach of deep learning and hidden Markov models (DL-HMM) is presented for\nsequential activity recognition. This hybrid approach integrates the\nhierarchical representations of deep activity recognition models with the\nstochastic modeling of temporal sequences in the hidden Markov models. We show\nsubstantial recognition improvement on real world datasets over\nstate-of-the-art methods of human activity recognition using triaxial\naccelerometers.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 06:23:40 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 07:39:29 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Alsheikh", "Mohammad Abu", ""], ["Selim", "Ahmed", ""], ["Niyato", "Dusit", ""], ["Doyle", "Linda", ""], ["Lin", "Shaowei", ""], ["Tan", "Hwee-Pink", ""]]}, {"id": "1511.04690", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Rongmei Lin, Meng Yang", "title": "Robust Elastic Net Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust elastic net (REN) model for high-dimensional sparse\nregression and give its performance guarantees (both the statistical error\nbound and the optimization bound). A simple idea of trimming the inner product\nis applied to the elastic net model. Specifically, we robustify the covariance\nmatrix by trimming the inner product based on the intuition that the trimmed\ninner product can not be significant affected by a bounded number of\narbitrarily corrupted points (outliers). The REN model can also derive two\ninteresting special cases: robust Lasso and robust soft thresholding.\nComprehensive experimental results show that the robustness of the proposed\nmodel consistently outperforms the original elastic net and matches the\nperformance guarantees nicely.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 12:17:00 GMT"}, {"version": "v2", "created": "Sun, 1 May 2016 18:03:05 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Liu", "Weiyang", ""], ["Lin", "Rongmei", ""], ["Yang", "Meng", ""]]}, {"id": "1511.04695", "submitter": "Linxiao Yang", "authors": "Linxiao Yang and Jun Fang and Hongbin Li and Bing Zeng", "title": "An Iterative Reweighted Method for Tucker Decomposition of Incomplete\n  Multiway Tensors", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2572047", "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of low-rank decomposition of incomplete multiway\ntensors. Since many real-world data lie on an intrinsically low dimensional\nsubspace, tensor low-rank decomposition with missing entries has applications\nin many data analysis problems such as recommender systems and image\ninpainting. In this paper, we focus on Tucker decomposition which represents an\nNth-order tensor in terms of N factor matrices and a core tensor via\nmultilinear operations. To exploit the underlying multilinear low-rank\nstructure in high-dimensional datasets, we propose a group-based log-sum\npenalty functional to place structural sparsity over the core tensor, which\nleads to a compact representation with smallest core tensor. The method for\nTucker decomposition is developed by iteratively minimizing a surrogate\nfunction that majorizes the original objective function, which results in an\niterative reweighted process. In addition, to reduce the computational\ncomplexity, an over-relaxed monotone fast iterative shrinkage-thresholding\ntechnique is adapted and embedded in the iterative reweighted process. The\nproposed method is able to determine the model complexity (i.e. multilinear\nrank) in an automatic way. Simulation results show that the proposed algorithm\noffers competitive performance compared with other existing algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 12:56:36 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Yang", "Linxiao", ""], ["Fang", "Jun", ""], ["Li", "Hongbin", ""], ["Zeng", "Bing", ""]]}, {"id": "1511.04707", "submitter": "Matthias Dorfer", "authors": "Matthias Dorfer, Rainer Kelz and Gerhard Widmer", "title": "Deep Linear Discriminant Analysis", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Linear Discriminant Analysis (DeepLDA) which learns\nlinearly separable latent representations in an end-to-end fashion. Classic LDA\nextracts features which preserve class separability and is used for\ndimensionality reduction for many classification problems. The central idea of\nthis paper is to put LDA on top of a deep neural network. This can be seen as a\nnon-linear extension of classic LDA. Instead of maximizing the likelihood of\ntarget labels for individual samples, we propose an objective function that\npushes the network to produce feature distributions which: (a) have low\nvariance within the same class and (b) high variance between different classes.\nOur objective is derived from the general LDA eigenvalue problem and still\nallows to train with stochastic gradient descent and back-propagation. For\nevaluation we test our approach on three different benchmark datasets (MNIST,\nCIFAR-10 and STL-10). DeepLDA produces competitive results on MNIST and\nCIFAR-10 and outperforms a network trained with categorical cross entropy (same\narchitecture) on a supervised setting of STL-10.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 14:33:26 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 08:05:10 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2015 17:59:18 GMT"}, {"version": "v4", "created": "Mon, 28 Dec 2015 09:52:47 GMT"}, {"version": "v5", "created": "Wed, 17 Feb 2016 08:32:47 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Dorfer", "Matthias", ""], ["Kelz", "Rainer", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1511.04747", "submitter": "Sayan Ghosh", "authors": "Sayan Ghosh, Eugene Laksana, Louis-Philippe Morency, Stefan Scherer", "title": "Learning Representations of Affect from Speech", "comments": "This is a submission for the ICLR (International Conference on\n  Learning Representations) Workshop 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a lot of prior work on representation learning for speech\nrecognition applications, but not much emphasis has been given to an\ninvestigation of effective representations of affect from speech, where the\nparalinguistic elements of speech are separated out from the verbal content. In\nthis paper, we explore denoising autoencoders for learning paralinguistic\nattributes i.e. categorical and dimensional affective traits from speech. We\nshow that the representations learnt by the bottleneck layer of the autoencoder\nare highly discriminative of activation intensity and at separating out\nnegative valence (sadness and anger) from positive valence (happiness). We\nexperiment with different input speech features (such as FFT and log-mel\nspectrograms with temporal context windows), and different autoencoder\narchitectures (such as stacked and deep autoencoders). We also learn utterance\nspecific representations by a combination of denoising autoencoders and BLSTM\nbased recurrent autoencoders. Emotion classification is performed with the\nlearnt temporal/dynamic representations to evaluate the quality of the\nrepresentations. Experiments on a well-established real-life speech dataset\n(IEMOCAP) show that the learnt representations are comparable to state of the\nart feature extractors (such as voice quality features and MFCCs) and are\ncompetitive with state-of-the-art approaches at emotion and dimensional affect\nrecognition.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 18:16:20 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 01:37:01 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2016 20:44:51 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2016 20:36:36 GMT"}, {"version": "v5", "created": "Tue, 19 Jan 2016 04:05:50 GMT"}, {"version": "v6", "created": "Sun, 14 Feb 2016 18:11:46 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Ghosh", "Sayan", ""], ["Laksana", "Eugene", ""], ["Morency", "Louis-Philippe", ""], ["Scherer", "Stefan", ""]]}, {"id": "1511.04773", "submitter": "Weiran Wang", "authors": "Weiran Wang, Karen Livescu", "title": "Large-Scale Approximate Kernel Canonical Correlation Analysis", "comments": "Published as a conference paper at International Conference on\n  Learning Representations (ICLR) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel canonical correlation analysis (KCCA) is a nonlinear multi-view\nrepresentation learning technique with broad applicability in statistics and\nmachine learning. Although there is a closed-form solution for the KCCA\nobjective, it involves solving an $N\\times N$ eigenvalue system where $N$ is\nthe training set size, making its computational requirements in both memory and\ntime prohibitive for large-scale problems. Various approximation techniques\nhave been developed for KCCA. A commonly used approach is to first transform\nthe original inputs to an $M$-dimensional random feature space so that inner\nproducts in the feature space approximate kernel evaluations, and then apply\nlinear CCA to the transformed inputs. In many applications, however, the\ndimensionality $M$ of the random feature space may need to be very large in\norder to obtain a sufficiently good approximation; it then becomes challenging\nto perform the linear CCA step on the resulting very high-dimensional data\nmatrices. We show how to use a stochastic optimization algorithm, recently\nproposed for linear CCA and its neural-network extension, to further alleviate\nthe computation requirements of approximate KCCA. This approach allows us to\nrun approximate KCCA on a speech dataset with $1.4$ million training samples\nand a random feature space of dimensionality $M=100000$ on a typical\nworkstation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 22:20:02 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 16:31:14 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 00:27:20 GMT"}, {"version": "v4", "created": "Mon, 29 Feb 2016 16:04:46 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Wang", "Weiran", ""], ["Livescu", "Karen", ""]]}, {"id": "1511.04775", "submitter": "Cyril Stark", "authors": "Cyril Stark", "title": "Expressive recommender systems through normalized nonnegative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce normalized nonnegative models (NNM) for explorative data\nanalysis. NNMs are partial convexifications of models from probability theory.\nWe demonstrate their value at the example of item recommendation. We show that\nNNM-based recommender systems satisfy three criteria that all recommender\nsystems should ideally satisfy: high predictive power, computational\ntractability, and expressive representations of users and items. Expressive\nuser and item representations are important in practice to succinctly summarize\nthe pool of customers and the pool of items. In NNMs, user representations are\nexpressive because each user's preference can be regarded as normalized mixture\nof preferences of stereotypical users. The interpretability of item and user\nrepresentations allow us to arrange properties of items (e.g., genres of movies\nor topics of documents) or users (e.g., personality traits) hierarchically.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 22:39:58 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Stark", "Cyril", ""]]}, {"id": "1511.04776", "submitter": "Marc Goessling", "authors": "Marc Goessling, Yali Amit", "title": "Mixtures of Sparse Autoregressive Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high-dimensional distribution estimation through autoregressive\nnetworks. By combining the concepts of sparsity, mixtures and parameter sharing\nwe obtain a simple model which is fast to train and which achieves\nstate-of-the-art or better results on several standard benchmark datasets.\nSpecifically, we use an L1-penalty to regularize the conditional distributions\nand introduce a procedure for automatic parameter sharing between mixture\ncomponents. Moreover, we propose a simple distributed representation which\npermits exact likelihood evaluations since the latent variables are interleaved\nwith the observable variables and can be easily integrated out. Our model\nachieves excellent generalization performance and scales well to extremely high\ndimensions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 22:54:02 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 04:21:25 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 05:01:11 GMT"}, {"version": "v4", "created": "Tue, 26 Apr 2016 23:12:32 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Goessling", "Marc", ""], ["Amit", "Yali", ""]]}, {"id": "1511.04780", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Timm Meyer, Ozan \\\"Ozdenizci, Bernhard\n  Sch\\\"olkopf, Tonio Ball, Moritz Grosse-Wentrup", "title": "Causal interpretation rules for encoding and decoding models in\n  neuroimaging", "comments": "accepted manuscript", "journal-ref": "NeuroImage, 110:48-59, 2015", "doi": "10.1016/j.neuroimage.2015.01.036", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal terminology is often introduced in the interpretation of encoding and\ndecoding models trained on neuroimaging data. In this article, we investigate\nwhich causal statements are warranted and which ones are not supported by\nempirical evidence. We argue that the distinction between encoding and decoding\nmodels is not sufficient for this purpose: relevant features in encoding and\ndecoding models carry a different meaning in stimulus- and in response-based\nexperimental paradigms. We show that only encoding models in the stimulus-based\nsetting support unambiguous causal interpretations. By combining encoding and\ndecoding models trained on the same data, however, we obtain insights into\ncausal relations beyond those that are implied by each individual model type.\nWe illustrate the empirical relevance of our theoretical findings on EEG data\nrecorded during a visuo-motor learning task.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 23:16:10 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Meyer", "Timm", ""], ["\u00d6zdenizci", "Ozan", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Ball", "Tonio", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1511.04813", "submitter": "Jing Lu", "authors": "Jing Lu, Steven C.H. Hoi, Doyen Sahoo, Peilin Zhao", "title": "Budget Online Multiple Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning with multiple kernels has gained increasing interests in\nrecent years and found many applications. For classification tasks, Online\nMultiple Kernel Classification (OMKC), which learns a kernel based classifier\nby seeking the optimal linear combination of a pool of single kernel\nclassifiers in an online fashion, achieves superior accuracy and enjoys great\nflexibility compared with traditional single-kernel classifiers. Despite being\nstudied extensively, existing OMKC algorithms suffer from high computational\ncost due to their unbounded numbers of support vectors. To overcome this\ndrawback, we present a novel framework of Budget Online Multiple Kernel\nLearning (BOMKL) and propose a new Sparse Passive Aggressive learning to\nperform effective budget online learning. Specifically, we adopt a simple yet\neffective Bernoulli sampling to decide if an incoming instance should be added\nto the current set of support vectors. By limiting the number of support\nvectors, our method can significantly accelerate OMKC while maintaining\nsatisfactory accuracy that is comparable to that of the existing OMKC\nalgorithms. We theoretically prove that our new method achieves an optimal\nregret bound in expectation, and empirically found that the proposed algorithm\noutperforms various OMKC algorithms and can easily scale up to large-scale\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 03:40:50 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 08:08:43 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Lu", "Jing", ""], ["Hoi", "Steven C. H.", ""], ["Sahoo", "Doyen", ""], ["Zhao", "Peilin", ""]]}, {"id": "1511.04834", "submitter": "Arvind Neelakantan", "authors": "Arvind Neelakantan, Quoc V. Le, Ilya Sutskever", "title": "Neural Programmer: Inducing Latent Programs with Gradient Descent", "comments": "Accepted as a conference paper at ICLR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive supervised classification\nperformance in many tasks including image recognition, speech recognition, and\nsequence to sequence learning. However, this success has not been translated to\napplications like question answering that may involve complex arithmetic and\nlogic reasoning. A major limitation of these models is in their inability to\nlearn even simple arithmetic and logic operations. For example, it has been\nshown that neural networks fail to learn to add two binary numbers reliably. In\nthis work, we propose Neural Programmer, an end-to-end differentiable neural\nnetwork augmented with a small set of basic arithmetic and logic operations.\nNeural Programmer can call these augmented operations over several steps,\nthereby inducing compositional programs that are more complex than the built-in\noperations. The model learns from a weak supervision signal which is the result\nof execution of the correct program, hence it does not require expensive\nannotation of the correct program itself. The decisions of what operations to\ncall, and what data segments to apply to are inferred by Neural Programmer.\nSuch decisions, during training, are done in a differentiable fashion so that\nthe entire network can be trained jointly by gradient descent. We find that\ntraining the model is difficult, but it can be greatly improved by adding\nrandom noise to the gradient. On a fairly complex synthetic table-comprehension\ndataset, traditional recurrent networks and attentional models perform poorly\nwhile Neural Programmer typically obtains nearly perfect accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 06:03:58 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 07:00:28 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2016 18:23:03 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Neelakantan", "Arvind", ""], ["Le", "Quoc V.", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1511.04839", "submitter": "Weiran Wang", "authors": "Tomer Michaeli, Weiran Wang, Karen Livescu", "title": "Nonparametric Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical correlation analysis (CCA) is a classical representation learning\ntechnique for finding correlated variables in multi-view data. Several\nnonlinear extensions of the original linear CCA have been proposed, including\nkernel and deep neural network methods. These approaches seek maximally\ncorrelated projections among families of functions, which the user specifies\n(by choosing a kernel or neural network structure), and are computationally\ndemanding. Interestingly, the theory of nonlinear CCA, without functional\nrestrictions, had been studied in the population setting by Lancaster already\nin the 1950s, but these results have not inspired practical algorithms. We\nrevisit Lancaster's theory to devise a practical algorithm for nonparametric\nCCA (NCCA). Specifically, we show that the solution can be expressed in terms\nof the singular value decomposition of a certain operator associated with the\njoint density of the views. Thus, by estimating the population density from\ndata, NCCA reduces to solving an eigenvalue system, superficially like kernel\nCCA but, importantly, without requiring the inversion of any kernel matrix. We\nalso derive a partially linear CCA (PLCCA) variant in which one of the views\nundergoes a linear projection while the other is nonparametric. Using a kernel\ndensity estimate based on a small number of nearest neighbors, our NCCA and\nPLCCA algorithms are memory-efficient, often run much faster, and perform\nbetter than kernel CCA and comparable to deep CCA.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 06:25:59 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 16:26:17 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2016 15:16:00 GMT"}, {"version": "v4", "created": "Sun, 7 Feb 2016 16:11:45 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Michaeli", "Tomer", ""], ["Wang", "Weiran", ""], ["Livescu", "Karen", ""]]}, {"id": "1511.04855", "submitter": "Marc Chaumont", "authors": "Lionel Pibre, Pasquet J\\'er\\^ome, Dino Ienco, Marc Chaumont", "title": "Deep learning is a good steganalysis tool when embedding key is reused\n  for different images, even if there is a cover source-mismatch", "comments": "IS&T. Media Watermarking, Security, and Forensics, Part of IS&T\n  International Symposium on Electronic Imaging, EI'2016, Feb 2015, San\n  Fransisco, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the BOSS competition, in 2010, most steganalysis approaches use a\nlearning methodology involving two steps: feature extraction, such as the Rich\nModels (RM), for the image representation, and use of the Ensemble Classifier\n(EC) for the learning step. In 2015, Qian et al. have shown that the use of a\ndeep learning approach that jointly learns and computes the features, is very\npromising for the steganalysis. In this paper, we follow-up the study of Qian\net al., and show that, due to intrinsic joint minimization, the results\nobtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural\nNetwork (FNN), if well parameterized, surpass the conventional use of a RM with\nan EC. First, numerous experiments were conducted in order to find the best \"\nshape \" of the CNN. Second, experiments were carried out in the clairvoyant\nscenario in order to compare the CNN and FNN to an RM with an EC. The results\nshow more than 16% reduction in the classification error with our CNN or FNN.\nThird, experiments were also performed in a cover-source mismatch setting. The\nresults show that the CNN and FNN are naturally robust to the mismatch problem.\nIn Addition to the experiments, we provide discussions on the internal\nmechanisms of a CNN, and weave links with some previously stated ideas, in\norder to understand the impressive results we obtained.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 07:59:14 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 07:49:46 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Pibre", "Lionel", ""], ["J\u00e9r\u00f4me", "Pasquet", ""], ["Ienco", "Dino", ""], ["Chaumont", "Marc", ""]]}, {"id": "1511.04868", "submitter": "Navdeep Jaitly", "authors": "Navdeep Jaitly, David Sussillo, Quoc V. Le, Oriol Vinyals, Ilya\n  Sutskever and Samy Bengio", "title": "A Neural Transducer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence models have achieved impressive results on various\ntasks. However, they are unsuitable for tasks that require incremental\npredictions to be made as more data arrives or tasks that have long input\nsequences and output sequences. This is because they generate an output\nsequence conditioned on an entire input sequence. In this paper, we present a\nNeural Transducer that can make incremental predictions as more input arrives,\nwithout redoing the entire computation. Unlike sequence-to-sequence models, the\nNeural Transducer computes the next-step distribution conditioned on the\npartially observed input sequence and the partially generated sequence. At each\ntime step, the transducer can decide to emit zero to many output symbols. The\ndata can be processed using an encoder and presented as input to the\ntransducer. The discrete decision to emit a symbol at every time step makes it\ndifficult to learn with conventional backpropagation. It is however possible to\ntrain the transducer by using a dynamic programming algorithm to generate\ntarget discrete decisions. Our experiments show that the Neural Transducer\nworks well in settings where it is required to produce output predictions as\ndata come in. We also find that the Neural Transducer performs well for long\nsequences even when attention mechanisms are not used.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 08:53:44 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 19:56:58 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2015 19:27:14 GMT"}, {"version": "v4", "created": "Thu, 4 Aug 2016 23:31:46 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Jaitly", "Navdeep", ""], ["Sussillo", "David", ""], ["Le", "Quoc V.", ""], ["Vinyals", "Oriol", ""], ["Sutskever", "Ilya", ""], ["Bengio", "Samy", ""]]}, {"id": "1511.04891", "submitter": "Mohamed Elhoseiny Mohamed Elhoseiny", "authors": "Mohamed Elhoseiny, Scott Cohen, Walter Chang, Brian Price, Ahmed\n  Elgammal", "title": "Sherlock: Scalable Fact Learning in Images", "comments": "Jan 7 Update", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study scalable and uniform understanding of facts in images. Existing\nvisual recognition systems are typically modeled differently for each fact type\nsuch as objects, actions, and interactions. We propose a setting where all\nthese facts can be modeled simultaneously with a capacity to understand\nunbounded number of facts in a structured way. The training data comes as\nstructured facts in images, including (1) objects (e.g., $<$boy$>$), (2)\nattributes (e.g., $<$boy, tall$>$), (3) actions (e.g., $<$boy, playing$>$), and\n(4) interactions (e.g., $<$boy, riding, a horse $>$). Each fact has a semantic\nlanguage view (e.g., $<$ boy, playing$>$) and a visual view (an image with this\nfact). We show that learning visual facts in a structured way enables not only\na uniform but also generalizable visual understanding. We propose and\ninvestigate recent and strong approaches from the multiview learning literature\nand also introduce two learning representation models as potential baselines.\nWe applied the investigated methods on several datasets that we augmented with\nstructured facts and a large scale dataset of more than 202,000 facts and\n814,000 images. Our experiments show the advantage of relating facts by the\nstructure by the proposed models compared to the designed baselines on\nbidirectional fact retrieval.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 09:56:04 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 22:36:55 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 02:56:24 GMT"}, {"version": "v4", "created": "Sat, 2 Apr 2016 05:26:39 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Elhoseiny", "Mohamed", ""], ["Cohen", "Scott", ""], ["Chang", "Walter", ""], ["Price", "Brian", ""], ["Elgammal", "Ahmed", ""]]}, {"id": "1511.04906", "submitter": "Jaime Zaratiegui", "authors": "Jaime Zaratiegui, Ana Montoro and Federico Castanedo", "title": "Performing Highly Accurate Predictions Through Convolutional Networks\n  for Actual Telecommunication Challenges", "comments": "11 pages, 6 figures, accepted by IJCAI-16 Workshop on Deep Learning\n  for Artificial Intelligence (DLAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated how the application of deep learning, specifically the use of\nconvolutional networks trained with GPUs, can help to build better predictive\nmodels in telecommunication business environments, and fill this gap. In\nparticular, we focus on the non-trivial problem of predicting customer churn in\ntelecommunication operators. Our model, called WiseNet, consists of a\nconvolutional network and a novel encoding method that transforms customer\nactivity data and Call Detail Records (CDRs) into images. Experimental\nevaluation with several machine learning classifiers supports the ability of\nWiseNet for learning features when using structured input data. For this type\nof telecommunication business problems, we found that WiseNet outperforms\nmachine learning models with hand-crafted features, and does not require the\nlabor-intensive step of feature engineering. Furthermore, the same model has\nbeen applied without retraining to a different market, achieving consistent\nresults. This confirms the generalization property of WiseNet and the ability\nto extract useful representations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 10:42:08 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 18:36:24 GMT"}, {"version": "v3", "created": "Thu, 14 Jul 2016 10:21:47 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Zaratiegui", "Jaime", ""], ["Montoro", "Ana", ""], ["Castanedo", "Federico", ""]]}, {"id": "1511.04986", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, Aleksandar Matic, Josep Luis Arcos, Alexandros\n  Karatzoglou", "title": "A genetic algorithm to discover flexible motifs with support", "comments": "9 pages, 8 figures, code available at\n  https://github.com/joansj/genmotif", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding repeated patterns or motifs in a time series is an important\nunsupervised task that has still a number of open issues, starting by the\ndefinition of motif. In this paper, we revise the notion of motif support,\ncharacterizing it as the number of patterns or repetitions that define a motif.\nWe then propose GENMOTIF, a genetic algorithm to discover motifs with support\nwhich, at the same time, is flexible enough to accommodate other motif\nspecifications and task characteristics. GENMOTIF is an anytime algorithm that\neasily adapts to many situations: searching in a range of segment lengths,\napplying uniform scaling, dealing with multiple dimensions, using different\nsimilarity and grouping criteria, etc. GENMOTIF is also parameter-friendly: it\nhas only two intuitive parameters which, if set within reasonable bounds, do\nnot substantially affect its performance. We demonstrate the value of our\napproach in a number of synthetic and real-world settings, considering traffic\nvolume measurements, accelerometer signals, and telephone call records.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 15:14:56 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 15:26:45 GMT"}, {"version": "v3", "created": "Tue, 28 Jun 2016 10:12:05 GMT"}, {"version": "v4", "created": "Mon, 5 Dec 2016 13:21:21 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Matic", "Aleksandar", ""], ["Arcos", "Josep Luis", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1511.05042", "submitter": "Alexandre de Br\\'ebisson", "authors": "Alexandre de Br\\'ebisson and Pascal Vincent", "title": "An Exploration of Softmax Alternatives Belonging to the Spherical Loss\n  Family", "comments": "Published at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multi-class classification problem, it is standard to model the output\nof a neural network as a categorical distribution conditioned on the inputs.\nThe output must therefore be positive and sum to one, which is traditionally\nenforced by a softmax. This probabilistic mapping allows to use the maximum\nlikelihood principle, which leads to the well-known log-softmax loss. However\nthe choice of the softmax function seems somehow arbitrary as there are many\nother possible normalizing functions. It is thus unclear why the log-softmax\nloss would perform better than other loss alternatives. In particular Vincent\net al. (2015) recently introduced a class of loss functions, called the\nspherical family, for which there exists an efficient algorithm to compute the\nupdates of the output weights irrespective of the output size. In this paper,\nwe explore several loss functions from this family as possible alternatives to\nthe traditional log-softmax. In particular, we focus our investigation on\nspherical bounds of the log-softmax loss and on two spherical log-likelihood\nlosses, namely the log-Spherical Softmax suggested by Vincent et al. (2015) and\nthe log-Taylor Softmax that we introduce. Although these alternatives do not\nyield as good results as the log-softmax loss on two language modeling tasks,\nthey surprisingly outperform it in our experiments on MNIST and CIFAR-10,\nsuggesting that they might be relevant in a broad range of applications.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 17:15:51 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 21:36:50 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2016 13:22:44 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["de Br\u00e9bisson", "Alexandre", ""], ["Vincent", "Pascal", ""]]}, {"id": "1511.05077", "submitter": "Zelda Mariet", "authors": "Zelda Mariet, Suvrit Sra", "title": "Diversity Networks: Neural Network Compression Using Determinantal Point\n  Processes", "comments": "This paper appeared under the shorter title Diversity Networks at\n  ICLR 2016\n  (http://www.iclr.cc/doku.php?id=iclr2016:main#accepted_papers_conference_track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce Divnet, a flexible technique for learning networks with diverse\nneurons. Divnet models neuronal diversity by placing a Determinantal Point\nProcess (DPP) over neurons in a given layer. It uses this DPP to select a\nsubset of diverse neurons and subsequently fuses the redundant neurons into the\nselected ones. Compared with previous approaches, Divnet offers a more\nprincipled, flexible technique for capturing neuronal diversity and thus\nimplicitly enforcing regularization. This enables effective auto-tuning of\nnetwork architecture and leads to smaller network sizes without hurting\nperformance. Moreover, through its focus on diversity and neuron fusing, Divnet\nremains compatible with other procedures that seek to reduce memory footprints\nof networks. We present experimental results to corroborate our claims: for\npruning neural networks, Divnet is seen to be notably superior to competing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 18:28:10 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 02:22:30 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 17:55:06 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2016 18:14:16 GMT"}, {"version": "v5", "created": "Wed, 3 Feb 2016 16:37:39 GMT"}, {"version": "v6", "created": "Tue, 18 Apr 2017 20:33:53 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Mariet", "Zelda", ""], ["Sra", "Suvrit", ""]]}, {"id": "1511.05082", "submitter": "Yehezkel Resheff", "authors": "Yehezkel S. Resheff, Shay Rotics, Ran Nathan, Daphna Weinshall", "title": "Topic Modeling of Behavioral Modes Using Sensor Data", "comments": "Invited Extended version of a paper \\cite{resheffmatrix} presented at\n  the international conference \\textit{Data Science and Advanced Analytics},\n  Paris, France, 19-21 OCtober 2015", "journal-ref": "International Journal of Data Science and Analytics 1.1 (2016):\n  51-60", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Movement Ecology, like so many other fields, is experiencing a\nperiod of rapid growth in availability of data. As the volume rises,\ntraditional methods are giving way to machine learning and data science, which\nare playing an increasingly large part it turning this data into\nscience-driving insights. One rich and interesting source is the bio-logger.\nThese small electronic wearable devices are attached to animals free to roam in\ntheir natural habitats, and report back readings from multiple sensors,\nincluding GPS and accelerometer bursts. A common use of accelerometer data is\nfor supervised learning of behavioral modes. However, we need unsupervised\nanalysis tools as well, in order to overcome the inherent difficulties of\nobtaining a labeled dataset, which in some cases is either infeasible or does\nnot successfully encompass the full repertoire of behavioral modes of interest.\nHere we present a matrix factorization based topic-model method for\naccelerometer bursts, derived using a linear mixture property of patch\nfeatures. Our method is validated via comparison to a labeled dataset, and is\nfurther compared to standard clustering algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 18:42:04 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Resheff", "Yehezkel S.", ""], ["Rotics", "Shay", ""], ["Nathan", "Ran", ""], ["Weinshall", "Daphna", ""]]}, {"id": "1511.05099", "submitter": "Peng Zhang", "authors": "Peng Zhang, Yash Goyal, Douglas Summers-Stay, Dhruv Batra, Devi Parikh", "title": "Yin and Yang: Balancing and Answering Binary Visual Questions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complex compositional structure of language makes problems at the\nintersection of vision and language challenging. But language also provides a\nstrong prior that can result in good superficial performance, without the\nunderlying models truly understanding the visual content. This can hinder\nprogress in pushing state of art in the computer vision aspects of multi-modal\nAI. In this paper, we address binary Visual Question Answering (VQA) on\nabstract scenes. We formulate this problem as visual verification of concepts\ninquired in the questions. Specifically, we convert the question to a tuple\nthat concisely summarizes the visual concept to be detected in the image. If\nthe concept can be found in the image, the answer to the question is \"yes\", and\notherwise \"no\". Abstract scenes play two roles (1) They allow us to focus on\nthe high-level semantics of the VQA task as opposed to the low-level\nrecognition problems, and perhaps more importantly, (2) They provide us the\nmodality to balance the dataset such that language priors are controlled, and\nthe role of vision is essential. In particular, we collect fine-grained pairs\nof scenes for every question, such that the answer to the question is \"yes\" for\none scene, and \"no\" for the other for the exact same question. Indeed, language\npriors alone do not perform better than chance on our balanced dataset.\nMoreover, our proposed approach matches the performance of a state-of-the-art\nVQA approach on the unbalanced dataset, and outperforms it on the balanced\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 19:38:14 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 20:54:47 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2015 20:54:35 GMT"}, {"version": "v4", "created": "Sun, 31 Jan 2016 20:58:39 GMT"}, {"version": "v5", "created": "Tue, 19 Apr 2016 19:30:00 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Zhang", "Peng", ""], ["Goyal", "Yash", ""], ["Summers-Stay", "Douglas", ""], ["Batra", "Dhruv", ""], ["Parikh", "Devi", ""]]}, {"id": "1511.05101", "submitter": "Ferenc Husz\\'ar", "authors": "Ferenc Husz\\'ar", "title": "How (not) to Train your Generative Model: Scheduled Sampling,\n  Likelihood, Adversary?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern applications and progress in deep learning research have created\nrenewed interest for generative models of text and of images. However, even\ntoday it is unclear what objective functions one should use to train and\nevaluate these models. In this paper we present two contributions.\n  Firstly, we present a critique of scheduled sampling, a state-of-the-art\ntraining method that contributed to the winning entry to the MSCOCO image\ncaptioning benchmark in 2015. Here we show that despite this impressive\nempirical performance, the objective function underlying scheduled sampling is\nimproper and leads to an inconsistent learning algorithm.\n  Secondly, we revisit the problems that scheduled sampling was meant to\naddress, and present an alternative interpretation. We argue that maximum\nlikelihood is an inappropriate training objective when the end-goal is to\ngenerate natural-looking samples. We go on to derive an ideal objective\nfunction to use in this situation instead. We introduce a generalisation of\nadversarial training, and show how such method can interpolate between maximum\nlikelihood training and our ideal training objective. To our knowledge this is\nthe first theoretical analysis that explains why adversarial training tends to\nproduce samples with higher perceived quality.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 19:43:19 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Husz\u00e1r", "Ferenc", ""]]}, {"id": "1511.05102", "submitter": "Denise Reeves PhD", "authors": "Denise M. Reeves", "title": "Resolving the Geometric Locus Dilemma for Support Vector Learning\n  Machines", "comments": "170 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capacity control, the bias/variance dilemma, and learning unknown functions\nfrom data, are all concerned with identifying effective and consistent fits of\nunknown geometric loci to random data points. A geometric locus is a curve or\nsurface formed by points, all of which possess some uniform property. A\ngeometric locus of an algebraic equation is the set of points whose coordinates\nare solutions of the equation. Any given curve or surface must pass through\neach point on a specified locus. This paper argues that it is impossible to fit\nrandom data points to algebraic equations of partially configured geometric\nloci that reference arbitrary Cartesian coordinate systems. It also argues that\nthe fundamental curve of a linear decision boundary is actually a principal\neigenaxis. It is shown that learning principal eigenaxes of linear decision\nboundaries involves finding a point of statistical equilibrium for which\neigenenergies of principal eigenaxis components are symmetrically balanced with\neach other. It is demonstrated that learning linear decision boundaries\ninvolves strong duality relationships between a statistical eigenlocus of\nprincipal eigenaxis components and its algebraic forms, in primal and dual,\ncorrelated Hilbert spaces. Locus equations are introduced and developed that\ndescribe principal eigen-coordinate systems for lines, planes, and hyperplanes.\nThese equations are used to introduce and develop primal and dual statistical\neigenlocus equations of principal eigenaxes of linear decision boundaries.\nImportant generalizations for linear decision boundaries are shown to be\nencoded within a dual statistical eigenlocus of principal eigenaxis components.\nPrincipal eigenaxes of linear decision boundaries are shown to encode Bayes'\nlikelihood ratio for common covariance data and a robust likelihood ratio for\nall other data.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 19:44:54 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Reeves", "Denise M.", ""]]}, {"id": "1511.05118", "submitter": "Gilles Puy", "authors": "Gilles Puy, Nicolas Tremblay, R\\'emi Gribonval, Pierre Vandergheynst", "title": "Random sampling of bandlimited signals on graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of sampling k-bandlimited signals on graphs. We propose\ntwo sampling strategies that consist in selecting a small subset of nodes at\nrandom. The first strategy is non-adaptive, i.e., independent of the graph\nstructure, and its performance depends on a parameter called the graph\ncoherence. On the contrary, the second strategy is adaptive but yields optimal\nresults. Indeed, no more than O(k log(k)) measurements are sufficient to ensure\nan accurate and stable recovery of all k-bandlimited signals. This second\nstrategy is based on a careful choice of the sampling distribution, which can\nbe estimated quickly. Then, we propose a computationally efficient decoder to\nreconstruct k-bandlimited signals from their samples. We prove that it yields\naccurate reconstructions and that it is also stable to noise. Finally, we\nconduct several experiments to test these techniques.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 20:38:37 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 12:36:39 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Puy", "Gilles", ""], ["Tremblay", "Nicolas", ""], ["Gribonval", "R\u00e9mi", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1511.05121", "submitter": "Rahul Gopal Krishnan", "authors": "Rahul G. Krishnan, Uri Shalit, David Sontag", "title": "Deep Kalman Filters", "comments": "17 pages, 14 figures: Fixed typo in Fig. 1(b) and added reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman Filters are one of the most influential models of time-varying\nphenomena. They admit an intuitive probabilistic interpretation, have a simple\nfunctional form, and enjoy widespread adoption in a variety of disciplines.\nMotivated by recent variational methods for learning deep generative models, we\nintroduce a unified algorithm to efficiently learn a broad spectrum of Kalman\nfilters. Of particular interest is the use of temporal generative models for\ncounterfactual inference. We investigate the efficacy of such models for\ncounterfactual inference, and to that end we introduce the \"Healing MNIST\"\ndataset where long-term structure, noise and actions are applied to sequences\nof digits. We show the efficacy of our method for modeling this dataset. We\nfurther show how our model can be used for counterfactual inference for\npatients, based on electronic health record data of 8,000 patients over 4.5\nyears.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 20:46:38 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 20:47:00 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Krishnan", "Rahul G.", ""], ["Shalit", "Uri", ""], ["Sontag", "David", ""]]}, {"id": "1511.05122", "submitter": "Sara Sabour", "authors": "Sara Sabour, Yanshuai Cao, Fartash Faghri, David J. Fleet", "title": "Adversarial Manipulation of Deep Representations", "comments": "Accepted as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We show that the representation of an image in a deep neural network (DNN)\ncan be manipulated to mimic those of other natural images, with only minor,\nimperceptible perturbations to the original image. Previous methods for\ngenerating adversarial images focused on image perturbations designed to\nproduce erroneous class labels, while we concentrate on the internal layers of\nDNN representations. In this way our new class of adversarial images differs\nqualitatively from others. While the adversary is perceptually similar to one\nimage, its internal representation appears remarkably similar to a different\nimage, one from a different class, bearing little if any apparent similarity to\nthe input; they appear generic and consistent with the space of natural images.\nThis phenomenon raises questions about DNN representations, as well as the\nproperties of natural images themselves.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 20:48:20 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 21:00:44 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2015 20:56:44 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2015 21:03:14 GMT"}, {"version": "v5", "created": "Thu, 7 Jan 2016 20:59:55 GMT"}, {"version": "v6", "created": "Tue, 12 Jan 2016 20:51:51 GMT"}, {"version": "v7", "created": "Wed, 13 Jan 2016 20:57:33 GMT"}, {"version": "v8", "created": "Tue, 1 Mar 2016 20:51:06 GMT"}, {"version": "v9", "created": "Fri, 4 Mar 2016 20:21:24 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Sabour", "Sara", ""], ["Cao", "Yanshuai", ""], ["Faghri", "Fartash", ""], ["Fleet", "David J.", ""]]}, {"id": "1511.05133", "submitter": "Canyi Lu", "authors": "Canyi Lu, Huan Li, Zhouchen Lin, Shuicheng Yan", "title": "Fast Proximal Linearized Alternating Direction Method of Multiplier with\n  Parallel Splitting", "comments": "AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Augmented Lagragian Method (ALM) and Alternating Direction Method of\nMultiplier (ADMM) have been powerful optimization methods for general convex\nprogramming subject to linear constraint. We consider the convex problem whose\nobjective consists of a smooth part and a nonsmooth but simple part. We propose\nthe Fast Proximal Augmented Lagragian Method (Fast PALM) which achieves the\nconvergence rate $O(1/K^2)$, compared with $O(1/K)$ by the traditional PALM. In\norder to further reduce the per-iteration complexity and handle the\nmulti-blocks problem, we propose the Fast Proximal ADMM with Parallel Splitting\n(Fast PL-ADMM-PS) method. It also partially improves the rate related to the\nsmooth part of the objective function. Experimental results on both synthesized\nand real world data demonstrate that our fast methods significantly improve the\nprevious PALM and ADMM.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 13:14:42 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Lu", "Canyi", ""], ["Li", "Huan", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1511.05175", "submitter": "Mohamed Elhoseiny Mohamed Elhoseiny", "authors": "Mohamed Elhoseiny, Tarek El-Gaaly, Amr Bakry, Ahmed Elgammal", "title": "Convolutional Models for Joint Object Categorization and Pose Estimation", "comments": "only for workshop presentation at ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the task of Object Recognition, there exists a dichotomy between the\ncategorization of objects and estimating object pose, where the former\nnecessitates a view-invariant representation, while the latter requires a\nrepresentation capable of capturing pose information over different categories\nof objects. With the rise of deep architectures, the prime focus has been on\nobject category recognition. Deep learning methods have achieved wide success\nin this task. In contrast, object pose regression using these approaches has\nreceived relatively much less attention. In this paper we show how deep\narchitectures, specifically Convolutional Neural Networks (CNN), can be adapted\nto the task of simultaneous categorization and pose estimation of objects. We\ninvestigate and analyze the layers of various CNN models and extensively\ncompare between them with the goal of discovering how the layers of distributed\nrepresentations of CNNs represent object pose information and how this\ncontradicts with object category representations. We extensively experiment on\ntwo recent large and challenging multi-view datasets. Our models achieve better\nthan state-of-the-art performance on both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 21:08:22 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 23:17:11 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 23:40:23 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2016 22:41:19 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2016 23:54:23 GMT"}, {"version": "v6", "created": "Tue, 19 Apr 2016 17:56:34 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Elhoseiny", "Mohamed", ""], ["El-Gaaly", "Tarek", ""], ["Bakry", "Amr", ""], ["Elgammal", "Ahmed", ""]]}, {"id": "1511.05176", "submitter": "Shixiang Gu", "authors": "Shixiang Gu, Sergey Levine, Ilya Sutskever, Andriy Mnih", "title": "MuProp: Unbiased Backpropagation for Stochastic Neural Networks", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are powerful parametric models that can be trained\nefficiently using the backpropagation algorithm. Stochastic neural networks\ncombine the power of large parametric functions with that of graphical models,\nwhich makes it possible to learn very complex distributions. However, as\nbackpropagation is not directly applicable to stochastic networks that include\ndiscrete sampling operations within their computational graph, training such\nnetworks remains difficult. We present MuProp, an unbiased gradient estimator\nfor stochastic networks, designed to make this task easier. MuProp improves on\nthe likelihood-ratio estimator by reducing its variance using a control variate\nbased on the first-order Taylor expansion of a mean-field network. Crucially,\nunlike prior attempts at using backpropagation for training stochastic\nnetworks, the resulting estimator is unbiased and well behaved. Our experiments\non structured output prediction and discrete latent variable modeling\ndemonstrate that MuProp yields consistently good performance across a range of\ndifficult tasks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 21:08:25 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 21:44:35 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2016 20:36:21 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Gu", "Shixiang", ""], ["Levine", "Sergey", ""], ["Sutskever", "Ilya", ""], ["Mnih", "Andriy", ""]]}, {"id": "1511.05191", "submitter": "Mahdi Pakdaman Naeini", "authors": "Mahdi Pakdaman Naeini, Gregory F. Cooper", "title": "Binary Classifier Calibration using an Ensemble of Near Isotonic\n  Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning accurate probabilistic models from data is crucial in many practical\ntasks in data mining. In this paper we present a new non-parametric calibration\nmethod called \\textit{ensemble of near isotonic regression} (ENIR). The method\ncan be considered as an extension of BBQ, a recently proposed calibration\nmethod, as well as the commonly used calibration method based on isotonic\nregression. ENIR is designed to address the key limitation of isotonic\nregression which is the monotonicity assumption of the predictions. Similar to\nBBQ, the method post-processes the output of a binary classifier to obtain\ncalibrated probabilities. Thus it can be combined with many existing\nclassification models. We demonstrate the performance of ENIR on synthetic and\nreal datasets for the commonly used binary classification models. Experimental\nresults show that the method outperforms several common binary classifier\ncalibration methods. In particular on the real data, ENIR commonly performs\nstatistically significantly better than the other methods, and never worse. It\nis able to improve the calibration power of classifiers, while retaining their\ndiscrimination power. The method is also computationally tractable for large\nscale datasets, as it is $O(N \\log N)$ time, where $N$ is the number of\nsamples.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 21:46:40 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Naeini", "Mahdi Pakdaman", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1511.05194", "submitter": "Lingchen Zhu", "authors": "Lingchen Zhu, Entao Liu, James H. McClellan", "title": "Sparse-promoting Full Waveform Inversion based on Online Orthonormal\n  Dictionary Learning", "comments": "This paper has already been accepted by Geophysics", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Full waveform inversion (FWI) delivers high-resolution images of the\nsubsurface by minimizing iteratively the misfit between the recorded and\ncalculated seismic data. It has been attacked successfully with the\nGauss-Newton method and sparsity promoting regularization based on fixed\nmultiscale transforms that permit significant subsampling of the seismic data\nwhen the model perturbation at each FWI data-fitting iteration can be\nrepresented with sparse coefficients. Rather than using analytical transforms\nwith predefined dictionaries to achieve sparse representation, we introduce an\nadaptive transform called the Sparse Orthonormal Transform (SOT) whose\ndictionary is learned from many small training patches taken from the model\nperturbations in previous iterations. The patch-based dictionary is constrained\nto be orthonormal and trained with an online approach to provide the best\nsparse representation of the complex features and variations of the entire\nmodel perturbation. The complexity of the training method is proportional to\nthe cube of the number of samples in one small patch. By incorporating both\ncompressive subsampling and the adaptive SOT-based representation into the\nGauss-Newton least-squares problem for each FWI iteration, the model\nperturbation can be recovered after an l1-norm sparsity constraint is applied\non the SOT coefficients. Numerical experiments on synthetic models demonstrate\nthat the SOT-based sparsity promoting regularization can provide robust FWI\nresults with reduced computation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 21:50:48 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 02:04:52 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Zhu", "Lingchen", ""], ["Liu", "Entao", ""], ["McClellan", "James H.", ""]]}, {"id": "1511.05212", "submitter": "Anna Choromanska", "authors": "Anna Choromanska and Krzysztof Choromanski and Mariusz Bojarski and\n  Tony Jebara and Sanjiv Kumar and Yann LeCun", "title": "Binary embeddings with structured hashed projections", "comments": "arXiv admin note: text overlap with arXiv:1505.03190", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the hashing mechanism for constructing binary embeddings, that\ninvolves pseudo-random projections followed by nonlinear (sign function)\nmappings. The pseudo-random projection is described by a matrix, where not all\nentries are independent random variables but instead a fixed \"budget of\nrandomness\" is distributed across the matrix. Such matrices can be efficiently\nstored in sub-quadratic or even linear space, provide reduction in randomness\nusage (i.e. number of required random values), and very often lead to\ncomputational speed ups. We prove several theoretical results showing that\nprojections via various structured matrices followed by nonlinear mappings\naccurately preserve the angular distance between input high-dimensional\nvectors. To the best of our knowledge, these results are the first that give\ntheoretical ground for the use of general structured matrices in the nonlinear\nsetting. In particular, they generalize previous extensions of the\nJohnson-Lindenstrauss lemma and prove the plausibility of the approach that was\nso far only heuristically confirmed for some special structured matrices.\nConsequently, we show that many structured matrices can be used as an efficient\ninformation compression mechanism. Our findings build a better understanding of\ncertain deep architectures, which contain randomly weighted and untrained\nlayers, and yet achieve high performance on different learning tasks. We\nempirically verify our theoretical findings and show the dependence of learning\nvia structured hashed projections on the performance of neural network as well\nas nearest neighbor classifier.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 23:01:12 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2016 03:56:09 GMT"}, {"version": "v3", "created": "Tue, 24 May 2016 01:51:33 GMT"}, {"version": "v4", "created": "Tue, 31 May 2016 12:05:06 GMT"}, {"version": "v5", "created": "Fri, 1 Jul 2016 16:39:05 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Choromanska", "Anna", ""], ["Choromanski", "Krzysztof", ""], ["Bojarski", "Mariusz", ""], ["Jebara", "Tony", ""], ["Kumar", "Sanjiv", ""], ["LeCun", "Yann", ""]]}, {"id": "1511.05219", "submitter": "James Zou", "authors": "Daniel Russo and James Zou", "title": "How much does your data exploration overfit? Controlling bias via\n  information usage", "comments": "Accepted at IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data is messy and high-dimensional, and it is often not clear a priori\nwhat are the right questions to ask. Instead, the analyst typically needs to\nuse the data to search for interesting analyses to perform and hypotheses to\ntest. This is an adaptive process, where the choice of analysis to be performed\nnext depends on the results of the previous analyses on the same data.\nUltimately, which results are reported can be heavily influenced by the data.\nIt is widely recognized that this process, even if well-intentioned, can lead\nto biases and false discoveries, contributing to the crisis of reproducibility\nin science. But while %the adaptive nature of exploration any data-exploration\nrenders standard statistical theory invalid, experience suggests that different\ntypes of exploratory analysis can lead to disparate levels of bias, and the\ndegree of bias also depends on the particulars of the data set. In this paper,\nwe propose a general information usage framework to quantify and provably bound\nthe bias and other error metrics of an arbitrary exploratory analysis. We prove\nthat our mutual information based bound is tight in natural settings, and then\nuse it to give rigorous insights into when commonly used procedures do or do\nnot lead to substantially biased estimation. Through the lens of information\nusage, we analyze the bias of specific exploration procedures such as\nfiltering, rank selection and clustering. Our general framework also naturally\nmotivates randomization techniques that provably reduces exploration bias while\npreserving the utility of the data analysis. We discuss the connections between\nour approach and related ideas from differential privacy and blinded data\nanalysis, and supplement our results with illustrative simulations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 23:36:25 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 04:53:06 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 01:14:03 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Russo", "Daniel", ""], ["Zou", "James", ""]]}, {"id": "1511.05236", "submitter": "Patrick Judd", "authors": "Patrick Judd, Jorge Albericio, Tayler Hetherington, Tor Aamodt,\n  Natalie Enright Jerger, Raquel Urtasun, Andreas Moshovos", "title": "Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets", "comments": "Submitted to ICLR 2016, 12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates how using reduced precision data in Convolutional\nNeural Networks (CNNs) affects network accuracy during classification. More\nspecifically, this study considers networks where each layer may use different\nprecision data. Our key result is the observation that the tolerance of CNNs to\nreduced precision data not only varies across networks, a well established\nobservation, but also within networks. Tuning precision per layer is appealing\nas it could enable energy and performance improvements. In this paper we study\nhow error tolerance across layers varies and propose a method for finding a low\nprecision configuration for a network while maintaining high accuracy. A\ndiverse set of CNNs is analyzed showing that compared to a conventional\nimplementation using a 32-bit floating-point representation for all layers, and\nwith less than 1% loss in relative accuracy, the data footprint required by\nthese networks can be reduced by an average of 74% and up to 92%.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 01:03:03 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 20:38:17 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2015 00:20:48 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2016 07:22:41 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Judd", "Patrick", ""], ["Albericio", "Jorge", ""], ["Hetherington", "Tayler", ""], ["Aamodt", "Tor", ""], ["Jerger", "Natalie Enright", ""], ["Urtasun", "Raquel", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1511.05240", "submitter": "Richard Combes", "authors": "Richard Combes", "title": "An extension of McDiarmid's inequality", "comments": "Note (4 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an extension of McDiarmid's inequality for functions $f$ with\nbounded differences on a high probability set ${\\cal Y}$ (instead of almost\nsurely). The behavior of $f$ outside ${\\cal Y}$ may be arbitrary. The proof is\nshort and elementary, and relies on an extension argument similar to\nKirszbraun's theorem.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 01:14:51 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Combes", "Richard", ""]]}, {"id": "1511.05261", "submitter": "Zhao Kang", "authors": "Zhao Kang, Chong Peng, Qiang Cheng", "title": "Robust PCA via Nonconvex Rank Approximation", "comments": "IEEE International Conference on Data Mining", "journal-ref": null, "doi": "10.1109/ICDM.2015.15", "report-no": null, "categories": "cs.CV cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous applications in data mining and machine learning require recovering\na matrix of minimal rank. Robust principal component analysis (RPCA) is a\ngeneral framework for handling this kind of problems. Nuclear norm based convex\nsurrogate of the rank function in RPCA is widely investigated. Under certain\nassumptions, it can recover the underlying true low rank matrix with high\nprobability. However, those assumptions may not hold in real-world\napplications. Since the nuclear norm approximates the rank by adding all\nsingular values together, which is essentially a $\\ell_1$-norm of the singular\nvalues, the resulting approximation error is not trivial and thus the resulting\nmatrix estimator can be significantly biased. To seek a closer approximation\nand to alleviate the above-mentioned limitations of the nuclear norm, we\npropose a nonconvex rank approximation. This approximation to the matrix rank\nis tighter than the nuclear norm. To solve the associated nonconvex\nminimization problem, we develop an efficient augmented Lagrange multiplier\nbased optimization algorithm. Experimental results demonstrate that our method\noutperforms current state-of-the-art algorithms in both accuracy and\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 03:00:30 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Kang", "Zhao", ""], ["Peng", "Chong", ""], ["Cheng", "Qiang", ""]]}, {"id": "1511.05263", "submitter": "Ivens Portugal", "authors": "Ivens Portugal, Paulo Alencar, Donald Cowan", "title": "The Use of Machine Learning Algorithms in Recommender Systems: A\n  Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems use algorithms to provide users with product or service\nrecommendations. Recently, these systems have been using machine learning\nalgorithms from the field of artificial intelligence. However, choosing a\nsuitable machine learning algorithm for a recommender system is difficult\nbecause of the number of algorithms described in the literature. Researchers\nand practitioners developing recommender systems are left with little\ninformation about the current approaches in algorithm usage. Moreover, the\ndevelopment of a recommender system using a machine learning algorithm often\nhas problems and open questions that must be evaluated, so software engineers\nknow where to focus research efforts. This paper presents a systematic review\nof the literature that analyzes the use of machine learning algorithms in\nrecommender systems and identifies research opportunities for software\nengineering research. The study concludes that Bayesian and decision tree\nalgorithms are widely used in recommender systems because of their relative\nsimplicity, and that requirement and design phases of recommender system\ndevelopment appear to offer opportunities for further research.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 03:14:46 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2015 14:38:22 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2016 15:36:32 GMT"}, {"version": "v4", "created": "Wed, 24 Feb 2016 18:58:32 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Portugal", "Ivens", ""], ["Alencar", "Paulo", ""], ["Cowan", "Donald", ""]]}, {"id": "1511.05265", "submitter": "Siqi Sun", "authors": "Sheng Wang, Siqi Sun and Jinbo Xu", "title": "AUC-maximized Deep Convolutional Neural Fields for Sequence Labeling", "comments": "Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (DCNN) has shown excellent performance in\na variety of machine learning tasks. This manuscript presents Deep\nConvolutional Neural Fields (DeepCNF), a combination of DCNN with Conditional\nRandom Field (CRF), for sequence labeling with highly imbalanced label\ndistribution. The widely-used training methods, such as maximum-likelihood and\nmaximum labelwise accuracy, do not work well on highly imbalanced data. To\nhandle this, we present a new training algorithm called maximum-AUC for\nDeepCNF. That is, we train DeepCNF by directly maximizing the empirical Area\nUnder the ROC Curve (AUC), which is an unbiased measurement for imbalanced\ndata. To fulfill this, we formulate AUC in a pairwise ranking framework,\napproximate it by a polynomial function and then apply a gradient-based\nprocedure to optimize it. We then test our AUC-maximized DeepCNF on three very\ndifferent protein sequence labeling tasks: solvent accessibility prediction,\n8-state secondary structure prediction, and disorder prediction. Our\nexperimental results confirm that maximum-AUC greatly outperforms the other two\ntraining methods on 8-state secondary structure prediction and disorder\nprediction since their label distributions are highly imbalanced and also have\nsimilar performance as the other two training methods on the solvent\naccessibility prediction problem which has three equally-distributed labels.\nFurthermore, our experimental results also show that our AUC-trained DeepCNF\nmodels greatly outperform existing popular predictors of these three tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 03:21:43 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 22:45:31 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Wang", "Sheng", ""], ["Sun", "Siqi", ""], ["Xu", "Jinbo", ""]]}, {"id": "1511.05266", "submitter": "Rana Forsati Dr.", "authors": "Iman Barjasteh, Rana Forsati, Abdol-Hossein Esfahanian, Hayder Radha", "title": "Semi-supervised Collaborative Ranking with Push at Top", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing collaborative ranking based recommender systems tend to perform best\nwhen there is enough observed ratings for each user and the observation is made\ncompletely at random. Under this setting recommender systems can properly\nsuggest a list of recommendations according to the user interests. However,\nwhen the observed ratings are extremely sparse (e.g. in the case of cold-start\nusers where no rating data is available), and are not sampled uniformly at\nrandom, existing ranking methods fail to effectively leverage side information\nto transduct the knowledge from existing ratings to unobserved ones. We propose\na semi-supervised collaborative ranking model, dubbed \\texttt{S$^2$COR}, to\nimprove the quality of cold-start recommendation. \\texttt{S$^2$COR} mitigates\nthe sparsity issue by leveraging side information about both observed and\nmissing ratings by collaboratively learning the ranking model. This enables it\nto deal with the case of missing data not at random, but to also effectively\nincorporate the available side information in transduction. We experimentally\nevaluated our proposed algorithm on a number of challenging real-world datasets\nand compared against state-of-the-art models for cold-start recommendation. We\nreport significantly higher quality recommendations with our algorithm compared\nto the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 04:02:26 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Barjasteh", "Iman", ""], ["Forsati", "Rana", ""], ["Esfahanian", "Abdol-Hossein", ""], ["Radha", "Hayder", ""]]}, {"id": "1511.05297", "submitter": "Vamsi Ithapu", "authors": "Vamsi K Ithapu, Sathya N Ravi, Vikas Singh", "title": "On the interplay of network structure and gradient convergence in deep\n  learning", "comments": "54th Allerton Conference on Communication, Control and Computing\n  2016; pgs 488-495", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The regularization and output consistency behavior of dropout and layer-wise\npretraining for learning deep networks have been fairly well studied. However,\nour understanding of how the asymptotic convergence of backpropagation in deep\narchitectures is related to the structural properties of the network and other\ndesign choices (like denoising and dropout rate) is less clear at this time. An\ninteresting question one may ask is whether the network architecture and input\ndata statistics may guide the choices of learning parameters and vice versa. In\nthis work, we explore the association between such structural, distributional\nand learnability aspects vis-\\`a-vis their interaction with parameter\nconvergence rates. We present a framework to address these questions based on\nconvergence of backpropagation for general nonconvex objectives using\nfirst-order information. This analysis suggests an interesting relationship\nbetween feature denoising and dropout. Building upon these results, we obtain a\nsetup that provides systematic guidance regarding the choice of learning\nparameters and network sizes that achieve a certain level of convergence (in\nthe optimization sense) often mediated by statistical attributes of the inputs.\nOur results are supported by a set of experimental evaluations as well as\nindependent empirical observations reported by other groups.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 07:31:56 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 21:49:44 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 21:47:36 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2016 20:17:03 GMT"}, {"version": "v5", "created": "Tue, 29 Mar 2016 23:16:43 GMT"}, {"version": "v6", "created": "Mon, 3 Oct 2016 16:21:39 GMT"}, {"version": "v7", "created": "Tue, 4 Oct 2016 20:56:42 GMT"}, {"version": "v8", "created": "Wed, 22 Feb 2017 17:28:01 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Ithapu", "Vamsi K", ""], ["Ravi", "Sathya N", ""], ["Singh", "Vikas", ""]]}, {"id": "1511.05298", "submitter": "Ashesh Jain", "authors": "Ashesh Jain, Amir R. Zamir, Silvio Savarese, Ashutosh Saxena", "title": "Structural-RNN: Deep Learning on Spatio-Temporal Graphs", "comments": "CVPR 2016 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Recurrent Neural Network architectures, though remarkably capable at\nmodeling sequences, lack an intuitive high-level spatio-temporal structure.\nThat is while many problems in computer vision inherently have an underlying\nhigh-level structure and can benefit from it. Spatio-temporal graphs are a\npopular tool for imposing such high-level intuitions in the formulation of real\nworld problems. In this paper, we propose an approach for combining the power\nof high-level spatio-temporal graphs and sequence learning success of Recurrent\nNeural Networks~(RNNs). We develop a scalable method for casting an arbitrary\nspatio-temporal graph as a rich RNN mixture that is feedforward, fully\ndifferentiable, and jointly trainable. The proposed method is generic and\nprincipled as it can be used for transforming any spatio-temporal graph through\nemploying a certain set of well defined steps. The evaluations of the proposed\napproach on a diverse set of problems, ranging from modeling human motion to\nobject interactions, shows improvement over the state-of-the-art with a large\nmargin. We expect this method to empower new approaches to problem formulation\nthrough high-level spatio-temporal graphs and Recurrent Neural Networks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 07:49:58 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 01:26:23 GMT"}, {"version": "v3", "created": "Mon, 11 Apr 2016 19:00:24 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Jain", "Ashesh", ""], ["Zamir", "Amir R.", ""], ["Savarese", "Silvio", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1511.05371", "submitter": "Markus Schneider", "authors": "Markus Schneider and Wolfgang Ertel and G\\\"unther Palm", "title": "Constant Time EXPected Similarity Estimation using Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithm named EXPected Similarity Estimation (EXPoSE) was recently\nproposed to solve the problem of large-scale anomaly detection. It is a\nnon-parametric and distribution free kernel method based on the Hilbert space\nembedding of probability measures. Given a dataset of $n$ samples, EXPoSE needs\nonly $\\mathcal{O}(n)$ (linear time) to build a model and $\\mathcal{O}(1)$\n(constant time) to make a prediction. In this work we improve the linear\ncomputational complexity and show that an $\\epsilon$-accurate model can be\nestimated in constant time, which has significant implications for large-scale\nlearning problems. To achieve this goal, we cast the original EXPoSE\nformulation into a stochastic optimization problem. It is crucial that this\napproach allows us to determine the number of iteration based on a desired\naccuracy $\\epsilon$, independent of the dataset size $n$. We will show that the\nproposed stochastic gradient descent algorithm works in general (possible\ninfinite-dimensional) Hilbert spaces, is easy to implement and requires no\nadditional step-size parameters.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 12:10:03 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Schneider", "Markus", ""], ["Ertel", "Wolfgang", ""], ["Palm", "G\u00fcnther", ""]]}, {"id": "1511.05385", "submitter": "Ruth Misener", "authors": "Doniyor Ulmasov, Caroline Baroukh, Benoit Chachuat, Marc Peter\n  Deisenroth, Ruth Misener", "title": "Bayesian Optimization with Dimension Scheduling: Application to\n  Biological Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is a data-efficient method for global black-box\noptimization of an expensive-to-evaluate fitness function. BO typically assumes\nthat computation cost of BO is cheap, but experiments are time consuming or\ncostly. In practice, this allows us to optimize ten or fewer critical\nparameters in up to 1,000 experiments. But experiments may be less expensive\nthan BO methods assume: In some simulation models, we may be able to conduct\nmultiple thousands of experiments in a few hours, and the computational burden\nof BO is no longer negligible compared to experimentation time. To address this\nchallenge we introduce a new Dimension Scheduling Algorithm (DSA), which\nreduces the computational burden of BO for many experiments. The key idea is\nthat DSA optimizes the fitness function only along a small set of dimensions at\neach iteration. This DSA strategy (1) reduces the necessary computation time,\n(2) finds good solutions faster than the traditional BO method, and (3) can be\nparallelized straightforwardly. We evaluate the DSA in the context of\noptimizing parameters of dynamic models of microalgae metabolism and show\nfaster convergence than traditional BO.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 13:08:10 GMT"}], "update_date": "2016-08-18", "authors_parsed": [["Ulmasov", "Doniyor", ""], ["Baroukh", "Caroline", ""], ["Chachuat", "Benoit", ""], ["Deisenroth", "Marc Peter", ""], ["Misener", "Ruth", ""]]}, {"id": "1511.05392", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Sachin Ravi", "title": "Learning the Dimensionality of Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for learning word embeddings with data-dependent\ndimensionality. Our Stochastic Dimensionality Skip-Gram (SD-SG) and Stochastic\nDimensionality Continuous Bag-of-Words (SD-CBOW) are nonparametric analogs of\nMikolov et al.'s (2013) well-known 'word2vec' models. Vector dimensionality is\nmade dynamic by employing techniques used by Cote & Larochelle (2016) to define\nan RBM with an infinite number of hidden units. We show qualitatively and\nquantitatively that SD-SG and SD-CBOW are competitive with their\nfixed-dimension counterparts while providing a distribution over embedding\ndimensionalities, which offers a window into how semantics distribute across\ndimensions.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 13:28:55 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 04:43:11 GMT"}, {"version": "v3", "created": "Thu, 13 Apr 2017 17:44:37 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Nalisnick", "Eric", ""], ["Ravi", "Sachin", ""]]}, {"id": "1511.05432", "submitter": "Uri Shaham", "authors": "Uri Shaham, Yutaro Yamada, and Sahand Negahban", "title": "Understanding Adversarial Training: Increasing Local Stability of Neural\n  Nets through Robust Optimization", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2018.04.027", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for increasing local stability of Artificial\nNeural Nets (ANNs) using Robust Optimization (RO). We achieve this through an\nalternating minimization-maximization procedure, in which the loss of the\nnetwork is minimized over perturbed examples that are generated at each\nparameter update. We show that adversarial training of ANNs is in fact\nrobustification of the network optimization, and that our proposed framework\ngeneralizes previous approaches for increasing local stability of ANNs.\nExperimental results reveal that our approach increases the robustness of the\nnetwork to existing adversarial examples, while making it harder to generate\nnew ones. Furthermore, our algorithm improves the accuracy of the network also\non the original test data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 15:14:57 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 16:35:50 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2016 19:05:27 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Shaham", "Uri", ""], ["Yamada", "Yutaro", ""], ["Negahban", "Sahand", ""]]}, {"id": "1511.05440", "submitter": "Michael Mathieu", "authors": "Michael Mathieu, Camille Couprie and Yann LeCun", "title": "Deep multi-scale video prediction beyond mean square error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to predict future images from a video sequence involves the\nconstruction of an internal representation that models the image evolution\naccurately, and therefore, to some degree, its content and dynamics. This is\nwhy pixel-space video prediction may be viewed as a promising avenue for\nunsupervised feature learning. In addition, while optical flow has been a very\nstudied problem in computer vision for a long time, future frame prediction is\nrarely approached. Still, many vision applications could benefit from the\nknowledge of the next frames of videos, that does not require the complexity of\ntracking every pixel trajectories. In this work, we train a convolutional\nnetwork to generate future frames given an input sequence. To deal with the\ninherently blurry predictions obtained from the standard Mean Squared Error\n(MSE) loss function, we propose three different and complementary feature\nlearning strategies: a multi-scale architecture, an adversarial training\nmethod, and an image gradient difference loss function. We compare our\npredictions to different published results based on recurrent neural networks\non the UCF101 dataset\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 15:36:32 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 23:21:22 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2015 04:58:24 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 21:52:53 GMT"}, {"version": "v5", "created": "Fri, 15 Jan 2016 02:09:16 GMT"}, {"version": "v6", "created": "Fri, 26 Feb 2016 22:10:30 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Mathieu", "Michael", ""], ["Couprie", "Camille", ""], ["LeCun", "Yann", ""]]}, {"id": "1511.05464", "submitter": "Joseph  Salmon", "authors": "Igor Colin and Aur\\'elien Bellet and Joseph Salmon and St\\'ephan\n  Cl\\'emen\\c{c}on", "title": "Extending Gossip Algorithms to Distributed Estimation of U-Statistics", "comments": "to be presented at NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.SY stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and robust algorithms for decentralized estimation in networks are\nessential to many distributed systems. Whereas distributed estimation of sample\nmean statistics has been the subject of a good deal of attention, computation\nof $U$-statistics, relying on more expensive averaging over pairs of\nobservations, is a less investigated area. Yet, such data functionals are\nessential to describe global properties of a statistical population, with\nimportant examples including Area Under the Curve, empirical variance, Gini\nmean difference and within-cluster point scatter. This paper proposes new\nsynchronous and asynchronous randomized gossip algorithms which simultaneously\npropagate data across the network and maintain local estimates of the\n$U$-statistic of interest. We establish convergence rate bounds of $O(1/t)$ and\n$O(\\log t / t)$ for the synchronous and asynchronous cases respectively, where\n$t$ is the number of iterations, with explicit data and network dependent\nterms. Beyond favorable comparisons in terms of rate analysis, numerical\nexperiments provide empirical evidence the proposed algorithms surpasses the\npreviously introduced approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 16:49:52 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Colin", "Igor", ""], ["Bellet", "Aur\u00e9lien", ""], ["Salmon", "Joseph", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""]]}, {"id": "1511.05493", "submitter": "Yujia Li", "authors": "Yujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel", "title": "Gated Graph Sequence Neural Networks", "comments": "Published as a conference paper in ICLR 2016. Fixed a typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-structured data appears frequently in domains including chemistry,\nnatural language semantics, social networks, and knowledge bases. In this work,\nwe study feature learning techniques for graph-structured inputs. Our starting\npoint is previous work on Graph Neural Networks (Scarselli et al., 2009), which\nwe modify to use gated recurrent units and modern optimization techniques and\nthen extend to output sequences. The result is a flexible and broadly useful\nclass of neural network models that has favorable inductive biases relative to\npurely sequence-based models (e.g., LSTMs) when the problem is\ngraph-structured. We demonstrate the capabilities on some simple AI (bAbI) and\ngraph algorithm learning tasks. We then show it achieves state-of-the-art\nperformance on a problem from program verification, in which subgraphs need to\nbe matched to abstract data structures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 18:10:12 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 22:03:02 GMT"}, {"version": "v3", "created": "Tue, 3 May 2016 21:55:01 GMT"}, {"version": "v4", "created": "Fri, 22 Sep 2017 21:36:00 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Li", "Yujia", ""], ["Tarlow", "Daniel", ""], ["Brockschmidt", "Marc", ""], ["Zemel", "Richard", ""]]}, {"id": "1511.05497", "submitter": "Suraj Srinivas", "authors": "Suraj Srinivas and R. Venkatesh Babu", "title": "Learning Neural Network Architectures using Backpropagation", "comments": "BMVC 2016 ; Title modified from 'Learning the Architecture of Deep\n  Neural Networks'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with millions of parameters are at the heart of many\nstate of the art machine learning models today. However, recent works have\nshown that models with much smaller number of parameters can also perform just\nas well. In this work, we introduce the problem of architecture-learning, i.e;\nlearning the architecture of a neural network along with weights. We introduce\na new trainable parameter called tri-state ReLU, which helps in eliminating\nunnecessary neurons. We also propose a smooth regularizer which encourages the\ntotal number of neurons after elimination to be small. The resulting objective\nis differentiable and simple to optimize. We experimentally validate our method\non both small and large networks, and show that it can learn models with a\nconsiderably small number of parameters without affecting prediction accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 18:26:11 GMT"}, {"version": "v2", "created": "Tue, 2 Aug 2016 11:46:48 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Srinivas", "Suraj", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1511.05520", "submitter": "Tian Wang", "authors": "Peter Li and Jiyuan Qian and Tian Wang", "title": "Automatic Instrument Recognition in Polyphonic Music Using Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods to tackle many music information retrieval tasks\ntypically follow a two-step architecture: feature engineering followed by a\nsimple learning algorithm. In these \"shallow\" architectures, feature\nengineering and learning are typically disjoint and unrelated. Additionally,\nfeature engineering is difficult, and typically depends on extensive domain\nexpertise.\n  In this paper, we present an application of convolutional neural networks for\nthe task of automatic musical instrument identification. In this model, feature\nextraction and learning algorithms are trained together in an end-to-end\nfashion. We show that a convolutional neural network trained on raw audio can\nachieve performance surpassing traditional methods that rely on hand-crafted\nfeatures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 19:43:53 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Li", "Peter", ""], ["Qian", "Jiyuan", ""], ["Wang", "Tian", ""]]}, {"id": "1511.05547", "submitter": "Baochen Sun", "authors": "Baochen Sun, Jiashi Feng, Kate Saenko", "title": "Return of Frustratingly Easy Domain Adaptation", "comments": "Fixed typos. Full paper to appear in AAAI-16. Extended Abstract of\n  the full paper to appear in TASK-CV 2015 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike human learning, machine learning often fails to handle changes between\ntraining (source) and test (target) input distributions. Such domain shifts,\ncommon in practical scenarios, severely damage the performance of conventional\nmachine learning methods. Supervised domain adaptation methods have been\nproposed for the case when the target data have labels, including some that\nperform very well despite being \"frustratingly easy\" to implement. However, in\npractice, the target domain is often unlabeled, requiring unsupervised\nadaptation. We propose a simple, effective, and efficient method for\nunsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL\nminimizes domain shift by aligning the second-order statistics of source and\ntarget distributions, without requiring any target labels. Even though it is\nextraordinarily simple--it can be implemented in four lines of Matlab\ncode--CORAL performs remarkably well in extensive evaluations on standard\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 20:53:26 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2015 05:39:43 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Sun", "Baochen", ""], ["Feng", "Jiashi", ""], ["Saenko", "Kate", ""]]}, {"id": "1511.05607", "submitter": "Min Li", "authors": "Min Li, Sudeep Gaddam, Xiaolin Li, Yinan Zhao, Jingzhe Ma, Jian Ge", "title": "Identifying the Absorption Bump with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive interstellar dust grains provide significant insights to\nunderstand the formation and evolution of the stars, planetary systems, and the\ngalaxies, and may harbor the building blocks of life. One of the most effective\nway to analyze the dust is via their interaction with the light from background\nsources. The observed extinction curves and spectral features carry the size\nand composition information of dust. The broad absorption bump at 2175 Angstrom\nis the most prominent feature in the extinction curves. Traditionally,\nstatistical methods are applied to detect the existence of the absorption bump.\nThese methods require heavy preprocessing and the co-existence of other\nreference features to alleviate the influence from the noises. In this paper,\nwe apply Deep Learning techniques to detect the broad absorption bump. We\ndemonstrate the key steps for training the selected models and their results.\nThe success of Deep Learning based method inspires us to generalize a common\nmethodology for broader science discovery problems. We present our on-going\nwork to build the DeepDis system for such kind of applications.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 22:27:05 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 14:20:46 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Li", "Min", ""], ["Gaddam", "Sudeep", ""], ["Li", "Xiaolin", ""], ["Zhao", "Yinan", ""], ["Ma", "Jingzhe", ""], ["Ge", "Jian", ""]]}, {"id": "1511.05612", "submitter": "Jingchu Liu", "authors": "Huimin Pan, Jingchu Liu, Sheng Zhou, Zhisheng Niu", "title": "A Block Regression Model for Short-Term Mobile Traffic Forecasting", "comments": "5 pages, 6 figures. IEEE/CIC ICCC'15", "journal-ref": null, "doi": "10.1109/ICCChina.2015.7448619", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate mobile traffic forecast is important for efficient network planning\nand operations. However, existing traffic forecasting models have high\ncomplexity, making the forecasting process slow and costly. In this paper, we\nanalyze some characteristics of mobile traffic such as periodicity, spatial\nsimilarity and short term relativity. Based on these characteristics, we\npropose a \\emph{Block Regression} ({BR}) model for mobile traffic forecasting.\nThis model employs seasonal differentiation so as to take into account of the\ntemporally repetitive nature of mobile traffic. One of the key features of our\n{BR} model lies in its low complexity since it constructs a single model for\nall base stations. We evaluate the accuracy of {BR} model based on real traffic\ndata and compare it with the existing models. Results show that our {BR} model\noffers equal accuracy to the existing models but has much less complexity.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 23:17:17 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Pan", "Huimin", ""], ["Liu", "Jingchu", ""], ["Zhou", "Sheng", ""], ["Niu", "Zhisheng", ""]]}, {"id": "1511.05616", "submitter": "Hexiang Hu", "authors": "Hexiang Hu, Guang-Tong Zhou, Zhiwei Deng, Zicheng Liao, Greg Mori", "title": "Learning Structured Inference Neural Networks with Label Relations", "comments": "Conference on Computer Vision and Pattern Recognition(CVPR) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images of scenes have various objects as well as abundant attributes, and\ndiverse levels of visual categorization are possible. A natural image could be\nassigned with fine-grained labels that describe major components,\ncoarse-grained labels that depict high level abstraction or a set of labels\nthat reveal attributes. Such categorization at different concept layers can be\nmodeled with label graphs encoding label information. In this paper, we exploit\nthis rich information with a state-of-art deep learning framework, and propose\na generic structured model that leverages diverse label relations to improve\nimage classification performance. Our approach employs a novel stacked label\nprediction neural network, capturing both inter-level and intra-level label\nsemantics. We evaluate our method on benchmark image datasets, and empirical\nresults illustrate the efficacy of our model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 23:22:25 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 06:13:16 GMT"}, {"version": "v3", "created": "Fri, 8 Apr 2016 05:04:52 GMT"}, {"version": "v4", "created": "Mon, 24 Oct 2016 18:20:20 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Hu", "Hexiang", ""], ["Zhou", "Guang-Tong", ""], ["Deng", "Zhiwei", ""], ["Liao", "Zicheng", ""], ["Mori", "Greg", ""]]}, {"id": "1511.05622", "submitter": "Yann Dauphin", "authors": "Yann N. Dauphin, David Grangier", "title": "Predicting distributions with Linearizing Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional belief networks introduce stochastic binary variables in neural\nnetworks. Contrary to a classical neural network, a belief network can predict\nmore than the expected value of the output $Y$ given the input $X$. It can\npredict a distribution of outputs $Y$ which is useful when an input can admit\nmultiple outputs whose average is not necessarily a valid answer. Such networks\nare particularly relevant to inverse problems such as image prediction for\ndenoising, or text to speech. However, traditional sigmoid belief networks are\nhard to train and are not suited to continuous problems. This work introduces a\nnew family of networks called linearizing belief nets or LBNs. A LBN decomposes\ninto a deep linear network where each linear unit can be turned on or off by\nnon-deterministic binary latent units. It is a universal approximator of\nreal-valued conditional distributions and can be trained using gradient\ndescent. Moreover, the linear pathways efficiently propagate continuous\ninformation and they act as multiplicative skip-connections that help\noptimization by removing gradient diffusion. This yields a model which trains\nefficiently and improves the state-of-the-art on image denoising and facial\nexpression generation with the Toronto faces dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 23:50:35 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 00:40:38 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2015 01:45:01 GMT"}, {"version": "v4", "created": "Mon, 2 May 2016 03:22:01 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Dauphin", "Yann N.", ""], ["Grangier", "David", ""]]}, {"id": "1511.05635", "submitter": "Zhibin Liao", "authors": "Zhibin Liao, Gustavo Carneiro", "title": "Competitive Multi-scale Convolution", "comments": null, "journal-ref": "Pattern Recognition 71 (2017), 94-105", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new deep convolutional neural network (ConvNet)\nmodule that promotes competition among a set of multi-scale convolutional\nfilters. This new module is inspired by the inception module, where we replace\nthe original collaborative pooling stage (consisting of a concatenation of the\nmulti-scale filter outputs) by a competitive pooling represented by a maxout\nactivation unit. This extension has the following two objectives: 1) the\nselection of the maximum response among the multi-scale filters prevents filter\nco-adaptation and allows the formation of multiple sub-networks within the same\nmodel, which has been shown to facilitate the training of complex learning\nproblems; and 2) the maxout unit reduces the dimensionality of the outputs from\nthe multi-scale filters. We show that the use of our proposed module in typical\ndeep ConvNets produces classification results that are either better than or\ncomparable to the state of the art on the following benchmark datasets: MNIST,\nCIFAR-10, CIFAR-100 and SVHN.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 01:19:00 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Liao", "Zhibin", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "1511.05641", "submitter": "Tianqi Chen", "authors": "Tianqi Chen and Ian Goodfellow and Jonathon Shlens", "title": "Net2Net: Accelerating Learning via Knowledge Transfer", "comments": "ICLR 2016 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce techniques for rapidly transferring the information stored in\none neural net into another neural net. The main purpose is to accelerate the\ntraining of a significantly larger neural net. During real-world workflows, one\noften trains very many different neural networks during the experimentation and\ndesign process. This is a wasteful process in which each new model is trained\nfrom scratch. Our Net2Net technique accelerates the experimentation process by\ninstantaneously transferring the knowledge from a previous network to each new\ndeeper or wider network. Our techniques are based on the concept of\nfunction-preserving transformations between neural network specifications. This\ndiffers from previous approaches to pre-training that altered the function\nrepresented by a neural net when adding layers to it. Using our knowledge\ntransfer mechanism to add depth to Inception modules, we demonstrate a new\nstate of the art accuracy rating on the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 02:09:20 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 19:07:40 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 22:54:48 GMT"}, {"version": "v4", "created": "Sat, 23 Apr 2016 23:14:39 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Chen", "Tianqi", ""], ["Goodfellow", "Ian", ""], ["Shlens", "Jonathon", ""]]}, {"id": "1511.05643", "submitter": "Md Kamrul Hasan", "authors": "Md Kamrul Hasan, Christopher J. Pal", "title": "A New Smooth Approximation to the Zero One Loss with a Probabilistic\n  Interpretation", "comments": "32 pages, 7 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a new form of smooth approximation to the zero one loss in which\nlearning is performed using a reformulation of the widely used logistic\nfunction. Our approach is based on using the posterior mean of a novel\ngeneralized Beta-Bernoulli formulation. This leads to a generalized logistic\nfunction that approximates the zero one loss, but retains a probabilistic\nformulation conferring a number of useful properties. The approach is easily\ngeneralized to kernel logistic regression and easily integrated into methods\nfor structured prediction. We present experiments in which we learn such models\nusing an optimization method consisting of a combination of gradient descent\nand coordinate descent using localized grid search so as to escape from local\nminima. Our experiments indicate that optimization quality is improved when\nlearning meta-parameters are themselves optimized using a validation set. Our\nexperiments show improved performance relative to widely used logistic and\nhinge loss methods on a wide variety of problems ranging from standard UC\nIrvine and libSVM evaluation datasets to product review predictions and a\nvisual information extraction task. We observe that the approach: 1) is more\nrobust to outliers compared to the logistic and hinge losses; 2) outperforms\ncomparable logistic and max margin models on larger scale benchmark problems;\n3) when combined with Gaussian- Laplacian mixture prior on parameters the\nkernelized version of our formulation yields sparser solutions than Support\nVector Machine classifiers; and 4) when integrated into a probabilistic\nstructured prediction technique our approach provides more accurate\nprobabilities yielding improved inference and increasing information extraction\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 02:31:16 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Hasan", "Md Kamrul", ""], ["Pal", "Christopher J.", ""]]}, {"id": "1511.05644", "submitter": "Alireza Makhzani", "authors": "Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow,\n  Brendan Frey", "title": "Adversarial Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the \"adversarial autoencoder\" (AAE), which is a\nprobabilistic autoencoder that uses the recently proposed generative\nadversarial networks (GAN) to perform variational inference by matching the\naggregated posterior of the hidden code vector of the autoencoder with an\narbitrary prior distribution. Matching the aggregated posterior to the prior\nensures that generating from any part of prior space results in meaningful\nsamples. As a result, the decoder of the adversarial autoencoder learns a deep\ngenerative model that maps the imposed prior to the data distribution. We show\nhow the adversarial autoencoder can be used in applications such as\nsemi-supervised classification, disentangling style and content of images,\nunsupervised clustering, dimensionality reduction and data visualization. We\nperformed experiments on MNIST, Street View House Numbers and Toronto Face\ndatasets and show that adversarial autoencoders achieve competitive results in\ngenerative modeling and semi-supervised classification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 02:32:39 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 00:17:45 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Makhzani", "Alireza", ""], ["Shlens", "Jonathon", ""], ["Jaitly", "Navdeep", ""], ["Goodfellow", "Ian", ""], ["Frey", "Brendan", ""]]}, {"id": "1511.05650", "submitter": "Seungjin Choi", "authors": "Juho Lee and Seungjin Choi", "title": "Tree-Guided MCMC Inference for Normalized Random Measure Mixture Models", "comments": "12 pages, 10 figures, NIPS-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalized random measures (NRMs) provide a broad class of discrete random\nmeasures that are often used as priors for Bayesian nonparametric models.\nDirichlet process is a well-known example of NRMs. Most of posterior inference\nmethods for NRM mixture models rely on MCMC methods since they are easy to\nimplement and their convergence is well studied. However, MCMC often suffers\nfrom slow convergence when the acceptance rate is low. Tree-based inference is\nan alternative deterministic posterior inference method, where Bayesian\nhierarchical clustering (BHC) or incremental Bayesian hierarchical clustering\n(IBHC) have been developed for DP or NRM mixture (NRMM) models, respectively.\nAlthough IBHC is a promising method for posterior inference for NRMM models due\nto its efficiency and applicability to online inference, its convergence is not\nguaranteed since it uses heuristics that simply selects the best solution after\nmultiple trials are made. In this paper, we present a hybrid inference\nalgorithm for NRMM models, which combines the merits of both MCMC and IBHC.\nTrees built by IBHC outlines partitions of data, which guides\nMetropolis-Hastings procedure to employ appropriate proposals. Inheriting the\nnature of MCMC, our tree-guided MCMC (tgMCMC) is guaranteed to converge, and\nenjoys the fast convergence thanks to the effective proposals guided by trees.\nExperiments on both synthetic and real-world datasets demonstrate the benefit\nof our method.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 03:16:27 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Lee", "Juho", ""], ["Choi", "Seungjin", ""]]}, {"id": "1511.05653", "submitter": "Yingyu Liang", "authors": "Sanjeev Arora and Yingyu Liang and Tengyu Ma", "title": "Why are deep nets reversible: A simple theory, with implications for\n  training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models for deep learning are promising both to improve\nunderstanding of the model, and yield training methods requiring fewer labeled\nsamples.\n  Recent works use generative model approaches to produce the deep net's input\ngiven the value of a hidden layer several levels above. However, there is no\naccompanying \"proof of correctness\" for the generative model, showing that the\nfeedforward deep net is the correct inference method for recovering the hidden\nlayer given the input. Furthermore, these models are complicated.\n  The current paper takes a more theoretical tack. It presents a very simple\ngenerative model for RELU deep nets, with the following characteristics: (i)\nThe generative model is just the reverse of the feedforward net: if the forward\ntransformation at a layer is $A$ then the reverse transformation is $A^T$.\n(This can be seen as an explanation of the old weight tying idea for denoising\nautoencoders.) (ii) Its correctness can be proven under a clean theoretical\nassumption: the edge weights in real-life deep nets behave like random numbers.\nUnder this assumption ---which is experimentally tested on real-life nets like\nAlexNet--- it is formally proved that feed forward net is a correct inference\nmethod for recovering the hidden layer.\n  The generative model suggests a simple modification for training: use the\ngenerative model to produce synthetic data with labels and include it in the\ntraining set. Experiments are shown to support this theory of random-like deep\nnets; and that it helps the training.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 04:33:09 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 23:48:36 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Arora", "Sanjeev", ""], ["Liang", "Yingyu", ""], ["Ma", "Tengyu", ""]]}, {"id": "1511.05678", "submitter": "Xingyuan Pan", "authors": "Xingyuan Pan and Vivek Srikumar", "title": "Expressiveness of Rectifier Networks", "comments": "Published in ICML 2016. Supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rectified Linear Units (ReLUs) have been shown to ameliorate the vanishing\ngradient problem, allow for efficient backpropagation, and empirically promote\nsparsity in the learned parameters. They have led to state-of-the-art results\nin a variety of applications. However, unlike threshold and sigmoid networks,\nReLU networks are less explored from the perspective of their expressiveness.\nThis paper studies the expressiveness of ReLU networks. We characterize the\ndecision boundary of two-layer ReLU networks by constructing functionally\nequivalent threshold networks. We show that while the decision boundary of a\ntwo-layer ReLU network can be captured by a threshold network, the latter may\nrequire an exponentially larger number of hidden units. We also formulate\nsufficient conditions for a corresponding logarithmic reduction in the number\nof hidden units to represent a sign network as a ReLU network. Finally, we\nexperimentally compare threshold networks and their much smaller ReLU\ncounterparts with respect to their ability to learn from synthetically\ngenerated data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 07:26:12 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 18:53:11 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 05:11:55 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Pan", "Xingyuan", ""], ["Srikumar", "Vivek", ""]]}, {"id": "1511.05688", "submitter": "Ameen Eetemadi", "authors": "Ameen Eetemadi, Ilias Tagkopoulos", "title": "A Distribution Adaptive Framework for Prediction Interval Estimation\n  Using Nominal Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proposed methods for prediction interval estimation so far focus on cases\nwhere input variables are numerical. In datasets with solely nominal input\nvariables, we observe records with the exact same input $x^u$, but different\nreal valued outputs due to the inherent noise in the system. Existing\nprediction interval estimation methods do not use representations that can\naccurately model such inherent noise in the case of nominal inputs. We propose\na new prediction interval estimation method tailored for this type of data,\nwhich is prevalent in biology and medicine. We call this method Distribution\nAdaptive Prediction Interval Estimation given Nominal inputs (DAPIEN) and has\nfour main phases. First, we select a distribution function that can best\nrepresent the inherent noise of the system for all unique inputs. Then we infer\nthe parameters $\\theta_i$ (e.g. $\\theta_i=[mean_i, variance_i]$) of the\nselected distribution function for all unique input vectors $x^u_i$ and\ngenerate a new corresponding training set using pairs of $x^u_i, \\theta_i$.\nIII). Then, we train a model to predict $\\theta$ given a new $x_u$. Finally, we\ncalculate the prediction interval for a new sample using the inverse of the\ncumulative distribution function once the parameters $\\theta$ is predicted by\nthe trained model. We compared DAPIEN to the commonly used Bootstrap method on\nthree synthetic datasets. Our results show that DAPIEN provides tighter\nprediction intervals while preserving the requested coverage when compared to\nBootstrap. This work can facilitate broader usage of regression methods in\nmedicine and biology where it is necessary to provide tight prediction\nintervals while preserving coverage when input variables are nominal.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 08:13:35 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 08:12:23 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Eetemadi", "Ameen", ""], ["Tagkopoulos", "Ilias", ""]]}, {"id": "1511.05706", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria and Maksim Lapin and Matthias Hein and Bernt Schiele", "title": "Efficient Output Kernel Learning for Multiple Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paradigm of multi-task learning is that one can achieve better\ngeneralization by learning tasks jointly and thus exploiting the similarity\nbetween the tasks rather than learning them independently of each other. While\npreviously the relationship between tasks had to be user-defined in the form of\nan output kernel, recent approaches jointly learn the tasks and the output\nkernel. As the output kernel is a positive semidefinite matrix, the resulting\noptimization problems are not scalable in the number of tasks as an\neigendecomposition is required in each step. \\mbox{Using} the theory of\npositive semidefinite kernels we show in this paper that for a certain class of\nregularizers on the output kernel, the constraint of being positive\nsemidefinite can be dropped as it is automatically satisfied for the relaxed\nproblem. This leads to an unconstrained dual problem which can be solved\nefficiently. Experiments on several multi-task and multi-class data sets\nillustrate the efficacy of our approach in terms of computational efficiency as\nwell as generalization performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 09:37:54 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Lapin", "Maksim", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "1511.05710", "submitter": "Rafael Boloix-Tortosa", "authors": "Rafael Boloix-Tortosa, Eva Arias-de-Reyna, F. Javier Payan-Somet, Juan\n  J. Murillo-Fuentes", "title": "Complex-Valued Gaussian Processes for Regression", "comments": "13 pages, 18 figures", "journal-ref": "IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS, 2018", "doi": "10.1109/TNNLS.2018.2805019", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel Bayesian solution for nonlinear regression\nin complex fields. Previous solutions for kernels methods usually assume a\ncomplexification approach, where the real-valued kernel is replaced by a\ncomplex-valued one. This approach is limited. Based on results in\ncomplex-valued linear theory and Gaussian random processes we show that a\npseudo-kernel must be included. This is the starting point to develop the new\ncomplex-valued formulation for Gaussian process for regression (CGPR). We face\nthe design of the covariance and pseudo-covariance based on a convolution\napproach and for several scenarios. Just in the particular case where the\noutputs are proper, the pseudo-kernel cancels. Also, the hyperparameters of the\ncovariance {can be learnt} maximizing the marginal likelihood using Wirtinger's\ncalculus and patterned complex-valued matrix derivatives. In the experiments\nincluded, we show how CGPR successfully solve systems where real and imaginary\nparts are correlated. Besides, we successfully solve the nonlinear channel\nequalization problem by developing a recursive solution with basis removal. We\nreport remarkable improvements compared to previous solutions: a 2-4 dB\nreduction of the MSE with {just a quarter} of the training samples used by\nprevious approaches.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 09:49:22 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 22:14:01 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Boloix-Tortosa", "Rafael", ""], ["Arias-de-Reyna", "Eva", ""], ["Payan-Somet", "F. Javier", ""], ["Murillo-Fuentes", "Juan J.", ""]]}, {"id": "1511.05720", "submitter": "Jonathan Weed", "authors": "Jonathan Weed, Vianney Perchet, Philippe Rigollet", "title": "Online learning in repeated auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by online advertising auctions, we consider repeated Vickrey\nauctions where goods of unknown value are sold sequentially and bidders only\nlearn (potentially noisy) information about a good's value once it is\npurchased. We adopt an online learning approach with bandit feedback to model\nthis problem and derive bidding strategies for two models: stochastic and\nadversarial. In the stochastic model, the observed values of the goods are\nrandom variables centered around the true value of the good. In this case,\nlogarithmic regret is achievable when competing against well behaved\nadversaries. In the adversarial model, the goods need not be identical and we\nsimply compare our performance against that of the best fixed bid in hindsight.\nWe show that sublinear regret is also achievable in this case and prove\nmatching minimax lower bounds. To our knowledge, this is the first complete set\nof strategies for bidders participating in auctions of this type.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 10:17:33 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Weed", "Jonathan", ""], ["Perchet", "Vianney", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1511.05743", "submitter": "Prathamesh Chandrasekar", "authors": "Ning Zhang and Prathamesh Chandrasekar", "title": "Sparse learning of maximum likelihood model for optimization of complex\n  loss function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine learning methods usually minimize a simple loss function\nto learn a predictive model, and then use a complex performance measure to\nmeasure the prediction performance. However, minimizing a simple loss function\ncannot guarantee that an optimal performance. In this paper, we study the\nproblem of optimizing the complex performance measure directly to obtain a\npredictive model. We proposed to construct a maximum likelihood model for this\nproblem, and to learn the model parameter, we minimize a com- plex loss\nfunction corresponding to the desired complex performance measure. To optimize\nthe loss function, we approximate the upper bound of the complex loss. We also\npropose impose the sparsity to the model parameter to obtain a sparse model. An\nobjective is constructed by combining the upper bound of the loss function and\nthe sparsity of the model parameter, and we develop an iterative algorithm to\nminimize it by using the fast iterative shrinkage- thresholding algorithm\nframework. The experiments on optimization on three different complex\nperformance measures, including F-score, receiver operating characteristic\ncurve, and recall precision curve break even point, over three real-world\napplications, aircraft event recognition of civil aviation safety, in- trusion\ndetection in wireless mesh networks, and image classification, show the\nadvantages of the proposed method over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 11:40:02 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Zhang", "Ning", ""], ["Chandrasekar", "Prathamesh", ""]]}, {"id": "1511.05756", "submitter": "Hyeonwoo Noh", "authors": "Hyeonwoo Noh, Paul Hongsuck Seo, Bohyung Han", "title": "Image Question Answering using Convolutional Neural Network with Dynamic\n  Parameter Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle image question answering (ImageQA) problem by learning a\nconvolutional neural network (CNN) with a dynamic parameter layer whose weights\nare determined adaptively based on questions. For the adaptive parameter\nprediction, we employ a separate parameter prediction network, which consists\nof gated recurrent unit (GRU) taking a question as its input and a\nfully-connected layer generating a set of candidate weights as its output.\nHowever, it is challenging to construct a parameter prediction network for a\nlarge number of parameters in the fully-connected dynamic parameter layer of\nthe CNN. We reduce the complexity of this problem by incorporating a hashing\ntechnique, where the candidate weights given by the parameter prediction\nnetwork are selected using a predefined hash function to determine individual\nweights in the dynamic parameter layer. The proposed network---joint network\nwith the CNN for ImageQA and the parameter prediction network---is trained\nend-to-end through back-propagation, where its weights are initialized using a\npre-trained CNN and GRU. The proposed algorithm illustrates the\nstate-of-the-art performance on all available public ImageQA benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 12:30:57 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Noh", "Hyeonwoo", ""], ["Seo", "Paul Hongsuck", ""], ["Han", "Bohyung", ""]]}, {"id": "1511.05789", "submitter": "Pauline Wauquier", "authors": "Pauline Wauquier and Mikaela Keller", "title": "Metric learning approach for graph-based label propagation", "comments": "Workshop track submission ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of graph-based semi-supervised algorithms depends on the graph\nof instances on which they are applied. The instances are often in a vectorial\nform before a graph linking them is built. The construction of the graph relies\non a metric over the vectorial space that help define the weight of the\nconnection between entities. The classic choice for this metric is usually a\ndistance measure or a similarity measure based on the euclidean norm. We claim\nthat in some cases the euclidean norm on the initial vectorial space might not\nbe the more appropriate to solve the task efficiently. We propose an algorithm\nthat aims at learning the most appropriate vectorial representation for\nbuilding a graph on which the task at hand is solved efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 14:04:55 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 21:58:32 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2015 14:03:22 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 21:41:36 GMT"}, {"version": "v5", "created": "Tue, 19 Jan 2016 20:59:03 GMT"}, {"version": "v6", "created": "Thu, 18 Feb 2016 15:53:01 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Wauquier", "Pauline", ""], ["Keller", "Mikaela", ""]]}, {"id": "1511.05897", "submitter": "Harrison Edwards", "authors": "Harrison Edwards, Amos Storkey", "title": "Censoring Representations with an Adversary", "comments": "Paper accepted to ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, there are often explicit constraints on what representations or\ndecisions are acceptable in an application of machine learning. For example it\nmay be a legal requirement that a decision must not favour a particular group.\nAlternatively it can be that that representation of data must not have\nidentifying information. We address these two related issues by learning\nflexible representations that minimize the capability of an adversarial critic.\nThis adversary is trying to predict the relevant sensitive variable from the\nrepresentation, and so minimizing the performance of the adversary ensures\nthere is little or no information in the representation about the sensitive\nvariable. We demonstrate this adversarial approach on two problems: making\ndecisions free from discrimination and removing private information from\nimages. We formulate the adversarial model as a minimax problem, and optimize\nthat minimax objective using a stochastic gradient alternate min-max optimizer.\nWe demonstrate the ability to provide discriminant free representations for\nstandard test problems, and compare with previous state of the art methods for\nfairness, showing statistically significant improvement across most cases. The\nflexibility of this method is shown via a novel problem: removing annotations\nfrom images, from unaligned training examples of annotated and unannotated\nimages, and with no a priori knowledge of the form of annotation provided to\nthe model.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 18:06:24 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 15:53:45 GMT"}, {"version": "v3", "created": "Fri, 4 Mar 2016 11:01:34 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Edwards", "Harrison", ""], ["Storkey", "Amos", ""]]}, {"id": "1511.05926", "submitter": "Thien Nguyen", "authors": "Thien Huu Nguyen and Ralph Grishman", "title": "Combining Neural Networks and Log-linear Models to Improve Relation\n  Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed the success of the traditional feature-based\nmethod on exploiting the discrete structures such as words or lexical patterns\nto extract relations from text. Recently, convolutional and recurrent neural\nnetworks has provided very effective mechanisms to capture the hidden\nstructures within sentences via continuous representations, thereby\nsignificantly advancing the performance of relation extraction. The advantage\nof convolutional neural networks is their capacity to generalize the\nconsecutive k-grams in the sentences while recurrent neural networks are\neffective to encode long ranges of sentence context. This paper proposes to\ncombine the traditional feature-based method, the convolutional and recurrent\nneural networks to simultaneously benefit from their advantages. Our systematic\nevaluation of different network architectures and combination methods\ndemonstrates the effectiveness of this approach and results in the\nstate-of-the-art performance on the ACE 2005 and SemEval dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:17:39 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Nguyen", "Thien Huu", ""], ["Grishman", "Ralph", ""]]}, {"id": "1511.05932", "submitter": "Simon Lacoste-Julien", "authors": "Simon Lacoste-Julien and Martin Jaggi", "title": "On the Global Linear Convergence of Frank-Wolfe Optimization Variants", "comments": "Appears in: Advances in Neural Information Processing Systems 28\n  (NIPS 2015). 26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularity\nthanks in particular to its ability to nicely handle the structured constraints\nappearing in machine learning applications. However, its convergence rate is\nknown to be slow (sublinear) when the solution lies at the boundary. A simple\nless-known fix is to add the possibility to take 'away steps' during\noptimization, an operation that importantly does not require a feasibility\noracle. In this paper, we highlight and clarify several variants of the\nFrank-Wolfe optimization algorithm that have been successfully applied in\npractice: away-steps FW, pairwise FW, fully-corrective FW and Wolfe's minimum\nnorm point algorithm, and prove for the first time that they all enjoy global\nlinear convergence, under a weaker condition than strong convexity of the\nobjective. The constant in the convergence rate has an elegant interpretation\nas the product of the (classical) condition number of the function with a novel\ngeometric quantity that plays the role of a 'condition number' of the\nconstraint set. We provide pointers to where these algorithms have made a\ndifference in practice, in particular with the flow polytope, the marginal\npolytope and the base polytope for submodular optimization.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:24:43 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Lacoste-Julien", "Simon", ""], ["Jaggi", "Martin", ""]]}, {"id": "1511.05933", "submitter": "Sayantan Dasgupta", "authors": "Sayantan Dasgupta", "title": "Seeding K-Means using Method of Moments", "comments": "Paper contained an error in Equation 5 and 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-means is one of the most widely used algorithms for clustering in Data\nMining applications, which attempts to minimize the sum of the square of the\nEuclidean distance of the points in the clusters from the respective means of\nthe clusters. However, K-means suffers from local minima problem and is not\nguaranteed to converge to the optimal cost. K-means++ tries to address the\nproblem by seeding the means using a distance-based sampling scheme. However,\nseeding the means in K-means++ needs $O\\left(K\\right)$ sequential passes\nthrough the entire dataset, and this can be very costly for large datasets.\nHere we propose a method of seeding the initial means based on factorizations\nof higher order moments for bounded data. Our method takes $O\\left(1\\right)$\npasses through the entire dataset to extract the initial set of means, and its\nfinal cost can be proven to be within $O(\\sqrt{K})$ of the optimal cost. We\ndemonstrate the performance of our algorithm in comparison with the existing\nalgorithms on various benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:26:42 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2015 21:54:01 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2016 10:21:55 GMT"}, {"version": "v4", "created": "Thu, 3 Mar 2016 17:40:02 GMT"}, {"version": "v5", "created": "Thu, 21 Apr 2016 21:50:39 GMT"}, {"version": "v6", "created": "Fri, 3 Jun 2016 17:50:10 GMT"}, {"version": "v7", "created": "Mon, 12 Sep 2016 22:33:06 GMT"}, {"version": "v8", "created": "Mon, 31 Oct 2016 15:59:13 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Dasgupta", "Sayantan", ""]]}, {"id": "1511.05939", "submitter": "Oren Rippel", "authors": "Oren Rippel, Manohar Paluri, Piotr Dollar, Lubomir Bourdev", "title": "Metric Learning with Adaptive Density Discrimination", "comments": "ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distance metric learning (DML) approaches learn a transformation to a\nrepresentation space where distance is in correspondence with a predefined\nnotion of similarity. While such models offer a number of compelling benefits,\nit has been difficult for these to compete with modern classification\nalgorithms in performance and even in feature extraction.\n  In this work, we propose a novel approach explicitly designed to address a\nnumber of subtle yet important issues which have stymied earlier DML\nalgorithms. It maintains an explicit model of the distributions of the\ndifferent classes in representation space. It then employs this knowledge to\nadaptively assess similarity, and achieve local discrimination by penalizing\nclass distribution overlap.\n  We demonstrate the effectiveness of this idea on several tasks. Our approach\nachieves state-of-the-art classification results on a number of fine-grained\nvisual recognition datasets, surpassing the standard softmax classifier and\noutperforming triplet loss by a relative margin of 30-40%. In terms of\ncomputational performance, it alleviates training inefficiencies in the\ntraditional triplet loss, reaching the same error in 5-30 times fewer\niterations. Beyond classification, we further validate the saliency of the\nlearnt representations via their attribute concentration and hierarchy recovery\nproperties, achieving 10-25% relative gains on the softmax classifier and\n25-50% on triplet loss in these tasks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:41:05 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 04:52:08 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Rippel", "Oren", ""], ["Paluri", "Manohar", ""], ["Dollar", "Piotr", ""], ["Bourdev", "Lubomir", ""]]}, {"id": "1511.05942", "submitter": "Edward Choi", "authors": "Edward Choi and Mohammad Taha Bahadori and Andy Schuetz and Walter F.\n  Stewart and Jimeng Sun", "title": "Doctor AI: Predicting Clinical Events via Recurrent Neural Networks", "comments": "Presented at 2016 Machine Learning and Healthcare Conference (MLHC\n  2016), Los Angeles, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging large historical data in electronic health record (EHR), we\ndeveloped Doctor AI, a generic predictive model that covers observed medical\nconditions and medication uses. Doctor AI is a temporal model using recurrent\nneural networks (RNN) and was developed and applied to longitudinal time\nstamped EHR data from 260K patients over 8 years. Encounter records (e.g.\ndiagnosis codes, medication codes or procedure codes) were input to RNN to\npredict (all) the diagnosis and medication categories for a subsequent visit.\nDoctor AI assesses the history of patients to make multilabel predictions (one\nlabel for each diagnosis or medication category). Based on separate blind test\nset evaluation, Doctor AI can perform differential diagnosis with up to 79%\nrecall@30, significantly higher than several baselines. Moreover, we\ndemonstrate great generalizability of Doctor AI by adapting the resulting\nmodels from one institution to another without losing substantial accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:47:44 GMT"}, {"version": "v10", "created": "Tue, 30 Aug 2016 06:05:18 GMT"}, {"version": "v11", "created": "Wed, 28 Sep 2016 19:11:19 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 12:40:27 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2015 14:21:11 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2016 19:18:22 GMT"}, {"version": "v5", "created": "Thu, 7 Jan 2016 18:23:06 GMT"}, {"version": "v6", "created": "Wed, 17 Feb 2016 22:47:47 GMT"}, {"version": "v7", "created": "Thu, 10 Mar 2016 13:46:11 GMT"}, {"version": "v8", "created": "Sat, 19 Mar 2016 17:02:10 GMT"}, {"version": "v9", "created": "Thu, 4 Aug 2016 02:52:55 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Choi", "Edward", ""], ["Bahadori", "Mohammad Taha", ""], ["Schuetz", "Andy", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1511.05943", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Marios Savvides", "title": "Unitary-Group Invariant Kernels and Features from Transformed Unlabeled\n  Data", "comments": "11 page main paper (including references), 2 page supplementary, for\n  a total of 13 pages. Submitted for review at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of representations invariant to common transformations of the data\nis important to learning. Most techniques have focused on local approximate\ninvariance implemented within expensive optimization frameworks lacking\nexplicit theoretical guarantees. In this paper, we study kernels that are\ninvariant to the unitary group while having theoretical guarantees in\naddressing practical issues such as (1) unavailability of transformed versions\nof labelled data and (2) not observing all transformations. We present a\ntheoretically motivated alternate approach to the invariant kernel SVM. Unlike\nprevious approaches to the invariant SVM, the proposed formulation solves both\nissues mentioned. We also present a kernel extension of a recent technique to\nextract linear unitary-group invariant features addressing both issues and\nextend some guarantees regarding invariance and stability. We present\nexperiments on the UCI ML datasets to illustrate and validate our methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:48:18 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Pal", "Dipan K.", ""], ["Savvides", "Marios", ""]]}, {"id": "1511.05946", "submitter": "Marcin Moczulski", "authors": "Marcin Moczulski, Misha Denil, Jeremy Appleyard, Nando de Freitas", "title": "ACDC: A Structured Efficient Linear Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The linear layer is one of the most pervasive modules in deep learning\nrepresentations. However, it requires $O(N^2)$ parameters and $O(N^2)$\noperations. These costs can be prohibitive in mobile applications or prevent\nscaling in many domains. Here, we introduce a deep, differentiable,\nfully-connected neural network module composed of diagonal matrices of\nparameters, $\\mathbf{A}$ and $\\mathbf{D}$, and the discrete cosine transform\n$\\mathbf{C}$. The core module, structured as $\\mathbf{ACDC^{-1}}$, has $O(N)$\nparameters and incurs $O(N log N )$ operations. We present theoretical results\nshowing how deep cascades of ACDC layers approximate linear layers. ACDC is,\nhowever, a stand-alone module and can be used in combination with any other\ntypes of module. In our experiments, we show that it can indeed be successfully\ninterleaved with ReLU modules in convolutional neural networks for image\nrecognition. Our experiments also study critical factors in the training of\nthese structured modules, including initialization and depth. Finally, this\npaper also provides a connection between structured linear transforms used in\ndeep learning and the field of Fourier optics, illustrating how ACDC could in\nprinciple be implemented with lenses and diffractive elements.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:52:17 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 01:37:57 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2016 02:27:52 GMT"}, {"version": "v4", "created": "Tue, 1 Mar 2016 03:37:23 GMT"}, {"version": "v5", "created": "Sat, 19 Mar 2016 23:31:15 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Moczulski", "Marcin", ""], ["Denil", "Misha", ""], ["Appleyard", "Jeremy", ""], ["de Freitas", "Nando", ""]]}, {"id": "1511.05950", "submitter": "Wei Zhang", "authors": "Wei Zhang, Suyog Gupta, Xiangru Lian, Ji Liu", "title": "Staleness-aware Async-SGD for Distributed Deep Learning", "comments": "Accepted by IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been shown to achieve state-of-the-art performance\nin several machine learning tasks. Stochastic Gradient Descent (SGD) is the\npreferred optimization algorithm for training these networks and asynchronous\nSGD (ASGD) has been widely adopted for accelerating the training of large-scale\ndeep networks in a distributed computing environment. However, in practice it\nis quite challenging to tune the training hyperparameters (such as learning\nrate) when using ASGD so as achieve convergence and linear speedup, since the\nstability of the optimization algorithm is strongly influenced by the\nasynchronous nature of parameter updates. In this paper, we propose a variant\nof the ASGD algorithm in which the learning rate is modulated according to the\ngradient staleness and provide theoretical guarantees for convergence of this\nalgorithm. Experimental verification is performed on commonly-used image\nclassification benchmarks: CIFAR10 and Imagenet to demonstrate the superior\neffectiveness of the proposed approach, compared to SSGD (Synchronous SGD) and\nthe conventional ASGD algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:53:33 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 16:36:23 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2015 20:34:57 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2015 22:38:52 GMT"}, {"version": "v5", "created": "Tue, 5 Apr 2016 06:21:03 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Zhang", "Wei", ""], ["Gupta", "Suyog", ""], ["Lian", "Xiangru", ""], ["Liu", "Ji", ""]]}, {"id": "1511.05952", "submitter": "Tom Schaul", "authors": "Tom Schaul, John Quan, Ioannis Antonoglou, David Silver", "title": "Prioritized Experience Replay", "comments": "Published at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience replay lets online reinforcement learning agents remember and\nreuse experiences from the past. In prior work, experience transitions were\nuniformly sampled from a replay memory. However, this approach simply replays\ntransitions at the same frequency that they were originally experienced,\nregardless of their significance. In this paper we develop a framework for\nprioritizing experience, so as to replay important transitions more frequently,\nand therefore learn more efficiently. We use prioritized experience replay in\nDeep Q-Networks (DQN), a reinforcement learning algorithm that achieved\nhuman-level performance across many Atari games. DQN with prioritized\nexperience replay achieves a new state-of-the-art, outperforming DQN with\nuniform replay on 41 out of 49 games.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 20:54:44 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 18:38:04 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 01:53:42 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2016 17:55:31 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Schaul", "Tom", ""], ["Quan", "John", ""], ["Antonoglou", "Ioannis", ""], ["Silver", "David", ""]]}, {"id": "1511.06001", "submitter": "Francesca Giordaniello", "authors": "Francesca Giordaniello", "title": "A pilot study on the daily control capability of s-EMG prosthetic hands\n  by amputees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography is a valid tool to gather muscular contraction\nsignals from intact and amputated subjects. Electromyographic signals can be\nused to control prosthetic devices in a noninvasive way distinguishing the\nmovements performed by the particular EMG electrodes activity. According to the\nliterature, several algorithms have been used to control prosthetic hands\nthrough s-EMG signals. The main issue is to correctly classify the signals\nacquired as the movement actually performed. This work presents a study on the\nSupport Vector Machine's performance in a short-time period, gained using two\ndifferent feature representation (Mean Absolute Value and Waveform Length) of\nthe sEMG signals. In particular, we paid close attention to the repeatability\nproblem, that is the capability to achieve a stable and satisfactory level of\naccuracy in repeated experiments. Results on a limited setting are encouraging,\nas they show an average accuracy above 73% even in the worst case scenario.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 22:13:39 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 10:06:14 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Giordaniello", "Francesca", ""]]}, {"id": "1511.06004", "submitter": "Mara Graziani Ms", "authors": "Mara Graziani", "title": "Studying the control of non invasive prosthetic hands over large time\n  spans", "comments": "10 pages, 18 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electromyography (EMG) signal is the electrical manifestation of a\nneuromuscular activation that provides access to physiological processes which\ncause the muscle to generate force and produce movement. Non invasive\nprostheses use such signals detected by the electrodes placed on the user's\nstump, as input to generate hand posture movements according to the intentions\nof the prosthesis wearer. The aim of this pilot study is to explore the\nrepeatability issue, i.e. the ability to classify 17 different hand postures,\nrepresented by EMG signal, across a time span of days by a control algorithm.\nData collection experiments lasted four days and signals were collected from\nthe forearm of a single subject. We find that Support Vector Machine (SVM)\nclassification results are high enough to guarantee a correct classification of\nmore than 10 postures in each moment of the considered time span.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 22:29:03 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Graziani", "Mara", ""]]}, {"id": "1511.06014", "submitter": "Tor Lattimore", "authors": "Tor Lattimore", "title": "Regret Analysis of the Finite-Horizon Gittins Index Strategy for\n  Multi-Armed Bandits", "comments": "32 pages, to appear in COLT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I analyse the frequentist regret of the famous Gittins index strategy for\nmulti-armed bandits with Gaussian noise and a finite horizon. Remarkably it\nturns out that this approach leads to finite-time regret guarantees comparable\nto those available for the popular UCB algorithm. Along the way I derive\nfinite-time bounds on the Gittins index that are asymptotically exact and may\nbe of independent interest. I also discuss some computational issues and\npresent experimental results suggesting that a particular version of the\nGittins index strategy is a modest improvement on existing algorithms with\nfinite-time regret guarantees such as UCB and Thompson sampling.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 22:52:26 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 01:31:35 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 22:07:00 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Lattimore", "Tor", ""]]}, {"id": "1511.06018", "submitter": "Lingpeng Kong", "authors": "Lingpeng Kong, Chris Dyer, Noah A. Smith", "title": "Segmental Recurrent Neural Networks", "comments": "10 pages, published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce segmental recurrent neural networks (SRNNs) which define, given\nan input sequence, a joint probability distribution over segmentations of the\ninput and labelings of the segments. Representations of the input segments\n(i.e., contiguous subsequences of the input) are computed by encoding their\nconstituent tokens using bidirectional recurrent neural nets, and these\n\"segment embeddings\" are used to define compatibility scores with output\nlabels. These local compatibility scores are integrated using a global\nsemi-Markov conditional random field. Both fully supervised training -- in\nwhich segment boundaries and labels are observed -- as well as partially\nsupervised training -- in which segment boundaries are latent -- are\nstraightforward. Experiments on handwriting recognition and joint Chinese word\nsegmentation/POS tagging show that, compared to models that do not explicitly\nrepresent segments such as BIO tagging schemes and connectionist temporal\nclassification (CTC), SRNNs obtain substantially higher accuracies.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 23:02:45 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 22:46:37 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Kong", "Lingpeng", ""], ["Dyer", "Chris", ""], ["Smith", "Noah A.", ""]]}, {"id": "1511.06038", "submitter": "Yishu Miao", "authors": "Yishu Miao, Lei Yu and Phil Blunsom", "title": "Neural Variational Inference for Text Processing", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural variational inference have spawned a renaissance in\ndeep latent variable models. In this paper we introduce a generic variational\ninference framework for generative and conditional models of text. While\ntraditional variational methods derive an analytic approximation for the\nintractable distributions over latent variables, here we construct an inference\nnetwork conditioned on the discrete text input to provide the variational\ndistribution. We validate this framework on two very different text modelling\napplications, generative document modelling and supervised question answering.\nOur neural variational document model combines a continuous stochastic document\nrepresentation with a bag-of-words generative model and achieves the lowest\nreported perplexities on two standard test corpora. The neural answer selection\nmodel employs a stochastic representation layer within an attention mechanism\nto extract the semantics between a question and answer pair. On two question\nanswering benchmarks this model exceeds all previous published benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 01:23:28 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 14:35:48 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 19:49:17 GMT"}, {"version": "v4", "created": "Sat, 4 Jun 2016 06:41:58 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Miao", "Yishu", ""], ["Yu", "Lei", ""], ["Blunsom", "Phil", ""]]}, {"id": "1511.06049", "submitter": "Deyu Meng", "authors": "Deyu Meng and Qian Zhao and Lu Jiang", "title": "What Objective Does Self-paced Learning Indeed Optimize?", "comments": "25 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Self-paced learning (SPL) is a recently raised methodology designed through\nsimulating the learning principle of humans/animals. A variety of SPL\nrealization schemes have been designed for different computer vision and\npattern recognition tasks, and empirically substantiated to be effective in\nthese applications. However, the investigation on its theoretical insight is\nstill a blank. To this issue, this study attempts to provide some new\ntheoretical understanding under the SPL scheme. Specifically, we prove that the\nsolving strategy on SPL accords with a majorization minimization algorithm\nimplemented on a latent objective function. Furthermore, we find that the loss\nfunction contained in this latent objective has a similar configuration with\nnon-convex regularized penalty (NSPR) known in statistics and machine learning.\nSuch connection inspires us discovering more intrinsic relationship between SPL\nregimes and NSPR forms, like SCAD, LOG and EXP. The robustness insight under\nSPL can then be finely explained. We also analyze the capability of SPL on its\neasy loss prior embedding property, and provide an insightful interpretation to\nthe effectiveness mechanism under previous SPL variations. Besides, we design a\ngroup-partial-order loss prior, which is especially useful to weakly labeled\nlarge-scale data processing tasks. Through applying SPL with this loss prior to\nthe FCVID dataset, which is currently one of the biggest manually annotated\nvideo dataset, our method achieves state-of-the-art performance beyond previous\nmethods, which further helps supports the proposed theoretical arguments.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 02:55:18 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 13:59:27 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Meng", "Deyu", ""], ["Zhao", "Qian", ""], ["Jiang", "Lu", ""]]}, {"id": "1511.06051", "submitter": "Robert Nishihara", "authors": "Philipp Moritz, Robert Nishihara, Ion Stoica, Michael I. Jordan", "title": "SparkNet: Training Deep Networks in Spark", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep networks is a time-consuming process, with networks for object\nrecognition often requiring multiple days to train. For this reason, leveraging\nthe resources of a cluster to speed up training is an important area of work.\nHowever, widely-popular batch-processing computational frameworks like\nMapReduce and Spark were not designed to support the asynchronous and\ncommunication-intensive workloads of existing distributed deep learning\nsystems. We introduce SparkNet, a framework for training deep networks in\nSpark. Our implementation includes a convenient interface for reading data from\nSpark RDDs, a Scala interface to the Caffe deep learning framework, and a\nlightweight multi-dimensional tensor library. Using a simple parallelization\nscheme for stochastic gradient descent, SparkNet scales well with the cluster\nsize and tolerates very high-latency communication. Furthermore, it is easy to\ndeploy and use with no parameter tuning, and it is compatible with existing\nCaffe models. We quantify the dependence of the speedup obtained by SparkNet on\nthe number of machines, the communication frequency, and the cluster's\ncommunication overhead, and we benchmark our system's performance on the\nImageNet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 03:29:56 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2015 10:35:40 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 07:48:06 GMT"}, {"version": "v4", "created": "Sun, 28 Feb 2016 23:43:36 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Moritz", "Philipp", ""], ["Nishihara", "Robert", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1511.06063", "submitter": "Nirav Bhatt", "authors": "P Satya Jayadev, Aravind Rajeswaran, Nirav P Bhatt, Ramkrishna\n  Pasumarthy", "title": "A Novel Approach for Phase Identification in Smart Grids Using Graph\n  Theory and Principal Component Analysis", "comments": "Accepted for the presentation at ACC 16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumers with low demand, like households, are generally supplied\nsingle-phase power by connecting their service mains to one of the phases of a\ndistribution transformer. The distribution companies face the problem of\nkeeping a record of consumer connectivity to a phase due to uninformed changes\nthat happen. The exact phase connectivity information is important for the\nefficient operation and control of distribution system. We propose a new data\ndriven approach to the problem based on Principal Component Analysis (PCA) and\nits Graph Theoretic interpretations, using energy measurements in equally timed\nshort intervals, generated from smart meters. We propose an algorithm for\ninferring phase connectivity from noisy measurements. The algorithm is\ndemonstrated using simulated data for phase connectivities in distribution\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 05:39:16 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 14:31:29 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Jayadev", "P Satya", ""], ["Rajeswaran", "Aravind", ""], ["Bhatt", "Nirav P", ""], ["Pasumarthy", "Ramkrishna", ""]]}, {"id": "1511.06065", "submitter": "Yang Gao", "authors": "Yang Gao, Lisa Anne Hendricks, Katherine J. Kuchenbecker, Trevor\n  Darrell", "title": "Deep Learning for Tactile Understanding From Visual and Haptic Data", "comments": "Camera ready version for ICRA 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots which interact with the physical world will benefit from a\nfine-grained tactile understanding of objects and surfaces. Additionally, for\ncertain tasks, robots may need to know the haptic properties of an object\nbefore touching it. To enable better tactile understanding for robots, we\npropose a method of classifying surfaces with haptic adjectives (e.g.,\ncompressible or smooth) from both visual and physical interaction data. Humans\ntypically combine visual predictions and feedback from physical interactions to\naccurately predict haptic properties and interact with the world. Inspired by\nthis cognitive pattern, we propose and explore a purely visual haptic\nprediction model. Purely visual models enable a robot to \"feel\" without\nphysical interaction. Furthermore, we demonstrate that using both visual and\nphysical interaction signals together yields more accurate haptic\nclassification. Our models take advantage of recent advances in deep neural\nnetworks by employing a unified approach to learning features for physical\ninteraction and visual observations. Even though we employ little domain\nspecific knowledge, our model still achieves better results than methods based\non hand-designed features.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 05:52:15 GMT"}, {"version": "v2", "created": "Tue, 12 Apr 2016 00:16:21 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Gao", "Yang", ""], ["Hendricks", "Lisa Anne", ""], ["Kuchenbecker", "Katherine J.", ""], ["Darrell", "Trevor", ""]]}, {"id": "1511.06066", "submitter": "Dong Wang", "authors": "Dong Wang and Thomas Fang Zheng", "title": "Transfer Learning for Speech and Language Processing", "comments": "13 pages, APSIPA 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is a vital technique that generalizes models trained for\none setting or task to other settings or tasks. For example in speech\nrecognition, an acoustic model trained for one language can be used to\nrecognize speech in another language, with little or no re-training data.\nTransfer learning is closely related to multi-task learning (cross-lingual vs.\nmultilingual), and is traditionally studied in the name of `model adaptation'.\nRecent advance in deep learning shows that transfer learning becomes much\neasier and more effective with high-level abstract features learned by deep\nmodels, and the `transfer' can be conducted not only between data distributions\nand data types, but also between model structures (e.g., shallow nets and deep\nnets) or even model types (e.g., Bayesian models and neural models). This\nreview paper summarizes some recent prominent research towards this direction,\nparticularly for speech and language processing. We also report some results\nfrom our group and highlight the potential of this very interesting research\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 05:54:45 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Wang", "Dong", ""], ["Zheng", "Thomas Fang", ""]]}, {"id": "1511.06067", "submitter": "Cheng Tai", "authors": "Cheng Tai, Tong Xiao, Yi Zhang, Xiaogang Wang, Weinan E", "title": "Convolutional neural networks with low-rank regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large CNNs have delivered impressive performance in various computer vision\napplications. But the storage and computation requirements make it problematic\nfor deploying these models on mobile devices. Recently, tensor decompositions\nhave been used for speeding up CNNs. In this paper, we further develop the\ntensor decomposition technique. We propose a new algorithm for computing the\nlow-rank tensor decomposition for removing the redundancy in the convolution\nkernels. The algorithm finds the exact global optimizer of the decomposition\nand is more effective than iterative methods. Based on the decomposition, we\nfurther propose a new method for training low-rank constrained CNNs from\nscratch. Interestingly, while achieving a significant speedup, sometimes the\nlow-rank constrained CNNs delivers significantly better performance than their\nnon-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rank\nNIN model achieves $91.31\\%$ accuracy (without data augmentation), which also\nimproves upon state-of-the-art result. We evaluated the proposed method on\nCIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet,\nNIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 is\nreduced by half while the performance is still comparable. Empirical success\nsuggests that low-rank tensor decompositions can be a very useful tool for\nspeeding up large CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 06:13:55 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 23:46:17 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2016 03:46:09 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Tai", "Cheng", ""], ["Xiao", "Tong", ""], ["Zhang", "Yi", ""], ["Wang", "Xiaogang", ""], ["E", "Weinan", ""]]}, {"id": "1511.06068", "submitter": "Michael Cogswell", "authors": "Michael Cogswell, Faruk Ahmed, Ross Girshick, Larry Zitnick, Dhruv\n  Batra", "title": "Reducing Overfitting in Deep Networks by Decorrelating Representations", "comments": "12 pages, 5 figures, 5 tables, Accepted to ICLR 2016, (v4 adds\n  acknowledgements)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major challenge in training Deep Neural Networks is preventing\noverfitting. Many techniques such as data augmentation and novel regularizers\nsuch as Dropout have been proposed to prevent overfitting without requiring a\nmassive amount of training data. In this work, we propose a new regularizer\ncalled DeCov which leads to significantly reduced overfitting (as indicated by\nthe difference between train and val performance), and better generalization.\nOur regularizer encourages diverse or non-redundant representations in Deep\nNeural Networks by minimizing the cross-covariance of hidden activations. This\nsimple intuition has been explored in a number of past works but surprisingly\nhas never been applied as a regularizer in supervised learning. Experiments\nacross a range of datasets and network architectures show that this loss always\nreduces overfitting while almost always maintaining or increasing\ngeneralization performance and often improving performance over Dropout.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 06:23:09 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 21:12:29 GMT"}, {"version": "v3", "created": "Mon, 29 Feb 2016 21:23:05 GMT"}, {"version": "v4", "created": "Fri, 10 Jun 2016 10:59:37 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Cogswell", "Michael", ""], ["Ahmed", "Faruk", ""], ["Girshick", "Ross", ""], ["Zitnick", "Larry", ""], ["Batra", "Dhruv", ""]]}, {"id": "1511.06072", "submitter": "Sebastian Agethen", "authors": "Sebastian Agethen, Winston H. Hsu", "title": "Mediated Experts for Deep Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new supervised architecture termed Mediated Mixture-of-Experts\n(MMoE) that allows us to improve classification accuracy of Deep Convolutional\nNetworks (DCN). Our architecture achieves this with the help of expert\nnetworks: A network is trained on a disjoint subset of a given dataset and then\nrun in parallel to other experts during deployment. A mediator is employed if\nexperts contradict each other. This allows our framework to naturally support\nincremental learning, as adding new classes requires (re-)training of the new\nexpert only. We also propose two measures to control computational complexity:\nAn early-stopping mechanism halts experts that have low confidence in their\nprediction. The system allows to trade-off accuracy and complexity without\nfurther retraining. We also suggest to share low-level convolutional layers\nbetween experts in an effort to avoid computation of a near-duplicate feature\nset. We evaluate our system on a popular dataset and report improved accuracy\ncompared to a single model of same configuration.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 07:01:36 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Agethen", "Sebastian", ""], ["Hsu", "Winston H.", ""]]}, {"id": "1511.06078", "submitter": "Liwei Wang", "authors": "Liwei Wang, Yin Li, Svetlana Lazebnik", "title": "Learning Deep Structure-Preserving Image-Text Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for learning joint embeddings of images and text\nusing a two-branch neural network with multiple layers of linear projections\nfollowed by nonlinearities. The network is trained using a large margin\nobjective that combines cross-view ranking constraints with within-view\nneighborhood structure preservation constraints inspired by metric learning\nliterature. Extensive experiments show that our approach gains significant\nimprovements in accuracy for image-to-text and text-to-image retrieval. Our\nmethod achieves new state-of-the-art results on the Flickr30K and MSCOCO\nimage-sentence datasets and shows promise on the new task of phrase\nlocalization on the Flickr30K Entities dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 07:17:49 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2016 03:10:04 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Wang", "Liwei", ""], ["Li", "Yin", ""], ["Lazebnik", "Svetlana", ""]]}, {"id": "1511.06085", "submitter": "George Toderici", "authors": "George Toderici, Sean M. O'Malley, Sung Jin Hwang, Damien Vincent,\n  David Minnen, Shumeet Baluja, Michele Covell, Rahul Sukthankar", "title": "Variable Rate Image Compression with Recurrent Neural Networks", "comments": "Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large fraction of Internet traffic is now driven by requests from mobile\ndevices with relatively small screens and often stringent bandwidth\nrequirements. Due to these factors, it has become the norm for modern\ngraphics-heavy websites to transmit low-resolution, low-bytecount image\npreviews (thumbnails) as part of the initial page load process to improve\napparent page responsiveness. Increasing thumbnail compression beyond the\ncapabilities of existing codecs is therefore a current research focus, as any\nbyte savings will significantly enhance the experience of mobile device users.\nToward this end, we propose a general framework for variable-rate image\ncompression and a novel architecture based on convolutional and deconvolutional\nLSTM recurrent networks. Our models address the main issues that have prevented\nautoencoder neural networks from competing with existing image compression\nalgorithms: (1) our networks only need to be trained once (not per-image),\nregardless of input image dimensions and the desired compression rate; (2) our\nnetworks are progressive, meaning that the more bits are sent, the more\naccurate the image reconstruction; and (3) the proposed architecture is at\nleast as efficient as a standard purpose-trained autoencoder for a given number\nof bits. On a large-scale benchmark of 32$\\times$32 thumbnails, our LSTM-based\napproaches provide better visual quality than (headerless) JPEG, JPEG2000 and\nWebP, with a storage size that is reduced by 10% or more.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 07:50:46 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2015 01:44:51 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2016 02:43:40 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2016 20:57:42 GMT"}, {"version": "v5", "created": "Tue, 1 Mar 2016 22:13:44 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Toderici", "George", ""], ["O'Malley", "Sean M.", ""], ["Hwang", "Sung Jin", ""], ["Vincent", "Damien", ""], ["Minnen", "David", ""], ["Baluja", "Shumeet", ""], ["Covell", "Michele", ""], ["Sukthankar", "Rahul", ""]]}, {"id": "1511.06103", "submitter": "Pierre Baque", "authors": "Pierre Baqu\\'e, Timur Bagautdinov, Fran\\c{c}ois Fleuret and Pascal Fua", "title": "Principled Parallel Mean-Field Inference for Discrete Random Fields", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean-field variational inference is one of the most popular approaches to\ninference in discrete random fields. Standard mean-field optimization is based\non coordinate descent and in many situations can be impractical. Thus, in\npractice, various parallel techniques are used, which either rely on ad-hoc\nsmoothing with heuristically set parameters, or put strong constraints on the\ntype of models. In this paper, we propose a novel proximal gradient-based\napproach to optimizing the variational objective. It is naturally\nparallelizable and easy to implement. We prove its convergence, and then\ndemonstrate that, in practice, it yields faster convergence and often finds\nbetter optima than more traditional mean-field optimization techniques.\nMoreover, our method is less sensitive to the choice of parameters.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 09:44:20 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 10:26:03 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Baqu\u00e9", "Pierre", ""], ["Bagautdinov", "Timur", ""], ["Fleuret", "Fran\u00e7ois", ""], ["Fua", "Pascal", ""]]}, {"id": "1511.06104", "submitter": "Sheng-Yi Bai", "authors": "Sheng-Yi Bai, Sebastian Agethen, Ting-Hsuan Chao, Winston Hsu", "title": "Semi-supervised Learning for Convolutional Neural Networks via Online\n  Graph Construction", "comments": "As the original submission of iclr is withdrawn, the arxiv submission\n  should be withdrawn as well", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent promising achievements of deep learning rely on the large amount\nof labeled data. Considering the abundance of data on the web, most of them do\nnot have labels at all. Therefore, it is important to improve generalization\nperformance using unlabeled data on supervised tasks with few labeled\ninstances. In this work, we revisit graph-based semi-supervised learning\nalgorithms and propose an online graph construction technique which suits deep\nconvolutional neural network better. We consider an EM-like algorithm for\nsemi-supervised learning on deep neural networks: In forward pass, the graph is\nconstructed based on the network output, and the graph is then used for loss\ncalculation to help update the network by back propagation in the backward\npass. We demonstrate the strength of our online approach compared to the\nconventional ones whose graph is constructed on static but not robust enough\nfeature representations beforehand.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 09:44:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 00:56:08 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Bai", "Sheng-Yi", ""], ["Agethen", "Sebastian", ""], ["Chao", "Ting-Hsuan", ""], ["Hsu", "Winston", ""]]}, {"id": "1511.06114", "submitter": "Minh-Thang Luong", "authors": "Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, Lukasz\n  Kaiser", "title": "Multi-task Sequence to Sequence Learning", "comments": "10 pages, 4 figures, ICLR 2016 camera-ready, added parsing SOTA\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence to sequence learning has recently emerged as a new paradigm in\nsupervised learning. To date, most of its applications focused on only one task\nand not much work explored this framework for multiple tasks. This paper\nexamines three multi-task learning (MTL) settings for sequence to sequence\nmodels: (a) the oneto-many setting - where the encoder is shared between\nseveral tasks such as machine translation and syntactic parsing, (b) the\nmany-to-one setting - useful when only the decoder can be shared, as in the\ncase of translation and image caption generation, and (c) the many-to-many\nsetting - where multiple encoders and decoders are shared, which is the case\nwith unsupervised objectives and translation. Our results show that training on\na small amount of parsing and image caption data can improve the translation\nquality between English and German by up to 1.5 BLEU points over strong\nsingle-task baselines on the WMT benchmarks. Furthermore, we have established a\nnew state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we\nreveal interesting properties of the two unsupervised learning objectives,\nautoencoder and skip-thought, in the MTL context: autoencoder helps less in\nterms of perplexities but more on BLEU scores compared to skip-thought.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 10:24:14 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 06:46:29 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2016 08:10:59 GMT"}, {"version": "v4", "created": "Tue, 1 Mar 2016 10:55:58 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Luong", "Minh-Thang", ""], ["Le", "Quoc V.", ""], ["Sutskever", "Ilya", ""], ["Vinyals", "Oriol", ""], ["Kaiser", "Lukasz", ""]]}, {"id": "1511.06147", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey, Nikhil Naik, Dan Raviv, Rahul Sukthankar and Ramesh\n  Raskar", "title": "Coreset-Based Adaptive Tracking", "comments": "8 pages, 5 figures, In submission to IEEE TPAMI (Transactions on\n  Pattern Analysis and Machine Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for learning from streaming visual data using a compact,\nconstant size representation of all the data that was seen until a given\nmoment. Specifically, we construct a 'coreset' representation of streaming data\nusing a parallelized algorithm, which is an approximation of a set with\nrelation to the squared distances between this set and all other points in its\nambient space. We learn an adaptive object appearance model from the coreset\ntree in constant time and logarithmic space and use it for object tracking by\ndetection. Our method obtains excellent results for object tracking on three\nstandard datasets over more than 100 videos. The ability to summarize data\nefficiently makes our method ideally suited for tracking in long videos in\npresence of space and time constraints. We demonstrate this ability by\noutperforming a variety of algorithms on the TLD dataset with 2685 frames on\naverage. This coreset based learning approach can be applied for both real-time\nlearning of small, varied data and fast learning of big data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 12:59:20 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Naik", "Nikhil", ""], ["Raviv", "Dan", ""], ["Sukthankar", "Rahul", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1511.06201", "submitter": "Zhirong Wu", "authors": "Zhirong Wu, Dahua Lin, Xiaoou Tang", "title": "Adjustable Bounded Rectifiers: Towards Deep Binary Representations", "comments": "Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary representation is desirable for its memory efficiency, computation\nspeed and robustness. In this paper, we propose adjustable bounded rectifiers\nto learn binary representations for deep neural networks. While hard\nconstraining representations across layers to be binary makes training\nunreasonably difficult, we softly encourage activations to diverge from real\nvalues to binary by approximating step functions. Our final representation is\ncompletely binary. We test our approach on MNIST, CIFAR10, and ILSVRC2012\ndataset, and systematically study the training dynamics of the binarization\nprocess. Our approach can binarize the last layer representation without loss\nof performance and binarize all the layers with reasonably small degradations.\nThe memory space that it saves may allow more sophisticated models to be\ndeployed, thus compensating the loss. To the best of our knowledge, this is the\nfirst work to report results on current deep network architectures using\ncomplete binary middle representations. Given the learned representations, we\nfind that the firing or inhibition of a binary neuron is usually associated\nwith a meaningful interpretation across different classes. This suggests that\nthe semantic structure of a neural network may be manifested through a guided\nbinarization process.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 15:14:02 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Wu", "Zhirong", ""], ["Lin", "Dahua", ""], ["Tang", "Xiaoou", ""]]}, {"id": "1511.06208", "submitter": "Moshe Salhov", "authors": "Moshe Salhov and Amit Bermanis and Guy Wolf and Amir Averbuch", "title": "Diffusion Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion Maps framework is a kernel based method for manifold learning and\ndata analysis that defines diffusion similarities by imposing a Markovian\nprocess on the given dataset. Analysis by this process uncovers the intrinsic\ngeometric structures in the data. Recently, it was suggested to replace the\nstandard kernel by a measure-based kernel that incorporates information about\nthe density of the data. Thus, the manifold assumption is replaced by a more\ngeneral measure-based assumption.\n  The measure-based diffusion kernel incorporates two separate independent\nrepresentations. The first determines a measure that correlates with a density\nthat represents normal behaviors and patterns in the data. The second consists\nof the analyzed multidimensional data points.\n  In this paper, we present a representation framework for data analysis of\ndatasets that is based on a closed-form decomposition of the measure-based\nkernel. The proposed representation preserves pairwise diffusion distances that\ndoes not depend on the data size while being invariant to scale. For a\nstationary data, no out-of-sample extension is needed for embedding newly\narrived data points in the representation space. Several aspects of the\npresented methodology are demonstrated on analytically generated data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 15:30:39 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Salhov", "Moshe", ""], ["Bermanis", "Amit", ""], ["Wolf", "Guy", ""], ["Averbuch", "Amir", ""]]}, {"id": "1511.06219", "submitter": "Lucas Sterckx", "authors": "Lucas Sterckx and Thomas Demeester and Johannes Deleu and Chris\n  Develder", "title": "Knowledge Base Population using Semantic Label Propagation", "comments": "Submitted to Knowledge Based Systems, special issue on Knowledge\n  Bases for Natural Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial aspect of a knowledge base population system that extracts new\nfacts from text corpora, is the generation of training data for its relation\nextractors. In this paper, we present a method that maximizes the effectiveness\nof newly trained relation extractors at a minimal annotation cost. Manual\nlabeling can be significantly reduced by Distant Supervision, which is a method\nto construct training data automatically by aligning a large text corpus with\nan existing knowledge base of known facts. For example, all sentences\nmentioning both 'Barack Obama' and 'US' may serve as positive training\ninstances for the relation born_in(subject,object). However, distant\nsupervision typically results in a highly noisy training set: many training\nsentences do not really express the intended relation. We propose to combine\ndistant supervision with minimal manual supervision in a technique called\nfeature labeling, to eliminate noise from the large and noisy initial training\nset, resulting in a significant increase of precision. We further improve on\nthis approach by introducing the Semantic Label Propagation method, which uses\nthe similarity between low-dimensional representations of candidate training\ninstances, to extend the training set in order to increase recall while\nmaintaining high precision. Our proposed strategy for generating training data\nis studied and evaluated on an established test collection designed for\nknowledge base population tasks. The experimental results show that the\nSemantic Label Propagation strategy leads to substantial performance gains when\ncompared to existing approaches, while requiring an almost negligible manual\nannotation effort.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 15:51:31 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 11:52:14 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Sterckx", "Lucas", ""], ["Demeester", "Thomas", ""], ["Deleu", "Johannes", ""], ["Develder", "Chris", ""]]}, {"id": "1511.06233", "submitter": "Abhijit Bendale", "authors": "Abhijit Bendale, Terrance Boult", "title": "Towards Open Set Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have produced significant gains for various visual recognition\nproblems, leading to high impact academic and commercial applications. Recent\nwork in deep networks highlighted that it is easy to generate images that\nhumans would never classify as a particular object class, yet networks classify\nsuch images high confidence as that given class - deep network are easily\nfooled with images humans do not consider meaningful. The closed set nature of\ndeep networks forces them to choose from one of the known classes leading to\nsuch artifacts. Recognition in the real world is open set, i.e. the recognition\nsystem should reject unknown/unseen classes at test time. We present a\nmethodology to adapt deep networks for open set recognition, by introducing a\nnew model layer, OpenMax, which estimates the probability of an input being\nfrom an unknown class. A key element of estimating the unknown probability is\nadapting Meta-Recognition concepts to the activation patterns in the\npenultimate layer of the network. OpenMax allows rejection of \"fooling\" and\nunrelated open set images presented to the system; OpenMax greatly reduces the\nnumber of obvious errors made by a deep network. We prove that the OpenMax\nconcept provides bounded open space risk, thereby formally providing an open\nset recognition solution. We evaluate the resulting open set deep networks\nusing pre-trained networks from the Caffe Model-zoo on ImageNet 2012 validation\ndata, and thousands of fooling and open set images. The proposed OpenMax model\nsignificantly outperforms open set recognition accuracy of basic deep networks\nas well as deep networks with thresholding of SoftMax probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 16:13:55 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Bendale", "Abhijit", ""], ["Boult", "Terrance", ""]]}, {"id": "1511.06238", "submitter": "Miriam Cha", "authors": "Miriam Cha, Youngjune Gwon, H.T. Kung", "title": "Multimodal sparse representation learning and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised methods have proven effective for discriminative tasks in a\nsingle-modality scenario. In this paper, we present a multimodal framework for\nlearning sparse representations that can capture semantic correlation between\nmodalities. The framework can model relationships at a higher level by forcing\nthe shared sparse representation. In particular, we propose the use of joint\ndictionary learning technique for sparse coding and formulate the joint\nrepresentation for concision, cross-modal representations (in case of a missing\nmodality), and union of the cross-modal representations. Given the accelerated\ngrowth of multimodal data posted on the Web such as YouTube, Wikipedia, and\nTwitter, learning good multimodal features is becoming increasingly important.\nWe show that the shared representations enabled by our framework substantially\nimprove the classification performance under both unimodal and multimodal\nsettings. We further show how deep architectures built on the proposed\nframework are effective for the case of highly nonlinear correlations between\nmodalities. The effectiveness of our approach is demonstrated experimentally in\nimage denoising, multimedia event detection and retrieval on the TRECVID\ndataset (audio-video), category classification on the Wikipedia dataset\n(image-text), and sentiment classification on PhotoTweet (image-text).\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 16:26:24 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2016 23:18:09 GMT"}, {"version": "v3", "created": "Wed, 2 Mar 2016 19:22:48 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Cha", "Miriam", ""], ["Gwon", "Youngjune", ""], ["Kung", "H. T.", ""]]}, {"id": "1511.06241", "submitter": "Aysegul Dundar", "authors": "Aysegul Dundar, Jonghoon Jin and Eugenio Culurciello", "title": "Convolutional Clustering for Unsupervised Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of labeling data for training deep neural networks is daunting and\ntedious, requiring millions of labels to achieve the current state-of-the-art\nresults. Such reliance on large amounts of labeled data can be relaxed by\nexploiting hierarchical features via unsupervised learning techniques. In this\nwork, we propose to train a deep convolutional network based on an enhanced\nversion of the k-means clustering algorithm, which reduces the number of\ncorrelated parameters in the form of similar filters, and thus increases test\ncategorization accuracy. We call our algorithm convolutional k-means\nclustering. We further show that learning the connection between the layers of\na deep convolutional neural network improves its ability to be trained on a\nsmaller amount of labeled data. Our experiments show that the proposed\nalgorithm outperforms other techniques that learn filters unsupervised.\nSpecifically, we obtained a test accuracy of 74.1% on STL-10 and a test error\nof 0.5% on MNIST.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 16:31:46 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 16:46:53 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Dundar", "Aysegul", ""], ["Jin", "Jonghoon", ""], ["Culurciello", "Eugenio", ""]]}, {"id": "1511.06247", "submitter": "Armando Vieira", "authors": "Armando Vieira", "title": "Predicting online user behaviour using deep learning algorithms", "comments": "21 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1412.6601, arXiv:1406.1231, arXiv:1508.03856 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust classifier to predict buying intentions based on user\nbehaviour within a large e-commerce website. In this work we compare\ntraditional machine learning techniques with the most advanced deep learning\napproaches. We show that both Deep Belief Networks and Stacked Denoising\nauto-Encoders achieved a substantial improvement by extracting features from\nhigh dimensional data during the pre-train phase. They prove also to be more\nconvenient to deal with severe class imbalance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 16:47:00 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2015 18:53:45 GMT"}, {"version": "v3", "created": "Thu, 26 May 2016 11:53:55 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Vieira", "Armando", ""]]}, {"id": "1511.06251", "submitter": "Qianxiao Li", "authors": "Qianxiao Li, Cheng Tai, Weinan E", "title": "Stochastic modified equations and adaptive stochastic gradient\n  algorithms", "comments": "Major changes including a proof of the weak approximation, asymptotic\n  expansions and application-oriented adaptive algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the method of stochastic modified equations (SME), in which\nstochastic gradient algorithms are approximated in the weak sense by\ncontinuous-time stochastic differential equations. We exploit the continuous\nformulation together with optimal control theory to derive novel adaptive\nhyper-parameter adjustment policies. Our algorithms have competitive\nperformance with the added benefit of being robust to varying models and\ndatasets. This provides a general methodology for the analysis and design of\nstochastic gradient algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 16:49:33 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 19:58:15 GMT"}, {"version": "v3", "created": "Tue, 20 Jun 2017 13:56:33 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Li", "Qianxiao", ""], ["Tai", "Cheng", ""], ["E", "Weinan", ""]]}, {"id": "1511.06267", "submitter": "Youssef  Mroueh", "authors": "Youssef Mroueh, Etienne Marcheret, Vaibhava Goel", "title": "Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding\n  For Image & Text Retrieval", "comments": "Under Review CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint modeling of language and vision has been drawing increasing interest. A\nmultimodal data representation allowing for bidirectional retrieval of images\nby sentences and vice versa is a key aspect. In this paper we present three\ncontributions in canonical correlation analysis (CCA) based multimodal\nretrieval. Firstly, we show that an asymmetric weighting of the canonical\nweights, while achieving a cross view mapping from the search to the query\nspace, improves the retrieval performance. Secondly, we devise a\ncomputationally efficient model selection, crucial to generalization and\nstability, in the framework of the Bj\\\"ork Golub algorithm for regularized CCA\nvia spectral filtering. Finally, we introduce a Hierarchical Kernel Sentence\nEmbedding (HKSE) that approximates Kernel CCA for a special similarity kernel\nbetween distribution of words embedded in a vector space. State of the art\nresults are obtained on MSCOCO and Flickr benchmarks when these three\ntechniques are used in conjunction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 17:29:00 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 03:53:40 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 16:20:50 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2016 15:53:18 GMT"}, {"version": "v5", "created": "Mon, 5 Dec 2016 21:06:43 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Mroueh", "Youssef", ""], ["Marcheret", "Etienne", ""], ["Goel", "Vaibhava", ""]]}, {"id": "1511.06276", "submitter": "Saurabh Sihag", "authors": "Saurabh Sihag and Pranab Kumar Dutta", "title": "Faster method for Deep Belief Network based Object classification using\n  DWT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Deep Belief Network (DBN) requires large, multiple hidden layers with high\nnumber of hidden units to learn good features from the raw pixels of large\nimages. This implies more training time as well as computational complexity. By\nintegrating DBN with Discrete Wavelet Transform (DWT), both training time and\ncomputational complexity can be reduced. The low resolution images obtained\nafter application of DWT are used to train multiple DBNs. The results obtained\nfrom these DBNs are combined using a weighted voting algorithm. The performance\nof this method is found to be competent and faster in comparison with that of\ntraditional DBNs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 17:41:08 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Sihag", "Saurabh", ""], ["Dutta", "Pranab Kumar", ""]]}, {"id": "1511.06279", "submitter": "Scott Reed", "authors": "Scott Reed and Nando de Freitas", "title": "Neural Programmer-Interpreters", "comments": "ICLR 2016 conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the neural programmer-interpreter (NPI): a recurrent and\ncompositional neural network that learns to represent and execute programs. NPI\nhas three learnable components: a task-agnostic recurrent core, a persistent\nkey-value program memory, and domain-specific encoders that enable a single NPI\nto operate in multiple perceptually diverse environments with distinct\naffordances. By learning to compose lower-level programs to express\nhigher-level programs, NPI reduces sample complexity and increases\ngeneralization ability compared to sequence-to-sequence LSTMs. The program\nmemory allows efficient learning of additional tasks by building on existing\nprograms. NPI can also harness the environment (e.g. a scratch pad with\nread-write pointers) to cache intermediate results of computation, lessening\nthe long-term memory burden on recurrent hidden units. In this work we train\nthe NPI with fully-supervised execution traces; each program has example\nsequences of calls to the immediate subprograms conditioned on the input.\nRather than training on a huge number of relatively weak labels, NPI learns\nfrom a small number of rich examples. We demonstrate the capability of our\nmodel to learn several types of compositional programs: addition, sorting, and\ncanonicalizing 3D models. Furthermore, a single NPI learns to execute these\nprograms and all 21 associated subprograms.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 17:49:32 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 19:30:01 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2015 18:11:35 GMT"}, {"version": "v4", "created": "Mon, 29 Feb 2016 11:12:36 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Reed", "Scott", ""], ["de Freitas", "Nando", ""]]}, {"id": "1511.06281", "submitter": "Johannes Ball\\'e", "authors": "Johannes Ball\\'e and Valero Laparra and Eero P. Simoncelli", "title": "Density Modeling of Images using a Generalized Normalization\n  Transformation", "comments": "published as a conference paper at ICLR 2016", "journal-ref": "Int'l Conf on Learning Representations (ICLR), San Juan, Puerto\n  Rico, May 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a parametric nonlinear transformation that is well-suited for\nGaussianizing data from natural images. The data are linearly transformed, and\neach component is then normalized by a pooled activity measure, computed by\nexponentiating a weighted sum of rectified and exponentiated components and a\nconstant. We optimize the parameters of the full transformation (linear\ntransform, exponents, weights, constant) over a database of natural images,\ndirectly minimizing the negentropy of the responses. The optimized\ntransformation substantially Gaussianizes the data, achieving a significantly\nsmaller mutual information between transformed components than alternative\nmethods including ICA and radial Gaussianization. The transformation is\ndifferentiable and can be efficiently inverted, and thus induces a density\nmodel on images. We show that samples of this model are visually similar to\nsamples of natural image patches. We demonstrate the use of the model as a\nprior probability density that can be used to remove additive noise. Finally,\nwe show that the transformation can be cascaded, with each layer optimized\nusing the same Gaussianization objective, thus offering an unsupervised method\nof optimizing a deep network architecture.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 17:52:01 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 22:05:15 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2016 03:14:40 GMT"}, {"version": "v4", "created": "Mon, 29 Feb 2016 21:07:30 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Ball\u00e9", "Johannes", ""], ["Laparra", "Valero", ""], ["Simoncelli", "Eero P.", ""]]}, {"id": "1511.06292", "submitter": "Xavier Boix E", "authors": "Yan Luo, Xavier Boix, Gemma Roig, Tomaso Poggio, Qi Zhao", "title": "Foveation-based Mechanisms Alleviate Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that adversarial examples, i.e., the visually imperceptible\nperturbations that result in Convolutional Neural Networks (CNNs) fail, can be\nalleviated with a mechanism based on foveations---applying the CNN in different\nimage regions. To see this, first, we report results in ImageNet that lead to a\nrevision of the hypothesis that adversarial perturbations are a consequence of\nCNNs acting as a linear classifier: CNNs act locally linearly to changes in the\nimage regions with objects recognized by the CNN, and in other regions the CNN\nmay act non-linearly. Then, we corroborate that when the neural responses are\nlinear, applying the foveation mechanism to the adversarial example tends to\nsignificantly reduce the effect of the perturbation. This is because,\nhypothetically, the CNNs for ImageNet are robust to changes of scale and\ntranslation of the object produced by the foveation, but this property does not\ngeneralize to transformations of the perturbation. As a result, the accuracy\nafter a foveation is almost the same as the accuracy of the CNN without the\nadversarial perturbation, even if the adversarial perturbation is calculated\ntaking into account a foveation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 18:35:07 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 14:13:58 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2016 18:15:28 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Luo", "Yan", ""], ["Boix", "Xavier", ""], ["Roig", "Gemma", ""], ["Poggio", "Tomaso", ""], ["Zhao", "Qi", ""]]}, {"id": "1511.06295", "submitter": "Andrei Rusu", "authors": "Andrei A. Rusu, Sergio Gomez Colmenarejo, Caglar Gulcehre, Guillaume\n  Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray\n  Kavukcuoglu, Raia Hadsell", "title": "Policy Distillation", "comments": "Submitted to ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policies for complex visual tasks have been successfully learned with deep\nreinforcement learning, using an approach called deep Q-networks (DQN), but\nrelatively large (task-specific) networks and extensive training are needed to\nachieve good performance. In this work, we present a novel method called policy\ndistillation that can be used to extract the policy of a reinforcement learning\nagent and train a new network that performs at the expert level while being\ndramatically smaller and more efficient. Furthermore, the same method can be\nused to consolidate multiple task-specific policies into a single policy. We\ndemonstrate these claims using the Atari domain and show that the multi-task\ndistilled agent outperforms the single-task teachers as well as a\njointly-trained DQN agent.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 18:38:47 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 18:43:03 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Rusu", "Andrei A.", ""], ["Colmenarejo", "Sergio Gomez", ""], ["Gulcehre", "Caglar", ""], ["Desjardins", "Guillaume", ""], ["Kirkpatrick", "James", ""], ["Pascanu", "Razvan", ""], ["Mnih", "Volodymyr", ""], ["Kavukcuoglu", "Koray", ""], ["Hadsell", "Raia", ""]]}, {"id": "1511.06297", "submitter": "Emmanuel Bengio", "authors": "Emmanuel Bengio, Pierre-Luc Bacon, Joelle Pineau and Doina Precup", "title": "Conditional Computation in Neural Networks for faster models", "comments": "ICLR 2016 submission, revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become the state-of-art tool in many applications, but the\nevaluation and training of deep models can be time-consuming and\ncomputationally expensive. The conditional computation approach has been\nproposed to tackle this problem (Bengio et al., 2013; Davis & Arel, 2013). It\noperates by selectively activating only parts of the network at a time. In this\npaper, we use reinforcement learning as a tool to optimize conditional\ncomputation policies. More specifically, we cast the problem of learning\nactivation-dependent policies for dropping out blocks of units as a\nreinforcement learning problem. We propose a learning scheme motivated by\ncomputation speed, capturing the idea of wanting to have parsimonious\nactivations while maintaining prediction accuracy. We apply a policy gradient\nalgorithm for learning policies that optimize this loss function and propose a\nregularization mechanism that encourages diversification of the dropout policy.\nWe present encouraging empirical results showing that this approach improves\nthe speed of computation without impacting the quality of the approximation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 18:40:22 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 22:41:10 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Bengio", "Emmanuel", ""], ["Bacon", "Pierre-Luc", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""]]}, {"id": "1511.06303", "submitter": "Piotr Bojanowski", "authors": "Piotr Bojanowski and Armand Joulin and Tomas Mikolov", "title": "Alternative structures for character-level RNNs", "comments": "First revision. Updated Table 3, extended Sec. 5.3 and added a\n  paragraph to the conclusion,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are convenient and efficient models for language\nmodeling. However, when applied on the level of characters instead of words,\nthey suffer from several problems. In order to successfully model long-term\ndependencies, the hidden representation needs to be large. This in turn implies\nhigher computational costs, which can become prohibitive in practice. We\npropose two alternative structural modifications to the classical RNN model.\nThe first one consists on conditioning the character level representation on\nthe previous word representation. The other one uses the character history to\ncondition the output probability. We evaluate the performance of the two\nproposed modifications on challenging, multi-lingual real world data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 18:46:21 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 17:35:35 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Bojanowski", "Piotr", ""], ["Joulin", "Armand", ""], ["Mikolov", "Tomas", ""]]}, {"id": "1511.06306", "submitter": "Jonghoon Jin", "authors": "Jonghoon Jin, Aysegul Dundar, Eugenio Culurciello", "title": "Robust Convolutional Neural Networks under Adversarial Noise", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that Convolutional Neural Networks (CNNs) are\nvulnerable to a small perturbation of input called \"adversarial examples\". In\nthis work, we propose a new feedforward CNN that improves robustness in the\npresence of adversarial noise. Our model uses stochastic additive noise added\nto the input image and to the CNN models. The proposed model operates in\nconjunction with a CNN trained with either standard or adversarial objective\nfunction. In particular, convolution, max-pooling, and ReLU layers are modified\nto benefit from the noise model. Our feedforward model is parameterized by only\na mean and variance per pixel which simplifies computations and makes our\nmethod scalable to a deep architecture. From CIFAR-10 and ImageNet test, the\nproposed model outperforms other methods and the improvement is more evident\nfor difficult classification tasks or stronger adversarial noise.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 18:51:08 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 16:30:04 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Jin", "Jonghoon", ""], ["Dundar", "Aysegul", ""], ["Culurciello", "Eugenio", ""]]}, {"id": "1511.06309", "submitter": "Viorica Patraucean", "authors": "Viorica Patraucean, Ankur Handa, Roberto Cipolla", "title": "Spatio-temporal video autoencoder with differentiable memory", "comments": "The experiments section has been extended and a direct application to\n  weakly-supervised video segmentation through label propagation has been\n  included", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe a new spatio-temporal video autoencoder, based on a classic\nspatial image autoencoder and a novel nested temporal autoencoder. The temporal\nencoder is represented by a differentiable visual memory composed of\nconvolutional long short-term memory (LSTM) cells that integrate changes over\ntime. Here we target motion changes and use as temporal decoder a robust\noptical flow prediction module together with an image sampler serving as\nbuilt-in feedback loop. The architecture is end-to-end differentiable. At each\ntime step, the system receives as input a video frame, predicts the optical\nflow based on the current observation and the LSTM memory state as a dense\ntransformation map, and applies it to the current frame to generate the next\nframe. By minimising the reconstruction error between the predicted next frame\nand the corresponding ground truth next frame, we train the whole system to\nextract features useful for motion estimation without any supervision effort.\nWe present one direct application of the proposed framework in\nweakly-supervised semantic segmentation of videos through label propagation\nusing optical flow.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 19:06:28 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 21:07:11 GMT"}, {"version": "v3", "created": "Sat, 6 Aug 2016 16:24:58 GMT"}, {"version": "v4", "created": "Wed, 10 Aug 2016 14:46:49 GMT"}, {"version": "v5", "created": "Thu, 1 Sep 2016 11:36:40 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Patraucean", "Viorica", ""], ["Handa", "Ankur", ""], ["Cipolla", "Roberto", ""]]}, {"id": "1511.06314", "submitter": "Stefan Lee", "authors": "Stefan Lee, Senthil Purushwalkam, Michael Cogswell, David Crandall,\n  and Dhruv Batra", "title": "Why M Heads are Better than One: Training a Diverse Ensemble of Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks have achieved state-of-the-art performance on a\nwide range of tasks. Most benchmarks are led by ensembles of these powerful\nlearners, but ensembling is typically treated as a post-hoc procedure\nimplemented by averaging independently trained models with model variation\ninduced by bagging or random initialization. In this paper, we rigorously treat\nensembling as a first-class problem to explicitly address the question: what\nare the best strategies to create an ensemble? We first compare a large number\nof ensembling strategies, and then propose and evaluate novel strategies, such\nas parameter sharing (through a new family of models we call TreeNets) as well\nas training under ensemble-aware and diversity-encouraging losses. We\ndemonstrate that TreeNets can improve ensemble performance and that diverse\nensembles can be trained end-to-end under a unified loss, achieving\nsignificantly higher \"oracle\" accuracies than classical ensembles.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 19:19:58 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Lee", "Stefan", ""], ["Purushwalkam", "Senthil", ""], ["Cogswell", "Michael", ""], ["Crandall", "David", ""], ["Batra", "Dhruv", ""]]}, {"id": "1511.06321", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Zsolt Kira", "title": "Neural network-based clustering using pairwise constraints", "comments": "ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a neural network-based end-to-end clustering framework.\nWe design a novel strategy to utilize the contrastive criteria for pushing\ndata-forming clusters directly from raw data, in addition to learning a feature\nembedding suitable for such clustering. The network is trained with weak\nlabels, specifically partial pairwise relationships between data instances. The\ncluster assignments and their probabilities are then obtained at the output\nlayer by feed-forwarding the data. The framework has the interesting\ncharacteristic that no cluster centers need to be explicitly specified, thus\nthe resulting cluster distribution is purely data-driven and no distance\nmetrics need to be predefined. The experiments show that the proposed approach\nbeats the conventional two-stage method (feature embedding with k-means) by a\nsignificant margin. It also compares favorably to the performance of the\nstandard cross entropy loss for classification. Robustness analysis also shows\nthat the method is largely insensitive to the number of clusters. Specifically,\nwe show that the number of dominant clusters is close to the true number of\nclusters even when a large k is used for clustering.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 19:36:38 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2015 17:24:34 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2015 18:53:46 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2016 23:46:17 GMT"}, {"version": "v5", "created": "Tue, 26 Apr 2016 15:59:39 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Kira", "Zsolt", ""]]}, {"id": "1511.06328", "submitter": "Shuangfei Zhai", "authors": "Shuangfei Zhai, Zhongfei Zhang", "title": "Manifold Regularized Discriminative Neural Networks", "comments": "In submission to ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unregularized deep neural networks (DNNs) can be easily overfit with a\nlimited sample size. We argue that this is mostly due to the disriminative\nnature of DNNs which directly model the conditional probability (or score) of\nlabels given the input. The ignorance of input distribution makes DNNs\ndifficult to generalize to unseen data. Recent advances in regularization\ntechniques, such as pretraining and dropout, indicate that modeling input data\ndistribution (either explicitly or implicitly) greatly improves the\ngeneralization ability of a DNN. In this work, we explore the manifold\nhypothesis which assumes that instances within the same class lie in a smooth\nmanifold. We accordingly propose two simple regularizers to a standard\ndiscriminative DNN. The first one, named Label-Aware Manifold Regularization,\nassumes the availability of labels and penalizes large norms of the loss\nfunction w.r.t. data points. The second one, named Label-Independent Manifold\nRegularization, does not use label information and instead penalizes the\nFrobenius norm of the Jacobian matrix of prediction scores w.r.t. data points,\nwhich makes semi-supervised learning possible. We perform extensive control\nexperiments on fully supervised and semi-supervised tasks using the MNIST,\nCIFAR10 and SVHN datasets and achieve excellent results.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 19:46:39 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 17:11:25 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 22:05:56 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Zhai", "Shuangfei", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "1511.06333", "submitter": "Saiprasad Ravishankar", "authors": "Saiprasad Ravishankar, Raj Rao Nadakuditi, Jeffrey A. Fessler", "title": "Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) and Its\n  Application to Inverse Problems", "comments": "Accepted to IEEE Transactions on Computational Imaging. This paper\n  also cites experimental results reported in arXiv:1511.08842", "journal-ref": "IEEE Transactions on Computational Imaging, 3(4):694-709 Dec 2017", "doi": "10.1109/TCI.2017.2697206", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparsity of signals in a transform domain or dictionary has been\nexploited in applications such as compression, denoising and inverse problems.\nMore recently, data-driven adaptation of synthesis dictionaries has shown\npromise compared to analytical dictionary models. However, dictionary learning\nproblems are typically non-convex and NP-hard, and the usual alternating\nminimization approaches for these problems are often computationally expensive,\nwith the computations dominated by the NP-hard synthesis sparse coding step.\nThis paper exploits the ideas that drive algorithms such as K-SVD, and\ninvestigates in detail efficient methods for aggregate sparsity penalized\ndictionary learning by first approximating the data with a sum of sparse\nrank-one matrices (outer products) and then using a block coordinate descent\napproach to estimate the unknowns. The resulting block coordinate descent\nalgorithms involve efficient closed-form solutions. Furthermore, we consider\nthe problem of dictionary-blind image reconstruction, and propose novel and\nefficient algorithms for adaptive image reconstruction using block coordinate\ndescent and sum of outer products methodologies. We provide a convergence study\nof the algorithms for dictionary learning and dictionary-blind image\nreconstruction. Our numerical experiments show the promising performance and\nspeed-ups provided by the proposed methods over previous schemes in sparse data\nrepresentation and compressed sensing-based image reconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:01:24 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2015 03:56:34 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 23:47:05 GMT"}, {"version": "v4", "created": "Fri, 21 Apr 2017 01:39:38 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Nadakuditi", "Raj Rao", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1511.06335", "submitter": "Junyuan Xie", "authors": "Junyuan Xie, Ross Girshick, Ali Farhadi", "title": "Unsupervised Deep Embedding for Clustering Analysis", "comments": "icml2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is central to many data-driven application domains and has been\nstudied extensively in terms of distance functions and grouping algorithms.\nRelatively little work has focused on learning representations for clustering.\nIn this paper, we propose Deep Embedded Clustering (DEC), a method that\nsimultaneously learns feature representations and cluster assignments using\ndeep neural networks. DEC learns a mapping from the data space to a\nlower-dimensional feature space in which it iteratively optimizes a clustering\nobjective. Our experimental evaluations on image and text corpora show\nsignificant improvement over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:06:14 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 22:27:35 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Xie", "Junyuan", ""], ["Girshick", "Ross", ""], ["Farhadi", "Ali", ""]]}, {"id": "1511.06340", "submitter": "Yanwei Fu", "authors": "Yanwei Fu and De-An Huang and Leonid Sigal", "title": "Robust Classification by Pre-conditioned LASSO and Transductive\n  Diffusion Component Analysis", "comments": "we will significantly change the content of this paper which makes it\n  another paper. In order not to misleading, we decided to withdraw it. The\n  updated version can not be shared currently, for some reason. We will update\n  it once it is OK to be shared", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning-based recognition approaches require large-scale\ndatasets with large number of labelled training images. However, such datasets\nare inherently difficult and costly to collect and annotate. Hence there is a\ngreat and growing interest in automatic dataset collection methods that can\nleverage the web. % which are collected % in a cheap, efficient and yet\nunreliable way. Collecting datasets in this way, however, requires robust and\nefficient ways for detecting and excluding outliers that are common and\nprevalent. % Outliers are thus a % prominent treat of using these dataset. So\nfar, there have been a limited effort in machine learning community to directly\ndetect outliers for robust classification. Inspired by the recent work on\nPre-conditioned LASSO, this paper formulates the outlier detection task using\nPre-conditioned LASSO and employs \\red{unsupervised} transductive diffusion\ncomponent analysis to both integrate the topological structure of the data\nmanifold, from labeled and unlabeled instances, and reduce the feature\ndimensionality. Synthetic experiments as well as results on two real-world\nclassification tasks show that our framework can robustly detect the outliers\nand improve classification.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:13:51 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 02:06:46 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Fu", "Yanwei", ""], ["Huang", "De-An", ""], ["Sigal", "Leonid", ""]]}, {"id": "1511.06342", "submitter": "Emilio Parisotto", "authors": "Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov", "title": "Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning", "comments": "Accepted as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to act in multiple environments and transfer previous knowledge\nto new situations can be considered a critical aspect of any intelligent agent.\nTowards this goal, we define a novel method of multitask and transfer learning\nthat enables an autonomous agent to learn how to behave in multiple tasks\nsimultaneously, and then generalize its knowledge to new domains. This method,\ntermed \"Actor-Mimic\", exploits the use of deep reinforcement learning and model\ncompression techniques to train a single policy network that learns how to act\nin a set of distinct tasks by using the guidance of several expert teachers. We\nthen show that the representations learnt by the deep policy network are\ncapable of generalizing to new tasks with no prior expert guidance, speeding up\nlearning in novel environments. Although our method can in general be applied\nto a wide range of problems, we use Atari games as a testing environment to\ndemonstrate these methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:17:27 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 20:54:04 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 06:57:34 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2016 19:59:40 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Parisotto", "Emilio", ""], ["Ba", "Jimmy Lei", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1511.06343", "submitter": "Ilya Loshchilov", "authors": "Ilya Loshchilov and Frank Hutter", "title": "Online Batch Selection for Faster Training of Neural Networks", "comments": "Workshop paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are commonly trained using stochastic non-convex\noptimization procedures, which are driven by gradient information estimated on\nfractions (batches) of the dataset. While it is commonly accepted that batch\nsize is an important parameter for offline tuning, the benefits of online\nselection of batches remain poorly understood. We investigate online batch\nselection strategies for two state-of-the-art methods of stochastic\ngradient-based optimization, AdaDelta and Adam. As the loss function to be\nminimized for the whole dataset is an aggregation of loss functions of\nindividual datapoints, intuitively, datapoints with the greatest loss should be\nconsidered (selected in a batch) more frequently. However, the limitations of\nthis intuition and the proper control of the selection pressure over time are\nopen questions. We propose a simple strategy where all datapoints are ranked\nw.r.t. their latest known loss value and the probability to be selected decays\nexponentially as a function of rank. Our experimental results on the MNIST\ndataset suggest that selecting batches speeds up both AdaDelta and Adam by a\nfactor of about 5.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:24:09 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 22:15:38 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2016 13:06:15 GMT"}, {"version": "v4", "created": "Mon, 25 Apr 2016 14:00:21 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Loshchilov", "Ilya", ""], ["Hutter", "Frank", ""]]}, {"id": "1511.06348", "submitter": "Synho Do", "authors": "Junghwan Cho, Kyewook Lee, Ellie Shin, Garry Choy, Synho Do", "title": "How much data is needed to train a medical image deep learning system to\n  achieve necessary high accuracy?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Convolutional Neural Networks (CNN) in natural image\nclassification systems has produced very impressive results. Combined with the\ninherent nature of medical images that make them ideal for deep-learning,\nfurther application of such systems to medical image classification holds much\npromise. However, the usefulness and potential impact of such a system can be\ncompletely negated if it does not reach a target accuracy. In this paper, we\npresent a study on determining the optimum size of the training data set\nnecessary to achieve high classification accuracy with low variance in medical\nimage classification systems. The CNN was applied to classify axial Computed\nTomography (CT) images into six anatomical classes. We trained the CNN using\nsix different sizes of training data set (5, 10, 20, 50, 100, and 200) and then\ntested the resulting system with a total of 6000 CT images. All images were\nacquired from the Massachusetts General Hospital (MGH) Picture Archiving and\nCommunication System (PACS). Using this data, we employ the learning curve\napproach to predict classification accuracy at a given training sample size.\nOur research will present a general methodology for determining the training\ndata set size necessary to achieve a certain target classification accuracy\nthat can be easily applied to other problems within such systems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:38:43 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 21:08:10 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Cho", "Junghwan", ""], ["Lee", "Kyewook", ""], ["Shin", "Ellie", ""], ["Choy", "Garry", ""], ["Do", "Synho", ""]]}, {"id": "1511.06349", "submitter": "Samuel Bowman", "authors": "Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew M. Dai, Rafal\n  Jozefowicz, Samy Bengio", "title": "Generating Sentences from a Continuous Space", "comments": "First two authors contributed equally. Work was done when all authors\n  were at Google, Inc", "journal-ref": "SIGNLL Conference on Computational Natural Language Learning\n  (CONLL), 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard recurrent neural network language model (RNNLM) generates\nsentences one word at a time and does not work from an explicit global sentence\nrepresentation. In this work, we introduce and study an RNN-based variational\nautoencoder generative model that incorporates distributed latent\nrepresentations of entire sentences. This factorization allows it to explicitly\nmodel holistic properties of sentences such as style, topic, and high-level\nsyntactic features. Samples from the prior over these sentence representations\nremarkably produce diverse and well-formed sentences through simple\ndeterministic decoding. By examining paths through this latent space, we are\nable to generate coherent novel sentences that interpolate between known\nsentences. We present techniques for solving the difficult learning problem\npresented by this model, demonstrate its effectiveness in imputing missing\nwords, explore many interesting properties of the model's latent sentence\nspace, and present negative results on the use of the model in language\nmodeling.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:38:45 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 02:59:34 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2016 17:38:42 GMT"}, {"version": "v4", "created": "Thu, 12 May 2016 20:51:23 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Bowman", "Samuel R.", ""], ["Vilnis", "Luke", ""], ["Vinyals", "Oriol", ""], ["Dai", "Andrew M.", ""], ["Jozefowicz", "Rafal", ""], ["Bengio", "Samy", ""]]}, {"id": "1511.06350", "submitter": "David Belanger", "authors": "David Belanger, Andrew McCallum", "title": "Structured Prediction Energy Networks", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce structured prediction energy networks (SPENs), a flexible\nframework for structured prediction. A deep architecture is used to define an\nenergy function of candidate labels, and then predictions are produced by using\nback-propagation to iteratively optimize the energy with respect to the labels.\nThis deep architecture captures dependencies between labels that would lead to\nintractable graphical models, and performs structure learning by automatically\nlearning discriminative features of the structured output. One natural\napplication of our technique is multi-label classification, which traditionally\nhas required strict prior assumptions about the interactions between labels to\nensure tractable learning and prediction. We are able to apply SPENs to\nmulti-label problems with substantially larger label sets than previous\napplications of structured prediction, while modeling high-order interactions\nusing minimal structural assumptions. Overall, deep learning provides\nremarkable tools for learning features of the inputs to a prediction problem,\nand this work extends these techniques to learning features of structured\noutputs. Our experiments provide impressive performance on a variety of\nbenchmark multi-label classification tasks, demonstrate that our technique can\nbe used to provide interpretable structure learning, and illuminate fundamental\ntrade-offs between feed-forward and iterative structured prediction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:39:59 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 16:28:36 GMT"}, {"version": "v3", "created": "Thu, 23 Jun 2016 20:21:11 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Belanger", "David", ""], ["McCallum", "Andrew", ""]]}, {"id": "1511.06351", "submitter": "Andy Sarroff", "authors": "Andy M. Sarroff, Victor Shepardson, Michael A. Casey", "title": "Learning Representations Using Complex-Valued Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex-valued neural networks (CVNNs) are an emerging field of research in\nneural networks due to their potential representational properties for audio,\nimage, and physiological signals. It is common in signal processing to\ntransform sequences of real values to the complex domain via a set of complex\nbasis functions, such as the Fourier transform. We show how CVNNs can be used\nto learn complex representations of real valued time-series data. We present\nmethods and results using a framework that can compose holomorphic and\nnon-holomorphic functions in a multi-layer network using a theoretical result\ncalled the Wirtinger derivative. We test our methods on a representation\nlearning task for real-valued signals, recurrent complex-valued networks and\ntheir real-valued counterparts. Our results show that recurrent complex-valued\nnetworks can perform as well as their real-valued counterparts while learning\nfilters that are representative of the domain of the data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:44:10 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Sarroff", "Andy M.", ""], ["Shepardson", "Victor", ""], ["Casey", "Michael A.", ""]]}, {"id": "1511.06359", "submitter": "Bihan Wen Mr", "authors": "Bihan Wen, Saiprasad Ravishankar, and Yoram Bresler", "title": "FRIST - Flipping and Rotation Invariant Sparsifying Transform Learning\n  and Applications", "comments": "Published in Inverse Problems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Features based on sparse representation, especially using the synthesis\ndictionary model, have been heavily exploited in signal processing and computer\nvision. However, synthesis dictionary learning typically involves NP-hard\nsparse coding and expensive learning steps. Recently, sparsifying transform\nlearning received interest for its cheap computation and its optimal updates in\nthe alternating algorithms. In this work, we develop a methodology for learning\nFlipping and Rotation Invariant Sparsifying Transforms, dubbed FRIST, to better\nrepresent natural images that contain textures with various geometrical\ndirections. The proposed alternating FRIST learning algorithm involves\nefficient optimal updates. We provide a convergence guarantee, and demonstrate\nthe empirical convergence behavior of the proposed FRIST learning approach.\nPreliminary experiments show the promising performance of FRIST learning for\nsparse image representation, segmentation, denoising, robust inpainting, and\ncompressed sensing-based magnetic resonance image reconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:55:49 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 06:43:38 GMT"}, {"version": "v3", "created": "Tue, 17 May 2016 03:54:47 GMT"}, {"version": "v4", "created": "Mon, 16 Oct 2017 02:42:20 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Wen", "Bihan", ""], ["Ravishankar", "Saiprasad", ""], ["Bresler", "Yoram", ""]]}, {"id": "1511.06361", "submitter": "Ivan Vendrov", "authors": "Ivan Vendrov, Ryan Kiros, Sanja Fidler, Raquel Urtasun", "title": "Order-Embeddings of Images and Language", "comments": "ICLR camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypernymy, textual entailment, and image captioning can be seen as special\ncases of a single visual-semantic hierarchy over words, sentences, and images.\nIn this paper we advocate for explicitly modeling the partial order structure\nof this hierarchy. Towards this goal, we introduce a general method for\nlearning ordered representations, and show how it can be applied to a variety\nof tasks involving images and language. We show that the resulting\nrepresentations improve performance over current approaches for hypernym\nprediction and image-caption retrieval.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:56:14 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2015 21:19:30 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2015 04:32:53 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 04:58:08 GMT"}, {"version": "v5", "created": "Sun, 17 Jan 2016 03:08:20 GMT"}, {"version": "v6", "created": "Tue, 1 Mar 2016 08:23:50 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Vendrov", "Ivan", ""], ["Kiros", "Ryan", ""], ["Fidler", "Sanja", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1511.06362", "submitter": "Jonathan Huang", "authors": "Jonathan Huang and Kevin Murphy", "title": "Efficient inference in occlusion-aware generative models of images", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model of images based on layering, in which image\nlayers are individually generated, then composited from front to back. We are\nthus able to factor the appearance of an image into the appearance of\nindividual objects within the image --- and additionally for each individual\nobject, we can factor content from pose. Unlike prior work on layered models,\nwe learn a shape prior for each object/layer, allowing the model to tease out\nwhich object is in front by looking for a consistent shape, without needing\naccess to motion cues or any labeled data. We show that ordinary stochastic\ngradient variational bayes (SGVB), which optimizes our fully differentiable\nlower-bound on the log-likelihood, is sufficient to learn an interpretable\nrepresentation of images. Finally we present experiments demonstrating the\neffectiveness of the model for inferring foreground and background objects in\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 20:56:27 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 07:22:02 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Huang", "Jonathan", ""], ["Murphy", "Kevin", ""]]}, {"id": "1511.06379", "submitter": "Richard Searle Dr", "authors": "Richard Searle, Megan Bingham-Walker", "title": "Dynamic Adaptive Network Intelligence", "comments": "8 pages, 2 figures, 3 tables, ICLR 2016 conference paper submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate representational learning of both the explicit and implicit\nrelationships within data is critical to the ability of machines to perform\nmore complex and abstract reasoning tasks. We describe the efficient weakly\nsupervised learning of such inferences by our Dynamic Adaptive Network\nIntelligence (DANI) model. We report state-of-the-art results for DANI over\nquestion answering tasks in the bAbI dataset that have proved difficult for\ncontemporary approaches to learning representation (Weston et al., 2015).\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:07:27 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Searle", "Richard", ""], ["Bingham-Walker", "Megan", ""]]}, {"id": "1511.06380", "submitter": "William Lotter", "authors": "William Lotter, Gabriel Kreiman, David Cox", "title": "Unsupervised Learning of Visual Structure using Predictive Generative\n  Networks", "comments": "under review as conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict future states of the environment is a central pillar\nof intelligence. At its core, effective prediction requires an internal model\nof the world and an understanding of the rules by which the world changes.\nHere, we explore the internal models developed by deep neural networks trained\nusing a loss based on predicting future frames in synthetic video sequences,\nusing a CNN-LSTM-deCNN framework. We first show that this architecture can\nachieve excellent performance in visual sequence prediction tasks, including\nstate-of-the-art performance in a standard 'bouncing balls' dataset (Sutskever\net al., 2009). Using a weighted mean-squared error and adversarial loss\n(Goodfellow et al., 2014), the same architecture successfully extrapolates\nout-of-the-plane rotations of computer-generated faces. Furthermore, despite\nbeing trained end-to-end to predict only pixel-level information, our\nPredictive Generative Networks learn a representation of the latent structure\nof the underlying three-dimensional objects themselves. Importantly, we find\nthat this representation is naturally tolerant to object transformations, and\ngeneralizes well to new tasks, such as classification of static images. Similar\nmodels trained solely with a reconstruction loss fail to generalize as\neffectively. We argue that prediction can serve as a powerful unsupervised loss\nfor learning rich internal representations of high-level object features.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:10:17 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2016 05:50:46 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Lotter", "William", ""], ["Kreiman", "Gabriel", ""], ["Cox", "David", ""]]}, {"id": "1511.06381", "submitter": "Taehoon Lee", "authors": "Taehoon Lee, Minsuk Choi, and Sungroh Yoon", "title": "Manifold Regularized Deep Neural Networks using Adversarial Examples", "comments": "Figure 2, 5, 7, and several descriptions revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful representations using deep neural networks involves\ndesigning efficient training schemes and well-structured networks. Currently,\nthe method of stochastic gradient descent that has a momentum with dropout is\none of the most popular training protocols. Based on that, more advanced\nmethods (i.e., Maxout and Batch Normalization) have been proposed in recent\nyears, but most still suffer from performance degradation caused by small\nperturbations, also known as adversarial examples. To address this issue, we\npropose manifold regularized networks (MRnet) that utilize a novel training\nobjective function that minimizes the difference between multi-layer embedding\nresults of samples and those adversarial. Our experimental results demonstrated\nthat MRnet is more resilient to adversarial examples and helps us to generalize\nrepresentations on manifolds. Furthermore, combining MRnet and dropout allowed\nus to achieve competitive classification performances for three well-known\nbenchmarks: MNIST, CIFAR-10, and SVHN.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:10:29 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2016 16:35:11 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Lee", "Taehoon", ""], ["Choi", "Minsuk", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1511.06382", "submitter": "R Devon Hjelm", "authors": "R Devon Hjelm and Kyunghyun Cho and Junyoung Chung and Russ\n  Salakhutdinov and Vince Calhoun and Nebojsa Jojic", "title": "Iterative Refinement of the Approximate Posterior for Directed Belief\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational methods that rely on a recognition network to approximate the\nposterior of directed graphical models offer better inference and learning than\nprevious methods. Recent advances that exploit the capacity and flexibility in\nthis approach have expanded what kinds of models can be trained. However, as a\nproposal for the posterior, the capacity of the recognition network is limited,\nwhich can constrain the representational power of the generative model and\nincrease the variance of Monte Carlo estimates. To address these issues, we\nintroduce an iterative refinement procedure for improving the approximate\nposterior of the recognition network and show that training with the refined\nposterior is competitive with state-of-the-art methods. The advantages of\nrefinement are further evident in an increased effective sample size, which\nimplies a lower variance of gradient estimates.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:11:12 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 21:40:50 GMT"}, {"version": "v3", "created": "Sun, 3 Jan 2016 05:05:30 GMT"}, {"version": "v4", "created": "Mon, 14 Mar 2016 16:56:38 GMT"}, {"version": "v5", "created": "Sat, 29 Oct 2016 05:10:31 GMT"}, {"version": "v6", "created": "Tue, 20 Feb 2018 16:02:50 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Hjelm", "R Devon", ""], ["Cho", "Kyunghyun", ""], ["Chung", "Junyoung", ""], ["Salakhutdinov", "Russ", ""], ["Calhoun", "Vince", ""], ["Jojic", "Nebojsa", ""]]}, {"id": "1511.06385", "submitter": "Chunchuan Lv Mr.", "authors": "Chunchuan Lyu, Kaizhu Huang, Hai-Ning Liang", "title": "A Unified Gradient Regularization Family for Adversarial Examples", "comments": "The paper has been presented at ICDM 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are augmented data points generated by imperceptible\nperturbation of input samples. They have recently drawn much attention with the\nmachine learning and data mining community. Being difficult to distinguish from\nreal examples, such adversarial examples could change the prediction of many of\nthe best learning models including the state-of-the-art deep learning models.\nRecent attempts have been made to build robust models that take into account\nadversarial examples. However, these methods can either lead to performance\ndrops or lack mathematical motivations. In this paper, we propose a unified\nframework to build robust machine learning models against adversarial examples.\nMore specifically, using the unified framework, we develop a family of gradient\nregularization methods that effectively penalize the gradient of loss function\nw.r.t. inputs. Our proposed framework is appealing in that it offers a unified\nview to deal with adversarial examples. It incorporates another\nrecently-proposed perturbation based approach as a special case. In addition,\nwe present some visual effects that reveals semantic meaning in those\nperturbations, and thus support our regularization method and provide another\nexplanation for generalizability of adversarial examples. By applying this\ntechnique to Maxout networks, we conduct a series of experiments and achieve\nencouraging results on two benchmark datasets. In particular,we attain the best\naccuracy on MNIST data (without data augmentation) and competitive performance\non CIFAR-10 data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:14:43 GMT"}], "update_date": "2016-03-03", "authors_parsed": [["Lyu", "Chunchuan", ""], ["Huang", "Kaizhu", ""], ["Liang", "Hai-Ning", ""]]}, {"id": "1511.06388", "submitter": "Andrew Trask", "authors": "Andrew Trask, Phil Michalak, John Liu", "title": "sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In\n  Neural Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural word representations have proven useful in Natural Language Processing\n(NLP) tasks due to their ability to efficiently model complex semantic and\nsyntactic word relationships. However, most techniques model only one\nrepresentation per word, despite the fact that a single word can have multiple\nmeanings or \"senses\". Some techniques model words by using multiple vectors\nthat are clustered based on context. However, recent neural approaches rarely\nfocus on the application to a consuming NLP algorithm. Furthermore, the\ntraining process of recent word-sense models is expensive relative to\nsingle-sense embedding processes. This paper presents a novel approach which\naddresses these concerns by modeling multiple embeddings for each word based on\nsupervised disambiguation, which provides a fast and accurate way for a\nconsuming NLP model to select a sense-disambiguated embedding. We demonstrate\nthat these embeddings can disambiguate both contrastive senses such as nominal\nand verbal senses as well as nuanced senses such as sarcasm. We further\nevaluate Part-of-Speech disambiguated embeddings on neural dependency parsing,\nyielding a greater than 8% average error reduction in unlabeled attachment\nscores across 6 languages.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:22:42 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Trask", "Andrew", ""], ["Michalak", "Phil", ""], ["Liu", "John", ""]]}, {"id": "1511.06390", "submitter": "Jost Tobias Springenberg", "authors": "Jost Tobias Springenberg", "title": "Unsupervised and Semi-supervised Learning with Categorical Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method for learning a discriminative classifier\nfrom unlabeled or partially labeled data. Our approach is based on an objective\nfunction that trades-off mutual information between observed examples and their\npredicted categorical class distribution, against robustness of the classifier\nto an adversarial generative model. The resulting algorithm can either be\ninterpreted as a natural generalization of the generative adversarial networks\n(GAN) framework or as an extension of the regularized information maximization\n(RIM) framework to robust classification against an optimal adversary. We\nempirically evaluate our method - which we dub categorical generative\nadversarial networks (or CatGAN) - on synthetic data as well as on challenging\nimage classification tasks, demonstrating the robustness of the learned\nclassifiers. We further qualitatively assess the fidelity of samples generated\nby the adversarial generator that is learned alongside the discriminative\nclassifier, and identify links between the CatGAN objective and discriminative\nclustering algorithms (such as RIM).\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:26:58 GMT"}, {"version": "v2", "created": "Sat, 30 Apr 2016 21:23:46 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Springenberg", "Jost Tobias", ""]]}, {"id": "1511.06391", "submitter": "Oriol Vinyals", "authors": "Oriol Vinyals, Samy Bengio, Manjunath Kudlur", "title": "Order Matters: Sequence to sequence for sets", "comments": "Accepted as a conference paper at ICLR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences have become first class citizens in supervised learning thanks to\nthe resurgence of recurrent neural networks. Many complex tasks that require\nmapping from or to a sequence of observations can now be formulated with the\nsequence-to-sequence (seq2seq) framework which employs the chain rule to\nefficiently represent the joint probability of sequences. In many cases,\nhowever, variable sized inputs and/or outputs might not be naturally expressed\nas sequences. For instance, it is not clear how to input a set of numbers into\na model where the task is to sort them; similarly, we do not know how to\norganize outputs when they correspond to random variables and the task is to\nmodel their unknown joint probability. In this paper, we first show using\nvarious examples that the order in which we organize input and/or output data\nmatters significantly when learning an underlying model. We then discuss an\nextension of the seq2seq framework that goes beyond sequences and handles input\nsets in a principled way. In addition, we propose a loss which, by searching\nover possible orders during training, deals with the lack of structure of\noutput sets. We show empirical evidence of our claims regarding ordering, and\non the modifications to the seq2seq framework on benchmark language modeling\nand parsing tasks, as well as two artificial tasks -- sorting numbers and\nestimating the joint probability of unknown graphical models.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:31:26 GMT"}, {"version": "v2", "created": "Sat, 16 Jan 2016 16:50:35 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2016 17:03:38 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2016 22:25:12 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Vinyals", "Oriol", ""], ["Bengio", "Samy", ""], ["Kudlur", "Manjunath", ""]]}, {"id": "1511.06392", "submitter": "Karol Kurach", "authors": "Karol Kurach, Marcin Andrychowicz, Ilya Sutskever", "title": "Neural Random-Access Machines", "comments": "ICLR submission, 17 pages, 9 figures, 6 tables (with bibliography and\n  appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and investigate a new neural network architecture\ncalled Neural Random Access Machine. It can manipulate and dereference pointers\nto an external variable-size random-access memory. The model is trained from\npure input-output examples using backpropagation.\n  We evaluate the new model on a number of simple algorithmic tasks whose\nsolutions require pointer manipulation and dereferencing. Our results show that\nthe proposed model can learn to solve algorithmic tasks of such type and is\ncapable of operating on simple data structures like linked-lists and binary\ntrees. For easier tasks, the learned solutions generalize to sequences of\narbitrary length. Moreover, memory access during inference can be done in a\nconstant time under some assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:36:28 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 10:27:06 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2016 21:29:07 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Kurach", "Karol", ""], ["Andrychowicz", "Marcin", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1511.06393", "submitter": "Darryl Lin", "authors": "Darryl D. Lin, Sachin S. Talathi, V. Sreekanth Annapureddy", "title": "Fixed Point Quantization of Deep Convolutional Networks", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years increasingly complex architectures for deep convolution\nnetworks (DCNs) have been proposed to boost the performance on image\nrecognition tasks. However, the gains in performance have come at a cost of\nsubstantial increase in computation and model storage resources. Fixed point\nimplementation of DCNs has the potential to alleviate some of these\ncomplexities and facilitate potential deployment on embedded hardware. In this\npaper, we propose a quantizer design for fixed point implementation of DCNs. We\nformulate and solve an optimization problem to identify optimal fixed point\nbit-width allocation across DCN layers. Our experiments show that in comparison\nto equal bit-width settings, the fixed point DCNs with optimized bit width\nallocation offer >20% reduction in the model size without any loss in accuracy\non CIFAR-10 benchmark. We also demonstrate that fine-tuning can further enhance\nthe accuracy of fixed point DCNs beyond that of the original floating point\nmodel. In doing so, we report a new state-of-the-art fixed point performance of\n6.78% error-rate on CIFAR-10 benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:37:06 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 22:20:06 GMT"}, {"version": "v3", "created": "Thu, 2 Jun 2016 06:21:42 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Lin", "Darryl D.", ""], ["Talathi", "Sachin S.", ""], ["Annapureddy", "V. Sreekanth", ""]]}, {"id": "1511.06394", "submitter": "Olivier  H\\'enaff", "authors": "Olivier J. H\\'enaff and Eero P. Simoncelli", "title": "Geodesics of learned representations", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": "Presented at: Int'l Conf on Learning Representations (ICLR), San\n  Juan, Puerto Rico, May 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method for visualizing and refining the invariances of\nlearned representations. Specifically, we test for a general form of\ninvariance, linearization, in which the action of a transformation is confined\nto a low-dimensional subspace. Given two reference images (typically, differing\nby some transformation), we synthesize a sequence of images lying on a path\nbetween them that is of minimal length in the space of the representation (a\n\"representational geodesic\"). If the transformation relating the two reference\nimages is linearized by the representation, this sequence should follow the\ngradual evolution of this transformation. We use this method to assess the\ninvariance properties of a state-of-the-art image classification network and\nfind that geodesics generated for image pairs differing by translation,\nrotation, and dilation do not evolve according to their associated\ntransformations. Our method also suggests a remedy for these failures, and\nfollowing this prescription, we show that the modified representation is able\nto linearize a variety of geometric image transformations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:40:13 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 21:10:58 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2016 21:05:40 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2016 17:42:25 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["H\u00e9naff", "Olivier J.", ""], ["Simoncelli", "Eero P.", ""]]}, {"id": "1511.06396", "submitter": "Patrick Verga", "authors": "Patrick Verga, David Belanger, Emma Strubell, Benjamin Roth, Andrew\n  McCallum", "title": "Multilingual Relation Extraction using Compositional Universal Schema", "comments": "Accepted to NAACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal schema builds a knowledge base (KB) of entities and relations by\njointly embedding all relation types from input KBs as well as textual patterns\nexpressing relations from raw text. In most previous applications of universal\nschema, each textual pattern is represented as a single embedding, preventing\ngeneralization to unseen patterns. Recent work employs a neural network to\ncapture patterns' compositional semantics, providing generalization to all\npossible input text. In response, this paper introduces significant further\nimprovements to the coverage and flexibility of universal schema relation\nextraction: predictions for entities unseen in training and multilingual\ntransfer learning to domains with no annotation. We evaluate our model through\nextensive experiments on the English and Spanish TAC KBP benchmark,\noutperforming the top system from TAC 2013 slot-filling using no handwritten\npatterns or additional annotation. We also consider a multilingual setting in\nwhich English training data entities overlap with the seed KB, but Spanish text\ndoes not. Despite having no annotation for Spanish data, we train an accurate\npredictor, with additional improvements obtained by tying word embeddings\nacross languages. Furthermore, we find that multilingual training improves\nEnglish relation extraction accuracy. Our approach is thus suited to\nbroad-coverage automated knowledge base construction in a variety of languages\nand domains.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:42:23 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 20:28:36 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Verga", "Patrick", ""], ["Belanger", "David", ""], ["Strubell", "Emma", ""], ["Roth", "Benjamin", ""], ["McCallum", "Andrew", ""]]}, {"id": "1511.06397", "submitter": "Martin Andrews", "authors": "Martin Andrews", "title": "Compressing Word Embeddings", "comments": "10 pages, 0 figures, submitted to ICONIP-2016. Previous experimental\n  results were submitted to ICLR-2016, but the paper has been significantly\n  updated, since a new experimental set-up worked much better", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent methods for learning vector space representations of words have\nsucceeded in capturing fine-grained semantic and syntactic regularities using\nvector arithmetic. However, these vector space representations (created through\nlarge-scale text analysis) are typically stored verbatim, since their internal\nstructure is opaque. Using word-analogy tests to monitor the level of detail\nstored in compressed re-representations of the same vector space, the\ntrade-offs between the reduction in memory usage and expressiveness are\ninvestigated. A simple scheme is outlined that can reduce the memory footprint\nof a state-of-the-art embedding by a factor of 10, with only minimal impact on\nperformance. Then, using the same `bit budget', a binary (approximate)\nfactorisation of the same space is also explored, with the aim of creating an\nequivalent representation with better interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:42:47 GMT"}, {"version": "v2", "created": "Mon, 16 May 2016 17:19:51 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Andrews", "Martin", ""]]}, {"id": "1511.06406", "submitter": "Daniel Jiwoong  Im", "authors": "Daniel Jiwoong Im, Sungjin Ahn, Roland Memisevic, Yoshua Bengio", "title": "Denoising Criterion for Variational Auto-Encoding Framework", "comments": "ICLR conference submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Denoising autoencoders (DAE) are trained to reconstruct their clean inputs\nwith noise injected at the input level, while variational autoencoders (VAE)\nare trained with noise injected in their stochastic hidden layer, with a\nregularizer that encourages this noise injection. In this paper, we show that\ninjecting noise both in input and in the stochastic hidden layer can be\nadvantageous and we propose a modified variational lower bound as an improved\nobjective function in this setup. When input is corrupted, then the standard\nVAE lower bound involves marginalizing the encoder conditional distribution\nover the input noise, which makes the training criterion intractable. Instead,\nwe propose a modified training criterion which corresponds to a tractable bound\nwhen input is corrupted. Experimentally, we find that the proposed denoising\nvariational autoencoder (DVAE) yields better average log-likelihood than the\nVAE and the importance weighted autoencoder on the MNIST and Frey Face\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:56:21 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 15:12:46 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Ahn", "Sungjin", ""], ["Memisevic", "Roland", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1511.06407", "submitter": "Suyoun Kim", "authors": "Suyoun Kim, Ian Lane", "title": "Recurrent Models for Auditory Attention in Multi-Microphone Distance\n  Speech Recognition", "comments": "Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration of multiple microphone data is one of the key ways to achieve\nrobust speech recognition in noisy environments or when the speaker is located\nat some distance from the input device. Signal processing techniques such as\nbeamforming are widely used to extract a speech signal of interest from\nbackground noise. These techniques, however, are highly dependent on prior\nspatial information about the microphones and the environment in which the\nsystem is being used. In this work, we present a neural attention network that\ndirectly combines multi-channel audio to generate phonetic states without\nrequiring any prior knowledge of the microphone layout or any explicit signal\npreprocessing for speech enhancement. We embed an attention mechanism within a\nRecurrent Neural Network (RNN) based acoustic model to automatically tune its\nattention to a more reliable input source. Unlike traditional multi-channel\npreprocessing, our system can be optimized towards the desired output in one\nstep. Although attention-based models have recently achieved impressive results\non sequence-to-sequence learning, no attention mechanisms have previously been\napplied to learn potentially asynchronous and non-stationary multiple inputs.\nWe evaluate our neural attention model on the CHiME-3 challenge task, and show\nthat the model achieves comparable performance to beamforming using a purely\ndata-driven method.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:56:53 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 22:16:54 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Kim", "Suyoun", ""], ["Lane", "Ian", ""]]}, {"id": "1511.06409", "submitter": "Jake Snell", "authors": "Jake Snell, Karl Ridgeway, Renjie Liao, Brett D. Roads, Michael C.\n  Mozer, Richard S. Zemel", "title": "Learning to Generate Images with Perceptual Similarity Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks are increasingly being applied to problems involving image\nsynthesis, e.g., generating images from textual descriptions and reconstructing\nan input image from a compact representation. Supervised training of\nimage-synthesis networks typically uses a pixel-wise loss (PL) to indicate the\nmismatch between a generated image and its corresponding target image. We\npropose instead to use a loss function that is better calibrated to human\nperceptual judgments of image quality: the multiscale structural-similarity\nscore (MS-SSIM). Because MS-SSIM is differentiable, it is easily incorporated\ninto gradient-descent learning. We compare the consequences of using MS-SSIM\nversus PL loss on training deterministic and stochastic autoencoders. For three\ndifferent architectures, we collected human judgments of the quality of image\nreconstructions. Observers reliably prefer images synthesized by\nMS-SSIM-optimized models over those synthesized by PL-optimized models, for two\ndistinct PL measures ($\\ell_1$ and $\\ell_2$ distances). We also explore the\neffect of training objective on image encoding and analyze conditions under\nwhich perceptually-optimized representations yield better performance on image\nclassification. Finally, we demonstrate the superiority of\nperceptually-optimized networks for super-resolution imaging. Just as computer\nvision has advanced through the use of convolutional architectures that mimic\nthe structure of the mammalian visual system, we argue that significant\nadditional advances can be made in modeling images through the use of training\nobjectives that are well aligned to characteristics of human perception.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:57:46 GMT"}, {"version": "v2", "created": "Thu, 17 Mar 2016 17:21:56 GMT"}, {"version": "v3", "created": "Tue, 24 Jan 2017 02:03:41 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Snell", "Jake", ""], ["Ridgeway", "Karl", ""], ["Liao", "Renjie", ""], ["Roads", "Brett D.", ""], ["Mozer", "Michael C.", ""], ["Zemel", "Richard S.", ""]]}, {"id": "1511.06410", "submitter": "Yuandong Tian", "authors": "Yuandong Tian and Yan Zhu", "title": "Better Computer Go Player with Neural Network and Long-term Prediction", "comments": "10 pages, 9 without references. Submission for ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competing with top human players in the ancient game of Go has been a\nlong-term goal of artificial intelligence. Go's high branching factor makes\ntraditional search techniques ineffective, even on leading-edge hardware, and\nGo's evaluation function could change drastically with one stone change. Recent\nworks [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not\nstrictly necessary for machine Go players. A pure pattern-matching approach,\nbased on a Deep Convolutional Neural Network (DCNN) that predicts the next\nmove, can perform as well as Monte Carlo Tree Search (MCTS)-based open source\nGo engines such as Pachi [Baudis & Gailly (2012)] if its search budget is\nlimited. We extend this idea in our bot named darkforest, which relies on a\nDCNN designed for long-term predictions. Darkforest substantially improves the\nwin rate for pattern-matching approaches against MCTS-based approaches, even\nwith looser search budgets. Against human players, the newest versions,\ndarkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, a\nsubstantial improvement upon the estimated 4k-5k ranks for DCNN reported in\nClark & Storkey (2015) based on games against other machine players. Adding\nMCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000\nrollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rollouts\nit achieves a stable 5d level in KGS server, on par with state-of-the-art Go\nAIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al.\n(2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 21:59:58 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2016 07:17:06 GMT"}, {"version": "v3", "created": "Mon, 29 Feb 2016 15:52:34 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Tian", "Yuandong", ""], ["Zhu", "Yan", ""]]}, {"id": "1511.06411", "submitter": "Yang Song", "authors": "Yang Song, Alexander G. Schwing, Richard S. Zemel, Raquel Urtasun", "title": "Training Deep Neural Networks via Direct Loss Minimization", "comments": "ICML2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised training of deep neural nets typically relies on minimizing\ncross-entropy. However, in many domains, we are interested in performing well\non metrics specific to the application. In this paper we propose a direct loss\nminimization approach to train deep neural networks, which provably minimizes\nthe application-specific loss function. This is often non-trivial, since these\nfunctions are neither smooth nor decomposable and thus are not amenable to\noptimization with standard gradient-based methods. We demonstrate the\neffectiveness of our approach in the context of maximizing average precision\nfor ranking problems. Towards this goal, we develop a novel dynamic programming\nalgorithm that can efficiently compute the weight updates. Our approach proves\nsuperior to a variety of baselines in the context of action classification and\nobject detection, especially in the presence of label noise.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:02:26 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 00:56:59 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Song", "Yang", ""], ["Schwing", "Alexander G.", ""], ["Zemel", "Richard S.", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1511.06412", "submitter": "M\\'elanie Ducoffe", "authors": "Melanie Ducoffe and Frederic Precioso", "title": "QBDC: Query by dropout committee for training deep supervised\n  architecture", "comments": "Submitted to ICLR2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the current trend is to increase the depth of neural networks to\nincrease their performance, the size of their training database has to grow\naccordingly. We notice an emergence of tremendous databases, although providing\nlabels to build a training set still remains a very expensive task. We tackle\nthe problem of selecting the samples to be labelled in an online fashion. In\nthis paper, we present an active learning strategy based on query by committee\nand dropout technique to train a Convolutional Neural Network (CNN). We derive\na commmittee of partial CNNs resulting from batchwise dropout runs on the\ninitial CNN. We evaluate our active learning strategy for CNN on MNIST\nbenchmark, showing in particular that selecting less than 30 % from the\nannotated database is enough to get similar error rate as using the full\ntraining set on MNIST. We also studied the robustness of our method against\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:03:14 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2015 14:19:01 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Ducoffe", "Melanie", ""], ["Precioso", "Frederic", ""]]}, {"id": "1511.06416", "submitter": "Daniel Seita", "authors": "Daniel Seita, Haoyu Chen, and John Canny", "title": "Fast Parallel SAME Gibbs Sampling on General Discrete Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental task in machine learning and related fields is to perform\ninference on Bayesian networks. Since exact inference takes exponential time in\ngeneral, a variety of approximate methods are used. Gibbs sampling is one of\nthe most accurate approaches and provides unbiased samples from the posterior\nbut it has historically been too expensive for large models. In this paper, we\npresent an optimized, parallel Gibbs sampler augmented with state replication\n(SAME or State Augmented Marginal Estimation) to decrease convergence time. We\nfind that SAME can improve the quality of parameter estimates while\naccelerating convergence. Experiments on both synthetic and real data show that\nour Gibbs sampler is substantially faster than the state of the art sampler,\nJAGS, without sacrificing accuracy. Our ultimate objective is to introduce the\nGibbs sampler to researchers in many fields to expand their range of feasible\ninference problems.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:08:22 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Seita", "Daniel", ""], ["Chen", "Haoyu", ""], ["Canny", "John", ""]]}, {"id": "1511.06418", "submitter": "Klaus Greff", "authors": "Klaus Greff, Rupesh Kumar Srivastava, J\\\"urgen Schmidhuber", "title": "Binding via Reconstruction Clustering", "comments": "12 pages, plus 12 pages Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Disentangled distributed representations of data are desirable for machine\nlearning, since they are more expressive and can generalize from fewer\nexamples. However, for complex data, the distributed representations of\nmultiple objects present in the same input can interfere and lead to\nambiguities, which is commonly referred to as the binding problem. We argue for\nthe importance of the binding problem to the field of representation learning,\nand develop a probabilistic framework that explicitly models inputs as a\ncomposition of multiple objects. We propose an unsupervised algorithm that uses\ndenoising autoencoders to dynamically bind features together in multi-object\ninputs through an Expectation-Maximization-like clustering process. The\neffectiveness of this method is demonstrated on artificially generated datasets\nof binary images, showing that it can even generalize to bind together new\nobjects never seen by the autoencoder during training.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:13:11 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2015 23:35:10 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 20:48:53 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2016 19:31:17 GMT"}], "update_date": "2016-01-21", "authors_parsed": [["Greff", "Klaus", ""], ["Srivastava", "Rupesh Kumar", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1511.06419", "submitter": "Maria De-Arteaga", "authors": "Maria De-Arteaga, Artur Dubrawski, Peter Huggins", "title": "Canonical Autocorrelation Analysis", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of sparse Canonical Correlation Analysis (CCA)\ndesigned for finding multiple-to-multiple linear correlations within a single\nset of variables. Unlike CCA, which finds correlations between two sets of data\nwhere the rows are matched exactly but the columns represent separate sets of\nvariables, the method proposed here, Canonical Autocorrelation Analysis (CAA),\nfinds multivariate correlations within just one set of variables. This can be\nuseful when we look for hidden parsimonious structures in data, each involving\nonly a small subset of all features. In addition, the discovered correlations\nare highly interpretable as they are formed by pairs of sparse linear\ncombinations of the original features. We show how CAA can be of use as a tool\nfor anomaly detection when the expected structure of correlations is not\nfollowed by anomalous data. We illustrate the utility of CAA in two application\ndomains where single-class and unsupervised learning of correlation structures\nare particularly relevant: breast cancer diagnosis and radiation threat\ndetection. When applied to the Wisconsin Breast Cancer data, single-class CAA\nis competitive with supervised methods used in literature. On the radiation\nthreat detection task, unsupervised CAA performs significantly better than an\nunsupervised alternative prevalent in the domain, while providing valuable\nadditional insights for threat analysis.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:13:43 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["De-Arteaga", "Maria", ""], ["Dubrawski", "Artur", ""], ["Huggins", "Peter", ""]]}, {"id": "1511.06420", "submitter": "Ethan Caballero V", "authors": "Ethan Caballero", "title": "Skip-Thought Memory Networks", "comments": "Removed by arXiv administrators because submission violated the terms\n  of arXiv's license agreement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA) is fundamental to natural language processing in that\nmost nlp problems can be phrased as QA (Kumar et al., 2015). Current weakly\nsupervised memory network models that have been proposed so far struggle at\nanswering questions that involve relations among multiple entities (such as\nfacebook's bAbi qa5-three-arg-relations in (Weston et al., 2015)). To address\nthis problem of learning multi-argument multi-hop semantic relations for the\npurpose of QA, we propose a method that combines the jointly learned long-term\nread-write memory and attentive inference components of end-to-end memory\nnetworks (MemN2N) (Sukhbaatar et al., 2015) with distributed sentence vector\nrepresentations encoded by a Skip-Thought model (Kiros et al., 2015). This\nchoice to append Skip-Thought Vectors to the existing MemN2N framework is\nmotivated by the fact that Skip-Thought Vectors have been shown to accurately\nmodel multi-argument semantic relations (Kiros et al., 2015).\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:15:46 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 02:30:16 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Caballero", "Ethan", ""]]}, {"id": "1511.06421", "submitter": "Jacob Gardner", "authors": "Jacob R. Gardner, Paul Upchurch, Matt J. Kusner, Yixuan Li, Kilian Q.\n  Weinberger, Kavita Bala, John E. Hopcroft", "title": "Deep Manifold Traversal: Changing Labels with Convolutional Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in computer vision can be cast as a \"label changing\" problem,\nwhere the goal is to make a semantic change to the appearance of an image or\nsome subject in an image in order to alter the class membership. Although\nsuccessful task-specific methods have been developed for some label changing\napplications, to date no general purpose method exists. Motivated by this we\npropose deep manifold traversal, a method that addresses the problem in its\nmost general form: it first approximates the manifold of natural images then\nmorphs a test image along a traversal path away from a source class and towards\na target class while staying near the manifold throughout. The resulting\nalgorithm is surprisingly effective and versatile. It is completely data\ndriven, requiring only an example set of images from the desired source and\ntarget domains. We demonstrate deep manifold traversal on highly diverse label\nchanging tasks: changing an individual's appearance (age and hair color),\nchanging the season of an outdoor image, and transforming a city skyline\ntowards nighttime.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:17:20 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 01:37:02 GMT"}, {"version": "v3", "created": "Thu, 17 Mar 2016 17:57:55 GMT"}], "update_date": "2016-03-21", "authors_parsed": [["Gardner", "Jacob R.", ""], ["Upchurch", "Paul", ""], ["Kusner", "Matt J.", ""], ["Li", "Yixuan", ""], ["Weinberger", "Kilian Q.", ""], ["Bala", "Kavita", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1511.06422", "submitter": "Dmytro Mishkin", "authors": "Dmytro Mishkin, Jiri Matas", "title": "All you need is a good init", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer-sequential unit-variance (LSUV) initialization - a simple method for\nweight initialization for deep net learning - is proposed. The method consists\nof the two steps. First, pre-initialize weights of each convolution or\ninner-product layer with orthonormal matrices. Second, proceed from the first\nto the final layer, normalizing the variance of the output of each layer to be\nequal to one.\n  Experiment with different activation functions (maxout, ReLU-family, tanh)\nshow that the proposed initialization leads to learning of very deep nets that\n(i) produces networks with test accuracy better or equal to standard methods\nand (ii) is at least as fast as the complex schemes proposed specifically for\nvery deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava\net al. (2015)).\n  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets\nand the state-of-the-art, or very close to it, is achieved on the MNIST,\nCIFAR-10/100 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:19:15 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2015 14:38:33 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2016 18:46:03 GMT"}, {"version": "v4", "created": "Wed, 13 Jan 2016 17:47:07 GMT"}, {"version": "v5", "created": "Mon, 18 Jan 2016 20:07:09 GMT"}, {"version": "v6", "created": "Wed, 27 Jan 2016 15:10:19 GMT"}, {"version": "v7", "created": "Fri, 19 Feb 2016 14:37:10 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Mishkin", "Dmytro", ""], ["Matas", "Jiri", ""]]}, {"id": "1511.06423", "submitter": "Ziyuan Lin", "authors": "Ziyuan Lin and Jaakko Peltonen", "title": "An Information Retrieval Approach to Finding Dependent Subspaces of\n  Multiple Views", "comments": "9 pages, 15 figures. Submitted for ICLR 2016; the authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding relationships between multiple views of data is essential both for\nexploratory analysis and as pre-processing for predictive tasks. A prominent\napproach is to apply variants of Canonical Correlation Analysis (CCA), a\nclassical method seeking correlated components between views. The basic CCA is\nrestricted to maximizing a simple dependency criterion, correlation, measured\ndirectly between data coordinates. We introduce a new method that finds\ndependent subspaces of views directly optimized for the data analysis task of\n\\textit{neighbor retrieval between multiple views}. We optimize mappings for\neach view such as linear transformations to maximize cross-view similarity\nbetween neighborhoods of data samples. The criterion arises directly from the\nwell-defined retrieval task, detects nonlinear and local similarities, is able\nto measure dependency of data relationships rather than only individual data\ncoordinates, and is related to well understood measures of information\nretrieval quality. In experiments we show the proposed method outperforms\nalternatives in preserving cross-view neighborhood similarities, and yields\ninsights into local dependencies between multiple views.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:20:34 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 23:09:07 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Lin", "Ziyuan", ""], ["Peltonen", "Jaakko", ""]]}, {"id": "1511.06425", "submitter": "KyungHyun Cho", "authors": "Quan Gan, Qipeng Guo, Zheng Zhang, Kyunghyun Cho", "title": "First Step toward Model-Free, Anonymous Object Tracking with Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study a novel visual object tracking approach\nbased on convolutional networks and recurrent networks. The proposed approach\nis distinct from the existing approaches to visual object tracking, such as\nfiltering-based ones and tracking-by-detection ones, in the sense that the\ntracking system is explicitly trained off-line to track anonymous objects in a\nnoisy environment. The proposed visual tracking model is end-to-end trainable,\nminimizing any adversarial effect from mismatches in object representation and\nbetween the true underlying dynamics and learning dynamics. We empirically show\nthat the proposed tracking approach works well in various scenarios by\ngenerating artificial video sequences with varying conditions; the number of\nobjects, amount of noise and the match between the training shapes and test\nshapes.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:24:15 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 19:44:15 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Gan", "Quan", ""], ["Guo", "Qipeng", ""], ["Zhang", "Zheng", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1511.06428", "submitter": "Kelvin Xu", "authors": "Marcin Moczulski, Kelvin Xu, Aaron Courville, Kyunghyun Cho", "title": "A Controller-Recognizer Framework: How necessary is recognition for\n  control?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been growing interest in building active visual object\nrecognizers, as opposed to the usual passive recognizers which classifies a\ngiven static image into a predefined set of object categories. In this paper we\npropose to generalize these recently proposed end-to-end active visual\nrecognizers into a controller-recognizer framework. A model in the\ncontroller-recognizer framework consists of a controller, which interfaces with\nan external manipulator, and a recognizer which classifies the visual input\nadjusted by the manipulator. We describe two most recently proposed\ncontroller-recognizer models: recurrent attention model and spatial transformer\nnetwork as representative examples of controller-recognizer models. Based on\nthis description we observe that most existing end-to-end\ncontroller-recognizers tightly, or completely, couple a controller and\nrecognizer. We ask a question whether this tight coupling is necessary, and try\nto answer this empirically by building a controller-recognizer model with a\ndecoupled controller and recognizer. Our experiments revealed that it is not\nalways necessary to tightly couple them and that by decoupling a controller and\nrecognizer, there is a possibility of building a generic controller that is\npretrained and works together with any subsequent recognizer.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:38:53 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2015 03:51:33 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2015 18:47:15 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2016 20:58:21 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Moczulski", "Marcin", ""], ["Xu", "Kelvin", ""], ["Courville", "Aaron", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1511.06429", "submitter": "Sebastian H\\\"ofer", "authors": "Rico Jonschkowski, Sebastian H\\\"ofer, Oliver Brock", "title": "Patterns for Learning with Side Information", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised, semi-supervised, and unsupervised learning estimate a function\ngiven input/output samples. Generalization of the learned function to unseen\ndata can be improved by incorporating side information into learning. Side\ninformation are data that are neither from the input space nor from the output\nspace of the function, but include useful information for learning it. In this\npaper we show that learning with side information subsumes a variety of related\napproaches, e.g. multi-task learning, multi-view learning and learning using\nprivileged information. Our main contributions are (i) a new perspective that\nconnects these previously isolated approaches, (ii) insights about how these\nmethods incorporate different types of prior knowledge, and hence implement\ndifferent patterns, (iii) facilitating the application of these methods in\nnovel tasks, as well as (iv) a systematic experimental evaluation of these\npatterns in two supervised learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:39:35 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 06:35:18 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2015 12:38:26 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 16:45:52 GMT"}, {"version": "v5", "created": "Wed, 10 Feb 2016 11:57:18 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Jonschkowski", "Rico", ""], ["H\u00f6fer", "Sebastian", ""], ["Brock", "Oliver", ""]]}, {"id": "1511.06430", "submitter": "Mohammad Pezeshki", "authors": "Mohammad Pezeshki, Linxi Fan, Philemon Brakel, Aaron Courville, Yoshua\n  Bengio", "title": "Deconstructing the Ladder Network Architecture", "comments": "Proceedings of the 33 rd International Conference on Machine\n  Learning, New York, NY, USA, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Manual labeling of data is and will remain a costly endeavor. For this\nreason, semi-supervised learning remains a topic of practical importance. The\nrecently proposed Ladder Network is one such approach that has proven to be\nvery successful. In addition to the supervised objective, the Ladder Network\nalso adds an unsupervised objective corresponding to the reconstruction costs\nof a stack of denoising autoencoders. Although the empirical results are\nimpressive, the Ladder Network has many components intertwined, whose\ncontributions are not obvious in such a complex architecture. In order to help\nelucidate and disentangle the different ingredients in the Ladder Network\nrecipe, this paper presents an extensive experimental investigation of variants\nof the Ladder Network in which we replace or remove individual components to\ngain more insight into their relative importance. We find that all of the\ncomponents are necessary for achieving optimal performance, but they do not\ncontribute equally. For semi-supervised tasks, we conclude that the most\nimportant contribution is made by the lateral connection, followed by the\napplication of noise, and finally the choice of what we refer to as the\n`combinator function' in the decoder path. We also find that as the number of\nlabeled training examples increases, the lateral connections and reconstruction\ncriterion become less important, with most of the improvement in generalization\nbeing due to the injection of noise in each layer. Furthermore, we present a\nnew type of combinator function that outperforms the original design in both\nfully- and semi-supervised tasks, reducing record test error rates on\nPermutation-Invariant MNIST to 0.57% for the supervised setting, and to 0.97%\nand 1.0% for semi-supervised settings with 1000 and 100 labeled examples\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:45:20 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2015 18:17:44 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2016 09:23:24 GMT"}, {"version": "v4", "created": "Tue, 24 May 2016 15:53:23 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Pezeshki", "Mohammad", ""], ["Fan", "Linxi", ""], ["Brakel", "Philemon", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1511.06432", "submitter": "Nicolas Ballas", "authors": "Nicolas Ballas, Li Yao, Chris Pal, Aaron Courville", "title": "Delving Deeper into Convolutional Networks for Learning Video\n  Representations", "comments": "ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to learn spatio-temporal features in videos from\nintermediate visual representations we call \"percepts\" using\nGated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on percepts\nthat are extracted from all level of a deep convolutional network trained on\nthe large ImageNet dataset. While high-level percepts contain highly\ndiscriminative information, they tend to have a low-spatial resolution.\nLow-level percepts, on the other hand, preserve a higher spatial resolution\nfrom which we can model finer motion patterns. Using low-level percepts can\nleads to high-dimensionality video representations. To mitigate this effect and\ncontrol the model number of parameters, we introduce a variant of the GRU model\nthat leverages the convolution operations to enforce sparse connectivity of the\nmodel units and share parameters across the input spatial locations.\n  We empirically validate our approach on both Human Action Recognition and\nVideo Captioning tasks. In particular, we achieve results equivalent to\nstate-of-art on the YouTube2Text dataset using a simpler text-decoder model and\nwithout extra 3D CNN features.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:46:13 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 02:46:54 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 19:43:19 GMT"}, {"version": "v4", "created": "Tue, 1 Mar 2016 18:54:11 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Ballas", "Nicolas", ""], ["Yao", "Li", ""], ["Pal", "Chris", ""], ["Courville", "Aaron", ""]]}, {"id": "1511.06433", "submitter": "Krzysztof Geras", "authors": "Krzysztof J. Geras, Abdel-rahman Mohamed, Rich Caruana, Gregor Urban,\n  Shengjie Wang, Ozlem Aslan, Matthai Philipose, Matthew Richardson, Charles\n  Sutton", "title": "Blending LSTMs into CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider whether deep convolutional networks (CNNs) can represent decision\nfunctions with similar accuracy as recurrent networks such as LSTMs. First, we\nshow that a deep CNN with an architecture inspired by the models recently\nintroduced in image recognition can yield better accuracy than previous\nconvolutional and LSTM networks on the standard 309h Switchboard automatic\nspeech recognition task. Then we show that even more accurate CNNs can be\ntrained under the guidance of LSTMs using a variant of model compression, which\nwe call model blending because the teacher and student models are similar in\ncomplexity but different in inductive bias. Blending further improves the\naccuracy of our CNN, yielding a computationally efficient model of accuracy\nhigher than any of the other individual models. Examining the effect of \"dark\nknowledge\" in this model compression task, we find that less than 1% of the\nhighest probability labels are needed for accurate model compression.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:48:59 GMT"}, {"version": "v2", "created": "Fri, 4 Mar 2016 13:43:02 GMT"}, {"version": "v3", "created": "Wed, 14 Sep 2016 14:36:53 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Geras", "Krzysztof J.", ""], ["Mohamed", "Abdel-rahman", ""], ["Caruana", "Rich", ""], ["Urban", "Gregor", ""], ["Wang", "Shengjie", ""], ["Aslan", "Ozlem", ""], ["Philipose", "Matthai", ""], ["Richardson", "Matthew", ""], ["Sutton", "Charles", ""]]}, {"id": "1511.06434", "submitter": "Alec Radford", "authors": "Alec Radford, Luke Metz, and Soumith Chintala", "title": "Unsupervised Representation Learning with Deep Convolutional Generative\n  Adversarial Networks", "comments": "Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, supervised learning with convolutional networks (CNNs) has\nseen huge adoption in computer vision applications. Comparatively, unsupervised\nlearning with CNNs has received less attention. In this work we hope to help\nbridge the gap between the success of CNNs for supervised learning and\nunsupervised learning. We introduce a class of CNNs called deep convolutional\ngenerative adversarial networks (DCGANs), that have certain architectural\nconstraints, and demonstrate that they are a strong candidate for unsupervised\nlearning. Training on various image datasets, we show convincing evidence that\nour deep convolutional adversarial pair learns a hierarchy of representations\nfrom object parts to scenes in both the generator and discriminator.\nAdditionally, we use the learned features for novel tasks - demonstrating their\napplicability as general image representations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:50:32 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 23:09:39 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Radford", "Alec", ""], ["Metz", "Luke", ""], ["Chintala", "Soumith", ""]]}, {"id": "1511.06435", "submitter": "Soheil Bahrampour", "authors": "Soheil Bahrampour, Naveen Ramakrishnan, Lukas Schott, Mohak Shah", "title": "Comparative Study of Deep Learning Software Frameworks", "comments": "Submitted to KDD 2016 with TensorFlow results added. At the time of\n  submission to KDD, TensorFlow was available only with cuDNN v.2 and thus its\n  performance is reported with that version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have resulted in significant performance improvements\nin several application domains and as such several software frameworks have\nbeen developed to facilitate their implementation. This paper presents a\ncomparative study of five deep learning frameworks, namely Caffe, Neon,\nTensorFlow, Theano, and Torch, on three aspects: extensibility, hardware\nutilization, and speed. The study is performed on several types of deep\nlearning architectures and we evaluate the performance of the above frameworks\nwhen employed on a single machine for both (multi-threaded) CPU and GPU (Nvidia\nTitan X) settings. The speed performance metrics used here include the gradient\ncomputation time, which is important during the training phase of deep\nnetworks, and the forward time, which is important from the deployment\nperspective of trained networks. For convolutional networks, we also report how\neach of these frameworks support various convolutional algorithms and their\ncorresponding performance. From our experiments, we observe that Theano and\nTorch are the most easily extensible frameworks. We observe that Torch is best\nsuited for any deep architecture on CPU, followed by Theano. It also achieves\nthe best performance on the GPU for large convolutional and fully connected\nnetworks, followed closely by Neon. Theano achieves the best performance on GPU\nfor training and deployment of LSTM networks. Caffe is the easiest for\nevaluating the performance of standard deep architectures. Finally, TensorFlow\nis a very flexible framework, similar to Theano, but its performance is\ncurrently not competitive compared to the other studied frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:51:38 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 22:03:33 GMT"}, {"version": "v3", "created": "Wed, 30 Mar 2016 00:54:34 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Bahrampour", "Soheil", ""], ["Ramakrishnan", "Naveen", ""], ["Schott", "Lukas", ""], ["Shah", "Mohak", ""]]}, {"id": "1511.06437", "submitter": "Rodrigo Benenson", "authors": "Jan Hosang, Rodrigo Benenson, Bernt Schiele", "title": "A convnet for non-maximum suppression", "comments": "Included comments from reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-maximum suppression (NMS) is used in virtually all state-of-the-art\nobject detection pipelines. While essential object detection ingredients such\nas features, classifiers, and proposal methods have been extensively researched\nsurprisingly little work has aimed to systematically address NMS. The de-facto\nstandard for NMS is based on greedy clustering with a fixed distance threshold,\nwhich forces to trade-off recall versus precision. We propose a convnet\ndesigned to perform NMS of a given set of detections. We report experiments on\na synthetic setup, and results on crowded pedestrian detection scenes. Our\napproach overcomes the intrinsic limitations of greedy NMS, obtaining better\nrecall and precision.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 22:56:18 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 08:16:33 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 00:00:21 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Hosang", "Jan", ""], ["Benenson", "Rodrigo", ""], ["Schiele", "Bernt", ""]]}, {"id": "1511.06440", "submitter": "Ilya Sutskever", "authors": "Ilya Sutskever, Rafal Jozefowicz, Karol Gregor, Danilo Rezende, Tim\n  Lillicrap, Oriol Vinyals", "title": "Towards Principled Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General unsupervised learning is a long-standing conceptual problem in\nmachine learning. Supervised learning is successful because it can be solved by\nthe minimization of the training error cost function. Unsupervised learning is\nnot as successful, because the unsupervised objective may be unrelated to the\nsupervised task of interest. For an example, density modelling and\nreconstruction have often been used for unsupervised learning, but they did not\nproduced the sought-after performance gains, because they have no knowledge of\nthe supervised tasks.\n  In this paper, we present an unsupervised cost function which we name the\nOutput Distribution Matching (ODM) cost, which measures a divergence between\nthe distribution of predictions and distributions of labels. The ODM cost is\nappealing because it is consistent with the supervised cost in the following\nsense: a perfect supervised classifier is also perfect according to the ODM\ncost. Therefore, by aggressively optimizing the ODM cost, we are almost\nguaranteed to improve our supervised performance whenever the space of possible\npredictions is exponentially large.\n  We demonstrate that the ODM cost works well on number of small and\nsemi-artificial datasets using no (or almost no) labelled training cases.\nFinally, we show that the ODM cost can be used for one-shot domain adaptation,\nwhich allows the model to classify inputs that differ from the input\ndistribution in significant ways without the need for prior exposure to the new\ndomain.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:04:23 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 17:24:22 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Sutskever", "Ilya", ""], ["Jozefowicz", "Rafal", ""], ["Gregor", "Karol", ""], ["Rezende", "Danilo", ""], ["Lillicrap", "Tim", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1511.06442", "submitter": "Henry Gouk", "authors": "Henry Gouk, Bernhard Pfahringer, Michael Cree", "title": "Fast Metric Learning For Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity metrics are a core component of many information retrieval and\nmachine learning systems. In this work we propose a method capable of learning\na similarity metric from data equipped with a binary relation. By considering\nonly the similarity constraints, and initially ignoring the features, we are\nable to learn target vectors for each instance using one of several\nappropriately designed loss functions. A regression model can then be\nconstructed that maps novel feature vectors to the same target vector space,\nresulting in a feature extractor that computes vectors for which a predefined\nmetric is a meaningful measure of similarity. We present results on both\nmulticlass and multi-label classification datasets that demonstrate\nconsiderably faster convergence, as well as higher accuracy on the majority of\nthe intrinsic evaluation tasks and all extrinsic evaluation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:10:00 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 06:05:30 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2015 15:27:11 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2016 02:11:00 GMT"}, {"version": "v5", "created": "Tue, 5 Apr 2016 07:29:48 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Gouk", "Henry", ""], ["Pfahringer", "Bernhard", ""], ["Cree", "Michael", ""]]}, {"id": "1511.06443", "submitter": "Daniel Roy", "authors": "Gintare Karolina Dziugaite and Daniel M. Roy", "title": "Neural Network Matrix Factorization", "comments": "Minor modifications to notation. Added additional experiments and\n  discussion. 7 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data often comes in the form of an array or matrix. Matrix factorization\ntechniques attempt to recover missing or corrupted entries by assuming that the\nmatrix can be written as the product of two low-rank matrices. In other words,\nmatrix factorization approximates the entries of the matrix by a simple, fixed\nfunction---namely, the inner product---acting on the latent feature vectors for\nthe corresponding row and column. Here we consider replacing the inner product\nby an arbitrary function that we learn from the data at the same time as we\nlearn the latent feature vectors. In particular, we replace the inner product\nby a multi-layer feed-forward neural network, and learn by alternating between\noptimizing the network for fixed latent features, and optimizing the latent\nfeatures for a fixed network. The resulting approach---which we call neural\nnetwork matrix factorization or NNMF, for short---dominates standard low-rank\ntechniques on a suite of benchmark but is dominated by some recent proposals\nthat take advantage of the graph features. Given the vast range of\narchitectures, activation functions, regularizers, and optimization techniques\nthat could be used within the NNMF framework, it seems likely the true\npotential of the approach has yet to be reached.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:13:29 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2015 04:29:39 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Dziugaite", "Gintare Karolina", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1511.06444", "submitter": "Levent Sagun", "authors": "Levent Sagun, Thomas Trogdon and Yann LeCun", "title": "Universal halting times in optimization and machine learning", "comments": null, "journal-ref": "Quart. Appl. Math. 76 (2018), 289-301", "doi": "10.1090/qam/1483", "report-no": null, "categories": "cs.LG math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The authors present empirical distributions for the halting time (measured by\nthe number of iterations to reach a given accuracy) of optimization algorithms\napplied to two random systems: spin glasses and deep learning. Given an\nalgorithm, which we take to be both the optimization routine and the form of\nthe random landscape, the fluctuations of the halting time follow a\ndistribution that, after centering and scaling, remains unchanged even when the\ndistribution on the landscape is changed. We observe two qualitative classes: A\nGumbel-like distribution that appears in Google searches, human decision times,\nthe QR eigenvalue algorithm and spin glasses, and a Gaussian-like distribution\nthat appears in conjugate gradient method, deep network with MNIST input data\nand deep network with random input data. This empirical evidence suggests\npresence of a class of distributions for which the halting time is independent\nof the underlying distribution under some conditions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:14:25 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 20:18:58 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2017 02:49:58 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Sagun", "Levent", ""], ["Trogdon", "Thomas", ""], ["LeCun", "Yann", ""]]}, {"id": "1511.06448", "submitter": "Pouya Bashivan", "authors": "Pouya Bashivan, Irina Rish, Mohammed Yeasin, Noel Codella", "title": "Learning Representations from EEG with Deep Recurrent-Convolutional\n  Neural Networks", "comments": "To be published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in modeling cognitive events from electroencephalogram\n(EEG) data is finding representations that are invariant to inter- and\nintra-subject differences, as well as to inherent noise associated with such\ndata. Herein, we propose a novel approach for learning such representations\nfrom multi-channel EEG time-series, and demonstrate its advantages in the\ncontext of mental load classification task. First, we transform EEG activities\ninto a sequence of topology-preserving multi-spectral images, as opposed to\nstandard EEG analysis techniques that ignore such spatial information. Next, we\ntrain a deep recurrent-convolutional network inspired by state-of-the-art video\nclassification to learn robust representations from the sequence of images. The\nproposed approach is designed to preserve the spatial, spectral, and temporal\nstructure of EEG which leads to finding features that are less sensitive to\nvariations and distortions within each dimension. Empirical evaluation on the\ncognitive load classification task demonstrated significant improvements in\nclassification accuracy over current state-of-the-art approaches in this field.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:29:55 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 22:04:23 GMT"}, {"version": "v3", "created": "Mon, 29 Feb 2016 21:33:45 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Bashivan", "Pouya", ""], ["Rish", "Irina", ""], ["Yeasin", "Mohammed", ""], ["Codella", "Noel", ""]]}, {"id": "1511.06449", "submitter": "Eunbyung Park", "authors": "Eunbyung Park, Alexander C. Berg", "title": "Learning to decompose for object detection and instance segmentation", "comments": "ICLR 2016 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep convolutional neural networks(CNNs) have achieved remarkable\nresults on object detection and segmentation, pre- and post-processing steps\nsuch as region proposals and non-maximum suppression(NMS), have been required.\nThese steps result in high computational complexity and sensitivity to\nhyperparameters, e.g. thresholds for NMS. In this work, we propose a novel\nend-to-end trainable deep neural network architecture, which consists of\nconvolutional and recurrent layers, that generates the correct number of object\ninstances and their bounding boxes (or segmentation masks) given an image,\nusing only a single network evaluation without any pre- or post-processing\nsteps. We have tested on detecting digits in multi-digit images synthesized\nusing MNIST, automatically segmenting digits in these images, and detecting\ncars in the KITTI benchmark dataset. The proposed approach outperforms a strong\nCNN baseline on the synthesized digits datasets and shows promising results on\nKITTI car detection.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:30:06 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 06:07:28 GMT"}, {"version": "v3", "created": "Wed, 11 May 2016 02:55:29 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Park", "Eunbyung", ""], ["Berg", "Alexander C.", ""]]}, {"id": "1511.06452", "submitter": "Hyun Oh Song", "authors": "Hyun Oh Song, Yu Xiang, Stefanie Jegelka, Silvio Savarese", "title": "Deep Metric Learning via Lifted Structured Feature Embedding", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the distance metric between pairs of examples is of great importance\nfor learning and visual recognition. With the remarkable success from the state\nof the art convolutional neural networks, recent works have shown promising\nresults on discriminatively training the networks to learn semantic feature\nembeddings where similar examples are mapped close to each other and dissimilar\nexamples are mapped farther apart. In this paper, we describe an algorithm for\ntaking full advantage of the training batches in the neural network training by\nlifting the vector of pairwise distances within the batch to the matrix of\npairwise distances. This step enables the algorithm to learn the state of the\nart feature embedding by optimizing a novel structured prediction objective on\nthe lifted problem. Additionally, we collected Online Products dataset: 120k\nimages of 23k classes of online products for metric learning. Our experiments\non the CUB-200-2011, CARS196, and Online Products datasets demonstrate\nsignificant improvement over existing deep feature embedding methods on all\nexperimented embedding sizes with the GoogLeNet network.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:41:11 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Song", "Hyun Oh", ""], ["Xiang", "Yu", ""], ["Jegelka", "Stefanie", ""], ["Savarese", "Silvio", ""]]}, {"id": "1511.06455", "submitter": "Zhenwen Dai", "authors": "Zhenwen Dai, Andreas Damianou, Javier Gonz\\'alez, Neil Lawrence", "title": "Variational Auto-encoded Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a scalable deep non-parametric generative model by augmenting deep\nGaussian processes with a recognition model. Inference is performed in a novel\nscalable variational framework where the variational posterior distributions\nare reparametrized through a multilayer perceptron. The key aspect of this\nreformulation is that it prevents the proliferation of variational parameters\nwhich otherwise grow linearly in proportion to the sample size. We derive a new\nformulation of the variational lower bound that allows us to distribute most of\nthe computation in a way that enables to handle datasets of the size of\nmainstream deep learning tasks. We show the efficacy of the method on a variety\nof challenges including deep unsupervised learning and deep Bayesian\noptimization.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:47:34 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 21:34:58 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Dai", "Zhenwen", ""], ["Damianou", "Andreas", ""], ["Gonz\u00e1lez", "Javier", ""], ["Lawrence", "Neil", ""]]}, {"id": "1511.06456", "submitter": "Dzmitry Bahdanau", "authors": "Dzmitry Bahdanau, Dmitriy Serdyuk, Phil\\'emon Brakel, Nan Rosemary Ke,\n  Jan Chorowski, Aaron Courville, Yoshua Bengio", "title": "Task Loss Estimation for Sequence Prediction", "comments": "Submitted to ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, the performance on a supervised machine learning task is evaluated\nwith a emph{task loss} function that cannot be optimized directly. Examples of\nsuch loss functions include the classification error, the edit distance and the\nBLEU score. A common workaround for this problem is to instead optimize a\nemph{surrogate loss} function, such as for instance cross-entropy or hinge\nloss. In order for this remedy to be effective, it is important to ensure that\nminimization of the surrogate loss results in minimization of the task loss, a\ncondition that we call emph{consistency with the task loss}. In this work, we\npropose another method for deriving differentiable surrogate losses that\nprovably meet this requirement. We focus on the broad class of models that\ndefine a score for every input-output pair. Our idea is that this score can be\ninterpreted as an estimate of the task loss, and that the estimation error may\nbe used as a consistent surrogate loss. A distinct feature of such an approach\nis that it defines the desirable value of the score for every input-output\npair. We use this property to design specialized surrogate losses for\nEncoder-Decoder models often used for sequence prediction tasks. In our\nexperiment, we benchmark on the task of speech recognition. Using a new\nsurrogate loss instead of cross-entropy to train an Encoder-Decoder speech\nrecognizer brings a significant ~13% relative improvement in terms of Character\nError Rate (CER) in the case when no extra corpora are used for language\nmodeling.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 23:51:31 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2015 22:53:47 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 15:28:19 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2016 20:48:19 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Bahdanau", "Dzmitry", ""], ["Serdyuk", "Dmitriy", ""], ["Brakel", "Phil\u00e9mon", ""], ["Ke", "Nan Rosemary", ""], ["Chorowski", "Jan", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1511.06457", "submitter": "Peng Wang", "authors": "Peng Wang and Alan Yuille", "title": "DOC: Deep OCclusion Estimation From a Single Image", "comments": "Accepted to ECCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering the occlusion relationships between objects is a fundamental human\nvisual ability which yields important information about the 3D world. In this\npaper we propose a deep network architecture, called DOC, which acts on a\nsingle image, detects object boundaries and estimates the border ownership\n(i.e. which side of the boundary is foreground and which is background). We\nrepresent occlusion relations by a binary edge map, to indicate the object\nboundary, and an occlusion orientation variable which is tangential to the\nboundary and whose direction specifies border ownership by a left-hand rule. We\ntrain two related deep convolutional neural networks, called DOC, which exploit\nlocal and non-local image cues to estimate this representation and hence\nrecover occlusion relations. In order to train and test DOC we construct a\nlarge-scale instance occlusion boundary dataset using PASCAL VOC images, which\nwe call the PASCAL instance occlusion dataset (PIOD). This contains 10,000\nimages and hence is two orders of magnitude larger than existing occlusion\ndatasets for outdoor images. We test two variants of DOC on PIOD and on the\nBSDS occlusion dataset and show they outperform state-of-the-art methods.\nFinally, we perform numerous experiments investigating multiple settings of DOC\nand transfer between BSDS and PIOD, which provides more insights for further\nstudy of occlusion estimation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 00:04:06 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 00:49:47 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 06:46:26 GMT"}, {"version": "v4", "created": "Sun, 24 Jul 2016 07:16:54 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Wang", "Peng", ""], ["Yuille", "Alan", ""]]}, {"id": "1511.06458", "submitter": "Nathan Wiebe", "authors": "Nathan Wiebe, Christopher Granade, Ashish Kapoor, Krysta M Svore", "title": "Bayesian inference via rejection filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a method for approximating Bayesian inference using rejection\nsampling. We not only make the process efficient, but also dramatically reduce\nthe memory required relative to conventional methods by combining rejection\nsampling with particle filtering. We also provide an approximate form of\nrejection sampling that makes rejection filtering tractable in cases where\nexact rejection sampling is not efficient. Finally, we present several\nnumerical examples of rejection filtering that show its ability to track time\ndependent parameters in online settings and also benchmark its performance on\nMNIST classification problems.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 00:08:07 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 02:01:59 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Wiebe", "Nathan", ""], ["Granade", "Christopher", ""], ["Kapoor", "Ashish", ""], ["Svore", "Krysta M", ""]]}, {"id": "1511.06464", "submitter": "Martin Arjovsky", "authors": "Martin Arjovsky, Amar Shah, Yoshua Bengio", "title": "Unitary Evolution Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are notoriously difficult to train. When the\neigenvalues of the hidden to hidden weight matrix deviate from absolute value\n1, optimization becomes difficult due to the well studied issue of vanishing\nand exploding gradients, especially when trying to learn long-term\ndependencies. To circumvent this problem, we propose a new architecture that\nlearns a unitary weight matrix, with eigenvalues of absolute value exactly 1.\nThe challenge we address is that of parametrizing unitary matrices in a way\nthat does not require expensive computations (such as eigendecomposition) after\neach weight update. We construct an expressive unitary weight matrix by\ncomposing several structured matrices that act as building blocks with\nparameters to be learned. Optimization with this parameterization becomes\nfeasible only when considering hidden states in the complex domain. We\ndemonstrate the potential of this architecture by achieving state of the art\nresults in several hard tasks involving very long-term dependencies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 00:37:33 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2015 18:42:08 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2016 00:52:28 GMT"}, {"version": "v4", "created": "Wed, 25 May 2016 23:34:38 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Arjovsky", "Martin", ""], ["Shah", "Amar", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1511.06480", "submitter": "Felix X. Yu", "authors": "Felix X. Yu, Aditya Bhaskara, Sanjiv Kumar, Yunchao Gong, Shih-Fu\n  Chang", "title": "On Binary Embedding using Circulant Matrices", "comments": "This is an extended version of a paper by the first, third, fourth\n  and fifth authors that appeared in ICML 2014 [arXiv:1405.3162]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary embeddings provide efficient and powerful ways to perform operations\non large scale data. However binary embedding typically requires long codes in\norder to preserve the discriminative power of the input space. Thus binary\ncoding methods traditionally suffer from high computation and storage costs in\nsuch a scenario. To address this problem, we propose Circulant Binary Embedding\n(CBE) which generates binary codes by projecting the data with a circulant\nmatrix. The circulant structure allows us to use Fast Fourier Transform\nalgorithms to speed up the computation. For obtaining $k$-bit binary codes from\n$d$-dimensional data, this improves the time complexity from $O(dk)$ to\n$O(d\\log{d})$, and the space complexity from $O(dk)$ to $O(d)$.\n  We study two settings, which differ in the way we choose the parameters of\nthe circulant matrix. In the first, the parameters are chosen randomly and in\nthe second, the parameters are learned using the data. For randomized CBE, we\ngive a theoretical analysis comparing it with binary embedding using an\nunstructured random projection matrix. The challenge here is to show that the\ndependencies in the entries of the circulant matrix do not lead to a loss in\nperformance. In the second setting, we design a novel time-frequency\nalternating optimization to learn data-dependent circulant projections, which\nalternatively minimizes the objective in original and Fourier domains. In both\nthe settings, we show by extensive experiments that the CBE approach gives much\nbetter performance than the state-of-the-art approaches if we fix a running\ntime, and provides much faster computation with negligible performance\ndegradation if we fix the number of bits in the embedding.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 03:05:15 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2015 02:36:10 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Yu", "Felix X.", ""], ["Bhaskara", "Aditya", ""], ["Kumar", "Sanjiv", ""], ["Gong", "Yunchao", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1511.06481", "submitter": "Guillaume Alain", "authors": "Guillaume Alain, Alex Lamb, Chinnadhurai Sankar, Aaron Courville,\n  Yoshua Bengio", "title": "Variance Reduction in SGD by Distributed Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to accelerate their learning by selecting training materials\nthat are the most informative and at the appropriate level of difficulty. We\npropose a framework for distributing deep learning in which one set of workers\nsearch for the most informative examples in parallel while a single worker\nupdates the model on examples selected by importance sampling. This leads the\nmodel to update using an unbiased estimate of the gradient which also has\nminimum variance when the sampling proposal is proportional to the L2-norm of\nthe gradient. We show experimentally that this method reduces gradient variance\neven in a context where the cost of synchronization across machines cannot be\nignored, and where the factors for importance sampling are not updated\ninstantly across the training set.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 03:09:43 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 23:26:44 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2015 14:45:25 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 20:43:32 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2016 04:45:44 GMT"}, {"version": "v6", "created": "Thu, 21 Jan 2016 04:33:21 GMT"}, {"version": "v7", "created": "Sat, 16 Apr 2016 19:40:08 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Alain", "Guillaume", ""], ["Lamb", "Alex", ""], ["Sankar", "Chinnadhurai", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1511.06485", "submitter": "Pratik Chaudhari", "authors": "Pratik Chaudhari, Stefano Soatto", "title": "On the energy landscape of deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"AnnealSGD\", a regularized stochastic gradient descent algorithm\nmotivated by an analysis of the energy landscape of a particular class of deep\nnetworks with sparse random weights. The loss function of such networks can be\napproximated by the Hamiltonian of a spherical spin glass with Gaussian\ncoupling. While different from currently-popular architectures such as\nconvolutional ones, spin glasses are amenable to analysis, which provides\ninsights on the topology of the loss function and motivates algorithms to\nminimize it. Specifically, we show that a regularization term akin to a\nmagnetic field can be modulated with a single scalar parameter to transition\nthe loss function from a complex, non-convex landscape with exponentially many\nlocal minima, to a phase with a polynomial number of minima, all the way down\nto a trivial landscape with a unique minimum. AnnealSGD starts training in the\nrelaxed polynomial regime and gradually tightens the regularization parameter\nto steer the energy towards the original exponential regime. Even for\nconvolutional neural networks, which are quite unlike sparse random networks,\nwe empirically show that AnnealSGD improves the generalization error using\ncompetitive baselines on MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 04:31:05 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 08:43:53 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 19:06:59 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2016 02:20:02 GMT"}, {"version": "v5", "created": "Fri, 21 Apr 2017 22:56:46 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Chaudhari", "Pratik", ""], ["Soatto", "Stefano", ""]]}, {"id": "1511.06488", "submitter": "Sungho Shin", "authors": "Wonyong Sung, Sungho Shin, Kyuyeon Hwang", "title": "Resiliency of Deep Neural Networks under Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of deep neural network algorithms for hardware implementation\ncan be much lowered by optimizing the word-length of weights and signals.\nDirect quantization of floating-point weights, however, does not show good\nperformance when the number of bits assigned is small. Retraining of quantized\nnetworks has been developed to relieve this problem. In this work, the effects\nof retraining are analyzed for a feedforward deep neural network (FFDNN) and a\nconvolutional neural network (CNN). The network complexity is controlled to\nknow their effects on the resiliency of quantized networks by retraining. The\ncomplexity of the FFDNN is controlled by varying the unit size in each hidden\nlayer and the number of layers, while that of the CNN is done by modifying the\nfeature map configuration. We find that the performance gap between the\nfloating-point and the retrain-based ternary (+1, 0, -1) weight neural networks\nexists with a fair amount in 'complexity limited' networks, but the discrepancy\nalmost vanishes in fully complex networks whose capability is limited by the\ntraining data, rather than by the number of connections. This research shows\nthat highly complex DNNs have the capability of absorbing the effects of severe\nweight quantization through retraining, but connection limited networks are\nless resilient. This paper also presents the effective compression ratio to\nguide the trade-off between the network size and the precision when the\nhardware resource is limited.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 04:55:46 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 12:59:38 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 13:50:22 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Sung", "Wonyong", ""], ["Shin", "Sungho", ""], ["Hwang", "Kyuyeon", ""]]}, {"id": "1511.06499", "submitter": "Dustin Tran", "authors": "Dustin Tran, Rajesh Ranganath, David M. Blei", "title": "The Variational Gaussian Process", "comments": "Appears in International Conference on Learning Representations, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is a powerful tool for approximate inference, and it\nhas been recently applied for representation learning with deep generative\nmodels. We develop the variational Gaussian process (VGP), a Bayesian\nnonparametric variational family, which adapts its shape to match complex\nposterior distributions. The VGP generates approximate posterior samples by\ngenerating latent inputs and warping them through random non-linear mappings;\nthe distribution over random mappings is learned during inference, enabling the\ntransformed outputs to adapt to varying complexity. We prove a universal\napproximation theorem for the VGP, demonstrating its representative power for\nlearning any model. For inference we present a variational objective inspired\nby auto-encoders and perform black box inference over a wide class of models.\nThe VGP achieves new state-of-the-art results for unsupervised learning,\ninferring models such as the deep latent Gaussian model and the recently\nproposed DRAW.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 06:01:23 GMT"}, {"version": "v2", "created": "Fri, 4 Mar 2016 20:56:01 GMT"}, {"version": "v3", "created": "Wed, 23 Mar 2016 23:11:38 GMT"}, {"version": "v4", "created": "Sun, 17 Apr 2016 22:14:13 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Tran", "Dustin", ""], ["Ranganath", "Rajesh", ""], ["Blei", "David M.", ""]]}, {"id": "1511.06522", "submitter": "Yan Zhang", "authors": "Yan Zhang, Mete Ozay, Xing Liu, Takayuki Okatani", "title": "Integrating Deep Features for Material Recognition", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for integration of features extracted using deep\nrepresentations of Convolutional Neural Networks (CNNs) each of which is\nlearned using a different image dataset of objects and materials for material\nrecognition. Given a set of representations of multiple pre-trained CNNs, we\nfirst compute activations of features using the representations on the images\nto select a set of samples which are best represented by the features. Then, we\nmeasure the uncertainty of the features by computing the entropy of class\ndistributions for each sample set. Finally, we compute the contribution of each\nfeature to representation of classes for feature selection and integration. We\nexamine the proposed method on three benchmark datasets for material\nrecognition. Experimental results show that the proposed method achieves\nstate-of-the-art performance by integrating deep features. Additionally, we\nintroduce a new material dataset called EFMD by extending Flickr Material\nDatabase (FMD). By the employment of the EFMD with transfer learning for\nupdating the learned CNN models, we achieve 84.0%+/-1.8% accuracy on the FMD\ndataset which is close to human performance that is 84.9%.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 08:31:00 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2015 14:21:28 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2015 13:39:24 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2016 14:36:36 GMT"}, {"version": "v5", "created": "Tue, 5 Apr 2016 09:18:49 GMT"}, {"version": "v6", "created": "Thu, 21 Apr 2016 10:19:56 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Zhang", "Yan", ""], ["Ozay", "Mete", ""], ["Liu", "Xing", ""], ["Okatani", "Takayuki", ""]]}, {"id": "1511.06530", "submitter": "Yong-Deok Kim", "authors": "Yong-Deok Kim, Eunhyeok Park, Sungjoo Yoo, Taelim Choi, Lu Yang,\n  Dongjun Shin", "title": "Compression of Deep Convolutional Neural Networks for Fast and Low Power\n  Mobile Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the latest high-end smartphone has powerful CPU and GPU, running\ndeeper convolutional neural networks (CNNs) for complex tasks such as ImageNet\nclassification on mobile devices is challenging. To deploy deep CNNs on mobile\ndevices, we present a simple and effective scheme to compress the entire CNN,\nwhich we call one-shot whole network compression. The proposed scheme consists\nof three steps: (1) rank selection with variational Bayesian matrix\nfactorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuning\nto recover accumulated loss of accuracy, and each step can be easily\nimplemented using publicly available tools. We demonstrate the effectiveness of\nthe proposed scheme by testing the performance of various compressed CNNs\n(AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significant\nreductions in model size, runtime, and energy consumption are obtained, at the\ncost of small loss in accuracy. In addition, we address the important\nimplementation level issue on 1?1 convolution, which is a key operation of\ninception module of GoogLeNet as well as CNNs compressed by our proposed\nscheme.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 09:20:08 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2016 11:52:12 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Kim", "Yong-Deok", ""], ["Park", "Eunhyeok", ""], ["Yoo", "Sungjoo", ""], ["Choi", "Taelim", ""], ["Yang", "Lu", ""], ["Shin", "Dongjun", ""]]}, {"id": "1511.06581", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Tom Schaul, Matteo Hessel, Hado van Hasselt, Marc Lanctot,\n  Nando de Freitas", "title": "Dueling Network Architectures for Deep Reinforcement Learning", "comments": "15 pages, 5 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there have been many successes of using deep representations\nin reinforcement learning. Still, many of these applications use conventional\narchitectures, such as convolutional networks, LSTMs, or auto-encoders. In this\npaper, we present a new neural network architecture for model-free\nreinforcement learning. Our dueling network represents two separate estimators:\none for the state value function and one for the state-dependent action\nadvantage function. The main benefit of this factoring is to generalize\nlearning across actions without imposing any change to the underlying\nreinforcement learning algorithm. Our results show that this architecture leads\nto better policy evaluation in the presence of many similar-valued actions.\nMoreover, the dueling architecture enables our RL agent to outperform the\nstate-of-the-art on the Atari 2600 domain.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 13:07:54 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 11:37:42 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2016 09:03:06 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Wang", "Ziyu", ""], ["Schaul", "Tom", ""], ["Hessel", "Matteo", ""], ["van Hasselt", "Hado", ""], ["Lanctot", "Marc", ""], ["de Freitas", "Nando", ""]]}, {"id": "1511.06603", "submitter": "Ghazal Zand", "authors": "Ghazal Zand, Mojtaba Taherkhani, Reza Safabakhsh", "title": "Exponential Natural Particle Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle Filter algorithm (PF) suffers from some problems such as the loss of\nparticle diversity, the need for large number of particles, and the costly\nselection of the importance density functions. In this paper, a novel\nExponential Natural Particle Filter (xNPF) is introduced to solve the above\nproblems. In this approach, a state transitional probability with the use of\nnatural gradient learning is proposed which balances exploration and\nexploitation more robustly. The results show that xNPF converges much closer to\nthe true target states than the other state of the art particle filter.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 14:08:33 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Zand", "Ghazal", ""], ["Taherkhani", "Mojtaba", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "1511.06606", "submitter": "Hristo Paskov", "authors": "Hristo S. Paskov, John C. Mitchell, Trevor J. Hastie", "title": "Data Representation and Compression Using Linear-Programming\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose `Dracula', a new framework for unsupervised feature selection from\nsequential data such as text. Dracula learns a dictionary of $n$-grams that\nefficiently compresses a given corpus and recursively compresses its own\ndictionary; in effect, Dracula is a `deep' extension of Compressive Feature\nLearning. It requires solving a binary linear program that may be relaxed to a\nlinear program. Both problems exhibit considerable structure, their solution\npaths are well behaved, and we identify parameters which control the depth and\ndiversity of the dictionary. We also discuss how to derive features from the\ncompressed documents and show that while certain unregularized linear models\nare invariant to the structure of the compressed dictionary, this structure may\nbe used to regularize learning. Experiments are presented that demonstrate the\nefficacy of Dracula's features.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 14:21:44 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 22:37:58 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2016 23:13:18 GMT"}, {"version": "v4", "created": "Mon, 2 May 2016 11:06:31 GMT"}, {"version": "v5", "created": "Tue, 3 May 2016 01:02:04 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Paskov", "Hristo S.", ""], ["Mitchell", "John C.", ""], ["Hastie", "Trevor J.", ""]]}, {"id": "1511.06644", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "C\\'esar Lincoln C. Mattos, Zhenwen Dai, Andreas Damianou, Jeremy\n  Forth, Guilherme A. Barreto, Neil D. Lawrence", "title": "Recurrent Gaussian Processes", "comments": "Published as a conference paper at ICLR 2016. 12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define Recurrent Gaussian Processes (RGP) models, a general family of\nBayesian nonparametric models with recurrent GP priors which are able to learn\ndynamical patterns from sequential data. Similar to Recurrent Neural Networks\n(RNNs), RGPs can have different formulations for their internal states,\ndistinct inference methods and be extended with deep structures. In such\ncontext, we propose a novel deep RGP model whose autoregressive states are\nlatent, thereby performing representation and dynamical learning\nsimultaneously. To fully exploit the Bayesian nature of the RGP model we\ndevelop the Recurrent Variational Bayes (REVARB) framework, which enables\nefficient inference and strong regularization through coherent propagation of\nuncertainty across the RGP layers and states. We also introduce a RGP extension\nwhere variational parameters are greatly reduced by being reparametrized\nthrough RNN-based sequential recognition models. We apply our model to the\ntasks of nonlinear system identification and human motion modeling. The\npromising obtained results indicate that our RGP model maintains its highly\nflexibility while being able to avoid overfitting and being applicable even\nwhen larger datasets are not available.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 15:37:24 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 10:39:07 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2016 12:15:13 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2016 18:03:50 GMT"}, {"version": "v5", "created": "Tue, 9 Feb 2016 12:39:07 GMT"}, {"version": "v6", "created": "Wed, 24 Feb 2016 20:01:19 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Mattos", "C\u00e9sar Lincoln C.", ""], ["Dai", "Zhenwen", ""], ["Damianou", "Andreas", ""], ["Forth", "Jeremy", ""], ["Barreto", "Guilherme A.", ""], ["Lawrence", "Neil D.", ""]]}, {"id": "1511.06653", "submitter": "F\\'elix G. Harvey", "authors": "F\\'elix G. Harvey, Julien Roy, David Kanaa, Christopher Pal", "title": "Recurrent Semi-supervised Classification and Constrained Adversarial\n  Generation with Motion Capture Data", "comments": "IVC Journal Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore recurrent encoder multi-decoder neural network architectures for\nsemi-supervised sequence classification and reconstruction. We find that the\nuse of multiple reconstruction modules helps models generalize in a\nclassification task when only a small amount of labeled data is available,\nwhich is often the case in practice. Such models provide useful high-level\nrepresentations of motions allowing clustering, searching and faster labeling\nof new sequences. We also propose a new, realistic partitioning of a\nwell-known, high quality motion-capture dataset for better evaluations. We\nfurther explore a novel formulation for future-predicting decoders based on\nconditional recurrent generative adversarial networks, for which we propose\nboth soft and hard constraints for transition generation derived from desired\nphysical properties of synthesized future movements and desired animation\ngoals. We find that using such constraints allow to stabilize the training of\nrecurrent adversarial architectures for animation generation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 15:47:55 GMT"}, {"version": "v2", "created": "Mon, 11 Apr 2016 01:03:26 GMT"}, {"version": "v3", "created": "Mon, 25 Jul 2016 18:13:00 GMT"}, {"version": "v4", "created": "Fri, 26 May 2017 18:31:48 GMT"}, {"version": "v5", "created": "Mon, 5 Jun 2017 13:54:26 GMT"}, {"version": "v6", "created": "Tue, 6 Jun 2017 12:54:48 GMT"}, {"version": "v7", "created": "Wed, 21 Feb 2018 15:04:43 GMT"}, {"version": "v8", "created": "Wed, 11 Jul 2018 12:25:55 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Harvey", "F\u00e9lix G.", ""], ["Roy", "Julien", ""], ["Kanaa", "David", ""], ["Pal", "Christopher", ""]]}, {"id": "1511.06660", "submitter": "Bjarke Felbo", "authors": "Bjarke Felbo, P{\\aa}l Sunds{\\o}y, Alex 'Sandy' Pentland, Sune Lehmann,\n  Yves-Alexandre de Montjoye", "title": "Modeling the Temporal Nature of Human Behavior for Demographics\n  Prediction", "comments": "Accepted at ECML 2017. A previous version of this paper was titled\n  'Using Deep Learning to Predict Demographics from Mobile Phone Metadata' and\n  was accepted at the ICLR 2016 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phone metadata is increasingly used for humanitarian purposes in\ndeveloping countries as traditional data is scarce. Basic demographic\ninformation is however often absent from mobile phone datasets, limiting the\noperational impact of the datasets. For these reasons, there has been a growing\ninterest in predicting demographic information from mobile phone metadata.\nPrevious work focused on creating increasingly advanced features to be modeled\nwith standard machine learning algorithms. We here instead model the raw mobile\nphone metadata directly using deep learning, exploiting the temporal nature of\nthe patterns in the data. From high-level assumptions we design a data\nrepresentation and convolutional network architecture for modeling patterns\nwithin a week. We then examine three strategies for aggregating patterns across\nweeks and show that our method reaches state-of-the-art accuracy on both age\nand gender prediction using only the temporal modality in mobile metadata. We\nfinally validate our method on low activity users and evaluate the modeling\nassumptions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 16:07:21 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2015 17:13:22 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2016 21:00:39 GMT"}, {"version": "v4", "created": "Sat, 13 Feb 2016 14:08:15 GMT"}, {"version": "v5", "created": "Wed, 15 Nov 2017 18:06:50 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Felbo", "Bjarke", ""], ["Sunds\u00f8y", "P\u00e5l", ""], ["Pentland", "Alex 'Sandy'", ""], ["Lehmann", "Sune", ""], ["de Montjoye", "Yves-Alexandre", ""]]}, {"id": "1511.06663", "submitter": "Cecilia Damon", "authors": "Luca Talenti, Margaux Luck, Anastasia Yartseva, Nicolas Argy, Sandrine\n  Houz\\'e and Cecilia Damon", "title": "L1 logistic regression as a feature selection step for training stable\n  classification trees for the prediction of severity criteria in imported\n  malaria", "comments": "18 pages, 10 figures, ICLR, computational science - Learning,\n  Imported Malaria, L1 logistic regression, Decision tree", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate classification methods using explanatory and predictive models\nare necessary for characterizing subgroups of patients according to their risk\nprofiles. Popular methods include logistic regression and classification trees\nwith performances that vary according to the nature and the characteristics of\nthe dataset. In the context of imported malaria, we aimed at classifying\nseverity criteria based on a heterogeneous patient population. We investigated\nthese approaches by implementing two different strategies: L1 logistic\nregression (L1LR) that models a single global solution and classification trees\nthat model multiple local solutions corresponding to discriminant subregions of\nthe feature space. For each strategy, we built a standard model, and a sparser\nversion of it. As an alternative to pruning, we explore a promising approach\nthat first constrains the tree model with an L1LR-based feature selection, an\napproach we called L1LR-Tree. The objective is to decrease its vulnerability to\nsmall data variations by removing variables corresponding to unstable local\nphenomena. Our study is twofold: i) from a methodological perspective comparing\nthe performances and the stability of the three previous methods, i.e L1LR,\nclassification trees and L1LR-Tree, for the classification of severe forms of\nimported malaria, and ii) from an applied perspective improving the actual\nclassification of severe forms of imported malaria by identifying more\npersonalized profiles predictive of several clinical criteria based on\nvariables dismissed for the clinical definition of the disease. The main\nmethodological results show that the combined method L1LR-Tree builds sparse\nand stable models that significantly predicts the different severity criteria\nand outperforms all the other methods in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 16:12:59 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Talenti", "Luca", ""], ["Luck", "Margaux", ""], ["Yartseva", "Anastasia", ""], ["Argy", "Nicolas", ""], ["Houz\u00e9", "Sandrine", ""], ["Damon", "Cecilia", ""]]}, {"id": "1511.06683", "submitter": "Maksim Lapin", "authors": "Maksim Lapin, Matthias Hein and Bernt Schiele", "title": "Top-k Multiclass SVM", "comments": "NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class ambiguity is typical in image classification problems with a large\nnumber of classes. When classes are difficult to discriminate, it makes sense\nto allow k guesses and evaluate classifiers based on the top-k error instead of\nthe standard zero-one loss. We propose top-k multiclass SVM as a direct method\nto optimize for top-k performance. Our generalization of the well-known\nmulticlass SVM is based on a tight convex upper bound of the top-k error. We\npropose a fast optimization scheme based on an efficient projection onto the\ntop-k simplex, which is of its own interest. Experiments on five datasets show\nconsistent improvements in top-k accuracy compared to various baselines.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 16:49:33 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Lapin", "Maksim", ""], ["Hein", "Matthias", ""], ["Schiele", "Bernt", ""]]}, {"id": "1511.06718", "submitter": "Cyril Stark", "authors": "Cyril Stark", "title": "Top-N recommendations from expressive recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalized nonnegative models assign probability distributions to users and\nrandom variables to items; see [Stark, 2015]. Rating an item is regarded as\nsampling the random variable assigned to the item with respect to the\ndistribution assigned to the user who rates the item. Models of that kind are\nhighly expressive. For instance, using normalized nonnegative models we can\nunderstand users' preferences as mixtures of interpretable user stereotypes,\nand we can arrange properties of users and items in a hierarchical manner.\nThese features would not be useful if the predictive power of normalized\nnonnegative models was poor. Thus, we analyze here the performance of\nnormalized nonnegative models for top-N recommendation and observe that their\nperformance matches the performance of methods like PureSVD which was\nintroduced in [Cremonesi et al., 2010]. We conclude that normalized nonnegative\nmodels not only provide accurate recommendations but they also deliver (for\nfree) representations that are interpretable. We deepen the discussion of\nnormalized nonnegative models by providing further theoretical insights. In\nparticular, we introduce total variational distance as an operational\nsimilarity measure, we discover scenarios where normalized nonnegative models\nyield unique representations of users and items, we prove that the inference of\noptimal normalized nonnegative models is NP-hard and finally, we discuss the\nrelationship between normalized nonnegative models and nonnegative matrix\nfactorization.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 18:18:45 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Stark", "Cyril", ""]]}, {"id": "1511.06727", "submitter": "Jelena Luketina", "authors": "Jelena Luketina, Mathias Berglund, Klaus Greff, Tapani Raiko", "title": "Scalable Gradient-Based Tuning of Continuous Regularization\n  Hyperparameters", "comments": "9 pages, 7 figures. Accepted at ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter selection generally relies on running multiple full training\ntrials, with selection based on validation set performance. We propose a\ngradient-based approach for locally adjusting hyperparameters during training\nof the model. Hyperparameters are adjusted so as to make the model parameter\ngradients, and hence updates, more advantageous for the validation cost. We\nexplore the approach for tuning regularization hyperparameters and find that in\nexperiments on MNIST, SVHN and CIFAR-10, the resulting regularization levels\nare within the optimal regions. The additional computational cost depends on\nhow frequently the hyperparameters are trained, but the tested scheme adds only\n30% computational overhead regardless of the model size. Since the method is\nsignificantly less computationally demanding compared to similar gradient-based\napproaches to hyperparameter optimization, and consistently finds good\nhyperparameter values, it can be a useful tool for training neural network\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 19:10:16 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2015 06:28:07 GMT"}, {"version": "v3", "created": "Fri, 17 Jun 2016 19:25:32 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Luketina", "Jelena", ""], ["Berglund", "Mathias", ""], ["Greff", "Klaus", ""], ["Raiko", "Tapani", ""]]}, {"id": "1511.06728", "submitter": "Natalia Neverova", "authors": "Natalia Neverova, Christian Wolf, Florian Nebout, Graham Taylor", "title": "Hand Pose Estimation through Semi-Supervised and Weakly-Supervised\n  Learning", "comments": "13 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for hand pose estimation based on a deep regressor\ntrained on two different kinds of input. Raw depth data is fused with an\nintermediate representation in the form of a segmentation of the hand into\nparts. This intermediate representation contains important topological\ninformation and provides useful cues for reasoning about joint locations. The\nmapping from raw depth to segmentation maps is learned in a\nsemi/weakly-supervised way from two different datasets: (i) a synthetic dataset\ncreated through a rendering pipeline including densely labeled ground truth\n(pixelwise segmentations); and (ii) a dataset with real images for which ground\ntruth joint positions are available, but not dense segmentations. Loss for\ntraining on real images is generated from a patch-wise restoration process,\nwhich aligns tentative segmentation maps with a large dictionary of synthetic\nposes. The underlying premise is that the domain shift between synthetic and\nreal data is smaller in the intermediate representation, where labels carry\ngeometric and topological meaning, than in the raw input domain. Experiments on\nthe NYU dataset show that the proposed training method decreases error on\njoints over direct regression of joints from depth data by 15.7%.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 19:19:00 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 13:31:05 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2016 06:08:54 GMT"}, {"version": "v4", "created": "Fri, 15 Sep 2017 09:24:57 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Neverova", "Natalia", ""], ["Wolf", "Christian", ""], ["Nebout", "Florian", ""], ["Taylor", "Graham", ""]]}, {"id": "1511.06732", "submitter": "Marc'Aurelio Ranzato", "authors": "Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, Wojciech Zaremba", "title": "Sequence Level Training with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural language processing applications use language models to generate\ntext. These models are typically trained to predict the next word in a\nsequence, given the previous words and some context such as an image. However,\nat test time the model is expected to generate the entire sequence from\nscratch. This discrepancy makes generation brittle, as errors may accumulate\nalong the way. We address this issue by proposing a novel sequence level\ntraining algorithm that directly optimizes the metric used at test time, such\nas BLEU or ROUGE. On three different tasks, our approach outperforms several\nstrong baselines for greedy generation. The method is also competitive when\nthese baselines employ beam search, while being several times faster.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 19:25:54 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2015 16:11:27 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2015 16:51:31 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2016 06:24:58 GMT"}, {"version": "v5", "created": "Fri, 12 Feb 2016 16:05:32 GMT"}, {"version": "v6", "created": "Wed, 4 May 2016 13:43:39 GMT"}, {"version": "v7", "created": "Fri, 6 May 2016 21:18:46 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Ranzato", "Marc'Aurelio", ""], ["Chopra", "Sumit", ""], ["Auli", "Michael", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1511.06744", "submitter": "Yani Ioannou", "authors": "Yani Ioannou, Duncan Robertson, Jamie Shotton, Roberto Cipolla,\n  Antonio Criminisi", "title": "Training CNNs with Low-Rank Filters for Efficient Image Classification", "comments": "Published as a conference paper at ICLR 2016. v3: updated ICLR\n  status. v2: Incorporated reviewer's feedback including: Amend Fig. 2 and 5\n  descriptions to explain that there are no ReLUs within the figures. Fix\n  headings of Table 5 - Fix typo in the sentence at bottom of page 6. Add ref.\n  to Predicting Parameters in Deep Learning. Fix Table 6, GMP-LR and GMP-LR-2x\n  had incorrect numbers of filters", "journal-ref": "International Conference on Learning Representations (ICLR), San\n  Juan, Puerto Rico, 2-4 May 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for creating computationally efficient convolutional\nneural networks (CNNs) by using low-rank representations of convolutional\nfilters. Rather than approximating filters in previously-trained networks with\nmore efficient versions, we learn a set of small basis filters from scratch;\nduring training, the network learns to combine these basis filters into more\ncomplex filters that are discriminative for image classification. To train such\nnetworks, a novel weight initialization scheme is used. This allows effective\ninitialization of connection weights in convolutional layers composed of groups\nof differently-shaped filters. We validate our approach by applying it to\nseveral existing CNN architectures and training these networks from scratch\nusing the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or\nhigher accuracy than conventional CNNs with much less compute. Applying our\nmethod to an improved version of VGG-11 network using global max-pooling, we\nachieve comparable validation accuracy using 41% less compute and only 24% of\nthe original VGG-11 model parameters; another variant of our method gives a 1\npercentage point increase in accuracy over our improved VGG-11 model, giving a\ntop-5 center-crop validation accuracy of 89.7% while reducing computation by\n16% relative to the original VGG-11 model. Applying our method to the GoogLeNet\narchitecture for ILSVRC, we achieved comparable accuracy with 26% less compute\nand 41% fewer model parameters. Applying our method to a near state-of-the-art\nnetwork for CIFAR, we achieved comparable accuracy with 46% less compute and\n55% fewer parameters.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 20:14:28 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2016 17:07:02 GMT"}, {"version": "v3", "created": "Sun, 7 Feb 2016 21:23:19 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Ioannou", "Yani", ""], ["Robertson", "Duncan", ""], ["Shotton", "Jamie", ""], ["Cipolla", "Roberto", ""], ["Criminisi", "Antonio", ""]]}, {"id": "1511.06746", "submitter": "Kamelia Aryafar", "authors": "Corey Lynch, Kamelia Aryafar, Josh Attenberg", "title": "Images Don't Lie: Transferring Deep Visual Semantic Features to\n  Large-Scale Multimodal Learning to Rank", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search is at the heart of modern e-commerce. As a result, the task of ranking\nsearch results automatically (learning to rank) is a multibillion dollar\nmachine learning problem. Traditional models optimize over a few\nhand-constructed features based on the item's text. In this paper, we introduce\na multimodal learning to rank model that combines these traditional features\nwith visual semantic features transferred from a deep convolutional neural\nnetwork. In a large scale experiment using data from the online marketplace\nEtsy, we verify that moving to a multimodal representation significantly\nimproves ranking quality. We show how image features can capture fine-grained\nstyle information not available in a text-only representation. In addition, we\nshow concrete examples of how image information can successfully disentangle\npairs of highly different items that are ranked similarly by a text-only model.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 20:26:26 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Lynch", "Corey", ""], ["Aryafar", "Kamelia", ""], ["Attenberg", "Josh", ""]]}, {"id": "1511.06747", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Ryota Tomioka, Ruslan Salakhutdinov, Nathan Srebro", "title": "Data-Dependent Path Normalization in Neural Networks", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified framework for neural net normalization, regularization\nand optimization, which includes Path-SGD and Batch-Normalization and\ninterpolates between them across two different dimensions. Through this\nframework we investigate issue of invariance of the optimization, data\ndependence and the connection with natural gradients.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 20:27:45 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2015 20:52:51 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 20:13:03 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2016 20:57:47 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Tomioka", "Ryota", ""], ["Salakhutdinov", "Ruslan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1511.06807", "submitter": "Arvind Neelakantan", "authors": "Arvind Neelakantan, Luke Vilnis, Quoc V. Le, Ilya Sutskever, Lukasz\n  Kaiser, Karol Kurach, James Martens", "title": "Adding Gradient Noise Improves Learning for Very Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep feedforward and recurrent networks have achieved impressive results in\nmany perception and language processing applications. This success is partially\nattributed to architectural innovations such as convolutional and long\nshort-term memory networks. The main motivation for these architectural\ninnovations is that they capture better domain knowledge, and importantly are\neasier to optimize than more basic architectures. Recently, more complex\narchitectures such as Neural Turing Machines and Memory Networks have been\nproposed for tasks including question answering and general computation,\ncreating a new set of optimization challenges. In this paper, we discuss a\nlow-overhead and easy-to-implement technique of adding gradient noise which we\nfind to be surprisingly effective when training these very deep architectures.\nThe technique not only helps to avoid overfitting, but also can result in lower\ntraining loss. This method alone allows a fully-connected 20-layer deep network\nto be trained with standard gradient descent, even starting from a poor\ninitialization. We see consistent improvements for many complex models,\nincluding a 72% relative reduction in error rate over a carefully-tuned\nbaseline on a challenging question-answering task, and a doubling of the number\nof accurate binary multiplication models learned across 7,000 random restarts.\nWe encourage further application of this technique to additional complex modern\narchitectures.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 01:11:29 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Neelakantan", "Arvind", ""], ["Vilnis", "Luke", ""], ["Le", "Quoc V.", ""], ["Sutskever", "Ilya", ""], ["Kaiser", "Lukasz", ""], ["Kurach", "Karol", ""], ["Martens", "James", ""]]}, {"id": "1511.06811", "submitter": "Phillip Isola", "authors": "Phillip Isola, Daniel Zoran, Dilip Krishnan, Edward H. Adelson", "title": "Learning visual groups from co-occurrences in space and time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a self-supervised framework that learns to group visual entities\nbased on their rate of co-occurrence in space and time. To model statistical\ndependencies between the entities, we set up a simple binary classification\nproblem in which the goal is to predict if two visual primitives occur in the\nsame spatial or temporal context. We apply this framework to three domains:\nlearning patch affinities from spatial adjacency in images, learning frame\naffinities from temporal adjacency in videos, and learning photo affinities\nfrom geospatial proximity in image collections. We demonstrate that in each\ncase the learned affinities uncover meaningful semantic groupings. From patch\naffinities we generate object proposals that are competitive with\nstate-of-the-art supervised methods. From frame affinities we generate movie\nscene segmentations that correlate well with DVD chapter structure. Finally,\nfrom geospatial affinities we learn groups that relate well to semantic place\ncategories.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 01:33:12 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Isola", "Phillip", ""], ["Zoran", "Daniel", ""], ["Krishnan", "Dilip", ""], ["Adelson", "Edward H.", ""]]}, {"id": "1511.06827", "submitter": "Diogo Almeida", "authors": "Diogo Almeida, Nate Sauder", "title": "GradNets: Dynamic Interpolation Between Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, there is a fundamental trade-off between ease of\noptimization and expressive power. Neural Networks, in particular, have\nenormous expressive power and yet are notoriously challenging to train. The\nnature of that optimization challenge changes over the course of learning.\nTraditionally in deep learning, one makes a static trade-off between the needs\nof early and late optimization. In this paper, we investigate a novel\nframework, GradNets, for dynamically adapting architectures during training to\nget the benefits of both. For example, we can gradually transition from linear\nto non-linear networks, deterministic to stochastic computation, shallow to\ndeep architectures, or even simple downsampling to fully differentiable\nattention mechanisms. Benefits include increased accuracy, easier convergence\nwith more complex architectures, solutions to test-time execution of batch\nnormalization, and the ability to train networks of up to 200 layers.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 03:50:49 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Almeida", "Diogo", ""], ["Sauder", "Nate", ""]]}, {"id": "1511.06841", "submitter": "Kyuyeon Hwang", "authors": "Kyuyeon Hwang, Wonyong Sung", "title": "Online Sequence Training of Recurrent Neural Networks with Connectionist\n  Temporal Classification", "comments": "Final version: Kyuyeon Hwang and Wonyong Sung, \"Sequence to Sequence\n  Training of CTC-RNNs with Partial Windowing,\" Proceedings of The 33rd\n  International Conference on Machine Learning, pp. 2178-2187, 2016. URL:\n  http://www.jmlr.org/proceedings/papers/v48/hwanga16.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist temporal classification (CTC) based supervised sequence\ntraining of recurrent neural networks (RNNs) has shown great success in many\nmachine learning areas including end-to-end speech and handwritten character\nrecognition. For the CTC training, however, it is required to unroll (or\nunfold) the RNN by the length of an input sequence. This unrolling requires a\nlot of memory and hinders a small footprint implementation of online learning\nor adaptation. Furthermore, the length of training sequences is usually not\nuniform, which makes parallel training with multiple sequences inefficient on\nshared memory models such as graphics processing units (GPUs). In this work, we\nintroduce an expectation-maximization (EM) based online CTC algorithm that\nenables unidirectional RNNs to learn sequences that are longer than the amount\nof unrolling. The RNNs can also be trained to process an infinitely long input\nsequence without pre-segmentation or external reset. Moreover, the proposed\napproach allows efficient parallel training on GPUs. For evaluation, phoneme\nrecognition and end-to-end speech recognition examples are presented on the\nTIMIT and Wall Street Journal (WSJ) corpora, respectively. Our online model\nachieves 20.7% phoneme error rate (PER) on the very long input sequence that is\ngenerated by concatenating all 192 utterances in the TIMIT core test set. On\nWSJ, a network can be trained with only 64 times of unrolling while sacrificing\n4.5% relative word error rate (WER).\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 05:22:37 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2015 19:10:36 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2015 12:09:14 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 20:52:42 GMT"}, {"version": "v5", "created": "Thu, 2 Feb 2017 13:42:49 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Hwang", "Kyuyeon", ""], ["Sung", "Wonyong", ""]]}, {"id": "1511.06855", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Zhishuai Zhang, Cihang Xie, Vittal Premachandran, Alan\n  Yuille", "title": "Unsupervised learning of object semantic parts from internal states of\n  CNNs by population encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the key question of how object part representations can be found\nfrom the internal states of CNNs that are trained for high-level tasks, such as\nobject classification. This work provides a new unsupervised method to learn\nsemantic parts and gives new understanding of the internal representations of\nCNNs. Our technique is based on the hypothesis that semantic parts are\nrepresented by populations of neurons rather than by single filters. We propose\na clustering technique to extract part representations, which we call Visual\nConcepts. We show that visual concepts are semantically coherent in that they\nrepresent semantic parts, and visually coherent in that corresponding image\npatches appear very similar. Also, visual concepts provide full spatial\ncoverage of the parts of an object, rather than a few sparse parts as is\ntypically found in keypoint annotations. Furthermore, We treat single visual\nconcept as part detector and evaluate it for keypoint detection using the\nPASCAL3D+ dataset and for part detection using our newly annotated ImageNetPart\ndataset. The experiments demonstrate that visual concepts can be used to detect\nparts. We also show that some visual concepts respond to several semantic\nparts, provided these parts are visually similar. Thus visual concepts have the\nessential properties: semantic meaning and detection capability. Note that our\nImageNetPart dataset gives rich part annotations which cover the whole object,\nmaking it useful for other part-related applications.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 09:02:21 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 22:10:52 GMT"}, {"version": "v3", "created": "Sat, 12 Nov 2016 13:37:07 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Wang", "Jianyu", ""], ["Zhang", "Zhishuai", ""], ["Xie", "Cihang", ""], ["Premachandran", "Vittal", ""], ["Yuille", "Alan", ""]]}, {"id": "1511.06856", "submitter": "Philipp Kr\\\"ahenb\\\"uhl", "authors": "Philipp Kr\\\"ahenb\\\"uhl, Carl Doersch, Jeff Donahue, Trevor Darrell", "title": "Data-dependent Initializations of Convolutional Neural Networks", "comments": "ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks spread through computer vision like a wildfire,\nimpacting almost all visual tasks imaginable. Despite this, few researchers\ndare to train their models from scratch. Most work builds on one of a handful\nof ImageNet pre-trained models, and fine-tunes or adapts these for specific\ntasks. This is in large part due to the difficulty of properly initializing\nthese networks from scratch. A small miscalibration of the initial weights\nleads to vanishing or exploding gradients, as well as poor convergence\nproperties. In this work we present a fast and simple data-dependent\ninitialization procedure, that sets the weights of a network such that all\nunits in the network train at roughly the same rate, avoiding vanishing or\nexploding gradients. Our initialization matches the current state-of-the-art\nunsupervised or self-supervised pre-training methods on standard computer\nvision tasks, such as image classification and object detection, while being\nroughly three orders of magnitude faster. When combined with pre-training\nmethods, our initialization significantly outperforms prior work, narrowing the\ngap between supervised and unsupervised pre-training.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 09:07:08 GMT"}, {"version": "v2", "created": "Fri, 29 Apr 2016 03:36:16 GMT"}, {"version": "v3", "created": "Thu, 22 Sep 2016 22:14:17 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Doersch", "Carl", ""], ["Donahue", "Jeff", ""], ["Darrell", "Trevor", ""]]}, {"id": "1511.06881", "submitter": "Fangting Xia", "authors": "Fangting Xia, Peng Wang, Liang-Chieh Chen, Alan L. Yuille", "title": "Zoom Better to See Clearer: Human and Object Parsing with Hierarchical\n  Auto-Zoom Net", "comments": "A shortened version has been submitted to ECCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parsing articulated objects, e.g. humans and animals, into semantic parts\n(e.g. body, head and arms, etc.) from natural images is a challenging and\nfundamental problem for computer vision. A big difficulty is the large\nvariability of scale and location for objects and their corresponding parts.\nEven limited mistakes in estimating scale and location will degrade the parsing\noutput and cause errors in boundary details. To tackle these difficulties, we\npropose a \"Hierarchical Auto-Zoom Net\" (HAZN) for object part parsing which\nadapts to the local scales of objects and parts. HAZN is a sequence of two\n\"Auto-Zoom Net\" (AZNs), each employing fully convolutional networks that\nperform two tasks: (1) predict the locations and scales of object instances\n(the first AZN) or their parts (the second AZN); (2) estimate the part scores\nfor predicted object instance or part regions. Our model can adaptively \"zoom\"\n(resize) predicted image regions into their proper scales to refine the\nparsing.\n  We conduct extensive experiments over the PASCAL part datasets on humans,\nhorses, and cows. For humans, our approach significantly outperforms the\nstate-of-the-arts by 5% mIOU and is especially better at segmenting small\ninstances and small parts. We obtain similar improvements for parsing cows and\nhorses over alternative methods. In summary, our strategy of first zooming into\nobjects and then zooming into parts is very effective. It also enables us to\nprocess different regions of the image at different scales adaptively so that,\nfor example, we do not need to waste computational resources scaling the entire\nimage.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 13:32:26 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 00:39:14 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2015 02:32:33 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 23:48:34 GMT"}, {"version": "v5", "created": "Mon, 28 Mar 2016 21:53:31 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Xia", "Fangting", ""], ["Wang", "Peng", ""], ["Chen", "Liang-Chieh", ""], ["Yuille", "Alan L.", ""]]}, {"id": "1511.06890", "submitter": "Kian Hsiang Low", "authors": "Chun Kai Ling, Kian Hsiang Low, Patrick Jaillet", "title": "Gaussian Process Planning with Lipschitz Continuous Reward Functions:\n  Towards Unifying Bayesian Optimization, Active Learning, and Beyond", "comments": "30th AAAI Conference on Artificial Intelligence (AAAI 2016), Extended\n  version with proofs, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel nonmyopic adaptive Gaussian process planning\n(GPP) framework endowed with a general class of Lipschitz continuous reward\nfunctions that can unify some active learning/sensing and Bayesian optimization\ncriteria and offer practitioners some flexibility to specify their desired\nchoices for defining new tasks/problems. In particular, it utilizes a\nprincipled Bayesian sequential decision problem framework for jointly and\nnaturally optimizing the exploration-exploitation trade-off. In general, the\nresulting induced GPP policy cannot be derived exactly due to an uncountable\nset of candidate observations. A key contribution of our work here thus lies in\nexploiting the Lipschitz continuity of the reward functions to solve for a\nnonmyopic adaptive epsilon-optimal GPP (epsilon-GPP) policy. To plan in real\ntime, we further propose an asymptotically optimal, branch-and-bound anytime\nvariant of epsilon-GPP with performance guarantee. We empirically demonstrate\nthe effectiveness of our epsilon-GPP policy and its anytime variant in Bayesian\noptimization and an energy harvesting task.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 14:57:48 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Ling", "Chun Kai", ""], ["Low", "Kian Hsiang", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1511.06891", "submitter": "Kian Hsiang Low", "authors": "Yehong Zhang, Trong Nghia Hoang, Kian Hsiang Low, Mohan Kankanhalli", "title": "Near-Optimal Active Learning of Multi-Output Gaussian Processes", "comments": "30th AAAI Conference on Artificial Intelligence (AAAI 2016), Extended\n  version with proofs, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of active learning of a multi-output\nGaussian process (MOGP) model representing multiple types of coexisting\ncorrelated environmental phenomena. In contrast to existing works, our active\nlearning problem involves selecting not just the most informative sampling\nlocations to be observed but also the types of measurements at each selected\nlocation for minimizing the predictive uncertainty (i.e., posterior joint\nentropy) of a target phenomenon of interest given a sampling budget.\nUnfortunately, such an entropy criterion scales poorly in the numbers of\ncandidate sampling locations and selected observations when optimized. To\nresolve this issue, we first exploit a structure common to sparse MOGP models\nfor deriving a novel active learning criterion. Then, we exploit a relaxed form\nof submodularity property of our new criterion for devising a polynomial-time\napproximation algorithm that guarantees a constant-factor approximation of that\nachieved by the optimal set of selected observations. Empirical evaluation on\nreal-world datasets shows that our proposed approach outperforms existing\nalgorithms for active learning of MOGP and single-output GP models.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 15:08:53 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 08:45:36 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Zhang", "Yehong", ""], ["Hoang", "Trong Nghia", ""], ["Low", "Kian Hsiang", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1511.06909", "submitter": "Shihao Ji", "authors": "Shihao Ji, S. V. N. Vishwanathan, Nadathur Satish, Michael J. Anderson\n  and Pradeep Dubey", "title": "BlackOut: Speeding up Recurrent Neural Network Language Models With Very\n  Large Vocabularies", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose BlackOut, an approximation algorithm to efficiently train massive\nrecurrent neural network language models (RNNLMs) with million word\nvocabularies. BlackOut is motivated by using a discriminative loss, and we\ndescribe a new sampling strategy which significantly reduces computation while\nimproving stability, sample efficiency, and rate of convergence. One way to\nunderstand BlackOut is to view it as an extension of the DropOut strategy to\nthe output layer, wherein we use a discriminative training loss and a weighted\nsampling scheme. We also establish close connections between BlackOut,\nimportance sampling, and noise contrastive estimation (NCE). Our experiments,\non the recently released one billion word language modeling benchmark,\ndemonstrate scalability and accuracy of BlackOut; we outperform the\nstate-of-the art, and achieve the lowest perplexity scores on this dataset.\nMoreover, unlike other established methods which typically require GPUs or CPU\nclusters, we show that a carefully implemented version of BlackOut requires\nonly 1-10 days on a single machine to train a RNNLM with a million word\nvocabulary and billions of parameters on one billion words. Although we\ndescribe BlackOut in the context of RNNLM training, it can be used to any\nnetworks with large softmax output layers.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 17:49:30 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 07:09:16 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2015 06:08:54 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2015 04:40:55 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2016 21:57:56 GMT"}, {"version": "v6", "created": "Sun, 21 Feb 2016 16:40:26 GMT"}, {"version": "v7", "created": "Thu, 31 Mar 2016 17:37:25 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Ji", "Shihao", ""], ["Vishwanathan", "S. V. N.", ""], ["Satish", "Nadathur", ""], ["Anderson", "Michael J.", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1511.06910", "submitter": "Noura AlNuaimi", "authors": "Noura AlNuaimi, Mohammad M Masud and Farhan Mohammed", "title": "ICU Patient Deterioration prediction: a Data-Mining Approach", "comments": "16 pages, 3 figures, 10 tables, confeence", "journal-ref": null, "doi": "10.5121/csit.2015.51517", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A huge amount of medical data is generated every day, which presents a\nchallenge in analysing these data. The obvious solution to this challenge is to\nreduce the amount of data without information loss. Dimension reduction is\nconsidered the most popular approach for reducing data size and also to reduce\nnoise and redundancies in data. In this paper, we investigate the effect of\nfeature selection in improving the prediction of patient deterioration in ICUs.\nWe consider lab tests as features. Thus, choosing a subset of features would\nmean choosing the most important lab tests to perform. If the number of tests\ncan be reduced by identifying the most important tests, then we could also\nidentify the redundant tests. By omitting the redundant tests, observation time\ncould be reduced and early treatment could be provided to avoid the risk.\nAdditionally, unnecessary monetary cost would be avoided. Our approach uses\nstate-ofthe- art feature selection for predicting ICU patient deterioration\nusing the medical lab results. We apply our technique on the publicly available\nMIMIC-II database and show the effectiveness of the feature selection. We also\nprovide a detailed analysis of the best features identified by our approach.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 17:50:20 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["AlNuaimi", "Noura", ""], ["Masud", "Mohammad M", ""], ["Mohammed", "Farhan", ""]]}, {"id": "1511.06931", "submitter": "Jason  Weston", "authors": "Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra,\n  Alexander Miller, Arthur Szlam, Jason Weston", "title": "Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-term goal of machine learning is to build intelligent conversational\nagents. One recent popular approach is to train end-to-end models on a large\namount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals\n& Le, 2015; Shang et al., 2015). However, this approach leaves many questions\nunanswered as an understanding of the precise successes and shortcomings of\neach model is hard to assess. A contrasting recent proposal are the bAbI tasks\n(Weston et al., 2015b) which are synthetic data that measure the ability of\nlearning machines at various reasoning tasks over toy language. Unfortunately,\nthose tests are very small and hence may encourage methods that do not scale.\nIn this work, we propose a suite of new tasks of a much larger scale that\nattempt to bridge the gap between the two regimes. Choosing the domain of\nmovies, we provide tasks that test the ability of models to answer factual\nquestions (utilizing OMDB), provide personalization (utilizing MovieLens),\ncarry short conversations about the two, and finally to perform on natural\ndialogs from Reddit. We provide a dataset covering 75k movie entities and with\n3.5M training examples. We present results of various models on these tasks,\nand evaluate their performance.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 22:26:49 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2015 09:31:59 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 04:51:54 GMT"}, {"version": "v4", "created": "Fri, 1 Apr 2016 06:22:44 GMT"}, {"version": "v5", "created": "Fri, 15 Apr 2016 20:22:13 GMT"}, {"version": "v6", "created": "Tue, 19 Apr 2016 15:30:29 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Dodge", "Jesse", ""], ["Gane", "Andreea", ""], ["Zhang", "Xiang", ""], ["Bordes", "Antoine", ""], ["Chopra", "Sumit", ""], ["Miller", "Alexander", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""]]}, {"id": "1511.06939", "submitter": "Bal\\'azs Hidasi", "authors": "Bal\\'azs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, Domonkos\n  Tikk", "title": "Session-based Recommendations with Recurrent Neural Networks", "comments": "Camera ready version (17th February, 2016) Affiliation update (29th\n  March, 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply recurrent neural networks (RNN) on a new domain, namely recommender\nsystems. Real-life recommender systems often face the problem of having to base\nrecommendations only on short session-based data (e.g. a small sportsware\nwebsite) instead of long user histories (as in the case of Netflix). In this\nsituation the frequently praised matrix factorization approaches are not\naccurate. This problem is usually overcome in practice by resorting to\nitem-to-item recommendations, i.e. recommending similar items. We argue that by\nmodeling the whole session, more accurate recommendations can be provided. We\ntherefore propose an RNN-based approach for session-based recommendations. Our\napproach also considers practical aspects of the task and introduces several\nmodifications to classic RNNs such as a ranking loss function that make it more\nviable for this specific problem. Experimental results on two data-sets show\nmarked improvements over widely used approaches.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 23:42:59 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 21:13:50 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2016 16:41:37 GMT"}, {"version": "v4", "created": "Tue, 29 Mar 2016 14:52:58 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Hidasi", "Bal\u00e1zs", ""], ["Karatzoglou", "Alexandros", ""], ["Baltrunas", "Linas", ""], ["Tikk", "Domonkos", ""]]}, {"id": "1511.06951", "submitter": "Leslie Smith", "authors": "Leslie N. Smith, Emily M. Hand, Timothy Doster", "title": "Gradual DropIn of Layers to Train Very Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of dynamically growing a neural network during\ntraining. In particular, an untrainable deep network starts as a trainable\nshallow network and newly added layers are slowly, organically added during\ntraining, thereby increasing the network's depth. This is accomplished by a new\nlayer, which we call DropIn. The DropIn layer starts by passing the output from\na previous layer (effectively skipping over the newly added layers), then\nincreasingly including units from the new layers for both feedforward and\nbackpropagation. We show that deep networks, which are untrainable with\nconventional methods, will converge with DropIn layers interspersed in the\narchitecture. In addition, we demonstrate that DropIn provides regularization\nduring training in an analogous way as dropout. Experiments are described with\nthe MNIST dataset and various expanded LeNet architectures, CIFAR-10 dataset\nwith its architecture expanded from 3 to 11 layers, and on the ImageNet dataset\nwith the AlexNet architecture expanded to 13 layers and the VGG 16-layer\narchitecture.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 02:33:08 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Smith", "Leslie N.", ""], ["Hand", "Emily M.", ""], ["Doster", "Timothy", ""]]}, {"id": "1511.06961", "submitter": "Lisa Lee", "authors": "Lisa Seung-Yeon Lee", "title": "On the Linear Algebraic Structure of Distributed Word Representations", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we leverage the linear algebraic structure of distributed word\nrepresentations to automatically extend knowledge bases and allow a machine to\nlearn new facts about the world. Our goal is to extract structured facts from\ncorpora in a simpler manner, without applying classifiers or patterns, and\nusing only the co-occurrence statistics of words. We demonstrate that the\nlinear algebraic structure of word embeddings can be used to reduce data\nrequirements for methods of learning facts. In particular, we demonstrate that\nwords belonging to a common category, or pairs of words satisfying a certain\nrelation, form a low-rank subspace in the projected space. We compute a basis\nfor this low-rank subspace using singular value decomposition (SVD), then use\nthis basis to discover new facts and to fit vectors for less frequent words\nwhich we do not yet have vectors for.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 04:28:39 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Lee", "Lisa Seung-Yeon", ""]]}, {"id": "1511.06964", "submitter": "Alexander Ororbia II", "authors": "Alexander G. Ororbia II, C. Lee Giles, David Reitter", "title": "Online Semi-Supervised Learning with Deep Hybrid Boltzmann Machines and\n  Denoising Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine and\nthe Deep Hybrid Denoising Auto-encoder, are proposed for handling\nsemi-supervised learning problems. The models combine experts that model\nrelevant distributions at different levels of abstraction to improve overall\npredictive performance on discriminative tasks. Theoretical motivations and\nalgorithms for joint learning for each are presented. We apply the new models\nto the domain of data-streams in work towards life-long learning. The proposed\narchitectures show improved performance compared to a pseudo-labeled, drop-out\nrectifier network.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 04:53:43 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 22:12:51 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2015 05:06:36 GMT"}, {"version": "v4", "created": "Sun, 13 Dec 2015 07:24:34 GMT"}, {"version": "v5", "created": "Thu, 7 Jan 2016 19:44:42 GMT"}, {"version": "v6", "created": "Fri, 8 Jan 2016 06:19:07 GMT"}, {"version": "v7", "created": "Mon, 18 Jan 2016 18:06:01 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Ororbia", "Alexander G.", "II"], ["Giles", "C. Lee", ""], ["Reitter", "David", ""]]}, {"id": "1511.06984", "submitter": "Serena Yeung", "authors": "Serena Yeung, Olga Russakovsky, Greg Mori, Li Fei-Fei", "title": "End-to-end Learning of Action Detection from Frame Glimpses in Videos", "comments": "Update to version in CVPR 2016 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a fully end-to-end approach for action detection in\nvideos that learns to directly predict the temporal bounds of actions. Our\nintuition is that the process of detecting actions is naturally one of\nobservation and refinement: observing moments in video, and refining hypotheses\nabout when an action is occurring. Based on this insight, we formulate our\nmodel as a recurrent neural network-based agent that interacts with a video\nover time. The agent observes video frames and decides both where to look next\nand when to emit a prediction. Since backpropagation is not adequate in this\nnon-differentiable setting, we use REINFORCE to learn the agent's decision\npolicy. Our model achieves state-of-the-art results on the THUMOS'14 and\nActivityNet datasets while observing only a fraction (2% or less) of the video\nframes.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 09:41:50 GMT"}, {"version": "v2", "created": "Mon, 13 Mar 2017 07:33:15 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Yeung", "Serena", ""], ["Russakovsky", "Olga", ""], ["Mori", "Greg", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1511.07023", "submitter": "Divya Kundra", "authors": "Prerna Juneja, Divya Kundra, Ashish Sureka", "title": "Anvaya: An Algorithm and Case-Study on Improving the Goodness of\n  Software Process Models generated by Mining Event-Log Data in Issue Tracking\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Issue Tracking Systems (ITS) such as Bugzilla can be viewed as Process Aware\nInformation Systems (PAIS) generating event-logs during the life-cycle of a bug\nreport. Process Mining consists of mining event logs generated from PAIS for\nprocess model discovery, conformance and enhancement. We apply process map\ndiscovery techniques to mine event trace data generated from ITS of open source\nFirefox browser project to generate and study process models. Bug life-cycle\nconsists of diversity and variance. Therefore, the process models generated\nfrom the event-logs are spaghetti-like with large number of edges,\ninter-connections and nodes. Such models are complex to analyse and difficult\nto comprehend by a process analyst. We improve the Goodness (fitness and\nstructural complexity) of the process models by splitting the event-log into\nhomogeneous subsets by clustering structurally similar traces. We adapt the\nK-Medoid clustering algorithm with two different distance metrics: Longest\nCommon Subsequence (LCS) and Dynamic Time Warping (DTW). We evaluate the\ngoodness of the process models generated from the clusters using complexity and\nfitness metrics. We study back-forth \\& self-loops, bug reopening, and\nbottleneck in the clusters obtained and show that clustering enables better\nanalysis. We also propose an algorithm to automate the clustering process -the\nalgorithm takes as input the event log and returns the best cluster set.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 15:43:29 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Juneja", "Prerna", ""], ["Kundra", "Divya", ""], ["Sureka", "Ashish", ""]]}, {"id": "1511.07035", "submitter": "Lex Fridman", "authors": "Irman Abdi\\'c, Lex Fridman, Erik Marchi, Daniel E Brown, William\n  Angell, Bryan Reimer, Bj\\\"orn Schuller", "title": "Detecting Road Surface Wetness from Audio: A Deep Learning Approach", "comments": "Under review in IEEE Signal Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a recurrent neural network architecture for automated road\nsurface wetness detection from audio of tire-surface interaction. The\nrobustness of our approach is evaluated on 785,826 bins of audio that span an\nextensive range of vehicle speeds, noises from the environment, road surface\ntypes, and pavement conditions including international roughness index (IRI)\nvalues from 25 in/mi to 1400 in/mi. The training and evaluation of the model\nare performed on different roads to minimize the impact of environmental and\nother external factors on the accuracy of the classification. We achieve an\nunweighted average recall (UAR) of 93.2% across all vehicle speeds including 0\nmph. The classifier still works at 0 mph because the discriminating signal is\npresent in the sound of other vehicles driving by.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 17:20:23 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2015 20:05:22 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Abdi\u0107", "Irman", ""], ["Fridman", "Lex", ""], ["Marchi", "Erik", ""], ["Brown", "Daniel E", ""], ["Angell", "William", ""], ["Reimer", "Bryan", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1511.07053", "submitter": "Francesco Visin", "authors": "Francesco Visin, Marco Ciccone, Adriana Romero, Kyle Kastner,\n  Kyunghyun Cho, Yoshua Bengio, Matteo Matteucci, Aaron Courville", "title": "ReSeg: A Recurrent Neural Network-based Model for Semantic Segmentation", "comments": "In CVPR Deep Vision Workshop, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a structured prediction architecture, which exploits the local\ngeneric features extracted by Convolutional Neural Networks and the capacity of\nRecurrent Neural Networks (RNN) to retrieve distant dependencies. The proposed\narchitecture, called ReSeg, is based on the recently introduced ReNet model for\nimage classification. We modify and extend it to perform the more challenging\ntask of semantic segmentation. Each ReNet layer is composed of four RNN that\nsweep the image horizontally and vertically in both directions, encoding\npatches or activations, and providing relevant global information. Moreover,\nReNet layers are stacked on top of pre-trained convolutional layers, benefiting\nfrom generic local features. Upsampling layers follow ReNet layers to recover\nthe original image resolution in the final predictions. The proposed ReSeg\narchitecture is efficient, flexible and suitable for a variety of semantic\nsegmentation tasks. We evaluate ReSeg on several widely-used semantic\nsegmentation datasets: Weizmann Horse, Oxford Flower, and CamVid; achieving\nstate-of-the-art performance. Results show that ReSeg can act as a suitable\narchitecture for semantic segmentation tasks, and may have further applications\nin other structured prediction problems. The source code and model\nhyperparameters are available on https://github.com/fvisin/reseg.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 19:25:27 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2016 14:41:56 GMT"}, {"version": "v3", "created": "Tue, 24 May 2016 15:55:41 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Visin", "Francesco", ""], ["Ciccone", "Marco", ""], ["Romero", "Adriana", ""], ["Kastner", "Kyle", ""], ["Cho", "Kyunghyun", ""], ["Bengio", "Yoshua", ""], ["Matteucci", "Matteo", ""], ["Courville", "Aaron", ""]]}, {"id": "1511.07085", "submitter": "Vladislav Malyshkin", "authors": "Vladislav Gennadievich Malyshkin", "title": "Multiple--Instance Learning: Christoffel Function Approach to\n  Distribution Regression Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A two--step Christoffel function based solution is proposed to distribution\nregression problem. On the first step, to model distribution of observations\ninside a bag, build Christoffel function for each bag of observations. Then, on\nthe second step, build outcome variable Christoffel function, but use the bag's\nChristoffel function value at given point as the weight for the bag's outcome.\nThe approach allows the result to be obtained in closed form and then to be\nevaluated numerically. While most of existing approaches minimize some kind an\nerror between outcome and prediction, the proposed approach is conceptually\ndifferent, because it uses Christoffel function for knowledge representation,\nwhat is conceptually equivalent working with probabilities only. To receive\npossible outcomes and their probabilities Gauss quadrature for second--step\nmeasure can be built, then the nodes give possible outcomes and normalized\nweights -- outcome probabilities. A library providing numerically stable\npolynomial basis for these calculations is available, what make the proposed\napproach practical.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 23:19:23 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Malyshkin", "Vladislav Gennadievich", ""]]}, {"id": "1511.07110", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Yuntian Deng, Eric Xing", "title": "On the Generalization Error Bounds of Neural Networks under\n  Diversity-Inducing Mutual Angular Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently diversity-inducing regularization methods for latent variable models\n(LVMs), which encourage the components in LVMs to be diverse, have been studied\nto address several issues involved in latent variable modeling: (1) how to\ncapture long-tail patterns underlying data; (2) how to reduce model complexity\nwithout sacrificing expressivity; (3) how to improve the interpretability of\nlearned patterns. While the effectiveness of diversity-inducing regularizers\nsuch as the mutual angular regularizer has been demonstrated empirically, a\nrigorous theoretical analysis of them is still missing. In this paper, we aim\nto bridge this gap and analyze how the mutual angular regularizer (MAR) affects\nthe generalization performance of supervised LVMs. We use neural network (NN)\nas a model instance to carry out the study and the analysis shows that\nincreasing the diversity of hidden units in NN would reduce estimation error\nand increase approximation error. In addition to theoretical analysis, we also\npresent empirical study which demonstrates that the MAR can greatly improve the\nperformance of NN and the empirical observations are in accordance with the\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 04:51:49 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Xie", "Pengtao", ""], ["Deng", "Yuntian", ""], ["Xing", "Eric", ""]]}, {"id": "1511.07118", "submitter": "Dong-Hyun Lee", "authors": "Dong-Hyun Lee", "title": "Cascading Denoising Auto-Encoder as a Deep Directed Generative Model", "comments": "not completed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work (Bengio et al., 2013) has shown howDenoising Auto-Encoders(DAE)\nbecome gener-ative models as a density estimator. However,in practice, the\nframework suffers from a mixingproblem in the MCMC sampling process and\nnodirect method to estimate the test log-likelihood.We consider a directed\nmodel with an stochas-tic identity mapping (simple corruption pro-cess) as an\ninference model and a DAE as agenerative model. By cascading these mod-els, we\npropose Cascading Denoising Auto-Encoders(CDAE) which can generate samples\nofdata distribution from tractable prior distributionunder the assumption that\nprobabilistic distribu-tion of corrupted data approaches tractable\npriordistribution as the level of corruption increases.This work tries to\nanswer two questions. On theone hand, can deep directed models be success-fully\ntrained without intractable posterior infer-ence and difficult optimization of\nvery deep neu-ral networks in inference and generative mod-els? These are\nunavoidable when recent suc-cessful directed model like VAE (Kingma &Welling,\n2014) is trained on complex dataset likereal images. On the other hand, can\nDAEs getclean samples of data distribution from heavilycorrupted samples which\ncan be considered oftractable prior distribution far from data mani-fold?\nso-called global denoising scheme.Our results show positive responses of\nthesequestions and this work can provide fairly simpleframework for generative\nmodels of very com-plex dataset.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 06:32:57 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2017 19:09:52 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Lee", "Dong-Hyun", ""]]}, {"id": "1511.07125", "submitter": "Patrick Gallagher", "authors": "Patrick W. Gallagher, Shuai Tang, Zhuowen Tu", "title": "What Happened to My Dog in That Network: Unraveling Top-down Generators\n  in Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Top-down information plays a central role in human perception, but plays\nrelatively little role in many current state-of-the-art deep networks, such as\nConvolutional Neural Networks (CNNs). This work seeks to explore a path by\nwhich top-down information can have a direct impact within current deep\nnetworks. We explore this path by learning and using \"generators\" corresponding\nto the network internal effects of three types of transformation (each a\nrestriction of a general affine transformation): rotation, scaling, and\ntranslation. We demonstrate how these learned generators can be used to\ntransfer top-down information to novel settings, as mediated by the \"feature\nflows\" that the transformations (and the associated generators) correspond to\ninside the network. Specifically, we explore three aspects: 1) using generators\nas part of a method for synthesizing transformed images --- given a previously\nunseen image, produce versions of that image corresponding to one or more\nspecified transformations, 2) \"zero-shot learning\" --- when provided with a\nfeature flow corresponding to the effect of a transformation of unknown amount,\nleverage learned generators as part of a method by which to perform an accurate\ncategorization of the amount of transformation, even for amounts never observed\nduring training, and 3) (inside-CNN) \"data augmentation\" --- improve the\nclassification performance of an existing network by using the learned\ngenerators to directly provide additional training \"inside the CNN\".\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 07:48:01 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Gallagher", "Patrick W.", ""], ["Tang", "Shuai", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1511.07130", "submitter": "Amar Shah", "authors": "Amar Shah, Zoubin Ghahramani", "title": "Parallel Predictive Entropy Search for Batch Global Optimization of\n  Expensive Objective Functions", "comments": "12 pages in Neural Information Processing Systems 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop parallel predictive entropy search (PPES), a novel algorithm for\nBayesian optimization of expensive black-box objective functions. At each\niteration, PPES aims to select a batch of points which will maximize the\ninformation gain about the global maximizer of the objective. Well known\nstrategies exist for suggesting a single evaluation point based on previous\nobservations, while far fewer are known for selecting batches of points to\nevaluate in parallel. The few batch selection schemes that have been studied\nall resort to greedy methods to compute an optimal batch. To the best of our\nknowledge, PPES is the first non-greedy batch Bayesian optimization strategy.\nWe demonstrate the benefit of this approach in optimization performance on both\nsynthetic and real world applications, including problems in machine learning,\nrocket science and robotics.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 08:21:17 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Shah", "Amar", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1511.07147", "submitter": "Rishi Gupta", "authors": "Rishi Gupta and Tim Roughgarden", "title": "A PAC Approach to Application-Specific Algorithm Selection", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best algorithm for a computational problem generally depends on the\n\"relevant inputs,\" a concept that depends on the application domain and often\ndefies formal articulation. While there is a large literature on empirical\napproaches to selecting the best algorithm for a given application domain,\nthere has been surprisingly little theoretical analysis of the problem.\n  This paper adapts concepts from statistical and online learning theory to\nreason about application-specific algorithm selection. Our models capture\nseveral state-of-the-art empirical and theoretical approaches to the problem,\nranging from self-improving algorithms to empirical performance models, and our\nresults identify conditions under which these approaches are guaranteed to\nperform well. We present one framework that models algorithm selection as a\nstatistical learning problem, and our work here shows that dimension notions\nfrom statistical learning theory, historically used to measure the complexity\nof classes of binary- and real-valued functions, are relevant in a much broader\nalgorithmic context. We also study the online version of the algorithm\nselection problem, and give possibility and impossibility results for the\nexistence of no-regret learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 09:30:19 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 21:06:20 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Gupta", "Rishi", ""], ["Roughgarden", "Tim", ""]]}, {"id": "1511.07211", "submitter": "Adish Singla", "authors": "Adish Singla, Sebastian Tschiatschek, Andreas Krause", "title": "Noisy Submodular Maximization via Adaptive Sampling with Applications to\n  Crowdsourced Image Collection Summarization", "comments": "Extended version of AAAI'16 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of maximizing an unknown submodular function that can\nonly be accessed via noisy evaluations. Our work is motivated by the task of\nsummarizing content, e.g., image collections, by leveraging users' feedback in\nform of clicks or ratings. For summarization tasks with the goal of maximizing\ncoverage and diversity, submodular set functions are a natural choice. When the\nunderlying submodular function is unknown, users' feedback can provide noisy\nevaluations of the function that we seek to maximize. We provide a generic\nalgorithm -- \\submM{} -- for maximizing an unknown submodular function under\ncardinality constraints. This algorithm makes use of a novel exploration module\n-- \\blbox{} -- that proposes good elements based on adaptively sampling noisy\nfunction evaluations. \\blbox{} is able to accommodate different kinds of\nobservation models such as value queries and pairwise comparisons. We provide\nPAC-style guarantees on the quality and sampling cost of the solution obtained\nby \\submM{}. We demonstrate the effectiveness of our approach in an\ninteractive, crowdsourced image collection summarization application.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 13:19:05 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 09:49:35 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Singla", "Adish", ""], ["Tschiatschek", "Sebastian", ""], ["Krause", "Andreas", ""]]}, {"id": "1511.07247", "submitter": "Relja Arandjelovi\\'c", "authors": "Relja Arandjelovi\\'c, Petr Gronat, Akihiko Torii, Tomas Pajdla, Josef\n  Sivic", "title": "NetVLAD: CNN architecture for weakly supervised place recognition", "comments": "Appears in: IEEE Computer Vision and Pattern Recognition (CVPR) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of large scale visual place recognition, where the task\nis to quickly and accurately recognize the location of a given query\nphotograph. We present the following three principal contributions. First, we\ndevelop a convolutional neural network (CNN) architecture that is trainable in\nan end-to-end manner directly for the place recognition task. The main\ncomponent of this architecture, NetVLAD, is a new generalized VLAD layer,\ninspired by the \"Vector of Locally Aggregated Descriptors\" image representation\ncommonly used in image retrieval. The layer is readily pluggable into any CNN\narchitecture and amenable to training via backpropagation. Second, we develop a\ntraining procedure, based on a new weakly supervised ranking loss, to learn\nparameters of the architecture in an end-to-end manner from images depicting\nthe same places over time downloaded from Google Street View Time Machine.\nFinally, we show that the proposed architecture significantly outperforms\nnon-learnt image representations and off-the-shelf CNN descriptors on two\nchallenging place recognition benchmarks, and improves over current\nstate-of-the-art compact image representations on standard image retrieval\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 14:51:51 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2016 17:19:39 GMT"}, {"version": "v3", "created": "Mon, 2 May 2016 15:42:41 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Arandjelovi\u0107", "Relja", ""], ["Gronat", "Petr", ""], ["Torii", "Akihiko", ""], ["Pajdla", "Tomas", ""], ["Sivic", "Josef", ""]]}, {"id": "1511.07263", "submitter": "Cameron Musco", "authors": "Michael B. Cohen, Cameron Musco, Christopher Musco", "title": "Input Sparsity Time Low-Rank Approximation via Ridge Leverage Score\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for finding a near optimal low-rank approximation\nof a matrix $A$ in $O(nnz(A))$ time. Our method is based on a recursive\nsampling scheme for computing a representative subset of $A$'s columns, which\nis then used to find a low-rank approximation.\n  This approach differs substantially from prior $O(nnz(A))$ time algorithms,\nwhich are all based on fast Johnson-Lindenstrauss random projections. It\nmatches the guarantees of these methods while offering a number of advantages.\n  Not only are sampling algorithms faster for sparse and structured data, but\nthey can also be applied in settings where random projections cannot. For\nexample, we give new single-pass streaming algorithms for the column subset\nselection and projection-cost preserving sample problems. Our method has also\nbeen used to give the fastest algorithms for provably approximating kernel\nmatrices [MM16].\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 15:10:05 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 22:48:49 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Cohen", "Michael B.", ""], ["Musco", "Cameron", ""], ["Musco", "Christopher", ""]]}, {"id": "1511.07275", "submitter": "Wojciech Zaremba", "authors": "Wojciech Zaremba, Tomas Mikolov, Armand Joulin, Rob Fergus", "title": "Learning Simple Algorithms from Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for learning simple algorithms such as copying,\nmulti-digit addition and single digit multiplication directly from examples.\nOur framework consists of a set of interfaces, accessed by a controller.\nTypical interfaces are 1-D tapes or 2-D grids that hold the input and output\ndata. For the controller, we explore a range of neural network-based models\nwhich vary in their ability to abstract the underlying algorithm from training\ninstances and generalize to test examples with many thousands of digits. The\ncontroller is trained using $Q$-learning with several enhancements and we show\nthat the bottleneck is in the capabilities of the controller rather than in the\nsearch incurred by $Q$-learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 15:31:54 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 03:28:35 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Zaremba", "Wojciech", ""], ["Mikolov", "Tomas", ""], ["Joulin", "Armand", ""], ["Fergus", "Rob", ""]]}, {"id": "1511.07289", "submitter": "Djork-Arn\\'e Clevert", "authors": "Djork-Arn\\'e Clevert, Thomas Unterthiner, Sepp Hochreiter", "title": "Fast and Accurate Deep Network Learning by Exponential Linear Units\n  (ELUs)", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \"exponential linear unit\" (ELU) which speeds up learning in\ndeep neural networks and leads to higher classification accuracies. Like\nrectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs\n(PReLUs), ELUs alleviate the vanishing gradient problem via the identity for\npositive values. However, ELUs have improved learning characteristics compared\nto the units with other activation functions. In contrast to ReLUs, ELUs have\nnegative values which allows them to push mean unit activations closer to zero\nlike batch normalization but with lower computational complexity. Mean shifts\ntoward zero speed up learning by bringing the normal gradient closer to the\nunit natural gradient because of a reduced bias shift effect. While LReLUs and\nPReLUs have negative values, too, they do not ensure a noise-robust\ndeactivation state. ELUs saturate to a negative value with smaller inputs and\nthereby decrease the forward propagated variation and information. Therefore,\nELUs code the degree of presence of particular phenomena in the input, while\nthey do not quantitatively model the degree of their absence. In experiments,\nELUs lead not only to faster learning, but also to significantly better\ngeneralization performance than ReLUs and LReLUs on networks with more than 5\nlayers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with\nbatch normalization while batch normalization does not improve ELU networks.\nELU networks are among the top 10 reported CIFAR-10 results and yield the best\npublished result on CIFAR-100, without resorting to multi-view evaluation or\nmodel averaging. On ImageNet, ELU networks considerably speed up learning\ncompared to a ReLU network with the same architecture, obtaining less than 10%\nclassification error for a single crop, single model network.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 15:58:05 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 16:19:05 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2016 17:55:53 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2016 17:29:21 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2016 07:02:58 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Clevert", "Djork-Arn\u00e9", ""], ["Unterthiner", "Thomas", ""], ["Hochreiter", "Sepp", ""]]}, {"id": "1511.07293", "submitter": "Zhaosong Lu", "authors": "Zhaosong Lu and Xiaorui Li", "title": "Sparse Recovery via Partial Regularization: Models, Theory and\n  Algorithms", "comments": "35 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of sparse recovery, it is known that most of existing\nregularizers such as $\\ell_1$ suffer from some bias incurred by some leading\nentries (in magnitude) of the associated vector. To neutralize this bias, we\npropose a class of models with partial regularizers for recovering a sparse\nsolution of a linear system. We show that every local minimizer of these models\nis sufficiently sparse or the magnitude of all its nonzero entries is above a\nuniform constant depending only on the data of the linear system. Moreover, for\na class of partial regularizers, any global minimizer of these models is a\nsparsest solution to the linear system. We also establish some sufficient\nconditions for local or global recovery of the sparsest solution to the linear\nsystem, among which one of the conditions is weaker than the best known\nrestricted isometry property (RIP) condition for sparse recovery by $\\ell_1$.\nIn addition, a first-order feasible augmented Lagrangian (FAL) method is\nproposed for solving these models, in which each subproblem is solved by a\nnonmonotone proximal gradient (NPG) method. Despite the complication of the\npartial regularizers, we show that each proximal subproblem in NPG can be\nsolved as a certain number of one-dimensional optimization problems, which\nusually have a closed-form solution. We also show that any accumulation point\nof the sequence generated by FAL is a first-order stationary point of the\nmodels. Numerical results on compressed sensing and sparse logistic regression\ndemonstrate that the proposed models substantially outperform the widely used\nones in the literature in terms of solution quality.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 16:08:24 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Lu", "Zhaosong", ""], ["Li", "Xiaorui", ""]]}, {"id": "1511.07340", "submitter": "Henry WJ Reeve", "authors": "Henry W J Reeve and Gavin Brown", "title": "Modular Autoencoders for Ensemble Feature Extraction", "comments": "18 pages, 8 figures, to appear in a special issue of The Journal Of\n  Machine Learning Research (vol.44, Dec 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of a Modular Autoencoder (MAE), capable of learning\na set of diverse but complementary representations from unlabelled data, that\ncan later be used for supervised tasks. The learning of the representations is\ncontrolled by a trade off parameter, and we show on six benchmark datasets the\noptimum lies between two extremes: a set of smaller, independent autoencoders\neach with low capacity, versus a single monolithic encoding, outperforming an\nappropriate baseline. In the present paper we explore the special case of\nlinear MAE, and derive an SVD-based algorithm which converges several orders of\nmagnitude faster than gradient descent.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 17:51:18 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Reeve", "Henry W J", ""], ["Brown", "Gavin", ""]]}, {"id": "1511.07361", "submitter": "Guolong Su", "authors": "Guolong Su, Dennis Wei, Kush R. Varshney, Dmitry M. Malioutov", "title": "Interpretable Two-level Boolean Rule Learning for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes algorithms for learning two-level Boolean rules in\nConjunctive Normal Form (CNF, i.e. AND-of-ORs) or Disjunctive Normal Form (DNF,\ni.e. OR-of-ANDs) as a type of human-interpretable classification model, aiming\nfor a favorable trade-off between the classification accuracy and the\nsimplicity of the rule. Two formulations are proposed. The first is an integer\nprogram whose objective function is a combination of the total number of errors\nand the total number of features used in the rule. We generalize a previously\nproposed linear programming (LP) relaxation from one-level to two-level rules.\nThe second formulation replaces the 0-1 classification error with the Hamming\ndistance from the current two-level rule to the closest rule that correctly\nclassifies a sample. Based on this second formulation, block coordinate descent\nand alternating minimization algorithms are developed. Experiments show that\nthe two-level rules can yield noticeably better performance than one-level\nrules due to their dramatically larger modeling capacity, and the two\nalgorithms based on the Hamming distance formulation are generally superior to\nthe other two-level rule learning methods in our comparison. A proposed\napproach to binarize any fractional values in the optimal solutions of LP\nrelaxations is also shown to be effective.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 18:52:21 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Su", "Guolong", ""], ["Wei", "Dennis", ""], ["Varshney", "Kush R.", ""], ["Malioutov", "Dmitry M.", ""]]}, {"id": "1511.07386", "submitter": "Iasonas Kokkinos", "authors": "Iasonas Kokkinos", "title": "Pushing the Boundaries of Boundary Detection using Deep Learning", "comments": "The previous version reported large improvements w.r.t. the LPO\n  region proposal baseline, which turned out to be due to a wrong computation\n  for the baseline. The improvements are currently less important, and are\n  omitted. We are sorry if the reported results caused any confusion. We have\n  also integrated reviewer feedback regarding human performance on the BSD\n  benchmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show that adapting Deep Convolutional Neural Network training\nto the task of boundary detection can result in substantial improvements over\nthe current state-of-the-art in boundary detection.\n  Our contributions consist firstly in combining a careful design of the loss\nfor boundary detection training, a multi-resolution architecture and training\nwith external data to improve the detection accuracy of the current state of\nthe art. When measured on the standard Berkeley Segmentation Dataset, we\nimprove theoptimal dataset scale F-measure from 0.780 to 0.808 - while human\nperformance is at 0.803. We further improve performance to 0.813 by combining\ndeep learning with grouping, integrating the Normalized Cuts technique within a\ndeep network.\n  We also examine the potential of our boundary detector in conjunction with\nthe task of semantic segmentation and demonstrate clear improvements over\nstate-of-the-art systems. Our detector is fully integrated in the popular Caffe\nframework and processes a 320x420 image in less than a second.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 19:54:09 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2016 15:31:32 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Kokkinos", "Iasonas", ""]]}, {"id": "1511.07401", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Arthur Szlam, Gabriel Synnaeve, Soumith\n  Chintala, Rob Fergus", "title": "MazeBase: A Sandbox for Learning from Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces MazeBase: an environment for simple 2D games, designed\nas a sandbox for machine learning approaches to reasoning and planning. Within\nit, we create 10 simple games embodying a range of algorithmic tasks (e.g.\nif-then statements or set negation). A variety of neural models (fully\nconnected, convolutional network, memory network) are deployed via\nreinforcement learning on these games, with and without a procedurally\ngenerated curriculum. Despite the tasks' simplicity, the performance of the\nmodels is far from optimal, suggesting directions for future development. We\nalso demonstrate the versatility of MazeBase by using it to emulate small\ncombat scenarios from StarCraft. Models trained on the MazeBase version can be\ndirectly applied to StarCraft, where they consistently beat the in-game AI.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 20:23:53 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 18:41:14 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Szlam", "Arthur", ""], ["Synnaeve", "Gabriel", ""], ["Chintala", "Soumith", ""], ["Fergus", "Rob", ""]]}, {"id": "1511.07409", "submitter": "Saining Xie", "authors": "Saining Xie, Xun Huang and Zhuowen Tu", "title": "Top-Down Learning for Structured Labeling with Convolutional Pseudoprior", "comments": "To appear in ECCV 2016, 16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current practice in convolutional neural networks (CNN) remains largely\nbottom-up and the role of top-down process in CNN for pattern analysis and\nvisual inference is not very clear. In this paper, we propose a new method for\nstructured labeling by developing convolutional pseudo-prior (ConvPP) on the\nground-truth labels. Our method has several interesting properties: (1)\ncompared with classical machine learning algorithms like CRFs and Structural\nSVM, ConvPP automatically learns rich convolutional kernels to capture both\nshort- and long- range contexts; (2) compared with cascade classifiers like\nAuto-Context, ConvPP avoids the iterative steps of learning a series of\ndiscriminative classifiers and automatically learns contextual configurations;\n(3) compared with recent efforts combing CNN models with CRFs and RNNs, ConvPP\nlearns convolution in the labeling space with much improved modeling capability\nand less manual specification; (4) compared with Bayesian models like MRFs,\nConvPP capitalizes on the rich representation power of convolution by\nautomatically learning priors built on convolutional filters. We accomplish our\ntask using pseudo-likelihood approximation to the prior under a novel\nfixed-point network structure that facilitates an end-to-end learning process.\nWe show state-of-the-art results on sequential labeling and image labeling\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 20:43:14 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 05:25:29 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Xie", "Saining", ""], ["Huang", "Xun", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1511.07471", "submitter": "Huizhen Yu", "authors": "Huizhen Yu", "title": "Weak Convergence Properties of Constrained Emphatic Temporal-difference\n  Learning with Constant and Slowly Diminishing Stepsize", "comments": "Minor edits; 53 pages. Longer and more proof details than the journal\n  version", "journal-ref": "Journal of Machine Learning Research, 17(220):1-58, 2016", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the emphatic temporal-difference (TD) algorithm, ETD($\\lambda$),\nfor learning the value functions of stationary policies in a discounted, finite\nstate and action Markov decision process. The ETD($\\lambda$) algorithm was\nrecently proposed by Sutton, Mahmood, and White to solve a long-standing\ndivergence problem of the standard TD algorithm when it is applied to\noff-policy training, where data from an exploratory policy are used to evaluate\nother policies of interest. The almost sure convergence of ETD($\\lambda$) has\nbeen proved in our recent work under general off-policy training conditions,\nbut for a narrow range of diminishing stepsize. In this paper we present\nconvergence results for constrained versions of ETD($\\lambda$) with constant\nstepsize and with diminishing stepsize from a broad range. Our results\ncharacterize the asymptotic behavior of the trajectory of iterates produced by\nthose algorithms, and are derived by combining key properties of ETD($\\lambda$)\nwith powerful convergence theorems from the weak convergence methods in\nstochastic approximation theory. For the case of constant stepsize, in addition\nto analyzing the behavior of the algorithms in the limit as the stepsize\nparameter approaches zero, we also analyze their behavior for a fixed stepsize\nand bound the deviations of their averaged iterates from the desired solution.\nThese results are obtained by exploiting the weak Feller property of the Markov\nchains associated with the algorithms, and by using ergodic theorems for weak\nFeller Markov chains, in conjunction with the convergence results we get from\nthe weak convergence methods. Besides ETD($\\lambda$), our analysis also applies\nto the off-policy TD($\\lambda$) algorithm, when the divergence issue is avoided\nby setting $\\lambda$ sufficiently large.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 21:29:43 GMT"}, {"version": "v2", "created": "Tue, 10 May 2016 18:38:32 GMT"}, {"version": "v3", "created": "Fri, 20 Jan 2017 18:35:27 GMT"}], "update_date": "2017-01-23", "authors_parsed": [["Yu", "Huizhen", ""]]}, {"id": "1511.07497", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Philipp Kr\\\"ahenb\\\"uhl, Stella X. Yu, Trevor Darrell", "title": "Constrained Structured Regression with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have recently emerged as the dominant\nmodel in computer vision. If provided with enough training data, they predict\nalmost any visual quantity. In a discrete setting, such as classification, CNNs\nare not only able to predict a label but often predict a confidence in the form\nof a probability distribution over the output space. In continuous regression\ntasks, such a probability estimate is often lacking. We present a regression\nframework which models the output distribution of neural networks. This output\ndistribution allows us to infer the most likely labeling following a set of\nphysical or modeling constraints. These constraints capture the intricate\ninterplay between different input and output variables, and complement the\noutput of a CNN. However, they may not hold everywhere. Our setup further\nallows to learn a confidence with which a constraint holds, in the form of a\ndistribution of the constrain satisfaction. We evaluate our approach on the\nproblem of intrinsic image decomposition, and show that constrained structured\nregression significantly increases the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 22:43:37 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Pathak", "Deepak", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Yu", "Stella X.", ""], ["Darrell", "Trevor", ""]]}, {"id": "1511.07528", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel and Somesh Jha and Matt\n  Fredrikson and Z. Berkay Celik and Ananthram Swami", "title": "The Limitations of Deep Learning in Adversarial Settings", "comments": "Accepted to the 1st IEEE European Symposium on Security & Privacy,\n  IEEE 2016. Saarbrucken, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning takes advantage of large datasets and computationally efficient\ntraining algorithms to outperform other approaches at various machine learning\ntasks. However, imperfections in the training phase of deep neural networks\nmake them vulnerable to adversarial samples: inputs crafted by adversaries with\nthe intent of causing deep neural networks to misclassify. In this work, we\nformalize the space of adversaries against deep neural networks (DNNs) and\nintroduce a novel class of algorithms to craft adversarial samples based on a\nprecise understanding of the mapping between inputs and outputs of DNNs. In an\napplication to computer vision, we show that our algorithms can reliably\nproduce samples correctly classified by human subjects but misclassified in\nspecific targets by a DNN with a 97% adversarial success rate while only\nmodifying on average 4.02% of the input features per sample. We then evaluate\nthe vulnerability of different sample classes to adversarial perturbations by\ndefining a hardness measure. Finally, we describe preliminary work outlining\ndefenses against adversarial samples by defining a predictive measure of\ndistance between a benign input and a target classification.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 01:07:08 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Jha", "Somesh", ""], ["Fredrikson", "Matt", ""], ["Celik", "Z. Berkay", ""], ["Swami", "Ananthram", ""]]}, {"id": "1511.07543", "submitter": "Yixuan Li", "authors": "Yixuan Li, Jason Yosinski, Jeff Clune, Hod Lipson and John Hopcroft", "title": "Convergent Learning: Do different neural networks learn the same\n  representations?", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent success in training deep neural networks have prompted active\ninvestigation into the features learned on their intermediate layers. Such\nresearch is difficult because it requires making sense of non-linear\ncomputations performed by millions of parameters, but valuable because it\nincreases our ability to understand current models and create improved versions\nof them. In this paper we investigate the extent to which neural networks\nexhibit what we call convergent learning, which is when the representations\nlearned by multiple nets converge to a set of features which are either\nindividually similar between networks or where subsets of features span similar\nlow-dimensional spaces. We propose a specific method of probing\nrepresentations: training multiple networks and then comparing and contrasting\ntheir individual, learned representations at the level of neurons or groups of\nneurons. We begin research into this question using three techniques to\napproximately align different neural networks on a feature level: a bipartite\nmatching approach that makes one-to-one assignments between neurons, a sparse\nprediction approach that finds one-to-many mappings, and a spectral clustering\napproach that finds many-to-many mappings. This initial investigation reveals a\nfew previously unknown properties of neural networks, and we argue that future\nresearch into the question of convergent learning will yield many more. The\ninsights described here include (1) that some features are learned reliably in\nmultiple networks, yet other features are not consistently learned; (2) that\nunits learn to span low-dimensional subspaces and, while these subspaces are\ncommon to multiple networks, the specific basis vectors learned are not; (3)\nthat the representation codes show evidence of being a mix between a local code\nand slightly, but not fully, distributed codes across multiple units.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 02:31:46 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 02:33:05 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2016 22:04:54 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Li", "Yixuan", ""], ["Yosinski", "Jason", ""], ["Clune", "Jeff", ""], ["Lipson", "Hod", ""], ["Hopcroft", "John", ""]]}, {"id": "1511.07551", "submitter": "Yanshuai Cao", "authors": "Yanshuai Cao, David J. Fleet", "title": "Transductive Log Opinion Pool of Gaussian Process Experts", "comments": "Accepted at NIPS2015 Workshop on Nonparametric Methods for Large\n  Scale Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for analyzing transductive combination of Gaussian\nprocess (GP) experts, where independently trained GP experts are combined in a\nway that depends on test point location, in order to scale GPs to big data. The\nframework provides some theoretical justification for the generalized product\nof GP experts (gPoE-GP) which was previously shown to work well in practice but\nlacks theoretical basis. Based on the proposed framework, an improvement over\ngPoE-GP is introduced and empirically validated.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 03:08:59 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Cao", "Yanshuai", ""], ["Fleet", "David J.", ""]]}, {"id": "1511.07571", "submitter": "Justin Johnson", "authors": "Justin Johnson and Andrej Karpathy and Li Fei-Fei", "title": "DenseCap: Fully Convolutional Localization Networks for Dense Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the dense captioning task, which requires a computer vision\nsystem to both localize and describe salient regions in images in natural\nlanguage. The dense captioning task generalizes object detection when the\ndescriptions consist of a single word, and Image Captioning when one predicted\nregion covers the full image. To address the localization and description task\njointly we propose a Fully Convolutional Localization Network (FCLN)\narchitecture that processes an image with a single, efficient forward pass,\nrequires no external regions proposals, and can be trained end-to-end with a\nsingle round of optimization. The architecture is composed of a Convolutional\nNetwork, a novel dense localization layer, and Recurrent Neural Network\nlanguage model that generates the label sequences. We evaluate our network on\nthe Visual Genome dataset, which comprises 94,000 images and 4,100,000\nregion-grounded captions. We observe both speed and accuracy improvements over\nbaselines based on current state of the art approaches in both generation and\nretrieval settings.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 05:13:54 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Johnson", "Justin", ""], ["Karpathy", "Andrej", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1511.07608", "submitter": "Janne V. Kujala", "authors": "Janne V. Kujala, Tuomas J. Lukka, and Harri Holopainen", "title": "Picking a Conveyor Clean by an Autonomously Learning Robot", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a research picking prototype related to our company's industrial\nwaste sorting application. The goal of the prototype is to be as autonomous as\npossible and it both calibrates itself and improves its picking with minimal\nhuman intervention. The system learns to pick objects better based on a\nfeedback sensor in its gripper and uses machine learning to choosing the best\nproposal from a random sample produced by simple hard-coded geometric models.\nWe show experimentally the system improving its picking autonomously by\nmeasuring the pick success rate as function of time. We also show how this\nsystem can pick a conveyor belt clean, depositing 70 out of 80 objects in a\ndifficult to manipulate pile of novel objects into the correct chute. We\ndiscuss potential improvements and next steps in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 08:35:49 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Kujala", "Janne V.", ""], ["Lukka", "Tuomas J.", ""], ["Holopainen", "Harri", ""]]}, {"id": "1511.07763", "submitter": "Spyros Gidaris", "authors": "Spyros Gidaris, Nikos Komodakis", "title": "LocNet: Improving Localization Accuracy for Object Detection", "comments": "Extended technical report -- short version to appear as oral paper on\n  CVPR 2016. Code: https://github.com/gidariss/LocNet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel object localization methodology with the purpose of\nboosting the localization accuracy of state-of-the-art object detection\nsystems. Our model, given a search region, aims at returning the bounding box\nof an object of interest inside this region. To accomplish its goal, it relies\non assigning conditional probabilities to each row and column of this region,\nwhere these probabilities provide useful information regarding the location of\nthe boundaries of the object inside the search region and allow the accurate\ninference of the object bounding box under a simple probabilistic framework.\n  For implementing our localization model, we make use of a convolutional\nneural network architecture that is properly adapted for this task, called\nLocNet. We show experimentally that LocNet achieves a very significant\nimprovement on the mAP for high IoU thresholds on PASCAL VOC2007 test set and\nthat it can be very easily coupled with recent state-of-the-art object\ndetection systems, helping them to boost their performance. Finally, we\ndemonstrate that our detection approach can achieve high detection accuracy\neven when it is given as input a set of sliding windows, thus proving that it\nis independent of box proposal methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 15:42:01 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 15:09:15 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Gidaris", "Spyros", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1511.07837", "submitter": "Zhaosong Lu", "authors": "Zhaosong Lu and Xiaojun Chen", "title": "Generalized Conjugate Gradient Methods for $\\ell_1$ Regularized Convex\n  Quadratic Programming with Finite Convergence", "comments": "36 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conjugate gradient (CG) method is an efficient iterative method for\nsolving large-scale strongly convex quadratic programming (QP). In this paper\nwe propose some generalized CG (GCG) methods for solving the\n$\\ell_1$-regularized (possibly not strongly) convex QP that terminate at an\noptimal solution in a finite number of iterations. At each iteration, our\nmethods first identify a face of an orthant and then either perform an exact\nline search along the direction of the negative projected minimum-norm\nsubgradient of the objective function or execute a CG subroutine that conducts\na sequence of CG iterations until a CG iterate crosses the boundary of this\nface or an approximate minimizer of over this face or a subface is found. We\ndetermine which type of step should be taken by comparing the magnitude of some\ncomponents of the minimum-norm subgradient of the objective function to that of\nits rest components. Our analysis on finite convergence of these methods makes\nuse of an error bound result and some key properties of the aforementioned\nexact line search and the CG subroutine. We also show that the proposed methods\nare capable of finding an approximate solution of the problem by allowing some\ninexactness on the execution of the CG subroutine. The overall arithmetic\noperation cost of our GCG methods for finding an $\\epsilon$-optimal solution\ndepends on $\\epsilon$ in $O(\\log(1/\\epsilon))$, which is superior to the\naccelerated proximal gradient method [2,23] that depends on $\\epsilon$ in\n$O(1/\\sqrt{\\epsilon})$. In addition, our GCG methods can be extended\nstraightforwardly to solve box-constrained convex QP with finite convergence.\nNumerical results demonstrate that our methods are very favorable for solving\nill-conditioned problems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 19:28:09 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 22:16:30 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2016 19:23:49 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Lu", "Zhaosong", ""], ["Chen", "Xiaojun", ""]]}, {"id": "1511.07838", "submitter": "Amjad Almahairi", "authors": "Amjad Almahairi, Nicolas Ballas, Tim Cooijmans, Yin Zheng, Hugo\n  Larochelle, Aaron Courville", "title": "Dynamic Capacity Networks", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Dynamic Capacity Network (DCN), a neural network that can\nadaptively assign its capacity across different portions of the input data.\nThis is achieved by combining modules of two types: low-capacity sub-networks\nand high-capacity sub-networks. The low-capacity sub-networks are applied\nacross most of the input, but also provide a guide to select a few portions of\nthe input on which to apply the high-capacity sub-networks. The selection is\nmade using a novel gradient-based attention mechanism, that efficiently\nidentifies input regions for which the DCN's output is most sensitive and to\nwhich we should devote more capacity. We focus our empirical evaluation on the\nCluttered MNIST and SVHN image datasets. Our findings indicate that DCNs are\nable to drastically reduce the number of computations, compared to traditional\nconvolutional neural networks, while maintaining similar or even better\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 19:30:19 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2015 19:17:53 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2015 16:13:21 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 22:44:43 GMT"}, {"version": "v5", "created": "Tue, 9 Feb 2016 16:49:55 GMT"}, {"version": "v6", "created": "Wed, 6 Apr 2016 19:48:32 GMT"}, {"version": "v7", "created": "Sun, 22 May 2016 20:58:11 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Almahairi", "Amjad", ""], ["Ballas", "Nicolas", ""], ["Cooijmans", "Tim", ""], ["Zheng", "Yin", ""], ["Larochelle", "Hugo", ""], ["Courville", "Aaron", ""]]}, {"id": "1511.07896", "submitter": "Vishesh Karwa", "authors": "Vishesh Karwa and Dan Kifer and Aleksandra B. Slavkovi\\'c", "title": "Private Posterior distributions from Variational approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving mechanisms such as differential privacy inject additional\nrandomness in the form of noise in the data, beyond the sampling mechanism.\nIgnoring this additional noise can lead to inaccurate and invalid inferences.\nIn this paper, we incorporate the privacy mechanism explicitly into the\nlikelihood function by treating the original data as missing, with an end goal\nof estimating posterior distributions over model parameters. This leads to a\nprincipled way of performing valid statistical inference using private data,\nhowever, the corresponding likelihoods are intractable. In this paper, we\nderive fast and accurate variational approximations to tackle such intractable\nlikelihoods that arise due to privacy. We focus on estimating posterior\ndistributions of parameters of the naive Bayes log-linear model, where the\nsufficient statistics of this model are shared using a differentially private\ninterface. Using a simulation study, we show that the posterior approximations\noutperform the naive method of ignoring the noise addition mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 21:49:02 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Karwa", "Vishesh", ""], ["Kifer", "Dan", ""], ["Slavkovi\u0107", "Aleksandra B.", ""]]}, {"id": "1511.07902", "submitter": "Bicheng Ying", "authors": "Bicheng Ying and Ali H. Sayed", "title": "Performance Limits of Stochastic Sub-Gradient Learning, Part I: Single\n  Agent Case", "comments": "Part II is available on http://arxiv.org/abs/1704.06025", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work and the supporting Part II, we examine the performance of\nstochastic sub-gradient learning strategies under weaker conditions than\nusually considered in the literature. The new conditions are shown to be\nautomatically satisfied by several important cases of interest including SVM,\nLASSO, and Total-Variation denoising formulations. In comparison, these\nproblems do not satisfy the traditional assumptions used in prior analyses and,\ntherefore, conclusions derived from these earlier treatments are not directly\napplicable to these problems. The results in this article establish that\nstochastic sub-gradient strategies can attain linear convergence rates, as\nopposed to sub-linear rates, to the steady-state regime. A realizable\nexponential-weighting procedure is employed to smooth the intermediate iterates\nand guarantee useful performance bounds in terms of convergence rate and\nexcessive risk performance. Part I of this work focuses on single-agent\nscenarios, which are common in stand-alone learning applications, while Part II\nextends the analysis to networked learners. The theoretical conclusions are\nillustrated by several examples and simulations, including comparisons with the\nFISTA procedure.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 22:31:19 GMT"}, {"version": "v2", "created": "Sun, 24 Apr 2016 21:04:14 GMT"}, {"version": "v3", "created": "Sat, 30 Jul 2016 22:17:34 GMT"}, {"version": "v4", "created": "Fri, 21 Apr 2017 17:55:25 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Ying", "Bicheng", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1511.07917", "submitter": "Anton Osokin", "authors": "Tuan-Hung Vu, Anton Osokin, Ivan Laptev", "title": "Context-aware CNNs for person head detection", "comments": "To appear in International Conference on Computer Vision (ICCV), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person detection is a key problem for many computer vision tasks. While face\ndetection has reached maturity, detecting people under a full variation of\ncamera view-points, human poses, lighting conditions and occlusions is still a\ndifficult challenge. In this work we focus on detecting human heads in natural\nscenes. Starting from the recent local R-CNN object detector, we extend it with\ntwo types of contextual cues. First, we leverage person-scene relations and\npropose a Global CNN model trained to predict positions and scales of heads\ndirectly from the full image. Second, we explicitly model pairwise relations\namong objects and train a Pairwise CNN model using a structured-output\nsurrogate loss. The Local, Global and Pairwise models are combined into a joint\nCNN framework. To train and test our full model, we introduce a large dataset\ncomposed of 369,846 human heads annotated in 224,740 movie frames. We evaluate\nour method and demonstrate improvements of person head detection against\nseveral recent baselines in three datasets. We also show improvements of the\ndetection speed provided by our model.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 23:23:18 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Vu", "Tuan-Hung", ""], ["Osokin", "Anton", ""], ["Laptev", "Ivan", ""]]}, {"id": "1511.07938", "submitter": "Narges Razavian", "authors": "Narges Razavian, David Sontag", "title": "Temporal Convolutional Neural Networks for Diagnosis from Lab Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early diagnosis of treatable diseases is essential for improving healthcare,\nand many diseases' onsets are predictable from annual lab tests and their\ntemporal trends. We introduce a multi-resolution convolutional neural network\nfor early detection of multiple diseases from irregularly measured sparse lab\nvalues. Our novel architecture takes as input both an imputed version of the\ndata and a binary observation matrix. For imputing the temporal sparse\nobservations, we develop a flexible, fast to train method for differentiable\nmultivariate kernel regression. Our experiments on data from 298K individuals\nover 8 years, 18 common lab measurements, and 171 diseases show that the\ntemporal signatures learned via convolution are significantly more predictive\nthan baselines commonly used for early disease diagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 02:56:33 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 05:27:22 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2016 22:19:40 GMT"}, {"version": "v4", "created": "Fri, 11 Mar 2016 00:00:50 GMT"}], "update_date": "2016-03-14", "authors_parsed": [["Razavian", "Narges", ""], ["Sontag", "David", ""]]}, {"id": "1511.07948", "submitter": "Yuchen Zhang", "authors": "Yuchen Zhang, Jason D. Lee, Martin J. Wainwright, Michael I. Jordan", "title": "Learning Halfspaces and Neural Networks with Random Initialization", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study non-convex empirical risk minimization for learning halfspaces and\nneural networks. For loss functions that are $L$-Lipschitz continuous, we\npresent algorithms to learn halfspaces and multi-layer neural networks that\nachieve arbitrarily small excess risk $\\epsilon>0$. The time complexity is\npolynomial in the input dimension $d$ and the sample size $n$, but exponential\nin the quantity $(L/\\epsilon^2)\\log(L/\\epsilon)$. These algorithms run multiple\nrounds of random initialization followed by arbitrary optimization steps. We\nfurther show that if the data is separable by some neural network with constant\nmargin $\\gamma>0$, then there is a polynomial-time algorithm for learning a\nneural network that separates the training data with margin $\\Omega(\\gamma)$.\nAs a consequence, the algorithm achieves arbitrary generalization error\n$\\epsilon>0$ with ${\\rm poly}(d,1/\\epsilon)$ sample and time complexity. We\nestablish the same learnability result when the labels are randomly flipped\nwith probability $\\eta<1/2$.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 04:41:20 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Zhang", "Yuchen", ""], ["Lee", "Jason D.", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1511.07953", "submitter": "Aditya Jami", "authors": "Amit Garg, Jonathan Noyola, Romil Verma, Ashutosh Saxena, Aditya Jami", "title": "Exploring Correlation between Labels to improve Multi-Label\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts multi-label classification by extending the idea of\nindependent binary classification models for each output label, and exploring\nhow the inherent correlation between output labels can be used to improve\npredictions. Logistic Regression, Naive Bayes, Random Forest, and SVM models\nwere constructed, with SVM giving the best results: an improvement of 12.9\\%\nover binary models was achieved for hold out cross validation by augmenting\nwith pairwise correlation probabilities of the labels.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 05:21:53 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Garg", "Amit", ""], ["Noyola", "Jonathan", ""], ["Verma", "Romil", ""], ["Saxena", "Ashutosh", ""], ["Jami", "Aditya", ""]]}, {"id": "1511.07961", "submitter": "Benjamin Rubinstein", "authors": "Jiazhen He, Benjamin I. P. Rubinstein, James Bailey, Rui Zhang, Sandra\n  Milligan, Jeffrey Chan", "title": "MOOCs Meet Measurement Theory: A Topic-Modelling Approach", "comments": "12 pages, 9 figures; accepted into AAAI'2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper adapts topic models to the psychometric testing of MOOC students\nbased on their online forum postings. Measurement theory from education and\npsychology provides statistical models for quantifying a person's attainment of\nintangible attributes such as attitudes, abilities or intelligence. Such models\ninfer latent skill levels by relating them to individuals' observed responses\non a series of items such as quiz questions. The set of items can be used to\nmeasure a latent skill if individuals' responses on them conform to a Guttman\nscale. Such well-scaled items differentiate between individuals and inferred\nlevels span the entire range from most basic to the advanced. In practice,\neducation researchers manually devise items (quiz questions) while optimising\nwell-scaled conformance. Due to the costly nature and expert requirements of\nthis process, psychometric testing has found limited use in everyday teaching.\nWe aim to develop usable measurement models for highly-instrumented MOOC\ndelivery platforms, by using participation in automatically-extracted online\nforum topics as items. The challenge is to formalise the Guttman scale\neducational constraint and incorporate it into topic models. To favour topics\nthat automatically conform to a Guttman scale, we introduce a novel\nregularisation into non-negative matrix factorisation-based topic modelling. We\ndemonstrate the suitability of our approach with both quantitative experiments\non three Coursera MOOCs, and with a qualitative survey of topic\ninterpretability on two MOOCs by domain expert interviews.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 06:04:43 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["He", "Jiazhen", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Bailey", "James", ""], ["Zhang", "Rui", ""], ["Milligan", "Sandra", ""], ["Chan", "Jeffrey", ""]]}, {"id": "1511.07972", "submitter": "Volker Tresp", "authors": "Volker Tresp and Crist\\'obal Esteban and Yinchong Yang and Stephan\n  Baier and Denis Krompa{\\ss}", "title": "Learning with Memory Embeddings", "comments": "29 pages, NIPS 2015 Workshop on Nonparametric Methods for Large Scale\n  Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding learning, a.k.a. representation learning, has been shown to be able\nto model large-scale semantic knowledge graphs. A key concept is a mapping of\nthe knowledge graph to a tensor representation whose entries are predicted by\nmodels using latent representations of generalized entities. Latent variable\nmodels are well suited to deal with the high dimensionality and sparsity of\ntypical knowledge graphs. In recent publications the embedding models were\nextended to also consider time evolutions, time patterns and subsymbolic\nrepresentations. In this paper we map embedding models, which were developed\npurely as solutions to technical problems for modelling temporal knowledge\ngraphs, to various cognitive memory functions, in particular to semantic and\nconcept memory, episodic memory, sensory memory, short-term memory, and working\nmemory. We discuss learning, query answering, the path from sensory input to\nsemantic decoding, and the relationship between episodic memory and semantic\nmemory. We introduce a number of hypotheses on human memory that can be derived\nfrom the developed mathematical models.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 07:06:09 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 05:53:38 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2015 23:38:03 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2015 22:35:39 GMT"}, {"version": "v5", "created": "Mon, 25 Jan 2016 20:02:39 GMT"}, {"version": "v6", "created": "Wed, 13 Apr 2016 17:23:42 GMT"}, {"version": "v7", "created": "Thu, 21 Apr 2016 04:40:58 GMT"}, {"version": "v8", "created": "Thu, 5 May 2016 14:57:41 GMT"}, {"version": "v9", "created": "Sat, 7 May 2016 09:06:15 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Tresp", "Volker", ""], ["Esteban", "Crist\u00f3bal", ""], ["Yang", "Yinchong", ""], ["Baier", "Stephan", ""], ["Krompa\u00df", "Denis", ""]]}, {"id": "1511.08032", "submitter": "Christos Tzelepis", "authors": "Christos Tzelepis, Damianos Galanopoulos, Vasileios Mezaris, Ioannis\n  Patras", "title": "Learning to detect video events from zero or very few video examples", "comments": "Image and Vision Computing Journal, Elsevier, 2015, accepted for\n  publication", "journal-ref": "Image and Vision Computing Journal, Elsevier, 2015", "doi": "10.1016/j.imavis.2015.09.005", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we deal with the problem of high-level event detection in video.\nSpecifically, we study the challenging problems of i) learning to detect video\nevents from solely a textual description of the event, without using any\npositive video examples, and ii) additionally exploiting very few positive\ntraining samples together with a small number of ``related'' videos. For\nlearning only from an event's textual description, we first identify a general\nlearning framework and then study the impact of different design choices for\nvarious stages of this framework. For additionally learning from example\nvideos, when true positive training samples are scarce, we employ an extension\nof the Support Vector Machine that allows us to exploit ``related'' event\nvideos by automatically introducing different weights for subsets of the videos\nin the overall training set. Experimental evaluations performed on the\nlarge-scale TRECVID MED 2014 video dataset provide insight on the effectiveness\nof the proposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 12:17:50 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Tzelepis", "Christos", ""], ["Galanopoulos", "Damianos", ""], ["Mezaris", "Vasileios", ""], ["Patras", "Ioannis", ""]]}, {"id": "1511.08062", "submitter": "Chen Xu", "authors": "Chen Xu, Zhouchen Lin, Zhenyu Zhao, Hongbin Zha", "title": "Relaxed Majorization-Minimization for Non-smooth and Non-convex\n  Optimization", "comments": "AAAI16", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new majorization-minimization (MM) method for non-smooth and\nnon-convex programs, which is general enough to include the existing MM\nmethods. Besides the local majorization condition, we only require that the\ndifference between the directional derivatives of the objective function and\nits surrogate function vanishes when the number of iterations approaches\ninfinity, which is a very weak condition. So our method can use a surrogate\nfunction that directly approximates the non-smooth objective function. In\ncomparison, all the existing MM methods construct the surrogate function by\napproximating the smooth component of the objective function. We apply our\nrelaxed MM methods to the robust matrix factorization (RMF) problem with\ndifferent regularizations, where our locally majorant algorithm shows\nadvantages over the state-of-the-art approaches for RMF. This is the first\nalgorithm for RMF ensuring, without extra assumptions, that any limit point of\nthe iterates is a stationary point.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 13:55:57 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Xu", "Chen", ""], ["Lin", "Zhouchen", ""], ["Zhao", "Zhenyu", ""], ["Zha", "Hongbin", ""]]}, {"id": "1511.08099", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Simon Keizer, Oliver Lemon", "title": "Strategic Dialogue Management via Deep Reinforcement Learning", "comments": "NIPS'15 Workshop on Deep Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificially intelligent agents equipped with strategic skills that can\nnegotiate during their interactions with other natural or artificial agents are\nstill underdeveloped. This paper describes a successful application of Deep\nReinforcement Learning (DRL) for training intelligent agents with strategic\nconversational skills, in a situated dialogue setting. Previous studies have\nmodelled the behaviour of strategic agents using supervised learning and\ntraditional reinforcement learning techniques, the latter using tabular\nrepresentations or learning with linear function approximation. In this study,\nwe apply DRL with a high-dimensional state space to the strategic board game of\nSettlers of Catan---where players can offer resources in exchange for others\nand they can also reply to offers made by other players. Our experimental\nresults report that the DRL-based learnt policies significantly outperformed\nseveral baselines including random, rule-based, and supervised-based\nbehaviours. The DRL-based policy has a 53% win rate versus 3 automated players\n(`bots'), whereas a supervised player trained on a dialogue corpus in this\nsetting achieved only 27%, versus the same 3 bots. This result supports the\nclaim that DRL is a promising framework for training dialogue systems, and\nstrategic agents with negotiation abilities.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 15:48:59 GMT"}], "update_date": "2015-11-28", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Keizer", "Simon", ""], ["Lemon", "Oliver", ""]]}, {"id": "1511.08136", "submitter": "Yisen Wang", "authors": "Yisen Wang, Chaobing Song, Shu-Tao Xia", "title": "Unifying Decision Trees Split Criteria Using Tsallis Entropy", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of efficient and effective decision trees remains a key\ntopic in machine learning because of their simplicity and flexibility. A lot of\nheuristic algorithms have been proposed to construct near-optimal decision\ntrees. ID3, C4.5 and CART are classical decision tree algorithms and the split\ncriteria they used are Shannon entropy, Gain Ratio and Gini index respectively.\nAll the split criteria seem to be independent, actually, they can be unified in\na Tsallis entropy framework. Tsallis entropy is a generalization of Shannon\nentropy and provides a new approach to enhance decision trees' performance with\nan adjustable parameter $q$. In this paper, a Tsallis Entropy Criterion (TEC)\nalgorithm is proposed to unify Shannon entropy, Gain Ratio and Gini index,\nwhich generalizes the split criteria of decision trees. More importantly, we\nreveal the relations between Tsallis entropy with different $q$ and other split\ncriteria. Experimental results on UCI data sets indicate that the TEC algorithm\nachieves statistically significant improvement over the classical algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 17:49:55 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2015 02:29:07 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2015 08:08:22 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2016 07:53:55 GMT"}, {"version": "v5", "created": "Tue, 23 Aug 2016 01:02:14 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Wang", "Yisen", ""], ["Song", "Chaobing", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1511.08198", "submitter": "John Wieting", "authors": "John Wieting, Mohit Bansal, Kevin Gimpel, Karen Livescu", "title": "Towards Universal Paraphrastic Sentence Embeddings", "comments": "Published as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning general-purpose, paraphrastic sentence\nembeddings based on supervision from the Paraphrase Database (Ganitkevitch et\nal., 2013). We compare six compositional architectures, evaluating them on\nannotated textual similarity datasets drawn both from the same distribution as\nthe training data and from a wide range of other domains. We find that the most\ncomplex architectures, such as long short-term memory (LSTM) recurrent neural\nnetworks, perform best on the in-domain data. However, in out-of-domain\nscenarios, simple architectures such as word averaging vastly outperform LSTMs.\nOur simplest averaging model is even competitive with systems tuned for the\nparticular tasks while also being extremely efficient and easy to use.\n  In order to better understand how these architectures compare, we conduct\nfurther experiments on three supervised NLP tasks: sentence similarity,\nentailment, and sentiment classification. We again find that the word averaging\nmodels perform well for sentence similarity and entailment, outperforming\nLSTMs. However, on sentiment classification, we find that the LSTM performs\nvery strongly-even recording new state-of-the-art performance on the Stanford\nSentiment Treebank.\n  We then demonstrate how to combine our pretrained sentence embeddings with\nthese supervised tasks, using them both as a prior and as a black box feature\nextractor. This leads to performance rivaling the state of the art on the SICK\nsimilarity and entailment tasks. We release all of our resources to the\nresearch community with the hope that they can serve as the new baseline for\nfurther work on universal sentence embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 20:52:15 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 20:59:39 GMT"}, {"version": "v3", "created": "Fri, 4 Mar 2016 20:54:30 GMT"}], "update_date": "2016-03-07", "authors_parsed": [["Wieting", "John", ""], ["Bansal", "Mohit", ""], ["Gimpel", "Kevin", ""], ["Livescu", "Karen", ""]]}, {"id": "1511.08228", "submitter": "{\\L}ukasz Kaiser", "authors": "{\\L}ukasz Kaiser and Ilya Sutskever", "title": "Neural GPUs Learn Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning an algorithm from examples is a fundamental problem that has been\nwidely studied. Recently it has been addressed using neural networks, in\nparticular by Neural Turing Machines (NTMs). These are fully differentiable\ncomputers that use backpropagation to learn their own programming. Despite\ntheir appeal NTMs have a weakness that is caused by their sequential nature:\nthey are not parallel and are are hard to train due to their large depth when\nunfolded.\n  We present a neural network architecture to address this problem: the Neural\nGPU. It is based on a type of convolutional gated recurrent unit and, like the\nNTM, is computationally universal. Unlike the NTM, the Neural GPU is highly\nparallel which makes it easier to train and efficient to run.\n  An essential property of algorithms is their ability to handle inputs of\narbitrary size. We show that the Neural GPU can be trained on short instances\nof an algorithmic task and successfully generalize to long instances. We\nverified it on a number of tasks including long addition and long\nmultiplication of numbers represented in binary. We train the Neural GPU on\nnumbers with upto 20 bits and observe no errors whatsoever while testing it,\neven on much longer numbers.\n  To achieve these results we introduce a technique for training deep recurrent\nnetworks: parameter sharing relaxation. We also found a small amount of dropout\nand gradient noise to have a large positive effect on learning and\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 21:17:43 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 14:44:27 GMT"}, {"version": "v3", "created": "Tue, 15 Mar 2016 00:20:54 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Kaiser", "\u0141ukasz", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1511.08299", "submitter": "Aditya Jami", "authors": "Matthew Long, Aditya Jami, Ashutosh Saxena", "title": "Hierarchical classification of e-commerce related social media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we attempt to classify tweets into root categories of the\nAmazon browse node hierarchy using a set of tweets with browse node ID labels,\na much larger set of tweets without labels, and a set of Amazon reviews.\nExamining twitter data presents unique challenges in that the samples are short\n(under 140 characters) and often contain misspellings or abbreviations that are\ntrivial for a human to decipher but difficult for a computer to parse. A\nvariety of query and document expansion techniques are implemented in an effort\nto improve information retrieval to modest success.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 06:57:06 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Long", "Matthew", ""], ["Jami", "Aditya", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1511.08308", "submitter": "Eric Nichols", "authors": "Jason P.C. Chiu and Eric Nichols", "title": "Named Entity Recognition with Bidirectional LSTM-CNNs", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition is a challenging task that has traditionally\nrequired large amounts of knowledge in the form of feature engineering and\nlexicons to achieve high performance. In this paper, we present a novel neural\nnetwork architecture that automatically detects word- and character-level\nfeatures using a hybrid bidirectional LSTM and CNN architecture, eliminating\nthe need for most feature engineering. We also propose a novel method of\nencoding partial lexicon matches in neural networks and compare it to existing\napproaches. Extensive evaluation shows that, given only tokenized text and\npublicly available word embeddings, our system is competitive on the CoNLL-2003\ndataset and surpasses the previously reported state of the art performance on\nthe OntoNotes 5.0 dataset by 2.13 F1 points. By using two lexicons constructed\nfrom publicly-available sources, we establish new state of the art performance\nwith an F1 score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes, surpassing\nsystems that employ heavy feature engineering, proprietary lexicons, and rich\nentity linking information.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 07:40:33 GMT"}, {"version": "v2", "created": "Fri, 25 Mar 2016 09:23:52 GMT"}, {"version": "v3", "created": "Tue, 29 Mar 2016 06:25:57 GMT"}, {"version": "v4", "created": "Thu, 16 Jun 2016 06:15:49 GMT"}, {"version": "v5", "created": "Tue, 19 Jul 2016 05:02:51 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Chiu", "Jason P. C.", ""], ["Nichols", "Eric", ""]]}, {"id": "1511.08327", "submitter": "Nathalie Villa-Vialaneix", "authors": "Robin Genuer (ISPED, SISTM), Jean-Michel Poggi (UPD5, LM-Orsay),\n  Christine Tuleau-Malot (JAD), Nathalie Villa-Vialaneix (MIAT INRA)", "title": "Random Forests for Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data is one of the major challenges of statistical science and has\nnumerous consequences from algorithmic and theoretical viewpoints. Big Data\nalways involve massive data but they also often include online data and data\nheterogeneity. Recently some statistical methods have been adapted to process\nBig Data, like linear regression models, clustering methods and bootstrapping\nschemes. Based on decision trees combined with aggregation and bootstrap ideas,\nrandom forests were introduced by Breiman in 2001. They are a powerful\nnonparametric statistical method allowing to consider in a single and versatile\nframework regression problems, as well as two-class and multi-class\nclassification problems. Focusing on classification problems, this paper\nproposes a selective review of available proposals that deal with scaling\nrandom forests to Big Data problems. These proposals rely on parallel\nenvironments or on online adaptations of random forests. We also describe how\nrelated quantities -- such as out-of-bag error and variable importance -- are\naddressed in these methods. Then, we formulate various remarks for random\nforests in the Big Data context. Finally, we experiment five variants on two\nmassive datasets (15 and 120 millions of observations), a simulated one as well\nas real world data. One variant relies on subsampling while three others are\nrelated to parallel implementations of random forests and involve either\nvarious adaptations of bootstrap to Big Data or to \"divide-and-conquer\"\napproaches. The fifth variant relates on online learning of random forests.\nThese numerical experiments lead to highlight the relative performance of the\ndifferent variants, as well as some of their limitations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 09:04:47 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 14:51:57 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Genuer", "Robin", "", "ISPED, SISTM"], ["Poggi", "Jean-Michel", "", "UPD5, LM-Orsay"], ["Tuleau-Malot", "Christine", "", "JAD"], ["Villa-Vialaneix", "Nathalie", "", "MIAT INRA"]]}, {"id": "1511.08343", "submitter": "Jaesik Choi", "authors": "Yunseong Hwang, Anh Tong and Jaesik Choi", "title": "The Automatic Statistician: A Relational Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Processes (GPs) provide a general and analytically tractable way of\nmodeling complex time-varying, nonparametric functions. The Automatic Bayesian\nCovariance Discovery (ABCD) system constructs natural-language description of\ntime-series data by treating unknown time-series data nonparametrically using\nGP with a composite covariance kernel function. Unfortunately, learning a\ncomposite covariance kernel with a single time-series data set often results in\nless informative kernel that may not give qualitative, distinctive descriptions\nof data. We address this challenge by proposing two relational kernel learning\nmethods which can model multiple time-series data sets by finding common,\nshared causes of changes. We show that the relational kernel learning methods\nfind more accurate models for regression problems on several real-world data\nsets; US stock data, US house price index data and currency exchange rate data.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 10:26:51 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 03:08:12 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Hwang", "Yunseong", ""], ["Tong", "Anh", ""], ["Choi", "Jaesik", ""]]}, {"id": "1511.08400", "submitter": "David Krueger", "authors": "David Krueger, Roland Memisevic", "title": "Regularizing RNNs by Stabilizing Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We stabilize the activations of Recurrent Neural Networks (RNNs) by\npenalizing the squared distance between successive hidden states' norms.\n  This penalty term is an effective regularizer for RNNs including LSTMs and\nIRNNs, improving performance on character-level language modeling and phoneme\nrecognition, and outperforming weight noise and dropout.\n  We achieve competitive performance (18.6\\% PER) on the TIMIT phoneme\nrecognition task for RNNs evaluated without beam search or an RNN transducer.\n  With this penalty term, IRNN can achieve similar performance to LSTM on\nlanguage modeling, although adding the penalty term to the LSTM results in\nsuperior performance.\n  Our penalty term also prevents the exponential growth of IRNN's activations\noutside of their training horizon, allowing them to generalize to much longer\nsequences.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 14:35:27 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2015 04:52:03 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2015 02:09:00 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2016 00:58:39 GMT"}, {"version": "v5", "created": "Fri, 5 Feb 2016 04:58:47 GMT"}, {"version": "v6", "created": "Wed, 2 Mar 2016 20:42:08 GMT"}, {"version": "v7", "created": "Tue, 26 Apr 2016 05:21:11 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Krueger", "David", ""], ["Memisevic", "Roland", ""]]}, {"id": "1511.08405", "submitter": "Joon Kwon", "authors": "Joon Kwon and Vianney Perchet", "title": "Gains and Losses are Fundamentally Different in Regret Minimization: The\n  Sparse Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that, in the classical non-stochastic regret minimization\nproblem with $d$ decisions, gains and losses to be respectively maximized or\nminimized are fundamentally different. Indeed, by considering the additional\nsparsity assumption (at each stage, at most $s$ decisions incur a nonzero\noutcome), we derive optimal regret bounds of different orders. Specifically,\nwith gains, we obtain an optimal regret guarantee after $T$ stages of order\n$\\sqrt{T\\log s}$, so the classical dependency in the dimension is replaced by\nthe sparsity size. With losses, we provide matching upper and lower bounds of\norder $\\sqrt{Ts\\log(d)/d}$, which is decreasing in $d$. Eventually, we also\nstudy the bandit setting, and obtain an upper bound of order $\\sqrt{Ts\\log\n(d/s)}$ when outcomes are losses. This bound is proven to be optimal up to the\nlogarithmic factor $\\sqrt{\\log(d/s)}$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 14:53:00 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Kwon", "Joon", ""], ["Perchet", "Vianney", ""]]}, {"id": "1511.08407", "submitter": "Ran Tian", "authors": "Ran Tian, Naoaki Okazaki, Kentaro Inui", "title": "The Mechanism of Additive Composition", "comments": "More explanations on theory and additional experiments added.\n  Accepted by Machine Learning Journal", "journal-ref": null, "doi": "10.1007/s10994-017-5634-8", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive composition (Foltz et al, 1998; Landauer and Dumais, 1997; Mitchell\nand Lapata, 2010) is a widely used method for computing meanings of phrases,\nwhich takes the average of vector representations of the constituent words. In\nthis article, we prove an upper bound for the bias of additive composition,\nwhich is the first theoretical analysis on compositional frameworks from a\nmachine learning point of view. The bound is written in terms of collocation\nstrength; we prove that the more exclusively two successive words tend to occur\ntogether, the more accurate one can guarantee their additive composition as an\napproximation to the natural phrase vector. Our proof relies on properties of\nnatural language data that are empirically verified, and can be theoretically\nderived from an assumption that the data is generated from a Hierarchical\nPitman-Yor Process. The theory endorses additive composition as a reasonable\noperation for calculating meanings of phrases, and suggests ways to improve\nadditive compositionality, including: transforming entries of distributional\nword vectors by a function that meets a specific condition, constructing a\nnovel type of vector representations to make additive composition sensitive to\nword order, and utilizing singular value decomposition to train word vectors.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 14:58:17 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2015 23:34:40 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 04:28:21 GMT"}, {"version": "v4", "created": "Tue, 7 Mar 2017 02:39:58 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Tian", "Ran", ""], ["Okazaki", "Naoaki", ""], ["Inui", "Kentaro", ""]]}, {"id": "1511.08458", "submitter": "Keiron O'Shea", "authors": "Keiron O'Shea and Ryan Nash", "title": "An Introduction to Convolutional Neural Networks", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of machine learning has taken a dramatic twist in recent times,\nwith the rise of the Artificial Neural Network (ANN). These biologically\ninspired computational models are able to far exceed the performance of\nprevious forms of artificial intelligence in common machine learning tasks. One\nof the most impressive forms of ANN architecture is that of the Convolutional\nNeural Network (CNN). CNNs are primarily used to solve difficult image-driven\npattern recognition tasks and with their precise yet simple architecture,\noffers a simplified method of getting started with ANNs.\n  This document provides a brief introduction to CNNs, discussing recently\npublished papers and newly formed techniques in developing these brilliantly\nfantastic image recognition models. This introduction assumes you are familiar\nwith the fundamentals of ANNs and machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 17:45:01 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 18:06:03 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["O'Shea", "Keiron", ""], ["Nash", "Ryan", ""]]}, {"id": "1511.08486", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Jin Kyu Kim, Yi Zhou, Qirong Ho, Abhimanu Kumar, Yaoliang\n  Yu, Eric Xing", "title": "Distributed Machine Learning via Sufficient Factor Broadcasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix-parametrized models, including multiclass logistic regression and\nsparse coding, are used in machine learning (ML) applications ranging from\ncomputer vision to computational biology. When these models are applied to\nlarge-scale ML problems starting at millions of samples and tens of thousands\nof classes, their parameter matrix can grow at an unexpected rate, resulting in\nhigh parameter synchronization costs that greatly slow down distributed\nlearning. To address this issue, we propose a Sufficient Factor Broadcasting\n(SFB) computation model for efficient distributed learning of a large family of\nmatrix-parameterized models, which share the following property: the parameter\nupdate computed on each data sample is a rank-1 matrix, i.e., the outer product\nof two \"sufficient factors\" (SFs). By broadcasting the SFs among worker\nmachines and reconstructing the update matrices locally at each worker, SFB\nimproves communication efficiency --- communication costs are linear in the\nparameter matrix's dimensions, rather than quadratic --- without affecting\ncomputational correctness. We present a theoretical convergence analysis of\nSFB, and empirically corroborate its efficiency on four different\nmatrix-parametrized ML models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 19:42:39 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Xie", "Pengtao", ""], ["Kim", "Jin Kyu", ""], ["Zhou", "Yi", ""], ["Ho", "Qirong", ""], ["Kumar", "Abhimanu", ""], ["Yu", "Yaoliang", ""], ["Xing", "Eric", ""]]}, {"id": "1511.08495", "submitter": "Yangchen Pan", "authors": "Clement Gehring, Yangchen Pan, Martha White", "title": "Incremental Truncated LSTD", "comments": "Accepted to IJCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balancing between computational efficiency and sample efficiency is an\nimportant goal in reinforcement learning. Temporal difference (TD) learning\nalgorithms stochastically update the value function, with a linear time\ncomplexity in the number of features, whereas least-squares temporal difference\n(LSTD) algorithms are sample efficient but can be quadratic in the number of\nfeatures. In this work, we develop an efficient incremental low-rank\nLSTD({\\lambda}) algorithm that progresses towards the goal of better balancing\ncomputation and sample efficiency. The algorithm reduces the computation and\nstorage complexity to the number of features times the chosen rank parameter\nwhile summarizing past samples efficiently to nearly obtain the sample\ncomplexity of LSTD. We derive a simulation bound on the solution given by\ntruncated low-rank approximation, illustrating a bias- variance trade-off\ndependent on the choice of rank. We demonstrate that the algorithm effectively\nbalances computational complexity and sample efficiency for policy evaluation\nin a benchmark task and a high-dimensional energy allocation domain.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 20:37:09 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 18:40:20 GMT"}, {"version": "v3", "created": "Fri, 18 Nov 2016 05:58:06 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Gehring", "Clement", ""], ["Pan", "Yangchen", ""], ["White", "Martha", ""]]}, {"id": "1511.08498", "submitter": "Ke Li", "authors": "Ke Li, Bharath Hariharan, Jitendra Malik", "title": "Iterative Instance Segmentation", "comments": "13 pages, 10 figures; IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for pixel-wise labelling tasks generally disregard the\nunderlying structure of labellings, often leading to predictions that are\nvisually implausible. While incorporating structure into the model should\nimprove prediction quality, doing so is challenging - manually specifying the\nform of structural constraints may be impractical and inference often becomes\nintractable even if structural constraints are given. We sidestep this problem\nby reducing structured prediction to a sequence of unconstrained prediction\nproblems and demonstrate that this approach is capable of automatically\ndiscovering priors on shape, contiguity of region predictions and smoothness of\nregion contours from data without any a priori specification. On the instance\nsegmentation task, this method outperforms the state-of-the-art, achieving a\nmean $\\mathrm{AP}^{r}$ of 63.6% at 50% overlap and 43.3% at 70% overlap.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 20:51:17 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 19:55:31 GMT"}, {"version": "v3", "created": "Fri, 10 Jun 2016 18:48:10 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Li", "Ke", ""], ["Hariharan", "Bharath", ""], ["Malik", "Jitendra", ""]]}, {"id": "1511.08551", "submitter": "Xinyang Yi", "authors": "Xinyang Yi and Constantine Caramanis", "title": "Regularized EM Algorithms: A Unified Framework and Statistical\n  Guarantees", "comments": "53 pages, 3 figures. A shorter version appears in NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models are a fundamental modeling tool in machine learning\napplications, but they present significant computational and analytical\nchallenges. The popular EM algorithm and its variants, is a much used\nalgorithmic tool; yet our rigorous understanding of its performance is highly\nincomplete. Recently, work in Balakrishnan et al. (2014) has demonstrated that\nfor an important class of problems, EM exhibits linear local convergence. In\nthe high-dimensional setting, however, the M-step may not be well defined. We\naddress precisely this setting through a unified treatment using\nregularization. While regularization for high-dimensional problems is by now\nwell understood, the iterative EM algorithm requires a careful balancing of\nmaking progress towards the solution while identifying the right structure\n(e.g., sparsity or low-rank). In particular, regularizing the M-step using the\nstate-of-the-art high-dimensional prescriptions (e.g., Wainwright (2014)) is\nnot guaranteed to provide this balance. Our algorithm and analysis are linked\nin a way that reveals the balance between optimization and statistical errors.\nWe specialize our general framework to sparse gaussian mixture models,\nhigh-dimensional mixed regression, and regression with missing variables,\nobtaining statistical guarantees for each of these examples.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 03:46:36 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2015 09:54:59 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Yi", "Xinyang", ""], ["Caramanis", "Constantine", ""]]}, {"id": "1511.08552", "submitter": "Mark Bun", "authors": "Mark Bun and Kobbi Nissim and Uri Stemmer", "title": "Simultaneous Private Learning of Multiple Concepts", "comments": "29 pages. To appear in ITCS '16", "journal-ref": null, "doi": "10.1145/2840728.2840747", "report-no": null, "categories": "cs.DS cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the direct-sum problem in the context of differentially\nprivate PAC learning: What is the sample complexity of solving $k$ learning\ntasks simultaneously under differential privacy, and how does this cost compare\nto that of solving $k$ learning tasks without privacy? In our setting, an\nindividual example consists of a domain element $x$ labeled by $k$ unknown\nconcepts $(c_1,\\ldots,c_k)$. The goal of a multi-learner is to output $k$\nhypotheses $(h_1,\\ldots,h_k)$ that generalize the input examples.\n  Without concern for privacy, the sample complexity needed to simultaneously\nlearn $k$ concepts is essentially the same as needed for learning a single\nconcept. Under differential privacy, the basic strategy of learning each\nhypothesis independently yields sample complexity that grows polynomially with\n$k$. For some concept classes, we give multi-learners that require fewer\nsamples than the basic strategy. Unfortunately, however, we also give lower\nbounds showing that even for very simple concept classes, the sample cost of\nprivate multi-learning must grow polynomially in $k$.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 03:57:22 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Bun", "Mark", ""], ["Nissim", "Kobbi", ""], ["Stemmer", "Uri", ""]]}, {"id": "1511.08589", "submitter": "Raj Kumar Maity", "authors": "Chandrashekar Lakshmi Narayanan, Raj Kumar Maity and Shalabh Bhatnagar", "title": "Shaping Proto-Value Functions via Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we combine task-dependent reward shaping and task-independent\nproto-value functions to obtain reward dependent proto-value functions (RPVFs).\nIn constructing the RPVFs we are making use of the immediate rewards which are\navailable during the sampling phase but are not used in the PVF construction.\nWe show via experiments that learning with an RPVF based representation is\nbetter than learning with just reward shaping or PVFs. In particular, when the\nstate space is symmetrical and the rewards are asymmetrical, the RPVF capture\nthe asymmetry better than the PVFs.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 09:13:04 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Narayanan", "Chandrashekar Lakshmi", ""], ["Maity", "Raj Kumar", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1511.08681", "submitter": "Christos Dimitrakakis", "authors": "Aristide Tossou, Christos Dimitrakakis", "title": "Algorithms for Differentially Private Multi-Armed Bandits", "comments": null, "journal-ref": "AAAI 2016, Feb 2016, Phoenix, Arizona, United States", "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present differentially private algorithms for the stochastic Multi-Armed\nBandit (MAB) problem. This is a problem for applications such as adaptive\nclinical trials, experiment design, and user-targeted advertising where private\ninformation is connected to individual rewards. Our major contribution is to\nshow that there exist $(\\epsilon, \\delta)$ differentially private variants of\nUpper Confidence Bound algorithms which have optimal regret, $O(\\epsilon^{-1} +\n\\log T)$. This is a significant improvement over previous results, which only\nachieve poly-log regret $O(\\epsilon^{-2} \\log^{2} T)$, because of our use of a\nnovel interval-based mechanism. We also substantially improve the bounds of\nprevious family of algorithms which use a continual release mechanism.\nExperiments clearly validate our theoretical bounds.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 14:16:00 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Tossou", "Aristide", ""], ["Dimitrakakis", "Christos", ""]]}, {"id": "1511.08724", "submitter": "Tom Ameloot", "authors": "Tom J. Ameloot and Jan Van den Bussche", "title": "On the convergence of cycle detection for navigational reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a reinforcement learning framework where agents have to navigate\nfrom start states to goal states. We prove convergence of a cycle-detection\nlearning algorithm on a class of tasks that we call reducible. Reducible tasks\nhave an acyclic solution. We also syntactically characterize the form of the\nfinal policy. This characterization can be used to precisely detect the\nconvergence point in a simulation. Our result demonstrates that even simple\nalgorithms can be successful in learning a large class of nontrivial tasks. In\naddition, our framework is elementary in the sense that we only use basic\nconcepts to formally prove convergence.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 16:16:55 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2016 14:08:35 GMT"}], "update_date": "2016-01-06", "authors_parsed": [["Ameloot", "Tom J.", ""], ["Bussche", "Jan Van den", ""]]}, {"id": "1511.08762", "submitter": "Tijl De Bie", "authors": "Tijl De Bie, Jefrey Lijffijt, Raul Santos-Rodriguez, Bo Kang", "title": "Informative Data Projections: A Framework and Two Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for Projection Pursuit aim to facilitate the visual exploration of\nhigh-dimensional data by identifying interesting low-dimensional projections. A\nmajor challenge is the design of a suitable quality metric of projections,\ncommonly referred to as the projection index, to be maximized by the Projection\nPursuit algorithm. In this paper, we introduce a new information-theoretic\nstrategy for tackling this problem, based on quantifying the amount of\ninformation the projection conveys to a user given their prior beliefs about\nthe data. The resulting projection index is a subjective quantity, explicitly\ndependent on the intended user. As a useful illustration, we developed this\nidea for two particular kinds of prior beliefs. The first kind leads to PCA\n(Principal Component Analysis), shining new light on when PCA is (not)\nappropriate. The second kind leads to a novel projection index, the\nmaximization of which can be regarded as a robust variant of PCA. We show how\nthis projection index, though non-convex, can be effectively maximized using a\nmodified power method as well as using a semidefinite programming relaxation.\nThe usefulness of this new projection index is demonstrated in comparative\nempirical experiments against PCA and a popular Projection Pursuit method.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 17:53:46 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["De Bie", "Tijl", ""], ["Lijffijt", "Jefrey", ""], ["Santos-Rodriguez", "Raul", ""], ["Kang", "Bo", ""]]}, {"id": "1511.08779", "submitter": "Jaan Aru", "authors": "Ardi Tampuu, Tambet Matiisen, Dorian Kodelja, Ilya Kuzovkin, Kristjan\n  Korjus, Juhan Aru, Jaan Aru and Raul Vicente", "title": "Multiagent Cooperation and Competition with Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent systems appear in most social, economical, and political\nsituations. In the present work we extend the Deep Q-Learning Network\narchitecture proposed by Google DeepMind to multiagent environments and\ninvestigate how two agents controlled by independent Deep Q-Networks interact\nin the classic videogame Pong. By manipulating the classical rewarding scheme\nof Pong we demonstrate how competitive and collaborative behaviors emerge.\nCompetitive agents learn to play and score efficiently. Agents trained under\ncollaborative rewarding schemes find an optimal strategy to keep the ball in\nthe game as long as possible. We also describe the progression from competitive\nto collaborative behavior. The present work demonstrates that Deep Q-Networks\ncan become a practical tool for studying the decentralized learning of\nmultiagent systems living in highly complex environments.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 20:01:45 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Tampuu", "Ardi", ""], ["Matiisen", "Tambet", ""], ["Kodelja", "Dorian", ""], ["Kuzovkin", "Ilya", ""], ["Korjus", "Kristjan", ""], ["Aru", "Juhan", ""], ["Aru", "Jaan", ""], ["Vicente", "Raul", ""]]}, {"id": "1511.08842", "submitter": "Saiprasad Ravishankar", "authors": "Saiprasad Ravishankar, Raj Rao Nadakuditi, Jeffrey A. Fessler", "title": "Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) - The\n  $\\ell_0$ Method", "comments": "This work is cited by the IEEE Transactions on Computational Imaging\n  Paper arXiv:1511.06333 (DOI: 10.1109/TCI.2017.2697206)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sparsity of natural signals and images in a transform domain or\ndictionary has been extensively exploited in several applications such as\ncompression, denoising and inverse problems. More recently, data-driven\nadaptation of synthesis dictionaries has shown promise in many applications\ncompared to fixed or analytical dictionary models. However, dictionary learning\nproblems are typically non-convex and NP-hard, and the usual alternating\nminimization approaches for these problems are often computationally expensive,\nwith the computations dominated by the NP-hard synthesis sparse coding step. In\nthis work, we investigate an efficient method for $\\ell_{0}$ \"norm\"-based\ndictionary learning by first approximating the training data set with a sum of\nsparse rank-one matrices and then using a block coordinate descent approach to\nestimate the unknowns. The proposed block coordinate descent algorithm involves\nefficient closed-form solutions. In particular, the sparse coding step involves\na simple form of thresholding. We provide a convergence analysis for the\nproposed block coordinate descent approach. Our numerical experiments show the\npromising performance and significant speed-ups provided by our method over the\nclassical K-SVD scheme in sparse signal representation and image denoising.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 22:32:43 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 02:31:13 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Ravishankar", "Saiprasad", ""], ["Nadakuditi", "Raj Rao", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1511.08862", "submitter": "Joydip Ghosh", "authors": "Ehsan Zahedinejad, Joydip Ghosh, Barry C. Sanders", "title": "Designing High-Fidelity Single-Shot Three-Qubit Gates: A Machine\n  Learning Approach", "comments": "18 pages, 13 figures. Accepted for publication in Phys. Rev. Applied", "journal-ref": "Phys. Rev. Applied 6, 054005 (2016)", "doi": "10.1103/PhysRevApplied.6.054005", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three-qubit quantum gates are key ingredients for quantum error correction\nand quantum information processing. We generate quantum-control procedures to\ndesign three types of three-qubit gates, namely Toffoli, Controlled-Not-Not and\nFredkin gates. The design procedures are applicable to a system comprising\nthree nearest-neighbor-coupled superconducting artificial atoms. For each\nthree-qubit gate, the numerical simulation of the proposed scheme achieves\n99.9% fidelity, which is an accepted threshold fidelity for fault-tolerant\nquantum computing. We test our procedure in the presence of decoherence-induced\nnoise as well as show its robustness against random external noise generated by\nthe control electronics. The three-qubit gates are designed via the machine\nlearning algorithm called Subspace-Selective Self-Adaptive Differential\nEvolution (SuSSADE).\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2015 02:09:28 GMT"}, {"version": "v2", "created": "Sun, 23 Oct 2016 15:33:52 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zahedinejad", "Ehsan", ""], ["Ghosh", "Joydip", ""], ["Sanders", "Barry C.", ""]]}, {"id": "1511.08951", "submitter": "Basura Fernando", "authors": "Basura Fernando, Efstratios Gavves, Damien Muselet, Tinne Tuytelaars", "title": "MidRank: Learning to rank based on subsequences", "comments": "To appear in ICCV 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a supervised learning to rank algorithm that effectively orders\nimages by exploiting the structure in image sequences. Most often in the\nsupervised learning to rank literature, ranking is approached either by\nanalyzing pairs of images or by optimizing a list-wise surrogate loss function\non full sequences. In this work we propose MidRank, which learns from\nmoderately sized sub-sequences instead. These sub-sequences contain useful\nstructural ranking information that leads to better learnability during\ntraining and better generalization during testing. By exploiting sub-sequences,\nthe proposed MidRank improves ranking accuracy considerably on an extensive\narray of image ranking applications and datasets.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2015 00:47:19 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Fernando", "Basura", ""], ["Gavves", "Efstratios", ""], ["Muselet", "Damien", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1511.08963", "submitter": "Bryon Aragam", "authors": "Bryon Aragam, Arash A. Amini, Qing Zhou", "title": "Learning Directed Acyclic Graphs with Penalized Neighbourhood Regression", "comments": "54 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a family of regularized score-based estimators for learning the\nstructure of a directed acyclic graph (DAG) for a multivariate normal\ndistribution from high-dimensional data with $p\\gg n$. Our main results\nestablish support recovery guarantees and deviation bounds for a family of\npenalized least-squares estimators under concave regularization without\nassuming prior knowledge of a variable ordering. These results apply to a\nvariety of practical situations that allow for arbitrary nondegenerate\ncovariance structures as well as many popular regularizers including the MCP,\nSCAD, $\\ell_{0}$ and $\\ell_{1}$. The proof relies on interpreting a DAG as a\nrecursive linear structural equation model, which reduces the estimation\nproblem to a series of neighbourhood regressions. We provide a novel\nstatistical analysis of these neighbourhood problems, establishing uniform\ncontrol over the superexponential family of neighbourhoods associated with a\nGaussian distribution. We then apply these results to study the statistical\nproperties of score-based DAG estimators, learning causal DAGs, and inferring\nconditional independence relations via graphical models. Our results\nyield---for the first time---finite-sample guarantees for structure learning of\nGaussian DAGs in high-dimensions via score-based estimation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2015 03:52:28 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2015 19:41:19 GMT"}, {"version": "v3", "created": "Mon, 2 Oct 2017 02:59:27 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Aragam", "Bryon", ""], ["Amini", "Arash A.", ""], ["Zhou", "Qing", ""]]}, {"id": "1511.08967", "submitter": "Lisa Lee", "authors": "Lisa Lee", "title": "Robotic Search & Rescue via Online Multi-task Reinforcement Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a general and well-known method that a robot\ncan use to learn an optimal control policy to solve a particular task. We would\nlike to build a versatile robot that can learn multiple tasks, but using RL for\neach of them would be prohibitively expensive in terms of both time and\nwear-and-tear on the robot. To remedy this problem, we use the Policy Gradient\nEfficient Lifelong Learning Algorithm (PG-ELLA), an online multi-task RL\nalgorithm that enables the robot to efficiently learn multiple consecutive\ntasks by sharing knowledge between these tasks to accelerate learning and\nimprove performance. We implemented and evaluated three RL methods--Q-learning,\npolicy gradient RL, and PG-ELLA--on a ground robot whose task is to find a\ntarget object in an environment under different surface conditions. In this\npaper, we discuss our implementations as well as present an empirical analysis\nof their learning performance.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2015 04:33:51 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Lee", "Lisa", ""]]}, {"id": "1511.08987", "submitter": "Napas Udomsak", "authors": "Napas Udomsak", "title": "How do the naive Bayes classifier and the Support Vector Machine compare\n  in their ability to forecast the Stock Exchange of Thailand?", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This essay investigates the question of how the naive Bayes classifier and\nthe support vector machine compare in their ability to forecast the Stock\nExchange of Thailand. The theory behind the SVM and the naive Bayes classifier\nis explored. The algorithms are trained using data from the month of January\n2010, extracted from the MarketWatch.com website. Input features are selected\nbased on previous studies of the SET100 Index. The Weka 3 software is used to\ncreate models from the labeled training data. Mean squared error and proportion\nof correctly classified instances, and a number of other error measurements are\nthe used to compare the two algorithms. This essay shows that these two\nalgorithms are currently not advanced enough to accurately model the stock\nexchange. Nevertheless, the naive Bayes is better than the support vector\nmachine at predicting the Stock Exchange of Thailand.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2015 09:57:42 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Udomsak", "Napas", ""]]}, {"id": "1511.09058", "submitter": "Vladislav Malyshkin", "authors": "Vladislav Gennadievich Malyshkin", "title": "Multiple-Instance Learning: Radon-Nikodym Approach to Distribution\n  Regression Problem", "comments": "Gramar fixes. Off by one error in eigenvalues problem fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For distribution regression problem, where a bag of $x$--observations is\nmapped to a single $y$ value, a one--step solution is proposed. The problem of\nrandom distribution to random value is transformed to random vector to random\nvalue by taking distribution moments of $x$ observations in a bag as random\nvector. Then Radon--Nikodym or least squares theory can be applied, what give\n$y(x)$ estimator. The probability distribution of $y$ is also obtained, what\nrequires solving generalized eigenvalues problem, matrix spectrum (not\ndepending on $x$) give possible $y$ outcomes and depending on $x$ probabilities\nof outcomes can be obtained by projecting the distribution with fixed $x$ value\n(delta--function) to corresponding eigenvector. A library providing numerically\nstable polynomial basis for these calculations is available, what make the\nproposed approach practical.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2015 18:41:02 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 11:02:01 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Malyshkin", "Vladislav Gennadievich", ""]]}, {"id": "1511.09099", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Enrico De Santis, Hedieh Montazeri, Parisa\n  Naraei, Alireza Sadeghian", "title": "Position paper: a general framework for applying machine learning\n  techniques in operating room", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper we describe a general framework for applying machine\nlearning and pattern recognition techniques in healthcare. In particular, we\nare interested in providing an automated tool for monitoring and incrementing\nthe level of awareness in the operating room and for identifying human errors\nwhich occur during the laparoscopy surgical operation. The framework that we\npresent is divided in three different layers: each layer implements algorithms\nwhich have an increasing level of complexity and which perform functionality\nwith an higher degree of abstraction. In the first layer, raw data collected\nfrom sensors in the operating room during surgical operation, they are\npre-processed and aggregated. The results of this initial phase are transferred\nto a second layer, which implements pattern recognition techniques and extract\nrelevant features from the data. Finally, in the last layer, expert systems are\nemployed to take high level decisions, which represent the final output of the\nsystem.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2015 21:58:30 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["De Santis", "Enrico", ""], ["Montazeri", "Hedieh", ""], ["Naraei", "Parisa", ""], ["Sadeghian", "Alireza", ""]]}, {"id": "1511.09123", "submitter": "Ka-Chun Wong", "authors": "Ka-Chun Wong", "title": "A Short Survey on Data Clustering Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapidly increasing data, clustering algorithms are important tools for\ndata analytics in modern research. They have been successfully applied to a\nwide range of domains; for instance, bioinformatics, speech recognition, and\nfinancial analysis. Formally speaking, given a set of data instances, a\nclustering algorithm is expected to divide the set of data instances into the\nsubsets which maximize the intra-subset similarity and inter-subset\ndissimilarity, where a similarity measure is defined beforehand. In this work,\nthe state-of-the-arts clustering algorithms are reviewed from design concept to\nmethodology; Different clustering paradigms are discussed. Advanced clustering\nalgorithms are also discussed. After that, the existing clustering evaluation\nmetrics are reviewed. A summary with future insights is provided at the end.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 08:02:37 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Wong", "Ka-Chun", ""]]}, {"id": "1511.09128", "submitter": "Haibing Wu", "authors": "Haibing Wu, Yiwei Gu, Shangdi Sun and Xiaodong Gu", "title": "Aspect-based Opinion Summarization with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers Aspect-based Opinion Summarization (AOS) of reviews on\nparticular products. To enable real applications, an AOS system needs to\naddress two core subtasks, aspect extraction and sentiment classification. Most\nexisting approaches to aspect extraction, which use linguistic analysis or\ntopic modeling, are general across different products but not precise enough or\nsuitable for particular products. Instead we take a less general but more\nprecise scheme, directly mapping each review sentence into pre-defined aspects.\nTo tackle aspect mapping and sentiment classification, we propose two\nConvolutional Neural Network (CNN) based methods, cascaded CNN and multitask\nCNN. Cascaded CNN contains two levels of convolutional networks. Multiple CNNs\nat level 1 deal with aspect mapping task, and a single CNN at level 2 deals\nwith sentiment classification. Multitask CNN also contains multiple aspect CNNs\nand a sentiment CNN, but different networks share the same word embeddings.\nExperimental results indicate that both cascaded and multitask CNNs outperform\nSVM-based methods by large margins. Multitask CNN generally performs better\nthan cascaded CNN.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 01:46:15 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Wu", "Haibing", ""], ["Gu", "Yiwei", ""], ["Sun", "Shangdi", ""], ["Gu", "Xiaodong", ""]]}, {"id": "1511.09159", "submitter": "Yangyang Xu", "authors": "Yangyang Xu, Ioannis Akrotirianakis, Amit Chakraborty", "title": "Proximal gradient method for huberized support vector machine", "comments": "in Pattern analysis and application, 2015", "journal-ref": null, "doi": "10.1007/s10044-015-0485-z", "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Support Vector Machine (SVM) has been used in a wide variety of\nclassification problems. The original SVM uses the hinge loss function, which\nis non-differentiable and makes the problem difficult to solve in particular\nfor regularized SVMs, such as with $\\ell_1$-regularization. This paper\nconsiders the Huberized SVM (HSVM), which uses a differentiable approximation\nof the hinge loss function. We first explore the use of the Proximal Gradient\n(PG) method to solving binary-class HSVM (B-HSVM) and then generalize it to\nmulti-class HSVM (M-HSVM). Under strong convexity assumptions, we show that our\nalgorithm converges linearly. In addition, we give a finite convergence result\nabout the support of the solution, based on which we further accelerate the\nalgorithm by a two-stage method. We present extensive numerical experiments on\nboth synthetic and real datasets which demonstrate the superiority of our\nmethods over some state-of-the-art methods for both binary- and multi-class\nSVMs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 05:02:02 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Xu", "Yangyang", ""], ["Akrotirianakis", "Ioannis", ""], ["Chakraborty", "Amit", ""]]}, {"id": "1511.09180", "submitter": "Xiaochuan Zhao", "authors": "Ali H. Sayed and Xiaochuan Zhao", "title": "Asynchronous adaptive networks", "comments": "To appear as book chapter in the edited volume entitled Cooperative\n  and Graph Signal Processing, P. Djuric and C. Richard, editors, Elsevier,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent article [1] we surveyed advances related to adaptation, learning,\nand optimization over synchronous networks. Various distributed strategies were\ndiscussed that enable a collection of networked agents to interact locally in\nresponse to streaming data and to continually learn and adapt to track drifts\nin the data and models. Under reasonable technical conditions on the data, the\nadaptive networks were shown to be mean-square stable in the slow adaptation\nregime, and their mean-square-error performance and convergence rate were\ncharacterized in terms of the network topology and data statistical moments\n[2]. Classical results for single-agent adaptation and learning were recovered\nas special cases. Following the works [3]-[5], this chapter complements the\nexposition from [1] and extends the results to asynchronous networks. The\noperation of this class of networks can be subject to various sources of\nuncertainties that influence their dynamic behavior, including randomly\nchanging topologies, random link failures, random data arrival times, and\nagents turning on and off randomly. In an asynchronous environment, agents may\nstop updating their solutions or may stop sending or receiving information in a\nrandom manner and without coordination with other agents. The presentation will\nreveal that the mean-square-error performance of asynchronous networks remains\nlargely unaltered compared to synchronous networks. The results justify the\nremarkable resilience of cooperative networks in the face of random events.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 07:09:21 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 03:15:26 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Sayed", "Ali H.", ""], ["Zhao", "Xiaochuan", ""]]}, {"id": "1511.09196", "submitter": "Hamid Kameli", "authors": "Hamid Kameli", "title": "Non-adaptive Group Testing on Graphs", "comments": null, "journal-ref": "Discrete Mathematics & Theoretical Computer Science, Vol. 20 no.\n  1, Combinatorics (March 26, 2018) dmtcs:4351", "doi": "10.23638/DMTCS-20-1-9", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grebinski and Kucherov (1998) and Alon et al. (2004-2005) study the problem\nof learning a hidden graph for some especial cases, such as hamiltonian cycle,\ncliques, stars, and matchings. This problem is motivated by problems in\nchemical reactions, molecular biology and genome sequencing.\n  In this paper, we present a generalization of this problem. Precisely, we\nconsider a graph G and a subgraph H of G and we assume that G contains exactly\none defective subgraph isomorphic to H. The goal is to find the defective\nsubgraph by testing whether an induced subgraph contains an edge of the\ndefective subgraph, with the minimum number of tests. We present an upper bound\nfor the number of tests to find the defective subgraph by using the symmetric\nand high probability variation of Lov\\'asz Local Lemma.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 08:26:10 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 10:11:58 GMT"}, {"version": "v3", "created": "Sun, 30 Apr 2017 15:14:24 GMT"}, {"version": "v4", "created": "Sat, 30 Dec 2017 12:07:46 GMT"}, {"version": "v5", "created": "Sun, 4 Mar 2018 09:39:48 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kameli", "Hamid", ""]]}, {"id": "1511.09249", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "On Learning to Think: Algorithmic Information Theory for Novel\n  Combinations of Reinforcement Learning Controllers and Recurrent Neural World\n  Models", "comments": "36 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:1404.7828", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the general problem of reinforcement learning (RL) in\npartially observable environments. In 2013, our large RL recurrent neural\nnetworks (RNNs) learned from scratch to drive simulated cars from\nhigh-dimensional video input. However, real brains are more powerful in many\nways. In particular, they learn a predictive model of their initially unknown\nenvironment, and somehow use it for abstract (e.g., hierarchical) planning and\nreasoning. Guided by algorithmic information theory, we describe RNN-based AIs\n(RNNAIs) designed to do the same. Such an RNNAI can be trained on never-ending\nsequences of tasks, some of them provided by the user, others invented by the\nRNNAI itself in a curious, playful fashion, to improve its RNN-based world\nmodel. Unlike our previous model-building RNN-based RL machines dating back to\n1990, the RNNAI learns to actively query its model for abstract reasoning and\nplanning and decision making, essentially \"learning to think.\" The basic ideas\nof this report can be applied to many other cases where one RNN-like system\nexploits the algorithmic information content of another. They are taken from a\ngrant proposal submitted in Fall 2014, and also explain concepts such as\n\"mirror neurons.\" Experimental results will be described in separate papers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 11:35:26 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}, {"id": "1511.09263", "submitter": "Kui Yu", "authors": "Kui Yu, Xindong Wu, Wei Ding, and Jian Pei", "title": "Scalable and Accurate Online Feature Selection for Big Data", "comments": "This paper has been accepted by the journal of ACM Transactions on\n  Knowledge Discovery from Data (TKDD) and will be available soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is important in many big data applications. Two critical\nchallenges closely associate with big data. Firstly, in many big data\napplications, the dimensionality is extremely high, in millions, and keeps\ngrowing. Secondly, big data applications call for highly scalable feature\nselection algorithms in an online manner such that each feature can be\nprocessed in a sequential scan. We present SAOLA, a Scalable and Accurate\nOnLine Approach for feature selection in this paper. With a theoretical\nanalysis on bounds of the pairwise correlations between features, SAOLA employs\nnovel pairwise comparison techniques and maintain a parsimonious model over\ntime in an online manner. Furthermore, to deal with upcoming features that\narrive by groups, we extend the SAOLA algorithm, and then propose a new\ngroup-SAOLA algorithm for online group feature selection. The group-SAOLA\nalgorithm can online maintain a set of feature groups that is sparse at the\nlevels of both groups and individual features simultaneously. An empirical\nstudy using a series of benchmark real data sets shows that our two algorithms,\nSAOLA and group-SAOLA, are scalable on data sets of extremely high\ndimensionality, and have superior performance over the state-of-the-art feature\nselection methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 12:11:43 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2016 01:04:16 GMT"}, {"version": "v3", "created": "Mon, 25 Jul 2016 03:11:09 GMT"}, {"version": "v4", "created": "Thu, 28 Jul 2016 01:49:01 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Yu", "Kui", ""], ["Wu", "Xindong", ""], ["Ding", "Wei", ""], ["Pei", "Jian", ""]]}, {"id": "1511.09337", "submitter": "Yu-An Chung", "authors": "Yu-An Chung, Hsuan-Tien Lin, Shao-Wen Yang", "title": "Cost-aware Pre-training for Multiclass Cost-sensitive Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been one of the most prominent machine learning techniques\nnowadays, being the state-of-the-art on a broad range of applications where\nautomatic feature extraction is needed. Many such applications also demand\nvarying costs for different types of mis-classification errors, but it is not\nclear whether or how such cost information can be incorporated into deep\nlearning to improve performance. In this work, we propose a novel cost-aware\nalgorithm that takes into account the cost information into not only the\ntraining stage but also the pre-training stage of deep learning. The approach\nallows deep learning to conduct automatic feature extraction with the cost\ninformation effectively. Extensive experimental results demonstrate that the\nproposed approach outperforms other deep learning models that do not digest the\ncost information in the pre-training stage.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 14:54:28 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2016 07:30:13 GMT"}, {"version": "v3", "created": "Tue, 24 May 2016 04:00:11 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Chung", "Yu-An", ""], ["Lin", "Hsuan-Tien", ""], ["Yang", "Shao-Wen", ""]]}]