[{"id": "1801.00025", "submitter": "Xiaodan Li", "authors": "Wangyan Feng, Shuning Wu, Xiaodan Li, Kevin Kunkle", "title": "A Deep Belief Network Based Machine Learning System for Risky Host\n  Detection", "comments": "10 pages, 10 figures. The paper is accepted by IEEE Conference on\n  Communications and Network Security 2017. However, it is not published\n  because either of the authors showed up in the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To assure cyber security of an enterprise, typically SIEM (Security\nInformation and Event Management) system is in place to normalize security\nevent from different preventive technologies and flag alerts. Analysts in the\nsecurity operation center (SOC) investigate the alerts to decide if it is truly\nmalicious or not. However, generally the number of alerts is overwhelming with\nmajority of them being false positive and exceeding the SOC's capacity to\nhandle all alerts. There is a great need to reduce the false positive rate as\nmuch as possible. While most previous research focused on network intrusion\ndetection, we focus on risk detection and propose an intelligent Deep Belief\nNetwork machine learning system. The system leverages alert information,\nvarious security logs and analysts' investigation results in a real enterprise\nenvironment to flag hosts that have high likelihood of being compromised. Text\nmining and graph based method are used to generate targets and create features\nfor machine learning. In the experiment, Deep Belief Network is compared with\nother machine learning algorithms, including multi-layer neural network, random\nforest, support vector machine and logistic regression. Results on real\nenterprise data indicate that the deep belief network machine learning system\nperforms better than other algorithms for our problem and is six times more\neffective than current rule-based system. We also implement the whole system\nfrom data collection, label creation, feature engineering to host score\ngeneration in a real enterprise production environment.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 19:46:09 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Feng", "Wangyan", ""], ["Wu", "Shuning", ""], ["Li", "Xiaodan", ""], ["Kunkle", "Kevin", ""]]}, {"id": "1801.00056", "submitter": "Boris Belousov", "authors": "Boris Belousov, Jan Peters", "title": "f-Divergence constrained policy improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure stability of learning, state-of-the-art generalized policy\niteration algorithms augment the policy improvement step with a trust region\nconstraint bounding the information loss. The size of the trust region is\ncommonly determined by the Kullback-Leibler (KL) divergence, which not only\ncaptures the notion of distance well but also yields closed-form solutions. In\nthis paper, we consider a more general class of f-divergences and derive the\ncorresponding policy update rules. The generic solution is expressed through\nthe derivative of the convex conjugate function to f and includes the KL\nsolution as a special case. Within the class of f-divergences, we further focus\non a one-parameter family of $\\alpha$-divergences to study effects of the\nchoice of divergence on policy improvement. Previously known as well as new\npolicy updates emerge for different values of $\\alpha$. We show that every type\nof policy update comes with a compatible policy evaluation resulting from the\nchosen f-divergence. Interestingly, the mean-squared Bellman error minimization\nis closely related to policy evaluation with the Pearson $\\chi^2$-divergence\npenalty, while the KL divergence results in the soft-max policy update and a\nlog-sum-exp critic. We carry out asymptotic analysis of the solutions for\ndifferent values of $\\alpha$ and demonstrate the effects of using different\ndivergence functions on a multi-armed bandit problem and on common standard\nreinforcement learning problems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 23:07:26 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 11:36:12 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Belousov", "Boris", ""], ["Peters", "Jan", ""]]}, {"id": "1801.00062", "submitter": "Jo\\~ao Sacramento", "authors": "Jo\\~ao Sacramento and Rui Ponte Costa and Yoshua Bengio and Walter\n  Senn", "title": "Dendritic error backpropagation in deep cortical microcircuits", "comments": "27 pages, 5 figures, 10 pages supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animal behaviour depends on learning to associate sensory stimuli with the\ndesired motor command. Understanding how the brain orchestrates the necessary\nsynaptic modifications across different brain areas has remained a longstanding\npuzzle. Here, we introduce a multi-area neuronal network model in which\nsynaptic plasticity continuously adapts the network towards a global desired\noutput. In this model synaptic learning is driven by a local dendritic\nprediction error that arises from a failure to predict the top-down input given\nthe bottom-up activities. Such errors occur at apical dendrites of pyramidal\nneurons where both long-range excitatory feedback and local inhibitory\npredictions are integrated. When local inhibition fails to match excitatory\nfeedback an error occurs which triggers plasticity at bottom-up synapses at\nbasal dendrites of the same pyramidal neurons. We demonstrate the learning\ncapabilities of the model in a number of tasks and show that it approximates\nthe classical error backpropagation algorithm. Finally, complementing this\ncortical circuit with a disinhibitory mechanism enables attention-like stimulus\ndenoising and generation. Our framework makes several experimental predictions\non the function of dendritic integration and cortical microcircuits, is\nconsistent with recent observations of cross-area learning, and suggests a\nbiological implementation of deep learning.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 00:16:56 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Sacramento", "Jo\u00e3o", ""], ["Costa", "Rui Ponte", ""], ["Bengio", "Yoshua", ""], ["Senn", "Walter", ""]]}, {"id": "1801.00085", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Chunyuan Li, Changyou Chen, Lawrence Carin", "title": "Learning Structural Weight Uncertainty for Sequential Decision-Making", "comments": "Accepted by AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning probability distributions on the weights of neural networks (NNs)\nhas recently proven beneficial in many applications. Bayesian methods, such as\nStein variational gradient descent (SVGD), offer an elegant framework to reason\nabout NN model uncertainty. However, by assuming independent Gaussian priors\nfor the individual NN weights (as often applied), SVGD does not impose prior\nknowledge that there is often structural information (dependence) among\nweights. We propose efficient posterior learning of structural weight\nuncertainty, within an SVGD framework, by employing matrix variate Gaussian\npriors on NN parameters. We further investigate the learned structural\nuncertainty in sequential decision-making problems, including contextual\nbandits and reinforcement learning. Experiments on several synthetic and real\ndatasets indicate the superiority of our model, compared with state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 04:34:34 GMT"}, {"version": "v2", "created": "Mon, 2 Apr 2018 01:06:13 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Li", "Chunyuan", ""], ["Chen", "Changyou", ""], ["Carin", "Lawrence", ""]]}, {"id": "1801.00096", "submitter": "Timothy Rozario", "authors": "Timothy Rozario, Troy Long, Mingli Chen, Weiguo Lu and Steve Jiang", "title": "Towards automated patient data cleaning using deep learning: A\n  feasibility study on the standardization of organ labeling", "comments": "17 pages, 7 figures, 3 tables, 39 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data cleaning consumes about 80% of the time spent on data analysis for\nclinical research projects. This is a much bigger problem in the era of big\ndata and machine learning in the field of medicine where large volumes of data\nare being generated. We report an initial effort towards automated patient data\ncleaning using deep learning: the standardization of organ labeling in\nradiation therapy. Organs are often labeled inconsistently at different\ninstitutions (sometimes even within the same institution) and at different time\nperiods, which poses a problem for clinical research, especially for\nmulti-institutional collaborative clinical research where the acquired patient\ndata is not being used effectively. We developed a convolutional neural network\n(CNN) to automatically identify each organ in the CT image and then label it\nwith the standardized nomenclature presented at AAPM Task Group 263. We tested\nthis model on the CT images of 54 patients with prostate and 100 patients with\nhead and neck cancer who previously received radiation therapy. The model\nachieved 100% accuracy in detecting organs and assigning standardized labels\nfor the patients tested. This work shows the feasibility of using deep learning\nin patient data cleaning that enables standardized datasets to be generated for\neffective intra- and interinstitutional collaborative clinical research.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 07:56:46 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Rozario", "Timothy", ""], ["Long", "Troy", ""], ["Chen", "Mingli", ""], ["Lu", "Weiguo", ""], ["Jiang", "Steve", ""]]}, {"id": "1801.00101", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Satyen Kale, Mehryar Mohri, Karthik Sridharan", "title": "Parameter-free online learning via model selection", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an efficient algorithmic framework for model selection in online\nlearning, also known as parameter-free online learning. Departing from previous\nwork, which has focused on highly structured function classes such as nested\nballs in Hilbert space, we propose a generic meta-algorithm framework that\nachieves online model selection oracle inequalities under minimal structural\nassumptions. We give the first computationally efficient parameter-free\nalgorithms that work in arbitrary Banach spaces under mild smoothness\nassumptions; previous results applied only to Hilbert spaces. We further derive\nnew oracle inequalities for matrix classes, non-nested convex sets, and\n$\\mathbb{R}^{d}$ with generic regularizers. Finally, we generalize these\nresults by providing oracle inequalities for arbitrary non-linear classes in\nthe online supervised learning model. These results are all derived through a\nunified meta-algorithm scheme using a novel \"multi-scale\" algorithm for\nprediction with expert advice based on random playout, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 08:21:19 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 22:25:05 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Foster", "Dylan J.", ""], ["Kale", "Satyen", ""], ["Mohri", "Mehryar", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1801.00132", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Won-Yong Shin, Andreas Spitz", "title": "Community Detection in Partially Observable Social Networks", "comments": "24 pages, 8 figures, 5 tables; to appear in the ACM Transactions on\n  Knowledge Discovery from Data (Please cite our journal version that will\n  appear in an upcoming issue.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of community structures in social networks has gained\nsignificant attention since it is a fundamental problem in understanding the\nnetworks' topology and functions. However, most social network data are\ncollected from partially observable networks with both missing nodes and edges.\nIn this paper, we address a new problem of detecting overlapping community\nstructures in the context of such an incomplete network, where communities in\nthe network are allowed to overlap since nodes belong to multiple communities\nat once. To solve this problem, we introduce KroMFac, a new framework that\nconducts community detection via regularized nonnegative matrix factorization\n(NMF) based on the Kronecker graph model. Specifically, from an inferred\nKronecker generative parameter matrix, we first estimate the missing part of\nthe network. As our major contribution to the proposed framework, to improve\ncommunity detection accuracy, we then characterize and select influential nodes\n(which tend to have high degrees) by ranking, and add them to the existing\ngraph. Finally, we uncover the community structures by solving the regularized\nNMF-aided optimization problem in terms of maximizing the likelihood of the\nunderlying graph. Furthermore, adopting normalized mutual information (NMI), we\nempirically show superiority of our KroMFac approach over two baseline schemes\nby using both synthetic and real-world networks.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 13:22:29 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 03:49:03 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 08:58:08 GMT"}, {"version": "v4", "created": "Tue, 9 Apr 2019 04:32:51 GMT"}, {"version": "v5", "created": "Thu, 3 Oct 2019 13:52:59 GMT"}, {"version": "v6", "created": "Tue, 31 Mar 2020 01:28:25 GMT"}, {"version": "v7", "created": "Mon, 20 Apr 2020 02:08:25 GMT"}, {"version": "v8", "created": "Fri, 16 Apr 2021 07:47:32 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Tran", "Cong", ""], ["Shin", "Won-Yong", ""], ["Spitz", "Andreas", ""]]}, {"id": "1801.00171", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas, Mike Davies, Pierre Vandergheynst", "title": "PAC-Bayesian Margin Bounds for Convolutional Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1707.09564 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the generalization error of deep neural networks has been analyzed\nthrough the PAC-Bayesian framework, for the case of fully connected layers. We\nadapt this approach to the convolutional setting.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 18:11:59 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 09:27:47 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Pitas", "Konstantinos", ""], ["Davies", "Mike", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1801.00173", "submitter": "Qianli Liao", "authors": "Tomaso Poggio, Kenji Kawaguchi, Qianli Liao, Brando Miranda, Lorenzo\n  Rosasco, Xavier Boix, Jack Hidary, Hrushikesh Mhaskar", "title": "Theory of Deep Learning III: explaining the non-overfitting puzzle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main puzzle of deep networks revolves around the absence of overfitting\ndespite large overparametrization and despite the large capacity demonstrated\nby zero training error on randomly labeled data. In this note, we show that the\ndynamics associated to gradient descent minimization of nonlinear networks is\ntopologically equivalent, near the asymptotically stable minima of the\nempirical error, to linear gradient system in a quadratic potential with a\ndegenerate (for square loss) or almost degenerate (for logistic or crossentropy\nloss) Hessian. The proposition depends on the qualitative theory of dynamical\nsystems and is supported by numerical results. Our main propositions extend to\ndeep nonlinear networks two properties of gradient descent for linear networks,\nthat have been recently established (1) to be key to their generalization\nproperties: 1. Gradient descent enforces a form of implicit regularization\ncontrolled by the number of iterations, and asymptotically converges to the\nminimum norm solution for appropriate initial conditions of gradient descent.\nThis implies that there is usually an optimum early stopping that avoids\noverfitting of the loss. This property, valid for the square loss and many\nother loss functions, is relevant especially for regression. 2. For\nclassification, the asymptotic convergence to the minimum norm solution implies\nconvergence to the maximum margin solution which guarantees good classification\nerror for \"low noise\" datasets. This property holds for loss functions such as\nthe logistic and cross-entropy loss independently of the initial conditions.\nThe robustness to overparametrization has suggestive implications for the\nrobustness of the architecture of deep convolutional networks with respect to\nthe curse of dimensionality.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 18:27:35 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 08:54:12 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Poggio", "Tomaso", ""], ["Kawaguchi", "Kenji", ""], ["Liao", "Qianli", ""], ["Miranda", "Brando", ""], ["Rosasco", "Lorenzo", ""], ["Boix", "Xavier", ""], ["Hidary", "Jack", ""], ["Mhaskar", "Hrushikesh", ""]]}, {"id": "1801.00209", "submitter": "Xiangyu Zhao", "authors": "Xiangyu Zhao and Liang Zhang and Long Xia and Zhuoye Ding and Dawei\n  Yin and Jiliang Tang", "title": "Deep Reinforcement Learning for List-wise Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems play a crucial role in mitigating the problem of\ninformation overload by suggesting users' personalized items or services. The\nvast majority of traditional recommender systems consider the recommendation\nprocedure as a static process and make recommendations following a fixed\nstrategy. In this paper, we propose a novel recommender system with the\ncapability of continuously improving its strategies during the interactions\nwith users. We model the sequential interactions between users and a\nrecommender system as a Markov Decision Process (MDP) and leverage\nReinforcement Learning (RL) to automatically learn the optimal strategies via\nrecommending trial-and-error items and receiving reinforcements of these items\nfrom users' feedbacks. In particular, we introduce an online user-agent\ninteracting environment simulator, which can pre-train and evaluate model\nparameters offline before applying the model online. Moreover, we validate the\nimportance of list-wise recommendations during the interactions between users\nand agent, and develop a novel approach to incorporate them into the proposed\nframework LIRD for list-wide recommendations. The experimental results based on\na real-world e-commerce dataset demonstrate the effectiveness of the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 23:30:36 GMT"}, {"version": "v2", "created": "Fri, 5 Jan 2018 14:57:45 GMT"}, {"version": "v3", "created": "Thu, 27 Jun 2019 06:29:27 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Zhang", "Liang", ""], ["Xia", "Long", ""], ["Ding", "Zhuoye", ""], ["Yin", "Dawei", ""], ["Tang", "Jiliang", ""]]}, {"id": "1801.00282", "submitter": "Zhou Honggang", "authors": "Jie Jia, Honggang Zhou, Yunchun Li", "title": "Using Deep Neural Network Approximate Bayesian Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method to approximate posterior probabilities of Bayesian\nNetwork using Deep Neural Network. Experiment results on several public\nBayesian Network datasets shows that Deep Neural Network is capable of learning\njoint probability distri- bution of Bayesian Network by learning from a few\nobservation and posterior probability distribution pairs with high accuracy.\nCompared with traditional approximate method likelihood weighting sampling\nalgorithm, our method is much faster and gains higher accuracy in medium sized\nBayesian Network. Another advantage of our method is that our method can be\nparallelled much easier in GPU without extra effort. We also ex- plored the\nconnection between the accuracy of our model and the number of training\nexamples. The result shows that our model saturate as the number of training\nexamples grow and we don't need many training examples to get reasonably good\nresult. Another contribution of our work is that we have shown discriminative\nmodel like Deep Neural Network can approximate generative model like Bayesian\nNetwork.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 13:26:20 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 05:36:36 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Jia", "Jie", ""], ["Zhou", "Honggang", ""], ["Li", "Yunchun", ""]]}, {"id": "1801.00283", "submitter": "Klaus Broelemann", "authors": "Klaus Broelemann, Thomas Gottron and Gjergji Kasneci", "title": "Restricted Boltzmann Machines for Robust and Fast Latent Truth Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of latent truth discovery, LTD for short, where the\ngoal is to discover the underlying true values of entity attributes in the\npresence of noisy, conflicting or incomplete information. Despite a multitude\nof algorithms to address the LTD problem that can be found in literature, only\nlittle is known about their overall performance with respect to effectiveness\n(in terms of truth discovery capabilities), efficiency and robustness. A\npractical LTD approach should satisfy all these characteristics so that it can\nbe applied to heterogeneous datasets of varying quality and degrees of\ncleanliness.\n  We propose a novel algorithm for LTD that satisfies the above requirements.\nThe proposed model is based on Restricted Boltzmann Machines, thus coined\nLTD-RBM. In extensive experiments on various heterogeneous and publicly\navailable datasets, LTD-RBM is superior to state-of-the-art LTD techniques in\nterms of an overall consideration of effectiveness, efficiency and robustness.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 13:26:51 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Broelemann", "Klaus", ""], ["Gottron", "Thomas", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "1801.00315", "submitter": "E.M. Stoudenmire", "authors": "E.M. Stoudenmire", "title": "Learning Relevant Features of Data with Multi-scale Tensor Networks", "comments": "12 pages, 13 figures", "journal-ref": "Quantum Science and Technology 3, 034003 (2018)", "doi": "10.1088/2058-9565/aaba1a", "report-no": null, "categories": "stat.ML cond-mat.stat-mech cond-mat.str-el cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by coarse-graining approaches used in physics, we show how similar\nalgorithms can be adapted for data. The resulting algorithms are based on\nlayered tree tensor networks and scale linearly with both the dimension of the\ninput and the training set size. Computing most of the layers with an\nunsupervised algorithm, then optimizing just the top layer for supervised\nclassification of the MNIST and fashion-MNIST data sets gives very good\nresults. We also discuss mixing a prior guess for supervised weights together\nwith an unsupervised representation of the data, yielding a smaller number of\nfeatures nevertheless able to give good performance.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 16:53:12 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Stoudenmire", "E. M.", ""]]}, {"id": "1801.00318", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "Towards Building an Intelligent Anti-Malware System: A Deep Learning\n  Approach using Support Vector Machine (SVM) for Malware Classification", "comments": "5 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Effective and efficient mitigation of malware is a long-time endeavor in the\ninformation security community. The development of an anti-malware system that\ncan counteract an unknown malware is a prolific activity that may benefit\nseveral sectors. We envision an intelligent anti-malware system that utilizes\nthe power of deep learning (DL) models. Using such models would enable the\ndetection of newly-released malware through mathematical generalization. That\nis, finding the relationship between a given malware $x$ and its corresponding\nmalware family $y$, $f: x \\mapsto y$. To accomplish this feat, we used the\nMalimg dataset (Nataraj et al., 2011) which consists of malware images that\nwere processed from malware binaries, and then we trained the following DL\nmodels 1 to classify each malware family: CNN-SVM (Tang, 2013), GRU-SVM\n(Agarap, 2017), and MLP-SVM. Empirical evidence has shown that the GRU-SVM\nstands out among the DL models with a predictive accuracy of ~84.92%. This\nstands to reason for the mentioned model had the relatively most sophisticated\narchitecture design among the presented models. The exploration of an even more\noptimal DL-SVM model is the next stage towards the engineering of an\nintelligent anti-malware system.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 17:13:55 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 06:19:41 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1801.00329", "submitter": "Yang Yu", "authors": "Yu-Ren Liu, Yi-Qi Hu, Hong Qian, Yang Yu, Chao Qian", "title": "ZOOpt: Toolbox for Derivative-Free Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances of derivative-free optimization allow efficient approximating\nthe global optimal solutions of sophisticated functions, such as functions with\nmany local optima, non-differentiable and non-continuous functions. This\narticle describes the ZOOpt (https://github.com/eyounx/ZOOpt) toolbox that\nprovides efficient derivative-free solvers and are designed easy to use. ZOOpt\nprovides a Python package for single-thread optimization, and a light-weighted\ndistributed version with the help of the Julia language for Python described\nfunctions. ZOOpt toolbox particularly focuses on optimization problems in\nmachine learning, addressing high-dimensional, noisy, and large-scale problems.\nThe toolbox is being maintained toward ready-to-use tool in real-world machine\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 18:06:25 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 21:11:13 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Liu", "Yu-Ren", ""], ["Hu", "Yi-Qi", ""], ["Qian", "Hong", ""], ["Yu", "Yang", ""], ["Qian", "Chao", ""]]}, {"id": "1801.00384", "submitter": "Mehrnaz Najafi", "authors": "Mehrnaz Najafi, Lifang He, Philip S. Yu", "title": "Error-Robust Multi-View Clustering", "comments": "10 pages, 2017 IEEE International Conference on Big Data (Big Data\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data, data may come from multiple sources, known as\nmulti-view data. Multi-view clustering aims at generating better clusters by\nexploiting complementary and consistent information from multiple views rather\nthan relying on the individual view. Due to inevitable system errors caused by\ndata-captured sensors or others, the data in each view may be erroneous.\nVarious types of errors behave differently and inconsistently in each view.\nMore precisely, error could exhibit as noise and corruptions in reality.\nUnfortunately, none of the existing multi-view clustering approaches handle all\nof these error types. Consequently, their clustering performance is\ndramatically degraded. In this paper, we propose a novel Markov chain method\nfor Error-Robust Multi-View Clustering (EMVC). By decomposing each view into a\nshared transition probability matrix and error matrix and imposing structured\nsparsity-inducing norms on error matrices, we characterize and handle typical\ntypes of errors explicitly. To solve the challenging optimization problem, we\npropose a new efficient algorithm based on Augmented Lagrangian Multipliers and\nprove its convergence rigorously. Experimental results on various synthetic and\nreal-world datasets show the superiority of the proposed EMVC method over the\nbaseline methods and its robustness against different types of errors.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 02:42:04 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Najafi", "Mehrnaz", ""], ["He", "Lifang", ""], ["Yu", "Philip S.", ""]]}, {"id": "1801.00393", "submitter": "Manolis Tsakiris", "authors": "Manolis C. Tsakiris and Rene Vidal", "title": "Theoretical Analysis of Sparse Subspace Clustering with Missing Entries", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:4975-4984, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Subspace Clustering (SSC) is a popular unsupervised machine learning\nmethod for clustering data lying close to an unknown union of low-dimensional\nlinear subspaces; a problem with numerous applications in pattern recognition\nand computer vision. Even though the behavior of SSC for complete data is by\nnow well-understood, little is known about its theoretical properties when\napplied to data with missing entries. In this paper we give theoretical\nguarantees for SSC with incomplete data, and analytically establish that\nprojecting the zero-filled data onto the observation pattern of the point being\nexpressed leads to a substantial improvement in performance. The main insight\nthat stems from our analysis is that even though the projection induces\nadditional missing entries, this is counterbalanced by the fact that the\nprojected and zero-filled data are in effect incomplete points associated with\nthe union of the corresponding projected subspaces, with respect to which the\npoint being expressed is complete. The significance of this phenomenon\npotentially extends to the entire class of self-expressive methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 04:51:46 GMT"}, {"version": "v2", "created": "Sat, 3 Feb 2018 08:43:52 GMT"}, {"version": "v3", "created": "Fri, 9 Feb 2018 17:27:43 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Tsakiris", "Manolis C.", ""], ["Vidal", "Rene", ""]]}, {"id": "1801.00507", "submitter": "Alexander Zimin", "authors": "Alexander Zimin and Christoph Lampert", "title": "MACRO: A Meta-Algorithm for Conditional Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study conditional risk minimization (CRM), i.e. the problem of learning a\nhypothesis of minimal risk for prediction at the next step of sequentially\narriving dependent data. Despite it being a fundamental problem, successful\nlearning in the CRM sense has so far only been demonstrated using theoretical\nalgorithms that cannot be used for real problems as they would require storing\nall incoming data. In this work, we introduce MACRO, a meta-algorithm for CRM\nthat does not suffer from this shortcoming, but nevertheless offers learning\nguarantees. Instead of storing all data it maintains and iteratively updates a\nset of learning subroutines. With suitable approximations, MACRO applied to\nreal data, yielding improved prediction performance compared to traditional\nnon-conditional learning.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 20:48:33 GMT"}, {"version": "v2", "created": "Sat, 3 Nov 2018 21:20:44 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Zimin", "Alexander", ""], ["Lampert", "Christoph", ""]]}, {"id": "1801.00512", "submitter": "Haik Manukian", "authors": "Haik Manukian, Fabio L. Traversa, Massimiliano Di Ventra", "title": "Accelerating Deep Learning with Memcomputing", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines (RBMs) and their extensions, called\n'deep-belief networks', are powerful neural networks that have found\napplications in the fields of machine learning and artificial intelligence. The\nstandard way to training these models resorts to an iterative unsupervised\nprocedure based on Gibbs sampling, called 'contrastive divergence' (CD), and\nadditional supervised tuning via back-propagation. However, this procedure has\nbeen shown not to follow any gradient and can lead to suboptimal solutions. In\nthis paper, we show an efficient alternative to CD by means of simulations of\ndigital memcomputing machines (DMMs). We test our approach on pattern\nrecognition using a modified version of the MNIST data set. DMMs sample\neffectively the vast phase space given by the model distribution of the RBM,\nand provide a very good approximation close to the optimum. This efficient\nsearch significantly reduces the number of pretraining iterations necessary to\nachieve a given level of accuracy, as well as a total performance gain over CD.\nIn fact, the acceleration of pretraining achieved by simulating DMMs is\ncomparable to, in number of iterations, the recently reported hardware\napplication of the quantum annealing method on the same network and data set.\nNotably, however, DMMs perform far better than the reported quantum annealing\nresults in terms of quality of the training. We also compare our method to\nadvances in supervised training, like batch-normalization and rectifiers, that\nwork to reduce the advantage of pretraining. We find that the memcomputing\nmethod still maintains a quality advantage ($>1\\%$ in accuracy, and a $20\\%$\nreduction in error rate) over these approaches. Furthermore, our method is\nagnostic about the connectivity of the network. Therefore, it can be extended\nto train full Boltzmann machines, and even deep networks at once.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 21:27:11 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 01:33:19 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 19:23:11 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Manukian", "Haik", ""], ["Traversa", "Fabio L.", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1801.00515", "submitter": "James P. Crutchfield", "authors": "Adam Rupe and James P. Crutchfield", "title": "Local Causal States and Discrete Coherent Structures", "comments": "27 pages, 10 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/dcs.htm", "journal-ref": null, "doi": "10.1063/1.5021130", "report-no": null, "categories": "cond-mat.stat-mech cs.LG math.DS nlin.CG nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coherent structures form spontaneously in nonlinear spatiotemporal systems\nand are found at all spatial scales in natural phenomena from laboratory\nhydrodynamic flows and chemical reactions to ocean, atmosphere, and planetary\nclimate dynamics. Phenomenologically, they appear as key components that\norganize the macroscopic behaviors in such systems. Despite a century of\neffort, they have eluded rigorous analysis and empirical prediction, with\nprogress being made only recently. As a step in this, we present a formal\ntheory of coherent structures in fully-discrete dynamical field theories. It\nbuilds on the notion of structure introduced by computational mechanics,\ngeneralizing it to a local spatiotemporal setting. The analysis' main tool\nemploys the \\localstates, which are used to uncover a system's hidden\nspatiotemporal symmetries and which identify coherent structures as\nspatially-localized deviations from those symmetries. The approach is\nbehavior-driven in the sense that it does not rely on directly analyzing\nspatiotemporal equations of motion, rather it considers only the spatiotemporal\nfields a system generates. As such, it offers an unsupervised approach to\ndiscover and describe coherent structures. We illustrate the approach by\nanalyzing coherent structures generated by elementary cellular automata,\ncomparing the results with an earlier, dynamic-invariant-set approach that\ndecomposes fields into domains, particles, and particle interactions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 21:43:18 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Rupe", "Adam", ""], ["Crutchfield", "James P.", ""]]}, {"id": "1801.00548", "submitter": "Ahmed Attia", "authors": "Azam Moosavi, Ahmed Attia and Adrian Sandu", "title": "A Machine Learning Approach to Adaptive Covariance Localization", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": "CSTR-01", "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data assimilation plays a key role in large-scale atmospheric weather\nforecasting, where the state of the physical system is estimated from model\noutputs and observations, and is then used as initial condition to produce\naccurate future forecasts. The Ensemble Kalman Filter (EnKF) provides a\npractical implementation of the statistical solution of the data assimilation\nproblem and has gained wide popularity as. This success can be attributed to\nits simple formulation and ease of implementation. EnKF is a Monte-Carlo\nalgorithm that solves the data assimilation problem by sampling the probability\ndistributions involved in Bayes theorem. Because of this, all flavors of EnKF\nare fundamentally prone to sampling errors when the ensemble size is small. In\ntypical weather forecasting applications, the model state space has dimension\n$10^{9}-10^{12}$, while the ensemble size typically ranges between $30-100$\nmembers. Sampling errors manifest themselves as long-range spurious\ncorrelations and have been shown to cause filter divergence. To alleviate this\neffect covariance localization dampens spurious correlations between state\nvariables located at a large distance in the physical space, via an empirical\ndistance-dependent function. The quality of the resulting analysis and forecast\nis greatly influenced by the choice of the localization function parameters,\ne.g., the radius of influence. The localization radius is generally tuned\nempirically to yield desirable results.This work, proposes two adaptive\nalgorithms for covariance localization in the EnKF framework, both based on a\nmachine learning approach. The first algorithm adapts the localization radius\nin time, while the second algorithm tunes the localization radius in both time\nand space. Numerical experiments carried out with the Lorenz-96 model, and a\nquasi-geostrophic model, reveal the potential of the proposed machine learning\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 04:39:59 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 02:41:03 GMT"}, {"version": "v3", "created": "Sun, 11 Feb 2018 04:30:49 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Moosavi", "Azam", ""], ["Attia", "Ahmed", ""], ["Sandu", "Adrian", ""]]}, {"id": "1801.00584", "submitter": "Bernhard C. Geiger", "authors": "Clemens Bloechl, Rana Ali Amjad, Bernhard C. Geiger", "title": "Co-Clustering via Information-Theoretic Markov Aggregation", "comments": "accepted for publication in IEEE Trans. on Knowledge and Data\n  Engineering; (c) 2018 IEEE", "journal-ref": null, "doi": "10.1109/TKDE.2018.2846252", "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an information-theoretic cost function for co-clustering, i.e.,\nfor simultaneous clustering of two sets based on similarities between their\nelements. By constructing a simple random walk on the corresponding bipartite\ngraph, our cost function is derived from a recently proposed generalized\nframework for information-theoretic Markov chain aggregation. The goal of our\ncost function is to minimize relevant information loss, hence it connects to\nthe information bottleneck formalism. Moreover, via the connection to Markov\naggregation, our cost function is not ad hoc, but inherits its justification\nfrom the operational qualities associated with the corresponding Markov\naggregation problem. We furthermore show that, for appropriate parameter\nsettings, our cost function is identical to well-known approaches from the\nliterature, such as Information-Theoretic Co-Clustering of Dhillon et al.\nHence, understanding the influence of this parameter admits a deeper\nunderstanding of the relationship between previously proposed\ninformation-theoretic cost functions. We highlight some strengths and\nweaknesses of the cost function for different parameters. We also illustrate\nthe performance of our cost function, optimized with a simple sequential\nheuristic, on several synthetic and real-world data sets, including the\nNewsgroup20 and the MovieLens100k data sets.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 09:00:41 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 07:48:51 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Bloechl", "Clemens", ""], ["Amjad", "Rana Ali", ""], ["Geiger", "Bernhard C.", ""]]}, {"id": "1801.00631", "submitter": "Gary Marcus", "authors": "Gary Marcus", "title": "Deep Learning: A Critical Appraisal", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has historical roots going back decades, neither the\nterm \"deep learning\" nor the approach was popular just over five years ago,\nwhen the field was reignited by papers such as Krizhevsky, Sutskever and\nHinton's now classic (2012) deep network model of Imagenet. What has the field\ndiscovered in the five subsequent years? Against a background of considerable\nprogress in areas such as speech recognition, image recognition, and game\nplaying, and considerable enthusiasm in the popular press, I present ten\nconcerns for deep learning, and suggest that deep learning must be supplemented\nby other techniques if we are to reach artificial general intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 12:49:35 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Marcus", "Gary", ""]]}, {"id": "1801.00632", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Thomas Demeester, Bart Dhoedt", "title": "Character-level Recurrent Neural Networks in Practice: Comparing\n  Training and Sampling Schemes", "comments": "23 pages, 11 figures, 4 tables", "journal-ref": null, "doi": "10.1007/s00521-017-3322-z", "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent neural networks are nowadays successfully used in an abundance of\napplications, going from text, speech and image processing to recommender\nsystems. Backpropagation through time is the algorithm that is commonly used to\ntrain these networks on specific tasks. Many deep learning frameworks have\ntheir own implementation of training and sampling procedures for recurrent\nneural networks, while there are in fact multiple other possibilities to choose\nfrom and other parameters to tune. In existing literature this is very often\noverlooked or ignored. In this paper we therefore give an overview of possible\ntraining and sampling schemes for character-level recurrent neural networks to\nsolve the task of predicting the next token in a given sequence. We test these\ndifferent schemes on a variety of datasets, neural network architectures and\nparameter settings, and formulate a number of take-home recommendations. The\nchoice of training and sampling scheme turns out to be subject to a number of\ntrade-offs, such as training stability, sampling time, model performance and\nimplementation effort, but is largely independent of the data. Perhaps the most\nsurprising result is that transferring hidden states for correctly initializing\nthe model on subsequences often leads to unstable training behavior depending\non the dataset.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 12:50:12 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 09:15:07 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["De Boom", "Cedric", ""], ["Demeester", "Thomas", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1801.00634", "submitter": "Simant Dube", "authors": "Simant Dube", "title": "High Dimensional Spaces, Deep Learning and Adversarial Examples", "comments": "29 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze deep learning from a mathematical point of view and\nderive several novel results. The results are based on intriguing mathematical\nproperties of high dimensional spaces. We first look at perturbation based\nadversarial examples and show how they can be understood using topological and\ngeometrical arguments in high dimensions. We point out mistake in an argument\npresented in prior published literature, and we present a more rigorous,\ngeneral and correct mathematical result to explain adversarial examples in\nterms of topology of image manifolds. Second, we look at optimization\nlandscapes of deep neural networks and examine the number of saddle points\nrelative to that of local minima. Third, we show how multiresolution nature of\nimages explains perturbation based adversarial examples in form of a stronger\nresult. Our results state that expectation of $L_2$-norm of adversarial\nperturbations is $O\\left(\\frac{1}{\\sqrt{n}}\\right)$ and therefore shrinks to 0\nas image resolution $n$ becomes arbitrarily large. Finally, by incorporating\nthe parts-whole manifold learning hypothesis for natural images, we investigate\nthe working of deep neural networks and root causes of adversarial examples and\ndiscuss how future improvements can be made and how adversarial examples can be\neliminated.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 12:54:22 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 05:30:30 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 13:53:22 GMT"}, {"version": "v4", "created": "Sun, 14 Jan 2018 01:57:47 GMT"}, {"version": "v5", "created": "Sun, 15 Apr 2018 19:39:11 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Dube", "Simant", ""]]}, {"id": "1801.00711", "submitter": "Shiliang Sun", "authors": "Shiliang Sun, Rongqing Huang, Ya Gao", "title": "Network-Scale Traffic Modeling and Forecasting with Graphical Lasso and\n  Neural Networks", "comments": null, "journal-ref": "Journal of Transportation Engineering, 2012, 138(11): 1358-1367", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic flow forecasting, especially the short-term case, is an important\ntopic in intelligent transportation systems (ITS). This paper does a lot of\nresearch on network-scale modeling and forecasting of short-term traffic flows.\nFirstly, we propose the concepts of single-link and multi-link models of\ntraffic flow forecasting. Secondly, we construct four prediction models by\ncombining the two models with single-task learning and multi-task learning. The\ncombination of the multi-link model and multi-task learning not only improves\nthe experimental efficiency but also the prediction accuracy. Moreover, a new\nmulti-link single-task approach that combines graphical lasso (GL) with neural\nnetwork (NN) is proposed. GL provides a general methodology for solving\nproblems involving lots of variables. Using L1 regularization, GL builds a\nsparse graphical model making use of the sparse inverse covariance matrix. In\naddition, Gaussian process regression (GPR) is a classic regression algorithm\nin Bayesian machine learning. Although there is wide research on GPR, there are\nfew applications of GPR in traffic flow forecasting. In this paper, we apply\nGPR to traffic flow forecasting and show its potential. Through sufficient\nexperiments, we compare all of the proposed approaches and make an overall\nassessment at last.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 03:08:15 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Sun", "Shiliang", ""], ["Huang", "Rongqing", ""], ["Gao", "Ya", ""]]}, {"id": "1801.00723", "submitter": "Pegah Karimi", "authors": "Pegah Karimi, Nicholas Davis, Kazjon Grace, Mary Lou Maher", "title": "Deep Learning for Identifying Potential Conceptual Shifts for\n  Co-creative Drawing", "comments": "This is an extended version of the paper presented at 31st Conference\n  on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n  Workshop on Machine Learning for Creativity and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for identifying conceptual shifts between visual\ncategories, which will form the basis for a co-creative drawing system to help\nusers draw more creative sketches. The system recognizes human sketches and\nmatches them to structurally similar sketches from categories to which they do\nnot belong. This would allow a co-creative drawing system to produce an\nambiguous sketch that blends features from both categories.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 16:51:22 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Karimi", "Pegah", ""], ["Davis", "Nicholas", ""], ["Grace", "Kazjon", ""], ["Maher", "Mary Lou", ""]]}, {"id": "1801.00746", "submitter": "Yu Ji", "authors": "Yu Ji, YouHui Zhang, WenGuang Chen, Yuan Xie", "title": "Bridging the Gap Between Neural Networks and Neuromorphic Hardware with\n  A Neural Network Compiler", "comments": "Accepted by ASPLOS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from developing neural networks (NNs) for general-purpose\nprocessors, the development for NN chips usually faces with some\nhardware-specific restrictions, such as limited precision of network signals\nand parameters, constrained computation scale, and limited types of non-linear\nfunctions.\n  This paper proposes a general methodology to address the challenges. We\ndecouple the NN applications from the target hardware by introducing a compiler\nthat can transform an existing trained, unrestricted NN into an equivalent\nnetwork that meets the given hardware's constraints. We propose multiple\ntechniques to make the transformation adaptable to different kinds of NN chips,\nand reliable for restrict hardware constraints.\n  We have built such a software tool that supports both spiking neural networks\n(SNNs) and traditional artificial neural networks (ANNs). We have demonstrated\nits effectiveness with a fabricated neuromorphic chip and a\nprocessing-in-memory (PIM) design. Tests show that the inference error caused\nby this solution is insignificant and the transformation time is much shorter\nthan the retraining time. Also, we have studied the parameter-sensitivity\nevaluations to explore the tradeoffs between network error and resource\nutilization for different transformation strategies, which could provide\ninsights for co-design optimization of neuromorphic hardware and software.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 22:52:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 01:16:42 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 18:05:39 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Ji", "Yu", ""], ["Zhang", "YouHui", ""], ["Chen", "WenGuang", ""], ["Xie", "Yuan", ""]]}, {"id": "1801.00753", "submitter": "Franz J. Kir\\'aly", "authors": "Frithjof Gressmann, Franz J. Kir\\'aly, Bilal Mateen and Harald\n  Oberhauser", "title": "Probabilistic supervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modelling and supervised learning are central to modern data\nscience. With predictions from an ever-expanding number of supervised black-box\nstrategies - e.g., kernel methods, random forests, deep learning aka neural\nnetworks - being employed as a basis for decision making processes, it is\ncrucial to understand the statistical uncertainty associated with these\npredictions.\n  As a general means to approach the issue, we present an overarching framework\nfor black-box prediction strategies that not only predict the target but also\ntheir own predictions' uncertainty. Moreover, the framework allows for fair\nassessment and comparison of disparate prediction strategies. For this, we\nformally consider strategies capable of predicting full distributions from\nfeature variables, so-called probabilistic supervised learning strategies.\n  Our work draws from prior work including Bayesian statistics, information\ntheory, and modern supervised machine learning, and in a novel synthesis leads\nto (a) new theoretical insights such as a probabilistic bias-variance\ndecomposition and an entropic formulation of prediction, as well as to (b) new\nalgorithms and meta-algorithms, such as composite prediction strategies,\nprobabilistic boosting and bagging, and a probabilistic predictive independence\ntest.\n  Our black-box formulation also leads (c) to a new modular interface view on\nprobabilistic supervised learning and a modelling workflow API design, which we\nhave implemented in the newly released skpro machine learning toolbox,\nextending the familiar modelling interface and meta-modelling functionality of\nsklearn. The skpro package provides interfaces for construction, composition,\nand tuning of probabilistic supervised learning strategies, together with\norchestration features for validation and comparison of any such strategy - be\nit frequentist, Bayesian, or other.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 18:08:49 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 21:22:42 GMT"}, {"version": "v3", "created": "Tue, 7 May 2019 14:30:27 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Gressmann", "Frithjof", ""], ["Kir\u00e1ly", "Franz J.", ""], ["Mateen", "Bilal", ""], ["Oberhauser", "Harald", ""]]}, {"id": "1801.00779", "submitter": "Hao Li", "authors": "Zhijian Liu, Di Wu, Hongyu Wei, Guoqing Cao", "title": "Machine Learning for Building Energy and Indoor Environment: A\n  Perspective", "comments": "Submitted to a Interdisciplinary Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a promising technique for many practical applications. In\nthis perspective, we illustrate the development and application for machine\nlearning. It is indicated that the theories and applications of machine\nlearning method in the field of energy conservation and indoor environment are\nnot mature, due to the difficulty of the determination for model structure with\nbetter prediction. In order to significantly contribute to the problems, we\nutilize the ANN model to predict the indoor culturable fungi concentration,\nwhich achieves the better accuracy and convenience. The proposal of hybrid\nmethod is further expand the application fields of machine learning method.\nFurther, ANN model based on HTS was successfully applied for the optimization\nof building energy system. We hope that this novel method could capture more\nattention from investigators via our introduction and perspective, due to its\npotential development with accuracy and reliability. However, its feasibility\nin other fields needs to be promoted further.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 02:06:30 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Liu", "Zhijian", ""], ["Wu", "Di", ""], ["Wei", "Hongyu", ""], ["Cao", "Guoqing", ""]]}, {"id": "1801.00820", "submitter": "Jindong Wang", "authors": "Jindong Wang and Yiqiang Chen and Lisha Hu and Xiaohui Peng and Philip\n  S. Yu", "title": "Stratified Transfer Learning for Cross-domain Activity Recognition", "comments": "10 pages; accepted by IEEE PerCom 2018; full paper. (camera-ready\n  version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In activity recognition, it is often expensive and time-consuming to acquire\nsufficient activity labels. To solve this problem, transfer learning leverages\nthe labeled samples from the source domain to annotate the target domain which\nhas few or none labels. Existing approaches typically consider learning a\nglobal domain shift while ignoring the intra-affinity between classes, which\nwill hinder the performance of the algorithms. In this paper, we propose a\nnovel and general cross-domain learning framework that can exploit the\nintra-affinity of classes to perform intra-class knowledge transfer. The\nproposed framework, referred to as Stratified Transfer Learning (STL), can\ndramatically improve the classification accuracy for cross-domain activity\nrecognition. Specifically, STL first obtains pseudo labels for the target\ndomain via majority voting technique. Then, it performs intra-class knowledge\ntransfer iteratively to transform both domains into the same subspaces.\nFinally, the labels of target domain are obtained via the second annotation. To\nevaluate the performance of STL, we conduct comprehensive experiments on three\nlarge public activity recognition datasets~(i.e. OPPORTUNITY, PAMAP2, and UCI\nDSADS), which demonstrates that STL significantly outperforms other\nstate-of-the-art methods w.r.t. classification accuracy (improvement of 7.68%).\nFurthermore, we extensively investigate the performance of STL across different\ndegrees of similarities and activity levels between domains. And we also\ndiscuss the potential of STL in other pervasive computing applications to\nprovide empirical experience for future research.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 06:18:31 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Wang", "Jindong", ""], ["Chen", "Yiqiang", ""], ["Hu", "Lisha", ""], ["Peng", "Xiaohui", ""], ["Yu", "Philip S.", ""]]}, {"id": "1801.00823", "submitter": "Thee Chanyaswad", "authors": "Thee Chanyaswad, Alex Dytso, H. Vincent Poor, Prateek Mittal", "title": "MVG Mechanism: Differential Privacy under Matrix-Valued Query", "comments": "Appeared in CCS'18", "journal-ref": "Thee Chanyaswad, Alex Dytso, H. Vincent Poor, and Prateek Mittal.\n  2018. MVG Mechanism: Differential Privacy under Matrix-Valued Query. In 2018\n  ACM SIGSAC Conference on Computer and Communications Security (CCS'18)", "doi": "10.1145/3243734.3243750", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy mechanism design has traditionally been tailored for a\nscalar-valued query function. Although many mechanisms such as the Laplace and\nGaussian mechanisms can be extended to a matrix-valued query function by adding\ni.i.d. noise to each element of the matrix, this method is often suboptimal as\nit forfeits an opportunity to exploit the structural characteristics typically\nassociated with matrix analysis. To address this challenge, we propose a novel\ndifferential privacy mechanism called the Matrix-Variate Gaussian (MVG)\nmechanism, which adds a matrix-valued noise drawn from a matrix-variate\nGaussian distribution, and we rigorously prove that the MVG mechanism preserves\n$(\\epsilon,\\delta)$-differential privacy. Furthermore, we introduce the concept\nof directional noise made possible by the design of the MVG mechanism.\nDirectional noise allows the impact of the noise on the utility of the\nmatrix-valued query function to be moderated. Finally, we experimentally\ndemonstrate the performance of our mechanism using three matrix-valued queries\non three privacy-sensitive datasets. We find that the MVG mechanism notably\noutperforms four previous state-of-the-art approaches, and provides comparable\nutility to the non-private baseline.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 20:24:24 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 20:48:34 GMT"}, {"version": "v3", "created": "Tue, 16 Oct 2018 21:31:23 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Chanyaswad", "Thee", ""], ["Dytso", "Alex", ""], ["Poor", "H. Vincent", ""], ["Mittal", "Prateek", ""]]}, {"id": "1801.00857", "submitter": "Alireza Karbalayghareh", "authors": "Alireza Karbalayghareh, Xiaoning Qian, and Edward R. Dougherty", "title": "Optimal Bayesian Transfer Learning", "comments": "IEEE Transactions on Signal Processing", "journal-ref": "IEEE Transactions On Signal Processing, Vol. 66, No. 14, July 15,\n  2018", "doi": "10.1109/TSP.2018.2839583", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has recently attracted significant research attention, as\nit simultaneously learns from different source domains, which have plenty of\nlabeled data, and transfers the relevant knowledge to the target domain with\nlimited labeled data to improve the prediction performance. We propose a\nBayesian transfer learning framework where the source and target domains are\nrelated through the joint prior density of the model parameters. The modeling\nof joint prior densities enables better understanding of the \"transferability\"\nbetween domains. We define a joint Wishart density for the precision matrices\nof the Gaussian feature-label distributions in the source and target domains to\nact like a bridge that transfers the useful information of the source domain to\nhelp classification in the target domain by improving the target posteriors.\nUsing several theorems in multivariate statistics, the posteriors and posterior\npredictive densities are derived in closed forms with hypergeometric functions\nof matrix argument, leading to our novel closed-form and fast Optimal Bayesian\nTransfer Learning (OBTL) classifier. Experimental results on both synthetic and\nreal-world benchmark data confirm the superb performance of the OBTL compared\nto the other state-of-the-art transfer learning and domain adaptation methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 23:15:56 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 17:30:44 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Karbalayghareh", "Alireza", ""], ["Qian", "Xiaoning", ""], ["Dougherty", "Edward R.", ""]]}, {"id": "1801.00903", "submitter": "Christopher M. Poskitt", "authors": "Yuqi Chen, Christopher M. Poskitt, Jun Sun", "title": "Learning from Mutants: Using Code Mutation to Learn and Monitor\n  Invariants of a Cyber-Physical System", "comments": "Accepted by IEEE S&P 2018", "journal-ref": "In Proc. IEEE Symposium on Security & Privacy (S&P 2018), pages\n  648-660. IEEE, 2018", "doi": "10.1109/SP.2018.00016", "report-no": null, "categories": "cs.SE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical systems (CPS) consist of sensors, actuators, and controllers\nall communicating over a network; if any subset becomes compromised, an\nattacker could cause significant damage. With access to data logs and a model\nof the CPS, the physical effects of an attack could potentially be detected\nbefore any damage is done. Manually building a model that is accurate enough in\npractice, however, is extremely difficult. In this paper, we propose a novel\napproach for constructing models of CPS automatically, by applying supervised\nmachine learning to data traces obtained after systematically seeding their\nsoftware components with faults (\"mutants\"). We demonstrate the efficacy of\nthis approach on the simulator of a real-world water purification plant,\npresenting a framework that automatically generates mutants, collects data\ntraces, and learns an SVM-based model. Using cross-validation and statistical\nmodel checking, we show that the learnt model characterises an invariant\nphysical property of the system. Furthermore, we demonstrate the usefulness of\nthe invariant by subjecting the system to 55 network and code-modification\nattacks, and showing that it can detect 85% of them from the data logs\ngenerated at runtime.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 05:42:19 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 04:24:00 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Chen", "Yuqi", ""], ["Poskitt", "Christopher M.", ""], ["Sun", "Jun", ""]]}, {"id": "1801.00905", "submitter": "Mayank Singh", "authors": "Mayank Singh, Abhishek Sinha and Balaji Krishnamurthy", "title": "Neural Networks in Adversarial Setting and Ill-Conditioned Weight Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Neural networks have seen a huge surge in its adoption due to their\nability to provide high accuracy on various tasks. On the other hand, the\nexistence of adversarial examples have raised suspicions regarding the\ngeneralization capabilities of neural networks. In this work, we focus on the\nweight matrix learnt by the neural networks and hypothesize that ill\nconditioned weight matrix is one of the contributing factors in neural\nnetwork's susceptibility towards adversarial examples. For ensuring that the\nlearnt weight matrix's condition number remains sufficiently low, we suggest\nusing orthogonal regularizer. We show that this indeed helps in increasing the\nadversarial accuracy on MNIST and F-MNIST datasets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 05:52:52 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Singh", "Mayank", ""], ["Sinha", "Abhishek", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1801.01017", "submitter": "Sambarta Dasgupta", "authors": "Sambarta Dasgupta, Keivan Ebrahimi, and Umesh Vaidya", "title": "Particle Clustering Machine: A Dynamical System Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of the clusters from an unlabeled data set is one of the most\nimportant problems in Unsupervised Machine Learning. The state of the art\nclustering algorithms are based on either the statistical properties or the\ngeometric properties of the data set. In this work, we propose a novel method\nto cluster the data points using dynamical systems theory. After constructing a\ngradient dynamical system using interaction potential, we prove that the\nasymptotic dynamics of this system will determine the cluster centers, when the\ndynamical system is initialized at the data points. Most of the existing\nheuristic-based clustering techniques suffer from a disadvantage, namely the\nstochastic nature of the solution. Whereas, the proposed algorithm is\ndeterministic, and the outcome would not change over multiple runs of the\nproposed algorithm with the same input data. Another advantage of the proposed\nmethod is that the number of clusters, which is difficult to determine in\npractice, does not have to be specified in advance. Simulation results with are\npresented, and comparisons are made with the existing methods.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 00:24:48 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Dasgupta", "Sambarta", ""], ["Ebrahimi", "Keivan", ""], ["Vaidya", "Umesh", ""]]}, {"id": "1801.01019", "submitter": "Nghia (Andy) Nguyen", "authors": "Christine A. Liang, Lei Chen, Amer Wahed, Andy N.D. Nguyen", "title": "Proteomics Analysis of FLT3-ITD Mutation in Acute Myeloid Leukemia Using\n  Deep Learning Neural Network", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning can significantly benefit cancer proteomics and genomics. In\nthis study, we attempt to determine a set of critical proteins that are\nassociated with the FLT3-ITD mutation in newly-diagnosed acute myeloid leukemia\npatients. A Deep Learning network consisting of autoencoders forming a\nhierarchical model from which high-level features are extracted without labeled\ntraining data. Dimensional reduction reduced the number of critical proteins\nfrom 231 to 20. Deep Learning found an excellent correlation between FLT3-ITD\nmutation with the levels of these 20 critical proteins (accuracy 97%,\nsensitivity 90%, specificity 100%). Our Deep Learning network could hone in on\n20 proteins with the strongest association with FLT3-ITD. The results of this\nstudy allow a novel approach to determine critical protein pathways in the\nFLT3-ITD mutation, and provide proof-of-concept for an accurate approach to\nmodel big data in cancer proteomics and genomics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 13:05:30 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Liang", "Christine A.", ""], ["Chen", "Lei", ""], ["Wahed", "Amer", ""], ["Nguyen", "Andy N. D.", ""]]}, {"id": "1801.01058", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Polynomial-based rotation invariant features", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of basic difficulties of machine learning is handling unknown rotations\nof objects, for example in image recognition. A related problem is evaluation\nof similarity of shapes, for example of two chemical molecules, for which\ndirect approach requires costly pairwise rotation alignment and comparison.\nRotation invariants are useful tools for such purposes, allowing to extract\nfeatures describing shape up to rotation, which can be used for example to\nsearch for similar rotated patterns, or fast evaluation of similarity of shapes\ne.g. for virtual screening, or machine learning including features directly\ndescribing shape. A standard approach are rotationally invariant cylindrical or\nspherical harmonics, which can be seen as based on polynomials on sphere,\nhowever, they provide very few invariants - only one per degree of polynomial.\nThere will be discussed a general approach to construct arbitrarily large sets\nof rotation invariants of polynomials, for degree $D$ in $\\mathbb{R}^n$ up to\n$O(n^D)$ independent invariants instead of $O(D)$ offered by standard\napproaches, possibly also a complete set: providing not only necessary, but\nalso sufficient condition for differing only by rotation (and reflectional\nsymmetry).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 15:55:39 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1801.01061", "submitter": "Mu Niu", "authors": "Mu Niu, Pokman Cheung, Lizhen Lin, Zhenwen Dai, Neil Lawrence, David\n  Dunson", "title": "Intrinsic Gaussian processes on complex constrained domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a class of intrinsic Gaussian processes (in-GPs) for\ninterpolation, regression and classification on manifolds with a primary focus\non complex constrained domains or irregular shaped spaces arising as subsets or\nsubmanifolds of R, R2, R3 and beyond. For example, in-GPs can accommodate\nspatial domains arising as complex subsets of Euclidean space. in-GPs respect\nthe potentially complex boundary or interior conditions as well as the\nintrinsic geometry of the spaces. The key novelty of the proposed approach is\nto utilise the relationship between heat kernels and the transition density of\nBrownian motion on manifolds for constructing and approximating valid and\ncomputationally feasible covariance kernels. This enables in-GPs to be\npractically applied in great generality, while existing approaches for\nsmoothing on constrained domains are limited to simple special cases. The broad\nutilities of the in-GP approach is illustrated through simulation studies and\ndata examples.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 16:07:33 GMT"}], "update_date": "2018-01-05", "authors_parsed": [["Niu", "Mu", ""], ["Cheung", "Pokman", ""], ["Lin", "Lizhen", ""], ["Dai", "Zhenwen", ""], ["Lawrence", "Neil", ""], ["Dunson", "David", ""]]}, {"id": "1801.01117", "submitter": "Ge Wang", "authors": "Fenglei Fan, Ge Wang", "title": "Learning from Pseudo-Randomness With an Artificial Neural Network - Does\n  God Play Pseudo-Dice?", "comments": "9 pages, 5 figures, 22 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the fact that the neural network, as the mainstream for machine\nlearning, has brought successes in many application areas, here we propose to\nuse this approach for decoding hidden correlation among pseudo-random data and\npredicting events accordingly. With a simple neural network structure and a\ntypical training procedure, we demonstrate the learning and prediction power of\nthe neural network in extremely random environment. Finally, we postulate that\nthe high sensitivity and efficiency of the neural network may allow to\ncritically test if there could be any fundamental difference between quantum\nrandomness and pseudo randomness, which is equivalent to the question: Does God\nplay dice?\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 02:10:32 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Fan", "Fenglei", ""], ["Wang", "Ge", ""]]}, {"id": "1801.01204", "submitter": "Ioannis Paschalidis", "authors": "Theodora S. Brisimi, Tingting Xu, Taiyao Wang, Wuyang Dai, William G.\n  Adams and Ioannis Ch. Paschalidis", "title": "Predicting Chronic Disease Hospitalizations from Electronic Health\n  Records: An Interpretable Classification Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban living in modern large cities has significant adverse effects on\nhealth, increasing the risk of several chronic diseases. We focus on the two\nleading clusters of chronic disease, heart disease and diabetes, and develop\ndata-driven methods to predict hospitalizations due to these conditions. We\nbase these predictions on the patients' medical history, recent and more\ndistant, as described in their Electronic Health Records (EHR). We formulate\nthe prediction problem as a binary classification problem and consider a\nvariety of machine learning methods, including kernelized and sparse Support\nVector Machines (SVM), sparse logistic regression, and random forests. To\nstrike a balance between accuracy and interpretability of the prediction, which\nis important in a medical setting, we propose two novel methods: K-LRT, a\nlikelihood ratio test-based method, and a Joint Clustering and Classification\n(JCC) method which identifies hidden patient clusters and adapts classifiers to\neach cluster. We develop theoretical out-of-sample guarantees for the latter\nmethod. We validate our algorithms on large datasets from the Boston Medical\nCenter, the largest safety-net hospital system in New England.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 23:22:58 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Brisimi", "Theodora S.", ""], ["Xu", "Tingting", ""], ["Wang", "Taiyao", ""], ["Dai", "Wuyang", ""], ["Adams", "William G.", ""], ["Paschalidis", "Ioannis Ch.", ""]]}, {"id": "1801.01253", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel and Max Simchowitz and Kannan Ramchandran and Martin\n  J. Wainwright", "title": "Approximate Ranking from Pairwise Comparisons", "comments": "AISTATS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in machine learning is to rank a set of n items based on\npairwise comparisons. Here ranking refers to partitioning the items into sets\nof pre-specified sizes according to their scores, which includes identification\nof the top-k items as the most prominent special case. The score of a given\nitem is defined as the probability that it beats a randomly chosen other item.\nFinding an exact ranking typically requires a prohibitively large number of\ncomparisons, but in practice, approximate rankings are often adequate.\nAccordingly, we study the problem of finding approximate rankings from pairwise\ncomparisons. We analyze an active ranking algorithm that counts the number of\ncomparisons won, and decides whether to stop or which pair of items to compare\nnext, based on confidence intervals computed from the data collected in\nprevious steps. We show that this algorithm succeeds in recovering approximate\nrankings using a number of comparisons that is close to optimal up to\nlogarithmic factors. We also present numerical results, showing that in\npractice, approximation can drastically reduce the number of comparisons\nrequired to estimate a ranking.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 06:18:39 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Heckel", "Reinhard", ""], ["Simchowitz", "Max", ""], ["Ramchandran", "Kannan", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1801.01258", "submitter": "Jong Chul Ye", "authors": "Yoseob Han, Jingu Kang, and Jong Chul Ye", "title": "Deep Learning Reconstruction for 9-View Dual Energy CT Baggage Scanner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For homeland and transportation security applications, 2D X-ray explosive\ndetection system (EDS) have been widely used, but they have limitations in\nrecognizing 3D shape of the hidden objects. Among various types of 3D computed\ntomography (CT) systems to address this issue, this paper is interested in a\nstationary CT using fixed X-ray sources and detectors. However, due to the\nlimited number of projection views, analytic reconstruction algorithms produce\nsevere streaking artifacts. Inspired by recent success of deep learning\napproach for sparse view CT reconstruction, here we propose a novel image and\nsinogram domain deep learning architecture for 3D reconstruction from very\nsparse view measurement. The algorithm has been tested with the real data from\na prototype 9-view dual energy stationary CT EDS carry-on baggage scanner\ndeveloped by GEMSS Medical Systems, Korea, which confirms the superior\nreconstruction performance over the existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 06:35:53 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Han", "Yoseob", ""], ["Kang", "Jingu", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1801.01275", "submitter": "Anush Sankaran", "authors": "Senthil Mani, Anush Sankaran, Rahul Aralikatte", "title": "DeepTriage: Exploring the Effectiveness of Deep Learning for Bug\n  Triaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given software bug report, identifying an appropriate developer who\ncould potentially fix the bug is the primary task of a bug triaging process. A\nbug title (summary) and a detailed description is present in most of the bug\ntracking systems. Automatic bug triaging algorithm can be formulated as a\nclassification problem, with the bug title and description as the input,\nmapping it to one of the available developers (classes). The major challenge is\nthat the bug description usually contains a combination of free unstructured\ntext, code snippets, and stack trace making the input data noisy. The existing\nbag-of-words (BOW) feature models do not consider the syntactical and\nsequential word information available in the unstructured text. We propose a\nnovel bug report representation algorithm using an attention based deep\nbidirectional recurrent neural network (DBRNN-A) model that learns a syntactic\nand semantic feature from long word sequences in an unsupervised manner.\nInstead of BOW features, the DBRNN-A based bug representation is then used for\ntraining the classifier. Using an attention mechanism enables the model to\nlearn the context representation over a long word sequence, as in a bug report.\nTo provide a large amount of data to learn the feature learning model, the\nunfixed bug reports (~70% bugs in an open source bug tracking system) are\nleveraged, which were completely ignored in the previous studies. Another\ncontribution is to make this research reproducible by making the source code\navailable and creating a public benchmark dataset of bug reports from three\nopen source bug tracking system: Google Chromium (383,104 bug reports), Mozilla\nCore (314,388 bug reports), and Mozilla Firefox (162,307 bug reports).\nExperimentally we compare our approach with BOW model and machine learning\napproaches and observe that DBRNN-A provides a higher rank-10 average accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 08:32:05 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Mani", "Senthil", ""], ["Sankaran", "Anush", ""], ["Aralikatte", "Rahul", ""]]}, {"id": "1801.01281", "submitter": "Matthieu Grard", "authors": "Matthieu Grard, Romain Br\\'egier, Florian Sella, Emmanuel\n  Dellandr\\'ea, Liming Chen", "title": "Object segmentation in depth maps with one user click and a\n  synthetically trained fully convolutional network", "comments": "This is a pre-print of an article published in Human Friendly\n  Robotics, 10th International Workshop, Springer Proceedings in Advanced\n  Robotics, vol 7. The final authenticated version is available online at:\n  https://doi.org/10.1007/978-3-319-89327-3\\_16, Springer Proceedings in\n  Advanced Robotics, Siciliano Bruno, Khatib Oussama, In press, Human Friendly\n  Robotics, 10th International Workshop, 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With more and more household objects built on planned obsolescence and\nconsumed by a fast-growing population, hazardous waste recycling has become a\ncritical challenge. Given the large variability of household waste, current\nrecycling platforms mostly rely on human operators to analyze the scene,\ntypically composed of many object instances piled up in bulk. Helping them by\nrobotizing the unitary extraction is a key challenge to speed up this tedious\nprocess. Whereas supervised deep learning has proven very efficient for such\nobject-level scene understanding, e.g., generic object detection and\nsegmentation in everyday scenes, it however requires large sets of per-pixel\nlabeled images, that are hardly available for numerous application contexts,\nincluding industrial robotics. We thus propose a step towards a practical\ninteractive application for generating an object-oriented robotic grasp,\nrequiring as inputs only one depth map of the scene and one user click on the\nnext object to extract. More precisely, we address in this paper the middle\nissue of object seg-mentation in top views of piles of bulk objects given a\npixel location, namely seed, provided interactively by a human operator. We\npropose a twofold framework for generating edge-driven instance segments.\nFirst, we repurpose a state-of-the-art fully convolutional object contour\ndetector for seed-based instance segmentation by introducing the notion of\nedge-mask duality with a novel patch-free and contour-oriented loss function.\nSecond, we train one model using only synthetic scenes, instead of manually\nlabeled training data. Our experimental results show that considering edge-mask\nduality for training an encoder-decoder network, as we suggest, outperforms a\nstate-of-the-art patch-based network in the present application context.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 09:13:20 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 09:06:37 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Grard", "Matthieu", ""], ["Br\u00e9gier", "Romain", ""], ["Sella", "Florian", ""], ["Dellandr\u00e9a", "Emmanuel", ""], ["Chen", "Liming", ""]]}, {"id": "1801.01290", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine", "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement\n  Learning with a Stochastic Actor", "comments": "ICML 2018 Videos: sites.google.com/view/soft-actor-critic Code:\n  github.com/haarnoja/sac", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) algorithms have been demonstrated\non a range of challenging decision making and control tasks. However, these\nmethods typically suffer from two major challenges: very high sample complexity\nand brittle convergence properties, which necessitate meticulous hyperparameter\ntuning. Both of these challenges severely limit the applicability of such\nmethods to complex, real-world domains. In this paper, we propose soft\nactor-critic, an off-policy actor-critic deep RL algorithm based on the maximum\nentropy reinforcement learning framework. In this framework, the actor aims to\nmaximize expected reward while also maximizing entropy. That is, to succeed at\nthe task while acting as randomly as possible. Prior deep RL methods based on\nthis framework have been formulated as Q-learning methods. By combining\noff-policy updates with a stable stochastic actor-critic formulation, our\nmethod achieves state-of-the-art performance on a range of continuous control\nbenchmark tasks, outperforming prior on-policy and off-policy methods.\nFurthermore, we demonstrate that, in contrast to other off-policy algorithms,\nour approach is very stable, achieving very similar performance across\ndifferent random seeds.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 09:50:50 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 21:27:08 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Zhou", "Aurick", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1801.01314", "submitter": "Chong Di", "authors": "Chong Di", "title": "Learning automata based SVM for intrusion detection", "comments": null, "journal-ref": "International Conference in Communications, Signal Processing, and\n  Systems. CSPS 2017. Lecture Notes in Electrical Engineering, vol 463.\n  Springer, Singapore", "doi": "10.1007/978-981-10-6571-2_252", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an indispensable defensive measure of network security, the intrusion\ndetection is a process of monitoring the events occurring in a computer system\nor network and analyzing them for signs of possible incidents. It is a\nclassifier to judge the event is normal or malicious. The information used for\nintrusion detection contains some redundant features which would increase the\ndifficulty of training the classifier for intrusion detection and increase the\ntime of making predictions. To simplify the training process and improve the\nefficiency of the classifier, it is necessary to remove these dispensable\nfeatures. in this paper, we propose a novel LA-SVM scheme to automatically\nremove redundant features focusing on intrusion detection. This is the first\napplication of learning automata for solving dimension reduction problems. The\nsimulation results indicate that the LA-SVM scheme achieves a higher accuracy\nand is more efficient in making predictions compared with traditional SVM.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 11:46:04 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Di", "Chong", ""]]}, {"id": "1801.01401", "submitter": "Danica J. Sutherland", "authors": "Miko{\\l}aj Bi\\'nkowski, Danica J. Sutherland, Michael Arbel, Arthur\n  Gretton", "title": "Demystifying MMD GANs", "comments": "Published at ICLR 2018: https://openreview.net/forum?id=r1lUOzWCW", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the training and performance of generative adversarial\nnetworks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.\nAs our main theoretical contribution, we clarify the situation with bias in GAN\nloss functions raised by recent work: we show that gradient estimators used in\nthe optimization process for both MMD GANs and Wasserstein GANs are unbiased,\nbut learning a discriminator based on samples leads to biased gradients for the\ngenerator parameters. We also discuss the issue of kernel choice for the MMD\ncritic, and characterize the kernel corresponding to the energy distance used\nfor the Cramer GAN critic. Being an integral probability metric, the MMD\nbenefits from training strategies recently developed for Wasserstein GANs. In\nexperiments, the MMD GAN is able to employ a smaller critic network than the\nWasserstein GAN, resulting in a simpler and faster-training algorithm with\nmatching performance. We also propose an improved measure of GAN convergence,\nthe Kernel Inception Distance, and show how to use it to dynamically adapt\nlearning rates during GAN training.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 15:25:26 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 17:58:23 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 16:56:14 GMT"}, {"version": "v4", "created": "Wed, 21 Mar 2018 17:25:27 GMT"}, {"version": "v5", "created": "Thu, 14 Jan 2021 05:36:59 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bi\u0144kowski", "Miko\u0142aj", ""], ["Sutherland", "Danica J.", ""], ["Arbel", "Michael", ""], ["Gretton", "Arthur", ""]]}, {"id": "1801.01423", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, D\\'idac Sur\\'is, Marius Miron, Alexandros Karatzoglou", "title": "Overcoming catastrophic forgetting with hard attention to the task", "comments": "Includes appendix. Accepted for ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting occurs when a neural network loses the information\nlearned in a previous task after training on subsequent tasks. This problem\nremains a hurdle for artificial intelligence systems with sequential learning\ncapabilities. In this paper, we propose a task-based hard attention mechanism\nthat preserves previous tasks' information without affecting the current task's\nlearning. A hard attention mask is learned concurrently to every task, through\nstochastic gradient descent, and previous masks are exploited to condition such\nlearning. We show that the proposed mechanism is effective for reducing\ncatastrophic forgetting, cutting current rates by 45 to 80%. We also show that\nit is robust to different hyperparameter choices, and that it offers a number\nof monitoring capabilities. The approach features the possibility to control\nboth the stability and compactness of the learned knowledge, which we believe\nmakes it also attractive for online learning or network compression\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 16:22:22 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 09:01:55 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 09:00:04 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Sur\u00eds", "D\u00eddac", ""], ["Miron", "Marius", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1801.01432", "submitter": "Charles Schaff", "authors": "Charles Schaff, David Yunis, Ayan Chakrabarti, Matthew R. Walter", "title": "Jointly Learning to Construct and Control Agents using Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physical design of a robot and the policy that controls its motion are\ninherently coupled, and should be determined according to the task and\nenvironment. In an increasing number of applications, data-driven and\nlearning-based approaches, such as deep reinforcement learning, have proven\neffective at designing control policies. For most tasks, the only way to\nevaluate a physical design with respect to such control policies is\nempirical--i.e., by picking a design and training a control policy for it.\nSince training these policies is time-consuming, it is computationally\ninfeasible to train separate policies for all possible designs as a means to\nidentify the best one. In this work, we address this limitation by introducing\na method that performs simultaneous joint optimization of the physical design\nand control network. Our approach maintains a distribution over designs and\nuses reinforcement learning to optimize a control policy to maximize expected\nreward over the design distribution. We give the controller access to design\nparameters to allow it to tailor its policy to each design in the distribution.\nThroughout training, we shift the distribution towards higher-performing\ndesigns, eventually converging to a design and control policy that are jointly\noptimal. We evaluate our approach in the context of legged locomotion, and\ndemonstrate that it discovers novel designs and walking gaits, outperforming\nbaselines in both performance and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 16:39:08 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 17:55:07 GMT"}, {"version": "v3", "created": "Fri, 14 Sep 2018 19:27:56 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Schaff", "Charles", ""], ["Yunis", "David", ""], ["Chakrabarti", "Ayan", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1801.01451", "submitter": "Andrew Kiruluta", "authors": "Andrew Kiruluta", "title": "Reducing Deep Network Complexity with Fourier Transform Methods", "comments": "mistake in tensorflow code with test data leakage into training set\n  leading to model over fitting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel way that uses shallow densely connected neuron network\narchitectures to achieve superior performance to convolution based neural\nnetworks (CNNs) approaches with the added benefits of lower computation burden\nrequiring dramatically less training examples to achieve high prediction\naccuracy ($>98\\%$). The advantages of our proposed method is demonstrated in\nresults on benchmark datasets which show significant performance gain over\nexisting state-of-the-art results on MNIST, CIFAR-10 and CIFAR-100. By Fourier\ntransforming the inputs, each point in the training sample then has a\nrepresentational energy of all the weighted information from every other point.\nThe consequence of using this input is a reduced complexity neuron network,\nreduced computation load and the lifting of the requirement for a large number\nof training examples to achieve high classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 20:30:09 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 12:09:37 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Kiruluta", "Andrew", ""]]}, {"id": "1801.01453", "submitter": "Mark Kibanov", "authors": "Mark Kibanov, Martin Becker, Juergen Mueller, Martin Atzmueller,\n  Andreas Hotho, Gerd Stumme", "title": "Adaptive kNN using Expected Accuracy for Classification of Geo-Spatial\n  Data", "comments": null, "journal-ref": null, "doi": "10.1145/3167132.3167226", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The k-Nearest Neighbor (kNN) classification approach is conceptually simple -\nyet widely applied since it often performs well in practical applications.\nHowever, using a global constant k does not always provide an optimal solution,\ne.g., for datasets with an irregular density distribution of data points. This\npaper proposes an adaptive kNN classifier where k is chosen dynamically for\neach instance (point) to be classified, such that the expected accuracy of\nclassification is maximized. We define the expected accuracy as the accuracy of\na set of structurally similar observations. An arbitrary similarity function\ncan be used to find these observations. We introduce and evaluate different\nsimilarity functions. For the evaluation, we use five different classification\ntasks based on geo-spatial data. Each classification task consists of (tens of)\nthousands of items. We demonstrate, that the presented expected accuracy\nmeasures can be a good estimator for kNN performance, and the proposed adaptive\nkNN classifier outperforms common kNN and previously introduced adaptive kNN\nalgorithms. Also, we show that the range of considered k can be significantly\nreduced to speed up the algorithm without negative influence on classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 14:09:06 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Kibanov", "Mark", ""], ["Becker", "Martin", ""], ["Mueller", "Juergen", ""], ["Atzmueller", "Martin", ""], ["Hotho", "Andreas", ""], ["Stumme", "Gerd", ""]]}, {"id": "1801.01455", "submitter": "Sunrita Poddar", "authors": "Sunrita Poddar, Mathews Jacob", "title": "Clustering of Data with Missing Entries", "comments": "arXiv admin note: substantial text overlap with arXiv:1709.01870", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of large datasets is often complicated by the presence of\nmissing entries, mainly because most of the current machine learning algorithms\nare designed to work with full data. The main focus of this work is to\nintroduce a clustering algorithm, that will provide good clustering even in the\npresence of missing data. The proposed technique solves an $\\ell_0$ fusion\npenalty based optimization problem to recover the clusters. We theoretically\nanalyze the conditions needed for the successful recovery of the clusters. We\nalso propose an algorithm to solve a relaxation of this problem using\nsaturating non-convex fusion penalties. The method is demonstrated on simulated\nand real datasets, and is observed to perform well in the presence of large\nfractions of missing entries.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 15:45:52 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Poddar", "Sunrita", ""], ["Jacob", "Mathews", ""]]}, {"id": "1801.01554", "submitter": "Michael Witbrock", "authors": "Michael Witbrock and Marco Zagha", "title": "An Implementation of Back-Propagation Learning on GF11, a Large SIMD\n  Parallel Computer", "comments": null, "journal-ref": "Witbrock, M., and Zagha, M. (1989). \"An Implementation of\n  Back-Propagation Learning on GF11, a Large SIMD Parallel Computer.\" School of\n  Computer Science, Carnegie Mellon University, Pittsburgh, PA, Technical\n  Report CMU-CS-89-208", "doi": null, "report-no": "CMU-CS-89-208", "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current connectionist simulations require huge computational resources. We\ndescribe a neural network simulator for the IBM GF11, an experimental SIMD\nmachine with 566 processors and a peak arithmetic performance of 11 Gigaflops.\nWe present our parallel implementation of the backpropagation learning\nalgorithm, techniques for increasing efficiency, performance measurements on\nthe NetTalk text-to-speech benchmark, and a performance model for the\nsimulator. Our simulator currently runs the back-propagation learning algorithm\nat 900 million connections per second, where each \"connection per second\"\nincludes both a forward and backward pass. This figure was obtained on the\nmachine when only 356 processors were working; with all 566 processors\noperational, our simulation will run at over one billion connections per\nsecond. We conclude that the GF11 is well-suited to neural network simulation,\nand we analyze our use of the machine to determine which features are the most\nimportant for high performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 21:52:28 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Witbrock", "Michael", ""], ["Zagha", "Marco", ""]]}, {"id": "1801.01586", "submitter": "David Charte", "authors": "David Charte and Francisco Charte and Salvador Garc\\'ia and Mar\\'ia J.\n  del Jesus and Francisco Herrera", "title": "A practical tutorial on autoencoders for nonlinear feature fusion:\n  Taxonomy, models, software and guidelines", "comments": null, "journal-ref": "Information Fusion 44 (2018) 78-96", "doi": "10.1016/j.inffus.2017.12.007", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the existing machine learning algorithms, both supervised and\nunsupervised, depend on the quality of the input characteristics to generate a\ngood model. The amount of these variables is also important, since performance\ntends to decline as the input dimensionality increases, hence the interest in\nusing feature fusion techniques, able to produce feature sets that are more\ncompact and higher level. A plethora of procedures to fuse original variables\nfor producing new ones has been developed in the past decades. The most basic\nones use linear combinations of the original variables, such as PCA (Principal\nComponent Analysis) and LDA (Linear Discriminant Analysis), while others find\nmanifold embeddings of lower dimensionality based on non-linear combinations,\nsuch as Isomap or LLE (Linear Locally Embedding) techniques.\n  More recently, autoencoders (AEs) have emerged as an alternative to manifold\nlearning for conducting nonlinear feature fusion. Dozens of AE models have been\nproposed lately, each with its own specific traits. Although many of them can\nbe used to generate reduced feature sets through the fusion of the original\nones, there also AEs designed with other applications in mind.\n  The goal of this paper is to provide the reader with a broad view of what an\nAE is, how they are used for feature fusion, a taxonomy gathering a broad range\nof models, and how they relate to other classical techniques. In addition, a\nset of didactic guidelines on how to choose the proper AE for a given task is\nsupplied, together with a discussion of the software tools available. Finally,\ntwo case studies illustrate the usage of AEs with datasets of handwritten\ndigits and breast cancer.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 23:51:05 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Charte", "David", ""], ["Charte", "Francisco", ""], ["Garc\u00eda", "Salvador", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "1801.01587", "submitter": "Uri Shaham", "authors": "Uri Shaham, Kelly Stanton, Henry Li, Boaz Nadler, Ronen Basri, Yuval\n  Kluger", "title": "SpectralNet: Spectral Clustering using Deep Neural Networks", "comments": "Added citations. Accepted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering is a leading and popular technique in unsupervised data\nanalysis. Two of its major limitations are scalability and generalization of\nthe spectral embedding (i.e., out-of-sample-extension). In this paper we\nintroduce a deep learning approach to spectral clustering that overcomes the\nabove shortcomings. Our network, which we call SpectralNet, learns a map that\nembeds input data points into the eigenspace of their associated graph\nLaplacian matrix and subsequently clusters them. We train SpectralNet using a\nprocedure that involves constrained stochastic optimization. Stochastic\noptimization allows it to scale to large datasets, while the constraints, which\nare implemented using a special-purpose output layer, allow us to keep the\nnetwork output orthogonal. Moreover, the map learned by SpectralNet naturally\ngeneralizes the spectral embedding to unseen data points. To further improve\nthe quality of the clustering, we replace the standard pairwise Gaussian\naffinities with affinities leaned from unlabeled data using a Siamese network.\nAdditional improvement can be achieved by applying the network to code\nrepresentations produced, e.g., by standard autoencoders. Our end-to-end\nlearning procedure is fully unsupervised. In addition, we apply VC dimension\ntheory to derive a lower bound on the size of SpectralNet. State-of-the-art\nclustering results are reported on the Reuters dataset. Our implementation is\npublicly available at https://github.com/kstant0725/SpectralNet .\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 23:56:36 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 14:06:31 GMT"}, {"version": "v3", "created": "Wed, 31 Jan 2018 21:29:15 GMT"}, {"version": "v4", "created": "Tue, 13 Mar 2018 18:17:10 GMT"}, {"version": "v5", "created": "Thu, 29 Mar 2018 16:20:36 GMT"}, {"version": "v6", "created": "Wed, 4 Apr 2018 12:46:19 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Shaham", "Uri", ""], ["Stanton", "Kelly", ""], ["Li", "Henry", ""], ["Nadler", "Boaz", ""], ["Basri", "Ronen", ""], ["Kluger", "Yuval", ""]]}, {"id": "1801.01594", "submitter": "Ting Wang", "authors": "Xinyang Zhang and Shouling Ji and Ting Wang", "title": "Differentially Private Releasing via Deep Generative Model (Technical\n  Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-preserving releasing of complex data (e.g., image, text, audio)\nrepresents a long-standing challenge for the data mining research community.\nDue to rich semantics of the data and lack of a priori knowledge about the\nanalysis task, excessive sanitization is often necessary to ensure privacy,\nleading to significant loss of the data utility. In this paper, we present\ndp-GAN, a general private releasing framework for semantic-rich data. Instead\nof sanitizing and then releasing the data, the data curator publishes a deep\ngenerative model which is trained using the original data in a differentially\nprivate manner; with the generative model, the analyst is able to produce an\nunlimited amount of synthetic data for arbitrary analysis tasks. In contrast of\nalternative solutions, dp-GAN highlights a set of key features: (i) it provides\ntheoretical privacy guarantee via enforcing the differential privacy principle;\n(ii) it retains desirable utility in the released model, enabling a variety of\notherwise impossible analyses; and (iii) most importantly, it achieves\npractical training scalability and stability by employing multi-fold\noptimization strategies. Through extensive empirical evaluation on benchmark\ndatasets and analyses, we validate the efficacy of dp-GAN.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 00:47:57 GMT"}, {"version": "v2", "created": "Sun, 25 Mar 2018 20:06:43 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhang", "Xinyang", ""], ["Ji", "Shouling", ""], ["Wang", "Ting", ""]]}, {"id": "1801.01596", "submitter": "Jiazhuo Wang", "authors": "Jiazhuo Wang, Jason Xu, Xuejun Wang", "title": "Combination of Hyperband and Bayesian Optimization for Hyperparameter\n  Optimization in Deep Learning", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved impressive results on many problems. However, it\nrequires high degree of expertise or a lot of experience to tune well the\nhyperparameters, and such manual tuning process is likely to be biased.\nMoreover, it is not practical to try out as many different hyperparameter\nconfigurations in deep learning as in other machine learning scenarios, because\nevaluating each single hyperparameter configuration in deep learning would mean\ntraining a deep neural network, which usually takes quite long time. Hyperband\nalgorithm achieves state-of-the-art performance on various hyperparameter\noptimization problems in the field of deep learning. However, Hyperband\nalgorithm does not utilize history information of previous explored\nhyperparameter configurations, thus the solution found is suboptimal. We\npropose to combine Hyperband algorithm with Bayesian optimization (which does\nnot ignore history when sampling next trial configuration). Experimental\nresults show that our combination approach is superior to other hyperparameter\noptimization approaches including Hyperband algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 01:00:03 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Wang", "Jiazhuo", ""], ["Xu", "Jason", ""], ["Wang", "Xuejun", ""]]}, {"id": "1801.01609", "submitter": "Yingzhen Yang", "authors": "Yingzhen Yang, Jianchao Yang, Ning Xu, Wei Han", "title": "Learning $3$D-FilterMap for Deep Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel and compact architecture for deep Convolutional Neural\nNetworks (CNNs) in this paper, termed $3$D-FilterMap Convolutional Neural\nNetworks ($3$D-FM-CNNs). The convolution layer of $3$D-FM-CNN learns a compact\nrepresentation of the filters, named $3$D-FilterMap, instead of a set of\nindependent filters in the conventional convolution layer. The filters are\nextracted from the $3$D-FilterMap as overlapping $3$D submatrics with weight\nsharing among nearby filters, and these filters are convolved with the input to\ngenerate the output of the convolution layer for $3$D-FM-CNN. Due to the weight\nsharing scheme, the parameter size of the $3$D-FilterMap is much smaller than\nthat of the filters to be learned in the conventional convolution layer when\n$3$D-FilterMap generates the same number of filters. Our work is fundamentally\ndifferent from the network compression literature that reduces the size of a\nlearned large network in the sense that a small network is directly learned\nfrom scratch. Experimental results demonstrate that $3$D-FM-CNN enjoys a small\nparameter space by learning compact $3$D-FilterMaps, while achieving\nperformance compared to that of the baseline CNNs which learn the same number\nof filters as that generated by the corresponding $3$D-FilterMap.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 01:52:35 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Yang", "Yingzhen", ""], ["Yang", "Jianchao", ""], ["Xu", "Ning", ""], ["Han", "Wei", ""]]}, {"id": "1801.01681", "submitter": "Zhen Li", "authors": "Zhen Li, Deqing Zou, Shouhuai Xu, Xinyu Ou, Hai Jin, Sujuan Wang,\n  Zhijun Deng, Yuyi Zhong", "title": "VulDeePecker: A Deep Learning-Based System for Vulnerability Detection", "comments": null, "journal-ref": null, "doi": "10.14722/ndss.2018.23158", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic detection of software vulnerabilities is an important research\nproblem. However, existing solutions to this problem rely on human experts to\ndefine features and often miss many vulnerabilities (i.e., incurring high false\nnegative rate). In this paper, we initiate the study of using deep\nlearning-based vulnerability detection to relieve human experts from the\ntedious and subjective task of manually defining features. Since deep learning\nis motivated to deal with problems that are very different from the problem of\nvulnerability detection, we need some guiding principles for applying deep\nlearning to vulnerability detection. In particular, we need to find\nrepresentations of software programs that are suitable for deep learning. For\nthis purpose, we propose using code gadgets to represent programs and then\ntransform them into vectors, where a code gadget is a number of (not\nnecessarily consecutive) lines of code that are semantically related to each\nother. This leads to the design and implementation of a deep learning-based\nvulnerability detection system, called Vulnerability Deep Pecker\n(VulDeePecker). In order to evaluate VulDeePecker, we present the first\nvulnerability dataset for deep learning approaches. Experimental results show\nthat VulDeePecker can achieve much fewer false negatives (with reasonable false\npositives) than other approaches. We further apply VulDeePecker to 3 software\nproducts (namely Xen, Seamonkey, and Libav) and detect 4 vulnerabilities, which\nare not reported in the National Vulnerability Database but were \"silently\"\npatched by the vendors when releasing later versions of these products; in\ncontrast, these vulnerabilities are almost entirely missed by the other\nvulnerability detection systems we experimented with.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 09:37:18 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Li", "Zhen", ""], ["Zou", "Deqing", ""], ["Xu", "Shouhuai", ""], ["Ou", "Xinyu", ""], ["Jin", "Hai", ""], ["Wang", "Sujuan", ""], ["Deng", "Zhijun", ""], ["Zhong", "Yuyi", ""]]}, {"id": "1801.01708", "submitter": "Olivier Gouvert", "authors": "Olivier Gouvert, Thomas Oberlin and C\\'edric F\\'evotte", "title": "Negative Binomial Matrix Factorization for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce negative binomial matrix factorization (NBMF), a matrix\nfactorization technique specially designed for analyzing over-dispersed count\ndata. It can be viewed as an extension of Poisson matrix factorization (PF)\nperturbed by a multiplicative term which models exposure. This term brings a\ndegree of freedom for controlling the dispersion, making NBMF more robust to\noutliers. We show that NBMF allows to skip traditional pre-processing stages,\nsuch as binarization, which lead to loss of information. Two estimation\napproaches are presented: maximum likelihood and variational Bayes inference.\nWe test our model with a recommendation task and show its ability to predict\nuser tastes with better precision than PF.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 11:00:46 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Gouvert", "Olivier", ""], ["Oberlin", "Thomas", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "1801.01750", "submitter": "Melody Guan", "authors": "Melody Y. Guan, Heinrich Jiang", "title": "Nonparametric Stochastic Contextual Bandits", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the $K$-armed bandit problem where the reward for each arm is a\nnoisy realization based on an observed context under mild nonparametric\nassumptions. We attain tight results for top-arm identification and a sublinear\nregret of $\\widetilde{O}\\Big(T^{\\frac{1+D}{2+D}}\\Big)$, where $D$ is the\ncontext dimension, for a modified UCB algorithm that is simple to implement\n($k$NN-UCB). We then give global intrinsic dimension dependent and ambient\ndimension independent regret bounds. We also discuss recovering topological\nstructures within the context space based on expected bandit performance and\nprovide an extension to infinite-armed contextual bandits. Finally, we\nexperimentally show the improvement of our algorithm over existing multi-armed\nbandit approaches for both simulated tasks and MNIST image classification.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 13:27:42 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Guan", "Melody Y.", ""], ["Jiang", "Heinrich", ""]]}, {"id": "1801.01777", "submitter": "Masaya Abe", "authors": "Masaya Abe, Hideki Nakayama", "title": "Deep Learning for Forecasting Stock Returns in the Cross-Section", "comments": "12 pages, 2 figures, 8 tables, accepted at PAKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies have been undertaken by using machine learning techniques,\nincluding neural networks, to predict stock returns. Recently, a method known\nas deep learning, which achieves high performance mainly in image recognition\nand speech recognition, has attracted attention in the machine learning field.\nThis paper implements deep learning to predict one-month-ahead stock returns in\nthe cross-section in the Japanese stock market and investigates the performance\nof the method. Our results show that deep neural networks generally outperform\nshallow neural networks, and the best networks also outperform representative\nmachine learning models. These results indicate that deep learning shows\npromise as a skillful machine learning method to predict stock returns in the\ncross-section.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 23:47:52 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 00:17:25 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 00:28:55 GMT"}, {"version": "v4", "created": "Wed, 13 Jun 2018 00:56:57 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Abe", "Masaya", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1801.01799", "submitter": "Louis Filstroff", "authors": "Louis Filstroff, Alberto Lumbreras, C\\'edric F\\'evotte", "title": "Closed-form Marginal Likelihood in Gamma-Poisson Matrix Factorization", "comments": "Accepted for publication at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel understandings of the Gamma-Poisson (GaP) model, a\nprobabilistic matrix factorization model for count data. We show that GaP can\nbe rewritten free of the score/activation matrix. This gives us new insights\nabout the estimation of the topic/dictionary matrix by maximum marginal\nlikelihood estimation. In particular, this explains the robustness of this\nestimator to over-specified values of the factorization rank, especially its\nability to automatically prune irrelevant dictionary columns, as empirically\nobserved in previous work. The marginalization of the activation matrix leads\nin turn to a new Monte Carlo Expectation-Maximization algorithm with favorable\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 15:50:39 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 11:59:21 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Filstroff", "Louis", ""], ["Lumbreras", "Alberto", ""], ["F\u00e9votte", "C\u00e9dric", ""]]}, {"id": "1801.01875", "submitter": "Mohamed Attia", "authors": "Mohamed A. Attia and Ravi Tandon", "title": "Near Optimal Coded Data Shuffling for Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data shuffling between distributed cluster of nodes is one of the critical\nsteps in implementing large-scale learning algorithms. Randomly shuffling the\ndata-set among a cluster of workers allows different nodes to obtain fresh data\nassignments at each learning epoch. This process has been shown to provide\nimprovements in the learning process. However, the statistical benefits of\ndistributed data shuffling come at the cost of extra communication overhead\nfrom the master node to worker nodes, and can act as one of the major\nbottlenecks in the overall time for computation. There has been significant\nrecent interest in devising approaches to minimize this communication overhead.\nOne approach is to provision for extra storage at the computing nodes. The\nother emerging approach is to leverage coded communication to minimize the\noverall communication overhead.\n  The focus of this work is to understand the fundamental trade-off between the\namount of storage and the communication overhead for distributed data\nshuffling. In this work, we first present an information theoretic formulation\nfor the data shuffling problem, accounting for the underlying problem\nparameters (number of workers, $K$, number of data points, $N$, and the\navailable storage, $S$ per node). We then present an information theoretic\nlower bound on the communication overhead for data shuffling as a function of\nthese parameters. We next present a novel coded communication scheme and show\nthat the resulting communication overhead of the proposed scheme is within a\nmultiplicative factor of at most $\\frac{K}{K-1}$ from the information-theoretic\nlower bound. Furthermore, we present the aligned coded shuffling scheme for\nsome storage values, which achieves the optimal storage vs communication\ntrade-off for $K<5$, and further reduces the maximum multiplicative gap down to\n$\\frac{K-\\frac{1}{3}}{K-1}$, for $K\\geq 5$.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 18:58:24 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Attia", "Mohamed A.", ""], ["Tandon", "Ravi", ""]]}, {"id": "1801.01899", "submitter": "Jun Li", "authors": "Hongfu Liu, Jun Li, Yue Wu and Yun Fu", "title": "Clustering with Outlier Removal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster analysis and outlier detection are strongly coupled tasks in data\nmining area. Cluster structure can be easily destroyed by few outliers; on the\ncontrary, outliers are defined by the concept of cluster, which are recognized\nas the points belonging to none of the clusters. Unfortunately, most existing\nstudies do not notice the coupled relationship between these two task and\nhandle them separately. In light of this, we consider the joint cluster\nanalysis and outlier detection problem, and propose the Clustering with Outlier\nRemoval (COR) algorithm. Generally speaking, the original space is transformed\ninto the binary space via generating basic partitions in order to define\nclusters. Then an objective function based Holoentropy is designed to enhance\nthe compactness of each cluster with a few outliers removed. With further\nanalyses on the objective function, only partial of the problem can be handled\nby K-means optimization. To provide an integrated solution, an auxiliary binary\nmatrix is nontrivally introduced so that COR completely and efficiently solves\nthe challenging problem via a unified K-means-- with theoretical supports.\nExtensive experimental results on numerous data sets in various domains\ndemonstrate the effectiveness and efficiency of COR significantly over\nstate-of-the-art methods in terms of cluster validity and outlier detection.\nSome key factors in COR are further analyzed for practical use. Finally, an\napplication on flight trajectory is provided to demonstrate the effectiveness\nof COR in the real-world scenario.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 19:15:17 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 22:44:16 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Liu", "Hongfu", ""], ["Li", "Jun", ""], ["Wu", "Yue", ""], ["Fu", "Yun", ""]]}, {"id": "1801.01900", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Ruslan Salakhutdinov", "title": "Knowledge-based Word Sense Disambiguation using Topic Models", "comments": "To appear in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word Sense Disambiguation is an open problem in Natural Language Processing\nwhich is particularly challenging and useful in the unsupervised setting where\nall the words in any given text need to be disambiguated without using any\nlabeled data. Typically WSD systems use the sentence or a small window of words\naround the target word as the context for disambiguation because their\ncomputational complexity scales exponentially with the size of the context. In\nthis paper, we leverage the formalism of topic model to design a WSD system\nthat scales linearly with the number of words in the context. As a result, our\nsystem is able to utilize the whole document as the context for a word to be\ndisambiguated. The proposed method is a variant of Latent Dirichlet Allocation\nin which the topic proportions for a document are replaced by synset\nproportions. We further utilize the information in the WordNet by assigning a\nnon-uniform prior to synset distribution over words and a logistic-normal prior\nfor document distribution over synsets. We evaluate the proposed method on\nSenseval-2, Senseval-3, SemEval-2007, SemEval-2013 and SemEval-2015 English\nAll-Word WSD datasets and show that it outperforms the state-of-the-art\nunsupervised knowledge-based WSD system by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 19:20:24 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1801.01944", "submitter": "Nicholas Carlini", "authors": "Nicholas Carlini, David Wagner", "title": "Audio Adversarial Examples: Targeted Attacks on Speech-to-Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct targeted audio adversarial examples on automatic speech\nrecognition. Given any audio waveform, we can produce another that is over\n99.9% similar, but transcribes as any phrase we choose (recognizing up to 50\ncharacters per second of audio). We apply our white-box iterative\noptimization-based attack to Mozilla's implementation DeepSpeech end-to-end,\nand show it has a 100% success rate. The feasibility of this attack introduce a\nnew domain to study adversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 23:40:04 GMT"}, {"version": "v2", "created": "Fri, 30 Mar 2018 02:06:30 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Carlini", "Nicholas", ""], ["Wagner", "David", ""]]}, {"id": "1801.01952", "submitter": "Lior Deutsch", "authors": "Lior Deutsch", "title": "Generating Neural Networks with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypernetworks are neural networks that generate weights for another neural\nnetwork. We formulate the hypernetwork training objective as a compromise\nbetween accuracy and diversity, where the diversity takes into account trivial\nsymmetry transformations of the target network. We explain how this simple\nformulation generalizes variational inference. We use multi-layered perceptrons\nto form the mapping from the low dimensional input random vector to the high\ndimensional weight space, and demonstrate how to reduce the number of\nparameters in this mapping by parameter sharing. We perform experiments and\nshow that the generated weights are diverse and lie on a non-trivial manifold.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 01:27:16 GMT"}, {"version": "v2", "created": "Sat, 17 Feb 2018 21:58:44 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2018 03:51:27 GMT"}, {"version": "v4", "created": "Fri, 6 Apr 2018 19:46:08 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Deutsch", "Lior", ""]]}, {"id": "1801.01953", "submitter": "Martin Gubri", "authors": "Martin Gubri", "title": "Adversarial Perturbation Intensity Achieving Chosen Intra-Technique\n  Transferability Level for Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine Learning models have been shown to be vulnerable to adversarial\nexamples, ie. the manipulation of data by a attacker to defeat a defender's\nclassifier at test time. We present a novel probabilistic definition of\nadversarial examples in perfect or limited knowledge setting using prior\nprobability distributions on the defender's classifier. Using the asymptotic\nproperties of the logistic regression, we derive a closed-form expression of\nthe intensity of any adversarial perturbation, in order to achieve a given\nexpected misclassification rate. This technique is relevant in a threat model\nof known model specifications and unknown training data. To our knowledge, this\nis the first method that allows an attacker to directly choose the probability\nof attack success. We evaluate our approach on two real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 01:37:30 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Gubri", "Martin", ""]]}, {"id": "1801.01959", "submitter": "Wen-Liang Hwang", "authors": "Wen-Liang Hwang, Ping-Tzan Huang, Tai-Lang Jong", "title": "Frame-based Sparse Analysis and Synthesis Signal Representations and\n  Parseval K-SVD", "comments": "32 pages, 31 figures", "journal-ref": null, "doi": "10.1109/TSP.2019.2916105", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frames are the foundation of the linear operators used in the decomposition\nand reconstruction of signals, such as the discrete Fourier transform, Gabor,\nwavelets, and curvelet transforms. The emergence of sparse representation\nmodels has shifted of the emphasis in frame theory toward sparse\nl1-minimization problems. In this paper, we apply frame theory to the sparse\nrepresentation of signals in which a synthesis dictionary is used for a frame\nand an analysis dictionary is used for a dual frame. We sought to formulate a\nnovel dual frame design in which the sparse vector obtained through the\ndecomposition of any signal is also the sparse solution representing signals\nbased on a reconstruction frame. Our findings demonstrate that this type of\ndual frame cannot be constructed for over-complete frames, thereby precluding\nthe use of any linear analysis operator in driving the sparse synthesis\ncoefficient for signal representation. Nonetheless, the best approximation to\nthe sparse synthesis solution can be derived from the analysis coefficient\nusing the canonical dual frame. In this study, we developed a novel dictionary\nlearning algorithm (called Parseval K-SVD) to learn a tight-frame dictionary.\nWe then leveraged the analysis and synthesis perspectives of signal\nrepresentation with frames to derive optimization formulations for problems\npertaining to image recovery. Our preliminary, results demonstrate that the\nimages recovered using this approach are correlated to the frame bounds of\ndictionaries, thereby demonstrating the importance of using different\ndictionaries for different applications.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 03:31:20 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Hwang", "Wen-Liang", ""], ["Huang", "Ping-Tzan", ""], ["Jong", "Tai-Lang", ""]]}, {"id": "1801.01968", "submitter": "Daichi Nishio", "authors": "Daichi Nishio and Satoshi Yamane", "title": "Faster Deep Q-learning using Neural Episodic Control", "comments": "6 pages, 6 figures, COMPSAC2018 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on deep reinforcement learning which estimates Q-value by deep\nlearning has been attracted the interest of researchers recently. In deep\nreinforcement learning, it is important to efficiently learn the experiences\nthat an agent has collected by exploring environment. We propose NEC2DQN that\nimproves learning speed of a poor sample efficiency algorithm such as DQN by\nusing good one such as NEC at the beginning of learning. We show it is able to\nlearn faster than Double DQN or N-step DQN in the experiments of Pong.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 05:17:49 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 07:38:46 GMT"}, {"version": "v3", "created": "Thu, 1 Feb 2018 14:52:53 GMT"}, {"version": "v4", "created": "Sun, 3 Jun 2018 05:29:45 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Nishio", "Daichi", ""], ["Yamane", "Satoshi", ""]]}, {"id": "1801.01973", "submitter": "Shane Barratt", "authors": "Shane Barratt, Rishi Sharma", "title": "A Note on the Inception Score", "comments": "Proc. ICML 2018 Workshop on Theoretical Foundations and Applications\n  of Deep Generative Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are powerful tools that have produced impressive\nresults in recent years. These advances have been for the most part empirically\ndriven, making it essential that we use high quality evaluation metrics. In\nthis paper, we provide new insights into the Inception Score, a recently\nproposed and widely used evaluation metric for generative models, and\ndemonstrate that it fails to provide useful guidance when comparing models. We\ndiscuss both suboptimalities of the metric itself and issues with its\napplication. Finally, we call for researchers to be more systematic and careful\nwhen evaluating and comparing generative models, as the advancement of the\nfield depends upon it.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 05:44:29 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 14:54:33 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Barratt", "Shane", ""], ["Sharma", "Rishi", ""]]}, {"id": "1801.02124", "submitter": "Xingyu Wang", "authors": "Xingyu Wang, Diego Klabjan", "title": "Competitive Multi-agent Inverse Reinforcement Learning with Sub-optimal\n  Demonstrations", "comments": "31 pages, to be presented at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of inverse reinforcement learning in\nzero-sum stochastic games when expert demonstrations are known to be not\noptimal. Compared to previous works that decouple agents in the game by\nassuming optimality in expert strategies, we introduce a new objective function\nthat directly pits experts against Nash Equilibrium strategies, and we design\nan algorithm to solve for the reward function in the context of inverse\nreinforcement learning with deep neural networks as model approximations. In\nour setting the model and algorithm do not decouple by agent. In order to find\nNash Equilibrium in large-scale games, we also propose an adversarial training\nalgorithm for zero-sum stochastic games, and show the theoretical appeal of\nnon-existence of local optima in its objective function. In our numerical\nexperiments, we demonstrate that our Nash Equilibrium and inverse reinforcement\nlearning algorithms address games that are not amenable to previous approaches\nusing tabular representations. Moreover, with sub-optimal expert demonstrations\nour algorithms recover both reward functions and strategies with good quality.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 03:53:30 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 23:01:54 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Wang", "Xingyu", ""], ["Klabjan", "Diego", ""]]}, {"id": "1801.02125", "submitter": "Tsuyoshi Kato", "authors": "Yuya Onuma, Rachelle Rivero, Tsuyoshi Kato", "title": "Threshold Auto-Tuning Metric Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been reported repeatedly that discriminative learning of distance\nmetric boosts the pattern recognition performance. A weak point of ITML-based\nmethods is that the distance threshold for similarity/dissimilarity constraints\nmust be determined manually and it is sensitive to generalization performance,\nalthough the ITML-based methods enjoy an advantage that the Bregman projection\nframework can be applied for optimization of distance metric. In this paper, we\npresent a new formulation of metric learning algorithm in which the distance\nthreshold is optimized together. Since the optimization is still in the Bregman\nprojection framework, the Dykstra algorithm can be applied for optimization. A\nnonlinear equation has to be solved to project the solution onto a half-space\nin each iteration. Na\\\"{i}ve method takes $O(LMn^{3})$ computational time to\nsolve the nonlinear equation. In this study, an efficient technique that can\nsolve the nonlinear equation in $O(Mn^{3})$ has been discovered. We have proved\nthat the root exists and is unique. We empirically show that the accuracy of\npattern recognition for the proposed metric learning algorithm is comparable to\nthe existing metric learning methods, yet the distance threshold is\nautomatically tuned for the proposed metric learning algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 04:01:24 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 03:20:43 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Onuma", "Yuya", ""], ["Rivero", "Rachelle", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "1801.02143", "submitter": "Zhiyong Cui", "authors": "Zhiyong Cui, Ruimin Ke, Ziyuan Pu, and Yinhai Wang", "title": "Deep Bidirectional and Unidirectional LSTM Recurrent Neural Network for\n  Network-wide Traffic Speed Prediction", "comments": "International Workshop on Urban Computing (UrbComp) 2017, Held in\n  conjunction with the ACM SIGKDD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term traffic forecasting based on deep learning methods, especially\nlong short-term memory (LSTM) neural networks, has received much attention in\nrecent years. However, the potential of deep learning methods in traffic\nforecasting has not yet fully been exploited in terms of the depth of the model\narchitecture, the spatial scale of the prediction area, and the predictive\npower of spatial-temporal data. In this paper, a deep stacked bidirectional and\nunidirectional LSTM (SBU- LSTM) neural network architecture is proposed, which\nconsiders both forward and backward dependencies in time series data, to\npredict network-wide traffic speed. A bidirectional LSTM (BDLSM) layer is\nexploited to capture spatial features and bidirectional temporal dependencies\nfrom historical data. To the best of our knowledge, this is the first time that\nBDLSTMs have been applied as building blocks for a deep architecture model to\nmeasure the backward dependency of traffic data for prediction. The proposed\nmodel can handle missing values in input data by using a masking mechanism.\nFurther, this scalable model can predict traffic speed for both freeway and\ncomplex urban traffic networks. Comparisons with other classical and\nstate-of-the-art models indicate that the proposed SBU-LSTM neural network\nachieves superior prediction performance for the whole traffic network in both\naccuracy and robustness.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 06:06:31 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2019 08:36:48 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Cui", "Zhiyong", ""], ["Ke", "Ruimin", ""], ["Pu", "Ziyuan", ""], ["Wang", "Yinhai", ""]]}, {"id": "1801.02144", "submitter": "Truong Son Hy", "authors": "Risi Kondor, Hy Truong Son, Horace Pan, Brandon Anderson, Shubhendu\n  Trivedi", "title": "Covariant Compositional Networks For Learning Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing neural networks for learning graphs address permutation\ninvariance by conceiving of the network as a message passing scheme, where each\nnode sums the feature vectors coming from its neighbors. We argue that this\nimposes a limitation on their representation power, and instead propose a new\ngeneral architecture for representing objects consisting of a hierarchy of\nparts, which we call Covariant Compositional Networks (CCNs). Here, covariance\nmeans that the activation of each neuron must transform in a specific way under\npermutations, similarly to steerability in CNNs. We achieve covariance by\nmaking each activation transform according to a tensor representation of the\npermutation group, and derive the corresponding tensor aggregation rules that\neach neuron must implement. Experiments show that CCNs can outperform competing\nmethods on standard graph learning benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 06:14:55 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Kondor", "Risi", ""], ["Son", "Hy Truong", ""], ["Pan", "Horace", ""], ["Anderson", "Brandon", ""], ["Trivedi", "Shubhendu", ""]]}, {"id": "1801.02149", "submitter": "Amirreza Mahdavi-Shahri", "authors": "Amirreza Mahdavi-Shahri, Mahboobeh Houshmand, Mahdi Yaghoobi, Mehrdad\n  Jalali", "title": "Applying an Ensemble Learning Method for Improving Multi-label\n  Classification Performance", "comments": null, "journal-ref": null, "doi": "10.1109/ICSPIS.2016.7869900", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, multi-label classification problem has become a\ncontroversial issue. In this kind of classification, each sample is associated\nwith a set of class labels. Ensemble approaches are supervised learning\nalgorithms in which an operator takes a number of learning algorithms, namely\nbase-level algorithms and combines their outcomes to make an estimation. The\nsimplest form of ensemble learning is to train the base-level algorithms on\nrandom subsets of data and then let them vote for the most popular\nclassifications or average the predictions of the base-level algorithms. In\nthis study, an ensemble learning method is proposed for improving multi-label\nclassification evaluation criteria. We have compared our method with well-known\nbase-level algorithms on some data sets. Experiment results show the proposed\napproach outperforms the base well-known classifiers for the multi-label\nclassification problem.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 06:43:46 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Mahdavi-Shahri", "Amirreza", ""], ["Houshmand", "Mahboobeh", ""], ["Yaghoobi", "Mahdi", ""], ["Jalali", "Mehrdad", ""]]}, {"id": "1801.02190", "submitter": "Stylianos Venieris", "authors": "Michalis Rizakis, Stylianos I. Venieris, Alexandros Kouris and\n  Christos-Savvas Bouganis", "title": "Approximate FPGA-based LSTMs under Computation Time Constraints", "comments": "Accepted at the 14th International Symposium in Applied\n  Reconfigurable Computing (ARC) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM)\nnetworks have demonstrated state-of-the-art accuracy in several emerging\nArtificial Intelligence tasks. However, the models are becoming increasingly\ndemanding in terms of computational and memory load. Emerging latency-sensitive\napplications including mobile robots and autonomous vehicles often operate\nunder stringent computation time constraints. In this paper, we address the\nchallenge of deploying computationally demanding LSTMs at a constrained time\nbudget by introducing an approximate computing scheme that combines iterative\nlow-rank compression and pruning, along with a novel FPGA-based LSTM\narchitecture. Combined in an end-to-end framework, the approximation method's\nparameters are optimised and the architecture is configured to address the\nproblem of high-performance LSTM execution in time-constrained applications.\nQuantitative evaluation on a real-life image captioning application indicates\nthat the proposed methods required up to 6.5x less time to achieve the same\napplication-level accuracy compared to a baseline method, while achieving an\naverage of 25x higher accuracy under the same computation time constraints.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 13:46:03 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Rizakis", "Michalis", ""], ["Venieris", "Stylianos I.", ""], ["Kouris", "Alexandros", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1801.02209", "submitter": "Yi Wu", "authors": "Yi Wu, Yuxin Wu, Georgia Gkioxari, Yuandong Tian", "title": "Building Generalizable Agents with a Realistic and Rich 3D Environment", "comments": "updated with improved content and more experinemnts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching an agent to navigate in an unseen 3D environment is a challenging\ntask, even in the event of simulated environments. To generalize to unseen\nenvironments, an agent needs to be robust to low-level variations (e.g. color,\ntexture, object changes), and also high-level variations (e.g. layout changes\nof the environment). To improve overall generalization, all types of variations\nin the environment have to be taken under consideration via different level of\ndata augmentation steps. To this end, we propose House3D, a rich, extensible\nand efficient environment that contains 45,622 human-designed 3D scenes of\nvisually realistic houses, ranging from single-room studios to multi-storied\nhouses, equipped with a diverse set of fully labeled 3D objects, textures and\nscene layouts, based on the SUNCG dataset (Song et.al.). The diversity in\nHouse3D opens the door towards scene-level augmentation, while the label-rich\nnature of House3D enables us to inject pixel- & task-level augmentations such\nas domain randomization (Toubin et. al.) and multi-task training. Using a\nsubset of houses in House3D, we show that reinforcement learning agents trained\nwith an enhancement of different levels of augmentations perform much better in\nunseen environments than our baselines with raw RGB input by over 8% in terms\nof navigation success rate. House3D is publicly available at\nhttp://github.com/facebookresearch/House3D.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 16:34:41 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 22:09:00 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Wu", "Yi", ""], ["Wu", "Yuxin", ""], ["Gkioxari", "Georgia", ""], ["Tian", "Yuandong", ""]]}, {"id": "1801.02227", "submitter": "Atsushi Nitanda", "authors": "Atsushi Nitanda and Taiji Suzuki", "title": "Gradient Layer: Enhancing the Convergence of Adversarial Training for\n  Generative Models", "comments": "14 pages, 4 figures, AISTATS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new technique that boosts the convergence of training generative\nadversarial networks. Generally, the rate of training deep models reduces\nseverely after multiple iterations. A key reason for this phenomenon is that a\ndeep network is expressed using a highly non-convex finite-dimensional model,\nand thus the parameter gets stuck in a local optimum. Because of this, methods\noften suffer not only from degeneration of the convergence speed but also from\nlimitations in the representational power of the trained network. To overcome\nthis issue, we propose an additional layer called the gradient layer to seek a\ndescent direction in an infinite-dimensional space. Because the layer is\nconstructed in the infinite-dimensional space, we are not restricted by the\nspecific model structure of finite-dimensional models. As a result, we can get\nout of the local optima in finite-dimensional models and move towards the\nglobal optimal function more directly. In this paper, this phenomenon is\nexplained from the functional gradient method perspective of the gradient\nlayer. Interestingly, the optimization procedure using the gradient layer\nnaturally constructs the deep structure of the network. Moreover, we\ndemonstrate that this procedure can be regarded as a discretization method of\nthe gradient flow that naturally reduces the objective function. Finally, the\nmethod is tested using several numerical experiments, which show its fast\nconvergence.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 18:44:10 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 10:48:55 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Nitanda", "Atsushi", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1801.02251", "submitter": "Siwei Feng", "authors": "Siwei Feng and Marco F.Duarte", "title": "Graph Autoencoder-Based Unsupervised Feature Selection with Broad and\n  Local Data Structure Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is a dimensionality reduction technique that selects a\nsubset of representative features from high dimensional data by eliminating\nirrelevant and redundant features. Recently, feature selection combined with\nsparse learning has attracted significant attention due to its outstanding\nperformance compared with traditional feature selection methods that ignores\ncorrelation between features. These works first map data onto a low-dimensional\nsubspace and then select features by posing a sparsity constraint on the\ntransformation matrix. However, they are restricted by design to linear data\ntransformation, a potential drawback given that the underlying correlation\nstructures of data are often non-linear. To leverage a more sophisticated\nembedding, we propose an autoencoder-based unsupervised feature selection\napproach that leverages a single-layer autoencoder for a joint framework of\nfeature selection and manifold learning. More specifically, we enforce column\nsparsity on the weight matrix connecting the input layer and the hidden layer,\nas in previous work. Additionally, we include spectral graph analysis on the\nprojected data into the learning process to achieve local data geometry\npreservation from the original data space to the low-dimensional feature space.\nExtensive experiments are conducted on image, audio, text, and biological data.\nThe promising experimental results validate the superiority of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 21:14:01 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 03:14:38 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Feng", "Siwei", ""], ["Duarte", "Marco F.", ""]]}, {"id": "1801.02254", "submitter": "Qianli Liao", "authors": "Chiyuan Zhang, Qianli Liao, Alexander Rakhlin, Brando Miranda, Noah\n  Golowich, Tomaso Poggio", "title": "Theory of Deep Learning IIb: Optimization Properties of SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Theory IIb we characterize with a mix of theory and experiments the\noptimization of deep convolutional networks by Stochastic Gradient Descent. The\nmain new result in this paper is theoretical and experimental evidence for the\nfollowing conjecture about SGD: SGD concentrates in probability -- like the\nclassical Langevin equation -- on large volume, \"flat\" minima, selecting flat\nminimizers which are with very high probability also global minimizers\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 21:43:28 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Liao", "Qianli", ""], ["Rakhlin", "Alexander", ""], ["Miranda", "Brando", ""], ["Golowich", "Noah", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1801.02257", "submitter": "Joani Mitro", "authors": "John Mitro and Derek Bridge and Steven Prestwich", "title": "Denoising Dictionary Learning Against Adversarial Perturbations", "comments": "8 pages, 10 figures, aaai18 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose denoising dictionary learning (DDL), a simple yet effective\ntechnique as a protection measure against adversarial perturbations. We\nexamined denoising dictionary learning on MNIST and CIFAR10 perturbed under two\ndifferent perturbation techniques, fast gradient sign (FGSM) and jacobian\nsaliency maps (JSMA). We evaluated it against five different deep neural\nnetworks (DNN) representing the building blocks of most recent architectures\nindicating a successive progression of model complexity of each other. We show\nthat each model tends to capture different representations based on their\narchitecture. For each model we recorded its accuracy both on the perturbed\ntest data previously misclassified with high confidence and on the denoised one\nafter the reconstruction using dictionary learning. The reconstruction quality\nof each data point is assessed by means of PSNR (Peak Signal to Noise Ratio)\nand Structure Similarity Index (SSI). We show that after applying (DDL) the\nreconstruction of the original data point from a noisy\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 22:03:20 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Mitro", "John", ""], ["Bridge", "Derek", ""], ["Prestwich", "Steven", ""]]}, {"id": "1801.02261", "submitter": "Avi Ben-Cohen", "authors": "Avi Ben-Cohen, Eyal Klang, Michal Marianne Amitai, Jacob Goldberger,\n  Hayit Greenspan", "title": "Anatomical Data Augmentation For CNN based Pixel-wise Classification", "comments": "To be presented at IEEE ISBI 2018", "journal-ref": null, "doi": "10.1109/ISBI.2018.8363762", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a method for anatomical data augmentation that is\nbased on using slices of computed tomography (CT) examinations that are\nadjacent to labeled slices as another resource of labeled data for training the\nnetwork. The extended labeled data is used to train a U-net network for a\npixel-wise classification into different hepatic lesions and normal liver\ntissues. Our dataset contains CT examinations from 140 patients with 333 CT\nimages annotated by an expert radiologist. We tested our approach and compared\nit to the conventional training process. Results indicate superiority of our\nmethod. Using the anatomical data augmentation we achieved an improvement of 3%\nin the success rate, 5% in the classification accuracy, and 4% in Dice.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 23:00:02 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ben-Cohen", "Avi", ""], ["Klang", "Eyal", ""], ["Amitai", "Michal Marianne", ""], ["Goldberger", "Jacob", ""], ["Greenspan", "Hayit", ""]]}, {"id": "1801.02268", "submitter": "Benjamin Spector", "authors": "Benjamin Spector, Serge Belongie", "title": "Sample-Efficient Reinforcement Learning through Transfer and\n  Architectural Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in deep reinforcement learning has allowed algorithms to learn\ncomplex tasks such as Atari 2600 games just from the reward provided by the\ngame, but these algorithms presently require millions of training steps in\norder to learn, making them approximately five orders of magnitude slower than\nhumans. One reason for this is that humans build robust shared representations\nthat are applicable to collections of problems, making it much easier to\nassimilate new variants. This paper first introduces the idea of\nautomatically-generated game sets to aid in transfer learning research, and\nthen demonstrates the utility of shared representations by showing that models\ncan substantially benefit from the incorporation of relevant architectural\npriors. This technique affords a remarkable 50x positive transfer on a toy\nproblem-set.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 23:13:29 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Spector", "Benjamin", ""], ["Belongie", "Serge", ""]]}, {"id": "1801.02294", "submitter": "Han Zhu", "authors": "Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, Kun Gai", "title": "Learning Tree-based Deep Model for Recommender Systems", "comments": "Accepted by KDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3219826", "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based methods for recommender systems have been studied extensively in\nrecent years. In systems with large corpus, however, the calculation cost for\nthe learnt model to predict all user-item preferences is tremendous, which\nmakes full corpus retrieval extremely difficult. To overcome the calculation\nbarriers, models such as matrix factorization resort to inner product form\n(i.e., model user-item preference as the inner product of user, item latent\nfactors) and indexes to facilitate efficient approximate k-nearest neighbor\nsearches. However, it still remains challenging to incorporate more expressive\ninteraction forms between user and item features, e.g., interactions through\ndeep neural networks, because of the calculation cost.\n  In this paper, we focus on the problem of introducing arbitrary advanced\nmodels to recommender systems with large corpus. We propose a novel tree-based\nmethod which can provide logarithmic complexity w.r.t. corpus size even with\nmore expressive models such as deep neural networks. Our main idea is to\npredict user interests from coarse to fine by traversing tree nodes in a\ntop-down fashion and making decisions for each user-node pair. We also show\nthat the tree structure can be jointly learnt towards better compatibility with\nusers' interest distribution and hence facilitate both training and prediction.\nExperimental evaluations with two large-scale real-world datasets show that the\nproposed method significantly outperforms traditional methods. Online A/B test\nresults in Taobao display advertising platform also demonstrate the\neffectiveness of the proposed method in production environments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 02:52:20 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 11:13:21 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 07:40:07 GMT"}, {"version": "v4", "created": "Thu, 1 Nov 2018 04:37:55 GMT"}, {"version": "v5", "created": "Fri, 21 Dec 2018 03:15:54 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Zhu", "Han", ""], ["Li", "Xiang", ""], ["Zhang", "Pengye", ""], ["Li", "Guozheng", ""], ["He", "Jie", ""], ["Li", "Han", ""], ["Gai", "Kun", ""]]}, {"id": "1801.02318", "submitter": "Li Chen", "authors": "Li Chen, Salmin Sultana, Ravi Sahita", "title": "HeNet: A Deep Learning Approach on Intel$^\\circledR$ Processor Trace for\n  Effective Exploit Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents HeNet, a hierarchical ensemble neural network, applied to\nclassify hardware-generated control flow traces for malware detection. Deep\nlearning-based malware detection has so far focused on analyzing executable\nfiles and runtime API calls. Static code analysis approaches face challenges\ndue to obfuscated code and adversarial perturbations. Behavioral data collected\nduring execution is more difficult to obfuscate but recent research has shown\nsuccessful attacks against API call based malware classifiers. We investigate\ncontrol flow based characterization of a program execution to build robust deep\nlearning malware classifiers. HeNet consists of a low-level behavior model and\na top-level ensemble model. The low-level model is a per-application behavior\nmodel, trained via transfer learning on a time-series of images generated from\ncontrol flow trace of an execution. We use Intel$^\\circledR$ Processor Trace\nenabled processor for low overhead execution tracing and design a lightweight\nimage conversion and segmentation of the control flow trace. The top-level\nensemble model aggregates the behavior classification of all the trace segments\nand detects an attack. The use of hardware trace adds portability to our system\nand the use of deep learning eliminates the manual effort of feature\nengineering. We evaluate HeNet against real-world exploitations of PDF readers.\nHeNet achieves 100\\% accuracy and 0\\% false positive on test set, and higher\nclassification accuracy compared to classical machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 06:34:40 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Chen", "Li", ""], ["Sultana", "Salmin", ""], ["Sahita", "Ravi", ""]]}, {"id": "1801.02321", "submitter": "Daniel Schmidt Dr", "authors": "Daniel F. Schmidt and Enes Makalic", "title": "Log-Scale Shrinkage Priors and Adaptive Bayesian Global-Local Shrinkage\n  Estimation", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global-local shrinkage hierarchies are an important innovation in Bayesian\nestimation. We propose the use of log-scale distributions as a novel basis for\ngenerating familes of prior distributions for local shrinkage hyperparameters.\nBy varying the scale parameter one may vary the degree to which the prior\ndistribution promotes sparsity in the coefficient estimates. By examining the\nclass of distributions over the logarithm of the local shrinkage parameter that\nhave log-linear, or sub-log-linear tails, we show that many standard prior\ndistributions for local shrinkage parameters can be unified in terms of the\ntail behaviour and concentration properties of their corresponding marginal\ndistributions over the coefficients $\\beta_j$. We derive upper bounds on the\nrate of concentration around $|\\beta_j|=0$, and the tail decay as $|\\beta_j|\n\\to \\infty$, achievable by this wide class of prior distributions.\n  We then propose a new type of ultra-heavy tailed prior, called the log-$t$\nprior with the property that, irrespective of the choice of associated scale\nparameter, the marginal distribution always diverges at $\\beta_j = 0$, and\nalways possesses super-Cauchy tails. We develop results demonstrating when\nprior distributions with (sub)-log-linear tails attain Kullback--Leibler\nsuper-efficiency and prove that the log-$t$ prior distribution is always\nsuper-efficient. We show that the log-$t$ prior is less sensitive to\nmisspecification of the global shrinkage parameter than the horseshoe or lasso\npriors. By incorporating the scale parameter of the log-scale prior\ndistributions into the Bayesian hierarchy we derive novel adaptive shrinkage\nprocedures. Simulations show that the adaptive log-$t$ procedure appears to\nalways perform well, irrespective of the level of sparsity or signal-to-noise\nratio of the underlying model.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 06:44:37 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 12:55:08 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Schmidt", "Daniel F.", ""], ["Makalic", "Enes", ""]]}, {"id": "1801.02328", "submitter": "Yu Cheng", "authors": "Yu Cheng, Angus Wong, Kevin Hung, Zhizhong Li, Weitong Li, Jun Zhang", "title": "Deep Nearest Class Mean Model for Incremental Odor Classification", "comments": "17 pages, 6 figures", "journal-ref": "IEEE Transactions on Instrumentation and Measurement ( Volume: 68\n  , Issue: 4 , April 2019 ) 952 - 962", "doi": "10.1109/TIM.2018.2863438", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, more machine learning algorithms have been applied to odor\nclassification. These odor classification algorithms usually assume that the\ntraining datasets are static. However, for some odor recognition tasks, new\nodor classes continually emerge. That is, the odor datasets are dynamically\ngrowing while both training samples and number of classes are increasing over\ntime. Motivated by this concern, this paper proposes a Deep Nearest Class Mean\n(DNCM) model based on the deep learning framework and nearest class mean\nmethod. The proposed model not only leverages deep neural network to extract\ndeep features, but is also able to dynamically integrate new classes over time.\nIn our experiments, the DNCM model was initially trained with 10 classes, then\n25 new classes are integrated. Experiment results demonstrate that the proposed\nmodel is very efficient for incremental odor classification, especially for new\nclasses with only a small number of training examples.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 07:46:31 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 01:19:47 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Cheng", "Yu", ""], ["Wong", "Angus", ""], ["Hung", "Kevin", ""], ["Li", "Zhizhong", ""], ["Li", "Weitong", ""], ["Zhang", "Jun", ""]]}, {"id": "1801.02330", "submitter": "Mouhammd Alkasassbeh", "authors": "Mohammad Almseidin, Maen Alzubi, Szilveszter Kovacs and Mouhammd\n  Alkasassbeh", "title": "Evaluation of Machine Learning Algorithms for Intrusion Detection System", "comments": null, "journal-ref": "Intelligent Systems and Informatics (SISY), 2017 IEEE 15th\n  International Symposium", "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection system (IDS) is one of the implemented solutions against\nharmful attacks. Furthermore, attackers always keep changing their tools and\ntechniques. However, implementing an accepted IDS system is also a challenging\ntask. In this paper, several experiments have been performed and evaluated to\nassess various machine learning classifiers based on KDD intrusion dataset. It\nsucceeded to compute several performance metrics in order to evaluate the\nselected classifiers. The focus was on false negative and false positive\nperformance metrics in order to enhance the detection rate of the intrusion\ndetection system. The implemented experiments demonstrated that the decision\ntable classifier achieved the lowest value of false negative while the random\nforest classifier has achieved the highest average accuracy rate.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 07:54:53 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Almseidin", "Mohammad", ""], ["Alzubi", "Maen", ""], ["Kovacs", "Szilveszter", ""], ["Alkasassbeh", "Mouhammd", ""]]}, {"id": "1801.02363", "submitter": "Michele Amoretti", "authors": "Davide Ferrari and Michele Amoretti", "title": "Efficient and Effective Quantum Compiling for Entanglement-based Machine\n  Learning on IBM Q Devices", "comments": "14 pages, 13 figures", "journal-ref": "International Journal of Quantum Information 16 (08), 1840006,\n  2018", "doi": "10.1142/S0219749918400063", "report-no": null, "categories": "quant-ph cs.DS cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum compiling means fast, device-aware implementation of quantum\nalgorithms (i.e., quantum circuits, in the quantum circuit model of\ncomputation). In this paper, we present a strategy for compiling IBM Q -aware,\nlow-depth quantum circuits that generate Greenberger-Horne-Zeilinger (GHZ)\nentangled states. The resulting compiler can replace the QISKit compiler for\nthe specific purpose of obtaining improved GHZ circuits. It is well known that\nGHZ states have several practical applications, including quantum machine\nlearning. We illustrate our experience in implementing and querying a uniform\nquantum example oracle based on the GHZ circuit, for solving the classically\nhard problem of learning parity with noise.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 10:06:53 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 09:23:09 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 15:36:18 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Ferrari", "Davide", ""], ["Amoretti", "Michele", ""]]}, {"id": "1801.02384", "submitter": "Rafael Valle", "authors": "Wilson Cai, Anish Doshi, Rafael Valle", "title": "Attacking Speaker Recognition With Deep Generative Models", "comments": "5 pages, 3 Figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the ability of generative adversarial networks\n(GANs) to synthesize spoofing attacks on modern speaker recognition systems. We\nfirst show that samples generated with SampleRNN and WaveNet are unable to fool\na CNN-based speaker recognition system. We propose a modification of the\nWasserstein GAN objective function to make use of data that is real but not\nfrom the class being learned. Our semi-supervised learning method is able to\nperform both targeted and untargeted attacks, raising questions related to\nsecurity in speaker authentication systems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 11:17:56 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Cai", "Wilson", ""], ["Doshi", "Anish", ""], ["Valle", "Rafael", ""]]}, {"id": "1801.02474", "submitter": "Meysam Golmohammadi", "authors": "Silvia Lopez, Aaron Gross, Scott Yang, Meysam Golmohammadi, Iyad Obeid\n  and Joseph Picone", "title": "An Analysis of Two Common Reference Points for EEGs", "comments": "Published In IEEE Signal Processing in Medicine and Biology\n  Symposium. Philadelphia, Pennsylvania, USA", "journal-ref": "S. Lopez, A. Gross, S. Yang, M. Golmohammadi, I. Obeid and J.\n  Picone, \"An analysis of two common reference points for EEGS,\" 2016 IEEE\n  Signal Processing in Medicine and Biology Symposium (SPMB), Philadelphia, PA,\n  2016, pp. 1-5", "doi": "10.1109/SPMB.2016.7846854", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical electroencephalographic (EEG) data varies significantly depending on\na number of operational conditions (e.g., the type and placement of electrodes,\nthe type of electrical grounding used). This investigation explores the\nstatistical differences present in two different referential montages: Linked\nEar (LE) and Averaged Reference (AR). Each of these accounts for approximately\n45% of the data in the TUH EEG Corpus. In this study, we explore the impact\nthis variability has on machine learning performance. We compare the\nstatistical properties of features generated using these two montages, and\nexplore the impact of performance on our standard Hidden Markov Model (HMM)\nbased classification system. We show that a system trained on LE data\nsignificantly outperforms one trained only on AR data (77.2% vs. 61.4%). We\nalso demonstrate that performance of a system trained on both data sets is\nsomewhat compromised (71.4% vs. 77.2%). A statistical analysis of the data\nsuggests that mean, variance and channel normalization should be considered.\nHowever, cepstral mean subtraction failed to produce an improvement in\nperformance, suggesting that the impact of these statistical differences is\nsubtler.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 01:37:45 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Lopez", "Silvia", ""], ["Gross", "Aaron", ""], ["Yang", "Scott", ""], ["Golmohammadi", "Meysam", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1801.02476", "submitter": "Meysam Golmohammadi", "authors": "Scott Yang, Silvia Lopez, Meysam Golmohammadi, Iyad Obeid and Joseph\n  Picone", "title": "Semi-automated Annotation of Signal Events in Clinical EEG Data", "comments": "Published in IEEE Signal Processing in Medicine and Biology\n  Symposium. Philadelphia, Pennsylvania, USA", "journal-ref": "S. Yang, S. Lopez, M. Golmohammadi, I. Obeid and J. Picone,\n  \"Semi-automated annotation of signal events in clinical EEG data,\" 2016 IEEE\n  Signal Processing in Medicine and Biology Symposium (SPMB), Philadelphia, PA,\n  2016, pp. 1-5", "doi": "10.1109/SPMB.2016.7846855", "report-no": null, "categories": "eess.SP cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To be effective, state of the art machine learning technology needs large\namounts of annotated data. There are numerous compelling applications in\nhealthcare that can benefit from high performance automated decision support\nsystems provided by deep learning technology, but they lack the comprehensive\ndata resources required to apply sophisticated machine learning models.\nFurther, for economic reasons, it is very difficult to justify the creation of\nlarge annotated corpora for these applications. Hence, automated annotation\ntechniques become increasingly important. In this study, we investigated the\neffectiveness of using an active learning algorithm to automatically annotate a\nlarge EEG corpus. The algorithm is designed to annotate six types of EEG\nevents. Two model training schemes, namely threshold-based and volume-based,\nare evaluated. In the threshold-based scheme the threshold of confidence scores\nis optimized in the initial training iteration, whereas for the volume-based\nscheme only a certain amount of data is preserved after each iteration.\nRecognition performance is improved 2% absolute and the system is capable of\nautomatically annotating previously unlabeled data. Given that the\ninterpretation of clinical EEG data is an exceedingly difficult task, this\nstudy provides some evidence that the proposed method is a viable alternative\nto expensive manual annotation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 03:47:20 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Yang", "Scott", ""], ["Lopez", "Silvia", ""], ["Golmohammadi", "Meysam", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1801.02567", "submitter": "Enrique Romero", "authors": "Enrique Romero Merino and Ferran Mazzanti Castrillejo and Jordi\n  Delgado Pin and David Buchaca Prats", "title": "Weighted Contrastive Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms for energy based Boltzmann architectures that rely on\ngradient descent are in general computationally prohibitive, typically due to\nthe exponential number of terms involved in computing the partition function.\nIn this way one has to resort to approximation schemes for the evaluation of\nthe gradient. This is the case of Restricted Boltzmann Machines (RBM) and its\nlearning algorithm Contrastive Divergence (CD). It is well-known that CD has a\nnumber of shortcomings, and its approximation to the gradient has several\ndrawbacks. Overcoming these defects has been the basis of much research and new\nalgorithms have been devised, such as persistent CD. In this manuscript we\npropose a new algorithm that we call Weighted CD (WCD), built from small\nmodifications of the negative phase in standard CD. However small these\nmodifications may be, experimental work reported in this paper suggest that WCD\nprovides a significant improvement over standard CD and persistent CD at a\nsmall additional computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 17:20:17 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 16:54:11 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Merino", "Enrique Romero", ""], ["Castrillejo", "Ferran Mazzanti", ""], ["Pin", "Jordi Delgado", ""], ["Prats", "David Buchaca", ""]]}, {"id": "1801.02608", "submitter": "Danny Karmon", "authors": "Danny Karmon, Daniel Zoran and Yoav Goldberg", "title": "LaVAN: Localized and Visible Adversarial Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most works on adversarial examples for deep-learning based image classifiers\nuse noise that, while small, covers the entire image. We explore the case where\nthe noise is allowed to be visible but confined to a small, localized patch of\nthe image, without covering any of the main object(s) in the image. We show\nthat it is possible to generate localized adversarial noises that cover only 2%\nof the pixels in the image, none of them over the main object, and that are\ntransferable across images and locations, and successfully fool a\nstate-of-the-art Inception v3 model with very high success rates.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 18:44:23 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 12:49:11 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Karmon", "Danny", ""], ["Zoran", "Daniel", ""], ["Goldberg", "Yoav", ""]]}, {"id": "1801.02613", "submitter": "Xingjun Ma", "authors": "Xingjun Ma, Bo Li, Yisen Wang, Sarah M. Erfani, Sudanthi Wijewickrema,\n  Grant Schoenebeck, Dawn Song, Michael E. Houle, James Bailey", "title": "Characterizing Adversarial Subspaces Using Local Intrinsic\n  Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have recently been shown to be vulnerable against\nadversarial examples, which are carefully crafted instances that can mislead\nDNNs to make errors during prediction. To better understand such attacks, a\ncharacterization is needed of the properties of regions (the so-called\n'adversarial subspaces') in which adversarial examples lie. We tackle this\nchallenge by characterizing the dimensional properties of adversarial regions,\nvia the use of Local Intrinsic Dimensionality (LID). LID assesses the\nspace-filling capability of the region surrounding a reference example, based\non the distance distribution of the example to its neighbors. We first provide\nexplanations about how adversarial perturbation can affect the LID\ncharacteristic of adversarial regions, and then show empirically that LID\ncharacteristics can facilitate the distinction of adversarial examples\ngenerated using state-of-the-art attacks. As a proof-of-concept, we show that a\npotential application of LID is to distinguish adversarial examples, and the\npreliminary results show that it can outperform several state-of-the-art\ndetection measures by large margins for five attack strategies considered in\nthis paper across three benchmark datasets. Our analysis of the LID\ncharacteristic for adversarial regions not only motivates new directions of\neffective adversarial defense, but also opens up more challenges for developing\nnew attacks to better understand the vulnerabilities of DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 18:54:40 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 14:53:21 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 07:24:10 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Ma", "Xingjun", ""], ["Li", "Bo", ""], ["Wang", "Yisen", ""], ["Erfani", "Sarah M.", ""], ["Wijewickrema", "Sudanthi", ""], ["Schoenebeck", "Grant", ""], ["Song", "Dawn", ""], ["Houle", "Michael E.", ""], ["Bailey", "James", ""]]}, {"id": "1801.02620", "submitter": "Rohit Guttal", "authors": "Karthik Airani, Rohit Guttal", "title": "A Machine Learning Framework for Register Placement Optimization in\n  Digital Circuit Design", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern digital circuit back-end design, designers heavily rely on\nelectronic-design-automoation (EDA) tool to close timing. However, the\nheuristic algorithms used in the place and route tool usually does not result\nin optimal solution. Thus, significant design effort is used to tune parameters\nor provide user constraints or guidelines to improve the tool performance. In\nthis paper, we targeted at those optimization space left behind by the EDA\ntools and propose a machine learning framework that helps to define what are\nthe guidelines and constraints for registers placement, which can yield better\nperformance and quality for back-end design. In other words, the framework is\ntrying to learn what are the flaws of the existing EDA tools and tries to\noptimize it by providing additional information. We discuss what is the proper\ninput feature vector to be extracted, and what is metric to be used for\nreference output. We also develop a scheme to generate perturbed training\nsamples using existing design based on Gaussian randomization. By applying our\nmethodology, we are able to improve the design runtime by up to 36% and timing\nquality by up to 23%.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 08:26:18 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Airani", "Karthik", ""], ["Guttal", "Rohit", ""]]}, {"id": "1801.02622", "submitter": "Trang Pham", "authors": "Trang Pham, Truyen Tran, Svetha Venkatesh", "title": "Graph Memory Networks for Molecular Activity Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular activity prediction is critical in drug design. Machine learning\ntechniques such as kernel methods and random forests have been successful for\nthis task. These models require fixed-size feature vectors as input while the\nmolecules are variable in size and structure. As a result, fixed-size\nfingerprint representation is poor in handling substructures for large\nmolecules. In addition, molecular activity tests, or a so-called BioAssays, are\nrelatively small in the number of tested molecules due to its complexity. Here\nwe approach the problem through deep neural networks as they are flexible in\nmodeling structured data such as grids, sequences and graphs. We train multiple\nBioAssays using a multi-task learning framework, which combines information\nfrom multiple sources to improve the performance of prediction, especially on\nsmall datasets. We propose Graph Memory Network (GraphMem), a memory-augmented\nneural network to model the graph structure in molecules. GraphMem consists of\na recurrent controller coupled with an external memory whose cells dynamically\ninteract and change through a multi-hop reasoning process. Applied to the\nmolecules, the dynamic interactions enable an iterative refinement of the\nrepresentation of molecular graphs with multiple bond types. GraphMem is\ncapable of jointly training on multiple datasets by using a specific-task query\nfed to the controller as an input. We demonstrate the effectiveness of the\nproposed model for separately and jointly training on more than 100K\nmeasurements, spanning across 9 BioAssay activity tests.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 03:06:25 GMT"}, {"version": "v2", "created": "Sat, 27 Jan 2018 04:57:00 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Pham", "Trang", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1801.02642", "submitter": "Akshay Pai", "authors": "Marco Singh and Akshay Pai", "title": "Boundary Optimizing Network (BON)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite all the success that deep neural networks have seen in classifying\ncertain datasets, the challenge of finding optimal solutions that generalize\nstill remains. In this paper, we propose the Boundary Optimizing Network (BON),\na new approach to generalization for deep neural networks when used for\nsupervised learning. Given a classification network, we propose to use a\ncollaborative generative network that produces new synthetic data points in the\nform of perturbations of original data points. In this way, we create a data\nsupport around each original data point which prevents decision boundaries from\npassing too close to the original data points, i.e. prevents overfitting. We\nshow that BON improves convergence on CIFAR-10 using the state-of-the-art\nDensenet. We do however observe that the generative network suffers from\ncatastrophic forgetting during training, and we therefore propose to use a\nvariation of Memory Aware Synapses to optimize the generative network (called\nBON++). On the Iris dataset, we visualize the effect of BON++ when the\ngenerator does not suffer from catastrophic forgetting and conclude that the\napproach has the potential to create better boundaries in a higher dimensional\nspace.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 19:02:44 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 21:32:05 GMT"}, {"version": "v3", "created": "Tue, 23 Jan 2018 10:24:09 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Singh", "Marco", ""], ["Pai", "Akshay", ""]]}, {"id": "1801.02710", "submitter": "Adrian Albert", "authors": "Adrian Albert, Emanuele Strano, Jasleen Kaur, Marta Gonzalez", "title": "Modeling urbanization patterns with generative adversarial networks", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we propose a new method to simulate hyper-realistic urban\npatterns using Generative Adversarial Networks trained with a global urban\nland-use inventory. We generated a synthetic urban \"universe\" that\nqualitatively reproduces the complex spatial organization observed in global\nurban patterns, while being able to quantitatively recover certain key\nhigh-level urban spatial metrics.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 23:04:01 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Albert", "Adrian", ""], ["Strano", "Emanuele", ""], ["Kaur", "Jasleen", ""], ["Gonzalez", "Marta", ""]]}, {"id": "1801.02746", "submitter": "Jaouhar Fattahi", "authors": "Takwa Omrani, Adel Dallali, Bilgacem Chibani Rhaimi, Jaouhar Fattahi", "title": "Fusion of ANN and SVM Classifiers for Network Attack Detection", "comments": "Accepted and presented at the 18th international conference on\n  Sciences and Techniques of Automatic control and computer engineering\n  STA'2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the progressive increase of network application and electronic devices\n(computers, mobile phones, android, etc.) attack and intrusion, detection has\nbecome a very challenging task in cybercrime detection area. in this context,\nmost of the existing approaches of attack detection rely mainly on a finite set\nof attacks. These solutions are vulnerable, that is, they fail in detecting\nsome attacks when sources of informations are ambiguous or imperfect. However,\nfew approaches started investigating in this direction. This paper investigates\nthe role of machine learning approach (ANN, SVM) in detecting a TCP connection\ntraffic as a normal or a suspicious one. But, using ANN and SVM is an expensive\ntechnique individually. In this paper, combining two classifiers are proposed,\nwhere artificial neural network (ANN) classifier and support vector machine\n(SVM) are both employed. Additionally, our proposed solution allows to\nvisualize obtained classification results. Accuracy of the proposed solution\nhas been compared with other classifier results. Experiments have been\nconducted with different network connections selected from NSL-KDD DARPA\ndataset. Empirical results show that combining ANN and SVM techniques for\nattack detection is a promising direction.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 01:52:31 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 02:26:18 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Omrani", "Takwa", ""], ["Dallali", "Adel", ""], ["Rhaimi", "Bilgacem Chibani", ""], ["Fattahi", "Jaouhar", ""]]}, {"id": "1801.02764", "submitter": "Jack Parker-Holder", "authors": "Jack Parker-Holder, Sam Gass", "title": "Compressing Deep Neural Networks: A New Hashing Pipeline Using Kac's\n  Random Walk Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of deep learning is increasing by the day. However, despite\nthe recent advancements in hardware, deep neural networks remain\ncomputationally intensive. Recent work has shown that by preserving the angular\ndistance between vectors, random feature maps are able to reduce dimensionality\nwithout introducing bias to the estimator. We test a variety of established\nhashing pipelines as well as a new approach using Kac's random walk matrices.\nWe demonstrate that this method achieves similar accuracy to existing\npipelines.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 02:40:12 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 19:49:48 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 02:25:51 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Parker-Holder", "Jack", ""], ["Gass", "Sam", ""]]}, {"id": "1801.02780", "submitter": "Arjun Nitin Bhagoji", "authors": "Chawin Sitawarin, Arjun Nitin Bhagoji, Arsalan Mosenia, Prateek Mittal\n  and Mung Chiang", "title": "Rogue Signs: Deceiving Traffic Sign Recognition with Malicious Ads and\n  Logos", "comments": "Extended abstract accepted for the 1st Deep Learning and Security\n  Workshop; 5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new real-world attack against the computer vision based systems\nof autonomous vehicles (AVs). Our novel Sign Embedding attack exploits the\nconcept of adversarial examples to modify innocuous signs and advertisements in\nthe environment such that they are classified as the adversary's desired\ntraffic sign with high confidence. Our attack greatly expands the scope of the\nthreat posed to AVs since adversaries are no longer restricted to just\nmodifying existing traffic signs as in previous work. Our attack pipeline\ngenerates adversarial samples which are robust to the environmental conditions\nand noisy image transformations present in the physical world. We ensure this\nby including a variety of possible image transformations in the optimization\nproblem used to generate adversarial samples. We verify the robustness of the\nadversarial samples by printing them out and carrying out drive-by tests\nsimulating the conditions under which image capture would occur in a real-world\nscenario. We experimented with physical attack samples for different distances,\nlighting conditions and camera angles. In addition, extensive evaluations were\ncarried out in the virtual setting for a variety of image transformations. The\nadversarial samples generated using our method have adversarial success rates\nin excess of 95% in the physical as well as virtual settings.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 03:33:33 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 20:56:10 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 20:28:30 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sitawarin", "Chawin", ""], ["Bhagoji", "Arjun Nitin", ""], ["Mosenia", "Arsalan", ""], ["Mittal", "Prateek", ""], ["Chiang", "Mung", ""]]}, {"id": "1801.02788", "submitter": "Ian Dewancker", "authors": "Ian Dewancker, Jakob Bauer, Michael McCourt", "title": "Sequential Preference-Based Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world engineering problems rely on human preferences to guide their\ndesign and optimization. We present PrefOpt, an open source package to simplify\nsequential optimization tasks that incorporate human preference feedback. Our\napproach extends an existing latent variable model for binary preferences to\nallow for observations of equivalent preference from users.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 04:13:11 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Dewancker", "Ian", ""], ["Bauer", "Jakob", ""], ["McCourt", "Michael", ""]]}, {"id": "1801.02808", "submitter": "Bing Liu", "authors": "Zhiyuan Chen, Nianzu Ma, Bing Liu", "title": "Lifelong Learning for Sentiment Classification", "comments": null, "journal-ref": "ACL 2015", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel lifelong learning (LL) approach to sentiment\nclassification. LL mimics the human continuous learning process, i.e.,\nretaining the knowledge learned from past tasks and use it to help future\nlearning. In this paper, we first discuss LL in general and then LL for\nsentiment classification in particular. The proposed LL approach adopts a\nBayesian optimization framework based on stochastic gradient descent. Our\nexperimental results show that the proposed method outperforms baseline methods\nsignificantly, which demonstrates that lifelong learning is a promising\nresearch direction.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 06:11:50 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Chen", "Zhiyuan", ""], ["Ma", "Nianzu", ""], ["Liu", "Bing", ""]]}, {"id": "1801.02850", "submitter": "Yongshuai Liu", "authors": "Yongshuai Liu, Jiyu Chen and Hao Chen", "title": "Less is More: Culling the Training Set to Improve Robustness of Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples. Prior defenses\nattempted to make deep networks more robust by either changing the network\narchitecture or augmenting the training set with adversarial examples, but both\nhave inherent limitations. Motivated by recent research that shows outliers in\nthe training set have a high negative influence on the trained model, we\nstudied the relationship between model robustness and the quality of the\ntraining set. We first show that outliers give the model better generalization\nability but weaker robustness. Next, we propose an adversarial example\ndetection framework, in which we design two methods for removing outliers from\ntraining set to obtain the sanitized model and then detect adversarial example\nby calculating the difference of outputs between the original and the sanitized\nmodel. We evaluated the framework on both MNIST and SVHN. Based on the\ndifference measured by Kullback-Leibler divergence, we could detect adversarial\nexamples with accuracy between 94.67% to 99.89%.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 09:36:56 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2018 03:52:47 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Liu", "Yongshuai", ""], ["Chen", "Jiyu", ""], ["Chen", "Hao", ""]]}, {"id": "1801.02901", "submitter": "Han Xiao", "authors": "Han Xiao", "title": "Convexification of Neural Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, most complex intelligence architectures are extremely\nnon-convex, which could not be well performed by convex optimization. However,\nthis paper decomposes complex structures into three types of nodes: operators,\nalgorithms and functions. Iteratively, propagating from node to node along\nedge, we prove that \"regarding the tree-structured neural graph, it is nearly\nconvex in each variable, when the other variables are fixed.\" In fact, the\nnon-convex properties stem from circles and functions, which could be\ntransformed to be convex with our proposed \\textit{\\textbf{scale mechanism}}.\nExperimentally, we justify our theoretical analysis by two practical\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 11:57:41 GMT"}, {"version": "v2", "created": "Sat, 13 Jan 2018 07:13:16 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Xiao", "Han", ""]]}, {"id": "1801.02929", "submitter": "Hiroshi Inoue", "authors": "Hiroshi Inoue", "title": "Data Augmentation by Pairing Samples for Images Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a widely used technique in many machine learning tasks,\nsuch as image classification, to virtually enlarge the training dataset size\nand avoid overfitting. Traditional data augmentation techniques for image\nclassification tasks create new samples from the original training data by, for\nexample, flipping, distorting, adding a small amount of noise to, or cropping a\npatch from an original image. In this paper, we introduce a simple but\nsurprisingly effective data augmentation technique for image classification\ntasks. With our technique, named SamplePairing, we synthesize a new sample from\none image by overlaying another image randomly chosen from the training data\n(i.e., taking an average of two images for each pixel). By using two images\nrandomly selected from the training set, we can generate $N^2$ new samples from\n$N$ training samples. This simple data augmentation technique significantly\nimproved classification accuracy for all the tested datasets; for example, the\ntop-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset\nwith GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show\nthat our SamplePairing technique largely improved accuracy when the number of\nsamples in the training set was very small. Therefore, our technique is more\nvaluable for tasks with a limited amount of training data, such as medical\nimaging tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 13:37:11 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 13:28:07 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Inoue", "Hiroshi", ""]]}, {"id": "1801.02937", "submitter": "Masud Moshtaghi", "authors": "Masud Moshtaghi, James C. Bezdek, Sarah M. Erfani, Christopher Leckie,\n  James Bailey", "title": "Online Cluster Validity Indices for Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cluster analysis is used to explore structure in unlabeled data sets in a\nwide range of applications. An important part of cluster analysis is validating\nthe quality of computationally obtained clusters. A large number of different\ninternal indices have been developed for validation in the offline setting.\nHowever, this concept has not been extended to the online setting. A key\nchallenge is to find an efficient incremental formulation of an index that can\ncapture both cohesion and separation of the clusters over potentially infinite\ndata streams. In this paper, we develop two online versions (with and without\nforgetting factors) of the Xie-Beni and Davies-Bouldin internal validity\nindices, and analyze their characteristics, using two streaming clustering\nalgorithms (sk-means and online ellipsoidal clustering), and illustrate their\nuse in monitoring evolving clusters in streaming data. We also show that\nincremental cluster validity indices are capable of sending a distress signal\nto online monitors when evolving clusters go awry. Our numerical examples\nindicate that the incremental Xie-Beni index with forgetting factor is superior\nto the other three indices tested.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 18:43:00 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Moshtaghi", "Masud", ""], ["Bezdek", "James C.", ""], ["Erfani", "Sarah M.", ""], ["Leckie", "Christopher", ""], ["Bailey", "James", ""]]}, {"id": "1801.02949", "submitter": "Marco Capo MSc", "authors": "Marco Cap\\'o, Aritz P\\'erez and Jose A. Lozano", "title": "An efficient K -means clustering algorithm for massive data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of continously larger datasets is a task of major importance in\na wide variety of scientific fields. In this sense, cluster analysis algorithms\nare a key element of exploratory data analysis, due to their easiness in the\nimplementation and relatively low computational cost. Among these algorithms,\nthe K -means algorithm stands out as the most popular approach, besides its\nhigh dependency on the initial conditions, as well as to the fact that it might\nnot scale well on massive datasets. In this article, we propose a recursive and\nparallel approximation to the K -means algorithm that scales well on both the\nnumber of instances and dimensionality of the problem, without affecting the\nquality of the approximation. In order to achieve this, instead of analyzing\nthe entire dataset, we work on small weighted sets of points that mostly intend\nto extract information from those regions where it is harder to determine the\ncorrect cluster assignment of the original instances. In addition to different\ntheoretical properties, which deduce the reasoning behind the algorithm,\nexperimental results indicate that our method outperforms the state-of-the-art\nin terms of the trade-off between number of distance computations and the\nquality of the solution obtained.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 14:32:06 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Cap\u00f3", "Marco", ""], ["P\u00e9rez", "Aritz", ""], ["Lozano", "Jose A.", ""]]}, {"id": "1801.02950", "submitter": "Abdullah Al-Dujaili", "authors": "Abdullah Al-Dujaili and Alex Huang and Erik Hemberg and Una-May\n  O'Reilly", "title": "Adversarial Deep Learning for Robust Detection of Binary Encoded Malware", "comments": "1ST Deep Learning and Security Workshop (co-located with the 39th\n  IEEE Symposium on Security and Privacy)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware is constantly adapting in order to avoid detection. Model based\nmalware detectors, such as SVM and neural networks, are vulnerable to so-called\nadversarial examples which are modest changes to detectable malware that allows\nthe resulting malware to evade detection. Continuous-valued methods that are\nrobust to adversarial examples of images have been developed using saddle-point\noptimization formulations. We are inspired by them to develop similar methods\nfor the discrete, e.g. binary, domain which characterizes the features of\nmalware. A specific extra challenge of malware is that the adversarial examples\nmust be generated in a way that preserves their malicious functionality. We\nintroduce methods capable of generating functionally preserved adversarial\nmalware examples in the binary domain. Using the saddle-point formulation, we\nincorporate the adversarial examples into the training of models that are\nrobust to them. We evaluate the effectiveness of the methods and others in the\nliterature on a set of Portable Execution~(PE) files. Comparison prompts our\nintroduction of an online measure computed during training to assess general\nexpectation of robustness.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 14:32:30 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 20:29:25 GMT"}, {"version": "v3", "created": "Sun, 25 Mar 2018 14:17:03 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Al-Dujaili", "Abdullah", ""], ["Huang", "Alex", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1801.02961", "submitter": "Milad Zafar Nezhad", "authors": "Najibesadat Sadati, Milad Zafar Nezhad, Ratna Babu Chinnam, Dongxiao\n  Zhu", "title": "Representation Learning with Autoencoders for Electronic Health Records:\n  A Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing volume of Electronic Health Records (EHR) in recent years provides\ngreat opportunities for data scientists to collaborate on different aspects of\nhealthcare research by applying advanced analytics to these EHR clinical data.\nA key requirement however is obtaining meaningful insights from high\ndimensional, sparse and complex clinical data. Data science approaches\ntypically address this challenge by performing feature learning in order to\nbuild more reliable and informative feature representations from clinical data\nfollowed by supervised learning. In this paper, we propose a predictive\nmodeling approach based on deep learning based feature representations and word\nembedding techniques. Our method uses different deep architectures (stacked\nsparse autoencoders, deep belief network, adversarial autoencoders and\nvariational autoencoders) for feature representation in higher-level\nabstraction to obtain effective and robust features from EHRs, and then build\nprediction models on top of them. Our approach is particularly useful when the\nunlabeled data is abundant whereas labeled data is scarce. We investigate the\nperformance of representation learning through a supervised learning approach.\nOur focus is to present a comparative study to evaluate the performance of\ndifferent deep architectures through supervised learning and provide insights\nin the choice of deep feature representation techniques. Our experiments\ndemonstrate that for small data sets, stacked sparse autoencoder demonstrates a\nsuperior generality performance in prediction due to sparsity regularization\nwhereas variational autoencoders outperform the competing approaches for large\ndata sets due to its capability of learning the representation distribution.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 23:17:24 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 14:01:32 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sadati", "Najibesadat", ""], ["Nezhad", "Milad Zafar", ""], ["Chinnam", "Ratna Babu", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1801.02982", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu", "title": "How To Make the Gradients Small Stochastically: Even Faster Convex and\n  Nonconvex SGD", "comments": "V2 added two applications to nonconvex stochastic optimization, and\n  V3 corrects a citation. arXiv admin note: text overlap with arXiv:1708.08694", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) gives an optimal convergence rate when\nminimizing convex stochastic objectives $f(x)$. However, in terms of making the\ngradients small, the original SGD does not give an optimal rate, even when\n$f(x)$ is convex.\n  If $f(x)$ is convex, to find a point with gradient norm $\\varepsilon$, we\ndesign an algorithm SGD3 with a near-optimal rate\n$\\tilde{O}(\\varepsilon^{-2})$, improving the best known rate\n$O(\\varepsilon^{-8/3})$ of [18].\n  If $f(x)$ is nonconvex, to find its $\\varepsilon$-approximate local minimum,\nwe design an algorithm SGD5 with rate $\\tilde{O}(\\varepsilon^{-3.5})$, where\npreviously SGD variants only achieve $\\tilde{O}(\\varepsilon^{-4})$ [6, 15, 33].\nThis is no slower than the best known stochastic version of Newton's method in\nall parameter regimes [30].\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 10:26:50 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 08:27:48 GMT"}, {"version": "v3", "created": "Wed, 28 Jul 2021 22:02:16 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""]]}, {"id": "1801.03039", "submitter": "Patryk Orzechowski", "authors": "Patryk Orzechowski, Moshe Sipper, Xiuzhen Huang, and Jason H. Moore", "title": "EBIC: an evolutionary-based parallel biclustering algorithm for pattern\n  discover", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": "10.1093/bioinformatics/bty401", "report-no": null, "categories": "cs.LG cs.CV cs.IR q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel biclustering algorithm based on artificial intelligence\n(AI) is introduced. The method called EBIC aims to detect biologically\nmeaningful, order-preserving patterns in complex data. The proposed algorithm\nis probably the first one capable of discovering with accuracy exceeding 50%\nmultiple complex patterns in real gene expression datasets. It is also one of\nthe very few biclustering methods designed for parallel environments with\nmultiple graphics processing units (GPUs). We demonstrate that EBIC outperforms\nstate-of-the-art biclustering methods, in terms of recovery and relevance, on\nboth synthetic and genetic datasets. EBIC also yields results over 12 times\nfaster than the most accurate reference algorithms. The proposed algorithm is\nanticipated to be added to the repertoire of unsupervised machine learning\nalgorithms for the analysis of datasets, including those from large-scale\ngenomic studies.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 17:13:07 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 14:08:11 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Orzechowski", "Patryk", ""], ["Sipper", "Moshe", ""], ["Huang", "Xiuzhen", ""], ["Moore", "Jason H.", ""]]}, {"id": "1801.03049", "submitter": "Eunbyung Park", "authors": "Eunbyung Park, Alexander C. Berg", "title": "Meta-Tracker: Fast and Robust Online Adaptation for Visual Object\n  Trackers", "comments": "Code: https://github.com/silverbottlep/meta_trackers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper improves state-of-the-art visual object trackers that use online\nadaptation. Our core contribution is an offline meta-learning-based method to\nadjust the initial deep networks used in online adaptation-based tracking. The\nmeta learning is driven by the goal of deep networks that can quickly be\nadapted to robustly model a particular target in future frames. Ideally the\nresulting models focus on features that are useful for future frames, and avoid\noverfitting to background clutter, small parts of the target, or noise. By\nenforcing a small number of update iterations during meta-learning, the\nresulting networks train significantly faster. We demonstrate this approach on\ntop of the high performance tracking approaches: tracking-by-detection based\nMDNet and the correlation based CREST. Experimental results on standard\nbenchmarks, OTB2015 and VOT2016, show that our meta-learned versions of both\ntrackers improve speed, accuracy, and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 17:38:10 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 19:48:00 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Park", "Eunbyung", ""], ["Berg", "Alexander C.", ""]]}, {"id": "1801.03137", "submitter": "Ben Parr", "authors": "Igor Gitman, Deepak Dilipkumar, Ben Parr", "title": "Convergence Analysis of Gradient Descent Algorithms with Proportional\n  Updates", "comments": "Source code (uses TensorFlow): https://github.com/bparr/lars", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of deep learning in recent years has brought with it increasingly\nclever optimization methods to deal with complex, non-linear loss functions.\nThese methods are often designed with convex optimization in mind, but have\nbeen shown to work well in practice even for the highly non-convex optimization\nassociated with neural networks. However, one significant drawback of these\nmethods when they are applied to deep learning is that the magnitude of the\nupdate step is sometimes disproportionate to the magnitude of the weights (much\nsmaller or larger), leading to training instabilities such as vanishing and\nexploding gradients. An idea to combat this issue is gradient descent with\nproportional updates. Gradient descent with proportional updates was introduced\nin 2017. It was independently developed by You et al (Layer-wise Adaptive Rate\nScaling (LARS) algorithm) and by Abu-El-Haija (PercentDelta algorithm). The\nbasic idea of both of these algorithms is to make each step of the gradient\ndescent proportional to the current weight norm and independent of the gradient\nmagnitude. It is common in the context of new optimization methods to prove\nconvergence or derive regret bounds under the assumption of Lipschitz\ncontinuity and convexity. However, even though LARS and PercentDelta were shown\nto work well in practice, there is no theoretical analysis of the convergence\nproperties of these algorithms. Thus it is not clear if the idea of gradient\ndescent with proportional updates is used in the optimal way, or if it could be\nimproved by using a different norm or specific learning rate schedule, for\nexample. Moreover, it is not clear if these algorithms can be extended to other\nproblems, besides neural networks. We attempt to answer these questions by\nestablishing the theoretical analysis of gradient descent with proportional\nupdates, and verifying this analysis with empirical examples.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 20:51:28 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Gitman", "Igor", ""], ["Dilipkumar", "Deepak", ""], ["Parr", "Ben", ""]]}, {"id": "1801.03143", "submitter": "Artit Wangperawong", "authors": "Artit Wangperawong, Kettip Kriangchaivech, Austin Lanari, Supui Lam,\n  Panthong Wangperawong", "title": "Comparing heterogeneous entities using artificial neural networks of\n  trainable weighted structural components and machine-learned activation\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To compare entities of differing types and structural components, the\nartificial neural network paradigm was used to cross-compare structural\ncomponents between heterogeneous documents. Trainable weighted structural\ncomponents were input into machine-learned activation functions of the neurons.\nThe model was used for matching news articles and videos, where the inputs and\nactivation functions respectively consisted of term vectors and cosine\nsimilarity measures between the weighted structural components. The model was\ntested with different weights, achieving as high as 59.2% accuracy for matching\nvideos to news articles. A mobile application user interface for recommending\nrelated videos for news articles was developed to demonstrate consumer value,\nincluding its potential usefulness for cross-selling products from unrelated\ncategories.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 21:20:08 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Wangperawong", "Artit", ""], ["Kriangchaivech", "Kettip", ""], ["Lanari", "Austin", ""], ["Lam", "Supui", ""], ["Wangperawong", "Panthong", ""]]}, {"id": "1801.03164", "submitter": "Justin Gottschlich", "authors": "Justin Gottschlich", "title": "Paranom: A Parallel Anomaly Dataset Generator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Paranom, a parallel anomaly dataset generator. We\ndiscuss its design and provide brief experimental results demonstrating its\nusefulness in improving the classification correctness of LSTM-AD, a\nstate-of-the-art anomaly detection model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 22:33:51 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Gottschlich", "Justin", ""]]}, {"id": "1801.03226", "submitter": "Ruoyu Li", "authors": "Ruoyu Li, Sheng Wang, Feiyun Zhu, Junzhou Huang", "title": "Adaptive Graph Convolutional Neural Networks", "comments": "The Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18), 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Neural Networks (Graph CNNs) are generalizations of\nclassical CNNs to handle graph data such as molecular data, point could and\nsocial networks. Current filters in graph CNNs are built for fixed and shared\ngraph structure. However, for most real data, the graph structures varies in\nboth size and connectivity. The paper proposes a generalized and flexible graph\nCNN taking data of arbitrary graph structure as input. In that way a\ntask-driven adaptive graph is learned for each graph data while training. To\nefficiently learn the graph, a distance metric learning is proposed. Extensive\nexperiments on nine graph-structured datasets have demonstrated the superior\nperformance improvement on both convergence speed and predictive accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 03:17:45 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Li", "Ruoyu", ""], ["Wang", "Sheng", ""], ["Zhu", "Feiyun", ""], ["Huang", "Junzhou", ""]]}, {"id": "1801.03230", "submitter": "Sarfaraz Hussein", "authors": "Sarfaraz Hussein, Pujan Kandel, Candice W. Bolan, Michael B. Wallace,\n  and Ulas Bagci", "title": "Lung and Pancreatic Tumor Characterization in the Deep Learning Era:\n  Novel Supervised and Unsupervised Learning Approaches", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging 2019", "journal-ref": null, "doi": "10.1109/TMI.2019.2894349", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk stratification (characterization) of tumors from radiology images can be\nmore accurate and faster with computer-aided diagnosis (CAD) tools. Tumor\ncharacterization through such tools can also enable non-invasive cancer\nstaging, prognosis, and foster personalized treatment planning as a part of\nprecision medicine. In this study, we propose both supervised and unsupervised\nmachine learning strategies to improve tumor characterization. Our first\napproach is based on supervised learning for which we demonstrate significant\ngains with deep learning algorithms, particularly by utilizing a 3D\nConvolutional Neural Network and Transfer Learning. Motivated by the\nradiologists' interpretations of the scans, we then show how to incorporate\ntask dependent feature representations into a CAD system via a\ngraph-regularized sparse Multi-Task Learning (MTL) framework. In the second\napproach, we explore an unsupervised learning algorithm to address the limited\navailability of labeled training data, a common problem in medical imaging\napplications. Inspired by learning from label proportion (LLP) approaches in\ncomputer vision, we propose to use proportion-SVM for characterizing tumors. We\nalso seek the answer to the fundamental question about the goodness of \"deep\nfeatures\" for unsupervised tumor classification. We evaluate our proposed\nsupervised and unsupervised learning algorithms on two different tumor\ndiagnosis challenges: lung and pancreas with 1018 CT and 171 MRI scans,\nrespectively, and obtain the state-of-the-art sensitivity and specificity\nresults in both problems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 03:47:07 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 05:30:33 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 13:25:51 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hussein", "Sarfaraz", ""], ["Kandel", "Pujan", ""], ["Bolan", "Candice W.", ""], ["Wallace", "Michael B.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1801.03244", "submitter": "Arijit Biswas", "authors": "Ashutosh Kumar, Arijit Biswas, Subhajit Sanyal", "title": "eCommerceGAN : A Generative Adversarial Network for E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce companies such as Amazon, Alibaba and Flipkart process billions of\norders every year. However, these orders represent only a small fraction of all\nplausible orders. Exploring the space of all plausible orders could help us\nbetter understand the relationships between the various entities in an\ne-commerce ecosystem, namely the customers and the products they purchase. In\nthis paper, we propose a Generative Adversarial Network (GAN) for orders made\nin e-commerce websites. Once trained, the generator in the GAN could generate\nany number of plausible orders. Our contributions include: (a) creating a dense\nand low-dimensional representation of e-commerce orders, (b) train an\necommerceGAN (ecGAN) with real orders to show the feasibility of the proposed\nparadigm, and (c) train an ecommerce-conditional-GAN (ec^2GAN) to generate the\nplausible orders involving a particular product. We propose several qualitative\nmethods to evaluate ecGAN and demonstrate its effectiveness. The ec^2GAN is\nused for various kinds of characterization of possible orders involving a\nproduct that has just been introduced into the e-commerce system. The proposed\napproach ec^2GAN performs significantly better than the baseline in most of the\nscenarios.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 05:58:09 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Kumar", "Ashutosh", ""], ["Biswas", "Arijit", ""], ["Sanyal", "Subhajit", ""]]}, {"id": "1801.03265", "submitter": "Chen-Yu Wei", "authors": "Chen-Yu Wei and Haipeng Luo", "title": "More Adaptive Algorithms for Adversarial Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel and generic algorithm for the adversarial multi-armed\nbandit problem (or more generally the combinatorial semi-bandit problem). When\ninstantiated differently, our algorithm achieves various new data-dependent\nregret bounds improving previous work. Examples include: 1) a regret bound\ndepending on the variance of only the best arm; 2) a regret bound depending on\nthe first-order path-length of only the best arm; 3) a regret bound depending\non the sum of first-order path-lengths of all arms as well as an important\nnegative term, which together lead to faster convergence rates for some normal\nform games with partial feedback; 4) a regret bound that simultaneously implies\nsmall regret when the best arm has small loss and logarithmic regret when there\nexists an arm whose expected loss is always smaller than those of others by a\nfixed gap (e.g. the classic i.i.d. setting). In some cases, such as the last\ntwo results, our algorithm is completely parameter-free.\n  The main idea of our algorithm is to apply the optimism and adaptivity\ntechniques to the well-known Online Mirror Descent framework with a special\nlog-barrier regularizer. The challenges are to come up with appropriate\noptimistic predictions and correction terms in this framework. Some of our\nresults also crucially rely on using a sophisticated increasing learning rate\nschedule.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 08:28:00 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 00:23:45 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 16:57:01 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Wei", "Chen-Yu", ""], ["Luo", "Haipeng", ""]]}, {"id": "1801.03329", "submitter": "Gil Keren", "authors": "Gil Keren, Maximilian Schmitt, Thomas Kehrenberg, Bj\\\"orn Schuller", "title": "Weakly Supervised One-Shot Detection with Attention Similarity Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models that are not conditioned on class identities were shown\nto facilitate knowledge transfer between classes and to be well-suited for\none-shot learning tasks. Following this motivation, we further explore and\nestablish such models and present a novel neural network architecture for the\ntask of weakly supervised one-shot detection. Our model is only conditioned on\na single exemplar of an unseen class and a larger target example that may or\nmay not contain an instance of the same class as the exemplar. By pairing a\nSiamese similarity network with an attention mechanism, we design a model that\nmanages to simultaneously identify and localise instances of classes unseen at\ntraining time. In experiments with datasets from the computer vision and audio\ndomains, the proposed method considerably outperforms the baseline methods for\nthe weakly supervised one-shot detection task.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 12:10:24 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 13:57:08 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 09:12:33 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Keren", "Gil", ""], ["Schmitt", "Maximilian", ""], ["Kehrenberg", "Thomas", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1801.03339", "submitter": "Felix Kreuk", "authors": "Felix Kreuk, Yossi Adi, Moustapha Cisse, Joseph Keshet", "title": "Fooling End-to-end Speaker Verification by Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification systems are increasingly used as the primary\nmeans to authenticate costumers. Recently, it has been proposed to train\nspeaker verification systems using end-to-end deep neural models. In this\npaper, we show that such systems are vulnerable to adversarial example attack.\nAdversarial examples are generated by adding a peculiar noise to original\nspeaker examples, in such a way that they are almost indistinguishable from the\noriginal examples by a human listener. Yet, the generated waveforms, which\nsound as speaker A can be used to fool such a system by claiming as if the\nwaveforms were uttered by speaker B. We present white-box attacks on an\nend-to-end deep network that was either trained on YOHO or NTIMIT. We also\npresent two black-box attacks: where the adversarial examples were generated\nwith a system that was trained on YOHO, but the attack is on a system that was\ntrained on NTIMIT; and when the adversarial examples were generated with a\nsystem that was trained on Mel-spectrum feature set, but the attack is on a\nsystem that was trained on MFCC. Results suggest that the accuracy of the\nattacked system was decreased and the false-positive rate was dramatically\nincreased.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 12:24:34 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 13:40:02 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Kreuk", "Felix", ""], ["Adi", "Yossi", ""], ["Cisse", "Moustapha", ""], ["Keshet", "Joseph", ""]]}, {"id": "1801.03421", "submitter": "Ivan Yu. Tyukin", "authors": "A.N. Gorban, I.Y. Tyukin", "title": "Blessing of dimensionality: mathematical foundations of the statistical\n  physics of data", "comments": "Accepted for publication in Philosophical Transactions of the Royal\n  Society A, 2018. Comprises of 17 pages and 4 figures", "journal-ref": "Phil. Trans. R. Soc. A volume 376, issue 2118, 376 20170237, 2018", "doi": "10.1098/rsta.2017.0237", "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concentration of measure phenomena were discovered as the mathematical\nbackground of statistical mechanics at the end of the XIX - beginning of the XX\ncentury and were then explored in mathematics of the XX-XXI centuries. At the\nbeginning of the XXI century, it became clear that the proper utilisation of\nthese phenomena in machine learning might transform the curse of dimensionality\ninto the blessing of dimensionality.\n  This paper summarises recently discovered phenomena of measure concentration\nwhich drastically simplify some machine learning problems in high dimension,\nand allow us to correct legacy artificial intelligence systems. The classical\nconcentration of measure theorems state that i.i.d. random points are\nconcentrated in a thin layer near a surface (a sphere or equators of a sphere,\nan average or median level set of energy or another Lipschitz function, etc.).\n  The new stochastic separation theorems describe the thin structure of these\nthin layers: the random points are not only concentrated in a thin layer but\nare all linearly separable from the rest of the set, even for exponentially\nlarge random sets. The linear functionals for separation of points can be\nselected in the form of the linear Fisher's discriminant.\n  All artificial intelligence systems make errors. Non-destructive correction\nrequires separation of the situations (samples) with errors from the samples\ncorresponding to correct behaviour by a simple and robust classifier. The\nstochastic separation theorems provide us by such classifiers and a\nnon-iterative (one-shot) procedure for learning.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 15:26:45 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Gorban", "A. N.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1801.03423", "submitter": "Jamie Morgenstern", "authors": "Sampath Kannan and Jamie Morgenstern and Aaron Roth and Bo Waggoner\n  and Zhiwei Steven Wu", "title": "A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual\n  Bandit Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit learning is characterized by the tension between long-term exploration\nand short-term exploitation. However, as has recently been noted, in settings\nin which the choices of the learning algorithm correspond to important\ndecisions about individual people (such as criminal recidivism prediction,\nlending, and sequential drug trials), exploration corresponds to explicitly\nsacrificing the well-being of one individual for the potential future benefit\nof others. This raises a fairness concern. In such settings, one might like to\nrun a \"greedy\" algorithm, which always makes the (myopically) optimal decision\nfor the individuals at hand - but doing this can result in a catastrophic\nfailure to learn. In this paper, we consider the linear contextual bandit\nproblem and revisit the performance of the greedy algorithm. We give a smoothed\nanalysis, showing that even when contexts may be chosen by an adversary, small\nperturbations of the adversary's choices suffice for the algorithm to achieve\n\"no regret\", perhaps (depending on the specifics of the setting) with a\nconstant amount of initial training data. This suggests that \"generically\"\n(i.e. in slightly perturbed environments), exploration and exploitation need\nnot be in conflict in the linear setting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 15:40:05 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Kannan", "Sampath", ""], ["Morgenstern", "Jamie", ""], ["Roth", "Aaron", ""], ["Waggoner", "Bo", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "1801.03437", "submitter": "Mikhail Belkin", "authors": "Mikhail Belkin", "title": "Approximation beats concentration? An approximation view on inference\n  with smooth radial kernels", "comments": null, "journal-ref": "Conference on Computational Learning Theory (COLT) 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive definite kernels and their associated Reproducing Kernel Hilbert\nSpaces provide a mathematically compelling and practically competitive\nframework for learning from data.\n  In this paper we take the approximation theory point of view to explore\nvarious aspects of smooth kernels related to their inferential properties. We\nanalyze eigenvalue decay of kernels operators and matrices, properties of\neigenfunctions/eigenvectors and \"Fourier\" coefficients of functions in the\nkernel space restricted to a discrete set of data points. We also investigate\nthe fitting capacity of kernels, giving explicit bounds on the fat shattering\ndimension of the balls in Reproducing Kernel Hilbert spaces. Interestingly, the\nsame properties that make kernels very effective approximators for functions in\ntheir \"native\" kernel space, also limit their capacity to represent arbitrary\nfunctions. We discuss various implications, including those for gradient\ndescent type methods.\n  It is important to note that most of our bounds are measure independent.\nMoreover, at least in moderate dimension, the bounds for eigenvalues are much\ntighter than the bounds which can be obtained from the usual matrix\nconcentration results. For example, we see that the eigenvalues of kernel\nmatrices show nearly exponential decay with constants depending only on the\nkernel and the domain. We call this \"approximation beats concentration\"\nphenomenon as even when the data are sampled from a probability distribution,\nsome of their aspects are better understood in terms of approximation theory.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 16:13:15 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 21:03:29 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Belkin", "Mikhail", ""]]}, {"id": "1801.03533", "submitter": "Manish Raghavan", "authors": "Jon Kleinberg, Manish Raghavan", "title": "Selection Problems in the Presence of Implicit Bias", "comments": "ITCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past two decades, the notion of implicit bias has come to serve as\nan important component in our understanding of discrimination in activities\nsuch as hiring, promotion, and school admissions. Research on implicit bias\nposits that when people evaluate others -- for example, in a hiring context --\ntheir unconscious biases about membership in particular groups can have an\neffect on their decision-making, even when they have no deliberate intention to\ndiscriminate against members of these groups. A growing body of experimental\nwork has pointed to the effect that implicit bias can have in producing adverse\noutcomes.\n  Here we propose a theoretical model for studying the effects of implicit bias\non selection decisions, and a way of analyzing possible procedural remedies for\nimplicit bias within this model. A canonical situation represented by our model\nis a hiring setting: a recruiting committee is trying to choose a set of\nfinalists to interview among the applicants for a job, evaluating these\napplicants based on their future potential, but their estimates of potential\nare skewed by implicit bias against members of one group. In this model, we\nshow that measures such as the Rooney Rule, a requirement that at least one of\nthe finalists be chosen from the affected group, can not only improve the\nrepresentation of this affected group, but also lead to higher payoffs in\nabsolute terms for the organization performing the recruiting. However,\nidentifying the conditions under which such measures can lead to improved\npayoffs involves subtle trade-offs between the extent of the bias and the\nunderlying distribution of applicant characteristics, leading to novel\ntheoretical questions about order statistics in the presence of probabilistic\nside information.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 06:53:58 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Kleinberg", "Jon", ""], ["Raghavan", "Manish", ""]]}, {"id": "1801.03558", "submitter": "Chris Cremer", "authors": "Chris Cremer, Xuechen Li, David Duvenaud", "title": "Inference Suboptimality in Variational Autoencoders", "comments": "ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amortized inference allows latent-variable models trained via variational\nlearning to scale to large datasets. The quality of approximate inference is\ndetermined by two factors: a) the capacity of the variational distribution to\nmatch the true posterior and b) the ability of the recognition network to\nproduce good variational parameters for each datapoint. We examine approximate\ninference in variational autoencoders in terms of these factors. We find that\ndivergence from the true posterior is often due to imperfect recognition\nnetworks, rather than the limited complexity of the approximating distribution.\nWe show that this is due partly to the generator learning to accommodate the\nchoice of approximation. Furthermore, we show that the parameters used to\nincrease the expressiveness of the approximation play a role in generalizing\ninference rather than simply improving the complexity of the approximation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 21:24:59 GMT"}, {"version": "v2", "created": "Fri, 23 Feb 2018 19:53:47 GMT"}, {"version": "v3", "created": "Sun, 27 May 2018 18:04:22 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Cremer", "Chris", ""], ["Li", "Xuechen", ""], ["Duvenaud", "David", ""]]}, {"id": "1801.03610", "submitter": "David Ahmedt Aristizabal", "authors": "David Ahmedt-Aristizabal, Clinton Fookes, Kien Nguyen, Sridha\n  Sridharan", "title": "Deep Classification of Epileptic Signals", "comments": "4 pages, 3 figures", "journal-ref": "In Proceedings of the IEEE International Conference of Engineering\n  in Medicine and Biology Society. 2018", "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrophysiological observation plays a major role in epilepsy evaluation.\nHowever, human interpretation of brain signals is subjective and prone to\nmisdiagnosis. Automating this process, especially seizure detection relying on\nscalp-based Electroencephalography (EEG) and intracranial EEG, has been the\nfocus of research over recent decades. Nevertheless, its numerous challenges\nhave inhibited a definitive solution. Inspired by recent advances in deep\nlearning, we propose a new classification approach for EEG time series based on\nRecurrent Neural Networks (RNNs) via the use of Long-Short Term Memory (LSTM)\nnetworks. The proposed deep network effectively learns and models\ndiscriminative temporal patterns from EEG sequential data. Especially, the\nfeatures are automatically discovered from the raw EEG data without any\npre-processing step, eliminating humans from laborious feature design task. We\nalso show that, in the epilepsy scenario, simple architectures can achieve\ncompetitive performance. Using simple architectures significantly benefits in\nthe practical scenario considering their low computation complexity and reduced\nrequirement for large training datasets. Using a public dataset, a multi-fold\ncross-validation scheme exhibited an average validation accuracy of 95.54\\% and\nan average AUC of 0.9582 of the ROC curve among all sets defined in the\nexperiment. This work reinforces the benefits of deep learning to be further\nattended in clinical applications and neuroscientific research.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 01:58:42 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Ahmedt-Aristizabal", "David", ""], ["Fookes", "Clinton", ""], ["Nguyen", "Kien", ""], ["Sridharan", "Sridha", ""]]}, {"id": "1801.03744", "submitter": "Boris Hanin", "authors": "Boris Hanin", "title": "Which Neural Net Architectures Give Rise To Exploding and Vanishing\n  Gradients?", "comments": "v3. 18p. 1 fig. Accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a rigorous analysis of the statistical behavior of gradients in a\nrandomly initialized fully connected network N with ReLU activations. Our\nresults show that the empirical variance of the squares of the entries in the\ninput-output Jacobian of N is exponential in a simple architecture-dependent\nconstant beta, given by the sum of the reciprocals of the hidden layer widths.\nWhen beta is large, the gradients computed by N at initialization vary wildly.\nOur approach complements the mean field theory analysis of random networks.\nFrom this point of view, we rigorously compute finite width corrections to the\nstatistics of gradients at the edge of chaos.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 13:17:22 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 13:25:08 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 01:02:57 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Hanin", "Boris", ""]]}, {"id": "1801.03749", "submitter": "R\\'emi Leblond", "authors": "R\\'emi Leblond and Fabian Pedregosa and Simon Lacoste-Julien", "title": "Improved asynchronous parallel optimization analysis for stochastic\n  incremental methods", "comments": "67 pages, published in JMLR, can be found online at\n  http://jmlr.org/papers/v19/17-650.html. arXiv admin note: substantial text\n  overlap with arXiv:1606.04809", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As datasets continue to increase in size and multi-core computer\narchitectures are developed, asynchronous parallel optimization algorithms\nbecome more and more essential to the field of Machine Learning. Unfortunately,\nconducting the theoretical analysis asynchronous methods is difficult, notably\ndue to the introduction of delay and inconsistency in inherently sequential\nalgorithms. Handling these issues often requires resorting to simplifying but\nunrealistic assumptions. Through a novel perspective, we revisit and clarify a\nsubtle but important technical issue present in a large fraction of the recent\nconvergence rate proofs for asynchronous parallel optimization algorithms, and\npropose a simplification of the recently introduced \"perturbed iterate\"\nframework that resolves it. We demonstrate the usefulness of our new framework\nby analyzing three distinct asynchronous parallel incremental optimization\nalgorithms: Hogwild (asynchronous SGD), KROMAGNON (asynchronous SVRG) and\nASAGA, a novel asynchronous parallel version of the incremental gradient\nalgorithm SAGA that enjoys fast linear convergence rates. We are able to both\nremove problematic assumptions and obtain better theoretical results. Notably,\nwe prove that ASAGA and KROMAGNON can obtain a theoretical linear speedup on\nmulti-core systems even without sparsity assumptions. We present results of an\nimplementation on a 40-core architecture illustrating the practical speedups as\nwell as the hardware overhead. Finally, we investigate the overlap constant, an\nill-understood but central quantity for the theoretical analysis of\nasynchronous parallel algorithms. We find that it encompasses much more\ncomplexity than suggested in previous work, and often is order-of-magnitude\nbigger than traditionally thought.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 13:31:33 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 10:55:58 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 21:52:08 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Leblond", "R\u00e9mi", ""], ["Pedregosa", "Fabian", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1801.03851", "submitter": "Chris Williams", "authors": "Christopher K. I. Williams, Charlie Nash, Alfredo Naz\\'abal", "title": "Autoencoders and Probabilistic Inference with Missing Data: An Exact\n  Solution for The Factor Analysis Case", "comments": "7 pages, 2 figures, Adding ref to Ilin and Raiko (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models can be used to probabilistically \"fill-in\" missing\ndata entries. The variational autoencoder architecture (Kingma and Welling,\n2014; Rezende et al., 2014) includes a \"recognition\" or \"encoder\" network that\ninfers the latent variables given the data variables. However, it is not clear\nhow to handle missing data variables in this network. The factor analysis (FA)\nmodel is a basic autoencoder, using linear encoder and decoder networks. We\nshow how to calculate exactly the latent posterior distribution for the factor\nanalysis (FA) model in the presence of missing data, and note that this\nsolution implies that a different encoder network is required for each pattern\nof missingness. We also discuss various approximations to the exact solution.\nExperiments compare the effectiveness of various approaches to filling in the\nmissing data.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 16:22:07 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 13:50:26 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2019 15:59:07 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Williams", "Christopher K. I.", ""], ["Nash", "Charlie", ""], ["Naz\u00e1bal", "Alfredo", ""]]}, {"id": "1801.03855", "submitter": "Amith Rajith Mamidala", "authors": "Amith R Mamidala, Georgios Kollias, Chris Ward, Fausto Artico", "title": "MXNET-MPI: Embedding MPI parallelism in Parameter Server Task Model for\n  scaling Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Deep Learning frameworks exclusively use either Parameter Server(PS)\napproach or MPI parallelism. In this paper, we discuss the drawbacks of such\napproaches and propose a generic framework supporting both PS and MPI\nprogramming paradigms, co-existing at the same time. The key advantage of the\nnew model is to embed the scaling benefits of MPI parallelism into the loosely\ncoupled PS task model. Apart from providing a practical usage model of MPI in\ncloud, such framework allows for novel communication avoiding algorithms that\ndo parameter averaging in Stochastic Gradient Descent(SGD) approaches. We show\nhow MPI and PS models can synergestically apply algorithms such as Elastic SGD\nto improve the rate of convergence against existing approaches. These new\nalgorithms directly help scaling SGD clusterwide. Further, we also optimize the\ncritical component of the framework, namely global aggregation or allreduce\nusing a novel concept of tensor collectives. These treat a group of vectors on\na node as a single object allowing for the existing single vector algorithms to\nbe directly applicable. We back our claims with sufficient emperical evidence\nusing large scale ImageNet 1K data. Our framework is built upon MXNET but the\ndesign is generic and can be adapted to other popular DL infrastructures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 16:32:10 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Mamidala", "Amith R", ""], ["Kollias", "Georgios", ""], ["Ward", "Chris", ""], ["Artico", "Fausto", ""]]}, {"id": "1801.03905", "submitter": "Ding Zhao", "authors": "Wenshuo Wang, Junqiang Xi, Ding Zhao", "title": "Learning and Inferring a Driver's Braking Action in Car-Following\n  Scenarios", "comments": null, "journal-ref": null, "doi": "10.1109/TVT.2018.2793889", "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting and inferring a driver's decision to brake is critical\nfor designing warning systems and avoiding collisions. In this paper we focus\non predicting a driver's intent to brake in car-following scenarios from a\nperception-decision-action perspective according to his/her driving history. A\nlearning-based inference method, using onboard data from CAN-Bus, radar and\ncameras as explanatory variables, is introduced to infer drivers' braking\ndecisions by combining a Gaussian mixture model (GMM) with a hidden Markov\nmodel (HMM). The GMM is used to model stochastic relationships among variables,\nwhile the HMM is applied to infer drivers' braking actions based on the GMM.\nReal-case driving data from 49 drivers (more than three years' driving data per\ndriver on average) have been collected from the University of Michigan Safety\nPilot Model Deployment database. We compare the GMM-HMM method to a support\nvector machine (SVM) method and an SVM-Bayesian filtering method. The\nexperimental results are evaluated by employing three performance metrics:\naccuracy, sensitivity, specificity. The comparison results show that the\nGMM-HMM obtains the best performance, with an accuracy of 90%, sensitivity of\n84%, and specificity of 97%. Thus, we believe that this method has great\npotential for real-world active safety systems.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 18:05:41 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Wang", "Wenshuo", ""], ["Xi", "Junqiang", ""], ["Zhao", "Ding", ""]]}, {"id": "1801.03911", "submitter": "Sahil Garg", "authors": "Sahil Garg and Greg Ver Steeg and Aram Galstyan", "title": "Stochastic Learning of Nonstationary Kernels for Natural Language\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing often involves computations with semantic or\nsyntactic graphs to facilitate sophisticated reasoning based on structural\nrelationships. While convolution kernels provide a powerful tool for comparing\ngraph structure based on node (word) level relationships, they are difficult to\ncustomize and can be computationally expensive. We propose a generalization of\nconvolution kernels, with a nonstationary model, for better expressibility of\nnatural languages in supervised settings. For a scalable learning of the\nparameters introduced with our model, we propose a novel algorithm that\nleverages stochastic sampling on k-nearest neighbor graphs, along with\napproximations based on locality-sensitive hashing. We demonstrate the\nadvantages of our approach on a challenging real-world (structured inference)\nproblem of automatically extracting biological models from the text of\nscientific papers.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 18:24:02 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 21:41:27 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Garg", "Sahil", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1801.03968", "submitter": "Eisa Alanazi", "authors": "Eisa Alanazi, Malek Mouhoub, Sandra Zilles", "title": "The Complexity of Learning Acyclic Conditional Preference Networks", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning of user preferences, as represented by, for example, Conditional\nPreference Networks (CP-nets), has become a core issue in AI research. Recent\nstudies investigate learning of CP-nets from randomly chosen examples or from\nmembership and equivalence queries. To assess the optimality of learning\nalgorithms as well as to better understand the combinatorial structure of\nclasses of CP-nets, it is helpful to calculate certain learning-theoretic\ninformation complexity parameters. This article focuses on the frequently\nstudied case of learning from so-called swap examples, which express\npreferences among objects that differ in only one attribute. It presents bounds\non or exact values of some well-studied information complexity parameters,\nnamely the VC dimension, the teaching dimension, and the recursive teaching\ndimension, for classes of acyclic CP-nets. We further provide algorithms that\nlearn tree-structured and general acyclic CP-nets from membership queries.\nUsing our results on complexity parameters, we assess the optimality of our\nalgorithms as well as that of another query learning algorithm for acyclic\nCP-nets presented in the literature. Our algorithms are near-optimal, and can,\nunder certain assumptions, be adapted to the case when the membership oracle is\nfaulty.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 19:56:43 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 20:06:48 GMT"}, {"version": "v3", "created": "Tue, 5 Feb 2019 17:45:09 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Alanazi", "Eisa", ""], ["Mouhoub", "Malek", ""], ["Zilles", "Sandra", ""]]}, {"id": "1801.04003", "submitter": "Abbas Mehrabian", "authors": "Hassan Ashtiani and Abbas Mehrabian", "title": "Some techniques in density estimation", "comments": "18 pages; new version includes tight results on mixtures of general\n  Gaussians", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation is an interdisciplinary topic at the intersection of\nstatistics, theoretical computer science and machine learning. We review some\nold and new techniques for bounding the sample complexity of estimating\ndensities of continuous distributions, focusing on the class of mixtures of\nGaussians and its subclasses. In particular, we review the main techniques used\nto prove the new sample complexity bounds for mixtures of Gaussians by\nAshtiani, Ben-David, Harvey, Liaw, Mehrabian, and Plan arXiv:1710.05209.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 21:51:18 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 05:44:21 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Ashtiani", "Hassan", ""], ["Mehrabian", "Abbas", ""]]}, {"id": "1801.04014", "submitter": "Mahdi Nazemi", "authors": "Mahdi Nazemi, Amir Erfan Eshratifar, Massoud Pedram", "title": "A Hardware-Friendly Algorithm for Scalable Training and Deployment of\n  Dimensionality Reduction Models on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With ever-increasing application of machine learning models in various\ndomains such as image classification, speech recognition and synthesis, and\nhealth care, designing efficient hardware for these models has gained a lot of\npopularity. While the majority of researches in this area focus on efficient\ndeployment of machine learning models (a.k.a inference), this work concentrates\non challenges of training these models in hardware. In particular, this paper\npresents a high-performance, scalable, reconfigurable solution for both\ntraining and deployment of different dimensionality reduction models in\nhardware by introducing a hardware-friendly algorithm. Compared to\nstate-of-the-art implementations, our proposed algorithm and its hardware\nrealization decrease resource consumption by 50\\% without any degradation in\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 23:15:20 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 17:47:53 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Nazemi", "Mahdi", ""], ["Eshratifar", "Amir Erfan", ""], ["Pedram", "Massoud", ""]]}, {"id": "1801.04016", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "Theoretical Impediments to Machine Learning With Seven Sparks from the\n  Causal Revolution", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "R-475", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current machine learning systems operate, almost exclusively, in a\nstatistical, or model-free mode, which entails severe theoretical limits on\ntheir power and performance. Such systems cannot reason about interventions and\nretrospection and, therefore, cannot serve as the basis for strong AI. To\nachieve human level intelligence, learning machines need the guidance of a\nmodel of reality, similar to the ones used in causal inference tasks. To\ndemonstrate the essential role of such models, I will present a summary of\nseven tasks which are beyond reach of current machine learning systems and\nwhich have been accomplished using the tools of causal modeling.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 23:37:48 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1801.04053", "submitter": "Osonde Osoba Ph.D.", "authors": "Osonde Osoba, Bart Kosko", "title": "Noisy Expectation-Maximization: Applications and Generalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a noise-injected version of the Expectation-Maximization (EM)\nalgorithm: the Noisy Expectation Maximization (NEM) algorithm. The NEM\nalgorithm uses noise to speed up the convergence of the EM algorithm. The NEM\ntheorem shows that injected noise speeds up the average convergence of the EM\nalgorithm to a local maximum of the likelihood surface if a positivity\ncondition holds. The generalized form of the noisy expectation-maximization\n(NEM) algorithm allow for arbitrary modes of noise injection including adding\nand multiplying noise to the data.\n  We demonstrate these noise benefits on EM algorithms for the Gaussian mixture\nmodel (GMM) with both additive and multiplicative NEM noise injection. A\nseparate theorem (not presented here) shows that the noise benefit for\nindependent identically distributed additive noise decreases with sample size\nin mixture models. This theorem implies that the noise benefit is most\npronounced if the data is sparse. Injecting blind noise only slowed\nconvergence.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 04:09:48 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Osoba", "Osonde", ""], ["Kosko", "Bart", ""]]}, {"id": "1801.04055", "submitter": "Aristide Baratin", "authors": "Akram Erraqabi, Aristide Baratin, Yoshua Bengio, Simon Lacoste-Julien", "title": "A3T: Adversarially Augmented Adversarial Training", "comments": "accepted for an oral presentation in Machine Deception Workshop, NIPS\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research showed that deep neural networks are highly sensitive to\nso-called adversarial perturbations, which are tiny perturbations of the input\ndata purposely designed to fool a machine learning classifier. Most\nclassification models, including deep learning models, are highly vulnerable to\nadversarial attacks. In this work, we investigate a procedure to improve\nadversarial robustness of deep neural networks through enforcing representation\ninvariance. The idea is to train the classifier jointly with a discriminator\nattached to one of its hidden layer and trained to filter the adversarial\nnoise. We perform preliminary experiments to test the viability of the approach\nand to compare it to other standard adversarial training methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 04:34:17 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Erraqabi", "Akram", ""], ["Baratin", "Aristide", ""], ["Bengio", "Yoshua", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1801.04062", "submitter": "Mohamed Ishmael Belghazi", "authors": "Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil\n  Ozair, Yoshua Bengio, Aaron Courville, R Devon Hjelm", "title": "MINE: Mutual Information Neural Estimation", "comments": "19 pages, 6 figures", "journal-ref": "ICML 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the estimation of mutual information between high dimensional\ncontinuous random variables can be achieved by gradient descent over neural\nnetworks. We present a Mutual Information Neural Estimator (MINE) that is\nlinearly scalable in dimensionality as well as in sample size, trainable\nthrough back-prop, and strongly consistent. We present a handful of\napplications on which MINE can be used to minimize or maximize mutual\ninformation. We apply MINE to improve adversarially trained generative models.\nWe also use MINE to implement Information Bottleneck, applying it to supervised\nclassification; our results demonstrate substantial improvement in flexibility\nand performance in these settings.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 05:42:58 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 03:31:35 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 15:56:13 GMT"}, {"version": "v4", "created": "Thu, 7 Jun 2018 20:13:11 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Belghazi", "Mohamed Ishmael", ""], ["Baratin", "Aristide", ""], ["Rajeswar", "Sai", ""], ["Ozair", "Sherjil", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""], ["Hjelm", "R Devon", ""]]}, {"id": "1801.04179", "submitter": "Andres Gomez Ramirez", "authors": "A. Gomez Ramirez and C. Lara and L. Betev and D. Bilanovic and U.\n  Kebschull (and for the ALICE Collaboration)", "title": "Arhuaco: Deep Learning and Isolation Based Security for Distributed\n  High-Throughput Computing", "comments": "Manuscript submitted to the Journal of Grid Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Grid computing systems require innovative methods and tools to identify\ncybersecurity incidents and perform autonomous actions i.e. without\nadministrator intervention. They also require methods to isolate and trace job\npayload activity in order to protect users and find evidence of malicious\nbehavior. We introduce an integrated approach of security monitoring via\nSecurity by Isolation with Linux Containers and Deep Learning methods for the\nanalysis of real time data in Grid jobs running inside virtualized\nHigh-Throughput Computing infrastructure in order to detect and prevent\nintrusions. A dataset for malware detection in Grid computing is described. We\nshow in addition the utilization of generative methods with Recurrent Neural\nNetworks to improve the collected dataset. We present Arhuaco, a prototype\nimplementation of the proposed methods. We empirically study the performance of\nour technique. The results show that Arhuaco outperforms other methods used in\nIntrusion Detection Systems for Grid Computing. The study is carried out in the\nALICE Collaboration Grid, part of the Worldwide LHC Computing Grid.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 14:35:19 GMT"}], "update_date": "2018-07-01", "authors_parsed": [["Ramirez", "A. Gomez", "", "and for the ALICE Collaboration"], ["Lara", "C.", "", "and for the ALICE Collaboration"], ["Betev", "L.", "", "and for the ALICE Collaboration"], ["Bilanovic", "D.", "", "and for the ALICE Collaboration"], ["Kebschull", "U.", "", "and for the ALICE Collaboration"]]}, {"id": "1801.04211", "submitter": "Felix Horger", "authors": "Felix Horger, Tobias W\\\"urfl, Vincent Christlein, Andreas Maier", "title": "Towards Arbitrary Noise Augmentation - Deep Learning for Sampling from\n  Arbitrary Probability Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate noise modelling is important for training of deep learning\nreconstruction algorithms. While noise models are well known for traditional\nimaging techniques, the noise distribution of a novel sensor may be difficult\nto determine a priori. Therefore, we propose learning arbitrary noise\ndistributions. To do so, this paper proposes a fully connected neural network\nmodel to map samples from a uniform distribution to samples of any explicitly\nknown probability density function. During the training, the Jensen-Shannon\ndivergence between the distribution of the model's output and the target\ndistribution is minimized. We experimentally demonstrate that our model\nconverges towards the desired state. It provides an alternative to existing\nsampling methods such as inversion sampling, rejection sampling, Gaussian\nmixture models and Markov-Chain-Monte-Carlo. Our model has high sampling\nefficiency and is easily applied to any probability distribution, without the\nneed of further analytical or numerical calculations.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 16:03:21 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 08:55:22 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Horger", "Felix", ""], ["W\u00fcrfl", "Tobias", ""], ["Christlein", "Vincent", ""], ["Maier", "Andreas", ""]]}, {"id": "1801.04260", "submitter": "Fabian Mentzer", "authors": "Fabian Mentzer, Eirikur Agustsson, Michael Tschannen, Radu Timofte,\n  Luc Van Gool", "title": "Conditional Probability Models for Deep Image Compression", "comments": "CVPR 2018. Code available at https://github.com/fab-jul/imgcomp-cvpr\n  . The first two authors contributed equally. Minor revision: fixed Fig. 2,\n  added page numbers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks trained as image auto-encoders have recently emerged as\na promising direction for advancing the state-of-the-art in image compression.\nThe key challenge in learning such networks is twofold: To deal with\nquantization, and to control the trade-off between reconstruction error\n(distortion) and entropy (rate) of the latent image representation. In this\npaper, we focus on the latter challenge and propose a new technique to navigate\nthe rate-distortion trade-off for an image compression auto-encoder. The main\nidea is to directly model the entropy of the latent representation by using a\ncontext model: A 3D-CNN which learns a conditional probability model of the\nlatent distribution of the auto-encoder. During training, the auto-encoder\nmakes use of the context model to estimate the entropy of its representation,\nand the context model is concurrently updated to learn the dependencies between\nthe symbols in the latent representation. Our experiments show that this\napproach, when measured in MS-SSIM, yields a state-of-the-art image compression\nsystem based on a simple convolutional auto-encoder.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 18:29:05 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 17:07:05 GMT"}, {"version": "v3", "created": "Mon, 4 Jun 2018 08:01:25 GMT"}, {"version": "v4", "created": "Tue, 4 Jun 2019 14:38:14 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Mentzer", "Fabian", ""], ["Agustsson", "Eirikur", ""], ["Tschannen", "Michael", ""], ["Timofte", "Radu", ""], ["Van Gool", "Luc", ""]]}, {"id": "1801.04271", "submitter": "Saifuddin Hitawala", "authors": "Saifuddin Hitawala", "title": "Comparative Study on Generative Adversarial Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been tremendous advancements in the field of\nmachine learning. These advancements have been made through both academic as\nwell as industrial research. Lately, a fair amount of research has been\ndedicated to the usage of generative models in the field of computer vision and\nimage classification. These generative models have been popularized through a\nnew framework called Generative Adversarial Networks. Moreover, many modified\nversions of this framework have been proposed in the last two years. We study\nthe original model proposed by Goodfellow et al. as well as modifications over\nthe original model and provide a comparative analysis of these models.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 01:37:16 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Hitawala", "Saifuddin", ""]]}, {"id": "1801.04289", "submitter": "Saad Mohamad", "authors": "Saad Mohamad, Abdelhamid Bouchachia, Moamar Sayed-Mouchaweh", "title": "Asynchronous Stochastic Variational Inference", "comments": "7 pages, 8 figures, 1 table, 2 algorithms, The paper has been\n  submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference (SVI) employs stochastic optimization to\nscale up Bayesian computation to massive data. Since SVI is at its core a\nstochastic gradient-based algorithm, horizontal parallelism can be harnessed to\nallow larger scale inference. We propose a lock-free parallel implementation\nfor SVI which allows distributed computations over multiple slaves in an\nasynchronous style. We show that our implementation leads to linear speed-up\nwhile guaranteeing an asymptotic ergodic convergence rate $O(1/\\sqrt(T)$ )\ngiven that the number of slaves is bounded by $\\sqrt(T)$ ($T$ is the total\nnumber of iterations). The implementation is done in a high-performance\ncomputing (HPC) environment using message passing interface (MPI) for python\n(MPI4py). The extensive empirical evaluation shows that our parallel SVI is\nlossless, performing comparably well to its counterpart serial SVI with linear\nspeed-up.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 19:05:09 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Mohamad", "Saad", ""], ["Bouchachia", "Abdelhamid", ""], ["Sayed-Mouchaweh", "Moamar", ""]]}, {"id": "1801.04295", "submitter": "Ankit Pensia", "authors": "Ankit Pensia, Varun Jog and Po-Ling Loh", "title": "Generalization Error Bounds for Noisy, Iterative Algorithms", "comments": "A shorter version of this paper was submitted to ISIT 2018. 14 pages,\n  1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical learning theory, generalization error is used to quantify the\ndegree to which a supervised machine learning algorithm may overfit to training\ndata. Recent work [Xu and Raginsky (2017)] has established a bound on the\ngeneralization error of empirical risk minimization based on the mutual\ninformation $I(S;W)$ between the algorithm input $S$ and the algorithm output\n$W$, when the loss function is sub-Gaussian. We leverage these results to\nderive generalization error bounds for a broad class of iterative algorithms\nthat are characterized by bounded, noisy updates with Markovian structure. Our\nbounds are very general and are applicable to numerous settings of interest,\nincluding stochastic gradient Langevin dynamics (SGLD) and variants of the\nstochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm. Furthermore, our\nerror bounds hold for any output function computed over the path of iterates,\nincluding the last iterate of the algorithm or the average of subsets of\niterates, and also allow for non-uniform sampling of data in successive updates\nof the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 19:26:35 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Pensia", "Ankit", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1801.04326", "submitter": "Liangzhen Lai", "authors": "Liangzhen Lai, Naveen Suda, Vikas Chandra", "title": "Not All Ops Are Created Equal!", "comments": "Accepted at SysML Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and compact neural network models are essential for enabling the\ndeployment on mobile and embedded devices. In this work, we point out that\ntypical design metrics for gauging the efficiency of neural network\narchitectures -- total number of operations and parameters -- are not\nsufficient. These metrics may not accurately correlate with the actual\ndeployment metrics such as energy and memory footprint. We show that throughput\nand energy varies by up to 5X across different neural network operation types\non an off-the-shelf Arm Cortex-M7 microcontroller. Furthermore, we show that\nthe memory required for activation data also need to be considered, apart from\nthe model parameters, for network architecture exploration studies.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 21:43:56 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 22:20:26 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Lai", "Liangzhen", ""], ["Suda", "Naveen", ""], ["Chandra", "Vikas", ""]]}, {"id": "1801.04339", "submitter": "Jason Klusowski M", "authors": "Jason M. Klusowski and Yihong Wu", "title": "Estimating the Number of Connected Components in a Graph via Subgraph\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DM cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning properties of large graphs from samples has been an important\nproblem in statistical network analysis since the early work of Goodman\n\\cite{Goodman1949} and Frank \\cite{Frank1978}. We revisit a problem formulated\nby Frank \\cite{Frank1978} of estimating the number of connected components in a\nlarge graph based on the subgraph sampling model, in which we randomly sample a\nsubset of the vertices and observe the induced subgraph. The key question is\nwhether accurate estimation is achievable in the \\emph{sublinear} regime where\nonly a vanishing fraction of the vertices are sampled. We show that it is\nimpossible if the parent graph is allowed to contain high-degree vertices or\nlong induced cycles. For the class of chordal graphs, where induced cycles of\nlength four or above are forbidden, we characterize the optimal sample\ncomplexity within constant factors and construct linear-time estimators that\nprovably achieve these bounds. This significantly expands the scope of previous\nresults which have focused on unbiased estimators and special classes of graphs\nsuch as forests or cliques.\n  Both the construction and the analysis of the proposed methodology rely on\ncombinatorial properties of chordal graphs and identities of induced subgraph\ncounts. They, in turn, also play a key role in proving minimax lower bounds\nbased on construction of random instances of graphs with matching structures of\nsmall subgraphs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 22:13:48 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 21:28:29 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 21:13:30 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Klusowski", "Jason M.", ""], ["Wu", "Yihong", ""]]}, {"id": "1801.04340", "submitter": "Sajan Patel", "authors": "Sajan Patel, Brent Griffin, Kristofer Kusano, Jason J. Corso", "title": "Predicting Future Lane Changes of Other Highway Vehicles using RNN-based\n  Deep Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the event of sensor failure, autonomous vehicles need to safely execute\nemergency maneuvers while avoiding other vehicles on the road. To accomplish\nthis, the sensor-failed vehicle must predict the future semantic behaviors of\nother drivers, such as lane changes, as well as their future trajectories given\na recent window of past sensor observations. We address the first issue of\nsemantic behavior prediction in this paper, which is a precursor to trajectory\nprediction, by introducing a framework that leverages the power of recurrent\nneural networks (RNNs) and graphical models. Our goal is to predict the future\ncategorical driving intent, for lane changes, of neighboring vehicles up to\nthree seconds into the future given as little as a one-second window of past\nLIDAR, GPS, inertial, and map data.\n  We collect real-world data containing over 20 hours of highway driving using\nan autonomous Toyota vehicle. We propose a composite RNN model by adopting the\nmethodology of Structural Recurrent Neural Networks (RNNs) to learn factor\nfunctions and take advantage of both the high-level structure of graphical\nmodels and the sequence modeling power of RNNs, which we expect to afford more\ntransparent modeling and activity than opaque, single RNN models. To\ndemonstrate our approach, we validate our model using authentic interstate\nhighway driving to predict the future lane change maneuvers of other vehicles\nneighboring our autonomous vehicle. We find that our composite Structural RNN\noutperforms baselines by as much as 12% in balanced accuracy metrics.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 22:16:05 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 22:07:01 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 04:13:17 GMT"}, {"version": "v4", "created": "Thu, 16 May 2019 16:56:16 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Patel", "Sajan", ""], ["Griffin", "Brent", ""], ["Kusano", "Kristofer", ""], ["Corso", "Jason J.", ""]]}, {"id": "1801.04342", "submitter": "Forough Arabshahi", "authors": "Forough Arabshahi, Sameer Singh, Animashree Anandkumar", "title": "Combining Symbolic Expressions and Black-box Function Evaluations in\n  Neural Programs", "comments": "Published as a conference paper at the sixth International Conference\n  on Learning Representations (ICLR), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural programming involves training neural networks to learn programs,\nmathematics, or logic from data. Previous works have failed to achieve good\ngeneralization performance, especially on problems and programs with high\ncomplexity or on large domains. This is because they mostly rely either on\nblack-box function evaluations that do not capture the structure of the\nprogram, or on detailed execution traces that are expensive to obtain, and\nhence the training data has poor coverage of the domain under consideration. We\npresent a novel framework that utilizes black-box function evaluations, in\nconjunction with symbolic expressions that define relationships between the\ngiven functions. We employ tree LSTMs to incorporate the structure of the\nsymbolic expression trees. We use tree encoding for numbers present in function\nevaluation data, based on their decimal representation. We present an\nevaluation benchmark for this task to demonstrate our proposed model combines\nsymbolic reasoning and function evaluation in a fruitful manner, obtaining high\naccuracies in our experiments. Our framework generalizes significantly better\nto expressions of higher depth and is able to fill partial equations with valid\ncompletions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 22:24:42 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 22:45:02 GMT"}, {"version": "v3", "created": "Thu, 26 Apr 2018 23:36:01 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Arabshahi", "Forough", ""], ["Singh", "Sameer", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "1801.04354", "submitter": "Yanjun  Qi Dr.", "authors": "Ji Gao, Jack Lanchantin, Mary Lou Soffa, Yanjun Qi", "title": "Black-box Generation of Adversarial Text Sequences to Evade Deep\n  Learning Classifiers", "comments": "This is an extended version of the 6page Workshop version appearing\n  in 1st Deep Learning and Security Workshop colocated with IEEE S&P", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although various techniques have been proposed to generate adversarial\nsamples for white-box attacks on text, little attention has been paid to\nblack-box attacks, which are more realistic scenarios. In this paper, we\npresent a novel algorithm, DeepWordBug, to effectively generate small text\nperturbations in a black-box setting that forces a deep-learning classifier to\nmisclassify a text input. We employ novel scoring strategies to identify the\ncritical tokens that, if modified, cause the classifier to make an incorrect\nprediction. Simple character-level transformations are applied to the\nhighest-ranked tokens in order to minimize the edit distance of the\nperturbation, yet change the original classification. We evaluated DeepWordBug\non eight real-world text datasets, including text classification, sentiment\nanalysis, and spam detection. We compare the result of DeepWordBug with two\nbaselines: Random (Black-box) and Gradient (White-box). Our experimental\nresults indicate that DeepWordBug reduces the prediction accuracy of current\nstate-of-the-art deep-learning models, including a decrease of 68\\% on average\nfor a Word-LSTM model and 48\\% on average for a Char-CNN model.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 00:42:30 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 02:59:45 GMT"}, {"version": "v3", "created": "Sat, 7 Apr 2018 03:32:12 GMT"}, {"version": "v4", "created": "Mon, 16 Apr 2018 12:59:01 GMT"}, {"version": "v5", "created": "Wed, 23 May 2018 15:55:55 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Gao", "Ji", ""], ["Lanchantin", "Jack", ""], ["Soffa", "Mary Lou", ""], ["Qi", "Yanjun", ""]]}, {"id": "1801.04378", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Sajad Khodadadian, Negar Kiyavash", "title": "Fairness in Supervised Learning: An Information Theoretic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated decision making systems are increasingly being used in real-world\napplications. In these systems for the most part, the decision rules are\nderived by minimizing the training error on the available historical data.\nTherefore, if there is a bias related to a sensitive attribute such as gender,\nrace, religion, etc. in the data, say, due to cultural/historical\ndiscriminatory practices against a certain demographic, the system could\ncontinue discrimination in decisions by including the said bias in its decision\nrule. We present an information theoretic framework for designing fair\npredictors from data, which aim to prevent discrimination against a specified\nsensitive attribute in a supervised learning setting. We use equalized odds as\nthe criterion for discrimination, which demands that the prediction should be\nindependent of the protected attribute conditioned on the actual label. To\nensure fairness and generalization simultaneously, we compress the data to an\nauxiliary variable, which is used for the prediction task. This auxiliary\nvariable is chosen such that it is decontaminated from the discriminatory\nattribute in the sense of equalized odds. The final predictor is obtained by\napplying a Bayesian decision rule to the auxiliary variable.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 04:03:04 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 21:49:01 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Khodadadian", "Sajad", ""], ["Kiyavash", "Negar", ""]]}, {"id": "1801.04380", "submitter": "Linnan Wang", "authors": "Linnan Wang, Jinmian Ye, Yiyang Zhao, Wei Wu, Ang Li, Shuaiwen Leon\n  Song, Zenglin Xu, Tim Kraska", "title": "SuperNeurons: Dynamic GPU Memory Management for Training Deep Neural\n  Networks", "comments": "PPoPP '2018: 23nd ACM SIGPLAN Symposium on Principles and Practice of\n  Parallel Programming", "journal-ref": null, "doi": "10.1145/3178487.3178491", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Going deeper and wider in neural architectures improves the accuracy, while\nthe limited GPU DRAM places an undesired restriction on the network design\ndomain. Deep Learning (DL) practitioners either need change to less desired\nnetwork architectures, or nontrivially dissect a network across multiGPUs.\nThese distract DL practitioners from concentrating on their original machine\nlearning tasks. We present SuperNeurons: a dynamic GPU memory scheduling\nruntime to enable the network training far beyond the GPU DRAM capacity.\nSuperNeurons features 3 memory optimizations, \\textit{Liveness Analysis},\n\\textit{Unified Tensor Pool}, and \\textit{Cost-Aware Recomputation}, all\ntogether they effectively reduce the network-wide peak memory usage down to the\nmaximal memory usage among layers. We also address the performance issues in\nthose memory saving techniques. Given the limited GPU DRAM, SuperNeurons not\nonly provisions the necessary memory for the training, but also dynamically\nallocates the memory for convolution workspaces to achieve the high\nperformance. Evaluations against Caffe, Torch, MXNet and TensorFlow have\ndemonstrated that SuperNeurons trains at least 3.2432 deeper network than\ncurrent ones with the leading performance. Particularly, SuperNeurons can train\nResNet2500 that has $10^4$ basic network layers on a 12GB K40c.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 04:11:41 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Wang", "Linnan", ""], ["Ye", "Jinmian", ""], ["Zhao", "Yiyang", ""], ["Wu", "Wei", ""], ["Li", "Ang", ""], ["Song", "Shuaiwen Leon", ""], ["Xu", "Zenglin", ""], ["Kraska", "Tim", ""]]}, {"id": "1801.04396", "submitter": "Yue Geng", "authors": "Yue Geng, Xinyu Luo", "title": "Cost-Sensitive Convolution based Neural Networks for Imbalanced\n  Time-Series Classification", "comments": "22 pages,12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Some deep convolutional neural networks were proposed for time-series\nclassification and class imbalanced problems. However, those models performed\ndegraded and even failed to recognize the minority class of an imbalanced\ntemporal sequences dataset. Minority samples would bring troubles for temporal\ndeep learning classifiers due to the equal treatments of majority and minority\nclass. Until recently, there were few works applying deep learning on\nimbalanced time-series classification (ITSC) tasks. Here, this paper aimed at\ntackling ITSC problems with deep learning. An adaptive cost-sensitive learning\nstrategy was proposed to modify temporal deep learning models. Through the\nproposed strategy, classifiers could automatically assign misclassification\npenalties to each class. In the experimental section, the proposed method was\nutilized to modify five neural networks. They were evaluated on a large volume,\nreal-life and imbalanced time-series dataset with six metrics. Each single\nnetwork was also tested alone and combined with several mainstream data\nsamplers. Experimental results illustrated that the proposed cost-sensitive\nmodified networks worked well on ITSC tasks. Compared to other methods, the\ncost-sensitive convolution neural network and residual network won out in the\nterms of all metrics. Consequently, the proposed cost-sensitive learning\nstrategy can be used to modify deep learning classifiers from cost-insensitive\nto cost-sensitive. Those cost-sensitive convolutional networks can be\neffectively applied to address ITSC issues.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 08:24:15 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Geng", "Yue", ""], ["Luo", "Xinyu", ""]]}, {"id": "1801.04405", "submitter": "Amir Ashouri", "authors": "Amir H. Ashouri, William Killian, John Cavazos, Gianluca Palermo and\n  Cristina Silvano", "title": "A Survey on Compiler Autotuning using Machine Learning", "comments": "version 5.0 (updated on September 2018)- Preprint Version For our\n  Accepted Journal @ ACM CSUR 2018 (42 pages) - This survey will be updated\n  quarterly here (Send me your new published papers to be added in the\n  subsequent version) History: Received November 2016; Revised August 2017;\n  Revised February 2018; Accepted March 2018-", "journal-ref": null, "doi": "10.1145/3197978", "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the mid-1990s, researchers have been trying to use machine-learning\nbased approaches to solve a number of different compiler optimization problems.\nThese techniques primarily enhance the quality of the obtained results and,\nmore importantly, make it feasible to tackle two main compiler optimization\nproblems: optimization selection (choosing which optimizations to apply) and\nphase-ordering (choosing the order of applying optimizations). The compiler\noptimization space continues to grow due to the advancement of applications,\nincreasing number of compiler optimizations, and new target architectures.\nGeneric optimization passes in compilers cannot fully leverage newly introduced\noptimizations and, therefore, cannot keep up with the pace of increasing\noptions. This survey summarizes and classifies the recent advances in using\nmachine learning for the compiler optimization field, particularly on the two\nmajor problems of (1) selecting the best optimizations and (2) the\nphase-ordering of optimizations. The survey highlights the approaches taken so\nfar, the obtained results, the fine-grain classification among different\napproaches and finally, the influential papers of the field.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 09:41:57 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 04:35:32 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 01:03:50 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 04:48:00 GMT"}, {"version": "v5", "created": "Mon, 3 Sep 2018 20:42:21 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Ashouri", "Amir H.", ""], ["Killian", "William", ""], ["Cavazos", "John", ""], ["Palermo", "Gianluca", ""], ["Silvano", "Cristina", ""]]}, {"id": "1801.04406", "submitter": "Lars Mescheder", "authors": "Lars Mescheder, Andreas Geiger, Sebastian Nowozin", "title": "Which Training Methods for GANs do actually Converge?", "comments": "conference", "journal-ref": "International Conference on Machine Learning 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown local convergence of GAN training for absolutely\ncontinuous data and generator distributions. In this paper, we show that the\nrequirement of absolute continuity is necessary: we describe a simple yet\nprototypical counterexample showing that in the more realistic case of\ndistributions that are not absolutely continuous, unregularized GAN training is\nnot always convergent. Furthermore, we discuss regularization strategies that\nwere recently proposed to stabilize GAN training. Our analysis shows that GAN\ntraining with instance noise or zero-centered gradient penalties converges. On\nthe other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number\nof discriminator updates per generator update do not always converge to the\nequilibrium point. We discuss these results, leading us to a new explanation\nfor the stability problems of GAN training. Based on our analysis, we extend\nour convergence results to more general GANs and prove local convergence for\nsimplified gradient penalties even if the generator and data distribution lie\non lower dimensional manifolds. We find these penalties to work well in\npractice and use them to learn high-resolution generative image models for a\nvariety of datasets with little hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 09:42:26 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 10:40:54 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 15:39:06 GMT"}, {"version": "v4", "created": "Tue, 31 Jul 2018 16:28:15 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Mescheder", "Lars", ""], ["Geiger", "Andreas", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "1801.04407", "submitter": "Unai Garciarena", "authors": "Unai Garciarena, Alexander Mendiburu, Roberto Santana", "title": "Towards a more efficient representation of imputation operators in TPOT", "comments": "13 pages, 4 figures. Continuation of a previous work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Machine Learning encompasses a set of meta-algorithms intended to\ndesign and apply machine learning techniques (e.g., model selection,\nhyperparameter tuning, model assessment, etc.). TPOT, a software for optimizing\nmachine learning pipelines based on genetic programming (GP), is a novel\nexample of this kind of applications. Recently we have proposed a way to\nintroduce imputation methods as part of TPOT. While our approach was able to\ndeal with problems with missing data, it can produce a high number of\nunfeasible pipelines. In this paper we propose a strongly-typed-GP based\napproach that enforces constraint satisfaction by GP solutions. The enhancement\nwe introduce is based on the redefinition of the operators and implicit\nenforcement of constraints in the generation of the GP trees. We evaluate the\nmethod to introduce imputation methods as part of TPOT. We show that the method\ncan notably increase the efficiency of the GP search for optimal pipelines.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 09:45:05 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Garciarena", "Unai", ""], ["Mendiburu", "Alexander", ""], ["Santana", "Roberto", ""]]}, {"id": "1801.04486", "submitter": "Aaron Hertzmann", "authors": "Aaron Hertzmann", "title": "Can Computers Create Art?", "comments": "to appear in Arts, special issue on Machine as Artist (21st Century)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This essay discusses whether computers, using Artificial Intelligence (AI),\ncould create art. First, the history of technologies that automated aspects of\nart is surveyed, including photography and animation. In each case, there were\ninitial fears and denial of the technology, followed by a blossoming of new\ncreative and professional opportunities for artists. The current hype and\nreality of Artificial Intelligence (AI) tools for art making is then discussed,\ntogether with predictions about how AI tools will be used. It is then\nspeculated about whether it could ever happen that AI systems could be credited\nwith authorship of artwork. It is theorized that art is something created by\nsocial agents, and so computers cannot be credited with authorship of art in\nour current understanding. A few ways that this could change are also\nhypothesized.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 21:04:13 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 03:37:22 GMT"}, {"version": "v3", "created": "Thu, 25 Jan 2018 06:25:17 GMT"}, {"version": "v4", "created": "Thu, 8 Feb 2018 19:23:07 GMT"}, {"version": "v5", "created": "Mon, 19 Mar 2018 06:32:02 GMT"}, {"version": "v6", "created": "Tue, 8 May 2018 03:45:56 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Hertzmann", "Aaron", ""]]}, {"id": "1801.04492", "submitter": "Sam Safavi", "authors": "Sam Safavi, Bikash Joshi, Guilherme Fran\\c{c}a, Jos\\'e Bento", "title": "An Explicit Convergence Rate for Nesterov's Method from SDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of Integral Quadratic Constraints (IQC) introduced by Lessard\net al. (2014) reduces the computation of upper bounds on the convergence rate\nof several optimization algorithms to semi-definite programming (SDP). In\nparticular, this technique was applied to Nesterov's accelerated method (NAM).\nFor quadratic functions, this SDP was explicitly solved leading to a new bound\non the convergence rate of NAM, and for arbitrary strongly convex functions it\nwas shown numerically that IQC can improve bounds from Nesterov (2004).\nUnfortunately, an explicit analytic solution to the SDP was not provided. In\nthis paper, we provide such an analytical solution, obtaining a new general and\nexplicit upper bound on the convergence rate of NAM, which we further optimize\nover its parameters. To the best of our knowledge, this is the best, and\nexplicit, upper bound on the convergence rate of NAM for strongly convex\nfunctions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 23:26:40 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Safavi", "Sam", ""], ["Joshi", "Bikash", ""], ["Fran\u00e7a", "Guilherme", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1801.04503", "submitter": "Fazle Karim", "authors": "Fazle Karim, Somshubra Majumdar, Houshang Darabi, Samuel Harford", "title": "Multivariate LSTM-FCNs for Time Series Classification", "comments": "18 pages, 2 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.neunet.2019.04.014", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, multivariate time series classification has received\ngreat attention. We propose transforming the existing univariate time series\nclassification models, the Long Short Term Memory Fully Convolutional Network\n(LSTM-FCN) and Attention LSTM-FCN (ALSTM-FCN), into a multivariate time series\nclassification model by augmenting the fully convolutional block with a\nsqueeze-and-excitation block to further improve accuracy. Our proposed models\noutperform most state-of-the-art models while requiring minimum preprocessing.\nThe proposed models work efficiently on various complex multivariate time\nseries classification tasks such as activity recognition or action recognition.\nFurthermore, the proposed models are highly efficient at test time and small\nenough to deploy on memory constrained systems.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 03:00:53 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 23:51:37 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Karim", "Fazle", ""], ["Majumdar", "Somshubra", ""], ["Darabi", "Houshang", ""], ["Harford", "Samuel", ""]]}, {"id": "1801.04510", "submitter": "Jia Wu", "authors": "Chenglong Dai, Jia Wu, Dechang Pi, Lin Cui", "title": "Brain EEG Time Series Selection: A Novel Graph-Based Approach for\n  Classification", "comments": "9 pages, 5 figures, Accepted by SDM-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain Electroencephalography (EEG) classification is widely applied to\nanalyze cerebral diseases in recent years. Unfortunately, invalid/noisy EEGs\ndegrade the diagnosis performance and most previously developed methods ignore\nthe necessity of EEG selection for classification. To this end, this paper\nproposes a novel maximum weight clique-based EEG selection approach, named\nmwcEEGs, to map EEG selection to searching maximum similarity-weighted cliques\nfrom an improved Fr\\'{e}chet distance-weighted undirected EEG graph\nsimultaneously considering edge weights and vertex weights. Our mwcEEGs\nimproves the classification performance by selecting intra-clique pairwise\nsimilar and inter-clique discriminative EEGs with similarity threshold\n$\\delta$. Experimental results demonstrate the algorithm effectiveness compared\nwith the state-of-the-art time series selection algorithms on real-world EEG\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 04:51:22 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 06:19:21 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Dai", "Chenglong", ""], ["Wu", "Jia", ""], ["Pi", "Dechang", ""], ["Cui", "Lin", ""]]}, {"id": "1801.04520", "submitter": "Dipan Pal", "authors": "Dipan K. Pal, Marios Savvides", "title": "Non-Parametric Transformation Networks", "comments": "Preprint only", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ConvNets, through their architecture, only enforce invariance to translation.\nIn this paper, we introduce a new class of deep convolutional architectures\ncalled Non-Parametric Transformation Networks (NPTNs) which can learn\n\\textit{general} invariances and symmetries directly from data. NPTNs are a\nnatural generalization of ConvNets and can be optimized directly using gradient\ndescent. Unlike almost all previous works in deep architectures, they make no\nassumption regarding the structure of the invariances present in the data and\nin that aspect are flexible and powerful. We also model ConvNets and NPTNs\nunder a unified framework called Transformation Networks (TN), which yields a\nbetter understanding of the connection between the two. We demonstrate the\nefficacy of NPTNs on data such as MNIST with extreme transformations and\nCIFAR10 where they outperform baselines, and further outperform several recent\nalgorithms on ETH-80. They do so while having the same number of parameters. We\nalso show that they are more effective than ConvNets in modelling symmetries\nand invariances from data, without the explicit knowledge of the added\narbitrary nuisance transformations. Finally, we replace ConvNets with NPTNs\nwithin Capsule Networks and show that this enables Capsule Nets to perform even\nbetter.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 06:48:45 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 05:10:50 GMT"}, {"version": "v3", "created": "Wed, 14 Feb 2018 20:34:23 GMT"}, {"version": "v4", "created": "Sat, 12 May 2018 15:57:39 GMT"}, {"version": "v5", "created": "Sat, 19 May 2018 13:32:14 GMT"}, {"version": "v6", "created": "Sat, 8 Sep 2018 22:45:23 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Pal", "Dipan K.", ""], ["Savvides", "Marios", ""]]}, {"id": "1801.04540", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Itay Hubara, Daniel Soudry", "title": "Fix your classifier: the marginal value of training the last weight\n  layer", "comments": "https://openreview.net/forum?id=S1Dh8Tg0-", "journal-ref": "International Conference on Learning Representations 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are commonly used as models for classification for a wide\nvariety of tasks. Typically, a learned affine transformation is placed at the\nend of such models, yielding a per-class value used for classification. This\nclassifier can have a vast number of parameters, which grows linearly with the\nnumber of possible classes, thus requiring increasingly more resources. In this\nwork we argue that this classifier can be fixed, up to a global scale constant,\nwith little or no loss of accuracy for most tasks, allowing memory and\ncomputational benefits. Moreover, we show that by initializing the classifier\nwith a Hadamard matrix we can speed up inference as well. We discuss the\nimplications for current understanding of neural network models.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 12:00:43 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 08:56:25 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Hoffer", "Elad", ""], ["Hubara", "Itay", ""], ["Soudry", "Daniel", ""]]}, {"id": "1801.04546", "submitter": "Andr\\'es G\\'omez Tato", "authors": "Andres Gomez Tato", "title": "Evaluation of Machine Learning Fameworks on Finis Terrae II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) and Deep Learning (DL) are two technologies used to\nextract representations of the data for a specific purpose. ML algorithms take\na set of data as input to generate one or several predictions. To define the\nfinal version of one model, usually there is an initial step devoted to train\nthe algorithm (get the right final values of the parameters of the model).\nThere are several techniques, from supervised learning to reinforcement\nlearning, which have different requirements. On the market, there are some\nframeworks or APIs that reduce the effort for designing a new ML model. In this\nreport, using the benchmark DLBENCH, we will analyse the performance and the\nexecution modes of some well-known ML frameworks on the Finis Terrae II\nsupercomputer when supervised learning is used. The report will show that\nplacement of data and allocated hardware can have a large influence on the\nfinal timeto-solution.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 12:50:00 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Tato", "Andres Gomez", ""]]}, {"id": "1801.04554", "submitter": "Charles Ferreira", "authors": "Charles Henrique Porto Ferreira, Debora Maria Rossi de Medeiros,\n  Fabricio Olivetti de Fran\\c{c}a", "title": "DCDistance: A Supervised Text Document Feature extraction based on class\n  labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text Mining is a field that aims at extracting information from textual data.\nOne of the challenges of such field of study comes from the pre-processing\nstage in which a vector (and structured) representation should be extracted\nfrom unstructured data. The common extraction creates large and sparse vectors\nrepresenting the importance of each term to a document. As such, this usually\nleads to the curse-of-dimensionality that plagues most machine learning\nalgorithms. To cope with this issue, in this paper we propose a new supervised\nfeature extraction and reduction algorithm, named DCDistance, that creates\nfeatures based on the distance between a document to a representative of each\nclass label. As such, the proposed technique can reduce the features set in\nmore than 99% of the original set. Additionally, this algorithm was also\ncapable of improving the classification accuracy over a set of benchmark\ndatasets when compared to traditional and state-of-the-art features selection\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 13:28:19 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Ferreira", "Charles Henrique Porto", ""], ["de Medeiros", "Debora Maria Rossi", ""], ["de Fran\u00e7a", "Fabricio Olivetti", ""]]}, {"id": "1801.04600", "submitter": "Zi Wang", "authors": "Zi Wang, Dali Wang, Chengcheng Li, Yichi Xu, Husheng Li, Zhirong Bao", "title": "Deep Reinforcement Learning of Cell Movement in the Early Stage of C.\n  elegans Embryogenesis", "comments": "We revised the manuscript to make it clearer to follow. Please notice\n  that the Abstract shown in this page is slightly different than that in the\n  manuscript due to the limitation of 1920 characters in arxiv.org", "journal-ref": "Bioinformatics, 2018", "doi": "10.1093/bioinformatics/bty323", "report-no": "bty323", "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell movement in the early phase of C. elegans development is regulated by a\nhighly complex process in which a set of rules and connections are formulated\nat distinct scales. Previous efforts have shown that agent-based, multi-scale\nmodeling systems can integrate physical and biological rules and provide new\navenues to study developmental systems. However, the application of these\nsystems to model cell movement is still challenging and requires a\ncomprehensive understanding of regulation networks at the right scales. Recent\ndevelopments in deep learning and reinforcement learning provide an\nunprecedented opportunity to explore cell movement using 3D time-lapse images.\nWe present a deep reinforcement learning approach within an ABM system to\ncharacterize cell movement in C. elegans embryogenesis. Our modeling system\ncaptures the complexity of cell movement patterns in the embryo and overcomes\nthe local optimization problem encountered by traditional rule-based, ABM that\nuses greedy algorithms. We tested our model with two real developmental\nprocesses: the anterior movement of the Cpaaa cell via intercalation and the\nrearrangement of the left-right asymmetry. In the first case, model results\nshowed that Cpaaa's intercalation is an active directional cell movement caused\nby the continuous effects from a longer distance, as opposed to a passive\nmovement caused by neighbor cell movements. This is because the learning-based\nsimulation found that a passive movement model could not lead Cpaaa to the\npredefined destination. In the second case, a leader-follower mechanism well\nexplained the collective cell movement pattern. These results showed that our\napproach to introduce deep reinforcement learning into ABM can test regulatory\nmechanisms by exploring cell migration paths in a reverse engineering\nperspective. This model opens new doors to explore large datasets generated by\nlive imaging.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 19:33:48 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 19:16:18 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wang", "Zi", ""], ["Wang", "Dali", ""], ["Li", "Chengcheng", ""], ["Xu", "Yichi", ""], ["Li", "Husheng", ""], ["Bao", "Zhirong", ""]]}, {"id": "1801.04693", "submitter": "Bo Luo", "authors": "Bo Luo, Yannan Liu, Lingxiao Wei, Qiang Xu", "title": "Towards Imperceptible and Robust Adversarial Example Attacks against\n  Neural Networks", "comments": "Adversarial example attacks, Robust and Imperceptible, Human\n  perceptual system, Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems based on deep neural networks, being able to produce\nstate-of-the-art results on various perception tasks, have gained mainstream\nadoption in many applications. However, they are shown to be vulnerable to\nadversarial example attack, which generates malicious output by adding slight\nperturbations to the input. Previous adversarial example crafting methods,\nhowever, use simple metrics to evaluate the distances between the original\nexamples and the adversarial ones, which could be easily detected by human\neyes. In addition, these attacks are often not robust due to the inevitable\nnoises and deviation in the physical world. In this work, we present a new\nadversarial example attack crafting method, which takes the human perceptual\nsystem into consideration and maximizes the noise tolerance of the crafted\nadversarial example. Experimental results demonstrate the efficacy of the\nproposed technique.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 08:15:33 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Luo", "Bo", ""], ["Liu", "Yannan", ""], ["Wei", "Lingxiao", ""], ["Xu", "Qiang", ""]]}, {"id": "1801.04695", "submitter": "Soorya Gopalakrishnan", "authors": "Zhinus Marzi, Soorya Gopalakrishnan, Upamanyu Madhow, Ramtin Pedarsani", "title": "Sparsity-based Defense against Adversarial Attacks on Linear Classifiers", "comments": "Published in IEEE International Symposium on Information Theory\n  (ISIT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks represent the state of the art in machine learning in a\ngrowing number of fields, including vision, speech and natural language\nprocessing. However, recent work raises important questions about the\nrobustness of such architectures, by showing that it is possible to induce\nclassification errors through tiny, almost imperceptible, perturbations.\nVulnerability to such \"adversarial attacks\", or \"adversarial examples\", has\nbeen conjectured to be due to the excessive linearity of deep networks. In this\npaper, we study this phenomenon in the setting of a linear classifier, and show\nthat it is possible to exploit sparsity in natural data to combat\n$\\ell_{\\infty}$-bounded adversarial perturbations. Specifically, we demonstrate\nthe efficacy of a sparsifying front end via an ensemble averaged analysis, and\nexperimental results for the MNIST handwritten digit database. To the best of\nour knowledge, this is the first work to show that sparsity provides a\ntheoretically rigorous framework for defense against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 08:18:33 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 23:21:58 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 07:16:51 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Marzi", "Zhinus", ""], ["Gopalakrishnan", "Soorya", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1801.04701", "submitter": "Ao Zhang", "authors": "Ao Zhang, Nan Li, Jian Pu, Jun Wang, Junchi Yan, Hongyuan Zha", "title": "tau-FPL: Tolerance-Constrained Learning in Linear Time", "comments": "32 pages, 3 figures. This is an extended version of our paper\n  published in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a classifier with control on the false-positive rate plays a\ncritical role in many machine learning applications. Existing approaches either\nintroduce prior knowledge dependent label cost or tune parameters based on\ntraditional classifiers, which lack consistency in methodology because they do\nnot strictly adhere to the false-positive rate constraint. In this paper, we\npropose a novel scoring-thresholding approach, tau-False Positive Learning\n(tau-FPL) to address this problem. We show the scoring problem which takes the\nfalse-positive rate tolerance into accounts can be efficiently solved in linear\ntime, also an out-of-bootstrap thresholding method can transform the learned\nranking function into a low false-positive classifier. Both theoretical\nanalysis and experimental results show superior performance of the proposed\ntau-FPL over existing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 08:56:49 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Zhang", "Ao", ""], ["Li", "Nan", ""], ["Pu", "Jian", ""], ["Wang", "Jun", ""], ["Yan", "Junchi", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1801.04813", "submitter": "Quan Hoang", "authors": "Quan Hoang", "title": "Predicting Movie Genres Based on Plot Summaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project explores several Machine Learning methods to predict movie\ngenres based on plot summaries. Naive Bayes, Word2Vec+XGBoost and Recurrent\nNeural Networks are used for text classification, while K-binary\ntransformation, rank method and probabilistic classification with learned\nprobability threshold are employed for the multi-label problem involved in the\ngenre tagging task.Experiments with more than 250,000 movies show that\nemploying the Gated Recurrent Units (GRU) neural networks for the probabilistic\nclassification with learned probability threshold approach achieves the best\nresult on the test set. The model attains a Jaccard Index of 50.0%, a F-score\nof 0.56, and a hit rate of 80.5%.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 14:11:57 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Hoang", "Quan", ""]]}, {"id": "1801.04856", "submitter": "Hao Peng", "authors": "Hao Peng, Xiaoli Bai", "title": "Improving Orbit Prediction Accuracy through Supervised Machine Learning", "comments": "30 pages, 21 figures, 4 tables, Preprint submitted to Advances in\n  Space Research, on December 14, 2017", "journal-ref": null, "doi": "10.1016/j.asr.2018.03.001", "report-no": null, "categories": "astro-ph.EP cs.CE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to the lack of information such as the space environment condition and\nresident space objects' (RSOs') body characteristics, current orbit predictions\nthat are solely grounded on physics-based models may fail to achieve required\naccuracy for collision avoidance and have led to satellite collisions already.\nThis paper presents a methodology to predict RSOs' trajectories with higher\naccuracy than that of the current methods. Inspired by the machine learning\n(ML) theory through which the models are learned based on large amounts of\nobserved data and the prediction is conducted without explicitly modeling space\nobjects and space environment, the proposed ML approach integrates\nphysics-based orbit prediction algorithms with a learning-based process that\nfocuses on reducing the prediction errors. Using a simulation-based space\ncatalog environment as the test bed, the paper demonstrates three types of\ngeneralization capability for the proposed ML approach: 1) the ML model can be\nused to improve the same RSO's orbit information that is not available during\nthe learning process but shares the same time interval as the training data; 2)\nthe ML model can be used to improve predictions of the same RSO at future\nepochs; and 3) the ML model based on a RSO can be applied to other RSOs that\nshare some common features.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 15:56:36 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Peng", "Hao", ""], ["Bai", "Xiaoli", ""]]}, {"id": "1801.04883", "submitter": "Aidan N. Gomez", "authors": "Aidan N. Gomez, Sicong Huang, Ivan Zhang, Bryan M. Li, Muhammad Osama,\n  Lukasz Kaiser", "title": "Unsupervised Cipher Cracking Using Discrete GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work details CipherGAN, an architecture inspired by CycleGAN used for\ninferring the underlying cipher mapping given banks of unpaired ciphertext and\nplaintext. We demonstrate that CipherGAN is capable of cracking language data\nenciphered using shift and Vigenere ciphers to a high degree of fidelity and\nfor vocabularies much larger than previously achieved. We present how CycleGAN\ncan be made compatible with discrete data and train in a stable way. We then\nprove that the technique used in CipherGAN avoids the common problem of\nuninformative discrimination associated with GANs applied to discrete data.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 17:32:04 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Gomez", "Aidan N.", ""], ["Huang", "Sicong", ""], ["Zhang", "Ivan", ""], ["Li", "Bryan M.", ""], ["Osama", "Muhammad", ""], ["Kaiser", "Lukasz", ""]]}, {"id": "1801.04928", "submitter": "Yatin Saraiya", "authors": "Yatin Saraiya", "title": "Leapfrogging for parallelism in deep neural networks", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique, which we term leapfrogging, to parallelize back-\npropagation in deep neural networks. We show that this technique yields a\nsavings of $1-1/k$ of a dominant term in backpropagation, where k is the number\nof threads (or gpus).\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 00:51:29 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Saraiya", "Yatin", ""]]}, {"id": "1801.04929", "submitter": "Mario Michael Krell", "authors": "Mario Michael Krell", "title": "Generalizing, Decoding, and Optimizing Support Vector Machine\n  Classification", "comments": null, "journal-ref": "PhD Thesis, University of Bremen, Bremen, 1-236, 2015", "doi": null, "report-no": "urn:nbn:de:gbv:46-00104380-12", "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classification of complex data usually requires the composition of\nprocessing steps. Here, a major challenge is the selection of optimal\nalgorithms for preprocessing and classification (including parameterizations).\nNowadays, parts of the optimization process are automized but expert knowledge\nand manual work are still required. We present three steps to face this process\nand ease the optimization. Namely, we take a theoretical view on classical\nclassifiers, provide an approach to interpret the classifier together with the\npreprocessing, and integrate both into one framework which enables a\nsemiautomatic optimization of the processing chain and which interfaces\nnumerous algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 16:49:52 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Krell", "Mario Michael", ""]]}, {"id": "1801.04958", "submitter": "Robert Giaquinto", "authors": "Robert Giaquinto and Arindam Banerjee", "title": "Topic Modeling on Health Journals with Regularized Variational Inference", "comments": "Published in Thirty-Second AAAI Conference on Artificial\n  Intelligence, February 2018, New Orleans, Louisiana, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling enables exploration and compact representation of a corpus.\nThe CaringBridge (CB) dataset is a massive collection of journals written by\npatients and caregivers during a health crisis. Topic modeling on the CB\ndataset, however, is challenging due to the asynchronous nature of multiple\nauthors writing about their health journeys. To overcome this challenge we\nintroduce the Dynamic Author-Persona topic model (DAP), a probabilistic\ngraphical model designed for temporal corpora with multiple authors. The\nnovelty of the DAP model lies in its representation of authors by a persona ---\nwhere personas capture the propensity to write about certain topics over time.\nFurther, we present a regularized variational inference algorithm, which we use\nto encourage the DAP model's personas to be distinct. Our results show\nsignificant improvements over competing topic models --- particularly after\nregularization, and highlight the DAP model's unique ability to capture common\njourneys shared by different authors.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 19:23:21 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Giaquinto", "Robert", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1801.04987", "submitter": "Jos\\'e Bento", "authors": "Jose Bento, Ralph Furmaniak, Surjyendu Ray", "title": "On the Complexity of the Weighted Fused Lasso", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2018.2867800", "report-no": null, "categories": "cs.LG cs.CC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The solution path of the 1D fused lasso for an $n$-dimensional input is\npiecewise linear with $\\mathcal{O}(n)$ segments (Hoefling et al. 2010 and\nTibshirani et al 2011). However, existing proofs of this bound do not hold for\nthe weighted fused lasso. At the same time, results for the generalized lasso,\nof which the weighted fused lasso is a special case, allow $\\Omega(3^n)$\nsegments (Mairal et al. 2012). In this paper, we prove that the number of\nsegments in the solution path of the weighted fused lasso is\n$\\mathcal{O}(n^2)$, and that, for some instances, it is $\\Omega(n^2)$. We also\ngive a new, very simple, proof of the $\\mathcal{O}(n)$ bound for the fused\nlasso.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 20:20:53 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 16:03:24 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 20:02:47 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Bento", "Jose", ""], ["Furmaniak", "Ralph", ""], ["Ray", "Surjyendu", ""]]}, {"id": "1801.05038", "submitter": "R\\'emi Cura", "authors": "Remi Cura, Julien Perret, Nicolas Paparoditis", "title": "An octree cells occupancy geometric dimensionality descriptor for\n  massive on-server point cloud visualisation and classification", "comments": "extracted from article arXiv:1602.06920 ( arXiv:1602.06920 was split\n  into 2 articles because it was to long and to hard to read)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lidar datasets are becoming more and more common. They are appreciated for\ntheir precise 3D nature, and have a wide range of applications, such as surface\nreconstruction, object detection, visualisation, etc. For all this\napplications, having additional semantic information per point has potential of\nincreasing the quality and the efficiency of the application. In the last\ndecade the use of Machine Learning and more specifically classification methods\nhave proved to be successful to create this semantic information. In this\nparadigm, the goal is to classify points into a set of given classes (for\ninstance tree, building, ground, other). Some of these methods use descriptors\n(also called feature) of a point to learn and predict its class. Designing the\ndescriptors is then the heart of these methods. Descriptors can be based on\npoints geometry and attributes, use contextual information, etc. Furthermore,\ndescriptors can be used by humans for easier visual understanding and sometimes\nfiltering. In this work we propose a new simple geometric descriptor that gives\ninformation about the implicit local dimensionality of the point cloud at\nvarious scale. For instance a tree seen from afar is more volumetric in nature\n(3D), yet locally each leaves is rather planar (2D). To do so we build an\noctree centred on the point to consider, and compare the variation of the\noccupancy of the cells across the levels of the octree. We compare this\ndescriptor with the state of the art dimensionality descriptor and show its\ninterest. We further test the descriptor for classification within the Point\nCloud Server, and demonstrate efficiency and correctness results.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 21:40:24 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Cura", "Remi", ""], ["Perret", "Julien", ""], ["Paparoditis", "Nicolas", ""]]}, {"id": "1801.05039", "submitter": "Rong Ge", "authors": "Maryam Fazel, Rong Ge, Sham M. Kakade, Mehran Mesbahi", "title": "Global Convergence of Policy Gradient Methods for the Linear Quadratic\n  Regulator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct policy gradient methods for reinforcement learning and continuous\ncontrol problems are a popular approach for a variety of reasons: 1) they are\neasy to implement without explicit knowledge of the underlying model 2) they\nare an \"end-to-end\" approach, directly optimizing the performance metric of\ninterest 3) they inherently allow for richly parameterized policies. A notable\ndrawback is that even in the most basic continuous control problem (that of\nlinear quadratic regulators), these methods must solve a non-convex\noptimization problem, where little is understood about their efficiency from\nboth computational and statistical perspectives. In contrast, system\nidentification and model based planning in optimal control theory have a much\nmore solid theoretical footing, where much is known with regards to their\ncomputational and statistical properties. This work bridges this gap showing\nthat (model free) policy gradient methods globally converge to the optimal\nsolution and are efficient (polynomially so in relevant problem dependent\nquantities) with regards to their sample and computational complexities.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 21:40:50 GMT"}, {"version": "v2", "created": "Sun, 21 Oct 2018 13:15:27 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2019 20:29:16 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Fazel", "Maryam", ""], ["Ge", "Rong", ""], ["Kakade", "Sham M.", ""], ["Mesbahi", "Mehran", ""]]}, {"id": "1801.05062", "submitter": "Xinyuan Zhang", "authors": "Xinyuan Zhang, Ricardo Henao, Zhe Gan, Yitong Li, Lawrence Carin", "title": "Multi-Label Learning from Medical Plain Text with Convolutional Residual\n  Models", "comments": "Machine Learning for Healthcare 2018 spotlight paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting diagnoses from Electronic Health Records (EHRs) is an important\nmedical application of multi-label learning. We propose a convolutional\nresidual model for multi-label classification from doctor notes in EHR data. A\ngiven patient may have multiple diagnoses, and therefore multi-label learning\nis required. We employ a Convolutional Neural Network (CNN) to encode plain\ntext into a fixed-length sentence embedding vector. Since diagnoses are\ntypically correlated, a deep residual network is employed on top of the CNN\nencoder, to capture label (diagnosis) dependencies and incorporate information\ndirectly from the encoded sentence vector. A real EHR dataset is considered,\nand we compare the proposed model with several well-known baselines, to predict\ndiagnoses based on doctor notes. Experimental results demonstrate the\nsuperiority of the proposed convolutional residual model.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 22:59:17 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 19:36:06 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Zhang", "Xinyuan", ""], ["Henao", "Ricardo", ""], ["Gan", "Zhe", ""], ["Li", "Yitong", ""], ["Carin", "Lawrence", ""]]}, {"id": "1801.05134", "submitter": "Xiang Li", "authors": "Xiang Li, Shuo Chen, Xiaolin Hu, Jian Yang", "title": "Understanding the Disharmony between Dropout and Batch Normalization by\n  Variance Shift", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper first answers the question \"why do the two most powerful\ntechniques Dropout and Batch Normalization (BN) often lead to a worse\nperformance when they are combined together?\" in both theoretical and\nstatistical aspects. Theoretically, we find that Dropout would shift the\nvariance of a specific neural unit when we transfer the state of that network\nfrom train to test. However, BN would maintain its statistical variance, which\nis accumulated from the entire learning procedure, in the test phase. The\ninconsistency of that variance (we name this scheme as \"variance shift\") causes\nthe unstable numerical behavior in inference that leads to more erroneous\npredictions finally, when applying Dropout before BN. Thorough experiments on\nDenseNet, ResNet, ResNeXt and Wide ResNet confirm our findings. According to\nthe uncovered mechanism, we next explore several strategies that modifies\nDropout and try to overcome the limitations of their combination by avoiding\nthe variance shift risks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 06:47:59 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Li", "Xiang", ""], ["Chen", "Shuo", ""], ["Hu", "Xiaolin", ""], ["Yang", "Jian", ""]]}, {"id": "1801.05159", "submitter": "Kamil Bennani-Smires", "authors": "Kamil Bennani-Smires, Claudiu Musat, Andreea Hossmann, Michael\n  Baeriswyl", "title": "GitGraph - Architecture Search Space Creation through Frequent\n  Computational Subgraph Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dramatic success of deep neural networks across multiple application\nareas often relies on experts painstakingly designing a network architecture\nspecific to each task. To simplify this process and make it more accessible, an\nemerging research effort seeks to automate the design of neural network\narchitectures, using e.g. evolutionary algorithms or reinforcement learning or\nsimple search in a constrained space of neural modules.\n  Considering the typical size of the search space (e.g. $10^{10}$ candidates\nfor a $10$-layer network) and the cost of evaluating a single candidate,\ncurrent architecture search methods are very restricted. They either rely on\nstatic pre-built modules to be recombined for the task at hand, or they define\na static hand-crafted framework within which they can generate new\narchitectures from the simplest possible operations.\n  In this paper, we relax these restrictions, by capitalizing on the collective\nwisdom contained in the plethora of neural networks published in online code\nrepositories. Concretely, we (a) extract and publish GitGraph, a corpus of\nneural architectures and their descriptions; (b) we create problem-specific\nneural architecture search spaces, implemented as a textual search mechanism\nover GitGraph; (c) we propose a method of identifying unique common subgraphs\nwithin the architectures solving each problem (e.g., image processing,\nreinforcement learning), that can then serve as modules in the newly created\nproblem specific neural search space.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 08:54:20 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Bennani-Smires", "Kamil", ""], ["Musat", "Claudiu", ""], ["Hossmann", "Andreea", ""], ["Baeriswyl", "Michael", ""]]}, {"id": "1801.05236", "submitter": "Joshua Gardner", "authors": "Josh Gardner, Christopher Brooks, Juan Miguel L. Andres, Ryan Baker", "title": "MORF: A Framework for Predictive Modeling and Replication At Scale With\n  Privacy-Restricted MOOC Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data repositories from online learning platforms such as Massive Open\nOnline Courses (MOOCs) represent an unprecedented opportunity to advance\nresearch on education at scale and impact a global population of learners. To\ndate, such research has been hindered by poor reproducibility and a lack of\nreplication, largely due to three types of barriers: experimental, inferential,\nand data. We present a novel system for large-scale computational research, the\nMOOC Replication Framework (MORF), to jointly address these barriers. We\ndiscuss MORF's architecture, an open-source platform-as-a-service (PaaS) which\nincludes a simple, flexible software API providing for multiple modes of\nresearch (predictive modeling or production rule analysis) integrated with a\nhigh-performance computing environment. All experiments conducted on MORF use\nexecutable Docker containers which ensure complete reproducibility while\nallowing for the use of any software or language which can be installed in the\nlinux-based Docker container. Each experimental artifact is assigned a DOI and\nmade publicly available. MORF has the potential to accelerate and democratize\nresearch on its massive data repository, which currently includes over 200\nMOOCs, as demonstrated by initial research conducted on the platform. We also\nhighlight ways in which MORF represents a solution template to a more general\nclass of problems faced by computational researchers in other domains.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 13:06:12 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 13:10:38 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 22:16:21 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Gardner", "Josh", ""], ["Brooks", "Christopher", ""], ["Andres", "Juan Miguel L.", ""], ["Baker", "Ryan", ""]]}, {"id": "1801.05243", "submitter": "Marcella Astrid", "authors": "Marcella Astrid, Seung-Ik Lee, Beom-Su Seo", "title": "Rank Selection of CP-decomposed Convolutional Layers with Variational\n  Bayesian Matrix Factorization", "comments": "Accepted as a conference paper at ICACT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) is one of successful method in many\nareas such as image classification tasks. However, the amount of memory and\ncomputational cost needed for CNNs inference obstructs them to run efficiently\nin mobile devices because of memory and computational ability limitation. One\nof the method to compress CNNs is compressing the layers iteratively, i.e. by\nlayer-by-layer compression and fine-tuning, with CP-decomposition in\nconvolutional layers. To compress with CP-decomposition, rank selection is\nimportant. In the previous approach rank selection that is based on sensitivity\nof each layer, the average rank of the network was still arbitrarily selected.\nAdditionally, the rank of all layers were decided before whole process of\niterative compression, while the rank of a layer can be changed after\nfine-tuning. Therefore, this paper proposes selecting rank of each layer using\nVariational Bayesian Matrix Factorization (VBMF) which is more systematic than\narbitrary approach. Furthermore, to consider the change of each layer's rank\nafter fine-tuning of previous iteration, the method is applied just before\ncompressing the target layer, i.e. after fine-tuning of the previous iteration.\nThe results show better accuracy while also having more compression rate in\nAlexNet's convolutional layers compression.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 13:19:55 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Astrid", "Marcella", ""], ["Lee", "Seung-Ik", ""], ["Seo", "Beom-Su", ""]]}, {"id": "1801.05372", "submitter": "Thanh Lam Hoang", "authors": "Hoang Thanh Lam, Tran Ngoc Minh, Mathieu Sinn, Beat Buesser and Martin\n  Wistuba", "title": "Neural Feature Learning From Relational Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering is one of the most important but most tedious tasks in\ndata science. This work studies automation of feature learning from relational\ndatabase. We first prove theoretically that finding the optimal features from\nrelational data for predictive tasks is NP-hard. We propose an efficient\nrule-based approach based on heuristics and a deep neural network to\nautomatically learn appropriate features from relational data. We benchmark our\napproaches in ensembles in past Kaggle competitions. Our new approach wins late\nmedals and beats the state-of-the-art solutions with significant margins. To\nthe best of our knowledge, this is the first time an automated data science\nsystem could win medals in Kaggle competitions with complex relational\ndatabase.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 17:18:29 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 14:41:52 GMT"}, {"version": "v3", "created": "Sun, 17 Jun 2018 07:28:31 GMT"}, {"version": "v4", "created": "Sat, 15 Jun 2019 05:25:25 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lam", "Hoang Thanh", ""], ["Minh", "Tran Ngoc", ""], ["Sinn", "Mathieu", ""], ["Buesser", "Beat", ""], ["Wistuba", "Martin", ""]]}, {"id": "1801.05387", "submitter": "Mohammad Javad Shafiee", "authors": "Mohammad Javad Shafiee, Brendan Chwyl, Francis Li, Rongyan Chen,\n  Michelle Karg, Christian Scharfenberger, Alexander Wong", "title": "StressedNets: Efficient Feature Representations via Stress-induced\n  Evolutionary Synthesis of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of leveraging deep neural networks for\nextracting deep feature representations is a significant barrier to its\nwidespread adoption, particularly for use in embedded devices. One particularly\npromising strategy to addressing the complexity issue is the notion of\nevolutionary synthesis of deep neural networks, which was demonstrated to\nsuccessfully produce highly efficient deep neural networks while retaining\nmodeling performance. Here, we further extend upon the evolutionary synthesis\nstrategy for achieving efficient feature extraction via the introduction of a\nstress-induced evolutionary synthesis framework, where stress signals are\nimposed upon the synapses of a deep neural network during training to induce\nstress and steer the synthesis process towards the production of more efficient\ndeep neural networks over successive generations and improved model fidelity at\na greater efficiency. The proposed stress-induced evolutionary synthesis\napproach is evaluated on a variety of different deep neural network\narchitectures (LeNet5, AlexNet, and YOLOv2) on different tasks (object\nclassification and object detection) to synthesize efficient StressedNets over\nmultiple generations. Experimental results demonstrate the efficacy of the\nproposed framework to synthesize StressedNets with significant improvement in\nnetwork architecture efficiency (e.g., 40x for AlexNet and 33x for YOLOv2) and\nspeed improvements (e.g., 5.5x inference speed-up for YOLOv2 on an Nvidia Tegra\nX1 mobile processor).\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 17:47:13 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Chwyl", "Brendan", ""], ["Li", "Francis", ""], ["Chen", "Rongyan", ""], ["Karg", "Michelle", ""], ["Scharfenberger", "Christian", ""], ["Wong", "Alexander", ""]]}, {"id": "1801.05394", "submitter": "Wei-Han Lee", "authors": "Wei-Han Lee, Jorge Ortiz, Bongjun Ko, Ruby Lee", "title": "Time Series Segmentation through Automatic Feature Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of things (IoT) applications have become increasingly popular in\nrecent years, with applications ranging from building energy monitoring to\npersonal health tracking and activity recognition. In order to leverage these\ndata, automatic knowledge extraction - whereby we map from observations to\ninterpretable states and transitions - must be done at scale. As such, we have\nseen many recent IoT data sets include annotations with a human expert\nspecifying states, recorded as a set of boundaries and associated labels in a\ndata sequence. These data can be used to build automatic labeling algorithms\nthat produce labels as an expert would. Here, we refer to human-specified\nboundaries as breakpoints. Traditional changepoint detection methods only look\nfor statistically-detectable boundaries that are defined as abrupt variations\nin the generative parameters of a data sequence. However, we observe that\nbreakpoints occur on more subtle boundaries that are non-trivial to detect with\nthese statistical methods. In this work, we propose a new unsupervised\napproach, based on deep learning, that outperforms existing techniques and\nlearns the more subtle, breakpoint boundaries with a high accuracy. Through\nextensive experiments on various real-world data sets - including\nhuman-activity sensing data, speech signals, and electroencephalogram (EEG)\nactivity traces - we demonstrate the effectiveness of our algorithm for\npractical applications. Furthermore, we show that our approach achieves\nsignificantly better performance than previous methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 18:05:08 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 11:51:31 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Lee", "Wei-Han", ""], ["Ortiz", "Jorge", ""], ["Ko", "Bongjun", ""], ["Lee", "Ruby", ""]]}, {"id": "1801.05398", "submitter": "Hao Wang", "authors": "Hao Wang, Berk Ustun, Flavio P. Calmon", "title": "On the Direction of Discrimination: An Information-Theoretic Analysis of\n  Disparate Impact in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of machine learning, disparate impact refers to a form of\nsystematic discrimination whereby the output distribution of a model depends on\nthe value of a sensitive attribute (e.g., race or gender). In this paper, we\npropose an information-theoretic framework to analyze the disparate impact of a\nbinary classification model. We view the model as a fixed channel, and quantify\ndisparate impact as the divergence in output distributions over two groups. Our\naim is to find a correction function that can perturb the input distributions\nof each group to align their output distributions. We present an optimization\nproblem that can be solved to obtain a correction function that will make the\noutput distributions statistically indistinguishable. We derive closed-form\nexpressions to efficiently compute the correction function, and demonstrate the\nbenefits of our framework on a recidivism prediction problem based on the\nProPublica COMPAS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 18:26:56 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 00:19:56 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 17:57:11 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Wang", "Hao", ""], ["Ustun", "Berk", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "1801.05407", "submitter": "Neil Mallinar", "authors": "Neil Mallinar and Corbin Rosset", "title": "Deep Canonically Correlated LSTMs", "comments": "8 pages, 3 figures, accepted as the undergraduate honors thesis for\n  Neil Mallinar by The Johns Hopkins University", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine Deep Canonically Correlated LSTMs as a way to learn nonlinear\ntransformations of variable length sequences and embed them into a correlated,\nfixed dimensional space. We use LSTMs to transform multi-view time-series data\nnon-linearly while learning temporal relationships within the data. We then\nperform correlation analysis on the outputs of these neural networks to find a\ncorrelated subspace through which we get our final representation via\nprojection. This work follows from previous work done on Deep Canonical\nCorrelation (DCCA), in which deep feed-forward neural networks were used to\nlearn nonlinear transformations of data while maximizing correlation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 18:44:31 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Mallinar", "Neil", ""], ["Rosset", "Corbin", ""]]}, {"id": "1801.05411", "submitter": "Burak \\c{C}akmak", "authors": "Burak \\c{C}akmak and Manfred Opper", "title": "Expectation Propagation for Approximate Inference: Free Probability\n  Framework", "comments": "Both authors are co-first authors. The main body of this paper is\n  accepted for publication in the proceedings of the 2018 IEEE International\n  Symposium on Information Theory (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study asymptotic properties of expectation propagation (EP) -- a method\nfor approximate inference originally developed in the field of machine\nlearning. Applied to generalized linear models, EP iteratively computes a\nmultivariate Gaussian approximation to the exact posterior distribution. The\ncomputational complexity of the repeated update of covariance matrices severely\nlimits the application of EP to large problem sizes. In this study, we present\na rigorous analysis by means of free probability theory that allows us to\novercome this computational bottleneck if specific data matrices in the problem\nfulfill certain properties of asymptotic freeness. We demonstrate the relevance\nof our approach on the gene selection problem of a microarray dataset.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 18:49:14 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 23:51:02 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["\u00c7akmak", "Burak", ""], ["Opper", "Manfred", ""]]}, {"id": "1801.05413", "submitter": "Thomas M\\\"ollenhoff", "authors": "Thomas M\\\"ollenhoff, Zhenzhang Ye, Tao Wu, Daniel Cremers", "title": "Combinatorial Preconditioners for Proximal Algorithms on Graphs", "comments": "Published as a conference paper at AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel preconditioning technique for proximal optimization\nmethods that relies on graph algorithms to construct effective preconditioners.\nSuch combinatorial preconditioners arise from partitioning the graph into\nforests. We prove that certain decompositions lead to a theoretically optimal\ncondition number. We also show how ideal decompositions can be realized using\nmatroid partitioning and propose efficient greedy variants thereof for\nlarge-scale problems. Coupled with specialized solvers for the resulting scaled\nproximal subproblems, the preconditioned algorithm achieves competitive\nperformance in machine learning and vision applications.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 18:50:13 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 11:18:24 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["M\u00f6llenhoff", "Thomas", ""], ["Ye", "Zhenzhang", ""], ["Wu", "Tao", ""], ["Cremers", "Daniel", ""]]}, {"id": "1801.05420", "submitter": "Qinglong Wang", "authors": "Qinglong Wang, Kaixuan Zhang, Alexander G. Ororbia II, Xinyu Xing, Xue\n  Liu, C. Lee Giles", "title": "A Comparative Study of Rule Extraction for Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding recurrent networks through rule extraction has a long history.\nThis has taken on new interests due to the need for interpreting or verifying\nneural networks. One basic form for representing stateful rules is\ndeterministic finite automata (DFA). Previous research shows that extracting\nDFAs from trained second-order recurrent networks is not only possible but also\nrelatively stable. Recently, several new types of recurrent networks with more\ncomplicated architectures have been introduced. These handle challenging\nlearning tasks usually involving sequential data. However, it remains an open\nproblem whether DFAs can be adequately extracted from these models.\nSpecifically, it is not clear how DFA extraction will be affected when applied\nto different recurrent networks trained on data sets with different levels of\ncomplexity. Here, we investigate DFA extraction on several widely adopted\nrecurrent networks that are trained to learn a set of seven regular Tomita\ngrammars. We first formally analyze the complexity of Tomita grammars and\ncategorize these grammars according to that complexity. Then we empirically\nevaluate different recurrent networks for their performance of DFA extraction\non all Tomita grammars. Our experiments show that for most recurrent networks,\ntheir extraction performance decreases as the complexity of the underlying\ngrammar increases. On grammars of lower complexity, most recurrent networks\nobtain desirable extraction performance. As for grammars with the highest level\nof complexity, while several complicated models fail with only certain\nrecurrent networks having satisfactory extraction performance.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 03:19:37 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 19:34:54 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Wang", "Qinglong", ""], ["Zhang", "Kaixuan", ""], ["Ororbia", "Alexander G.", "II"], ["Xing", "Xinyu", ""], ["Liu", "Xue", ""], ["Giles", "C. Lee", ""]]}, {"id": "1801.05453", "submitter": "William Murdoch", "authors": "W. James Murdoch, Peter J. Liu, Bin Yu", "title": "Beyond Word Importance: Contextual Decomposition to Extract Interactions\n  from LSTMs", "comments": "Oral presentation at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The driving force behind the recent success of LSTMs has been their ability\nto learn complex and non-linear relationships. Consequently, our inability to\ndescribe these relationships has led to LSTMs being characterized as black\nboxes. To this end, we introduce contextual decomposition (CD), an\ninterpretation algorithm for analysing individual predictions made by standard\nLSTMs, without any changes to the underlying model. By decomposing the output\nof a LSTM, CD captures the contributions of combinations of words or variables\nto the final prediction of an LSTM. On the task of sentiment analysis with the\nYelp and SST data sets, we show that CD is able to reliably identify words and\nphrases of contrasting sentiment, and how they are combined to yield the LSTM's\nfinal prediction. Using the phrase-level labels in SST, we also demonstrate\nthat CD is able to successfully extract positive and negative negations from an\nLSTM, something which has not previously been done.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 19:21:48 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 22:25:53 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Murdoch", "W. James", ""], ["Liu", "Peter J.", ""], ["Yu", "Bin", ""]]}, {"id": "1801.05457", "submitter": "J. G. Wolff", "authors": "J Gerard Wolff", "title": "Solutions to problems with deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the several successes of deep learning systems, there are concerns\nabout their limitations, discussed most recently by Gary Marcus. This paper\ndiscusses Marcus's concerns and some others, together with solutions to several\nof these problems provided by the \"P theory of intelligence\" and its\nrealisation in the \"SP computer model\". The main advantages of the SP system\nare: relatively small requirements for data and the ability to learn from a\nsingle experience; the ability to model both hierarchical and non-hierarchical\nstructures; strengths in several kinds of reasoning, including `commonsense'\nreasoning; transparency in the representation of knowledge, and the provision\nof an audit trail for all processing; the likelihood that the SP system could\nnot be fooled into bizarre or eccentric recognition of stimuli, as deep\nlearning systems can be; the SP system provides a robust solution to the\nproblem of `catastrophic forgetting' in deep learning systems; the SP system\nprovides a theoretically-coherent solution to the problems of correcting over-\nand under-generalisations in learning, and learning correct structures despite\nerrors in data; unlike most research on deep learning, the SP programme of\nresearch draws extensively on research on human learning, perception, and\ncognition; and the SP programme of research has an overarching theory,\nsupported by evidence, something that is largely missing from research on deep\nlearning. In general, the SP system provides a much firmer foundation than deep\nlearning for the development of artificial general intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 20:37:07 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Wolff", "J Gerard", ""]]}, {"id": "1801.05463", "submitter": "Yonggyun Yu", "authors": "Yonggyun Yu, Taeil Hur, Jaeho Jung and In Gwun Jang", "title": "Deep learning for determining a near-optimal topological design without\n  any iteration", "comments": "27 page, 11 figures, The paper is accepted in the Structural and\n  Multidisciplinary Optimization journal, Springer", "journal-ref": null, "doi": "10.1007/s00158-018-2101-5", "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a novel deep learning-based method to predict an\noptimized structure for a given boundary condition and optimization setting\nwithout using any iterative scheme. For this purpose, first, using open-source\ntopology optimization code, datasets of the optimized structures paired with\nthe corresponding information on boundary conditions and optimization settings\nare generated at low (32 x 32) and high (128 x 128) resolutions. To construct\nthe artificial neural network for the proposed method, a convolutional neural\nnetwork (CNN)-based encoder and decoder network is trained using the training\ndataset generated at low resolution. Then, as a two-stage refinement, the\nconditional generative adversarial network (cGAN) is trained with the optimized\nstructures paired at both low and high resolutions, and is connected to the\ntrained CNN-based encoder and decoder network. The performance evaluation\nresults of the integrated network demonstrate that the proposed method can\ndetermine a near-optimal structure in terms of pixel values and compliance with\nnegligible computational time.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 17:10:35 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 08:53:55 GMT"}, {"version": "v3", "created": "Sat, 22 Sep 2018 07:50:36 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Yu", "Yonggyun", ""], ["Hur", "Taeil", ""], ["Jung", "Jaeho", ""], ["Jang", "In Gwun", ""]]}, {"id": "1801.05504", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore and John Robinson", "title": "Automatic Classification of Music Genre using Masked Conditional Neural\n  Networks", "comments": "Restricted Boltzmann Machine; RBM; Conditional RBM; CRBM; Deep Belief\n  Net; DBN; Conditional Neural Network; CLNN; Masked Conditional Neural\n  Network; MCLNN; Music Information Retrieval; MIR. IEEE International\n  Conference on Data Mining (ICDM), 2017", "journal-ref": "IEEE International Conference on Data Mining (ICDM) Year: 2017\n  Pages: 979 - 984", "doi": "10.1109/ICDM.2017.125", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based architectures used for sound recognition are usually\nadapted from other application domains such as image recognition, which may not\nharness the time-frequency representation of a signal. The ConditionaL Neural\nNetworks (CLNN) and its extension the Masked ConditionaL Neural Networks\n(MCLNN) are designed for multidimensional temporal signal recognition. The CLNN\nis trained over a window of frames to preserve the inter-frame relation, and\nthe MCLNN enforces a systematic sparseness over the network's links that mimics\na filterbank-like behavior. The masking operation induces the network to learn\nin frequency bands, which decreases the network susceptibility to\nfrequency-shifts in time-frequency representations. Additionally, the mask\nallows an exploration of a range of feature combinations concurrently analogous\nto the manual handcrafting of the optimum collection of features for a\nrecognition task. MCLNN have achieved competitive performance on the Ballroom\nmusic dataset compared to several hand-crafted attempts and outperformed models\nbased on state-of-the-art Convolutional Neural Networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 23:43:34 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2019 09:00:47 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1801.05512", "submitter": "Stephane Fotso", "authors": "Stephane Fotso", "title": "Deep Neural Networks for Survival Analysis Based on a Multi-Task\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival analysis/time-to-event models are extremely useful as they can help\ncompanies predict when a customer will buy a product, churn or default on a\nloan, and therefore help them improve their ROI. In this paper, we introduce a\nnew method to calculate survival functions using the Multi-Task Logistic\nRegression (MTLR) model as its base and a deep learning architecture as its\ncore. Based on the Concordance index (C-index) and Brier score, this method\noutperforms the MTLR in all the experiments disclosed in this paper as well as\nthe Cox Proportional Hazard (CoxPH) model when nonlinear dependencies are\nfound.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 00:53:35 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Fotso", "Stephane", ""]]}, {"id": "1801.05535", "submitter": "Zhiyun Ren", "authors": "Zhiyun Ren, Xia Ning, Huzefa Rangwala", "title": "ALE: Additive Latent Effect Models for Grade Prediction", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The past decade has seen a growth in the development and deployment of\neducational technologies for assisting college-going students in choosing\nmajors, selecting courses and acquiring feedback based on past academic\nperformance. Grade prediction methods seek to estimate a grade that a student\nmay achieve in a course that she may take in the future (e.g., next term).\nAccurate and timely prediction of students' academic grades is important for\ndeveloping effective degree planners and early warning systems, and ultimately\nimproving educational outcomes. Existing grade pre- diction methods mostly\nfocus on modeling the knowledge components associated with each course and\nstudent, and often overlook other factors such as the difficulty of each\nknowledge component, course instructors, student interest, capabilities and\neffort. In this paper, we propose additive latent effect models that\nincorporate these factors to predict the student next-term grades.\nSpecifically, the proposed models take into account four factors: (i) student's\nacademic level, (ii) course instructors, (iii) student global latent factor,\nand (iv) latent knowledge factors. We compared the new models with several\nstate-of-the-art methods on students of various characteristics (e.g., whether\na student transferred in or not). The experimental results demonstrate that the\nproposed methods significantly outperform the baselines on grade prediction\nproblem. Moreover, we perform a thorough analysis on the importance of\ndifferent factors and how these factors can practically assist students in\ncourse selection, and finally improve their academic performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 03:10:27 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Ren", "Zhiyun", ""], ["Ning", "Xia", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1801.05558", "submitter": "Yoonho Lee", "authors": "Yoonho Lee and Seungjin Choi", "title": "Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace", "comments": "Accepted to ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learning methods leverage gradient descent to learn the\ncommonalities among various tasks. While previous such methods have been\nsuccessful in meta-learning tasks, they resort to simple gradient descent\nduring meta-testing. Our primary contribution is the {\\em MT-net}, which\nenables the meta-learner to learn on each layer's activation space a subspace\nthat the task-specific learner performs gradient descent on. Additionally, a\ntask-specific learner of an {\\em MT-net} performs gradient descent with respect\nto a meta-learned distance metric, which warps the activation space to be more\nsensitive to task identity. We demonstrate that the dimension of this learned\nsubspace reflects the complexity of the task-specific learner's adaptation\ntask, and also that our model is less sensitive to the choice of initial\nlearning rates than previous gradient-based meta-learning methods. Our method\nachieves state-of-the-art or comparable performance on few-shot classification\nand regression tasks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 05:34:08 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 07:40:00 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 12:33:23 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Lee", "Yoonho", ""], ["Choi", "Seungjin", ""]]}, {"id": "1801.05566", "submitter": "Jiaming Song", "authors": "Jiaming Song and Yuhuai Wu", "title": "An Empirical Analysis of Proximal Policy Optimization with\n  Kronecker-factored Natural Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we consider an approach that combines the PPO\nobjective and K-FAC natural gradient optimization, for which we call PPOKFAC.\nWe perform a range of empirical analysis on various aspects of the algorithm,\nsuch as sample complexity, training speed, and sensitivity to batch size and\ntraining epochs. We observe that PPOKFAC is able to outperform PPO in terms of\nsample complexity and speed in a range of MuJoCo environments, while being\nscalable in terms of batch size. In spite of this, it seems that adding more\nepochs is not necessarily helpful for sample efficiency, and PPOKFAC seems to\nbe worse than its A2C counterpart, ACKTR.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 06:09:09 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Song", "Jiaming", ""], ["Wu", "Yuhuai", ""]]}, {"id": "1801.05574", "submitter": "Ying Lu", "authors": "Ying Lu, Liming Chen, Alexandre Saidi, Xianfeng Gu", "title": "Brenier approach for optimal transportation between a quasi-discrete\n  measure and a discrete measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly estimating the discrepancy between two data distributions has\nalways been an important task in Machine Learning. Recently, Cuturi proposed\nthe Sinkhorn distance which makes use of an approximate Optimal Transport cost\nbetween two distributions as a distance to describe distribution discrepancy.\nAlthough it has been successfully adopted in various machine learning\napplications (e.g. in Natural Language Processing and Computer Vision) since\nthen, the Sinkhorn distance also suffers from two unnegligible limitations. The\nfirst one is that the Sinkhorn distance only gives an approximation of the real\nWasserstein distance, the second one is the `divide by zero' problem which\noften occurs during matrix scaling when setting the entropy regularization\ncoefficient to a small value. In this paper, we introduce a new Brenier\napproach for calculating a more accurate Wasserstein distance between two\ndiscrete distributions, this approach successfully avoids the two limitations\nshown above for Sinkhorn distance and gives an alternative way for estimating\ndistribution discrepancy.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 07:06:21 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Lu", "Ying", ""], ["Chen", "Liming", ""], ["Saidi", "Alexandre", ""], ["Gu", "Xianfeng", ""]]}, {"id": "1801.05609", "submitter": "Lei Shu", "authors": "Lei Shu, Hu Xu, Bing Liu", "title": "Unseen Class Discovery in Open-world Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns open-world classification, where the classifier not only\nneeds to classify test examples into seen classes that have appeared in\ntraining but also reject examples from unseen or novel classes that have not\nappeared in training. Specifically, this paper focuses on discovering the\nhidden unseen classes of the rejected examples. Clearly, without prior\nknowledge this is difficult. However, we do have the data from the seen\ntraining classes, which can tell us what kind of similarity/difference is\nexpected for examples from the same class or from different classes. It is\nreasonable to assume that this knowledge can be transferred to the rejected\nexamples and used to discover the hidden unseen classes in them. This paper\naims to solve this problem. It first proposes a joint open classification model\nwith a sub-model for classifying whether a pair of examples belongs to the same\nor different classes. This sub-model can serve as a distance function for\nclustering to discover the hidden classes of the rejected examples.\nExperimental results show that the proposed model is highly promising.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 09:50:41 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Shu", "Lei", ""], ["Xu", "Hu", ""], ["Liu", "Bing", ""]]}, {"id": "1801.05627", "submitter": "Patrick Glauner", "authors": "Patrick Glauner, Radu State, Petko Valtchev, Diogo Duarte", "title": "On the Reduction of Biases in Big Data Sets for the Detection of\n  Irregular Power Usage", "comments": null, "journal-ref": "Proceedings of the 13th International FLINS Conference on Data\n  Science and Knowledge Engineering for Sensing Decision Support (FLINS 2018)", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, a bias occurs whenever training sets are not\nrepresentative for the test data, which results in unreliable models. The most\ncommon biases in data are arguably class imbalance and covariate shift. In this\nwork, we aim to shed light on this topic in order to increase the overall\nattention to this issue in the field of machine learning. We propose a scalable\nnovel framework for reducing multiple biases in high-dimensional data sets in\norder to train more reliable predictors. We apply our methodology to the\ndetection of irregular power usage from real, noisy industrial data. In\nemerging markets, irregular power usage, and electricity theft in particular,\nmay range up to 40% of the total electricity distributed. Biased data sets are\nof particular issue in this domain. We show that reducing these biases\nincreases the accuracy of the trained predictors. Our models have the potential\nto generate significant economic value in a real world application, as they are\nbeing deployed in a commercial software for the detection of irregular power\nusage.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 11:48:18 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 09:06:42 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Glauner", "Patrick", ""], ["State", "Radu", ""], ["Valtchev", "Petko", ""], ["Duarte", "Diogo", ""]]}, {"id": "1801.05731", "submitter": "Roberto Bifulco", "authors": "Giuseppe Siracusano, Roberto Bifulco", "title": "In-network Neural Networks", "comments": "Accepted at SysML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present N2Net, a system that implements binary neural networks using\ncommodity switching chips deployed in network switches and routers. Our system\nshows that these devices can run simple neural network models, whose input is\nencoded in the network packets' header, at packet processing speeds (billions\nof packets per second). Furthermore, our experience highlights that switching\nchips could support even more complex models, provided that some minor and\ncheap modifications to the chip's design are applied. We believe N2Net provides\nan interesting building block for future end-to-end networked systems.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 16:17:28 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Siracusano", "Giuseppe", ""], ["Bifulco", "Roberto", ""]]}, {"id": "1801.05757", "submitter": "Zhiyuan Xu", "authors": "Zhiyuan Xu, Jian Tang, Jingsong Meng, Weiyi Zhang, Yanzhi Wang, Chi\n  Harold Liu and Dejun Yang", "title": "Experience-driven Networking: A Deep Reinforcement Learning based\n  Approach", "comments": "9 pages, 12 figures, paper is accepted as a conference paper at IEEE\n  Infocom 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern communication networks have become very complicated and highly\ndynamic, which makes them hard to model, predict and control. In this paper, we\ndevelop a novel experience-driven approach that can learn to well control a\ncommunication network from its own experience rather than an accurate\nmathematical model, just as a human learns a new skill (such as driving,\nswimming, etc). Specifically, we, for the first time, propose to leverage\nemerging Deep Reinforcement Learning (DRL) for enabling model-free control in\ncommunication networks; and present a novel and highly effective DRL-based\ncontrol framework, DRL-TE, for a fundamental networking problem: Traffic\nEngineering (TE). The proposed framework maximizes a widely-used utility\nfunction by jointly learning network environment and its dynamics, and making\ndecisions under the guidance of powerful Deep Neural Networks (DNNs). We\npropose two new techniques, TE-aware exploration and actor-critic-based\nprioritized experience replay, to optimize the general DRL framework\nparticularly for TE. To validate and evaluate the proposed framework, we\nimplemented it in ns-3, and tested it comprehensively with both representative\nand randomly generated network topologies. Extensive packet-level simulation\nresults show that 1) compared to several widely-used baseline methods, DRL-TE\nsignificantly reduces end-to-end delay and consistently improves the network\nutility, while offering better or comparable throughput; 2) DRL-TE is robust to\nnetwork changes; and 3) DRL-TE consistently outperforms a state-ofthe-art DRL\nmethod (for continuous control), Deep Deterministic Policy Gradient (DDPG),\nwhich, however, does not offer satisfying performance.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 17:09:01 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Xu", "Zhiyuan", ""], ["Tang", "Jian", ""], ["Meng", "Jingsong", ""], ["Zhang", "Weiyi", ""], ["Wang", "Yanzhi", ""], ["Liu", "Chi Harold", ""], ["Yang", "Dejun", ""]]}, {"id": "1801.05852", "submitter": "Daokun Zhang", "authors": "Daokun Zhang, Jie Yin, Xingquan Zhu and Chengqi Zhang", "title": "Network Representation Learning: A Survey", "comments": "Accepted by IEEE transactions on Big Data; 25 pages, 10 tables, 6\n  figures and 127 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the widespread use of information technologies, information networks are\nbecoming increasingly popular to capture complex relationships across various\ndisciplines, such as social networks, citation networks, telecommunication\nnetworks, and biological networks. Analyzing these networks sheds light on\ndifferent aspects of social life such as the structure of societies,\ninformation diffusion, and communication patterns. In reality, however, the\nlarge scale of information networks often makes network analytic tasks\ncomputationally expensive or intractable. Network representation learning has\nbeen recently proposed as a new learning paradigm to embed network vertices\ninto a low-dimensional vector space, by preserving network topology structure,\nvertex content, and other side information. This facilitates the original\nnetwork to be easily handled in the new vector space for further analysis. In\nthis survey, we perform a comprehensive review of the current literature on\nnetwork representation learning in the data mining and machine learning field.\nWe propose new taxonomies to categorize and summarize the state-of-the-art\nnetwork representation learning techniques according to the underlying learning\nmechanisms, the network information intended to preserve, as well as the\nalgorithmic designs and methodologies. We summarize evaluation protocols used\nfor validating network representation learning including published benchmark\ndatasets, evaluation methods, and open source algorithms. We also perform\nempirical studies to compare the performance of representative algorithms on\ncommon datasets, and analyze their computational complexity. Finally, we\nsuggest promising research directions to facilitate future study.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 03:28:54 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 05:16:49 GMT"}, {"version": "v3", "created": "Thu, 19 Jul 2018 09:11:08 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Zhang", "Daokun", ""], ["Yin", "Jie", ""], ["Zhu", "Xingquan", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1801.05856", "submitter": "Dan Kushnir", "authors": "Dan Kushnir, Benjamin Mirabelli", "title": "Active Community Detection with Maximal Expected Model Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel active learning algorithm for community detection on\nnetworks. Our proposed algorithm uses a Maximal Expected Model Change (MEMC)\ncriterion for querying network nodes label assignments. MEMC detects nodes that\nmaximally change the community assignment likelihood model following a query.\nOur method is inspired by detection in the benchmark Stochastic Block Model\n(SBM), where we provide sample complexity analysis and empirical study with SBM\nand real network data for binary as well as for the multi-class settings. The\nanalysis also covers the most challenging case of sparse degree and\nbelow-detection-threshold SBMs, where we observe a super-linear error\nreduction. MEMC is shown to be superior to the random selection baseline and\nother state-of-the-art active learners.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 03:26:16 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 19:39:14 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Kushnir", "Dan", ""], ["Mirabelli", "Benjamin", ""]]}, {"id": "1801.05894", "submitter": "Desmond Higham J", "authors": "Catherine F. Higham and Desmond J. Higham", "title": "Deep Learning: An Introduction for Applied Mathematicians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayered artificial neural networks are becoming a pervasive tool in a\nhost of application fields. At the heart of this deep learning revolution are\nfamiliar concepts from applied and computational mathematics; notably, in\ncalculus, approximation theory, optimization and linear algebra. This article\nprovides a very brief introduction to the basic ideas that underlie deep\nlearning from an applied mathematics perspective. Our target audience includes\npostgraduate and final year undergraduate students in mathematics who are keen\nto learn about the area. The article may also be useful for instructors in\nmathematics who wish to enliven their classes with references to the\napplication of deep learning techniques. We focus on three fundamental\nquestions: what is a deep neural network? how is a network trained? what is the\nstochastic gradient method? We illustrate the ideas with a short MATLAB code\nthat sets up and trains a network. We also show the use of state-of-the art\nsoftware on a large scale image classification problem. We finish with\nreferences to the current literature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 16:05:25 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Higham", "Catherine F.", ""], ["Higham", "Desmond J.", ""]]}, {"id": "1801.05927", "submitter": "Xiaojin Zhu", "authors": "Xiaojin Zhu, Adish Singla, Sandra Zilles, Anna N. Rafferty", "title": "An Overview of Machine Teaching", "comments": "A tutorial document grown out of NIPS 2017 Workshop on Teaching\n  Machines, Robots, and Humans", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we try to organize machine teaching as a coherent set of ideas.\nEach idea is presented as varying along a dimension. The collection of\ndimensions then form the problem space of machine teaching, such that existing\nteaching problems can be characterized in this space. We hope this organization\nallows us to gain deeper understanding of individual teaching problems,\ndiscover connections among them, and identify gaps in the field.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 03:53:56 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Zhu", "Xiaojin", ""], ["Singla", "Adish", ""], ["Zilles", "Sandra", ""], ["Rafferty", "Anna N.", ""]]}, {"id": "1801.05931", "submitter": "Vinod Kumar Chauhan", "authors": "Vinod Kumar Chauhan, Anuj Sharma and Kalpana Dahiya", "title": "Faster Learning by Reduction of Data Access Time", "comments": "80 figures, final journal version", "journal-ref": "Applied Intelligence, Springer, 2018", "doi": "10.1007/s10489-018-1235-x", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the major challenge in machine learning is the Big Data challenge.\nThe big data problems due to large number of data points or large number of\nfeatures in each data point, or both, the training of models have become very\nslow. The training time has two major components: Time to access the data and\ntime to process (learn from) the data. So far, the research has focused only on\nthe second part, i.e., learning from the data. In this paper, we have proposed\none possible solution to handle the big data problems in machine learning. The\nidea is to reduce the training time through reducing data access time by\nproposing systematic sampling and cyclic/sequential sampling to select\nmini-batches from the dataset. To prove the effectiveness of proposed sampling\ntechniques, we have used Empirical Risk Minimization, which is commonly used\nmachine learning problem, for strongly convex and smooth case. The problem has\nbeen solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each\nusing two step determination techniques, namely, constant step size and\nbacktracking line search method. Theoretical results prove the same convergence\nfor systematic sampling, cyclic sampling and the widely used random sampling\ntechnique, in expectation. Experimental results with bench marked datasets\nprove the efficacy of the proposed sampling techniques and show up to six times\nfaster training.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 04:31:40 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 09:18:20 GMT"}, {"version": "v3", "created": "Fri, 22 Jun 2018 07:38:28 GMT"}, {"version": "v4", "created": "Wed, 25 Jul 2018 04:27:05 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Chauhan", "Vinod Kumar", ""], ["Sharma", "Anuj", ""], ["Dahiya", "Kalpana", ""]]}, {"id": "1801.05984", "submitter": "Ferdi Kara", "authors": "Ferdi Kara, Hakan Kaya, Okan Erkaymaz, Ertan Ozturk", "title": "Prediction of the Optimal Threshold Value in DF Relay Selection Schemes\n  Based on Artificial Neural Networks", "comments": "6 pages,IEEE INnovations in Intelligent SysTems and Applications\n  (INISTA), 2016 International Symposium on", "journal-ref": null, "doi": "10.1109/INISTA.2016.7571823", "report-no": null, "categories": "eess.SP cs.LG cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless communications, the cooperative communication (CC) technology\npromises performance gains compared to traditional Single-Input Single Output\n(SISO) techniques. Therefore, the CC technique is one of the nominees for 5G\nnetworks. In the Decode-and-Forward (DF) relaying scheme which is one of the CC\ntechniques, determination of the threshold value at the relay has a key role\nfor the system performance and power usage. In this paper, we propose\nprediction of the optimal threshold values for the best relay selection scheme\nin cooperative communications, based on Artificial Neural Networks (ANNs) for\nthe first time in literature. The average link qualities and number of relays\nhave been used as inputs in the prediction of optimal threshold values using\nArtificial Neural Networks (ANNs): Multi-Layer Perceptron (MLP) and Radial\nBasis Function (RBF) networks. The MLP network has better performance from the\nRBF network on the prediction of optimal threshold value when the same number\nof neurons is used at the hidden layer for both networks. Besides, the optimal\nthreshold values obtained using ANNs are verified by the optimal threshold\nvalues obtained numerically using the closed form expression derived for the\nsystem. The results show that the optimal threshold values obtained by ANNs on\nthe best relay selection scheme provide a minimum Bit-Error-Rate (BER) because\nof the reduction of the probability that error propagation may occur. Also, for\nthe same BER performance goal, prediction of optimal threshold values provides\n2dB less power usage, which is great gain in terms of green communicationBER\nperformance goal, prediction of optimal threshold values provides 2dB less\npower usage, which is great gain in terms of green communication.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 12:36:38 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Kara", "Ferdi", ""], ["Kaya", "Hakan", ""], ["Erkaymaz", "Okan", ""], ["Ozturk", "Ertan", ""]]}, {"id": "1801.06024", "submitter": "Gino Brunner", "authors": "Gino Brunner, Yuyi Wang, Roger Wattenhofer, Michael Weigelt", "title": "Natural Language Multitasking: Analyzing and Improving Syntactic\n  Saliency of Hidden Representations", "comments": "The 31st Annual Conference on Neural Information Processing (NIPS) -\n  Workshop on Learning Disentangled Features: from Perception to Control, Long\n  Beach, CA, December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train multi-task autoencoders on linguistic tasks and analyze the learned\nhidden sentence representations. The representations change significantly when\ntranslation and part-of-speech decoders are added. The more decoders a model\nemploys, the better it clusters sentences according to their syntactic\nsimilarity, as the representation space becomes less entangled. We explore the\nstructure of the representation space by interpolating between sentences, which\nyields interesting pseudo-English sentences, many of which have recognizable\nsyntactic structure. Lastly, we point out an interesting property of our\nmodels: The difference-vector between two sentences can be added to change a\nthird sentence with similar features in a meaningful way.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 14:10:37 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Brunner", "Gino", ""], ["Wang", "Yuyi", ""], ["Wattenhofer", "Roger", ""], ["Weigelt", "Michael", ""]]}, {"id": "1801.06027", "submitter": "Divya Mahajan", "authors": "Divya Mahajan, Joon Kyung Kim, Jacob Sacks, Adel Ardalan, Arun Kumar,\n  Hadi Esmaeilzadeh", "title": "In-RDBMS Hardware Acceleration of Advanced Analytics", "comments": null, "journal-ref": "Divya Mahajan, Joon Kyung Kim, Jacob Sacks, Adel Ardalan, Arun\n  Kumar, and Hadi Esmaeilzadeh. In-RDBMS Hardware Acceleration of Advanced\n  Analytics. PVLDB, 11(11): 1317-1331, 2018", "doi": "10.14778/3236187.3236188", "report-no": null, "categories": "cs.DB cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data revolution is fueled by advances in machine learning, databases, and\nhardware design. Programmable accelerators are making their way into each of\nthese areas independently. As such, there is a void of solutions that enables\nhardware acceleration at the intersection of these disjoint fields. This paper\nsets out to be the initial step towards a unifying solution for in-Database\nAcceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such\nas FPGAs, for in-database analytics currently requires hand-designing the\nhardware and manually routing the data. Instead, DAnA automatically maps a\nhigh-level specification of advanced analytics queries to an FPGA accelerator.\nThe accelerator implementation is generated for a User Defined Function (UDF),\nexpressed as a part of an SQL query using a Python-embedded Domain-Specific\nLanguage (DSL). To realize an efficient in-database integration, DAnA\naccelerators contain a novel hardware structure, Striders, that directly\ninterface with the buffer pool of the database. Striders extract, cleanse, and\nprocess the training data tuples that are consumed by a multi-threaded FPGA\nengine that executes the analytics algorithm. We integrate DAnA with PostgreSQL\nto generate hardware accelerators for a range of real-world and synthetic\ndatasets running diverse ML algorithms. Results show that DAnA-enhanced\nPostgreSQL provides, on average, 8.3x end-to-end speedup for real datasets,\nwith a maximum of 28.2x. Moreover, DAnA-enhanced PostgreSQL is, on average,\n4.0x faster than the multi-threaded Apache MADLib running on Greenplum. DAnA\nprovides these benefits while hiding the complexity of hardware design from\ndata scientists and allowing them to express the algorithm in =30-60 lines of\nPython.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 19:04:13 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 13:55:56 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Mahajan", "Divya", ""], ["Kim", "Joon Kyung", ""], ["Sacks", "Jacob", ""], ["Ardalan", "Adel", ""], ["Kumar", "Arun", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1801.06043", "submitter": "Sam Ganzfried", "authors": "Sam Ganzfried, Farzana Yusuf", "title": "Optimal Weighting for Exam Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem faced by many instructors is that of designing exams that\naccurately assess the abilities of the students. Typically these exams are\nprepared several days in advance, and generic question scores are used based on\nrough approximation of the question difficulty and length. For example, for a\nrecent class taught by the author, there were 30 multiple choice questions\nworth 3 points, 15 true/false with explanation questions worth 4 points, and 5\nanalytical exercises worth 10 points. We describe a novel framework where\nalgorithms from machine learning are used to modify the exam question weights\nin order to optimize the exam scores, using the overall class grade as a proxy\nfor a student's true ability. We show that significant error reduction can be\nobtained by our approach over standard weighting schemes, and we make several\nnew observations regarding the properties of the \"good\" and \"bad\" exam\nquestions that can have impact on the design of improved future evaluation\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 05:35:47 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ganzfried", "Sam", ""], ["Yusuf", "Farzana", ""]]}, {"id": "1801.06048", "submitter": "Yuri G. Gordienko", "authors": "Yuri Gordienko, Sergii Stirenko, Yuriy Kochura, Oleg Alienin, Michail\n  Novotarskiy, Nikita Gordienko", "title": "Deep Learning for Fatigue Estimation on the Basis of Multimodal\n  Human-Machine Interactions", "comments": "12 pages, 10 figures, 1 table; presented at XXIX IUPAP Conference in\n  Computational Physics (CCP2017) July 9-13, 2017, Paris, University Pierre et\n  Marie Curie - Sorbonne (https://ccp2017.sciencesconf.org/program)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new method is proposed to monitor the level of current physical load and\naccumulated fatigue by several objective and subjective characteristics. It was\napplied to the dataset targeted to estimate the physical load and fatigue by\nseveral statistical and machine learning methods. The data from peripheral\nsensors (accelerometer, GPS, gyroscope, magnetometer) and brain-computing\ninterface (electroencephalography) were collected, integrated, and analyzed by\nseveral statistical and machine learning methods (moment analysis, cluster\nanalysis, principal component analysis, etc.). The hypothesis 1 was presented\nand proved that physical activity can be classified not only by objective\nparameters, but by subjective parameters also. The hypothesis 2 (experienced\nphysical load and subsequent restoration as fatigue level can be estimated\nquantitatively and distinctive patterns can be recognized) was presented and\nsome ways to prove it were demonstrated. Several \"physical load\" and \"fatigue\"\nmetrics were proposed. The results presented allow to extend application of the\nmachine learning methods for characterization of complex human activity\npatterns (for example, to estimate their actual physical load and fatigue, and\ngive cautions and advice).\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 17:49:03 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Gordienko", "Yuri", ""], ["Stirenko", "Sergii", ""], ["Kochura", "Yuriy", ""], ["Alienin", "Oleg", ""], ["Novotarskiy", "Michail", ""], ["Gordienko", "Nikita", ""]]}, {"id": "1801.06077", "submitter": "Igor Halperin", "authors": "Igor Halperin", "title": "The QLBS Q-Learner Goes NuQLear: Fitted Q Iteration, Inverse RL, and\n  Option Portfolios", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The QLBS model is a discrete-time option hedging and pricing model that is\nbased on Dynamic Programming (DP) and Reinforcement Learning (RL). It combines\nthe famous Q-Learning method for RL with the Black-Scholes (-Merton) model's\nidea of reducing the problem of option pricing and hedging to the problem of\noptimal rebalancing of a dynamic replicating portfolio for the option, which is\nmade of a stock and cash. Here we expand on several NuQLear (Numerical\nQ-Learning) topics with the QLBS model. First, we investigate the performance\nof Fitted Q Iteration for a RL (data-driven) solution to the model, and\nbenchmark it versus a DP (model-based) solution, as well as versus the BSM\nmodel. Second, we develop an Inverse Reinforcement Learning (IRL) setting for\nthe model, where we only observe prices and actions (re-hedges) taken by a\ntrader, but not rewards. Third, we outline how the QLBS model can be used for\npricing portfolios of options, rather than a single option in isolation, thus\nproviding its own, data-driven and model independent solution to the (in)famous\nvolatility smile problem of the Black-Scholes model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 15:51:09 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Halperin", "Igor", ""]]}, {"id": "1801.06126", "submitter": "Yedid Hoshen", "authors": "Yedid Hoshen and Lior Wolf", "title": "Non-Adversarial Unsupervised Word Translation", "comments": "EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised word translation from non-parallel inter-lingual corpora has\nattracted much research interest. Very recently, neural network methods trained\nwith adversarial loss functions achieved high accuracy on this task. Despite\nthe impressive success of the recent techniques, they suffer from the typical\ndrawbacks of generative adversarial models: sensitivity to hyper-parameters,\nlong training time and lack of interpretability. In this paper, we make the\nobservation that two sufficiently similar distributions can be aligned\ncorrectly with iterative matching methods. We present a novel method that first\naligns the second moment of the word distributions of the two languages and\nthen iteratively refines the alignment. Extensive experiments on word\ntranslation of European and Non-European languages show that our method\nachieves better performance than recent state-of-the-art deep adversarial\napproaches and is competitive with the supervised baseline. It is also\nefficient, easy to parallelize on CPU and interpretable.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 16:59:19 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 20:56:10 GMT"}, {"version": "v3", "created": "Mon, 13 Aug 2018 15:13:05 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Hoshen", "Yedid", ""], ["Wolf", "Lior", ""]]}, {"id": "1801.06136", "submitter": "Pauli Miettinen", "authors": "Sanjar Karaev, James Hook and Pauli Miettinen", "title": "Latitude: A Model for Mixed Linear-Tropical Matrix Factorization", "comments": "14 pages, 6 figures. To appear in 2018 SIAM International Conference\n  on Data Mining (SDM '18). For the source code, see\n  https://people.mpi-inf.mpg.de/~pmiettin/linear-tropical/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) is one of the most frequently-used\nmatrix factorization models in data analysis. A significant reason to the\npopularity of NMF is its interpretability and the `parts of whole'\ninterpretation of its components. Recently, max-times, or subtropical, matrix\nfactorization (SMF) has been introduced as an alternative model with equally\ninterpretable `winner takes it all' interpretation. In this paper we propose a\nnew mixed linear--tropical model, and a new algorithm, called Latitude, that\ncombines NMF and SMF, being able to smoothly alternate between the two. In our\nmodel, the data is modeled using the latent factors and latent parameters that\ncontrol whether the factors are interpreted as NMF or SMF features, or their\nmixtures. We present an algorithm for our novel matrix factorization. Our\nexperiments show that our algorithm improves over both baselines, and can yield\ninterpretable results that reveal more of the latent structure than either NMF\nor SMF alone.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 17:17:46 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Karaev", "Sanjar", ""], ["Hook", "James", ""], ["Miettinen", "Pauli", ""]]}, {"id": "1801.06146", "submitter": "Sebastian Ruder", "authors": "Jeremy Howard, Sebastian Ruder", "title": "Universal Language Model Fine-tuning for Text Classification", "comments": "ACL 2018, fixed denominator in Equation 3, line 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive transfer learning has greatly impacted computer vision, but\nexisting approaches in NLP still require task-specific modifications and\ntraining from scratch. We propose Universal Language Model Fine-tuning\n(ULMFiT), an effective transfer learning method that can be applied to any task\nin NLP, and introduce techniques that are key for fine-tuning a language model.\nOur method significantly outperforms the state-of-the-art on six text\nclassification tasks, reducing the error by 18-24% on the majority of datasets.\nFurthermore, with only 100 labeled examples, it matches the performance of\ntraining from scratch on 100x more data. We open-source our pretrained models\nand code.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 17:54:52 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 13:57:04 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 22:02:11 GMT"}, {"version": "v4", "created": "Thu, 17 May 2018 17:46:49 GMT"}, {"version": "v5", "created": "Wed, 23 May 2018 09:23:47 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Howard", "Jeremy", ""], ["Ruder", "Sebastian", ""]]}, {"id": "1801.06159", "submitter": "Lam Nguyen", "authors": "Lam M. Nguyen, Nam H. Nguyen, Dzung T. Phan, Jayant R. Kalagnanam,\n  Katya Scheinberg", "title": "When Does Stochastic Gradient Algorithm Work Well?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a general stochastic optimization problem which is\noften at the core of supervised learning, such as deep learning and linear\nclassification. We consider a standard stochastic gradient descent (SGD) method\nwith a fixed, large step size and propose a novel assumption on the objective\nfunction, under which this method has the improved convergence rates (to a\nneighborhood of the optimal solutions). We then empirically demonstrate that\nthese assumptions hold for logistic regression and standard deep neural\nnetworks on classical data sets. Thus our analysis helps to explain when\nefficient behavior can be expected from the SGD method in training\nclassification models and deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:23:02 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2018 04:35:17 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Nguyen", "Lam M.", ""], ["Nguyen", "Nam H.", ""], ["Phan", "Dzung T.", ""], ["Kalagnanam", "Jayant R.", ""], ["Scheinberg", "Katya", ""]]}, {"id": "1801.06176", "submitter": "Xiujun Li", "authors": "Baolin Peng and Xiujun Li and Jianfeng Gao and Jingjing Liu and\n  Kam-Fai Wong and Shang-Yu Su", "title": "Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy\n  Learning", "comments": "11 pages, 8 figures, Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a task-completion dialogue agent via reinforcement learning (RL) is\ncostly because it requires many interactions with real users. One common\nalternative is to use a user simulator. However, a user simulator usually lacks\nthe language complexity of human interlocutors and the biases in its design may\ntend to degrade the agent. To address these issues, we present Deep Dyna-Q,\nwhich to our knowledge is the first deep RL framework that integrates planning\nfor task-completion dialogue policy learning. We incorporate into the dialogue\nagent a model of the environment, referred to as the world model, to mimic real\nuser response and generate simulated experience. During dialogue policy\nlearning, the world model is constantly updated with real user experience to\napproach real user behavior, and in turn, the dialogue agent is optimized using\nboth real experience and simulated experience. The effectiveness of our\napproach is demonstrated on a movie-ticket booking task in both simulated and\nhuman-in-the-loop settings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:57:33 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 22:31:38 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 17:52:27 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Wong", "Kam-Fai", ""], ["Su", "Shang-Yu", ""]]}, {"id": "1801.06274", "submitter": "Yuhao Zhu", "authors": "Yuhao Zhu, Matthew Mattina, Paul Whatmough", "title": "Mobile Machine Learning Hardware at ARM: A Systems-on-Chip (SoC)\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is playing an increasingly significant role in emerging\nmobile application domains such as AR/VR, ADAS, etc. Accordingly, hardware\narchitects have designed customized hardware for machine learning algorithms,\nespecially neural networks, to improve compute efficiency. However, machine\nlearning is typically just one processing stage in complex end-to-end\napplications, involving multiple components in a mobile Systems-on-a-chip\n(SoC). Focusing only on ML accelerators loses bigger optimization opportunity\nat the system (SoC) level. This paper argues that hardware architects should\nexpand the optimization scope to the entire SoC. We demonstrate one particular\ncase-study in the domain of continuous computer vision where camera sensor,\nimage signal processor (ISP), memory, and NN accelerator are synergistically\nco-designed to achieve optimal system-level efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 02:42:10 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 23:54:27 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Zhu", "Yuhao", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul", ""]]}, {"id": "1801.06287", "submitter": "Linyuan Gong", "authors": "Linyuan Gong, Ruyi Ji", "title": "What Does a TextCNN Learn?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  TextCNN, the convolutional neural network for text, is a useful deep learning\nalgorithm for sentence classification tasks such as sentiment analysis and\nquestion classification. However, neural networks have long been known as black\nboxes because interpreting them is a challenging task. Researchers have\ndeveloped several tools to understand a CNN for image classification by deep\nvisualization, but research about deep TextCNNs is still insufficient. In this\npaper, we are trying to understand what a TextCNN learns on two classical NLP\ndatasets. Our work focuses on functions of different convolutional kernels and\ncorrelations between convolutional kernels.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 04:02:04 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Gong", "Linyuan", ""], ["Ji", "Ruyi", ""]]}, {"id": "1801.06294", "submitter": "Shaika Chowdhury", "authors": "Shaika Chowdhury, Chenwei Zhang and Philip S. Yu", "title": "Multi-Task Pharmacovigilance Mining from Social Media Posts", "comments": "Accepted in the research track of The Web Conference(WWW) 2018", "journal-ref": null, "doi": "10.1145/3178876.3186053", "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has grown to be a crucial information source for\npharmacovigilance studies where an increasing number of people post adverse\nreactions to medical drugs that are previously unreported. Aiming to\neffectively monitor various aspects of Adverse Drug Reactions (ADRs) from\ndiversely expressed social medical posts, we propose a multi-task neural\nnetwork framework that learns several tasks associated with ADR monitoring with\ndifferent levels of supervisions collectively. Besides being able to correctly\nclassify ADR posts and accurately extract ADR mentions from online posts, the\nproposed framework is also able to further understand reasons for which the\ndrug is being taken, known as 'indication', from the given social media post. A\ncoverage-based attention mechanism is adopted in our framework to help the\nmodel properly identify 'phrasal' ADRs and Indications that are attentive to\nmultiple words in a post. Our framework is applicable in situations where\nlimited parallel data for different pharmacovigilance tasks are available.We\nevaluate the proposed framework on real-world Twitter datasets, where the\nproposed model outperforms the state-of-the-art alternatives of each individual\ntask consistently.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 05:04:21 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 02:07:45 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 06:07:22 GMT"}, {"version": "v4", "created": "Thu, 15 Feb 2018 03:03:56 GMT"}, {"version": "v5", "created": "Fri, 16 Feb 2018 18:43:05 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Chowdhury", "Shaika", ""], ["Zhang", "Chenwei", ""], ["Yu", "Philip S.", ""]]}, {"id": "1801.06309", "submitter": "Rie Johnson", "authors": "Rie Johnson and Tong Zhang", "title": "Composite Functional Gradient Learning of Generative Adversarial Models", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper first presents a theory for generative adversarial methods that\ndoes not rely on the traditional minimax formulation. It shows that with a\nstrong discriminator, a good generator can be learned so that the KL divergence\nbetween the distributions of real data and generated data improves after each\nfunctional gradient step until it converges to zero. Based on the theory, we\npropose a new stable generative adversarial method. A theoretical insight into\nthe original GAN from this new viewpoint is also provided. The experiments on\nimage generation show the effectiveness of our new method.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 06:20:56 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 13:21:18 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Johnson", "Rie", ""], ["Zhang", "Tong", ""]]}, {"id": "1801.06378", "submitter": "Grigori Fursin", "authors": "Thierry Moreau, Anton Lokhmotov and Grigori Fursin", "title": "Introducing ReQuEST: an Open Platform for Reproducible and\n  Quality-Efficient Systems-ML Tournaments", "comments": "ReQuEST tournament website: http://cKnowledge.org/request", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Co-designing efficient machine learning based systems across the whole\nhardware/software stack to trade off speed, accuracy, energy and costs is\nbecoming extremely complex and time consuming. Researchers often struggle to\nevaluate and compare different published works across rapidly evolving software\nframeworks, heterogeneous hardware platforms, compilers, libraries, algorithms,\ndata sets, models, and environments.\n  We present our community effort to develop an open co-design tournament\nplatform with an online public scoreboard. It will gradually incorporate best\nresearch practices while providing a common way for multidisciplinary\nresearchers to optimize and compare the quality vs. efficiency Pareto\noptimality of various workloads on diverse and complete hardware/software\nsystems. We want to leverage the open-source Collective Knowledge framework and\nthe ACM artifact evaluation methodology to validate and share the complete\nmachine learning system implementations in a standardized, portable, and\nreproducible fashion. We plan to hold regular multi-objective optimization and\nco-design tournaments for emerging workloads such as deep learning, starting\nwith ASPLOS'18 (ACM conference on Architectural Support for Programming\nLanguages and Operating Systems - the premier forum for multidisciplinary\nsystems research spanning computer architecture and hardware, programming\nlanguages and compilers, operating systems and networking) to build a public\nrepository of the most efficient machine learning algorithms and systems which\ncan be easily customized, reused and built upon.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 12:22:51 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Moreau", "Thierry", ""], ["Lokhmotov", "Anton", ""], ["Fursin", "Grigori", ""]]}, {"id": "1801.06432", "submitter": "Mehdi Bahri", "authors": "Mehdi Bahri, Yannis Panagakis, Stefanos Zafeiriou", "title": "Robust Kronecker Component Analysis", "comments": "In IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  Special Issue on Compact and Efficient Feature Representation and Learning in\n  Computer Vision, 2018. Contains appendices. arXiv admin note: text overlap\n  with arXiv:1703.07886", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning and component analysis models are fundamental for\nlearning compact representations that are relevant to a given task (feature\nextraction, dimensionality reduction, denoising, etc.). The model complexity is\nencoded by means of specific structure, such as sparsity, low-rankness, or\nnonnegativity. Unfortunately, approaches like K-SVD - that learn dictionaries\nfor sparse coding via Singular Value Decomposition (SVD) - are hard to scale to\nhigh-volume and high-dimensional visual data, and fragile in the presence of\noutliers. Conversely, robust component analysis methods such as the Robust\nPrincipal Component Analysis (RPCA) are able to recover low-complexity (e.g.,\nlow-rank) representations from data corrupted with noise of unknown magnitude\nand support, but do not provide a dictionary that respects the structure of the\ndata (e.g., images), and also involve expensive computations. In this paper, we\npropose a novel Kronecker-decomposable component analysis model, coined as\nRobust Kronecker Component Analysis (RKCA), that combines ideas from sparse\ndictionary learning and robust component analysis. RKCA has several appealing\nproperties, including robustness to gross corruption; it can be used for\nlow-rank modeling, and leverages separability to solve significantly smaller\nproblems. We design an efficient learning algorithm by drawing links with a\nrestricted form of tensor factorization, and analyze its optimality and\nlow-rankness properties. The effectiveness of the proposed approach is\ndemonstrated on real-world applications, namely background subtraction and\nimage denoising and completion, by performing a thorough comparison with the\ncurrent state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:01:50 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 20:55:20 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Bahri", "Mehdi", ""], ["Panagakis", "Yannis", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1801.06481", "submitter": "Chen Liang", "authors": "Chen Liang, Jianbo Ye, Han Zhao, Bart Pursel, C. Lee Giles", "title": "Active Learning of Strict Partial Orders: A Case Study on Concept\n  Prerequisite Relations", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strict partial order is a mathematical structure commonly seen in relational\ndata. One obstacle to extracting such type of relations at scale is the lack of\nlarge-scale labels for building effective data-driven solutions. We develop an\nactive learning framework for mining such relations subject to a strict order.\nOur approach incorporates relational reasoning not only in finding new\nunlabeled pairs whose labels can be deduced from an existing label set, but\nalso in devising new query strategies that consider the relational structure of\nlabels. Our experiments on concept prerequisite relations show our proposed\nframework can substantially improve the classification performance with the\nsame query budget compared to other baseline approaches.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 16:26:18 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Liang", "Chen", ""], ["Ye", "Jianbo", ""], ["Zhao", "Han", ""], ["Pursel", "Bart", ""], ["Giles", "C. Lee", ""]]}, {"id": "1801.06490", "submitter": "Pankaj Pansari", "authors": "Pankaj Pansari, Chris Russell, M.Pawan Kumar", "title": "Worst-case Optimal Submodular Extensions for Marginal Estimation", "comments": "Accepted to AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular extensions of an energy function can be used to efficiently\ncompute approximate marginals via variational inference. The accuracy of the\nmarginals depends crucially on the quality of the submodular extension. To\nidentify the best possible extension, we show an equivalence between the\nsubmodular extensions of the energy and the objective functions of linear\nprogramming (LP) relaxations for the corresponding MAP estimation problem. This\nallows us to (i) establish the worst-case optimality of the submodular\nextension for Potts model used in the literature; (ii) identify the worst-case\noptimal submodular extension for the more general class of metric labeling; and\n(iii) efficiently compute the marginals for the widely used dense CRF model\nwith the help of a recently proposed Gaussian filtering method. Using synthetic\nand real data, we show that our approach provides comparable upper bounds on\nthe log-partition function to those obtained using tree-reweighted message\npassing (TRW) in cases where the latter is computationally feasible.\nImportantly, unlike TRW, our approach provides the first practical algorithm to\ncompute an upper bound on the dense CRF model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 14:36:57 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Pansari", "Pankaj", ""], ["Russell", "Chris", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "1801.06495", "submitter": "Yuri G. Gordienko", "authors": "Yu.Gordienko, Yu.Kochura, O.Alienin, O. Rokovyi, S. Stirenko, Peng\n  Gang, Jiang Hui, Wei Zeng", "title": "Dimensionality Reduction in Deep Learning for Chest X-Ray Analysis of\n  Lung Cancer", "comments": "6 pages, 14 figures", "journal-ref": "2018 Tenth International Conference on Advanced Computational\n  Intelligence (ICACI), Xiamen, 2018, pp. 878-883", "doi": "10.1109/ICACI.2018.8377579", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficiency of some dimensionality reduction techniques, like lung\nsegmentation, bone shadow exclusion, and t-distributed stochastic neighbor\nembedding (t-SNE) for exclusion of outliers, is estimated for analysis of chest\nX-ray (CXR) 2D images by deep learning approach to help radiologists identify\nmarks of lung cancer in CXR. Training and validation of the simple\nconvolutional neural network (CNN) was performed on the open JSRT dataset\n(dataset #01), the JSRT after bone shadow exclusion - BSE-JSRT (dataset #02),\nJSRT after lung segmentation (dataset #03), BSE-JSRT after lung segmentation\n(dataset #04), and segmented BSE-JSRT after exclusion of outliers by t-SNE\nmethod (dataset #05). The results demonstrate that the pre-processed dataset\nobtained after lung segmentation, bone shadow exclusion, and filtering out the\noutliers by t-SNE (dataset #05) demonstrates the highest training rate and best\naccuracy in comparison to the other pre-processed datasets.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 17:15:25 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Gordienko", "Yu.", ""], ["Kochura", "Yu.", ""], ["Alienin", "O.", ""], ["Rokovyi", "O.", ""], ["Stirenko", "S.", ""], ["Gang", "Peng", ""], ["Hui", "Jiang", ""], ["Zeng", "Wei", ""]]}, {"id": "1801.06503", "submitter": "Alexandre Attia", "authors": "Alexandre Attia, Sharone Dayan", "title": "Global overview of Imitation Learning", "comments": "9 pages, 5 figures, 5 appendix pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning is a sequential task where the learner tries to mimic an\nexpert's action in order to achieve the best performance. Several algorithms\nhave been proposed recently for this task. In this project, we aim at proposing\na wide review of these algorithms, presenting their main features and comparing\nthem on their performance and their regret bounds.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 17:40:09 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Attia", "Alexandre", ""], ["Dayan", "Sharone", ""]]}, {"id": "1801.06597", "submitter": "Yu Shi", "authors": "Yu Shi, Fangqiu Han, Xinwei He, Xinran He, Carl Yang, Jie Luo, Jiawei\n  Han", "title": "mvn2vec: Preservation and Collaboration in Multi-View Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view networks are broadly present in real-world applications. In the\nmeantime, network embedding has emerged as an effective representation learning\napproach for networked data. Therefore, we are motivated to study the problem\nof multi-view network embedding with a focus on the optimization objectives\nthat are specific and important in embedding this type of network. In our\npractice of embedding real-world multi-view networks, we explicitly identify\ntwo such objectives, which we refer to as preservation and collaboration. The\nin-depth analysis of these two objectives is discussed throughout this paper.\nIn addition, the mvn2vec algorithms are proposed to (i) study how varied extent\nof preservation and collaboration can impact embedding learning and (ii)\nexplore the feasibility of achieving better embedding quality by modeling them\nsimultaneously. With experiments on a series of synthetic datasets, a\nlarge-scale internal Snapchat dataset, and two public datasets, we confirm the\nvalidity and importance of preservation and collaboration as two objectives for\nmulti-view network embedding. These experiments further demonstrate that better\nembedding can be obtained by simultaneously modeling the two objectives, while\nnot over-complicating the model or requiring additional supervision. The code\nand the processed datasets are available at\nhttp://yushi2.web.engr.illinois.edu/.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 23:14:08 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:57:12 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 01:52:09 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shi", "Yu", ""], ["Han", "Fangqiu", ""], ["He", "Xinwei", ""], ["He", "Xinran", ""], ["Yang", "Carl", ""], ["Luo", "Jie", ""], ["Han", "Jiawei", ""]]}, {"id": "1801.06601", "submitter": "Vikas Chandra", "authors": "Liangzhen Lai, Naveen Suda, Vikas Chandra", "title": "CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are becoming increasingly popular in always-on IoT edge\ndevices performing data analytics right at the source, reducing latency as well\nas energy consumption for data communication. This paper presents CMSIS-NN,\nefficient kernels developed to maximize the performance and minimize the memory\nfootprint of neural network (NN) applications on Arm Cortex-M processors\ntargeted for intelligent IoT edge devices. Neural network inference based on\nCMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X\nimprovement in energy efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 23:39:15 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Lai", "Liangzhen", ""], ["Suda", "Naveen", ""], ["Chandra", "Vikas", ""]]}, {"id": "1801.06637", "submitter": "Maziar Raissi", "authors": "Maziar Raissi", "title": "Deep Hidden Physics Models: Deep Learning of Nonlinear Partial\n  Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing problem at the interface of artificial intelligence and\napplied mathematics is to devise an algorithm capable of achieving human level\nor even superhuman proficiency in transforming observed data into predictive\nmathematical models of the physical world. In the current era of abundance of\ndata and advanced machine learning capabilities, the natural question arises:\nHow can we automatically uncover the underlying laws of physics from\nhigh-dimensional data generated from experiments? In this work, we put forth a\ndeep learning approach for discovering nonlinear partial differential equations\nfrom scattered and potentially noisy observations in space and time.\nSpecifically, we approximate the unknown solution as well as the nonlinear\ndynamics by two deep neural networks. The first network acts as a prior on the\nunknown solution and essentially enables us to avoid numerical differentiations\nwhich are inherently ill-conditioned and unstable. The second network\nrepresents the nonlinear dynamics and helps us distill the mechanisms that\ngovern the evolution of a given spatiotemporal data-set. We test the\neffectiveness of our approach for several benchmark problems spanning a number\nof scientific domains and demonstrate how the proposed framework can help us\naccurately learn the underlying dynamics and forecast future states of the\nsystem. In particular, we study the Burgers', Korteweg-de Vries (KdV),\nKuramoto-Sivashinsky, nonlinear Schr\\\"{o}dinger, and Navier-Stokes equations.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 08:02:09 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Raissi", "Maziar", ""]]}, {"id": "1801.06665", "submitter": "Grigorios Chrysos", "authors": "Grigorios G. Chrysos, Yannis Panagakis, Stefanos Zafeiriou", "title": "Visual Data Augmentation through Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid progress in machine learning methods has been empowered by i) huge\ndatasets that have been collected and annotated, ii) improved engineering (e.g.\ndata pre-processing/normalization). The existing datasets typically include\nseveral million samples, which constitutes their extension a colossal task. In\naddition, the state-of-the-art data-driven methods demand a vast amount of\ndata, hence a standard engineering trick employed is artificial data\naugmentation for instance by adding into the data cropped and (affinely)\ntransformed images. However, this approach does not correspond to any change in\nthe natural 3D scene.\n  We propose instead to perform data augmentation through learning realistic\nlocal transformations. We learn a forward and an inverse transformation that\nmaps an image from the high-dimensional space of pixel intensities to a latent\nspace which varies (approximately) linearly with the latent space of a\nrealistically transformed version of the image. Such transformed images can be\nconsidered two successive frames in a video. Next, we utilize these\ntransformations to learn a linear model that modifies the latent spaces and\nthen use the inverse transformation to synthesize a new image. We argue that\nthe this procedure produces powerful invariant representations. We perform both\nqualitative and quantitative experiments that demonstrate our proposed method\ncreates new realistic images.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 12:08:59 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Chrysos", "Grigorios G.", ""], ["Panagakis", "Yannis", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1801.06700", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng\n  Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath\n  Chandar, Nan Rosemary Ke, Sai Rajeswar, Alexandre de Brebisson, Jose M. R.\n  Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau,\n  Yoshua Bengio", "title": "A Deep Reinforcement Learning Chatbot (Short Version)", "comments": "9 pages, 1 figure, 2 tables; presented at NIPS 2017, Conversational\n  AI: \"Today's Practice and Tomorrow's Potential\" Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including neural network and\ntemplate-based models. By applying reinforcement learning to crowdsourced data\nand real-world user interactions, the system has been trained to select an\nappropriate response from the models in its ensemble. The system has been\nevaluated through A/B testing with real-world users, where it performed\nsignificantly better than other systems. The results highlight the potential of\ncoupling ensemble systems with deep reinforcement learning as a fruitful path\nfor developing real-world, open-domain conversational agents.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 17:22:06 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Serban", "Iulian V.", ""], ["Sankar", "Chinnadhurai", ""], ["Germain", "Mathieu", ""], ["Zhang", "Saizheng", ""], ["Lin", "Zhouhan", ""], ["Subramanian", "Sandeep", ""], ["Kim", "Taesup", ""], ["Pieper", "Michael", ""], ["Chandar", "Sarath", ""], ["Ke", "Nan Rosemary", ""], ["Rajeswar", "Sai", ""], ["de Brebisson", "Alexandre", ""], ["Sotelo", "Jose M. R.", ""], ["Suhubdy", "Dendi", ""], ["Michalski", "Vincent", ""], ["Nguyen", "Alexandre", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1801.06720", "submitter": "Junhong Lin", "authors": "Junhong Lin, Alessandro Rudi, Lorenzo Rosasco, Volkan Cevher", "title": "Optimal Rates for Spectral Algorithms with Least-Squares Regression over\n  Hilbert Spaces", "comments": null, "journal-ref": "Applied and Computational Harmonic Analysis 2018", "doi": "10.1016/j.acha.2018.09.009", "report-no": null, "categories": "stat.ML cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study regression problems over a separable Hilbert space\nwith the square loss, covering non-parametric regression over a reproducing\nkernel Hilbert space. We investigate a class of spectral-regularized\nalgorithms, including ridge regression, principal component analysis, and\ngradient methods. We prove optimal, high-probability convergence results in\nterms of variants of norms for the studied algorithms, considering a capacity\nassumption on the hypothesis space and a general source condition on the target\nfunction. Consequently, we obtain almost sure convergence results with optimal\nrates. Our results improve and generalize previous results, filling a\ntheoretical gap for the non-attainable cases.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 20:02:00 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 20:46:30 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2018 15:26:26 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Lin", "Junhong", ""], ["Rudi", "Alessandro", ""], ["Rosasco", "Lorenzo", ""], ["Cevher", "Volkan", ""]]}, {"id": "1801.06801", "submitter": "Huan Long", "authors": "Tao Yu, Huan Long, John E. Hopcroft", "title": "Curvature-based Comparison of Two Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we show the similarities and differences of two deep neural\nnetworks by comparing the manifolds composed of activation vectors in each\nfully connected layer of them. The main contribution of this paper includes 1)\na new data generating algorithm which is crucial for determining the dimension\nof manifolds; 2) a systematic strategy to compare manifolds. Especially, we\ntake Riemann curvature and sectional curvature as part of criterion, which can\nreflect the intrinsic geometric properties of manifolds. Some interesting\nresults and phenomenon are given, which help in specifying the similarities and\ndifferences between the features extracted by two networks and demystifying the\nintrinsic mechanism of deep neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 10:17:33 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Yu", "Tao", ""], ["Long", "Huan", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1801.06805", "submitter": "Weichang Wu", "authors": "Weichang Wu, Junchi Yan, Xiaokang Yang, Hongyuan Zha", "title": "Decoupled Learning for Factorial Marked Temporal Point Processes", "comments": "9 pages, 8 figures, submitted to TNNLS, 21 Jan, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the factorial marked temporal point process model and\npresents efficient learning methods. In conventional (multi-dimensional) marked\ntemporal point process models, event is often encoded by a single discrete\nvariable i.e. a marker. In this paper, we describe the factorial marked point\nprocesses whereby time-stamped event is factored into multiple markers.\nAccordingly the size of the infectivity matrix modeling the effect between\npairwise markers is in power order w.r.t. the number of the discrete marker\nspace. We propose a decoupled learning method with two learning procedures: i)\ndirectly solving the model based on two techniques: Alternating Direction\nMethod of Multipliers and Fast Iterative Shrinkage-Thresholding Algorithm; ii)\ninvolving a reformulation that transforms the original problem into a Logistic\nRegression model for more efficient learning. Moreover, a sparse group\nregularizer is added to identify the key profile features and event labels.\nEmpirical results on real world datasets demonstrate the efficiency of our\ndecoupled and reformulated method. The source code is available online.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 11:13:29 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Wu", "Weichang", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""], ["Zha", "Hongyuan", ""]]}, {"id": "1801.06845", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Lorenzo Livi, Alberto Ferrante, Jelena\n  Milosevic, Miroslaw Malek", "title": "Time series kernel similarities for predicting Paroxysmal Atrial\n  Fibrillation from ECGs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of classifying Electrocardiography (ECG) signals with\nthe aim of predicting the onset of Paroxysmal Atrial Fibrillation (PAF). Atrial\nfibrillation is the most common type of arrhythmia, but in many cases PAF\nepisodes are asymptomatic. Therefore, in order to help diagnosing PAF, it is\nimportant to design procedures for detecting and, more importantly, predicting\nPAF episodes. We propose a method for predicting PAF events whose first step\nconsists of a feature extraction procedure that represents each ECG as a\nmulti-variate time series. Successively, we design a classification framework\nbased on kernel similarities for multi-variate time series, capable of handling\nmissing data. We consider different approaches to perform classification in the\noriginal space of the multi-variate time series and in an embedding space,\ndefined by the kernel similarity measure. We achieve a classification accuracy\ncomparable with state of the art methods, with the additional advantage of\ndetecting the PAF onset up to 15 minutes in advance.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 16:28:23 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 20:03:05 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Livi", "Lorenzo", ""], ["Ferrante", "Alberto", ""], ["Milosevic", "Jelena", ""], ["Malek", "Miroslaw", ""]]}, {"id": "1801.06879", "submitter": "Yinhao Zhu", "authors": "Yinhao Zhu, Nicholas Zabaras", "title": "Bayesian Deep Convolutional Encoder-Decoder Networks for Surrogate\n  Modeling and Uncertainty Quantification", "comments": "52 pages, 28 figures, submitted to Journal of Computational Physics", "journal-ref": null, "doi": "10.1016/j.jcp.2018.04.018", "report-no": null, "categories": "physics.comp-ph cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the development of surrogate models for uncertainty\nquantification and propagation in problems governed by stochastic PDEs using a\ndeep convolutional encoder-decoder network in a similar fashion to approaches\nconsidered in deep learning for image-to-image regression tasks. Since normal\nneural networks are data intensive and cannot provide predictive uncertainty,\nwe propose a Bayesian approach to convolutional neural nets. A recently\nintroduced variational gradient descent algorithm based on Stein's method is\nscaled to deep convolutional networks to perform approximate Bayesian inference\non millions of uncertain network parameters. This approach achieves state of\nthe art performance in terms of predictive accuracy and uncertainty\nquantification in comparison to other approaches in Bayesian neural networks as\nwell as techniques that include Gaussian processes and ensemble methods even\nwhen the training data size is relatively small. To evaluate the performance of\nthis approach, we consider standard uncertainty quantification benchmark\nproblems including flow in heterogeneous media defined in terms of limited\ndata-driven permeability realizations. The performance of the surrogate model\ndeveloped is very good even though there is no underlying structure shared\nbetween the input (permeability) and output (flow/pressure) fields as is often\nthe case in the image-to-image regression models used in computer vision\nproblems. Studies are performed with an underlying stochastic input\ndimensionality up to $4,225$ where most other uncertainty quantification\nmethods fail. Uncertainty propagation tasks are considered and the predictive\noutput Bayesian statistics are compared to those obtained with Monte Carlo\nestimates.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 19:18:13 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Zhu", "Yinhao", ""], ["Zabaras", "Nicholas", ""]]}, {"id": "1801.06889", "submitter": "Fred Hohman", "authors": "Fred Hohman, Minsuk Kahng, Robert Pienta, Duen Horng Chau", "title": "Visual Analytics in Deep Learning: An Interrogative Survey for the Next\n  Frontiers", "comments": "Under review for IEEE Transactions on Visualization and Computer\n  Graphics (TVCG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently seen rapid development and received significant\nattention due to its state-of-the-art performance on previously-thought hard\nproblems. However, because of the internal complexity and nonlinear structure\nof deep neural networks, the underlying decision making processes for why these\nmodels are achieving such performance are challenging and sometimes mystifying\nto interpret. As deep learning spreads across domains, it is of paramount\nimportance that we equip users of deep learning with tools for understanding\nwhen a model works correctly, when it fails, and ultimately how to improve its\nperformance. Standardized toolkits for building neural networks have helped\ndemocratize deep learning; visual analytics systems have now been developed to\nsupport model explanation, interpretation, debugging, and improvement. We\npresent a survey of the role of visual analytics in deep learning research,\nwhich highlights its short yet impactful history and thoroughly summarizes the\nstate-of-the-art using a human-centered interrogative framework, focusing on\nthe Five W's and How (Why, Who, What, How, When, and Where). We conclude by\nhighlighting research directions and open research problems. This survey helps\nresearchers and practitioners in both visual analytics and deep learning to\nquickly learn key aspects of this young and rapidly growing body of research,\nwhose impact spans a diverse range of domains.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 20:13:07 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 01:09:33 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 04:59:24 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Hohman", "Fred", ""], ["Kahng", "Minsuk", ""], ["Pienta", "Robert", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1801.06920", "submitter": "Girish Joshi", "authors": "Girish Joshi, Girish Chowdhary", "title": "Cross-Domain Transfer in Reinforcement Learning using Target Apprentice", "comments": "To appear as conference paper in ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new approach to Transfer Learning (TL) in\nReinforcement Learning (RL) for cross-domain tasks. Many of the available\ntechniques approach the transfer architecture as a method of speeding up the\ntarget task learning. We propose to adapt and reuse the mapped source task\noptimal-policy directly in related domains. We show the optimal policy from a\nrelated source task can be near optimal in target domain provided an adaptive\npolicy accounts for the model error between target and source. The main benefit\nof this policy augmentation is generalizing policies across multiple related\ndomains without having to re-learn the new tasks. Our results show that this\narchitecture leads to better sample efficiency in the transfer, reducing sample\ncomplexity of target task learning to target apprentice learning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 00:39:19 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Joshi", "Girish", ""], ["Chowdhary", "Girish", ""]]}, {"id": "1801.06934", "submitter": "Linbo Qiao", "authors": "Linbo Qiao, Tianyi Lin, Qi Qin, Xicheng Lu", "title": "On the Iteration Complexity Analysis of Stochastic Primal-Dual Hybrid\n  Gradient Approach with High Probability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a stochastic Primal-Dual Hybrid Gradient (PDHG)\napproach for solving a wide spectrum of regularized stochastic minimization\nproblems, where the regularization term is composite with a linear function. It\nhas been recognized that solving this kind of problem is challenging since the\nclosed-form solution of the proximal mapping associated with the regularization\nterm is not available due to the imposed linear composition, and the\nper-iteration cost of computing the full gradient of the expected objective\nfunction is extremely high when the number of input data samples is\nconsiderably large.\n  Our new approach overcomes these issues by exploring the special structure of\nthe regularization term and sampling a few data points at each iteration.\nRather than analyzing the convergence in expectation, we provide the detailed\niteration complexity analysis for the cases of both uniformly and non-uniformly\naveraged iterates with high probability. This strongly supports the good\npractical performance of the proposed approach. Numerical experiments\ndemonstrate that the efficiency of stochastic PDHG, which outperforms other\ncompeting algorithms, as expected by the high-probability convergence analysis.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 02:09:20 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 05:14:41 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Qiao", "Linbo", ""], ["Lin", "Tianyi", ""], ["Qin", "Qi", ""], ["Lu", "Xicheng", ""]]}, {"id": "1801.06975", "submitter": "Feng Li", "authors": "Feng Li, Sibo Yang, Huanhuan Huang, and Wei Wu", "title": "Extreme Learning Machine with Local Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the sparsification of the input-hidden weights\nof ELM (Extreme Learning Machine). For ordinary feedforward neural networks,\nthe sparsification is usually done by introducing certain regularization\ntechnique into the learning process of the network. But this strategy can not\nbe applied for ELM, since the input-hidden weights of ELM are supposed to be\nrandomly chosen rather than to be learned. To this end, we propose a modified\nELM, called ELM-LC (ELM with local connections), which is designed for the\nsparsification of the input-hidden weights as follows: The hidden nodes and the\ninput nodes are divided respectively into several corresponding groups, and an\ninput node group is fully connected with its corresponding hidden node group,\nbut is not connected with any other hidden node group. As in the usual ELM, the\nhidden-input weights are randomly given, and the hidden-output weights are\nobtained through a least square learning. In the numerical simulations on some\nbenchmark problems, the new ELM-CL behaves better than the traditional ELM.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 06:54:22 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Li", "Feng", ""], ["Yang", "Sibo", ""], ["Huang", "Huanhuan", ""], ["Wu", "Wei", ""]]}, {"id": "1801.07030", "submitter": "Thomas Nedelec", "authors": "Alexandre Gilotte, Cl\\'ement Calauz\\`enes, Thomas Nedelec, Alexandre\n  Abraham and Simon Doll\\'e", "title": "Offline A/B testing for Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3159652.3159687", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before A/B testing online a new version of a recommender system, it is usual\nto perform some offline evaluations on historical data. We focus on evaluation\nmethods that compute an estimator of the potential uplift in revenue that could\ngenerate this new technology. It helps to iterate faster and to avoid losing\nmoney by detecting poor policies. These estimators are known as counterfactual\nor off-policy estimators. We show that traditional counterfactual estimators\nsuch as capped importance sampling and normalised importance sampling are\nexperimentally not having satisfying bias-variance compromises in the context\nof personalised product recommendation for online advertising. We propose two\nvariants of counterfactual estimates with different modelling of the bias that\nprove to be accurate in real-world conditions. We provide a benchmark of these\nestimators by showing their correlation with business metrics observed by\nrunning online A/B tests on a commercial recommender system.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 10:31:56 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Gilotte", "Alexandre", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""], ["Nedelec", "Thomas", ""], ["Abraham", "Alexandre", ""], ["Doll\u00e9", "Simon", ""]]}, {"id": "1801.07110", "submitter": "Alessandro Betti", "authors": "Alessandro Betti and Marco Gori", "title": "Convolutional Networks in Visual Environments", "comments": "49 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The puzzle of computer vision might find new challenging solutions when we\nrealize that most successful methods are working at image level, which is\nremarkably more difficult than processing directly visual streams. In this\npaper, we claim that their processing naturally leads to formulate the motion\ninvariance principle, which enables the construction of a new theory of\nlearning with convolutional networks. The theory addresses a number of\nintriguing questions that arise in natural vision, and offers a well-posed\ncomputational scheme for the discovery of convolutional filters over the\nretina. They are driven by differential equations derived from the principle of\nleast cognitive action. Unlike traditional convolutional networks, which need\nmassive supervision, the proposed theory offers a truly new scenario in which\nfeature learning takes place by unsupervised processing of video signals. It is\npointed out that an opportune blurring of the video, along the interleaving of\nsegments of null signal, make it possible to conceive a novel learning\nmechanism that yields the minimum of the cognitive action. Basically, while the\ntheory enables the implementation of novel computer vision systems, it is also\nprovides an intriguing explanation of the solution that evolution has\ndiscovered for humans, where it looks like that the video blurring in newborns\nand the day-night rhythm seem to emerge in a general computational framework,\nregardless of biology.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 21:35:40 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1801.07145", "submitter": "Eric Alcaide", "authors": "Eric Alcaide", "title": "E-swish: Adjusting Activations to Different Network Depths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions have a notorious impact on neural networks on both\ntraining and testing the models against the desired problem. Currently, the\nmost used activation function is the Rectified Linear Unit (ReLU). This paper\nintroduces a new and novel activation function, closely related with the new\nactivation $Swish = x * sigmoid(x)$ (Ramachandran et al., 2017) which\ngeneralizes it. We call the new activation $E-swish = \\beta x * sigmoid(x)$. We\nshow that E-swish outperforms many other well-known activations including both\nReLU and Swish. For example, using E-swish provided 1.5% and 4.6% accuracy\nimprovements on Cifar10 and Cifar100 respectively for the WRN 10-2 when\ncompared to ReLU and 0.35% and 0.6% respectively when compared to Swish. The\ncode to reproduce all our experiments can be found at\nhttps://github.com/EricAlcaide/E-swish\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 15:40:29 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Alcaide", "Eric", ""]]}, {"id": "1801.07172", "submitter": "Shotaro Shiba", "authors": "Satoshi Iso, Shotaro Shiba and Sumito Yokoo", "title": "Scale-invariant Feature Extraction of Neural Network and Renormalization\n  Group Flow", "comments": "32 pages, 17 figures", "journal-ref": "Phys. Rev. E 97, 053304 (2018)", "doi": "10.1103/PhysRevE.97.053304", "report-no": "KEK-TH-2029", "categories": "hep-th cond-mat.stat-mech cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical understanding of how deep neural network (DNN) extracts features\nfrom input images is still unclear, but it is widely believed that the\nextraction is performed hierarchically through a process of coarse-graining. It\nreminds us of the basic concept of renormalization group (RG) in statistical\nphysics. In order to explore possible relations between DNN and RG, we use the\nRestricted Boltzmann machine (RBM) applied to Ising model and construct a flow\nof model parameters (in particular, temperature) generated by the RBM. We show\nthat the unsupervised RBM trained by spin configurations at various\ntemperatures from $T=0$ to $T=6$ generates a flow along which the temperature\napproaches the critical value $T_c=2.27$. This behavior is opposite to the\ntypical RG flow of the Ising model. By analyzing various properties of the\nweight matrices of the trained RBM, we discuss why it flows towards $T_c$ and\nhow the RBM learns to extract features of spin configurations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:18:04 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Iso", "Satoshi", ""], ["Shiba", "Shotaro", ""], ["Yokoo", "Sumito", ""]]}, {"id": "1801.07175", "submitter": "Zhitao Gong", "authors": "Zhitao Gong and Wenlu Wang and Bo Li and Dawn Song and Wei-Shinn Ku", "title": "Adversarial Texts with Gradient Methods", "comments": "This work lacks some crucial details. After careful discussion, we\n  decided to withdraw it temporarily and resubmit a full version afterward", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adversarial samples for images have been extensively studied in the\nliterature. Among many of the attacking methods, gradient-based methods are\nboth effective and easy to compute. In this work, we propose a framework to\nadapt the gradient attacking methods on images to text domain. The main\ndifficulties for generating adversarial texts with gradient methods are i) the\ninput space is discrete, which makes it difficult to accumulate small noise\ndirectly in the inputs, and ii) the measurement of the quality of the\nadversarial texts is difficult. We tackle the first problem by searching for\nadversarials in the embedding space and then reconstruct the adversarial texts\nvia nearest neighbor search. For the latter problem, we employ the Word Mover's\nDistance (WMD) to quantify the quality of adversarial texts. Through extensive\nexperiments on three datasets, IMDB movie reviews, Reuters-2 and Reuters-5\nnewswires, we show that our framework can leverage gradient attacking methods\nto generate very high-quality adversarial texts that are only a few words\ndifferent from the original texts. There are many cases where we can change one\nword to alter the label of the whole piece of text. We successfully incorporate\nFGM and DeepFool into our framework. In addition, we empirically show that WMD\nis closely related to the quality of adversarial texts.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:19:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 19:54:27 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Gong", "Zhitao", ""], ["Wang", "Wenlu", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""], ["Ku", "Wei-Shinn", ""]]}, {"id": "1801.07194", "submitter": "Davide Falessi", "authors": "Sean Bayley, Davide Falessi", "title": "Optimizing Prediction Intervals by Tuning Random Forest via\n  Meta-Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that tuning prediction models increases prediction\naccuracy and that Random Forest can be used to construct prediction intervals.\nHowever, to our best knowledge, no study has investigated the need to, and the\nmanner in which one can, tune Random Forest for optimizing prediction intervals\n{ this paper aims to fill this gap. We explore a tuning approach that combines\nan effectively exhaustive search with a validation technique on a single Random\nForest parameter. This paper investigates which, out of eight validation\ntechniques, are beneficial for tuning, i.e., which automatically choose a\nRandom Forest configuration constructing prediction intervals that are reliable\nand with a smaller width than the default configuration. Additionally, we\npresent and validate three meta-validation techniques to determine which are\nbeneficial, i.e., those which automatically chose a beneficial validation\ntechnique. This study uses data from our industrial partner (Keymind Inc.) and\nthe Tukutuku Research Project, related to post-release defect prediction and\nWeb application effort estimation, respectively. Results from our study\nindicate that: i) the default configuration is frequently unreliable, ii) most\nof the validation techniques, including previously successfully adopted ones\nsuch as 50/50 holdout and bootstrap, are counterproductive in most of the\ncases, and iii) the 75/25 holdout meta-validation technique is always\nbeneficial; i.e., it avoids the likely counterproductive effects of validation\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 17:05:20 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Bayley", "Sean", ""], ["Falessi", "Davide", ""]]}, {"id": "1801.07198", "submitter": "Chichen Fu", "authors": "Chichen Fu and Soonam Lee and David Joon Ho and Shuo Han and Paul\n  Salama and Kenneth W. Dunn and Edward J. Delp", "title": "Three Dimensional Fluorescence Microscopy Image Synthesis and\n  Segmentation", "comments": "Accepted by CVPR Workshop on Computer Vision for Microscopy Image\n  Analysis (CVMI)", "journal-ref": null, "doi": "10.1109/CVPRW.2018.00298", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in fluorescence microscopy enable acquisition of 3D image volumes\nwith better image quality and deeper penetration into tissue. Segmentation is a\nrequired step to characterize and analyze biological structures in the images\nand recent 3D segmentation using deep learning has achieved promising results.\nOne issue is that deep learning techniques require a large set of groundtruth\ndata which is impractical to annotate manually for large 3D microscopy volumes.\nThis paper describes a 3D deep learning nuclei segmentation method using\nsynthetic 3D volumes for training. A set of synthetic volumes and the\ncorresponding groundtruth are generated using spatially constrained\ncycle-consistent adversarial networks. Segmentation results demonstrate that\nour proposed method is capable of segmenting nuclei successfully for various\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 17:08:13 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 03:46:50 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Fu", "Chichen", ""], ["Lee", "Soonam", ""], ["Ho", "David Joon", ""], ["Han", "Shuo", ""], ["Salama", "Paul", ""], ["Dunn", "Kenneth W.", ""], ["Delp", "Edward J.", ""]]}, {"id": "1801.07222", "submitter": "Louis Faury", "authors": "Louis Faury, Flavian Vasile", "title": "Rover Descent: Learning to optimize by learning to navigate on\n  prototypical loss surfaces", "comments": "17 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to optimize - the idea that we can learn from data algorithms that\noptimize a numerical criterion - has recently been at the heart of a growing\nnumber of research efforts. One of the most challenging issues within this\napproach is to learn a policy that is able to optimize over classes of\nfunctions that are fairly different from the ones that it was trained on. We\npropose a novel way of framing learning to optimize as a problem of learning a\ngood navigation policy on a partially observable loss surface. To this end, we\ndevelop Rover Descent, a solution that allows us to learn a fairly broad\noptimization policy from training on a small set of prototypical\ntwo-dimensional surfaces that encompasses the classically hard cases such as\nvalleys, plateaus, cliffs and saddles and by using strictly zero-order\ninformation. We show that, without having access to gradient or curvature\ninformation, we achieve state-of-the-art convergence speed on optimization\nproblems not presented at training time such as the Rosenbrock function and\nother hard cases in two dimensions. We extend our framework to optimize over\nhigh dimensional landscapes, while still handling only two-dimensional local\nlandscape information and show good preliminary results.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 18:13:46 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 10:17:04 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 14:34:19 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Faury", "Louis", ""], ["Vasile", "Flavian", ""]]}, {"id": "1801.07226", "submitter": "Junhong Lin", "authors": "Junhong Lin and Volkan Cevher", "title": "Optimal Convergence for Distributed Learning with Stochastic Gradient\n  Methods and Spectral Algorithms", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.FA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generalization properties of distributed algorithms in the setting\nof nonparametric regression over a reproducing kernel Hilbert space (RKHS). We\nfirst investigate distributed stochastic gradient methods (SGM), with\nmini-batches and multi-passes over the data. We show that optimal\ngeneralization error bounds can be retained for distributed SGM provided that\nthe partition level is not too large. We then extend our results to\nspectral-regularization algorithms (SRA), including kernel ridge regression\n(KRR), kernel principal component analysis, and gradient methods. Our results\nare superior to the state-of-the-art theory. Particularly, our results show\nthat distributed SGM has a smaller theoretical computational complexity,\ncompared with distributed KRR and classic SGM. Moreover, even for\nnon-distributed SRA, they provide the first optimal, capacity-dependent\nconvergence rates, considering the case that the regression function may not be\nin the RKHS.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 18:14:11 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 15:21:59 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lin", "Junhong", ""], ["Cevher", "Volkan", ""]]}, {"id": "1801.07292", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Byron Boots", "title": "Convergence of Value Aggregation for Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value aggregation is a general framework for solving imitation learning\nproblems. Based on the idea of data aggregation, it generates a policy sequence\nby iteratively interleaving policy optimization and evaluation in an online\nlearning setting. While the existence of a good policy in the policy sequence\ncan be guaranteed non-asymptotically, little is known about the convergence of\nthe sequence or the performance of the last policy. In this paper, we debunk\nthe common belief that value aggregation always produces a convergent policy\nsequence with improving performance. Moreover, we identify a critical stability\ncondition for convergence and provide a tight non-asymptotic bound on the\nperformance of the last policy. These new theoretical insights let us stabilize\nproblems with regularization, which removes the inconvenient process of\nidentifying the best policy in the policy sequence in stochastic problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 19:47:34 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Cheng", "Ching-An", ""], ["Boots", "Byron", ""]]}, {"id": "1801.07299", "submitter": "Yibo Li", "authors": "Yibo Li, Liangren Zhang, Zhenming Liu", "title": "Multi-Objective De Novo Drug Design with Conditional Graph Generative\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep generative models have revealed itself as a promising way of\nperforming de novo molecule design. However, previous research has focused\nmainly on generating SMILES strings instead of molecular graphs. Although\ncurrent graph generative models are available, they are often too general and\ncomputationally expensive, which restricts their application to molecules with\nsmall sizes. In this work, a new de novo molecular design framework is proposed\nbased on a type sequential graph generators that do not use atom level\nrecurrent units. Compared with previous graph generative models, the proposed\nmethod is much more tuned for molecule generation and have been scaled up to\ncover significantly larger molecules in the ChEMBL database. It is shown that\nthe graph-based model outperforms SMILES based models in a variety of metrics,\nespecially in the rate of valid outputs. For the application of drug design\ntasks, conditional graph generative model is employed. This method offers\nhigher flexibility compared to previous fine-tuning based approach and is\nsuitable for generation based on multiple objectives. This approach is applied\nto solve several drug design problems, including the generation of compounds\ncontaining a given scaffold, generation of compounds with specific\ndrug-likeness and synthetic accessibility requirements, as well as generating\ndual inhibitors against JNK3 and GSK3$\\beta$. Results show high enrichment\nrates for outputs satisfying the given requirements.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 13:54:55 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 03:50:40 GMT"}, {"version": "v3", "created": "Sat, 21 Apr 2018 15:36:33 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Li", "Yibo", ""], ["Zhang", "Liangren", ""], ["Liu", "Zhenming", ""]]}, {"id": "1801.07316", "submitter": "Robert Kosar", "authors": "Robert Kosar and David W. Scott", "title": "The Hybrid Bootstrap: A Drop-in Replacement for Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is an important component of predictive model building. The\nhybrid bootstrap is a regularization technique that functions similarly to\ndropout except that features are resampled from other training points rather\nthan replaced with zeros. We show that the hybrid bootstrap offers superior\nperformance to dropout. We also present a sampling based technique to simplify\nhyperparameter choice. Next, we provide an alternative sampling technique for\nconvolutional neural networks. Finally, we demonstrate the efficacy of the\nhybrid bootstrap on non-image tasks using tree-based models.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 20:50:26 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Kosar", "Robert", ""], ["Scott", "David W.", ""]]}, {"id": "1801.07330", "submitter": "Hao Zhang", "authors": "Hao Zhang (1), Xinlin Xie (1), Chunyu Fang (1), Yicong Yang (1), Di\n  Jin (2) and Peng Fei (1 and 3) ((1) School of Optical and Electronic\n  Informaiton, Huazhong University of Science and Technology, Wuhan, China, (2)\n  Computer Science and Artificial Intelligence Laboratory, Massachusetts\n  Institute of Technology, Cambridge, U.S.A., (3) Britton Chance Center for\n  Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong\n  University of Science and Technology, Wuhan, China)", "title": "High-throughput, high-resolution registration-free generated adversarial\n  network microscopy", "comments": "21 pages, 9 figures and 1 table. Peng Fe and Di Jin conceived the\n  ides, initiated the investigation. Hao Zhang, Di Jin and Peng Fei prepared\n  the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP physics.optics q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine generative adversarial network (GAN) with light microscopy to\nachieve deep learning super-resolution under a large field of view (FOV). By\nappropriately adopting prior microscopy data in an adversarial training, the\nneural network can recover a high-resolution, accurate image of new specimen\nfrom its single low-resolution measurement. Its capacity has been broadly\ndemonstrated via imaging various types of samples, such as USAF resolution\ntarget, human pathological slides, fluorescence-labelled fibroblast cells, and\ndeep tissues in transgenic mouse brain, by both wide-field and light-sheet\nmicroscopes. The gigapixel, multi-color reconstruction of these samples\nverifies a successful GAN-based single image super-resolution procedure. We\nalso propose an image degrading model to generate low resolution images for\ntraining, making our approach free from the complex image registration during\ntraining dataset preparation. After a welltrained network being created, this\ndeep learning-based imaging approach is capable of recovering a large FOV (~95\nmm2), high-resolution (~1.7 {\\mu}m) image at high speed (within 1 second),\nwhile not necessarily introducing any changes to the setup of existing\nmicroscopes.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 09:47:48 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 07:39:45 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Zhang", "Hao", "", "1 and 3"], ["Xie", "Xinlin", "", "1 and 3"], ["Fang", "Chunyu", "", "1 and 3"], ["Yang", "Yicong", "", "1 and 3"], ["Jin", "Di", "", "1 and 3"], ["Fei", "Peng", "", "1 and 3"]]}, {"id": "1801.07353", "submitter": "Hokchhay Tann", "authors": "Hokchhay Tann, Soheil Hashemi, Sherief Reda", "title": "Flexible Deep Neural Network Processing", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of Deep Neural Networks (DNNs) has drastically improved\nthe state of the art for many application domains. While achieving high\naccuracy performance, deploying state-of-the-art DNNs is a challenge since they\ntypically require billions of expensive arithmetic computations. In addition,\nDNNs are typically deployed in ensemble to boost accuracy performance, which\nfurther exacerbates the system requirements. This computational overhead is an\nissue for many platforms, e.g. data centers and embedded systems, with tight\nlatency and energy budgets. In this article, we introduce flexible DNNs\nensemble processing technique, which achieves large reduction in average\ninference latency while incurring small to negligible accuracy drop. Our\ntechnique is flexible in that it allows for dynamic adaptation between quality\nof results (QoR) and execution runtime. We demonstrate the effectiveness of the\ntechnique on AlexNet and ResNet-50 using the ImageNet dataset. This technique\ncan also easily handle other types of networks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 00:02:57 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Tann", "Hokchhay", ""], ["Hashemi", "Soheil", ""], ["Reda", "Sherief", ""]]}, {"id": "1801.07379", "submitter": "Donghua Jiang", "authors": "Liang Xiao, Donghua Jiang, Dongjin Xu, Ning An", "title": "Secure Mobile Crowdsensing with Deep Learning", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to stimulate secure sensing for Internet of Things (IoT)\napplications such as healthcare and traffic monitoring, mobile crowdsensing\n(MCS) systems have to address security threats, such as jamming, spoofing and\nfaked sensing attacks, during both the sensing and the information exchange\nprocesses in large-scale dynamic and heterogenous networks. In this article, we\ninvestigate secure mobile crowdsensing and present how to use deep learning\n(DL) methods such as stacked autoencoder (SAE), deep neural network (DNN), and\nconvolutional neural network (CNN) to improve the MCS security approaches\nincluding authentication, privacy protection, faked sensing countermeasures,\nintrusion detection and anti-jamming transmissions in MCS. We discuss the\nperformance gain of these DL-based approaches compared with traditional\nsecurity schemes and identify the challenges that need to be addressed to\nimplement them in practical MCS systems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 02:57:12 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Xiao", "Liang", ""], ["Jiang", "Donghua", ""], ["Xu", "Dongjin", ""], ["An", "Ning", ""]]}, {"id": "1801.07384", "submitter": "Hugh Chen", "authors": "Hugh Chen, Scott Lundberg, Su-In Lee", "title": "Hybrid Gradient Boosting Trees and Neural Networks for Forecasting\n  Operating Room Data", "comments": "Presented at Machine Learning for Health Workshop: 31st Conference on\n  Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data constitutes a distinct and growing problem in machine\nlearning. As the corpus of time series data grows larger, deep models that\nsimultaneously learn features and classify with these features can be\nintractable or suboptimal. In this paper, we present feature learning via long\nshort term memory (LSTM) networks and prediction via gradient boosting trees\n(XGB). Focusing on the consequential setting of electronic health record data,\nwe predict the occurrence of hypoxemia five minutes into the future based on\npast features. We make two observations: 1) long short term memory networks are\neffective at capturing long term dependencies based on a single feature and 2)\ngradient boosting trees are capable of tractably combining a large number of\nfeatures including static features like height and weight. With these\nobservations in mind, we generate features by performing \"supervised\"\nrepresentation learning with LSTM networks. Augmenting the original XGB model\nwith these features gives significantly better performance than either\nindividual method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 03:18:14 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 02:11:40 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Chen", "Hugh", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "1801.07386", "submitter": "Cameron Musco", "authors": "Jeremy G. Hoskins and Cameron Musco and Christopher Musco and\n  Charalampos E. Tsourakakis", "title": "Learning Networks from Random Walk-Based Node Similarities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital presence in the world of online social media entails significant\nprivacy risks. In this work we consider a privacy threat to a social network in\nwhich an attacker has access to a subset of random walk-based node\nsimilarities, such as effective resistances (i.e., commute times) or\npersonalized PageRank scores. Using these similarities, the attacker's goal is\nto infer as much information as possible about the underlying network,\nincluding any remaining unknown pairwise node similarities and edges.\n  For the effective resistance metric, we show that with just a small subset of\nmeasurements, the attacker can learn a large fraction of edges in a social\nnetwork, even when the measurements are noisy. We also show that it is possible\nto learn a graph which accurately matches the underlying network on all other\neffective resistances. This second observation is interesting from a data\nmining perspective, since it can be expensive to accurately compute all\neffective resistances. As an alternative, our graphs learned from just a subset\nof approximate effective resistances can be used as surrogates in a wide range\nof applications that use effective resistances to probe graph structure,\nincluding for graph clustering, node centrality evaluation, and anomaly\ndetection.\n  We obtain our results by formalizing the graph learning objective\nmathematically, using two optimization problems. One formulation is convex and\ncan be solved provably in polynomial time. The other is not, but we solve it\nefficiently with projected gradient and coordinate descent. We demonstrate the\neffectiveness of these methods on a number of social networks obtained from\nFacebook. We also discuss how our methods can be generalized to other random\nwalk-based similarities, such as personalized PageRank. Our code is available\nat https://github.com/cnmusco/graph-similarity-learning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 03:22:57 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Hoskins", "Jeremy G.", ""], ["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1801.07426", "submitter": "Chunna Li", "authors": "Chun-Na Li, Yuan-Hai Shao, Wei-Jie Chen, Zhen Wang and Nai-Yang Deng", "title": "Generalized two-dimensional linear discriminant analysis with\n  regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances show that two-dimensional linear discriminant analysis\n(2DLDA) is a successful matrix based dimensionality reduction method. However,\n2DLDA may encounter the singularity issue theoretically and the sensitivity to\noutliers. In this paper, a generalized Lp-norm 2DLDA framework with\nregularization for an arbitrary $p>0$ is proposed, named G2DLDA. There are\nmainly two contributions of G2DLDA: one is G2DLDA model uses an arbitrary\nLp-norm to measure the between-class and within-class scatter, and hence a\nproper $p$ can be selected to achieve the robustness. The other one is that by\nintroducing an extra regularization term, G2DLDA achieves better generalization\nperformance, and solves the singularity problem. In addition, G2DLDA can be\nsolved through a series of convex problems with equality constraint, and it has\nclosed solution for each single problem. Its convergence can be guaranteed\ntheoretically when $1\\leq p\\leq2$. Preliminary experimental results on three\ncontaminated human face databases show the effectiveness of the proposed\nG2DLDA.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 08:03:25 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 00:45:27 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Li", "Chun-Na", ""], ["Shao", "Yuan-Hai", ""], ["Chen", "Wei-Jie", ""], ["Wang", "Zhen", ""], ["Deng", "Nai-Yang", ""]]}, {"id": "1801.07579", "submitter": "Xuejin Wen", "authors": "Xuejin Wen", "title": "A Work Zone Simulation Model for Travel Time Prediction in a Connected\n  Vehicle Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A work zone bottleneck in a roadway network can cause traffic delays,\nemissions and safety issues. Accurate measurement and prediction of work zone\ntravel time can help travelers make better routing decisions and therefore\nmitigate its impact. Historically, data used for travel time analyses comes\nfrom fixed loop detectors, which are expensive to install and maintain. With\nconnected vehicle technology, such as Vehicle-to-Infrastructure, portable\nroadside unit (RSU) can be located in and around a work zone segment to\ncommunicate with the vehicles and collect traffic data. A PARAMICS simulation\nmodel for a prototypical freeway work zone in a connected vehicle environment\nwas built to test this idea using traffic demand data from NY State Route 104.\nFor the simulation, twelve RSUs were placed along the work zone segment and\nsixteen variables were extracted from the simulation results to explore travel\ntime estimation and prediction. For the travel time analysis, four types of\nmodels were constructed, including linear regression, multivariate adaptive\nregression splines (MARS), stepwise regression and elastic net. The results\nshow that the modeling approaches under consideration have similar performance\nin terms of the Root of Mean Square Error (RMSE), which provides an opportunity\nfor model selection based on additional factors including the number and\nlocations of the RSUs according to the significant variables identified in the\nvarious models. Among the four approaches, the stepwise regression model only\nneeds variables from two RSUs: one placed sufficiently upstream of the work\nzone and one at the end of the work zone.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 01:27:45 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Wen", "Xuejin", ""]]}, {"id": "1801.07593", "submitter": "Margaret Mitchell", "authors": "Brian Hu Zhang, Blake Lemoine, Margaret Mitchell", "title": "Mitigating Unwanted Biases with Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a tool for building models that accurately represent\ninput training data. When undesired biases concerning demographic groups are in\nthe training data, well-trained models will reflect those biases. We present a\nframework for mitigating such biases by including a variable for the group of\ninterest and simultaneously learning a predictor and an adversary. The input to\nthe network X, here text or census data, produces a prediction Y, such as an\nanalogy completion or income bracket, while the adversary tries to model a\nprotected variable Z, here gender or zip code.\n  The objective is to maximize the predictor's ability to predict Y while\nminimizing the adversary's ability to predict Z. Applied to analogy completion,\nthis method results in accurate predictions that exhibit less evidence of\nstereotyping Z. When applied to a classification task using the UCI Adult\n(Census) Dataset, it results in a predictive model that does not lose much\naccuracy while achieving very close to equality of odds (Hardt, et al., 2016).\nThe method is flexible and applicable to multiple definitions of fairness as\nwell as a wide range of gradient-based learning models, including both\nregression and classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 06:45:23 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Zhang", "Brian Hu", ""], ["Lemoine", "Blake", ""], ["Mitchell", "Margaret", ""]]}, {"id": "1801.07599", "submitter": "Sibo Yang", "authors": "Sibo Yang, Chao Zhang, and Wei Wu", "title": "Binary output layer of feedforward neural networks for solving\n  multi-class classification problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Considered in this short note is the design of output layer nodes of\nfeedforward neural networks for solving multi-class classification problems\nwith r (bigger than or equal to 3) classes of samples. The common and\nconventional setting of output layer, called \"one-to-one approach\" in this\npaper, is as follows: The output layer contains r output nodes corresponding to\nthe r classes. And for an input sample of the i-th class, the ideal output is 1\nfor the i-th output node, and 0 for all the other output nodes. We propose in\nthis paper a new \"binary approach\": Suppose r is (2^(q minus 1), 2^q] with q\nbigger than or equal to 2, then we let the output layer contain q output nodes,\nand let the ideal outputs for the r classes be designed in a binary manner.\nNumerical experiments carried out in this paper show that our binary approach\ndoes equally good job as, but uses less output nodes than, the traditional\none-to-one approach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 09:48:18 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Yang", "Sibo", ""], ["Zhang", "Chao", ""], ["Wu", "Wei", ""]]}, {"id": "1801.07606", "submitter": "Qimai Li", "authors": "Qimai Li, Zhichao Han, Xiao-Ming Wu", "title": "Deeper Insights into Graph Convolutional Networks for Semi-Supervised\n  Learning", "comments": "AAAI-2018 Oral Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting problems in machine learning are being revisited with new\ndeep learning tools. For graph-based semisupervised learning, a recent\nimportant development is graph convolutional networks (GCNs), which nicely\nintegrate local vertex features and graph topology in the convolutional layers.\nAlthough the GCN model compares favorably with other state-of-the-art methods,\nits mechanisms are not clear and it still requires a considerable amount of\nlabeled data for validation and model selection. In this paper, we develop\ndeeper insights into the GCN model and address its fundamental limits. First,\nwe show that the graph convolution of the GCN model is actually a special form\nof Laplacian smoothing, which is the key reason why GCNs work, but it also\nbrings potential concerns of over-smoothing with many convolutional layers.\nSecond, to overcome the limits of the GCN model with shallow architectures, we\npropose both co-training and self-training approaches to train GCNs. Our\napproaches significantly improve GCNs in learning with very few labels, and\nexempt them from requiring additional labels for validation. Extensive\nexperiments on benchmarks have verified our theory and proposals.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 15:24:24 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Li", "Qimai", ""], ["Han", "Zhichao", ""], ["Wu", "Xiao-Ming", ""]]}, {"id": "1801.07648", "submitter": "Elie Aljalbout", "authors": "Elie Aljalbout, Vladimir Golkov, Yawar Siddiqui, Maximilian Strobel,\n  Daniel Cremers", "title": "Clustering with Deep Learning: Taxonomy and New Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering methods based on deep neural networks have proven promising for\nclustering real-world data because of their high representational power. In\nthis paper, we propose a systematic taxonomy of clustering methods that utilize\ndeep neural networks. We base our taxonomy on a comprehensive review of recent\nwork and validate the taxonomy in a case study. In this case study, we show\nthat the taxonomy enables researchers and practitioners to systematically\ncreate new clustering methods by selectively recombining and replacing distinct\naspects of previous methods with the goal of overcoming their individual\nlimitations. The experimental evaluation confirms this and shows that the\nmethod created for the case study achieves state-of-the-art clustering quality\nand surpasses it in some cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:41:03 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 19:41:22 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Aljalbout", "Elie", ""], ["Golkov", "Vladimir", ""], ["Siddiqui", "Yawar", ""], ["Strobel", "Maximilian", ""], ["Cremers", "Daniel", ""]]}, {"id": "1801.07650", "submitter": "Shinichi Shirakawa", "authors": "Shinichi Shirakawa, Yasushi Iwata, Youhei Akimoto", "title": "Dynamic Optimization of Neural Network Structures Using Probabilistic\n  Modeling", "comments": "To appear in the Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18), 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful machine learning models and have\nsucceeded in various artificial intelligence tasks. Although various\narchitectures and modules for the DNNs have been proposed, selecting and\ndesigning the appropriate network structure for a target problem is a\nchallenging task. In this paper, we propose a method to simultaneously optimize\nthe network structure and weight parameters during neural network training. We\nconsider a probability distribution that generates network structures, and\noptimize the parameters of the distribution instead of directly optimizing the\nnetwork structure. The proposed method can apply to the various network\nstructure optimization problems under the same framework. We apply the proposed\nmethod to several structure optimization problems such as selection of layers,\nselection of unit types, and selection of connections using the MNIST,\nCIFAR-10, and CIFAR-100 datasets. The experimental results show that the\nproposed method can find the appropriate and competitive network structures.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:43:59 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Shirakawa", "Shinichi", ""], ["Iwata", "Yasushi", ""], ["Akimoto", "Youhei", ""]]}, {"id": "1801.07654", "submitter": "Pablo Barros", "authors": "Pablo Barros, German I. Parisi, Di Fu, Xun Liu, and Stefan Wermter", "title": "Expectation Learning for Adaptive Crossmodal Stimuli Association", "comments": "3 pages 2017 EUCog meeting abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The human brain is able to learn, generalize, and predict crossmodal stimuli.\nLearning by expectation fine-tunes crossmodal processing at different levels,\nthus enhancing our power of generalization and adaptation in highly dynamic\nenvironments. In this paper, we propose a deep neural architecture trained by\nusing expectation learning accounting for unsupervised learning tasks. Our\nlearning model exhibits a self-adaptable behavior, setting the first steps\ntowards the development of deep learning architectures for crossmodal stimuli\nassociation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:47:32 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Barros", "Pablo", ""], ["Parisi", "German I.", ""], ["Fu", "Di", ""], ["Liu", "Xun", ""], ["Wermter", "Stefan", ""]]}, {"id": "1801.07668", "submitter": "Ivo Gon\\c{c}alves", "authors": "Mauro Castelli, Ivo Gon\\c{c}alves, Luca Manzoni, Leonardo Vanneschi", "title": "Pruning Techniques for Mixed Ensembles of Genetic Programming Models", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-77553-1_4", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to define an effective strategy for building\nan ensemble of Genetic Programming (GP) models. Ensemble methods are widely\nused in machine learning due to their features: they average out biases, they\nreduce the variance and they usually generalize better than single models.\nDespite these advantages, building ensemble of GP models is not a\nwell-developed topic in the evolutionary computation community. To fill this\ngap, we propose a strategy that blends individuals produced by standard\nsyntax-based GP and individuals produced by geometric semantic genetic\nprogramming, one of the newest semantics-based method developed in GP. In fact,\nrecent literature showed that combining syntax and semantics could improve the\ngeneralization ability of a GP model. Additionally, to improve the diversity of\nthe GP models used to build up the ensemble, we propose different pruning\ncriteria that are based on correlation and entropy, a commonly used measure in\ninformation theory. Experimental results,obtained over different complex\nproblems, suggest that the pruning criteria based on correlation and entropy\ncould be effective in improving the generalization ability of the ensemble\nmodel and in reducing the computational burden required to build it.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 17:29:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Castelli", "Mauro", ""], ["Gon\u00e7alves", "Ivo", ""], ["Manzoni", "Luca", ""], ["Vanneschi", "Leonardo", ""]]}, {"id": "1801.07674", "submitter": "James Davis", "authors": "James W. Davis, Christopher Menart, Muhammad Akbar, Roman Ilin", "title": "A Classification Refinement Strategy for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the observation that semantic segmentation errors are partially\npredictable, we propose a compact formulation using confusion statistics of the\ntrained classifier to refine (re-estimate) the initial pixel label hypotheses.\nThe proposed strategy is contingent upon computing the classifier confusion\nprobabilities for a given dataset and estimating a relevant prior on the object\nclasses present in the image to be classified. We provide a procedure to\nrobustly estimate the confusion probabilities and explore multiple prior\ndefinitions. Experiments are shown comparing performances on multiple\nchallenging datasets using different priors to improve a state-of-the-art\nsemantic segmentation classifier. This study demonstrates the potential to\nsignificantly improve semantic labeling and motivates future work for reliable\nlabel prior estimation from images.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 17:45:54 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Davis", "James W.", ""], ["Menart", "Christopher", ""], ["Akbar", "Muhammad", ""], ["Ilin", "Roman", ""]]}, {"id": "1801.07691", "submitter": "Junfeng Liu", "authors": "Yicheng He, Junfeng Liu and Xia Ning", "title": "Drug Selection via Joint Push and Learning to Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting the right drugs for the right patients is a primary goal of\nprecision medicine. In this manuscript, we consider the problem of cancer drug\nselection in a learning-to-rank framework. We have formulated the cancer drug\nselection problem as to accurately predicting 1). the ranking positions of\nsensitive drugs and 2). the ranking orders among sensitive drugs in cancer cell\nlines based on their responses to cancer drugs. We have developed a new\nlearning-to-rank method, denoted as pLETORg , that predicts drug ranking\nstructures in each cell line via using drug latent vectors and cell line latent\nvectors. The pLETORg method learns such latent vectors through explicitly\nenforcing that, in the drug ranking list of each cell line, the sensitive drugs\nare pushed above insensitive drugs, and meanwhile the ranking orders among\nsensitive drugs are correct. Genomics information on cell lines is leveraged in\nlearning the latent vectors. Our experimental results on a benchmark cell\nline-drug response dataset demonstrate that the new pLETORg significantly\noutperforms the state-of-the-art method in prioritizing new sensitive drugs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 18:26:54 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 22:50:38 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["He", "Yicheng", ""], ["Liu", "Junfeng", ""], ["Ning", "Xia", ""]]}, {"id": "1801.07693", "submitter": "Ifigeneia Apostolopoulou Ms", "authors": "Ifigeneia Apostolopoulou and Diana Marculescu", "title": "Tractable Learning and Inference for Large-Scale Probabilistic Boolean\n  Networks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Boolean Networks (PBNs) have been previously proposed so as to\ngain insights into complex dy- namical systems. However, identification of\nlarge networks and of the underlying discrete Markov Chain which describes\ntheir temporal evolution, still remains a challenge. In this paper, we\nintroduce an equivalent representation for the PBN, the Stochastic Conjunctive\nNormal Form (SCNF), which paves the way to a scalable learning algorithm and\nhelps predict long- run dynamic behavior of large-scale systems. Moreover, SCNF\nallows its efficient sampling so as to statistically infer multi- step\ntransition probabilities which can provide knowledge on the activity levels of\nindividual nodes in the long run.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 18:28:22 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Apostolopoulou", "Ifigeneia", ""], ["Marculescu", "Diana", ""]]}, {"id": "1801.07710", "submitter": "Vikram Mullachery", "authors": "Vikram Mullachery, Aniruddh Khera, Amir Husain", "title": "Bayesian Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1111.4246 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes and discusses Bayesian Neural Network (BNN). The paper\nshowcases a few different applications of them for classification and\nregression problems. BNNs are comprised of a Probabilistic Model and a Neural\nNetwork. The intent of such a design is to combine the strengths of Neural\nNetworks and Stochastic modeling. Neural Networks exhibit continuous function\napproximator capabilities. Stochastic models allow direct specification of a\nmodel with known interaction between parameters to generate data. During the\nprediction phase, stochastic models generate a complete posterior distribution\nand produce probabilistic guarantees on the predictions. Thus BNNs are a unique\ncombination of neural network and stochastic models with the stochastic model\nforming the core of this integration. BNNs can then produce probabilistic\nguarantees on it's predictions and also generate the distribution of parameters\nthat it has learnt from the observations. That means, in the parameter space,\none can deduce the nature and shape of the neural network's learnt parameters.\nThese two characteristics makes them highly attractive to theoreticians as well\nas practitioners. Recently there has been a lot of activity in this area, with\nthe advent of numerous probabilistic programming libraries such as: PyMC3,\nEdward, Stan etc. Further this area is rapidly gaining ground as a standard\nmachine learning approach for numerous problems\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 20:52:44 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 15:30:26 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Mullachery", "Vikram", ""], ["Khera", "Aniruddh", ""], ["Husain", "Amir", ""]]}, {"id": "1801.07736", "submitter": "William Fedus", "authors": "William Fedus, Ian Goodfellow and Andrew M. Dai", "title": "MaskGAN: Better Text Generation via Filling in the______", "comments": "16 pages, ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation models are often autoregressive language models or\nseq2seq models. These models generate text by sampling words sequentially, with\neach word conditioned on the previous word, and are state-of-the-art for\nseveral machine translation and summarization benchmarks. These benchmarks are\noften defined by validation perplexity even though this is not a direct measure\nof the quality of the generated text. Additionally, these models are typically\ntrained via maxi- mum likelihood and teacher forcing. These methods are\nwell-suited to optimizing perplexity but can result in poor sample quality\nsince generating text requires conditioning on sequences of words that may have\nnever been observed at training time. We propose to improve sample quality\nusing Generative Adversarial Networks (GANs), which explicitly train the\ngenerator to produce high quality samples and have shown a lot of success in\nimage generation. GANs were originally designed to output differentiable\nvalues, so discrete language generation is challenging for them. We claim that\nvalidation perplexity alone is not indicative of the quality of text generated\nby a model. We introduce an actor-critic conditional GAN that fills in missing\ntext conditioned on the surrounding context. We show qualitatively and\nquantitatively, evidence that this produces more realistic conditional and\nunconditional text samples compared to a maximum likelihood trained model.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 19:22:21 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 16:26:04 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 15:30:09 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Fedus", "William", ""], ["Goodfellow", "Ian", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1801.07756", "submitter": "Ulysse C\\^ot\\'e-Allard", "authors": "Ulysse C\\^ot\\'e-Allard, Cheikh Latyr Fall, Alexandre Drouin, Alexandre\n  Campeau-Lecours, Cl\\'ement Gosselin, Kyrre Glette, Fran\\c{c}ois Laviolette,\n  Benoit Gosselin", "title": "Deep Learning for Electromyographic Hand Gesture Signal Classification\n  Using Transfer Learning", "comments": "Source code and datasets available:\n  https://github.com/Giguelingueling/MyoArmbandDataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning algorithms have become increasingly more\nprominent for their unparalleled ability to automatically learn discriminant\nfeatures from large amounts of data. However, within the field of\nelectromyography-based gesture recognition, deep learning algorithms are seldom\nemployed as they require an unreasonable amount of effort from a single person,\nto generate tens of thousands of examples.\n  This work's hypothesis is that general, informative features can be learned\nfrom the large amounts of data generated by aggregating the signals of multiple\nusers, thus reducing the recording burden while enhancing gesture recognition.\nConsequently, this paper proposes applying transfer learning on aggregated data\nfrom multiple users, while leveraging the capacity of deep learning algorithms\nto learn discriminant features from large datasets. Two datasets comprised of\n19 and 17 able-bodied participants respectively (the first one is employed for\npre-training) were recorded for this work, using the Myo Armband. A third Myo\nArmband dataset was taken from the NinaPro database and is comprised of 10\nable-bodied participants. Three different deep learning networks employing\nthree different modalities as input (raw EMG, Spectrograms and Continuous\nWavelet Transform (CWT)) are tested on the second and third dataset. The\nproposed transfer learning scheme is shown to systematically and significantly\nenhance the performance for all three networks on the two datasets, achieving\nan offline accuracy of 98.31% for 7 gestures over 17 participants for the\nCWT-based ConvNet and 68.98% for 18 gestures over 10 participants for the raw\nEMG-based ConvNet. Finally, a use-case study employing eight able-bodied\nparticipants suggests that real-time feedback allows users to adapt their\nmuscle activation strategy which reduces the degradation in accuracy normally\nexperienced over time.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 11:42:30 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 14:29:42 GMT"}, {"version": "v3", "created": "Tue, 12 Jun 2018 09:25:44 GMT"}, {"version": "v4", "created": "Mon, 19 Nov 2018 16:48:25 GMT"}, {"version": "v5", "created": "Sat, 26 Jan 2019 04:00:47 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["C\u00f4t\u00e9-Allard", "Ulysse", ""], ["Fall", "Cheikh Latyr", ""], ["Drouin", "Alexandre", ""], ["Campeau-Lecours", "Alexandre", ""], ["Gosselin", "Cl\u00e9ment", ""], ["Glette", "Kyrre", ""], ["Laviolette", "Fran\u00e7ois", ""], ["Gosselin", "Benoit", ""]]}, {"id": "1801.07807", "submitter": "Ishanu Chattopadhyay", "authors": "Jaideep Dhanoa, Balaji Manicassamy and Ishanu Chattopadhyay", "title": "Algorithmic Bio-surveillance For Precise Spatio-temporal Prediction of\n  Zoonotic Emergence", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Viral zoonoses have emerged as the key drivers of recent pandemics. Human\ninfection by zoonotic viruses are either spillover events -- isolated\ninfections that fail to cause a widespread contagion -- or species jumps, where\nsuccessful adaptation to the new host leads to a pandemic. Despite expensive\nbio-surveillance efforts, historically emergence response has been reactive,\nand post-hoc. Here we use machine inference to demonstrate a high accuracy\npredictive bio-surveillance capability, designed to pro-actively localize an\nimpending species jump via automated interrogation of massive sequence\ndatabases of viral proteins. Our results suggest that a jump might not purely\nbe the result of an isolated unfortunate cross-infection localized in space and\ntime; there are subtle yet detectable patterns of genotypic changes\naccumulating in the global viral population leading up to emergence. Using tens\nof thousands of protein sequences simultaneously, we train models that track\nmaximum achievable accuracy for disambiguating host tropism from the primary\nstructure of surface proteins, and show that the inverse classification\naccuracy is a quantitative indicator of jump risk. We validate our claim in the\ncontext of the 2009 swine flu outbreak, and the 2004 emergence of H5N1\nsubspecies of Influenza A from avian reservoirs; illustrating that\ninterrogation of the global viral population can unambiguously track a near\nmonotonic risk elevation over several preceding years leading to eventual\nemergence.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 23:27:31 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Dhanoa", "Jaideep", ""], ["Manicassamy", "Balaji", ""], ["Chattopadhyay", "Ishanu", ""]]}, {"id": "1801.07827", "submitter": "Ming Zeng", "authors": "Ming Zeng, Tong Yu, Xiao Wang, Le T. Nguyen, Ole J. Mengshoel, Ian\n  Lane", "title": "Semi-Supervised Convolutional Neural Networks for Human Activity\n  Recognition", "comments": "Accepted by BigData2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeled data used for training activity recognition classifiers are usually\nlimited in terms of size and diversity. Thus, the learned model may not\ngeneralize well when used in real-world use cases. Semi-supervised learning\naugments labeled examples with unlabeled examples, often resulting in improved\nperformance. However, the semi-supervised methods studied in the activity\nrecognition literatures assume that feature engineering is already done. In\nthis paper, we lift this assumption and present two semi-supervised methods\nbased on convolutional neural networks (CNNs) to learn discriminative hidden\nfeatures. Our semi-supervised CNNs learn from both labeled and unlabeled data\nwhile also performing feature learning on raw sensor data. In experiments on\nthree real world datasets, we show that our CNNs outperform supervised methods\nand traditional semi-supervised learning methods by up to 18% in mean F1-score\n(Fm).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 20:18:16 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Zeng", "Ming", ""], ["Yu", "Tong", ""], ["Wang", "Xiao", ""], ["Nguyen", "Le T.", ""], ["Mengshoel", "Ole J.", ""], ["Lane", "Ian", ""]]}, {"id": "1801.07860", "submitter": "Eyal Oren", "authors": "Alvin Rajkomar, Eyal Oren, Kai Chen, Andrew M. Dai, Nissan Hajaj,\n  Peter J. Liu, Xiaobing Liu, Mimi Sun, Patrik Sundberg, Hector Yee, Kun Zhang,\n  Gavin E. Duggan, Gerardo Flores, Michaela Hardt, Jamie Irvine, Quoc Le, Kurt\n  Litsch, Jake Marcus, Alexander Mossin, Justin Tansuwan, De Wang, James\n  Wexler, Jimbo Wilson, Dana Ludwig, Samuel L. Volchenboum, Katherine Chou,\n  Michael Pearson, Srinivasan Madabushi, Nigam H. Shah, Atul J. Butte, Michael\n  Howell, Claire Cui, Greg Corrado, Jeff Dean", "title": "Scalable and accurate deep learning for electronic health records", "comments": "Published version from\n  https://www.nature.com/articles/s41746-018-0029-1", "journal-ref": "npj Digital Medicine 1:18 (2018)", "doi": "10.1038/s41746-018-0029-1", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive modeling with electronic health record (EHR) data is anticipated\nto drive personalized medicine and improve healthcare quality. Constructing\npredictive statistical models typically requires extraction of curated\npredictor variables from normalized EHR data, a labor-intensive process that\ndiscards the vast majority of information in each patient's record. We propose\na representation of patients' entire, raw EHR records based on the Fast\nHealthcare Interoperability Resources (FHIR) format. We demonstrate that deep\nlearning methods using this representation are capable of accurately predicting\nmultiple medical events from multiple centers without site-specific data\nharmonization. We validated our approach using de-identified EHR data from two\nU.S. academic medical centers with 216,221 adult patients hospitalized for at\nleast 24 hours. In the sequential format we propose, this volume of EHR data\nunrolled into a total of 46,864,534,945 data points, including clinical notes.\nDeep learning models achieved high accuracy for tasks such as predicting\nin-hospital mortality (AUROC across sites 0.93-0.94), 30-day unplanned\nreadmission (AUROC 0.75-0.76), prolonged length of stay (AUROC 0.85-0.86), and\nall of a patient's final discharge diagnoses (frequency-weighted AUROC 0.90).\nThese models outperformed state-of-the-art traditional predictive models in all\ncases. We also present a case-study of a neural-network attribution system,\nwhich illustrates how clinicians can gain some transparency into the\npredictions. We believe that this approach can be used to create accurate and\nscalable predictions for a variety of clinical scenarios, complete with\nexplanations that directly highlight evidence in the patient's chart.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 05:06:43 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 18:57:00 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 12:16:50 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Rajkomar", "Alvin", ""], ["Oren", "Eyal", ""], ["Chen", "Kai", ""], ["Dai", "Andrew M.", ""], ["Hajaj", "Nissan", ""], ["Liu", "Peter J.", ""], ["Liu", "Xiaobing", ""], ["Sun", "Mimi", ""], ["Sundberg", "Patrik", ""], ["Yee", "Hector", ""], ["Zhang", "Kun", ""], ["Duggan", "Gavin E.", ""], ["Flores", "Gerardo", ""], ["Hardt", "Michaela", ""], ["Irvine", "Jamie", ""], ["Le", "Quoc", ""], ["Litsch", "Kurt", ""], ["Marcus", "Jake", ""], ["Mossin", "Alexander", ""], ["Tansuwan", "Justin", ""], ["Wang", "De", ""], ["Wexler", "James", ""], ["Wilson", "Jimbo", ""], ["Ludwig", "Dana", ""], ["Volchenboum", "Samuel L.", ""], ["Chou", "Katherine", ""], ["Pearson", "Michael", ""], ["Madabushi", "Srinivasan", ""], ["Shah", "Nigam H.", ""], ["Butte", "Atul J.", ""], ["Howell", "Michael", ""], ["Cui", "Claire", ""], ["Corrado", "Greg", ""], ["Dean", "Jeff", ""]]}, {"id": "1801.07861", "submitter": "Zhen Wu", "authors": "Zhen Wu, Xin-Yu Dai, Cunyan Yin, Shujian Huang, Jiajun Chen", "title": "Improving Review Representations with User Attention and Product\n  Attention for Sentiment Classification", "comments": "Accepted by AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network methods have achieved great success in reviews sentiment\nclassification. Recently, some works achieved improvement by incorporating user\nand product information to generate a review representation. However, in\nreviews, we observe that some words or sentences show strong user's preference,\nand some others tend to indicate product's characteristic. The two kinds of\ninformation play different roles in determining the sentiment label of a\nreview. Therefore, it is not reasonable to encode user and product information\ntogether into one representation. In this paper, we propose a novel framework\nto encode user and product information. Firstly, we apply two individual\nhierarchical neural networks to generate two representations, with user\nattention or with product attention. Then, we design a combined strategy to\nmake full use of the two representations for training and final prediction. The\nexperimental results show that our model obviously outperforms other\nstate-of-the-art methods on IMDB and Yelp datasets. Through the visualization\nof attention over words related to user or product, we validate our observation\nmentioned above.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 05:11:57 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Wu", "Zhen", ""], ["Dai", "Xin-Yu", ""], ["Yin", "Cunyan", ""], ["Huang", "Shujian", ""], ["Chen", "Jiajun", ""]]}, {"id": "1801.07863", "submitter": "Rediet Abebe", "authors": "Rediet Abebe, Jon Kleinberg, David Parkes, Charalampos E. Tsourakakis", "title": "Opinion Dynamics with Varying Susceptibility to Persuasion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long line of work in social psychology has studied variations in people's\nsusceptibility to persuasion -- the extent to which they are willing to modify\ntheir opinions on a topic. This body of literature suggests an interesting\nperspective on theoretical models of opinion formation by interacting parties\nin a network: in addition to considering interventions that directly modify\npeople's intrinsic opinions, it is also natural to consider interventions that\nmodify people's susceptibility to persuasion. In this work, we adopt a popular\nmodel for social opinion dynamics, and we formalize the opinion maximization\nand minimization problems where interventions happen at the level of\nsusceptibility.\n  We show that modeling interventions at the level of susceptibility lead to an\ninteresting family of new questions in network opinion dynamics. We find that\nthe questions are quite different depending on whether there is an overall\nbudget constraining the number of agents we can target or not. We give a\npolynomial-time algorithm for finding the optimal target-set to optimize the\nsum of opinions when there are no budget constraints on the size of the\ntarget-set. We show that this problem is NP-hard when there is a budget, and\nthat the objective function is neither submodular nor supermodular. Finally, we\npropose a heuristic for the budgeted opinion optimization and show its efficacy\nat finding target-sets that optimize the sum of opinions compared on real world\nnetworks, including a Twitter network with real opinion estimates.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 05:12:45 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Abebe", "Rediet", ""], ["Kleinberg", "Jon", ""], ["Parkes", "David", ""], ["Tsourakakis", "Charalampos E.", ""]]}, {"id": "1801.07875", "submitter": "Michael Bloodgood", "authors": "Michael Bloodgood", "title": "Support Vector Machine Active Learning Algorithms with\n  Query-by-Committee versus Closest-to-Hyperplane Selection", "comments": "8 pages, 7 figures, 3 tables; published in Proceedings of the IEEE\n  12th International Conference on Semantic Computing (ICSC 2018), Laguna\n  Hills, CA, USA, pages 148-155, January 2018", "journal-ref": "In Proceedings of the 2018 IEEE 12th International Conference on\n  Semantic Computing (ICSC), pages 148-155, Laguna Hills, CA, USA, January\n  2018. IEEE", "doi": "10.1109/ICSC.2018.00029", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates and evaluates support vector machine active learning\nalgorithms for use with imbalanced datasets, which commonly arise in many\napplications such as information extraction applications. Algorithms based on\nclosest-to-hyperplane selection and query-by-committee selection are combined\nwith methods for addressing imbalance such as positive amplification based on\nprevalence statistics from initial random samples. Three algorithms (ClosestPA,\nQBagPA, and QBoostPA) are presented and carefully evaluated on datasets for\ntext classification and relation extraction. The ClosestPA algorithm is shown\nto consistently outperform the other two in a variety of ways and insights are\nprovided as to why this is the case.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 06:38:06 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:16:47 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bloodgood", "Michael", ""]]}, {"id": "1801.07883", "submitter": "Lei Zhang", "authors": "Lei Zhang, Shuai Wang, Bing Liu", "title": "Deep Learning for Sentiment Analysis : A Survey", "comments": "34 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has emerged as a powerful machine learning technique that\nlearns multiple layers of representations or features of the data and produces\nstate-of-the-art prediction results. Along with the success of deep learning in\nmany other application domains, deep learning is also popularly used in\nsentiment analysis in recent years. This paper first gives an overview of deep\nlearning and then provides a comprehensive survey of its current applications\nin sentiment analysis.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 07:32:29 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 07:20:41 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Zhang", "Lei", ""], ["Wang", "Shuai", ""], ["Liu", "Bing", ""]]}, {"id": "1801.07887", "submitter": "Michael Bloodgood", "authors": "Garrett Beatty, Ethan Kochis and Michael Bloodgood", "title": "Impact of Batch Size on Stopping Active Learning for Text Classification", "comments": "2 pages, 1 table; published in Proceedings of the IEEE 12th\n  International Conference on Semantic Computing (ICSC 2018), Laguna Hills, CA,\n  USA, pages 306-307, January 2018", "journal-ref": "In Proceedings of the 2018 IEEE 12th International Conference on\n  Semantic Computing (ICSC), pages 306-307, Laguna Hills, CA, USA, January\n  2018. IEEE", "doi": "10.1109/ICSC.2018.00059", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using active learning, smaller batch sizes are typically more efficient\nfrom a learning efficiency perspective. However, in practice due to speed and\nhuman annotator considerations, the use of larger batch sizes is necessary.\nWhile past work has shown that larger batch sizes decrease learning efficiency\nfrom a learning curve perspective, it remains an open question how batch size\nimpacts methods for stopping active learning. We find that large batch sizes\ndegrade the performance of a leading stopping method over and above the\ndegradation that results from reduced learning efficiency. We analyze this\ndegradation and find that it can be mitigated by changing the window size\nparameter of how many past iterations of learning are taken into account when\nmaking the stopping decision. We find that when using larger batch sizes,\nstopping methods are more effective when smaller window sizes are used.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 07:47:05 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 18:31:45 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Beatty", "Garrett", ""], ["Kochis", "Ethan", ""], ["Bloodgood", "Michael", ""]]}, {"id": "1801.07889", "submitter": "\\c{C}a\\u{g}lar Aytekin", "authors": "Caglar Aytekin, Francesco Cricri, Lixin Fan and Emre Aksu", "title": "A Theoretical Investigation of Graph Degree as an Unsupervised Normality\n  Measure", "comments": "Submitted to IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a graph representation of a dataset, a straightforward normality measure\nfor a sample can be its graph degree. Considering a weighted graph, degree of a\nsample is the sum of the corresponding row's values in a similarity matrix. The\nmeasure is intuitive given the abnormal samples are usually rare and they are\ndissimilar to the rest of the data. In order to have an in-depth theoretical\nunderstanding, in this manuscript, we investigate the graph degree in spectral\ngraph clustering based and kernel based point of views and draw connections to\na recent kernel method for the two sample problem. We show that our analyses\nguide us to choose fully-connected graphs whose edge weights are calculated via\nuniversal kernels. We show that a simple graph degree based unsupervised\nanomaly detection method with the above properties, achieves higher accuracy\ncompared to other unsupervised anomaly detection methods on average over 10\nwidely used datasets. We also provide an extensive analysis on the effect of\nthe kernel parameter on the method's accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 07:58:34 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 08:40:18 GMT"}, {"version": "v3", "created": "Mon, 5 Feb 2018 11:19:39 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Aytekin", "Caglar", ""], ["Cricri", "Francesco", ""], ["Fan", "Lixin", ""], ["Aksu", "Emre", ""]]}, {"id": "1801.07912", "submitter": "Rafael Garcia-Dias", "authors": "Rafael Garcia-Dias, Carlos Allende Prieto, Jorge S\\'anchez Almeida and\n  Ignacio Ordov\\'as-Pascual", "title": "Machine learning in APOGEE: Unsupervised spectral classification with\n  $K$-means", "comments": "23 pages, 24 images and online material", "journal-ref": "A&A 612, A98 (2018)", "doi": "10.1051/0004-6361/201732134", "report-no": null, "categories": "astro-ph.IM astro-ph.GA astro-ph.SR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The data volume generated by astronomical surveys is growing rapidly.\nTraditional analysis techniques in spectroscopy either demand intensive human\ninteraction or are computationally expensive. In this scenario, machine\nlearning, and unsupervised clustering algorithms in particular offer\ninteresting alternatives. The Apache Point Observatory Galactic Evolution\nExperiment (APOGEE) offers a vast data set of near-infrared stellar spectra\nwhich is perfect for testing such alternatives. Apply an unsupervised\nclassification scheme based on $K$-means to the massive APOGEE data set.\nExplore whether the data are amenable to classification into discrete classes.\nWe apply the $K$-means algorithm to 153,847 high resolution spectra\n($R\\approx22,500$). We discuss the main virtues and weaknesses of the\nalgorithm, as well as our choice of parameters. We show that a classification\nbased on normalised spectra captures the variations in stellar atmospheric\nparameters, chemical abundances, and rotational velocity, among other factors.\nThe algorithm is able to separate the bulge and halo populations, and\ndistinguish dwarfs, sub-giants, RC and RGB stars. However, a discrete\nclassification in flux space does not result in a neat organisation in the\nparameters space. Furthermore, the lack of obvious groups in flux space causes\nthe results to be fairly sensitive to the initialisation, and disrupts the\nefficiency of commonly-used methods to select the optimal number of clusters.\nOur classification is publicly available, including extensive online material\nassociated with the APOGEE Data Release 12 (DR12). Our description of the\nAPOGEE database can enormously help with the identification of specific types\nof targets for various applications. We find a lack of obvious groups in flux\nspace, and identify limitations of the $K$-means algorithm in dealing with this\nkind of data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 10:24:23 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 10:09:35 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Garcia-Dias", "Rafael", ""], ["Prieto", "Carlos Allende", ""], ["Almeida", "Jorge S\u00e1nchez", ""], ["Ordov\u00e1s-Pascual", "Ignacio", ""]]}, {"id": "1801.07936", "submitter": "Paolo Detti", "authors": "Paolo Detti, Garazi Zabalo Manrique de Lara, Renato Bruni, Marco\n  Pranzo, Francesco Sarnari", "title": "Anticipating epileptic seizures through the analysis of EEG\n  synchronization as a data classification problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a neurological disorder arising from anomalies of the electrical\nactivity in the brain, affecting about 0.5--0.8\\% of the world population.\nSeveral studies investigated the relationship between seizures and brainwave\nsynchronization patterns, pursuing the possibility of identifying interictal,\npreictal, ictal and postictal states. In this work, we introduce a graph-based\nmodel of the brain interactions developed to study synchronization patterns in\nthe electroencephalogram (EEG) signals. The aim is to develop a\npatient-specific approach, also for a real-time use, for the prediction of\nepileptic seizures' occurrences. Different synchronization measures of the EEG\nsignals and easily computable functions able to capture in real-time the\nvariations of EEG synchronization have been considered. Both standard and\nad-hoc classification algorithms have been developed and used. Results on scalp\nEEG signals show that this simple and computationally viable processing is able\nto highlight the changes in the synchronization corresponding to the preictal\nstate.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 11:43:29 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Detti", "Paolo", ""], ["de Lara", "Garazi Zabalo Manrique", ""], ["Bruni", "Renato", ""], ["Pranzo", "Marco", ""], ["Sarnari", "Francesco", ""]]}, {"id": "1801.07962", "submitter": "Florent Altche", "authors": "Florent Altch\\'e, Arnaud de La Fortelle", "title": "An LSTM Network for Highway Trajectory Prediction", "comments": "Presented at IEEE ITSC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to drive safely and efficiently on public roads, autonomous vehicles\nwill have to understand the intentions of surrounding vehicles, and adapt their\nown behavior accordingly. If experienced human drivers are generally good at\ninferring other vehicles' motion up to a few seconds in the future, most\ncurrent Advanced Driving Assistance Systems (ADAS) are unable to perform such\nmedium-term forecasts, and are usually limited to high-likelihood situations\nsuch as emergency braking. In this article, we present a first step towards\nconsistent trajectory prediction by introducing a long short-term memory (LSTM)\nneural network, which is capable of accurately predicting future longitudinal\nand lateral trajectories for vehicles on highway. Unlike previous work focusing\non a low number of trajectories collected from a few drivers, our network was\ntrained and validated on the NGSIM US-101 dataset, which contains a total of\n800 hours of recorded trajectories in various traffic densities, representing\nmore than 6000 individual drivers.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 12:45:01 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Altch\u00e9", "Florent", ""], ["de La Fortelle", "Arnaud", ""]]}, {"id": "1801.07985", "submitter": "Tom Hanika", "authors": "Tom Hanika and Friedrich Martin Schneider and Gerd Stumme", "title": "Intrinsic Dimension of Geometric Data Sets", "comments": "v3: 33 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curse of dimensionality is a phenomenon frequently observed in machine\nlearning (ML) and knowledge discovery (KD). There is a large body of literature\ninvestigating its origin and impact, using methods from mathematics as well as\nfrom computer science. Among the mathematical insights into data\ndimensionality, there is an intimate link between the dimension curse and the\nphenomenon of measure concentration, which makes the former accessible to\nmethods of geometric analysis. The present work provides a comprehensive study\nof the intrinsic geometry of a data set, based on Gromov's metric measure\ngeometry and Pestov's axiomatic approach to intrinsic dimension. In detail, we\ndefine a concept of geometric data set and introduce a metric as well as a\npartial order on the set of isomorphism classes of such data sets. Based on\nthese objects, we propose and investigate an axiomatic approach to the\nintrinsic dimension of geometric data sets and establish a concrete dimension\nfunction with the desired properties. Our model for data sets and their\nintrinsic dimension is computationally feasible and, moreover, adaptable to\nspecific ML/KD-algorithms, as illustrated by various experiments.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 13:49:37 GMT"}, {"version": "v2", "created": "Mon, 24 Dec 2018 22:54:02 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 12:42:25 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Hanika", "Tom", ""], ["Schneider", "Friedrich Martin", ""], ["Stumme", "Gerd", ""]]}, {"id": "1801.08019", "submitter": "Xuezhou Zhang", "authors": "Xuezhou Zhang, Xiaojin Zhu and Stephen J. Wright", "title": "Training Set Debugging Using Trusted Items", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training set bugs are flaws in the data that adversely affect machine\nlearning. The training set is usually too large for man- ual inspection, but\none may have the resources to verify a few trusted items. The set of trusted\nitems may not by itself be adequate for learning, so we propose an algorithm\nthat uses these items to identify bugs in the training set and thus im- proves\nlearning. Specifically, our approach seeks the smallest set of changes to the\ntraining set labels such that the model learned from this corrected training\nset predicts labels of the trusted items correctly. We flag the items whose\nlabels are changed as potential bugs, whose labels can be checked for veracity\nby human experts. To find the bugs in this way is a challenging combinatorial\nbilevel optimization problem, but it can be relaxed into a continuous\noptimization problem. Ex- periments on toy and real data demonstrate that our\napproach can identify training set bugs effectively and suggest appro- priate\nchanges to the labels. Our algorithm is a step toward trustworthy machine\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 15:21:57 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Zhang", "Xuezhou", ""], ["Zhu", "Xiaojin", ""], ["Wright", "Stephen J.", ""]]}, {"id": "1801.08030", "submitter": "Srinivas Sridharan", "authors": "Srinivas Sridharan, Karthikeyan Vaidyanathan, Dhiraj Kalamkar,\n  Dipankar Das, Mikhail E. Smorkalov, Mikhail Shiryaev, Dheevatsa Mudigere,\n  Naveen Mellempudi, Sasikanth Avancha, Bharat Kaul, Pradeep Dubey", "title": "On Scale-out Deep Learning Training for Cloud and HPC", "comments": "Accepted in SysML 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential growth in use of large deep neural networks has accelerated\nthe need for training these deep neural networks in hours or even minutes. This\ncan only be achieved through scalable and efficient distributed training, since\na single node/card cannot satisfy the compute, memory, and I/O requirements of\ntoday's state-of-the-art deep neural networks. However, scaling synchronous\nStochastic Gradient Descent (SGD) is still a challenging problem and requires\ncontinued research/development. This entails innovations spanning algorithms,\nframeworks, communication libraries, and system design. In this paper, we\ndescribe the philosophy, design, and implementation of Intel Machine Learning\nScalability Library (MLSL) and present proof-points demonstrating scaling DL\ntraining on 100s to 1000s of nodes across Cloud and HPC systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 15:38:17 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Sridharan", "Srinivas", ""], ["Vaidyanathan", "Karthikeyan", ""], ["Kalamkar", "Dhiraj", ""], ["Das", "Dipankar", ""], ["Smorkalov", "Mikhail E.", ""], ["Shiryaev", "Mikhail", ""], ["Mudigere", "Dheevatsa", ""], ["Mellempudi", "Naveen", ""], ["Avancha", "Sasikanth", ""], ["Kaul", "Bharat", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1801.08058", "submitter": "David Cyphers", "authors": "Scott Cyphers, Arjun K. Bansal, Anahita Bhiwandiwalla, Jayaram Bobba,\n  Matthew Brookhart, Avijit Chakraborty, Will Constable, Christian Convey,\n  Leona Cook, Omar Kanawi, Robert Kimball, Jason Knight, Nikolay Korovaiko,\n  Varun Kumar, Yixing Lao, Christopher R. Lishka, Jaikrishnan Menon, Jennifer\n  Myers, Sandeep Aswath Narayana, Adam Procter, Tristan J. Webb", "title": "Intel nGraph: An Intermediate Representation, Compiler, and Executor for\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Deep Learning (DL) community sees many novel topologies published each\nyear. Achieving high performance on each new topology remains challenging, as\neach requires some level of manual effort. This issue is compounded by the\nproliferation of frameworks and hardware platforms. The current approach, which\nwe call \"direct optimization\", requires deep changes within each framework to\nimprove the training performance for each hardware backend (CPUs, GPUs, FPGAs,\nASICs) and requires $\\mathcal{O}(fp)$ effort; where $f$ is the number of\nframeworks and $p$ is the number of platforms. While optimized kernels for\ndeep-learning primitives are provided via libraries like Intel Math Kernel\nLibrary for Deep Neural Networks (MKL-DNN), there are several compiler-inspired\nways in which performance can be further optimized. Building on our experience\ncreating neon (a fast deep learning library on GPUs), we developed Intel\nnGraph, a soon to be open-sourced C++ library to simplify the realization of\noptimized deep learning performance across frameworks and hardware platforms.\nInitially-supported frameworks include TensorFlow, MXNet, and Intel neon\nframework. Initial backends are Intel Architecture CPUs (CPU), the Intel(R)\nNervana Neural Network Processor(R) (NNP), and NVIDIA GPUs. Currently supported\ncompiler optimizations include efficient memory management and data layout\nabstraction. In this paper, we describe our overall architecture and its core\ncomponents. In the future, we envision extending nGraph API support to a wider\nrange of frameworks, hardware (including FPGAs and ASICs), and compiler\noptimizations (training versus inference optimizations, multi-node and\nmulti-device scaling via efficient sub-graph partitioning, and HW-specific\ncompounding of operations).\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 16:17:53 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 00:14:49 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Cyphers", "Scott", ""], ["Bansal", "Arjun K.", ""], ["Bhiwandiwalla", "Anahita", ""], ["Bobba", "Jayaram", ""], ["Brookhart", "Matthew", ""], ["Chakraborty", "Avijit", ""], ["Constable", "Will", ""], ["Convey", "Christian", ""], ["Cook", "Leona", ""], ["Kanawi", "Omar", ""], ["Kimball", "Robert", ""], ["Knight", "Jason", ""], ["Korovaiko", "Nikolay", ""], ["Kumar", "Varun", ""], ["Lao", "Yixing", ""], ["Lishka", "Christopher R.", ""], ["Menon", "Jaikrishnan", ""], ["Myers", "Jennifer", ""], ["Narayana", "Sandeep Aswath", ""], ["Procter", "Adam", ""], ["Webb", "Tristan J.", ""]]}, {"id": "1801.08092", "submitter": "Aditya Ganeshan Master", "authors": "Konda Reddy Mopuri, Aditya Ganeshan and R. Venkatesh Babu", "title": "Generalizable Data-free Objective for Crafting Universal Adversarial\n  Perturbations", "comments": "TPAMI | Repository: https://github.com/val-iisc/GD-UAP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are susceptible to adversarial perturbations: small\nchanges to input that can cause large changes in output. It is also\ndemonstrated that there exist input-agnostic perturbations, called universal\nadversarial perturbations, which can change the inference of target model on\nmost of the data samples. However, existing methods to craft universal\nperturbations are (i) task specific, (ii) require samples from the training\ndata distribution, and (iii) perform complex optimizations. Additionally,\nbecause of the data dependence, fooling ability of the crafted perturbations is\nproportional to the available training data. In this paper, we present a novel,\ngeneralizable and data-free approaches for crafting universal adversarial\nperturbations. Independent of the underlying task, our objective achieves\nfooling via corrupting the extracted features at multiple layers. Therefore,\nthe proposed objective is generalizable to craft image-agnostic perturbations\nacross multiple vision tasks such as object recognition, semantic segmentation,\nand depth estimation. In the practical setting of black-box attack scenario\n(when the attacker does not have access to the target model and it's training\ndata), we show that our objective outperforms the data dependent objectives to\nfool the learned models. Further, via exploiting simple priors related to the\ndata distribution, our objective remarkably boosts the fooling ability of the\ncrafted perturbations. Significant fooling rates achieved by our objective\nemphasize that the current deep learning models are now at an increased risk,\nsince our objective generalizes across multiple tasks without the requirement\nof training data for crafting the perturbations. To encourage reproducible\nresearch, we have released the codes for our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 17:36:57 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 12:43:10 GMT"}, {"version": "v3", "created": "Tue, 24 Jul 2018 08:19:43 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Mopuri", "Konda Reddy", ""], ["Ganeshan", "Aditya", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1801.08093", "submitter": "Wenhao Yu", "authors": "Wenhao Yu, Greg Turk and C.Karen Liu", "title": "Learning Symmetric and Low-energy Locomotion", "comments": "Accepted to SIGGRAPH 2018. Supplementary video:\n  https://www.youtube.com/watch?v=zkH90rU-uew&feature=youtu.be", "journal-ref": "ACM Transactions on Graphics 37(4), August 2018", "doi": "10.1145/3197517.3201397", "report-no": null, "categories": "cs.LG cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning locomotion skills is a challenging problem. To generate realistic\nand smooth locomotion, existing methods use motion capture, finite state\nmachines or morphology-specific knowledge to guide the motion generation\nalgorithms. Deep reinforcement learning (DRL) is a promising approach for the\nautomatic creation of locomotion control. Indeed, a standard benchmark for DRL\nis to automatically create a running controller for a biped character from a\nsimple reward function. Although several different DRL algorithms can\nsuccessfully create a running controller, the resulting motions usually look\nnothing like a real runner. This paper takes a minimalist learning approach to\nthe locomotion problem, without the use of motion examples, finite state\nmachines, or morphology-specific knowledge. We introduce two modifications to\nthe DRL approach that, when used together, produce locomotion behaviors that\nare symmetric, low-energy, and much closer to that of a real person. First, we\nintroduce a new term to the loss function (not the reward function) that\nencourages symmetric actions. Second, we introduce a new curriculum learning\nmethod that provides modulated physical assistance to help the character with\nleft/right balance and forward movement. The algorithm automatically computes\nappropriate assistance to the character and gradually relaxes this assistance,\nso that eventually the character learns to move entirely without help. Because\nour method does not make use of motion capture data, it can be applied to a\nvariety of character morphologies. We demonstrate locomotion controllers for\nthe lower half of a biped, a full humanoid, a quadruped, and a hexapod. Our\nresults show that learned policies are able to produce symmetric, low-energy\ngaits. In addition, speed-appropriate gait patterns emerge without any guidance\nfrom motion examples or contact planning.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 17:37:35 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 20:10:36 GMT"}, {"version": "v3", "created": "Sat, 12 May 2018 14:30:23 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Yu", "Wenhao", ""], ["Turk", "Greg", ""], ["Liu", "C. Karen", ""]]}, {"id": "1801.08094", "submitter": "Kui Zhao", "authors": "Kui Zhao, Yuechuan Li, Chi Zhang, Cheng Yang, Huan Xu", "title": "Adaptive Recurrent Neural Network Based on Mixture Layer", "comments": "7 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although Recurrent Neural Network (RNN) has been a powerful tool for modeling\nsequential data, its performance is inadequate when processing sequences with\nmultiple patterns. In this paper, we address this challenge by introducing a\nnovel mixture layer and constructing an adaptive RNN. The mixture layer\naugmented RNN (termed as M-RNN) partitions patterns in training sequences into\nseveral clusters and stores the principle patterns as prototype vectors of\ncomponents in a mixture model. By leveraging the mixture layer, the proposed\nmethod can adaptively update states according to the similarities between\nencoded inputs and prototype vectors, leading to a stronger capacity in\nassimilating sequences with multiple patterns. Moreover, our approach can be\nfurther extended by taking advantage of prior knowledge about data. Experiments\non both synthetic and real datasets demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 17:38:48 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 09:19:59 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 09:45:30 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 01:54:38 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Zhao", "Kui", ""], ["Li", "Yuechuan", ""], ["Zhang", "Chi", ""], ["Yang", "Cheng", ""], ["Xu", "Huan", ""]]}, {"id": "1801.08099", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, and Daniel Kroening", "title": "Logically-Constrained Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first model-free Reinforcement Learning (RL) algorithm to\nsynthesise policies for an unknown Markov Decision Process (MDP), such that a\nlinear time property is satisfied. The given temporal property is converted\ninto a Limit Deterministic Buchi Automaton (LDBA) and a robust reward function\nis defined over the state-action pairs of the MDP according to the resulting\nLDBA. With this reward function, the policy synthesis procedure is\n\"constrained\" by the given specification. These constraints guide the MDP\nexploration so as to minimize the solution time by only considering the portion\nof the MDP that is relevant to satisfaction of the LTL property. This improves\nperformance and scalability of the proposed method by avoiding an exhaustive\nupdate over the whole state space while the efficiency of standard methods such\nas dynamic programming is hindered by excessive memory requirements, caused by\nthe need to store a full-model in memory. Additionally, we show that the RL\nprocedure sets up a local value iteration method to efficiently calculate the\nmaximum probability of satisfying the given property, at any given state of the\nMDP. We prove that our algorithm is guaranteed to find a policy whose traces\nprobabilistically satisfy the LTL property if such a policy exists, and\nadditionally we show that our method produces reasonable control policies even\nwhen the LTL property cannot be satisfied. The performance of the algorithm is\nevaluated via a set of numerical examples. We observe an improvement of one\norder of magnitude in the number of iterations required for the synthesis\ncompared to existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 17:50:30 GMT"}, {"version": "v2", "created": "Sun, 11 Mar 2018 16:45:23 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 16:50:43 GMT"}, {"version": "v4", "created": "Thu, 17 May 2018 14:06:28 GMT"}, {"version": "v5", "created": "Wed, 4 Jul 2018 15:33:43 GMT"}, {"version": "v6", "created": "Mon, 22 Oct 2018 10:35:40 GMT"}, {"version": "v7", "created": "Thu, 6 Dec 2018 11:38:58 GMT"}, {"version": "v8", "created": "Sat, 16 Feb 2019 18:11:58 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "1801.08196", "submitter": "Baichuan Zhang", "authors": "Pin-Yu Chen, Baichuan Zhang, Mohammad Al Hasan", "title": "Incremental Eigenpair Computation for Graph Laplacian Matrices: Theory\n  and Applications", "comments": "Accept to publish in Social Network Analysis and Mining. arXiv admin\n  note: text overlap with arXiv:1512.07349", "journal-ref": "Social Network Analysis and Mining, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The smallest eigenvalues and the associated eigenvectors (i.e., eigenpairs)\nof a graph Laplacian matrix have been widely used in spectral clustering and\ncommunity detection. However, in real-life applications the number of clusters\nor communities (say, $K$) is generally unknown a-priori. Consequently, the\nmajority of the existing methods either choose $K$ heuristically or they repeat\nthe clustering method with different choices of $K$ and accept the best\nclustering result. The first option, more often, yields suboptimal result,\nwhile the second option is computationally expensive. In this work, we propose\nan incremental method for constructing the eigenspectrum of the graph Laplacian\nmatrix. This method leverages the eigenstructure of graph Laplacian matrix to\nobtain the $K$-th smallest eigenpair of the Laplacian matrix given a collection\nof all previously computed $K-1$ smallest eigenpairs. Our proposed method\nadapts the Laplacian matrix such that the batch eigenvalue decomposition\nproblem transforms into an efficient sequential leading eigenpair computation\nproblem. As a practical application, we consider user-guided spectral\nclustering. Specifically, we demonstrate that users can utilize the proposed\nincremental method for effective eigenpair computation and for determining the\ndesired number of clusters based on multiple clustering metrics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 19:04:35 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Zhang", "Baichuan", ""], ["Hasan", "Mohammad Al", ""]]}, {"id": "1801.08214", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Emilio Parisotto, Ruslan Salakhutdinov", "title": "Active Neural Localization", "comments": "Under Review at ICLR-18, 15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization is the problem of estimating the location of an autonomous agent\nfrom an observation and a map of the environment. Traditional methods of\nlocalization, which filter the belief based on the observations, are\nsub-optimal in the number of steps required, as they do not decide the actions\ntaken by the agent. We propose \"Active Neural Localizer\", a fully\ndifferentiable neural network that learns to localize accurately and\nefficiently. The proposed model incorporates ideas of traditional\nfiltering-based localization methods, by using a structured belief of the state\nwith multiplicative interactions to propagate belief, and combines it with a\npolicy model to localize accurately while minimizing the number of steps\nrequired for localization. Active Neural Localizer is trained end-to-end with\nreinforcement learning. We use a variety of simulation environments for our\nexperiments which include random 2D mazes, random mazes in the Doom game engine\nand a photo-realistic environment in the Unreal game engine. The results on the\n2D environments show the effectiveness of the learned policy in an idealistic\nsetting while results on the 3D environments demonstrate the model's capability\nof learning the policy and perceptual model jointly from raw-pixel based RGB\nobservations. We also show that a model trained on random textures in the Doom\nenvironment generalizes well to a photo-realistic office space environment in\nthe Unreal engine.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 22:06:55 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Parisotto", "Emilio", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1801.08284", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Fuzheng Zhang, Xing Xie, Minyi Guo", "title": "DKN: Deep Knowledge-Aware Network for News Recommendation", "comments": "The 27th International Conference on World Wide Web (WWW'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online news recommender systems aim to address the information explosion of\nnews and make personalized recommendation for users. In general, news language\nis highly condensed, full of knowledge entities and common sense. However,\nexisting methods are unaware of such external knowledge and cannot fully\ndiscover latent knowledge-level connections among news. The recommended results\nfor a user are consequently limited to simple patterns and cannot be extended\nreasonably. Moreover, news recommendation also faces the challenges of high\ntime-sensitivity of news and dynamic diversity of users' interests. To solve\nthe above problems, in this paper, we propose a deep knowledge-aware network\n(DKN) that incorporates knowledge graph representation into news\nrecommendation. DKN is a content-based deep recommendation framework for\nclick-through rate prediction. The key component of DKN is a multi-channel and\nword-entity-aligned knowledge-aware convolutional neural network (KCNN) that\nfuses semantic-level and knowledge-level representations of news. KCNN treats\nwords and entities as multiple channels, and explicitly keeps their alignment\nrelationship during convolution. In addition, to address users' diverse\ninterests, we also design an attention module in DKN to dynamically aggregate a\nuser's history with respect to current candidate news. Through extensive\nexperiments on a real online news platform, we demonstrate that DKN achieves\nsubstantial gains over state-of-the-art deep recommendation models. We also\nvalidate the efficacy of the usage of knowledge in DKN.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 06:15:16 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 02:42:56 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhang", "Fuzheng", ""], ["Xie", "Xing", ""], ["Guo", "Minyi", ""]]}, {"id": "1801.08297", "submitter": "Yuan Gao", "authors": "Yuan Gao, Jiayi Ma, Mingbo Zhao, Wei Liu, Alan L. Yuille", "title": "NDDR-CNN: Layerwise Feature Fusing in Multi-Task CNNs by Neural\n  Discriminative Dimensionality Reduction", "comments": "11 pages, 3 figures, 9 tables", "journal-ref": "IEEE Conference on Computer Vision and Pattern Recognition, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel Convolutional Neural Network (CNN)\nstructure for general-purpose multi-task learning (MTL), which enables\nautomatic feature fusing at every layer from different tasks. This is in\ncontrast with the most widely used MTL CNN structures which empirically or\nheuristically share features on some specific layers (e.g., share all the\nfeatures except the last convolutional layer). The proposed layerwise feature\nfusing scheme is formulated by combining existing CNN components in a novel\nway, with clear mathematical interpretability as discriminative dimensionality\nreduction, which is referred to as Neural Discriminative Dimensionality\nReduction (NDDR). Specifically, we first concatenate features with the same\nspatial resolution from different tasks according to their channel dimension.\nThen, we show that the discriminative dimensionality reduction can be fulfilled\nby 1x1 Convolution, Batch Normalization, and Weight Decay in one CNN. The use\nof existing CNN components ensures the end-to-end training and the\nextensibility of the proposed NDDR layer to various state-of-the-art CNN\narchitectures in a \"plug-and-play\" manner. The detailed ablation analysis shows\nthat the proposed NDDR layer is easy to train and also robust to different\nhyperparameters. Experiments on different task sets with various base network\narchitectures demonstrate the promising performance and desirable\ngeneralizability of our proposed method. The code of our paper is available at\nhttps://github.com/ethanygao/NDDR-CNN.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 07:38:52 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 11:57:07 GMT"}, {"version": "v3", "created": "Sun, 25 Nov 2018 19:15:47 GMT"}, {"version": "v4", "created": "Thu, 4 Apr 2019 23:24:48 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Gao", "Yuan", ""], ["Ma", "Jiayi", ""], ["Zhao", "Mingbo", ""], ["Liu", "Wei", ""], ["Yuille", "Alan L.", ""]]}, {"id": "1801.08379", "submitter": "Emre Aksan", "authors": "Emre Aksan, Fabrizio Pece, Otmar Hilliges", "title": "DeepWriting: Making Digital Ink Editable via Deep Generative Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital ink promises to combine the flexibility and aesthetics of handwriting\nand the ability to process, search and edit digital text. Character recognition\nconverts handwritten text into a digital representation, albeit at the cost of\nlosing personalized appearance due to the technical difficulties of separating\nthe interwoven components of content and style. In this paper, we propose a\nnovel generative neural network architecture that is capable of disentangling\nstyle from content and thus making digital ink editable. Our model can\nsynthesize arbitrary text, while giving users control over the visual\nappearance (style). For example, allowing for style transfer without changing\nthe content, editing of digital ink at the word level and other application\nscenarios such as spell-checking and correction of handwritten text. We\nfurthermore contribute a new dataset of handwritten text with fine-grained\nannotations at the character level and report results from an initial user\nevaluation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 12:39:42 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Aksan", "Emre", ""], ["Pece", "Fabrizio", ""], ["Hilliges", "Otmar", ""]]}, {"id": "1801.08383", "submitter": "Carl Andersson", "authors": "Carl Andersson, Niklas Wahlstr\\\"om, Thomas B. Sch\\\"on", "title": "Data-Driven Impulse Response Regularization via Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of impulse response estimation of stable linear\nsingle-input single-output systems. It is a well-studied problem where flexible\nnon-parametric models recently offered a leap in performance compared to the\nclassical finite-dimensional model structures. Inspired by this development and\nthe success of deep learning we propose a new flexible data-driven model. Our\nexperiments indicate that the new model is capable of exploiting even more of\nthe hidden patterns that are present in the input-output data as compared to\nthe non-parametric models.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 12:48:41 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 08:21:04 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Andersson", "Carl", ""], ["Wahlstr\u00f6m", "Niklas", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1801.08535", "submitter": "Yuxuan Chen", "authors": "Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai\n  Chen, Shengzhi Zhang, Heqing Huang, Xiaofeng Wang, and Carl A. Gunter", "title": "CommanderSong: A Systematic Approach for Practical Adversarial Voice\n  Recognition", "comments": "Accepted by USENIX Security 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of ASR (automatic speech recognition) systems, like Google\nVoice, Cortana, brings in security concerns, as demonstrated by recent attacks.\nThe impacts of such threats, however, are less clear, since they are either\nless stealthy (producing noise-like voice commands) or requiring the physical\npresence of an attack device (using ultrasound). In this paper, we demonstrate\nthat not only are more practical and surreptitious attacks feasible but they\ncan even be automatically constructed. Specifically, we find that the voice\ncommands can be stealthily embedded into songs, which, when played, can\neffectively control the target system through ASR without being noticed. For\nthis purpose, we developed novel techniques that address a key technical\nchallenge: integrating the commands into a song in a way that can be\neffectively recognized by ASR through the air, in the presence of background\nnoise, while not being detected by a human listener. Our research shows that\nthis can be done automatically against real world ASR applications. We also\ndemonstrate that such CommanderSongs can be spread through Internet (e.g.,\nYouTube) and radio, potentially affecting millions of ASR users. We further\npresent a new mitigation technique that controls this threat.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 22:02:40 GMT"}, {"version": "v2", "created": "Sun, 11 Feb 2018 01:44:21 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 00:08:16 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Yuan", "Xuejing", ""], ["Chen", "Yuxuan", ""], ["Zhao", "Yue", ""], ["Long", "Yunhui", ""], ["Liu", "Xiaokang", ""], ["Chen", "Kai", ""], ["Zhang", "Shengzhi", ""], ["Huang", "Heqing", ""], ["Wang", "Xiaofeng", ""], ["Gunter", "Carl A.", ""]]}, {"id": "1801.08570", "submitter": "Alexandr A. Kalinin", "authors": "Alexandr A. Kalinin, Gerald A. Higgins, Narathip Reamaroon, S.M. Reza\n  Soroushmehr, Ari Allyn-Feuer, Ivo D. Dinov, Kayvan Najarian, Brian D. Athey", "title": "Deep Learning in Pharmacogenomics: From Gene Regulation to Patient\n  Stratification", "comments": "Alexandr A. Kalinin and Gerald A. Higgins contributed equally to this\n  work. Corresponding author: Brian D. Athey, <bleu@umich.edu>", "journal-ref": null, "doi": "10.2217/pgs-2018-0008", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Perspective provides examples of current and future applications of deep\nlearning in pharmacogenomics, including: (1) identification of novel regulatory\nvariants located in noncoding domains and their function as applied to\npharmacoepigenomics; (2) patient stratification from medical records; and (3)\nprediction of drugs, targets, and their interactions. Deep learning\nencapsulates a family of machine learning algorithms that over the last decade\nhas transformed many important subfields of artificial intelligence (AI) and\nhas demonstrated breakthrough performance improvements on a wide range of tasks\nin biomedicine. We anticipate that in the future deep learning will be widely\nused to predict personalized drug response and optimize medication selection\nand dosing, using knowledge extracted from large and complex molecular,\nepidemiological, clinical, and demographic datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 19:21:15 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 00:25:37 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kalinin", "Alexandr A.", ""], ["Higgins", "Gerald A.", ""], ["Reamaroon", "Narathip", ""], ["Soroushmehr", "S. M. Reza", ""], ["Allyn-Feuer", "Ari", ""], ["Dinov", "Ivo D.", ""], ["Najarian", "Kayvan", ""], ["Athey", "Brian D.", ""]]}, {"id": "1801.08577", "submitter": "Jayanta Dutta", "authors": "Jayanta K Dutta, Jiayi Liu, Unmesh Kurup and Mohak Shah", "title": "Effective Building Block Design for Deep Convolutional Neural Networks\n  using Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has shown promising results on many machine learning tasks but\nDL models are often complex networks with large number of neurons and layers,\nand recently, complex layer structures known as building blocks. Finding the\nbest deep model requires a combination of finding both the right architecture\nand the correct set of parameters appropriate for that architecture. In\naddition, this complexity (in terms of layer types, number of neurons, and\nnumber of layers) also present problems with generalization since larger\nnetworks are easier to overfit to the data. In this paper, we propose a search\nframework for finding effective architectural building blocks for convolutional\nneural networks (CNN). Our approach is much faster at finding models that are\nclose to state-of-the-art in performance. In addition, the models discovered by\nour approach are also smaller than models discovered by similar techniques. We\nachieve these twin advantages by designing our search space in such a way that\nit searches over a reduced set of state-of-the-art building blocks for CNNs\nincluding residual block, inception block, inception-residual block, ResNeXt\nblock and many others. We apply this technique to generate models for multiple\nimage datasets and show that these models achieve performance comparable to\nstate-of-the-art (and even surpassing the state-of-the-art in one case). We\nalso show that learned models are transferable between datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 19:40:44 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Dutta", "Jayanta K", ""], ["Liu", "Jiayi", ""], ["Kurup", "Unmesh", ""], ["Shah", "Mohak", ""]]}, {"id": "1801.08618", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, Mohammad Saeed Abrishami, Massoud Pedram", "title": "JointDNN: An Efficient Training and Inference Engine for Intelligent\n  Mobile Cloud Computing Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are being deployed in many mobile intelligent\napplications. End-side services, such as intelligent personal assistants,\nautonomous cars, and smart home services often employ either simple local\nmodels on the mobile or complex remote models on the cloud. However, recent\nstudies have shown that partitioning the DNN computations between the mobile\nand cloud can increase the latency and energy efficiencies. In this paper, we\npropose an efficient, adaptive, and practical engine, JointDNN, for\ncollaborative computation between a mobile device and cloud for DNNs in both\ninference and training phase. JointDNN not only provides an energy and\nperformance efficient method of querying DNNs for the mobile side but also\nbenefits the cloud server by reducing the amount of its workload and\ncommunications compared to the cloud-only approach. Given the DNN architecture,\nwe investigate the efficiency of processing some layers on the mobile device\nand some layers on the cloud server. We provide optimization formulations at\nlayer granularity for forward- and backward-propagations in DNNs, which can\nadapt to mobile battery limitations and cloud server load constraints and\nquality of service. JointDNN achieves up to 18 and 32 times reductions on the\nlatency and mobile energy consumption of querying DNNs compared to the\nstatus-quo approaches, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 22:20:11 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 20:53:08 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Abrishami", "Mohammad Saeed", ""], ["Pedram", "Massoud", ""]]}, {"id": "1801.08621", "submitter": "Ian Taras", "authors": "Ian Taras and Dylan Malone Stuart", "title": "Quantization Error as a Metric for Dynamic Precision Scaling in Neural\n  Net Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has explored reduced numerical precision for parameters,\nactivations, and gradients during neural network training as a way to reduce\nthe computational cost of training (Na & Mukhopadhyay, 2016) (Courbariaux et\nal., 2014). We present a novel dynamic precision scaling (DPS) scheme. Using\nstochastic fixed-point rounding, a quantization-error based scaling scheme, and\ndynamic bit-widths during training, we achieve 98.8% test accuracy on the MNIST\ndataset using an average bit-width of just 16 bits for weights and 14 bits for\nactivations, compared to the standard 32-bit floating point values used in deep\nlearning frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 22:24:27 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 17:52:36 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Taras", "Ian", ""], ["Stuart", "Dylan Malone", ""]]}, {"id": "1801.08640", "submitter": "Sarah Tan", "authors": "Sarah Tan, Rich Caruana, Giles Hooker, Paul Koch, Albert Gordo", "title": "Learning Global Additive Explanations for Neural Nets Using Model\n  Distillation", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/214", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability has largely focused on local explanations, i.e. explaining\nwhy a model made a particular prediction for a sample. These explanations are\nappealing due to their simplicity and local fidelity. However, they do not\nprovide information about the general behavior of the model. We propose to\nleverage model distillation to learn global additive explanations that describe\nthe relationship between input features and model predictions. These global\nexplanations take the form of feature shapes, which are more expressive than\nfeature attributions. Through careful experimentation, we show qualitatively\nand quantitatively that global additive explanations are able to describe model\nbehavior and yield insights about models such as neural nets. A visualization\nof our approach applied to a neural net as it is trained is available at\nhttps://youtu.be/ErQYwNqzEdc.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 00:23:20 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 02:45:29 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Tan", "Sarah", ""], ["Caruana", "Rich", ""], ["Hooker", "Giles", ""], ["Koch", "Paul", ""], ["Gordo", "Albert", ""]]}, {"id": "1801.08676", "submitter": "Rodrigo Santa Cruz", "authors": "Rodrigo Santa Cruz, Basura Fernando, Anoop Cherian, and Stephen Gould", "title": "Neural Algebra of Classifiers", "comments": "2018 IEEE Winter Conference on Applications of Computer Vision (WACV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is fundamentally compositional, so it is natural to think of visual\nrecognition as the recognition of basic visually primitives that are composed\naccording to well-defined rules. This strategy allows us to recognize unseen\ncomplex concepts from simple visual primitives. However, the current trend in\nvisual recognition follows a data greedy approach where huge amounts of data\nare required to learn models for any desired visual concept. In this paper, we\nbuild on the compositionality principle and develop an \"algebra\" to compose\nclassifiers for complex visual concepts. To this end, we learn neural network\nmodules to perform boolean algebra operations on simple visual classifiers.\nSince these modules form a complete functional set, a classifier for any\ncomplex visual concept defined as a boolean expression of primitives can be\nobtained by recursively applying the learned modules, even if we do not have a\nsingle training sample. As our experiments show, using such a framework, we can\ncompose classifiers for complex visual concepts outperforming standard\nbaselines on two well-known visual recognition benchmarks. Finally, we present\na qualitative analysis of our method and its properties.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 05:13:10 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Cruz", "Rodrigo Santa", ""], ["Fernando", "Basura", ""], ["Cherian", "Anoop", ""], ["Gould", "Stephen", ""]]}, {"id": "1801.08694", "submitter": "Kalyan Ram Ayyalasomayajula", "authors": "Kalyan Ram Ayyalasomayajula, Filip Malmberg, Anders Brun", "title": "PDNet: Semantic Segmentation integrated with a Primal-Dual Network for\n  Document binarization", "comments": "Under consideration for Pattern Recognition Letters Special Issue on\n  Graphonomics for e-citizens: e-health, e-society, e-education 11 pages, 10\n  figures, 2 tables", "journal-ref": null, "doi": "10.1016/j.patrec.2018.05.011", "report-no": "PRLETTERS-D-17-01108", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarization of digital documents is the task of classifying each pixel in an\nimage of the document as belonging to the background (parchment/paper) or\nforeground (text/ink). Historical documents are often subjected to\ndegradations, that make the task challenging. In the current work a deep neural\nnetwork architecture is proposed that combines a fully convolutional network\nwith an unrolled primal-dual network that can be trained end-to-end to achieve\nstate of the art binarization on four out of seven datasets. Document\nbinarization is formulated as an energy minimization problem. A fully\nconvolutional neural network is trained for semantic segmentation of pixels\nthat provides labeling cost associated with each pixel. This cost estimate is\nrefined along the edges to compensate for any over or under estimation of the\nforeground class using a primal-dual approach. We provide necessary overview on\nproximal operator that facilitates theoretical underpinning required to train a\nprimal-dual network using a gradient descent algorithm. Numerical instabilities\nencountered due to the recurrent nature of primal-dual approach are handled. We\nprovide experimental results on document binarization competition dataset along\nwith network changes and hyperparameter tuning required for stability and\nperformance of the network. The network when pre-trained on synthetic dataset\nperforms better as per the competition metrics.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 07:07:07 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 07:08:03 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 10:33:54 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Ayyalasomayajula", "Kalyan Ram", ""], ["Malmberg", "Filip", ""], ["Brun", "Anders", ""]]}, {"id": "1801.08702", "submitter": "Masahiro Suzuki", "authors": "Masahiro Suzuki, Kotaro Nakayama, Yutaka Matsuo", "title": "Improving Bi-directional Generation between Different Modalities with\n  Variational Autoencoders", "comments": "Updated version of arXiv:1611.01891", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate deep generative models that can exchange multiple modalities\nbi-directionally, e.g., generating images from corresponding texts and vice\nversa. A major approach to achieve this objective is to train a model that\nintegrates all the information of different modalities into a joint\nrepresentation and then to generate one modality from the corresponding other\nmodality via this joint representation. We simply applied this approach to\nvariational autoencoders (VAEs), which we call a joint multimodal variational\nautoencoder (JMVAE). However, we found that when this model attempts to\ngenerate a large dimensional modality missing at the input, the joint\nrepresentation collapses and this modality cannot be generated successfully.\nFurthermore, we confirmed that this difficulty cannot be resolved even using a\nknown solution. Therefore, in this study, we propose two models to prevent this\ndifficulty: JMVAE-kl and JMVAE-h. Results of our experiments demonstrate that\nthese methods can prevent the difficulty above and that they generate\nmodalities bi-directionally with equal or higher likelihood than conventional\nVAE methods, which generate in only one direction. Moreover, we confirm that\nthese methods can obtain the joint representation appropriately, so that they\ncan generate various variations of modality by moving over the joint\nrepresentation or changing the value of another modality.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 08:06:34 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Suzuki", "Masahiro", ""], ["Nakayama", "Kotaro", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "1801.08712", "submitter": "Atanas Mirchev", "authors": "Atanas Mirchev, Seyed-Ahmad Ahmadi", "title": "Classification of sparsely labeled spatio-temporal data through\n  semi-supervised adversarial learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Generative Adversarial Networks (GAN) have emerged as a\npowerful method for learning the mapping from noisy latent spaces to realistic\ndata samples in high-dimensional space. So far, the development and application\nof GANs have been predominantly focused on spatial data such as images. In this\nproject, we aim at modeling of spatio-temporal sensor data instead, i.e.\ndynamic data over time. The main goal is to encode temporal data into a global\nand low-dimensional latent vector that captures the dynamics of the\nspatio-temporal signal. To this end, we incorporate auto-regressive RNNs,\nWasserstein GAN loss, spectral norm weight constraints and a semi-supervised\nlearning scheme into InfoGAN, a method for retrieval of meaningful latents in\nadversarial learning. To demonstrate the modeling capability of our method, we\nencode full-body skeletal human motion from a large dataset representing 60\nclasses of daily activities, recorded in a multi-Kinect setup. Initial results\nindicate competitive classification performance of the learned latent\nrepresentations, compared to direct CNN/RNN inference. In future work, we plan\nto apply this method on a related problem in the medical domain, i.e. on\nrecovery of meaningful latents in gait analysis of patients with vertigo and\nbalance disorders.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 08:32:34 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 10:13:35 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Mirchev", "Atanas", ""], ["Ahmadi", "Seyed-Ahmad", ""]]}, {"id": "1801.08788", "submitter": "Marko Nagode", "authors": "Marko Nagode", "title": "Multivariate normal mixture modeling, clustering and classification with\n  the rebmix package", "comments": "15 pages, 6 figures, R code", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rebmix package provides R functions for random univariate and\nmultivariate finite mixture model generation, estimation, clustering and\nclassification. The paper is focused on multivariate normal mixture models with\nunrestricted variance-covariance matrices. The objective is to show how to\ngenerate datasets for a known number of components, numbers of observations and\ncomponent parameters, how to estimate the number of components, component\nweights and component parameters and how to predict cluster and class\nmembership based upon a model trained by the REBMIX algorithm. The accompanying\nplotting, bootstrapping and other features of the package are dealt with, too.\nFor demonstration purpose a multivariate normal dataset with unrestricted\nvariance-covariance matrices is studied.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 12:52:39 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Nagode", "Marko", ""]]}, {"id": "1801.08881", "submitter": "Lucas Parra", "authors": "Lucas C. Parra, Stefan Haufe, Jacek P. Dmochowski", "title": "Correlated Components Analysis - Extracting Reliable Dimensions in\n  Multivariate Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How does one find dimensions in multivariate data that are reliably expressed\nacross repetitions? For example, in a brain imaging study one may want to\nidentify combinations of neural signals that are reliably expressed across\nmultiple trials or subjects. For a behavioral assessment with multiple ratings,\none may want to identify an aggregate score that is reliably reproduced across\nraters. Correlated Components Analysis (CorrCA) addresses this problem by\nidentifying components that are maximally correlated between repetitions (e.g.\ntrials, subjects, raters). Here we formalize this as the maximization of the\nratio of between-repetition to within-repetition covariance. We show that this\ncriterion maximizes repeat-reliability, defined as mean over variance across\nrepeats, and that it leads to CorrCA or to multi-set Canonical Correlation\nAnalysis, depending on the constraints. Surprisingly, we also find that CorrCA\nis equivalent to Linear Discriminant Analysis for zero-mean signals, which\nprovides an unexpected link between classic concepts of multivariate analysis.\nWe present an exact parametric test of statistical significance based on the\nF-statistic for normally distributed independent samples, and present and\nvalidate shuffle statistics for the case of dependent samples. Regularization\nand extension to non-linear mappings using kernels are also presented. The\nalgorithms are demonstrated on a series of data analysis applications, and we\nprovide all code and data required to reproduce the results.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 16:12:07 GMT"}, {"version": "v2", "created": "Sat, 10 Feb 2018 19:19:10 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 16:05:30 GMT"}, {"version": "v4", "created": "Mon, 10 Sep 2018 22:02:19 GMT"}, {"version": "v5", "created": "Sun, 20 Jan 2019 21:15:39 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Parra", "Lucas C.", ""], ["Haufe", "Stefan", ""], ["Dmochowski", "Jacek P.", ""]]}, {"id": "1801.08930", "submitter": "Erin Grant", "authors": "Erin Grant, Chelsea Finn, Sergey Levine, Trevor Darrell, Thomas\n  Griffiths", "title": "Recasting Gradient-Based Meta-Learning as Hierarchical Bayes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning allows an intelligent agent to leverage prior learning episodes\nas a basis for quickly improving performance on a novel task. Bayesian\nhierarchical modeling provides a theoretical framework for formalizing\nmeta-learning as inference for a set of parameters that are shared across\ntasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML)\nof Finn et al. (2017) as a method for probabilistic inference in a hierarchical\nBayesian model. In contrast to prior methods for meta-learning via hierarchical\nBayes, MAML is naturally applicable to complex function approximators through\nits use of a scalable gradient descent procedure for posterior inference.\nFurthermore, the identification of MAML as hierarchical Bayes provides a way to\nunderstand the algorithm's operation as a meta-learning procedure, as well as\nan opportunity to make use of computational strategies for efficient inference.\nWe use this opportunity to propose an improvement to the MAML algorithm that\nmakes use of techniques from approximate inference and curvature estimation.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 18:47:02 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Grant", "Erin", ""], ["Finn", "Chelsea", ""], ["Levine", "Sergey", ""], ["Darrell", "Trevor", ""], ["Griffiths", "Thomas", ""]]}, {"id": "1801.08985", "submitter": "Steven Hickson", "authors": "Steven Hickson, Anelia Angelova, Irfan Essa, Rahul Sukthankar", "title": "Object category learning and retrieval with weak supervision", "comments": "Camera-ready version for NIPS 2017 workshop Learning with Limited\n  Labeled Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of retrieving objects from image data and learning to\nclassify them into meaningful semantic categories with minimal supervision. To\nthat end, we propose a fully differentiable unsupervised deep clustering\napproach to learn semantic classes in an end-to-end fashion without individual\nclass labeling using only unlabeled object proposals. The key contributions of\nour work are 1) a kmeans clustering objective where the clusters are learned as\nparameters of the network and are represented as memory units, and 2)\nsimultaneously building a feature representation, or embedding, while learning\nto cluster it. This approach shows promising results on two popular computer\nvision datasets: on CIFAR10 for clustering objects, and on the more complex and\nchallenging Cityscapes dataset for semantically discovering classes which\nvisually correspond to cars, people, and bicycles. Currently, the only\nsupervision provided is segmentation objectness masks, but this method can be\nextended to use an unsupervised objectness-based object generation mechanism\nwhich will make the approach completely unsupervised.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 21:47:59 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 20:22:15 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Hickson", "Steven", ""], ["Angelova", "Anelia", ""], ["Essa", "Irfan", ""], ["Sukthankar", "Rahul", ""]]}, {"id": "1801.09028", "submitter": "Jonathan Kuck", "authors": "Jonathan Kuck, Ashish Sabharwal, Stefano Ermon", "title": "Approximate Inference via Weighted Rademacher Complexity", "comments": "In AAAI 2018 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rademacher complexity is often used to characterize the learnability of a\nhypothesis class and is known to be related to the class size. We leverage this\nobservation and introduce a new technique for estimating the size of an\narbitrary weighted set, defined as the sum of weights of all elements in the\nset. Our technique provides upper and lower bounds on a novel generalization of\nRademacher complexity to the weighted setting in terms of the weighted set\nsize. This generalizes Massart's Lemma, a known upper bound on the Rademacher\ncomplexity in terms of the unweighted set size. We show that the weighted\nRademacher complexity can be estimated by solving a randomly perturbed\noptimization problem, allowing us to derive high-probability bounds on the size\nof any weighted set. We apply our method to the problems of calculating the\npartition function of an Ising model and computing propositional model counts\n(#SAT). Our experiments demonstrate that we can produce tighter bounds than\ncompeting methods in both the weighted and unweighted settings.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 02:52:33 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Kuck", "Jonathan", ""], ["Sabharwal", "Ashish", ""], ["Ermon", "Stefano", ""]]}, {"id": "1801.09197", "submitter": "Markus Lange-Hegermann", "authors": "Markus Lange-Hegermann", "title": "Algorithmic Linearly Constrained Gaussian Processes", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We algorithmically construct multi-output Gaussian process priors which\nsatisfy linear differential equations. Our approach attempts to parametrize all\nsolutions of the equations using Gr\\\"obner bases. If successful, a push forward\nGaussian process along the paramerization is the desired prior. We consider\nseveral examples from physics, geomathematics and control, among them the full\ninhomogeneous system of Maxwell's equations. By bringing together stochastic\nlearning and computer algebra in a novel way, we combine noisy observations\nwith precise algebraic computations.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 09:07:05 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 13:51:01 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 17:33:23 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Lange-Hegermann", "Markus", ""]]}, {"id": "1801.09319", "submitter": "Olexandr Isayev", "authors": "Justin S. Smith, Ben Nebgen, Nicholas Lubbers, Olexandr Isayev, Adrian\n  E. Roitberg", "title": "Less is more: sampling chemical space with active learning", "comments": "Accepted at J. Chem. Phys", "journal-ref": "J. Chem. Phys. 148, 241733 (2018)", "doi": "10.1063/1.5023802", "report-no": null, "categories": "physics.comp-ph cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of accurate and transferable machine learning (ML) potentials\nfor predicting molecular energetics is a challenging task. The process of data\ngeneration to train such ML potentials is a task neither well understood nor\nresearched in detail. In this work, we present a fully automated approach for\nthe generation of datasets with the intent of training universal ML potentials.\nIt is based on the concept of active learning (AL) via Query by Committee\n(QBC), which uses the disagreement between an ensemble of ML potentials to\ninfer the reliability of the ensemble's prediction. QBC allows the presented AL\nalgorithm to automatically sample regions of chemical space where the ML\npotential fails to accurately predict the potential energy. AL improves the\noverall fitness of ANAKIN-ME (ANI) deep learning potentials in rigorous test\ncases by mitigating human biases in deciding what new training data to use. AL\nalso reduces the training set size to a fraction of the data required when\nusing naive random sampling techniques. To provide validation of our AL\napproach we develop the COMP6 benchmark (publicly available on GitHub), which\ncontains a diverse set of organic molecules. Through the AL process, it is\nshown that the AL-based potentials perform as well as the ANI-1 potential on\nCOMP6 with only 10% of the data, and vastly outperforms ANI-1 with 25% the\namount of data. Finally, we show that our proposed AL technique develops a\nuniversal ANI potential (ANI-1x) that provides accurate energy and force\npredictions on the entire COMP6 benchmark. This universal ML potential achieves\na level of accuracy on par with the best ML potentials for single molecule or\nmaterials, while remaining applicable to the general class of organic molecules\ncomprised of the elements CHNO.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 23:48:01 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 15:51:41 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Smith", "Justin S.", ""], ["Nebgen", "Ben", ""], ["Lubbers", "Nicholas", ""], ["Isayev", "Olexandr", ""], ["Roitberg", "Adrian E.", ""]]}, {"id": "1801.09321", "submitter": "Saikat Roy", "authors": "Arindam Das, Saikat Roy, Ujjwal Bhattacharya, Swapan Kumar Parui", "title": "Document Image Classification with Intra-Domain Transfer Learning and\n  Stacked Generalization of Deep Convolutional Neural Networks", "comments": "Accepted in 24th International Conference in Pattern Recognition\n  (ICPR), Beijing, China, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a region-based Deep Convolutional Neural Network framework is\nproposed for document structure learning. The contribution of this work\ninvolves efficient training of region based classifiers and effective\nensembling for document image classification. A primary level of `inter-domain'\ntransfer learning is used by exporting weights from a pre-trained VGG16\narchitecture on the ImageNet dataset to train a document classifier on whole\ndocument images. Exploiting the nature of region based influence modelling, a\nsecondary level of `intra-domain' transfer learning is used for rapid training\nof deep learning models for image segments. Finally, stacked generalization\nbased ensembling is utilized for combining the predictions of the base deep\nneural network models. The proposed method achieves state-of-the-art accuracy\nof 92.2% on the popular RVL-CDIP document image dataset, exceeding benchmarks\nset by existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 00:03:54 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 17:03:21 GMT"}, {"version": "v3", "created": "Thu, 30 Aug 2018 21:54:44 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Das", "Arindam", ""], ["Roy", "Saikat", ""], ["Bhattacharya", "Ujjwal", ""], ["Parui", "Swapan Kumar", ""]]}, {"id": "1801.09335", "submitter": "Jason Kuen", "authors": "Jason Kuen, Xiangfei Kong, Zhe Lin, Gang Wang, Jianxiong Yin, Simon\n  See, Yap-Peng Tan", "title": "Stochastic Downsampling for Cost-Adjustable Inference and Improved\n  Regularization in Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is desirable to train convolutional networks (CNNs) to run more\nefficiently during inference. In many cases however, the computational budget\nthat the system has for inference cannot be known beforehand during training,\nor the inference budget is dependent on the changing real-time resource\navailability. Thus, it is inadequate to train just inference-efficient CNNs,\nwhose inference costs are not adjustable and cannot adapt to varied inference\nbudgets. We propose a novel approach for cost-adjustable inference in CNNs -\nStochastic Downsampling Point (SDPoint). During training, SDPoint applies\nfeature map downsampling to a random point in the layer hierarchy, with a\nrandom downsampling ratio. The different stochastic downsampling configurations\nknown as SDPoint instances (of the same model) have computational costs\ndifferent from each other, while being trained to minimize the same prediction\nloss. Sharing network parameters across different instances provides\nsignificant regularization boost. During inference, one may handpick a SDPoint\ninstance that best fits the inference budget. The effectiveness of SDPoint, as\nboth a cost-adjustable inference approach and a regularizer, is validated\nthrough extensive experiments on image classification.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 01:16:03 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Kuen", "Jason", ""], ["Kong", "Xiangfei", ""], ["Lin", "Zhe", ""], ["Wang", "Gang", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""], ["Tan", "Yap-Peng", ""]]}, {"id": "1801.09344", "submitter": "Aditi Raghunathan", "authors": "Aditi Raghunathan, Jacob Steinhardt, Percy Liang", "title": "Certified Defenses against Adversarial Examples", "comments": "Published at the International Conference on Learning Representations\n  (ICLR) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks have achieved high accuracy on standard image\nclassification benchmarks, their accuracy drops to nearly zero in the presence\nof small adversarial perturbations to test inputs. Defenses based on\nregularization and adversarial training have been proposed, but often followed\nby new, stronger attacks that defeat these defenses. Can we somehow end this\narms race? In this work, we study this problem for neural networks with one\nhidden layer. We first propose a method based on a semidefinite relaxation that\noutputs a certificate that for a given network and test input, no attack can\nforce the error to exceed a certain value. Second, as this certificate is\ndifferentiable, we jointly optimize it with the network parameters, providing\nan adaptive regularizer that encourages robustness against all attacks. On\nMNIST, our approach produces a network and a certificate that no attack that\nperturbs each pixel by at most \\epsilon = 0.1 can cause more than 35% test\nerror.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 02:08:21 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 23:38:30 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Raghunathan", "Aditi", ""], ["Steinhardt", "Jacob", ""], ["Liang", "Percy", ""]]}, {"id": "1801.09354", "submitter": "Nayyar Zaidi", "authors": "Nayyar A. Zaidi, Geoffrey I. Webb, Francois Petitjean, Germain\n  Forestier", "title": "On the Inter-relationships among Drift rate, Forgetting rate,\n  Bias/variance profile and Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two general and falsifiable hypotheses about expectations on\ngeneralization error when learning in the context of concept drift. One posits\nthat as drift rate increases, the forgetting rate that minimizes generalization\nerror will also increase and vice versa. The other posits that as a learner's\nforgetting rate increases, the bias/variance profile that minimizes\ngeneralization error will have lower variance and vice versa. These hypotheses\nlead to the concept of the sweet path, a path through the 3-d space of\nalternative drift rates, forgetting rates and bias/variance profiles on which\ngeneralization error will be minimized, such that slow drift is coupled with\nlow forgetting and low bias, while rapid drift is coupled with fast forgetting\nand low variance. We present experiments that support the existence of such a\nsweet path. We also demonstrate that simple learners that select appropriate\nforgetting rates and bias/variance profiles are highly competitive with the\nstate-of-the-art in incremental learners for concept drift on real-world drift\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 03:35:55 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 01:18:03 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Zaidi", "Nayyar A.", ""], ["Webb", "Geoffrey I.", ""], ["Petitjean", "Francois", ""], ["Forestier", "Germain", ""]]}, {"id": "1801.09390", "submitter": "Yanning Shen", "authors": "Yanning Shen, Panagiotis A. Traganitis, Georgios B. Giannakis", "title": "Nonlinear Dimensionality Reduction on Graphs", "comments": "Dimensionality reduction, nonlinear modeling, signal processing over\n  graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of data deluge, many signal processing and machine learning tasks\nare faced with high-dimensional datasets, including images, videos, as well as\ntime series generated from social, commercial and brain network interactions.\nTheir efficient processing calls for dimensionality reduction techniques\ncapable of properly compressing the data while preserving task-related\ncharacteristics, going beyond pairwise data correlations. The present paper\nputs forth a nonlinear dimensionality reduction framework that accounts for\ndata lying on known graphs. The novel framework encompasses most of the\nexisting dimensionality reduction methods, but it is also capable of capturing\nand preserving possibly nonlinear correlations that are ignored by linear\nmethods. Furthermore, it can take into account information from multiple\ngraphs. The proposed algorithms were tested on synthetic as well as real\ndatasets to corroborate their effectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 08:11:04 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 06:56:17 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Shen", "Yanning", ""], ["Traganitis", "Panagiotis A.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1801.09403", "submitter": "Franco Manessi", "authors": "Franco Manessi and Alessandro Rozza", "title": "Learning Combinations of Activation Functions", "comments": "6 pages, 3 figures. Published as a conference paper at ICPR 2018.\n  Code:\n  https://bitbucket.org/francux/learning_combinations_of_activation_functions", "journal-ref": "2018 24th International Conference on Pattern Recognition (ICPR),\n  Beijing, 2018, pp. 61-66", "doi": "10.1109/ICPR.2018.8545362", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, an active area of research has been devoted to design\nnovel activation functions that are able to help deep neural networks to\nconverge, obtaining better performance. The training procedure of these\narchitectures usually involves optimization of the weights of their layers\nonly, while non-linearities are generally pre-specified and their (possible)\nparameters are usually considered as hyper-parameters to be tuned manually. In\nthis paper, we introduce two approaches to automatically learn different\ncombinations of base activation functions (such as the identity function, ReLU,\nand tanh) during the training phase. We present a thorough comparison of our\nnovel approaches with well-known architectures (such as LeNet-5, AlexNet, and\nResNet-56) on three standard datasets (Fashion-MNIST, CIFAR-10, and\nILSVRC-2012), showing substantial improvements in the overall performance, such\nas an increase in the top-1 accuracy for AlexNet on ILSVRC-2012 of 3.01\npercentage points.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 08:54:13 GMT"}, {"version": "v2", "created": "Sun, 6 Jan 2019 14:00:50 GMT"}, {"version": "v3", "created": "Thu, 25 Apr 2019 15:21:53 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Manessi", "Franco", ""], ["Rozza", "Alessandro", ""]]}, {"id": "1801.09419", "submitter": "Thibaut Le Gouic", "authors": "Thibaut Le Gouic (1), Quentin Paris (2) ((1) I2M, (2) CS-HSE)", "title": "A notion of stability for k-means clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we define and study a new notion of stability for the\n$k$-means clustering scheme building upon the notion of quantization of a\nprobability measure. We connect this notion of stability to a geometric feature\nof the underlying distribution of the data, named absolute margin condition,\ninspired by recent works on the subject.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 09:39:10 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 15:38:56 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Gouic", "Thibaut Le", "", "I2M"], ["Paris", "Quentin", "", "CS-HSE"]]}, {"id": "1801.09496", "submitter": "Gaurav Singh", "authors": "Gaurav Singh, James Thomas and John Shawe-Taylor", "title": "Improving Active Learning in Systematic Reviews", "comments": "10 pages, many figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic reviews are essential to summarizing the results of different\nclinical and social science studies. The first step in a systematic review task\nis to identify all the studies relevant to the review. The task of identifying\nrelevant studies for a given systematic review is usually performed manually,\nand as a result, involves substantial amounts of expensive human resource.\nLately, there have been some attempts to reduce this manual effort using active\nlearning. In this work, we build upon some such existing techniques, and\nvalidate by experimenting on a larger and comprehensive dataset than has been\nattempted until now. Our experiments provide insights on the use of different\nfeature extraction models for different disciplines. More importantly, we\nidentify that a naive active learning based screening process is biased in\nfavour of selecting similar documents. We aimed to improve the performance of\nthe screening process using a novel active learning algorithm with success.\nAdditionally, we propose a mechanism to choose the best feature extraction\nmethod for a given review.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 13:26:48 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Singh", "Gaurav", ""], ["Thomas", "James", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1801.09520", "submitter": "Guang-Hong Chen", "authors": "Juan C. Montoya, Yinsheng Li, Charles Strother, and Guang-Hong Chen", "title": "Deep Learning Angiography (DLA): Three-dimensional C-arm Cone Beam CT\n  Angiography Using Deep Learning", "comments": "26 pages, 4 figures, 2 tables. Accepted for publication at Americal\n  Journal of Neuroradiology (AJNR), 2018 (in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Purpose: Our purpose was to develop a deep learning\nangiography (DLA) method to generate 3D cerebral angiograms from a single\ncontrast-enhanced acquisition.\n  Material and Methods: Under an approved IRB protocol 105 3D-DSA exams were\nrandomly selected from an internal database. All were acquired using a clinical\nsystem (Axiom Artis zee, Siemens Healthineers) in conjunction with a standard\ninjection protocol. More than 150 million labeled voxels from 35 subjects were\nused for training. A deep convolutional neural network was trained to classify\neach image voxel into three tissue types (vasculature, bone and soft tissue).\nThe trained DLA model was then applied for tissue classification in a\nvalidation cohort of 8 subjects and a final testing cohort consisting of the\nremaining 62 subjects. The final vasculature tissue class was used to generate\nthe 3D-DLA images. To quantify the generalization error of the trained model,\naccuracy, sensitivity, precision and F1-scores were calculated for vasculature\nclassification in relevant anatomy. The 3D-DLA and clinical 3D-DSA images were\nsubject to a qualitative assessment for the presence of inter-sweep motion\nartifacts.\n  Results: Vasculature classification accuracy and 95% CI in the testing\ndataset was 98.7% ([98.3, 99.1] %). No residual signal from osseous structures\nwas observed for all 3D-DLA testing cases except for small regions in the otic\ncapsule and nasal cavity compared to 37% (23/62) of the 3D-DSAs.\n  Conclusion: DLA accurately recreated the vascular anatomy of the 3D-DSA\nreconstructions without mask. DLA reduced mis-registration artifacts induced by\ninter-sweep motion. DLA reduces radiation exposure required to obtain\nclinically useful 3D-DSA\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 15:54:11 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Montoya", "Juan C.", ""], ["Li", "Yinsheng", ""], ["Strother", "Charles", ""], ["Chen", "Guang-Hong", ""]]}, {"id": "1801.09522", "submitter": "Sharath Adavanne", "authors": "Sharath Adavanne, Archontis Politis, Tuomas Virtanen", "title": "Multichannel Sound Event Detection Using 3D Convolutional Neural\n  Networks for Learning Inter-channel Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a stacked convolutional and recurrent neural\nnetwork (CRNN) with a 3D convolutional neural network (CNN) in the first layer\nfor the multichannel sound event detection (SED) task. The 3D CNN enables the\nnetwork to simultaneously learn the inter- and intra-channel features from the\ninput multichannel audio. In order to evaluate the proposed method,\nmultichannel audio datasets with different number of overlapping sound sources\nare synthesized. Each of this dataset has a four-channel first-order Ambisonic,\nbinaural, and single-channel versions, on which the performance of SED using\nthe proposed method are compared to study the potential of SED using\nmultichannel audio. A similar study is also done with the binaural and\nsingle-channel versions of the real-life recording TUT-SED 2017 development\ndataset. The proposed method learns to recognize overlapping sound events from\nmultichannel features faster and performs better SED with a fewer number of\ntraining epochs. The results show that on using multichannel Ambisonic audio in\nplace of single-channel audio we improve the overall F-score by 7.5%, overall\nerror rate by 10% and recognize 15.6% more sound events in time frames with\nfour overlapping sound sources.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 14:24:39 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Adavanne", "Sharath", ""], ["Politis", "Archontis", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1801.09546", "submitter": "Michael Lash", "authors": "Michael T. Lash and Jason Slater and Philip M. Polgreen and Alberto M.\n  Segre", "title": "21 Million Opportunities: A 19 Facility Investigation of Factors\n  Affecting Hand Hygiene Compliance via Linear Predictive Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.03540", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This large-scale study, consisting of 21.3 million hand hygiene opportunities\nfrom 19 distinct facilities in 10 different states, uses linear predictive\nmodels to expose factors that may affect hand hygiene compliance. We examine\nthe use of features such as temperature, relative humidity, influenza severity,\nday/night shift, federal holidays and the presence of new medical residents in\npredicting daily hand hygiene compliance; the investigation is undertaken using\nboth a \"global\" model to glean general trends, and facility-specific models to\nelicit facility-specific insights. The results suggest that colder temperatures\nand federal holidays have an adverse effect on hand hygiene compliance rates,\nand that individual cultures and attitudes regarding hand hygiene exist among\nfacilities.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 04:40:59 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Lash", "Michael T.", ""], ["Slater", "Jason", ""], ["Polgreen", "Philip M.", ""], ["Segre", "Alberto M.", ""]]}, {"id": "1801.09555", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Chaochun Liu, Wei Fan, Xiaohui Xie", "title": "DeepLung: Deep 3D Dual Path Nets for Automated Pulmonary Nodule\n  Detection and Classification", "comments": "9 pages, 8 figures, IEEE WACV conference. arXiv admin note:\n  substantial text overlap with arXiv:1709.05538", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a fully automated lung computed tomography (CT)\ncancer diagnosis system, DeepLung. DeepLung consists of two components, nodule\ndetection (identifying the locations of candidate nodules) and classification\n(classifying candidate nodules into benign or malignant). Considering the 3D\nnature of lung CT data and the compactness of dual path networks (DPN), two\ndeep 3D DPN are designed for nodule detection and classification respectively.\nSpecifically, a 3D Faster Regions with Convolutional Neural Net (R-CNN) is\ndesigned for nodule detection with 3D dual path blocks and a U-net-like\nencoder-decoder structure to effectively learn nodule features. For nodule\nclassification, gradient boosting machine (GBM) with 3D dual path network\nfeatures is proposed. The nodule classification subnetwork was validated on a\npublic dataset from LIDC-IDRI, on which it achieved better performance than\nstate-of-the-art approaches and surpassed the performance of experienced\ndoctors based on image modality. Within the DeepLung system, candidate nodules\nare detected first by the nodule detection subnetwork, and nodule diagnosis is\nconducted by the classification subnetwork. Extensive experimental results\ndemonstrate that DeepLung has performance comparable to experienced doctors\nboth for the nodule-level and patient-level diagnosis on the LIDC-IDRI\ndataset.\\footnote{https://github.com/uci-cbcl/DeepLung.git}\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 23:22:00 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Zhu", "Wentao", ""], ["Liu", "Chaochun", ""], ["Fan", "Wei", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1801.09573", "submitter": "Enkhtogtokh Togootogtokh", "authors": "Enkhtogtokh Togootogtokh, Amarzaya Amartuvshin", "title": "Deep Learning Approach for Very Similar Objects Recognition Application\n  on Chihuahua and Muffin Problem", "comments": "8 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem to tackle the very similar objects like Chihuahua or\nmuffin problem to recognize at least in human vision level. Our regular deep\nstructured machine learning still does not solve it. We saw many times for\nabout year in our community the problem. Today we proposed the state-of-the-art\nsolution for it. Our approach is quite tricky to get the very high accuracy. We\npropose the deep transfer learning method which could be tackled all this type\nof problems not limited to just Chihuahua or muffin problem. It is the best\nmethod to train with small data set not like require huge amount data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 15:25:49 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Togootogtokh", "Enkhtogtokh", ""], ["Amartuvshin", "Amarzaya", ""]]}, {"id": "1801.09624", "submitter": "Erik Talvitie", "authors": "Erik Talvitie", "title": "Learning the Reward Function for a Misspecified Model", "comments": "To appear at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based reinforcement learning it is typical to decouple the problems\nof learning the dynamics model and learning the reward function. However, when\nthe dynamics model is flawed, it may generate erroneous states that would never\noccur in the true environment. It is not clear a priori what value the reward\nfunction should assign to such states. This paper presents a novel error bound\nthat accounts for the reward model's behavior in states sampled from the model.\nThis bound is used to extend the existing Hallucinated DAgger-MC algorithm,\nwhich offers theoretical performance guarantees in deterministic MDPs that do\nnot assume a perfect model can be learned. Empirically, this approach to reward\nlearning can yield dramatic improvements in control performance when the\ndynamics model is flawed.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 16:56:49 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 17:10:38 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 20:07:29 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Talvitie", "Erik", ""]]}, {"id": "1801.09627", "submitter": "Motoya Ohnishi", "authors": "Motoya Ohnishi, Li Wang, Gennaro Notomista, Magnus Egerstedt", "title": "Barrier-Certified Adaptive Reinforcement Learning with Applications to\n  Brushbot Navigation", "comments": "\\copyright 2019 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "Published in IEEE Transactions on Robotics, 2019", "doi": "10.1109/TRO.2019.2920206", "report-no": null, "categories": "cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a safe learning framework that employs an adaptive model\nlearning algorithm together with barrier certificates for systems with possibly\nnonstationary agent dynamics. To extract the dynamic structure of the model, we\nuse a sparse optimization technique. We use the learned model in combination\nwith control barrier certificates which constrain policies (feedback\ncontrollers) in order to maintain safety, which refers to avoiding particular\nundesirable regions of the state space. Under certain conditions, recovery of\nsafety in the sense of Lyapunov stability after violations of safety due to the\nnonstationarity is guaranteed. In addition, we reformulate an action-value\nfunction approximation to make any kernel-based nonlinear function estimation\nmethod applicable to our adaptive learning framework. Lastly, solutions to the\nbarrier-certified policy optimization are guaranteed to be globally optimal,\nensuring the greedy policy improvement under mild conditions. The resulting\nframework is validated via simulations of a quadrotor, which has previously\nbeen used under stationarity assumptions in the safe learnings literature, and\nis then tested on a real robot, the brushbot, whose dynamics is unknown, highly\ncomplex and nonstationary.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 17:04:45 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 06:20:30 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 10:43:58 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Ohnishi", "Motoya", ""], ["Wang", "Li", ""], ["Notomista", "Gennaro", ""], ["Egerstedt", "Magnus", ""]]}, {"id": "1801.09657", "submitter": "Deanna Needell", "authors": "Denali Molitor and Deanna Needell", "title": "Matrix Completion for Structured Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to predict or fill-in missing data, often referred to as matrix\ncompletion, is a common challenge in today's data-driven world. Previous\nstrategies typically assume that no structural difference between observed and\nmissing entries exists. Unfortunately, this assumption is woefully unrealistic\nin many applications. For example, in the classic Netflix challenge, in which\none hopes to predict user-movie ratings for unseen films, the fact that the\nviewer has not watched a given movie may indicate a lack of interest in that\nmovie, thus suggesting a lower rating than otherwise expected. We propose\nadjusting the standard nuclear norm minimization strategy for matrix completion\nto account for such structural differences between observed and unobserved\nentries by regularizing the values of the unobserved entries. We show that the\nproposed method outperforms nuclear norm minimization in certain settings.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 18:31:47 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Molitor", "Denali", ""], ["Needell", "Deanna", ""]]}, {"id": "1801.09710", "submitter": "Nils Thuerey", "authors": "You Xie, Erik Franz, Mengyu Chu, Nils Thuerey", "title": "tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution\n  Fluid Flow", "comments": "ACM Transaction on Graphics (SIGGRAPH 2018), further info:\n  https://ge.in.tum.de/publications/tempogan/", "journal-ref": "ACM Trans. Graph. 37, 4, Article 95 (July 2018)", "doi": "10.1145/3072959.3073643", "report-no": null, "categories": "cs.LG cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a temporally coherent generative model addressing the\nsuper-resolution problem for fluid flows. Our work represents a first approach\nto synthesize four-dimensional physics fields with neural networks. Based on a\nconditional generative adversarial network that is designed for the inference\nof three-dimensional volumetric data, our model generates consistent and\ndetailed results by using a novel temporal discriminator, in addition to the\ncommonly used spatial one. Our experiments show that the generator is able to\ninfer more realistic high-resolution details by using additional physical\nquantities, such as low-resolution velocities or vorticities. Besides\nimprovements in the training process and in the generated outputs, these inputs\noffer means for artistic control as well. We additionally employ a\nphysics-aware data augmentation step, which is crucial to avoid overfitting and\nto reduce memory requirements. In this way, our network learns to generate\nadvected quantities with highly detailed, realistic, and temporally coherent\nfeatures. Our method works instantaneously, using only a single time-step of\nlow-resolution fluid data. We demonstrate the abilities of our method using a\nvariety of complex inputs and applications in two and three dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 19:11:13 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 08:49:58 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Xie", "You", ""], ["Franz", "Erik", ""], ["Chu", "Mengyu", ""], ["Thuerey", "Nils", ""]]}, {"id": "1801.09720", "submitter": "Ammar Daskin", "authors": "Ammar Daskin, Sabre Kais", "title": "A Generalized Circuit for the Hamiltonian Dynamics Through the Truncated\n  Series", "comments": "MATLAB source code for the circuits can be downloaded from\n  https://github.com/adaskin/circuitforTaylorseries", "journal-ref": "Quantum Information Processing, 17:328, 2018", "doi": "10.1007/s11128-018-2099-z", "report-no": null, "categories": "quant-ph cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for the Hamiltonian simulation in the\ncontext of eigenvalue estimation problems which improves earlier results\ndealing with Hamiltonian simulation through the truncated Taylor series. In\nparticular, we present a fixed-quantum circuit design for the simulation of the\nHamiltonian dynamics, $H(t)$, through the truncated Taylor series method\ndescribed by Berry et al. \\cite{berry2015simulating}. The circuit is general\nand can be used to simulate any given matrix in the phase estimation algorithm\nby only changing the angle values of the quantum gates implementing the time\nvariable $t$ in the series. The circuit complexity depends on the number of\nsummation terms composing the Hamiltonian and requires $O(Ln)$ number of\nquantum gates for the simulation of a molecular Hamiltonian. Here, $n$ is the\nnumber of states of a spin orbital, and $L$ is the number of terms in the\nmolecular Hamiltonian and generally bounded by $O(n^4)$. We also discuss how to\nuse the circuit in adaptive processes and eigenvalue related problems along\nwith a slight modified version of the iterative phase estimation algorithm. In\naddition, a simple divide and conquer method is presented for mapping a matrix\nwhich are not given as sums of unitary matrices into the circuit. The\ncomplexity of the circuit is directly related to the structure of the matrix\nand can be bounded by $O(poly(n))$ for a matrix with $poly(n)-$sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 19:28:10 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 17:57:46 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 07:54:14 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Daskin", "Ammar", ""], ["Kais", "Sabre", ""]]}, {"id": "1801.09788", "submitter": "Nataliia Ruemmele", "authors": "Natalia Ruemmele, Yuriy Tyshetskiy, Alex Collins", "title": "Evaluating approaches for supervised semantic labeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data sources are still one of the most popular ways to store\nenterprise or Web data, however, the issue with relational schema is the lack\nof a well-defined semantic description. A common ontology provides a way to\nrepresent the meaning of a relational schema and can facilitate the integration\nof heterogeneous data sources within a domain. Semantic labeling is achieved by\nmapping attributes from the data sources to the classes and properties in the\nontology. We formulate this problem as a multi-class classification problem\nwhere previously labeled data sources are used to learn rules for labeling new\ndata sources. The majority of existing approaches for semantic labeling have\nfocused on data integration challenges such as naming conflicts and semantic\nheterogeneity. In addition, machine learning approaches typically have issues\naround class imbalance, lack of labeled instances and relative importance of\nattributes. To address these issues, we develop a new machine learning model\nwith engineered features as well as two deep learning models which do not\nrequire extensive feature engineering. We evaluate our new approaches with the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 22:43:32 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Ruemmele", "Natalia", ""], ["Tyshetskiy", "Yuriy", ""], ["Collins", "Alex", ""]]}, {"id": "1801.09797", "submitter": "{\\L}ukasz Kaiser", "authors": "{\\L}ukasz Kaiser and Samy Bengio", "title": "Discrete Autoencoders for Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recurrent models for sequences have been recently successful at many tasks,\nespecially for language modeling and machine translation. Nevertheless, it\nremains challenging to extract good representations from these models. For\ninstance, even though language has a clear hierarchical structure going from\ncharacters through words to sentences, it is not apparent in current language\nmodels. We propose to improve the representation in sequence models by\naugmenting current approaches with an autoencoder that is forced to compress\nthe sequence through an intermediate discrete latent space. In order to\npropagate gradients though this discrete representation we introduce an\nimproved semantic hashing technique. We show that this technique performs well\non a newly proposed quantitative efficiency measure. We also analyze latent\ncodes produced by the model showing how they correspond to words and phrases.\nFinally, we present an application of the autoencoder-augmented model to\ngenerating diverse translations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 23:36:11 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Kaiser", "\u0141ukasz", ""], ["Bengio", "Samy", ""]]}, {"id": "1801.09808", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Avinava Dubey, Eric P. Xing", "title": "The Intriguing Properties of Model Explanations", "comments": "Interpretable ML Symposium, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear approximations to the decision boundary of a complex model have become\none of the most popular tools for interpreting predictions. In this paper, we\nstudy such linear explanations produced either post-hoc by a few recent methods\nor generated along with predictions with contextual explanation networks\n(CENs). We focus on two questions: (i) whether linear explanations are always\nconsistent or can be misleading, and (ii) when integrated into the prediction\nprocess, whether and how explanations affect the performance of the model. Our\nanalysis sheds more light on certain properties of explanations produced by\ndifferent methods and suggests that learning models that explain and predict\njointly is often advantageous.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 00:16:45 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Dubey", "Avinava", ""], ["Xing", "Eric P.", ""]]}, {"id": "1801.09810", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat, Avinava Dubey, Eric P. Xing", "title": "Personalized Survival Prediction with Contextual Explanation Networks", "comments": "Machine Learning for Healthcare Workshop, NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and transparent prediction of cancer survival times on the level of\nindividual patients can inform and improve patient care and treatment\npractices. In this paper, we design a model that concurrently learns to\naccurately predict patient-specific survival distributions and to explain its\npredictions in terms of patient attributes such as clinical tests or\nassessments. Our model is flexible and based on a recurrent network, can handle\nvarious modalities of data including temporal measurements, and yet constructs\nand uses simple explanations in the form of patient- and time-specific linear\nregression. For analysis, we use two publicly available datasets and show that\nour networks outperform a number of baselines in prediction while providing a\nway to inspect the reasons behind each prediction.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 00:21:14 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Dubey", "Avinava", ""], ["Xing", "Eric P.", ""]]}, {"id": "1801.09821", "submitter": "Neal Master", "authors": "Neal Master", "title": "Learning to Emulate an Expert Projective Cone Scheduler", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projective cone scheduling defines a large class of rate-stabilizing policies\nfor queueing models relevant to several applications. While there exists\nconsiderable theory on the properties of projective cone schedulers, there is\nlittle practical guidance on choosing the parameters that define them. In this\npaper, we propose an algorithm for designing an automated projective cone\nscheduling system based on observations of an expert projective cone scheduler.\nWe show that the estimated scheduling policy is able to emulate the expert in\nthe sense that the average loss realized by the learned policy will converge to\nzero. Specifically, for a system with $n$ queues observed over a time horizon\n$T$, the average loss for the algorithm is $O(\\ln(T)\\sqrt{\\ln(n)/T})$. This\nupper bound holds regardless of the statistical characteristics of the system.\nThe algorithm uses the multiplicative weights update method and can be applied\nonline so that additional observations of the expert scheduler can be used to\nimprove an existing estimate of the policy. This provides a data-driven method\nfor designing a scheduling policy based on observations of a human expert. We\ndemonstrate the efficacy of the algorithm with a simple numerical example and\ndiscuss several extensions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 01:57:56 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Master", "Neal", ""]]}, {"id": "1801.09827", "submitter": "Pingping Zhang", "authors": "Jie Yang and Pingping Zhang and Yan Liu", "title": "Robustness of classification ability of spiking neural networks", "comments": "Aceppted by Nonlinear Dynamics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that the robustness of artificial neural networks (ANNs) is\nimportant for their wide ranges of applications. In this paper, we focus on the\nrobustness of the classification ability of a spiking neural network which\nreceives perturbed inputs. Actually, the perturbation is allowed to be\narbitrary styles. However, Gaussian perturbation and other regular ones have\nbeen rarely investigated. For classification problems, the closer to the\ndesired point, the more perturbed points there are in the input space. In\naddition, the perturbation may be periodic. Based on these facts, we only\nconsider sinusoidal and Gaussian perturbations in this paper. With the\nSpikeProp algorithm, we perform extensive experiments on the classical XOR\nproblem and other three benchmark datasets. The numerical results show that\nthere is not significant reduction in the classification ability of the network\nif the input signals are subject to sinusoidal and Gaussian perturbations.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 02:34:38 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Yang", "Jie", ""], ["Zhang", "Pingping", ""], ["Liu", "Yan", ""]]}, {"id": "1801.09856", "submitter": "Hu Wang", "authors": "Hu Wang", "title": "ReNN: Rule-embedded Neural Networks", "comments": "poster paper in ICPR, 6 pages, 4 figures, and 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artificial neural network shows powerful ability of inference, but it is\nstill criticized for lack of interpretability and prerequisite needs of big\ndataset. This paper proposes the Rule-embedded Neural Network (ReNN) to\novercome the shortages. ReNN first makes local-based inferences to detect local\npatterns, and then uses rules based on domain knowledge about the local\npatterns to generate rule-modulated map. After that, ReNN makes global-based\ninferences that synthesizes the local patterns and the rule-modulated map. To\nsolve the optimization problem caused by rules, we use a two-stage optimization\nstrategy to train the ReNN model. By introducing rules into ReNN, we can\nstrengthen traditional neural networks with long-term dependencies which are\ndifficult to learn with limited empirical dataset, thus improving inference\naccuracy. The complexity of neural networks can be reduced since long-term\ndependencies are not modeled with neural connections, and thus the amount of\ndata needed to optimize the neural networks can be reduced. Besides, inferences\nfrom ReNN can be analyzed with both local patterns and rules, and thus have\nbetter interpretability. In this paper, ReNN has been validated with a\ntime-series detection problem.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 05:47:01 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 06:57:05 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Wang", "Hu", ""]]}, {"id": "1801.09866", "submitter": "Kyungmin Lee", "authors": "Kyungmin Lee, Chiyoun Park, Namhoon Kim, and Jaewon Lee", "title": "Accelerating recurrent neural network language model based online speech\n  recognition system", "comments": "4 pages, 4 figures, 3 tables, ICASSP2018(Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents methods to accelerate recurrent neural network based\nlanguage models (RNNLMs) for online speech recognition systems. Firstly, a\nlossy compression of the past hidden layer outputs (history vector) with\ncaching is introduced in order to reduce the number of LM queries. Next, RNNLM\ncomputations are deployed in a CPU-GPU hybrid manner, which computes each layer\nof the model on a more advantageous platform. The added overhead by data\nexchanges between CPU and GPU is compensated through a frame-wise batching\nstrategy. The performance of the proposed methods evaluated on LibriSpeech test\nsets indicates that the reduction in history vector precision improves the\naverage recognition speed by 1.23 times with minimum degradation in accuracy.\nOn the other hand, the CPU-GPU hybrid parallelization enables RNNLM based\nreal-time recognition with a four times improvement in speed.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 06:58:50 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Lee", "Kyungmin", ""], ["Park", "Chiyoun", ""], ["Kim", "Namhoon", ""], ["Lee", "Jaewon", ""]]}, {"id": "1801.09870", "submitter": "Benjamin Donnot", "authors": "Benjamin Donnot (1, 2), Isabelle Guyon (1), Marc Schoenauer (1),\n  Antoine Marot, Patrick Panciatici ((1) TAU, (2) LRI)", "title": "Fast Power system security analysis with Guided Dropout", "comments": "European Symposium on Artificial Neural Networks, Apr 2018, Bruges,\n  Belgium", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to efficiently compute load-flows (the steady-state\nof the power-grid for given productions, consumptions and grid topology),\nsubstituting conventional simulators based on differential equation solvers. We\nuse a deep feed-forward neural network trained with load-flows precomputed by\nsimulation. Our architecture permits to train a network on so-called \"n-1\"\nproblems, in which load flows are evaluated for every possible line\ndisconnection, then generalize to \"n-2\" problems without retraining (a clear\nadvantage because of the combinatorial nature of the problem). To that end, we\ndeveloped a technique bearing similarity with \"dropout\", which we named \"guided\ndropout\".\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 07:10:36 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Donnot", "Benjamin", "", "TAU"], ["Guyon", "Isabelle", "", "TAU"], ["Schoenauer", "Marc", "", "TAU"], ["Marot", "Antoine", ""], ["Panciatici", "Patrick", ""]]}, {"id": "1801.09937", "submitter": "Tianlin Liu", "authors": "Tianlin Liu and Dae Gwan Lee", "title": "Binary Compressive Sensing via Smoothed $\\ell_0$ Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Compressive Sensing algorithm for reconstructing binary signals\nfrom its linear measurements. The proposed algorithm minimizes a non-convex\ncost function expressed as a weighted sum of smoothed $\\ell_0$ norms which\ntakes into account the binariness of signals. We show that for binary signals\nthe proposed algorithm outperforms other existing algorithms in recovery rate\nwhile requiring a short run time.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 11:32:51 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 17:10:39 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Liu", "Tianlin", ""], ["Lee", "Dae Gwan", ""]]}, {"id": "1801.09955", "submitter": "Toon Van Craenendonck", "authors": "Toon Van Craenendonck, Sebastijan Dumancic, Hendrik Blockeel", "title": "COBRA: A Fast and Simple Method for Active Clustering with Pairwise\n  Constraints", "comments": "Presented at IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is inherently ill-posed: there often exist multiple valid\nclusterings of a single dataset, and without any additional information a\nclustering system has no way of knowing which clustering it should produce.\nThis motivates the use of constraints in clustering, as they allow users to\ncommunicate their interests to the clustering system. Active constraint-based\nclustering algorithms select the most useful constraints to query, aiming to\nproduce a good clustering using as few constraints as possible. We propose\nCOBRA, an active method that first over-clusters the data by running K-means\nwith a $K$ that is intended to be too large, and subsequently merges the\nresulting small clusters into larger ones based on pairwise constraints. In its\nmerging step, COBRA is able to keep the number of pairwise queries low by\nmaximally exploiting constraint transitivity and entailment. We experimentally\nshow that COBRA outperforms the state of the art in terms of clustering quality\nand runtime, without requiring the number of clusters in advance.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 12:30:50 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Van Craenendonck", "Toon", ""], ["Dumancic", "Sebastijan", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1801.10033", "submitter": "Masun Nabhan Homsi", "authors": "Philip Warrick (1) and Masun Nabhan Homsi (2) ((1) PeriGen. Inc.,\n  Montreal, Canada, (2) Simon Bolivar University, Caracas, Venezuela)", "title": "Cardiac Arrhythmia Detection from ECG Combining Convolutional and Long\n  Short-Term Memory Networks", "comments": "Computing in Cardiology 2017, 4 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: Atrial fibrillation (AF) is a common heart rhythm disorder\nassociated with deadly and debilitating consequences including heart failure,\nstroke, poor mental health, reduced quality of life and death. Having an\nautomatic system that diagnoses various types of cardiac arrhythmias would\nassist cardiologists to initiate appropriate preventive measures and to improve\nthe analysis of cardiac disease. To this end, this paper introduces a new\napproach to detect and classify automatically cardiac arrhythmias in\nelectrocardiograms (ECG) recordings.\n  Methods: The proposed approach used a combination of Convolution Neural\nNetworks (CNNs) and a sequence of Long Short-Term Memory (LSTM) units, with\npooling, dropout and normalization techniques to improve their accuracy. The\nnetwork predicted a classification at every 18th input sample and we selected\nthe final prediction for classification. Results were cross-validated on the\nPhysionet Challenge 2017 training dataset, which contains 8,528 single lead ECG\nrecordings lasting from 9s to just over 60s.\n  Results: Using the proposed structure and no explicit feature selection,\n10-fold stratified cross-validation gave an overall F-measure of 0.83.10-0.015\non the held-out test data (mean-standard deviation over all folds) and 0.80 on\nthe hidden dataset of the Challenge entry server.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 14:59:57 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Warrick", "Philip", ""], ["Homsi", "Masun Nabhan", ""]]}, {"id": "1801.10058", "submitter": "Yuantao Gu", "authors": "Gen Li and Qinghua Liu and Yuantao Gu", "title": "Rigorous Restricted Isometry Property of Low-Dimensional Subspaces", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dimensionality reduction is in demand to reduce the complexity of solving\nlarge-scale problems with data lying in latent low-dimensional structures in\nmachine learning and computer version. Motivated by such need, in this work we\nstudy the Restricted Isometry Property (RIP) of Gaussian random projections for\nlow-dimensional subspaces in $\\mathbb{R}^N$, and rigorously prove that the\nprojection Frobenius norm distance between any two subspaces spanned by the\nprojected data in $\\mathbb{R}^n$ ($n<N$) remain almost the same as the distance\nbetween the original subspaces with probability no less than $1 - {\\rm\ne}^{-\\mathcal{O}(n)}$. Previously the well-known Johnson-Lindenstrauss (JL)\nLemma and RIP for sparse vectors have been the foundation of sparse signal\nprocessing including Compressed Sensing. As an analogy to JL Lemma and RIP for\nsparse vectors, this work allows the use of random projections to reduce the\nambient dimension with the theoretical guarantee that the distance between\nsubspaces after compression is well preserved.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 15:34:41 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Li", "Gen", ""], ["Liu", "Qinghua", ""], ["Gu", "Yuantao", ""]]}, {"id": "1801.10094", "submitter": "Robert Gardner Jr.", "authors": "James Zhang, Ilija Vukotic, Robert Gardner", "title": "Anomaly detection in wide area network mesh using two machine learning\n  anomaly detection algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is the practice of identifying items or events that do not\nconform to an expected behavior or do not correlate with other items in a\ndataset. It has previously been applied to areas such as intrusion detection,\nsystem health monitoring, and fraud detection in credit card transactions. In\nthis paper, we describe a new method for detecting anomalous behavior over\nnetwork performance data, gathered by perfSONAR, using two machine learning\nalgorithms: Boosted Decision Trees (BDT) and Simple Feedforward Neural Network.\nThe effectiveness of each algorithm was evaluated and compared. Both have shown\nsufficient performance and sensitivity.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 16:59:22 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Zhang", "James", ""], ["Vukotic", "Ilija", ""], ["Gardner", "Robert", ""]]}, {"id": "1801.10119", "submitter": "Linbo Qiao", "authors": "Linbo Qiao, Wei Liu, Steven Hoi", "title": "An Incremental Path-Following Splitting Method for Linearly Constrained\n  Nonconvex Nonsmooth Programs", "comments": "There is an error in Theorem 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stationary point of Problem 2 is NOT the stationary point of Problem 1.\nWe are sorry and we are working on fixing this error.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 18:07:01 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 08:29:20 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 06:20:25 GMT"}, {"version": "v4", "created": "Wed, 11 Apr 2018 13:44:16 GMT"}, {"version": "v5", "created": "Tue, 22 May 2018 04:58:25 GMT"}, {"version": "v6", "created": "Sat, 4 Aug 2018 07:12:58 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Qiao", "Linbo", ""], ["Liu", "Wei", ""], ["Hoi", "Steven", ""]]}, {"id": "1801.10123", "submitter": "Philip Mansfield", "authors": "Philip Andrew Mansfield, Quan Wang, Carlton Downey, Li Wan, Ignacio\n  Lopez Moreno", "title": "Links: A High-Dimensional Online Clustering Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel algorithm, called Links, designed to perform online\nclustering on unit vectors in a high-dimensional Euclidean space. The algorithm\nis appropriate when it is necessary to cluster data efficiently as it streams\nin, and is to be contrasted with traditional batch clustering algorithms that\nhave access to all data at once. For example, Links has been successfully\napplied to embedding vectors generated from face images or voice recordings for\nthe purpose of recognizing people, thereby providing real-time identification\nduring video or audio capture.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 18:15:02 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Mansfield", "Philip Andrew", ""], ["Wang", "Quan", ""], ["Downey", "Carlton", ""], ["Wan", "Li", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1801.10130", "submitter": "Taco Cohen", "authors": "Taco S. Cohen, Mario Geiger, Jonas Koehler, Max Welling", "title": "Spherical CNNs", "comments": "Proceedings of the 6th International Conference on Learning\n  Representations (ICLR), 2018", "journal-ref": "Proceedings of the International Conference on Learning\n  Representations, 2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have become the method of choice for\nlearning problems involving 2D planar images. However, a number of problems of\nrecent interest have created a demand for models that can analyze spherical\nimages. Examples include omnidirectional vision for drones, robots, and\nautonomous cars, molecular regression problems, and global weather and climate\nmodelling. A naive application of convolutional networks to a planar projection\nof the spherical signal is destined to fail, because the space-varying\ndistortions introduced by such a projection will make translational weight\nsharing ineffective.\n  In this paper we introduce the building blocks for constructing spherical\nCNNs. We propose a definition for the spherical cross-correlation that is both\nexpressive and rotation-equivariant. The spherical correlation satisfies a\ngeneralized Fourier theorem, which allows us to compute it efficiently using a\ngeneralized (non-commutative) Fast Fourier Transform (FFT) algorithm. We\ndemonstrate the computational efficiency, numerical accuracy, and effectiveness\nof spherical CNNs applied to 3D model recognition and atomization energy\nregression.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 18:28:30 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 08:06:34 GMT"}, {"version": "v3", "created": "Sun, 25 Feb 2018 13:43:49 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Cohen", "Taco S.", ""], ["Geiger", "Mario", ""], ["Koehler", "Jonas", ""], ["Welling", "Max", ""]]}, {"id": "1801.10182", "submitter": "Nathaniel Roth", "authors": "Reuben Brasher, Nat Roth, Justin Wagle", "title": "Sometimes You Want to Go Where Everybody Knows your Name", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-22871-2_44", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new metric for measuring how well a model personalizes to a\nuser's specific preferences. We define personalization as a weighting between\nperformance on user specific data and performance on a more general global\ndataset that represents many different users. This global term serves as a form\nof regularization that forces us to not overfit to individual users who have\nsmall amounts of data. In order to protect user privacy, we add the constraint\nthat we may not centralize or share user data. We also contribute a simple\nexperiment in which we simulate classifying sentiment for users with very\ndistinct vocabularies. This experiment functions as an example of the tension\nbetween doing well globally on all users, and doing well on any specific\nindividual user. It also provides a concrete example of how to employ our new\nmetric to help reason about and resolve this tension. We hope this work can\nhelp frame and ground future work into personalization.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 19:29:04 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Brasher", "Reuben", ""], ["Roth", "Nat", ""], ["Wagle", "Justin", ""]]}, {"id": "1801.10193", "submitter": "Hakime \\\"Ozt\\\"urk", "authors": "Hakime \\\"Ozt\\\"urk, Elif Ozkirimli, Arzucan \\\"Ozg\\\"ur", "title": "DeepDTA: Deep Drug-Target Binding Affinity Prediction", "comments": "extended version", "journal-ref": null, "doi": "10.1093/bioinformatics/bty593", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of novel drug-target (DT) interactions is a substantial\npart of the drug discovery process. Most of the computational methods that have\nbeen proposed to predict DT interactions have focused on binary classification,\nwhere the goal is to determine whether a DT pair interacts or not. However,\nprotein-ligand interactions assume a continuum of binding strength values, also\ncalled binding affinity and predicting this value still remains a challenge.\nThe increase in the affinity data available in DT knowledge-bases allows the\nuse of advanced learning techniques such as deep learning architectures in the\nprediction of binding affinities. In this study, we propose a deep-learning\nbased model that uses only sequence information of both targets and drugs to\npredict DT interaction binding affinities. The few studies that focus on DT\nbinding affinity prediction use either 3D structures of protein-ligand\ncomplexes or 2D features of compounds. One novel approach used in this work is\nthe modeling of protein sequences and compound 1D representations with\nconvolutional neural networks (CNNs). The results show that the proposed deep\nlearning based model that uses the 1D representations of targets and drugs is\nan effective approach for drug target binding affinity prediction. The model in\nwhich high-level representations of a drug and a target are constructed via\nCNNs achieved the best Concordance Index (CI) performance in one of our larger\nbenchmark data sets, outperforming the KronRLS algorithm and SimBoost, a\nstate-of-the-art method for DT binding affinity prediction.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 19:58:35 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 06:34:46 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["\u00d6zt\u00fcrk", "Hakime", ""], ["Ozkirimli", "Elif", ""], ["\u00d6zg\u00fcr", "Arzucan", ""]]}, {"id": "1801.10242", "submitter": "Jonas Mueller", "authors": "Jonas Mueller, Vasilis Syrgkanis, Matt Taddy", "title": "Low-Rank Bandit Methods for High-Dimensional Dynamic Pricing", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider dynamic pricing with many products under an evolving but\nlow-dimensional demand model. Assuming the temporal variation in\ncross-elasticities exhibits low-rank structure based on fixed (latent) features\nof the products, we show that the revenue maximization problem reduces to an\nonline bandit convex optimization with side information given by the observed\ndemands. We design dynamic pricing algorithms whose revenue approaches that of\nthe best fixed price vector in hindsight, at a rate that only depends on the\nintrinsic rank of the demand model and not the number of products. Our approach\napplies a bandit convex optimization algorithm in a projected low-dimensional\nspace spanned by the latent product features, while simultaneously learning\nthis span via online singular value decomposition of a carefully-crafted matrix\ncontaining the observed demands.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 22:19:13 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 03:54:27 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Mueller", "Jonas", ""], ["Syrgkanis", "Vasilis", ""], ["Taddy", "Matt", ""]]}, {"id": "1801.10247", "submitter": "Jie Chen", "authors": "Jie Chen, Tengfei Ma, Cao Xiao", "title": "FastGCN: Fast Learning with Graph Convolutional Networks via Importance\n  Sampling", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph convolutional networks (GCN) recently proposed by Kipf and Welling\nare an effective graph model for semi-supervised learning. This model, however,\nwas originally designed to be learned with the presence of both training and\ntest data. Moreover, the recursive neighborhood expansion across layers poses\ntime and memory challenges for training with large, dense graphs. To relax the\nrequirement of simultaneous availability of test data, we interpret graph\nconvolutions as integral transforms of embedding functions under probability\nmeasures. Such an interpretation allows for the use of Monte Carlo approaches\nto consistently estimate the integrals, which in turn leads to a batched\ntraining scheme as we propose in this work---FastGCN. Enhanced with importance\nsampling, FastGCN not only is efficient for training but also generalizes well\nfor inference. We show a comprehensive set of experiments to demonstrate its\neffectiveness compared with GCN and related models. In particular, training is\norders of magnitude more efficient while predictions remain comparably\naccurate.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 22:36:16 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Chen", "Jie", ""], ["Ma", "Tengfei", ""], ["Xiao", "Cao", ""]]}, {"id": "1801.10273", "submitter": "Congzheng Song", "authors": "Congzheng Song, Yiming Sun", "title": "Kernel Distillation for Fast Gaussian Processes Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) are flexible models that can capture complex\nstructure in large-scale dataset due to their non-parametric nature. However,\nthe usage of GPs in real-world application is limited due to their high\ncomputational cost at inference time. In this paper, we introduce a new\nframework, \\textit{kernel distillation}, to approximate a fully trained teacher\nGP model with kernel matrix of size $n\\times n$ for $n$ training points. We\ncombine inducing points method with sparse low-rank approximation in the\ndistillation procedure. The distilled student GP model only costs $O(m^2)$\nstorage for $m$ inducing points where $m \\ll n$ and improves the inference time\ncomplexity. We demonstrate empirically that kernel distillation provides better\ntrade-off between the prediction time and the test performance compared to the\nalternatives.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 01:59:58 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 16:54:59 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Song", "Congzheng", ""], ["Sun", "Yiming", ""]]}, {"id": "1801.10308", "submitter": "Joel Ruben Antony Moniz", "authors": "Joel Ruben Antony Moniz and David Krueger", "title": "Nested LSTMs", "comments": "Accepted at ACML 2017", "journal-ref": "Proceedings of the Ninth Asian Conference on Machine Learning,\n  PMLR 77:530-544, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Nested LSTMs (NLSTM), a novel RNN architecture with multiple\nlevels of memory. Nested LSTMs add depth to LSTMs via nesting as opposed to\nstacking. The value of a memory cell in an NLSTM is computed by an LSTM cell,\nwhich has its own inner memory cell. Specifically, instead of computing the\nvalue of the (outer) memory cell as $c^{outer}_t = f_t \\odot c_{t-1} + i_t\n\\odot g_t$, NLSTM memory cells use the concatenation $(f_t \\odot c_{t-1}, i_t\n\\odot g_t)$ as input to an inner LSTM (or NLSTM) memory cell, and set\n$c^{outer}_t$ = $h^{inner}_t$. Nested LSTMs outperform both stacked and\nsingle-layer LSTMs with similar numbers of parameters in our experiments on\nvarious character-level language modeling tasks, and the inner memories of an\nLSTM learn longer term dependencies compared with the higher-level units of a\nstacked LSTM.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 05:52:08 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Moniz", "Joel Ruben Antony", ""], ["Krueger", "David", ""]]}, {"id": "1801.10324", "submitter": "Li Liu", "authors": "Li Liu, Jie Chen, Paul Fieguth, Guoying Zhao, Rama Chellappa, Matti\n  Pietikainen", "title": "From BoW to CNN: Two Decades of Texture Representation for Texture\n  Classification", "comments": "Accepted by IJCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texture is a fundamental characteristic of many types of images, and texture\nrepresentation is one of the essential and challenging problems in computer\nvision and pattern recognition which has attracted extensive research\nattention. Since 2000, texture representations based on Bag of Words (BoW) and\non Convolutional Neural Networks (CNNs) have been extensively studied with\nimpressive performance. Given this period of remarkable evolution, this paper\naims to present a comprehensive survey of advances in texture representation\nover the last two decades. More than 200 major publications are cited in this\nsurvey covering different aspects of the research, which includes (i) problem\ndescription; (ii) recent advances in the broad categories of BoW-based,\nCNN-based and attribute-based methods; and (iii) evaluation issues,\nspecifically benchmark datasets and state of the art results. In retrospect of\nwhat has been achieved so far, the survey discusses open challenges and\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 07:06:12 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 20:55:57 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Liu", "Li", ""], ["Chen", "Jie", ""], ["Fieguth", "Paul", ""], ["Zhao", "Guoying", ""], ["Chellappa", "Rama", ""], ["Pietikainen", "Matti", ""]]}, {"id": "1801.10402", "submitter": "Guanqun Cao Dr", "authors": "Guanqun Cao and Alexandros Iosifidis and Moncef Gabbouj and Vijay\n  Raghavan and Raju Gottumukkala", "title": "Deep Multi-view Learning to Rank", "comments": "Published at IEEE TKDE", "journal-ref": null, "doi": "10.1109/TKDE.2019.2942590", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning to rank from multiple information sources.\nThough multi-view learning and learning to rank have been studied extensively\nleading to a wide range of applications, multi-view learning to rank as a\nsynergy of both topics has received little attention. The aim of the paper is\nto propose a composite ranking method while keeping a close correlation with\nthe individual rankings simultaneously. We present a generic framework for\nmulti-view subspace learning to rank (MvSL2R), and two novel solutions are\nintroduced under the framework. The first solution captures information of\nfeature mappings from within each view as well as across views using\nautoencoder-like networks. Novel feature embedding methods are formulated in\nthe optimization of multi-view unsupervised and discriminant autoencoders.\nMoreover, we introduce an end-to-end solution to learning towards both the\njoint ranking objective and the individual rankings. The proposed solution\nenhances the joint ranking with minimum view-specific ranking loss, so that it\ncan achieve the maximum global view agreements in a single optimization\nprocess. The proposed method is evaluated on three different ranking problems,\ni.e. university ranking, multi-view lingual text ranking and image data\nranking, providing superior results compared to related methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 11:13:49 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 06:57:57 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Cao", "Guanqun", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""], ["Raghavan", "Vijay", ""], ["Gottumukkala", "Raju", ""]]}, {"id": "1801.10459", "submitter": "Xiaoqin Zhang", "authors": "Xiaoqin Zhang, Huimin Ma", "title": "Pretraining Deep Actor-Critic Reinforcement Learning Algorithms With\n  Expert Demonstrations", "comments": "Added acknowledgements, modified references. 7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining with expert demonstrations have been found useful in speeding up\nthe training process of deep reinforcement learning algorithms since less\nonline simulation data is required. Some people use supervised learning to\nspeed up the process of feature learning, others pretrain the policies by\nimitating expert demonstrations. However, these methods are unstable and not\nsuitable for actor-critic reinforcement learning algorithms. Also, some\nexisting methods rely on the global optimum assumption, which is not true in\nmost scenarios. In this paper, we employ expert demonstrations in a\nactor-critic reinforcement learning framework, and meanwhile ensure that the\nperformance is not affected by the fact that expert demonstrations are not\nglobal optimal. We theoretically derive a method for computing policy gradients\nand value estimators with only expert demonstrations. Our method is\ntheoretically plausible for actor-critic reinforcement learning algorithms that\npretrains both policy and value functions. We apply our method to two of the\ntypical actor-critic reinforcement learning algorithms, DDPG and ACER, and\ndemonstrate with experiments that our method not only outperforms the RL\nalgorithms without pretraining process, but also is more simulation efficient.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 14:30:00 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 06:36:09 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Zhang", "Xiaoqin", ""], ["Ma", "Huimin", ""]]}, {"id": "1801.10502", "submitter": "Karen Seidel", "authors": "Martin Aschenbach, Timo K\\\"otzing and Karen Seidel", "title": "Learning from Informants: Relations between Learning Success Criteria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from positive and negative information, so-called \\emph{informants},\nbeing one of the models for human and machine learning introduced by\nE.~M.~Gold, is investigated. Particularly, naturally arising questions about\nthis learning setting, originating in results on learning from solely positive\ninformation, are answered. By a carefully arranged argument learners can be\nassumed to only change their hypothesis in case it is inconsistent with the\ndata (such a learning behavior is called \\emph{conservative}). The deduced main\ntheorem states the relations between the most important delayable learning\nsuccess criteria, being the ones not ruined by a delayed in time hypothesis\noutput. Additionally, our investigations concerning the non-delayable\nrequirement of consistent learning underpin the claim for \\emph{delayability}\nbeing the right structural property to gain a deeper understanding concerning\nthe nature of learning success criteria. Moreover, we obtain an anomalous\n\\emph{hierarchy} when allowing for an increasing finite number of\n\\emph{anomalies} of the hypothesized language by the learner compared with the\nlanguage to be learned. In contrast to the vacillatory hierarchy for learning\nfrom solely positive information, we observe a \\emph{duality} depending on\nwhether infinitely many \\emph{vacillations} between different (almost) correct\nhypotheses are still considered a successful learning behavior.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 15:41:45 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 13:27:13 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 11:40:17 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 12:53:45 GMT"}, {"version": "v5", "created": "Wed, 30 Jun 2021 07:31:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Aschenbach", "Martin", ""], ["K\u00f6tzing", "Timo", ""], ["Seidel", "Karen", ""]]}, {"id": "1801.10571", "submitter": "Dicong Qiu", "authors": "Dicong Qiu", "title": "Naive Bayes Entrapment Detection for Planetary Rovers", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entrapment detection is a prerequisite for planetary rovers to perform\nautonomous rescue procedure. In this study, rover entrapment and approximated\nentrapment criteria are formally defined. Entrapment detection using Naive\nBayes classifiers is proposed and discussed along with results from experiments\nwhere the Naive Bayes entrapment detector is applied to AutoKralwer rovers. And\nfinal conclusions and further discussions are presented in the final section.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 17:41:42 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Qiu", "Dicong", ""]]}, {"id": "1801.10578", "submitter": "Tsui-Wei Weng", "authors": "Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, Dong Su, Yupeng\n  Gao, Cho-Jui Hsieh, Luca Daniel", "title": "Evaluating the Robustness of Neural Networks: An Extreme Value Theory\n  Approach", "comments": "Accepted by Sixth International Conference on Learning\n  Representations (ICLR 2018). Tsui-Wei Weng and Huan Zhang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of neural networks to adversarial examples has received great\nattention due to security implications. Despite various attack approaches to\ncrafting visually imperceptible adversarial examples, little has been developed\ntowards a comprehensive measure of robustness. In this paper, we provide a\ntheoretical justification for converting robustness analysis into a local\nLipschitz constant estimation problem, and propose to use the Extreme Value\nTheory for efficient evaluation. Our analysis yields a novel robustness metric\ncalled CLEVER, which is short for Cross Lipschitz Extreme Value for nEtwork\nRobustness. The proposed CLEVER score is attack-agnostic and computationally\nfeasible for large neural networks. Experimental results on various networks,\nincluding ResNet, Inception-v3 and MobileNet, show that (i) CLEVER is aligned\nwith the robustness indication measured by the $\\ell_2$ and $\\ell_\\infty$ norms\nof adversarial examples from powerful attacks, and (ii) defended networks using\ndefensive distillation or bounded ReLU indeed achieve better CLEVER scores. To\nthe best of our knowledge, CLEVER is the first attack-independent robustness\nmetric that can be applied to any neural network classifier.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 17:51:32 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Zhang", "Huan", ""], ["Chen", "Pin-Yu", ""], ["Yi", "Jinfeng", ""], ["Su", "Dong", ""], ["Gao", "Yupeng", ""], ["Hsieh", "Cho-Jui", ""], ["Daniel", "Luca", ""]]}]