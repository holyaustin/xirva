[{"id": "1301.0015", "submitter": "Tony Jebara", "authors": "Adrian Weller and Tony Jebara", "title": "Bethe Bounds and Approximating the Global Optimum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference in general Markov random fields (MRFs) is NP-hard, though\nidentifying the maximum a posteriori (MAP) configuration of pairwise MRFs with\nsubmodular cost functions is efficiently solvable using graph cuts. Marginal\ninference, however, even for this restricted class, is in #P. We prove new\nformulations of derivatives of the Bethe free energy, provide bounds on the\nderivatives and bracket the locations of stationary points, introducing a new\ntechnique called Bethe bound propagation. Several results apply to pairwise\nmodels whether associative or not. Applying these to discretized\npseudo-marginals in the associative case we present a polynomial time\napproximation scheme for global optimization provided the maximum degree is\n$O(\\log n)$, and discuss several extensions.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 21:07:21 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Weller", "Adrian", ""], ["Jebara", "Tony", ""]]}, {"id": "1301.0047", "submitter": "Zaid Towfic", "authors": "Zaid J. Towfic, Jianshu Chen, Ali H. Sayed", "title": "On Distributed Online Classification in the Midst of Concept Drifts", "comments": "19 pages, 14 figures, to appear in Neurocomputing, 2013", "journal-ref": null, "doi": "10.1016/j.neucom.2012.12.043", "report-no": null, "categories": "math.OC cs.DC cs.LG cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we analyze the generalization ability of distributed online\nlearning algorithms under stationary and non-stationary environments. We derive\nbounds for the excess-risk attained by each node in a connected network of\nlearners and study the performance advantage that diffusion strategies have\nover individual non-cooperative processing. We conduct extensive simulations to\nillustrate the results.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 02:02:51 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Towfic", "Zaid J.", ""], ["Chen", "Jianshu", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1301.0082", "submitter": "F. Ozgur Catak", "authors": "F. Ozgur Catak and M. Erdal Balaban", "title": "CloudSVM : Training an SVM Classifier in Cloud Computing Systems", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional method, distributed support vector machines (SVM) algorithms\nare trained over pre-configured intranet/internet environments to find out an\noptimal classifier. These methods are very complicated and costly for large\ndatasets. Hence, we propose a method that is referred as the Cloud SVM training\nmechanism (CloudSVM) in a cloud computing environment with MapReduce technique\nfor distributed machine learning applications. Accordingly, (i) SVM algorithm\nis trained in distributed cloud storage servers that work concurrently; (ii)\nmerge all support vectors in every trained cloud node; and (iii) iterate these\ntwo steps until the SVM converges to the optimal classifier function. Large\nscale data sets are not possible to train using SVM algorithm on a single\ncomputer. The results of this study are important for training of large scale\ndata sets for machine learning applications. We provided that iterative\ntraining of splitted data set in cloud computing environment using SVM will\nconverge to a global optimal classifier in finite iteration size.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 13:20:27 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Catak", "F. Ozgur", ""], ["Balaban", "M. Erdal", ""]]}, {"id": "1301.0104", "submitter": "Aviv Tamar", "authors": "Aviv Tamar, Dotan Di Castro, Shie Mannor", "title": "Policy Evaluation with Variance Related Risk Criteria in Markov Decision\n  Processes", "comments": null, "journal-ref": "JMLR Workshop and Conference Proceedings 28 (3): 495-503, 2013", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend temporal difference policy evaluation algorithms to\nperformance criteria that include the variance of the cumulative reward. Such\ncriteria are useful for risk management, and are important in domains such as\nfinance and process control. We propose both TD(0) and LSTD(lambda) variants\nwith linear function approximation, prove their convergence, and demonstrate\ntheir utility in a 4-dimensional continuous state space problem.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 16:25:17 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Tamar", "Aviv", ""], ["Di Castro", "Dotan", ""], ["Mannor", "Shie", ""]]}, {"id": "1301.0142", "submitter": "David Lopez Paz", "authors": "David Lopez-Paz, Jos\\'e Miguel Hern\\'andez-Lobato, Bernhard\n  Sch\\\"olkopf", "title": "Semi-Supervised Domain Adaptation with Non-Parametric Copulas", "comments": "9 pages, Appearing on Advances in Neural Information Processing\n  Systems 25", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new framework based on the theory of copulas is proposed to address semi-\nsupervised domain adaptation problems. The presented method factorizes any\nmultivariate density into a product of marginal distributions and bivariate\ncop- ula functions. Therefore, changes in each of these factors can be detected\nand corrected to adapt a density model accross different learning domains.\nImpor- tantly, we introduce a novel vine copula model, which allows for this\nfactorization in a non-parametric manner. Experimental results on regression\nproblems with real-world data illustrate the efficacy of the proposed approach\nwhen compared to state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jan 2013 22:52:22 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Lopez-Paz", "David", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1301.0179", "submitter": "Doreswamy", "authors": "Doreswamy, K. S. Hemanth", "title": "A Novel Design Specification Distance(DSD) Based K-Mean Clustering\n  Performace Evluation on Engineering Materials Database", "comments": "International Journal of Computer Applications Vol.55(15), pp.26-33,\n  October 2012. Published by Foundation of Computer Science, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizing data into semantically more meaningful is one of the fundamental\nmodes of understanding and learning. Cluster analysis is a formal study of\nmethods for understanding and algorithm for learning. K-mean clustering\nalgorithm is one of the most fundamental and simple clustering algorithms. When\nthere is no prior knowledge about the distribution of data sets, K-mean is the\nfirst choice for clustering with an initial number of clusters. In this paper a\nnovel distance metric called Design Specification (DS) distance measure\nfunction is integrated with K-mean clustering algorithm to improve cluster\naccuracy. The K-means algorithm with proposed distance measure maximizes the\ncluster accuracy to 99.98% at P = 1.525, which is determined through the\niterative procedure. The performance of Design Specification (DS) distance\nmeasure function with K - mean algorithm is compared with the performances of\nother standard distance functions such as Euclidian, squared Euclidean, City\nBlock, and Chebshew similarity measures deployed with K-mean algorithm.The\nproposed method is evaluated on the engineering materials database. The\nexperiments on cluster analysis and the outlier profiling show that these is an\nexcellent improvement in the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2013 07:13:19 GMT"}], "update_date": "2013-01-03", "authors_parsed": [["Doreswamy", "", ""], ["Hemanth", "K. S.", ""]]}, {"id": "1301.0534", "submitter": "Peter Gr\\\"unwald", "authors": "Steven de Rooij, Tim van Erven, Peter D. Gr\\\"unwald, Wouter M. Koolen", "title": "Follow the Leader If You Can, Hedge If You Must", "comments": "under submission", "journal-ref": "Journal of Machine Learning Research, vol 15, p. 1281-1316, 2014", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Follow-the-Leader (FTL) is an intuitive sequential prediction strategy that\nguarantees constant regret in the stochastic setting, but has terrible\nperformance for worst-case data. Other hedging strategies have better\nworst-case guarantees but may perform much worse than FTL if the data are not\nmaximally adversarial. We introduce the FlipFlop algorithm, which is the first\nmethod that provably combines the best of both worlds.\n  As part of our construction, we develop AdaHedge, which is a new way of\ndynamically tuning the learning rate in Hedge without using the doubling trick.\nAdaHedge refines a method by Cesa-Bianchi, Mansour and Stoltz (2007), yielding\nslightly improved worst-case guarantees. By interleaving AdaHedge and FTL, the\nFlipFlop algorithm achieves regret within a constant factor of the FTL regret,\nwithout sacrificing AdaHedge's worst-case guarantees.\n  AdaHedge and FlipFlop do not need to know the range of the losses in advance;\nmoreover, unlike earlier methods, both have the intuitive property that the\nissued weights are invariant under rescaling and translation of the losses. The\nlosses are also allowed to be negative, in which case they may be interpreted\nas gains.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2013 19:49:14 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 10:03:03 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["de Rooij", "Steven", ""], ["van Erven", "Tim", ""], ["Gr\u00fcnwald", "Peter D.", ""], ["Koolen", "Wouter M.", ""]]}, {"id": "1301.0551", "submitter": "Dragomir Anguelov", "authors": "Dragomir Anguelov, Rahul Biswas, Daphne Koller, Benson Limketkai,\n  Sebastian Thrun", "title": "Learning Hierarchical Object Maps Of Non-Stationary Environments with\n  mobile robots", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-10-17", "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building models, or maps, of robot environments is a highly active research\narea; however, most existing techniques construct unstructured maps and assume\nstatic environments. In this paper, we present an algorithm for learning object\nmodels of non-stationary objects found in office-type environments. Our\nalgorithm exploits the fact that many objects found in office environments look\nalike (e.g., chairs, recycling bins). It does so through a two-level\nhierarchical representation, which links individual objects with generic shape\ntemplates of object classes. We derive an approximate EM algorithm for learning\nshape parameters at both levels of the hierarchy, using local occupancy grid\nmaps for representing shape. Additionally, we develop a Bayesian model\nselection algorithm that enables the robot to estimate the total number of\nobjects and object templates in the environment. Experimental results using a\nreal robot equipped with a laser range finder indicate that our approach\nperforms well at learning object-based maps of simple office environments. The\napproach outperforms a previously developed non-hierarchical algorithm that\nmodels objects but lacks class templates.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:05 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Anguelov", "Dragomir", ""], ["Biswas", "Rahul", ""], ["Koller", "Daphne", ""], ["Limketkai", "Benson", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1301.0554", "submitter": "Francis R. Bach", "authors": "Francis R. Bach, Michael I. Jordan", "title": "Tree-dependent Component Analysis", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-36-44", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generalization of independent component analysis (ICA), where\ninstead of looking for a linear transform that makes the data components\nindependent, we look for a transform that makes the data components well fit by\na tree-structured graphical model. Treating the problem as a semiparametric\nstatistical problem, we show that the optimal transform is found by minimizing\na contrast function based on mutual information, a function that directly\nextends the contrast function used for classical ICA. We provide two\napproximations of this contrast function, one using kernel density estimation,\nand another using kernel generalized variance. This tree-dependent component\nanalysis framework leads naturally to an efficient general multivariate density\nestimation technique where only bivariate density estimation needs to be\nperformed.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:17 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Bach", "Francis R.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.0556", "submitter": "David Blei", "authors": "David Blei, J Andrew Bagnell, Andrew McCallum", "title": "Learning with Scope, with Application to Information Extraction and\n  Classification", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-53-60", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In probabilistic approaches to classification and information extraction, one\ntypically builds a statistical model of words under the assumption that future\ndata will exhibit the same regularities as the training data. In many data\nsets, however, there are scope-limited features whose predictive power is only\napplicable to a certain subset of the data. For example, in information\nextraction from web pages, word formatting may be indicative of extraction\ncategory in different ways on different web pages. The difficulty with using\nsuch features is capturing and exploiting the new regularities encountered in\npreviously unseen data. In this paper, we propose a hierarchical probabilistic\nmodel that uses both local/scope-limited features, such as word formatting, and\nglobal features, such as word content. The local regularities are modeled as an\nunobserved random parameter which is drawn once for each local data set. This\nrandom parameter is estimated during the inference process and then used to\nperform classification with both the local and global features--- a procedure\nwhich is akin to automatically retuning the classifier to the local\nregularities on each newly encountered web page. Exact inference is intractable\nand we present approximations via point estimates and variational methods.\nEmpirical results on large collections of web data demonstrate that this method\nsignificantly improves performance from traditional models of global features\nalone.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:25 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Blei", "David", ""], ["Bagnell", "J Andrew", ""], ["McCallum", "Andrew", ""]]}, {"id": "1301.0562", "submitter": "Adrian Corduneanu", "authors": "Adrian Corduneanu, Tommi S. Jaakkola", "title": "Continuation Methods for Mixing Heterogenous Sources", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-111-118", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of modern learning tasks involve estimation from heterogeneous\ninformation sources. This includes classification with labeled and unlabeled\ndata as well as other problems with analogous structure such as competitive\n(game theoretic) problems. The associated estimation problems can be typically\nreduced to solving a set of fixed point equations (consistency conditions). We\nintroduce a general method for combining a preferred information source with\nanother in this setting by evolving continuous paths of fixed points at\nintermediate allocations. We explicitly identify critical points along the\nunique paths to either increase the stability of estimation or to ensure a\nsignificant departure from the initial source. The homotopy continuation\napproach is guaranteed to terminate at the second source, and involves no\ncombinatorial effort. We illustrate the power of these ideas both in\nclassification tasks with labeled and unlabeled data, as well as in the context\nof a competitive (min-max) formulation of DNA sequence motif discovery.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:50 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Corduneanu", "Adrian", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.0563", "submitter": "Scott Davies", "authors": "Scott Davies, Andrew Moore", "title": "Interpolating Conditional Density Trees", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-119-127", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint distributions over many variables are frequently modeled by decomposing\nthem into products of simpler, lower-dimensional conditional distributions,\nsuch as in sparsely connected Bayesian networks. However, automatically\nlearning such models can be very computationally expensive when there are many\ndatapoints and many continuous variables with complex nonlinear relationships,\nparticularly when no good ways of decomposing the joint distribution are known\na priori. In such situations, previous research has generally focused on the\nuse of discretization techniques in which each continuous variable has a single\ndiscretization that is used throughout the entire network. \\ In this paper, we\npresent and compare a wide variety of tree-based algorithms for learning and\nevaluating conditional density estimates over continuous variables. These trees\ncan be thought of as discretizations that vary according to the particular\ninteractions being modeled; however, the density within a given leaf of the\ntree need not be assumed constant, and we show that such nonuniform leaf\ndensities lead to more accurate density estimation. We have developed Bayesian\nnetwork structure-learning algorithms that employ these tree-based conditional\ndensity representations, and we show that they can be used to practically learn\ncomplex joint probability models over dozens of continuous variables from\nthousands of datapoints. We focus on finding models that are simultaneously\naccurate, fast to learn, and fast to evaluate once they are learned.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:55:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Davies", "Scott", ""], ["Moore", "Andrew", ""]]}, {"id": "1301.0565", "submitter": "Byron E Dom", "authors": "Byron E Dom", "title": "An Information-Theoretic External Cluster-Validity Measure", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-137-145", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a measure of clustering quality or accuracy that is\nappropriate in situations where it is desirable to evaluate a clustering\nalgorithm by somehow comparing the clusters it produces with ``ground truth'\nconsisting of classes assigned to the patterns by manual means or some other\nmeans in whose veracity there is confidence. Such measures are refered to as\n``external'. Our measure also has the characteristic of allowing clusterings\nwith different numbers of clusters to be compared in a quantitative and\nprincipled way. Our evaluation scheme quantitatively measures how useful the\ncluster labels of the patterns are as predictors of their class labels. In\ncases where all clusterings to be compared have the same number of clusters,\nthe measure is equivalent to the mutual information between the cluster labels\nand the class labels. In cases where the numbers of clusters are different,\nhowever, it computes the reduction in the number of bits that would be required\nto encode (compress) the class labels if both the encoder and decoder have free\nacccess to the cluster labels. To achieve this encoding the estimated\nconditional probabilities of the class labels given the cluster labels must\nalso be encoded. These estimated probabilities can be seen as a model for the\nclass labels and their associated code length as a model cost.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:02 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Dom", "Byron E", ""]]}, {"id": "1301.0567", "submitter": "Sarah Finney", "authors": "Sarah Finney, Natalia Gardiol, Leslie Pack Kaelbling, Tim Oates", "title": "The Thing That We Tried Didn't Work Very Well : Deictic Representation\n  in Reinforcement Learning", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-154-161", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most reinforcement learning methods operate on propositional representations\nof the world state. Such representations are often intractably large and\ngeneralize poorly. Using a deictic representation is believed to be a viable\nalternative: they promise generalization while allowing the use of existing\nreinforcement-learning methods. Yet, there are few experiments on learning with\ndeictic representations reported in the literature. In this paper we explore\nthe effectiveness of two forms of deictic representation and a na\\\"{i}ve\npropositional representation in a simple blocks-world domain. We find,\nempirically, that the deictic representations actually worsen learning\nperformance. We conclude with a discussion of possible causes of these results\nand strategies for more effective learning in domains with objects.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:10 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Finney", "Sarah", ""], ["Gardiol", "Natalia", ""], ["Kaelbling", "Leslie Pack", ""], ["Oates", "Tim", ""]]}, {"id": "1301.0578", "submitter": "Tomas Kocka", "authors": "Tomas Kocka, Nevin Lianwen Zhang", "title": "Dimension Correction for Hierarchical Latent Class Models", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-267-274", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model complexity is an important factor to consider when selecting among\ngraphical models. When all variables are observed, the complexity of a model\ncan be measured by its standard dimension, i.e. the number of independent\nparameters. When hidden variables are present, however, standard dimension\nmight no longer be appropriate. One should instead use effective dimension\n(Geiger et al. 1996). This paper is concerned with the computation of effective\ndimension. First we present an upper bound on the effective dimension of a\nlatent class (LC) model. This bound is tight and its computation is easy. We\nthen consider a generalization of LC models called hierarchical latent class\n(HLC) models (Zhang 2002). We show that the effective dimension of an HLC model\ncan be obtained from the effective dimensions of some related LC models. We\nalso demonstrate empirically that using effective dimension in place of\nstandard dimension improves the quality of models learned from data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Kocka", "Tomas", ""], ["Zhang", "Nevin Lianwen", ""]]}, {"id": "1301.0579", "submitter": "Samuel Kutin", "authors": "Samuel Kutin, Partha Niyogi", "title": "Almost-everywhere algorithmic stability and generalization error", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-275-282", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore in some detail the notion of algorithmic stability as a viable\nframework for analyzing the generalization error of learning algorithms. We\nintroduce the new notion of training stability of a learning algorithm and show\nthat, in a general setting, it is sufficient for good bounds on generalization\nerror. In the PAC setting, training stability is both necessary and sufficient\nfor learnability.\\ The approach based on training stability makes no reference\nto VC dimension or VC entropy. There is no need to prove uniform convergence,\nand generalization error is bounded directly via an extended McDiarmid\ninequality. As a result it potentially allows us to deal with a broader class\nof learning algorithms than Empirical Risk Minimization. \\ We also explore the\nrelationships among VC dimension, generalization error, and various notions of\nstability. Several examples of learning algorithms are considered.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:56:58 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Kutin", "Samuel", ""], ["Niyogi", "Partha", ""]]}, {"id": "1301.0584", "submitter": "Bhaskara Marthi", "authors": "Bhaskara Marthi, Hanna Pasula, Stuart Russell, Yuval Peres", "title": "Decayed MCMC Filtering", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-319-326", "categories": "cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filtering---estimating the state of a partially observable Markov process\nfrom a sequence of observations---is one of the most widely studied problems in\ncontrol theory, AI, and computational statistics. Exact computation of the\nposterior distribution is generally intractable for large discrete systems and\nfor nonlinear continuous systems, so a good deal of effort has gone into\ndeveloping robust approximation algorithms. This paper describes a simple\nstochastic approximation algorithm for filtering called {em decayed MCMC}. The\nalgorithm applies Markov chain Monte Carlo sampling to the space of state\ntrajectories using a proposal distribution that favours flips of more recent\nstate variables. The formal analysis of the algorithm involves a generalization\nof standard coupling arguments for MCMC convergence. We prove that for any\nergodic underlying Markov process, the convergence time of decayed MCMC with\ninverse-polynomial decay remains bounded as the length of the observation\nsequence grows. We show experimentally that decayed MCMC is at least\ncompetitive with other approximation algorithms such as particle filtering.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:19 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Marthi", "Bhaskara", ""], ["Pasula", "Hanna", ""], ["Russell", "Stuart", ""], ["Peres", "Yuval", ""]]}, {"id": "1301.0586", "submitter": "Christopher Meek", "authors": "Christopher Meek, Bo Thiesson, David Heckerman", "title": "Staged Mixture Modelling and Boosting", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-335-343", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce and evaluate a data-driven staged mixture\nmodeling technique for building density, regression, and classification models.\nOur basic approach is to sequentially add components to a finite mixture model\nusing the structural expectation maximization (SEM) algorithm. We show that our\ntechnique is qualitatively similar to boosting. This correspondence is a\nnatural byproduct of the fact that we use the SEM algorithm to sequentially fit\nthe mixture model. Finally, in our experimental evaluation, we demonstrate the\neffectiveness of our approach on a variety of prediction and density estimation\ntasks using real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:27 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Meek", "Christopher", ""], ["Thiesson", "Bo", ""], ["Heckerman", "David", ""]]}, {"id": "1301.0587", "submitter": "Ramgopal Mettu", "authors": "Ramgopal Mettu, Greg Plaxton", "title": "Optimal Time Bounds for Approximate Clustering", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-344-351", "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental problem in unsupervised learning, and has been\nstudied widely both as a problem of learning mixture models and as an\noptimization problem. In this paper, we study clustering with respect the\nemph{k-median} objective function, a natural formulation of clustering in which\nwe attempt to minimize the average distance to cluster centers. One of the main\ncontributions of this paper is a simple but powerful sampling technique that we\ncall emph{successive sampling} that could be of independent interest. We show\nthat our sampling procedure can rapidly identify a small set of points (of size\njust O(klog{n/k})) that summarize the input points for the purpose of\nclustering. Using successive sampling, we develop an algorithm for the k-median\nproblem that runs in O(nk) time for a wide range of values of k and is\nguaranteed, with high probability, to return a solution with cost at most a\nconstant factor times optimal. We also establish a lower bound of Omega(nk) on\nany randomized constant-factor approximation algorithm for the k-median problem\nthat succeeds with even a negligible (say 1/100) probability. Thus we establish\na tight time bound of Theta(nk) for the k-median problem for a wide range of\nvalues of k. The best previous upper bound for the problem was O(nk), where the\nO-notation hides polylogarithmic factors in n and k. The best previous lower\nbound of O(nk) applied only to deterministic k-median algorithms. While we\nfocus our presentation on the k-median objective, all our upper bounds are\nvalid for the k-means objective as well. In this context our algorithm compares\nfavorably to the widely used k-means heuristic, which requires O(nk) time for\njust one iteration and provides no useful approximation guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:31 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Mettu", "Ramgopal", ""], ["Plaxton", "Greg", ""]]}, {"id": "1301.0588", "submitter": "Thomas P. Minka", "authors": "Thomas P. Minka, John Lafferty", "title": "Expectation-Propogation for the Generative Aspect Model", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-352-359", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generative aspect model is an extension of the multinomial model for text\nthat allows word probabilities to vary stochastically across documents.\nPrevious results with aspect models have been promising, but hindered by the\ncomputational difficulty of carrying out inference and learning. This paper\ndemonstrates that the simple variational methods of Blei et al (2001) can lead\nto inaccurate inferences and biased learning for the generative aspect model.\nWe develop an alternative approach that leads to higher accuracy at comparable\ncost. An extension of Expectation-Propagation is used for inference and then\nembedded in an EM algorithm for learning. Experimental results are presented\nfor both synthetic and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:35 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Minka", "Thomas P.", ""], ["Lafferty", "John", ""]]}, {"id": "1301.0593", "submitter": "Tatjana Pavlenko", "authors": "Tatjana Pavlenko, Dietrich von Rosen", "title": "Bayesian Network Classifiers in a High Dimensional Framework", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-397-404", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a growing dimension asymptotic formalism. The perspective in this\npaper is classification theory and we show that it can accommodate\nprobabilistic networks classifiers, including naive Bayes model and its\naugmented version. When represented as a Bayesian network these classifiers\nhave an important advantage: The corresponding discriminant function turns out\nto be a specialized case of a generalized additive model, which makes it\npossible to get closed form expressions for the asymptotic misclassification\nprobabilities used here as a measure of classification accuracy. Moreover, in\nthis paper we propose a new quantity for assessing the discriminative power of\na set of features which is then used to elaborate the augmented naive Bayes\nclassifier. The result is a weighted form of the augmented naive Bayes that\ndistributes weights among the sets of features according to their\ndiscriminative power. We derive the asymptotic distribution of the sample based\ndiscriminative power and show that it is seriously overestimated in a high\ndimensional case. We then apply this result to find the optimal, in a sense of\nminimum misclassification probability, type of weighting.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:57:54 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Pavlenko", "Tatjana", ""], ["von Rosen", "Dietrich", ""]]}, {"id": "1301.0598", "submitter": "Dmitry Rusakov", "authors": "Dmitry Rusakov, Dan Geiger", "title": "Asymptotic Model Selection for Naive Bayesian Networks", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-438-445", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a closed form asymptotic formula to compute the marginal\nlikelihood of data given a naive Bayesian network model with two hidden states\nand binary features. This formula deviates from the standard BIC score. Our\nwork provides a concrete example that the BIC score is generally not valid for\nstatistical models that belong to a stratified exponential family. This stands\nin contrast to linear and curved exponential families, where the BIC score has\nbeen proven to provide a correct approximation for the marginal likelihood.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:13 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Rusakov", "Dmitry", ""], ["Geiger", "Dan", ""]]}, {"id": "1301.0599", "submitter": "Robert E. Schapire", "authors": "Robert E. Schapire", "title": "Advances in Boosting (Invited Talk)", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-446-452", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a general method of generating many simple classification rules\nand combining them into a single, highly accurate rule. In this talk, I will\nreview the AdaBoost boosting algorithm and some of its underlying theory, and\nthen look at how this theory has helped us to face some of the challenges of\napplying AdaBoost in two domains: In the first of these, we used boosting for\npredicting and modeling the uncertainty of prices in complicated, interacting\nauctions. The second application was to the classification of caller utterances\nin a telephone spoken-dialogue system where we faced two challenges: the need\nto incorporate prior knowledge to compensate for initially insufficient data;\nand a later need to filter the large stream of unlabeled examples being\ncollected to select the ones whose labels are likely to be most informative.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:17 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Schapire", "Robert E.", ""]]}, {"id": "1301.0600", "submitter": "Guy Shani", "authors": "Guy Shani, Ronen I. Brafman, David Heckerman", "title": "An MDP-based Recommender System", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-453-460", "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical Recommender systems adopt a static view of the recommendation process\nand treat it as a prediction problem. We argue that it is more appropriate to\nview the problem of generating recommendations as a sequential decision problem\nand, consequently, that Markov decision processes (MDP) provide a more\nappropriate model for Recommender systems. MDPs introduce two benefits: they\ntake into account the long-term effects of each recommendation, and they take\ninto account the expected value of each recommendation. To succeed in practice,\nan MDP-based Recommender system must employ a strong initial model; and the\nbulk of this paper is concerned with the generation of such a model. In\nparticular, we suggest the use of an n-gram predictive model for generating the\ninitial MDP. Our n-gram model induces a Markov-chain model of user behavior\nwhose predictive accuracy is greater than that of existing predictive models.\nWe describe our predictive model in detail and evaluate its performance on real\ndata. In addition, we show how the model can be used in an MDP-based\nRecommender system.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:21 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:00:34 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Shani", "Guy", ""], ["Brafman", "Ronen I.", ""], ["Heckerman", "David", ""]]}, {"id": "1301.0601", "submitter": "Christian R. Shelton", "authors": "Christian R. Shelton", "title": "Reinforcement Learning with Partially Known World Dynamics", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-461-468", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning would enjoy better success on real-world problems if\ndomain knowledge could be imparted to the algorithm by the modelers. Most\nproblems have both hidden state and unknown dynamics. Partially observable\nMarkov decision processes (POMDPs) allow for the modeling of both.\nUnfortunately, they do not provide a natural framework in which to specify\nknowledge about the domain dynamics. The designer must either admit to knowing\nnothing about the dynamics or completely specify the dynamics (thereby turning\nit into a planning problem). We propose a new framework called a partially\nknown Markov decision process (PKMDP) which allows the designer to specify\nknown dynamics while still leaving portions of the environment s dynamics\nunknown.The model represents NOT ONLY the environment dynamics but also the\nagents knowledge of the dynamics. We present a reinforcement learning algorithm\nfor this model based on importance sampling. The algorithm incorporates\nplanning based on the known dynamics and learning about the unknown dynamics.\nOur results clearly demonstrate the ability to add domain knowledge and the\nresulting benefits for learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:25 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Shelton", "Christian R.", ""]]}, {"id": "1301.0602", "submitter": "Harald Steck", "authors": "Harald Steck, Tommi S. Jaakkola", "title": "Unsupervised Active Learning in Large Domains", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-469-476", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is a powerful approach to analyzing data effectively. We show\nthat the feasibility of active learning depends crucially on the choice of\nmeasure with respect to which the query is being optimized. The standard\ninformation gain, for example, does not permit an accurate evaluation with a\nsmall committee, a representative subset of the model space. We propose a\nsurrogate measure requiring only a small committee and discuss the properties\nof this new measure. We devise, in addition, a bootstrap approach for committee\nselection. The advantages of this approach are illustrated in the context of\nrecovering (regulatory) network models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:30 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Steck", "Harald", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.0604", "submitter": "Ben Taskar", "authors": "Ben Taskar, Pieter Abbeel, Daphne Koller", "title": "Discriminative Probabilistic Models for Relational Data", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-485-492", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many supervised learning tasks, the entities to be labeled are related to\neach other in complex ways and their labels are not independent. For example,\nin hypertext classification, the labels of linked pages are highly correlated.\nA standard approach is to classify each entity independently, ignoring the\ncorrelations between them. Recently, Probabilistic Relational Models, a\nrelational version of Bayesian networks, were used to define a joint\nprobabilistic model for a collection of related entities. In this paper, we\npresent an alternative framework that builds on (conditional) Markov networks\nand addresses two limitations of the previous approach. First, undirected\nmodels do not impose the acyclicity constraint that hinders representation of\nmany important relational dependencies in directed models. Second, undirected\nmodels are well suited for discriminative training, where we optimize the\nconditional likelihood of the labels given the features, which generally\nimproves classification accuracy. We show how to train these models\neffectively, and how to use approximate probabilistic inference over the\nlearned model for collective classification of multiple related entities. We\nprovide experimental results on a webpage classification task, showing that\naccuracy can be significantly improved by modeling relational dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:58:38 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Taskar", "Ben", ""], ["Abbeel", "Pieter", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.0610", "submitter": "Martin Wainwright", "authors": "Martin Wainwright, Tommi S. Jaakkola, Alan Willsky", "title": "A New Class of Upper Bounds on the Log Partition Function", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-536-543", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounds on the log partition function are important in a variety of contexts,\nincluding approximate inference, model fitting, decision theory, and large\ndeviations analysis. We introduce a new class of upper bounds on the log\npartition function, based on convex combinations of distributions in the\nexponential domain, that is applicable to an arbitrary undirected graphical\nmodel. In the special case of convex combinations of tree-structured\ndistributions, we obtain a family of variational problems, similar to the Bethe\nfree energy, but distinguished by the following desirable properties: i. they\nare cnvex, and have a unique global minimum; and ii. the global minimum gives\nan upper bound on the log partition function. The global minimum is defined by\nstationary conditions very similar to those defining fixed points of belief\npropagation or tree-based reparameterization Wainwright et al., 2001. As with\nBP fixed points, the elements of the minimizing argument can be used as\napproximations to the marginals of the original model. The analysis described\nhere can be extended to structures of higher treewidth e.g., hypertrees,\nthereby making connections with more advanced approximations e.g., Kikuchi and\nvariants Yedidia et al., 2001; Minka, 2001.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:59:01 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Wainwright", "Martin", ""], ["Jaakkola", "Tommi S.", ""], ["Willsky", "Alan", ""]]}, {"id": "1301.0613", "submitter": "Wim Wiegerinck", "authors": "Wim Wiegerinck, Tom Heskes", "title": "IPF for Discrete Chain Factor Graphs", "comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2002-PG-560-567", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative Proportional Fitting (IPF), combined with EM, is commonly used as\nan algorithm for likelihood maximization in undirected graphical models. In\nthis paper, we present two iterative algorithms that generalize upon IPF. The\nfirst one is for likelihood maximization in discrete chain factor graphs, which\nwe define as a wide class of discrete variable models including undirected\ngraphical models and Bayesian networks, but also chain graphs and sigmoid\nbelief networks. The second one is for conditional likelihood maximization in\nstandard undirected models and Bayesian networks. In both algorithms, the\niteration steps are expressed in closed form. Numerical simulations show that\nthe algorithms are competitive with state of the art methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2012 15:59:15 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Wiegerinck", "Wim", ""], ["Heskes", "Tom", ""]]}, {"id": "1301.0725", "submitter": "Mathieu Senelle", "authors": "Mathieu Senelle, Silvia Garcia-Diez, Amin Mantrach, Masashi Shimbo,\n  Marco Saerens, Fran\\c{c}ois Fouss", "title": "The Sum-over-Forests density index: identifying dense regions in a graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel nonparametric density index defined on graphs,\nthe Sum-over-Forests (SoF) density index. It is based on a clear and intuitive\nidea: high-density regions in a graph are characterized by the fact that they\ncontain a large amount of low-cost trees with high outdegrees while low-density\nregions contain few ones. Therefore, a Boltzmann probability distribution on\nthe countable set of forests in the graph is defined so that large (high-cost)\nforests occur with a low probability while short (low-cost) forests occur with\na high probability. Then, the SoF density index of a node is defined as the\nexpected outdegree of this node in a non-trivial tree of the forest, thus\nproviding a measure of density around that node. Following the matrix-forest\ntheorem, and a statistical physics framework, it is shown that the SoF density\nindex can be easily computed in closed form through a simple matrix inversion.\nExperiments on artificial and real data sets show that the proposed index\nperforms well on finding dense regions, for graphs of various origins.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 13:56:25 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["Senelle", "Mathieu", ""], ["Garcia-Diez", "Silvia", ""], ["Mantrach", "Amin", ""], ["Shimbo", "Masashi", ""], ["Saerens", "Marco", ""], ["Fouss", "Fran\u00e7ois", ""]]}, {"id": "1301.0802", "submitter": "XuanLong Nguyen", "authors": "XuanLong Nguyen", "title": "Borrowing strengh in hierarchical Bayes: Posterior concentration of the\n  Dirichlet base measure", "comments": "Published at http://dx.doi.org/10.3150/15-BEJ703 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2016, Vol. 22, No. 3, 1535-1571", "doi": "10.3150/15-BEJ703", "report-no": "IMS-BEJ-BEJ703", "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies posterior concentration behavior of the base probability\nmeasure of a Dirichlet measure, given observations associated with the sampled\nDirichlet processes, as the number of observations tends to infinity. The base\nmeasure itself is endowed with another Dirichlet prior, a construction known as\nthe hierarchical Dirichlet processes (Teh et al. [J. Amer. Statist. Assoc. 101\n(2006) 1566-1581]). Convergence rates are established in transportation\ndistances (i.e., Wasserstein metrics) under various conditions on the geometry\nof the support of the true base measure. As a consequence of the theory, we\ndemonstrate the benefit of \"borrowing strength\" in the inference of multiple\ngroups of data - a powerful insight often invoked to motivate hierarchical\nmodeling. In certain settings, the gain in efficiency due to the latent\nhierarchy can be dramatic, improving from a standard nonparametric rate to a\nparametric rate of convergence. Tools developed include transportation\ndistances for nonparametric Bayesian hierarchies of random measures, the\nexistence of tests for Dirichlet measures, and geometric properties of the\nsupport of Dirichlet measures.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2013 18:55:41 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2013 07:01:51 GMT"}, {"version": "v3", "created": "Thu, 29 Jan 2015 16:28:03 GMT"}, {"version": "v4", "created": "Thu, 24 Mar 2016 14:26:50 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Nguyen", "XuanLong", ""]]}, {"id": "1301.1218", "submitter": "Matteo Riondato", "authors": "Matteo Riondato and Fabio Vandin", "title": "Finding the True Frequent Itemsets", "comments": "13 pages, Extended version of work appeared in SIAM International\n  Conference on Data Mining, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequent Itemsets (FIs) mining is a fundamental primitive in data mining. It\nrequires to identify all itemsets appearing in at least a fraction $\\theta$ of\na transactional dataset $\\mathcal{D}$. Often though, the ultimate goal of\nmining $\\mathcal{D}$ is not an analysis of the dataset \\emph{per se}, but the\nunderstanding of the underlying process that generated it. Specifically, in\nmany applications $\\mathcal{D}$ is a collection of samples obtained from an\nunknown probability distribution $\\pi$ on transactions, and by extracting the\nFIs in $\\mathcal{D}$ one attempts to infer itemsets that are frequently (i.e.,\nwith probability at least $\\theta$) generated by $\\pi$, which we call the True\nFrequent Itemsets (TFIs). Due to the inherently stochastic nature of the\ngenerative process, the set of FIs is only a rough approximation of the set of\nTFIs, as it often contains a huge number of \\emph{false positives}, i.e.,\nspurious itemsets that are not among the TFIs. In this work we design and\nanalyze an algorithm to identify a threshold $\\hat{\\theta}$ such that the\ncollection of itemsets with frequency at least $\\hat{\\theta}$ in $\\mathcal{D}$\ncontains only TFIs with probability at least $1-\\delta$, for some\nuser-specified $\\delta$. Our method uses results from statistical learning\ntheory involving the (empirical) VC-dimension of the problem at hand. This\nallows us to identify almost all the TFIs without including any false positive.\nWe also experimentally compare our method with the direct mining of\n$\\mathcal{D}$ at frequency $\\theta$ and with techniques based on widely-used\nstandard bounds (i.e., the Chernoff bounds) of the binomial distribution, and\nshow that our algorithm outperforms these methods and achieves even better\nresults than what is guaranteed by the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 15:04:43 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 12:54:12 GMT"}, {"version": "v3", "created": "Wed, 22 Jan 2014 16:38:44 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Riondato", "Matteo", ""], ["Vandin", "Fabio", ""]]}, {"id": "1301.1254", "submitter": "Eric Hall Mr", "authors": "Eric C. Hall and Rebecca M. Willett", "title": "Dynamical Models and Tracking Regret in Online Convex Programming", "comments": "To appear in ICML 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new online convex optimization method which\nincorporates a family of candidate dynamical models and establishes novel\ntracking regret bounds that scale with the comparator's deviation from the best\ndynamical model in this family. Previous online optimization methods are\ndesigned to have a total accumulated loss comparable to that of the best\ncomparator sequence, and existing tracking or shifting regret bounds scale with\nthe overall variation of the comparator sequence. In many practical scenarios,\nhowever, the environment is nonstationary and comparator sequences with small\nvariation are quite weak, resulting in large losses. The proposed Dynamic\nMirror Descent method, in contrast, can yield low regret relative to highly\nvariable comparator sequences by both tracking the best dynamical model and\nforming predictions based on that model. This concept is demonstrated\nempirically in the context of sequential compressive observations of a dynamic\nscene and tracking a dynamic social network.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 16:39:09 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Hall", "Eric C.", ""], ["Willett", "Rebecca M.", ""]]}, {"id": "1301.1299", "submitter": "Th\\'eophane  Weber", "authors": "David Wingate, Theophane Weber", "title": "Automated Variational Inference in Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present a new algorithm for approximate inference in probabilistic\nprograms, based on a stochastic gradient for variational programs. This method\nis efficient without restrictions on the probabilistic program; it is\nparticularly practical for distributions which are not analytically tractable,\nincluding highly structured distributions that arise in probabilistic programs.\nWe show how to automatically derive mean-field probabilistic programs and\noptimize them, and demonstrate that our perspective improves inference\nefficiency over other algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2013 18:48:02 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Wingate", "David", ""], ["Weber", "Theophane", ""]]}, {"id": "1301.1555", "submitter": "Amir Hesam Salavati", "authors": "Amin Karbasi, Amir Hesam Salavati, and Amin Shokrollahi", "title": "Coupled Neural Associative Memories", "comments": "A shorter version of this paper is going to be submitted to\n  International symposium on Information Theory (ISIT 2013) in Istanbul, Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel architecture to design a neural associative memory that is\ncapable of learning a large number of patterns and recalling them later in\npresence of noise. It is based on dividing the neurons into local clusters and\nparallel plains, very similar to the architecture of the visual cortex of\nmacaque brain. The common features of our proposed architecture with those of\nspatially-coupled codes enable us to show that the performance of such networks\nin eliminating noise is drastically better than the previous approaches while\nmaintaining the ability of learning an exponentially large number of patterns.\nPrevious work either failed in providing good performance during the recall\nphase or in offering large pattern retrieval (storage) capacities. We also\npresent computational experiments that lend additional support to the\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 14:55:45 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2013 22:57:53 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2013 12:48:16 GMT"}, {"version": "v4", "created": "Tue, 21 May 2013 15:02:19 GMT"}, {"version": "v5", "created": "Fri, 23 Aug 2013 14:26:16 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Karbasi", "Amin", ""], ["Salavati", "Amir Hesam", ""], ["Shokrollahi", "Amin", ""]]}, {"id": "1301.1590", "submitter": "Hamidreza Chitsaz", "authors": "Hamidreza Chitsaz and Elmirasadat Forouzmand and Gholamreza Haffari", "title": "An Efficient Algorithm for Upper Bound on the Partition Function of\n  Nucleic Acids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that minimum free energy structure for RNAs and RNA-RNA\ninteraction is often incorrect due to inaccuracies in the energy parameters and\ninherent limitations of the energy model. In contrast, ensemble based\nquantities such as melting temperature and equilibrium concentrations can be\nmore reliably predicted. Even structure prediction by sampling from the\nensemble and clustering those structures by Sfold [7] has proven to be more\nreliable than minimum free energy structure prediction. The main obstacle for\nensemble based approaches is the computational complexity of the partition\nfunction and base pairing probabilities. For instance, the space complexity of\nthe partition function for RNA-RNA interaction is $O(n^4)$ and the time\ncomplexity is $O(n^6)$ which are prohibitively large [4,12]. Our goal in this\npaper is to give a fast algorithm, based on sparse folding, to calculate an\nupper bound on the partition function. Our work is based on the recent\nalgorithm of Hazan and Jaakkola [10]. The space complexity of our algorithm is\nthe same as that of sparse folding algorithms, and the time complexity of our\nalgorithm is $O(MFE(n)\\ell)$ for single RNA and $O(MFE(m, n)\\ell)$ for RNA-RNA\ninteraction in practice, in which $MFE$ is the running time of sparse folding\nand $\\ell \\leq n$ ($\\ell \\leq n + m$) is a sequence dependent parameter.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 16:58:28 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Chitsaz", "Hamidreza", ""], ["Forouzmand", "Elmirasadat", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1301.1608", "submitter": "Hamidreza Chitsaz", "authors": "Elmirasadat Forouzmand and Hamidreza Chitsaz", "title": "The RNA Newton Polytope and Learnability of Energy Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite nearly two scores of research on RNA secondary structure and RNA-RNA\ninteraction prediction, the accuracy of the state-of-the-art algorithms are\nstill far from satisfactory. Researchers have proposed increasingly complex\nenergy models and improved parameter estimation methods in anticipation of\nendowing their methods with enough power to solve the problem. The output has\ndisappointingly been only modest improvements, not matching the expectations.\nEven recent massively featured machine learning approaches were not able to\nbreak the barrier. In this paper, we introduce the notion of learnability of\nthe parameters of an energy model as a measure of its inherent capability. We\nsay that the parameters of an energy model are learnable iff there exists at\nleast one set of such parameters that renders every known RNA structure to date\nthe minimum free energy structure. We derive a necessary condition for the\nlearnability and give a dynamic programming algorithm to assess it. Our\nalgorithm computes the convex hull of the feature vectors of all feasible\nstructures in the ensemble of a given input sequence. Interestingly, that\nconvex hull coincides with the Newton polytope of the partition function as a\npolynomial in energy parameters. We demonstrated the application of our theory\nto a simple energy model consisting of a weighted count of A-U and C-G base\npairs. Our results show that this simple energy model satisfies the necessary\ncondition for less than one third of the input unpseudoknotted\nsequence-structure pairs chosen from the RNA STRAND v2.0 database. For another\none third, the necessary condition is barely violated, which suggests that\naugmenting this simple energy model with more features such as the Turner loops\nmay solve the problem. The necessary condition is severely violated for 8%,\nwhich provides a small set of hard cases that require further investigation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 17:43:08 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Forouzmand", "Elmirasadat", ""], ["Chitsaz", "Hamidreza", ""]]}, {"id": "1301.1722", "submitter": "Andrea Montanari", "authors": "Yash Deshpande and Andrea Montanari", "title": "Linear Bandits in High Dimension and Recommendation Systems", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of online services provide automated recommendations to help\nusers to navigate through a large collection of items. New items (products,\nvideos, songs, advertisements) are suggested on the basis of the user's past\nhistory and --when available-- her demographic profile. Recommendations have to\nsatisfy the dual goal of helping the user to explore the space of available\nitems, while allowing the system to probe the user's preferences.\n  We model this trade-off using linearly parametrized multi-armed bandits,\npropose a policy and prove upper and lower bounds on the cumulative \"reward\"\nthat coincide up to constants in the data poor (high-dimensional) regime. Prior\nwork on linear bandits has focused on the data rich (low-dimensional) regime\nand used cumulative \"risk\" as the figure of merit. For this data rich regime,\nwe provide a simple modification for our policy that achieves near-optimal risk\nperformance under more restrictive assumptions on the geometry of the problem.\nWe test (a variation of) the scheme used for establishing achievability on the\nNetflix and MovieLens datasets and obtain good agreement with the qualitative\npredictions of the theory we develop.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2013 23:45:06 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Deshpande", "Yash", ""], ["Montanari", "Andrea", ""]]}, {"id": "1301.1936", "submitter": "Alessandro Lazaric", "authors": "Amir Sani (INRIA Lille - Nord Europe), Alessandro Lazaric (INRIA Lille\n  - Nord Europe), R\\'emi Munos (INRIA Lille - Nord Europe)", "title": "Risk-Aversion in Multi-armed Bandits", "comments": "(2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic multi-armed bandits solve the Exploration-Exploitation dilemma and\nultimately maximize the expected reward. Nonetheless, in many practical\nproblems, maximizing the expected reward is not the most desirable objective.\nIn this paper, we introduce a novel setting based on the principle of\nrisk-aversion where the objective is to compete against the arm with the best\nrisk-return trade-off. This setting proves to be intrinsically more difficult\nthan the standard multi-arm bandit setting due in part to an exploration risk\nwhich introduces a regret associated to the variability of an algorithm. Using\nvariance as a measure of risk, we introduce two new algorithms, investigate\ntheir theoretical guarantees, and report preliminary empirical results.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 18:02:54 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Sani", "Amir", "", "INRIA Lille - Nord Europe"], ["Lazaric", "Alessandro", "", "INRIA Lille\n  - Nord Europe"], ["Munos", "R\u00e9mi", "", "INRIA Lille - Nord Europe"]]}, {"id": "1301.1942", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Frank Hutter, Masrour Zoghi, David Matheson, Nando de\n  Freitas", "title": "Bayesian Optimization in a Billion Dimensions via Random Embeddings", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization techniques have been successfully applied to robotics,\nplanning, sensor placement, recommendation, advertising, intelligent user\ninterfaces and automatic algorithm configuration. Despite these successes, the\napproach is restricted to problems of moderate dimension, and several workshops\non Bayesian optimization have identified its scaling to high-dimensions as one\nof the holy grails of the field. In this paper, we introduce a novel random\nembedding idea to attack this problem. The resulting Random EMbedding Bayesian\nOptimization (REMBO) algorithm is very simple, has important invariance\nproperties, and applies to domains with both categorical and continuous\nvariables. We present a thorough theoretical analysis of REMBO. Empirical\nresults confirm that REMBO can effectively solve problems with billions of\ndimensions, provided the intrinsic dimensionality is low. They also show that\nREMBO achieves state-of-the-art performance in optimizing the 47 discrete\nparameters of a popular mixed integer linear programming solver.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2013 18:26:56 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2016 16:01:22 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Wang", "Ziyu", ""], ["Hutter", "Frank", ""], ["Zoghi", "Masrour", ""], ["Matheson", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1301.2012", "submitter": "Srivatsan Laxman", "authors": "Srivatsan Laxman, Sushil Mittal and Ramarathnam Venkatesan", "title": "Error Correction in Learning using SVMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with learning binary classifiers under adversarial\nlabel-noise. We introduce the problem of error-correction in learning where the\ngoal is to recover the original clean data from a label-manipulated version of\nit, given (i) no constraints on the adversary other than an upper-bound on the\nnumber of errors, and (ii) some regularity properties for the original data. We\npresent a simple and practical error-correction algorithm called SubSVMs that\nlearns individual SVMs on several small-size (log-size), class-balanced, random\nsubsets of the data and then reclassifies the training points using a majority\nvote. Our analysis reveals the need for the two main ingredients of SubSVMs,\nnamely class-balanced sampling and subsampled bagging. Experimental results on\nsynthetic as well as benchmark UCI data demonstrate the effectiveness of our\napproach. In addition to noise-tolerance, log-size subsampled bagging also\nyields significant run-time benefits over standard SVMs.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 00:47:21 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Laxman", "Srivatsan", ""], ["Mittal", "Sushil", ""], ["Venkatesan", "Ramarathnam", ""]]}, {"id": "1301.2015", "submitter": "Daniel Khashabi", "authors": "Daniel Khashabi, Mojtaba Ziyadi, Feng Liang", "title": "Heteroscedastic Relevance Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this work we propose a heteroscedastic generalization to RVM, a fast\nBayesian framework for regression, based on some recent similar works. We use\nvariational approximation and expectation propagation to tackle the problem.\nThe work is still under progress and we are examining the results and comparing\nwith the previous works.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 02:02:01 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Khashabi", "Daniel", ""], ["Ziyadi", "Mojtaba", ""], ["Liang", "Feng", ""]]}, {"id": "1301.2032", "submitter": "Chunhua Shen", "authors": "Chunhua Shen and Peng Wang and Sakrapee Paisitkriangkrai and Anton van\n  den Hengel", "title": "Training Effective Node Classifiers for Cascade Classification", "comments": "Appearing in Int'l J. Computer Vision. This is a substantially\n  revised version of http://arxiv.org/abs/1008.3742", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascade classifiers are widely used in real-time object detection. Different\nfrom conventional classifiers that are designed for a low overall\nclassification error rate, a classifier in each node of the cascade is required\nto achieve an extremely high detection rate and moderate false positive rate.\nAlthough there are a few reported methods addressing this requirement in the\ncontext of object detection, there is no principled feature selection method\nthat explicitly takes into account this asymmetric node learning objective. We\nprovide such an algorithm here. We show that a special case of the biased\nminimax probability machine has the same formulation as the linear asymmetric\nclassifier (LAC) of Wu et al (2005). We then design a new boosting algorithm\nthat directly optimizes the cost function of LAC. The resulting\ntotally-corrective boosting algorithm is implemented by the column generation\ntechnique in convex optimization. Experimental results on object detection\nverify the effectiveness of the proposed boosting algorithm as a node\nclassifier in cascade object detection, and show performance better than that\nof the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 05:26:18 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Shen", "Chunhua", ""], ["Wang", "Peng", ""], ["Paisitkriangkrai", "Sakrapee", ""], ["Hengel", "Anton van den", ""]]}, {"id": "1301.2115", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, David Balduzzi, Bernhard Sch\\\"olkopf", "title": "Domain Generalization via Invariant Feature Representation", "comments": "The 30th International Conference on Machine Learning (ICML 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates domain generalization: How to take knowledge acquired\nfrom an arbitrary number of related domains and apply it to previously unseen\ndomains? We propose Domain-Invariant Component Analysis (DICA), a kernel-based\noptimization algorithm that learns an invariant transformation by minimizing\nthe dissimilarity across domains, whilst preserving the functional relationship\nbetween input and output variables. A learning-theoretic analysis shows that\nreducing dissimilarity improves the expected generalization ability of\nclassifiers on new domains, motivating the proposed algorithm. Experimental\nresults on synthetic and real-world datasets demonstrate that DICA successfully\nlearns invariant features and improves classifier performance in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 13:29:17 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Muandet", "Krikamol", ""], ["Balduzzi", "David", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1301.2194", "submitter": "Steven Hill", "authors": "Steven M. Hill and Sach Mukherjee", "title": "Network-based clustering with mixtures of L1-penalized Gaussian\n  graphical models: an empirical investigation", "comments": "A version of this work also appears in the first author's PhD Thesis\n  (Sparse Graphical Models for Cancer Signalling, University of Warwick, 2012),\n  which can be accessed at http://wrap.warwick.ac.uk/id/eprint/49626", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, multivariate samples may harbor previously unrecognized\nheterogeneity at the level of conditional independence or network structure.\nFor example, in cancer biology, disease subtypes may differ with respect to\nsubtype-specific interplay between molecular components. Then, both subtype\ndiscovery and estimation of subtype-specific networks present important and\nrelated challenges. To enable such analyses, we put forward a mixture model\nwhose components are sparse Gaussian graphical models. This brings together\nmodel-based clustering and graphical modeling to permit simultaneous estimation\nof cluster assignments and cluster-specific networks. We carry out estimation\nwithin an L1-penalized framework, and investigate several specific penalization\nregimes. We present empirical results on simulated data and provide general\nrecommendations for the formulation and use of mixtures of L1-penalized\nGaussian graphical models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 17:23:11 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Hill", "Steven M.", ""], ["Mukherjee", "Sach", ""]]}, {"id": "1301.2262", "submitter": "Robert G. Cowell", "authors": "Robert G. Cowell", "title": "Conditions Under Which Conditional Independence and Scoring Methods Lead\n  to Identical Selection of Bayesian Network Models", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-91-97", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often stated in papers tackling the task of inferring Bayesian network\nstructures from data that there are these two distinct approaches: (i) Apply\nconditional independence tests when testing for the presence or otherwise of\nedges; (ii) Search the model space using a scoring metric. Here I argue that\nfor complete data and a given node ordering this division is a myth, by showing\nthat cross entropy methods for checking conditional independence are\nmathematically identical to methods based upon discriminating between models by\ntheir overall goodness-of-fit logarithmic scores.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:01 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Cowell", "Robert G.", ""]]}, {"id": "1301.2266", "submitter": "Nando de Freitas", "authors": "Nando de Freitas, Pedro Hojen-Sorensen, Michael I. Jordan, Stuart\n  Russell", "title": "Variational MCMC", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-120-127", "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of learning algorithms that combines variational\napproximation and Markov chain Monte Carlo (MCMC) simulation. Naive algorithms\nthat use the variational approximation as proposal distribution can perform\npoorly because this approximation tends to underestimate the true variance and\nother features of the data. We solve this problem by introducing more\nsophisticated MCMC algorithms. One of these algorithms is a mixture of two MCMC\nkernels: a random walk Metropolis kernel and a blockMetropolis-Hastings (MH)\nkernel with a variational approximation as proposaldistribution. The MH kernel\nallows one to locate regions of high probability efficiently. The Metropolis\nkernel allows us to explore the vicinity of these regions. This algorithm\noutperforms variationalapproximations because it yields slightly better\nestimates of the mean and considerably better estimates of higher moments, such\nas covariances. It also outperforms standard MCMC algorithms because it locates\ntheregions of high probability quickly, thus speeding up convergence. We\ndemonstrate this algorithm on the problem of Bayesian parameter estimation for\nlogistic (sigmoid) belief networks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:18 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["de Freitas", "Nando", ""], ["Hojen-Sorensen", "Pedro", ""], ["Jordan", "Michael I.", ""], ["Russell", "Stuart", ""]]}, {"id": "1301.2268", "submitter": "Tal El-Hay", "authors": "Tal El-Hay, Nir Friedman", "title": "Incorporating Expressive Graphical Models in Variational Approximations:\n  Chain-Graphs and Hidden Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-136-143", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global variational approximation methods in graphical models allow efficient\napproximate inference of complex posterior distributions by using a simpler\nmodel. The choice of the approximating model determines a tradeoff between the\ncomplexity of the approximation procedure and the quality of the approximation.\nIn this paper, we consider variational approximations based on two classes of\nmodels that are richer than standard Bayesian networks, Markov networks or\nmixture models. As such, these classes allow to find better tradeoffs in the\nspectrum of approximations. The first class of models are chain graphs, which\ncapture distributions that are partially directed. The second class of models\nare directed graphs (Bayesian networks) with additional latent variables. Both\nclasses allow representation of multi-variable dependencies that cannot be\neasily represented within a Bayesian network.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:26 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["El-Hay", "Tal", ""], ["Friedman", "Nir", ""]]}, {"id": "1301.2269", "submitter": "Gal Elidan", "authors": "Gal Elidan, Nir Friedman", "title": "Learning the Dimensionality of Hidden Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-144-151", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A serious problem in learning probabilistic models is the presence of hidden\nvariables. These variables are not observed, yet interact with several of the\nobserved variables. Detecting hidden variables poses two problems: determining\nthe relations to other variables in the model and determining the number of\nstates of the hidden variable. In this paper, we address the latter problem in\nthe context of Bayesian networks. We describe an approach that utilizes a\nscore-based agglomerative state-clustering. As we show, this approach allows us\nto efficiently evaluate models with a range of cardinalities for the hidden\nvariable. We show how to extend this procedure to deal with multiple\ninteracting hidden variables. We demonstrate the effectiveness of this approach\nby evaluating it on synthetic and real-life data. We show that our approach\nlearns models with hidden variables that generalize better and have better\nstructure than previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:30 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Elidan", "Gal", ""], ["Friedman", "Nir", ""]]}, {"id": "1301.2270", "submitter": "Nir Friedman", "authors": "Nir Friedman, Ori Mosenzon, Noam Slonim, Naftali Tishby", "title": "Multivariate Information Bottleneck", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-152-161", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information bottleneck method is an unsupervised non-parametric data\norganization technique. Given a joint distribution P(A,B), this method\nconstructs a new variable T that extracts partitions, or clusters, over the\nvalues of A that are informative about B. The information bottleneck has\nalready been applied to document classification, gene expression, neural code,\nand spectral analysis. In this paper, we introduce a general principled\nframework for multivariate extensions of the information bottleneck method.\nThis allows us to consider multiple systems of data partitions that are\ninter-related. Our approach utilizes Bayesian networks for specifying the\nsystems of clusters and what information each captures. We show that this\nconstruction provides insight about bottleneck variations and enables us to\ncharacterize solutions of these variations. We also present a general framework\nfor iterative algorithms for constructing solutions, and apply it to several\nexamples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:23:36 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Friedman", "Nir", ""], ["Mosenzon", "Ori", ""], ["Slonim", "Noam", ""], ["Tishby", "Naftali", ""]]}, {"id": "1301.2278", "submitter": "Geoffrey E. Hinton", "authors": "Geoffrey E. Hinton, Yee Whye Teh", "title": "Discovering Multiple Constraints that are Frequently Approximately\n  Satisfied", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-227-234", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some high-dimensional data.sets can be modelled by assuming that there are\nmany different linear constraints, each of which is Frequently Approximately\nSatisfied (FAS) by the data. The probability of a data vector under the model\nis then proportional to the product of the probabilities of its constraint\nviolations. We describe three methods of learning products of constraints using\na heavy-tailed probability distribution for the violations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:10 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Hinton", "Geoffrey E.", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1301.2280", "submitter": "Geoff A. Jarrad", "authors": "Geoff A. Jarrad", "title": "Estimating Well-Performing Bayesian Networks using Bernoulli Mixtures", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-245-252", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for estimating Bayesian network (BN) parameters from data is\npresented which provides improved performance on test data. Previous research\nhas shown the value of representing conditional probability distributions\n(CPDs) via neural networks(Neal 1992), noisy-OR gates (Neal 1992, Diez 1993)and\ndecision trees (Friedman and Goldszmidt 1996).The Bernoulli mixture network\n(BMN) explicitly represents the CPDs of discrete BN nodes as mixtures of local\ndistributions,each having a different set of parents.This increases the space\nof possible structures which can be considered,enabling the CPDs to have\nfiner-grained dependencies.The resulting estimation procedure induces a\nmodelthat is better able to emulate the underlying interactions occurring in\nthe data than conventional conditional Bernoulli network models.The results for\nartificially generated data indicate that overfitting is best reduced by\nrestricting the complexity of candidate mixture substructures local to each\nnode. Furthermore, mixtures of very simple substructures can perform almost as\nwell as more complex ones.The BMN is also applied to data collected from an\nonline adventure game with an application to keyhole plan recognition. The\nresults show that the BMN-based model brings a dramatic improvement in\nperformance over a conventional BN model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:19 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Jarrad", "Geoff A.", ""]]}, {"id": "1301.2283", "submitter": "Tomas Kocka", "authors": "Tomas Kocka, Robert Castelo", "title": "Improved learning of Bayesian networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-269-276", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search space of Bayesian Network structures is usually defined as Acyclic\nDirected Graphs (DAGs) and the search is done by local transformations of DAGs.\nBut the space of Bayesian Networks is ordered by DAG Markov model inclusion and\nit is natural to consider that a good search policy should take this into\naccount. First attempt to do this (Chickering 1996) was using equivalence\nclasses of DAGs instead of DAGs itself. This approach produces better results\nbut it is significantly slower. We present a compromise between these two\napproaches. It uses DAGs to search the space in such a way that the ordering by\ninclusion is taken into account. This is achieved by repetitive usage of local\nmoves within the equivalence class of DAGs. We show that this new approach\nproduces better results than the original DAGs approach without substantial\nchange in time complexity. We present empirical results, within the framework\nof heuristic search and Markov Chain Monte Carlo, provided through the Alarm\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:32 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kocka", "Tomas", ""], ["Castelo", "Robert", ""]]}, {"id": "1301.2284", "submitter": "Petri Kontkanen", "authors": "Petri Kontkanen, Petri Myllymaki, Henry Tirri", "title": "Classifier Learning with Supervised Marginal Likelihood", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-277-284", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued that in supervised classification tasks, in practice it\nmay be more sensible to perform model selection with respect to some more\nfocused model selection score, like the supervised (conditional) marginal\nlikelihood, than with respect to the standard marginal likelihood criterion.\nHowever, for most Bayesian network models, computing the supervised marginal\nlikelihood score takes exponential time with respect to the amount of observed\ndata. In this paper, we consider diagnostic Bayesian network classifiers where\nthe significant model parameters represent conditional distributions for the\nclass variable, given the values of the predictor variables, in which case the\nsupervised marginal likelihood can be computed in linear time with respect to\nthe data. As the number of model parameters grows in this case exponentially\nwith respect to the number of predictors, we focus on simple diagnostic models\nwhere the number of relevant predictors is small, and suggest two approaches\nfor applying this type of models in classification. The first approach is based\non mixtures of simple diagnostic models, while in the second approach we apply\nthe small predictor sets of the simple diagnostic models for augmenting the\nNaive Bayes classifier.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:36 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Kontkanen", "Petri", ""], ["Myllymaki", "Petri", ""], ["Tirri", "Henry", ""]]}, {"id": "1301.2286", "submitter": "John Lafferty", "authors": "John Lafferty, Larry A. Wasserman", "title": "Iterative Markov Chain Monte Carlo Computation of Reference Priors and\n  Minimax Risk", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-293-300", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an iterative Markov chainMonte Carlo algorithm for\ncomputingreference priors and minimax risk forgeneral parametric families.\nOurapproach uses MCMC techniques based onthe Blahut-Arimoto algorithm\nforcomputing channel capacity ininformation theory. We give astatistical\nanalysis of the algorithm,bounding the number of samples requiredfor the\nstochastic algorithm to closelyapproximate the deterministic algorithmin each\niteration. Simulations arepresented for several examples fromexponential\nfamilies. Although we focuson applications to reference priors andminimax risk,\nthe methods and analysiswe develop are applicable to a muchbroader class of\noptimization problemsand iterative algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:24:45 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Lafferty", "John", ""], ["Wasserman", "Larry A.", ""]]}, {"id": "1301.2292", "submitter": "Dimitris Margaritis", "authors": "Dimitris Margaritis, Sebastian Thrun", "title": "A Bayesian Multiresolution Independence Test for Continuous Variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-346-353", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method ofcomputing the posterior probability\nofconditional independence of two or morecontinuous variables from\ndata,examined at several resolutions. Ourapproach is motivated by\ntheobservation that the appearance ofcontinuous data varies widely atvarious\nresolutions, producing verydifferent independence estimatesbetween the\nvariablesinvolved. Therefore, it is difficultto ascertain independence\nwithoutexamining data at several carefullyselected resolutions. In our paper,\nweaccomplish this using the exactcomputation of the posteriorprobability of\nindependence, calculatedanalytically given a resolution. Ateach examined\nresolution, we assume amultinomial distribution with Dirichletpriors for the\ndiscretized tableparameters, and compute the posteriorusing Bayesian\nintegration. Acrossresolutions, we use a search procedureto approximate the\nBayesian integral ofprobability over an exponential numberof possible\nhistograms. Our methodgeneralizes to an arbitrary numbervariables in a\nstraightforward manner.The test is suitable for Bayesiannetwork learning\nalgorithms that useindependence tests to infer the networkstructure, in domains\nthat contain anymix of continuous, ordinal andcategorical variables.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:12 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Margaritis", "Dimitris", ""], ["Thrun", "Sebastian", ""]]}, {"id": "1301.2294", "submitter": "Thomas P. Minka", "authors": "Thomas P. Minka", "title": "Expectation Propagation for approximate Bayesian inference", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-362-369", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new deterministic approximation technique in Bayesian\nnetworks. This method, \"Expectation Propagation\", unifies two previous\ntechniques: assumed-density filtering, an extension of the Kalman filter, and\nloopy belief propagation, an extension of belief propagation in Bayesian\nnetworks. All three algorithms try to recover an approximate distribution which\nis close in KL divergence to the true distribution. Loopy belief propagation,\nbecause it propagates exact belief states, is useful for a limited class of\nbelief networks, such as those which are purely discrete. Expectation\nPropagation approximates the belief states by only retaining certain\nexpectations, such as mean and variance, and iterates until these expectations\nare consistent throughout the network. This makes it applicable to hybrid\nnetworks with discrete and continuous nodes. Expectation Propagation also\nextends belief propagation in the opposite direction - it can propagate richer\nbelief states that incorporate correlations between nodes. Experiments with\nGaussian mixture models show Expectation Propagation to be convincingly better\nthan methods with similar computational cost: Laplace's method, variational\nBayes, and Monte Carlo. Expectation Propagation also provides an efficient\nalgorithm for training Bayes point machine classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:20 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Minka", "Thomas P.", ""]]}, {"id": "1301.2303", "submitter": "Alexandrin Popescul", "authors": "Alexandrin Popescul, Lyle H. Ungar, David M Pennock, Steve Lawrence", "title": "Probabilistic Models for Unified Collaborative and Content-Based\n  Recommendation in Sparse-Data Environments", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-437-444", "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems leverage product and community information to target\nproducts to consumers. Researchers have developed collaborative recommenders,\ncontent-based recommenders, and (largely ad-hoc) hybrid systems. We propose a\nunified probabilistic framework for merging collaborative and content-based\nrecommendations. We extend Hofmann's [1999] aspect model to incorporate\nthree-way co-occurrence data among users, items, and item content. The relative\ninfluence of collaboration data versus content data is not imposed as an\nexogenous parameter, but rather emerges naturally from the given data sources.\nGlobal probabilistic models coupled with standard Expectation Maximization (EM)\nlearning algorithms tend to drastically overfit in sparse-data situations, as\nis typical in recommendation applications. We show that secondary content\ninformation can often be used to overcome sparsity. Experiments on data from\nthe ResearchIndex library of Computer Science publications show that\nappropriate mixture models incorporating secondary data produce significantly\nbetter quality recommenders than k-nearest neighbors (k-NN). Global\nprobabilistic models also allow more general inferences than local methods like\nk-NN.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:25:59 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Popescul", "Alexandrin", ""], ["Ungar", "Lyle H.", ""], ["Pennock", "David M", ""], ["Lawrence", "Steve", ""]]}, {"id": "1301.2309", "submitter": "Rita Sharma", "authors": "Rita Sharma, David L Poole", "title": "Symmetric Collaborative Filtering Using the Noisy Sensor Model", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-488-495", "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering is the process of making recommendations regarding\nthe potential preference of a user, for example shopping on the Internet, based\non the preference ratings of the user and a number of other users for various\nitems. This paper considers collaborative filtering based on\nexplicitmulti-valued ratings. To evaluate the algorithms, weconsider only {em\npure} collaborative filtering, using ratings exclusively, and no other\ninformation about the people or items.Our approach is to predict a user's\npreferences regarding a particularitem by using other people who rated that\nitem and other items ratedby the user as noisy sensors. The noisy sensor model\nuses Bayes' theorem to compute the probability distribution for the\nuser'srating of a new item. We give two variant models: in one, we learn a{em\nclassical normal linear regression} model of how users rate items; in\nanother,we assume different users rate items the same, but the accuracy of\nthesensors needs to be learned. We compare these variant models\nwithstate-of-the-art techniques and show how they are significantly\nbetter,whether a user has rated only two items or many. We reportempirical\nresults using the EachMovie database\nfootnote{http://research.compaq.com/SRC/eachmovie/} of movie ratings. Wealso\nshow that by considering items similarity along with theusers similarity, the\naccuracy of the prediction increases.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:26 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Sharma", "Rita", ""], ["Poole", "David L", ""]]}, {"id": "1301.2310", "submitter": "Christian R. Shelton", "authors": "Christian R. Shelton", "title": "Policy Improvement for POMDPs Using Normalized Importance Sampling", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-496-503", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for estimating the expected return of a POMDP from\nexperience. The method does not assume any knowledge of the POMDP and allows\nthe experience to be gathered from an arbitrary sequence of policies. The\nreturn is estimated for any new policy of the POMDP. We motivate the estimator\nfrom function-approximation and importance sampling points-of-view and derive\nits theoretical properties. Although the estimator is biased, it has low\nvariance and the bias is often irrelevant when the estimator is used for\npair-wise comparisons. We conclude by extending the estimator to policies with\nmemory and compare its performance in a greedy search algorithm to REINFORCE\nalgorithms showing an order of magnitude reduction in the number of trials\nrequired.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:30 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Shelton", "Christian R.", ""]]}, {"id": "1301.2311", "submitter": "Nathan Srebro", "authors": "Nathan Srebro", "title": "Maximum Likelihood Bounded Tree-Width Markov Networks", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-504-511", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chow and Liu (1968) studied the problem of learning a maximumlikelihood\nMarkov tree. We generalize their work to more complexMarkov networks by\nconsidering the problem of learning a maximumlikelihood Markov network of\nbounded complexity. We discuss howtree-width is in many ways the appropriate\nmeasure of complexity andthus analyze the problem of learning a maximum\nlikelihood Markovnetwork of bounded tree-width.Similar to the work of Chow and\nLiu, we are able to formalize thelearning problem as a combinatorial\noptimization problem on graphs. Weshow that learning a maximum likelihood\nMarkov network of boundedtree-width is equivalent to finding a maximum weight\nhypertree. Thisequivalence gives rise to global, integer-programming\nbased,approximation algorithms with provable performance guarantees, for\nthelearning problem. This contrasts with heuristic local-searchalgorithms which\nwere previously suggested (e.g. by Malvestuto 1991).The equivalence also allows\nus to study the computational hardness ofthe learning problem. We show that\nlearning a maximum likelihoodMarkov network of bounded tree-width is NP-hard,\nand discuss thehardness of approximation.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:35 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Srebro", "Nathan", ""]]}, {"id": "1301.2315", "submitter": "Lex Weaver", "authors": "Lex Weaver, Nigel Tao", "title": "The Optimal Reward Baseline for Gradient-Based Reinforcement Learning", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-538-545", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist a number of reinforcement learning algorithms which learnby\nclimbing the gradient of expected reward. Their long-runconvergence has been\nproved, even in partially observableenvironments with non-deterministic\nactions, and without the need fora system model. However, the variance of the\ngradient estimator hasbeen found to be a significant practical problem. Recent\napproacheshave discounted future rewards, introducing a bias-variance\ntrade-offinto the gradient estimate. We incorporate a reward baseline into\nthelearning system, and show that it affects variance without\nintroducingfurther bias. In particular, as we approach the\nzero-bias,high-variance parameterization, the optimal (or variance\nminimizing)constant reward baseline is equal to the long-term average\nexpectedreward. Modified policy-gradient algorithms are presented, and anumber\nof experiments demonstrate their improvement over previous work.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:53 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Weaver", "Lex", ""], ["Tao", "Nigel", ""]]}, {"id": "1301.2316", "submitter": "Jacob A. Wegelin", "authors": "Jacob A. Wegelin, Thomas S. Richardson", "title": "Cross-covariance modelling via DAGs with hidden variables", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-546-553", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DAG models with hidden variables present many difficulties that are not\npresent when all nodes are observed. In particular, fully observed DAG models\nare identified and correspond to well-defined sets ofdistributions, whereas\nthis is not true if nodes are unobserved. Inthis paper we characterize exactly\nthe set of distributions given by a class of one-dimensional Gaussian latent\nvariable models. These models relate two blocks of observed variables, modeling\nonly the cross-covariance matrix. We describe the relation of this model to the\nsingular value decomposition of the cross-covariance matrix. We show that,\nalthough the model is underidentified, useful information may be extracted. We\nfurther consider an alternative parametrization in which one latent variable is\nassociated with each block. Our analysis leads to some novel covariance\nequivalence results for Gaussian hidden variable models.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:26:57 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Wegelin", "Jacob A.", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1301.2317", "submitter": "Max Welling", "authors": "Max Welling, Yee Whye Teh", "title": "Belief Optimization for Binary Networks: A Stable Alternative to Loopy\n  Belief Propagation", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-554-561", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel inference algorithm for arbitrary, binary, undirected\ngraphs. Unlike loopy belief propagation, which iterates fixed point equations,\nwe directly descend on the Bethe free energy. The algorithm consists of two\nphases, first we update the pairwise probabilities, given the marginal\nprobabilities at each unit,using an analytic expression. Next, we update the\nmarginal probabilities, given the pairwise probabilities by following the\nnegative gradient of the Bethe free energy. Both steps are guaranteed to\ndecrease the Bethe free energy, and since it is lower bounded, the algorithm is\nguaranteed to converge to a local minimum. We also show that the Bethe free\nenergy is equal to the TAP free energy up to second order in the weights. In\nexperiments we confirm that when belief propagation converges it usually finds\nidentical solutions as our belief optimization method. However, in cases where\nbelief propagation fails to converge, belief optimization continues to converge\nto reasonable beliefs. The stable nature of belief optimization makes it\nideally suited for learning graphical models from data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:02 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Welling", "Max", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1301.2318", "submitter": "Steve Young", "authors": "Steve Young", "title": "Statistical Modeling in Continuous Speech Recognition (CSR)(Invited\n  Talk)", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-562-571", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic continuous speech recognition (CSR) is sufficiently mature that a\nvariety of real world applications are now possible including large vocabulary\ntranscription and interactive spoken dialogues. This paper reviews the\nevolution of the statistical modelling techniques which underlie current-day\nsystems, specifically hidden Markov models (HMMs) and N-grams. Starting from a\ndescription of the speech signal and its parameterisation, the various\nmodelling assumptions and their consequences are discussed. It then describes\nvarious techniques by which the effects of these assumptions can be mitigated.\nDespite the progress that has been made, the limitations of current modelling\ntechniques are still evident. The paper therefore concludes with a brief review\nof some of the more fundamental modelling work now in progress.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:07 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Young", "Steve", ""]]}, {"id": "1301.2320", "submitter": "Andrew Zimdars", "authors": "Andrew Zimdars, David Maxwell Chickering, Christopher Meek", "title": "Using Temporal Data for Making Recommendations", "comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2001-PG-580-588", "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We treat collaborative filtering as a univariate time series estimation\nproblem: given a user's previous votes, predict the next vote. We describe two\nfamilies of methods for transforming data to encode time order in ways amenable\nto off-the-shelf classification and density estimation tools, and examine the\nresults of using these approaches on several real-world data sets. The\nimprovements in predictive accuracy we realize recommend the use of other\npredictive algorithms that exploit the temporal order of data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 16:27:15 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["Zimdars", "Andrew", ""], ["Chickering", "David Maxwell", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.2343", "submitter": "Harm van Seijen", "authors": "Harm van Seijen and Richard S. Sutton", "title": "Planning by Prioritized Sweeping with Small Backups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient planning plays a crucial role in model-based reinforcement\nlearning. Traditionally, the main planning operation is a full backup based on\nthe current estimates of the successor states. Consequently, its computation\ntime is proportional to the number of successor states. In this paper, we\nintroduce a new planning backup that uses only the current value of a single\nsuccessor state and has a computation time independent of the number of\nsuccessor states. This new backup, which we call a small backup, opens the door\nto a new class of model-based reinforcement learning methods that exhibit much\nfiner control over their planning process than traditional methods. We\nempirically demonstrate that this increased flexibility allows for more\nefficient planning by showing that an implementation of prioritized sweeping\nbased on small backups achieves a substantial performance improvement over\nclassical implementations.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jan 2013 21:54:42 GMT"}], "update_date": "2013-01-14", "authors_parsed": [["van Seijen", "Harm", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1301.2603", "submitter": "Mahdi Soltanolkotabi", "authors": "Mahdi Soltanolkotabi, Ehsan Elhamifar, Emmanuel J. Cand\\`es", "title": "Robust subspace clustering", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1199 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2014, Vol. 42, No. 2, 669-699", "doi": "10.1214/13-AOS1199", "report-no": "IMS-AOS-AOS1199", "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering refers to the task of finding a multi-subspace\nrepresentation that best fits a collection of points taken from a\nhigh-dimensional space. This paper introduces an algorithm inspired by sparse\nsubspace clustering (SSC) [In IEEE Conference on Computer Vision and Pattern\nRecognition, CVPR (2009) 2790-2797] to cluster noisy data, and develops some\nnovel theory demonstrating its correctness. In particular, the theory uses\nideas from geometric functional analysis to show that the algorithm can\naccurately recover the underlying subspaces under minimal requirements on their\norientation, and on the number of samples per subspace. Synthetic as well as\nreal data experiments complement our theoretical study, illustrating our\napproach and demonstrating its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 21:05:23 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 00:39:13 GMT"}, {"version": "v3", "created": "Fri, 23 May 2014 13:19:54 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Soltanolkotabi", "Mahdi", ""], ["Elhamifar", "Ehsan", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1301.2609", "submitter": "Dan Russo", "authors": "Daniel Russo and Benjamin Van Roy", "title": "Learning to Optimize Via Posterior Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the use of a simple posterior sampling algorithm to\nbalance between exploration and exploitation when learning to optimize actions\nsuch as in multi-armed bandit problems. The algorithm, also known as Thompson\nSampling, offers significant advantages over the popular upper confidence bound\n(UCB) approach, and can be applied to problems with finite or infinite action\nspaces and complicated relationships among action rewards. We make two\ntheoretical contributions. The first establishes a connection between posterior\nsampling and UCB algorithms. This result lets us convert regret bounds\ndeveloped for UCB algorithms into Bayesian regret bounds for posterior\nsampling. Our second theoretical contribution is a Bayesian regret bound for\nposterior sampling that applies broadly and can be specialized to many model\nclasses. This bound depends on a new notion we refer to as the eluder\ndimension, which measures the degree of dependence among action rewards.\nCompared to UCB algorithm Bayesian regret bounds for specific model classes,\nour general bound matches the best available for linear models and is stronger\nthan the best available for generalized linear models. Further, our analysis\nprovides insight into performance advantages of posterior sampling, which are\nhighlighted through simulation results that demonstrate performance surpassing\nrecently proposed UCB algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 21:24:11 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2013 11:01:02 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2013 00:55:08 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2013 17:25:05 GMT"}, {"version": "v5", "created": "Mon, 3 Feb 2014 06:57:28 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Russo", "Daniel", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1301.2628", "submitter": "Xu-Cheng Yin", "authors": "Xu-Cheng Yin, Xuwang Yin, Kaizhu Huang, Hong-Wei Hao", "title": "Robust Text Detection in Natural Scene Images", "comments": "A Draft Version (Submitted to IEEE TPAMI)", "journal-ref": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 36,\n  no. 5, pp. 970-983, 2014", "doi": "10.1109/TPAMI.2013.182", "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text detection in natural scene images is an important prerequisite for many\ncontent-based image analysis tasks. In this paper, we propose an accurate and\nrobust method for detecting texts in natural scene images. A fast and effective\npruning algorithm is designed to extract Maximally Stable Extremal Regions\n(MSERs) as character candidates using the strategy of minimizing regularized\nvariations. Character candidates are grouped into text candidates by the\ningle-link clustering algorithm, where distance weights and threshold of the\nclustering algorithm are learned automatically by a novel self-training\ndistance metric learning algorithm. The posterior probabilities of text\ncandidates corresponding to non-text are estimated with an character\nclassifier; text candidates with high probabilities are then eliminated and\nfinally texts are identified with a text classifier. The proposed system is\nevaluated on the ICDAR 2011 Robust Reading Competition dataset; the f measure\nis over 76% and is significantly better than the state-of-the-art performance\nof 71%. Experimental results on a publicly available multilingual dataset also\nshow that our proposed method can outperform the other competitive method with\nthe f measure increase of over 9 percent. Finally, we have setup an online demo\nof our proposed scene text detection system at\nhttp://kems.ustb.edu.cn/learning/yin/dtext.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2013 23:08:15 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2013 19:57:46 GMT"}, {"version": "v3", "created": "Sun, 2 Jun 2013 16:27:49 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Yin", "Xu-Cheng", ""], ["Yin", "Xuwang", ""], ["Huang", "Kaizhu", ""], ["Hao", "Hong-Wei", ""]]}, {"id": "1301.2655", "submitter": "Preux Philippe", "authors": "Hachem Kadri (INRIA Lille - Nord Europe), Asma Rabaoui (IMS), Philippe\n  Preux (INRIA Lille - Nord Europe, LIFL), Emmanuel Duflos (INRIA Lille - Nord\n  Europe, LAGIS), Alain Rakotomamonjy (LITIS)", "title": "Functional Regularized Least Squares Classi cation with Operator-valued\n  Kernels", "comments": null, "journal-ref": "28th International Conference on Machine Learning (ICML), Seattle\n  : United States (2011)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although operator-valued kernels have recently received increasing interest\nin various machine learning and functional data analysis problems such as\nmulti-task learning or functional regression, little attention has been paid to\nthe understanding of their associated feature spaces. In this paper, we explore\nthe potential of adopting an operator-valued kernel feature space perspective\nfor the analysis of functional data. We then extend the Regularized Least\nSquares Classification (RLSC) algorithm to cover situations where there are\nmultiple functions per observation. Experiments on a sound recognition problem\nshow that the proposed method outperforms the classical RLSC algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 07:46:24 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Kadri", "Hachem", "", "INRIA Lille - Nord Europe"], ["Rabaoui", "Asma", "", "IMS"], ["Preux", "Philippe", "", "INRIA Lille - Nord Europe, LIFL"], ["Duflos", "Emmanuel", "", "INRIA Lille - Nord\n  Europe, LAGIS"], ["Rakotomamonjy", "Alain", "", "LITIS"]]}, {"id": "1301.2656", "submitter": "Preux Philippe", "authors": "Hachem Kadri (INRIA Lille - Nord Europe), Philippe Preux (INRIA Lille\n  - Nord Europe, LIFL), Emmanuel Duflos (INRIA Lille - Nord Europe, LAGIS),\n  St\\'ephane Canu (LITIS)", "title": "Multiple functional regression with both discrete and continuous\n  covariates", "comments": null, "journal-ref": "2nd International Workshop on Functional and Operatorial\n  Statistics (IWFOS), Santander : Spain (2011)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a nonparametric method for extending functional\nregression methodology to the situation where more than one functional\ncovariate is used to predict a functional response. Borrowing the idea from\nKadri et al. (2010a), the method, which support mixed discrete and continuous\nexplanatory variables, is based on estimating a function-valued function in\nreproducing kernel Hilbert spaces by virtue of positive operator-valued\nkernels.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 07:46:56 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Kadri", "Hachem", "", "INRIA Lille - Nord Europe"], ["Preux", "Philippe", "", "INRIA Lille\n  - Nord Europe, LIFL"], ["Duflos", "Emmanuel", "", "INRIA Lille - Nord Europe, LAGIS"], ["Canu", "St\u00e9phane", "", "LITIS"]]}, {"id": "1301.2659", "submitter": "Fabrice Rossi", "authors": "Romain Guigour\\`es, Marc Boull\\'e, Fabrice Rossi (SAMM)", "title": "A Triclustering Approach for Time Evolving Graphs", "comments": null, "journal-ref": "Co-clustering and Applications International Conference on Data\n  Mining Workshop, Brussels : Belgium (2012)", "doi": "10.1109/ICDMW.2012.61", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel technique to track structures in time evolving\ngraphs. The method is based on a parameter free approach for three-dimensional\nco-clustering of the source vertices, the target vertices and the time. All\nthese features are simultaneously segmented in order to build time segments and\nclusters of vertices whose edge distributions are similar and evolve in the\nsame way over the time segments. The main novelty of this approach lies in that\nthe time segments are directly inferred from the evolution of the edge\ndistribution between the vertices, thus not requiring the user to make an a\npriori discretization. Experiments conducted on a synthetic dataset illustrate\nthe good behaviour of the technique, and a study of a real-life dataset shows\nthe potential of the proposed approach for exploratory data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 07:51:14 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Guigour\u00e8s", "Romain", "", "SAMM"], ["Boull\u00e9", "Marc", "", "SAMM"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1301.2683", "submitter": "Josef Urban", "authors": "Josef Urban", "title": "BliStr: The Blind Strategymaker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BliStr is a system that automatically develops strategies for E prover on a\nlarge set of problems. The main idea is to interleave (i) iterated\nlow-timelimit local search for new strategies on small sets of similar easy\nproblems with (ii) higher-timelimit evaluation of the new strategies on all\nproblems. The accumulated results of the global higher-timelimit runs are used\nto define and evolve the notion of \"similar easy problems\", and to control the\nselection of the next strategy to be improved. The technique was used to\nsignificantly strengthen the set of E strategies used by the MaLARea, PS-E,\nE-MaLeS, and E systems in the CASC@Turing 2012 competition, particularly in the\nMizar division. Similar improvement was obtained on the problems created from\nthe Flyspeck corpus.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 13:02:21 GMT"}, {"version": "v2", "created": "Wed, 28 May 2014 12:54:41 GMT"}], "update_date": "2014-05-29", "authors_parsed": [["Urban", "Josef", ""]]}, {"id": "1301.2725", "submitter": "Yudong Chen", "authors": "Yudong Chen, Constantine Caramanis, Shie Mannor", "title": "Robust High Dimensional Sparse Regression and Matching Pursuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider high dimensional sparse regression, and develop strategies able\nto deal with arbitrary -- possibly, severe or coordinated -- errors in the\ncovariance matrix $X$. These may come from corrupted data, persistent\nexperimental errors, or malicious respondents in surveys/recommender systems,\netc. Such non-stochastic error-in-variables problems are notoriously difficult\nto treat, and as we demonstrate, the problem is particularly pronounced in\nhigh-dimensional settings where the primary goal is {\\em support recovery} of\nthe sparse regressor. We develop algorithms for support recovery in sparse\nregression, when some number $n_1$ out of $n+n_1$ total covariate/response\npairs are {\\it arbitrarily (possibly maliciously) corrupted}. We are interested\nin understanding how many outliers, $n_1$, we can tolerate, while identifying\nthe correct support. To the best of our knowledge, neither standard outlier\nrejection techniques, nor recently developed robust regression algorithms (that\nfocus only on corrupted response variables), nor recent algorithms for dealing\nwith stochastic noise or erasures, can provide guarantees on support recovery.\nPerhaps surprisingly, we also show that the natural brute force algorithm that\nsearches over all subsets of $n$ covariate/response pairs, and all subsets of\npossible support coordinates in order to minimize regression error, is\nremarkably poor, unable to correctly identify the support with even $n_1 =\nO(n/k)$ corrupted points, where $k$ is the sparsity. This is true even in the\nbasic setting we consider, where all authentic measurements and noise are\nindependent and sub-Gaussian. In this setting, we provide a simple algorithm --\nno more computationally taxing than OMP -- that gives stronger performance\nguarantees, recovering the support with up to $n_1 = O(n/(\\sqrt{k} \\log p))$\ncorrupted points, where $p$ is the dimension of the signal to be recovered.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jan 2013 22:39:56 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Chen", "Yudong", ""], ["Caramanis", "Constantine", ""], ["Mannor", "Shie", ""]]}, {"id": "1301.2785", "submitter": "Rafi Muhammad", "authors": "Muhammad Rafi, Mohammad Shahid Shaikh", "title": "A comparison of SVM and RVM for Document Classification", "comments": "ICoCSIM 2012, Medan Indonesia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document classification is a task of assigning a new unclassified document to\none of the predefined set of classes. The content based document classification\nuses the content of the document with some weighting criteria to assign it to\none of the predefined classes. It is a major task in library science,\nelectronic document management systems and information sciences. This paper\ninvestigates document classification by using two different classification\ntechniques (1) Support Vector Machine (SVM) and (2) Relevance Vector Machine\n(RVM). SVM is a supervised machine learning technique that can be used for\nclassification task. In its basic form, SVM represents the instances of the\ndata into space and tries to separate the distinct classes by a maximum\npossible wide gap (hyper plane) that separates the classes. On the other hand\nRVM uses probabilistic measure to define this separation space. RVM uses\nBayesian inference to obtain succinct solution, thus RVM uses significantly\nfewer basis functions. Experimental studies on three standard text\nclassification datasets reveal that although RVM takes more training time, its\nclassification is much better as compared to SVM.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2013 15:58:09 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Rafi", "Muhammad", ""], ["Shaikh", "Mohammad Shahid", ""]]}, {"id": "1301.2840", "submitter": "Christian Osendorfer", "authors": "Christian Osendorfer and Justin Bayer and Sebastian Urban and Patrick\n  van der Smagt", "title": "Unsupervised Feature Learning for low-level Local Image Descriptors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised feature learning has shown impressive results for a wide range\nof input modalities, in particular for object classification tasks in computer\nvision. Using a large amount of unlabeled data, unsupervised feature learning\nmethods are utilized to construct high-level representations that are\ndiscriminative enough for subsequently trained supervised classification\nalgorithms. However, it has never been \\emph{quantitatively} investigated yet\nhow well unsupervised learning methods can find \\emph{low-level\nrepresentations} for image patches without any additional supervision. In this\npaper we examine the performance of pure unsupervised methods on a low-level\ncorrespondence task, a problem that is central to many Computer Vision\napplications. We find that a special type of Restricted Boltzmann Machines\n(RBMs) performs comparably to hand-crafted descriptors. Additionally, a simple\nbinarization scheme produces compact representations that perform better than\nseveral state-of-the-art descriptors.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2013 01:34:17 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2013 13:42:10 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 18:54:11 GMT"}, {"version": "v4", "created": "Thu, 25 Apr 2013 14:26:04 GMT"}], "update_date": "2013-04-26", "authors_parsed": [["Osendorfer", "Christian", ""], ["Bayer", "Justin", ""], ["Urban", "Sebastian", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1301.3192", "submitter": "Joonseok Lee", "authors": "Joonseok Lee, Seungyeon Kim, Guy Lebanon, Yoram Singer", "title": "Matrix Approximation under Local Low-Rank Assumption", "comments": "3 pages, 2 figures, Workshop submission to the First International\n  Conference on Learning Representations (ICLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix approximation is a common tool in machine learning for building\naccurate prediction models for recommendation systems, text mining, and\ncomputer vision. A prevalent assumption in constructing matrix approximations\nis that the partially observed matrix is of low-rank. We propose a new matrix\napproximation model where we assume instead that the matrix is only locally of\nlow-rank, leading to a representation of the observed matrix as a weighted sum\nof low-rank matrices. We analyze the accuracy of the proposed local low-rank\nmodeling. Our experiments show improvements in prediction accuracy in\nrecommendation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 00:54:38 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Lee", "Joonseok", ""], ["Kim", "Seungyeon", ""], ["Lebanon", "Guy", ""], ["Singer", "Yoram", ""]]}, {"id": "1301.3193", "submitter": "Justin Domke", "authors": "Justin Domke", "title": "Learning Graphical Model Parameters with Approximate Marginal Inference", "comments": "To Appear, IEEE Transactions on Pattern Analysis and Machine\n  Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2013.31", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood based-learning of graphical models faces challenges of\ncomputational-complexity and robustness to model mis-specification. This paper\nstudies methods that fit parameters directly to maximize a measure of the\naccuracy of predicted marginals, taking into account both model and inference\napproximations at training time. Experiments on imaging problems suggest\nmarginalization-based learning performs better than likelihood-based\napproximations on difficult problems where the model being fit is approximate\nin nature.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 01:07:14 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Domke", "Justin", ""]]}, {"id": "1301.3224", "submitter": "Judy Hoffman", "authors": "Judy Hoffman, Erik Rodner, Jeff Donahue, Trevor Darrell, Kate Saenko", "title": "Efficient Learning of Domain-invariant Image Representations", "comments": null, "journal-ref": "ICLR 2013", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that learns representations which explicitly\ncompensate for domain mismatch and which can be efficiently realized as linear\nclassifiers. Specifically, we form a linear transformation that maps features\nfrom the target (test) domain to the source (training) domain as part of\ntraining the classifier. We optimize both the transformation and classifier\nparameters jointly, and introduce an efficient cost function based on\nmisclassification loss. Our method combines several features previously\nunavailable in a single algorithm: multi-class adaptation through\nrepresentation learning, ability to map across heterogeneous feature spaces,\nand scalability to large datasets. We present experiments on several image\ndatasets that demonstrate improved accuracy and computational advantages\ncompared to previous approaches.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 04:39:32 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 01:36:31 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 05:09:12 GMT"}, {"version": "v4", "created": "Sun, 17 Mar 2013 19:39:37 GMT"}, {"version": "v5", "created": "Tue, 9 Apr 2013 01:10:49 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Hoffman", "Judy", ""], ["Rodner", "Erik", ""], ["Donahue", "Jeff", ""], ["Darrell", "Trevor", ""], ["Saenko", "Kate", ""]]}, {"id": "1301.3226", "submitter": "Rami Al-Rfou'", "authors": "Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, Steven Skiena", "title": "The Expressive Power of Word Embeddings", "comments": "submitted to ICML 2013, Deep Learning for Audio, Speech and Language\n  Processing Workshop. 8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to better understand the difference in quality of the several\npublicly released embeddings. We propose several tasks that help to distinguish\nthe characteristics of different embeddings. Our evaluation of sentiment\npolarity and synonym/antonym relations shows that embeddings are able to\ncapture surprisingly nuanced semantics even in the absence of sentence\nstructure. Moreover, benchmarking the embeddings shows great variance in\nquality and characteristics of the semantics captured by the tested embeddings.\nFinally, we show the impact of varying the number of dimensions and the\nresolution of each dimension on the effective useful features captured by the\nembedding space. Our contributions highlight the importance of embeddings for\nNLP tasks and the effect of their quality on the final results.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 04:52:10 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2013 21:44:29 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2013 17:08:14 GMT"}, {"version": "v4", "created": "Wed, 29 May 2013 21:06:09 GMT"}], "update_date": "2013-05-31", "authors_parsed": [["Chen", "Yanqing", ""], ["Perozzi", "Bryan", ""], ["Al-Rfou", "Rami", ""], ["Skiena", "Steven", ""]]}, {"id": "1301.3323", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Takaki Makino and Kazuyuki Aihara", "title": "Auto-pooling: Learning to Improve Invariance of Image Features from\n  Image Sequences", "comments": "9 pages, 10 figures. Submission for ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning invariant representations from images is one of the hardest\nchallenges facing computer vision. Spatial pooling is widely used to create\ninvariance to spatial shifting, but it is restricted to convolutional models.\nIn this paper, we propose a novel pooling method that can learn soft clustering\nof features from image sequences. It is trained to improve the temporal\ncoherence of features, while keeping the information loss at minimum. Our\nmethod does not use spatial information, so it can be used with\nnon-convolutional models too. Experiments on images extracted from natural\nvideos showed that our method can cluster similar features together. When\ntrained by convolutional features, auto-pooling outperformed traditional\nspatial pooling on an image classification task, even though it does not use\nthe spatial topology of features.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 12:47:39 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 06:05:10 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2013 16:39:30 GMT"}, {"version": "v4", "created": "Mon, 18 Mar 2013 07:19:31 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Makino", "Takaki", ""], ["Aihara", "Kazuyuki", ""]]}, {"id": "1301.3342", "submitter": "Laurens van der Maaten", "authors": "Laurens van der Maaten", "title": "Barnes-Hut-SNE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an O(N log N)-implementation of t-SNE -- an embedding\ntechnique that is commonly used for the visualization of high-dimensional data\nin scatter plots and that normally runs in O(N^2). The new implementation uses\nvantage-point trees to compute sparse pairwise similarities between the input\ndata objects, and it uses a variant of the Barnes-Hut algorithm - an algorithm\nused by astronomers to perform N-body simulations - to approximate the forces\nbetween the corresponding points in the embedding. Our experiments show that\nthe new algorithm, called Barnes-Hut-SNE, leads to substantial computational\nadvantages over standard t-SNE, and that it makes it possible to learn\nembeddings of data sets with millions of objects.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 13:44:18 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2013 11:00:32 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["van der Maaten", "Laurens", ""]]}, {"id": "1301.3347", "submitter": "Michalis Smyrnakis", "authors": "Michalis Smyrnakis", "title": "Multi-agent learning using Fictitious Play and Extended Kalman Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralised optimisation tasks are important components of multi-agent\nsystems. These tasks can be interpreted as n-player potential games: therefore\ngame-theoretic learning algorithms can be used to solve decentralised\noptimisation tasks. Fictitious play is the canonical example of these\nalgorithms. Nevertheless fictitious play implicitly assumes that players have\nstationary strategies. We present a novel variant of fictitious play where\nplayers predict their opponents' strategies using Extended Kalman filters and\nuse their predictions to update their strategies.\n  We show that in 2 by 2 games with at least one pure Nash equilibrium and in\npotential games where players have two available actions, the proposed\nalgorithm converges to the pure Nash equilibrium. The performance of the\nproposed algorithm was empirically tested, in two strategic form games and an\nad-hoc sensor network surveillance problem. The proposed algorithm performs\nbetter than the classic fictitious play algorithm in these games and therefore\nimproves the performance of game-theoretical learning in decentralised\noptimisation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 14:00:55 GMT"}], "update_date": "2013-01-16", "authors_parsed": [["Smyrnakis", "Michalis", ""]]}, {"id": "1301.3389", "submitter": "Hugo Van hamme", "authors": "Hugo Van hamme", "title": "The Diagonalized Newton Algorithm for Nonnegative Matrix Factorization", "comments": "8 pages + references; International Conference on Learning\n  Representations, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) has become a popular machine learning\napproach to many problems in text mining, speech and image processing,\nbio-informatics and seismic data analysis to name a few. In NMF, a matrix of\nnon-negative data is approximated by the low-rank product of two matrices with\nnon-negative entries. In this paper, the approximation quality is measured by\nthe Kullback-Leibler divergence between the data and its low-rank\nreconstruction. The existence of the simple multiplicative update (MU)\nalgorithm for computing the matrix factors has contributed to the success of\nNMF. Despite the availability of algorithms showing faster convergence, MU\nremains popular due to its simplicity. In this paper, a diagonalized Newton\nalgorithm (DNA) is proposed showing faster convergence while the implementation\nremains simple and suitable for high-rank problems. The DNA algorithm is\napplied to various publicly available data sets, showing a substantial speed-up\non modern hardware.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 15:59:46 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 09:15:29 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Van hamme", "Hugo", ""]]}, {"id": "1301.3391", "submitter": "Felix Bauer", "authors": "Felix Bauer, Roland Memisevic", "title": "Feature grouping from spatially constrained multiplicative interaction", "comments": "(new version:) added training formulae; added minor clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a feature learning model that learns to encode relationships\nbetween images. The model is defined as a Gated Boltzmann Machine, which is\nconstrained such that hidden units that are nearby in space can gate each\nother's connections. We show how frequency/orientation \"columns\" as well as\ntopographic filter maps follow naturally from training the model on image\npairs. The model also helps explain why square-pooling models yield feature\ngroups with similar grouping properties. Experimental results on synthetic\nimage transformations show that spatially constrained gating is an effective\nway to reduce the number of parameters and thereby to regularize a\ntransformation-learning model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 16:06:11 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 16:43:56 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 15:38:05 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Bauer", "Felix", ""], ["Memisevic", "Roland", ""]]}, {"id": "1301.3461", "submitter": "Cheng Zhang", "authors": "Cheng Zhang and Carl Henrik Ek and Andreas Damianou and Hedvig\n  Kjellstrom", "title": "Factorized Topic Models", "comments": "ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a modification to a latent topic model, which makes\nthe model exploit supervision to produce a factorized representation of the\nobserved data. The structured parameterization separately encodes variance that\nis shared between classes from variance that is private to each class by the\nintroduction of a new prior over the topic space. The approach allows for a\nmore eff{}icient inference and provides an intuitive interpretation of the data\nin terms of an informative signal together with structured noise. The\nfactorized representation is shown to enhance inference performance for image,\ntext, and video classification.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 19:32:20 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 11:05:05 GMT"}, {"version": "v3", "created": "Thu, 24 Jan 2013 09:50:28 GMT"}, {"version": "v4", "created": "Thu, 7 Mar 2013 14:16:39 GMT"}, {"version": "v5", "created": "Fri, 15 Mar 2013 17:14:58 GMT"}, {"version": "v6", "created": "Wed, 10 Apr 2013 20:15:04 GMT"}, {"version": "v7", "created": "Tue, 23 Apr 2013 08:13:55 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Zhang", "Cheng", ""], ["Ek", "Carl Henrik", ""], ["Damianou", "Andreas", ""], ["Kjellstrom", "Hedvig", ""]]}, {"id": "1301.3468", "submitter": "KyungHyun Cho", "authors": "Kyunghyun Cho", "title": "Boltzmann Machines and Denoising Autoencoders for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image denoising based on a probabilistic model of local image patches has\nbeen employed by various researchers, and recently a deep (denoising)\nautoencoder has been proposed by Burger et al. [2012] and Xie et al. [2012] as\na good model for this. In this paper, we propose that another popular family of\nmodels in the field of deep learning, called Boltzmann machines, can perform\nimage denoising as well as, or in certain cases of high level of noise, better\nthan denoising autoencoders. We empirically evaluate the two models on three\ndifferent sets of images with different types and levels of noise. Throughout\nthe experiments we also examine the effect of the depth of the models. The\nexperiments confirmed our claim and revealed that the performance can be\nimproved by adding more hidden layers, especially when the level of noise is\nhigh.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 19:45:27 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 15:37:08 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2013 13:48:22 GMT"}, {"version": "v4", "created": "Mon, 28 Jan 2013 16:35:56 GMT"}, {"version": "v5", "created": "Thu, 14 Feb 2013 11:16:34 GMT"}, {"version": "v6", "created": "Mon, 4 Mar 2013 10:41:34 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Cho", "Kyunghyun", ""]]}, {"id": "1301.3476", "submitter": "Tommi Vatanen", "authors": "Tommi Vatanen, Tapani Raiko, Harri Valpola, Yann LeCun", "title": "Pushing Stochastic Gradient towards Second-Order Methods --\n  Backpropagation Learning with Transformations in Nonlinearities", "comments": "10 pages, 5 figures, ICLR2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we proposed to transform the outputs of each hidden neuron in a\nmulti-layer perceptron network to have zero output and zero slope on average,\nand use separate shortcut connections to model the linear dependencies instead.\nWe continue the work by firstly introducing a third transformation to normalize\nthe scale of the outputs of each hidden neuron, and secondly by analyzing the\nconnections to second order optimization methods. We show that the\ntransformations make a simple stochastic gradient behave closer to second-order\noptimization methods and thus speed up learning. This is shown both in theory\nand with experiments. The experiments on the third transformation show that\nwhile it further increases the speed of learning, it can also hurt performance\nby converging to a worse local optimum, where both the inputs and outputs of\nmany hidden neurons are close to zero.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 20:21:54 GMT"}, {"version": "v2", "created": "Wed, 16 Jan 2013 09:23:23 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 18:00:00 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Vatanen", "Tommi", ""], ["Raiko", "Tapani", ""], ["Valpola", "Harri", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3485", "submitter": "Antoine Bordes", "authors": "Xavier Glorot and Antoine Bordes and Jason Weston and Yoshua Bengio", "title": "A Semantic Matching Energy Function for Learning with Multi-relational\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale relational learning becomes crucial for handling the huge amounts\nof structured data generated daily in many application domains ranging from\ncomputational biology or information retrieval, to natural language processing.\nIn this paper, we present a new neural network architecture designed to embed\nmulti-relational graphs into a flexible continuous vector space in which the\noriginal data is kept and enhanced. The network is trained to encode the\nsemantics of these graphs in order to assign high probabilities to plausible\ncomponents. We empirically show that it reaches competitive performance in link\nprediction on standard datasets from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 20:52:50 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2013 17:02:48 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Glorot", "Xavier", ""], ["Bordes", "Antoine", ""], ["Weston", "Jason", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.3516", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Mario Fritz", "title": "Learnable Pooling Regions for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biologically inspired, from the early HMAX model to Spatial Pyramid Matching,\npooling has played an important role in visual recognition pipelines. Spatial\npooling, by grouping of local codes, equips these methods with a certain degree\nof robustness to translation and deformation yet preserving important spatial\ninformation. Despite the predominance of this approach in current recognition\nsystems, we have seen little progress to fully adapt the pooling strategy to\nthe task at hand. This paper proposes a model for learning task dependent\npooling scheme -- including previously proposed hand-crafted pooling schemes as\na particular instantiation. In our work, we investigate the role of different\nregularization terms showing that the smooth regularization term is crucial to\nachieve strong performance using the presented architecture. Finally, we\npropose an efficient and parallel method to train the model. Our experiments\nshow improved performance over hand-crafted pooling schemes on the CIFAR-10 and\nCIFAR-100 datasets -- in particular improving the state-of-the-art to 56.29% on\nthe latter.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 22:15:06 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2013 13:51:04 GMT"}, {"version": "v3", "created": "Tue, 5 May 2015 18:12:46 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Fritz", "Mario", ""]]}, {"id": "1301.3524", "submitter": "Indre Zliobaite", "authors": "Indre Zliobaite", "title": "How good is the Electricity benchmark for evaluating concept drift\n  adaptation", "comments": "2 pages of content, 1 appendix, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this correspondence, we will point out a problem with testing adaptive\nclassifiers on autocorrelated data. In such a case random change alarms may\nboost the accuracy figures. Hence, we cannot be sure if the adaptation is\nworking well.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 22:51:40 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Zliobaite", "Indre", ""]]}, {"id": "1301.3527", "submitter": "Vamsi Potluru", "authors": "Vamsi K. Potluru, Sergey M. Plis, Jonathan Le Roux, Barak A.\n  Pearlmutter, Vince D. Calhoun, Thomas P. Hayes", "title": "Block Coordinate Descent for Sparse NMF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has become a ubiquitous tool for data\nanalysis. An important variant is the sparse NMF problem which arises when we\nexplicitly require the learnt features to be sparse. A natural measure of\nsparsity is the L$_0$ norm, however its optimization is NP-hard. Mixed norms,\nsuch as L$_1$/L$_2$ measure, have been shown to model sparsity robustly, based\non intuitive attributes that such measures need to satisfy. This is in contrast\nto computationally cheaper alternatives such as the plain L$_1$ norm. However,\npresent algorithms designed for optimizing the mixed norm L$_1$/L$_2$ are slow\nand other formulations for sparse NMF have been proposed such as those based on\nL$_1$ and L$_0$ norms. Our proposed algorithm allows us to solve the mixed norm\nsparsity constraints while not sacrificing computation time. We present\nexperimental evidence on real-world datasets that shows our new algorithm\nperforms an order of magnitude faster compared to the current state-of-the-art\nsolvers optimizing the mixed norm and is suitable for large-scale datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 23:11:05 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 22:42:11 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Potluru", "Vamsi K.", ""], ["Plis", "Sergey M.", ""], ["Roux", "Jonathan Le", ""], ["Pearlmutter", "Barak A.", ""], ["Calhoun", "Vince D.", ""], ["Hayes", "Thomas P.", ""]]}, {"id": "1301.3528", "submitter": "Momiao Xiong", "authors": "Momiao Xiong and Long Ma", "title": "An Efficient Sufficient Dimension Reduction Method for Identifying\n  Genetic Variants of Clinical Significance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and cheaper next generation sequencing technologies will generate\nunprecedentedly massive and highly-dimensional genomic and epigenomic variation\ndata. In the near future, a routine part of medical record will include the\nsequenced genomes. A fundamental question is how to efficiently extract genomic\nand epigenomic variants of clinical utility which will provide information for\noptimal wellness and interference strategies. Traditional paradigm for\nidentifying variants of clinical validity is to test association of the\nvariants. However, significantly associated genetic variants may or may not be\nusefulness for diagnosis and prognosis of diseases. Alternative to association\nstudies for finding genetic variants of predictive utility is to systematically\nsearch variants that contain sufficient information for phenotype prediction.\nTo achieve this, we introduce concepts of sufficient dimension reduction and\ncoordinate hypothesis which project the original high dimensional data to very\nlow dimensional space while preserving all information on response phenotypes.\nWe then formulate clinically significant genetic variant discovery problem into\nsparse SDR problem and develop algorithms that can select significant genetic\nvariants from up to or even ten millions of predictors with the aid of dividing\nSDR for whole genome into a number of subSDR problems defined for genomic\nregions. The sparse SDR is in turn formulated as sparse optimal scoring\nproblem, but with penalty which can remove row vectors from the basis matrix.\nTo speed up computation, we develop the modified alternating direction method\nfor multipliers to solve the sparse optimal scoring problem which can easily be\nimplemented in parallel. To illustrate its application, the proposed method is\napplied to simulation data and the NHLBI's Exome Sequencing Project dataset\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 23:19:14 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Xiong", "Momiao", ""], ["Ma", "Long", ""]]}, {"id": "1301.3530", "submitter": "Charles Cadieu", "authors": "Charles F. Cadieu, Ha Hong, Dan Yamins, Nicolas Pinto, Najib J. Majaj,\n  James J. DiCarlo", "title": "The Neural Representation Benchmark and its Evaluation on Brain and\n  Machine", "comments": "The v1 version contained incorrectly computed kernel analysis curves\n  and KA-AUC values for V4, IT, and the HT-L3 models. They have been corrected\n  in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key requirement for the development of effective learning representations\nis their evaluation and comparison to representations we know to be effective.\nIn natural sensory domains, the community has viewed the brain as a source of\ninspiration and as an implicit benchmark for success. However, it has not been\npossible to directly test representational learning algorithms directly against\nthe representations contained in neural systems. Here, we propose a new\nbenchmark for visual representations on which we have directly tested the\nneural representation in multiple visual cortical areas in macaque (utilizing\ndata from [Majaj et al., 2012]), and on which any computer vision algorithm\nthat produces a feature space can be tested. The benchmark measures the\neffectiveness of the neural or machine representation by computing the\nclassification loss on the ordered eigendecomposition of a kernel matrix\n[Montavon et al., 2011]. In our analysis we find that the neural representation\nin visual area IT is superior to visual area V4. In our analysis of\nrepresentational learning algorithms, we find that three-layer models approach\nthe representational performance of V4 and the algorithm in [Le et al., 2012]\nsurpasses the performance of V4. Impressively, we find that a recent supervised\nalgorithm [Krizhevsky et al., 2012] achieves performance comparable to that of\nIT for an intermediate level of image variation difficulty, and surpasses IT at\na higher difficulty level. We believe this result represents a major milestone:\nit is the first learning algorithm we have found that exceeds our current\nestimate of IT representation performance. We hope that this benchmark will\nassist the community in matching the representational performance of visual\ncortex and will serve as an initial rallying point for further correspondence\nbetween representations derived in brains and machines.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 23:42:21 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2013 20:39:46 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Cadieu", "Charles F.", ""], ["Hong", "Ha", ""], ["Yamins", "Dan", ""], ["Pinto", "Nicolas", ""], ["Majaj", "Najib J.", ""], ["DiCarlo", "James J.", ""]]}, {"id": "1301.3533", "submitter": "Xanadu Halkias", "authors": "Xanadu Halkias, Sebastien Paris, Herve Glotin", "title": "Sparse Penalty in Deep Belief Networks: Using the Mixed Norm Constraint", "comments": "8 pages, 7 figures (including subfigures), ICleaR conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Belief Networks (DBN) have been successfully applied on popular machine\nlearning tasks. Specifically, when applied on hand-written digit recognition,\nDBNs have achieved approximate accuracy rates of 98.8%. In an effort to\noptimize the data representation achieved by the DBN and maximize their\ndescriptive power, recent advances have focused on inducing sparse constraints\nat each layer of the DBN. In this paper we present a theoretical approach for\nsparse constraints in the DBN using the mixed norm for both non-overlapping and\noverlapping groups. We explore how these constraints affect the classification\naccuracy for digit recognition in three different datasets (MNIST, USPS, RIMES)\nand provide initial estimations of their usefulness by altering different\nparameters such as the group size and overlap percentage.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 00:12:21 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 10:18:15 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Halkias", "Xanadu", ""], ["Paris", "Sebastien", ""], ["Glotin", "Herve", ""]]}, {"id": "1301.3539", "submitter": "Yoonseop Kang", "authors": "Yoonseop Kang and Seungjin Choi", "title": "Learning Features with Structure-Adapting Multi-view Exponential Family\n  Harmoniums", "comments": "3 pages, 2 figures, ICLR2013 workshop track submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposea graphical model for multi-view feature extraction that\nautomatically adapts its structure to achieve better representation of data\ndistribution. The proposed model, structure-adapting multi-view harmonium\n(SA-MVH) has switch parameters that control the connection between hidden nodes\nand input views, and learn the switch parameter while training. Numerical\nexperiments on synthetic and a real-world dataset demonstrate the useful\nbehavior of the SA-MVH, compared to existing multi-view feature extraction\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 01:07:38 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Kang", "Yoonseop", ""], ["Choi", "Seungjin", ""]]}, {"id": "1301.3541", "submitter": "Rakesh Chalasani", "authors": "Rakesh Chalasani and Jose C. Principe", "title": "Deep Predictive Coding Networks", "comments": "13 Pages, 7 figures, submission for ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of data representation in deep learning methods is directly\nrelated to the prior model imposed on the representations; however, generally\nused fixed priors are not capable of adjusting to the context in the data. To\naddress this issue, we propose deep predictive coding networks, a hierarchical\ngenerative model that empirically alters priors on the latent representations\nin a dynamic and context-sensitive manner. This model captures the temporal\ndependencies in time-varying signals and uses top-down information to modulate\nthe representation in lower layers. The centerpiece of our model is a novel\nprocedure to infer sparse states of a dynamic model which is used for feature\nextraction. We also extend this feature extraction block to introduce a pooling\nfunction that captures locally invariant representations. When applied on a\nnatural video data, we show that our method is able to learn high-level visual\nfeatures. We also demonstrate the role of the top-down connections by showing\nthe robustness of the proposed model to structured noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 01:27:15 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 01:29:17 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2013 19:25:30 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Chalasani", "Rakesh", ""], ["Principe", "Jose C.", ""]]}, {"id": "1301.3545", "submitter": "Guillaume Desjardins", "authors": "Guillaume Desjardins, Razvan Pascanu, Aaron Courville and Yoshua\n  Bengio", "title": "Metric-Free Natural Gradient for Joint-Training of Boltzmann Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Metric-Free Natural Gradient (MFNG) algorithm for\ntraining Boltzmann Machines. Similar in spirit to the Hessian-Free method of\nMartens [8], our algorithm belongs to the family of truncated Newton methods\nand exploits an efficient matrix-vector product to avoid explicitely storing\nthe natural gradient metric $L$. This metric is shown to be the expected second\nderivative of the log-partition function (under the model distribution), or\nequivalently, the variance of the vector of partial derivatives of the energy\nfunction. We evaluate our method on the task of joint-training a 3-layer Deep\nBoltzmann Machine and show that MFNG does indeed have faster per-epoch\nconvergence compared to Stochastic Maximum Likelihood with centering, though\nwall-clock performance is currently not competitive.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 01:40:20 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 16:07:12 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Desjardins", "Guillaume", ""], ["Pascanu", "Razvan", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.3551", "submitter": "Luis  Sanchez Giraldo", "authors": "Luis G. Sanchez Giraldo and Jose C. Principe", "title": "Information Theoretic Learning with Infinitely Divisible Kernels", "comments": "Modified submission for International Conference on Learning\n  Representations 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a framework for information theoretic learning\nbased on infinitely divisible matrices. We formulate an entropy-like functional\non positive definite matrices based on Renyi's axiomatic definition of entropy\nand examine some key properties of this functional that lead to the concept of\ninfinite divisibility. The proposed formulation avoids the plug in estimation\nof density and brings along the representation power of reproducing kernel\nHilbert spaces. As an application example, we derive a supervised metric\nlearning algorithm using a matrix based analogue to conditional entropy\nachieving results comparable with the state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 01:49:52 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2013 06:40:01 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2013 14:53:42 GMT"}, {"version": "v4", "created": "Tue, 16 Apr 2013 00:12:21 GMT"}, {"version": "v5", "created": "Wed, 1 May 2013 06:18:31 GMT"}, {"version": "v6", "created": "Tue, 4 Jun 2013 04:42:39 GMT"}], "update_date": "2013-06-05", "authors_parsed": [["Giraldo", "Luis G. Sanchez", ""], ["Principe", "Jose C.", ""]]}, {"id": "1301.3557", "submitter": "Matthew Zeiler", "authors": "Matthew D. Zeiler and Rob Fergus", "title": "Stochastic Pooling for Regularization of Deep Convolutional Neural\n  Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and effective method for regularizing large\nconvolutional neural networks. We replace the conventional deterministic\npooling operations with a stochastic procedure, randomly picking the activation\nwithin each pooling region according to a multinomial distribution, given by\nthe activities within the pooling region. The approach is hyper-parameter free\nand can be combined with other regularization approaches, such as dropout and\ndata augmentation. We achieve state-of-the-art performance on four image\ndatasets, relative to other approaches that do not utilize data augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 02:12:07 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Zeiler", "Matthew D.", ""], ["Fergus", "Rob", ""]]}, {"id": "1301.3568", "submitter": "Ian Goodfellow", "authors": "Ian J. Goodfellow and Aaron Courville and Yoshua Bengio", "title": "Joint Training Deep Boltzmann Machines for Classification", "comments": "Major revision with new techniques and experiments. This version\n  includes new material put on the poster for the ICLR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method for training deep Boltzmann machines jointly. Prior\nmethods of training DBMs require an initial learning pass that trains the model\ngreedily, one layer at a time, or do not perform well on classification tasks.\nIn our approach, we train all layers of the DBM simultaneously, using a novel\ntraining procedure called multi-prediction training. The resulting model can\neither be interpreted as a single generative model trained to maximize a\nvariational approximation to the generalized pseudolikelihood, or as a family\nof recurrent networks that share parameters and may be approximately averaged\ntogether using a novel technique we call the multi-inference trick. We show\nthat our approach performs competitively for classification and outperforms\nprevious methods in terms of accuracy of approximate inference and\nclassification with missing inputs.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 03:21:27 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2013 18:43:00 GMT"}, {"version": "v3", "created": "Wed, 1 May 2013 04:48:20 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Goodfellow", "Ian J.", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.3575", "submitter": "Boyi Xie", "authors": "Boyi Xie, Shuheng Zheng", "title": "Kernelized Locality-Sensitive Hashing for Semi-Supervised Agglomerative\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale agglomerative clustering is hindered by computational burdens. We\npropose a novel scheme where exact inter-instance distance calculation is\nreplaced by the Hamming distance between Kernelized Locality-Sensitive Hashing\n(KLSH) hashed values. This results in a method that drastically decreases\ncomputation time. Additionally, we take advantage of certain labeled data\npoints via distance metric learning to achieve a competitive precision and\nrecall comparing to K-Means but in much less computation time.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 03:52:09 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Xie", "Boyi", ""], ["Zheng", "Shuheng", ""]]}, {"id": "1301.3577", "submitter": "Rostislav Goroshin", "authors": "Rostislav Goroshin and Yann LeCun", "title": "Saturating Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple new regularizer for auto-encoders whose hidden-unit\nactivation functions contain at least one zero-gradient (saturated) region.\nThis regularizer explicitly encourages activations in the saturated region(s)\nof the corresponding activation function. We call these Saturating\nAuto-Encoders (SATAE). We show that the saturation regularizer explicitly\nlimits the SATAE's ability to reconstruct inputs which are not near the data\nmanifold. Furthermore, we show that a wide variety of features can be learned\nwhen different activation functions are used. Finally, connections are\nestablished with the Contractive and Sparse Auto-Encoders.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 04:07:46 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2013 00:28:01 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2013 15:37:33 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Goroshin", "Rostislav", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3583", "submitter": "Yann Dauphin", "authors": "Yann N. Dauphin, Yoshua Bengio", "title": "Big Neural Networks Waste Capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article exposes the failure of some big neural networks to leverage\nadded capacity to reduce underfitting. Past research suggest diminishing\nreturns when increasing the size of neural networks. Our experiments on\nImageNet LSVRC-2010 show that this may be due to the fact there are highly\ndiminishing returns for capacity in terms of training error, leading to\nunderfitting. This suggests that the optimization method - first order gradient\ndescent - fails at this regime. Directly attacking this problem, either through\nthe optimization method or the choices of parametrization, may allow to improve\nthe generalization error on large datasets, for which a large capacity is\nrequired.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 04:45:29 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 18:11:34 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2013 23:07:05 GMT"}, {"version": "v4", "created": "Thu, 14 Mar 2013 20:49:20 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Dauphin", "Yann N.", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.3584", "submitter": "Razvan Pascanu", "authors": "Razvan Pascanu and Yoshua Bengio", "title": "Revisiting Natural Gradient for Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate natural gradient, an algorithm originally proposed in Amari\n(1997), for learning deep models. The contributions of this paper are as\nfollows. We show the connection between natural gradient and three other\nrecently proposed methods for training deep models: Hessian-Free (Martens,\n2010), Krylov Subspace Descent (Vinyals and Povey, 2012) and TONGA (Le Roux et\nal., 2008). We describe how one can use unlabeled data to improve the\ngeneralization error obtained by natural gradient and empirically evaluate the\nrobustness of the algorithm to the ordering of the training set compared to\nstochastic gradient descent. Finally we extend natural gradient to incorporate\nsecond order information alongside the manifold information and provide a\nbenchmark of the new algorithm using a truncated Newton approach for inverting\nthe metric matrix instead of using a diagonal approximation of it.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 04:47:02 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 03:57:04 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2013 14:59:04 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2013 19:13:08 GMT"}, {"version": "v5", "created": "Fri, 20 Dec 2013 19:29:42 GMT"}, {"version": "v6", "created": "Tue, 7 Jan 2014 18:11:36 GMT"}, {"version": "v7", "created": "Mon, 17 Feb 2014 16:29:27 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Pascanu", "Razvan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.3592", "submitter": "Ian Lenz", "authors": "Ian Lenz and Honglak Lee and Ashutosh Saxena", "title": "Deep Learning for Detecting Robotic Grasps", "comments": "Current version was accepted to IJRR Special Issue on Robot Vision\n  2014 Workshop version accepted to ICLR 2013. Conference version accepted to\n  RSS 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting robotic grasps in an RGB-D view of a\nscene containing objects. In this work, we apply a deep learning approach to\nsolve this problem, which avoids time-consuming hand-design of features. This\npresents two main challenges. First, we need to evaluate a huge number of\ncandidate grasps. In order to make detection fast, as well as robust, we\npresent a two-step cascaded structure with two deep networks, where the top\ndetections from the first are re-evaluated by the second. The first network has\nfewer features, is faster to run, and can effectively prune out unlikely\ncandidate grasps. The second, with more features, is slower but has to run only\non the top few detections. Second, we need to handle multimodal inputs well,\nfor which we present a method to apply structured regularization on the weights\nbased on multimodal group regularization. We demonstrate that our method\noutperforms the previous state-of-the-art methods in robotic grasp detection,\nand can be used to successfully execute grasps on two different robotic\nplatforms.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 05:33:56 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 00:10:20 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2013 00:40:34 GMT"}, {"version": "v4", "created": "Fri, 3 May 2013 06:54:42 GMT"}, {"version": "v5", "created": "Fri, 2 Aug 2013 18:15:54 GMT"}, {"version": "v6", "created": "Thu, 21 Aug 2014 18:17:37 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Lenz", "Ian", ""], ["Lee", "Honglak", ""], ["Saxena", "Ashutosh", ""]]}, {"id": "1301.3605", "submitter": "Michael Seltzer", "authors": "Dong Yu, Michael L. Seltzer, Jinyu Li, Jui-Ting Huang, Frank Seide", "title": "Feature Learning in Deep Neural Networks - Studies on Speech Recognition\n  Tasks", "comments": "ICLR 2013, 9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep neural networks (DNNs) perform\nsignificantly better than shallow networks and Gaussian mixture models (GMMs)\non large vocabulary speech recognition tasks. In this paper, we argue that the\nimproved accuracy achieved by the DNNs is the result of their ability to\nextract discriminative internal representations that are robust to the many\nsources of variability in speech signals. We show that these representations\nbecome increasingly insensitive to small perturbations in the input with\nincreasing network depth, which leads to better speech recognition performance\nwith deeper networks. We also show that DNNs cannot extrapolate to test samples\nthat are substantially different from the training examples. If the training\ndata are sufficiently representative, however, internal features learned by the\nDNN are relatively stable with respect to speaker differences, bandwidth\ndifferences, and environment distortion. This enables DNN-based recognizers to\nperform as well or better than state-of-the-art systems based on GMMs or\nshallow networks without the need for explicit model adaptation or feature\nnormalization.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 07:23:19 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2013 07:42:07 GMT"}, {"version": "v3", "created": "Fri, 8 Mar 2013 19:42:37 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Yu", "Dong", ""], ["Seltzer", "Michael L.", ""], ["Li", "Jinyu", ""], ["Huang", "Jui-Ting", ""], ["Seide", "Frank", ""]]}, {"id": "1301.3618", "submitter": "Richard Socher", "authors": "Danqi Chen, Richard Socher, Christopher D. Manning, Andrew Y. Ng", "title": "Learning New Facts From Knowledge Bases With Neural Tensor Networks and\n  Semantic Word Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases provide applications with the benefit of easily accessible,\nsystematic relational knowledge but often suffer in practice from their\nincompleteness and lack of knowledge of new entities and relations. Much work\nhas focused on building or extending them by finding patterns in large\nunannotated text corpora. In contrast, here we mainly aim to complete a\nknowledge base by predicting additional true relationships between entities,\nbased on generalizations that can be discerned in the given knowledgebase. We\nintroduce a neural tensor network (NTN) model which predicts new relationship\nentries that can be added to the database. This model can be improved by\ninitializing entity representations with word vectors learned in an\nunsupervised fashion from text, and when doing this, existing relations can\neven be queried for entities that were not present in the database. Our model\ngeneralizes and outperforms existing models for this problem, and can classify\nunseen relationships in WordNet with an accuracy of 75.8%.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 08:05:35 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 03:23:26 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Chen", "Danqi", ""], ["Socher", "Richard", ""], ["Manning", "Christopher D.", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1301.3627", "submitter": "Hinrich Schuetze", "authors": "Hinrich Schuetze, Christian Scheible", "title": "Two SVDs produce more focal deep learning representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A key characteristic of work on deep learning and neural networks in general\nis that it relies on representations of the input that support generalization,\nrobust inference, domain adaptation and other desirable functionalities. Much\nrecent progress in the field has focused on efficient and effective methods for\ncomputing representations. In this paper, we propose an alternative method that\nis more efficient than prior work and produces representations that have a\nproperty we call focality -- a property we hypothesize to be important for\nneural network representations. The method consists of a simple application of\ntwo consecutive SVDs and is inspired by Anandkumar (2012).\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 08:37:39 GMT"}, {"version": "v2", "created": "Sat, 11 May 2013 12:17:44 GMT"}], "update_date": "2013-05-14", "authors_parsed": [["Schuetze", "Hinrich", ""], ["Scheible", "Christian", ""]]}, {"id": "1301.3630", "submitter": "Qifeng Qiao", "authors": "Qifeng Qiao and Peter A. Beling", "title": "Behavior Pattern Recognition using A New Representation Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of inverse reinforcement learning (IRL) as a tool for the\nrecognition of agents' behavior on the basis of observation of their sequential\ndecision behavior interacting with the environment. We model the problem faced\nby the agents as a Markov decision process (MDP) and model the observed\nbehavior of the agents in terms of forward planning for the MDP. We use IRL to\nlearn reward functions and then use these reward functions as the basis for\nclustering or classification models. Experimental studies with GridWorld, a\nnavigation problem, and the secretary problem, an optimal stopping problem,\nsuggest reward vectors found from IRL can be a good basis for behavior pattern\nrecognition problems. Empirical comparisons of our method with several existing\nIRL algorithms and with direct methods that use feature statistics observed in\nstate-action space suggest it may be superior for recognition problems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 09:01:47 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2013 09:26:22 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2013 06:06:08 GMT"}, {"version": "v4", "created": "Wed, 20 Mar 2013 21:18:07 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Qiao", "Qifeng", ""], ["Beling", "Peter A.", ""]]}, {"id": "1301.3641", "submitter": "Ryan Kiros", "authors": "Ryan Kiros", "title": "Training Neural Networks with Stochastic Hessian-Free Optimization", "comments": "11 pages, ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hessian-free (HF) optimization has been successfully used for training deep\nautoencoders and recurrent networks. HF uses the conjugate gradient algorithm\nto construct update directions through curvature-vector products that can be\ncomputed on the same order of time as gradients. In this paper we exploit this\nproperty and study stochastic HF with gradient and curvature mini-batches\nindependent of the dataset size. We modify Martens' HF for these settings and\nintegrate dropout, a method for preventing co-adaptation of feature detectors,\nto guard against overfitting. Stochastic Hessian-free optimization gives an\nintermediary between SGD and HF that achieves competitive performance on both\nclassification and deep autoencoder experiments.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 10:10:23 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2013 05:51:37 GMT"}, {"version": "v3", "created": "Wed, 1 May 2013 06:57:50 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Kiros", "Ryan", ""]]}, {"id": "1301.3644", "submitter": "Kye-Hyeon Kim", "authors": "Kye-Hyeon Kim, Rui Cai, Lei Zhang, Seungjin Choi", "title": "Regularized Discriminant Embedding for Visual Descriptor Learning", "comments": "3 pages + 1 additional page containing only cited references; The\n  full version of this manuscript is currently under review in an international\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images can vary according to changes in viewpoint, resolution, noise, and\nillumination. In this paper, we aim to learn representations for an image,\nwhich are robust to wide changes in such environmental conditions, using\ntraining pairs of matching and non-matching local image patches that are\ncollected under various environmental conditions. We present a regularized\ndiscriminant analysis that emphasizes two challenging categories among the\ngiven training pairs: (1) matching, but far apart pairs and (2) non-matching,\nbut close pairs in the original feature space (e.g., SIFT feature space).\nCompared to existing work on metric learning and discriminant analysis, our\nmethod can better distinguish relevant images from irrelevant, but look-alike\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 10:12:37 GMT"}], "update_date": "2013-01-17", "authors_parsed": [["Kim", "Kye-Hyeon", ""], ["Cai", "Rui", ""], ["Zhang", "Lei", ""], ["Choi", "Seungjin", ""]]}, {"id": "1301.3666", "submitter": "Richard Socher", "authors": "Richard Socher, Milind Ganjoo, Hamsa Sridhar, Osbert Bastani,\n  Christopher D. Manning, Andrew Y. Ng", "title": "Zero-Shot Learning Through Cross-Modal Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a model that can recognize objects in images even if no\ntraining data is available for the objects. The only necessary knowledge about\nthe unseen categories comes from unsupervised large text corpora. In our\nzero-shot framework distributional information in language can be seen as\nspanning a semantic basis for understanding what objects look like. Most\nprevious zero-shot learning models can only differentiate between unseen\nclasses. In contrast, our model can both obtain state of the art performance on\nclasses that have thousands of training images and obtain reasonable\nperformance on unseen classes. This is achieved by first using outlier\ndetection in the semantic space and then two separate recognition models.\nFurthermore, our model does not require any manually defined semantic features\nfor either words or images.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 12:01:34 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2013 00:44:08 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Socher", "Richard", ""], ["Ganjoo", "Milind", ""], ["Sridhar", "Hamsa", ""], ["Bastani", "Osbert", ""], ["Manning", "Christopher D.", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1301.3720", "submitter": "Federico Schl\\\"uter", "authors": "Federico Schl\\\"uter and Facundo Bromberg and Alejandro Edera", "title": "The IBMAP approach for Markov networks structure learning", "comments": null, "journal-ref": null, "doi": "10.1007/s10472-014-9419-5", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the problem of learning the structure of Markov\nnetworks from data. We present an approach for tackling this problem called\nIBMAP, together with an efficient instantiation of the approach: the IBMAP-HC\nalgorithm, designed for avoiding important limitations of existing\nindependence-based algorithms. These algorithms proceed by performing\nstatistical independence tests on data, trusting completely the outcome of each\ntest. In practice tests may be incorrect, resulting in potential cascading\nerrors and the consequent reduction in the quality of the structures learned.\nIBMAP contemplates this uncertainty in the outcome of the tests through a\nprobabilistic maximum-a-posteriori approach. The approach is instantiated in\nthe IBMAP-HC algorithm, a structure selection strategy that performs a\npolynomial heuristic local search in the space of possible structures. We\npresent an extensive empirical evaluation on synthetic and real data, showing\nthat our algorithm outperforms significantly the current independence-based\nalgorithms, in terms of data efficiency and quality of learned structures, with\nequivalent computational complexities. We also show the performance of IBMAP-HC\nin a real-world application of knowledge discovery: EDAs, which are\nevolutionary algorithms that use structure learning on each generation for\nmodeling the distribution of populations. The experiments show that when\nIBMAP-HC is used to learn the structure, EDAs improve the convergence to the\noptimum.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:21:19 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 17:32:50 GMT"}], "update_date": "2014-08-10", "authors_parsed": [["Schl\u00fcter", "Federico", ""], ["Bromberg", "Facundo", ""], ["Edera", "Alejandro", ""]]}, {"id": "1301.3753", "submitter": "Leif Johnson", "authors": "Leif Johnson and Craig Corcoran", "title": "Switched linear encoding with rectified linear autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent results in machine learning have established formal\nconnections between autoencoders---artificial neural network models that\nattempt to reproduce their inputs---and other coding models like sparse coding\nand K-means. This paper explores in depth an autoencoder model that is\nconstructed using rectified linear activations on its hidden units. Our\nanalysis builds on recent results to further unify the world of sparse linear\ncoding models. We provide an intuitive interpretation of the behavior of these\ncoding models and demonstrate this intuition using small, artificial datasets\nwith known distributions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 17:04:10 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2013 19:38:36 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Johnson", "Leif", ""], ["Corcoran", "Craig", ""]]}, {"id": "1301.3764", "submitter": "Tom Schaul", "authors": "Tom Schaul, Yann LeCun", "title": "Adaptive learning rates and parallelization for stochastic, sparse,\n  non-smooth gradients", "comments": "Published at the First International Conference on Learning\n  Representations (ICLR-2013). Public reviews are available at\n  http://openreview.net/document/c14f2204-fd66-4d91-bed4-153523694041#c14f2204-fd66-4d91-bed4-153523694041", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has established an empirically successful framework for adapting\nlearning rates for stochastic gradient descent (SGD). This effectively removes\nall needs for tuning, while automatically reducing learning rates over time on\nstationary problems, and permitting learning rates to grow appropriately in\nnon-stationary tasks. Here, we extend the idea in three directions, addressing\nproper minibatch parallelization, including reweighted updates for sparse or\northogonal gradients, improving robustness on non-smooth loss functions, in the\nprocess replacing the diagonal Hessian estimation procedure that may not always\nbe available by a robust finite-difference approximation. The final algorithm\nintegrates all these components, has linear complexity and is hyper-parameter\nfree.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 17:48:38 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 18:30:41 GMT"}], "update_date": "2013-03-28", "authors_parsed": [["Schaul", "Tom", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3775", "submitter": "Jason Rolfe", "authors": "Jason Tyler Rolfe and Yann LeCun", "title": "Discriminative Recurrent Sparse Auto-Encoders", "comments": "Added clarifications suggested by reviewers. 15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the discriminative recurrent sparse auto-encoder model, comprising\na recurrent encoder of rectified linear units, unrolled for a fixed number of\niterations, and connected to two linear decoders that reconstruct the input and\npredict its supervised classification. Training via\nbackpropagation-through-time initially minimizes an unsupervised sparse\nreconstruction error; the loss function is then augmented with a discriminative\nterm on the supervised classification. The depth implicit in the\ntemporally-unrolled form allows the system to exhibit all the power of deep\nnetworks, while substantially reducing the number of trainable parameters.\n  From an initially unstructured network the hidden units differentiate into\ncategorical-units, each of which represents an input prototype with a\nwell-defined class; and part-units representing deformations of these\nprototypes. The learned organization of the recurrent encoder is hierarchical:\npart-units are driven directly by the input, whereas the activity of\ncategorical-units builds up over time through interactions with the part-units.\nEven using a small number of hidden units per layer, discriminative recurrent\nsparse auto-encoders achieve excellent performance on MNIST.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 18:07:01 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 18:51:59 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2013 21:17:19 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2013 18:43:29 GMT"}], "update_date": "2013-03-20", "authors_parsed": [["Rolfe", "Jason Tyler", ""], ["LeCun", "Yann", ""]]}, {"id": "1301.3816", "submitter": "Francesco Dinuzzo", "authors": "Francesco Dinuzzo", "title": "Learning Output Kernels for Multi-Task Problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2013.02.024", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneously solving multiple related learning tasks is beneficial under a\nvariety of circumstances, but the prior knowledge necessary to correctly model\ntask relationships is rarely available in practice. In this paper, we develop a\nnovel kernel-based multi-task learning technique that automatically reveals\nstructural inter-task relationships. Building over the framework of output\nkernel learning (OKL), we introduce a method that jointly learns multiple\nfunctions and a low-rank multi-task kernel by solving a non-convex\nregularization problem. Optimization is carried out via a block coordinate\ndescent strategy, where each subproblem is solved using suitable conjugate\ngradient (CG) type iterative methods for linear operator equations. The\neffectiveness of the proposed approach is demonstrated on pharmacological and\ncollaborative filtering data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 20:16:02 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Dinuzzo", "Francesco", ""]]}, {"id": "1301.3833", "submitter": "Christophe Andrieu", "authors": "Christophe Andrieu, Nando de Freitas, Arnaud Doucet", "title": "Reversible Jump MCMC Simulated Annealing for Neural Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-11-18", "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reversible jump Markov chain Monte Carlo (MCMC) simulated\nannealing algorithm to optimize radial basis function (RBF) networks. This\nalgorithm enables us to maximize the joint posterior distribution of the\nnetwork parameters and the number of basis functions. It performs a global\nsearch in the joint space of the parameters and number of parameters, thereby\nsurmounting the problem of local minima. We also show that by calibrating a\nBayesian model, we can obtain the classical AIC, BIC and MDL model selection\ncriteria within a penalized likelihood framework. Finally, we show\ntheoretically and empirically that the algorithm converges to the modes of the\nfull posterior distribution in an efficient way.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:42 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Andrieu", "Christophe", ""], ["de Freitas", "Nando", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1301.3837", "submitter": "Jeff A. Bilmes", "authors": "Jeff A. Bilmes", "title": "Dynamic Bayesian Multinets", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-38-45", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, dynamic Bayesian multinets are introduced where a Markov chain\nstate at time t determines conditional independence patterns between random\nvariables lying within a local time window surrounding t. It is shown how\ninformation-theoretic criterion functions can be used to induce sparse,\ndiscriminative, and class-conditional network structures that yield an optimal\napproximation to the class posterior probability, and therefore are useful for\nthe classification task. Using a new structure learning heuristic, the\nresulting models are tested on a medium-vocabulary isolated-word speech\nrecognition task. It is demonstrated that these discriminatively structured\ndynamic Bayesian multinets, when trained in a maximum likelihood setting using\nEM, can outperform both HMMs and other dynamic Bayesian networks with a similar\nnumber of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:48:59 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Bilmes", "Jeff A.", ""]]}, {"id": "1301.3838", "submitter": "Christopher M. Bishop", "authors": "Christopher M. Bishop, Michael Tipping", "title": "Variational Relevance Vector Machines", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-46-53", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Support Vector Machine (SVM) of Vapnik (1998) has become widely\nestablished as one of the leading approaches to pattern recognition and machine\nlearning. It expresses predictions in terms of a linear combination of kernel\nfunctions centred on a subset of the training data, known as support vectors.\n  Despite its widespread success, the SVM suffers from some important\nlimitations, one of the most significant being that it makes point predictions\nrather than generating predictive distributions. Recently Tipping (1999) has\nformulated the Relevance Vector Machine (RVM), a probabilistic model whose\nfunctional form is equivalent to the SVM. It achieves comparable recognition\naccuracy to the SVM, yet provides a full predictive distribution, and also\nrequires substantially fewer kernel functions.\n  The original treatment of the RVM relied on the use of type II maximum\nlikelihood (the `evidence framework') to provide point estimates of the\nhyperparameters which govern model sparsity. In this paper we show how the RVM\ncan be formulated and solved within a completely Bayesian paradigm through the\nuse of variational inference, thereby giving a posterior distribution over both\nparameters and hyperparameters. We demonstrate the practicality and performance\nof the variational RVM using both synthetic and real world examples.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:03 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Bishop", "Christopher M.", ""], ["Tipping", "Michael", ""]]}, {"id": "1301.3840", "submitter": "Urszula Chajewska", "authors": "Urszula Chajewska, Daphne Koller", "title": "Utilities as Random Variables: Density Estimation and Structure\n  Discovery", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-63-71", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision theory does not traditionally include uncertainty over utility\nfunctions. We argue that the a person's utility value for a given outcome can\nbe treated as we treat other domain attributes: as a random variable with a\ndensity function over its possible values. We show that we can apply\nstatistical density estimation techniques to learn such a density function from\na database of partially elicited utility functions. In particular, we define a\nBayesian learning framework for this problem, assuming the distribution over\nutilities is a mixture of Gaussians, where the mixture components represent\nstatistically coherent subpopulations. We can also extend our techniques to the\nproblem of discovering generalized additivity structure in the utility\nfunctions in the population. We define a Bayesian model selection criterion for\nutility function structure and a search procedure over structures. The\nfactorization of the utilities in the learned model, and the generalization\nobtained from density estimation, allows us to provide robust estimates of\nutilities using a significantly smaller number of utility elicitation\nquestions. We experiment with our technique on synthetic utility data and on a\nreal database of utility functions in the domain of prenatal diagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:11 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Chajewska", "Urszula", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.3843", "submitter": "Frans Coetzee", "authors": "Frans Coetzee, Steve Lawrence, C. Lee Giles", "title": "Bayesian Classification and Feature Selection from Finite Data Sets", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-89-97", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection aims to select the smallest subset of features for a\nspecified level of performance. The optimal achievable classification\nperformance on a feature subset is summarized by its Receiver Operating Curve\n(ROC). When infinite data is available, the Neyman- Pearson (NP) design\nprocedure provides the most efficient way of obtaining this curve. In practice\nthe design procedure is applied to density estimates from finite data sets. We\nperform a detailed statistical analysis of the resulting error propagation on\nfinite alphabets. We show that the estimated performance curve (EPC) produced\nby the design procedure is arbitrarily accurate given sufficient data,\nindependent of the size of the feature set. However, the underlying likelihood\nranking procedure is highly sensitive to errors that reduces the probability\nthat the EPC is in fact the ROC. In the worst case, guaranteeing that the EPC\nis equal to the ROC may require data sizes exponential in the size of the\nfeature set. These results imply that in theory the NP design approach may only\nbe valid for characterizing relatively small feature subsets, even when the\nperformance of any given classifier can be estimated very accurately. We\ndiscuss the practical limitations for on-line methods that ensures that the NP\nprocedure operates in a statistically valid region.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:23 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Coetzee", "Frans", ""], ["Lawrence", "Steve", ""], ["Giles", "C. Lee", ""]]}, {"id": "1301.3849", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta", "title": "Experiments with Random Projection", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-143-151", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical work has identified random projection as a promising\ndimensionality reduction technique for learning mixtures of Gausians. Here we\nsummarize these results and illustrate them by a wide variety of experiments on\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:46 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Dasgupta", "Sanjoy", ""]]}, {"id": "1301.3850", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta, Leonard Schulman", "title": "A Two-round Variant of EM for Gaussian Mixtures", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-152-159", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of possible models (e.g., Bayesian network structures) and a data\nsample, in the unsupervised model selection problem the task is to choose the\nmost accurate model with respect to the domain joint probability distribution.\nIn contrast to this, in supervised model selection it is a priori known that\nthe chosen model will be used in the future for prediction tasks involving more\n``focused' predictive distributions. Although focused predictive distributions\ncan be produced from the joint probability distribution by marginalization, in\npractice the best model in the unsupervised sense does not necessarily perform\nwell in supervised domains. In particular, the standard marginal likelihood\nscore is a criterion for the unsupervised task, and, although frequently used\nfor supervised model selection also, does not perform well in such tasks. In\nthis paper we study the performance of the marginal likelihood score\nempirically in supervised Bayesian network selection tasks by using a large\nnumber of publicly available classification data sets, and compare the results\nto those obtained by alternative model selection criteria, including empirical\ncrossvalidation methods, an approximation of a supervised marginal likelihood\nmeasure, and a supervised version of Dawids prequential(predictive sequential)\nprinciple.The results demonstrate that the marginal likelihood score does NOT\nperform well FOR supervised model selection, WHILE the best results are\nobtained BY using Dawids prequential r napproach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:50 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Schulman", "Leonard", ""]]}, {"id": "1301.3851", "submitter": "Ian Davidson", "authors": "Ian Davidson", "title": "Minimum Message Length Clustering Using Gibbs Sampling", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-160-167", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The K-Mean and EM algorithms are popular in clustering and mixture modeling,\ndue to their simplicity and ease of implementation. However, they have several\nsignificant limitations. Both coverage to a local optimum of their respective\nobjective functions (ignoring the uncertainty in the model space), require the\napriori specification of the number of classes/clsuters, and are inconsistent.\nIn this work we overcome these limitations by using the Minimum Message Length\n(MML) principle and a variation to the K-Means/EM observation assignment and\nparameter calculation scheme. We maintain the simplicity of these approaches\nwhile constructing a Bayesian mixture modeling tool that samples/searches the\nmodel space using a Markov Chain Monte Carlo (MCMC) sampler known as a Gibbs\nsampler. Gibbs sampling allows us to visit each model according to its\nposterior probability. Therefore, if the model space is multi-modal we will\nvisit all models and not get stuck in local optima. We call our approach\nmultiple chains at equilibrium (MCE) MML sampling.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:54 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Davidson", "Ian", ""]]}, {"id": "1301.3852", "submitter": "Scott Davies", "authors": "Scott Davies, Andrew Moore", "title": "Mix-nets: Factored Mixtures of Gaussians in Bayesian Networks With Mixed\n  Continuous And Discrete Variables", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-168-175", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed techniques have made it possible to quickly learn accurate\nprobability density functions from data in low-dimensional continuous space. In\nparticular, mixtures of Gaussians can be fitted to data very quickly using an\naccelerated EM algorithm that employs multiresolution kd-trees (Moore, 1999).\nIn this paper, we propose a kind of Bayesian networks in which low-dimensional\nmixtures of Gaussians over different subsets of the domain's variables are\ncombined into a coherent joint probability model over the entire domain. The\nnetwork is also capable of modeling complex dependencies between discrete\nvariables and continuous variables without requiring discretization of the\ncontinuous variables. We present efficient heuristic algorithms for\nautomatically learning these networks from data, and perform comparative\nexperiments illustrated how well these networks model real scientific data and\nsynthetic data. We also briefly discuss some possible improvements to the\nnetworks, as well as possible applications.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:49:57 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Davies", "Scott", ""], ["Moore", "Andrew", ""]]}, {"id": "1301.3853", "submitter": "Arnaud Doucet", "authors": "Arnaud Doucet, Nando de Freitas, Kevin Murphy, Stuart Russell", "title": "Rao-Blackwellised Particle Filtering for Dynamic Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-176-183", "categories": "cs.LG cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle filters (PFs) are powerful sampling-based inference/learning\nalgorithms for dynamic Bayesian networks (DBNs). They allow us to treat, in a\nprincipled way, any type of probability distribution, nonlinearity and\nnon-stationarity. They have appeared in several fields under such names as\n\"condensation\", \"sequential Monte Carlo\" and \"survival of the fittest\". In this\npaper, we show how we can exploit the structure of the DBN to increase the\nefficiency of particle filtering, using a technique known as\nRao-Blackwellisation. Essentially, this samples some of the variables, and\nmarginalizes out the rest exactly, using the Kalman filter, HMM filter,\njunction tree algorithm, or any other finite dimensional optimal filter. We\nshow that Rao-Blackwellised particle filters (RBPFs) lead to more accurate\nestimates than standard PFs. We demonstrate RBPFs on two problems, namely\nnon-stationary online regression with radial basis function networks and robot\nlocalization and map building. We also discuss other potential application\nareas and provide references to some finite dimensional optimal filters.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:01 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Doucet", "Arnaud", ""], ["de Freitas", "Nando", ""], ["Murphy", "Kevin", ""], ["Russell", "Stuart", ""]]}, {"id": "1301.3854", "submitter": "Brendan J. Frey", "authors": "Brendan J. Frey, Nebojsa Jojic", "title": "Learning Graphical Models of Images, Videos and Their Spatial\n  Transformations", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-184-191", "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures of Gaussians, factor analyzers (probabilistic PCA) and hidden Markov\nmodels are staples of static and dynamic data modeling and image and video\nmodeling in particular. We show how topographic transformations in the input,\nsuch as translation and shearing in images, can be accounted for in these\nmodels by including a discrete transformation variable. The resulting models\nperform clustering, dimensionality reduction and time-series analysis in a way\nthat is invariant to transformations in the input. Using the EM algorithm,\nthese transformation-invariant models can be fit to static data and time\nseries. We give results on filtering microscopy images, face and facial pose\nclustering, handwritten digit modeling and recognition, video clustering,\nobject tracking, and removal of distractions from video sequences.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:06 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Frey", "Brendan J.", ""], ["Jojic", "Nebojsa", ""]]}, {"id": "1301.3856", "submitter": "Nir Friedman", "authors": "Nir Friedman, Daphne Koller", "title": "Being Bayesian about Network Structure", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-201-210", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, we are interested in analyzing the structure of the\nunderlying distribution, e.g., whether one variable is a direct parent of the\nother. Bayesian model-selection attempts to find the MAP model and use its\nstructure to answer these questions. However, when the amount of available data\nis modest, there might be many models that have non-negligible posterior. Thus,\nwe want compute the Bayesian posterior of a feature, i.e., the total posterior\nprobability of all models that contain it. In this paper, we propose a new\napproach for this task. We first show how to efficiently compute a sum over the\nexponential number of networks that are consistent with a fixed ordering over\nnetwork variables. This allows us to compute, for a given ordering, both the\nmarginal probability of the data and the posterior of a feature. We then use\nthis result as the basis for an algorithm that approximates the Bayesian\nposterior of a feature. Our approach uses a Markov Chain Monte Carlo (MCMC)\nmethod, but over orderings rather than over network structures. The space of\norderings is much smaller and more regular than the space of structures, and\nhas a smoother posterior `landscape'. We present empirical results on synthetic\nand real-life datasets that compare our approach to full model averaging (when\npossible), to MCMC over network structures, and to a non-Bayesian bootstrap\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:14 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Friedman", "Nir", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.3857", "submitter": "Nir Friedman", "authors": "Nir Friedman, Iftach Nachman", "title": "Gaussian Process Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-211-219", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of learning the structure of a Bayesian\nnetwork in domains with continuous variables. This task requires a procedure\nfor comparing different candidate structures. In the Bayesian framework, this\nis done by evaluating the {em marginal likelihood/} of the data given a\ncandidate structure. This term can be computed in closed-form for standard\nparametric families (e.g., Gaussians), and can be approximated, at some\ncomputational cost, for some semi-parametric families (e.g., mixtures of\nGaussians).\n  We present a new family of continuous variable probabilistic networks that\nare based on {em Gaussian Process/} priors. These priors are semi-parametric in\nnature and can learn almost arbitrary noisy functional relations. Using these\npriors, we can directly compute marginal likelihoods for structure learning.\nThe resulting method can discover a wide range of functional dependencies in\nmultivariate data. We develop the Bayesian score of Gaussian Process Networks\nand describe how to learn them from data. We present empirical results on\nartificial data as well as on real-life domains with non-linear dependencies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:18 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Friedman", "Nir", ""], ["Nachman", "Iftach", ""]]}, {"id": "1301.3861", "submitter": "Michael Harvey", "authors": "Michael Harvey, Radford M. Neal", "title": "Inference for Belief Networks Using Coupling From the Past", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-256-263", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference for belief networks using Gibbs sampling produces a distribution\nfor unobserved variables that differs from the correct distribution by a\n(usually) unknown error, since convergence to the right distribution occurs\nonly asymptotically. The method of \"coupling from the past\" samples from\nexactly the correct distribution by (conceptually) running dependent Gibbs\nsampling simulations from every possible starting state from a time far enough\nin the past that all runs reach the same state at time t=0. Explicitly\nconsidering every possible state is intractable for large networks, however. We\npropose a method for layered noisy-or networks that uses a compact, but often\nimprecise, summary of a set of states. This method samples from exactly the\ncorrect distribution, and requires only about twice the time per step as\nordinary Gibbs sampling, but it may require more simulation steps than would be\nneeded if chains were tracked exactly.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:34 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Harvey", "Michael", ""], ["Neal", "Radford M.", ""]]}, {"id": "1301.3862", "submitter": "David Heckerman", "authors": "David Heckerman, David Maxwell Chickering, Christopher Meek, Robert\n  Rounthwaite, Carl Kadie", "title": "Dependency Networks for Collaborative Filtering and Data Visualization", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-264-273", "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a graphical model for probabilistic relationships---an\nalternative to the Bayesian network---called a dependency network. The graph of\na dependency network, unlike a Bayesian network, is potentially cyclic. The\nprobability component of a dependency network, like a Bayesian network, is a\nset of conditional distributions, one for each node given its parents. We\nidentify several basic properties of this representation and describe a\ncomputationally efficient procedure for learning the graph and probability\ncomponents from data. We describe the application of this representation to\nprobabilistic inference, collaborative filtering (the task of predicting\npreferences), and the visualization of acausal predictive relationships.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:38 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Heckerman", "David", ""], ["Chickering", "David Maxwell", ""], ["Meek", "Christopher", ""], ["Rounthwaite", "Robert", ""], ["Kadie", "Carl", ""]]}, {"id": "1301.3865", "submitter": "Tony S. Jebara", "authors": "Tony S. Jebara, Tommi S. Jaakkola", "title": "Feature Selection and Dualities in Maximum Entropy Discrimination", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-291-300", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating feature selection into a classification or regression method\noften carries a number of advantages. In this paper we formalize feature\nselection specifically from a discriminative perspective of improving\nclassification/regression accuracy. The feature selection method is developed\nas an extension to the recently proposed maximum entropy discrimination (MED)\nframework. We describe MED as a flexible (Bayesian) regularization approach\nthat subsumes, e.g., support vector classification, regression and exponential\nfamily models. For brevity, we restrict ourselves primarily to feature\nselection in the context of linear classification/regression methods and\ndemonstrate that the proposed approach indeed carries substantial improvements\nin practice. Moreover, we discuss and develop various extensions of feature\nselection, including the problem of dealing with example specific but\nunobserved degrees of freedom -- alignments or invariants.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:50:50 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Jebara", "Tony S.", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.3875", "submitter": "Marina Meila", "authors": "Marina Meila, Tommi S. Jaakkola", "title": "Tractable Bayesian Learning of Tree Belief Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-380-388", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present decomposable priors, a family of priors over\nstructure and parameters of tree belief nets for which Bayesian learning with\ncomplete observations is tractable, in the sense that the posterior is also\ndecomposable and can be completely determined analytically in polynomial time.\nThis follows from two main results: First, we show that factored distributions\nover spanning trees in a graph can be integrated in closed form. Second, we\nexamine priors over tree parameters and show that a set of assumptions similar\nto (Heckerman and al. 1995) constrain the tree parameter priors to be a\ncompactly parameterized product of Dirichlet distributions. Beside allowing for\nexact Bayesian learning, these results permit us to formulate a new class of\ntractable latent variable models in which the likelihood of a data point is\ncomputed through an ensemble average over tree structures.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:30 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Meila", "Marina", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1301.3877", "submitter": "Andrew Moore", "authors": "Andrew Moore", "title": "The Anchors Hierachy: Using the triangle inequality to survive high\n  dimensional data", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-397-405", "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about metric data structures in high-dimensional or\nnon-Euclidean space that permit cached sufficient statistics accelerations of\nlearning algorithms.\n  It has recently been shown that for less than about 10 dimensions, decorating\nkd-trees with additional \"cached sufficient statistics\" such as first and\nsecond moments and contingency tables can provide satisfying acceleration for a\nvery wide range of statistical learning tasks such as kernel regression,\nlocally weighted regression, k-means clustering, mixture modeling and Bayes Net\nlearning.\n  In this paper, we begin by defining the anchors hierarchy - a fast data\nstructure and algorithm for localizing data based only on a\ntriangle-inequality-obeying distance metric. We show how this, in its own\nright, gives a fast and effective clustering of data. But more importantly we\nshow how it can produce a well-balanced structure similar to a Ball-Tree\n(Omohundro, 1991) or a kind of metric tree (Uhlmann, 1991; Ciaccia, Patella, &\nZezula, 1997) in a way that is neither \"top-down\" nor \"bottom-up\" but instead\n\"middle-out\". We then show how this structure, decorated with cached sufficient\nstatistics, allows a wide variety of statistical learning algorithms to be\naccelerated even in thousands of dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:38 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Moore", "Andrew", ""]]}, {"id": "1301.3878", "submitter": "Andrew Y. Ng", "authors": "Andrew Y. Ng, Michael I. Jordan", "title": "PEGASUS: A Policy Search Method for Large MDPs and POMDPs", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-406-415", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to the problem of searching a space of policies for\na Markov decision process (MDP) or a partially observable Markov decision\nprocess (POMDP), given a model. Our approach is based on the following\nobservation: Any (PO)MDP can be transformed into an \"equivalent\" POMDP in which\nall state transitions (given the current state and action) are deterministic.\nThis reduces the general problem of policy search to one in which we need only\nconsider POMDPs with deterministic transitions. We give a natural way of\nestimating the value of all policies in these transformed POMDPs. Policy search\nis then simply performed by searching for a policy with high estimated value.\nWe also establish conditions under which our value estimates will be good,\nrecovering theoretical results similar to those of Kearns, Mansour and Ng\n(1999), but with \"sample complexity\" bounds that have only a polynomial rather\nthan exponential dependence on the horizon time. Our method applies to\narbitrary POMDPs, including ones with infinite state and action spaces. We also\npresent empirical results for our approach on a small discrete problem, and on\na complex continuous state/continuous action problem involving learning to ride\na bicycle.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:42 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Ng", "Andrew Y.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.3882", "submitter": "Luis E. Ortiz", "authors": "Luis E. Ortiz, Leslie Pack Kaelbling", "title": "Adaptive Importance Sampling for Estimation in Structured Domains", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-446-454", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is an important tool for estimating large, complex sums and\nintegrals over high dimensional spaces. For instance, important sampling has\nbeen used as an alternative to exact methods for inference in belief networks.\nIdeally, we want to have a sampling distribution that provides optimal-variance\nestimators. In this paper, we present methods that improve the sampling\ndistribution by systematically adapting it as we obtain information from the\nsamples. We present a stochastic-gradient-descent method for sequentially\nupdating the sampling distribution based on the direct minization of the\nvariance. We also present other stochastic-gradient-descent methods based on\nthe minimizationof typical notions of distance between the current sampling\ndistribution and approximations of the target, optimal distribution. We finally\nvalidate and compare the different methods empirically by applying them to the\nproblem of action evaluation in influence diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:51:58 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Ortiz", "Luis E.", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1301.3890", "submitter": "Dale Schuurmans", "authors": "Dale Schuurmans, Finnegan Southey", "title": "Monte Carlo Inference via Greedy Importance Sampling", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-523-532", "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for conducting Monte Carlo inference in graphical\nmodels which combines explicit search with generalized importance sampling. The\nidea is to reduce the variance of importance sampling by searching for\nsignificant points in the target distribution. We prove that it is possible to\nintroduce search and still maintain unbiasedness. We then demonstrate our\nprocedure on a few simple inference tasks and show that it can improve the\ninference quality of standard MCMC methods, including Gibbs sampling,\nMetropolis sampling, and Hybrid Monte Carlo. This paper extends previous work\nwhich showed how greedy importance sampling could be correctly realized in the\none-dimensional case.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:30 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Schuurmans", "Dale", ""], ["Southey", "Finnegan", ""]]}, {"id": "1301.3891", "submitter": "Marc Sebban", "authors": "Marc Sebban, Richard Nock", "title": "Combining Feature and Prototype Pruning by Uncertainty Minimization", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-533-540", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus in this paper on dataset reduction techniques for use in k-nearest\nneighbor classification. In such a context, feature and prototype selections\nhave always been independently treated by the standard storage reduction\nalgorithms. While this certifying is theoretically justified by the fact that\neach subproblem is NP-hard, we assume in this paper that a joint storage\nreduction is in fact more intuitive and can in practice provide better results\nthan two independent processes. Moreover, it avoids a lot of distance\ncalculations by progressively removing useless instances during the feature\npruning. While standard selection algorithms often optimize the accuracy to\ndiscriminate the set of solutions, we use in this paper a criterion based on an\nuncertainty measure within a nearest-neighbor graph. This choice comes from\nrecent results that have proven that accuracy is not always the suitable\ncriterion to optimize. In our approach, a feature or an instance is removed if\nits deletion improves information of the graph. Numerous experiments are\npresented in this paper and a statistical analysis shows the relevance of our\napproach, and its tolerance in the presence of noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:33 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Sebban", "Marc", ""], ["Nock", "Richard", ""]]}, {"id": "1301.3895", "submitter": "Amos J. Storkey", "authors": "Amos J. Storkey", "title": "Dynamic Trees: A Structured Variational Method Giving Efficient\n  Propagation Rules", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-566-573", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic trees are mixtures of tree structured belief networks. They solve\nsome of the problems of fixed tree networks at the cost of making exact\ninference intractable. For this reason approximate methods such as sampling or\nmean field approaches have been used. However, mean field approximations assume\na factorized distribution over node states. Such a distribution seems unlickely\nin the posterior, as nodes are highly correlated in the prior. Here a\nstructured variational approach is used, where the posterior distribution over\nthe non-evidential nodes is itself approximated by a dynamic tree. It turns out\nthat this form can be used tractably and efficiently. The result is a set of\nupdate rules which can propagate information through the network to obtain both\na full variational approximation, and the relevant marginals. The progagtion\nrules are more efficient than the mean field approach and give noticeable\nquantitative and qualitative improvement in the inference. The marginals\ncalculated give better approximations to the posterior than loopy propagation\non a small toy problem.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:49 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Storkey", "Amos J.", ""]]}, {"id": "1301.3896", "submitter": "Loo-Nin Teow", "authors": "Loo-Nin Teow, Kia-Fock Loe", "title": "An Uncertainty Framework for Classification", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-574-579", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a generalized likelihood function based on uncertainty measures and\nshow that maximizing such a likelihood function for different measures induces\ndifferent types of classifiers. In the probabilistic framework, we obtain\nclassifiers that optimize the cross-entropy function. In the possibilistic\nframework, we obtain classifiers that maximize the interclass margin.\nFurthermore, we show that the support vector machine is a sub-class of these\nmaximum-margin classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:53 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Teow", "Loo-Nin", ""], ["Loe", "Kia-Fock", ""]]}, {"id": "1301.3897", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "A Branch-and-Bound Algorithm for MDL Learning Bayesian Networks", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-580-588", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the work in [Suzuki, 1996] and presents an efficient\ndepth-first branch-and-bound algorithm for learning Bayesian network\nstructures, based on the minimum description length (MDL) principle, for a\ngiven (consistent) variable ordering. The algorithm exhaustively searches\nthrough all network structures and guarantees to find the network with the best\nMDL score. Preliminary experiments show that the algorithm is efficient, and\nthat the time complexity grows slowly with the sample size. The algorithm is\nuseful for empirically studying both the performance of suboptimal heuristic\nsearch algorithms and the adequacy of the MDL principle in learning Bayesian\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:52:56 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1301.3899", "submitter": "Shivakumar Vaithyanathan", "authors": "Shivakumar Vaithyanathan, Byron E Dom", "title": "Model-Based Hierarchical Clustering", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-599-608", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to model-based hierarchical clustering by formulating\nan objective function based on a Bayesian analysis. This model organizes the\ndata into a cluster hierarchy while specifying a complex feature-set\npartitioning that is a key component of our model. Features can have either a\nunique distribution in every cluster or a common distribution over some (or\neven all) of the clusters. The cluster subsets over which these features have\nsuch a common distribution correspond to the nodes (clusters) of the tree\nrepresenting the hierarchy. We apply this general model to the problem of\ndocument clustering for which we use a multinomial likelihood function and\nDirichlet priors. Our algorithm consists of a two-stage process wherein we\nfirst perform a flat clustering followed by a modified hierarchical\nagglomerative merging process that includes determining the features that will\nhave common distributions over the merged clusters. The regularization induced\nby using the marginal likelihood automatically determines the optimal model\nstructure including number of clusters, the depth of the tree and the subset of\nfeatures to be modeled as having a common distribution at each node. We present\nexperimental results on both synthetic data and a real document collection.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:05 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Vaithyanathan", "Shivakumar", ""], ["Dom", "Byron E", ""]]}, {"id": "1301.3901", "submitter": "Wim Wiegerinck", "authors": "Wim Wiegerinck", "title": "Variational Approximations between Mean Field Theory and the Junction\n  Tree Algorithm", "comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2000-PG-626-633", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, variational approximations such as the mean field approximation\nhave received much interest. We extend the standard mean field method by using\nan approximating distribution that factorises into cluster potentials. This\nincludes undirected graphs, directed acyclic graphs and junction trees. We\nderive generalized mean field equations to optimize the cluster potentials. We\nshow that the method bridges the gap between the standard mean field\napproximation and the exact junction tree algorithm. In addition, we address\nthe problem of how to choose the graphical structure of the approximating\ndistribution. From the generalised mean field equations we derive rules to\nsimplify the structure of the approximating distribution in advance without\naffecting the quality of the approximation. We also show how the method fits\ninto some other variational approximations that are currently popular.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jan 2013 15:53:17 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Wiegerinck", "Wim", ""]]}, {"id": "1301.3966", "submitter": "Tingting Zhao Tingting Zhao", "authors": "Tingting Zhao, Hirotaka Hachiya, Voot Tangkaratt, Jun Morimoto,\n  Masashi Sugiyama", "title": "Efficient Sample Reuse in Policy Gradients with Parameter-based\n  Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The policy gradient approach is a flexible and powerful reinforcement\nlearning method particularly for problems with continuous actions such as robot\ncontrol. A common challenge in this scenario is how to reduce the variance of\npolicy gradient estimates for reliable policy updates. In this paper, we\ncombine the following three ideas and give a highly effective policy gradient\nmethod: (a) the policy gradients with parameter based exploration, which is a\nrecently proposed policy search method with low variance of gradient estimates,\n(b) an importance sampling technique, which allows us to reuse previously\ngathered data in a consistent way, and (c) an optimal baseline, which minimizes\nthe variance of gradient estimates with their unbiasedness being maintained.\nFor the proposed method, we give theoretical analysis of the variance of\ngradient estimates and show its usefulness through extensive experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 02:15:49 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Zhao", "Tingting", ""], ["Hachiya", "Hirotaka", ""], ["Tangkaratt", "Voot", ""], ["Morimoto", "Jun", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1301.4083", "submitter": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre", "authors": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre and Yoshua Bengio", "title": "Knowledge Matters: Importance of Prior Information for Optimization", "comments": "37 Pages, 5 figures, 5 tables JMLR Special Topics on Representation\n  Learning Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We explore the effect of introducing prior information into the intermediate\nlevel of neural networks for a learning task on which all the state-of-the-art\nmachine learning algorithms tested failed to learn. We motivate our work from\nthe hypothesis that humans learn such intermediate concepts from other\nindividuals via a form of supervision or guidance using a curriculum. The\nexperiments we have conducted provide positive evidence in favor of this\nhypothesis. In our experiments, a two-tiered MLP architecture is trained on a\ndataset with 64x64 binary inputs images, each image with three sprites. The\nfinal task is to decide whether all the sprites are the same or one of them is\ndifferent. Sprites are pentomino tetris shapes and they are placed in an image\nwith different locations using scaling and rotation transformations. The first\npart of the two-tiered MLP is pre-trained with intermediate-level targets being\nthe presence of sprites at each location, while the second part takes the\noutput of the first part as input and predicts the final task's target binary\nevent. The two-tiered MLP architecture, with a few tens of thousand examples,\nwas able to learn the task perfectly, whereas all other algorithms (include\nunsupervised pre-training, but also traditional algorithms like SVMs, decision\ntrees and boosting) all perform no better than chance. We hypothesize that the\noptimization difficulty involved when the intermediate pre-training is not\nperformed is due to the {\\em composition} of two highly non-linear tasks. Our\nfindings are also consistent with hypotheses on cultural learning inspired by\nthe observations of optimization problems with deep learning, presumably\nbecause of effective local minima.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 13:06:52 GMT"}, {"version": "v2", "created": "Sun, 20 Jan 2013 05:43:57 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2013 17:11:19 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2013 20:13:08 GMT"}, {"version": "v5", "created": "Fri, 15 Mar 2013 05:41:47 GMT"}, {"version": "v6", "created": "Sat, 13 Jul 2013 16:38:36 GMT"}], "update_date": "2013-07-16", "authors_parsed": [["G\u00fcl\u00e7ehre", "\u00c7a\u011flar", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1301.4157", "submitter": "Marcelo Cicconet", "authors": "Marcelo Cicconet", "title": "On the Product Rule for Classification Problems", "comments": "3 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss theoretical aspects of the product rule for classification\nproblems in supervised machine learning for the case of combining classifiers.\nWe show that (1) the product rule arises from the MAP classifier supposing\nequivalent priors and conditional independence given a class; (2) under some\nconditions, the product rule is equivalent to minimizing the sum of the squared\ndistances to the respective centers of the classes related with different\nfeatures, such distances being weighted by the spread of the classes; (3)\nobserving some hypothesis, the product rule is equivalent to concatenating the\nvectors of features.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 16:48:46 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Cicconet", "Marcelo", ""]]}, {"id": "1301.4168", "submitter": "Mareija Eskelinen", "authors": "Luke Bornn, Yutian Chen, Nando de Freitas, Mareija Eskelin, Jing Fang,\n  Max Welling", "title": "Herded Gibbs Sampling", "comments": "19 pages, including the appendix. Submission for ICLR 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gibbs sampler is one of the most popular algorithms for inference in\nstatistical models. In this paper, we introduce a herding variant of this\nalgorithm, called herded Gibbs, that is entirely deterministic. We prove that\nherded Gibbs has an $O(1/T)$ convergence rate for models with independent\nvariables and for fully connected probabilistic graphical models. Herded Gibbs\nis shown to outperform Gibbs in the tasks of image denoising with MRFs and\nnamed entity recognition with CRFs. However, the convergence for herded Gibbs\nfor sparsely connected probabilistic graphical models is still an open problem.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 17:37:56 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 01:55:06 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Bornn", "Luke", ""], ["Chen", "Yutian", ""], ["de Freitas", "Nando", ""], ["Eskelin", "Mareija", ""], ["Fang", "Jing", ""], ["Welling", "Max", ""]]}, {"id": "1301.4171", "submitter": "Jason  Weston", "authors": "Jason Weston, Ron Weiss, Hector Yee", "title": "Affinity Weighted Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised (linear) embedding models like Wsabie and PSI have proven\nsuccessful at ranking, recommendation and annotation tasks. However, despite\nbeing scalable to large datasets they do not take full advantage of the extra\ndata due to their linear nature, and typically underfit. We propose a new class\nof models which aim to provide improved performance while retaining many of the\nbenefits of the existing class of embedding models. Our new approach works by\niteratively learning a linear embedding model where the next iteration's\nfeatures and labels are reweighted as a function of the previous iteration. We\ndescribe several variants of the family, and give some initial results.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2013 17:46:27 GMT"}], "update_date": "2013-01-18", "authors_parsed": [["Weston", "Jason", ""], ["Weiss", "Ron", ""], ["Yee", "Hector", ""]]}, {"id": "1301.4293", "submitter": "Limin Yao", "authors": "Sebastian Riedel, Limin Yao, Andrew McCallum", "title": "Latent Relation Representations for Universal Schemas", "comments": "4 pages, ICLR workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional relation extraction predicts relations within some fixed and\nfinite target schema. Machine learning approaches to this task require either\nmanual annotation or, in the case of distant supervision, existing structured\nsources of the same schema. The need for existing datasets can be avoided by\nusing a universal schema: the union of all involved schemas (surface form\npredicates as in OpenIE, and relations in the schemas of pre-existing\ndatabases). This schema has an almost unlimited set of relations (due to\nsurface forms), and supports integration with existing structured data (through\nthe relation types of existing databases). To populate a database of such\nschema we present a family of matrix factorization models that predict affinity\nbetween database tuples and relations. We show that this achieves substantially\nhigher accuracy than the traditional classification approach. More importantly,\nby operating simultaneously on relations observed in text and in pre-existing\nstructured DBs such as Freebase, we are able to reason about unstructured and\nstructured data in mutually-supporting ways. By doing so our approach\noutperforms state-of-the-art distant supervision systems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2013 04:37:30 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2013 20:10:21 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Riedel", "Sebastian", ""], ["Yao", "Limin", ""], ["McCallum", "Andrew", ""]]}, {"id": "1301.4666", "submitter": "Dan Garber", "authors": "Dan Garber, Elad Hazan", "title": "A Linearly Convergent Conditional Gradient Algorithm with Applications\n  to Online and Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear optimization is many times algorithmically simpler than non-linear\nconvex optimization. Linear optimization over matroid polytopes, matching\npolytopes and path polytopes are example of problems for which we have simple\nand efficient combinatorial algorithms, but whose non-linear convex counterpart\nis harder and admits significantly less efficient algorithms. This motivates\nthe computational model of convex optimization, including the offline, online\nand stochastic settings, using a linear optimization oracle. In this\ncomputational model we give several new results that improve over the previous\nstate-of-the-art. Our main result is a novel conditional gradient algorithm for\nsmooth and strongly convex optimization over polyhedral sets that performs only\na single linear optimization step over the domain on each iteration and enjoys\na linear convergence rate. This gives an exponential improvement in convergence\nrate over previous results.\n  Based on this new conditional gradient algorithm we give the first algorithms\nfor online convex optimization over polyhedral sets that perform only a single\nlinear optimization step over the domain while having optimal regret\nguarantees, answering an open question of Kalai and Vempala, and Hazan and\nKale. Our online algorithms also imply conditional gradient algorithms for\nnon-smooth and stochastic convex optimization with the same convergence rates\nas projected (sub)gradient methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 15:54:22 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2013 22:32:09 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2013 17:06:16 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2013 20:49:45 GMT"}, {"version": "v5", "created": "Sun, 15 Sep 2013 10:50:33 GMT"}, {"version": "v6", "created": "Fri, 14 Aug 2015 18:02:18 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Garber", "Dan", ""], ["Hazan", "Elad", ""]]}, {"id": "1301.4679", "submitter": "Gerard Biau", "authors": "G\\'erard Biau (LPMA, LSTA, DMA, INRIA Paris - Rocquencourt), Luc\n  Devroye (SOCS)", "title": "Cellular Tree Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cellular tree classifier model addresses a fundamental problem in the\ndesign of classifiers for a parallel or distributed computing world: Given a\ndata set, is it sufficient to apply a majority rule for classification, or\nshall one split the data into two or more parts and send each part to a\npotentially different computer (or cell) for further processing? At first\nsight, it seems impossible to define with this paradigm a consistent classifier\nas no cell knows the \"original data size\", $n$. However, we show that this is\nnot so by exhibiting two different consistent classifiers. The consistency is\nuniversal but is only shown for distributions with nonatomic marginals.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2013 20:01:54 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 06:17:24 GMT"}], "update_date": "2013-06-26", "authors_parsed": [["Biau", "G\u00e9rard", "", "LPMA, LSTA, DMA, INRIA Paris - Rocquencourt"], ["Devroye", "Luc", "", "SOCS"]]}, {"id": "1301.4753", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi, Javid Taheri, Albert Y.Zomaya", "title": "Pattern Matching for Self- Tuning of MapReduce Jobs", "comments": "7 pages, previously published as \"On Using Pattern Matching\n  Algorithms in MapReduce Applications\" at ISPA 2011. arXiv admin note:\n  substantial text overlap with arXiv:1112.5505", "journal-ref": null, "doi": "10.1109/ISPA.2011.24", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study CPU utilization time patterns of several MapReduce\napplications. After extracting running patterns of several applications, they\nare saved in a reference database to be later used to tweak system parameters\nto efficiently execute unknown applications in future. To achieve this goal,\nCPU utilization patterns of new applications are compared with the already\nknown ones in the reference database to find/predict their most probable\nexecution patterns. Because of different patterns lengths, the Dynamic Time\nWarping (DTW) is utilized for such comparison; a correlation analysis is then\napplied to DTWs outcomes to produce feasible similarity patterns. Three real\napplications (WordCount, Exim Mainlog parsing and Terasort) are used to\nevaluate our hypothesis in tweaking system parameters in executing similar\napplications. Results were very promising and showed effectiveness of our\napproach on pseudo-distributed MapReduce platforms.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 04:57:05 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""], ["Taheri", "Javid", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1301.4767", "submitter": "Claudio Gentile", "authors": "Nicolo Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "A Linear Time Active Learning Algorithm for Link Classification -- Full\n  Version --", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present very efficient active learning algorithms for link classification\nin signed networks. Our algorithms are motivated by a stochastic model in which\nedge labels are obtained through perturbations of a initial sign assignment\nconsistent with a two-clustering of the nodes. We provide a theoretical\nanalysis within this model, showing that we can achieve an optimal (to whithin\na constant factor) number of mistakes on any graph G = (V,E) such that |E| =\n\\Omega(|V|^{3/2}) by querying O(|V|^{3/2}) edge labels. More generally, we show\nan algorithm that achieves optimality to within a factor of O(k) by querying at\nmost order of |V| + (|V|/k)^{3/2} edge labels. The running time of this\nalgorithm is at most of order |E| + |V|\\log|V|.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 07:02:50 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 17:57:53 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.4769", "submitter": "Claudio Gentile", "authors": "Nicolo Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "A Correlation Clustering Approach to Link Classification in Signed\n  Networks -- Full Version --", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by social balance theory, we develop a theory of link\nclassification in signed networks using the correlation clustering index as\nmeasure of label regularity. We derive learning bounds in terms of correlation\nclustering within three fundamental transductive learning settings: online,\nbatch and active. Our main algorithmic contribution is in the active setting,\nwhere we introduce a new family of efficient link classifiers based on covering\nthe input graph with small circuits. These are the first active algorithms for\nlink classification with mistake bounds that hold for arbitrary signed\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 07:28:44 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 17:44:24 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.4862", "submitter": "Pierre-Yves Oudeyer", "authors": "Adrien Baranes and Pierre-Yves Oudeyer", "title": "Active Learning of Inverse Models with Intrinsically Motivated Goal\n  Exploration in Robots", "comments": null, "journal-ref": "Baranes, A., Oudeyer, P-Y. (2013) Active Learning of Inverse\n  Models with Intrinsically Motivated Goal Exploration in Robots, Robotics and\n  Autonomous Systems, 61(1), pp. 49-73", "doi": "10.1016/j.robot.2012.05.008", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Self-Adaptive Goal Generation - Robust Intelligent Adaptive\nCuriosity (SAGG-RIAC) architecture as an intrinsi- cally motivated goal\nexploration mechanism which allows active learning of inverse models in\nhigh-dimensional redundant robots. This allows a robot to efficiently and\nactively learn distributions of parameterized motor skills/policies that solve\na corresponding distribution of parameterized tasks/goals. The architecture\nmakes the robot sample actively novel parameterized tasks in the task space,\nbased on a measure of competence progress, each of which triggers low-level\ngoal-directed learning of the motor policy pa- rameters that allow to solve it.\nFor both learning and generalization, the system leverages regression\ntechniques which allow to infer the motor policy parameters corresponding to a\ngiven novel parameterized task, and based on the previously learnt\ncorrespondences between policy and task parameters. We present experiments with\nhigh-dimensional continuous sensorimotor spaces in three different robotic\nsetups: 1) learning the inverse kinematics in a highly-redundant robotic arm,\n2) learning omnidirectional locomotion with motor primitives in a quadruped\nrobot, 3) an arm learning to control a fishing rod with a flexible wire. We\nshow that 1) exploration in the task space can be a lot faster than exploration\nin the actuator space for learning inverse models in redundant robots; 2)\nselecting goals maximizing competence progress creates developmental\ntrajectories driving the robot to progressively focus on tasks of increasing\ncomplexity and is statistically significantly more efficient than selecting\ntasks randomly, as well as more efficient than different standard active motor\nbabbling methods; 3) this architecture allows the robot to actively discover\nwhich parts of its task space it can learn to reach and which part it cannot.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 13:26:07 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Baranes", "Adrien", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1301.4917", "submitter": "Matus Telgarsky", "authors": "Matus Telgarsky", "title": "Dirichlet draws are sparse with high probability", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note provides an elementary proof of the folklore fact that draws from a\nDirichlet distribution (with parameters less than 1) are typically sparse (most\ncoordinates are small).\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 16:27:17 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Telgarsky", "Matus", ""]]}, {"id": "1301.4944", "submitter": "Julio Stern", "authors": "Marcelo S. Lauretto, Barbara B. C. Silva and Pablo M. Andrade", "title": "Evaluation of a Supervised Learning Approach for Stock Market Operations", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining methods have been widely applied in financial markets, with the\npurpose of providing suitable tools for prices forecasting and automatic\ntrading. Particularly, learning methods aim to identify patterns in time series\nand, based on such patterns, to recommend buy/sell operations. The objective of\nthis work is to evaluate the performance of Random Forests, a supervised\nlearning method based on ensembles of decision trees, for decision support in\nstock markets. Preliminary results indicate good rates of successful operations\nand good rates of return per operation, providing a strong motivation for\nfurther research in this topic.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2013 18:17:05 GMT"}], "update_date": "2013-01-22", "authors_parsed": [["Lauretto", "Marcelo S.", ""], ["Silva", "Barbara B. C.", ""], ["Andrade", "Pablo M.", ""]]}, {"id": "1301.5063", "submitter": "Ognjen Rudovic", "authors": "Ognjen Rudovic, Maja Pantic, Vladimir Pavlovic", "title": "Heteroscedastic Conditional Ordinal Random Fields for Pain Intensity\n  Estimation from Facial Images", "comments": "This paper has been withdrawn by the authors due to a crucial sign\n  error in equation 2&3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We propose a novel method for automatic pain intensity estimation from facial\nimages based on the framework of kernel Conditional Ordinal Random Fields\n(KCORF). We extend this framework to account for heteroscedasticity on the\noutput labels(i.e., pain intensity scores) and introduce a novel dynamic\nfeatures, dynamic ranks, that impose temporal ordinal constraints on the static\nranks (i.e., intensity scores). Our experimental results show that the proposed\napproach outperforms state-of-the art methods for sequence classification with\nordinal data and other ordinal regression models. The approach performs\nsignificantly better than other models in terms of Intra-Class Correlation\nmeasure, which is the most accepted evaluation measure in the tasks of facial\nbehaviour intensity estimation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 03:40:52 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2013 18:43:47 GMT"}], "update_date": "2013-04-04", "authors_parsed": [["Rudovic", "Ognjen", ""], ["Pantic", "Maja", ""], ["Pavlovic", "Vladimir", ""]]}, {"id": "1301.5088", "submitter": "Ian Goodfellow", "authors": "Ian J. Goodfellow", "title": "Piecewise Linear Multilayer Perceptrons and Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new type of hidden layer for a multilayer perceptron, and\ndemonstrate that it obtains the best reported performance for an MLP on the\nMNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 07:10:34 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Goodfellow", "Ian J.", ""]]}, {"id": "1301.5112", "submitter": "Claudio Gentile", "authors": "Nicolo Cesa-Bianchi, Claudio Gentile, Fabio Vitale, Giovanni Zappella", "title": "Active Learning on Trees and Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of active learning on a given tree whose nodes are\nassigned binary labels in an adversarial way. Inspired by recent results by\nGuillory and Bilmes, we characterize (up to constant factors) the optimal\nplacement of queries so to minimize the mistakes made on the non-queried nodes.\nOur query selection algorithm is extremely efficient, and the optimal number of\nmistakes on the non-queried nodes is achieved by a simple and efficient mincut\nclassifier. Through a simple modification of the query selection algorithm we\nalso show optimality (up to constant factors) with respect to the trade-off\nbetween number of queries and number of mistakes on non-queried nodes. By using\nspanning trees, our algorithms can be efficiently applied to general graphs,\nalthough the problem of finding optimal and efficient active learning\nalgorithms for general graphs remains open. Towards this end, we provide a\nlower bound on the number of mistakes made on arbitrary graphs by any active\nlearning algorithm using a number of queries which is up to a constant fraction\nof the graph size.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 09:00:28 GMT"}], "update_date": "2013-01-23", "authors_parsed": [["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Vitale", "Fabio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.5160", "submitter": "Claudio Gentile", "authors": "Fabio Vitale, Nicolo Cesa-Bianchi, Claudio Gentile, Giovanni Zappella", "title": "See the Tree Through the Lines: The Shazoo Algorithm -- Full Version --", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the nodes of a given graph is a fascinating theoretical problem\nwith applications in several domains. Since graph sparsification via spanning\ntrees retains enough information while making the task much easier, trees are\nan important special case of this problem. Although it is known how to predict\nthe nodes of an unweighted tree in a nearly optimal way, in the weighted case a\nfully satisfactory algorithm is not available yet. We fill this hole and\nintroduce an efficient node predictor, Shazoo, which is nearly optimal on any\nweighted tree. Moreover, we show that Shazoo can be viewed as a common\nnontrivial generalization of both previous approaches for unweighted trees and\nweighted lines. Experiments on real-world datasets confirm that Shazoo performs\nwell in that it fully exploits the structure of the input tree, and gets very\nclose to (and sometimes better than) less scalable energy minimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 11:59:04 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2013 17:31:08 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Vitale", "Fabio", ""], ["Cesa-Bianchi", "Nicolo", ""], ["Gentile", "Claudio", ""], ["Zappella", "Giovanni", ""]]}, {"id": "1301.5220", "submitter": "Kamil Ciosek", "authors": "Kamil Ciosek", "title": "Properties of the Least Squares Temporal Difference learning algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents four different ways of looking at the well-known Least\nSquares Temporal Differences (LSTD) algorithm for computing the value function\nof a Markov Reward Process, each of them leading to different insights: the\noperator-theory approach via the Galerkin method, the statistical approach via\ninstrumental variables, the linear dynamical system view as well as the limit\nof the TD iteration. We also give a geometric view of the algorithm as an\noblique projection. Furthermore, there is an extensive comparison of the\noptimization problem solved by LSTD as compared to Bellman Residual\nMinimization (BRM). We then review several schemes for the regularization of\nthe LSTD solution. We then proceed to treat the modification of LSTD for the\ncase of episodic Markov Reward Processes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 16:11:33 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2015 09:29:02 GMT"}], "update_date": "2015-04-06", "authors_parsed": [["Ciosek", "Kamil", ""]]}, {"id": "1301.5288", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and Bradley M. Bell and James V. Burke and\n  Gianluigi Pillonetto", "title": "The connection between Bayesian estimation of a Gaussian random field\n  and RKHS", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of a function from noisy data is often formulated as a\nregularized optimization problem over an infinite-dimensional reproducing\nkernel Hilbert space (RKHS). The solution describes the observed data and has a\nsmall RKHS norm. When the data fit is measured using a quadratic loss, this\nestimator has a known statistical interpretation. Given the noisy measurements,\nthe RKHS estimate represents the posterior mean (minimum variance estimate) of\na Gaussian random field with covariance proportional to the kernel associated\nwith the RKHS. In this paper, we provide a statistical interpretation when more\ngeneral losses are used, such as absolute value, Vapnik or Huber. Specifically,\nfor any finite set of sampling locations (including where the data were\ncollected), the MAP estimate for the signal samples is given by the RKHS\nestimate evaluated at these locations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 19:19:38 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2013 13:24:41 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2013 15:11:46 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Bell", "Bradley M.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1301.5332", "submitter": "Yuyang Wang", "authors": "Yuyang Wang, Roni Khardon, Dmitry Pechyony, Rosie Jones", "title": "Online Learning with Pairwise Loss Functions", "comments": "This is an extension of our COLT paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient online learning with pairwise loss functions is a crucial component\nin building large-scale learning system that maximizes the area under the\nReceiver Operator Characteristic (ROC) curve. In this paper we investigate the\ngeneralization performance of online learning algorithms with pairwise loss\nfunctions. We show that the existing proof techniques for generalization bounds\nof online algorithms with a univariate loss can not be directly applied to\npairwise losses. In this paper, we derive the first result providing\ndata-dependent bounds for the average risk of the sequence of hypotheses\ngenerated by an arbitrary online learner in terms of an easily computable\nstatistic, and show how to extract a low risk hypothesis from the sequence. We\ndemonstrate the generality of our results by applying it to two important\nproblems in machine learning. First, we analyze two online algorithms for\nbipartite ranking; one being a natural extension of the perceptron algorithm\nand the other using online convex optimization. Secondly, we provide an\nanalysis for the risk bound for an online algorithm for supervised metric\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2013 21:10:53 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Wang", "Yuyang", ""], ["Khardon", "Roni", ""], ["Pechyony", "Dmitry", ""], ["Jones", "Rosie", ""]]}, {"id": "1301.5348", "submitter": "Yangqing Jia", "authors": "Oriol Vinyals, Yangqing Jia, Trevor Darrell", "title": "Why Size Matters: Feature Coding as Nystrom Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the computer vision and machine learning community has been in\nfavor of feature extraction pipelines that rely on a coding step followed by a\nlinear classifier, due to their overall simplicity, well understood properties\nof linear classifiers, and their computational efficiency. In this paper we\npropose a novel view of this pipeline based on kernel methods and Nystrom\nsampling. In particular, we focus on the coding of a data point with a local\nrepresentation based on a dictionary with fewer elements than the number of\ndata points, and view it as an approximation to the actual function that would\ncompute pair-wise similarity to all data points (often too many to compute in\npractice), followed by a Nystrom sampling step to select a subset of all data\npoints.\n  Furthermore, since bounds are known on the approximation power of Nystrom\nsampling as a function of how many samples (i.e. dictionary size) we consider,\nwe can derive bounds on the approximation of the exact (but expensive to\ncompute) kernel matrix, and use it as a proxy to predict accuracy as a function\nof the dictionary size, which has been observed to increase but also to\nsaturate as we increase its size. This model may help explaining the positive\neffect of the codebook size and justifying the need to stack more layers (often\nreferred to as deep learning), as flat models empirically saturate as we add\nmore complexity.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2013 21:36:06 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2013 00:17:54 GMT"}], "update_date": "2013-04-17", "authors_parsed": [["Vinyals", "Oriol", ""], ["Jia", "Yangqing", ""], ["Darrell", "Trevor", ""]]}, {"id": "1301.5488", "submitter": "Manuel Lopes", "authors": "Francisco Melo and Manuel Lopes", "title": "Multi-class Generalized Binary Search for Active Inverse Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning a task from demonstration. We\nadopt the framework of inverse reinforcement learning, where tasks are\nrepresented in the form of a reward function. Our contribution is a novel\nactive learning algorithm that enables the learning agent to query the expert\nfor more informative demonstrations, thus leading to more sample-efficient\nlearning. For this novel algorithm (Generalized Binary Search for Inverse\nReinforcement Learning, or GBS-IRL), we provide a theoretical bound on sample\ncomplexity and illustrate its applicability on several different tasks. To our\nknowledge, GBS-IRL is the first active IRL algorithm with provable sample\ncomplexity bounds. We also discuss our method in light of other existing\nmethods in the literature and its general applicability in multi-class\nclassification problems. Finally, motivated by recent work on learning from\ndemonstration in robots, we also discuss how different forms of human feedback\ncan be integrated in a transparent manner in our learning framework.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 12:54:09 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Melo", "Francisco", ""], ["Lopes", "Manuel", ""]]}, {"id": "1301.5650", "submitter": "Marius Pachitariu", "authors": "Marius Pachitariu and Maneesh Sahani", "title": "Regularization and nonlinearities for neural language models: when are\n  they needed?", "comments": "Added new experiments on large datasets and on the Microsoft Research\n  Sentence Completion Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models (LMs) based on recurrent neural networks (RNN) are\nsome of the most successful word and character-level LMs. Why do they work so\nwell, in particular better than linear neural LMs? Possible explanations are\nthat RNNs have an implicitly better regularization or that RNNs have a higher\ncapacity for storing patterns due to their nonlinearities or both. Here we\nargue for the first explanation in the limit of little training data and the\nsecond explanation for large amounts of text data. We show state-of-the-art\nperformance on the popular and small Penn dataset when RNN LMs are regularized\nwith random dropout. Nonetheless, we show even better performance from a\nsimplified, much less expressive linear RNN model without off-diagonal entries\nin the recurrent matrix. We call this model an impulse-response LM (IRLM).\nUsing random dropout, column normalization and annealed learning rates, IRLMs\ndevelop neurons that keep a memory of up to 50 words in the past and achieve a\nperplexity of 102.5 on the Penn dataset. On two large datasets however, the\nsame regularization methods are unsuccessful for both models and the RNN's\nexpressivity allows it to overtake the IRLM by 10 and 20 percent perplexity,\nrespectively. Despite the perplexity gap, IRLMs still outperform RNNs on the\nMicrosoft Research Sentence Completion (MRSC) task. We develop a slightly\nmodified IRLM that separates long-context units (LCUs) from short-context units\nand show that the LCUs alone achieve a state-of-the-art performance on the MRSC\ntask of 60.8%. Our analysis indicates that a fruitful direction of research for\nneural LMs lies in developing more accessible internal representations, and\nsuggests an optimization regime of very high momentum terms for effectively\ntraining such models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 21:18:07 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2013 14:30:04 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Pachitariu", "Marius", ""], ["Sahani", "Maneesh", ""]]}, {"id": "1301.5686", "submitter": "Jeon-Hyung Kang", "authors": "Jeon-Hyung Kang, Jun Ma, Yan Liu", "title": "Transfer Topic Modeling with Ease and Scalability", "comments": "2012 SIAM International Conference on Data Mining (SDM12) Pages:\n  {564-575}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing volume of short texts generated on social media sites, such as\nTwitter or Facebook, creates a great demand for effective and efficient topic\nmodeling approaches. While latent Dirichlet allocation (LDA) can be applied, it\nis not optimal due to its weakness in handling short texts with fast-changing\ntopics and scalability concerns. In this paper, we propose a transfer learning\napproach that utilizes abundant labeled documents from other domains (such as\nYahoo! News or Wikipedia) to improve topic modeling, with better model fitting\nand result interpretation. Specifically, we develop Transfer Hierarchical LDA\n(thLDA) model, which incorporates the label information from other domains via\ninformative priors. In addition, we develop a parallel implementation of our\nmodel for large-scale applications. We demonstrate the effectiveness of our\nthLDA model on both a microblogging dataset and standard text collections\nincluding AP and RCV1 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 02:02:13 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2013 18:00:19 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Kang", "Jeon-Hyung", ""], ["Ma", "Jun", ""], ["Liu", "Yan", ""]]}, {"id": "1301.5734", "submitter": "Jean-Francois Laslier", "authors": "Benoit Laslier and Jean-Francois Laslier", "title": "Reinforcement learning from comparisons: Three alternatives is enough,\n  two is not", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with the problem of finding the best alternatives on the\nbasis of pairwise comparisons when these comparisons need not be transitive. In\nthis setting, we study a reinforcement urn model. We prove convergence to the\noptimal solution when reinforcement of a winning alternative occurs each time\nafter considering three random alternatives. The simpler process, which\nreinforces the winner of a random pair does not always converges: it may cycle.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 09:19:00 GMT"}], "update_date": "2013-01-25", "authors_parsed": [["Laslier", "Benoit", ""], ["Laslier", "Jean-Francois", ""]]}, {"id": "1301.5898", "submitter": "Lenka Zdeborova", "authors": "Florent Krzakala, Marc M\\'ezard, Lenka Zdeborov\\'a", "title": "Phase Diagram and Approximate Message Passing for Blind Calibration and\n  Dictionary Learning", "comments": "5 pages", "journal-ref": "Information Theory Proceedings (ISIT), 2013 IEEE International\n  Symposium on, page(s) 659 - 663", "doi": "10.1109/ISIT.2013.6620308", "report-no": null, "categories": "cs.IT cond-mat.stat-mech cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider dictionary learning and blind calibration for signals and\nmatrices created from a random ensemble. We study the mean-squared error in the\nlimit of large signal dimension using the replica method and unveil the\nappearance of phase transitions delimiting impossible, possible-but-hard and\npossible inference regions. We also introduce an approximate message passing\nalgorithm that asymptotically matches the theoretical performance, and show\nthrough numerical tests that it performs very well, for the calibration\nproblem, for tractable system sizes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2013 20:57:35 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Krzakala", "Florent", ""], ["M\u00e9zard", "Marc", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1301.6039", "submitter": "Jonathan Heras", "authors": "J\\'onathan Heras and Ekaterina Komendantskaya", "title": "Recycling Proof Patterns in Coq: Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of Interactive Theorem Provers has led to the creation of big\nlibraries and varied infrastructures for formal proofs. However, despite (or\nperhaps due to) their sophistication, the re-use of libraries by non-experts or\nacross domains is a challenge. In this paper, we provide detailed case studies\nand evaluate the machine-learning tool ML4PG built to interactively data-mine\nthe electronic libraries of proofs, and to provide user guidance on the basis\nof proof patterns found in the existing libraries.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 13:29:29 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2013 14:04:45 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 10:39:54 GMT"}, {"version": "v4", "created": "Fri, 7 Mar 2014 12:30:49 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Heras", "J\u00f3nathan", ""], ["Komendantskaya", "Ekaterina", ""]]}, {"id": "1301.6058", "submitter": "Edward Moroshko", "authors": "Edward Moroshko, Koby Crammer", "title": "Weighted Last-Step Min-Max Algorithm with Improved Sub-Logarithmic\n  Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online learning the performance of an algorithm is typically compared to\nthe performance of a fixed function from some class, with a quantity called\nregret. Forster proposed a last-step min-max algorithm which was somewhat\nsimpler than the algorithm of Vovk, yet with the same regret. In fact the\nalgorithm he analyzed assumed that the choices of the adversary are bounded,\nyielding artificially only the two extreme cases. We fix this problem by\nweighing the examples in such a way that the min-max problem will be well\ndefined, and provide analysis with logarithmic regret that may have better\nmultiplicative factor than both bounds of Forster and Vovk. We also derive a\nnew bound that may be sub-logarithmic, as a recent bound of Orabona et.al, but\nmay have better multiplicative factor. Finally, we analyze the algorithm in a\nweak-type of non-stationary setting, and show a bound that is sub-linear if the\nnon-stationarity is sub-linear as well.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2013 15:09:39 GMT"}], "update_date": "2013-01-28", "authors_parsed": [["Moroshko", "Edward", ""], ["Crammer", "Koby", ""]]}, {"id": "1301.6199", "submitter": "Ayaka Sakata", "authors": "Ayaka Sakata and Yoshiyuki Kabashima", "title": "Sample Complexity of Bayesian Optimal Dictionary Learning", "comments": "5pages, 5figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a learning problem of identifying a dictionary matrix D (M times\nN dimension) from a sample set of M dimensional vectors Y = N^{-1/2} DX, where\nX is a sparse matrix (N times P dimension) in which the density of non-zero\nentries is 0<rho< 1. In particular, we focus on the minimum sample size P_c\n(sample complexity) necessary for perfectly identifying D of the optimal\nlearning scheme when D and X are independently generated from certain\ndistributions. By using the replica method of statistical mechanics, we show\nthat P_c=O(N) holds as long as alpha = M/N >rho is satisfied in the limit of N\nto infinity. Our analysis also implies that the posterior distribution given Y\nis condensed only at the correct dictionary D when the compression rate alpha\nis greater than a certain critical value alpha_M(rho). This suggests that\nbelief propagation may allow us to learn D with a low computational complexity\nusing O(N) samples.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2013 01:27:46 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2014 13:21:56 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Sakata", "Ayaka", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "1301.6277", "submitter": "Jeon-Hyung Kang", "authors": "Jeon-Hyung Kang, Kristina Lerman, Lise Getoor", "title": "LA-LDA: A Limited Attention Topic Model for Social Recommendation", "comments": "The 2013 International Conference on Social Computing,\n  Behavioral-Cultural Modeling, & Prediction (SBP 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media users have finite attention which limits the number of incoming\nmessages from friends they can process. Moreover, they pay more attention to\nopinions and recommendations of some friends more than others. In this paper,\nwe propose LA-LDA, a latent topic model which incorporates limited,\nnon-uniformly divided attention in the diffusion process by which opinions and\ninformation spread on the social network. We show that our proposed model is\nable to learn more accurate user models from users' social network and item\nadoption behavior than models which do not take limited attention into account.\nWe analyze voting on news items on the social news aggregator Digg and show\nthat our proposed model is better able to predict held out votes than\nalternative models. Our study demonstrates that psycho-socially motivated\nmodels have better ability to describe and predict observed behavior than\nmodels which only consider topics.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jan 2013 18:26:36 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Kang", "Jeon-Hyung", ""], ["Lerman", "Kristina", ""], ["Getoor", "Lise", ""]]}, {"id": "1301.6314", "submitter": "Yakir Reshef", "authors": "David Reshef (1), Yakir Reshef (1), Michael Mitzenmacher (2), Pardis\n  Sabeti (2) (1, 2 - contributed equally)", "title": "Equitability Analysis of the Maximal Information Coefficient, with\n  Comparisons", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A measure of dependence is said to be equitable if it gives similar scores to\nequally noisy relationships of different types. Equitability is important in\ndata exploration when the goal is to identify a relatively small set of\nstrongest associations within a dataset as opposed to finding as many non-zero\nassociations as possible, which often are too many to sift through. Thus an\nequitable statistic, such as the maximal information coefficient (MIC), can be\nuseful for analyzing high-dimensional data sets. Here, we explore both\nequitability and the properties of MIC, and discuss several aspects of the\ntheory and practice of MIC. We begin by presenting an intuition behind the\nequitability of MIC through the exploration of the maximization and\nnormalization steps in its definition. We then examine the speed and optimality\nof the approximation algorithm used to compute MIC, and suggest some directions\nfor improving both. Finally, we demonstrate in a range of noise models and\nsample sizes that MIC is more equitable than natural alternatives, such as\nmutual information estimation and distance correlation.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 03:45:30 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2013 20:51:50 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Reshef", "David", ""], ["Reshef", "Yakir", ""], ["Mitzenmacher", "Michael", ""], ["Sabeti", "Pardis", ""]]}, {"id": "1301.6316", "submitter": "Hyun Ah Song", "authors": "Hyun Ah Song, Soo-Young Lee", "title": "Hierarchical Data Representation Model - Multi-layer NMF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a data representation model that demonstrates\nhierarchical feature learning using nsNMF. We extend unit algorithm into\nseveral layers. Experiments with document and image data successfully\ndiscovered feature hierarchies. We also prove that proposed method results in\nmuch better classification and reconstruction performance, especially for small\nnumber of features. feature hierarchies.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 04:51:21 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2013 05:25:58 GMT"}, {"version": "v3", "created": "Mon, 18 Mar 2013 18:37:37 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Song", "Hyun Ah", ""], ["Lee", "Soo-Young", ""]]}, {"id": "1301.6324", "submitter": "Togerchety Hitendra sarma", "authors": "T. Hitendra Sarma, P. Viswanath, D. Sai Koti Reddy and S. Sri Raghava", "title": "An improvement to k-nearest neighbor classifier", "comments": "Appeared in Third International Conference on Data Management, IMT\n  Ghaziabad, March 11-12, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Nearest neighbor classifier (k-NNC) is simple to use and has little design\ntime like finding k values in k-nearest neighbor classifier, hence these are\nsuitable to work with dynamically varying data-sets. There exists some\nfundamental improvements over the basic k-NNC, like weighted k-nearest\nneighbors classifier (where weights to nearest neighbors are given based on\nlinear interpolation), using artificially generated training set called\nbootstrapped training set, etc. These improvements are orthogonal to space\nreduction and classification time reduction techniques, hence can be coupled\nwith any of them. The paper proposes another improvement to the basic k-NNC\nwhere the weights to nearest neighbors are given based on Gaussian distribution\n(instead of linear interpolation as done in weighted k-NNC) which is also\nindependent of any space reduction and classification time reduction technique.\nWe formally show that our proposed method is closely related to non-parametric\ndensity estimation using a Gaussian kernel. We experimentally demonstrate using\nvarious standard data-sets that the proposed method is better than the existing\nones in most cases.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2013 06:55:55 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Sarma", "T. Hitendra", ""], ["Viswanath", "P.", ""], ["Reddy", "D. Sai Koti", ""], ["Raghava", "S. Sri", ""]]}, {"id": "1301.6626", "submitter": "Xiangnan Kong", "authors": "Xiangnan Kong, Philip S. Yu, Xue Wang, Ann B. Ragin", "title": "Discriminative Feature Selection for Uncertain Graph Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining discriminative features for graph data has attracted much attention in\nrecent years due to its important role in constructing graph classifiers,\ngenerating graph indices, etc. Most measurement of interestingness of\ndiscriminative subgraph features are defined on certain graphs, where the\nstructure of graph objects are certain, and the binary edges within each graph\nrepresent the \"presence\" of linkages among the nodes. In many real-world\napplications, however, the linkage structure of the graphs is inherently\nuncertain. Therefore, existing measurements of interestingness based upon\ncertain graphs are unable to capture the structural uncertainty in these\napplications effectively. In this paper, we study the problem of discriminative\nsubgraph feature selection from uncertain graphs. This problem is challenging\nand different from conventional subgraph mining problems because both the\nstructure of the graph objects and the discrimination score of each subgraph\nfeature are uncertain. To address these challenges, we propose a novel\ndiscriminative subgraph feature selection method, DUG, which can find\ndiscriminative subgraph features in uncertain graphs based upon different\nstatistical measures including expectation, median, mode and phi-probability.\nWe first compute the probability distribution of the discrimination scores for\neach subgraph feature based on dynamic programming. Then a branch-and-bound\nalgorithm is proposed to search for discriminative subgraphs efficiently.\nExtensive experiments on various neuroimaging applications (i.e., Alzheimer's\nDisease, ADHD and HIV) have been performed to analyze the gain in performance\nby taking into account structural uncertainties in identifying discriminative\nsubgraph features for graph classification.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 18:00:33 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Kong", "Xiangnan", ""], ["Yu", "Philip S.", ""], ["Wang", "Xue", ""], ["Ragin", "Ann B.", ""]]}, {"id": "1301.6630", "submitter": "Giovanni Zappella", "authors": "Corrado Monti, Alessandro Rozza, Giovanni Zappella, Matteo Zignani,\n  Adam Arvidsson, Monica Poletti", "title": "Political Disaffection: a case study on the Italian Twitter community", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our work we analyse the political disaffection or \"the subjective feeling\nof powerlessness, cynicism, and lack of confidence in the political process,\npoliticians, and democratic institutions, but with no questioning of the\npolitical regime\" by exploiting Twitter data through machine learning\ntechniques. In order to validate the quality of the time-series generated by\nthe Twitter data, we highlight the relations of these data with political\ndisaffection as measured by means of public opinion surveys. Moreover, we show\nthat important political news of Italian newspapers are often correlated with\nthe highest peaks of the produced time-series.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 18:17:22 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2013 14:33:18 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Monti", "Corrado", ""], ["Rozza", "Alessandro", ""], ["Zappella", "Giovanni", ""], ["Zignani", "Matteo", ""], ["Arvidsson", "Adam", ""], ["Poletti", "Monica", ""]]}, {"id": "1301.6659", "submitter": "Nima Mirbakhsh", "authors": "Nima Mirbakhsh and Charles X. Ling", "title": "Clustering-Based Matrix Factorization", "comments": "This paper has been withdrawn by the author due to crucial typo and\n  the poor grammatical text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are emerging technologies that nowadays can be found in\nmany applications such as Amazon, Netflix, and so on. These systems help users\nto find relevant information, recommendations, and their preferred items.\nSlightly improvement of the accuracy of these recommenders can highly affect\nthe quality of recommendations. Matrix Factorization is a popular method in\nRecommendation Systems showing promising results in accuracy and complexity. In\nthis paper we propose an extension of matrix factorization which adds general\nneighborhood information on the recommendation model. Users and items are\nclustered into different categories to see how these categories share\npreferences. We then employ these shared interests of categories in a fusion by\nBiased Matrix Factorization to achieve more accurate recommendations. This is a\ncomplement for the current neighborhood aware matrix factorization models which\nrely on using direct neighborhood information of users and items. The proposed\nmodel is tested on two well-known recommendation system datasets: Movielens100k\nand Netflix. Our experiment shows applying the general latent features of\ncategories into factorized recommender models improves the accuracy of\nrecommendations. The current neighborhood-aware models need a great number of\nneighbors to acheive good accuracies. To the best of our knowledge, the\nproposed model is better than or comparable with the current neighborhood-aware\nmodels when they consider fewer number of neighbors.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 20:01:57 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2013 22:16:44 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2013 01:04:55 GMT"}, {"version": "v4", "created": "Thu, 1 Aug 2013 22:06:49 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Mirbakhsh", "Nima", ""], ["Ling", "Charles X.", ""]]}, {"id": "1301.6676", "submitter": "Hagai Attias", "authors": "Hagai Attias", "title": "Inferring Parameters and Structure of Latent Variable Models by\n  Variational Bayes", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-21-30", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for learning graphical models with latent variables and a\nfixed structure estimate optimal values for the model parameters. Whereas this\napproach usually produces overfitting and suboptimal generalization\nperformance, carrying out the Bayesian program of computing the full posterior\ndistributions over the parameters remains a difficult problem. Moreover,\nlearning the structure of models with latent variables, for which the Bayesian\napproach is crucial, is yet a harder problem. In this paper I present the\nVariational Bayes framework, which provides a solution to these problems. This\napproach approximates full posterior distributions over model parameters and\nstructures, as well as latent variables, in an analytical manner without\nresorting to sampling methods. Unlike in the Laplace approximation, these\nposteriors are generally non-Gaussian and no Hessian needs to be computed. The\nresulting algorithm generalizes the standard Expectation Maximization\nalgorithm, and its convergence is guaranteed. I demonstrate that this algorithm\ncan be applied to a large class of models in several domains, including\nunsupervised clustering and blind source separation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:44 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Attias", "Hagai", ""]]}, {"id": "1301.6677", "submitter": "Katy S. Azoury", "authors": "Katy S. Azoury, Manfred K. Warmuth", "title": "Relative Loss Bounds for On-line Density Estimation with the Exponential\n  Family of Distributions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-31-40", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider on-line density estimation with a parameterized density from the\nexponential family. The on-line algorithm receives one example at a time and\nmaintains a parameter that is essentially an average of the past examples.\nAfter receiving an example the algorithm incurs a loss which is the negative\nlog-likelihood of the example w.r.t. the past parameter of the algorithm. An\noff-line algorithm can choose the best parameter based on all the examples. We\nprove bounds on the additional total loss of the on-line algorithm over the\ntotal loss of the off-line algorithm. These relative loss bounds hold for an\narbitrary sequence of examples. The goal is to design algorithms with the best\npossible relative loss bounds. We use a certain divergence to derive and\nanalyze the algorithms. This divergence is a relative entropy between two\nexponential distributions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:56:48 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Azoury", "Katy S.", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1301.6683", "submitter": "Xavier Boyen", "authors": "Xavier Boyen, Nir Friedman, Daphne Koller", "title": "Discovering the Hidden Structure of Complex Dynamic Systems", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-91-100", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Bayesian networks provide a compact and natural representation for\ncomplex dynamic systems. However, in many cases, there is no expert available\nfrom whom a model can be elicited. Learning provides an alternative approach\nfor constructing models of dynamic systems. In this paper, we address some of\nthe crucial computational aspects of learning the structure of dynamic systems,\nparticularly those where some relevant variables are partially observed or even\nentirely unknown. Our approach is based on the Structural Expectation\nMaximization (SEM) algorithm. The main computational cost of the SEM algorithm\nis the gathering of expected sufficient statistics. We propose a novel\napproximation scheme that allows these sufficient statistics to be computed\nefficiently. We also investigate the fundamental problem of discovering the\nexistence of hidden variables without exhaustive and expensive search. Our\napproach is based on the observation that, in dynamic systems, ignoring a\nhidden variable typically results in a violation of the Markov property. Thus,\nour algorithm searches for such violations in the data, and introduces hidden\nvariables to explain them. We provide empirical results showing that the\nalgorithm is able to learn the dynamics of complex systems in a computationally\ntractable way.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:10 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Boyen", "Xavier", ""], ["Friedman", "Nir", ""], ["Koller", "Daphne", ""]]}, {"id": "1301.6684", "submitter": "Jie Cheng", "authors": "Jie Cheng, Russell Greiner", "title": "Comparing Bayesian Network Classifiers", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-101-108", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we empirically evaluate algorithms for learning four types of\nBayesian network (BN) classifiers - Naive-Bayes, tree augmented Naive-Bayes, BN\naugmented Naive-Bayes and general BNs, where the latter two are learned using\ntwo variants of a conditional-independence (CI) based BN-learning algorithm.\nExperimental results show the obtained classifiers, learned using the CI based\nalgorithms, are competitive with (or superior to) the best known classifiers,\nbased on both Bayesian networks and other formalisms; and that the\ncomputational time for learning and using these classifiers is relatively\nsmall. Moreover, these results also suggest a way to learn yet more effective\nclassifiers; we demonstrate empirically that this new algorithm does work as\nexpected. Collectively, these results argue that BN classifiers deserve more\nattention in machine learning and data mining communities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:14 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Cheng", "Jie", ""], ["Greiner", "Russell", ""]]}, {"id": "1301.6685", "submitter": "Max Chickering", "authors": "David Maxwell Chickering, David Heckerman", "title": "Fast Learning from Sparse Data", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-109-115", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two techniques that significantly improve the running time of\nseveral standard machine-learning algorithms when data is sparse. The first\ntechnique is an algorithm that effeciently extracts one-way and two-way\ncounts--either real or expected-- from discrete data. Extracting such counts is\na fundamental step in learning algorithms for constructing a variety of models\nincluding decision trees, decision graphs, Bayesian networks, and naive-Bayes\nclustering models. The second technique is an algorithm that efficiently\nperforms the E-step of the EM algorithm (i.e. inference) when applied to a\nnaive-Bayes clustering model. Using real-world data sets, we demonstrate a\ndramatic decrease in running time for algorithms that incorporate these\ntechniques.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:18 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:09:53 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""]]}, {"id": "1301.6688", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta", "title": "Learning Polytrees", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-134-141", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of learning the maximum-likelihood polytree from data.\nOur first result is a performance guarantee establishing that the optimal\nbranching (or Chow-Liu tree), which can be computed very easily, constitutes a\ngood approximation to the best polytree. We then show that it is not possible\nto do very much better, since the learning problem is NP-hard even to\napproximately solve within some constant factor.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:30 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Dasgupta", "Sanjoy", ""]]}, {"id": "1301.6690", "submitter": "Richard Dearden", "authors": "Richard Dearden, Nir Friedman, David Andre", "title": "Model-Based Bayesian Exploration", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-150-159", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning systems are often concerned with balancing exploration\nof untested actions against exploitation of actions that are known to be good.\nThe benefit of exploration can be estimated using the classical notion of Value\nof Information - the expected improvement in future decision quality arising\nfrom the information acquired by exploration. Estimating this quantity requires\nan assessment of the agent's uncertainty about its current value estimates for\nstates. In this paper we investigate ways of representing and reasoning about\nthis uncertainty in algorithms where the system attempts to learn a model of\nits environment. We explicitly represent uncertainty about the parameters of\nthe model and build probability distributions over Q-values based on these.\nThese distributions are used to compute a myopic approximation to the value of\ninformation for each action and hence to select the action that best balances\nexploration and exploitation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:57:38 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Dearden", "Richard", ""], ["Friedman", "Nir", ""], ["Andre", "David", ""]]}, {"id": "1301.6695", "submitter": "Nir Friedman", "authors": "Nir Friedman, Moises Goldszmidt, Abraham Wyner", "title": "Data Analysis with Bayesian Networks: A Bootstrap Approach", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-196-205", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been significant progress in algorithms and methods\nfor inducing Bayesian networks from data. However, in complex data analysis\nproblems, we need to go beyond being satisfied with inducing networks with high\nscores. We need to provide confidence measures on features of these networks:\nIs the existence of an edge between two nodes warranted? Is the Markov blanket\nof a given node robust? Can we say something about the ordering of the\nvariables? We should be able to address these questions, even when the amount\nof data is not enough to induce a high scoring network. In this paper we\npropose Efron's Bootstrap as a computationally efficient approach for answering\nthese questions. In addition, we propose to use these confidence measures to\ninduce better structures from the data, and to detect the presence of latent\nvariables.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:00 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Friedman", "Nir", ""], ["Goldszmidt", "Moises", ""], ["Wyner", "Abraham", ""]]}, {"id": "1301.6696", "submitter": "Nir Friedman", "authors": "Nir Friedman, Iftach Nachman, Dana Pe'er", "title": "Learning Bayesian Network Structure from Massive Datasets: The \"Sparse\n  Candidate\" Algorithm", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-206-215", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Bayesian networks is often cast as an optimization problem, where\nthe computational task is to find a structure that maximizes a statistically\nmotivated score. By and large, existing learning tools address this\noptimization problem using standard heuristic search techniques. Since the\nsearch space is extremely large, such search procedures can spend most of the\ntime examining candidates that are extremely unreasonable. This problem becomes\ncritical when we deal with data sets that are large either in the number of\ninstances, or the number of attributes. In this paper, we introduce an\nalgorithm that achieves faster learning by restricting the search space. This\niterative algorithm restricts the parents of each variable to belong to a small\nsubset of candidates. We then search for a network that satisfies these\nconstraints. The learned network is then used for selecting better candidates\nfor the next iteration. We evaluate this algorithm both on synthetic and\nreal-life data. Our results show that it is significantly faster than\nalternative search procedures without loss of quality in the learned\nstructures.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:05 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Friedman", "Nir", ""], ["Nachman", "Iftach", ""], ["Pe'er", "Dana", ""]]}, {"id": "1301.6697", "submitter": "David Heckerman", "authors": "Dan Geiger, David Heckerman", "title": "Parameter Priors for Directed Acyclic Graphical Models and the\n  Characterization of Several Probability Distributions", "comments": "This version has improved pointers to the literature. arXiv admin\n  note: substantial text overlap with arXiv:2105.03248", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-216-225", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the only parameter prior for complete Gaussian DAG models that\nsatisfies global parameter independence, complete model equivalence, and some\nweak regularity assumptions, is the normal-Wishart distribution. Our analysis\nis based on the following new characterization of the Wishart distribution: let\nW be an n x n, n >= 3, positive-definite symmetric matrix of random variables\nand f(W) be a pdf of W. Then, f(W) is a Wishart distribution if and only if\nW_{11}-W_{12}W_{22}^{-1}W_{12}' is independent of {W_{12}, W_{22}} for every\nblock partitioning W_{11}, W_{12}, W_{12}', W_{22} of W. Similar\ncharacterizations of the normal and normal-Wishart distributions are provided\nas well. We also show how to construct a prior for every DAG model over X from\nthe prior of a single regression model.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:09 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:08:10 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 13:33:49 GMT"}, {"version": "v4", "created": "Tue, 29 Jun 2021 19:43:51 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Geiger", "Dan", ""], ["Heckerman", "David", ""]]}, {"id": "1301.6705", "submitter": "Thomas Hofmann", "authors": "Thomas Hofmann", "title": "Probabilistic Latent Semantic Analysis", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-289-296", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Latent Semantic Analysis is a novel statistical technique for\nthe analysis of two-mode and co-occurrence data, which has applications in\ninformation retrieval and filtering, natural language processing, machine\nlearning from text, and in related areas. Compared to standard Latent Semantic\nAnalysis which stems from linear algebra and performs a Singular Value\nDecomposition of co-occurrence tables, the proposed method is based on a\nmixture decomposition derived from a latent class model. This results in a more\nprincipled approach which has a solid foundation in statistics. In order to\navoid overfitting, we propose a widely applicable generalization of maximum\nlikelihood model fitting by tempered EM. Our approach yields substantial and\nconsistent improvements over Latent Semantic Analysis in a number of\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:58:43 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Hofmann", "Thomas", ""]]}, {"id": "1301.6710", "submitter": "Petri Kontkanen", "authors": "Petri Kontkanen, Petri Myllymaki, Tomi Silander, Henry Tirri", "title": "On Supervised Selection of Bayesian Networks", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-334-342", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a set of possible models (e.g., Bayesian network structures) and a data\nsample, in the unsupervised model selection problem the task is to choose the\nmost accurate model with respect to the domain joint probability distribution.\nIn contrast to this, in supervised model selection it is a priori known that\nthe chosen model will be used in the future for prediction tasks involving more\n``focused' predictive distributions. Although focused predictive distributions\ncan be produced from the joint probability distribution by marginalization, in\npractice the best model in the unsupervised sense does not necessarily perform\nwell in supervised domains. In particular, the standard marginal likelihood\nscore is a criterion for the unsupervised task, and, although frequently used\nfor supervised model selection also, does not perform well in such tasks. In\nthis paper we study the performance of the marginal likelihood score\nempirically in supervised Bayesian network selection tasks by using a large\nnumber of publicly available classification data sets, and compare the results\nto those obtained by alternative model selection criteria, including empirical\ncrossvalidation methods, an approximation of a supervised marginal likelihood\nmeasure, and a supervised version of Dawids prequential(predictive sequential)\nprinciple.The results demonstrate that the marginal likelihood score does NOT\nperform well FOR supervised model selection, WHILE the best results are\nobtained BY using Dawids prequential r napproach.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:02 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Kontkanen", "Petri", ""], ["Myllymaki", "Petri", ""], ["Silander", "Tomi", ""], ["Tirri", "Henry", ""]]}, {"id": "1301.6723", "submitter": "Stefano Monti", "authors": "Stefano Monti, Gregory F. Cooper", "title": "A Bayesian Network Classifier that Combines a Finite Mixture Model and a\n  Naive Bayes Model", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-447-456", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new Bayesian network model for classification that\ncombines the naive-Bayes (NB) classifier and the finite-mixture (FM)\nclassifier. The resulting classifier aims at relaxing the strong assumptions on\nwhich the two component models are based, in an attempt to improve on their\nclassification performance, both in terms of accuracy and in terms of\ncalibration of the estimated probabilities. The proposed classifier is obtained\nby superimposing a finite mixture model on the set of feature variables of a\nnaive Bayes model. We present experimental results that compare the predictive\nperformance on real datasets of the new classifier with the predictive\nperformance of the NB classifier and the FM classifier.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:54 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Monti", "Stefano", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1301.6724", "submitter": "Kevin Murphy", "authors": "Kevin Murphy", "title": "A Variational Approximation for Bayesian Networks with Discrete and\n  Continuous Latent Variables", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-457-466", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to use a variational approximation to the logistic function to\nperform approximate inference in Bayesian networks containing discrete nodes\nwith continuous parents. Essentially, we convert the logistic function to a\nGaussian, which facilitates exact inference, and then iteratively adjust the\nvariational parameters to improve the quality of the approximation. We\ndemonstrate experimentally that this approximation is faster and potentially\nmore accurate than sampling. We also introduce a simple new technique for\nhandling evidence, which allows us to handle arbitrary distributions on\nobserved nodes, as well as achieving a significant speedup in networks with\ndiscrete variables of large cardinality.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 15:59:58 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Murphy", "Kevin", ""]]}, {"id": "1301.6725", "submitter": "Kevin Murphy", "authors": "Kevin Murphy, Yair Weiss, Michael I. Jordan", "title": "Loopy Belief Propagation for Approximate Inference: An Empirical Study", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-467-476", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers have demonstrated that loopy belief propagation - the\nuse of Pearls polytree algorithm IN a Bayesian network WITH loops OF error-\ncorrecting codes.The most dramatic instance OF this IS the near Shannon - limit\nperformance OF Turbo Codes codes whose decoding algorithm IS equivalent TO\nloopy belief propagation IN a chain - structured Bayesian network. IN this\npaper we ask : IS there something special about the error - correcting code\ncontext, OR does loopy propagation WORK AS an approximate inference schemeIN a\nmore general setting? We compare the marginals computed using loopy propagation\nTO the exact ones IN four Bayesian network architectures, including two real -\nworld networks : ALARM AND QMR.We find that the loopy beliefs often converge\nAND WHEN they do, they give a good approximation TO the correct\nmarginals.However,ON the QMR network, the loopy beliefs oscillated AND had no\nobvious relationship TO the correct posteriors. We present SOME initial\ninvestigations INTO the cause OF these oscillations, AND show that SOME simple\nmethods OF preventing them lead TO the wrong results.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:02 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Murphy", "Kevin", ""], ["Weiss", "Yair", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.6726", "submitter": "James W. Myers", "authors": "James W. Myers, Kathryn Blackmond Laskey, Tod S. Levitt", "title": "Learning Bayesian Networks from Incomplete Data with Stochastic Search\n  Algorithms", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-476-485", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes stochastic search approaches, including a new stochastic\nalgorithm and an adaptive mutation operator, for learning Bayesian networks\nfrom incomplete data. This problem is characterized by a huge solution space\nwith a highly multimodal landscape. State-of-the-art approaches all involve\nusing deterministic approaches such as the expectation-maximization algorithm.\nThese approaches are guaranteed to find local maxima, but do not explore the\nlandscape for other modes. Our approach evolves structure and the missing data.\nWe compare our stochastic algorithms and show they all produce accurate\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:06 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Myers", "James W.", ""], ["Laskey", "Kathryn Blackmond", ""], ["Levitt", "Tod S.", ""]]}, {"id": "1301.6727", "submitter": "Julian R. Neil", "authors": "Julian R. Neil, Chris S. Wallace, Kevin B. Korb", "title": "Learning Bayesian Networks with Restricted Causal Interactions", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-486-493", "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major problem for the learning of Bayesian networks (BNs) is the\nexponential number of parameters needed for conditional probability tables.\nRecent research reduces this complexity by modeling local structure in the\nprobability tables. We examine the use of log-linear local models. While\nlog-linear models in this context are not new (Whittaker, 1990; Buntine, 1991;\nNeal, 1992; Heckerman and Meek, 1997), for structure learning they are\ngenerally subsumed under a naive Bayes model. We describe an alternative\ninterpretation, and use a Minimum Message Length (MML) (Wallace, 1987) metric\nfor structure learning of networks exhibiting causal independence, which we\nterm first-order networks (FONs). We also investigate local model selection on\na node-by-node basis.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:10 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Neil", "Julian R.", ""], ["Wallace", "Chris S.", ""], ["Korb", "Kevin B.", ""]]}, {"id": "1301.6730", "submitter": "Luis E. Ortiz", "authors": "Luis E. Ortiz, Leslie Pack Kaelbling", "title": "Accelerating EM: An Empirical Study", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-512-521", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require that we learn the parameters of a model from data.\nEM is a method used to learn the parameters of probabilistic models for which\nthe data for some of the variables in the models is either missing or hidden.\nThere are instances in which this method is slow to converge. Therefore,\nseveral accelerations have been proposed to improve the method. None of the\nproposed acceleration methods are theoretically dominant and experimental\ncomparisons are lacking. In this paper, we present the different proposed\naccelerations and try to compare them experimentally. From the results of the\nexperiments, we argue that some acceleration of EM is always possible, but that\nwhich acceleration is superior depends on properties of the problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:21 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Ortiz", "Luis E.", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1301.6731", "submitter": "Vladimir Pavlovic", "authors": "Vladimir Pavlovic, Brendan J. Frey, Thomas S. Huang", "title": "Variational Learning in Mixed-State Dynamic Graphical Models", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-522-530", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-valued stochastic time-series are locally linear (Gassian), but\nglobally non-linear. For example, the trajectory of a human hand gesture can be\nviewed as a linear dynamic system driven by a nonlinear dynamic system that\nrepresents muscle actions. We present a mixed-state dynamic graphical model in\nwhich a hidden Markov model drives a linear dynamic system. This combination\nallows us to model both the discrete and continuous causes of trajectories such\nas human gestures. The number of computations needed for exact inference is\nexponential in the sequence length, so we derive an approximate variational\ninference technique that can also be used to learn the parameters of the\ndiscrete and continuous models. We show how the mixed-state model and the\nvariational technique can be used to classify human hand gestures made with a\ncomputer mouse.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:25 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Pavlovic", "Vladimir", ""], ["Frey", "Brendan J.", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1301.6738", "submitter": "Raffaella Settimi", "authors": "Raffaella Settimi, Jim Q. Smith, A. S. Gargoum", "title": "Approximate Learning in Complex Dynamic Bayesian Networks", "comments": "Appears in Proceedings of the Fifteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1999)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1999-PG-585-593", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we extend the work of Smith and Papamichail (1999) and present\nfast approximate Bayesian algorithms for learning in complex scenarios where at\nany time frame, the relationships between explanatory state space variables can\nbe described by a Bayesian network that evolve dynamically over time and the\nobservations taken are not necessarily Gaussian. It uses recent developments in\napproximate Bayesian forecasting methods in combination with more familiar\nGaussian propagation algorithms on junction trees. The procedure for learning\nstate parameters from data is given explicitly for common sampling\ndistributions and the methodology is illustrated through a real application.\nThe efficiency of the dynamic approximation is explored by using the Hellinger\ndivergence measure and theoretical bounds for the efficacy of such a procedure\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2013 16:00:53 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Settimi", "Raffaella", ""], ["Smith", "Jim Q.", ""], ["Gargoum", "A. S.", ""]]}, {"id": "1301.6770", "submitter": "Zhixiang Eddie Xu", "authors": "Zhixiang (Eddie) Xu, Minmin Chen, Kilian Q. Weinberger, Fei Sha", "title": "An alternative text representation to TF-IDF and Bag-of-Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text mining, information retrieval, and machine learning, text documents\nare commonly represented through variants of sparse Bag of Words (sBoW) vectors\n(e.g. TF-IDF). Although simple and intuitive, sBoW style representations suffer\nfrom their inherent over-sparsity and fail to capture word-level synonymy and\npolysemy. Especially when labeled data is limited (e.g. in document\nclassification), or the text documents are short (e.g. emails or abstracts),\nmany features are rarely observed within the training corpus. This leads to\noverfitting and reduced generalization accuracy. In this paper we propose Dense\nCohort of Terms (dCoT), an unsupervised algorithm to learn improved sBoW\ndocument features. dCoT explicitly models absent words by removing and\nreconstructing random sub-sets of words in the unlabeled corpus. With this\napproach, dCoT learns to reconstruct frequent words from co-occurring\ninfrequent words and maps the high dimensional sparse sBoW vectors into a\nlow-dimensional dense representation. We show that the feature removal can be\nmarginalized out and that the reconstruction can be solved for in closed-form.\nWe demonstrate empirically, on several benchmark datasets, that dCoT features\nsignificantly improve the classification accuracy across several document\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 21:04:45 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Zhixiang", "", "", "Eddie"], ["Xu", "", ""], ["Chen", "Minmin", ""], ["Weinberger", "Kilian Q.", ""], ["Sha", "Fei", ""]]}, {"id": "1301.6791", "submitter": "Weiyu Xu", "authors": "Jian-Feng Cai and Weiyu Xu", "title": "Guarantees of Total Variation Minimization for Signal Recovery", "comments": "lower bounds added; version with Gaussian width, improved bounds;\n  stability results added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CV cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider using total variation minimization to recover\nsignals whose gradients have a sparse support, from a small number of\nmeasurements. We establish the proof for the performance guarantee of total\nvariation (TV) minimization in recovering \\emph{one-dimensional} signal with\nsparse gradient support. This partially answers the open problem of proving the\nfidelity of total variation minimization in such a setting \\cite{TVMulti}. In\nparticular, we have shown that the recoverable gradient sparsity can grow\nlinearly with the signal dimension when TV minimization is used. Recoverable\nsparsity thresholds of TV minimization are explicitly computed for\n1-dimensional signal by using the Grassmann angle framework. We also extend our\nresults to TV minimization for multidimensional signals. Stability of\nrecovering signal itself using 1-D TV minimization has also been established\nthrough a property called \"almost Euclidean property for 1-dimensional TV\nnorm\". We further give a lower bound on the number of random Gaussian\nmeasurements for recovering 1-dimensional signal vectors with $N$ elements and\n$K$-sparse gradients. Interestingly, the number of needed measurements is lower\nbounded by $\\Omega((NK)^{\\frac{1}{2}})$, rather than the $O(K\\log(N/K))$ bound\nfrequently appearing in recovering $K$-sparse signal vectors.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2013 22:01:22 GMT"}, {"version": "v2", "created": "Sun, 17 Mar 2013 19:33:11 GMT"}, {"version": "v3", "created": "Fri, 17 May 2013 05:00:55 GMT"}, {"version": "v4", "created": "Mon, 20 May 2013 17:34:30 GMT"}, {"version": "v5", "created": "Wed, 18 Sep 2013 19:59:04 GMT"}, {"version": "v6", "created": "Fri, 11 Oct 2013 16:47:24 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["Cai", "Jian-Feng", ""], ["Xu", "Weiyu", ""]]}, {"id": "1301.6939", "submitter": "Edward Grefenstette", "authors": "Edward Grefenstette, Georgiana Dinu, Yao-Zhong Zhang, Mehrnoosh\n  Sadrzadeh and Marco Baroni", "title": "Multi-Step Regression Learning for Compositional Distributional\n  Semantics", "comments": "10 pages + 1 page references, to be presented at the 10th\n  International Conference on Computational Semantics (IWCS 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model for compositional distributional semantics related to the\nframework of Coecke et al. (2010), and emulating formal semantics by\nrepresenting functions as tensors and arguments as vectors. We introduce a new\nlearning method for tensors, generalising the approach of Baroni and Zamparelli\n(2010). We evaluate it on two benchmark data sets, and find it to outperform\nexisting leading methods. We argue in our analysis that the nature of this\nlearning method also renders it suitable for solving more subtle problems\ncompositional distributional models might face.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 14:59:34 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 12:01:23 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Grefenstette", "Edward", ""], ["Dinu", "Georgiana", ""], ["Zhang", "Yao-Zhong", ""], ["Sadrzadeh", "Mehrnoosh", ""], ["Baroni", "Marco", ""]]}, {"id": "1301.6944", "submitter": "Andreas Christmann", "authors": "Andreas Christmann and Robert Hable", "title": "On the Consistency of the Bootstrap Approach for Support Vector Machines\n  and Related Kernel Based Methods", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that bootstrap approximations of support vector machines (SVMs)\nbased on a general convex and smooth loss function and on a general kernel are\nconsistent. This result is useful to approximate the unknown finite sample\ndistribution of SVMs by the bootstrap approach.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 15:09:56 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Christmann", "Andreas", ""], ["Hable", "Robert", ""]]}, {"id": "1301.7047", "submitter": "Yunpeng Zhao", "authors": "Yunpeng Zhao, Elizaveta Levina and Ji Zhu", "title": "Link prediction for partially observed networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is one of the fundamental problems in network analysis. In\nmany applications, notably in genetics, a partially observed network may not\ncontain any negative examples of absent edges, which creates a difficulty for\nmany existing supervised learning approaches. We develop a new method which\ntreats the observed network as a sample of the true network with different\nsampling rates for positive and negative examples. We obtain a relative ranking\nof potential links by their probabilities, utilizing information on node\ncovariates as well as on network topology. Empirically, the method performs\nwell under many settings, including when the observed network is sparse. We\napply the method to a protein-protein interaction network and a school\nfriendship network.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2013 20:22:46 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Zhao", "Yunpeng", ""], ["Levina", "Elizaveta", ""], ["Zhu", "Ji", ""]]}, {"id": "1301.7363", "submitter": "John S. Breese", "authors": "John S. Breese, David Heckerman, Carl Kadie", "title": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-43-52", "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering or recommender systems use a database about user\npreferences to predict additional topics or products a new user might like. In\nthis paper we describe several algorithms designed for this task, including\ntechniques based on correlation coefficients, vector-based similarity\ncalculations, and statistical Bayesian methods. We compare the predictive\naccuracy of the various methods in a set of representative problem domains. We\nuse two basic classes of evaluation metrics. The first characterizes accuracy\nover a set of individual predictions in terms of average absolute deviation.\nThe second estimates the utility of a ranked list of suggested items. This\nmetric uses an estimate of the probability that a user will see a\nrecommendation in an ordered list. Experiments were run for datasets associated\nwith 3 application areas, 4 experimental protocols, and the 2 evaluation\nmetrics for the various algorithms. Results indicate that for a wide range of\nconditions, Bayesian networks with decision trees at each node and correlation\nmethods outperform Bayesian-clustering and vector-similarity methods. Between\ncorrelation and Bayesian networks, the preferred method depends on the nature\nof the dataset, nature of the application (ranked versus one-by-one\npresentation), and the availability of votes with which to make predictions.\nOther considerations include the size of database, speed of predictions, and\nlearning time.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:02:44 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Breese", "John S.", ""], ["Heckerman", "David", ""], ["Kadie", "Carl", ""]]}, {"id": "1301.7373", "submitter": "Nir Friedman", "authors": "Nir Friedman", "title": "The Bayesian Structural EM Algorithm", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-129-138", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a flurry of works on learning Bayesian\nnetworks from data. One of the hard problems in this area is how to effectively\nlearn the structure of a belief network from incomplete data- that is, in the\npresence of missing values or hidden variables. In a recent paper, I introduced\nan algorithm called Structural EM that combines the standard Expectation\nMaximization (EM) algorithm, which optimizes parameters, with structure search\nfor model selection. That algorithm learns networks based on penalized\nlikelihood scores, which include the BIC/MDL score and various approximations\nto the Bayesian score. In this paper, I extend Structural EM to deal directly\nwith Bayesian model selection. I prove the convergence of the resulting\nalgorithm and show how to apply it for learning a large class of probabilistic\nmodels, including Bayesian networks and some variants thereof.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:37 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Friedman", "Nir", ""]]}, {"id": "1301.7374", "submitter": "Nir Friedman", "authors": "Nir Friedman, Kevin Murphy, Stuart Russell", "title": "Learning the Structure of Dynamic Probabilistic Networks", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-139-147", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic probabilistic networks are a compact representation of complex\nstochastic processes. In this paper we examine how to learn the structure of a\nDPN from data. We extend structure scoring rules for standard probabilistic\nnetworks to the dynamic case, and show how to search for structure when some of\nthe variables are hidden. Finally, we examine two applications where such a\ntechnology might be useful: predicting and classifying dynamic behaviors, and\nlearning causal orderings in biological processes. We provide empirical results\nthat demonstrate the applicability of our methods in both domains.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:42 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Friedman", "Nir", ""], ["Murphy", "Kevin", ""], ["Russell", "Stuart", ""]]}, {"id": "1301.7375", "submitter": "Alex Gammerman", "authors": "Alex Gammerman, Volodya Vovk, Vladimir Vapnik", "title": "Learning by Transduction", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-148-155", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for predicting a classification of an object given\nclassifications of the objects in the training set, assuming that the pairs\nobject/classification are generated by an i.i.d. process from a continuous\nprobability distribution. Our method is a modification of Vapnik's\nsupport-vector machine; its main novelty is that it gives not only the\nprediction itself but also a practicable measure of the evidence found in\nsupport of that prediction. We also describe a procedure for assigning degrees\nof confidence to predictions made by the support vector machine. Some\nexperimental results are presented, and possible extensions of the algorithms\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:47 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Gammerman", "Alex", ""], ["Vovk", "Volodya", ""], ["Vapnik", "Vladimir", ""]]}, {"id": "1301.7376", "submitter": "Dan Geiger", "authors": "Dan Geiger, Christopher Meek", "title": "Graphical Models and Exponential Families", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-156-165", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a classification of graphical models according to their\nrepresentation as subfamilies of exponential families. Undirected graphical\nmodels with no hidden variables are linear exponential families (LEFs),\ndirected acyclic graphical models and chain graphs with no hidden variables,\nincluding Bayesian networks with several families of local distributions, are\ncurved exponential families (CEFs) and graphical models with hidden variables\nare stratified exponential families (SEFs). An SEF is a finite union of CEFs\nsatisfying a frontier condition. In addition, we illustrate how one can\nautomatically generate independence and non-independence constraints on the\ndistributions over the observable variables implied by a Bayesian network with\nhidden variables. The relevance of these results for model selection is\nexamined.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:03:52 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Geiger", "Dan", ""], ["Meek", "Christopher", ""]]}, {"id": "1301.7378", "submitter": "Peter D Grunwald", "authors": "Peter D Grunwald, Petri Kontkanen, Petri Myllymaki, Tomi Silander,\n  Henry Tirri", "title": "Minimum Encoding Approaches for Predictive Modeling", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-183-192", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze differences between two information-theoretically motivated\napproaches to statistical inference and model selection: the Minimum\nDescription Length (MDL) principle, and the Minimum Message Length (MML)\nprinciple. Based on this analysis, we present two revised versions of MML: a\npointwise estimator which gives the MML-optimal single parameter model, and a\nvolumewise estimator which gives the MML-optimal region in the parameter space.\nOur empirical results suggest that with small data sets, the MDL approach\nyields more accurate predictions than the MML estimators. The empirical results\nalso demonstrate that the revised MML estimators introduced here perform better\nthan the original MML estimator suggested by Wallace and Freeman.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:02 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Grunwald", "Peter D", ""], ["Kontkanen", "Petri", ""], ["Myllymaki", "Petri", ""], ["Silander", "Tomi", ""], ["Tirri", "Henry", ""]]}, {"id": "1301.7390", "submitter": "Wenxin Jiang", "authors": "Wenxin Jiang, Martin A. Tanner", "title": "Hierarchical Mixtures-of-Experts for Exponential Family Regression\n  Models with Generalized Linear Mean Functions: A Survey of Approximation and\n  Consistency Results", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-296-303", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a class of hierarchical mixtures-of-experts (HME) models where\nexponential family regression models with generalized linear mean functions of\nthe form psi(ga+fx^Tfgb) are mixed. Here psi(...) is the inverse link function.\nSuppose the true response y follows an exponential family regression model with\nmean function belonging to a class of smooth functions of the form psi(h(fx))\nwhere h(...)in W_2^infty (a Sobolev class over [0,1]^{s}). It is shown that the\nHME probability density functions can approximate the true density, at a rate\nof O(m^{-2/s}) in L_p norm, and at a rate of O(m^{-4/s}) in Kullback-Leibler\ndivergence. These rates can be achieved within the family of HME structures\nwith no more than s-layers, where s is the dimension of the predictor fx. It is\nalso shown that likelihood-based inference based on HME is consistent in\nrecovering the truth, in the sense that as the sample size n and the number of\nexperts m both increase, the mean square error of the predicted mean response\ngoes to zero. Conditions for such results to hold are stated and discussed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:04:59 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Jiang", "Wenxin", ""], ["Tanner", "Martin A.", ""]]}, {"id": "1301.7392", "submitter": "Michael Kearns", "authors": "Michael Kearns, Lawrence Saul", "title": "Large Deviation Methods for Approximate Probabilistic Inference", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-311-319", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two-layer belief networks of binary random variables in which the\nconditional probabilities Pr[childlparents] depend monotonically on weighted\nsums of the parents. In large networks where exact probabilistic inference is\nintractable, we show how to compute upper and lower bounds on many\nprobabilities of interest. In particular, using methods from large deviation\ntheory, we derive rigorous bounds on marginal probabilities such as\nPr[children] and prove rates of convergence for the accuracy of our bounds as a\nfunction of network size. Our results apply to networks with generic transfer\nfunction parameterizations of the conditional probability tables, such as\nsigmoid and noisy-OR. They also explicitly illustrate the types of averaging\nbehavior that can simplify the problem of inference in large networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:09 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Kearns", "Michael", ""], ["Saul", "Lawrence", ""]]}, {"id": "1301.7393", "submitter": "Neil D. Lawrence", "authors": "Neil D. Lawrence, Christopher M. Bishop, Michael I. Jordan", "title": "Mixture Representations for Inference and Learning in Boltzmann Machines", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-320-327", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines are undirected graphical models with two-state stochastic\nvariables, in which the logarithms of the clique potentials are quadratic\nfunctions of the node states. They have been widely studied in the neural\ncomputing literature, although their practical applicability has been limited\nby the difficulty of finding an effective learning algorithm. One\nwell-established approach, known as mean field theory, represents the\nstochastic distribution using a factorized approximation. However, the\ncorresponding learning algorithm often fails to find a good solution. We\nconjecture that this is due to the implicit uni-modality of the mean field\napproximation which is therefore unable to capture multi-modality in the true\ndistribution. In this paper we use variational methods to approximate the\nstochastic distribution using multi-modal mixtures of factorized distributions.\nWe present results for both inference and learning to demonstrate the\neffectiveness of this approach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:15 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Lawrence", "Neil D.", ""], ["Bishop", "Christopher M.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1301.7401", "submitter": "Marina Meila", "authors": "Marina Meila, David Heckerman", "title": "An Experimental Comparison of Several Clustering and Initialization\n  Methods", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-386-395", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine methods for clustering in high dimensions. In the first part of\nthe paper, we perform an experimental comparison between three batch clustering\nalgorithms: the Expectation-Maximization (EM) algorithm, a winner take all\nversion of the EM algorithm reminiscent of the K-means algorithm, and\nmodel-based hierarchical agglomerative clustering. We learn naive-Bayes models\nwith a hidden root node, using high-dimensional discrete-variable data sets\n(both real and synthetic). We find that the EM algorithm significantly\noutperforms the other methods, and proceed to investigate the effect of various\ninitialization schemes on the final solution produced by the EM algorithm. The\ninitializations that we consider are (1) parameters sampled from an\nuninformative prior, (2) random perturbations of the marginal distribution of\nthe data, and (3) the output of hierarchical agglomerative clustering. Although\nthe methods are substantially different, they lead to learned models that are\nstrikingly similar in quality.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:05:55 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:17:06 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Meila", "Marina", ""], ["Heckerman", "David", ""]]}, {"id": "1301.7403", "submitter": "Stefano Monti", "authors": "Stefano Monti, Gregory F. Cooper", "title": "A Multivariate Discretization Method for Learning Bayesian Networks from\n  Mixed Data", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-404-413", "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of discretization in the context of\nlearning Bayesian networks (BNs) from data containing both continuous and\ndiscrete variables. We describe a new technique for <EM>multivariate</EM>\ndiscretization, whereby each continuous variable is discretized while taking\ninto account its interaction with the other variables. The technique is based\non the use of a Bayesian scoring metric that scores the discretization policy\nfor a continuous variable given a BN structure and the observed data. Since the\nmetric is relative to the BN structure currently being evaluated, the\ndiscretization of a variable needs to be dynamically adjusted as the BN\nstructure changes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:05 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Monti", "Stefano", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1301.7411", "submitter": "Raffaella Settimi", "authors": "Raffaella Settimi, Jim Q. Smith", "title": "On the Geometry of Bayesian Graphical Models with Hidden Variables", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-472-479", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the geometry of the likelihood of the unknown\nparameters in a simple class of Bayesian directed graphs with hidden variables.\nThis enables us, before any numerical algorithms are employed, to obtain\ncertain insights in the nature of the unidentifiability inherent in such\nmodels, the way posterior densities will be sensitive to prior densities and\nthe typical geometrical form these posterior densities might take. Many of\nthese insights carry over into more complicated Bayesian networks with\nsystematic missing data.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:06:43 GMT"}], "update_date": "2013-02-01", "authors_parsed": [["Settimi", "Raffaella", ""], ["Smith", "Jim Q.", ""]]}, {"id": "1301.7415", "submitter": "Bo Thiesson", "authors": "Bo Thiesson, Christopher Meek, David Maxwell Chickering, David\n  Heckerman", "title": "Learning Mixtures of DAG Models", "comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1998-PG-504-513", "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe computationally efficient methods for learning mixtures in which\neach component is a directed acyclic graphical model (mixtures of DAGs or\nMDAGs). We argue that simple search-and-score algorithms are infeasible for a\nvariety of problems, and introduce a feasible approach in which parameter and\nstructure search is interleaved and expected data is treated as real data. Our\napproach can be viewed as a combination of (1) the Cheeseman--Stutz asymptotic\napproximation for model posterior probability and (2) the\nExpectation--Maximization algorithm. We evaluate our procedure for selecting\namong MDAGs on synthetic and real examples.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 15:07:02 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 23:27:23 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Thiesson", "Bo", ""], ["Meek", "Christopher", ""], ["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""]]}, {"id": "1301.7473", "submitter": "Georg Martius", "authors": "Georg Martius, Ralf Der, Nihat Ay", "title": "Information driven self-organization of complex robotic behaviors", "comments": "29 pages, 12 figures", "journal-ref": "PLoS ONE 8(5): e63400", "doi": "10.1371/journal.pone.0063400", "report-no": null, "categories": "cs.RO cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Information theory is a powerful tool to express principles to drive\nautonomous systems because it is domain invariant and allows for an intuitive\ninterpretation. This paper studies the use of the predictive information (PI),\nalso called excess entropy or effective measure complexity, of the sensorimotor\nprocess as a driving force to generate behavior. We study nonlinear and\nnonstationary systems and introduce the time-local predicting information\n(TiPI) which allows us to derive exact results together with explicit update\nrules for the parameters of the controller in the dynamical systems framework.\nIn this way the information principle, formulated at the level of behavior, is\ntranslated to the dynamics of the synapses. We underpin our results with a\nnumber of case studies with high-dimensional robotic systems. We show the\nspontaneous cooperativity in a complex physical system with decentralized\ncontrol. Moreover, a jointly controlled humanoid robot develops a high\nbehavioral variety depending on its physics and the environment it is\ndynamically embedded into. The behavior can be decomposed into a succession of\nlow-dimensional modes that increasingly explore the behavior space. This is a\npromising way to avoid the curse of dimensionality which hinders learning\nsystems to scale well.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2013 23:44:25 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2013 21:22:18 GMT"}], "update_date": "2013-07-19", "authors_parsed": [["Martius", "Georg", ""], ["Der", "Ralf", ""], ["Ay", "Nihat", ""]]}, {"id": "1301.7619", "submitter": "Gonzalo Mateos", "authors": "Juan Andres Bazerque, Gonzalo Mateos, and Georgios B. Giannakis", "title": "Rank regularization and Bayesian inference for tensor completion and\n  extrapolation", "comments": "12 pages, submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2013.2278516", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel regularizer of the PARAFAC decomposition factors capturing the\ntensor's rank is proposed in this paper, as the key enabler for completion of\nthree-way data arrays with missing entries. Set in a Bayesian framework, the\ntensor completion method incorporates prior information to enhance its\nsmoothing and prediction capabilities. This probabilistic approach can\nnaturally accommodate general models for the data distribution, lending itself\nto various fitting criteria that yield optimum estimates in the\nmaximum-a-posteriori sense. In particular, two algorithms are devised for\nGaussian- and Poisson-distributed data, that minimize the rank-regularized\nleast-squares error and Kullback-Leibler divergence, respectively. The proposed\ntechnique is able to recover the \"ground-truth'' tensor rank when tested on\nsynthetic data, and to complete brain imaging and yeast gene expression\ndatasets with 50% and 15% of missing entries respectively, resulting in\nrecovery errors at -10dB and -15dB.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 14:17:28 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Bazerque", "Juan Andres", ""], ["Mateos", "Gonzalo", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1301.7724", "submitter": "Santiago Segarra", "authors": "Gunnar Carlsson, Facundo M\\'emoli, Alejandro Ribeiro and Santiago\n  Segarra", "title": "Axiomatic Construction of Hierarchical Clustering in Asymmetric Networks", "comments": "This is a largely extended version of the previous conference\n  submission under the same title. The current version contains the material in\n  the previous version (published in ICASSP 2013) as well as material presented\n  at the Asilomar Conference on Signal, Systems, and Computers 2013, GlobalSIP\n  2013, and ICML 2014. Also, unpublished material is included in the current\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers networks where relationships between nodes are\nrepresented by directed dissimilarities. The goal is to study methods for the\ndetermination of hierarchical clusters, i.e., a family of nested partitions\nindexed by a connectivity parameter, induced by the given dissimilarity\nstructures. Our construction of hierarchical clustering methods is based on\ndefining admissible methods to be those methods that abide by the axioms of\nvalue - nodes in a network with two nodes are clustered together at the maximum\nof the two dissimilarities between them - and transformation - when\ndissimilarities are reduced, the network may become more clustered but not\nless. Several admissible methods are constructed and two particular methods,\ntermed reciprocal and nonreciprocal clustering, are shown to provide upper and\nlower bounds in the space of admissible methods. Alternative clustering\nmethodologies and axioms are further considered. Allowing the outcome of\nhierarchical clustering to be asymmetric, so that it matches the asymmetry of\nthe original data, leads to the inception of quasi-clustering methods. The\nexistence of a unique quasi-clustering method is shown. Allowing clustering in\na two-node network to proceed at the minimum of the two dissimilarities\ngenerates an alternative axiomatic construction. There is a unique clustering\nmethod in this case too. The paper also develops algorithms for the computation\nof hierarchical clusters using matrix powers on a min-max dioid algebra and\nstudies the stability of the methods proposed. We proved that most of the\nmethods introduced in this paper are such that similar networks yield similar\nhierarchical clustering results. Algorithms are exemplified through their\napplication to networks describing internal migration within states of the\nUnited States (U.S.) and the interrelation between sectors of the U.S. economy.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2013 19:39:03 GMT"}, {"version": "v2", "created": "Tue, 2 Sep 2014 18:21:18 GMT"}], "update_date": "2014-09-03", "authors_parsed": [["Carlsson", "Gunnar", ""], ["M\u00e9moli", "Facundo", ""], ["Ribeiro", "Alejandro", ""], ["Segarra", "Santiago", ""]]}]